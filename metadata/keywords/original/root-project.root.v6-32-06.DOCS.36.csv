id,quality_attribute,keyword,matched_word,match_idx,sentence,source,filename,author,repo,version,wiki,url
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v522/index.html:4735,Testability,log,log,4735," TProof::AddInputData(TObject *); if the input-data objects are in a; file you can use TProof::SetInputDataFile(const char *file); the final; set of input-data objects is assembled from the objects added via; AddInputData and those found in the file defined bySetInputDataFile.  . Improvements:. More; complete set of tests in test/stressProof . To run with PROOF-Lite pass; the argument 'lite' as master URL, e.g. './stressProof lite'.Possibility; to control on the client via rc variable the location of the sandbox,; package directory, cache and dataset directory (the latters two only; for PROOF-Lite); the variable names are 'Proof.Sandbox', ; 'Proof.PackageDir', 'Proof.CacheDir' and 'Proof.DataSetDir'. The default location of the sandbox has been changed from ""~/proof"" to ""~/.proof"" to avoid interferences with possible users' working areas.XrdProofd plug-in. Overall refactorization for easier; maintainance and improved solidity; Improved format of printout messages: all information; messages contain now the tag 'xpd-I' and all error messages the; tag 'xpd-E', so that they can easily be grepped out from the; log file.; . Log sending. Implement selective sending of logs from workers to master to avoid duplicating; too many text lines on the master log. Logs are now sent only after Exec, Print; requests and in case an error (level >= kError) occured. Of course, the full; logs can always be retrieved via TProofMgr::GetSessionLogs; . Log retrieval:. for 'grep' operations, use the system 'grep' command; via 'popen'; instead of a handmade filtering; this implies that the full grep; functionality is now available; set the default number of displayed lines to 100; instead of 10. Improve diagnostic in case of worker death: clients will; now; receive a message containing the low level reason for the failure and a; hint for getting more informationIn; TProofOutputFile, support the ""<user>"" and ""<group>""; placeholders in the output file name to automatically re-direct the; output ",MatchSource.DOCS,proof/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v522/index.html:4792,Testability,log,logs,4792," AddInputData and those found in the file defined bySetInputDataFile.  . Improvements:. More; complete set of tests in test/stressProof . To run with PROOF-Lite pass; the argument 'lite' as master URL, e.g. './stressProof lite'.Possibility; to control on the client via rc variable the location of the sandbox,; package directory, cache and dataset directory (the latters two only; for PROOF-Lite); the variable names are 'Proof.Sandbox', ; 'Proof.PackageDir', 'Proof.CacheDir' and 'Proof.DataSetDir'. The default location of the sandbox has been changed from ""~/proof"" to ""~/.proof"" to avoid interferences with possible users' working areas.XrdProofd plug-in. Overall refactorization for easier; maintainance and improved solidity; Improved format of printout messages: all information; messages contain now the tag 'xpd-I' and all error messages the; tag 'xpd-E', so that they can easily be grepped out from the; log file.; . Log sending. Implement selective sending of logs from workers to master to avoid duplicating; too many text lines on the master log. Logs are now sent only after Exec, Print; requests and in case an error (level >= kError) occured. Of course, the full; logs can always be retrieved via TProofMgr::GetSessionLogs; . Log retrieval:. for 'grep' operations, use the system 'grep' command; via 'popen'; instead of a handmade filtering; this implies that the full grep; functionality is now available; set the default number of displayed lines to 100; instead of 10. Improve diagnostic in case of worker death: clients will; now; receive a message containing the low level reason for the failure and a; hint for getting more informationIn; TProofOutputFile, support the ""<user>"" and ""<group>""; placeholders in the output file name to automatically re-direct the; output to an area specific to the logged user.; Addition of a new class TProofProgressStatus, which is used to keep; the query progress stauts in all the TProofPlayer objects and in the; TPacketizerAdaptive. It is a",MatchSource.DOCS,proof/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v522/index.html:4876,Testability,log,log,4876," AddInputData and those found in the file defined bySetInputDataFile.  . Improvements:. More; complete set of tests in test/stressProof . To run with PROOF-Lite pass; the argument 'lite' as master URL, e.g. './stressProof lite'.Possibility; to control on the client via rc variable the location of the sandbox,; package directory, cache and dataset directory (the latters two only; for PROOF-Lite); the variable names are 'Proof.Sandbox', ; 'Proof.PackageDir', 'Proof.CacheDir' and 'Proof.DataSetDir'. The default location of the sandbox has been changed from ""~/proof"" to ""~/.proof"" to avoid interferences with possible users' working areas.XrdProofd plug-in. Overall refactorization for easier; maintainance and improved solidity; Improved format of printout messages: all information; messages contain now the tag 'xpd-I' and all error messages the; tag 'xpd-E', so that they can easily be grepped out from the; log file.; . Log sending. Implement selective sending of logs from workers to master to avoid duplicating; too many text lines on the master log. Logs are now sent only after Exec, Print; requests and in case an error (level >= kError) occured. Of course, the full; logs can always be retrieved via TProofMgr::GetSessionLogs; . Log retrieval:. for 'grep' operations, use the system 'grep' command; via 'popen'; instead of a handmade filtering; this implies that the full grep; functionality is now available; set the default number of displayed lines to 100; instead of 10. Improve diagnostic in case of worker death: clients will; now; receive a message containing the low level reason for the failure and a; hint for getting more informationIn; TProofOutputFile, support the ""<user>"" and ""<group>""; placeholders in the output file name to automatically re-direct the; output to an area specific to the logged user.; Addition of a new class TProofProgressStatus, which is used to keep; the query progress stauts in all the TProofPlayer objects and in the; TPacketizerAdaptive. It is a",MatchSource.DOCS,proof/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v522/index.html:5001,Testability,log,logs,5001,", e.g. './stressProof lite'.Possibility; to control on the client via rc variable the location of the sandbox,; package directory, cache and dataset directory (the latters two only; for PROOF-Lite); the variable names are 'Proof.Sandbox', ; 'Proof.PackageDir', 'Proof.CacheDir' and 'Proof.DataSetDir'. The default location of the sandbox has been changed from ""~/proof"" to ""~/.proof"" to avoid interferences with possible users' working areas.XrdProofd plug-in. Overall refactorization for easier; maintainance and improved solidity; Improved format of printout messages: all information; messages contain now the tag 'xpd-I' and all error messages the; tag 'xpd-E', so that they can easily be grepped out from the; log file.; . Log sending. Implement selective sending of logs from workers to master to avoid duplicating; too many text lines on the master log. Logs are now sent only after Exec, Print; requests and in case an error (level >= kError) occured. Of course, the full; logs can always be retrieved via TProofMgr::GetSessionLogs; . Log retrieval:. for 'grep' operations, use the system 'grep' command; via 'popen'; instead of a handmade filtering; this implies that the full grep; functionality is now available; set the default number of displayed lines to 100; instead of 10. Improve diagnostic in case of worker death: clients will; now; receive a message containing the low level reason for the failure and a; hint for getting more informationIn; TProofOutputFile, support the ""<user>"" and ""<group>""; placeholders in the output file name to automatically re-direct the; output to an area specific to the logged user.; Addition of a new class TProofProgressStatus, which is used to keep; the query progress stauts in all the TProofPlayer objects and in the; TPacketizerAdaptive. It is also send in kPROOF_GETPACKET and; kPROOF_STOPPROCESS messages. ; The class TPacketizerProgressive is removed. . Fixes. Enable; the max number of sessions ('mxsess' parameter in the xpd.schedparam; dire",MatchSource.DOCS,proof/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v522/index.html:5639,Testability,log,logged,5639,". Overall refactorization for easier; maintainance and improved solidity; Improved format of printout messages: all information; messages contain now the tag 'xpd-I' and all error messages the; tag 'xpd-E', so that they can easily be grepped out from the; log file.; . Log sending. Implement selective sending of logs from workers to master to avoid duplicating; too many text lines on the master log. Logs are now sent only after Exec, Print; requests and in case an error (level >= kError) occured. Of course, the full; logs can always be retrieved via TProofMgr::GetSessionLogs; . Log retrieval:. for 'grep' operations, use the system 'grep' command; via 'popen'; instead of a handmade filtering; this implies that the full grep; functionality is now available; set the default number of displayed lines to 100; instead of 10. Improve diagnostic in case of worker death: clients will; now; receive a message containing the low level reason for the failure and a; hint for getting more informationIn; TProofOutputFile, support the ""<user>"" and ""<group>""; placeholders in the output file name to automatically re-direct the; output to an area specific to the logged user.; Addition of a new class TProofProgressStatus, which is used to keep; the query progress stauts in all the TProofPlayer objects and in the; TPacketizerAdaptive. It is also send in kPROOF_GETPACKET and; kPROOF_STOPPROCESS messages. ; The class TPacketizerProgressive is removed. . Fixes. Enable; the max number of sessions ('mxsess' parameter in the xpd.schedparam; directive); users are just refused to start a session if this limit is; reached.Make sure to collect consistently input messages when running in asynchronous modeFix; a few problems with TProof::SendFile (used by UploadPackage, Load); appearing when a rapid sequence of these commands was submitted Invalidate the TProofMgr when the physical connection is; closed; avoids; crashing when trying to get the logs after a failure. ; Fix a memory leak in log retrieval",MatchSource.DOCS,proof/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v522/index.html:6422,Testability,log,logs,6422,"displayed lines to 100; instead of 10. Improve diagnostic in case of worker death: clients will; now; receive a message containing the low level reason for the failure and a; hint for getting more informationIn; TProofOutputFile, support the ""<user>"" and ""<group>""; placeholders in the output file name to automatically re-direct the; output to an area specific to the logged user.; Addition of a new class TProofProgressStatus, which is used to keep; the query progress stauts in all the TProofPlayer objects and in the; TPacketizerAdaptive. It is also send in kPROOF_GETPACKET and; kPROOF_STOPPROCESS messages. ; The class TPacketizerProgressive is removed. . Fixes. Enable; the max number of sessions ('mxsess' parameter in the xpd.schedparam; directive); users are just refused to start a session if this limit is; reached.Make sure to collect consistently input messages when running in asynchronous modeFix; a few problems with TProof::SendFile (used by UploadPackage, Load); appearing when a rapid sequence of these commands was submitted Invalidate the TProofMgr when the physical connection is; closed; avoids; crashing when trying to get the logs after a failure. ; Fix a memory leak in log retrieval (the TProofLog object; was never; deleted); Add protections for the cases the manager cannot be; initialized; Fix a race condition possibly affecting the handling of; workers death; Avoid duplicating worker logs in the master log file; unless; when explicitly needed by the request (Exec(...), Print(...)) or when; an error occuredFix; problem with the determination and transmission of the name of the; object to be processed. The problem appeared when processing files; containing >1 trees in changing order.Fix problem with TProof::Load loading the macro to one worker only per machineFix wrong return code preventing the correct propagation of the full ClearPackage to workersFix a problem causing the whole query to stop even in the case a worker was terminated gently with SIGTERM.; ",MatchSource.DOCS,proof/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v522/index.html:6467,Testability,log,log,6467,"t the; output to an area specific to the logged user.; Addition of a new class TProofProgressStatus, which is used to keep; the query progress stauts in all the TProofPlayer objects and in the; TPacketizerAdaptive. It is also send in kPROOF_GETPACKET and; kPROOF_STOPPROCESS messages. ; The class TPacketizerProgressive is removed. . Fixes. Enable; the max number of sessions ('mxsess' parameter in the xpd.schedparam; directive); users are just refused to start a session if this limit is; reached.Make sure to collect consistently input messages when running in asynchronous modeFix; a few problems with TProof::SendFile (used by UploadPackage, Load); appearing when a rapid sequence of these commands was submitted Invalidate the TProofMgr when the physical connection is; closed; avoids; crashing when trying to get the logs after a failure. ; Fix a memory leak in log retrieval (the TProofLog object; was never; deleted); Add protections for the cases the manager cannot be; initialized; Fix a race condition possibly affecting the handling of; workers death; Avoid duplicating worker logs in the master log file; unless; when explicitly needed by the request (Exec(...), Print(...)) or when; an error occuredFix; problem with the determination and transmission of the name of the; object to be processed. The problem appeared when processing files; containing >1 trees in changing order.Fix problem with TProof::Load loading the macro to one worker only per machineFix wrong return code preventing the correct propagation of the full ClearPackage to workersFix a problem causing the whole query to stop even in the case a worker was terminated gently with SIGTERM.; Fix a problem triggering full re-build of a package upon change of a; single file; the version info file was wrongly reset; this should; happen only after a re-build.Make sure that in case multiple TProofOutputFile are present, each get merged correctlyFix problem in TProofServLogHandler::Notify due to bad usage of Form(...). ",MatchSource.DOCS,proof/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v522/index.html:6688,Testability,log,logs,6688,"t the; output to an area specific to the logged user.; Addition of a new class TProofProgressStatus, which is used to keep; the query progress stauts in all the TProofPlayer objects and in the; TPacketizerAdaptive. It is also send in kPROOF_GETPACKET and; kPROOF_STOPPROCESS messages. ; The class TPacketizerProgressive is removed. . Fixes. Enable; the max number of sessions ('mxsess' parameter in the xpd.schedparam; directive); users are just refused to start a session if this limit is; reached.Make sure to collect consistently input messages when running in asynchronous modeFix; a few problems with TProof::SendFile (used by UploadPackage, Load); appearing when a rapid sequence of these commands was submitted Invalidate the TProofMgr when the physical connection is; closed; avoids; crashing when trying to get the logs after a failure. ; Fix a memory leak in log retrieval (the TProofLog object; was never; deleted); Add protections for the cases the manager cannot be; initialized; Fix a race condition possibly affecting the handling of; workers death; Avoid duplicating worker logs in the master log file; unless; when explicitly needed by the request (Exec(...), Print(...)) or when; an error occuredFix; problem with the determination and transmission of the name of the; object to be processed. The problem appeared when processing files; containing >1 trees in changing order.Fix problem with TProof::Load loading the macro to one worker only per machineFix wrong return code preventing the correct propagation of the full ClearPackage to workersFix a problem causing the whole query to stop even in the case a worker was terminated gently with SIGTERM.; Fix a problem triggering full re-build of a package upon change of a; single file; the version info file was wrongly reset; this should; happen only after a re-build.Make sure that in case multiple TProofOutputFile are present, each get merged correctlyFix problem in TProofServLogHandler::Notify due to bad usage of Form(...). ",MatchSource.DOCS,proof/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v522/index.html:6707,Testability,log,log,6707,"t the; output to an area specific to the logged user.; Addition of a new class TProofProgressStatus, which is used to keep; the query progress stauts in all the TProofPlayer objects and in the; TPacketizerAdaptive. It is also send in kPROOF_GETPACKET and; kPROOF_STOPPROCESS messages. ; The class TPacketizerProgressive is removed. . Fixes. Enable; the max number of sessions ('mxsess' parameter in the xpd.schedparam; directive); users are just refused to start a session if this limit is; reached.Make sure to collect consistently input messages when running in asynchronous modeFix; a few problems with TProof::SendFile (used by UploadPackage, Load); appearing when a rapid sequence of these commands was submitted Invalidate the TProofMgr when the physical connection is; closed; avoids; crashing when trying to get the logs after a failure. ; Fix a memory leak in log retrieval (the TProofLog object; was never; deleted); Add protections for the cases the manager cannot be; initialized; Fix a race condition possibly affecting the handling of; workers death; Avoid duplicating worker logs in the master log file; unless; when explicitly needed by the request (Exec(...), Print(...)) or when; an error occuredFix; problem with the determination and transmission of the name of the; object to be processed. The problem appeared when processing files; containing >1 trees in changing order.Fix problem with TProof::Load loading the macro to one worker only per machineFix wrong return code preventing the correct propagation of the full ClearPackage to workersFix a problem causing the whole query to stop even in the case a worker was terminated gently with SIGTERM.; Fix a problem triggering full re-build of a package upon change of a; single file; the version info file was wrongly reset; this should; happen only after a re-build.Make sure that in case multiple TProofOutputFile are present, each get merged correctlyFix problem in TProofServLogHandler::Notify due to bad usage of Form(...). ",MatchSource.DOCS,proof/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:3396,Availability,failure,failure,3396,"tives specified via 'xpd.putenv'; Add the configuration directive 'proofservparents' to; allow specifying a different list of parent names for the 'proofserv'; tasks. This is needed to avoid untimely killing of 'proofserv'; instances in test setups when multiple instances of the daemons are; running on the same machines under different names.; Add the possibility to switch to asynchronous mode while; running synchronously. A new button ""Run; in background"" has been added; to the dialog box. The behaviour of Ctrl-C has also been modified: the; user is prompted for a choice among continuing asynchronously, stopping; (terminating) or aborting the query.; Add the possibility to define the dataset information; sources via the directive 'xpd.datasetsrc'.; In this way the permissions; should be set correctly and the related problems disappear.; Record the logs from the ROOT version validation tests; (proofserv forked in test mode). In case of failure - or if the debug; flag is on - the log files are kept under; <xproof_adminpath>/rootsysvalidation/root.<tag>.log; (the <tag> has all the '/' replaced by '-'). This should; facilitate understanding the problems when in case of validation; failures.; Add support for automatic; running of PROOF sessions in valgrind. The second; argument of TProof::Open is used to trigger the relevant; settings. To valgrind the master session start PROOF; with TProof::Open(""<master>"",""valgrind=master"");; to valgrind two workers sessions use; TProof::Open(""<master>"",""valgrind=workers""); to valgrind; master and 2 workers, use; TProof::Open(""<master>"",""valgrind=master+workers""). Other; combinations are available. ; The valgrind logs are available with the tag; '<ordinal>-valgrind' in the log dialog or form; TProofMgr::GetSessionLogs() .; To add options to valgrind execute; TProof::AddEnvVar(""PROOF_WRAPPERCMD"",; ""valgrind_opts:<options>"") before starting the; session. ; Add new static TProof::LogViewer(""<master>""); to graphically browse the session l",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:3643,Availability,failure,failures,3643,"asks. This is needed to avoid untimely killing of 'proofserv'; instances in test setups when multiple instances of the daemons are; running on the same machines under different names.; Add the possibility to switch to asynchronous mode while; running synchronously. A new button ""Run; in background"" has been added; to the dialog box. The behaviour of Ctrl-C has also been modified: the; user is prompted for a choice among continuing asynchronously, stopping; (terminating) or aborting the query.; Add the possibility to define the dataset information; sources via the directive 'xpd.datasetsrc'.; In this way the permissions; should be set correctly and the related problems disappear.; Record the logs from the ROOT version validation tests; (proofserv forked in test mode). In case of failure - or if the debug; flag is on - the log files are kept under; <xproof_adminpath>/rootsysvalidation/root.<tag>.log; (the <tag> has all the '/' replaced by '-'). This should; facilitate understanding the problems when in case of validation; failures.; Add support for automatic; running of PROOF sessions in valgrind. The second; argument of TProof::Open is used to trigger the relevant; settings. To valgrind the master session start PROOF; with TProof::Open(""<master>"",""valgrind=master"");; to valgrind two workers sessions use; TProof::Open(""<master>"",""valgrind=workers""); to valgrind; master and 2 workers, use; TProof::Open(""<master>"",""valgrind=master+workers""). Other; combinations are available. ; The valgrind logs are available with the tag; '<ordinal>-valgrind' in the log dialog or form; TProofMgr::GetSessionLogs() .; To add options to valgrind execute; TProof::AddEnvVar(""PROOF_WRAPPERCMD"",; ""valgrind_opts:<options>"") before starting the; session. ; Add new static TProof::LogViewer(""<master>""); to graphically browse the session logs independently of the progress; dialog. The improved log window allows to chose a different master; and/or session  and displays human readable information abo",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:4093,Availability,avail,available,4093,"aborting the query.; Add the possibility to define the dataset information; sources via the directive 'xpd.datasetsrc'.; In this way the permissions; should be set correctly and the related problems disappear.; Record the logs from the ROOT version validation tests; (proofserv forked in test mode). In case of failure - or if the debug; flag is on - the log files are kept under; <xproof_adminpath>/rootsysvalidation/root.<tag>.log; (the <tag> has all the '/' replaced by '-'). This should; facilitate understanding the problems when in case of validation; failures.; Add support for automatic; running of PROOF sessions in valgrind. The second; argument of TProof::Open is used to trigger the relevant; settings. To valgrind the master session start PROOF; with TProof::Open(""<master>"",""valgrind=master"");; to valgrind two workers sessions use; TProof::Open(""<master>"",""valgrind=workers""); to valgrind; master and 2 workers, use; TProof::Open(""<master>"",""valgrind=master+workers""). Other; combinations are available. ; The valgrind logs are available with the tag; '<ordinal>-valgrind' in the log dialog or form; TProofMgr::GetSessionLogs() .; To add options to valgrind execute; TProof::AddEnvVar(""PROOF_WRAPPERCMD"",; ""valgrind_opts:<options>"") before starting the; session. ; Add new static TProof::LogViewer(""<master>""); to graphically browse the session logs independently of the progress; dialog. The improved log window allows to chose a different master; and/or session  and displays human readable information about; the starting time of the session being browsed.; A set of scripts for quick interaction with a dataset; manager via PROOF are available under $ROOTSYS/etc/proof/utils/pq2 .; The scripts are prefixed; pq2 (proof; quick query - or; proof-dq2); and allow to {browse, register, remove, verify} datasets on a given; PROOF master. See $ROOTSYS/etc/proof/utils/pq2/README for more; information. Improvements. Enable by default schema evolution in TMessage; can be; disabled setting",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:4128,Availability,avail,available,4128,"es via the directive 'xpd.datasetsrc'.; In this way the permissions; should be set correctly and the related problems disappear.; Record the logs from the ROOT version validation tests; (proofserv forked in test mode). In case of failure - or if the debug; flag is on - the log files are kept under; <xproof_adminpath>/rootsysvalidation/root.<tag>.log; (the <tag> has all the '/' replaced by '-'). This should; facilitate understanding the problems when in case of validation; failures.; Add support for automatic; running of PROOF sessions in valgrind. The second; argument of TProof::Open is used to trigger the relevant; settings. To valgrind the master session start PROOF; with TProof::Open(""<master>"",""valgrind=master"");; to valgrind two workers sessions use; TProof::Open(""<master>"",""valgrind=workers""); to valgrind; master and 2 workers, use; TProof::Open(""<master>"",""valgrind=master+workers""). Other; combinations are available. ; The valgrind logs are available with the tag; '<ordinal>-valgrind' in the log dialog or form; TProofMgr::GetSessionLogs() .; To add options to valgrind execute; TProof::AddEnvVar(""PROOF_WRAPPERCMD"",; ""valgrind_opts:<options>"") before starting the; session. ; Add new static TProof::LogViewer(""<master>""); to graphically browse the session logs independently of the progress; dialog. The improved log window allows to chose a different master; and/or session  and displays human readable information about; the starting time of the session being browsed.; A set of scripts for quick interaction with a dataset; manager via PROOF are available under $ROOTSYS/etc/proof/utils/pq2 .; The scripts are prefixed; pq2 (proof; quick query - or; proof-dq2); and allow to {browse, register, remove, verify} datasets on a given; PROOF master. See $ROOTSYS/etc/proof/utils/pq2/README for more; information. Improvements. Enable by default schema evolution in TMessage; can be; disabled setting 'Proof.SchemaEvolution:; 0' .; Extend the functionality of the dataset API to o",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:4738,Availability,avail,available,4738,"he second; argument of TProof::Open is used to trigger the relevant; settings. To valgrind the master session start PROOF; with TProof::Open(""<master>"",""valgrind=master"");; to valgrind two workers sessions use; TProof::Open(""<master>"",""valgrind=workers""); to valgrind; master and 2 workers, use; TProof::Open(""<master>"",""valgrind=master+workers""). Other; combinations are available. ; The valgrind logs are available with the tag; '<ordinal>-valgrind' in the log dialog or form; TProofMgr::GetSessionLogs() .; To add options to valgrind execute; TProof::AddEnvVar(""PROOF_WRAPPERCMD"",; ""valgrind_opts:<options>"") before starting the; session. ; Add new static TProof::LogViewer(""<master>""); to graphically browse the session logs independently of the progress; dialog. The improved log window allows to chose a different master; and/or session  and displays human readable information about; the starting time of the session being browsed.; A set of scripts for quick interaction with a dataset; manager via PROOF are available under $ROOTSYS/etc/proof/utils/pq2 .; The scripts are prefixed; pq2 (proof; quick query - or; proof-dq2); and allow to {browse, register, remove, verify} datasets on a given; PROOF master. See $ROOTSYS/etc/proof/utils/pq2/README for more; information. Improvements. Enable by default schema evolution in TMessage; can be; disabled setting 'Proof.SchemaEvolution:; 0' .; Extend the functionality of the dataset API to obtaine; information on per-server base; add also two new methods:. TProof::SetDataSetTreeName(<dataset>,<treename>):; set/change the default tree name in the TFileCollection;; TProof::ExistsDataSet(<dataset>):; check; by-name the availability of a given dataset;. In ProofBench, . Load the macro before executing it. This allows to; circumvent a problem recently fixed giving less dependency on the; server version.; In make_dset.C, simplification of the body and of the; signature, eliminating one redundant argument. In TProofOutputFile, improve flexibil",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:5396,Availability,avail,availability,5396,""") before starting the; session. ; Add new static TProof::LogViewer(""<master>""); to graphically browse the session logs independently of the progress; dialog. The improved log window allows to chose a different master; and/or session  and displays human readable information about; the starting time of the session being browsed.; A set of scripts for quick interaction with a dataset; manager via PROOF are available under $ROOTSYS/etc/proof/utils/pq2 .; The scripts are prefixed; pq2 (proof; quick query - or; proof-dq2); and allow to {browse, register, remove, verify} datasets on a given; PROOF master. See $ROOTSYS/etc/proof/utils/pq2/README for more; information. Improvements. Enable by default schema evolution in TMessage; can be; disabled setting 'Proof.SchemaEvolution:; 0' .; Extend the functionality of the dataset API to obtaine; information on per-server base; add also two new methods:. TProof::SetDataSetTreeName(<dataset>,<treename>):; set/change the default tree name in the TFileCollection;; TProof::ExistsDataSet(<dataset>):; check; by-name the availability of a given dataset;. In ProofBench, . Load the macro before executing it. This allows to; circumvent a problem recently fixed giving less dependency on the; server version.; In make_dset.C, simplification of the body and of the; signature, eliminating one redundant argument. In TProofOutputFile, improve flexibility in defining the; URL for the local files server. The ""LOCALDATASERVER"" env is tested,; which can defined with placeholders via the xpd.putenv directive in the; xrootd/xproofd config files.; Improving parsing of lines with memory info.; This solves occasional crashes while generating the memory; plots.; In TProofMgr::GetSessionLogs:. add the possibility to postpone the retrieval of the; logs files when the TProofLog object is created. This improved; functionality is exploited in the log window.; add decoding of the session starting time and full; information about the master URL. Enable new xrootd c",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:5665,Availability,redundant,redundant,5665,"sion being browsed.; A set of scripts for quick interaction with a dataset; manager via PROOF are available under $ROOTSYS/etc/proof/utils/pq2 .; The scripts are prefixed; pq2 (proof; quick query - or; proof-dq2); and allow to {browse, register, remove, verify} datasets on a given; PROOF master. See $ROOTSYS/etc/proof/utils/pq2/README for more; information. Improvements. Enable by default schema evolution in TMessage; can be; disabled setting 'Proof.SchemaEvolution:; 0' .; Extend the functionality of the dataset API to obtaine; information on per-server base; add also two new methods:. TProof::SetDataSetTreeName(<dataset>,<treename>):; set/change the default tree name in the TFileCollection;; TProof::ExistsDataSet(<dataset>):; check; by-name the availability of a given dataset;. In ProofBench, . Load the macro before executing it. This allows to; circumvent a problem recently fixed giving less dependency on the; server version.; In make_dset.C, simplification of the body and of the; signature, eliminating one redundant argument. In TProofOutputFile, improve flexibility in defining the; URL for the local files server. The ""LOCALDATASERVER"" env is tested,; which can defined with placeholders via the xpd.putenv directive in the; xrootd/xproofd config files.; Improving parsing of lines with memory info.; This solves occasional crashes while generating the memory; plots.; In TProofMgr::GetSessionLogs:. add the possibility to postpone the retrieval of the; logs files when the TProofLog object is created. This improved; functionality is exploited in the log window.; add decoding of the session starting time and full; information about the master URL. Enable new xrootd configuration options, including the; possibility to set the compiler and linker; Cleanup of the TProofMgr functions DetachSession and; ShutdownSession, and better handling of the internal list registration,; to fix potential segvs when reopening a PROOF session inside the same; ROOT session.; Optimize the wa",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:9684,Availability,error,error,9684,"as de facto disactivating the cache; the; other was causing a std::bad_alloc exception to be thrown on workers; when opening a remote file after a local one.    ; Fix several problems in TChain::Draw including. drawing into an existing histogram, i.e.; chain->Draw(""var>>myhist"");. treatment of histogram merging in case of small; statistics, i.e. when; the autobinning is not or only partially active;. usage of existing canvases when different histogram; names are specified;. Fix a problem causing a duplication of the final feedback; object. Fix problem with determining the subdir name in; TFileMerger::MergeRecursive on Windows; Make sure that the default sandbox is under $HOME/.proof; Fix a problem with dataset validation in multi-level; master setups; Fix a problem with ordinal numbers in multi-master setups; Fix a problem with defining the internal paths for; executables when configuring with '--prefix'; Fix backward-incompatibility issue giving the error; message  ""unknown action code: 5112""; Fix a few problems with file retrieval from the cache; Fix a problem with iteration of a std::list occasionally; causing seg-violations in TXSocket; Fix a few problems preventing correct usage of entry; lists in PROOF; Fix a problem with the permissions of the credentials; files created under <sandbox>/.creds; Fix a potential problem while determining the log paths; in log retrieval. Do not use vnsprintf in the XrdProofd plug-in, potential; source of deadlocks.; Fix a problem overwriting the local environment settings; for the xrootd sec modules; In XrdProofdProofServMgr::Destroy, fix segv in message; creation when all sessions are destroyed at once; Fix a problem determining the relative time order of old; sessions for log retrieval; In TProof::HandleInputMessage, fix possible double delete; after kPROOF_STOPPROCESS; Fix a couple of issues on reconnection to a running; session (some dialog buttons not in the correct state; logs not; correctly redirected); Fix a problem creati",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:1823,Deployability,configurat,configuration,1823,"ere is a; rotation among queued; sessions. In the case of load-based worker assignment, the max number; of running; queries is determined dynamically.; Add support for repeat functionality in the xrd.worker; directive. To avoid repeating the same line N times; one can just add; 'repeat=N'; in the line; for; example;            ;     xpd.worker worker; proofwrks:2093 repeat=4; will define 4 workers on port 2093 of machine 'proofwrks'.; Add support for port specification via the directive; 'xpd.port'; Enable variable; substitution in 'xpd.' directives using the standard; Scalla mechanism described in; http://xrootd.slac.stanford.edu/doc/dev/Syntax_config.htm .; Build also a binary named 'xproofd' which runs; a xrootd; daemon with only the XrdProofdProtocol (i.e. no data serving).; This simplifies setups when data serving is not needed and also allows; to better disantagle problems related to one specific protocol. The new; binary accepts the same arguments as 'xrootd' and parses the same; directives form the same configuration file, with the exception of; 'xpd.protocol xproofd libXrdProofd.so' which should now be dropped. AN; alternative port can be specified via the new 'xpd.port' directive (see; above).; Add support for 'MasterOnly' mode in starting a PROOF; session. This avoids starting the workers when one wants just to browse; the datasets or retrieve results. To start a session in 'MasterOnly'; mode enter ""masteronly""; as second argument to TProof::Open, e.g.;  ;          root[]; TProof *p = TProof::Open(""<masterurl>"", ""masteronly""); Add full support for placeholders; <uid>,; <gid>, <group> and <homedir>; for the directives specified via 'xpd.putenv'; Add the configuration directive 'proofservparents' to; allow specifying a different list of parent names for the 'proofserv'; tasks. This is needed to avoid untimely killing of 'proofserv'; instances in test setups when multiple instances of the daemons are; running on the same machines under different names.; Add ",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:2488,Deployability,configurat,configuration,2488,"e XrdProofdProtocol (i.e. no data serving).; This simplifies setups when data serving is not needed and also allows; to better disantagle problems related to one specific protocol. The new; binary accepts the same arguments as 'xrootd' and parses the same; directives form the same configuration file, with the exception of; 'xpd.protocol xproofd libXrdProofd.so' which should now be dropped. AN; alternative port can be specified via the new 'xpd.port' directive (see; above).; Add support for 'MasterOnly' mode in starting a PROOF; session. This avoids starting the workers when one wants just to browse; the datasets or retrieve results. To start a session in 'MasterOnly'; mode enter ""masteronly""; as second argument to TProof::Open, e.g.;  ;          root[]; TProof *p = TProof::Open(""<masterurl>"", ""masteronly""); Add full support for placeholders; <uid>,; <gid>, <group> and <homedir>; for the directives specified via 'xpd.putenv'; Add the configuration directive 'proofservparents' to; allow specifying a different list of parent names for the 'proofserv'; tasks. This is needed to avoid untimely killing of 'proofserv'; instances in test setups when multiple instances of the daemons are; running on the same machines under different names.; Add the possibility to switch to asynchronous mode while; running synchronously. A new button ""Run; in background"" has been added; to the dialog box. The behaviour of Ctrl-C has also been modified: the; user is prompted for a choice among continuing asynchronously, stopping; (terminating) or aborting the query.; Add the possibility to define the dataset information; sources via the directive 'xpd.datasetsrc'.; In this way the permissions; should be set correctly and the related problems disappear.; Record the logs from the ROOT version validation tests; (proofserv forked in test mode). In case of failure - or if the debug; flag is on - the log files are kept under; <xproof_adminpath>/rootsysvalidation/root.<tag>.log; (the <tag> has all the ",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:6330,Deployability,configurat,configuration,6330,"e executing it. This allows to; circumvent a problem recently fixed giving less dependency on the; server version.; In make_dset.C, simplification of the body and of the; signature, eliminating one redundant argument. In TProofOutputFile, improve flexibility in defining the; URL for the local files server. The ""LOCALDATASERVER"" env is tested,; which can defined with placeholders via the xpd.putenv directive in the; xrootd/xproofd config files.; Improving parsing of lines with memory info.; This solves occasional crashes while generating the memory; plots.; In TProofMgr::GetSessionLogs:. add the possibility to postpone the retrieval of the; logs files when the TProofLog object is created. This improved; functionality is exploited in the log window.; add decoding of the session starting time and full; information about the master URL. Enable new xrootd configuration options, including the; possibility to set the compiler and linker; Cleanup of the TProofMgr functions DetachSession and; ShutdownSession, and better handling of the internal list registration,; to fix potential segvs when reopening a PROOF session inside the same; ROOT session.; Optimize the way results are transferred and merged:. Output objects are added to the same TMessage until a; HWM is reached (default 1MB; controlled by 'ProofServ.MsgSizeHWM');; this limits the number of transfers in the case of large numbers of; small objects.; Reasonably small histograms (GetSize() <; MsgSizeHWM) are merged in one-go at the end instead of one-by-one to; exploit, for example, the better performance of TH1::Merge on the full; list of histos.; Add possibility to compress the messages; this is; controlled by ProofServ.CompressMessage; <compression_level>; The default is still 'no compression' but this will allow to study the; impact of compression. Add sort of 'progress' counter for merging is now shown; on the client:;  ;     root [n] p->Process(...);       ... ;       Mst-0: merging output objects ... / (4; worker",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:206,Energy Efficiency,schedul,scheduler,206,". ; PROOF. Warning. The; classes; TProofDataSetManager; and TProofDataSetManagerFile have been renamed; TDataSetManager; and TDataSetManagerFile. New; functionality. Add support for session; queuing in the scheduler. This; allows to control the number of sessions allowed to process queries; concurrently. The feature is enabled by a new parameter 'queue:fifo' in; the 'xpd.schedparam'; directive. In case of static worker assignment; (default, random,; round-robin) the max number of running sessions can be limited by; another new parameter 'mxrun';; for; example;            ;     xpd.schedparam default; mxrun:3 queue:fifo; will run concurrently only 3 sessions. Additional requests are queued; and run as soon as one of the running; sessions goes idle. The current policy is FIFO, so that there is a; rotation among queued; sessions. In the case of load-based worker assignment, the max number; of running; queries is determined dynamically.; Add support for repeat functionality in the xrd.worker; directive. To avoid repeating the same line N times; one can just add; 'repeat=N'; in the line; for; example;            ;     xpd.worker worker; proofwrks:2093 repeat=4; will define 4 workers on port 2093 of machine 'proofwrks'.; Add support for port specification via the directive; 'xpd.port'; Enable variable; substitution in 'xpd.' directives using the standard; Scalla mechanism described in; http://xrootd.slac.stanford.edu/doc/dev/Syntax_config.htm .; Build also a binary named 'xproofd' which runs; a xrootd; daemon with only the XrdProofdProtocol (i.e. no data serving).; This simplifies setups when data serving is not needed and also allows; to better disantagle problems related to one specific protocol. The new; binary accepts the same arguments as 'xrootd' and parses the same; directives form the same configuration file, with the exception of; 'xpd.protocol xproofd libXrdProofd.so' which should now be dropped. AN; alternative port can be specified via the new 'xpd.port' direct",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:1712,Integrability,protocol,protocol,1712,"ly 3 sessions. Additional requests are queued; and run as soon as one of the running; sessions goes idle. The current policy is FIFO, so that there is a; rotation among queued; sessions. In the case of load-based worker assignment, the max number; of running; queries is determined dynamically.; Add support for repeat functionality in the xrd.worker; directive. To avoid repeating the same line N times; one can just add; 'repeat=N'; in the line; for; example;            ;     xpd.worker worker; proofwrks:2093 repeat=4; will define 4 workers on port 2093 of machine 'proofwrks'.; Add support for port specification via the directive; 'xpd.port'; Enable variable; substitution in 'xpd.' directives using the standard; Scalla mechanism described in; http://xrootd.slac.stanford.edu/doc/dev/Syntax_config.htm .; Build also a binary named 'xproofd' which runs; a xrootd; daemon with only the XrdProofdProtocol (i.e. no data serving).; This simplifies setups when data serving is not needed and also allows; to better disantagle problems related to one specific protocol. The new; binary accepts the same arguments as 'xrootd' and parses the same; directives form the same configuration file, with the exception of; 'xpd.protocol xproofd libXrdProofd.so' which should now be dropped. AN; alternative port can be specified via the new 'xpd.port' directive (see; above).; Add support for 'MasterOnly' mode in starting a PROOF; session. This avoids starting the workers when one wants just to browse; the datasets or retrieve results. To start a session in 'MasterOnly'; mode enter ""masteronly""; as second argument to TProof::Open, e.g.;  ;          root[]; TProof *p = TProof::Open(""<masterurl>"", ""masteronly""); Add full support for placeholders; <uid>,; <gid>, <group> and <homedir>; for the directives specified via 'xpd.putenv'; Add the configuration directive 'proofservparents' to; allow specifying a different list of parent names for the 'proofserv'; tasks. This is needed to avoid untimely killing",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:1871,Integrability,protocol,protocol,1871,"e max number; of running; queries is determined dynamically.; Add support for repeat functionality in the xrd.worker; directive. To avoid repeating the same line N times; one can just add; 'repeat=N'; in the line; for; example;            ;     xpd.worker worker; proofwrks:2093 repeat=4; will define 4 workers on port 2093 of machine 'proofwrks'.; Add support for port specification via the directive; 'xpd.port'; Enable variable; substitution in 'xpd.' directives using the standard; Scalla mechanism described in; http://xrootd.slac.stanford.edu/doc/dev/Syntax_config.htm .; Build also a binary named 'xproofd' which runs; a xrootd; daemon with only the XrdProofdProtocol (i.e. no data serving).; This simplifies setups when data serving is not needed and also allows; to better disantagle problems related to one specific protocol. The new; binary accepts the same arguments as 'xrootd' and parses the same; directives form the same configuration file, with the exception of; 'xpd.protocol xproofd libXrdProofd.so' which should now be dropped. AN; alternative port can be specified via the new 'xpd.port' directive (see; above).; Add support for 'MasterOnly' mode in starting a PROOF; session. This avoids starting the workers when one wants just to browse; the datasets or retrieve results. To start a session in 'MasterOnly'; mode enter ""masteronly""; as second argument to TProof::Open, e.g.;  ;          root[]; TProof *p = TProof::Open(""<masterurl>"", ""masteronly""); Add full support for placeholders; <uid>,; <gid>, <group> and <homedir>; for the directives specified via 'xpd.putenv'; Add the configuration directive 'proofservparents' to; allow specifying a different list of parent names for the 'proofserv'; tasks. This is needed to avoid untimely killing of 'proofserv'; instances in test setups when multiple instances of the daemons are; running on the same machines under different names.; Add the possibility to switch to asynchronous mode while; running synchronously. A new button ",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:5547,Integrability,depend,dependency,5547,"different master; and/or session  and displays human readable information about; the starting time of the session being browsed.; A set of scripts for quick interaction with a dataset; manager via PROOF are available under $ROOTSYS/etc/proof/utils/pq2 .; The scripts are prefixed; pq2 (proof; quick query - or; proof-dq2); and allow to {browse, register, remove, verify} datasets on a given; PROOF master. See $ROOTSYS/etc/proof/utils/pq2/README for more; information. Improvements. Enable by default schema evolution in TMessage; can be; disabled setting 'Proof.SchemaEvolution:; 0' .; Extend the functionality of the dataset API to obtaine; information on per-server base; add also two new methods:. TProof::SetDataSetTreeName(<dataset>,<treename>):; set/change the default tree name in the TFileCollection;; TProof::ExistsDataSet(<dataset>):; check; by-name the availability of a given dataset;. In ProofBench, . Load the macro before executing it. This allows to; circumvent a problem recently fixed giving less dependency on the; server version.; In make_dset.C, simplification of the body and of the; signature, eliminating one redundant argument. In TProofOutputFile, improve flexibility in defining the; URL for the local files server. The ""LOCALDATASERVER"" env is tested,; which can defined with placeholders via the xpd.putenv directive in the; xrootd/xproofd config files.; Improving parsing of lines with memory info.; This solves occasional crashes while generating the memory; plots.; In TProofMgr::GetSessionLogs:. add the possibility to postpone the retrieval of the; logs files when the TProofLog object is created. This improved; functionality is exploited in the log window.; add decoding of the session starting time and full; information about the master URL. Enable new xrootd configuration options, including the; possibility to set the compiler and linker; Cleanup of the TProofMgr functions DetachSession and; ShutdownSession, and better handling of the internal list registra",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:7121,Integrability,message,messages,7121," when the TProofLog object is created. This improved; functionality is exploited in the log window.; add decoding of the session starting time and full; information about the master URL. Enable new xrootd configuration options, including the; possibility to set the compiler and linker; Cleanup of the TProofMgr functions DetachSession and; ShutdownSession, and better handling of the internal list registration,; to fix potential segvs when reopening a PROOF session inside the same; ROOT session.; Optimize the way results are transferred and merged:. Output objects are added to the same TMessage until a; HWM is reached (default 1MB; controlled by 'ProofServ.MsgSizeHWM');; this limits the number of transfers in the case of large numbers of; small objects.; Reasonably small histograms (GetSize() <; MsgSizeHWM) are merged in one-go at the end instead of one-by-one to; exploit, for example, the better performance of TH1::Merge on the full; list of histos.; Add possibility to compress the messages; this is; controlled by ProofServ.CompressMessage; <compression_level>; The default is still 'no compression' but this will allow to study the; impact of compression. Add sort of 'progress' counter for merging is now shown; on the client:;  ;     root [n] p->Process(...);       ... ;       Mst-0: merging output objects ... / (4; workers still sending). This asserts socket activity and fixes the timeout; problems during long merging phases reported in a few cases.; In TFileMerger, create directly the output file at the; final destination do not make a local copy in the temp directory first; (if needed, one can always set the temporary destination to temp; followed by a TFile::Cp to the final destination); this allows to avoid; reported problems with small temp partitions (see Forum).; In XrdProofConn, enable cycling through the; authentication protocol presented by the server. This only holds for; the choice of the protocol, because the server currently supports only; one full hands",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:7985,Integrability,protocol,protocol,7985,"end instead of one-by-one to; exploit, for example, the better performance of TH1::Merge on the full; list of histos.; Add possibility to compress the messages; this is; controlled by ProofServ.CompressMessage; <compression_level>; The default is still 'no compression' but this will allow to study the; impact of compression. Add sort of 'progress' counter for merging is now shown; on the client:;  ;     root [n] p->Process(...);       ... ;       Mst-0: merging output objects ... / (4; workers still sending). This asserts socket activity and fixes the timeout; problems during long merging phases reported in a few cases.; In TFileMerger, create directly the output file at the; final destination do not make a local copy in the temp directory first; (if needed, one can always set the temporary destination to temp; followed by a TFile::Cp to the final destination); this allows to avoid; reported problems with small temp partitions (see Forum).; In XrdProofConn, enable cycling through the; authentication protocol presented by the server. This only holds for; the choice of the protocol, because the server currently supports only; one full handshake.; In test/stressProof.cxx, avoid interferences between the; settings used for the PROOF tutorial and possible local settings; (daemon, dataset manager).; Add possibility to control the automatic re-loading of; the <proof.conf> file via the keyword; 'reload:1'/'reload:0'; in the xpd.resource directive.; Move the validation of <proof.conf> at the; moment of use; this allows to specify a file path and to dynamically; create/modify/destroy the file; used by PoD.; Improve displaying speed of large log files. Fixes. Fix two severe; bugs in the way TTreeCache; was used in PROOF: one bug was de facto disactivating the cache; the; other was causing a std::bad_alloc exception to be thrown on workers; when opening a remote file after a local one.    ; Fix several problems in TChain::Draw including. drawing into an existing histogram, i.e.;",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:8058,Integrability,protocol,protocol,8058,"st of histos.; Add possibility to compress the messages; this is; controlled by ProofServ.CompressMessage; <compression_level>; The default is still 'no compression' but this will allow to study the; impact of compression. Add sort of 'progress' counter for merging is now shown; on the client:;  ;     root [n] p->Process(...);       ... ;       Mst-0: merging output objects ... / (4; workers still sending). This asserts socket activity and fixes the timeout; problems during long merging phases reported in a few cases.; In TFileMerger, create directly the output file at the; final destination do not make a local copy in the temp directory first; (if needed, one can always set the temporary destination to temp; followed by a TFile::Cp to the final destination); this allows to avoid; reported problems with small temp partitions (see Forum).; In XrdProofConn, enable cycling through the; authentication protocol presented by the server. This only holds for; the choice of the protocol, because the server currently supports only; one full handshake.; In test/stressProof.cxx, avoid interferences between the; settings used for the PROOF tutorial and possible local settings; (daemon, dataset manager).; Add possibility to control the automatic re-loading of; the <proof.conf> file via the keyword; 'reload:1'/'reload:0'; in the xpd.resource directive.; Move the validation of <proof.conf> at the; moment of use; this allows to specify a file path and to dynamically; create/modify/destroy the file; used by PoD.; Improve displaying speed of large log files. Fixes. Fix two severe; bugs in the way TTreeCache; was used in PROOF: one bug was de facto disactivating the cache; the; other was causing a std::bad_alloc exception to be thrown on workers; when opening a remote file after a local one.    ; Fix several problems in TChain::Draw including. drawing into an existing histogram, i.e.; chain->Draw(""var>>myhist"");. treatment of histogram merging in case of small; statistics, i.e. when; th",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:9691,Integrability,message,message,9691,"as de facto disactivating the cache; the; other was causing a std::bad_alloc exception to be thrown on workers; when opening a remote file after a local one.    ; Fix several problems in TChain::Draw including. drawing into an existing histogram, i.e.; chain->Draw(""var>>myhist"");. treatment of histogram merging in case of small; statistics, i.e. when; the autobinning is not or only partially active;. usage of existing canvases when different histogram; names are specified;. Fix a problem causing a duplication of the final feedback; object. Fix problem with determining the subdir name in; TFileMerger::MergeRecursive on Windows; Make sure that the default sandbox is under $HOME/.proof; Fix a problem with dataset validation in multi-level; master setups; Fix a problem with ordinal numbers in multi-master setups; Fix a problem with defining the internal paths for; executables when configuring with '--prefix'; Fix backward-incompatibility issue giving the error; message  ""unknown action code: 5112""; Fix a few problems with file retrieval from the cache; Fix a problem with iteration of a std::list occasionally; causing seg-violations in TXSocket; Fix a few problems preventing correct usage of entry; lists in PROOF; Fix a problem with the permissions of the credentials; files created under <sandbox>/.creds; Fix a potential problem while determining the log paths; in log retrieval. Do not use vnsprintf in the XrdProofd plug-in, potential; source of deadlocks.; Fix a problem overwriting the local environment settings; for the xrootd sec modules; In XrdProofdProofServMgr::Destroy, fix segv in message; creation when all sessions are destroyed at once; Fix a problem determining the relative time order of old; sessions for log retrieval; In TProof::HandleInputMessage, fix possible double delete; after kPROOF_STOPPROCESS; Fix a couple of issues on reconnection to a running; session (some dialog buttons not in the correct state; logs not; correctly redirected); Fix a problem creati",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:10329,Integrability,message,message,10329,"r was causing a std::bad_alloc exception to be thrown on workers; when opening a remote file after a local one.    ; Fix several problems in TChain::Draw including. drawing into an existing histogram, i.e.; chain->Draw(""var>>myhist"");. treatment of histogram merging in case of small; statistics, i.e. when; the autobinning is not or only partially active;. usage of existing canvases when different histogram; names are specified;. Fix a problem causing a duplication of the final feedback; object. Fix problem with determining the subdir name in; TFileMerger::MergeRecursive on Windows; Make sure that the default sandbox is under $HOME/.proof; Fix a problem with dataset validation in multi-level; master setups; Fix a problem with ordinal numbers in multi-master setups; Fix a problem with defining the internal paths for; executables when configuring with '--prefix'; Fix backward-incompatibility issue giving the error; message  ""unknown action code: 5112""; Fix a few problems with file retrieval from the cache; Fix a problem with iteration of a std::list occasionally; causing seg-violations in TXSocket; Fix a few problems preventing correct usage of entry; lists in PROOF; Fix a problem with the permissions of the credentials; files created under <sandbox>/.creds; Fix a potential problem while determining the log paths; in log retrieval. Do not use vnsprintf in the XrdProofd plug-in, potential; source of deadlocks.; Fix a problem overwriting the local environment settings; for the xrootd sec modules; In XrdProofdProofServMgr::Destroy, fix segv in message; creation when all sessions are destroyed at once; Fix a problem determining the relative time order of old; sessions for log retrieval; In TProof::HandleInputMessage, fix possible double delete; after kPROOF_STOPPROCESS; Fix a couple of issues on reconnection to a running; session (some dialog buttons not in the correct state; logs not; correctly redirected); Fix a problem creating spurious warnings during 'draw'; queries. ",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:1308,Modifiability,variab,variable,1308,"e is enabled by a new parameter 'queue:fifo' in; the 'xpd.schedparam'; directive. In case of static worker assignment; (default, random,; round-robin) the max number of running sessions can be limited by; another new parameter 'mxrun';; for; example;            ;     xpd.schedparam default; mxrun:3 queue:fifo; will run concurrently only 3 sessions. Additional requests are queued; and run as soon as one of the running; sessions goes idle. The current policy is FIFO, so that there is a; rotation among queued; sessions. In the case of load-based worker assignment, the max number; of running; queries is determined dynamically.; Add support for repeat functionality in the xrd.worker; directive. To avoid repeating the same line N times; one can just add; 'repeat=N'; in the line; for; example;            ;     xpd.worker worker; proofwrks:2093 repeat=4; will define 4 workers on port 2093 of machine 'proofwrks'.; Add support for port specification via the directive; 'xpd.port'; Enable variable; substitution in 'xpd.' directives using the standard; Scalla mechanism described in; http://xrootd.slac.stanford.edu/doc/dev/Syntax_config.htm .; Build also a binary named 'xproofd' which runs; a xrootd; daemon with only the XrdProofdProtocol (i.e. no data serving).; This simplifies setups when data serving is not needed and also allows; to better disantagle problems related to one specific protocol. The new; binary accepts the same arguments as 'xrootd' and parses the same; directives form the same configuration file, with the exception of; 'xpd.protocol xproofd libXrdProofd.so' which should now be dropped. AN; alternative port can be specified via the new 'xpd.port' directive (see; above).; Add support for 'MasterOnly' mode in starting a PROOF; session. This avoids starting the workers when one wants just to browse; the datasets or retrieve results. To start a session in 'MasterOnly'; mode enter ""masteronly""; as second argument to TProof::Open, e.g.;  ;          root[]; TProof *p = ",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:1823,Modifiability,config,configuration,1823,"ere is a; rotation among queued; sessions. In the case of load-based worker assignment, the max number; of running; queries is determined dynamically.; Add support for repeat functionality in the xrd.worker; directive. To avoid repeating the same line N times; one can just add; 'repeat=N'; in the line; for; example;            ;     xpd.worker worker; proofwrks:2093 repeat=4; will define 4 workers on port 2093 of machine 'proofwrks'.; Add support for port specification via the directive; 'xpd.port'; Enable variable; substitution in 'xpd.' directives using the standard; Scalla mechanism described in; http://xrootd.slac.stanford.edu/doc/dev/Syntax_config.htm .; Build also a binary named 'xproofd' which runs; a xrootd; daemon with only the XrdProofdProtocol (i.e. no data serving).; This simplifies setups when data serving is not needed and also allows; to better disantagle problems related to one specific protocol. The new; binary accepts the same arguments as 'xrootd' and parses the same; directives form the same configuration file, with the exception of; 'xpd.protocol xproofd libXrdProofd.so' which should now be dropped. AN; alternative port can be specified via the new 'xpd.port' directive (see; above).; Add support for 'MasterOnly' mode in starting a PROOF; session. This avoids starting the workers when one wants just to browse; the datasets or retrieve results. To start a session in 'MasterOnly'; mode enter ""masteronly""; as second argument to TProof::Open, e.g.;  ;          root[]; TProof *p = TProof::Open(""<masterurl>"", ""masteronly""); Add full support for placeholders; <uid>,; <gid>, <group> and <homedir>; for the directives specified via 'xpd.putenv'; Add the configuration directive 'proofservparents' to; allow specifying a different list of parent names for the 'proofserv'; tasks. This is needed to avoid untimely killing of 'proofserv'; instances in test setups when multiple instances of the daemons are; running on the same machines under different names.; Add ",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:2488,Modifiability,config,configuration,2488,"e XrdProofdProtocol (i.e. no data serving).; This simplifies setups when data serving is not needed and also allows; to better disantagle problems related to one specific protocol. The new; binary accepts the same arguments as 'xrootd' and parses the same; directives form the same configuration file, with the exception of; 'xpd.protocol xproofd libXrdProofd.so' which should now be dropped. AN; alternative port can be specified via the new 'xpd.port' directive (see; above).; Add support for 'MasterOnly' mode in starting a PROOF; session. This avoids starting the workers when one wants just to browse; the datasets or retrieve results. To start a session in 'MasterOnly'; mode enter ""masteronly""; as second argument to TProof::Open, e.g.;  ;          root[]; TProof *p = TProof::Open(""<masterurl>"", ""masteronly""); Add full support for placeholders; <uid>,; <gid>, <group> and <homedir>; for the directives specified via 'xpd.putenv'; Add the configuration directive 'proofservparents' to; allow specifying a different list of parent names for the 'proofserv'; tasks. This is needed to avoid untimely killing of 'proofserv'; instances in test setups when multiple instances of the daemons are; running on the same machines under different names.; Add the possibility to switch to asynchronous mode while; running synchronously. A new button ""Run; in background"" has been added; to the dialog box. The behaviour of Ctrl-C has also been modified: the; user is prompted for a choice among continuing asynchronously, stopping; (terminating) or aborting the query.; Add the possibility to define the dataset information; sources via the directive 'xpd.datasetsrc'.; In this way the permissions; should be set correctly and the related problems disappear.; Record the logs from the ROOT version validation tests; (proofserv forked in test mode). In case of failure - or if the debug; flag is on - the log files are kept under; <xproof_adminpath>/rootsysvalidation/root.<tag>.log; (the <tag> has all the ",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:5901,Modifiability,config,config,5901,"emove, verify} datasets on a given; PROOF master. See $ROOTSYS/etc/proof/utils/pq2/README for more; information. Improvements. Enable by default schema evolution in TMessage; can be; disabled setting 'Proof.SchemaEvolution:; 0' .; Extend the functionality of the dataset API to obtaine; information on per-server base; add also two new methods:. TProof::SetDataSetTreeName(<dataset>,<treename>):; set/change the default tree name in the TFileCollection;; TProof::ExistsDataSet(<dataset>):; check; by-name the availability of a given dataset;. In ProofBench, . Load the macro before executing it. This allows to; circumvent a problem recently fixed giving less dependency on the; server version.; In make_dset.C, simplification of the body and of the; signature, eliminating one redundant argument. In TProofOutputFile, improve flexibility in defining the; URL for the local files server. The ""LOCALDATASERVER"" env is tested,; which can defined with placeholders via the xpd.putenv directive in the; xrootd/xproofd config files.; Improving parsing of lines with memory info.; This solves occasional crashes while generating the memory; plots.; In TProofMgr::GetSessionLogs:. add the possibility to postpone the retrieval of the; logs files when the TProofLog object is created. This improved; functionality is exploited in the log window.; add decoding of the session starting time and full; information about the master URL. Enable new xrootd configuration options, including the; possibility to set the compiler and linker; Cleanup of the TProofMgr functions DetachSession and; ShutdownSession, and better handling of the internal list registration,; to fix potential segvs when reopening a PROOF session inside the same; ROOT session.; Optimize the way results are transferred and merged:. Output objects are added to the same TMessage until a; HWM is reached (default 1MB; controlled by 'ProofServ.MsgSizeHWM');; this limits the number of transfers in the case of large numbers of; small objects.; ",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:6330,Modifiability,config,configuration,6330,"e executing it. This allows to; circumvent a problem recently fixed giving less dependency on the; server version.; In make_dset.C, simplification of the body and of the; signature, eliminating one redundant argument. In TProofOutputFile, improve flexibility in defining the; URL for the local files server. The ""LOCALDATASERVER"" env is tested,; which can defined with placeholders via the xpd.putenv directive in the; xrootd/xproofd config files.; Improving parsing of lines with memory info.; This solves occasional crashes while generating the memory; plots.; In TProofMgr::GetSessionLogs:. add the possibility to postpone the retrieval of the; logs files when the TProofLog object is created. This improved; functionality is exploited in the log window.; add decoding of the session starting time and full; information about the master URL. Enable new xrootd configuration options, including the; possibility to set the compiler and linker; Cleanup of the TProofMgr functions DetachSession and; ShutdownSession, and better handling of the internal list registration,; to fix potential segvs when reopening a PROOF session inside the same; ROOT session.; Optimize the way results are transferred and merged:. Output objects are added to the same TMessage until a; HWM is reached (default 1MB; controlled by 'ProofServ.MsgSizeHWM');; this limits the number of transfers in the case of large numbers of; small objects.; Reasonably small histograms (GetSize() <; MsgSizeHWM) are merged in one-go at the end instead of one-by-one to; exploit, for example, the better performance of TH1::Merge on the full; list of histos.; Add possibility to compress the messages; this is; controlled by ProofServ.CompressMessage; <compression_level>; The default is still 'no compression' but this will allow to study the; impact of compression. Add sort of 'progress' counter for merging is now shown; on the client:;  ;     root [n] p->Process(...);       ... ;       Mst-0: merging output objects ... / (4; worker",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:9381,Modifiability,sandbox,sandbox,9381,"ng of; the <proof.conf> file via the keyword; 'reload:1'/'reload:0'; in the xpd.resource directive.; Move the validation of <proof.conf> at the; moment of use; this allows to specify a file path and to dynamically; create/modify/destroy the file; used by PoD.; Improve displaying speed of large log files. Fixes. Fix two severe; bugs in the way TTreeCache; was used in PROOF: one bug was de facto disactivating the cache; the; other was causing a std::bad_alloc exception to be thrown on workers; when opening a remote file after a local one.    ; Fix several problems in TChain::Draw including. drawing into an existing histogram, i.e.; chain->Draw(""var>>myhist"");. treatment of histogram merging in case of small; statistics, i.e. when; the autobinning is not or only partially active;. usage of existing canvases when different histogram; names are specified;. Fix a problem causing a duplication of the final feedback; object. Fix problem with determining the subdir name in; TFileMerger::MergeRecursive on Windows; Make sure that the default sandbox is under $HOME/.proof; Fix a problem with dataset validation in multi-level; master setups; Fix a problem with ordinal numbers in multi-master setups; Fix a problem with defining the internal paths for; executables when configuring with '--prefix'; Fix backward-incompatibility issue giving the error; message  ""unknown action code: 5112""; Fix a few problems with file retrieval from the cache; Fix a problem with iteration of a std::list occasionally; causing seg-violations in TXSocket; Fix a few problems preventing correct usage of entry; lists in PROOF; Fix a problem with the permissions of the credentials; files created under <sandbox>/.creds; Fix a potential problem while determining the log paths; in log retrieval. Do not use vnsprintf in the XrdProofd plug-in, potential; source of deadlocks.; Fix a problem overwriting the local environment settings; for the xrootd sec modules; In XrdProofdProofServMgr::Destroy, fix segv in messag",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:9609,Modifiability,config,configuring,9609,"as de facto disactivating the cache; the; other was causing a std::bad_alloc exception to be thrown on workers; when opening a remote file after a local one.    ; Fix several problems in TChain::Draw including. drawing into an existing histogram, i.e.; chain->Draw(""var>>myhist"");. treatment of histogram merging in case of small; statistics, i.e. when; the autobinning is not or only partially active;. usage of existing canvases when different histogram; names are specified;. Fix a problem causing a duplication of the final feedback; object. Fix problem with determining the subdir name in; TFileMerger::MergeRecursive on Windows; Make sure that the default sandbox is under $HOME/.proof; Fix a problem with dataset validation in multi-level; master setups; Fix a problem with ordinal numbers in multi-master setups; Fix a problem with defining the internal paths for; executables when configuring with '--prefix'; Fix backward-incompatibility issue giving the error; message  ""unknown action code: 5112""; Fix a few problems with file retrieval from the cache; Fix a problem with iteration of a std::list occasionally; causing seg-violations in TXSocket; Fix a few problems preventing correct usage of entry; lists in PROOF; Fix a problem with the permissions of the credentials; files created under <sandbox>/.creds; Fix a potential problem while determining the log paths; in log retrieval. Do not use vnsprintf in the XrdProofd plug-in, potential; source of deadlocks.; Fix a problem overwriting the local environment settings; for the xrootd sec modules; In XrdProofdProofServMgr::Destroy, fix segv in message; creation when all sessions are destroyed at once; Fix a problem determining the relative time order of old; sessions for log retrieval; In TProof::HandleInputMessage, fix possible double delete; after kPROOF_STOPPROCESS; Fix a couple of issues on reconnection to a running; session (some dialog buttons not in the correct state; logs not; correctly redirected); Fix a problem creati",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:10024,Modifiability,sandbox,sandbox,10024,"as de facto disactivating the cache; the; other was causing a std::bad_alloc exception to be thrown on workers; when opening a remote file after a local one.    ; Fix several problems in TChain::Draw including. drawing into an existing histogram, i.e.; chain->Draw(""var>>myhist"");. treatment of histogram merging in case of small; statistics, i.e. when; the autobinning is not or only partially active;. usage of existing canvases when different histogram; names are specified;. Fix a problem causing a duplication of the final feedback; object. Fix problem with determining the subdir name in; TFileMerger::MergeRecursive on Windows; Make sure that the default sandbox is under $HOME/.proof; Fix a problem with dataset validation in multi-level; master setups; Fix a problem with ordinal numbers in multi-master setups; Fix a problem with defining the internal paths for; executables when configuring with '--prefix'; Fix backward-incompatibility issue giving the error; message  ""unknown action code: 5112""; Fix a few problems with file retrieval from the cache; Fix a problem with iteration of a std::list occasionally; causing seg-violations in TXSocket; Fix a few problems preventing correct usage of entry; lists in PROOF; Fix a problem with the permissions of the credentials; files created under <sandbox>/.creds; Fix a potential problem while determining the log paths; in log retrieval. Do not use vnsprintf in the XrdProofd plug-in, potential; source of deadlocks.; Fix a problem overwriting the local environment settings; for the xrootd sec modules; In XrdProofdProofServMgr::Destroy, fix segv in message; creation when all sessions are destroyed at once; Fix a problem determining the relative time order of old; sessions for log retrieval; In TProof::HandleInputMessage, fix possible double delete; after kPROOF_STOPPROCESS; Fix a couple of issues on reconnection to a running; session (some dialog buttons not in the correct state; logs not; correctly redirected); Fix a problem creati",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:10154,Modifiability,plug-in,plug-in,10154,"r was causing a std::bad_alloc exception to be thrown on workers; when opening a remote file after a local one.    ; Fix several problems in TChain::Draw including. drawing into an existing histogram, i.e.; chain->Draw(""var>>myhist"");. treatment of histogram merging in case of small; statistics, i.e. when; the autobinning is not or only partially active;. usage of existing canvases when different histogram; names are specified;. Fix a problem causing a duplication of the final feedback; object. Fix problem with determining the subdir name in; TFileMerger::MergeRecursive on Windows; Make sure that the default sandbox is under $HOME/.proof; Fix a problem with dataset validation in multi-level; master setups; Fix a problem with ordinal numbers in multi-master setups; Fix a problem with defining the internal paths for; executables when configuring with '--prefix'; Fix backward-incompatibility issue giving the error; message  ""unknown action code: 5112""; Fix a few problems with file retrieval from the cache; Fix a problem with iteration of a std::list occasionally; causing seg-violations in TXSocket; Fix a few problems preventing correct usage of entry; lists in PROOF; Fix a problem with the permissions of the credentials; files created under <sandbox>/.creds; Fix a potential problem while determining the log paths; in log retrieval. Do not use vnsprintf in the XrdProofd plug-in, potential; source of deadlocks.; Fix a problem overwriting the local environment settings; for the xrootd sec modules; In XrdProofdProofServMgr::Destroy, fix segv in message; creation when all sessions are destroyed at once; Fix a problem determining the relative time order of old; sessions for log retrieval; In TProof::HandleInputMessage, fix possible double delete; after kPROOF_STOPPROCESS; Fix a couple of issues on reconnection to a running; session (some dialog buttons not in the correct state; logs not; correctly redirected); Fix a problem creating spurious warnings during 'draw'; queries. ",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:292,Performance,concurren,concurrently,292,". ; PROOF. Warning. The; classes; TProofDataSetManager; and TProofDataSetManagerFile have been renamed; TDataSetManager; and TDataSetManagerFile. New; functionality. Add support for session; queuing in the scheduler. This; allows to control the number of sessions allowed to process queries; concurrently. The feature is enabled by a new parameter 'queue:fifo' in; the 'xpd.schedparam'; directive. In case of static worker assignment; (default, random,; round-robin) the max number of running sessions can be limited by; another new parameter 'mxrun';; for; example;            ;     xpd.schedparam default; mxrun:3 queue:fifo; will run concurrently only 3 sessions. Additional requests are queued; and run as soon as one of the running; sessions goes idle. The current policy is FIFO, so that there is a; rotation among queued; sessions. In the case of load-based worker assignment, the max number; of running; queries is determined dynamically.; Add support for repeat functionality in the xrd.worker; directive. To avoid repeating the same line N times; one can just add; 'repeat=N'; in the line; for; example;            ;     xpd.worker worker; proofwrks:2093 repeat=4; will define 4 workers on port 2093 of machine 'proofwrks'.; Add support for port specification via the directive; 'xpd.port'; Enable variable; substitution in 'xpd.' directives using the standard; Scalla mechanism described in; http://xrootd.slac.stanford.edu/doc/dev/Syntax_config.htm .; Build also a binary named 'xproofd' which runs; a xrootd; daemon with only the XrdProofdProtocol (i.e. no data serving).; This simplifies setups when data serving is not needed and also allows; to better disantagle problems related to one specific protocol. The new; binary accepts the same arguments as 'xrootd' and parses the same; directives form the same configuration file, with the exception of; 'xpd.protocol xproofd libXrdProofd.so' which should now be dropped. AN; alternative port can be specified via the new 'xpd.port' direct",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:349,Performance,queue,queue,349,". ; PROOF. Warning. The; classes; TProofDataSetManager; and TProofDataSetManagerFile have been renamed; TDataSetManager; and TDataSetManagerFile. New; functionality. Add support for session; queuing in the scheduler. This; allows to control the number of sessions allowed to process queries; concurrently. The feature is enabled by a new parameter 'queue:fifo' in; the 'xpd.schedparam'; directive. In case of static worker assignment; (default, random,; round-robin) the max number of running sessions can be limited by; another new parameter 'mxrun';; for; example;            ;     xpd.schedparam default; mxrun:3 queue:fifo; will run concurrently only 3 sessions. Additional requests are queued; and run as soon as one of the running; sessions goes idle. The current policy is FIFO, so that there is a; rotation among queued; sessions. In the case of load-based worker assignment, the max number; of running; queries is determined dynamically.; Add support for repeat functionality in the xrd.worker; directive. To avoid repeating the same line N times; one can just add; 'repeat=N'; in the line; for; example;            ;     xpd.worker worker; proofwrks:2093 repeat=4; will define 4 workers on port 2093 of machine 'proofwrks'.; Add support for port specification via the directive; 'xpd.port'; Enable variable; substitution in 'xpd.' directives using the standard; Scalla mechanism described in; http://xrootd.slac.stanford.edu/doc/dev/Syntax_config.htm .; Build also a binary named 'xproofd' which runs; a xrootd; daemon with only the XrdProofdProtocol (i.e. no data serving).; This simplifies setups when data serving is not needed and also allows; to better disantagle problems related to one specific protocol. The new; binary accepts the same arguments as 'xrootd' and parses the same; directives form the same configuration file, with the exception of; 'xpd.protocol xproofd libXrdProofd.so' which should now be dropped. AN; alternative port can be specified via the new 'xpd.port' direct",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:616,Performance,queue,queue,616,". ; PROOF. Warning. The; classes; TProofDataSetManager; and TProofDataSetManagerFile have been renamed; TDataSetManager; and TDataSetManagerFile. New; functionality. Add support for session; queuing in the scheduler. This; allows to control the number of sessions allowed to process queries; concurrently. The feature is enabled by a new parameter 'queue:fifo' in; the 'xpd.schedparam'; directive. In case of static worker assignment; (default, random,; round-robin) the max number of running sessions can be limited by; another new parameter 'mxrun';; for; example;            ;     xpd.schedparam default; mxrun:3 queue:fifo; will run concurrently only 3 sessions. Additional requests are queued; and run as soon as one of the running; sessions goes idle. The current policy is FIFO, so that there is a; rotation among queued; sessions. In the case of load-based worker assignment, the max number; of running; queries is determined dynamically.; Add support for repeat functionality in the xrd.worker; directive. To avoid repeating the same line N times; one can just add; 'repeat=N'; in the line; for; example;            ;     xpd.worker worker; proofwrks:2093 repeat=4; will define 4 workers on port 2093 of machine 'proofwrks'.; Add support for port specification via the directive; 'xpd.port'; Enable variable; substitution in 'xpd.' directives using the standard; Scalla mechanism described in; http://xrootd.slac.stanford.edu/doc/dev/Syntax_config.htm .; Build also a binary named 'xproofd' which runs; a xrootd; daemon with only the XrdProofdProtocol (i.e. no data serving).; This simplifies setups when data serving is not needed and also allows; to better disantagle problems related to one specific protocol. The new; binary accepts the same arguments as 'xrootd' and parses the same; directives form the same configuration file, with the exception of; 'xpd.protocol xproofd libXrdProofd.so' which should now be dropped. AN; alternative port can be specified via the new 'xpd.port' direct",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:637,Performance,concurren,concurrently,637,". ; PROOF. Warning. The; classes; TProofDataSetManager; and TProofDataSetManagerFile have been renamed; TDataSetManager; and TDataSetManagerFile. New; functionality. Add support for session; queuing in the scheduler. This; allows to control the number of sessions allowed to process queries; concurrently. The feature is enabled by a new parameter 'queue:fifo' in; the 'xpd.schedparam'; directive. In case of static worker assignment; (default, random,; round-robin) the max number of running sessions can be limited by; another new parameter 'mxrun';; for; example;            ;     xpd.schedparam default; mxrun:3 queue:fifo; will run concurrently only 3 sessions. Additional requests are queued; and run as soon as one of the running; sessions goes idle. The current policy is FIFO, so that there is a; rotation among queued; sessions. In the case of load-based worker assignment, the max number; of running; queries is determined dynamically.; Add support for repeat functionality in the xrd.worker; directive. To avoid repeating the same line N times; one can just add; 'repeat=N'; in the line; for; example;            ;     xpd.worker worker; proofwrks:2093 repeat=4; will define 4 workers on port 2093 of machine 'proofwrks'.; Add support for port specification via the directive; 'xpd.port'; Enable variable; substitution in 'xpd.' directives using the standard; Scalla mechanism described in; http://xrootd.slac.stanford.edu/doc/dev/Syntax_config.htm .; Build also a binary named 'xproofd' which runs; a xrootd; daemon with only the XrdProofdProtocol (i.e. no data serving).; This simplifies setups when data serving is not needed and also allows; to better disantagle problems related to one specific protocol. The new; binary accepts the same arguments as 'xrootd' and parses the same; directives form the same configuration file, with the exception of; 'xpd.protocol xproofd libXrdProofd.so' which should now be dropped. AN; alternative port can be specified via the new 'xpd.port' direct",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:691,Performance,queue,queued,691,". ; PROOF. Warning. The; classes; TProofDataSetManager; and TProofDataSetManagerFile have been renamed; TDataSetManager; and TDataSetManagerFile. New; functionality. Add support for session; queuing in the scheduler. This; allows to control the number of sessions allowed to process queries; concurrently. The feature is enabled by a new parameter 'queue:fifo' in; the 'xpd.schedparam'; directive. In case of static worker assignment; (default, random,; round-robin) the max number of running sessions can be limited by; another new parameter 'mxrun';; for; example;            ;     xpd.schedparam default; mxrun:3 queue:fifo; will run concurrently only 3 sessions. Additional requests are queued; and run as soon as one of the running; sessions goes idle. The current policy is FIFO, so that there is a; rotation among queued; sessions. In the case of load-based worker assignment, the max number; of running; queries is determined dynamically.; Add support for repeat functionality in the xrd.worker; directive. To avoid repeating the same line N times; one can just add; 'repeat=N'; in the line; for; example;            ;     xpd.worker worker; proofwrks:2093 repeat=4; will define 4 workers on port 2093 of machine 'proofwrks'.; Add support for port specification via the directive; 'xpd.port'; Enable variable; substitution in 'xpd.' directives using the standard; Scalla mechanism described in; http://xrootd.slac.stanford.edu/doc/dev/Syntax_config.htm .; Build also a binary named 'xproofd' which runs; a xrootd; daemon with only the XrdProofdProtocol (i.e. no data serving).; This simplifies setups when data serving is not needed and also allows; to better disantagle problems related to one specific protocol. The new; binary accepts the same arguments as 'xrootd' and parses the same; directives form the same configuration file, with the exception of; 'xpd.protocol xproofd libXrdProofd.so' which should now be dropped. AN; alternative port can be specified via the new 'xpd.port' direct",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:821,Performance,queue,queued,821,". ; PROOF. Warning. The; classes; TProofDataSetManager; and TProofDataSetManagerFile have been renamed; TDataSetManager; and TDataSetManagerFile. New; functionality. Add support for session; queuing in the scheduler. This; allows to control the number of sessions allowed to process queries; concurrently. The feature is enabled by a new parameter 'queue:fifo' in; the 'xpd.schedparam'; directive. In case of static worker assignment; (default, random,; round-robin) the max number of running sessions can be limited by; another new parameter 'mxrun';; for; example;            ;     xpd.schedparam default; mxrun:3 queue:fifo; will run concurrently only 3 sessions. Additional requests are queued; and run as soon as one of the running; sessions goes idle. The current policy is FIFO, so that there is a; rotation among queued; sessions. In the case of load-based worker assignment, the max number; of running; queries is determined dynamically.; Add support for repeat functionality in the xrd.worker; directive. To avoid repeating the same line N times; one can just add; 'repeat=N'; in the line; for; example;            ;     xpd.worker worker; proofwrks:2093 repeat=4; will define 4 workers on port 2093 of machine 'proofwrks'.; Add support for port specification via the directive; 'xpd.port'; Enable variable; substitution in 'xpd.' directives using the standard; Scalla mechanism described in; http://xrootd.slac.stanford.edu/doc/dev/Syntax_config.htm .; Build also a binary named 'xproofd' which runs; a xrootd; daemon with only the XrdProofdProtocol (i.e. no data serving).; This simplifies setups when data serving is not needed and also allows; to better disantagle problems related to one specific protocol. The new; binary accepts the same arguments as 'xrootd' and parses the same; directives form the same configuration file, with the exception of; 'xpd.protocol xproofd libXrdProofd.so' which should now be dropped. AN; alternative port can be specified via the new 'xpd.port' direct",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:854,Performance,load,load-based,854,". ; PROOF. Warning. The; classes; TProofDataSetManager; and TProofDataSetManagerFile have been renamed; TDataSetManager; and TDataSetManagerFile. New; functionality. Add support for session; queuing in the scheduler. This; allows to control the number of sessions allowed to process queries; concurrently. The feature is enabled by a new parameter 'queue:fifo' in; the 'xpd.schedparam'; directive. In case of static worker assignment; (default, random,; round-robin) the max number of running sessions can be limited by; another new parameter 'mxrun';; for; example;            ;     xpd.schedparam default; mxrun:3 queue:fifo; will run concurrently only 3 sessions. Additional requests are queued; and run as soon as one of the running; sessions goes idle. The current policy is FIFO, so that there is a; rotation among queued; sessions. In the case of load-based worker assignment, the max number; of running; queries is determined dynamically.; Add support for repeat functionality in the xrd.worker; directive. To avoid repeating the same line N times; one can just add; 'repeat=N'; in the line; for; example;            ;     xpd.worker worker; proofwrks:2093 repeat=4; will define 4 workers on port 2093 of machine 'proofwrks'.; Add support for port specification via the directive; 'xpd.port'; Enable variable; substitution in 'xpd.' directives using the standard; Scalla mechanism described in; http://xrootd.slac.stanford.edu/doc/dev/Syntax_config.htm .; Build also a binary named 'xproofd' which runs; a xrootd; daemon with only the XrdProofdProtocol (i.e. no data serving).; This simplifies setups when data serving is not needed and also allows; to better disantagle problems related to one specific protocol. The new; binary accepts the same arguments as 'xrootd' and parses the same; directives form the same configuration file, with the exception of; 'xpd.protocol xproofd libXrdProofd.so' which should now be dropped. AN; alternative port can be specified via the new 'xpd.port' direct",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:7033,Performance,perform,performance,7033,"rashes while generating the memory; plots.; In TProofMgr::GetSessionLogs:. add the possibility to postpone the retrieval of the; logs files when the TProofLog object is created. This improved; functionality is exploited in the log window.; add decoding of the session starting time and full; information about the master URL. Enable new xrootd configuration options, including the; possibility to set the compiler and linker; Cleanup of the TProofMgr functions DetachSession and; ShutdownSession, and better handling of the internal list registration,; to fix potential segvs when reopening a PROOF session inside the same; ROOT session.; Optimize the way results are transferred and merged:. Output objects are added to the same TMessage until a; HWM is reached (default 1MB; controlled by 'ProofServ.MsgSizeHWM');; this limits the number of transfers in the case of large numbers of; small objects.; Reasonably small histograms (GetSize() <; MsgSizeHWM) are merged in one-go at the end instead of one-by-one to; exploit, for example, the better performance of TH1::Merge on the full; list of histos.; Add possibility to compress the messages; this is; controlled by ProofServ.CompressMessage; <compression_level>; The default is still 'no compression' but this will allow to study the; impact of compression. Add sort of 'progress' counter for merging is now shown; on the client:;  ;     root [n] p->Process(...);       ... ;       Mst-0: merging output objects ... / (4; workers still sending). This asserts socket activity and fixes the timeout; problems during long merging phases reported in a few cases.; In TFileMerger, create directly the output file at the; final destination do not make a local copy in the temp directory first; (if needed, one can always set the temporary destination to temp; followed by a TFile::Cp to the final destination); this allows to avoid; reported problems with small temp partitions (see Forum).; In XrdProofConn, enable cycling through the; authentication pr",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:8329,Performance,load,loading,8329,"s' counter for merging is now shown; on the client:;  ;     root [n] p->Process(...);       ... ;       Mst-0: merging output objects ... / (4; workers still sending). This asserts socket activity and fixes the timeout; problems during long merging phases reported in a few cases.; In TFileMerger, create directly the output file at the; final destination do not make a local copy in the temp directory first; (if needed, one can always set the temporary destination to temp; followed by a TFile::Cp to the final destination); this allows to avoid; reported problems with small temp partitions (see Forum).; In XrdProofConn, enable cycling through the; authentication protocol presented by the server. This only holds for; the choice of the protocol, because the server currently supports only; one full handshake.; In test/stressProof.cxx, avoid interferences between the; settings used for the PROOF tutorial and possible local settings; (daemon, dataset manager).; Add possibility to control the automatic re-loading of; the <proof.conf> file via the keyword; 'reload:1'/'reload:0'; in the xpd.resource directive.; Move the validation of <proof.conf> at the; moment of use; this allows to specify a file path and to dynamically; create/modify/destroy the file; used by PoD.; Improve displaying speed of large log files. Fixes. Fix two severe; bugs in the way TTreeCache; was used in PROOF: one bug was de facto disactivating the cache; the; other was causing a std::bad_alloc exception to be thrown on workers; when opening a remote file after a local one.    ; Fix several problems in TChain::Draw including. drawing into an existing histogram, i.e.; chain->Draw(""var>>myhist"");. treatment of histogram merging in case of small; statistics, i.e. when; the autobinning is not or only partially active;. usage of existing canvases when different histogram; names are specified;. Fix a problem causing a duplication of the final feedback; object. Fix problem with determining the subdir name in; TFil",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:8749,Performance,cache,cache,8749," temporary destination to temp; followed by a TFile::Cp to the final destination); this allows to avoid; reported problems with small temp partitions (see Forum).; In XrdProofConn, enable cycling through the; authentication protocol presented by the server. This only holds for; the choice of the protocol, because the server currently supports only; one full handshake.; In test/stressProof.cxx, avoid interferences between the; settings used for the PROOF tutorial and possible local settings; (daemon, dataset manager).; Add possibility to control the automatic re-loading of; the <proof.conf> file via the keyword; 'reload:1'/'reload:0'; in the xpd.resource directive.; Move the validation of <proof.conf> at the; moment of use; this allows to specify a file path and to dynamically; create/modify/destroy the file; used by PoD.; Improve displaying speed of large log files. Fixes. Fix two severe; bugs in the way TTreeCache; was used in PROOF: one bug was de facto disactivating the cache; the; other was causing a std::bad_alloc exception to be thrown on workers; when opening a remote file after a local one.    ; Fix several problems in TChain::Draw including. drawing into an existing histogram, i.e.; chain->Draw(""var>>myhist"");. treatment of histogram merging in case of small; statistics, i.e. when; the autobinning is not or only partially active;. usage of existing canvases when different histogram; names are specified;. Fix a problem causing a duplication of the final feedback; object. Fix problem with determining the subdir name in; TFileMerger::MergeRecursive on Windows; Make sure that the default sandbox is under $HOME/.proof; Fix a problem with dataset validation in multi-level; master setups; Fix a problem with ordinal numbers in multi-master setups; Fix a problem with defining the internal paths for; executables when configuring with '--prefix'; Fix backward-incompatibility issue giving the error; message  ""unknown action code: 5112""; Fix a few problems with file ret",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:9777,Performance,cache,cache,9777,"as de facto disactivating the cache; the; other was causing a std::bad_alloc exception to be thrown on workers; when opening a remote file after a local one.    ; Fix several problems in TChain::Draw including. drawing into an existing histogram, i.e.; chain->Draw(""var>>myhist"");. treatment of histogram merging in case of small; statistics, i.e. when; the autobinning is not or only partially active;. usage of existing canvases when different histogram; names are specified;. Fix a problem causing a duplication of the final feedback; object. Fix problem with determining the subdir name in; TFileMerger::MergeRecursive on Windows; Make sure that the default sandbox is under $HOME/.proof; Fix a problem with dataset validation in multi-level; master setups; Fix a problem with ordinal numbers in multi-master setups; Fix a problem with defining the internal paths for; executables when configuring with '--prefix'; Fix backward-incompatibility issue giving the error; message  ""unknown action code: 5112""; Fix a few problems with file retrieval from the cache; Fix a problem with iteration of a std::list occasionally; causing seg-violations in TXSocket; Fix a few problems preventing correct usage of entry; lists in PROOF; Fix a problem with the permissions of the credentials; files created under <sandbox>/.creds; Fix a potential problem while determining the log paths; in log retrieval. Do not use vnsprintf in the XrdProofd plug-in, potential; source of deadlocks.; Fix a problem overwriting the local environment settings; for the xrootd sec modules; In XrdProofdProofServMgr::Destroy, fix segv in message; creation when all sessions are destroyed at once; Fix a problem determining the relative time order of old; sessions for log retrieval; In TProof::HandleInputMessage, fix possible double delete; after kPROOF_STOPPROCESS; Fix a couple of issues on reconnection to a running; session (some dialog buttons not in the correct state; logs not; correctly redirected); Fix a problem creati",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:1018,Safety,avoid,avoid,1018,"anagerFile have been renamed; TDataSetManager; and TDataSetManagerFile. New; functionality. Add support for session; queuing in the scheduler. This; allows to control the number of sessions allowed to process queries; concurrently. The feature is enabled by a new parameter 'queue:fifo' in; the 'xpd.schedparam'; directive. In case of static worker assignment; (default, random,; round-robin) the max number of running sessions can be limited by; another new parameter 'mxrun';; for; example;            ;     xpd.schedparam default; mxrun:3 queue:fifo; will run concurrently only 3 sessions. Additional requests are queued; and run as soon as one of the running; sessions goes idle. The current policy is FIFO, so that there is a; rotation among queued; sessions. In the case of load-based worker assignment, the max number; of running; queries is determined dynamically.; Add support for repeat functionality in the xrd.worker; directive. To avoid repeating the same line N times; one can just add; 'repeat=N'; in the line; for; example;            ;     xpd.worker worker; proofwrks:2093 repeat=4; will define 4 workers on port 2093 of machine 'proofwrks'.; Add support for port specification via the directive; 'xpd.port'; Enable variable; substitution in 'xpd.' directives using the standard; Scalla mechanism described in; http://xrootd.slac.stanford.edu/doc/dev/Syntax_config.htm .; Build also a binary named 'xproofd' which runs; a xrootd; daemon with only the XrdProofdProtocol (i.e. no data serving).; This simplifies setups when data serving is not needed and also allows; to better disantagle problems related to one specific protocol. The new; binary accepts the same arguments as 'xrootd' and parses the same; directives form the same configuration file, with the exception of; 'xpd.protocol xproofd libXrdProofd.so' which should now be dropped. AN; alternative port can be specified via the new 'xpd.port' directive (see; above).; Add support for 'MasterOnly' mode in starting a PROOF; ",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:2089,Safety,avoid,avoids,2089,"pd.worker worker; proofwrks:2093 repeat=4; will define 4 workers on port 2093 of machine 'proofwrks'.; Add support for port specification via the directive; 'xpd.port'; Enable variable; substitution in 'xpd.' directives using the standard; Scalla mechanism described in; http://xrootd.slac.stanford.edu/doc/dev/Syntax_config.htm .; Build also a binary named 'xproofd' which runs; a xrootd; daemon with only the XrdProofdProtocol (i.e. no data serving).; This simplifies setups when data serving is not needed and also allows; to better disantagle problems related to one specific protocol. The new; binary accepts the same arguments as 'xrootd' and parses the same; directives form the same configuration file, with the exception of; 'xpd.protocol xproofd libXrdProofd.so' which should now be dropped. AN; alternative port can be specified via the new 'xpd.port' directive (see; above).; Add support for 'MasterOnly' mode in starting a PROOF; session. This avoids starting the workers when one wants just to browse; the datasets or retrieve results. To start a session in 'MasterOnly'; mode enter ""masteronly""; as second argument to TProof::Open, e.g.;  ;          root[]; TProof *p = TProof::Open(""<masterurl>"", ""masteronly""); Add full support for placeholders; <uid>,; <gid>, <group> and <homedir>; for the directives specified via 'xpd.putenv'; Add the configuration directive 'proofservparents' to; allow specifying a different list of parent names for the 'proofserv'; tasks. This is needed to avoid untimely killing of 'proofserv'; instances in test setups when multiple instances of the daemons are; running on the same machines under different names.; Add the possibility to switch to asynchronous mode while; running synchronously. A new button ""Run; in background"" has been added; to the dialog box. The behaviour of Ctrl-C has also been modified: the; user is prompted for a choice among continuing asynchronously, stopping; (terminating) or aborting the query.; Add the possibility to def",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:2631,Safety,avoid,avoid,2631,"e specific protocol. The new; binary accepts the same arguments as 'xrootd' and parses the same; directives form the same configuration file, with the exception of; 'xpd.protocol xproofd libXrdProofd.so' which should now be dropped. AN; alternative port can be specified via the new 'xpd.port' directive (see; above).; Add support for 'MasterOnly' mode in starting a PROOF; session. This avoids starting the workers when one wants just to browse; the datasets or retrieve results. To start a session in 'MasterOnly'; mode enter ""masteronly""; as second argument to TProof::Open, e.g.;  ;          root[]; TProof *p = TProof::Open(""<masterurl>"", ""masteronly""); Add full support for placeholders; <uid>,; <gid>, <group> and <homedir>; for the directives specified via 'xpd.putenv'; Add the configuration directive 'proofservparents' to; allow specifying a different list of parent names for the 'proofserv'; tasks. This is needed to avoid untimely killing of 'proofserv'; instances in test setups when multiple instances of the daemons are; running on the same machines under different names.; Add the possibility to switch to asynchronous mode while; running synchronously. A new button ""Run; in background"" has been added; to the dialog box. The behaviour of Ctrl-C has also been modified: the; user is prompted for a choice among continuing asynchronously, stopping; (terminating) or aborting the query.; Add the possibility to define the dataset information; sources via the directive 'xpd.datasetsrc'.; In this way the permissions; should be set correctly and the related problems disappear.; Record the logs from the ROOT version validation tests; (proofserv forked in test mode). In case of failure - or if the debug; flag is on - the log files are kept under; <xproof_adminpath>/rootsysvalidation/root.<tag>.log; (the <tag> has all the '/' replaced by '-'). This should; facilitate understanding the problems when in case of validation; failures.; Add support for automatic; running of PROOF ses",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:3085,Safety,abort,aborting,3085,"d support for 'MasterOnly' mode in starting a PROOF; session. This avoids starting the workers when one wants just to browse; the datasets or retrieve results. To start a session in 'MasterOnly'; mode enter ""masteronly""; as second argument to TProof::Open, e.g.;  ;          root[]; TProof *p = TProof::Open(""<masterurl>"", ""masteronly""); Add full support for placeholders; <uid>,; <gid>, <group> and <homedir>; for the directives specified via 'xpd.putenv'; Add the configuration directive 'proofservparents' to; allow specifying a different list of parent names for the 'proofserv'; tasks. This is needed to avoid untimely killing of 'proofserv'; instances in test setups when multiple instances of the daemons are; running on the same machines under different names.; Add the possibility to switch to asynchronous mode while; running synchronously. A new button ""Run; in background"" has been added; to the dialog box. The behaviour of Ctrl-C has also been modified: the; user is prompted for a choice among continuing asynchronously, stopping; (terminating) or aborting the query.; Add the possibility to define the dataset information; sources via the directive 'xpd.datasetsrc'.; In this way the permissions; should be set correctly and the related problems disappear.; Record the logs from the ROOT version validation tests; (proofserv forked in test mode). In case of failure - or if the debug; flag is on - the log files are kept under; <xproof_adminpath>/rootsysvalidation/root.<tag>.log; (the <tag> has all the '/' replaced by '-'). This should; facilitate understanding the problems when in case of validation; failures.; Add support for automatic; running of PROOF sessions in valgrind. The second; argument of TProof::Open is used to trigger the relevant; settings. To valgrind the master session start PROOF; with TProof::Open(""<master>"",""valgrind=master"");; to valgrind two workers sessions use; TProof::Open(""<master>"",""valgrind=workers""); to valgrind; master and 2 workers, use; TProof",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:5665,Safety,redund,redundant,5665,"sion being browsed.; A set of scripts for quick interaction with a dataset; manager via PROOF are available under $ROOTSYS/etc/proof/utils/pq2 .; The scripts are prefixed; pq2 (proof; quick query - or; proof-dq2); and allow to {browse, register, remove, verify} datasets on a given; PROOF master. See $ROOTSYS/etc/proof/utils/pq2/README for more; information. Improvements. Enable by default schema evolution in TMessage; can be; disabled setting 'Proof.SchemaEvolution:; 0' .; Extend the functionality of the dataset API to obtaine; information on per-server base; add also two new methods:. TProof::SetDataSetTreeName(<dataset>,<treename>):; set/change the default tree name in the TFileCollection;; TProof::ExistsDataSet(<dataset>):; check; by-name the availability of a given dataset;. In ProofBench, . Load the macro before executing it. This allows to; circumvent a problem recently fixed giving less dependency on the; server version.; In make_dset.C, simplification of the body and of the; signature, eliminating one redundant argument. In TProofOutputFile, improve flexibility in defining the; URL for the local files server. The ""LOCALDATASERVER"" env is tested,; which can defined with placeholders via the xpd.putenv directive in the; xrootd/xproofd config files.; Improving parsing of lines with memory info.; This solves occasional crashes while generating the memory; plots.; In TProofMgr::GetSessionLogs:. add the possibility to postpone the retrieval of the; logs files when the TProofLog object is created. This improved; functionality is exploited in the log window.; add decoding of the session starting time and full; information about the master URL. Enable new xrootd configuration options, including the; possibility to set the compiler and linker; Cleanup of the TProofMgr functions DetachSession and; ShutdownSession, and better handling of the internal list registration,; to fix potential segvs when reopening a PROOF session inside the same; ROOT session.; Optimize the wa",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:7528,Safety,timeout,timeout,7528,"o fix potential segvs when reopening a PROOF session inside the same; ROOT session.; Optimize the way results are transferred and merged:. Output objects are added to the same TMessage until a; HWM is reached (default 1MB; controlled by 'ProofServ.MsgSizeHWM');; this limits the number of transfers in the case of large numbers of; small objects.; Reasonably small histograms (GetSize() <; MsgSizeHWM) are merged in one-go at the end instead of one-by-one to; exploit, for example, the better performance of TH1::Merge on the full; list of histos.; Add possibility to compress the messages; this is; controlled by ProofServ.CompressMessage; <compression_level>; The default is still 'no compression' but this will allow to study the; impact of compression. Add sort of 'progress' counter for merging is now shown; on the client:;  ;     root [n] p->Process(...);       ... ;       Mst-0: merging output objects ... / (4; workers still sending). This asserts socket activity and fixes the timeout; problems during long merging phases reported in a few cases.; In TFileMerger, create directly the output file at the; final destination do not make a local copy in the temp directory first; (if needed, one can always set the temporary destination to temp; followed by a TFile::Cp to the final destination); this allows to avoid; reported problems with small temp partitions (see Forum).; In XrdProofConn, enable cycling through the; authentication protocol presented by the server. This only holds for; the choice of the protocol, because the server currently supports only; one full handshake.; In test/stressProof.cxx, avoid interferences between the; settings used for the PROOF tutorial and possible local settings; (daemon, dataset manager).; Add possibility to control the automatic re-loading of; the <proof.conf> file via the keyword; 'reload:1'/'reload:0'; in the xpd.resource directive.; Move the validation of <proof.conf> at the; moment of use; this allows to specify a file path and to dynam",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:7859,Safety,avoid,avoid,7859,"B; controlled by 'ProofServ.MsgSizeHWM');; this limits the number of transfers in the case of large numbers of; small objects.; Reasonably small histograms (GetSize() <; MsgSizeHWM) are merged in one-go at the end instead of one-by-one to; exploit, for example, the better performance of TH1::Merge on the full; list of histos.; Add possibility to compress the messages; this is; controlled by ProofServ.CompressMessage; <compression_level>; The default is still 'no compression' but this will allow to study the; impact of compression. Add sort of 'progress' counter for merging is now shown; on the client:;  ;     root [n] p->Process(...);       ... ;       Mst-0: merging output objects ... / (4; workers still sending). This asserts socket activity and fixes the timeout; problems during long merging phases reported in a few cases.; In TFileMerger, create directly the output file at the; final destination do not make a local copy in the temp directory first; (if needed, one can always set the temporary destination to temp; followed by a TFile::Cp to the final destination); this allows to avoid; reported problems with small temp partitions (see Forum).; In XrdProofConn, enable cycling through the; authentication protocol presented by the server. This only holds for; the choice of the protocol, because the server currently supports only; one full handshake.; In test/stressProof.cxx, avoid interferences between the; settings used for the PROOF tutorial and possible local settings; (daemon, dataset manager).; Add possibility to control the automatic re-loading of; the <proof.conf> file via the keyword; 'reload:1'/'reload:0'; in the xpd.resource directive.; Move the validation of <proof.conf> at the; moment of use; this allows to specify a file path and to dynamically; create/modify/destroy the file; used by PoD.; Improve displaying speed of large log files. Fixes. Fix two severe; bugs in the way TTreeCache; was used in PROOF: one bug was de facto disactivating the cache; the;",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:8158,Safety,avoid,avoid,8158,"till 'no compression' but this will allow to study the; impact of compression. Add sort of 'progress' counter for merging is now shown; on the client:;  ;     root [n] p->Process(...);       ... ;       Mst-0: merging output objects ... / (4; workers still sending). This asserts socket activity and fixes the timeout; problems during long merging phases reported in a few cases.; In TFileMerger, create directly the output file at the; final destination do not make a local copy in the temp directory first; (if needed, one can always set the temporary destination to temp; followed by a TFile::Cp to the final destination); this allows to avoid; reported problems with small temp partitions (see Forum).; In XrdProofConn, enable cycling through the; authentication protocol presented by the server. This only holds for; the choice of the protocol, because the server currently supports only; one full handshake.; In test/stressProof.cxx, avoid interferences between the; settings used for the PROOF tutorial and possible local settings; (daemon, dataset manager).; Add possibility to control the automatic re-loading of; the <proof.conf> file via the keyword; 'reload:1'/'reload:0'; in the xpd.resource directive.; Move the validation of <proof.conf> at the; moment of use; this allows to specify a file path and to dynamically; create/modify/destroy the file; used by PoD.; Improve displaying speed of large log files. Fixes. Fix two severe; bugs in the way TTreeCache; was used in PROOF: one bug was de facto disactivating the cache; the; other was causing a std::bad_alloc exception to be thrown on workers; when opening a remote file after a local one.    ; Fix several problems in TChain::Draw including. drawing into an existing histogram, i.e.; chain->Draw(""var>>myhist"");. treatment of histogram merging in case of small; statistics, i.e. when; the autobinning is not or only partially active;. usage of existing canvases when different histogram; names are specified;. Fix a problem causin",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:3334,Security,validat,validation,3334,"rl>"", ""masteronly""); Add full support for placeholders; <uid>,; <gid>, <group> and <homedir>; for the directives specified via 'xpd.putenv'; Add the configuration directive 'proofservparents' to; allow specifying a different list of parent names for the 'proofserv'; tasks. This is needed to avoid untimely killing of 'proofserv'; instances in test setups when multiple instances of the daemons are; running on the same machines under different names.; Add the possibility to switch to asynchronous mode while; running synchronously. A new button ""Run; in background"" has been added; to the dialog box. The behaviour of Ctrl-C has also been modified: the; user is prompted for a choice among continuing asynchronously, stopping; (terminating) or aborting the query.; Add the possibility to define the dataset information; sources via the directive 'xpd.datasetsrc'.; In this way the permissions; should be set correctly and the related problems disappear.; Record the logs from the ROOT version validation tests; (proofserv forked in test mode). In case of failure - or if the debug; flag is on - the log files are kept under; <xproof_adminpath>/rootsysvalidation/root.<tag>.log; (the <tag> has all the '/' replaced by '-'). This should; facilitate understanding the problems when in case of validation; failures.; Add support for automatic; running of PROOF sessions in valgrind. The second; argument of TProof::Open is used to trigger the relevant; settings. To valgrind the master session start PROOF; with TProof::Open(""<master>"",""valgrind=master"");; to valgrind two workers sessions use; TProof::Open(""<master>"",""valgrind=workers""); to valgrind; master and 2 workers, use; TProof::Open(""<master>"",""valgrind=master+workers""). Other; combinations are available. ; The valgrind logs are available with the tag; '<ordinal>-valgrind' in the log dialog or form; TProofMgr::GetSessionLogs() .; To add options to valgrind execute; TProof::AddEnvVar(""PROOF_WRAPPERCMD"",; ""valgrind_opts:<options>"") before",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:3631,Security,validat,validation,3631,"asks. This is needed to avoid untimely killing of 'proofserv'; instances in test setups when multiple instances of the daemons are; running on the same machines under different names.; Add the possibility to switch to asynchronous mode while; running synchronously. A new button ""Run; in background"" has been added; to the dialog box. The behaviour of Ctrl-C has also been modified: the; user is prompted for a choice among continuing asynchronously, stopping; (terminating) or aborting the query.; Add the possibility to define the dataset information; sources via the directive 'xpd.datasetsrc'.; In this way the permissions; should be set correctly and the related problems disappear.; Record the logs from the ROOT version validation tests; (proofserv forked in test mode). In case of failure - or if the debug; flag is on - the log files are kept under; <xproof_adminpath>/rootsysvalidation/root.<tag>.log; (the <tag> has all the '/' replaced by '-'). This should; facilitate understanding the problems when in case of validation; failures.; Add support for automatic; running of PROOF sessions in valgrind. The second; argument of TProof::Open is used to trigger the relevant; settings. To valgrind the master session start PROOF; with TProof::Open(""<master>"",""valgrind=master"");; to valgrind two workers sessions use; TProof::Open(""<master>"",""valgrind=workers""); to valgrind; master and 2 workers, use; TProof::Open(""<master>"",""valgrind=master+workers""). Other; combinations are available. ; The valgrind logs are available with the tag; '<ordinal>-valgrind' in the log dialog or form; TProofMgr::GetSessionLogs() .; To add options to valgrind execute; TProof::AddEnvVar(""PROOF_WRAPPERCMD"",; ""valgrind_opts:<options>"") before starting the; session. ; Add new static TProof::LogViewer(""<master>""); to graphically browse the session logs independently of the progress; dialog. The improved log window allows to chose a different master; and/or session  and displays human readable information abo",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:7970,Security,authenticat,authentication,7970,"end instead of one-by-one to; exploit, for example, the better performance of TH1::Merge on the full; list of histos.; Add possibility to compress the messages; this is; controlled by ProofServ.CompressMessage; <compression_level>; The default is still 'no compression' but this will allow to study the; impact of compression. Add sort of 'progress' counter for merging is now shown; on the client:;  ;     root [n] p->Process(...);       ... ;       Mst-0: merging output objects ... / (4; workers still sending). This asserts socket activity and fixes the timeout; problems during long merging phases reported in a few cases.; In TFileMerger, create directly the output file at the; final destination do not make a local copy in the temp directory first; (if needed, one can always set the temporary destination to temp; followed by a TFile::Cp to the final destination); this allows to avoid; reported problems with small temp partitions (see Forum).; In XrdProofConn, enable cycling through the; authentication protocol presented by the server. This only holds for; the choice of the protocol, because the server currently supports only; one full handshake.; In test/stressProof.cxx, avoid interferences between the; settings used for the PROOF tutorial and possible local settings; (daemon, dataset manager).; Add possibility to control the automatic re-loading of; the <proof.conf> file via the keyword; 'reload:1'/'reload:0'; in the xpd.resource directive.; Move the validation of <proof.conf> at the; moment of use; this allows to specify a file path and to dynamically; create/modify/destroy the file; used by PoD.; Improve displaying speed of large log files. Fixes. Fix two severe; bugs in the way TTreeCache; was used in PROOF: one bug was de facto disactivating the cache; the; other was causing a std::bad_alloc exception to be thrown on workers; when opening a remote file after a local one.    ; Fix several problems in TChain::Draw including. drawing into an existing histogram, i.e.;",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:8444,Security,validat,validation,8444,"s ... / (4; workers still sending). This asserts socket activity and fixes the timeout; problems during long merging phases reported in a few cases.; In TFileMerger, create directly the output file at the; final destination do not make a local copy in the temp directory first; (if needed, one can always set the temporary destination to temp; followed by a TFile::Cp to the final destination); this allows to avoid; reported problems with small temp partitions (see Forum).; In XrdProofConn, enable cycling through the; authentication protocol presented by the server. This only holds for; the choice of the protocol, because the server currently supports only; one full handshake.; In test/stressProof.cxx, avoid interferences between the; settings used for the PROOF tutorial and possible local settings; (daemon, dataset manager).; Add possibility to control the automatic re-loading of; the <proof.conf> file via the keyword; 'reload:1'/'reload:0'; in the xpd.resource directive.; Move the validation of <proof.conf> at the; moment of use; this allows to specify a file path and to dynamically; create/modify/destroy the file; used by PoD.; Improve displaying speed of large log files. Fixes. Fix two severe; bugs in the way TTreeCache; was used in PROOF: one bug was de facto disactivating the cache; the; other was causing a std::bad_alloc exception to be thrown on workers; when opening a remote file after a local one.    ; Fix several problems in TChain::Draw including. drawing into an existing histogram, i.e.; chain->Draw(""var>>myhist"");. treatment of histogram merging in case of small; statistics, i.e. when; the autobinning is not or only partially active;. usage of existing canvases when different histogram; names are specified;. Fix a problem causing a duplication of the final feedback; object. Fix problem with determining the subdir name in; TFileMerger::MergeRecursive on Windows; Make sure that the default sandbox is under $HOME/.proof; Fix a problem with dataset validation",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:9439,Security,validat,validation,9439,"as de facto disactivating the cache; the; other was causing a std::bad_alloc exception to be thrown on workers; when opening a remote file after a local one.    ; Fix several problems in TChain::Draw including. drawing into an existing histogram, i.e.; chain->Draw(""var>>myhist"");. treatment of histogram merging in case of small; statistics, i.e. when; the autobinning is not or only partially active;. usage of existing canvases when different histogram; names are specified;. Fix a problem causing a duplication of the final feedback; object. Fix problem with determining the subdir name in; TFileMerger::MergeRecursive on Windows; Make sure that the default sandbox is under $HOME/.proof; Fix a problem with dataset validation in multi-level; master setups; Fix a problem with ordinal numbers in multi-master setups; Fix a problem with defining the internal paths for; executables when configuring with '--prefix'; Fix backward-incompatibility issue giving the error; message  ""unknown action code: 5112""; Fix a few problems with file retrieval from the cache; Fix a problem with iteration of a std::list occasionally; causing seg-violations in TXSocket; Fix a few problems preventing correct usage of entry; lists in PROOF; Fix a problem with the permissions of the credentials; files created under <sandbox>/.creds; Fix a potential problem while determining the log paths; in log retrieval. Do not use vnsprintf in the XrdProofd plug-in, potential; source of deadlocks.; Fix a problem overwriting the local environment settings; for the xrootd sec modules; In XrdProofdProofServMgr::Destroy, fix segv in message; creation when all sessions are destroyed at once; Fix a problem determining the relative time order of old; sessions for log retrieval; In TProof::HandleInputMessage, fix possible double delete; after kPROOF_STOPPROCESS; Fix a couple of issues on reconnection to a running; session (some dialog buttons not in the correct state; logs not; correctly redirected); Fix a problem creati",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:2683,Testability,test,test,2683,"e specific protocol. The new; binary accepts the same arguments as 'xrootd' and parses the same; directives form the same configuration file, with the exception of; 'xpd.protocol xproofd libXrdProofd.so' which should now be dropped. AN; alternative port can be specified via the new 'xpd.port' directive (see; above).; Add support for 'MasterOnly' mode in starting a PROOF; session. This avoids starting the workers when one wants just to browse; the datasets or retrieve results. To start a session in 'MasterOnly'; mode enter ""masteronly""; as second argument to TProof::Open, e.g.;  ;          root[]; TProof *p = TProof::Open(""<masterurl>"", ""masteronly""); Add full support for placeholders; <uid>,; <gid>, <group> and <homedir>; for the directives specified via 'xpd.putenv'; Add the configuration directive 'proofservparents' to; allow specifying a different list of parent names for the 'proofserv'; tasks. This is needed to avoid untimely killing of 'proofserv'; instances in test setups when multiple instances of the daemons are; running on the same machines under different names.; Add the possibility to switch to asynchronous mode while; running synchronously. A new button ""Run; in background"" has been added; to the dialog box. The behaviour of Ctrl-C has also been modified: the; user is prompted for a choice among continuing asynchronously, stopping; (terminating) or aborting the query.; Add the possibility to define the dataset information; sources via the directive 'xpd.datasetsrc'.; In this way the permissions; should be set correctly and the related problems disappear.; Record the logs from the ROOT version validation tests; (proofserv forked in test mode). In case of failure - or if the debug; flag is on - the log files are kept under; <xproof_adminpath>/rootsysvalidation/root.<tag>.log; (the <tag> has all the '/' replaced by '-'). This should; facilitate understanding the problems when in case of validation; failures.; Add support for automatic; running of PROOF ses",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:3307,Testability,log,logs,3307,"rl>"", ""masteronly""); Add full support for placeholders; <uid>,; <gid>, <group> and <homedir>; for the directives specified via 'xpd.putenv'; Add the configuration directive 'proofservparents' to; allow specifying a different list of parent names for the 'proofserv'; tasks. This is needed to avoid untimely killing of 'proofserv'; instances in test setups when multiple instances of the daemons are; running on the same machines under different names.; Add the possibility to switch to asynchronous mode while; running synchronously. A new button ""Run; in background"" has been added; to the dialog box. The behaviour of Ctrl-C has also been modified: the; user is prompted for a choice among continuing asynchronously, stopping; (terminating) or aborting the query.; Add the possibility to define the dataset information; sources via the directive 'xpd.datasetsrc'.; In this way the permissions; should be set correctly and the related problems disappear.; Record the logs from the ROOT version validation tests; (proofserv forked in test mode). In case of failure - or if the debug; flag is on - the log files are kept under; <xproof_adminpath>/rootsysvalidation/root.<tag>.log; (the <tag> has all the '/' replaced by '-'). This should; facilitate understanding the problems when in case of validation; failures.; Add support for automatic; running of PROOF sessions in valgrind. The second; argument of TProof::Open is used to trigger the relevant; settings. To valgrind the master session start PROOF; with TProof::Open(""<master>"",""valgrind=master"");; to valgrind two workers sessions use; TProof::Open(""<master>"",""valgrind=workers""); to valgrind; master and 2 workers, use; TProof::Open(""<master>"",""valgrind=master+workers""). Other; combinations are available. ; The valgrind logs are available with the tag; '<ordinal>-valgrind' in the log dialog or form; TProofMgr::GetSessionLogs() .; To add options to valgrind execute; TProof::AddEnvVar(""PROOF_WRAPPERCMD"",; ""valgrind_opts:<options>"") before",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:3345,Testability,test,tests,3345,"rl>"", ""masteronly""); Add full support for placeholders; <uid>,; <gid>, <group> and <homedir>; for the directives specified via 'xpd.putenv'; Add the configuration directive 'proofservparents' to; allow specifying a different list of parent names for the 'proofserv'; tasks. This is needed to avoid untimely killing of 'proofserv'; instances in test setups when multiple instances of the daemons are; running on the same machines under different names.; Add the possibility to switch to asynchronous mode while; running synchronously. A new button ""Run; in background"" has been added; to the dialog box. The behaviour of Ctrl-C has also been modified: the; user is prompted for a choice among continuing asynchronously, stopping; (terminating) or aborting the query.; Add the possibility to define the dataset information; sources via the directive 'xpd.datasetsrc'.; In this way the permissions; should be set correctly and the related problems disappear.; Record the logs from the ROOT version validation tests; (proofserv forked in test mode). In case of failure - or if the debug; flag is on - the log files are kept under; <xproof_adminpath>/rootsysvalidation/root.<tag>.log; (the <tag> has all the '/' replaced by '-'). This should; facilitate understanding the problems when in case of validation; failures.; Add support for automatic; running of PROOF sessions in valgrind. The second; argument of TProof::Open is used to trigger the relevant; settings. To valgrind the master session start PROOF; with TProof::Open(""<master>"",""valgrind=master"");; to valgrind two workers sessions use; TProof::Open(""<master>"",""valgrind=workers""); to valgrind; master and 2 workers, use; TProof::Open(""<master>"",""valgrind=master+workers""). Other; combinations are available. ; The valgrind logs are available with the tag; '<ordinal>-valgrind' in the log dialog or form; TProofMgr::GetSessionLogs() .; To add options to valgrind execute; TProof::AddEnvVar(""PROOF_WRAPPERCMD"",; ""valgrind_opts:<options>"") before",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:3373,Testability,test,test,3373,"rl>"", ""masteronly""); Add full support for placeholders; <uid>,; <gid>, <group> and <homedir>; for the directives specified via 'xpd.putenv'; Add the configuration directive 'proofservparents' to; allow specifying a different list of parent names for the 'proofserv'; tasks. This is needed to avoid untimely killing of 'proofserv'; instances in test setups when multiple instances of the daemons are; running on the same machines under different names.; Add the possibility to switch to asynchronous mode while; running synchronously. A new button ""Run; in background"" has been added; to the dialog box. The behaviour of Ctrl-C has also been modified: the; user is prompted for a choice among continuing asynchronously, stopping; (terminating) or aborting the query.; Add the possibility to define the dataset information; sources via the directive 'xpd.datasetsrc'.; In this way the permissions; should be set correctly and the related problems disappear.; Record the logs from the ROOT version validation tests; (proofserv forked in test mode). In case of failure - or if the debug; flag is on - the log files are kept under; <xproof_adminpath>/rootsysvalidation/root.<tag>.log; (the <tag> has all the '/' replaced by '-'). This should; facilitate understanding the problems when in case of validation; failures.; Add support for automatic; running of PROOF sessions in valgrind. The second; argument of TProof::Open is used to trigger the relevant; settings. To valgrind the master session start PROOF; with TProof::Open(""<master>"",""valgrind=master"");; to valgrind two workers sessions use; TProof::Open(""<master>"",""valgrind=workers""); to valgrind; master and 2 workers, use; TProof::Open(""<master>"",""valgrind=master+workers""). Other; combinations are available. ; The valgrind logs are available with the tag; '<ordinal>-valgrind' in the log dialog or form; TProofMgr::GetSessionLogs() .; To add options to valgrind execute; TProof::AddEnvVar(""PROOF_WRAPPERCMD"",; ""valgrind_opts:<options>"") before",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:3440,Testability,log,log,3440,"tives specified via 'xpd.putenv'; Add the configuration directive 'proofservparents' to; allow specifying a different list of parent names for the 'proofserv'; tasks. This is needed to avoid untimely killing of 'proofserv'; instances in test setups when multiple instances of the daemons are; running on the same machines under different names.; Add the possibility to switch to asynchronous mode while; running synchronously. A new button ""Run; in background"" has been added; to the dialog box. The behaviour of Ctrl-C has also been modified: the; user is prompted for a choice among continuing asynchronously, stopping; (terminating) or aborting the query.; Add the possibility to define the dataset information; sources via the directive 'xpd.datasetsrc'.; In this way the permissions; should be set correctly and the related problems disappear.; Record the logs from the ROOT version validation tests; (proofserv forked in test mode). In case of failure - or if the debug; flag is on - the log files are kept under; <xproof_adminpath>/rootsysvalidation/root.<tag>.log; (the <tag> has all the '/' replaced by '-'). This should; facilitate understanding the problems when in case of validation; failures.; Add support for automatic; running of PROOF sessions in valgrind. The second; argument of TProof::Open is used to trigger the relevant; settings. To valgrind the master session start PROOF; with TProof::Open(""<master>"",""valgrind=master"");; to valgrind two workers sessions use; TProof::Open(""<master>"",""valgrind=workers""); to valgrind; master and 2 workers, use; TProof::Open(""<master>"",""valgrind=master+workers""). Other; combinations are available. ; The valgrind logs are available with the tag; '<ordinal>-valgrind' in the log dialog or form; TProofMgr::GetSessionLogs() .; To add options to valgrind execute; TProof::AddEnvVar(""PROOF_WRAPPERCMD"",; ""valgrind_opts:<options>"") before starting the; session. ; Add new static TProof::LogViewer(""<master>""); to graphically browse the session l",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:3514,Testability,log,log,3514,"ow specifying a different list of parent names for the 'proofserv'; tasks. This is needed to avoid untimely killing of 'proofserv'; instances in test setups when multiple instances of the daemons are; running on the same machines under different names.; Add the possibility to switch to asynchronous mode while; running synchronously. A new button ""Run; in background"" has been added; to the dialog box. The behaviour of Ctrl-C has also been modified: the; user is prompted for a choice among continuing asynchronously, stopping; (terminating) or aborting the query.; Add the possibility to define the dataset information; sources via the directive 'xpd.datasetsrc'.; In this way the permissions; should be set correctly and the related problems disappear.; Record the logs from the ROOT version validation tests; (proofserv forked in test mode). In case of failure - or if the debug; flag is on - the log files are kept under; <xproof_adminpath>/rootsysvalidation/root.<tag>.log; (the <tag> has all the '/' replaced by '-'). This should; facilitate understanding the problems when in case of validation; failures.; Add support for automatic; running of PROOF sessions in valgrind. The second; argument of TProof::Open is used to trigger the relevant; settings. To valgrind the master session start PROOF; with TProof::Open(""<master>"",""valgrind=master"");; to valgrind two workers sessions use; TProof::Open(""<master>"",""valgrind=workers""); to valgrind; master and 2 workers, use; TProof::Open(""<master>"",""valgrind=master+workers""). Other; combinations are available. ; The valgrind logs are available with the tag; '<ordinal>-valgrind' in the log dialog or form; TProofMgr::GetSessionLogs() .; To add options to valgrind execute; TProof::AddEnvVar(""PROOF_WRAPPERCMD"",; ""valgrind_opts:<options>"") before starting the; session. ; Add new static TProof::LogViewer(""<master>""); to graphically browse the session logs independently of the progress; dialog. The improved log window allows to chose a differen",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:4119,Testability,log,logs,4119,"es via the directive 'xpd.datasetsrc'.; In this way the permissions; should be set correctly and the related problems disappear.; Record the logs from the ROOT version validation tests; (proofserv forked in test mode). In case of failure - or if the debug; flag is on - the log files are kept under; <xproof_adminpath>/rootsysvalidation/root.<tag>.log; (the <tag> has all the '/' replaced by '-'). This should; facilitate understanding the problems when in case of validation; failures.; Add support for automatic; running of PROOF sessions in valgrind. The second; argument of TProof::Open is used to trigger the relevant; settings. To valgrind the master session start PROOF; with TProof::Open(""<master>"",""valgrind=master"");; to valgrind two workers sessions use; TProof::Open(""<master>"",""valgrind=workers""); to valgrind; master and 2 workers, use; TProof::Open(""<master>"",""valgrind=master+workers""). Other; combinations are available. ; The valgrind logs are available with the tag; '<ordinal>-valgrind' in the log dialog or form; TProofMgr::GetSessionLogs() .; To add options to valgrind execute; TProof::AddEnvVar(""PROOF_WRAPPERCMD"",; ""valgrind_opts:<options>"") before starting the; session. ; Add new static TProof::LogViewer(""<master>""); to graphically browse the session logs independently of the progress; dialog. The improved log window allows to chose a different master; and/or session  and displays human readable information about; the starting time of the session being browsed.; A set of scripts for quick interaction with a dataset; manager via PROOF are available under $ROOTSYS/etc/proof/utils/pq2 .; The scripts are prefixed; pq2 (proof; quick query - or; proof-dq2); and allow to {browse, register, remove, verify} datasets on a given; PROOF master. See $ROOTSYS/etc/proof/utils/pq2/README for more; information. Improvements. Enable by default schema evolution in TMessage; can be; disabled setting 'Proof.SchemaEvolution:; 0' .; Extend the functionality of the dataset API to o",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:4180,Testability,log,log,4180,"es via the directive 'xpd.datasetsrc'.; In this way the permissions; should be set correctly and the related problems disappear.; Record the logs from the ROOT version validation tests; (proofserv forked in test mode). In case of failure - or if the debug; flag is on - the log files are kept under; <xproof_adminpath>/rootsysvalidation/root.<tag>.log; (the <tag> has all the '/' replaced by '-'). This should; facilitate understanding the problems when in case of validation; failures.; Add support for automatic; running of PROOF sessions in valgrind. The second; argument of TProof::Open is used to trigger the relevant; settings. To valgrind the master session start PROOF; with TProof::Open(""<master>"",""valgrind=master"");; to valgrind two workers sessions use; TProof::Open(""<master>"",""valgrind=workers""); to valgrind; master and 2 workers, use; TProof::Open(""<master>"",""valgrind=master+workers""). Other; combinations are available. ; The valgrind logs are available with the tag; '<ordinal>-valgrind' in the log dialog or form; TProofMgr::GetSessionLogs() .; To add options to valgrind execute; TProof::AddEnvVar(""PROOF_WRAPPERCMD"",; ""valgrind_opts:<options>"") before starting the; session. ; Add new static TProof::LogViewer(""<master>""); to graphically browse the session logs independently of the progress; dialog. The improved log window allows to chose a different master; and/or session  and displays human readable information about; the starting time of the session being browsed.; A set of scripts for quick interaction with a dataset; manager via PROOF are available under $ROOTSYS/etc/proof/utils/pq2 .; The scripts are prefixed; pq2 (proof; quick query - or; proof-dq2); and allow to {browse, register, remove, verify} datasets on a given; PROOF master. See $ROOTSYS/etc/proof/utils/pq2/README for more; information. Improvements. Enable by default schema evolution in TMessage; can be; disabled setting 'Proof.SchemaEvolution:; 0' .; Extend the functionality of the dataset API to o",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:4445,Testability,log,logs,4445,"ag is on - the log files are kept under; <xproof_adminpath>/rootsysvalidation/root.<tag>.log; (the <tag> has all the '/' replaced by '-'). This should; facilitate understanding the problems when in case of validation; failures.; Add support for automatic; running of PROOF sessions in valgrind. The second; argument of TProof::Open is used to trigger the relevant; settings. To valgrind the master session start PROOF; with TProof::Open(""<master>"",""valgrind=master"");; to valgrind two workers sessions use; TProof::Open(""<master>"",""valgrind=workers""); to valgrind; master and 2 workers, use; TProof::Open(""<master>"",""valgrind=master+workers""). Other; combinations are available. ; The valgrind logs are available with the tag; '<ordinal>-valgrind' in the log dialog or form; TProofMgr::GetSessionLogs() .; To add options to valgrind execute; TProof::AddEnvVar(""PROOF_WRAPPERCMD"",; ""valgrind_opts:<options>"") before starting the; session. ; Add new static TProof::LogViewer(""<master>""); to graphically browse the session logs independently of the progress; dialog. The improved log window allows to chose a different master; and/or session  and displays human readable information about; the starting time of the session being browsed.; A set of scripts for quick interaction with a dataset; manager via PROOF are available under $ROOTSYS/etc/proof/utils/pq2 .; The scripts are prefixed; pq2 (proof; quick query - or; proof-dq2); and allow to {browse, register, remove, verify} datasets on a given; PROOF master. See $ROOTSYS/etc/proof/utils/pq2/README for more; information. Improvements. Enable by default schema evolution in TMessage; can be; disabled setting 'Proof.SchemaEvolution:; 0' .; Extend the functionality of the dataset API to obtaine; information on per-server base; add also two new methods:. TProof::SetDataSetTreeName(<dataset>,<treename>):; set/change the default tree name in the TFileCollection;; TProof::ExistsDataSet(<dataset>):; check; by-name the availability of a given datas",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:4502,Testability,log,log,4502,"ld; facilitate understanding the problems when in case of validation; failures.; Add support for automatic; running of PROOF sessions in valgrind. The second; argument of TProof::Open is used to trigger the relevant; settings. To valgrind the master session start PROOF; with TProof::Open(""<master>"",""valgrind=master"");; to valgrind two workers sessions use; TProof::Open(""<master>"",""valgrind=workers""); to valgrind; master and 2 workers, use; TProof::Open(""<master>"",""valgrind=master+workers""). Other; combinations are available. ; The valgrind logs are available with the tag; '<ordinal>-valgrind' in the log dialog or form; TProofMgr::GetSessionLogs() .; To add options to valgrind execute; TProof::AddEnvVar(""PROOF_WRAPPERCMD"",; ""valgrind_opts:<options>"") before starting the; session. ; Add new static TProof::LogViewer(""<master>""); to graphically browse the session logs independently of the progress; dialog. The improved log window allows to chose a different master; and/or session  and displays human readable information about; the starting time of the session being browsed.; A set of scripts for quick interaction with a dataset; manager via PROOF are available under $ROOTSYS/etc/proof/utils/pq2 .; The scripts are prefixed; pq2 (proof; quick query - or; proof-dq2); and allow to {browse, register, remove, verify} datasets on a given; PROOF master. See $ROOTSYS/etc/proof/utils/pq2/README for more; information. Improvements. Enable by default schema evolution in TMessage; can be; disabled setting 'Proof.SchemaEvolution:; 0' .; Extend the functionality of the dataset API to obtaine; information on per-server base; add also two new methods:. TProof::SetDataSetTreeName(<dataset>,<treename>):; set/change the default tree name in the TFileCollection;; TProof::ExistsDataSet(<dataset>):; check; by-name the availability of a given dataset;. In ProofBench, . Load the macro before executing it. This allows to; circumvent a problem recently fixed giving less dependency on the; server v",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:5804,Testability,test,tested,5804,"proof; quick query - or; proof-dq2); and allow to {browse, register, remove, verify} datasets on a given; PROOF master. See $ROOTSYS/etc/proof/utils/pq2/README for more; information. Improvements. Enable by default schema evolution in TMessage; can be; disabled setting 'Proof.SchemaEvolution:; 0' .; Extend the functionality of the dataset API to obtaine; information on per-server base; add also two new methods:. TProof::SetDataSetTreeName(<dataset>,<treename>):; set/change the default tree name in the TFileCollection;; TProof::ExistsDataSet(<dataset>):; check; by-name the availability of a given dataset;. In ProofBench, . Load the macro before executing it. This allows to; circumvent a problem recently fixed giving less dependency on the; server version.; In make_dset.C, simplification of the body and of the; signature, eliminating one redundant argument. In TProofOutputFile, improve flexibility in defining the; URL for the local files server. The ""LOCALDATASERVER"" env is tested,; which can defined with placeholders via the xpd.putenv directive in the; xrootd/xproofd config files.; Improving parsing of lines with memory info.; This solves occasional crashes while generating the memory; plots.; In TProofMgr::GetSessionLogs:. add the possibility to postpone the retrieval of the; logs files when the TProofLog object is created. This improved; functionality is exploited in the log window.; add decoding of the session starting time and full; information about the master URL. Enable new xrootd configuration options, including the; possibility to set the compiler and linker; Cleanup of the TProofMgr functions DetachSession and; ShutdownSession, and better handling of the internal list registration,; to fix potential segvs when reopening a PROOF session inside the same; ROOT session.; Optimize the way results are transferred and merged:. Output objects are added to the same TMessage until a; HWM is reached (default 1MB; controlled by 'ProofServ.MsgSizeHWM');; this limits the",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:6115,Testability,log,logs,6115," 0' .; Extend the functionality of the dataset API to obtaine; information on per-server base; add also two new methods:. TProof::SetDataSetTreeName(<dataset>,<treename>):; set/change the default tree name in the TFileCollection;; TProof::ExistsDataSet(<dataset>):; check; by-name the availability of a given dataset;. In ProofBench, . Load the macro before executing it. This allows to; circumvent a problem recently fixed giving less dependency on the; server version.; In make_dset.C, simplification of the body and of the; signature, eliminating one redundant argument. In TProofOutputFile, improve flexibility in defining the; URL for the local files server. The ""LOCALDATASERVER"" env is tested,; which can defined with placeholders via the xpd.putenv directive in the; xrootd/xproofd config files.; Improving parsing of lines with memory info.; This solves occasional crashes while generating the memory; plots.; In TProofMgr::GetSessionLogs:. add the possibility to postpone the retrieval of the; logs files when the TProofLog object is created. This improved; functionality is exploited in the log window.; add decoding of the session starting time and full; information about the master URL. Enable new xrootd configuration options, including the; possibility to set the compiler and linker; Cleanup of the TProofMgr functions DetachSession and; ShutdownSession, and better handling of the internal list registration,; to fix potential segvs when reopening a PROOF session inside the same; ROOT session.; Optimize the way results are transferred and merged:. Output objects are added to the same TMessage until a; HWM is reached (default 1MB; controlled by 'ProofServ.MsgSizeHWM');; this limits the number of transfers in the case of large numbers of; small objects.; Reasonably small histograms (GetSize() <; MsgSizeHWM) are merged in one-go at the end instead of one-by-one to; exploit, for example, the better performance of TH1::Merge on the full; list of histos.; Add possibility to comp",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:6213,Testability,log,log,6213,"server base; add also two new methods:. TProof::SetDataSetTreeName(<dataset>,<treename>):; set/change the default tree name in the TFileCollection;; TProof::ExistsDataSet(<dataset>):; check; by-name the availability of a given dataset;. In ProofBench, . Load the macro before executing it. This allows to; circumvent a problem recently fixed giving less dependency on the; server version.; In make_dset.C, simplification of the body and of the; signature, eliminating one redundant argument. In TProofOutputFile, improve flexibility in defining the; URL for the local files server. The ""LOCALDATASERVER"" env is tested,; which can defined with placeholders via the xpd.putenv directive in the; xrootd/xproofd config files.; Improving parsing of lines with memory info.; This solves occasional crashes while generating the memory; plots.; In TProofMgr::GetSessionLogs:. add the possibility to postpone the retrieval of the; logs files when the TProofLog object is created. This improved; functionality is exploited in the log window.; add decoding of the session starting time and full; information about the master URL. Enable new xrootd configuration options, including the; possibility to set the compiler and linker; Cleanup of the TProofMgr functions DetachSession and; ShutdownSession, and better handling of the internal list registration,; to fix potential segvs when reopening a PROOF session inside the same; ROOT session.; Optimize the way results are transferred and merged:. Output objects are added to the same TMessage until a; HWM is reached (default 1MB; controlled by 'ProofServ.MsgSizeHWM');; this limits the number of transfers in the case of large numbers of; small objects.; Reasonably small histograms (GetSize() <; MsgSizeHWM) are merged in one-go at the end instead of one-by-one to; exploit, for example, the better performance of TH1::Merge on the full; list of histos.; Add possibility to compress the messages; this is; controlled by ProofServ.CompressMessage; <compression_",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:7490,Testability,assert,asserts,7490,"o fix potential segvs when reopening a PROOF session inside the same; ROOT session.; Optimize the way results are transferred and merged:. Output objects are added to the same TMessage until a; HWM is reached (default 1MB; controlled by 'ProofServ.MsgSizeHWM');; this limits the number of transfers in the case of large numbers of; small objects.; Reasonably small histograms (GetSize() <; MsgSizeHWM) are merged in one-go at the end instead of one-by-one to; exploit, for example, the better performance of TH1::Merge on the full; list of histos.; Add possibility to compress the messages; this is; controlled by ProofServ.CompressMessage; <compression_level>; The default is still 'no compression' but this will allow to study the; impact of compression. Add sort of 'progress' counter for merging is now shown; on the client:;  ;     root [n] p->Process(...);       ... ;       Mst-0: merging output objects ... / (4; workers still sending). This asserts socket activity and fixes the timeout; problems during long merging phases reported in a few cases.; In TFileMerger, create directly the output file at the; final destination do not make a local copy in the temp directory first; (if needed, one can always set the temporary destination to temp; followed by a TFile::Cp to the final destination); this allows to avoid; reported problems with small temp partitions (see Forum).; In XrdProofConn, enable cycling through the; authentication protocol presented by the server. This only holds for; the choice of the protocol, because the server currently supports only; one full handshake.; In test/stressProof.cxx, avoid interferences between the; settings used for the PROOF tutorial and possible local settings; (daemon, dataset manager).; Add possibility to control the automatic re-loading of; the <proof.conf> file via the keyword; 'reload:1'/'reload:0'; in the xpd.resource directive.; Move the validation of <proof.conf> at the; moment of use; this allows to specify a file path and to dynam",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:8136,Testability,test,test,8136,"ntrolled by ProofServ.CompressMessage; <compression_level>; The default is still 'no compression' but this will allow to study the; impact of compression. Add sort of 'progress' counter for merging is now shown; on the client:;  ;     root [n] p->Process(...);       ... ;       Mst-0: merging output objects ... / (4; workers still sending). This asserts socket activity and fixes the timeout; problems during long merging phases reported in a few cases.; In TFileMerger, create directly the output file at the; final destination do not make a local copy in the temp directory first; (if needed, one can always set the temporary destination to temp; followed by a TFile::Cp to the final destination); this allows to avoid; reported problems with small temp partitions (see Forum).; In XrdProofConn, enable cycling through the; authentication protocol presented by the server. This only holds for; the choice of the protocol, because the server currently supports only; one full handshake.; In test/stressProof.cxx, avoid interferences between the; settings used for the PROOF tutorial and possible local settings; (daemon, dataset manager).; Add possibility to control the automatic re-loading of; the <proof.conf> file via the keyword; 'reload:1'/'reload:0'; in the xpd.resource directive.; Move the validation of <proof.conf> at the; moment of use; this allows to specify a file path and to dynamically; create/modify/destroy the file; used by PoD.; Improve displaying speed of large log files. Fixes. Fix two severe; bugs in the way TTreeCache; was used in PROOF: one bug was de facto disactivating the cache; the; other was causing a std::bad_alloc exception to be thrown on workers; when opening a remote file after a local one.    ; Fix several problems in TChain::Draw including. drawing into an existing histogram, i.e.; chain->Draw(""var>>myhist"");. treatment of histogram merging in case of small; statistics, i.e. when; the autobinning is not or only partially active;. usage of existing c",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:8629,Testability,log,log,8629,"reate directly the output file at the; final destination do not make a local copy in the temp directory first; (if needed, one can always set the temporary destination to temp; followed by a TFile::Cp to the final destination); this allows to avoid; reported problems with small temp partitions (see Forum).; In XrdProofConn, enable cycling through the; authentication protocol presented by the server. This only holds for; the choice of the protocol, because the server currently supports only; one full handshake.; In test/stressProof.cxx, avoid interferences between the; settings used for the PROOF tutorial and possible local settings; (daemon, dataset manager).; Add possibility to control the automatic re-loading of; the <proof.conf> file via the keyword; 'reload:1'/'reload:0'; in the xpd.resource directive.; Move the validation of <proof.conf> at the; moment of use; this allows to specify a file path and to dynamically; create/modify/destroy the file; used by PoD.; Improve displaying speed of large log files. Fixes. Fix two severe; bugs in the way TTreeCache; was used in PROOF: one bug was de facto disactivating the cache; the; other was causing a std::bad_alloc exception to be thrown on workers; when opening a remote file after a local one.    ; Fix several problems in TChain::Draw including. drawing into an existing histogram, i.e.; chain->Draw(""var>>myhist"");. treatment of histogram merging in case of small; statistics, i.e. when; the autobinning is not or only partially active;. usage of existing canvases when different histogram; names are specified;. Fix a problem causing a duplication of the final feedback; object. Fix problem with determining the subdir name in; TFileMerger::MergeRecursive on Windows; Make sure that the default sandbox is under $HOME/.proof; Fix a problem with dataset validation in multi-level; master setups; Fix a problem with ordinal numbers in multi-master setups; Fix a problem with defining the internal paths for; executables when configu",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:9381,Testability,sandbox,sandbox,9381,"ng of; the <proof.conf> file via the keyword; 'reload:1'/'reload:0'; in the xpd.resource directive.; Move the validation of <proof.conf> at the; moment of use; this allows to specify a file path and to dynamically; create/modify/destroy the file; used by PoD.; Improve displaying speed of large log files. Fixes. Fix two severe; bugs in the way TTreeCache; was used in PROOF: one bug was de facto disactivating the cache; the; other was causing a std::bad_alloc exception to be thrown on workers; when opening a remote file after a local one.    ; Fix several problems in TChain::Draw including. drawing into an existing histogram, i.e.; chain->Draw(""var>>myhist"");. treatment of histogram merging in case of small; statistics, i.e. when; the autobinning is not or only partially active;. usage of existing canvases when different histogram; names are specified;. Fix a problem causing a duplication of the final feedback; object. Fix problem with determining the subdir name in; TFileMerger::MergeRecursive on Windows; Make sure that the default sandbox is under $HOME/.proof; Fix a problem with dataset validation in multi-level; master setups; Fix a problem with ordinal numbers in multi-master setups; Fix a problem with defining the internal paths for; executables when configuring with '--prefix'; Fix backward-incompatibility issue giving the error; message  ""unknown action code: 5112""; Fix a few problems with file retrieval from the cache; Fix a problem with iteration of a std::list occasionally; causing seg-violations in TXSocket; Fix a few problems preventing correct usage of entry; lists in PROOF; Fix a problem with the permissions of the credentials; files created under <sandbox>/.creds; Fix a potential problem while determining the log paths; in log retrieval. Do not use vnsprintf in the XrdProofd plug-in, potential; source of deadlocks.; Fix a problem overwriting the local environment settings; for the xrootd sec modules; In XrdProofdProofServMgr::Destroy, fix segv in messag",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:10024,Testability,sandbox,sandbox,10024,"as de facto disactivating the cache; the; other was causing a std::bad_alloc exception to be thrown on workers; when opening a remote file after a local one.    ; Fix several problems in TChain::Draw including. drawing into an existing histogram, i.e.; chain->Draw(""var>>myhist"");. treatment of histogram merging in case of small; statistics, i.e. when; the autobinning is not or only partially active;. usage of existing canvases when different histogram; names are specified;. Fix a problem causing a duplication of the final feedback; object. Fix problem with determining the subdir name in; TFileMerger::MergeRecursive on Windows; Make sure that the default sandbox is under $HOME/.proof; Fix a problem with dataset validation in multi-level; master setups; Fix a problem with ordinal numbers in multi-master setups; Fix a problem with defining the internal paths for; executables when configuring with '--prefix'; Fix backward-incompatibility issue giving the error; message  ""unknown action code: 5112""; Fix a few problems with file retrieval from the cache; Fix a problem with iteration of a std::list occasionally; causing seg-violations in TXSocket; Fix a few problems preventing correct usage of entry; lists in PROOF; Fix a problem with the permissions of the credentials; files created under <sandbox>/.creds; Fix a potential problem while determining the log paths; in log retrieval. Do not use vnsprintf in the XrdProofd plug-in, potential; source of deadlocks.; Fix a problem overwriting the local environment settings; for the xrootd sec modules; In XrdProofdProofServMgr::Destroy, fix segv in message; creation when all sessions are destroyed at once; Fix a problem determining the relative time order of old; sessions for log retrieval; In TProof::HandleInputMessage, fix possible double delete; after kPROOF_STOPPROCESS; Fix a couple of issues on reconnection to a running; session (some dialog buttons not in the correct state; logs not; correctly redirected); Fix a problem creati",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:10087,Testability,log,log,10087,"r was causing a std::bad_alloc exception to be thrown on workers; when opening a remote file after a local one.    ; Fix several problems in TChain::Draw including. drawing into an existing histogram, i.e.; chain->Draw(""var>>myhist"");. treatment of histogram merging in case of small; statistics, i.e. when; the autobinning is not or only partially active;. usage of existing canvases when different histogram; names are specified;. Fix a problem causing a duplication of the final feedback; object. Fix problem with determining the subdir name in; TFileMerger::MergeRecursive on Windows; Make sure that the default sandbox is under $HOME/.proof; Fix a problem with dataset validation in multi-level; master setups; Fix a problem with ordinal numbers in multi-master setups; Fix a problem with defining the internal paths for; executables when configuring with '--prefix'; Fix backward-incompatibility issue giving the error; message  ""unknown action code: 5112""; Fix a few problems with file retrieval from the cache; Fix a problem with iteration of a std::list occasionally; causing seg-violations in TXSocket; Fix a few problems preventing correct usage of entry; lists in PROOF; Fix a problem with the permissions of the credentials; files created under <sandbox>/.creds; Fix a potential problem while determining the log paths; in log retrieval. Do not use vnsprintf in the XrdProofd plug-in, potential; source of deadlocks.; Fix a problem overwriting the local environment settings; for the xrootd sec modules; In XrdProofdProofServMgr::Destroy, fix segv in message; creation when all sessions are destroyed at once; Fix a problem determining the relative time order of old; sessions for log retrieval; In TProof::HandleInputMessage, fix possible double delete; after kPROOF_STOPPROCESS; Fix a couple of issues on reconnection to a running; session (some dialog buttons not in the correct state; logs not; correctly redirected); Fix a problem creating spurious warnings during 'draw'; queries. ",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:10101,Testability,log,log,10101,"r was causing a std::bad_alloc exception to be thrown on workers; when opening a remote file after a local one.    ; Fix several problems in TChain::Draw including. drawing into an existing histogram, i.e.; chain->Draw(""var>>myhist"");. treatment of histogram merging in case of small; statistics, i.e. when; the autobinning is not or only partially active;. usage of existing canvases when different histogram; names are specified;. Fix a problem causing a duplication of the final feedback; object. Fix problem with determining the subdir name in; TFileMerger::MergeRecursive on Windows; Make sure that the default sandbox is under $HOME/.proof; Fix a problem with dataset validation in multi-level; master setups; Fix a problem with ordinal numbers in multi-master setups; Fix a problem with defining the internal paths for; executables when configuring with '--prefix'; Fix backward-incompatibility issue giving the error; message  ""unknown action code: 5112""; Fix a few problems with file retrieval from the cache; Fix a problem with iteration of a std::list occasionally; causing seg-violations in TXSocket; Fix a few problems preventing correct usage of entry; lists in PROOF; Fix a problem with the permissions of the credentials; files created under <sandbox>/.creds; Fix a potential problem while determining the log paths; in log retrieval. Do not use vnsprintf in the XrdProofd plug-in, potential; source of deadlocks.; Fix a problem overwriting the local environment settings; for the xrootd sec modules; In XrdProofdProofServMgr::Destroy, fix segv in message; creation when all sessions are destroyed at once; Fix a problem determining the relative time order of old; sessions for log retrieval; In TProof::HandleInputMessage, fix possible double delete; after kPROOF_STOPPROCESS; Fix a couple of issues on reconnection to a running; session (some dialog buttons not in the correct state; logs not; correctly redirected); Fix a problem creating spurious warnings during 'draw'; queries. ",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:10459,Testability,log,log,10459,"r was causing a std::bad_alloc exception to be thrown on workers; when opening a remote file after a local one.    ; Fix several problems in TChain::Draw including. drawing into an existing histogram, i.e.; chain->Draw(""var>>myhist"");. treatment of histogram merging in case of small; statistics, i.e. when; the autobinning is not or only partially active;. usage of existing canvases when different histogram; names are specified;. Fix a problem causing a duplication of the final feedback; object. Fix problem with determining the subdir name in; TFileMerger::MergeRecursive on Windows; Make sure that the default sandbox is under $HOME/.proof; Fix a problem with dataset validation in multi-level; master setups; Fix a problem with ordinal numbers in multi-master setups; Fix a problem with defining the internal paths for; executables when configuring with '--prefix'; Fix backward-incompatibility issue giving the error; message  ""unknown action code: 5112""; Fix a few problems with file retrieval from the cache; Fix a problem with iteration of a std::list occasionally; causing seg-violations in TXSocket; Fix a few problems preventing correct usage of entry; lists in PROOF; Fix a problem with the permissions of the credentials; files created under <sandbox>/.creds; Fix a potential problem while determining the log paths; in log retrieval. Do not use vnsprintf in the XrdProofd plug-in, potential; source of deadlocks.; Fix a problem overwriting the local environment settings; for the xrootd sec modules; In XrdProofdProofServMgr::Destroy, fix segv in message; creation when all sessions are destroyed at once; Fix a problem determining the relative time order of old; sessions for log retrieval; In TProof::HandleInputMessage, fix possible double delete; after kPROOF_STOPPROCESS; Fix a couple of issues on reconnection to a running; session (some dialog buttons not in the correct state; logs not; correctly redirected); Fix a problem creating spurious warnings during 'draw'; queries. ",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:10667,Testability,log,logs,10667,"r was causing a std::bad_alloc exception to be thrown on workers; when opening a remote file after a local one.    ; Fix several problems in TChain::Draw including. drawing into an existing histogram, i.e.; chain->Draw(""var>>myhist"");. treatment of histogram merging in case of small; statistics, i.e. when; the autobinning is not or only partially active;. usage of existing canvases when different histogram; names are specified;. Fix a problem causing a duplication of the final feedback; object. Fix problem with determining the subdir name in; TFileMerger::MergeRecursive on Windows; Make sure that the default sandbox is under $HOME/.proof; Fix a problem with dataset validation in multi-level; master setups; Fix a problem with ordinal numbers in multi-master setups; Fix a problem with defining the internal paths for; executables when configuring with '--prefix'; Fix backward-incompatibility issue giving the error; message  ""unknown action code: 5112""; Fix a few problems with file retrieval from the cache; Fix a problem with iteration of a std::list occasionally; causing seg-violations in TXSocket; Fix a few problems preventing correct usage of entry; lists in PROOF; Fix a problem with the permissions of the credentials; files created under <sandbox>/.creds; Fix a potential problem while determining the log paths; in log retrieval. Do not use vnsprintf in the XrdProofd plug-in, potential; source of deadlocks.; Fix a problem overwriting the local environment settings; for the xrootd sec modules; In XrdProofdProofServMgr::Destroy, fix segv in message; creation when all sessions are destroyed at once; Fix a problem determining the relative time order of old; sessions for log retrieval; In TProof::HandleInputMessage, fix possible double delete; after kPROOF_STOPPROCESS; Fix a couple of issues on reconnection to a running; session (some dialog buttons not in the correct state; logs not; correctly redirected); Fix a problem creating spurious warnings during 'draw'; queries. ",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:1591,Usability,simpl,simplifies,1591,"ly 3 sessions. Additional requests are queued; and run as soon as one of the running; sessions goes idle. The current policy is FIFO, so that there is a; rotation among queued; sessions. In the case of load-based worker assignment, the max number; of running; queries is determined dynamically.; Add support for repeat functionality in the xrd.worker; directive. To avoid repeating the same line N times; one can just add; 'repeat=N'; in the line; for; example;            ;     xpd.worker worker; proofwrks:2093 repeat=4; will define 4 workers on port 2093 of machine 'proofwrks'.; Add support for port specification via the directive; 'xpd.port'; Enable variable; substitution in 'xpd.' directives using the standard; Scalla mechanism described in; http://xrootd.slac.stanford.edu/doc/dev/Syntax_config.htm .; Build also a binary named 'xproofd' which runs; a xrootd; daemon with only the XrdProofdProtocol (i.e. no data serving).; This simplifies setups when data serving is not needed and also allows; to better disantagle problems related to one specific protocol. The new; binary accepts the same arguments as 'xrootd' and parses the same; directives form the same configuration file, with the exception of; 'xpd.protocol xproofd libXrdProofd.so' which should now be dropped. AN; alternative port can be specified via the new 'xpd.port' directive (see; above).; Add support for 'MasterOnly' mode in starting a PROOF; session. This avoids starting the workers when one wants just to browse; the datasets or retrieve results. To start a session in 'MasterOnly'; mode enter ""masteronly""; as second argument to TProof::Open, e.g.;  ;          root[]; TProof *p = TProof::Open(""<masterurl>"", ""masteronly""); Add full support for placeholders; <uid>,; <gid>, <group> and <homedir>; for the directives specified via 'xpd.putenv'; Add the configuration directive 'proofservparents' to; allow specifying a different list of parent names for the 'proofserv'; tasks. This is needed to avoid untimely killing",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:5599,Usability,simpl,simplification,5599,"sion being browsed.; A set of scripts for quick interaction with a dataset; manager via PROOF are available under $ROOTSYS/etc/proof/utils/pq2 .; The scripts are prefixed; pq2 (proof; quick query - or; proof-dq2); and allow to {browse, register, remove, verify} datasets on a given; PROOF master. See $ROOTSYS/etc/proof/utils/pq2/README for more; information. Improvements. Enable by default schema evolution in TMessage; can be; disabled setting 'Proof.SchemaEvolution:; 0' .; Extend the functionality of the dataset API to obtaine; information on per-server base; add also two new methods:. TProof::SetDataSetTreeName(<dataset>,<treename>):; set/change the default tree name in the TFileCollection;; TProof::ExistsDataSet(<dataset>):; check; by-name the availability of a given dataset;. In ProofBench, . Load the macro before executing it. This allows to; circumvent a problem recently fixed giving less dependency on the; server version.; In make_dset.C, simplification of the body and of the; signature, eliminating one redundant argument. In TProofOutputFile, improve flexibility in defining the; URL for the local files server. The ""LOCALDATASERVER"" env is tested,; which can defined with placeholders via the xpd.putenv directive in the; xrootd/xproofd config files.; Improving parsing of lines with memory info.; This solves occasional crashes while generating the memory; plots.; In TProofMgr::GetSessionLogs:. add the possibility to postpone the retrieval of the; logs files when the TProofLog object is created. This improved; functionality is exploited in the log window.; add decoding of the session starting time and full; information about the master URL. Enable new xrootd configuration options, including the; possibility to set the compiler and linker; Cleanup of the TProofMgr functions DetachSession and; ShutdownSession, and better handling of the internal list registration,; to fix potential segvs when reopening a PROOF session inside the same; ROOT session.; Optimize the wa",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html:9247,Usability,feedback,feedback,9247,"d possible local settings; (daemon, dataset manager).; Add possibility to control the automatic re-loading of; the <proof.conf> file via the keyword; 'reload:1'/'reload:0'; in the xpd.resource directive.; Move the validation of <proof.conf> at the; moment of use; this allows to specify a file path and to dynamically; create/modify/destroy the file; used by PoD.; Improve displaying speed of large log files. Fixes. Fix two severe; bugs in the way TTreeCache; was used in PROOF: one bug was de facto disactivating the cache; the; other was causing a std::bad_alloc exception to be thrown on workers; when opening a remote file after a local one.    ; Fix several problems in TChain::Draw including. drawing into an existing histogram, i.e.; chain->Draw(""var>>myhist"");. treatment of histogram merging in case of small; statistics, i.e. when; the autobinning is not or only partially active;. usage of existing canvases when different histogram; names are specified;. Fix a problem causing a duplication of the final feedback; object. Fix problem with determining the subdir name in; TFileMerger::MergeRecursive on Windows; Make sure that the default sandbox is under $HOME/.proof; Fix a problem with dataset validation in multi-level; master setups; Fix a problem with ordinal numbers in multi-master setups; Fix a problem with defining the internal paths for; executables when configuring with '--prefix'; Fix backward-incompatibility issue giving the error; message  ""unknown action code: 5112""; Fix a few problems with file retrieval from the cache; Fix a problem with iteration of a std::list occasionally; causing seg-violations in TXSocket; Fix a few problems preventing correct usage of entry; lists in PROOF; Fix a problem with the permissions of the credentials; files created under <sandbox>/.creds; Fix a potential problem while determining the log paths; in log retrieval. Do not use vnsprintf in the XrdProofd plug-in, potential; source of deadlocks.; Fix a problem overwriting the local",MatchSource.DOCS,proof/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html:157,Availability,down,download,157,". ; Proof. New functionality. TProofMgr. Add support for the following functionality:. sandbox file listing and browsing; sandbox file removal; file upload, download. TProofDraw. Allow to set a color, size, size, width for lines,; area, markers; the attributes are transmitted via the input list and; automatically derived from the ones of the chain. Support automatic creation of a dataset out of files; created on the worker nodes by worker processes. The implementation is; an extension of the functionality of the class TProofOutputFile used; for merging via file.; Add the possibility to enable/disable the tree cache and; to change its size on per-query base; two new parameters are available:. PROOF_UseTreeCache   ; Int_t       ; Enable (0) or Disable (1) the tree cache (default 1); PROOF_CacheSize      ; Long64_t     Cache size in bytes; (default 10000000). Examples:;        ; a) to disable the cache for the next run enter:;                                 ; proof->SetParameter(""PROOF_UseTreeCache"", 0);        ; b) to set the cache size to 20M;                                 ; proof->SetParameter(""PROOF_CacheSize"", 20000000);  Add the parameter; PROOF_UseParallelUnzip to toggle the use of the parallel unzip; (default off for now); to enable it add the following call;            ;            ;        ;  proof->SetParameter(""PROOF_UseParallelUnzip"", 1).  Add the possibility to give indications about; the number of workers at startup.;  E.g.;        1. To; start max 5 workers;             ; TProof::Open(""<master>"",""workers=5"");        2. To; start max 2 workers per physical machine;             ; TProof::Open(""<master>"",""workers=2x"");      This is useful in general when; running tests (equivalent but quicker then full startup;      followed by; TProof::SetParallel(n) or TProof::DeactivateWorker(...)).; Add support for the worker SysInfo_t in TSlaveInfo; (obtained via TProof::GetListOfSlaveInfos()); Add new submerger functionality to speed up the merging; phase. At the e",MatchSource.DOCS,proof/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html:689,Availability,avail,available,689,". ; Proof. New functionality. TProofMgr. Add support for the following functionality:. sandbox file listing and browsing; sandbox file removal; file upload, download. TProofDraw. Allow to set a color, size, size, width for lines,; area, markers; the attributes are transmitted via the input list and; automatically derived from the ones of the chain. Support automatic creation of a dataset out of files; created on the worker nodes by worker processes. The implementation is; an extension of the functionality of the class TProofOutputFile used; for merging via file.; Add the possibility to enable/disable the tree cache and; to change its size on per-query base; two new parameters are available:. PROOF_UseTreeCache   ; Int_t       ; Enable (0) or Disable (1) the tree cache (default 1); PROOF_CacheSize      ; Long64_t     Cache size in bytes; (default 10000000). Examples:;        ; a) to disable the cache for the next run enter:;                                 ; proof->SetParameter(""PROOF_UseTreeCache"", 0);        ; b) to set the cache size to 20M;                                 ; proof->SetParameter(""PROOF_CacheSize"", 20000000);  Add the parameter; PROOF_UseParallelUnzip to toggle the use of the parallel unzip; (default off for now); to enable it add the following call;            ;            ;        ;  proof->SetParameter(""PROOF_UseParallelUnzip"", 1).  Add the possibility to give indications about; the number of workers at startup.;  E.g.;        1. To; start max 5 workers;             ; TProof::Open(""<master>"",""workers=5"");        2. To; start max 2 workers per physical machine;             ; TProof::Open(""<master>"",""workers=2x"");      This is useful in general when; running tests (equivalent but quicker then full startup;      followed by; TProof::SetParallel(n) or TProof::DeactivateWorker(...)).; Add support for the worker SysInfo_t in TSlaveInfo; (obtained via TProof::GetListOfSlaveInfos()); Add new submerger functionality to speed up the merging; phase. At the e",MatchSource.DOCS,proof/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html:6246,Availability,error,error,6246,"sessions running; concurrently on the cluster (started by the same daemon); this plot is; present only is the number is at least onec different from 1. If enabled, send monitoring information from the master; at each GetNextPacket (at each call of TPerfStat::PacketEvent) to allow; extrnal real-time progress monitoring.; Save the status of a 'proofserv' session into a new file; in the 'activesessions' area. The full path of the new file is;          ; <admin_path>/.xproofd.<port>/activesessions/<user>.<group>.<pid>.status. The status indicates whether the session is idle, running or queued.; The status is updated every 'checkfq' secs (see xpd.proofservmgr;; default 30 s). The status is dumped by the reader thread of TXProofServ; and therefore its r/w access is protected. Enable the use of the tree cache also for local files,; adapting the default settings for the cache to the recent changes; In the XrdProofd plug-in. Improve synchronization between parent and child during; fork; Optimize loops over directory entries; Improve error and notification messages. Improved handling of Ctrl-C; this follows from a fix in; TMonitor and an improved handling of non-finished query state in the; workers (results are not send to master if the query was aborted) . Fixes. TFileMerger. Fix a problem preventing correct transmission of all; non-mergeable objects (fixes bug #52886); Remove the argument isdir from the function; MergeRecursive; Do not remove the first file in the list when returning; from MergeRecursive (fixes bug #54591); Fix a major leak when merging files with collections; written using kSingleKey option.  The merger was reading each; key in memory and deleted the object at the end, but the container is; not owner by default, so all objects inside leaked. PROOF-Lite. Fix a couple of memory leaks showing up when running; repeated queries; Fix a problem in TProofServ::CopyFromCache affecting; the case where the sandbox dir has a '.' and the macro name has no '.',; e.g. com",MatchSource.DOCS,proof/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html:1190,Deployability,toggle,toggle,1190,"; sandbox file removal; file upload, download. TProofDraw. Allow to set a color, size, size, width for lines,; area, markers; the attributes are transmitted via the input list and; automatically derived from the ones of the chain. Support automatic creation of a dataset out of files; created on the worker nodes by worker processes. The implementation is; an extension of the functionality of the class TProofOutputFile used; for merging via file.; Add the possibility to enable/disable the tree cache and; to change its size on per-query base; two new parameters are available:. PROOF_UseTreeCache   ; Int_t       ; Enable (0) or Disable (1) the tree cache (default 1); PROOF_CacheSize      ; Long64_t     Cache size in bytes; (default 10000000). Examples:;        ; a) to disable the cache for the next run enter:;                                 ; proof->SetParameter(""PROOF_UseTreeCache"", 0);        ; b) to set the cache size to 20M;                                 ; proof->SetParameter(""PROOF_CacheSize"", 20000000);  Add the parameter; PROOF_UseParallelUnzip to toggle the use of the parallel unzip; (default off for now); to enable it add the following call;            ;            ;        ;  proof->SetParameter(""PROOF_UseParallelUnzip"", 1).  Add the possibility to give indications about; the number of workers at startup.;  E.g.;        1. To; start max 5 workers;             ; TProof::Open(""<master>"",""workers=5"");        2. To; start max 2 workers per physical machine;             ; TProof::Open(""<master>"",""workers=2x"");      This is useful in general when; running tests (equivalent but quicker then full startup;      followed by; TProof::SetParallel(n) or TProof::DeactivateWorker(...)).; Add support for the worker SysInfo_t in TSlaveInfo; (obtained via TProof::GetListOfSlaveInfos()); Add new submerger functionality to speed up the merging; phase. At the end of the query, a set of workers are promoted; submergers and assigned a sub-set of workers to merge. Once each; sub-me",MatchSource.DOCS,proof/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html:5818,Deployability,update,updated,5818,"etter; estimated by a better estimation of the normalizing times; Average read chunck size, defined as; TFile::GetFileBytesRead() / TFile::GetFileReadCalls() during the last; unit of time; this allows to monitor the usage of the cache; this plot; is present only if some I/O is done, i.e. not for pure CPU tasks.; The number of active workers; The number of total and effecive sessions running; concurrently on the cluster (started by the same daemon); this plot is; present only is the number is at least onec different from 1. If enabled, send monitoring information from the master; at each GetNextPacket (at each call of TPerfStat::PacketEvent) to allow; extrnal real-time progress monitoring.; Save the status of a 'proofserv' session into a new file; in the 'activesessions' area. The full path of the new file is;          ; <admin_path>/.xproofd.<port>/activesessions/<user>.<group>.<pid>.status. The status indicates whether the session is idle, running or queued.; The status is updated every 'checkfq' secs (see xpd.proofservmgr;; default 30 s). The status is dumped by the reader thread of TXProofServ; and therefore its r/w access is protected. Enable the use of the tree cache also for local files,; adapting the default settings for the cache to the recent changes; In the XrdProofd plug-in. Improve synchronization between parent and child during; fork; Optimize loops over directory entries; Improve error and notification messages. Improved handling of Ctrl-C; this follows from a fix in; TMonitor and an improved handling of non-finished query state in the; workers (results are not send to master if the query was aborted) . Fixes. TFileMerger. Fix a problem preventing correct transmission of all; non-mergeable objects (fixes bug #52886); Remove the argument isdir from the function; MergeRecursive; Do not remove the first file in the list when returning; from MergeRecursive (fixes bug #54591); Fix a major leak when merging files with collections; written using kSingleKey op",MatchSource.DOCS,proof/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html:9094,Deployability,integrat,integration,9094,"e end-point URL for local; files; Improve realtime notification during 'verify'. TProofDraw. Fix a problem with the axis ranges of the underlying; histogram in PolyMarker3D; Allow to use the default pad instead of forcing; creation of one pad per object; Add wrapper to handle the feedback default canvas. TEventIter. Fix a problem with changing the tree cache size: the; size was reset to the default value after the first file. TDataSetManagerFile. Solve a consistency problem in checking URLs for; duplication when adding them to the relevant TFileInfo; During dataset validation, do not fail on duplications; but notify and add them to the bad file list. TPacketizerAdaptive, TPacketizer. Improve data node / worker matching by always using the; host FQDN. TPacketizerUnit, TEventIter. Make sure that the entry; number passed to TSelector::Process is unique and in increasing order; for non-data driven processing (packetizer TPacketizerUnit). This; allows to give a meaning to this variable, for example to related it to; one dimension of an integration. Fixes in PROOF-Lite:. Make sure that with envs settings via TProof::AddEnvVar; are effective; this enables, for example, the automatic valgrind setup; introduced in 5.24/00 or the experiment specific settings via the; script defined by the env PROOF_INIT; Fix a problem with TProof::Load so that now it can be; also be used for PROOF-Lite. TProofPlayerRemote. In SendSelector, add misisng; option kCpBin when sending the selector source; the binary files were;  never retrieved, even if present and valid. TProofPlayerSlave. In; Process, fix a problem with cache directory locking while building; the selector;  the net effect was that each worker process was; re-buidling its own selector binary. . TProofServ; Fix; the order in which the log file is sent in asynchronous processing; the; wrong order was screwing up an immediate synchronous query submission; after an asynchronous run; this case occured, for example, in; 'stressProof' . ",MatchSource.DOCS,proof/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html:4626,Energy Efficiency,monitor,monitoring,4626,"t from hadd a better way to invoke Merge for; generic objects; add option to merge histograms in one go, instead of; one-by-one as for generic objects (this option is not yet supported by; hadd). TProofOutputFile. Add support for the placeholder <file>; the definition of the outputfile. This allows to have complete URL and; to pass options to TFile::Open. XrdProofd plugin. Add automatically the line 'Path.ForceRemote 1' to the; session rootrc file if the ROOT version is < 5.24/00 ; this acts; as a workaround for the wrong TTreeCache initialization at the; transition between local and remote files fixed in 5.24/00 . Enable mass storage domain settings when working with; TChain's; in multi-master mode. The Mass Storage Domain must be specified as; option in the URL.              ; chain.AddFile(""root:// .....?msd=CERN"").  and the string must match the value specified in defining the; submaster node.; Improved performance monitoring: the 'Rate plot' button; in the dialog box has been renamed 'Performance Plot' and now shows up; to 4 plots as a function of the processing time:. Instantaneous processing rate, which is now better; estimated by a better estimation of the normalizing times; Average read chunck size, defined as; TFile::GetFileBytesRead() / TFile::GetFileReadCalls() during the last; unit of time; this allows to monitor the usage of the cache; this plot; is present only if some I/O is done, i.e. not for pure CPU tasks.; The number of active workers; The number of total and effecive sessions running; concurrently on the cluster (started by the same daemon); this plot is; present only is the number is at least onec different from 1. If enabled, send monitoring information from the master; at each GetNextPacket (at each call of TPerfStat::PacketEvent) to allow; extrnal real-time progress monitoring.; Save the status of a 'proofserv' session into a new file; in the 'activesessions' area. The full path of the new file is;          ; <admin_path>/.xproofd.<port>/act",MatchSource.DOCS,proof/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html:5033,Energy Efficiency,monitor,monitor,5033,"e definition of the outputfile. This allows to have complete URL and; to pass options to TFile::Open. XrdProofd plugin. Add automatically the line 'Path.ForceRemote 1' to the; session rootrc file if the ROOT version is < 5.24/00 ; this acts; as a workaround for the wrong TTreeCache initialization at the; transition between local and remote files fixed in 5.24/00 . Enable mass storage domain settings when working with; TChain's; in multi-master mode. The Mass Storage Domain must be specified as; option in the URL.              ; chain.AddFile(""root:// .....?msd=CERN"").  and the string must match the value specified in defining the; submaster node.; Improved performance monitoring: the 'Rate plot' button; in the dialog box has been renamed 'Performance Plot' and now shows up; to 4 plots as a function of the processing time:. Instantaneous processing rate, which is now better; estimated by a better estimation of the normalizing times; Average read chunck size, defined as; TFile::GetFileBytesRead() / TFile::GetFileReadCalls() during the last; unit of time; this allows to monitor the usage of the cache; this plot; is present only if some I/O is done, i.e. not for pure CPU tasks.; The number of active workers; The number of total and effecive sessions running; concurrently on the cluster (started by the same daemon); this plot is; present only is the number is at least onec different from 1. If enabled, send monitoring information from the master; at each GetNextPacket (at each call of TPerfStat::PacketEvent) to allow; extrnal real-time progress monitoring.; Save the status of a 'proofserv' session into a new file; in the 'activesessions' area. The full path of the new file is;          ; <admin_path>/.xproofd.<port>/activesessions/<user>.<group>.<pid>.status. The status indicates whether the session is idle, running or queued.; The status is updated every 'checkfq' secs (see xpd.proofservmgr;; default 30 s). The status is dumped by the reader thread of TXProofServ; and t",MatchSource.DOCS,proof/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html:5375,Energy Efficiency,monitor,monitoring,5375,"ied as; option in the URL.              ; chain.AddFile(""root:// .....?msd=CERN"").  and the string must match the value specified in defining the; submaster node.; Improved performance monitoring: the 'Rate plot' button; in the dialog box has been renamed 'Performance Plot' and now shows up; to 4 plots as a function of the processing time:. Instantaneous processing rate, which is now better; estimated by a better estimation of the normalizing times; Average read chunck size, defined as; TFile::GetFileBytesRead() / TFile::GetFileReadCalls() during the last; unit of time; this allows to monitor the usage of the cache; this plot; is present only if some I/O is done, i.e. not for pure CPU tasks.; The number of active workers; The number of total and effecive sessions running; concurrently on the cluster (started by the same daemon); this plot is; present only is the number is at least onec different from 1. If enabled, send monitoring information from the master; at each GetNextPacket (at each call of TPerfStat::PacketEvent) to allow; extrnal real-time progress monitoring.; Save the status of a 'proofserv' session into a new file; in the 'activesessions' area. The full path of the new file is;          ; <admin_path>/.xproofd.<port>/activesessions/<user>.<group>.<pid>.status. The status indicates whether the session is idle, running or queued.; The status is updated every 'checkfq' secs (see xpd.proofservmgr;; default 30 s). The status is dumped by the reader thread of TXProofServ; and therefore its r/w access is protected. Enable the use of the tree cache also for local files,; adapting the default settings for the cache to the recent changes; In the XrdProofd plug-in. Improve synchronization between parent and child during; fork; Optimize loops over directory entries; Improve error and notification messages. Improved handling of Ctrl-C; this follows from a fix in; TMonitor and an improved handling of non-finished query state in the; workers (results are not send to mas",MatchSource.DOCS,proof/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html:5515,Energy Efficiency,monitor,monitoring,5515,"ied as; option in the URL.              ; chain.AddFile(""root:// .....?msd=CERN"").  and the string must match the value specified in defining the; submaster node.; Improved performance monitoring: the 'Rate plot' button; in the dialog box has been renamed 'Performance Plot' and now shows up; to 4 plots as a function of the processing time:. Instantaneous processing rate, which is now better; estimated by a better estimation of the normalizing times; Average read chunck size, defined as; TFile::GetFileBytesRead() / TFile::GetFileReadCalls() during the last; unit of time; this allows to monitor the usage of the cache; this plot; is present only if some I/O is done, i.e. not for pure CPU tasks.; The number of active workers; The number of total and effecive sessions running; concurrently on the cluster (started by the same daemon); this plot is; present only is the number is at least onec different from 1. If enabled, send monitoring information from the master; at each GetNextPacket (at each call of TPerfStat::PacketEvent) to allow; extrnal real-time progress monitoring.; Save the status of a 'proofserv' session into a new file; in the 'activesessions' area. The full path of the new file is;          ; <admin_path>/.xproofd.<port>/activesessions/<user>.<group>.<pid>.status. The status indicates whether the session is idle, running or queued.; The status is updated every 'checkfq' secs (see xpd.proofservmgr;; default 30 s). The status is dumped by the reader thread of TXProofServ; and therefore its r/w access is protected. Enable the use of the tree cache also for local files,; adapting the default settings for the cache to the recent changes; In the XrdProofd plug-in. Improve synchronization between parent and child during; fork; Optimize loops over directory entries; Improve error and notification messages. Improved handling of Ctrl-C; this follows from a fix in; TMonitor and an improved handling of non-finished query state in the; workers (results are not send to mas",MatchSource.DOCS,proof/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html:6043,Energy Efficiency,adapt,adapting,6043,"che; this plot; is present only if some I/O is done, i.e. not for pure CPU tasks.; The number of active workers; The number of total and effecive sessions running; concurrently on the cluster (started by the same daemon); this plot is; present only is the number is at least onec different from 1. If enabled, send monitoring information from the master; at each GetNextPacket (at each call of TPerfStat::PacketEvent) to allow; extrnal real-time progress monitoring.; Save the status of a 'proofserv' session into a new file; in the 'activesessions' area. The full path of the new file is;          ; <admin_path>/.xproofd.<port>/activesessions/<user>.<group>.<pid>.status. The status indicates whether the session is idle, running or queued.; The status is updated every 'checkfq' secs (see xpd.proofservmgr;; default 30 s). The status is dumped by the reader thread of TXProofServ; and therefore its r/w access is protected. Enable the use of the tree cache also for local files,; adapting the default settings for the cache to the recent changes; In the XrdProofd plug-in. Improve synchronization between parent and child during; fork; Optimize loops over directory entries; Improve error and notification messages. Improved handling of Ctrl-C; this follows from a fix in; TMonitor and an improved handling of non-finished query state in the; workers (results are not send to master if the query was aborted) . Fixes. TFileMerger. Fix a problem preventing correct transmission of all; non-mergeable objects (fixes bug #52886); Remove the argument isdir from the function; MergeRecursive; Do not remove the first file in the list when returning; from MergeRecursive (fixes bug #54591); Fix a major leak when merging files with collections; written using kSingleKey option.  The merger was reading each; key in memory and deleted the object at the end, but the container is; not owner by default, so all objects inside leaked. PROOF-Lite. Fix a couple of memory leaks showing up when running; repeate",MatchSource.DOCS,proof/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html:6144,Integrability,synchroniz,synchronization,6144,"sessions running; concurrently on the cluster (started by the same daemon); this plot is; present only is the number is at least onec different from 1. If enabled, send monitoring information from the master; at each GetNextPacket (at each call of TPerfStat::PacketEvent) to allow; extrnal real-time progress monitoring.; Save the status of a 'proofserv' session into a new file; in the 'activesessions' area. The full path of the new file is;          ; <admin_path>/.xproofd.<port>/activesessions/<user>.<group>.<pid>.status. The status indicates whether the session is idle, running or queued.; The status is updated every 'checkfq' secs (see xpd.proofservmgr;; default 30 s). The status is dumped by the reader thread of TXProofServ; and therefore its r/w access is protected. Enable the use of the tree cache also for local files,; adapting the default settings for the cache to the recent changes; In the XrdProofd plug-in. Improve synchronization between parent and child during; fork; Optimize loops over directory entries; Improve error and notification messages. Improved handling of Ctrl-C; this follows from a fix in; TMonitor and an improved handling of non-finished query state in the; workers (results are not send to master if the query was aborted) . Fixes. TFileMerger. Fix a problem preventing correct transmission of all; non-mergeable objects (fixes bug #52886); Remove the argument isdir from the function; MergeRecursive; Do not remove the first file in the list when returning; from MergeRecursive (fixes bug #54591); Fix a major leak when merging files with collections; written using kSingleKey option.  The merger was reading each; key in memory and deleted the object at the end, but the container is; not owner by default, so all objects inside leaked. PROOF-Lite. Fix a couple of memory leaks showing up when running; repeated queries; Fix a problem in TProofServ::CopyFromCache affecting; the case where the sandbox dir has a '.' and the macro name has no '.',; e.g. com",MatchSource.DOCS,proof/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html:6269,Integrability,message,messages,6269,"sessions running; concurrently on the cluster (started by the same daemon); this plot is; present only is the number is at least onec different from 1. If enabled, send monitoring information from the master; at each GetNextPacket (at each call of TPerfStat::PacketEvent) to allow; extrnal real-time progress monitoring.; Save the status of a 'proofserv' session into a new file; in the 'activesessions' area. The full path of the new file is;          ; <admin_path>/.xproofd.<port>/activesessions/<user>.<group>.<pid>.status. The status indicates whether the session is idle, running or queued.; The status is updated every 'checkfq' secs (see xpd.proofservmgr;; default 30 s). The status is dumped by the reader thread of TXProofServ; and therefore its r/w access is protected. Enable the use of the tree cache also for local files,; adapting the default settings for the cache to the recent changes; In the XrdProofd plug-in. Improve synchronization between parent and child during; fork; Optimize loops over directory entries; Improve error and notification messages. Improved handling of Ctrl-C; this follows from a fix in; TMonitor and an improved handling of non-finished query state in the; workers (results are not send to master if the query was aborted) . Fixes. TFileMerger. Fix a problem preventing correct transmission of all; non-mergeable objects (fixes bug #52886); Remove the argument isdir from the function; MergeRecursive; Do not remove the first file in the list when returning; from MergeRecursive (fixes bug #54591); Fix a major leak when merging files with collections; written using kSingleKey option.  The merger was reading each; key in memory and deleted the object at the end, but the container is; not owner by default, so all objects inside leaked. PROOF-Lite. Fix a couple of memory leaks showing up when running; repeated queries; Fix a problem in TProofServ::CopyFromCache affecting; the case where the sandbox dir has a '.' and the macro name has no '.',; e.g. com",MatchSource.DOCS,proof/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html:8306,Integrability,wrap,wrapper,8306,"utputFile. Fix a problem with the determination of the fDir member; affecting mostly PROOF-Lite; Fix a serious issue whose net effect was to delete the; outputfile just after having open it. XrdProofd plugin. Make sure that the limit on the number of old; sessions is applied whenever a new session is started and not only when; the daemon is started.; Fix the behaviour of the xpd.allowedusers directive: if; at least one of these directives is present, users in the password file; are not allowed by default but must be explicitly appear in one; xpd.allowedusers directive  ; Fix a source for memory leak in; XrdProofdProtocol::SendMsg; Optimize the usage of strings in a few places. DataSet manager. Correctly classify as TTree all TTree derived classes; (e.g. TNtuple's); Fix a problem in saving the end-point URL for local; files; Improve realtime notification during 'verify'. TProofDraw. Fix a problem with the axis ranges of the underlying; histogram in PolyMarker3D; Allow to use the default pad instead of forcing; creation of one pad per object; Add wrapper to handle the feedback default canvas. TEventIter. Fix a problem with changing the tree cache size: the; size was reset to the default value after the first file. TDataSetManagerFile. Solve a consistency problem in checking URLs for; duplication when adding them to the relevant TFileInfo; During dataset validation, do not fail on duplications; but notify and add them to the bad file list. TPacketizerAdaptive, TPacketizer. Improve data node / worker matching by always using the; host FQDN. TPacketizerUnit, TEventIter. Make sure that the entry; number passed to TSelector::Process is unique and in increasing order; for non-data driven processing (packetizer TPacketizerUnit). This; allows to give a meaning to this variable, for example to related it to; one dimension of an integration. Fixes in PROOF-Lite:. Make sure that with envs settings via TProof::AddEnvVar; are effective; this enables, for example, the automatic valg",MatchSource.DOCS,proof/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html:9094,Integrability,integrat,integration,9094,"e end-point URL for local; files; Improve realtime notification during 'verify'. TProofDraw. Fix a problem with the axis ranges of the underlying; histogram in PolyMarker3D; Allow to use the default pad instead of forcing; creation of one pad per object; Add wrapper to handle the feedback default canvas. TEventIter. Fix a problem with changing the tree cache size: the; size was reset to the default value after the first file. TDataSetManagerFile. Solve a consistency problem in checking URLs for; duplication when adding them to the relevant TFileInfo; During dataset validation, do not fail on duplications; but notify and add them to the bad file list. TPacketizerAdaptive, TPacketizer. Improve data node / worker matching by always using the; host FQDN. TPacketizerUnit, TEventIter. Make sure that the entry; number passed to TSelector::Process is unique and in increasing order; for non-data driven processing (packetizer TPacketizerUnit). This; allows to give a meaning to this variable, for example to related it to; one dimension of an integration. Fixes in PROOF-Lite:. Make sure that with envs settings via TProof::AddEnvVar; are effective; this enables, for example, the automatic valgrind setup; introduced in 5.24/00 or the experiment specific settings via the; script defined by the env PROOF_INIT; Fix a problem with TProof::Load so that now it can be; also be used for PROOF-Lite. TProofPlayerRemote. In SendSelector, add misisng; option kCpBin when sending the selector source; the binary files were;  never retrieved, even if present and valid. TProofPlayerSlave. In; Process, fix a problem with cache directory locking while building; the selector;  the net effect was that each worker process was; re-buidling its own selector binary. . TProofServ; Fix; the order in which the log file is sent in asynchronous processing; the; wrong order was screwing up an immediate synchronous query submission; after an asynchronous run; this case occured, for example, in; 'stressProof' . ",MatchSource.DOCS,proof/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html:87,Modifiability,sandbox,sandbox,87,". ; Proof. New functionality. TProofMgr. Add support for the following functionality:. sandbox file listing and browsing; sandbox file removal; file upload, download. TProofDraw. Allow to set a color, size, size, width for lines,; area, markers; the attributes are transmitted via the input list and; automatically derived from the ones of the chain. Support automatic creation of a dataset out of files; created on the worker nodes by worker processes. The implementation is; an extension of the functionality of the class TProofOutputFile used; for merging via file.; Add the possibility to enable/disable the tree cache and; to change its size on per-query base; two new parameters are available:. PROOF_UseTreeCache   ; Int_t       ; Enable (0) or Disable (1) the tree cache (default 1); PROOF_CacheSize      ; Long64_t     Cache size in bytes; (default 10000000). Examples:;        ; a) to disable the cache for the next run enter:;                                 ; proof->SetParameter(""PROOF_UseTreeCache"", 0);        ; b) to set the cache size to 20M;                                 ; proof->SetParameter(""PROOF_CacheSize"", 20000000);  Add the parameter; PROOF_UseParallelUnzip to toggle the use of the parallel unzip; (default off for now); to enable it add the following call;            ;            ;        ;  proof->SetParameter(""PROOF_UseParallelUnzip"", 1).  Add the possibility to give indications about; the number of workers at startup.;  E.g.;        1. To; start max 5 workers;             ; TProof::Open(""<master>"",""workers=5"");        2. To; start max 2 workers per physical machine;             ; TProof::Open(""<master>"",""workers=2x"");      This is useful in general when; running tests (equivalent but quicker then full startup;      followed by; TProof::SetParallel(n) or TProof::DeactivateWorker(...)).; Add support for the worker SysInfo_t in TSlaveInfo; (obtained via TProof::GetListOfSlaveInfos()); Add new submerger functionality to speed up the merging; phase. At the e",MatchSource.DOCS,proof/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html:122,Modifiability,sandbox,sandbox,122,". ; Proof. New functionality. TProofMgr. Add support for the following functionality:. sandbox file listing and browsing; sandbox file removal; file upload, download. TProofDraw. Allow to set a color, size, size, width for lines,; area, markers; the attributes are transmitted via the input list and; automatically derived from the ones of the chain. Support automatic creation of a dataset out of files; created on the worker nodes by worker processes. The implementation is; an extension of the functionality of the class TProofOutputFile used; for merging via file.; Add the possibility to enable/disable the tree cache and; to change its size on per-query base; two new parameters are available:. PROOF_UseTreeCache   ; Int_t       ; Enable (0) or Disable (1) the tree cache (default 1); PROOF_CacheSize      ; Long64_t     Cache size in bytes; (default 10000000). Examples:;        ; a) to disable the cache for the next run enter:;                                 ; proof->SetParameter(""PROOF_UseTreeCache"", 0);        ; b) to set the cache size to 20M;                                 ; proof->SetParameter(""PROOF_CacheSize"", 20000000);  Add the parameter; PROOF_UseParallelUnzip to toggle the use of the parallel unzip; (default off for now); to enable it add the following call;            ;            ;        ;  proof->SetParameter(""PROOF_UseParallelUnzip"", 1).  Add the possibility to give indications about; the number of workers at startup.;  E.g.;        1. To; start max 5 workers;             ; TProof::Open(""<master>"",""workers=5"");        2. To; start max 2 workers per physical machine;             ; TProof::Open(""<master>"",""workers=2x"");      This is useful in general when; running tests (equivalent but quicker then full startup;      followed by; TProof::SetParallel(n) or TProof::DeactivateWorker(...)).; Add support for the worker SysInfo_t in TSlaveInfo; (obtained via TProof::GetListOfSlaveInfos()); Add new submerger functionality to speed up the merging; phase. At the e",MatchSource.DOCS,proof/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html:3378,Modifiability,variab,variable,3378,". An optimal (i.e. giving the; highest speed-up) number can be calculated analytically under simple; assumptions.; Merging via submergers is by default disabled. To enable it, with the; optimal number of sub-mergers, one should set the integer parameter; 'PROOF_UseMergers' to 0, i.e.                     ; proof->SetParameter(""PROOF_UseMergers"", 0). To force S sub-mergers (regardless of the optimal number) do.                     ; proof->SetParameter(""PROOF_UseMergers"", S). The new functionality can be tested in tutorials by adding the argument; 'submergers' to runProof, e.g. .        ;        ;      root [0] .L; tutorials/proof/runProof.C+ ;        ;        ;      root [1]; runProof(""simple(nhist=10000,submergers)"") . (see the top of tutorials/proof/runProof.C for additional options). A test for the submerger functionality has also been added to; test/stressProof.cxx .; In PROOF-Lite, add the possibility for the administrator; to control the number of workers. This is done using; the rootrc variable ProofLite.MaxWorkers, which is read out of; /etc/system.rootrc and cannot be overwritten by users. Setting the; value to 0 disables PROOF-Lite. Improvements. TFileMerger. A few improvements on the way to make TFileMerger and; hadd totally equivalent:. import from hadd an optimization of key hashing; import from hadd a better way to invoke Merge for; generic objects; add option to merge histograms in one go, instead of; one-by-one as for generic objects (this option is not yet supported by; hadd). TProofOutputFile. Add support for the placeholder <file>; the definition of the outputfile. This allows to have complete URL and; to pass options to TFile::Open. XrdProofd plugin. Add automatically the line 'Path.ForceRemote 1' to the; session rootrc file if the ROOT version is < 5.24/00 ; this acts; as a workaround for the wrong TTreeCache initialization at the; transition between local and remote files fixed in 5.24/00 . Enable mass storage domain settings when working with; T",MatchSource.DOCS,proof/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html:4061,Modifiability,plugin,plugin,4061,"roof(""simple(nhist=10000,submergers)"") . (see the top of tutorials/proof/runProof.C for additional options). A test for the submerger functionality has also been added to; test/stressProof.cxx .; In PROOF-Lite, add the possibility for the administrator; to control the number of workers. This is done using; the rootrc variable ProofLite.MaxWorkers, which is read out of; /etc/system.rootrc and cannot be overwritten by users. Setting the; value to 0 disables PROOF-Lite. Improvements. TFileMerger. A few improvements on the way to make TFileMerger and; hadd totally equivalent:. import from hadd an optimization of key hashing; import from hadd a better way to invoke Merge for; generic objects; add option to merge histograms in one go, instead of; one-by-one as for generic objects (this option is not yet supported by; hadd). TProofOutputFile. Add support for the placeholder <file>; the definition of the outputfile. This allows to have complete URL and; to pass options to TFile::Open. XrdProofd plugin. Add automatically the line 'Path.ForceRemote 1' to the; session rootrc file if the ROOT version is < 5.24/00 ; this acts; as a workaround for the wrong TTreeCache initialization at the; transition between local and remote files fixed in 5.24/00 . Enable mass storage domain settings when working with; TChain's; in multi-master mode. The Mass Storage Domain must be specified as; option in the URL.              ; chain.AddFile(""root:// .....?msd=CERN"").  and the string must match the value specified in defining the; submaster node.; Improved performance monitoring: the 'Rate plot' button; in the dialog box has been renamed 'Performance Plot' and now shows up; to 4 plots as a function of the processing time:. Instantaneous processing rate, which is now better; estimated by a better estimation of the normalizing times; Average read chunck size, defined as; TFile::GetFileBytesRead() / TFile::GetFileReadCalls() during the last; unit of time; this allows to monitor the usage of the c",MatchSource.DOCS,proof/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html:6043,Modifiability,adapt,adapting,6043,"che; this plot; is present only if some I/O is done, i.e. not for pure CPU tasks.; The number of active workers; The number of total and effecive sessions running; concurrently on the cluster (started by the same daemon); this plot is; present only is the number is at least onec different from 1. If enabled, send monitoring information from the master; at each GetNextPacket (at each call of TPerfStat::PacketEvent) to allow; extrnal real-time progress monitoring.; Save the status of a 'proofserv' session into a new file; in the 'activesessions' area. The full path of the new file is;          ; <admin_path>/.xproofd.<port>/activesessions/<user>.<group>.<pid>.status. The status indicates whether the session is idle, running or queued.; The status is updated every 'checkfq' secs (see xpd.proofservmgr;; default 30 s). The status is dumped by the reader thread of TXProofServ; and therefore its r/w access is protected. Enable the use of the tree cache also for local files,; adapting the default settings for the cache to the recent changes; In the XrdProofd plug-in. Improve synchronization between parent and child during; fork; Optimize loops over directory entries; Improve error and notification messages. Improved handling of Ctrl-C; this follows from a fix in; TMonitor and an improved handling of non-finished query state in the; workers (results are not send to master if the query was aborted) . Fixes. TFileMerger. Fix a problem preventing correct transmission of all; non-mergeable objects (fixes bug #52886); Remove the argument isdir from the function; MergeRecursive; Do not remove the first file in the list when returning; from MergeRecursive (fixes bug #54591); Fix a major leak when merging files with collections; written using kSingleKey option.  The merger was reading each; key in memory and deleted the object at the end, but the container is; not owner by default, so all objects inside leaked. PROOF-Lite. Fix a couple of memory leaks showing up when running; repeate",MatchSource.DOCS,proof/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html:6127,Modifiability,plug-in,plug-in,6127,"che; this plot; is present only if some I/O is done, i.e. not for pure CPU tasks.; The number of active workers; The number of total and effecive sessions running; concurrently on the cluster (started by the same daemon); this plot is; present only is the number is at least onec different from 1. If enabled, send monitoring information from the master; at each GetNextPacket (at each call of TPerfStat::PacketEvent) to allow; extrnal real-time progress monitoring.; Save the status of a 'proofserv' session into a new file; in the 'activesessions' area. The full path of the new file is;          ; <admin_path>/.xproofd.<port>/activesessions/<user>.<group>.<pid>.status. The status indicates whether the session is idle, running or queued.; The status is updated every 'checkfq' secs (see xpd.proofservmgr;; default 30 s). The status is dumped by the reader thread of TXProofServ; and therefore its r/w access is protected. Enable the use of the tree cache also for local files,; adapting the default settings for the cache to the recent changes; In the XrdProofd plug-in. Improve synchronization between parent and child during; fork; Optimize loops over directory entries; Improve error and notification messages. Improved handling of Ctrl-C; this follows from a fix in; TMonitor and an improved handling of non-finished query state in the; workers (results are not send to master if the query was aborted) . Fixes. TFileMerger. Fix a problem preventing correct transmission of all; non-mergeable objects (fixes bug #52886); Remove the argument isdir from the function; MergeRecursive; Do not remove the first file in the list when returning; from MergeRecursive (fixes bug #54591); Fix a major leak when merging files with collections; written using kSingleKey option.  The merger was reading each; key in memory and deleted the object at the end, but the container is; not owner by default, so all objects inside leaked. PROOF-Lite. Fix a couple of memory leaks showing up when running; repeate",MatchSource.DOCS,proof/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html:7145,Modifiability,sandbox,sandbox,7145,"ache to the recent changes; In the XrdProofd plug-in. Improve synchronization between parent and child during; fork; Optimize loops over directory entries; Improve error and notification messages. Improved handling of Ctrl-C; this follows from a fix in; TMonitor and an improved handling of non-finished query state in the; workers (results are not send to master if the query was aborted) . Fixes. TFileMerger. Fix a problem preventing correct transmission of all; non-mergeable objects (fixes bug #52886); Remove the argument isdir from the function; MergeRecursive; Do not remove the first file in the list when returning; from MergeRecursive (fixes bug #54591); Fix a major leak when merging files with collections; written using kSingleKey option.  The merger was reading each; key in memory and deleted the object at the end, but the container is; not owner by default, so all objects inside leaked. PROOF-Lite. Fix a couple of memory leaks showing up when running; repeated queries; Fix a problem in TProofServ::CopyFromCache affecting; the case where the sandbox dir has a '.' and the macro name has no '.',; e.g. compiled selectors in PROOF-Lite. TProofOutputFile. Fix a problem with the determination of the fDir member; affecting mostly PROOF-Lite; Fix a serious issue whose net effect was to delete the; outputfile just after having open it. XrdProofd plugin. Make sure that the limit on the number of old; sessions is applied whenever a new session is started and not only when; the daemon is started.; Fix the behaviour of the xpd.allowedusers directive: if; at least one of these directives is present, users in the password file; are not allowed by default but must be explicitly appear in one; xpd.allowedusers directive  ; Fix a source for memory leak in; XrdProofdProtocol::SendMsg; Optimize the usage of strings in a few places. DataSet manager. Correctly classify as TTree all TTree derived classes; (e.g. TNtuple's); Fix a problem in saving the end-point URL for local; files; I",MatchSource.DOCS,proof/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html:7446,Modifiability,plugin,plugin,7446,"r if the query was aborted) . Fixes. TFileMerger. Fix a problem preventing correct transmission of all; non-mergeable objects (fixes bug #52886); Remove the argument isdir from the function; MergeRecursive; Do not remove the first file in the list when returning; from MergeRecursive (fixes bug #54591); Fix a major leak when merging files with collections; written using kSingleKey option.  The merger was reading each; key in memory and deleted the object at the end, but the container is; not owner by default, so all objects inside leaked. PROOF-Lite. Fix a couple of memory leaks showing up when running; repeated queries; Fix a problem in TProofServ::CopyFromCache affecting; the case where the sandbox dir has a '.' and the macro name has no '.',; e.g. compiled selectors in PROOF-Lite. TProofOutputFile. Fix a problem with the determination of the fDir member; affecting mostly PROOF-Lite; Fix a serious issue whose net effect was to delete the; outputfile just after having open it. XrdProofd plugin. Make sure that the limit on the number of old; sessions is applied whenever a new session is started and not only when; the daemon is started.; Fix the behaviour of the xpd.allowedusers directive: if; at least one of these directives is present, users in the password file; are not allowed by default but must be explicitly appear in one; xpd.allowedusers directive  ; Fix a source for memory leak in; XrdProofdProtocol::SendMsg; Optimize the usage of strings in a few places. DataSet manager. Correctly classify as TTree all TTree derived classes; (e.g. TNtuple's); Fix a problem in saving the end-point URL for local; files; Improve realtime notification during 'verify'. TProofDraw. Fix a problem with the axis ranges of the underlying; histogram in PolyMarker3D; Allow to use the default pad instead of forcing; creation of one pad per object; Add wrapper to handle the feedback default canvas. TEventIter. Fix a problem with changing the tree cache size: the; size was reset to the def",MatchSource.DOCS,proof/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html:9034,Modifiability,variab,variable,9034,"e end-point URL for local; files; Improve realtime notification during 'verify'. TProofDraw. Fix a problem with the axis ranges of the underlying; histogram in PolyMarker3D; Allow to use the default pad instead of forcing; creation of one pad per object; Add wrapper to handle the feedback default canvas. TEventIter. Fix a problem with changing the tree cache size: the; size was reset to the default value after the first file. TDataSetManagerFile. Solve a consistency problem in checking URLs for; duplication when adding them to the relevant TFileInfo; During dataset validation, do not fail on duplications; but notify and add them to the bad file list. TPacketizerAdaptive, TPacketizer. Improve data node / worker matching by always using the; host FQDN. TPacketizerUnit, TEventIter. Make sure that the entry; number passed to TSelector::Process is unique and in increasing order; for non-data driven processing (packetizer TPacketizerUnit). This; allows to give a meaning to this variable, for example to related it to; one dimension of an integration. Fixes in PROOF-Lite:. Make sure that with envs settings via TProof::AddEnvVar; are effective; this enables, for example, the automatic valgrind setup; introduced in 5.24/00 or the experiment specific settings via the; script defined by the env PROOF_INIT; Fix a problem with TProof::Load so that now it can be; also be used for PROOF-Lite. TProofPlayerRemote. In SendSelector, add misisng; option kCpBin when sending the selector source; the binary files were;  never retrieved, even if present and valid. TProofPlayerSlave. In; Process, fix a problem with cache directory locking while building; the selector;  the net effect was that each worker process was; re-buidling its own selector binary. . TProofServ; Fix; the order in which the log file is sent in asynchronous processing; the; wrong order was screwing up an immediate synchronous query submission; after an asynchronous run; this case occured, for example, in; 'stressProof' . ",MatchSource.DOCS,proof/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html:617,Performance,cache,cache,617,". ; Proof. New functionality. TProofMgr. Add support for the following functionality:. sandbox file listing and browsing; sandbox file removal; file upload, download. TProofDraw. Allow to set a color, size, size, width for lines,; area, markers; the attributes are transmitted via the input list and; automatically derived from the ones of the chain. Support automatic creation of a dataset out of files; created on the worker nodes by worker processes. The implementation is; an extension of the functionality of the class TProofOutputFile used; for merging via file.; Add the possibility to enable/disable the tree cache and; to change its size on per-query base; two new parameters are available:. PROOF_UseTreeCache   ; Int_t       ; Enable (0) or Disable (1) the tree cache (default 1); PROOF_CacheSize      ; Long64_t     Cache size in bytes; (default 10000000). Examples:;        ; a) to disable the cache for the next run enter:;                                 ; proof->SetParameter(""PROOF_UseTreeCache"", 0);        ; b) to set the cache size to 20M;                                 ; proof->SetParameter(""PROOF_CacheSize"", 20000000);  Add the parameter; PROOF_UseParallelUnzip to toggle the use of the parallel unzip; (default off for now); to enable it add the following call;            ;            ;        ;  proof->SetParameter(""PROOF_UseParallelUnzip"", 1).  Add the possibility to give indications about; the number of workers at startup.;  E.g.;        1. To; start max 5 workers;             ; TProof::Open(""<master>"",""workers=5"");        2. To; start max 2 workers per physical machine;             ; TProof::Open(""<master>"",""workers=2x"");      This is useful in general when; running tests (equivalent but quicker then full startup;      followed by; TProof::SetParallel(n) or TProof::DeactivateWorker(...)).; Add support for the worker SysInfo_t in TSlaveInfo; (obtained via TProof::GetListOfSlaveInfos()); Add new submerger functionality to speed up the merging; phase. At the e",MatchSource.DOCS,proof/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html:773,Performance,cache,cache,773,". ; Proof. New functionality. TProofMgr. Add support for the following functionality:. sandbox file listing and browsing; sandbox file removal; file upload, download. TProofDraw. Allow to set a color, size, size, width for lines,; area, markers; the attributes are transmitted via the input list and; automatically derived from the ones of the chain. Support automatic creation of a dataset out of files; created on the worker nodes by worker processes. The implementation is; an extension of the functionality of the class TProofOutputFile used; for merging via file.; Add the possibility to enable/disable the tree cache and; to change its size on per-query base; two new parameters are available:. PROOF_UseTreeCache   ; Int_t       ; Enable (0) or Disable (1) the tree cache (default 1); PROOF_CacheSize      ; Long64_t     Cache size in bytes; (default 10000000). Examples:;        ; a) to disable the cache for the next run enter:;                                 ; proof->SetParameter(""PROOF_UseTreeCache"", 0);        ; b) to set the cache size to 20M;                                 ; proof->SetParameter(""PROOF_CacheSize"", 20000000);  Add the parameter; PROOF_UseParallelUnzip to toggle the use of the parallel unzip; (default off for now); to enable it add the following call;            ;            ;        ;  proof->SetParameter(""PROOF_UseParallelUnzip"", 1).  Add the possibility to give indications about; the number of workers at startup.;  E.g.;        1. To; start max 5 workers;             ; TProof::Open(""<master>"",""workers=5"");        2. To; start max 2 workers per physical machine;             ; TProof::Open(""<master>"",""workers=2x"");      This is useful in general when; running tests (equivalent but quicker then full startup;      followed by; TProof::SetParallel(n) or TProof::DeactivateWorker(...)).; Add support for the worker SysInfo_t in TSlaveInfo; (obtained via TProof::GetListOfSlaveInfos()); Add new submerger functionality to speed up the merging; phase. At the e",MatchSource.DOCS,proof/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html:907,Performance,cache,cache,907,"; sandbox file removal; file upload, download. TProofDraw. Allow to set a color, size, size, width for lines,; area, markers; the attributes are transmitted via the input list and; automatically derived from the ones of the chain. Support automatic creation of a dataset out of files; created on the worker nodes by worker processes. The implementation is; an extension of the functionality of the class TProofOutputFile used; for merging via file.; Add the possibility to enable/disable the tree cache and; to change its size on per-query base; two new parameters are available:. PROOF_UseTreeCache   ; Int_t       ; Enable (0) or Disable (1) the tree cache (default 1); PROOF_CacheSize      ; Long64_t     Cache size in bytes; (default 10000000). Examples:;        ; a) to disable the cache for the next run enter:;                                 ; proof->SetParameter(""PROOF_UseTreeCache"", 0);        ; b) to set the cache size to 20M;                                 ; proof->SetParameter(""PROOF_CacheSize"", 20000000);  Add the parameter; PROOF_UseParallelUnzip to toggle the use of the parallel unzip; (default off for now); to enable it add the following call;            ;            ;        ;  proof->SetParameter(""PROOF_UseParallelUnzip"", 1).  Add the possibility to give indications about; the number of workers at startup.;  E.g.;        1. To; start max 5 workers;             ; TProof::Open(""<master>"",""workers=5"");        2. To; start max 2 workers per physical machine;             ; TProof::Open(""<master>"",""workers=2x"");      This is useful in general when; running tests (equivalent but quicker then full startup;      followed by; TProof::SetParallel(n) or TProof::DeactivateWorker(...)).; Add support for the worker SysInfo_t in TSlaveInfo; (obtained via TProof::GetListOfSlaveInfos()); Add new submerger functionality to speed up the merging; phase. At the end of the query, a set of workers are promoted; submergers and assigned a sub-set of workers to merge. Once each; sub-me",MatchSource.DOCS,proof/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html:1041,Performance,cache,cache,1041,"; sandbox file removal; file upload, download. TProofDraw. Allow to set a color, size, size, width for lines,; area, markers; the attributes are transmitted via the input list and; automatically derived from the ones of the chain. Support automatic creation of a dataset out of files; created on the worker nodes by worker processes. The implementation is; an extension of the functionality of the class TProofOutputFile used; for merging via file.; Add the possibility to enable/disable the tree cache and; to change its size on per-query base; two new parameters are available:. PROOF_UseTreeCache   ; Int_t       ; Enable (0) or Disable (1) the tree cache (default 1); PROOF_CacheSize      ; Long64_t     Cache size in bytes; (default 10000000). Examples:;        ; a) to disable the cache for the next run enter:;                                 ; proof->SetParameter(""PROOF_UseTreeCache"", 0);        ; b) to set the cache size to 20M;                                 ; proof->SetParameter(""PROOF_CacheSize"", 20000000);  Add the parameter; PROOF_UseParallelUnzip to toggle the use of the parallel unzip; (default off for now); to enable it add the following call;            ;            ;        ;  proof->SetParameter(""PROOF_UseParallelUnzip"", 1).  Add the possibility to give indications about; the number of workers at startup.;  E.g.;        1. To; start max 5 workers;             ; TProof::Open(""<master>"",""workers=5"");        2. To; start max 2 workers per physical machine;             ; TProof::Open(""<master>"",""workers=2x"");      This is useful in general when; running tests (equivalent but quicker then full startup;      followed by; TProof::SetParallel(n) or TProof::DeactivateWorker(...)).; Add support for the worker SysInfo_t in TSlaveInfo; (obtained via TProof::GetListOfSlaveInfos()); Add new submerger functionality to speed up the merging; phase. At the end of the query, a set of workers are promoted; submergers and assigned a sub-set of workers to merge. Once each; sub-me",MatchSource.DOCS,proof/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html:2349,Performance,perform,performance,2349,"     ;  proof->SetParameter(""PROOF_UseParallelUnzip"", 1).  Add the possibility to give indications about; the number of workers at startup.;  E.g.;        1. To; start max 5 workers;             ; TProof::Open(""<master>"",""workers=5"");        2. To; start max 2 workers per physical machine;             ; TProof::Open(""<master>"",""workers=2x"");      This is useful in general when; running tests (equivalent but quicker then full startup;      followed by; TProof::SetParallel(n) or TProof::DeactivateWorker(...)).; Add support for the worker SysInfo_t in TSlaveInfo; (obtained via TProof::GetListOfSlaveInfos()); Add new submerger functionality to speed up the merging; phase. At the end of the query, a set of workers are promoted; submergers and assigned a sub-set of workers to merge. Once each; sub-merger has merged its sub-set of workers, it sends its result to; the master, which merges the partial results into the final; set of results.; The determination of the sub-mergers is always done dynamically, based; on the recent performance of workers. An optimal (i.e. giving the; highest speed-up) number can be calculated analytically under simple; assumptions.; Merging via submergers is by default disabled. To enable it, with the; optimal number of sub-mergers, one should set the integer parameter; 'PROOF_UseMergers' to 0, i.e.                     ; proof->SetParameter(""PROOF_UseMergers"", 0). To force S sub-mergers (regardless of the optimal number) do.                     ; proof->SetParameter(""PROOF_UseMergers"", S). The new functionality can be tested in tutorials by adding the argument; 'submergers' to runProof, e.g. .        ;        ;      root [0] .L; tutorials/proof/runProof.C+ ;        ;        ;      root [1]; runProof(""simple(nhist=10000,submergers)"") . (see the top of tutorials/proof/runProof.C for additional options). A test for the submerger functionality has also been added to; test/stressProof.cxx .; In PROOF-Lite, add the possibility for the administrator; to c",MatchSource.DOCS,proof/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html:3659,Performance,optimiz,optimization,3659," optimal number) do.                     ; proof->SetParameter(""PROOF_UseMergers"", S). The new functionality can be tested in tutorials by adding the argument; 'submergers' to runProof, e.g. .        ;        ;      root [0] .L; tutorials/proof/runProof.C+ ;        ;        ;      root [1]; runProof(""simple(nhist=10000,submergers)"") . (see the top of tutorials/proof/runProof.C for additional options). A test for the submerger functionality has also been added to; test/stressProof.cxx .; In PROOF-Lite, add the possibility for the administrator; to control the number of workers. This is done using; the rootrc variable ProofLite.MaxWorkers, which is read out of; /etc/system.rootrc and cannot be overwritten by users. Setting the; value to 0 disables PROOF-Lite. Improvements. TFileMerger. A few improvements on the way to make TFileMerger and; hadd totally equivalent:. import from hadd an optimization of key hashing; import from hadd a better way to invoke Merge for; generic objects; add option to merge histograms in one go, instead of; one-by-one as for generic objects (this option is not yet supported by; hadd). TProofOutputFile. Add support for the placeholder <file>; the definition of the outputfile. This allows to have complete URL and; to pass options to TFile::Open. XrdProofd plugin. Add automatically the line 'Path.ForceRemote 1' to the; session rootrc file if the ROOT version is < 5.24/00 ; this acts; as a workaround for the wrong TTreeCache initialization at the; transition between local and remote files fixed in 5.24/00 . Enable mass storage domain settings when working with; TChain's; in multi-master mode. The Mass Storage Domain must be specified as; option in the URL.              ; chain.AddFile(""root:// .....?msd=CERN"").  and the string must match the value specified in defining the; submaster node.; Improved performance monitoring: the 'Rate plot' button; in the dialog box has been renamed 'Performance Plot' and now shows up; to 4 plots as a function of t",MatchSource.DOCS,proof/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html:4614,Performance,perform,performance,4614,"t from hadd a better way to invoke Merge for; generic objects; add option to merge histograms in one go, instead of; one-by-one as for generic objects (this option is not yet supported by; hadd). TProofOutputFile. Add support for the placeholder <file>; the definition of the outputfile. This allows to have complete URL and; to pass options to TFile::Open. XrdProofd plugin. Add automatically the line 'Path.ForceRemote 1' to the; session rootrc file if the ROOT version is < 5.24/00 ; this acts; as a workaround for the wrong TTreeCache initialization at the; transition between local and remote files fixed in 5.24/00 . Enable mass storage domain settings when working with; TChain's; in multi-master mode. The Mass Storage Domain must be specified as; option in the URL.              ; chain.AddFile(""root:// .....?msd=CERN"").  and the string must match the value specified in defining the; submaster node.; Improved performance monitoring: the 'Rate plot' button; in the dialog box has been renamed 'Performance Plot' and now shows up; to 4 plots as a function of the processing time:. Instantaneous processing rate, which is now better; estimated by a better estimation of the normalizing times; Average read chunck size, defined as; TFile::GetFileBytesRead() / TFile::GetFileReadCalls() during the last; unit of time; this allows to monitor the usage of the cache; this plot; is present only if some I/O is done, i.e. not for pure CPU tasks.; The number of active workers; The number of total and effecive sessions running; concurrently on the cluster (started by the same daemon); this plot is; present only is the number is at least onec different from 1. If enabled, send monitoring information from the master; at each GetNextPacket (at each call of TPerfStat::PacketEvent) to allow; extrnal real-time progress monitoring.; Save the status of a 'proofserv' session into a new file; in the 'activesessions' area. The full path of the new file is;          ; <admin_path>/.xproofd.<port>/act",MatchSource.DOCS,proof/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html:5058,Performance,cache,cache,5058,"e definition of the outputfile. This allows to have complete URL and; to pass options to TFile::Open. XrdProofd plugin. Add automatically the line 'Path.ForceRemote 1' to the; session rootrc file if the ROOT version is < 5.24/00 ; this acts; as a workaround for the wrong TTreeCache initialization at the; transition between local and remote files fixed in 5.24/00 . Enable mass storage domain settings when working with; TChain's; in multi-master mode. The Mass Storage Domain must be specified as; option in the URL.              ; chain.AddFile(""root:// .....?msd=CERN"").  and the string must match the value specified in defining the; submaster node.; Improved performance monitoring: the 'Rate plot' button; in the dialog box has been renamed 'Performance Plot' and now shows up; to 4 plots as a function of the processing time:. Instantaneous processing rate, which is now better; estimated by a better estimation of the normalizing times; Average read chunck size, defined as; TFile::GetFileBytesRead() / TFile::GetFileReadCalls() during the last; unit of time; this allows to monitor the usage of the cache; this plot; is present only if some I/O is done, i.e. not for pure CPU tasks.; The number of active workers; The number of total and effecive sessions running; concurrently on the cluster (started by the same daemon); this plot is; present only is the number is at least onec different from 1. If enabled, send monitoring information from the master; at each GetNextPacket (at each call of TPerfStat::PacketEvent) to allow; extrnal real-time progress monitoring.; Save the status of a 'proofserv' session into a new file; in the 'activesessions' area. The full path of the new file is;          ; <admin_path>/.xproofd.<port>/activesessions/<user>.<group>.<pid>.status. The status indicates whether the session is idle, running or queued.; The status is updated every 'checkfq' secs (see xpd.proofservmgr;; default 30 s). The status is dumped by the reader thread of TXProofServ; and t",MatchSource.DOCS,proof/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html:5224,Performance,concurren,concurrently,5224," the; transition between local and remote files fixed in 5.24/00 . Enable mass storage domain settings when working with; TChain's; in multi-master mode. The Mass Storage Domain must be specified as; option in the URL.              ; chain.AddFile(""root:// .....?msd=CERN"").  and the string must match the value specified in defining the; submaster node.; Improved performance monitoring: the 'Rate plot' button; in the dialog box has been renamed 'Performance Plot' and now shows up; to 4 plots as a function of the processing time:. Instantaneous processing rate, which is now better; estimated by a better estimation of the normalizing times; Average read chunck size, defined as; TFile::GetFileBytesRead() / TFile::GetFileReadCalls() during the last; unit of time; this allows to monitor the usage of the cache; this plot; is present only if some I/O is done, i.e. not for pure CPU tasks.; The number of active workers; The number of total and effecive sessions running; concurrently on the cluster (started by the same daemon); this plot is; present only is the number is at least onec different from 1. If enabled, send monitoring information from the master; at each GetNextPacket (at each call of TPerfStat::PacketEvent) to allow; extrnal real-time progress monitoring.; Save the status of a 'proofserv' session into a new file; in the 'activesessions' area. The full path of the new file is;          ; <admin_path>/.xproofd.<port>/activesessions/<user>.<group>.<pid>.status. The status indicates whether the session is idle, running or queued.; The status is updated every 'checkfq' secs (see xpd.proofservmgr;; default 30 s). The status is dumped by the reader thread of TXProofServ; and therefore its r/w access is protected. Enable the use of the tree cache also for local files,; adapting the default settings for the cache to the recent changes; In the XrdProofd plug-in. Improve synchronization between parent and child during; fork; Optimize loops over directory entries; Improve err",MatchSource.DOCS,proof/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html:5795,Performance,queue,queued,5795,"rocessing time:. Instantaneous processing rate, which is now better; estimated by a better estimation of the normalizing times; Average read chunck size, defined as; TFile::GetFileBytesRead() / TFile::GetFileReadCalls() during the last; unit of time; this allows to monitor the usage of the cache; this plot; is present only if some I/O is done, i.e. not for pure CPU tasks.; The number of active workers; The number of total and effecive sessions running; concurrently on the cluster (started by the same daemon); this plot is; present only is the number is at least onec different from 1. If enabled, send monitoring information from the master; at each GetNextPacket (at each call of TPerfStat::PacketEvent) to allow; extrnal real-time progress monitoring.; Save the status of a 'proofserv' session into a new file; in the 'activesessions' area. The full path of the new file is;          ; <admin_path>/.xproofd.<port>/activesessions/<user>.<group>.<pid>.status. The status indicates whether the session is idle, running or queued.; The status is updated every 'checkfq' secs (see xpd.proofservmgr;; default 30 s). The status is dumped by the reader thread of TXProofServ; and therefore its r/w access is protected. Enable the use of the tree cache also for local files,; adapting the default settings for the cache to the recent changes; In the XrdProofd plug-in. Improve synchronization between parent and child during; fork; Optimize loops over directory entries; Improve error and notification messages. Improved handling of Ctrl-C; this follows from a fix in; TMonitor and an improved handling of non-finished query state in the; workers (results are not send to master if the query was aborted) . Fixes. TFileMerger. Fix a problem preventing correct transmission of all; non-mergeable objects (fixes bug #52886); Remove the argument isdir from the function; MergeRecursive; Do not remove the first file in the list when returning; from MergeRecursive (fixes bug #54591); Fix a major leak whe",MatchSource.DOCS,proof/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html:6014,Performance,cache,cache,6014,"che; this plot; is present only if some I/O is done, i.e. not for pure CPU tasks.; The number of active workers; The number of total and effecive sessions running; concurrently on the cluster (started by the same daemon); this plot is; present only is the number is at least onec different from 1. If enabled, send monitoring information from the master; at each GetNextPacket (at each call of TPerfStat::PacketEvent) to allow; extrnal real-time progress monitoring.; Save the status of a 'proofserv' session into a new file; in the 'activesessions' area. The full path of the new file is;          ; <admin_path>/.xproofd.<port>/activesessions/<user>.<group>.<pid>.status. The status indicates whether the session is idle, running or queued.; The status is updated every 'checkfq' secs (see xpd.proofservmgr;; default 30 s). The status is dumped by the reader thread of TXProofServ; and therefore its r/w access is protected. Enable the use of the tree cache also for local files,; adapting the default settings for the cache to the recent changes; In the XrdProofd plug-in. Improve synchronization between parent and child during; fork; Optimize loops over directory entries; Improve error and notification messages. Improved handling of Ctrl-C; this follows from a fix in; TMonitor and an improved handling of non-finished query state in the; workers (results are not send to master if the query was aborted) . Fixes. TFileMerger. Fix a problem preventing correct transmission of all; non-mergeable objects (fixes bug #52886); Remove the argument isdir from the function; MergeRecursive; Do not remove the first file in the list when returning; from MergeRecursive (fixes bug #54591); Fix a major leak when merging files with collections; written using kSingleKey option.  The merger was reading each; key in memory and deleted the object at the end, but the container is; not owner by default, so all objects inside leaked. PROOF-Lite. Fix a couple of memory leaks showing up when running; repeate",MatchSource.DOCS,proof/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html:6081,Performance,cache,cache,6081,"che; this plot; is present only if some I/O is done, i.e. not for pure CPU tasks.; The number of active workers; The number of total and effecive sessions running; concurrently on the cluster (started by the same daemon); this plot is; present only is the number is at least onec different from 1. If enabled, send monitoring information from the master; at each GetNextPacket (at each call of TPerfStat::PacketEvent) to allow; extrnal real-time progress monitoring.; Save the status of a 'proofserv' session into a new file; in the 'activesessions' area. The full path of the new file is;          ; <admin_path>/.xproofd.<port>/activesessions/<user>.<group>.<pid>.status. The status indicates whether the session is idle, running or queued.; The status is updated every 'checkfq' secs (see xpd.proofservmgr;; default 30 s). The status is dumped by the reader thread of TXProofServ; and therefore its r/w access is protected. Enable the use of the tree cache also for local files,; adapting the default settings for the cache to the recent changes; In the XrdProofd plug-in. Improve synchronization between parent and child during; fork; Optimize loops over directory entries; Improve error and notification messages. Improved handling of Ctrl-C; this follows from a fix in; TMonitor and an improved handling of non-finished query state in the; workers (results are not send to master if the query was aborted) . Fixes. TFileMerger. Fix a problem preventing correct transmission of all; non-mergeable objects (fixes bug #52886); Remove the argument isdir from the function; MergeRecursive; Do not remove the first file in the list when returning; from MergeRecursive (fixes bug #54591); Fix a major leak when merging files with collections; written using kSingleKey option.  The merger was reading each; key in memory and deleted the object at the end, but the container is; not owner by default, so all objects inside leaked. PROOF-Lite. Fix a couple of memory leaks showing up when running; repeate",MatchSource.DOCS,proof/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html:8402,Performance,cache,cache,8402,"having open it. XrdProofd plugin. Make sure that the limit on the number of old; sessions is applied whenever a new session is started and not only when; the daemon is started.; Fix the behaviour of the xpd.allowedusers directive: if; at least one of these directives is present, users in the password file; are not allowed by default but must be explicitly appear in one; xpd.allowedusers directive  ; Fix a source for memory leak in; XrdProofdProtocol::SendMsg; Optimize the usage of strings in a few places. DataSet manager. Correctly classify as TTree all TTree derived classes; (e.g. TNtuple's); Fix a problem in saving the end-point URL for local; files; Improve realtime notification during 'verify'. TProofDraw. Fix a problem with the axis ranges of the underlying; histogram in PolyMarker3D; Allow to use the default pad instead of forcing; creation of one pad per object; Add wrapper to handle the feedback default canvas. TEventIter. Fix a problem with changing the tree cache size: the; size was reset to the default value after the first file. TDataSetManagerFile. Solve a consistency problem in checking URLs for; duplication when adding them to the relevant TFileInfo; During dataset validation, do not fail on duplications; but notify and add them to the bad file list. TPacketizerAdaptive, TPacketizer. Improve data node / worker matching by always using the; host FQDN. TPacketizerUnit, TEventIter. Make sure that the entry; number passed to TSelector::Process is unique and in increasing order; for non-data driven processing (packetizer TPacketizerUnit). This; allows to give a meaning to this variable, for example to related it to; one dimension of an integration. Fixes in PROOF-Lite:. Make sure that with envs settings via TProof::AddEnvVar; are effective; this enables, for example, the automatic valgrind setup; introduced in 5.24/00 or the experiment specific settings via the; script defined by the env PROOF_INIT; Fix a problem with TProof::Load so that now it can be; al",MatchSource.DOCS,proof/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html:9664,Performance,cache,cache,9664,"e end-point URL for local; files; Improve realtime notification during 'verify'. TProofDraw. Fix a problem with the axis ranges of the underlying; histogram in PolyMarker3D; Allow to use the default pad instead of forcing; creation of one pad per object; Add wrapper to handle the feedback default canvas. TEventIter. Fix a problem with changing the tree cache size: the; size was reset to the default value after the first file. TDataSetManagerFile. Solve a consistency problem in checking URLs for; duplication when adding them to the relevant TFileInfo; During dataset validation, do not fail on duplications; but notify and add them to the bad file list. TPacketizerAdaptive, TPacketizer. Improve data node / worker matching by always using the; host FQDN. TPacketizerUnit, TEventIter. Make sure that the entry; number passed to TSelector::Process is unique and in increasing order; for non-data driven processing (packetizer TPacketizerUnit). This; allows to give a meaning to this variable, for example to related it to; one dimension of an integration. Fixes in PROOF-Lite:. Make sure that with envs settings via TProof::AddEnvVar; are effective; this enables, for example, the automatic valgrind setup; introduced in 5.24/00 or the experiment specific settings via the; script defined by the env PROOF_INIT; Fix a problem with TProof::Load so that now it can be; also be used for PROOF-Lite. TProofPlayerRemote. In SendSelector, add misisng; option kCpBin when sending the selector source; the binary files were;  never retrieved, even if present and valid. TProofPlayerSlave. In; Process, fix a problem with cache directory locking while building; the selector;  the net effect was that each worker process was; re-buidling its own selector binary. . TProofServ; Fix; the order in which the log file is sent in asynchronous processing; the; wrong order was screwing up an immediate synchronous query submission; after an asynchronous run; this case occured, for example, in; 'stressProof' . ",MatchSource.DOCS,proof/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html:6463,Safety,abort,aborted,6463,"monitoring information from the master; at each GetNextPacket (at each call of TPerfStat::PacketEvent) to allow; extrnal real-time progress monitoring.; Save the status of a 'proofserv' session into a new file; in the 'activesessions' area. The full path of the new file is;          ; <admin_path>/.xproofd.<port>/activesessions/<user>.<group>.<pid>.status. The status indicates whether the session is idle, running or queued.; The status is updated every 'checkfq' secs (see xpd.proofservmgr;; default 30 s). The status is dumped by the reader thread of TXProofServ; and therefore its r/w access is protected. Enable the use of the tree cache also for local files,; adapting the default settings for the cache to the recent changes; In the XrdProofd plug-in. Improve synchronization between parent and child during; fork; Optimize loops over directory entries; Improve error and notification messages. Improved handling of Ctrl-C; this follows from a fix in; TMonitor and an improved handling of non-finished query state in the; workers (results are not send to master if the query was aborted) . Fixes. TFileMerger. Fix a problem preventing correct transmission of all; non-mergeable objects (fixes bug #52886); Remove the argument isdir from the function; MergeRecursive; Do not remove the first file in the list when returning; from MergeRecursive (fixes bug #54591); Fix a major leak when merging files with collections; written using kSingleKey option.  The merger was reading each; key in memory and deleted the object at the end, but the container is; not owner by default, so all objects inside leaked. PROOF-Lite. Fix a couple of memory leaks showing up when running; repeated queries; Fix a problem in TProofServ::CopyFromCache affecting; the case where the sandbox dir has a '.' and the macro name has no '.',; e.g. compiled selectors in PROOF-Lite. TProofOutputFile. Fix a problem with the determination of the fDir member; affecting mostly PROOF-Lite; Fix a serious issue whose net effe",MatchSource.DOCS,proof/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html:3679,Security,hash,hashing,3679," optimal number) do.                     ; proof->SetParameter(""PROOF_UseMergers"", S). The new functionality can be tested in tutorials by adding the argument; 'submergers' to runProof, e.g. .        ;        ;      root [0] .L; tutorials/proof/runProof.C+ ;        ;        ;      root [1]; runProof(""simple(nhist=10000,submergers)"") . (see the top of tutorials/proof/runProof.C for additional options). A test for the submerger functionality has also been added to; test/stressProof.cxx .; In PROOF-Lite, add the possibility for the administrator; to control the number of workers. This is done using; the rootrc variable ProofLite.MaxWorkers, which is read out of; /etc/system.rootrc and cannot be overwritten by users. Setting the; value to 0 disables PROOF-Lite. Improvements. TFileMerger. A few improvements on the way to make TFileMerger and; hadd totally equivalent:. import from hadd an optimization of key hashing; import from hadd a better way to invoke Merge for; generic objects; add option to merge histograms in one go, instead of; one-by-one as for generic objects (this option is not yet supported by; hadd). TProofOutputFile. Add support for the placeholder <file>; the definition of the outputfile. This allows to have complete URL and; to pass options to TFile::Open. XrdProofd plugin. Add automatically the line 'Path.ForceRemote 1' to the; session rootrc file if the ROOT version is < 5.24/00 ; this acts; as a workaround for the wrong TTreeCache initialization at the; transition between local and remote files fixed in 5.24/00 . Enable mass storage domain settings when working with; TChain's; in multi-master mode. The Mass Storage Domain must be specified as; option in the URL.              ; chain.AddFile(""root:// .....?msd=CERN"").  and the string must match the value specified in defining the; submaster node.; Improved performance monitoring: the 'Rate plot' button; in the dialog box has been renamed 'Performance Plot' and now shows up; to 4 plots as a function of t",MatchSource.DOCS,proof/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html:5966,Security,access,access,5966,"ile::GetFileBytesRead() / TFile::GetFileReadCalls() during the last; unit of time; this allows to monitor the usage of the cache; this plot; is present only if some I/O is done, i.e. not for pure CPU tasks.; The number of active workers; The number of total and effecive sessions running; concurrently on the cluster (started by the same daemon); this plot is; present only is the number is at least onec different from 1. If enabled, send monitoring information from the master; at each GetNextPacket (at each call of TPerfStat::PacketEvent) to allow; extrnal real-time progress monitoring.; Save the status of a 'proofserv' session into a new file; in the 'activesessions' area. The full path of the new file is;          ; <admin_path>/.xproofd.<port>/activesessions/<user>.<group>.<pid>.status. The status indicates whether the session is idle, running or queued.; The status is updated every 'checkfq' secs (see xpd.proofservmgr;; default 30 s). The status is dumped by the reader thread of TXProofServ; and therefore its r/w access is protected. Enable the use of the tree cache also for local files,; adapting the default settings for the cache to the recent changes; In the XrdProofd plug-in. Improve synchronization between parent and child during; fork; Optimize loops over directory entries; Improve error and notification messages. Improved handling of Ctrl-C; this follows from a fix in; TMonitor and an improved handling of non-finished query state in the; workers (results are not send to master if the query was aborted) . Fixes. TFileMerger. Fix a problem preventing correct transmission of all; non-mergeable objects (fixes bug #52886); Remove the argument isdir from the function; MergeRecursive; Do not remove the first file in the list when returning; from MergeRecursive (fixes bug #54591); Fix a major leak when merging files with collections; written using kSingleKey option.  The merger was reading each; key in memory and deleted the object at the end, but the container is; ",MatchSource.DOCS,proof/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html:7713,Security,password,password,7713," MergeRecursive (fixes bug #54591); Fix a major leak when merging files with collections; written using kSingleKey option.  The merger was reading each; key in memory and deleted the object at the end, but the container is; not owner by default, so all objects inside leaked. PROOF-Lite. Fix a couple of memory leaks showing up when running; repeated queries; Fix a problem in TProofServ::CopyFromCache affecting; the case where the sandbox dir has a '.' and the macro name has no '.',; e.g. compiled selectors in PROOF-Lite. TProofOutputFile. Fix a problem with the determination of the fDir member; affecting mostly PROOF-Lite; Fix a serious issue whose net effect was to delete the; outputfile just after having open it. XrdProofd plugin. Make sure that the limit on the number of old; sessions is applied whenever a new session is started and not only when; the daemon is started.; Fix the behaviour of the xpd.allowedusers directive: if; at least one of these directives is present, users in the password file; are not allowed by default but must be explicitly appear in one; xpd.allowedusers directive  ; Fix a source for memory leak in; XrdProofdProtocol::SendMsg; Optimize the usage of strings in a few places. DataSet manager. Correctly classify as TTree all TTree derived classes; (e.g. TNtuple's); Fix a problem in saving the end-point URL for local; files; Improve realtime notification during 'verify'. TProofDraw. Fix a problem with the axis ranges of the underlying; histogram in PolyMarker3D; Allow to use the default pad instead of forcing; creation of one pad per object; Add wrapper to handle the feedback default canvas. TEventIter. Fix a problem with changing the tree cache size: the; size was reset to the default value after the first file. TDataSetManagerFile. Solve a consistency problem in checking URLs for; duplication when adding them to the relevant TFileInfo; During dataset validation, do not fail on duplications; but notify and add them to the bad file list. TPacke",MatchSource.DOCS,proof/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html:8619,Security,validat,validation,8619," the behaviour of the xpd.allowedusers directive: if; at least one of these directives is present, users in the password file; are not allowed by default but must be explicitly appear in one; xpd.allowedusers directive  ; Fix a source for memory leak in; XrdProofdProtocol::SendMsg; Optimize the usage of strings in a few places. DataSet manager. Correctly classify as TTree all TTree derived classes; (e.g. TNtuple's); Fix a problem in saving the end-point URL for local; files; Improve realtime notification during 'verify'. TProofDraw. Fix a problem with the axis ranges of the underlying; histogram in PolyMarker3D; Allow to use the default pad instead of forcing; creation of one pad per object; Add wrapper to handle the feedback default canvas. TEventIter. Fix a problem with changing the tree cache size: the; size was reset to the default value after the first file. TDataSetManagerFile. Solve a consistency problem in checking URLs for; duplication when adding them to the relevant TFileInfo; During dataset validation, do not fail on duplications; but notify and add them to the bad file list. TPacketizerAdaptive, TPacketizer. Improve data node / worker matching by always using the; host FQDN. TPacketizerUnit, TEventIter. Make sure that the entry; number passed to TSelector::Process is unique and in increasing order; for non-data driven processing (packetizer TPacketizerUnit). This; allows to give a meaning to this variable, for example to related it to; one dimension of an integration. Fixes in PROOF-Lite:. Make sure that with envs settings via TProof::AddEnvVar; are effective; this enables, for example, the automatic valgrind setup; introduced in 5.24/00 or the experiment specific settings via the; script defined by the env PROOF_INIT; Fix a problem with TProof::Load so that now it can be; also be used for PROOF-Lite. TProofPlayerRemote. In SendSelector, add misisng; option kCpBin when sending the selector source; the binary files were;  never retrieved, even if present",MatchSource.DOCS,proof/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html:87,Testability,sandbox,sandbox,87,". ; Proof. New functionality. TProofMgr. Add support for the following functionality:. sandbox file listing and browsing; sandbox file removal; file upload, download. TProofDraw. Allow to set a color, size, size, width for lines,; area, markers; the attributes are transmitted via the input list and; automatically derived from the ones of the chain. Support automatic creation of a dataset out of files; created on the worker nodes by worker processes. The implementation is; an extension of the functionality of the class TProofOutputFile used; for merging via file.; Add the possibility to enable/disable the tree cache and; to change its size on per-query base; two new parameters are available:. PROOF_UseTreeCache   ; Int_t       ; Enable (0) or Disable (1) the tree cache (default 1); PROOF_CacheSize      ; Long64_t     Cache size in bytes; (default 10000000). Examples:;        ; a) to disable the cache for the next run enter:;                                 ; proof->SetParameter(""PROOF_UseTreeCache"", 0);        ; b) to set the cache size to 20M;                                 ; proof->SetParameter(""PROOF_CacheSize"", 20000000);  Add the parameter; PROOF_UseParallelUnzip to toggle the use of the parallel unzip; (default off for now); to enable it add the following call;            ;            ;        ;  proof->SetParameter(""PROOF_UseParallelUnzip"", 1).  Add the possibility to give indications about; the number of workers at startup.;  E.g.;        1. To; start max 5 workers;             ; TProof::Open(""<master>"",""workers=5"");        2. To; start max 2 workers per physical machine;             ; TProof::Open(""<master>"",""workers=2x"");      This is useful in general when; running tests (equivalent but quicker then full startup;      followed by; TProof::SetParallel(n) or TProof::DeactivateWorker(...)).; Add support for the worker SysInfo_t in TSlaveInfo; (obtained via TProof::GetListOfSlaveInfos()); Add new submerger functionality to speed up the merging; phase. At the e",MatchSource.DOCS,proof/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html:122,Testability,sandbox,sandbox,122,". ; Proof. New functionality. TProofMgr. Add support for the following functionality:. sandbox file listing and browsing; sandbox file removal; file upload, download. TProofDraw. Allow to set a color, size, size, width for lines,; area, markers; the attributes are transmitted via the input list and; automatically derived from the ones of the chain. Support automatic creation of a dataset out of files; created on the worker nodes by worker processes. The implementation is; an extension of the functionality of the class TProofOutputFile used; for merging via file.; Add the possibility to enable/disable the tree cache and; to change its size on per-query base; two new parameters are available:. PROOF_UseTreeCache   ; Int_t       ; Enable (0) or Disable (1) the tree cache (default 1); PROOF_CacheSize      ; Long64_t     Cache size in bytes; (default 10000000). Examples:;        ; a) to disable the cache for the next run enter:;                                 ; proof->SetParameter(""PROOF_UseTreeCache"", 0);        ; b) to set the cache size to 20M;                                 ; proof->SetParameter(""PROOF_CacheSize"", 20000000);  Add the parameter; PROOF_UseParallelUnzip to toggle the use of the parallel unzip; (default off for now); to enable it add the following call;            ;            ;        ;  proof->SetParameter(""PROOF_UseParallelUnzip"", 1).  Add the possibility to give indications about; the number of workers at startup.;  E.g.;        1. To; start max 5 workers;             ; TProof::Open(""<master>"",""workers=5"");        2. To; start max 2 workers per physical machine;             ; TProof::Open(""<master>"",""workers=2x"");      This is useful in general when; running tests (equivalent but quicker then full startup;      followed by; TProof::SetParallel(n) or TProof::DeactivateWorker(...)).; Add support for the worker SysInfo_t in TSlaveInfo; (obtained via TProof::GetListOfSlaveInfos()); Add new submerger functionality to speed up the merging; phase. At the e",MatchSource.DOCS,proof/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html:1705,Testability,test,tests,1705,"ilable:. PROOF_UseTreeCache   ; Int_t       ; Enable (0) or Disable (1) the tree cache (default 1); PROOF_CacheSize      ; Long64_t     Cache size in bytes; (default 10000000). Examples:;        ; a) to disable the cache for the next run enter:;                                 ; proof->SetParameter(""PROOF_UseTreeCache"", 0);        ; b) to set the cache size to 20M;                                 ; proof->SetParameter(""PROOF_CacheSize"", 20000000);  Add the parameter; PROOF_UseParallelUnzip to toggle the use of the parallel unzip; (default off for now); to enable it add the following call;            ;            ;        ;  proof->SetParameter(""PROOF_UseParallelUnzip"", 1).  Add the possibility to give indications about; the number of workers at startup.;  E.g.;        1. To; start max 5 workers;             ; TProof::Open(""<master>"",""workers=5"");        2. To; start max 2 workers per physical machine;             ; TProof::Open(""<master>"",""workers=2x"");      This is useful in general when; running tests (equivalent but quicker then full startup;      followed by; TProof::SetParallel(n) or TProof::DeactivateWorker(...)).; Add support for the worker SysInfo_t in TSlaveInfo; (obtained via TProof::GetListOfSlaveInfos()); Add new submerger functionality to speed up the merging; phase. At the end of the query, a set of workers are promoted; submergers and assigned a sub-set of workers to merge. Once each; sub-merger has merged its sub-set of workers, it sends its result to; the master, which merges the partial results into the final; set of results.; The determination of the sub-mergers is always done dynamically, based; on the recent performance of workers. An optimal (i.e. giving the; highest speed-up) number can be calculated analytically under simple; assumptions.; Merging via submergers is by default disabled. To enable it, with the; optimal number of sub-mergers, one should set the integer parameter; 'PROOF_UseMergers' to 0, i.e.                     ; proof->SetPara",MatchSource.DOCS,proof/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html:2879,Testability,test,tested,2879,"oof::GetListOfSlaveInfos()); Add new submerger functionality to speed up the merging; phase. At the end of the query, a set of workers are promoted; submergers and assigned a sub-set of workers to merge. Once each; sub-merger has merged its sub-set of workers, it sends its result to; the master, which merges the partial results into the final; set of results.; The determination of the sub-mergers is always done dynamically, based; on the recent performance of workers. An optimal (i.e. giving the; highest speed-up) number can be calculated analytically under simple; assumptions.; Merging via submergers is by default disabled. To enable it, with the; optimal number of sub-mergers, one should set the integer parameter; 'PROOF_UseMergers' to 0, i.e.                     ; proof->SetParameter(""PROOF_UseMergers"", 0). To force S sub-mergers (regardless of the optimal number) do.                     ; proof->SetParameter(""PROOF_UseMergers"", S). The new functionality can be tested in tutorials by adding the argument; 'submergers' to runProof, e.g. .        ;        ;      root [0] .L; tutorials/proof/runProof.C+ ;        ;        ;      root [1]; runProof(""simple(nhist=10000,submergers)"") . (see the top of tutorials/proof/runProof.C for additional options). A test for the submerger functionality has also been added to; test/stressProof.cxx .; In PROOF-Lite, add the possibility for the administrator; to control the number of workers. This is done using; the rootrc variable ProofLite.MaxWorkers, which is read out of; /etc/system.rootrc and cannot be overwritten by users. Setting the; value to 0 disables PROOF-Lite. Improvements. TFileMerger. A few improvements on the way to make TFileMerger and; hadd totally equivalent:. import from hadd an optimization of key hashing; import from hadd a better way to invoke Merge for; generic objects; add option to merge histograms in one go, instead of; one-by-one as for generic objects (this option is not yet supported by; hadd). TProofOutpu",MatchSource.DOCS,proof/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html:3170,Testability,test,test,3170,"es the partial results into the final; set of results.; The determination of the sub-mergers is always done dynamically, based; on the recent performance of workers. An optimal (i.e. giving the; highest speed-up) number can be calculated analytically under simple; assumptions.; Merging via submergers is by default disabled. To enable it, with the; optimal number of sub-mergers, one should set the integer parameter; 'PROOF_UseMergers' to 0, i.e.                     ; proof->SetParameter(""PROOF_UseMergers"", 0). To force S sub-mergers (regardless of the optimal number) do.                     ; proof->SetParameter(""PROOF_UseMergers"", S). The new functionality can be tested in tutorials by adding the argument; 'submergers' to runProof, e.g. .        ;        ;      root [0] .L; tutorials/proof/runProof.C+ ;        ;        ;      root [1]; runProof(""simple(nhist=10000,submergers)"") . (see the top of tutorials/proof/runProof.C for additional options). A test for the submerger functionality has also been added to; test/stressProof.cxx .; In PROOF-Lite, add the possibility for the administrator; to control the number of workers. This is done using; the rootrc variable ProofLite.MaxWorkers, which is read out of; /etc/system.rootrc and cannot be overwritten by users. Setting the; value to 0 disables PROOF-Lite. Improvements. TFileMerger. A few improvements on the way to make TFileMerger and; hadd totally equivalent:. import from hadd an optimization of key hashing; import from hadd a better way to invoke Merge for; generic objects; add option to merge histograms in one go, instead of; one-by-one as for generic objects (this option is not yet supported by; hadd). TProofOutputFile. Add support for the placeholder <file>; the definition of the outputfile. This allows to have complete URL and; to pass options to TFile::Open. XrdProofd plugin. Add automatically the line 'Path.ForceRemote 1' to the; session rootrc file if the ROOT version is < 5.24/00 ; this acts; as a workaround f",MatchSource.DOCS,proof/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html:3231,Testability,test,test,3231,"es the partial results into the final; set of results.; The determination of the sub-mergers is always done dynamically, based; on the recent performance of workers. An optimal (i.e. giving the; highest speed-up) number can be calculated analytically under simple; assumptions.; Merging via submergers is by default disabled. To enable it, with the; optimal number of sub-mergers, one should set the integer parameter; 'PROOF_UseMergers' to 0, i.e.                     ; proof->SetParameter(""PROOF_UseMergers"", 0). To force S sub-mergers (regardless of the optimal number) do.                     ; proof->SetParameter(""PROOF_UseMergers"", S). The new functionality can be tested in tutorials by adding the argument; 'submergers' to runProof, e.g. .        ;        ;      root [0] .L; tutorials/proof/runProof.C+ ;        ;        ;      root [1]; runProof(""simple(nhist=10000,submergers)"") . (see the top of tutorials/proof/runProof.C for additional options). A test for the submerger functionality has also been added to; test/stressProof.cxx .; In PROOF-Lite, add the possibility for the administrator; to control the number of workers. This is done using; the rootrc variable ProofLite.MaxWorkers, which is read out of; /etc/system.rootrc and cannot be overwritten by users. Setting the; value to 0 disables PROOF-Lite. Improvements. TFileMerger. A few improvements on the way to make TFileMerger and; hadd totally equivalent:. import from hadd an optimization of key hashing; import from hadd a better way to invoke Merge for; generic objects; add option to merge histograms in one go, instead of; one-by-one as for generic objects (this option is not yet supported by; hadd). TProofOutputFile. Add support for the placeholder <file>; the definition of the outputfile. This allows to have complete URL and; to pass options to TFile::Open. XrdProofd plugin. Add automatically the line 'Path.ForceRemote 1' to the; session rootrc file if the ROOT version is < 5.24/00 ; this acts; as a workaround f",MatchSource.DOCS,proof/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html:7145,Testability,sandbox,sandbox,7145,"ache to the recent changes; In the XrdProofd plug-in. Improve synchronization between parent and child during; fork; Optimize loops over directory entries; Improve error and notification messages. Improved handling of Ctrl-C; this follows from a fix in; TMonitor and an improved handling of non-finished query state in the; workers (results are not send to master if the query was aborted) . Fixes. TFileMerger. Fix a problem preventing correct transmission of all; non-mergeable objects (fixes bug #52886); Remove the argument isdir from the function; MergeRecursive; Do not remove the first file in the list when returning; from MergeRecursive (fixes bug #54591); Fix a major leak when merging files with collections; written using kSingleKey option.  The merger was reading each; key in memory and deleted the object at the end, but the container is; not owner by default, so all objects inside leaked. PROOF-Lite. Fix a couple of memory leaks showing up when running; repeated queries; Fix a problem in TProofServ::CopyFromCache affecting; the case where the sandbox dir has a '.' and the macro name has no '.',; e.g. compiled selectors in PROOF-Lite. TProofOutputFile. Fix a problem with the determination of the fDir member; affecting mostly PROOF-Lite; Fix a serious issue whose net effect was to delete the; outputfile just after having open it. XrdProofd plugin. Make sure that the limit on the number of old; sessions is applied whenever a new session is started and not only when; the daemon is started.; Fix the behaviour of the xpd.allowedusers directive: if; at least one of these directives is present, users in the password file; are not allowed by default but must be explicitly appear in one; xpd.allowedusers directive  ; Fix a source for memory leak in; XrdProofdProtocol::SendMsg; Optimize the usage of strings in a few places. DataSet manager. Correctly classify as TTree all TTree derived classes; (e.g. TNtuple's); Fix a problem in saving the end-point URL for local; files; I",MatchSource.DOCS,proof/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html:9847,Testability,log,log,9847,"e end-point URL for local; files; Improve realtime notification during 'verify'. TProofDraw. Fix a problem with the axis ranges of the underlying; histogram in PolyMarker3D; Allow to use the default pad instead of forcing; creation of one pad per object; Add wrapper to handle the feedback default canvas. TEventIter. Fix a problem with changing the tree cache size: the; size was reset to the default value after the first file. TDataSetManagerFile. Solve a consistency problem in checking URLs for; duplication when adding them to the relevant TFileInfo; During dataset validation, do not fail on duplications; but notify and add them to the bad file list. TPacketizerAdaptive, TPacketizer. Improve data node / worker matching by always using the; host FQDN. TPacketizerUnit, TEventIter. Make sure that the entry; number passed to TSelector::Process is unique and in increasing order; for non-data driven processing (packetizer TPacketizerUnit). This; allows to give a meaning to this variable, for example to related it to; one dimension of an integration. Fixes in PROOF-Lite:. Make sure that with envs settings via TProof::AddEnvVar; are effective; this enables, for example, the automatic valgrind setup; introduced in 5.24/00 or the experiment specific settings via the; script defined by the env PROOF_INIT; Fix a problem with TProof::Load so that now it can be; also be used for PROOF-Lite. TProofPlayerRemote. In SendSelector, add misisng; option kCpBin when sending the selector source; the binary files were;  never retrieved, even if present and valid. TProofPlayerSlave. In; Process, fix a problem with cache directory locking while building; the selector;  the net effect was that each worker process was; re-buidling its own selector binary. . TProofServ; Fix; the order in which the log file is sent in asynchronous processing; the; wrong order was screwing up an immediate synchronous query submission; after an asynchronous run; this case occured, for example, in; 'stressProof' . ",MatchSource.DOCS,proof/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html:2464,Usability,simpl,simple,2464,"workers at startup.;  E.g.;        1. To; start max 5 workers;             ; TProof::Open(""<master>"",""workers=5"");        2. To; start max 2 workers per physical machine;             ; TProof::Open(""<master>"",""workers=2x"");      This is useful in general when; running tests (equivalent but quicker then full startup;      followed by; TProof::SetParallel(n) or TProof::DeactivateWorker(...)).; Add support for the worker SysInfo_t in TSlaveInfo; (obtained via TProof::GetListOfSlaveInfos()); Add new submerger functionality to speed up the merging; phase. At the end of the query, a set of workers are promoted; submergers and assigned a sub-set of workers to merge. Once each; sub-merger has merged its sub-set of workers, it sends its result to; the master, which merges the partial results into the final; set of results.; The determination of the sub-mergers is always done dynamically, based; on the recent performance of workers. An optimal (i.e. giving the; highest speed-up) number can be calculated analytically under simple; assumptions.; Merging via submergers is by default disabled. To enable it, with the; optimal number of sub-mergers, one should set the integer parameter; 'PROOF_UseMergers' to 0, i.e.                     ; proof->SetParameter(""PROOF_UseMergers"", 0). To force S sub-mergers (regardless of the optimal number) do.                     ; proof->SetParameter(""PROOF_UseMergers"", S). The new functionality can be tested in tutorials by adding the argument; 'submergers' to runProof, e.g. .        ;        ;      root [0] .L; tutorials/proof/runProof.C+ ;        ;        ;      root [1]; runProof(""simple(nhist=10000,submergers)"") . (see the top of tutorials/proof/runProof.C for additional options). A test for the submerger functionality has also been added to; test/stressProof.cxx .; In PROOF-Lite, add the possibility for the administrator; to control the number of workers. This is done using; the rootrc variable ProofLite.MaxWorkers, which is read out of; /etc/s",MatchSource.DOCS,proof/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html:3065,Usability,simpl,simple,3065,"s and assigned a sub-set of workers to merge. Once each; sub-merger has merged its sub-set of workers, it sends its result to; the master, which merges the partial results into the final; set of results.; The determination of the sub-mergers is always done dynamically, based; on the recent performance of workers. An optimal (i.e. giving the; highest speed-up) number can be calculated analytically under simple; assumptions.; Merging via submergers is by default disabled. To enable it, with the; optimal number of sub-mergers, one should set the integer parameter; 'PROOF_UseMergers' to 0, i.e.                     ; proof->SetParameter(""PROOF_UseMergers"", 0). To force S sub-mergers (regardless of the optimal number) do.                     ; proof->SetParameter(""PROOF_UseMergers"", S). The new functionality can be tested in tutorials by adding the argument; 'submergers' to runProof, e.g. .        ;        ;      root [0] .L; tutorials/proof/runProof.C+ ;        ;        ;      root [1]; runProof(""simple(nhist=10000,submergers)"") . (see the top of tutorials/proof/runProof.C for additional options). A test for the submerger functionality has also been added to; test/stressProof.cxx .; In PROOF-Lite, add the possibility for the administrator; to control the number of workers. This is done using; the rootrc variable ProofLite.MaxWorkers, which is read out of; /etc/system.rootrc and cannot be overwritten by users. Setting the; value to 0 disables PROOF-Lite. Improvements. TFileMerger. A few improvements on the way to make TFileMerger and; hadd totally equivalent:. import from hadd an optimization of key hashing; import from hadd a better way to invoke Merge for; generic objects; add option to merge histograms in one go, instead of; one-by-one as for generic objects (this option is not yet supported by; hadd). TProofOutputFile. Add support for the placeholder <file>; the definition of the outputfile. This allows to have complete URL and; to pass options to TFile::Open. XrdProo",MatchSource.DOCS,proof/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html:8328,Usability,feedback,feedback,8328,"utputFile. Fix a problem with the determination of the fDir member; affecting mostly PROOF-Lite; Fix a serious issue whose net effect was to delete the; outputfile just after having open it. XrdProofd plugin. Make sure that the limit on the number of old; sessions is applied whenever a new session is started and not only when; the daemon is started.; Fix the behaviour of the xpd.allowedusers directive: if; at least one of these directives is present, users in the password file; are not allowed by default but must be explicitly appear in one; xpd.allowedusers directive  ; Fix a source for memory leak in; XrdProofdProtocol::SendMsg; Optimize the usage of strings in a few places. DataSet manager. Correctly classify as TTree all TTree derived classes; (e.g. TNtuple's); Fix a problem in saving the end-point URL for local; files; Improve realtime notification during 'verify'. TProofDraw. Fix a problem with the axis ranges of the underlying; histogram in PolyMarker3D; Allow to use the default pad instead of forcing; creation of one pad per object; Add wrapper to handle the feedback default canvas. TEventIter. Fix a problem with changing the tree cache size: the; size was reset to the default value after the first file. TDataSetManagerFile. Solve a consistency problem in checking URLs for; duplication when adding them to the relevant TFileInfo; During dataset validation, do not fail on duplications; but notify and add them to the bad file list. TPacketizerAdaptive, TPacketizer. Improve data node / worker matching by always using the; host FQDN. TPacketizerUnit, TEventIter. Make sure that the entry; number passed to TSelector::Process is unique and in increasing order; for non-data driven processing (packetizer TPacketizerUnit). This; allows to give a meaning to this variable, for example to related it to; one dimension of an integration. Fixes in PROOF-Lite:. Make sure that with envs settings via TProof::AddEnvVar; are effective; this enables, for example, the automatic valg",MatchSource.DOCS,proof/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:937,Availability,down,download,937,". Proof. New functionality. Add support for processing; many datasets in one go in TProof::Process(const char; *dataset, ...).; Two options are provided:;  - 'grand; dataset':   the datasets are added up; and considered as a single dataset (syntax:; ""dataset1|dataset2|..."");  - 'keep; separated':; the datasets are processed one after the other; the user is notified in; the selector of the change of dataset so they have the opportunity to; separate the results. A new packetizer, TPacketizerMulti, has been; developed for this case: it basically contains a list of standard; packetizers (one for each dataset) and loops over them (syntax:; ""dataset1,dataset2,..."" or dataset1 dataset2 ..."").; In; both cases, entry-list can be applied using the syntax; ""dataset<<entrylist"", e.g.; ""dataset1<<el1|dataset2<<el2|"".; The datasets to be processed can also be specified on one or multiple lines in a text file.; Add; support for automatic download of a package when available on the; master but not locally. The downloaded packages are store under <sandbox>/packages/downloaded; and automatically checked for updates against the master repository. If; a local version of the same package is created (using the; UploadPackage) the entry in downloaded is; cleared, so that the behaviour is unchanged.; Add; the possibility to remap the server for the files in a dataset. This; allows, for example, to reuse the dataset information for the same; files stored in a different cluster.; Add a local cache for; TDataSetManagerFile. This is mainly used to improve the speed of; TDataSetManager::ShowDataSets, which is run very often by users and may; be very slow if the number of dataset is large. The cache is also used; to cache frequently received dataset objects.Add the possibility to audit the activity on the nodes via syslog. .; New packetizer TPacketizerFile generating packets which contain a single; file path to be used in processing single files. Used, for example, in; tasks generating files. The",MatchSource.DOCS,proof/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:964,Availability,avail,available,964,". Proof. New functionality. Add support for processing; many datasets in one go in TProof::Process(const char; *dataset, ...).; Two options are provided:;  - 'grand; dataset':   the datasets are added up; and considered as a single dataset (syntax:; ""dataset1|dataset2|..."");  - 'keep; separated':; the datasets are processed one after the other; the user is notified in; the selector of the change of dataset so they have the opportunity to; separate the results. A new packetizer, TPacketizerMulti, has been; developed for this case: it basically contains a list of standard; packetizers (one for each dataset) and loops over them (syntax:; ""dataset1,dataset2,..."" or dataset1 dataset2 ..."").; In; both cases, entry-list can be applied using the syntax; ""dataset<<entrylist"", e.g.; ""dataset1<<el1|dataset2<<el2|"".; The datasets to be processed can also be specified on one or multiple lines in a text file.; Add; support for automatic download of a package when available on the; master but not locally. The downloaded packages are store under <sandbox>/packages/downloaded; and automatically checked for updates against the master repository. If; a local version of the same package is created (using the; UploadPackage) the entry in downloaded is; cleared, so that the behaviour is unchanged.; Add; the possibility to remap the server for the files in a dataset. This; allows, for example, to reuse the dataset information for the same; files stored in a different cluster.; Add a local cache for; TDataSetManagerFile. This is mainly used to improve the speed of; TDataSetManager::ShowDataSets, which is run very often by users and may; be very slow if the number of dataset is large. The cache is also used; to cache frequently received dataset objects.Add the possibility to audit the activity on the nodes via syslog. .; New packetizer TPacketizerFile generating packets which contain a single; file path to be used in processing single files. Used, for example, in; tasks generating files. The",MatchSource.DOCS,proof/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:1010,Availability,down,downloaded,1010,"e go in TProof::Process(const char; *dataset, ...).; Two options are provided:;  - 'grand; dataset':   the datasets are added up; and considered as a single dataset (syntax:; ""dataset1|dataset2|..."");  - 'keep; separated':; the datasets are processed one after the other; the user is notified in; the selector of the change of dataset so they have the opportunity to; separate the results. A new packetizer, TPacketizerMulti, has been; developed for this case: it basically contains a list of standard; packetizers (one for each dataset) and loops over them (syntax:; ""dataset1,dataset2,..."" or dataset1 dataset2 ..."").; In; both cases, entry-list can be applied using the syntax; ""dataset<<entrylist"", e.g.; ""dataset1<<el1|dataset2<<el2|"".; The datasets to be processed can also be specified on one or multiple lines in a text file.; Add; support for automatic download of a package when available on the; master but not locally. The downloaded packages are store under <sandbox>/packages/downloaded; and automatically checked for updates against the master repository. If; a local version of the same package is created (using the; UploadPackage) the entry in downloaded is; cleared, so that the behaviour is unchanged.; Add; the possibility to remap the server for the files in a dataset. This; allows, for example, to reuse the dataset information for the same; files stored in a different cluster.; Add a local cache for; TDataSetManagerFile. This is mainly used to improve the speed of; TDataSetManager::ShowDataSets, which is run very often by users and may; be very slow if the number of dataset is large. The cache is also used; to cache frequently received dataset objects.Add the possibility to audit the activity on the nodes via syslog. .; New packetizer TPacketizerFile generating packets which contain a single; file path to be used in processing single files. Used, for example, in; tasks generating files. The files are specified into a TMap - named; 'PROOF_FilesToProcess' - contain",MatchSource.DOCS,proof/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:1065,Availability,down,downloaded,1065,"e go in TProof::Process(const char; *dataset, ...).; Two options are provided:;  - 'grand; dataset':   the datasets are added up; and considered as a single dataset (syntax:; ""dataset1|dataset2|..."");  - 'keep; separated':; the datasets are processed one after the other; the user is notified in; the selector of the change of dataset so they have the opportunity to; separate the results. A new packetizer, TPacketizerMulti, has been; developed for this case: it basically contains a list of standard; packetizers (one for each dataset) and loops over them (syntax:; ""dataset1,dataset2,..."" or dataset1 dataset2 ..."").; In; both cases, entry-list can be applied using the syntax; ""dataset<<entrylist"", e.g.; ""dataset1<<el1|dataset2<<el2|"".; The datasets to be processed can also be specified on one or multiple lines in a text file.; Add; support for automatic download of a package when available on the; master but not locally. The downloaded packages are store under <sandbox>/packages/downloaded; and automatically checked for updates against the master repository. If; a local version of the same package is created (using the; UploadPackage) the entry in downloaded is; cleared, so that the behaviour is unchanged.; Add; the possibility to remap the server for the files in a dataset. This; allows, for example, to reuse the dataset information for the same; files stored in a different cluster.; Add a local cache for; TDataSetManagerFile. This is mainly used to improve the speed of; TDataSetManager::ShowDataSets, which is run very often by users and may; be very slow if the number of dataset is large. The cache is also used; to cache frequently received dataset objects.Add the possibility to audit the activity on the nodes via syslog. .; New packetizer TPacketizerFile generating packets which contain a single; file path to be used in processing single files. Used, for example, in; tasks generating files. The files are specified into a TMap - named; 'PROOF_FilesToProcess' - contain",MatchSource.DOCS,proof/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:1237,Availability,down,downloaded,1237,"as a single dataset (syntax:; ""dataset1|dataset2|..."");  - 'keep; separated':; the datasets are processed one after the other; the user is notified in; the selector of the change of dataset so they have the opportunity to; separate the results. A new packetizer, TPacketizerMulti, has been; developed for this case: it basically contains a list of standard; packetizers (one for each dataset) and loops over them (syntax:; ""dataset1,dataset2,..."" or dataset1 dataset2 ..."").; In; both cases, entry-list can be applied using the syntax; ""dataset<<entrylist"", e.g.; ""dataset1<<el1|dataset2<<el2|"".; The datasets to be processed can also be specified on one or multiple lines in a text file.; Add; support for automatic download of a package when available on the; master but not locally. The downloaded packages are store under <sandbox>/packages/downloaded; and automatically checked for updates against the master repository. If; a local version of the same package is created (using the; UploadPackage) the entry in downloaded is; cleared, so that the behaviour is unchanged.; Add; the possibility to remap the server for the files in a dataset. This; allows, for example, to reuse the dataset information for the same; files stored in a different cluster.; Add a local cache for; TDataSetManagerFile. This is mainly used to improve the speed of; TDataSetManager::ShowDataSets, which is run very often by users and may; be very slow if the number of dataset is large. The cache is also used; to cache frequently received dataset objects.Add the possibility to audit the activity on the nodes via syslog. .; New packetizer TPacketizerFile generating packets which contain a single; file path to be used in processing single files. Used, for example, in; tasks generating files. The files are specified into a TMap - named; 'PROOF_FilesToProcess' - containing the list of files to be generated; per host (the key is the host name, the value the TList of TObjString; (or TFileInfo) with the files names ",MatchSource.DOCS,proof/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:3894,Availability,avail,available,3894,"ariable PROOF_ENVVARS. This addition allows to change; the variables wthout changing the macro or application running; TProof::Open.; Add the possibility to save the perfomance information shown; by the dialog into a small ntuple included in the output list. The; ntuple contains 5 floats (processing time, number of active workers,; event rate, MBytes read, number of effective sessions on the cluster); and it is filled each time the number of active workers changes or at; max 100 regular intervals at least 5 secs apart; in this way the ntuple; has at most O(100 entries + number of workers). To enable the saving of; the ntuple execute the following:;         proof->SetParameter(""PROOF_SaveProgressPerf"", ""yes"");; before running the query. The ntuple is called 'PROOF_ProgressPerfNtuple'.; Add support for worker autodiscovery in PROOF using the; Avahi/Bonjour technology. The new functionality is supported on Mac; (MacOsX >= 10.4; no need of additional installs) and linux (requires; the Avahi framework, available by default on most of the; distributions). To use this functionality (instead-of or in-addition-to; the the static worker configuration via proof.conf or xpd.worker) the; new directive 'xpd.bonjour' must be used. Improvements. Improve support for valgrind runs in PROOF-Lite; Add the possibility to add files to a dataset. This is; achieved with a new option 'U' (for update) to RegisterDataSet.; Add; methof TProof::GetStatistics to allow the client to retrieve the; correct values of fBytesRead, fRealTime and fCpuTime at any moment;; this will be used to setup a sort of ROOTmarks in stressProof .; Several improvements in the test program 'stressProof'; and in the tutorials under 'tutorials/proof'; Avoid; contacting the DNS when initializing TProofMgr as base class of; TProofMgrLite: it is not needed and it may introduce long startup; delays.; Make TProof::LogViewer("""") start the viewer for; a Lite session, in parallel to whats happen for TProof::Open("""").; Several; i",MatchSource.DOCS,proof/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:5377,Availability,avail,available,5377,"ow the client to retrieve the; correct values of fBytesRead, fRealTime and fCpuTime at any moment;; this will be used to setup a sort of ROOTmarks in stressProof .; Several improvements in the test program 'stressProof'; and in the tutorials under 'tutorials/proof'; Avoid; contacting the DNS when initializing TProofMgr as base class of; TProofMgrLite: it is not needed and it may introduce long startup; delays.; Make TProof::LogViewer("""") start the viewer for; a Lite session, in parallel to whats happen for TProof::Open("""").; Several; improvements in the handling of wild cards in the dataset manager; for; example, issuing a GetDataSet(...) on a dataset URI containign wild; cards will return a grand dataset sum of all the datasets matching the; URI.; Add options to get a list of all dataset registered names; from ScanDataSets (option kList; the result is a TMap of {TObjString,; TObjString} with the second TObjString empty).Improved version of the PQ2 scripts; the scripts now invoke a dedicated ROOT application (named pq2) available under $ROOTSYS/bin .Add; support for recursive reading of group config files via the 'include; sub-file' directive. This allows to have a common part and, for; example, customize differently the quotas.Fix an issue with TTreeFriends. New tutorial showing how to use friends in PROOF.Package; management: add support for arguments in the SETUP function: it is; possible now to pass a string or a list of objects. The; TProof::EnablePackage interface has been extended to support this.Optimize; the validation step in the case not all the entries are required. The; validation step is stopped as soon as the requested number of events is; reached. If the parameter ""PROOF_ValidateByFile"" is set to 1, the; number of files is exactly what needed; otherwise the number of files; may exceed the number of files needed by (Number_Of_Workers - 1) .; New directive 'xpd.datadir' to better control the user data directories and their permission settings. In TPacke",MatchSource.DOCS,proof/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:9482,Availability,error,error,9482,"selective definition of env and rootrc; variables. Different values can be set for different users, groups, SVN; versions or ROOT versions.; Improve the diagnostic in case of exceptions. Information; about the event and file being processed at the moment the exception; was raised is sent to the client, e.g.;    0.5: caught exception triggered by signal '1' while; processing dset:'EventTree',; file:'http://root.cern.ch/files/data/event_3.root', event:1 - check; logs for possible stacktrace; The patch also fixes a problem with submergers observed when a worker; was stopped because above the memory limits: this worker was; established as merger but could not do the work, for obvious reasons,; freezing the session.; Add two new methods to TProof: ShowMissingFiles() to facilitate; the display of the list of missing files; and GetMissingFiles() to get; a TFileCollection (dataset) with the missing files for further; processing. Fixes. Fix a bug in error status transmission which avoid; session freezing in some cases; FIx; a few issues in libXrdProofd.so with handling of connection used for; admin operation: this should solve some cases where the daemon was not; responding. ; Fix a few memory leaks showing up when; running several queries in the same session; Fix a few issues affecting the new sub-merging option; Fix an issue preventing proper real-time notification; during VerifyDataSet; Fix an issue with TQueryResult ordering (was causing; random 'stressProof' failures); Fix; an issue with TProof::AskStatistics (fBytesRead, fRealTime and fCpuTime; were not correctly filled on the client; the values on the master,; displayed by TProof::Print were correct).; Fix several small issues affecting the handling of global; package directories; Fix an issue with socket handling in the main event-loop; while sendign or receiving files via TProofMgr.; Fix; a problem counting valid nodes in sequential or 'masteronly' mode,; generating the fake error message ""GoParallel: attaching to ca",MatchSource.DOCS,proof/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:10006,Availability,failure,failures,10006,"ta/event_3.root', event:1 - check; logs for possible stacktrace; The patch also fixes a problem with submergers observed when a worker; was stopped because above the memory limits: this worker was; established as merger but could not do the work, for obvious reasons,; freezing the session.; Add two new methods to TProof: ShowMissingFiles() to facilitate; the display of the list of missing files; and GetMissingFiles() to get; a TFileCollection (dataset) with the missing files for further; processing. Fixes. Fix a bug in error status transmission which avoid; session freezing in some cases; FIx; a few issues in libXrdProofd.so with handling of connection used for; admin operation: this should solve some cases where the daemon was not; responding. ; Fix a few memory leaks showing up when; running several queries in the same session; Fix a few issues affecting the new sub-merging option; Fix an issue preventing proper real-time notification; during VerifyDataSet; Fix an issue with TQueryResult ordering (was causing; random 'stressProof' failures); Fix; an issue with TProof::AskStatistics (fBytesRead, fRealTime and fCpuTime; were not correctly filled on the client; the values on the master,; displayed by TProof::Print were correct).; Fix several small issues affecting the handling of global; package directories; Fix an issue with socket handling in the main event-loop; while sendign or receiving files via TProofMgr.; Fix; a problem counting valid nodes in sequential or 'masteronly' mode,; generating the fake error message ""GoParallel: attaching to candidate!""; Fix a few issues with the length of Unix socket paths; affecting PROOF-Lite and xproofd on MacOsX ; Fix an issue with the release of file descriptors when; recovering sessions .; Fix an issue with a fake error message (""Error in; <TROOT::cd>: No such file root:/"") in PROOF-Lite when; issuing TProof::SetParallel().; Fix a problem with negative values for 'workers still; sending' in PROOF-Lite .; Fix locking issue whi",MatchSource.DOCS,proof/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:10486,Availability,error,error,10486,"FIx; a few issues in libXrdProofd.so with handling of connection used for; admin operation: this should solve some cases where the daemon was not; responding. ; Fix a few memory leaks showing up when; running several queries in the same session; Fix a few issues affecting the new sub-merging option; Fix an issue preventing proper real-time notification; during VerifyDataSet; Fix an issue with TQueryResult ordering (was causing; random 'stressProof' failures); Fix; an issue with TProof::AskStatistics (fBytesRead, fRealTime and fCpuTime; were not correctly filled on the client; the values on the master,; displayed by TProof::Print were correct).; Fix several small issues affecting the handling of global; package directories; Fix an issue with socket handling in the main event-loop; while sendign or receiving files via TProofMgr.; Fix; a problem counting valid nodes in sequential or 'masteronly' mode,; generating the fake error message ""GoParallel: attaching to candidate!""; Fix a few issues with the length of Unix socket paths; affecting PROOF-Lite and xproofd on MacOsX ; Fix an issue with the release of file descriptors when; recovering sessions .; Fix an issue with a fake error message (""Error in; <TROOT::cd>: No such file root:/"") in PROOF-Lite when; issuing TProof::SetParallel().; Fix a problem with negative values for 'workers still; sending' in PROOF-Lite .; Fix locking issue while building packages locally.; Fix issue setting permission and ownership of the dataset; user directories.Fix; a subtle bug affecting the (possibly rare) case when not all entries; are required and # entries does not correspond to an complete subset of; files (e.g. # entries = 1001000 with files of 100000 entries each). The; effect was uncomplete processing (skipped events, magenta bar) or a; session freeze.; Fix problem with packet re-assignment in case of a worker death (some packets were processed twice or more times).; Fix problem with the transmission of non-default file; attributes ",MatchSource.DOCS,proof/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:10695,Availability,recover,recovering,10695,"FIx; a few issues in libXrdProofd.so with handling of connection used for; admin operation: this should solve some cases where the daemon was not; responding. ; Fix a few memory leaks showing up when; running several queries in the same session; Fix a few issues affecting the new sub-merging option; Fix an issue preventing proper real-time notification; during VerifyDataSet; Fix an issue with TQueryResult ordering (was causing; random 'stressProof' failures); Fix; an issue with TProof::AskStatistics (fBytesRead, fRealTime and fCpuTime; were not correctly filled on the client; the values on the master,; displayed by TProof::Print were correct).; Fix several small issues affecting the handling of global; package directories; Fix an issue with socket handling in the main event-loop; while sendign or receiving files via TProofMgr.; Fix; a problem counting valid nodes in sequential or 'masteronly' mode,; generating the fake error message ""GoParallel: attaching to candidate!""; Fix a few issues with the length of Unix socket paths; affecting PROOF-Lite and xproofd on MacOsX ; Fix an issue with the release of file descriptors when; recovering sessions .; Fix an issue with a fake error message (""Error in; <TROOT::cd>: No such file root:/"") in PROOF-Lite when; issuing TProof::SetParallel().; Fix a problem with negative values for 'workers still; sending' in PROOF-Lite .; Fix locking issue while building packages locally.; Fix issue setting permission and ownership of the dataset; user directories.Fix; a subtle bug affecting the (possibly rare) case when not all entries; are required and # entries does not correspond to an complete subset of; files (e.g. # entries = 1001000 with files of 100000 entries each). The; effect was uncomplete processing (skipped events, magenta bar) or a; session freeze.; Fix problem with packet re-assignment in case of a worker death (some packets were processed twice or more times).; Fix problem with the transmission of non-default file; attributes ",MatchSource.DOCS,proof/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:10743,Availability,error,error,10743,"same session; Fix a few issues affecting the new sub-merging option; Fix an issue preventing proper real-time notification; during VerifyDataSet; Fix an issue with TQueryResult ordering (was causing; random 'stressProof' failures); Fix; an issue with TProof::AskStatistics (fBytesRead, fRealTime and fCpuTime; were not correctly filled on the client; the values on the master,; displayed by TProof::Print were correct).; Fix several small issues affecting the handling of global; package directories; Fix an issue with socket handling in the main event-loop; while sendign or receiving files via TProofMgr.; Fix; a problem counting valid nodes in sequential or 'masteronly' mode,; generating the fake error message ""GoParallel: attaching to candidate!""; Fix a few issues with the length of Unix socket paths; affecting PROOF-Lite and xproofd on MacOsX ; Fix an issue with the release of file descriptors when; recovering sessions .; Fix an issue with a fake error message (""Error in; <TROOT::cd>: No such file root:/"") in PROOF-Lite when; issuing TProof::SetParallel().; Fix a problem with negative values for 'workers still; sending' in PROOF-Lite .; Fix locking issue while building packages locally.; Fix issue setting permission and ownership of the dataset; user directories.Fix; a subtle bug affecting the (possibly rare) case when not all entries; are required and # entries does not correspond to an complete subset of; files (e.g. # entries = 1001000 with files of 100000 entries each). The; effect was uncomplete processing (skipped events, magenta bar) or a; session freeze.; Fix problem with packet re-assignment in case of a worker death (some packets were processed twice or more times).; Fix problem with the transmission of non-default file; attributes (e.g. the number of entries) from TChainElement to; TDSetElement during TChain processing in PROOF; Fix problem in the default packetizer with validating the; exact number of needed files when the information about the entries is; ",MatchSource.DOCS,proof/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:11793,Availability,avail,available,11793,"riptors when; recovering sessions .; Fix an issue with a fake error message (""Error in; <TROOT::cd>: No such file root:/"") in PROOF-Lite when; issuing TProof::SetParallel().; Fix a problem with negative values for 'workers still; sending' in PROOF-Lite .; Fix locking issue while building packages locally.; Fix issue setting permission and ownership of the dataset; user directories.Fix; a subtle bug affecting the (possibly rare) case when not all entries; are required and # entries does not correspond to an complete subset of; files (e.g. # entries = 1001000 with files of 100000 entries each). The; effect was uncomplete processing (skipped events, magenta bar) or a; session freeze.; Fix problem with packet re-assignment in case of a worker death (some packets were processed twice or more times).; Fix problem with the transmission of non-default file; attributes (e.g. the number of entries) from TChainElement to; TDSetElement during TChain processing in PROOF; Fix problem in the default packetizer with validating the; exact number of needed files when the information about the entries is; already available.; Fix problem with 'xpd.putenv' and 'xpd.putrc' occuring when the variables themselves contain commas.; Avoid resolving the workers FQDN when running in PROOF-Lite,; creating unnecessary delays when running PROOF-Lite within virtual; machines.; Fix problem with the permissions of the user data directory.; Add files to the list of files to process only when finally validated.; Fix; problem with canvases when the feedback canvas and the final canvas are; the same (do not delete the feedback canvas at the end of processing); Make sure that TProof::Load, TProofPlayer::SendSelector and; TSelector::GetSelector treat consistently the extensions of the; implementation files.; Unlock the cache after failure to load a selector; prevents session freezing; Correctly update the number of submergers when workers die; Add missing protection causing a crash in submergers when the o",MatchSource.DOCS,proof/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:12503,Availability,failure,failure,12503," processed twice or more times).; Fix problem with the transmission of non-default file; attributes (e.g. the number of entries) from TChainElement to; TDSetElement during TChain processing in PROOF; Fix problem in the default packetizer with validating the; exact number of needed files when the information about the entries is; already available.; Fix problem with 'xpd.putenv' and 'xpd.putrc' occuring when the variables themselves contain commas.; Avoid resolving the workers FQDN when running in PROOF-Lite,; creating unnecessary delays when running PROOF-Lite within virtual; machines.; Fix problem with the permissions of the user data directory.; Add files to the list of files to process only when finally validated.; Fix; problem with canvases when the feedback canvas and the final canvas are; the same (do not delete the feedback canvas at the end of processing); Make sure that TProof::Load, TProofPlayer::SendSelector and; TSelector::GetSelector treat consistently the extensions of the; implementation files.; Unlock the cache after failure to load a selector; prevents session freezing; Correctly update the number of submergers when workers die; Add missing protection causing a crash in submergers when the output list contained TProofOutputFile objects.; Move the creation and start of the idle timeout from the end; of SetupCommon to the end of CreateServer, so that the timeout is not; active during worker setup.; Make sure that the TProof instance on the client is invalidated after an idle timeout.; Fix an old issue with DeactivateWorker(""*"") (the session is; was terminated because no worker was active; this call coudl not be; used as intermediate step to select a small number of workers).; Consistently check both Proof.Sandbox and ProofLite.Sandbox for sandbox non-default location as done in TProofLite; Fix a problem with the registration of missing files in the; 'MissingFiles' list (files which could not be open on the workers were; not always added to the list). ",MatchSource.DOCS,proof/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:1107,Deployability,update,updates,1107,"e go in TProof::Process(const char; *dataset, ...).; Two options are provided:;  - 'grand; dataset':   the datasets are added up; and considered as a single dataset (syntax:; ""dataset1|dataset2|..."");  - 'keep; separated':; the datasets are processed one after the other; the user is notified in; the selector of the change of dataset so they have the opportunity to; separate the results. A new packetizer, TPacketizerMulti, has been; developed for this case: it basically contains a list of standard; packetizers (one for each dataset) and loops over them (syntax:; ""dataset1,dataset2,..."" or dataset1 dataset2 ..."").; In; both cases, entry-list can be applied using the syntax; ""dataset<<entrylist"", e.g.; ""dataset1<<el1|dataset2<<el2|"".; The datasets to be processed can also be specified on one or multiple lines in a text file.; Add; support for automatic download of a package when available on the; master but not locally. The downloaded packages are store under <sandbox>/packages/downloaded; and automatically checked for updates against the master repository. If; a local version of the same package is created (using the; UploadPackage) the entry in downloaded is; cleared, so that the behaviour is unchanged.; Add; the possibility to remap the server for the files in a dataset. This; allows, for example, to reuse the dataset information for the same; files stored in a different cluster.; Add a local cache for; TDataSetManagerFile. This is mainly used to improve the speed of; TDataSetManager::ShowDataSets, which is run very often by users and may; be very slow if the number of dataset is large. The cache is also used; to cache frequently received dataset objects.Add the possibility to audit the activity on the nodes via syslog. .; New packetizer TPacketizerFile generating packets which contain a single; file path to be used in processing single files. Used, for example, in; tasks generating files. The files are specified into a TMap - named; 'PROOF_FilesToProcess' - contain",MatchSource.DOCS,proof/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:3842,Deployability,install,installs,3842,"ariable PROOF_ENVVARS. This addition allows to change; the variables wthout changing the macro or application running; TProof::Open.; Add the possibility to save the perfomance information shown; by the dialog into a small ntuple included in the output list. The; ntuple contains 5 floats (processing time, number of active workers,; event rate, MBytes read, number of effective sessions on the cluster); and it is filled each time the number of active workers changes or at; max 100 regular intervals at least 5 secs apart; in this way the ntuple; has at most O(100 entries + number of workers). To enable the saving of; the ntuple execute the following:;         proof->SetParameter(""PROOF_SaveProgressPerf"", ""yes"");; before running the query. The ntuple is called 'PROOF_ProgressPerfNtuple'.; Add support for worker autodiscovery in PROOF using the; Avahi/Bonjour technology. The new functionality is supported on Mac; (MacOsX >= 10.4; no need of additional installs) and linux (requires; the Avahi framework, available by default on most of the; distributions). To use this functionality (instead-of or in-addition-to; the the static worker configuration via proof.conf or xpd.worker) the; new directive 'xpd.bonjour' must be used. Improvements. Improve support for valgrind runs in PROOF-Lite; Add the possibility to add files to a dataset. This is; achieved with a new option 'U' (for update) to RegisterDataSet.; Add; methof TProof::GetStatistics to allow the client to retrieve the; correct values of fBytesRead, fRealTime and fCpuTime at any moment;; this will be used to setup a sort of ROOTmarks in stressProof .; Several improvements in the test program 'stressProof'; and in the tutorials under 'tutorials/proof'; Avoid; contacting the DNS when initializing TProofMgr as base class of; TProofMgrLite: it is not needed and it may introduce long startup; delays.; Make TProof::LogViewer("""") start the viewer for; a Lite session, in parallel to whats happen for TProof::Open("""").; Several; i",MatchSource.DOCS,proof/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:4026,Deployability,configurat,configuration,4026,"; TProof::Open.; Add the possibility to save the perfomance information shown; by the dialog into a small ntuple included in the output list. The; ntuple contains 5 floats (processing time, number of active workers,; event rate, MBytes read, number of effective sessions on the cluster); and it is filled each time the number of active workers changes or at; max 100 regular intervals at least 5 secs apart; in this way the ntuple; has at most O(100 entries + number of workers). To enable the saving of; the ntuple execute the following:;         proof->SetParameter(""PROOF_SaveProgressPerf"", ""yes"");; before running the query. The ntuple is called 'PROOF_ProgressPerfNtuple'.; Add support for worker autodiscovery in PROOF using the; Avahi/Bonjour technology. The new functionality is supported on Mac; (MacOsX >= 10.4; no need of additional installs) and linux (requires; the Avahi framework, available by default on most of the; distributions). To use this functionality (instead-of or in-addition-to; the the static worker configuration via proof.conf or xpd.worker) the; new directive 'xpd.bonjour' must be used. Improvements. Improve support for valgrind runs in PROOF-Lite; Add the possibility to add files to a dataset. This is; achieved with a new option 'U' (for update) to RegisterDataSet.; Add; methof TProof::GetStatistics to allow the client to retrieve the; correct values of fBytesRead, fRealTime and fCpuTime at any moment;; this will be used to setup a sort of ROOTmarks in stressProof .; Several improvements in the test program 'stressProof'; and in the tutorials under 'tutorials/proof'; Avoid; contacting the DNS when initializing TProofMgr as base class of; TProofMgrLite: it is not needed and it may introduce long startup; delays.; Make TProof::LogViewer("""") start the viewer for; a Lite session, in parallel to whats happen for TProof::Open("""").; Several; improvements in the handling of wild cards in the dataset manager; for; example, issuing a GetDataSet(...) on a datas",MatchSource.DOCS,proof/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:4272,Deployability,update,update,4272,"ssions on the cluster); and it is filled each time the number of active workers changes or at; max 100 regular intervals at least 5 secs apart; in this way the ntuple; has at most O(100 entries + number of workers). To enable the saving of; the ntuple execute the following:;         proof->SetParameter(""PROOF_SaveProgressPerf"", ""yes"");; before running the query. The ntuple is called 'PROOF_ProgressPerfNtuple'.; Add support for worker autodiscovery in PROOF using the; Avahi/Bonjour technology. The new functionality is supported on Mac; (MacOsX >= 10.4; no need of additional installs) and linux (requires; the Avahi framework, available by default on most of the; distributions). To use this functionality (instead-of or in-addition-to; the the static worker configuration via proof.conf or xpd.worker) the; new directive 'xpd.bonjour' must be used. Improvements. Improve support for valgrind runs in PROOF-Lite; Add the possibility to add files to a dataset. This is; achieved with a new option 'U' (for update) to RegisterDataSet.; Add; methof TProof::GetStatistics to allow the client to retrieve the; correct values of fBytesRead, fRealTime and fCpuTime at any moment;; this will be used to setup a sort of ROOTmarks in stressProof .; Several improvements in the test program 'stressProof'; and in the tutorials under 'tutorials/proof'; Avoid; contacting the DNS when initializing TProofMgr as base class of; TProofMgrLite: it is not needed and it may introduce long startup; delays.; Make TProof::LogViewer("""") start the viewer for; a Lite session, in parallel to whats happen for TProof::Open("""").; Several; improvements in the handling of wild cards in the dataset manager; for; example, issuing a GetDataSet(...) on a dataset URI containign wild; cards will return a grand dataset sum of all the datasets matching the; URI.; Add options to get a list of all dataset registered names; from ScanDataSets (option kList; the result is a TMap of {TObjString,; TObjString} with the second TObjS",MatchSource.DOCS,proof/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:8409,Deployability,configurat,configuration,8409,"; this works adding the beginning of a path in the name; defining a new TFileNode (e.g. 'host://disk1' instead of 'host' only as; it was so far). These feature can be enabled by defining the rootrc; variable 'Packetizer.Partitions', e.g.;            Packetizer.Partitions  /disk1,/disk2,/disk3; Add to the output list the parameters used by the active packetizer. . In the PrintProgress function used to display a text progress; bar, show also the average reading rate in [k,M,G}bytes/s in addition; to the event processing rate. This is useful to have a feeling of the; rate when running of a remote machine in batch mode.; Add the possibility to control the resident and virtual; memory of a proofserv using 'ulimit', which has less limitations and; more flexibility than setrlimit.; Deactivate workers when the requested packages could not be enabled properly.; Add support for reconfiguring the group manager and the; {env,rootrc} settings. The related configuration files are checked for; changes during the regular checks done by the XrdProofdManager.; Add support for selective definition of env and rootrc; variables. Different values can be set for different users, groups, SVN; versions or ROOT versions.; Improve the diagnostic in case of exceptions. Information; about the event and file being processed at the moment the exception; was raised is sent to the client, e.g.;    0.5: caught exception triggered by signal '1' while; processing dset:'EventTree',; file:'http://root.cern.ch/files/data/event_3.root', event:1 - check; logs for possible stacktrace; The patch also fixes a problem with submergers observed when a worker; was stopped because above the memory limits: this worker was; established as merger but could not do the work, for obvious reasons,; freezing the session.; Add two new methods to TProof: ShowMissingFiles() to facilitate; the display of the list of missing files; and GetMissingFiles() to get; a TFileCollection (dataset) with the missing files for further; pro",MatchSource.DOCS,proof/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:9026,Deployability,patch,patch,9026," the resident and virtual; memory of a proofserv using 'ulimit', which has less limitations and; more flexibility than setrlimit.; Deactivate workers when the requested packages could not be enabled properly.; Add support for reconfiguring the group manager and the; {env,rootrc} settings. The related configuration files are checked for; changes during the regular checks done by the XrdProofdManager.; Add support for selective definition of env and rootrc; variables. Different values can be set for different users, groups, SVN; versions or ROOT versions.; Improve the diagnostic in case of exceptions. Information; about the event and file being processed at the moment the exception; was raised is sent to the client, e.g.;    0.5: caught exception triggered by signal '1' while; processing dset:'EventTree',; file:'http://root.cern.ch/files/data/event_3.root', event:1 - check; logs for possible stacktrace; The patch also fixes a problem with submergers observed when a worker; was stopped because above the memory limits: this worker was; established as merger but could not do the work, for obvious reasons,; freezing the session.; Add two new methods to TProof: ShowMissingFiles() to facilitate; the display of the list of missing files; and GetMissingFiles() to get; a TFileCollection (dataset) with the missing files for further; processing. Fixes. Fix a bug in error status transmission which avoid; session freezing in some cases; FIx; a few issues in libXrdProofd.so with handling of connection used for; admin operation: this should solve some cases where the daemon was not; responding. ; Fix a few memory leaks showing up when; running several queries in the same session; Fix a few issues affecting the new sub-merging option; Fix an issue preventing proper real-time notification; during VerifyDataSet; Fix an issue with TQueryResult ordering (was causing; random 'stressProof' failures); Fix; an issue with TProof::AskStatistics (fBytesRead, fRealTime and fCpuTime; were not corr",MatchSource.DOCS,proof/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:10661,Deployability,release,release,10661,"FIx; a few issues in libXrdProofd.so with handling of connection used for; admin operation: this should solve some cases where the daemon was not; responding. ; Fix a few memory leaks showing up when; running several queries in the same session; Fix a few issues affecting the new sub-merging option; Fix an issue preventing proper real-time notification; during VerifyDataSet; Fix an issue with TQueryResult ordering (was causing; random 'stressProof' failures); Fix; an issue with TProof::AskStatistics (fBytesRead, fRealTime and fCpuTime; were not correctly filled on the client; the values on the master,; displayed by TProof::Print were correct).; Fix several small issues affecting the handling of global; package directories; Fix an issue with socket handling in the main event-loop; while sendign or receiving files via TProofMgr.; Fix; a problem counting valid nodes in sequential or 'masteronly' mode,; generating the fake error message ""GoParallel: attaching to candidate!""; Fix a few issues with the length of Unix socket paths; affecting PROOF-Lite and xproofd on MacOsX ; Fix an issue with the release of file descriptors when; recovering sessions .; Fix an issue with a fake error message (""Error in; <TROOT::cd>: No such file root:/"") in PROOF-Lite when; issuing TProof::SetParallel().; Fix a problem with negative values for 'workers still; sending' in PROOF-Lite .; Fix locking issue while building packages locally.; Fix issue setting permission and ownership of the dataset; user directories.Fix; a subtle bug affecting the (possibly rare) case when not all entries; are required and # entries does not correspond to an complete subset of; files (e.g. # entries = 1001000 with files of 100000 entries each). The; effect was uncomplete processing (skipped events, magenta bar) or a; session freeze.; Fix problem with packet re-assignment in case of a worker death (some packets were processed twice or more times).; Fix problem with the transmission of non-default file; attributes ",MatchSource.DOCS,proof/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:12568,Deployability,update,update,12568," processed twice or more times).; Fix problem with the transmission of non-default file; attributes (e.g. the number of entries) from TChainElement to; TDSetElement during TChain processing in PROOF; Fix problem in the default packetizer with validating the; exact number of needed files when the information about the entries is; already available.; Fix problem with 'xpd.putenv' and 'xpd.putrc' occuring when the variables themselves contain commas.; Avoid resolving the workers FQDN when running in PROOF-Lite,; creating unnecessary delays when running PROOF-Lite within virtual; machines.; Fix problem with the permissions of the user data directory.; Add files to the list of files to process only when finally validated.; Fix; problem with canvases when the feedback canvas and the final canvas are; the same (do not delete the feedback canvas at the end of processing); Make sure that TProof::Load, TProofPlayer::SendSelector and; TSelector::GetSelector treat consistently the extensions of the; implementation files.; Unlock the cache after failure to load a selector; prevents session freezing; Correctly update the number of submergers when workers die; Add missing protection causing a crash in submergers when the output list contained TProofOutputFile objects.; Move the creation and start of the idle timeout from the end; of SetupCommon to the end of CreateServer, so that the timeout is not; active during worker setup.; Make sure that the TProof instance on the client is invalidated after an idle timeout.; Fix an old issue with DeactivateWorker(""*"") (the session is; was terminated because no worker was active; this call coudl not be; used as intermediate step to select a small number of workers).; Consistently check both Proof.Sandbox and ProofLite.Sandbox for sandbox non-default location as done in TProofLite; Fix a problem with the registration of missing files in the; 'MissingFiles' list (files which could not be open on the workers were; not always added to the list). ",MatchSource.DOCS,proof/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:5826,Integrability,interface,interface,5826,"o whats happen for TProof::Open("""").; Several; improvements in the handling of wild cards in the dataset manager; for; example, issuing a GetDataSet(...) on a dataset URI containign wild; cards will return a grand dataset sum of all the datasets matching the; URI.; Add options to get a list of all dataset registered names; from ScanDataSets (option kList; the result is a TMap of {TObjString,; TObjString} with the second TObjString empty).Improved version of the PQ2 scripts; the scripts now invoke a dedicated ROOT application (named pq2) available under $ROOTSYS/bin .Add; support for recursive reading of group config files via the 'include; sub-file' directive. This allows to have a common part and, for; example, customize differently the quotas.Fix an issue with TTreeFriends. New tutorial showing how to use friends in PROOF.Package; management: add support for arguments in the SETUP function: it is; possible now to pass a string or a list of objects. The; TProof::EnablePackage interface has been extended to support this.Optimize; the validation step in the case not all the entries are required. The; validation step is stopped as soon as the requested number of events is; reached. If the parameter ""PROOF_ValidateByFile"" is set to 1, the; number of files is exactly what needed; otherwise the number of files; may exceed the number of files needed by (Number_Of_Workers - 1) .; New directive 'xpd.datadir' to better control the user data directories and their permission settings. In TPacketizerUnit, add the possibility to exactly share the number of cycles between the workers.; See the parameter PROOF_PacketizerFixedNum.Implement; a timer to terminate idle sessions. The timeout value is controlled by; the variable ProofServ.IdleTimeout (value in seconds). This variable; can be set for all sessions in the xproofd config file via the 'xpd.putrc' directive.; Add the possibility to control the use of sub-mergers with; the ROOTrc variable Proof.SubMergers. It has the same mean",MatchSource.DOCS,proof/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:10492,Integrability,message,message,10492,"FIx; a few issues in libXrdProofd.so with handling of connection used for; admin operation: this should solve some cases where the daemon was not; responding. ; Fix a few memory leaks showing up when; running several queries in the same session; Fix a few issues affecting the new sub-merging option; Fix an issue preventing proper real-time notification; during VerifyDataSet; Fix an issue with TQueryResult ordering (was causing; random 'stressProof' failures); Fix; an issue with TProof::AskStatistics (fBytesRead, fRealTime and fCpuTime; were not correctly filled on the client; the values on the master,; displayed by TProof::Print were correct).; Fix several small issues affecting the handling of global; package directories; Fix an issue with socket handling in the main event-loop; while sendign or receiving files via TProofMgr.; Fix; a problem counting valid nodes in sequential or 'masteronly' mode,; generating the fake error message ""GoParallel: attaching to candidate!""; Fix a few issues with the length of Unix socket paths; affecting PROOF-Lite and xproofd on MacOsX ; Fix an issue with the release of file descriptors when; recovering sessions .; Fix an issue with a fake error message (""Error in; <TROOT::cd>: No such file root:/"") in PROOF-Lite when; issuing TProof::SetParallel().; Fix a problem with negative values for 'workers still; sending' in PROOF-Lite .; Fix locking issue while building packages locally.; Fix issue setting permission and ownership of the dataset; user directories.Fix; a subtle bug affecting the (possibly rare) case when not all entries; are required and # entries does not correspond to an complete subset of; files (e.g. # entries = 1001000 with files of 100000 entries each). The; effect was uncomplete processing (skipped events, magenta bar) or a; session freeze.; Fix problem with packet re-assignment in case of a worker death (some packets were processed twice or more times).; Fix problem with the transmission of non-default file; attributes ",MatchSource.DOCS,proof/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:10749,Integrability,message,message,10749,"same session; Fix a few issues affecting the new sub-merging option; Fix an issue preventing proper real-time notification; during VerifyDataSet; Fix an issue with TQueryResult ordering (was causing; random 'stressProof' failures); Fix; an issue with TProof::AskStatistics (fBytesRead, fRealTime and fCpuTime; were not correctly filled on the client; the values on the master,; displayed by TProof::Print were correct).; Fix several small issues affecting the handling of global; package directories; Fix an issue with socket handling in the main event-loop; while sendign or receiving files via TProofMgr.; Fix; a problem counting valid nodes in sequential or 'masteronly' mode,; generating the fake error message ""GoParallel: attaching to candidate!""; Fix a few issues with the length of Unix socket paths; affecting PROOF-Lite and xproofd on MacOsX ; Fix an issue with the release of file descriptors when; recovering sessions .; Fix an issue with a fake error message (""Error in; <TROOT::cd>: No such file root:/"") in PROOF-Lite when; issuing TProof::SetParallel().; Fix a problem with negative values for 'workers still; sending' in PROOF-Lite .; Fix locking issue while building packages locally.; Fix issue setting permission and ownership of the dataset; user directories.Fix; a subtle bug affecting the (possibly rare) case when not all entries; are required and # entries does not correspond to an complete subset of; files (e.g. # entries = 1001000 with files of 100000 entries each). The; effect was uncomplete processing (skipped events, magenta bar) or a; session freeze.; Fix problem with packet re-assignment in case of a worker death (some packets were processed twice or more times).; Fix problem with the transmission of non-default file; attributes (e.g. the number of entries) from TChainElement to; TDSetElement during TChain processing in PROOF; Fix problem in the default packetizer with validating the; exact number of needed files when the information about the entries is; ",MatchSource.DOCS,proof/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:1047,Modifiability,sandbox,sandbox,1047,"e go in TProof::Process(const char; *dataset, ...).; Two options are provided:;  - 'grand; dataset':   the datasets are added up; and considered as a single dataset (syntax:; ""dataset1|dataset2|..."");  - 'keep; separated':; the datasets are processed one after the other; the user is notified in; the selector of the change of dataset so they have the opportunity to; separate the results. A new packetizer, TPacketizerMulti, has been; developed for this case: it basically contains a list of standard; packetizers (one for each dataset) and loops over them (syntax:; ""dataset1,dataset2,..."" or dataset1 dataset2 ..."").; In; both cases, entry-list can be applied using the syntax; ""dataset<<entrylist"", e.g.; ""dataset1<<el1|dataset2<<el2|"".; The datasets to be processed can also be specified on one or multiple lines in a text file.; Add; support for automatic download of a package when available on the; master but not locally. The downloaded packages are store under <sandbox>/packages/downloaded; and automatically checked for updates against the master repository. If; a local version of the same package is created (using the; UploadPackage) the entry in downloaded is; cleared, so that the behaviour is unchanged.; Add; the possibility to remap the server for the files in a dataset. This; allows, for example, to reuse the dataset information for the same; files stored in a different cluster.; Add a local cache for; TDataSetManagerFile. This is mainly used to improve the speed of; TDataSetManager::ShowDataSets, which is run very often by users and may; be very slow if the number of dataset is large. The cache is also used; to cache frequently received dataset objects.Add the possibility to audit the activity on the nodes via syslog. .; New packetizer TPacketizerFile generating packets which contain a single; file path to be used in processing single files. Used, for example, in; tasks generating files. The files are specified into a TMap - named; 'PROOF_FilesToProcess' - contain",MatchSource.DOCS,proof/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:2791,Modifiability,variab,variables,2791,"t the activity on the nodes via syslog. .; New packetizer TPacketizerFile generating packets which contain a single; file path to be used in processing single files. Used, for example, in; tasks generating files. The files are specified into a TMap - named; 'PROOF_FilesToProcess' - containing the list of files to be generated; per host (the key is the host name, the value the TList of TObjString; (or TFileInfo) with the files names - or a TFileCollection: the output; of TFileCollection::GetFilesPerServer() can be directly passed as files; map). Workers are first assigned files belonging to; the list with host name matching the worker name. The map is; distributed to the master via the input list.Add support for; automatic setting of pointer data members to the relevant object in the; output list. The use of fOutputList->FindObject(""name"") in; TSelector::Terminate is not needed anymore for pointer data members,; e.g. histograms.; Add the possibility to define an external list of environment; variables to be transmitted to the master and workers. This is done via; the environment variable PROOF_ENVVARS. This addition allows to change; the variables wthout changing the macro or application running; TProof::Open.; Add the possibility to save the perfomance information shown; by the dialog into a small ntuple included in the output list. The; ntuple contains 5 floats (processing time, number of active workers,; event rate, MBytes read, number of effective sessions on the cluster); and it is filled each time the number of active workers changes or at; max 100 regular intervals at least 5 secs apart; in this way the ntuple; has at most O(100 entries + number of workers). To enable the saving of; the ntuple execute the following:;         proof->SetParameter(""PROOF_SaveProgressPerf"", ""yes"");; before running the query. The ntuple is called 'PROOF_ProgressPerfNtuple'.; Add support for worker autodiscovery in PROOF using the; Avahi/Bonjour technology. The new functionality is s",MatchSource.DOCS,proof/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:2880,Modifiability,variab,variable,2880,"ets which contain a single; file path to be used in processing single files. Used, for example, in; tasks generating files. The files are specified into a TMap - named; 'PROOF_FilesToProcess' - containing the list of files to be generated; per host (the key is the host name, the value the TList of TObjString; (or TFileInfo) with the files names - or a TFileCollection: the output; of TFileCollection::GetFilesPerServer() can be directly passed as files; map). Workers are first assigned files belonging to; the list with host name matching the worker name. The map is; distributed to the master via the input list.Add support for; automatic setting of pointer data members to the relevant object in the; output list. The use of fOutputList->FindObject(""name"") in; TSelector::Terminate is not needed anymore for pointer data members,; e.g. histograms.; Add the possibility to define an external list of environment; variables to be transmitted to the master and workers. This is done via; the environment variable PROOF_ENVVARS. This addition allows to change; the variables wthout changing the macro or application running; TProof::Open.; Add the possibility to save the perfomance information shown; by the dialog into a small ntuple included in the output list. The; ntuple contains 5 floats (processing time, number of active workers,; event rate, MBytes read, number of effective sessions on the cluster); and it is filled each time the number of active workers changes or at; max 100 regular intervals at least 5 secs apart; in this way the ntuple; has at most O(100 entries + number of workers). To enable the saving of; the ntuple execute the following:;         proof->SetParameter(""PROOF_SaveProgressPerf"", ""yes"");; before running the query. The ntuple is called 'PROOF_ProgressPerfNtuple'.; Add support for worker autodiscovery in PROOF using the; Avahi/Bonjour technology. The new functionality is supported on Mac; (MacOsX >= 10.4; no need of additional installs) and linux (requires; t",MatchSource.DOCS,proof/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:2940,Modifiability,variab,variables,2940,"or example, in; tasks generating files. The files are specified into a TMap - named; 'PROOF_FilesToProcess' - containing the list of files to be generated; per host (the key is the host name, the value the TList of TObjString; (or TFileInfo) with the files names - or a TFileCollection: the output; of TFileCollection::GetFilesPerServer() can be directly passed as files; map). Workers are first assigned files belonging to; the list with host name matching the worker name. The map is; distributed to the master via the input list.Add support for; automatic setting of pointer data members to the relevant object in the; output list. The use of fOutputList->FindObject(""name"") in; TSelector::Terminate is not needed anymore for pointer data members,; e.g. histograms.; Add the possibility to define an external list of environment; variables to be transmitted to the master and workers. This is done via; the environment variable PROOF_ENVVARS. This addition allows to change; the variables wthout changing the macro or application running; TProof::Open.; Add the possibility to save the perfomance information shown; by the dialog into a small ntuple included in the output list. The; ntuple contains 5 floats (processing time, number of active workers,; event rate, MBytes read, number of effective sessions on the cluster); and it is filled each time the number of active workers changes or at; max 100 regular intervals at least 5 secs apart; in this way the ntuple; has at most O(100 entries + number of workers). To enable the saving of; the ntuple execute the following:;         proof->SetParameter(""PROOF_SaveProgressPerf"", ""yes"");; before running the query. The ntuple is called 'PROOF_ProgressPerfNtuple'.; Add support for worker autodiscovery in PROOF using the; Avahi/Bonjour technology. The new functionality is supported on Mac; (MacOsX >= 10.4; no need of additional installs) and linux (requires; the Avahi framework, available by default on most of the; distributions). To use this",MatchSource.DOCS,proof/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:4026,Modifiability,config,configuration,4026,"; TProof::Open.; Add the possibility to save the perfomance information shown; by the dialog into a small ntuple included in the output list. The; ntuple contains 5 floats (processing time, number of active workers,; event rate, MBytes read, number of effective sessions on the cluster); and it is filled each time the number of active workers changes or at; max 100 regular intervals at least 5 secs apart; in this way the ntuple; has at most O(100 entries + number of workers). To enable the saving of; the ntuple execute the following:;         proof->SetParameter(""PROOF_SaveProgressPerf"", ""yes"");; before running the query. The ntuple is called 'PROOF_ProgressPerfNtuple'.; Add support for worker autodiscovery in PROOF using the; Avahi/Bonjour technology. The new functionality is supported on Mac; (MacOsX >= 10.4; no need of additional installs) and linux (requires; the Avahi framework, available by default on most of the; distributions). To use this functionality (instead-of or in-addition-to; the the static worker configuration via proof.conf or xpd.worker) the; new directive 'xpd.bonjour' must be used. Improvements. Improve support for valgrind runs in PROOF-Lite; Add the possibility to add files to a dataset. This is; achieved with a new option 'U' (for update) to RegisterDataSet.; Add; methof TProof::GetStatistics to allow the client to retrieve the; correct values of fBytesRead, fRealTime and fCpuTime at any moment;; this will be used to setup a sort of ROOTmarks in stressProof .; Several improvements in the test program 'stressProof'; and in the tutorials under 'tutorials/proof'; Avoid; contacting the DNS when initializing TProofMgr as base class of; TProofMgrLite: it is not needed and it may introduce long startup; delays.; Make TProof::LogViewer("""") start the viewer for; a Lite session, in parallel to whats happen for TProof::Open("""").; Several; improvements in the handling of wild cards in the dataset manager; for; example, issuing a GetDataSet(...) on a datas",MatchSource.DOCS,proof/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:5451,Modifiability,config,config,5451,"used to setup a sort of ROOTmarks in stressProof .; Several improvements in the test program 'stressProof'; and in the tutorials under 'tutorials/proof'; Avoid; contacting the DNS when initializing TProofMgr as base class of; TProofMgrLite: it is not needed and it may introduce long startup; delays.; Make TProof::LogViewer("""") start the viewer for; a Lite session, in parallel to whats happen for TProof::Open("""").; Several; improvements in the handling of wild cards in the dataset manager; for; example, issuing a GetDataSet(...) on a dataset URI containign wild; cards will return a grand dataset sum of all the datasets matching the; URI.; Add options to get a list of all dataset registered names; from ScanDataSets (option kList; the result is a TMap of {TObjString,; TObjString} with the second TObjString empty).Improved version of the PQ2 scripts; the scripts now invoke a dedicated ROOT application (named pq2) available under $ROOTSYS/bin .Add; support for recursive reading of group config files via the 'include; sub-file' directive. This allows to have a common part and, for; example, customize differently the quotas.Fix an issue with TTreeFriends. New tutorial showing how to use friends in PROOF.Package; management: add support for arguments in the SETUP function: it is; possible now to pass a string or a list of objects. The; TProof::EnablePackage interface has been extended to support this.Optimize; the validation step in the case not all the entries are required. The; validation step is stopped as soon as the requested number of events is; reached. If the parameter ""PROOF_ValidateByFile"" is set to 1, the; number of files is exactly what needed; otherwise the number of files; may exceed the number of files needed by (Number_Of_Workers - 1) .; New directive 'xpd.datadir' to better control the user data directories and their permission settings. In TPacketizerUnit, add the possibility to exactly share the number of cycles between the workers.; See the parameter PROO",MatchSource.DOCS,proof/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:5845,Modifiability,extend,extended,5845,"o whats happen for TProof::Open("""").; Several; improvements in the handling of wild cards in the dataset manager; for; example, issuing a GetDataSet(...) on a dataset URI containign wild; cards will return a grand dataset sum of all the datasets matching the; URI.; Add options to get a list of all dataset registered names; from ScanDataSets (option kList; the result is a TMap of {TObjString,; TObjString} with the second TObjString empty).Improved version of the PQ2 scripts; the scripts now invoke a dedicated ROOT application (named pq2) available under $ROOTSYS/bin .Add; support for recursive reading of group config files via the 'include; sub-file' directive. This allows to have a common part and, for; example, customize differently the quotas.Fix an issue with TTreeFriends. New tutorial showing how to use friends in PROOF.Package; management: add support for arguments in the SETUP function: it is; possible now to pass a string or a list of objects. The; TProof::EnablePackage interface has been extended to support this.Optimize; the validation step in the case not all the entries are required. The; validation step is stopped as soon as the requested number of events is; reached. If the parameter ""PROOF_ValidateByFile"" is set to 1, the; number of files is exactly what needed; otherwise the number of files; may exceed the number of files needed by (Number_Of_Workers - 1) .; New directive 'xpd.datadir' to better control the user data directories and their permission settings. In TPacketizerUnit, add the possibility to exactly share the number of cycles between the workers.; See the parameter PROOF_PacketizerFixedNum.Implement; a timer to terminate idle sessions. The timeout value is controlled by; the variable ProofServ.IdleTimeout (value in seconds). This variable; can be set for all sessions in the xproofd config file via the 'xpd.putrc' directive.; Add the possibility to control the use of sub-mergers with; the ROOTrc variable Proof.SubMergers. It has the same mean",MatchSource.DOCS,proof/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:6563,Modifiability,variab,variable,6563,"le, customize differently the quotas.Fix an issue with TTreeFriends. New tutorial showing how to use friends in PROOF.Package; management: add support for arguments in the SETUP function: it is; possible now to pass a string or a list of objects. The; TProof::EnablePackage interface has been extended to support this.Optimize; the validation step in the case not all the entries are required. The; validation step is stopped as soon as the requested number of events is; reached. If the parameter ""PROOF_ValidateByFile"" is set to 1, the; number of files is exactly what needed; otherwise the number of files; may exceed the number of files needed by (Number_Of_Workers - 1) .; New directive 'xpd.datadir' to better control the user data directories and their permission settings. In TPacketizerUnit, add the possibility to exactly share the number of cycles between the workers.; See the parameter PROOF_PacketizerFixedNum.Implement; a timer to terminate idle sessions. The timeout value is controlled by; the variable ProofServ.IdleTimeout (value in seconds). This variable; can be set for all sessions in the xproofd config file via the 'xpd.putrc' directive.; Add the possibility to control the use of sub-mergers with; the ROOTrc variable Proof.SubMergers. It has the same meaning of the; parameter 'PROOF_UseMergers'. The capabilities of the latter have been; extended: now -1 means disable the use of submergers (before  negative values were ignored and there was no way for the user to disable the use of submergers). . Packetizer optimizations: improved worked distribution when; the number of files left to be processed is smaller than the number of; workers and at least one file has a number of events significantly; larger than the average; better apply the upper/lower limits on the; expected packet processing time.; Add the possibility to single-out disk partitions in the; packetizer; this works adding the beginning of a path in the name; defining a new TFileNode (e.g. 'host://disk",MatchSource.DOCS,proof/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:6619,Modifiability,variab,variable,6619,"iends in PROOF.Package; management: add support for arguments in the SETUP function: it is; possible now to pass a string or a list of objects. The; TProof::EnablePackage interface has been extended to support this.Optimize; the validation step in the case not all the entries are required. The; validation step is stopped as soon as the requested number of events is; reached. If the parameter ""PROOF_ValidateByFile"" is set to 1, the; number of files is exactly what needed; otherwise the number of files; may exceed the number of files needed by (Number_Of_Workers - 1) .; New directive 'xpd.datadir' to better control the user data directories and their permission settings. In TPacketizerUnit, add the possibility to exactly share the number of cycles between the workers.; See the parameter PROOF_PacketizerFixedNum.Implement; a timer to terminate idle sessions. The timeout value is controlled by; the variable ProofServ.IdleTimeout (value in seconds). This variable; can be set for all sessions in the xproofd config file via the 'xpd.putrc' directive.; Add the possibility to control the use of sub-mergers with; the ROOTrc variable Proof.SubMergers. It has the same meaning of the; parameter 'PROOF_UseMergers'. The capabilities of the latter have been; extended: now -1 means disable the use of submergers (before  negative values were ignored and there was no way for the user to disable the use of submergers). . Packetizer optimizations: improved worked distribution when; the number of files left to be processed is smaller than the number of; workers and at least one file has a number of events significantly; larger than the average; better apply the upper/lower limits on the; expected packet processing time.; Add the possibility to single-out disk partitions in the; packetizer; this works adding the beginning of a path in the name; defining a new TFileNode (e.g. 'host://disk1' instead of 'host' only as; it was so far). These feature can be enabled by defining the rootrc; vari",MatchSource.DOCS,proof/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:6672,Modifiability,config,config,6672,"iends in PROOF.Package; management: add support for arguments in the SETUP function: it is; possible now to pass a string or a list of objects. The; TProof::EnablePackage interface has been extended to support this.Optimize; the validation step in the case not all the entries are required. The; validation step is stopped as soon as the requested number of events is; reached. If the parameter ""PROOF_ValidateByFile"" is set to 1, the; number of files is exactly what needed; otherwise the number of files; may exceed the number of files needed by (Number_Of_Workers - 1) .; New directive 'xpd.datadir' to better control the user data directories and their permission settings. In TPacketizerUnit, add the possibility to exactly share the number of cycles between the workers.; See the parameter PROOF_PacketizerFixedNum.Implement; a timer to terminate idle sessions. The timeout value is controlled by; the variable ProofServ.IdleTimeout (value in seconds). This variable; can be set for all sessions in the xproofd config file via the 'xpd.putrc' directive.; Add the possibility to control the use of sub-mergers with; the ROOTrc variable Proof.SubMergers. It has the same meaning of the; parameter 'PROOF_UseMergers'. The capabilities of the latter have been; extended: now -1 means disable the use of submergers (before  negative values were ignored and there was no way for the user to disable the use of submergers). . Packetizer optimizations: improved worked distribution when; the number of files left to be processed is smaller than the number of; workers and at least one file has a number of events significantly; larger than the average; better apply the upper/lower limits on the; expected packet processing time.; Add the possibility to single-out disk partitions in the; packetizer; this works adding the beginning of a path in the name; defining a new TFileNode (e.g. 'host://disk1' instead of 'host' only as; it was so far). These feature can be enabled by defining the rootrc; vari",MatchSource.DOCS,proof/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:6787,Modifiability,variab,variable,6787,"w to pass a string or a list of objects. The; TProof::EnablePackage interface has been extended to support this.Optimize; the validation step in the case not all the entries are required. The; validation step is stopped as soon as the requested number of events is; reached. If the parameter ""PROOF_ValidateByFile"" is set to 1, the; number of files is exactly what needed; otherwise the number of files; may exceed the number of files needed by (Number_Of_Workers - 1) .; New directive 'xpd.datadir' to better control the user data directories and their permission settings. In TPacketizerUnit, add the possibility to exactly share the number of cycles between the workers.; See the parameter PROOF_PacketizerFixedNum.Implement; a timer to terminate idle sessions. The timeout value is controlled by; the variable ProofServ.IdleTimeout (value in seconds). This variable; can be set for all sessions in the xproofd config file via the 'xpd.putrc' directive.; Add the possibility to control the use of sub-mergers with; the ROOTrc variable Proof.SubMergers. It has the same meaning of the; parameter 'PROOF_UseMergers'. The capabilities of the latter have been; extended: now -1 means disable the use of submergers (before  negative values were ignored and there was no way for the user to disable the use of submergers). . Packetizer optimizations: improved worked distribution when; the number of files left to be processed is smaller than the number of; workers and at least one file has a number of events significantly; larger than the average; better apply the upper/lower limits on the; expected packet processing time.; Add the possibility to single-out disk partitions in the; packetizer; this works adding the beginning of a path in the name; defining a new TFileNode (e.g. 'host://disk1' instead of 'host' only as; it was so far). These feature can be enabled by defining the rootrc; variable 'Packetizer.Partitions', e.g.;            Packetizer.Partitions  /disk1,/disk2,/disk3; Add to the ",MatchSource.DOCS,proof/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:6918,Modifiability,extend,extended,6918,"d as soon as the requested number of events is; reached. If the parameter ""PROOF_ValidateByFile"" is set to 1, the; number of files is exactly what needed; otherwise the number of files; may exceed the number of files needed by (Number_Of_Workers - 1) .; New directive 'xpd.datadir' to better control the user data directories and their permission settings. In TPacketizerUnit, add the possibility to exactly share the number of cycles between the workers.; See the parameter PROOF_PacketizerFixedNum.Implement; a timer to terminate idle sessions. The timeout value is controlled by; the variable ProofServ.IdleTimeout (value in seconds). This variable; can be set for all sessions in the xproofd config file via the 'xpd.putrc' directive.; Add the possibility to control the use of sub-mergers with; the ROOTrc variable Proof.SubMergers. It has the same meaning of the; parameter 'PROOF_UseMergers'. The capabilities of the latter have been; extended: now -1 means disable the use of submergers (before  negative values were ignored and there was no way for the user to disable the use of submergers). . Packetizer optimizations: improved worked distribution when; the number of files left to be processed is smaller than the number of; workers and at least one file has a number of events significantly; larger than the average; better apply the upper/lower limits on the; expected packet processing time.; Add the possibility to single-out disk partitions in the; packetizer; this works adding the beginning of a path in the name; defining a new TFileNode (e.g. 'host://disk1' instead of 'host' only as; it was so far). These feature can be enabled by defining the rootrc; variable 'Packetizer.Partitions', e.g.;            Packetizer.Partitions  /disk1,/disk2,/disk3; Add to the output list the parameters used by the active packetizer. . In the PrintProgress function used to display a text progress; bar, show also the average reading rate in [k,M,G}bytes/s in addition; to the event processing ",MatchSource.DOCS,proof/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:7651,Modifiability,variab,variable,7651,"e set for all sessions in the xproofd config file via the 'xpd.putrc' directive.; Add the possibility to control the use of sub-mergers with; the ROOTrc variable Proof.SubMergers. It has the same meaning of the; parameter 'PROOF_UseMergers'. The capabilities of the latter have been; extended: now -1 means disable the use of submergers (before  negative values were ignored and there was no way for the user to disable the use of submergers). . Packetizer optimizations: improved worked distribution when; the number of files left to be processed is smaller than the number of; workers and at least one file has a number of events significantly; larger than the average; better apply the upper/lower limits on the; expected packet processing time.; Add the possibility to single-out disk partitions in the; packetizer; this works adding the beginning of a path in the name; defining a new TFileNode (e.g. 'host://disk1' instead of 'host' only as; it was so far). These feature can be enabled by defining the rootrc; variable 'Packetizer.Partitions', e.g.;            Packetizer.Partitions  /disk1,/disk2,/disk3; Add to the output list the parameters used by the active packetizer. . In the PrintProgress function used to display a text progress; bar, show also the average reading rate in [k,M,G}bytes/s in addition; to the event processing rate. This is useful to have a feeling of the; rate when running of a remote machine in batch mode.; Add the possibility to control the resident and virtual; memory of a proofserv using 'ulimit', which has less limitations and; more flexibility than setrlimit.; Deactivate workers when the requested packages could not be enabled properly.; Add support for reconfiguring the group manager and the; {env,rootrc} settings. The related configuration files are checked for; changes during the regular checks done by the XrdProofdManager.; Add support for selective definition of env and rootrc; variables. Different values can be set for different users, groups, ",MatchSource.DOCS,proof/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:8409,Modifiability,config,configuration,8409,"; this works adding the beginning of a path in the name; defining a new TFileNode (e.g. 'host://disk1' instead of 'host' only as; it was so far). These feature can be enabled by defining the rootrc; variable 'Packetizer.Partitions', e.g.;            Packetizer.Partitions  /disk1,/disk2,/disk3; Add to the output list the parameters used by the active packetizer. . In the PrintProgress function used to display a text progress; bar, show also the average reading rate in [k,M,G}bytes/s in addition; to the event processing rate. This is useful to have a feeling of the; rate when running of a remote machine in batch mode.; Add the possibility to control the resident and virtual; memory of a proofserv using 'ulimit', which has less limitations and; more flexibility than setrlimit.; Deactivate workers when the requested packages could not be enabled properly.; Add support for reconfiguring the group manager and the; {env,rootrc} settings. The related configuration files are checked for; changes during the regular checks done by the XrdProofdManager.; Add support for selective definition of env and rootrc; variables. Different values can be set for different users, groups, SVN; versions or ROOT versions.; Improve the diagnostic in case of exceptions. Information; about the event and file being processed at the moment the exception; was raised is sent to the client, e.g.;    0.5: caught exception triggered by signal '1' while; processing dset:'EventTree',; file:'http://root.cern.ch/files/data/event_3.root', event:1 - check; logs for possible stacktrace; The patch also fixes a problem with submergers observed when a worker; was stopped because above the memory limits: this worker was; established as merger but could not do the work, for obvious reasons,; freezing the session.; Add two new methods to TProof: ShowMissingFiles() to facilitate; the display of the list of missing files; and GetMissingFiles() to get; a TFileCollection (dataset) with the missing files for further; pro",MatchSource.DOCS,proof/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:8567,Modifiability,variab,variables,8567,"st://disk1' instead of 'host' only as; it was so far). These feature can be enabled by defining the rootrc; variable 'Packetizer.Partitions', e.g.;            Packetizer.Partitions  /disk1,/disk2,/disk3; Add to the output list the parameters used by the active packetizer. . In the PrintProgress function used to display a text progress; bar, show also the average reading rate in [k,M,G}bytes/s in addition; to the event processing rate. This is useful to have a feeling of the; rate when running of a remote machine in batch mode.; Add the possibility to control the resident and virtual; memory of a proofserv using 'ulimit', which has less limitations and; more flexibility than setrlimit.; Deactivate workers when the requested packages could not be enabled properly.; Add support for reconfiguring the group manager and the; {env,rootrc} settings. The related configuration files are checked for; changes during the regular checks done by the XrdProofdManager.; Add support for selective definition of env and rootrc; variables. Different values can be set for different users, groups, SVN; versions or ROOT versions.; Improve the diagnostic in case of exceptions. Information; about the event and file being processed at the moment the exception; was raised is sent to the client, e.g.;    0.5: caught exception triggered by signal '1' while; processing dset:'EventTree',; file:'http://root.cern.ch/files/data/event_3.root', event:1 - check; logs for possible stacktrace; The patch also fixes a problem with submergers observed when a worker; was stopped because above the memory limits: this worker was; established as merger but could not do the work, for obvious reasons,; freezing the session.; Add two new methods to TProof: ShowMissingFiles() to facilitate; the display of the list of missing files; and GetMissingFiles() to get; a TFileCollection (dataset) with the missing files for further; processing. Fixes. Fix a bug in error status transmission which avoid; session freezing in so",MatchSource.DOCS,proof/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:11869,Modifiability,variab,variables,11869," negative values for 'workers still; sending' in PROOF-Lite .; Fix locking issue while building packages locally.; Fix issue setting permission and ownership of the dataset; user directories.Fix; a subtle bug affecting the (possibly rare) case when not all entries; are required and # entries does not correspond to an complete subset of; files (e.g. # entries = 1001000 with files of 100000 entries each). The; effect was uncomplete processing (skipped events, magenta bar) or a; session freeze.; Fix problem with packet re-assignment in case of a worker death (some packets were processed twice or more times).; Fix problem with the transmission of non-default file; attributes (e.g. the number of entries) from TChainElement to; TDSetElement during TChain processing in PROOF; Fix problem in the default packetizer with validating the; exact number of needed files when the information about the entries is; already available.; Fix problem with 'xpd.putenv' and 'xpd.putrc' occuring when the variables themselves contain commas.; Avoid resolving the workers FQDN when running in PROOF-Lite,; creating unnecessary delays when running PROOF-Lite within virtual; machines.; Fix problem with the permissions of the user data directory.; Add files to the list of files to process only when finally validated.; Fix; problem with canvases when the feedback canvas and the final canvas are; the same (do not delete the feedback canvas at the end of processing); Make sure that TProof::Load, TProofPlayer::SendSelector and; TSelector::GetSelector treat consistently the extensions of the; implementation files.; Unlock the cache after failure to load a selector; prevents session freezing; Correctly update the number of submergers when workers die; Add missing protection causing a crash in submergers when the output list contained TProofOutputFile objects.; Move the creation and start of the idle timeout from the end; of SetupCommon to the end of CreateServer, so that the timeout is not; active during",MatchSource.DOCS,proof/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:13238,Modifiability,sandbox,sandbox,13238," processed twice or more times).; Fix problem with the transmission of non-default file; attributes (e.g. the number of entries) from TChainElement to; TDSetElement during TChain processing in PROOF; Fix problem in the default packetizer with validating the; exact number of needed files when the information about the entries is; already available.; Fix problem with 'xpd.putenv' and 'xpd.putrc' occuring when the variables themselves contain commas.; Avoid resolving the workers FQDN when running in PROOF-Lite,; creating unnecessary delays when running PROOF-Lite within virtual; machines.; Fix problem with the permissions of the user data directory.; Add files to the list of files to process only when finally validated.; Fix; problem with canvases when the feedback canvas and the final canvas are; the same (do not delete the feedback canvas at the end of processing); Make sure that TProof::Load, TProofPlayer::SendSelector and; TSelector::GetSelector treat consistently the extensions of the; implementation files.; Unlock the cache after failure to load a selector; prevents session freezing; Correctly update the number of submergers when workers die; Add missing protection causing a crash in submergers when the output list contained TProofOutputFile objects.; Move the creation and start of the idle timeout from the end; of SetupCommon to the end of CreateServer, so that the timeout is not; active during worker setup.; Make sure that the TProof instance on the client is invalidated after an idle timeout.; Fix an old issue with DeactivateWorker(""*"") (the session is; was terminated because no worker was active; this call coudl not be; used as intermediate step to select a small number of workers).; Consistently check both Proof.Sandbox and ProofLite.Sandbox for sandbox non-default location as done in TProofLite; Fix a problem with the registration of missing files in the; 'MissingFiles' list (files which could not be open on the workers were; not always added to the list). ",MatchSource.DOCS,proof/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:1491,Performance,cache,cache,1491,", has been; developed for this case: it basically contains a list of standard; packetizers (one for each dataset) and loops over them (syntax:; ""dataset1,dataset2,..."" or dataset1 dataset2 ..."").; In; both cases, entry-list can be applied using the syntax; ""dataset<<entrylist"", e.g.; ""dataset1<<el1|dataset2<<el2|"".; The datasets to be processed can also be specified on one or multiple lines in a text file.; Add; support for automatic download of a package when available on the; master but not locally. The downloaded packages are store under <sandbox>/packages/downloaded; and automatically checked for updates against the master repository. If; a local version of the same package is created (using the; UploadPackage) the entry in downloaded is; cleared, so that the behaviour is unchanged.; Add; the possibility to remap the server for the files in a dataset. This; allows, for example, to reuse the dataset information for the same; files stored in a different cluster.; Add a local cache for; TDataSetManagerFile. This is mainly used to improve the speed of; TDataSetManager::ShowDataSets, which is run very often by users and may; be very slow if the number of dataset is large. The cache is also used; to cache frequently received dataset objects.Add the possibility to audit the activity on the nodes via syslog. .; New packetizer TPacketizerFile generating packets which contain a single; file path to be used in processing single files. Used, for example, in; tasks generating files. The files are specified into a TMap - named; 'PROOF_FilesToProcess' - containing the list of files to be generated; per host (the key is the host name, the value the TList of TObjString; (or TFileInfo) with the files names - or a TFileCollection: the output; of TFileCollection::GetFilesPerServer() can be directly passed as files; map). Workers are first assigned files belonging to; the list with host name matching the worker name. The map is; distributed to the master via the input list.Add suppor",MatchSource.DOCS,proof/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:1693,Performance,cache,cache,1693,"can be applied using the syntax; ""dataset<<entrylist"", e.g.; ""dataset1<<el1|dataset2<<el2|"".; The datasets to be processed can also be specified on one or multiple lines in a text file.; Add; support for automatic download of a package when available on the; master but not locally. The downloaded packages are store under <sandbox>/packages/downloaded; and automatically checked for updates against the master repository. If; a local version of the same package is created (using the; UploadPackage) the entry in downloaded is; cleared, so that the behaviour is unchanged.; Add; the possibility to remap the server for the files in a dataset. This; allows, for example, to reuse the dataset information for the same; files stored in a different cluster.; Add a local cache for; TDataSetManagerFile. This is mainly used to improve the speed of; TDataSetManager::ShowDataSets, which is run very often by users and may; be very slow if the number of dataset is large. The cache is also used; to cache frequently received dataset objects.Add the possibility to audit the activity on the nodes via syslog. .; New packetizer TPacketizerFile generating packets which contain a single; file path to be used in processing single files. Used, for example, in; tasks generating files. The files are specified into a TMap - named; 'PROOF_FilesToProcess' - containing the list of files to be generated; per host (the key is the host name, the value the TList of TObjString; (or TFileInfo) with the files names - or a TFileCollection: the output; of TFileCollection::GetFilesPerServer() can be directly passed as files; map). Workers are first assigned files belonging to; the list with host name matching the worker name. The map is; distributed to the master via the input list.Add support for; automatic setting of pointer data members to the relevant object in the; output list. The use of fOutputList->FindObject(""name"") in; TSelector::Terminate is not needed anymore for pointer data members,; e.g. histogra",MatchSource.DOCS,proof/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:1716,Performance,cache,cache,1716,"can be applied using the syntax; ""dataset<<entrylist"", e.g.; ""dataset1<<el1|dataset2<<el2|"".; The datasets to be processed can also be specified on one or multiple lines in a text file.; Add; support for automatic download of a package when available on the; master but not locally. The downloaded packages are store under <sandbox>/packages/downloaded; and automatically checked for updates against the master repository. If; a local version of the same package is created (using the; UploadPackage) the entry in downloaded is; cleared, so that the behaviour is unchanged.; Add; the possibility to remap the server for the files in a dataset. This; allows, for example, to reuse the dataset information for the same; files stored in a different cluster.; Add a local cache for; TDataSetManagerFile. This is mainly used to improve the speed of; TDataSetManager::ShowDataSets, which is run very often by users and may; be very slow if the number of dataset is large. The cache is also used; to cache frequently received dataset objects.Add the possibility to audit the activity on the nodes via syslog. .; New packetizer TPacketizerFile generating packets which contain a single; file path to be used in processing single files. Used, for example, in; tasks generating files. The files are specified into a TMap - named; 'PROOF_FilesToProcess' - containing the list of files to be generated; per host (the key is the host name, the value the TList of TObjString; (or TFileInfo) with the files names - or a TFileCollection: the output; of TFileCollection::GetFilesPerServer() can be directly passed as files; map). Workers are first assigned files belonging to; the list with host name matching the worker name. The map is; distributed to the master via the input list.Add support for; automatic setting of pointer data members to the relevant object in the; output list. The use of fOutputList->FindObject(""name"") in; TSelector::Terminate is not needed anymore for pointer data members,; e.g. histogra",MatchSource.DOCS,proof/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:7091,Performance,optimiz,optimizations,7091,"New directive 'xpd.datadir' to better control the user data directories and their permission settings. In TPacketizerUnit, add the possibility to exactly share the number of cycles between the workers.; See the parameter PROOF_PacketizerFixedNum.Implement; a timer to terminate idle sessions. The timeout value is controlled by; the variable ProofServ.IdleTimeout (value in seconds). This variable; can be set for all sessions in the xproofd config file via the 'xpd.putrc' directive.; Add the possibility to control the use of sub-mergers with; the ROOTrc variable Proof.SubMergers. It has the same meaning of the; parameter 'PROOF_UseMergers'. The capabilities of the latter have been; extended: now -1 means disable the use of submergers (before  negative values were ignored and there was no way for the user to disable the use of submergers). . Packetizer optimizations: improved worked distribution when; the number of files left to be processed is smaller than the number of; workers and at least one file has a number of events significantly; larger than the average; better apply the upper/lower limits on the; expected packet processing time.; Add the possibility to single-out disk partitions in the; packetizer; this works adding the beginning of a path in the name; defining a new TFileNode (e.g. 'host://disk1' instead of 'host' only as; it was so far). These feature can be enabled by defining the rootrc; variable 'Packetizer.Partitions', e.g.;            Packetizer.Partitions  /disk1,/disk2,/disk3; Add to the output list the parameters used by the active packetizer. . In the PrintProgress function used to display a text progress; bar, show also the average reading rate in [k,M,G}bytes/s in addition; to the event processing rate. This is useful to have a feeling of the; rate when running of a remote machine in batch mode.; Add the possibility to control the resident and virtual; memory of a proofserv using 'ulimit', which has less limitations and; more flexibility than setrl",MatchSource.DOCS,proof/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:12491,Performance,cache,cache,12491," processed twice or more times).; Fix problem with the transmission of non-default file; attributes (e.g. the number of entries) from TChainElement to; TDSetElement during TChain processing in PROOF; Fix problem in the default packetizer with validating the; exact number of needed files when the information about the entries is; already available.; Fix problem with 'xpd.putenv' and 'xpd.putrc' occuring when the variables themselves contain commas.; Avoid resolving the workers FQDN when running in PROOF-Lite,; creating unnecessary delays when running PROOF-Lite within virtual; machines.; Fix problem with the permissions of the user data directory.; Add files to the list of files to process only when finally validated.; Fix; problem with canvases when the feedback canvas and the final canvas are; the same (do not delete the feedback canvas at the end of processing); Make sure that TProof::Load, TProofPlayer::SendSelector and; TSelector::GetSelector treat consistently the extensions of the; implementation files.; Unlock the cache after failure to load a selector; prevents session freezing; Correctly update the number of submergers when workers die; Add missing protection causing a crash in submergers when the output list contained TProofOutputFile objects.; Move the creation and start of the idle timeout from the end; of SetupCommon to the end of CreateServer, so that the timeout is not; active during worker setup.; Make sure that the TProof instance on the client is invalidated after an idle timeout.; Fix an old issue with DeactivateWorker(""*"") (the session is; was terminated because no worker was active; this call coudl not be; used as intermediate step to select a small number of workers).; Consistently check both Proof.Sandbox and ProofLite.Sandbox for sandbox non-default location as done in TProofLite; Fix a problem with the registration of missing files in the; 'MissingFiles' list (files which could not be open on the workers were; not always added to the list). ",MatchSource.DOCS,proof/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:12514,Performance,load,load,12514," processed twice or more times).; Fix problem with the transmission of non-default file; attributes (e.g. the number of entries) from TChainElement to; TDSetElement during TChain processing in PROOF; Fix problem in the default packetizer with validating the; exact number of needed files when the information about the entries is; already available.; Fix problem with 'xpd.putenv' and 'xpd.putrc' occuring when the variables themselves contain commas.; Avoid resolving the workers FQDN when running in PROOF-Lite,; creating unnecessary delays when running PROOF-Lite within virtual; machines.; Fix problem with the permissions of the user data directory.; Add files to the list of files to process only when finally validated.; Fix; problem with canvases when the feedback canvas and the final canvas are; the same (do not delete the feedback canvas at the end of processing); Make sure that TProof::Load, TProofPlayer::SendSelector and; TSelector::GetSelector treat consistently the extensions of the; implementation files.; Unlock the cache after failure to load a selector; prevents session freezing; Correctly update the number of submergers when workers die; Add missing protection causing a crash in submergers when the output list contained TProofOutputFile objects.; Move the creation and start of the idle timeout from the end; of SetupCommon to the end of CreateServer, so that the timeout is not; active during worker setup.; Make sure that the TProof instance on the client is invalidated after an idle timeout.; Fix an old issue with DeactivateWorker(""*"") (the session is; was terminated because no worker was active; this call coudl not be; used as intermediate step to select a small number of workers).; Consistently check both Proof.Sandbox and ProofLite.Sandbox for sandbox non-default location as done in TProofLite; Fix a problem with the registration of missing files in the; 'MissingFiles' list (files which could not be open on the workers were; not always added to the list). ",MatchSource.DOCS,proof/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:6527,Safety,timeout,timeout,6527,"le, customize differently the quotas.Fix an issue with TTreeFriends. New tutorial showing how to use friends in PROOF.Package; management: add support for arguments in the SETUP function: it is; possible now to pass a string or a list of objects. The; TProof::EnablePackage interface has been extended to support this.Optimize; the validation step in the case not all the entries are required. The; validation step is stopped as soon as the requested number of events is; reached. If the parameter ""PROOF_ValidateByFile"" is set to 1, the; number of files is exactly what needed; otherwise the number of files; may exceed the number of files needed by (Number_Of_Workers - 1) .; New directive 'xpd.datadir' to better control the user data directories and their permission settings. In TPacketizerUnit, add the possibility to exactly share the number of cycles between the workers.; See the parameter PROOF_PacketizerFixedNum.Implement; a timer to terminate idle sessions. The timeout value is controlled by; the variable ProofServ.IdleTimeout (value in seconds). This variable; can be set for all sessions in the xproofd config file via the 'xpd.putrc' directive.; Add the possibility to control the use of sub-mergers with; the ROOTrc variable Proof.SubMergers. It has the same meaning of the; parameter 'PROOF_UseMergers'. The capabilities of the latter have been; extended: now -1 means disable the use of submergers (before  negative values were ignored and there was no way for the user to disable the use of submergers). . Packetizer optimizations: improved worked distribution when; the number of files left to be processed is smaller than the number of; workers and at least one file has a number of events significantly; larger than the average; better apply the upper/lower limits on the; expected packet processing time.; Add the possibility to single-out disk partitions in the; packetizer; this works adding the beginning of a path in the name; defining a new TFileNode (e.g. 'host://disk",MatchSource.DOCS,proof/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:9514,Safety,avoid,avoid,9514,"selective definition of env and rootrc; variables. Different values can be set for different users, groups, SVN; versions or ROOT versions.; Improve the diagnostic in case of exceptions. Information; about the event and file being processed at the moment the exception; was raised is sent to the client, e.g.;    0.5: caught exception triggered by signal '1' while; processing dset:'EventTree',; file:'http://root.cern.ch/files/data/event_3.root', event:1 - check; logs for possible stacktrace; The patch also fixes a problem with submergers observed when a worker; was stopped because above the memory limits: this worker was; established as merger but could not do the work, for obvious reasons,; freezing the session.; Add two new methods to TProof: ShowMissingFiles() to facilitate; the display of the list of missing files; and GetMissingFiles() to get; a TFileCollection (dataset) with the missing files for further; processing. Fixes. Fix a bug in error status transmission which avoid; session freezing in some cases; FIx; a few issues in libXrdProofd.so with handling of connection used for; admin operation: this should solve some cases where the daemon was not; responding. ; Fix a few memory leaks showing up when; running several queries in the same session; Fix a few issues affecting the new sub-merging option; Fix an issue preventing proper real-time notification; during VerifyDataSet; Fix an issue with TQueryResult ordering (was causing; random 'stressProof' failures); Fix; an issue with TProof::AskStatistics (fBytesRead, fRealTime and fCpuTime; were not correctly filled on the client; the values on the master,; displayed by TProof::Print were correct).; Fix several small issues affecting the handling of global; package directories; Fix an issue with socket handling in the main event-loop; while sendign or receiving files via TProofMgr.; Fix; a problem counting valid nodes in sequential or 'masteronly' mode,; generating the fake error message ""GoParallel: attaching to ca",MatchSource.DOCS,proof/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:10695,Safety,recover,recovering,10695,"FIx; a few issues in libXrdProofd.so with handling of connection used for; admin operation: this should solve some cases where the daemon was not; responding. ; Fix a few memory leaks showing up when; running several queries in the same session; Fix a few issues affecting the new sub-merging option; Fix an issue preventing proper real-time notification; during VerifyDataSet; Fix an issue with TQueryResult ordering (was causing; random 'stressProof' failures); Fix; an issue with TProof::AskStatistics (fBytesRead, fRealTime and fCpuTime; were not correctly filled on the client; the values on the master,; displayed by TProof::Print were correct).; Fix several small issues affecting the handling of global; package directories; Fix an issue with socket handling in the main event-loop; while sendign or receiving files via TProofMgr.; Fix; a problem counting valid nodes in sequential or 'masteronly' mode,; generating the fake error message ""GoParallel: attaching to candidate!""; Fix a few issues with the length of Unix socket paths; affecting PROOF-Lite and xproofd on MacOsX ; Fix an issue with the release of file descriptors when; recovering sessions .; Fix an issue with a fake error message (""Error in; <TROOT::cd>: No such file root:/"") in PROOF-Lite when; issuing TProof::SetParallel().; Fix a problem with negative values for 'workers still; sending' in PROOF-Lite .; Fix locking issue while building packages locally.; Fix issue setting permission and ownership of the dataset; user directories.Fix; a subtle bug affecting the (possibly rare) case when not all entries; are required and # entries does not correspond to an complete subset of; files (e.g. # entries = 1001000 with files of 100000 entries each). The; effect was uncomplete processing (skipped events, magenta bar) or a; session freeze.; Fix problem with packet re-assignment in case of a worker death (some packets were processed twice or more times).; Fix problem with the transmission of non-default file; attributes ",MatchSource.DOCS,proof/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:12769,Safety,timeout,timeout,12769," processed twice or more times).; Fix problem with the transmission of non-default file; attributes (e.g. the number of entries) from TChainElement to; TDSetElement during TChain processing in PROOF; Fix problem in the default packetizer with validating the; exact number of needed files when the information about the entries is; already available.; Fix problem with 'xpd.putenv' and 'xpd.putrc' occuring when the variables themselves contain commas.; Avoid resolving the workers FQDN when running in PROOF-Lite,; creating unnecessary delays when running PROOF-Lite within virtual; machines.; Fix problem with the permissions of the user data directory.; Add files to the list of files to process only when finally validated.; Fix; problem with canvases when the feedback canvas and the final canvas are; the same (do not delete the feedback canvas at the end of processing); Make sure that TProof::Load, TProofPlayer::SendSelector and; TSelector::GetSelector treat consistently the extensions of the; implementation files.; Unlock the cache after failure to load a selector; prevents session freezing; Correctly update the number of submergers when workers die; Add missing protection causing a crash in submergers when the output list contained TProofOutputFile objects.; Move the creation and start of the idle timeout from the end; of SetupCommon to the end of CreateServer, so that the timeout is not; active during worker setup.; Make sure that the TProof instance on the client is invalidated after an idle timeout.; Fix an old issue with DeactivateWorker(""*"") (the session is; was terminated because no worker was active; this call coudl not be; used as intermediate step to select a small number of workers).; Consistently check both Proof.Sandbox and ProofLite.Sandbox for sandbox non-default location as done in TProofLite; Fix a problem with the registration of missing files in the; 'MissingFiles' list (files which could not be open on the workers were; not always added to the list). ",MatchSource.DOCS,proof/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:12846,Safety,timeout,timeout,12846," processed twice or more times).; Fix problem with the transmission of non-default file; attributes (e.g. the number of entries) from TChainElement to; TDSetElement during TChain processing in PROOF; Fix problem in the default packetizer with validating the; exact number of needed files when the information about the entries is; already available.; Fix problem with 'xpd.putenv' and 'xpd.putrc' occuring when the variables themselves contain commas.; Avoid resolving the workers FQDN when running in PROOF-Lite,; creating unnecessary delays when running PROOF-Lite within virtual; machines.; Fix problem with the permissions of the user data directory.; Add files to the list of files to process only when finally validated.; Fix; problem with canvases when the feedback canvas and the final canvas are; the same (do not delete the feedback canvas at the end of processing); Make sure that TProof::Load, TProofPlayer::SendSelector and; TSelector::GetSelector treat consistently the extensions of the; implementation files.; Unlock the cache after failure to load a selector; prevents session freezing; Correctly update the number of submergers when workers die; Add missing protection causing a crash in submergers when the output list contained TProofOutputFile objects.; Move the creation and start of the idle timeout from the end; of SetupCommon to the end of CreateServer, so that the timeout is not; active during worker setup.; Make sure that the TProof instance on the client is invalidated after an idle timeout.; Fix an old issue with DeactivateWorker(""*"") (the session is; was terminated because no worker was active; this call coudl not be; used as intermediate step to select a small number of workers).; Consistently check both Proof.Sandbox and ProofLite.Sandbox for sandbox non-default location as done in TProofLite; Fix a problem with the registration of missing files in the; 'MissingFiles' list (files which could not be open on the workers were; not always added to the list). ",MatchSource.DOCS,proof/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:12969,Safety,timeout,timeout,12969," processed twice or more times).; Fix problem with the transmission of non-default file; attributes (e.g. the number of entries) from TChainElement to; TDSetElement during TChain processing in PROOF; Fix problem in the default packetizer with validating the; exact number of needed files when the information about the entries is; already available.; Fix problem with 'xpd.putenv' and 'xpd.putrc' occuring when the variables themselves contain commas.; Avoid resolving the workers FQDN when running in PROOF-Lite,; creating unnecessary delays when running PROOF-Lite within virtual; machines.; Fix problem with the permissions of the user data directory.; Add files to the list of files to process only when finally validated.; Fix; problem with canvases when the feedback canvas and the final canvas are; the same (do not delete the feedback canvas at the end of processing); Make sure that TProof::Load, TProofPlayer::SendSelector and; TSelector::GetSelector treat consistently the extensions of the; implementation files.; Unlock the cache after failure to load a selector; prevents session freezing; Correctly update the number of submergers when workers die; Add missing protection causing a crash in submergers when the output list contained TProofOutputFile objects.; Move the creation and start of the idle timeout from the end; of SetupCommon to the end of CreateServer, so that the timeout is not; active during worker setup.; Make sure that the TProof instance on the client is invalidated after an idle timeout.; Fix an old issue with DeactivateWorker(""*"") (the session is; was terminated because no worker was active; this call coudl not be; used as intermediate step to select a small number of workers).; Consistently check both Proof.Sandbox and ProofLite.Sandbox for sandbox non-default location as done in TProofLite; Fix a problem with the registration of missing files in the; 'MissingFiles' list (files which could not be open on the workers were; not always added to the list). ",MatchSource.DOCS,proof/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:1781,Security,audit,audit,1781,"t1<<el1|dataset2<<el2|"".; The datasets to be processed can also be specified on one or multiple lines in a text file.; Add; support for automatic download of a package when available on the; master but not locally. The downloaded packages are store under <sandbox>/packages/downloaded; and automatically checked for updates against the master repository. If; a local version of the same package is created (using the; UploadPackage) the entry in downloaded is; cleared, so that the behaviour is unchanged.; Add; the possibility to remap the server for the files in a dataset. This; allows, for example, to reuse the dataset information for the same; files stored in a different cluster.; Add a local cache for; TDataSetManagerFile. This is mainly used to improve the speed of; TDataSetManager::ShowDataSets, which is run very often by users and may; be very slow if the number of dataset is large. The cache is also used; to cache frequently received dataset objects.Add the possibility to audit the activity on the nodes via syslog. .; New packetizer TPacketizerFile generating packets which contain a single; file path to be used in processing single files. Used, for example, in; tasks generating files. The files are specified into a TMap - named; 'PROOF_FilesToProcess' - containing the list of files to be generated; per host (the key is the host name, the value the TList of TObjString; (or TFileInfo) with the files names - or a TFileCollection: the output; of TFileCollection::GetFilesPerServer() can be directly passed as files; map). Workers are first assigned files belonging to; the list with host name matching the worker name. The map is; distributed to the master via the input list.Add support for; automatic setting of pointer data members to the relevant object in the; output list. The use of fOutputList->FindObject(""name"") in; TSelector::Terminate is not needed anymore for pointer data members,; e.g. histograms.; Add the possibility to define an external list of environment; ",MatchSource.DOCS,proof/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:5884,Security,validat,validation,5884,"ng of wild cards in the dataset manager; for; example, issuing a GetDataSet(...) on a dataset URI containign wild; cards will return a grand dataset sum of all the datasets matching the; URI.; Add options to get a list of all dataset registered names; from ScanDataSets (option kList; the result is a TMap of {TObjString,; TObjString} with the second TObjString empty).Improved version of the PQ2 scripts; the scripts now invoke a dedicated ROOT application (named pq2) available under $ROOTSYS/bin .Add; support for recursive reading of group config files via the 'include; sub-file' directive. This allows to have a common part and, for; example, customize differently the quotas.Fix an issue with TTreeFriends. New tutorial showing how to use friends in PROOF.Package; management: add support for arguments in the SETUP function: it is; possible now to pass a string or a list of objects. The; TProof::EnablePackage interface has been extended to support this.Optimize; the validation step in the case not all the entries are required. The; validation step is stopped as soon as the requested number of events is; reached. If the parameter ""PROOF_ValidateByFile"" is set to 1, the; number of files is exactly what needed; otherwise the number of files; may exceed the number of files needed by (Number_Of_Workers - 1) .; New directive 'xpd.datadir' to better control the user data directories and their permission settings. In TPacketizerUnit, add the possibility to exactly share the number of cycles between the workers.; See the parameter PROOF_PacketizerFixedNum.Implement; a timer to terminate idle sessions. The timeout value is controlled by; the variable ProofServ.IdleTimeout (value in seconds). This variable; can be set for all sessions in the xproofd config file via the 'xpd.putrc' directive.; Add the possibility to control the use of sub-mergers with; the ROOTrc variable Proof.SubMergers. It has the same meaning of the; parameter 'PROOF_UseMergers'. The capabilities of the latter h",MatchSource.DOCS,proof/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:5951,Security,validat,validation,5951,"on a dataset URI containign wild; cards will return a grand dataset sum of all the datasets matching the; URI.; Add options to get a list of all dataset registered names; from ScanDataSets (option kList; the result is a TMap of {TObjString,; TObjString} with the second TObjString empty).Improved version of the PQ2 scripts; the scripts now invoke a dedicated ROOT application (named pq2) available under $ROOTSYS/bin .Add; support for recursive reading of group config files via the 'include; sub-file' directive. This allows to have a common part and, for; example, customize differently the quotas.Fix an issue with TTreeFriends. New tutorial showing how to use friends in PROOF.Package; management: add support for arguments in the SETUP function: it is; possible now to pass a string or a list of objects. The; TProof::EnablePackage interface has been extended to support this.Optimize; the validation step in the case not all the entries are required. The; validation step is stopped as soon as the requested number of events is; reached. If the parameter ""PROOF_ValidateByFile"" is set to 1, the; number of files is exactly what needed; otherwise the number of files; may exceed the number of files needed by (Number_Of_Workers - 1) .; New directive 'xpd.datadir' to better control the user data directories and their permission settings. In TPacketizerUnit, add the possibility to exactly share the number of cycles between the workers.; See the parameter PROOF_PacketizerFixedNum.Implement; a timer to terminate idle sessions. The timeout value is controlled by; the variable ProofServ.IdleTimeout (value in seconds). This variable; can be set for all sessions in the xproofd config file via the 'xpd.putrc' directive.; Add the possibility to control the use of sub-mergers with; the ROOTrc variable Proof.SubMergers. It has the same meaning of the; parameter 'PROOF_UseMergers'. The capabilities of the latter have been; extended: now -1 means disable the use of submergers (before  negative ",MatchSource.DOCS,proof/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:11697,Security,validat,validating,11697,"riptors when; recovering sessions .; Fix an issue with a fake error message (""Error in; <TROOT::cd>: No such file root:/"") in PROOF-Lite when; issuing TProof::SetParallel().; Fix a problem with negative values for 'workers still; sending' in PROOF-Lite .; Fix locking issue while building packages locally.; Fix issue setting permission and ownership of the dataset; user directories.Fix; a subtle bug affecting the (possibly rare) case when not all entries; are required and # entries does not correspond to an complete subset of; files (e.g. # entries = 1001000 with files of 100000 entries each). The; effect was uncomplete processing (skipped events, magenta bar) or a; session freeze.; Fix problem with packet re-assignment in case of a worker death (some packets were processed twice or more times).; Fix problem with the transmission of non-default file; attributes (e.g. the number of entries) from TChainElement to; TDSetElement during TChain processing in PROOF; Fix problem in the default packetizer with validating the; exact number of needed files when the information about the entries is; already available.; Fix problem with 'xpd.putenv' and 'xpd.putrc' occuring when the variables themselves contain commas.; Avoid resolving the workers FQDN when running in PROOF-Lite,; creating unnecessary delays when running PROOF-Lite within virtual; machines.; Fix problem with the permissions of the user data directory.; Add files to the list of files to process only when finally validated.; Fix; problem with canvases when the feedback canvas and the final canvas are; the same (do not delete the feedback canvas at the end of processing); Make sure that TProof::Load, TProofPlayer::SendSelector and; TSelector::GetSelector treat consistently the extensions of the; implementation files.; Unlock the cache after failure to load a selector; prevents session freezing; Correctly update the number of submergers when workers die; Add missing protection causing a crash in submergers when the o",MatchSource.DOCS,proof/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:12170,Security,validat,validated,12170,"required and # entries does not correspond to an complete subset of; files (e.g. # entries = 1001000 with files of 100000 entries each). The; effect was uncomplete processing (skipped events, magenta bar) or a; session freeze.; Fix problem with packet re-assignment in case of a worker death (some packets were processed twice or more times).; Fix problem with the transmission of non-default file; attributes (e.g. the number of entries) from TChainElement to; TDSetElement during TChain processing in PROOF; Fix problem in the default packetizer with validating the; exact number of needed files when the information about the entries is; already available.; Fix problem with 'xpd.putenv' and 'xpd.putrc' occuring when the variables themselves contain commas.; Avoid resolving the workers FQDN when running in PROOF-Lite,; creating unnecessary delays when running PROOF-Lite within virtual; machines.; Fix problem with the permissions of the user data directory.; Add files to the list of files to process only when finally validated.; Fix; problem with canvases when the feedback canvas and the final canvas are; the same (do not delete the feedback canvas at the end of processing); Make sure that TProof::Load, TProofPlayer::SendSelector and; TSelector::GetSelector treat consistently the extensions of the; implementation files.; Unlock the cache after failure to load a selector; prevents session freezing; Correctly update the number of submergers when workers die; Add missing protection causing a crash in submergers when the output list contained TProofOutputFile objects.; Move the creation and start of the idle timeout from the end; of SetupCommon to the end of CreateServer, so that the timeout is not; active during worker setup.; Make sure that the TProof instance on the client is invalidated after an idle timeout.; Fix an old issue with DeactivateWorker(""*"") (the session is; was terminated because no worker was active; this call coudl not be; used as intermediate step to select",MatchSource.DOCS,proof/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:1047,Testability,sandbox,sandbox,1047,"e go in TProof::Process(const char; *dataset, ...).; Two options are provided:;  - 'grand; dataset':   the datasets are added up; and considered as a single dataset (syntax:; ""dataset1|dataset2|..."");  - 'keep; separated':; the datasets are processed one after the other; the user is notified in; the selector of the change of dataset so they have the opportunity to; separate the results. A new packetizer, TPacketizerMulti, has been; developed for this case: it basically contains a list of standard; packetizers (one for each dataset) and loops over them (syntax:; ""dataset1,dataset2,..."" or dataset1 dataset2 ..."").; In; both cases, entry-list can be applied using the syntax; ""dataset<<entrylist"", e.g.; ""dataset1<<el1|dataset2<<el2|"".; The datasets to be processed can also be specified on one or multiple lines in a text file.; Add; support for automatic download of a package when available on the; master but not locally. The downloaded packages are store under <sandbox>/packages/downloaded; and automatically checked for updates against the master repository. If; a local version of the same package is created (using the; UploadPackage) the entry in downloaded is; cleared, so that the behaviour is unchanged.; Add; the possibility to remap the server for the files in a dataset. This; allows, for example, to reuse the dataset information for the same; files stored in a different cluster.; Add a local cache for; TDataSetManagerFile. This is mainly used to improve the speed of; TDataSetManager::ShowDataSets, which is run very often by users and may; be very slow if the number of dataset is large. The cache is also used; to cache frequently received dataset objects.Add the possibility to audit the activity on the nodes via syslog. .; New packetizer TPacketizerFile generating packets which contain a single; file path to be used in processing single files. Used, for example, in; tasks generating files. The files are specified into a TMap - named; 'PROOF_FilesToProcess' - contain",MatchSource.DOCS,proof/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:4534,Testability,test,test,4534,"e ntuple is called 'PROOF_ProgressPerfNtuple'.; Add support for worker autodiscovery in PROOF using the; Avahi/Bonjour technology. The new functionality is supported on Mac; (MacOsX >= 10.4; no need of additional installs) and linux (requires; the Avahi framework, available by default on most of the; distributions). To use this functionality (instead-of or in-addition-to; the the static worker configuration via proof.conf or xpd.worker) the; new directive 'xpd.bonjour' must be used. Improvements. Improve support for valgrind runs in PROOF-Lite; Add the possibility to add files to a dataset. This is; achieved with a new option 'U' (for update) to RegisterDataSet.; Add; methof TProof::GetStatistics to allow the client to retrieve the; correct values of fBytesRead, fRealTime and fCpuTime at any moment;; this will be used to setup a sort of ROOTmarks in stressProof .; Several improvements in the test program 'stressProof'; and in the tutorials under 'tutorials/proof'; Avoid; contacting the DNS when initializing TProofMgr as base class of; TProofMgrLite: it is not needed and it may introduce long startup; delays.; Make TProof::LogViewer("""") start the viewer for; a Lite session, in parallel to whats happen for TProof::Open("""").; Several; improvements in the handling of wild cards in the dataset manager; for; example, issuing a GetDataSet(...) on a dataset URI containign wild; cards will return a grand dataset sum of all the datasets matching the; URI.; Add options to get a list of all dataset registered names; from ScanDataSets (option kList; the result is a TMap of {TObjString,; TObjString} with the second TObjString empty).Improved version of the PQ2 scripts; the scripts now invoke a dedicated ROOT application (named pq2) available under $ROOTSYS/bin .Add; support for recursive reading of group config files via the 'include; sub-file' directive. This allows to have a common part and, for; example, customize differently the quotas.Fix an issue with TTreeFriends. New tuto",MatchSource.DOCS,proof/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:8992,Testability,log,logs,8992," the resident and virtual; memory of a proofserv using 'ulimit', which has less limitations and; more flexibility than setrlimit.; Deactivate workers when the requested packages could not be enabled properly.; Add support for reconfiguring the group manager and the; {env,rootrc} settings. The related configuration files are checked for; changes during the regular checks done by the XrdProofdManager.; Add support for selective definition of env and rootrc; variables. Different values can be set for different users, groups, SVN; versions or ROOT versions.; Improve the diagnostic in case of exceptions. Information; about the event and file being processed at the moment the exception; was raised is sent to the client, e.g.;    0.5: caught exception triggered by signal '1' while; processing dset:'EventTree',; file:'http://root.cern.ch/files/data/event_3.root', event:1 - check; logs for possible stacktrace; The patch also fixes a problem with submergers observed when a worker; was stopped because above the memory limits: this worker was; established as merger but could not do the work, for obvious reasons,; freezing the session.; Add two new methods to TProof: ShowMissingFiles() to facilitate; the display of the list of missing files; and GetMissingFiles() to get; a TFileCollection (dataset) with the missing files for further; processing. Fixes. Fix a bug in error status transmission which avoid; session freezing in some cases; FIx; a few issues in libXrdProofd.so with handling of connection used for; admin operation: this should solve some cases where the daemon was not; responding. ; Fix a few memory leaks showing up when; running several queries in the same session; Fix a few issues affecting the new sub-merging option; Fix an issue preventing proper real-time notification; during VerifyDataSet; Fix an issue with TQueryResult ordering (was causing; random 'stressProof' failures); Fix; an issue with TProof::AskStatistics (fBytesRead, fRealTime and fCpuTime; were not corr",MatchSource.DOCS,proof/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:13238,Testability,sandbox,sandbox,13238," processed twice or more times).; Fix problem with the transmission of non-default file; attributes (e.g. the number of entries) from TChainElement to; TDSetElement during TChain processing in PROOF; Fix problem in the default packetizer with validating the; exact number of needed files when the information about the entries is; already available.; Fix problem with 'xpd.putenv' and 'xpd.putrc' occuring when the variables themselves contain commas.; Avoid resolving the workers FQDN when running in PROOF-Lite,; creating unnecessary delays when running PROOF-Lite within virtual; machines.; Fix problem with the permissions of the user data directory.; Add files to the list of files to process only when finally validated.; Fix; problem with canvases when the feedback canvas and the final canvas are; the same (do not delete the feedback canvas at the end of processing); Make sure that TProof::Load, TProofPlayer::SendSelector and; TSelector::GetSelector treat consistently the extensions of the; implementation files.; Unlock the cache after failure to load a selector; prevents session freezing; Correctly update the number of submergers when workers die; Add missing protection causing a crash in submergers when the output list contained TProofOutputFile objects.; Move the creation and start of the idle timeout from the end; of SetupCommon to the end of CreateServer, so that the timeout is not; active during worker setup.; Make sure that the TProof instance on the client is invalidated after an idle timeout.; Fix an old issue with DeactivateWorker(""*"") (the session is; was terminated because no worker was active; this call coudl not be; used as intermediate step to select a small number of workers).; Consistently check both Proof.Sandbox and ProofLite.Sandbox for sandbox non-default location as done in TProofLite; Fix a problem with the registration of missing files in the; 'MissingFiles' list (files which could not be open on the workers were; not always added to the list). ",MatchSource.DOCS,proof/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:1252,Usability,clear,cleared,1252,"as a single dataset (syntax:; ""dataset1|dataset2|..."");  - 'keep; separated':; the datasets are processed one after the other; the user is notified in; the selector of the change of dataset so they have the opportunity to; separate the results. A new packetizer, TPacketizerMulti, has been; developed for this case: it basically contains a list of standard; packetizers (one for each dataset) and loops over them (syntax:; ""dataset1,dataset2,..."" or dataset1 dataset2 ..."").; In; both cases, entry-list can be applied using the syntax; ""dataset<<entrylist"", e.g.; ""dataset1<<el1|dataset2<<el2|"".; The datasets to be processed can also be specified on one or multiple lines in a text file.; Add; support for automatic download of a package when available on the; master but not locally. The downloaded packages are store under <sandbox>/packages/downloaded; and automatically checked for updates against the master repository. If; a local version of the same package is created (using the; UploadPackage) the entry in downloaded is; cleared, so that the behaviour is unchanged.; Add; the possibility to remap the server for the files in a dataset. This; allows, for example, to reuse the dataset information for the same; files stored in a different cluster.; Add a local cache for; TDataSetManagerFile. This is mainly used to improve the speed of; TDataSetManager::ShowDataSets, which is run very often by users and may; be very slow if the number of dataset is large. The cache is also used; to cache frequently received dataset objects.Add the possibility to audit the activity on the nodes via syslog. .; New packetizer TPacketizerFile generating packets which contain a single; file path to be used in processing single files. Used, for example, in; tasks generating files. The files are specified into a TMap - named; 'PROOF_FilesToProcess' - containing the list of files to be generated; per host (the key is the host name, the value the TList of TObjString; (or TFileInfo) with the files names ",MatchSource.DOCS,proof/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:12218,Usability,feedback,feedback,12218,"vents, magenta bar) or a; session freeze.; Fix problem with packet re-assignment in case of a worker death (some packets were processed twice or more times).; Fix problem with the transmission of non-default file; attributes (e.g. the number of entries) from TChainElement to; TDSetElement during TChain processing in PROOF; Fix problem in the default packetizer with validating the; exact number of needed files when the information about the entries is; already available.; Fix problem with 'xpd.putenv' and 'xpd.putrc' occuring when the variables themselves contain commas.; Avoid resolving the workers FQDN when running in PROOF-Lite,; creating unnecessary delays when running PROOF-Lite within virtual; machines.; Fix problem with the permissions of the user data directory.; Add files to the list of files to process only when finally validated.; Fix; problem with canvases when the feedback canvas and the final canvas are; the same (do not delete the feedback canvas at the end of processing); Make sure that TProof::Load, TProofPlayer::SendSelector and; TSelector::GetSelector treat consistently the extensions of the; implementation files.; Unlock the cache after failure to load a selector; prevents session freezing; Correctly update the number of submergers when workers die; Add missing protection causing a crash in submergers when the output list contained TProofOutputFile objects.; Move the creation and start of the idle timeout from the end; of SetupCommon to the end of CreateServer, so that the timeout is not; active during worker setup.; Make sure that the TProof instance on the client is invalidated after an idle timeout.; Fix an old issue with DeactivateWorker(""*"") (the session is; was terminated because no worker was active; this call coudl not be; used as intermediate step to select a small number of workers).; Consistently check both Proof.Sandbox and ProofLite.Sandbox for sandbox non-default location as done in TProofLite; Fix a problem with the registration of ",MatchSource.DOCS,proof/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html:12288,Usability,feedback,feedback,12288,"vents, magenta bar) or a; session freeze.; Fix problem with packet re-assignment in case of a worker death (some packets were processed twice or more times).; Fix problem with the transmission of non-default file; attributes (e.g. the number of entries) from TChainElement to; TDSetElement during TChain processing in PROOF; Fix problem in the default packetizer with validating the; exact number of needed files when the information about the entries is; already available.; Fix problem with 'xpd.putenv' and 'xpd.putrc' occuring when the variables themselves contain commas.; Avoid resolving the workers FQDN when running in PROOF-Lite,; creating unnecessary delays when running PROOF-Lite within virtual; machines.; Fix problem with the permissions of the user data directory.; Add files to the list of files to process only when finally validated.; Fix; problem with canvases when the feedback canvas and the final canvas are; the same (do not delete the feedback canvas at the end of processing); Make sure that TProof::Load, TProofPlayer::SendSelector and; TSelector::GetSelector treat consistently the extensions of the; implementation files.; Unlock the cache after failure to load a selector; prevents session freezing; Correctly update the number of submergers when workers die; Add missing protection causing a crash in submergers when the output list contained TProofOutputFile objects.; Move the creation and start of the idle timeout from the end; of SetupCommon to the end of CreateServer, so that the timeout is not; active during worker setup.; Make sure that the TProof instance on the client is invalidated after an idle timeout.; Fix an old issue with DeactivateWorker(""*"") (the session is; was terminated because no worker was active; this call coudl not be; used as intermediate step to select a small number of workers).; Consistently check both Proof.Sandbox and ProofLite.Sandbox for sandbox non-default location as done in TProofLite; Fix a problem with the registration of ",MatchSource.DOCS,proof/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html:424,Availability,avail,available,424,". Proof. New functionality; ; In TProof::Load, add the possibility to define a list of files to be; sent because needed by the main macro file. The list is comma-separated; and the first file is considered as the main one. For example.        ; proof->Load(""<macropath>/mymacro.C+,<thispath>/thisheader.h,<thatpath>/thatheader.h""). will make sure that the files 'thisheader.h' and 'thatheader.h', needed; by 'mymacro.C' are available in the sandbox on the worker machines.; Note that 'thisheader.h' and 'thatheader.h' will be available remotely; in the sandbox, as 'mymacro.C'; so they should be included directly by; 'mymacro.C', e.g. '#include ""thisheader.h""' .; Import the dataset stager daemon 'afdsmgrd' into ROOT; this is used; to manage data staging based on the dataset information (see; http://code.google.com/p/afdsmgrd/ for more info). The daemon is; located under $ROOTSYS/proof/afdsmgrd .; New PROOF bench suite, a framework to run CPU and IO benchmarks with; default selectors/data or with user-provided ones. The code is located; under proof/proofbench.; Add the possibility to access the files on the workers via the same; port used by PROOF. This is useful for cases when it is not possible to; start a file server daemon on a different port (because, for eample, of; a firewall or just inconvenience) and workers do not share a file; system. Internally this works by forking a 'rootd' after identifying a; file request and trasferring the connection to it. The client side is a; TNetFile and it is triggered by the protocol ""rootd://"" (the just; implemented etc/plugins/TFile/P120_TNetFile.C includes this; protocol).; Add support for log file truncation. Truncation is disabled by; default. Enabling is controlled by the rootrc variable.           ; ProofServ.LogFileMaxSize  ; {<bytes>|<kilobytes>K|<megabytes>M|<gigabytes>G}.  indicating the max number of bytes. The number can be followed by; a {K,M,G} to indicate KBytes, MBytes or GBytes, respectively.; Add new derivation of T",MatchSource.DOCS,proof/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html:526,Availability,avail,available,526,". Proof. New functionality; ; In TProof::Load, add the possibility to define a list of files to be; sent because needed by the main macro file. The list is comma-separated; and the first file is considered as the main one. For example.        ; proof->Load(""<macropath>/mymacro.C+,<thispath>/thisheader.h,<thatpath>/thatheader.h""). will make sure that the files 'thisheader.h' and 'thatheader.h', needed; by 'mymacro.C' are available in the sandbox on the worker machines.; Note that 'thisheader.h' and 'thatheader.h' will be available remotely; in the sandbox, as 'mymacro.C'; so they should be included directly by; 'mymacro.C', e.g. '#include ""thisheader.h""' .; Import the dataset stager daemon 'afdsmgrd' into ROOT; this is used; to manage data staging based on the dataset information (see; http://code.google.com/p/afdsmgrd/ for more info). The daemon is; located under $ROOTSYS/proof/afdsmgrd .; New PROOF bench suite, a framework to run CPU and IO benchmarks with; default selectors/data or with user-provided ones. The code is located; under proof/proofbench.; Add the possibility to access the files on the workers via the same; port used by PROOF. This is useful for cases when it is not possible to; start a file server daemon on a different port (because, for eample, of; a firewall or just inconvenience) and workers do not share a file; system. Internally this works by forking a 'rootd' after identifying a; file request and trasferring the connection to it. The client side is a; TNetFile and it is triggered by the protocol ""rootd://"" (the just; implemented etc/plugins/TFile/P120_TNetFile.C includes this; protocol).; Add support for log file truncation. Truncation is disabled by; default. Enabling is controlled by the rootrc variable.           ; ProofServ.LogFileMaxSize  ; {<bytes>|<kilobytes>K|<megabytes>M|<gigabytes>G}.  indicating the max number of bytes. The number can be followed by; a {K,M,G} to indicate KBytes, MBytes or GBytes, respectively.; Add new derivation of T",MatchSource.DOCS,proof/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html:5032,Availability,failure,failures,5032,"roup'; keyword in SQL); add new field 'querytag' VARCHAR(64) with the unique; query tag; in WriteQueryLog fill also the field 'totevents'; in; PacketEvent, add switch to control whether to send te information to; the monitoring system on per packet level (may be too much for SQL).; The switch is called fMonitorPerPacket and it is globally controlled by; the rootrc variable 'Proof.MonitorPerPacket' and at session level with; the parameter PROOF_MonitorPerPacket .; Improve treatment of the case when temporary files are asked to be; created on a shared file system not containing the sandboxes. This; case, which seems to be a rather common one, should be now fully; supported.; Correctly honour selector abort status settings; TSelector::kAbortProcess and TSelector::kAbortFile.; Improve reporting of the non-processed {files, events} in the final; 'MissingFiles' list.  ; Improved algorithm for TPacketizerUnit to fix issue with non; homogeneous machines.; Improve the way the information about log files is saved in case of; failures. The log paths for these failing now should be now correctly; saved and accessible via TProofLog.; Improve merging of histograms. Just use TH1::Add whne the axis are; equal; much faster than TH1::Merge. Fixes; ; In TDataSetManagerFile::NotifyUpdate fix handling of the case when; the global list file does not exist yet (new dataset directory). Fixes; error messages during editing dataset operations.; Fix issue with machine names consistency when working on a local; machine ('localhost' or 'localhost.localdomain' are mapped to; gSystem->HostName()); solves possible matching problems in the; packetizer.; In TProofServ, fill the ""grand total"" message with more blanks, so; that no remnants of the previous message are visible on the screen.; In the autoconf/bonjour interface, fix issue preventing the correct; port (the protocol one, which may be different from the application; default) being used when registering the service. . In TProofPlayer::AddQuer",MatchSource.DOCS,proof/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html:5393,Availability,error,error,5393,"ion level with; the parameter PROOF_MonitorPerPacket .; Improve treatment of the case when temporary files are asked to be; created on a shared file system not containing the sandboxes. This; case, which seems to be a rather common one, should be now fully; supported.; Correctly honour selector abort status settings; TSelector::kAbortProcess and TSelector::kAbortFile.; Improve reporting of the non-processed {files, events} in the final; 'MissingFiles' list.  ; Improved algorithm for TPacketizerUnit to fix issue with non; homogeneous machines.; Improve the way the information about log files is saved in case of; failures. The log paths for these failing now should be now correctly; saved and accessible via TProofLog.; Improve merging of histograms. Just use TH1::Add whne the axis are; equal; much faster than TH1::Merge. Fixes; ; In TDataSetManagerFile::NotifyUpdate fix handling of the case when; the global list file does not exist yet (new dataset directory). Fixes; error messages during editing dataset operations.; Fix issue with machine names consistency when working on a local; machine ('localhost' or 'localhost.localdomain' are mapped to; gSystem->HostName()); solves possible matching problems in the; packetizer.; In TProofServ, fill the ""grand total"" message with more blanks, so; that no remnants of the previous message are visible on the screen.; In the autoconf/bonjour interface, fix issue preventing the correct; port (the protocol one, which may be different from the application; default) being used when registering the service. . In TProofPlayer::AddQueryResult, fix a bug affecting the order in; whihc query results are registered when the start time is within 1; second.; Fix worker name in TSlaveLite.; Fix problem with enabling packages with option 'notOnClient' in; PROOF-Lite .; Make sure the log file is flushed at the end of startup to avoid; spurious log messages on next commands .; In CreateSession(), fix an issue with the validity check for existing; ses",MatchSource.DOCS,proof/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html:7742,Deployability,update,update,7742," when the start time is within 1; second.; Fix worker name in TSlaveLite.; Fix problem with enabling packages with option 'notOnClient' in; PROOF-Lite .; Make sure the log file is flushed at the end of startup to avoid; spurious log messages on next commands .; In CreateSession(), fix an issue with the validity check for existing; sessions .; In TProofLite: fix problem with passing the 'varexp' and 'selection'; strings for processing, preventing correct usage of the operators '|'; and '||' in TTreeFormula.; In the TProofOutputFile constructor, remove the 'localroot' prefix; only if present in the path. Fixes possible truncation problems; occuring when the paths are not under the localroot scope.; In TXSocket and TXSlave: fix problem with the way collection over a; socket just marked as 'bad' was interrupted; the interrupt was de facto; ineffective, so that collection stayed always until the timeout expired; (default: 5 minutes). Should solve some of the cases were slow response; was experienced.; Fix a problem with log path transmission when the node dies early or; not even starts. The log path was empty and wrong was filled in when; retrieving the log buffers, disorienting debugging.; Fix a bug checking the first event which rendered ineffective the; request for processing a subset of events in a given dataset or; chain.; In pq2-ana-dist, fix problem with the labels of the distribution; histo occuring when machines are represented by IPs instead of; names.; Add missing calls to closedir() and TSystem::FreeDirectory, cuasing a; large number of filedescriptors remaining opened after xproofd; initialization.; Fix a problem with the final update of the progress information; affecting occasionally cases with skipped events.; Fix merging of TproofOutputFile when using submergers (the; intermediate files were not correctly handled).; Fix the way TChain weights are transmitted to TProofDraw in; DrawSelect operations. AoB; ; The class TFileMerger has been moved to 'io/io'. ",MatchSource.DOCS,proof/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html:2272,Energy Efficiency,monitor,monitoring,2272,"works by forking a 'rootd' after identifying a; file request and trasferring the connection to it. The client side is a; TNetFile and it is triggered by the protocol ""rootd://"" (the just; implemented etc/plugins/TFile/P120_TNetFile.C includes this; protocol).; Add support for log file truncation. Truncation is disabled by; default. Enabling is controlled by the rootrc variable.           ; ProofServ.LogFileMaxSize  ; {<bytes>|<kilobytes>K|<megabytes>M|<gigabytes>G}.  indicating the max number of bytes. The number can be followed by; a {K,M,G} to indicate KBytes, MBytes or GBytes, respectively.; Add new derivation of TList (TProofOutputList) to be used on the; PROOF client to filter out PROOF internal objects when displaying or; printing the list. By default objects was names start with 'PROOF_' are; not shown. The presence of a non empty missing file list is; notified.; In the PROOF monitoring to: send additional information about memory; usage during the query, the name and size (# of files) of the dataset; processed (if any); add possibility to send the information to multiple; monitoring collectors.; Add support for block activation/deactivation of workers.; Add possibility to start the proofserv with 'system()' instead of; 'fork()' as done in PROOF-Lite. A new switch 'usefrk' has been added to; 'xpd.proofservmgr' to control that. Default is still fork(). Improvements; ; In TProof::ClearPackages, use the manager to execute the command on; all known worker machines. Improves the consistency when re-istalling; packages. In TProof::GetDataSets, add support for option ':lite:'; this allows; to fill the map with only the summary information about the datasets; (the header of TFileCollections), significantly increasing the speed; and the memory footprint when the number of datasets is very large.; Accept '.' in user names.; Add switch to control caching of the files read on MacOsX. A call to; fcntl(fd, F_NOCACHE, 1) is done after opening the file.; Add export of the en",MatchSource.DOCS,proof/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html:2473,Energy Efficiency,monitor,monitoring,2473,"works by forking a 'rootd' after identifying a; file request and trasferring the connection to it. The client side is a; TNetFile and it is triggered by the protocol ""rootd://"" (the just; implemented etc/plugins/TFile/P120_TNetFile.C includes this; protocol).; Add support for log file truncation. Truncation is disabled by; default. Enabling is controlled by the rootrc variable.           ; ProofServ.LogFileMaxSize  ; {<bytes>|<kilobytes>K|<megabytes>M|<gigabytes>G}.  indicating the max number of bytes. The number can be followed by; a {K,M,G} to indicate KBytes, MBytes or GBytes, respectively.; Add new derivation of TList (TProofOutputList) to be used on the; PROOF client to filter out PROOF internal objects when displaying or; printing the list. By default objects was names start with 'PROOF_' are; not shown. The presence of a non empty missing file list is; notified.; In the PROOF monitoring to: send additional information about memory; usage during the query, the name and size (# of files) of the dataset; processed (if any); add possibility to send the information to multiple; monitoring collectors.; Add support for block activation/deactivation of workers.; Add possibility to start the proofserv with 'system()' instead of; 'fork()' as done in PROOF-Lite. A new switch 'usefrk' has been added to; 'xpd.proofservmgr' to control that. Default is still fork(). Improvements; ; In TProof::ClearPackages, use the manager to execute the command on; all known worker machines. Improves the consistency when re-istalling; packages. In TProof::GetDataSets, add support for option ':lite:'; this allows; to fill the map with only the summary information about the datasets; (the header of TFileCollections), significantly increasing the speed; and the memory footprint when the number of datasets is very large.; Accept '.' in user names.; Add switch to control caching of the files read on MacOsX. A call to; fcntl(fd, F_NOCACHE, 1) is done after opening the file.; Add export of the en",MatchSource.DOCS,proof/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html:3718,Energy Efficiency,monitor,monitoring,3718,"ts; ; In TProof::ClearPackages, use the manager to execute the command on; all known worker machines. Improves the consistency when re-istalling; packages. In TProof::GetDataSets, add support for option ':lite:'; this allows; to fill the map with only the summary information about the datasets; (the header of TFileCollections), significantly increasing the speed; and the memory footprint when the number of datasets is very large.; Accept '.' in user names.; Add switch to control caching of the files read on MacOsX. A call to; fcntl(fd, F_NOCACHE, 1) is done after opening the file.; Add export of the envs ROOTPROOFCLIENT and ROOTPROOFLITE when; appropriate. These allow to steer building and/or enabling of PAR files; in PROOF-INF/BUILD.sh and/or PROOF-INF/SETUP.C, improving transparency; between normal ROOT and PROOF. The example PAR; 'tutorials/proof/event.par' has been modified to check the two; variables.; Fix a few issues in SQL PROOF monitoring: in; TSQLMonitoringWriter::SendParameters, drop ''' around field names in; the INSERT string; also use TString::Format(...) instead of Form(...); where relevant.  In TPerfStats: call 'proofgroup' instead of; 'group' the field with the PROOF group (interference with the 'group'; keyword in SQL); add new field 'querytag' VARCHAR(64) with the unique; query tag; in WriteQueryLog fill also the field 'totevents'; in; PacketEvent, add switch to control whether to send te information to; the monitoring system on per packet level (may be too much for SQL).; The switch is called fMonitorPerPacket and it is globally controlled by; the rootrc variable 'Proof.MonitorPerPacket' and at session level with; the parameter PROOF_MonitorPerPacket .; Improve treatment of the case when temporary files are asked to be; created on a shared file system not containing the sandboxes. This; case, which seems to be a rather common one, should be now fully; supported.; Correctly honour selector abort status settings; TSelector::kAbortProcess and TSelect",MatchSource.DOCS,proof/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html:4218,Energy Efficiency,monitor,monitoring,4218,"lections), significantly increasing the speed; and the memory footprint when the number of datasets is very large.; Accept '.' in user names.; Add switch to control caching of the files read on MacOsX. A call to; fcntl(fd, F_NOCACHE, 1) is done after opening the file.; Add export of the envs ROOTPROOFCLIENT and ROOTPROOFLITE when; appropriate. These allow to steer building and/or enabling of PAR files; in PROOF-INF/BUILD.sh and/or PROOF-INF/SETUP.C, improving transparency; between normal ROOT and PROOF. The example PAR; 'tutorials/proof/event.par' has been modified to check the two; variables.; Fix a few issues in SQL PROOF monitoring: in; TSQLMonitoringWriter::SendParameters, drop ''' around field names in; the INSERT string; also use TString::Format(...) instead of Form(...); where relevant.  In TPerfStats: call 'proofgroup' instead of; 'group' the field with the PROOF group (interference with the 'group'; keyword in SQL); add new field 'querytag' VARCHAR(64) with the unique; query tag; in WriteQueryLog fill also the field 'totevents'; in; PacketEvent, add switch to control whether to send te information to; the monitoring system on per packet level (may be too much for SQL).; The switch is called fMonitorPerPacket and it is globally controlled by; the rootrc variable 'Proof.MonitorPerPacket' and at session level with; the parameter PROOF_MonitorPerPacket .; Improve treatment of the case when temporary files are asked to be; created on a shared file system not containing the sandboxes. This; case, which seems to be a rather common one, should be now fully; supported.; Correctly honour selector abort status settings; TSelector::kAbortProcess and TSelector::kAbortFile.; Improve reporting of the non-processed {files, events} in the final; 'MissingFiles' list.  ; Improved algorithm for TPacketizerUnit to fix issue with non; homogeneous machines.; Improve the way the information about log files is saved in case of; failures. The log paths for these failing now should b",MatchSource.DOCS,proof/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html:1533,Integrability,protocol,protocol,1533,"ely; in the sandbox, as 'mymacro.C'; so they should be included directly by; 'mymacro.C', e.g. '#include ""thisheader.h""' .; Import the dataset stager daemon 'afdsmgrd' into ROOT; this is used; to manage data staging based on the dataset information (see; http://code.google.com/p/afdsmgrd/ for more info). The daemon is; located under $ROOTSYS/proof/afdsmgrd .; New PROOF bench suite, a framework to run CPU and IO benchmarks with; default selectors/data or with user-provided ones. The code is located; under proof/proofbench.; Add the possibility to access the files on the workers via the same; port used by PROOF. This is useful for cases when it is not possible to; start a file server daemon on a different port (because, for eample, of; a firewall or just inconvenience) and workers do not share a file; system. Internally this works by forking a 'rootd' after identifying a; file request and trasferring the connection to it. The client side is a; TNetFile and it is triggered by the protocol ""rootd://"" (the just; implemented etc/plugins/TFile/P120_TNetFile.C includes this; protocol).; Add support for log file truncation. Truncation is disabled by; default. Enabling is controlled by the rootrc variable.           ; ProofServ.LogFileMaxSize  ; {<bytes>|<kilobytes>K|<megabytes>M|<gigabytes>G}.  indicating the max number of bytes. The number can be followed by; a {K,M,G} to indicate KBytes, MBytes or GBytes, respectively.; Add new derivation of TList (TProofOutputList) to be used on the; PROOF client to filter out PROOF internal objects when displaying or; printing the list. By default objects was names start with 'PROOF_' are; not shown. The presence of a non empty missing file list is; notified.; In the PROOF monitoring to: send additional information about memory; usage during the query, the name and size (# of files) of the dataset; processed (if any); add possibility to send the information to multiple; monitoring collectors.; Add support for block activation/deactivatio",MatchSource.DOCS,proof/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html:1625,Integrability,protocol,protocol,1625,"macro.C', e.g. '#include ""thisheader.h""' .; Import the dataset stager daemon 'afdsmgrd' into ROOT; this is used; to manage data staging based on the dataset information (see; http://code.google.com/p/afdsmgrd/ for more info). The daemon is; located under $ROOTSYS/proof/afdsmgrd .; New PROOF bench suite, a framework to run CPU and IO benchmarks with; default selectors/data or with user-provided ones. The code is located; under proof/proofbench.; Add the possibility to access the files on the workers via the same; port used by PROOF. This is useful for cases when it is not possible to; start a file server daemon on a different port (because, for eample, of; a firewall or just inconvenience) and workers do not share a file; system. Internally this works by forking a 'rootd' after identifying a; file request and trasferring the connection to it. The client side is a; TNetFile and it is triggered by the protocol ""rootd://"" (the just; implemented etc/plugins/TFile/P120_TNetFile.C includes this; protocol).; Add support for log file truncation. Truncation is disabled by; default. Enabling is controlled by the rootrc variable.           ; ProofServ.LogFileMaxSize  ; {<bytes>|<kilobytes>K|<megabytes>M|<gigabytes>G}.  indicating the max number of bytes. The number can be followed by; a {K,M,G} to indicate KBytes, MBytes or GBytes, respectively.; Add new derivation of TList (TProofOutputList) to be used on the; PROOF client to filter out PROOF internal objects when displaying or; printing the list. By default objects was names start with 'PROOF_' are; not shown. The presence of a non empty missing file list is; notified.; In the PROOF monitoring to: send additional information about memory; usage during the query, the name and size (# of files) of the dataset; processed (if any); add possibility to send the information to multiple; monitoring collectors.; Add support for block activation/deactivation of workers.; Add possibility to start the proofserv with 'system()' instead of;",MatchSource.DOCS,proof/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html:5399,Integrability,message,messages,5399,"ion level with; the parameter PROOF_MonitorPerPacket .; Improve treatment of the case when temporary files are asked to be; created on a shared file system not containing the sandboxes. This; case, which seems to be a rather common one, should be now fully; supported.; Correctly honour selector abort status settings; TSelector::kAbortProcess and TSelector::kAbortFile.; Improve reporting of the non-processed {files, events} in the final; 'MissingFiles' list.  ; Improved algorithm for TPacketizerUnit to fix issue with non; homogeneous machines.; Improve the way the information about log files is saved in case of; failures. The log paths for these failing now should be now correctly; saved and accessible via TProofLog.; Improve merging of histograms. Just use TH1::Add whne the axis are; equal; much faster than TH1::Merge. Fixes; ; In TDataSetManagerFile::NotifyUpdate fix handling of the case when; the global list file does not exist yet (new dataset directory). Fixes; error messages during editing dataset operations.; Fix issue with machine names consistency when working on a local; machine ('localhost' or 'localhost.localdomain' are mapped to; gSystem->HostName()); solves possible matching problems in the; packetizer.; In TProofServ, fill the ""grand total"" message with more blanks, so; that no remnants of the previous message are visible on the screen.; In the autoconf/bonjour interface, fix issue preventing the correct; port (the protocol one, which may be different from the application; default) being used when registering the service. . In TProofPlayer::AddQueryResult, fix a bug affecting the order in; whihc query results are registered when the start time is within 1; second.; Fix worker name in TSlaveLite.; Fix problem with enabling packages with option 'notOnClient' in; PROOF-Lite .; Make sure the log file is flushed at the end of startup to avoid; spurious log messages on next commands .; In CreateSession(), fix an issue with the validity check for existing; ses",MatchSource.DOCS,proof/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html:5688,Integrability,message,message,5688,"tatus settings; TSelector::kAbortProcess and TSelector::kAbortFile.; Improve reporting of the non-processed {files, events} in the final; 'MissingFiles' list.  ; Improved algorithm for TPacketizerUnit to fix issue with non; homogeneous machines.; Improve the way the information about log files is saved in case of; failures. The log paths for these failing now should be now correctly; saved and accessible via TProofLog.; Improve merging of histograms. Just use TH1::Add whne the axis are; equal; much faster than TH1::Merge. Fixes; ; In TDataSetManagerFile::NotifyUpdate fix handling of the case when; the global list file does not exist yet (new dataset directory). Fixes; error messages during editing dataset operations.; Fix issue with machine names consistency when working on a local; machine ('localhost' or 'localhost.localdomain' are mapped to; gSystem->HostName()); solves possible matching problems in the; packetizer.; In TProofServ, fill the ""grand total"" message with more blanks, so; that no remnants of the previous message are visible on the screen.; In the autoconf/bonjour interface, fix issue preventing the correct; port (the protocol one, which may be different from the application; default) being used when registering the service. . In TProofPlayer::AddQueryResult, fix a bug affecting the order in; whihc query results are registered when the start time is within 1; second.; Fix worker name in TSlaveLite.; Fix problem with enabling packages with option 'notOnClient' in; PROOF-Lite .; Make sure the log file is flushed at the end of startup to avoid; spurious log messages on next commands .; In CreateSession(), fix an issue with the validity check for existing; sessions .; In TProofLite: fix problem with passing the 'varexp' and 'selection'; strings for processing, preventing correct usage of the operators '|'; and '||' in TTreeFormula.; In the TProofOutputFile constructor, remove the 'localroot' prefix; only if present in the path. Fixes possible truncation pro",MatchSource.DOCS,proof/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html:5751,Integrability,message,message,5751,"tatus settings; TSelector::kAbortProcess and TSelector::kAbortFile.; Improve reporting of the non-processed {files, events} in the final; 'MissingFiles' list.  ; Improved algorithm for TPacketizerUnit to fix issue with non; homogeneous machines.; Improve the way the information about log files is saved in case of; failures. The log paths for these failing now should be now correctly; saved and accessible via TProofLog.; Improve merging of histograms. Just use TH1::Add whne the axis are; equal; much faster than TH1::Merge. Fixes; ; In TDataSetManagerFile::NotifyUpdate fix handling of the case when; the global list file does not exist yet (new dataset directory). Fixes; error messages during editing dataset operations.; Fix issue with machine names consistency when working on a local; machine ('localhost' or 'localhost.localdomain' are mapped to; gSystem->HostName()); solves possible matching problems in the; packetizer.; In TProofServ, fill the ""grand total"" message with more blanks, so; that no remnants of the previous message are visible on the screen.; In the autoconf/bonjour interface, fix issue preventing the correct; port (the protocol one, which may be different from the application; default) being used when registering the service. . In TProofPlayer::AddQueryResult, fix a bug affecting the order in; whihc query results are registered when the start time is within 1; second.; Fix worker name in TSlaveLite.; Fix problem with enabling packages with option 'notOnClient' in; PROOF-Lite .; Make sure the log file is flushed at the end of startup to avoid; spurious log messages on next commands .; In CreateSession(), fix an issue with the validity check for existing; sessions .; In TProofLite: fix problem with passing the 'varexp' and 'selection'; strings for processing, preventing correct usage of the operators '|'; and '||' in TTreeFormula.; In the TProofOutputFile constructor, remove the 'localroot' prefix; only if present in the path. Fixes possible truncation pro",MatchSource.DOCS,proof/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html:5811,Integrability,interface,interface,5811,"mproved algorithm for TPacketizerUnit to fix issue with non; homogeneous machines.; Improve the way the information about log files is saved in case of; failures. The log paths for these failing now should be now correctly; saved and accessible via TProofLog.; Improve merging of histograms. Just use TH1::Add whne the axis are; equal; much faster than TH1::Merge. Fixes; ; In TDataSetManagerFile::NotifyUpdate fix handling of the case when; the global list file does not exist yet (new dataset directory). Fixes; error messages during editing dataset operations.; Fix issue with machine names consistency when working on a local; machine ('localhost' or 'localhost.localdomain' are mapped to; gSystem->HostName()); solves possible matching problems in the; packetizer.; In TProofServ, fill the ""grand total"" message with more blanks, so; that no remnants of the previous message are visible on the screen.; In the autoconf/bonjour interface, fix issue preventing the correct; port (the protocol one, which may be different from the application; default) being used when registering the service. . In TProofPlayer::AddQueryResult, fix a bug affecting the order in; whihc query results are registered when the start time is within 1; second.; Fix worker name in TSlaveLite.; Fix problem with enabling packages with option 'notOnClient' in; PROOF-Lite .; Make sure the log file is flushed at the end of startup to avoid; spurious log messages on next commands .; In CreateSession(), fix an issue with the validity check for existing; sessions .; In TProofLite: fix problem with passing the 'varexp' and 'selection'; strings for processing, preventing correct usage of the operators '|'; and '||' in TTreeFormula.; In the TProofOutputFile constructor, remove the 'localroot' prefix; only if present in the path. Fixes possible truncation problems; occuring when the paths are not under the localroot scope.; In TXSocket and TXSlave: fix problem with the way collection over a; socket just marked as 'bad'",MatchSource.DOCS,proof/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html:5866,Integrability,protocol,protocol,5866,"mproved algorithm for TPacketizerUnit to fix issue with non; homogeneous machines.; Improve the way the information about log files is saved in case of; failures. The log paths for these failing now should be now correctly; saved and accessible via TProofLog.; Improve merging of histograms. Just use TH1::Add whne the axis are; equal; much faster than TH1::Merge. Fixes; ; In TDataSetManagerFile::NotifyUpdate fix handling of the case when; the global list file does not exist yet (new dataset directory). Fixes; error messages during editing dataset operations.; Fix issue with machine names consistency when working on a local; machine ('localhost' or 'localhost.localdomain' are mapped to; gSystem->HostName()); solves possible matching problems in the; packetizer.; In TProofServ, fill the ""grand total"" message with more blanks, so; that no remnants of the previous message are visible on the screen.; In the autoconf/bonjour interface, fix issue preventing the correct; port (the protocol one, which may be different from the application; default) being used when registering the service. . In TProofPlayer::AddQueryResult, fix a bug affecting the order in; whihc query results are registered when the start time is within 1; second.; Fix worker name in TSlaveLite.; Fix problem with enabling packages with option 'notOnClient' in; PROOF-Lite .; Make sure the log file is flushed at the end of startup to avoid; spurious log messages on next commands .; In CreateSession(), fix an issue with the validity check for existing; sessions .; In TProofLite: fix problem with passing the 'varexp' and 'selection'; strings for processing, preventing correct usage of the operators '|'; and '||' in TTreeFormula.; In the TProofOutputFile constructor, remove the 'localroot' prefix; only if present in the path. Fixes possible truncation problems; occuring when the paths are not under the localroot scope.; In TXSocket and TXSlave: fix problem with the way collection over a; socket just marked as 'bad'",MatchSource.DOCS,proof/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html:6311,Integrability,message,messages,6311,"pdate fix handling of the case when; the global list file does not exist yet (new dataset directory). Fixes; error messages during editing dataset operations.; Fix issue with machine names consistency when working on a local; machine ('localhost' or 'localhost.localdomain' are mapped to; gSystem->HostName()); solves possible matching problems in the; packetizer.; In TProofServ, fill the ""grand total"" message with more blanks, so; that no remnants of the previous message are visible on the screen.; In the autoconf/bonjour interface, fix issue preventing the correct; port (the protocol one, which may be different from the application; default) being used when registering the service. . In TProofPlayer::AddQueryResult, fix a bug affecting the order in; whihc query results are registered when the start time is within 1; second.; Fix worker name in TSlaveLite.; Fix problem with enabling packages with option 'notOnClient' in; PROOF-Lite .; Make sure the log file is flushed at the end of startup to avoid; spurious log messages on next commands .; In CreateSession(), fix an issue with the validity check for existing; sessions .; In TProofLite: fix problem with passing the 'varexp' and 'selection'; strings for processing, preventing correct usage of the operators '|'; and '||' in TTreeFormula.; In the TProofOutputFile constructor, remove the 'localroot' prefix; only if present in the path. Fixes possible truncation problems; occuring when the paths are not under the localroot scope.; In TXSocket and TXSlave: fix problem with the way collection over a; socket just marked as 'bad' was interrupted; the interrupt was de facto; ineffective, so that collection stayed always until the timeout expired; (default: 5 minutes). Should solve some of the cases were slow response; was experienced.; Fix a problem with log path transmission when the node dies early or; not even starts. The log path was empty and wrong was filled in when; retrieving the log buffers, disorienting debugging.; F",MatchSource.DOCS,proof/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html:441,Modifiability,sandbox,sandbox,441,". Proof. New functionality; ; In TProof::Load, add the possibility to define a list of files to be; sent because needed by the main macro file. The list is comma-separated; and the first file is considered as the main one. For example.        ; proof->Load(""<macropath>/mymacro.C+,<thispath>/thisheader.h,<thatpath>/thatheader.h""). will make sure that the files 'thisheader.h' and 'thatheader.h', needed; by 'mymacro.C' are available in the sandbox on the worker machines.; Note that 'thisheader.h' and 'thatheader.h' will be available remotely; in the sandbox, as 'mymacro.C'; so they should be included directly by; 'mymacro.C', e.g. '#include ""thisheader.h""' .; Import the dataset stager daemon 'afdsmgrd' into ROOT; this is used; to manage data staging based on the dataset information (see; http://code.google.com/p/afdsmgrd/ for more info). The daemon is; located under $ROOTSYS/proof/afdsmgrd .; New PROOF bench suite, a framework to run CPU and IO benchmarks with; default selectors/data or with user-provided ones. The code is located; under proof/proofbench.; Add the possibility to access the files on the workers via the same; port used by PROOF. This is useful for cases when it is not possible to; start a file server daemon on a different port (because, for eample, of; a firewall or just inconvenience) and workers do not share a file; system. Internally this works by forking a 'rootd' after identifying a; file request and trasferring the connection to it. The client side is a; TNetFile and it is triggered by the protocol ""rootd://"" (the just; implemented etc/plugins/TFile/P120_TNetFile.C includes this; protocol).; Add support for log file truncation. Truncation is disabled by; default. Enabling is controlled by the rootrc variable.           ; ProofServ.LogFileMaxSize  ; {<bytes>|<kilobytes>K|<megabytes>M|<gigabytes>G}.  indicating the max number of bytes. The number can be followed by; a {K,M,G} to indicate KBytes, MBytes or GBytes, respectively.; Add new derivation of T",MatchSource.DOCS,proof/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html:553,Modifiability,sandbox,sandbox,553,". Proof. New functionality; ; In TProof::Load, add the possibility to define a list of files to be; sent because needed by the main macro file. The list is comma-separated; and the first file is considered as the main one. For example.        ; proof->Load(""<macropath>/mymacro.C+,<thispath>/thisheader.h,<thatpath>/thatheader.h""). will make sure that the files 'thisheader.h' and 'thatheader.h', needed; by 'mymacro.C' are available in the sandbox on the worker machines.; Note that 'thisheader.h' and 'thatheader.h' will be available remotely; in the sandbox, as 'mymacro.C'; so they should be included directly by; 'mymacro.C', e.g. '#include ""thisheader.h""' .; Import the dataset stager daemon 'afdsmgrd' into ROOT; this is used; to manage data staging based on the dataset information (see; http://code.google.com/p/afdsmgrd/ for more info). The daemon is; located under $ROOTSYS/proof/afdsmgrd .; New PROOF bench suite, a framework to run CPU and IO benchmarks with; default selectors/data or with user-provided ones. The code is located; under proof/proofbench.; Add the possibility to access the files on the workers via the same; port used by PROOF. This is useful for cases when it is not possible to; start a file server daemon on a different port (because, for eample, of; a firewall or just inconvenience) and workers do not share a file; system. Internally this works by forking a 'rootd' after identifying a; file request and trasferring the connection to it. The client side is a; TNetFile and it is triggered by the protocol ""rootd://"" (the just; implemented etc/plugins/TFile/P120_TNetFile.C includes this; protocol).; Add support for log file truncation. Truncation is disabled by; default. Enabling is controlled by the rootrc variable.           ; ProofServ.LogFileMaxSize  ; {<bytes>|<kilobytes>K|<megabytes>M|<gigabytes>G}.  indicating the max number of bytes. The number can be followed by; a {K,M,G} to indicate KBytes, MBytes or GBytes, respectively.; Add new derivation of T",MatchSource.DOCS,proof/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html:1580,Modifiability,plugin,plugins,1580,"ely; in the sandbox, as 'mymacro.C'; so they should be included directly by; 'mymacro.C', e.g. '#include ""thisheader.h""' .; Import the dataset stager daemon 'afdsmgrd' into ROOT; this is used; to manage data staging based on the dataset information (see; http://code.google.com/p/afdsmgrd/ for more info). The daemon is; located under $ROOTSYS/proof/afdsmgrd .; New PROOF bench suite, a framework to run CPU and IO benchmarks with; default selectors/data or with user-provided ones. The code is located; under proof/proofbench.; Add the possibility to access the files on the workers via the same; port used by PROOF. This is useful for cases when it is not possible to; start a file server daemon on a different port (because, for eample, of; a firewall or just inconvenience) and workers do not share a file; system. Internally this works by forking a 'rootd' after identifying a; file request and trasferring the connection to it. The client side is a; TNetFile and it is triggered by the protocol ""rootd://"" (the just; implemented etc/plugins/TFile/P120_TNetFile.C includes this; protocol).; Add support for log file truncation. Truncation is disabled by; default. Enabling is controlled by the rootrc variable.           ; ProofServ.LogFileMaxSize  ; {<bytes>|<kilobytes>K|<megabytes>M|<gigabytes>G}.  indicating the max number of bytes. The number can be followed by; a {K,M,G} to indicate KBytes, MBytes or GBytes, respectively.; Add new derivation of TList (TProofOutputList) to be used on the; PROOF client to filter out PROOF internal objects when displaying or; printing the list. By default objects was names start with 'PROOF_' are; not shown. The presence of a non empty missing file list is; notified.; In the PROOF monitoring to: send additional information about memory; usage during the query, the name and size (# of files) of the dataset; processed (if any); add possibility to send the information to multiple; monitoring collectors.; Add support for block activation/deactivatio",MatchSource.DOCS,proof/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html:1747,Modifiability,variab,variable,1747,"; to manage data staging based on the dataset information (see; http://code.google.com/p/afdsmgrd/ for more info). The daemon is; located under $ROOTSYS/proof/afdsmgrd .; New PROOF bench suite, a framework to run CPU and IO benchmarks with; default selectors/data or with user-provided ones. The code is located; under proof/proofbench.; Add the possibility to access the files on the workers via the same; port used by PROOF. This is useful for cases when it is not possible to; start a file server daemon on a different port (because, for eample, of; a firewall or just inconvenience) and workers do not share a file; system. Internally this works by forking a 'rootd' after identifying a; file request and trasferring the connection to it. The client side is a; TNetFile and it is triggered by the protocol ""rootd://"" (the just; implemented etc/plugins/TFile/P120_TNetFile.C includes this; protocol).; Add support for log file truncation. Truncation is disabled by; default. Enabling is controlled by the rootrc variable.           ; ProofServ.LogFileMaxSize  ; {<bytes>|<kilobytes>K|<megabytes>M|<gigabytes>G}.  indicating the max number of bytes. The number can be followed by; a {K,M,G} to indicate KBytes, MBytes or GBytes, respectively.; Add new derivation of TList (TProofOutputList) to be used on the; PROOF client to filter out PROOF internal objects when displaying or; printing the list. By default objects was names start with 'PROOF_' are; not shown. The presence of a non empty missing file list is; notified.; In the PROOF monitoring to: send additional information about memory; usage during the query, the name and size (# of files) of the dataset; processed (if any); add possibility to send the information to multiple; monitoring collectors.; Add support for block activation/deactivation of workers.; Add possibility to start the proofserv with 'system()' instead of; 'fork()' as done in PROOF-Lite. A new switch 'usefrk' has been added to; 'xpd.proofservmgr' to control that. D",MatchSource.DOCS,proof/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html:3676,Modifiability,variab,variables,3676," switch 'usefrk' has been added to; 'xpd.proofservmgr' to control that. Default is still fork(). Improvements; ; In TProof::ClearPackages, use the manager to execute the command on; all known worker machines. Improves the consistency when re-istalling; packages. In TProof::GetDataSets, add support for option ':lite:'; this allows; to fill the map with only the summary information about the datasets; (the header of TFileCollections), significantly increasing the speed; and the memory footprint when the number of datasets is very large.; Accept '.' in user names.; Add switch to control caching of the files read on MacOsX. A call to; fcntl(fd, F_NOCACHE, 1) is done after opening the file.; Add export of the envs ROOTPROOFCLIENT and ROOTPROOFLITE when; appropriate. These allow to steer building and/or enabling of PAR files; in PROOF-INF/BUILD.sh and/or PROOF-INF/SETUP.C, improving transparency; between normal ROOT and PROOF. The example PAR; 'tutorials/proof/event.par' has been modified to check the two; variables.; Fix a few issues in SQL PROOF monitoring: in; TSQLMonitoringWriter::SendParameters, drop ''' around field names in; the INSERT string; also use TString::Format(...) instead of Form(...); where relevant.  In TPerfStats: call 'proofgroup' instead of; 'group' the field with the PROOF group (interference with the 'group'; keyword in SQL); add new field 'querytag' VARCHAR(64) with the unique; query tag; in WriteQueryLog fill also the field 'totevents'; in; PacketEvent, add switch to control whether to send te information to; the monitoring system on per packet level (may be too much for SQL).; The switch is called fMonitorPerPacket and it is globally controlled by; the rootrc variable 'Proof.MonitorPerPacket' and at session level with; the parameter PROOF_MonitorPerPacket .; Improve treatment of the case when temporary files are asked to be; created on a shared file system not containing the sandboxes. This; case, which seems to be a rather common one, should be n",MatchSource.DOCS,proof/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html:4368,Modifiability,variab,variable,4368,"ter opening the file.; Add export of the envs ROOTPROOFCLIENT and ROOTPROOFLITE when; appropriate. These allow to steer building and/or enabling of PAR files; in PROOF-INF/BUILD.sh and/or PROOF-INF/SETUP.C, improving transparency; between normal ROOT and PROOF. The example PAR; 'tutorials/proof/event.par' has been modified to check the two; variables.; Fix a few issues in SQL PROOF monitoring: in; TSQLMonitoringWriter::SendParameters, drop ''' around field names in; the INSERT string; also use TString::Format(...) instead of Form(...); where relevant.  In TPerfStats: call 'proofgroup' instead of; 'group' the field with the PROOF group (interference with the 'group'; keyword in SQL); add new field 'querytag' VARCHAR(64) with the unique; query tag; in WriteQueryLog fill also the field 'totevents'; in; PacketEvent, add switch to control whether to send te information to; the monitoring system on per packet level (may be too much for SQL).; The switch is called fMonitorPerPacket and it is globally controlled by; the rootrc variable 'Proof.MonitorPerPacket' and at session level with; the parameter PROOF_MonitorPerPacket .; Improve treatment of the case when temporary files are asked to be; created on a shared file system not containing the sandboxes. This; case, which seems to be a rather common one, should be now fully; supported.; Correctly honour selector abort status settings; TSelector::kAbortProcess and TSelector::kAbortFile.; Improve reporting of the non-processed {files, events} in the final; 'MissingFiles' list.  ; Improved algorithm for TPacketizerUnit to fix issue with non; homogeneous machines.; Improve the way the information about log files is saved in case of; failures. The log paths for these failing now should be now correctly; saved and accessible via TProofLog.; Improve merging of histograms. Just use TH1::Add whne the axis are; equal; much faster than TH1::Merge. Fixes; ; In TDataSetManagerFile::NotifyUpdate fix handling of the case when; the global l",MatchSource.DOCS,proof/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html:4588,Modifiability,sandbox,sandboxes,4588,"ETUP.C, improving transparency; between normal ROOT and PROOF. The example PAR; 'tutorials/proof/event.par' has been modified to check the two; variables.; Fix a few issues in SQL PROOF monitoring: in; TSQLMonitoringWriter::SendParameters, drop ''' around field names in; the INSERT string; also use TString::Format(...) instead of Form(...); where relevant.  In TPerfStats: call 'proofgroup' instead of; 'group' the field with the PROOF group (interference with the 'group'; keyword in SQL); add new field 'querytag' VARCHAR(64) with the unique; query tag; in WriteQueryLog fill also the field 'totevents'; in; PacketEvent, add switch to control whether to send te information to; the monitoring system on per packet level (may be too much for SQL).; The switch is called fMonitorPerPacket and it is globally controlled by; the rootrc variable 'Proof.MonitorPerPacket' and at session level with; the parameter PROOF_MonitorPerPacket .; Improve treatment of the case when temporary files are asked to be; created on a shared file system not containing the sandboxes. This; case, which seems to be a rather common one, should be now fully; supported.; Correctly honour selector abort status settings; TSelector::kAbortProcess and TSelector::kAbortFile.; Improve reporting of the non-processed {files, events} in the final; 'MissingFiles' list.  ; Improved algorithm for TPacketizerUnit to fix issue with non; homogeneous machines.; Improve the way the information about log files is saved in case of; failures. The log paths for these failing now should be now correctly; saved and accessible via TProofLog.; Improve merging of histograms. Just use TH1::Add whne the axis are; equal; much faster than TH1::Merge. Fixes; ; In TDataSetManagerFile::NotifyUpdate fix handling of the case when; the global list file does not exist yet (new dataset directory). Fixes; error messages during editing dataset operations.; Fix issue with machine names consistency when working on a local; machine ('localhost' or",MatchSource.DOCS,proof/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html:4709,Safety,abort,abort,4709,"; TSQLMonitoringWriter::SendParameters, drop ''' around field names in; the INSERT string; also use TString::Format(...) instead of Form(...); where relevant.  In TPerfStats: call 'proofgroup' instead of; 'group' the field with the PROOF group (interference with the 'group'; keyword in SQL); add new field 'querytag' VARCHAR(64) with the unique; query tag; in WriteQueryLog fill also the field 'totevents'; in; PacketEvent, add switch to control whether to send te information to; the monitoring system on per packet level (may be too much for SQL).; The switch is called fMonitorPerPacket and it is globally controlled by; the rootrc variable 'Proof.MonitorPerPacket' and at session level with; the parameter PROOF_MonitorPerPacket .; Improve treatment of the case when temporary files are asked to be; created on a shared file system not containing the sandboxes. This; case, which seems to be a rather common one, should be now fully; supported.; Correctly honour selector abort status settings; TSelector::kAbortProcess and TSelector::kAbortFile.; Improve reporting of the non-processed {files, events} in the final; 'MissingFiles' list.  ; Improved algorithm for TPacketizerUnit to fix issue with non; homogeneous machines.; Improve the way the information about log files is saved in case of; failures. The log paths for these failing now should be now correctly; saved and accessible via TProofLog.; Improve merging of histograms. Just use TH1::Add whne the axis are; equal; much faster than TH1::Merge. Fixes; ; In TDataSetManagerFile::NotifyUpdate fix handling of the case when; the global list file does not exist yet (new dataset directory). Fixes; error messages during editing dataset operations.; Fix issue with machine names consistency when working on a local; machine ('localhost' or 'localhost.localdomain' are mapped to; gSystem->HostName()); solves possible matching problems in the; packetizer.; In TProofServ, fill the ""grand total"" message with more blanks, so; that no remnan",MatchSource.DOCS,proof/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html:6291,Safety,avoid,avoid,6291,"pdate fix handling of the case when; the global list file does not exist yet (new dataset directory). Fixes; error messages during editing dataset operations.; Fix issue with machine names consistency when working on a local; machine ('localhost' or 'localhost.localdomain' are mapped to; gSystem->HostName()); solves possible matching problems in the; packetizer.; In TProofServ, fill the ""grand total"" message with more blanks, so; that no remnants of the previous message are visible on the screen.; In the autoconf/bonjour interface, fix issue preventing the correct; port (the protocol one, which may be different from the application; default) being used when registering the service. . In TProofPlayer::AddQueryResult, fix a bug affecting the order in; whihc query results are registered when the start time is within 1; second.; Fix worker name in TSlaveLite.; Fix problem with enabling packages with option 'notOnClient' in; PROOF-Lite .; Make sure the log file is flushed at the end of startup to avoid; spurious log messages on next commands .; In CreateSession(), fix an issue with the validity check for existing; sessions .; In TProofLite: fix problem with passing the 'varexp' and 'selection'; strings for processing, preventing correct usage of the operators '|'; and '||' in TTreeFormula.; In the TProofOutputFile constructor, remove the 'localroot' prefix; only if present in the path. Fixes possible truncation problems; occuring when the paths are not under the localroot scope.; In TXSocket and TXSlave: fix problem with the way collection over a; socket just marked as 'bad' was interrupted; the interrupt was de facto; ineffective, so that collection stayed always until the timeout expired; (default: 5 minutes). Should solve some of the cases were slow response; was experienced.; Fix a problem with log path transmission when the node dies early or; not even starts. The log path was empty and wrong was filled in when; retrieving the log buffers, disorienting debugging.; F",MatchSource.DOCS,proof/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html:6982,Safety,timeout,timeout,6982,"t from the application; default) being used when registering the service. . In TProofPlayer::AddQueryResult, fix a bug affecting the order in; whihc query results are registered when the start time is within 1; second.; Fix worker name in TSlaveLite.; Fix problem with enabling packages with option 'notOnClient' in; PROOF-Lite .; Make sure the log file is flushed at the end of startup to avoid; spurious log messages on next commands .; In CreateSession(), fix an issue with the validity check for existing; sessions .; In TProofLite: fix problem with passing the 'varexp' and 'selection'; strings for processing, preventing correct usage of the operators '|'; and '||' in TTreeFormula.; In the TProofOutputFile constructor, remove the 'localroot' prefix; only if present in the path. Fixes possible truncation problems; occuring when the paths are not under the localroot scope.; In TXSocket and TXSlave: fix problem with the way collection over a; socket just marked as 'bad' was interrupted; the interrupt was de facto; ineffective, so that collection stayed always until the timeout expired; (default: 5 minutes). Should solve some of the cases were slow response; was experienced.; Fix a problem with log path transmission when the node dies early or; not even starts. The log path was empty and wrong was filled in when; retrieving the log buffers, disorienting debugging.; Fix a bug checking the first event which rendered ineffective the; request for processing a subset of events in a given dataset or; chain.; In pq2-ana-dist, fix problem with the labels of the distribution; histo occuring when machines are represented by IPs instead of; names.; Add missing calls to closedir() and TSystem::FreeDirectory, cuasing a; large number of filedescriptors remaining opened after xproofd; initialization.; Fix a problem with the final update of the progress information; affecting occasionally cases with skipped events.; Fix merging of TproofOutputFile when using submergers (the; intermediate",MatchSource.DOCS,proof/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html:1093,Security,access,access,1093,"needed by the main macro file. The list is comma-separated; and the first file is considered as the main one. For example.        ; proof->Load(""<macropath>/mymacro.C+,<thispath>/thisheader.h,<thatpath>/thatheader.h""). will make sure that the files 'thisheader.h' and 'thatheader.h', needed; by 'mymacro.C' are available in the sandbox on the worker machines.; Note that 'thisheader.h' and 'thatheader.h' will be available remotely; in the sandbox, as 'mymacro.C'; so they should be included directly by; 'mymacro.C', e.g. '#include ""thisheader.h""' .; Import the dataset stager daemon 'afdsmgrd' into ROOT; this is used; to manage data staging based on the dataset information (see; http://code.google.com/p/afdsmgrd/ for more info). The daemon is; located under $ROOTSYS/proof/afdsmgrd .; New PROOF bench suite, a framework to run CPU and IO benchmarks with; default selectors/data or with user-provided ones. The code is located; under proof/proofbench.; Add the possibility to access the files on the workers via the same; port used by PROOF. This is useful for cases when it is not possible to; start a file server daemon on a different port (because, for eample, of; a firewall or just inconvenience) and workers do not share a file; system. Internally this works by forking a 'rootd' after identifying a; file request and trasferring the connection to it. The client side is a; TNetFile and it is triggered by the protocol ""rootd://"" (the just; implemented etc/plugins/TFile/P120_TNetFile.C includes this; protocol).; Add support for log file truncation. Truncation is disabled by; default. Enabling is controlled by the rootrc variable.           ; ProofServ.LogFileMaxSize  ; {<bytes>|<kilobytes>K|<megabytes>M|<gigabytes>G}.  indicating the max number of bytes. The number can be followed by; a {K,M,G} to indicate KBytes, MBytes or GBytes, respectively.; Add new derivation of TList (TProofOutputList) to be used on the; PROOF client to filter out PROOF internal objects when displaying or;",MatchSource.DOCS,proof/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html:1287,Security,firewall,firewall,1287,"<macropath>/mymacro.C+,<thispath>/thisheader.h,<thatpath>/thatheader.h""). will make sure that the files 'thisheader.h' and 'thatheader.h', needed; by 'mymacro.C' are available in the sandbox on the worker machines.; Note that 'thisheader.h' and 'thatheader.h' will be available remotely; in the sandbox, as 'mymacro.C'; so they should be included directly by; 'mymacro.C', e.g. '#include ""thisheader.h""' .; Import the dataset stager daemon 'afdsmgrd' into ROOT; this is used; to manage data staging based on the dataset information (see; http://code.google.com/p/afdsmgrd/ for more info). The daemon is; located under $ROOTSYS/proof/afdsmgrd .; New PROOF bench suite, a framework to run CPU and IO benchmarks with; default selectors/data or with user-provided ones. The code is located; under proof/proofbench.; Add the possibility to access the files on the workers via the same; port used by PROOF. This is useful for cases when it is not possible to; start a file server daemon on a different port (because, for eample, of; a firewall or just inconvenience) and workers do not share a file; system. Internally this works by forking a 'rootd' after identifying a; file request and trasferring the connection to it. The client side is a; TNetFile and it is triggered by the protocol ""rootd://"" (the just; implemented etc/plugins/TFile/P120_TNetFile.C includes this; protocol).; Add support for log file truncation. Truncation is disabled by; default. Enabling is controlled by the rootrc variable.           ; ProofServ.LogFileMaxSize  ; {<bytes>|<kilobytes>K|<megabytes>M|<gigabytes>G}.  indicating the max number of bytes. The number can be followed by; a {K,M,G} to indicate KBytes, MBytes or GBytes, respectively.; Add new derivation of TList (TProofOutputList) to be used on the; PROOF client to filter out PROOF internal objects when displaying or; printing the list. By default objects was names start with 'PROOF_' are; not shown. The presence of a non empty missing file list is; notified.; ",MatchSource.DOCS,proof/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html:5113,Security,access,accessible,5113," in WriteQueryLog fill also the field 'totevents'; in; PacketEvent, add switch to control whether to send te information to; the monitoring system on per packet level (may be too much for SQL).; The switch is called fMonitorPerPacket and it is globally controlled by; the rootrc variable 'Proof.MonitorPerPacket' and at session level with; the parameter PROOF_MonitorPerPacket .; Improve treatment of the case when temporary files are asked to be; created on a shared file system not containing the sandboxes. This; case, which seems to be a rather common one, should be now fully; supported.; Correctly honour selector abort status settings; TSelector::kAbortProcess and TSelector::kAbortFile.; Improve reporting of the non-processed {files, events} in the final; 'MissingFiles' list.  ; Improved algorithm for TPacketizerUnit to fix issue with non; homogeneous machines.; Improve the way the information about log files is saved in case of; failures. The log paths for these failing now should be now correctly; saved and accessible via TProofLog.; Improve merging of histograms. Just use TH1::Add whne the axis are; equal; much faster than TH1::Merge. Fixes; ; In TDataSetManagerFile::NotifyUpdate fix handling of the case when; the global list file does not exist yet (new dataset directory). Fixes; error messages during editing dataset operations.; Fix issue with machine names consistency when working on a local; machine ('localhost' or 'localhost.localdomain' are mapped to; gSystem->HostName()); solves possible matching problems in the; packetizer.; In TProofServ, fill the ""grand total"" message with more blanks, so; that no remnants of the previous message are visible on the screen.; In the autoconf/bonjour interface, fix issue preventing the correct; port (the protocol one, which may be different from the application; default) being used when registering the service. . In TProofPlayer::AddQueryResult, fix a bug affecting the order in; whihc query results are registered when the st",MatchSource.DOCS,proof/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html:441,Testability,sandbox,sandbox,441,". Proof. New functionality; ; In TProof::Load, add the possibility to define a list of files to be; sent because needed by the main macro file. The list is comma-separated; and the first file is considered as the main one. For example.        ; proof->Load(""<macropath>/mymacro.C+,<thispath>/thisheader.h,<thatpath>/thatheader.h""). will make sure that the files 'thisheader.h' and 'thatheader.h', needed; by 'mymacro.C' are available in the sandbox on the worker machines.; Note that 'thisheader.h' and 'thatheader.h' will be available remotely; in the sandbox, as 'mymacro.C'; so they should be included directly by; 'mymacro.C', e.g. '#include ""thisheader.h""' .; Import the dataset stager daemon 'afdsmgrd' into ROOT; this is used; to manage data staging based on the dataset information (see; http://code.google.com/p/afdsmgrd/ for more info). The daemon is; located under $ROOTSYS/proof/afdsmgrd .; New PROOF bench suite, a framework to run CPU and IO benchmarks with; default selectors/data or with user-provided ones. The code is located; under proof/proofbench.; Add the possibility to access the files on the workers via the same; port used by PROOF. This is useful for cases when it is not possible to; start a file server daemon on a different port (because, for eample, of; a firewall or just inconvenience) and workers do not share a file; system. Internally this works by forking a 'rootd' after identifying a; file request and trasferring the connection to it. The client side is a; TNetFile and it is triggered by the protocol ""rootd://"" (the just; implemented etc/plugins/TFile/P120_TNetFile.C includes this; protocol).; Add support for log file truncation. Truncation is disabled by; default. Enabling is controlled by the rootrc variable.           ; ProofServ.LogFileMaxSize  ; {<bytes>|<kilobytes>K|<megabytes>M|<gigabytes>G}.  indicating the max number of bytes. The number can be followed by; a {K,M,G} to indicate KBytes, MBytes or GBytes, respectively.; Add new derivation of T",MatchSource.DOCS,proof/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html:553,Testability,sandbox,sandbox,553,". Proof. New functionality; ; In TProof::Load, add the possibility to define a list of files to be; sent because needed by the main macro file. The list is comma-separated; and the first file is considered as the main one. For example.        ; proof->Load(""<macropath>/mymacro.C+,<thispath>/thisheader.h,<thatpath>/thatheader.h""). will make sure that the files 'thisheader.h' and 'thatheader.h', needed; by 'mymacro.C' are available in the sandbox on the worker machines.; Note that 'thisheader.h' and 'thatheader.h' will be available remotely; in the sandbox, as 'mymacro.C'; so they should be included directly by; 'mymacro.C', e.g. '#include ""thisheader.h""' .; Import the dataset stager daemon 'afdsmgrd' into ROOT; this is used; to manage data staging based on the dataset information (see; http://code.google.com/p/afdsmgrd/ for more info). The daemon is; located under $ROOTSYS/proof/afdsmgrd .; New PROOF bench suite, a framework to run CPU and IO benchmarks with; default selectors/data or with user-provided ones. The code is located; under proof/proofbench.; Add the possibility to access the files on the workers via the same; port used by PROOF. This is useful for cases when it is not possible to; start a file server daemon on a different port (because, for eample, of; a firewall or just inconvenience) and workers do not share a file; system. Internally this works by forking a 'rootd' after identifying a; file request and trasferring the connection to it. The client side is a; TNetFile and it is triggered by the protocol ""rootd://"" (the just; implemented etc/plugins/TFile/P120_TNetFile.C includes this; protocol).; Add support for log file truncation. Truncation is disabled by; default. Enabling is controlled by the rootrc variable.           ; ProofServ.LogFileMaxSize  ; {<bytes>|<kilobytes>K|<megabytes>M|<gigabytes>G}.  indicating the max number of bytes. The number can be followed by; a {K,M,G} to indicate KBytes, MBytes or GBytes, respectively.; Add new derivation of T",MatchSource.DOCS,proof/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html:956,Testability,benchmark,benchmarks,956,". Proof. New functionality; ; In TProof::Load, add the possibility to define a list of files to be; sent because needed by the main macro file. The list is comma-separated; and the first file is considered as the main one. For example.        ; proof->Load(""<macropath>/mymacro.C+,<thispath>/thisheader.h,<thatpath>/thatheader.h""). will make sure that the files 'thisheader.h' and 'thatheader.h', needed; by 'mymacro.C' are available in the sandbox on the worker machines.; Note that 'thisheader.h' and 'thatheader.h' will be available remotely; in the sandbox, as 'mymacro.C'; so they should be included directly by; 'mymacro.C', e.g. '#include ""thisheader.h""' .; Import the dataset stager daemon 'afdsmgrd' into ROOT; this is used; to manage data staging based on the dataset information (see; http://code.google.com/p/afdsmgrd/ for more info). The daemon is; located under $ROOTSYS/proof/afdsmgrd .; New PROOF bench suite, a framework to run CPU and IO benchmarks with; default selectors/data or with user-provided ones. The code is located; under proof/proofbench.; Add the possibility to access the files on the workers via the same; port used by PROOF. This is useful for cases when it is not possible to; start a file server daemon on a different port (because, for eample, of; a firewall or just inconvenience) and workers do not share a file; system. Internally this works by forking a 'rootd' after identifying a; file request and trasferring the connection to it. The client side is a; TNetFile and it is triggered by the protocol ""rootd://"" (the just; implemented etc/plugins/TFile/P120_TNetFile.C includes this; protocol).; Add support for log file truncation. Truncation is disabled by; default. Enabling is controlled by the rootrc variable.           ; ProofServ.LogFileMaxSize  ; {<bytes>|<kilobytes>K|<megabytes>M|<gigabytes>G}.  indicating the max number of bytes. The number can be followed by; a {K,M,G} to indicate KBytes, MBytes or GBytes, respectively.; Add new derivation of T",MatchSource.DOCS,proof/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html:1653,Testability,log,log,1653,"der.h""' .; Import the dataset stager daemon 'afdsmgrd' into ROOT; this is used; to manage data staging based on the dataset information (see; http://code.google.com/p/afdsmgrd/ for more info). The daemon is; located under $ROOTSYS/proof/afdsmgrd .; New PROOF bench suite, a framework to run CPU and IO benchmarks with; default selectors/data or with user-provided ones. The code is located; under proof/proofbench.; Add the possibility to access the files on the workers via the same; port used by PROOF. This is useful for cases when it is not possible to; start a file server daemon on a different port (because, for eample, of; a firewall or just inconvenience) and workers do not share a file; system. Internally this works by forking a 'rootd' after identifying a; file request and trasferring the connection to it. The client side is a; TNetFile and it is triggered by the protocol ""rootd://"" (the just; implemented etc/plugins/TFile/P120_TNetFile.C includes this; protocol).; Add support for log file truncation. Truncation is disabled by; default. Enabling is controlled by the rootrc variable.           ; ProofServ.LogFileMaxSize  ; {<bytes>|<kilobytes>K|<megabytes>M|<gigabytes>G}.  indicating the max number of bytes. The number can be followed by; a {K,M,G} to indicate KBytes, MBytes or GBytes, respectively.; Add new derivation of TList (TProofOutputList) to be used on the; PROOF client to filter out PROOF internal objects when displaying or; printing the list. By default objects was names start with 'PROOF_' are; not shown. The presence of a non empty missing file list is; notified.; In the PROOF monitoring to: send additional information about memory; usage during the query, the name and size (# of files) of the dataset; processed (if any); add possibility to send the information to multiple; monitoring collectors.; Add support for block activation/deactivation of workers.; Add possibility to start the proofserv with 'system()' instead of; 'fork()' as done in PROOF-Lite.",MatchSource.DOCS,proof/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html:4588,Testability,sandbox,sandboxes,4588,"ETUP.C, improving transparency; between normal ROOT and PROOF. The example PAR; 'tutorials/proof/event.par' has been modified to check the two; variables.; Fix a few issues in SQL PROOF monitoring: in; TSQLMonitoringWriter::SendParameters, drop ''' around field names in; the INSERT string; also use TString::Format(...) instead of Form(...); where relevant.  In TPerfStats: call 'proofgroup' instead of; 'group' the field with the PROOF group (interference with the 'group'; keyword in SQL); add new field 'querytag' VARCHAR(64) with the unique; query tag; in WriteQueryLog fill also the field 'totevents'; in; PacketEvent, add switch to control whether to send te information to; the monitoring system on per packet level (may be too much for SQL).; The switch is called fMonitorPerPacket and it is globally controlled by; the rootrc variable 'Proof.MonitorPerPacket' and at session level with; the parameter PROOF_MonitorPerPacket .; Improve treatment of the case when temporary files are asked to be; created on a shared file system not containing the sandboxes. This; case, which seems to be a rather common one, should be now fully; supported.; Correctly honour selector abort status settings; TSelector::kAbortProcess and TSelector::kAbortFile.; Improve reporting of the non-processed {files, events} in the final; 'MissingFiles' list.  ; Improved algorithm for TPacketizerUnit to fix issue with non; homogeneous machines.; Improve the way the information about log files is saved in case of; failures. The log paths for these failing now should be now correctly; saved and accessible via TProofLog.; Improve merging of histograms. Just use TH1::Add whne the axis are; equal; much faster than TH1::Merge. Fixes; ; In TDataSetManagerFile::NotifyUpdate fix handling of the case when; the global list file does not exist yet (new dataset directory). Fixes; error messages during editing dataset operations.; Fix issue with machine names consistency when working on a local; machine ('localhost' or",MatchSource.DOCS,proof/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html:5001,Testability,log,log,5001,"roup'; keyword in SQL); add new field 'querytag' VARCHAR(64) with the unique; query tag; in WriteQueryLog fill also the field 'totevents'; in; PacketEvent, add switch to control whether to send te information to; the monitoring system on per packet level (may be too much for SQL).; The switch is called fMonitorPerPacket and it is globally controlled by; the rootrc variable 'Proof.MonitorPerPacket' and at session level with; the parameter PROOF_MonitorPerPacket .; Improve treatment of the case when temporary files are asked to be; created on a shared file system not containing the sandboxes. This; case, which seems to be a rather common one, should be now fully; supported.; Correctly honour selector abort status settings; TSelector::kAbortProcess and TSelector::kAbortFile.; Improve reporting of the non-processed {files, events} in the final; 'MissingFiles' list.  ; Improved algorithm for TPacketizerUnit to fix issue with non; homogeneous machines.; Improve the way the information about log files is saved in case of; failures. The log paths for these failing now should be now correctly; saved and accessible via TProofLog.; Improve merging of histograms. Just use TH1::Add whne the axis are; equal; much faster than TH1::Merge. Fixes; ; In TDataSetManagerFile::NotifyUpdate fix handling of the case when; the global list file does not exist yet (new dataset directory). Fixes; error messages during editing dataset operations.; Fix issue with machine names consistency when working on a local; machine ('localhost' or 'localhost.localdomain' are mapped to; gSystem->HostName()); solves possible matching problems in the; packetizer.; In TProofServ, fill the ""grand total"" message with more blanks, so; that no remnants of the previous message are visible on the screen.; In the autoconf/bonjour interface, fix issue preventing the correct; port (the protocol one, which may be different from the application; default) being used when registering the service. . In TProofPlayer::AddQuer",MatchSource.DOCS,proof/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html:5046,Testability,log,log,5046," in WriteQueryLog fill also the field 'totevents'; in; PacketEvent, add switch to control whether to send te information to; the monitoring system on per packet level (may be too much for SQL).; The switch is called fMonitorPerPacket and it is globally controlled by; the rootrc variable 'Proof.MonitorPerPacket' and at session level with; the parameter PROOF_MonitorPerPacket .; Improve treatment of the case when temporary files are asked to be; created on a shared file system not containing the sandboxes. This; case, which seems to be a rather common one, should be now fully; supported.; Correctly honour selector abort status settings; TSelector::kAbortProcess and TSelector::kAbortFile.; Improve reporting of the non-processed {files, events} in the final; 'MissingFiles' list.  ; Improved algorithm for TPacketizerUnit to fix issue with non; homogeneous machines.; Improve the way the information about log files is saved in case of; failures. The log paths for these failing now should be now correctly; saved and accessible via TProofLog.; Improve merging of histograms. Just use TH1::Add whne the axis are; equal; much faster than TH1::Merge. Fixes; ; In TDataSetManagerFile::NotifyUpdate fix handling of the case when; the global list file does not exist yet (new dataset directory). Fixes; error messages during editing dataset operations.; Fix issue with machine names consistency when working on a local; machine ('localhost' or 'localhost.localdomain' are mapped to; gSystem->HostName()); solves possible matching problems in the; packetizer.; In TProofServ, fill the ""grand total"" message with more blanks, so; that no remnants of the previous message are visible on the screen.; In the autoconf/bonjour interface, fix issue preventing the correct; port (the protocol one, which may be different from the application; default) being used when registering the service. . In TProofPlayer::AddQueryResult, fix a bug affecting the order in; whihc query results are registered when the st",MatchSource.DOCS,proof/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html:6246,Testability,log,log,6246,"pdate fix handling of the case when; the global list file does not exist yet (new dataset directory). Fixes; error messages during editing dataset operations.; Fix issue with machine names consistency when working on a local; machine ('localhost' or 'localhost.localdomain' are mapped to; gSystem->HostName()); solves possible matching problems in the; packetizer.; In TProofServ, fill the ""grand total"" message with more blanks, so; that no remnants of the previous message are visible on the screen.; In the autoconf/bonjour interface, fix issue preventing the correct; port (the protocol one, which may be different from the application; default) being used when registering the service. . In TProofPlayer::AddQueryResult, fix a bug affecting the order in; whihc query results are registered when the start time is within 1; second.; Fix worker name in TSlaveLite.; Fix problem with enabling packages with option 'notOnClient' in; PROOF-Lite .; Make sure the log file is flushed at the end of startup to avoid; spurious log messages on next commands .; In CreateSession(), fix an issue with the validity check for existing; sessions .; In TProofLite: fix problem with passing the 'varexp' and 'selection'; strings for processing, preventing correct usage of the operators '|'; and '||' in TTreeFormula.; In the TProofOutputFile constructor, remove the 'localroot' prefix; only if present in the path. Fixes possible truncation problems; occuring when the paths are not under the localroot scope.; In TXSocket and TXSlave: fix problem with the way collection over a; socket just marked as 'bad' was interrupted; the interrupt was de facto; ineffective, so that collection stayed always until the timeout expired; (default: 5 minutes). Should solve some of the cases were slow response; was experienced.; Fix a problem with log path transmission when the node dies early or; not even starts. The log path was empty and wrong was filled in when; retrieving the log buffers, disorienting debugging.; F",MatchSource.DOCS,proof/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html:6307,Testability,log,log,6307,"pdate fix handling of the case when; the global list file does not exist yet (new dataset directory). Fixes; error messages during editing dataset operations.; Fix issue with machine names consistency when working on a local; machine ('localhost' or 'localhost.localdomain' are mapped to; gSystem->HostName()); solves possible matching problems in the; packetizer.; In TProofServ, fill the ""grand total"" message with more blanks, so; that no remnants of the previous message are visible on the screen.; In the autoconf/bonjour interface, fix issue preventing the correct; port (the protocol one, which may be different from the application; default) being used when registering the service. . In TProofPlayer::AddQueryResult, fix a bug affecting the order in; whihc query results are registered when the start time is within 1; second.; Fix worker name in TSlaveLite.; Fix problem with enabling packages with option 'notOnClient' in; PROOF-Lite .; Make sure the log file is flushed at the end of startup to avoid; spurious log messages on next commands .; In CreateSession(), fix an issue with the validity check for existing; sessions .; In TProofLite: fix problem with passing the 'varexp' and 'selection'; strings for processing, preventing correct usage of the operators '|'; and '||' in TTreeFormula.; In the TProofOutputFile constructor, remove the 'localroot' prefix; only if present in the path. Fixes possible truncation problems; occuring when the paths are not under the localroot scope.; In TXSocket and TXSlave: fix problem with the way collection over a; socket just marked as 'bad' was interrupted; the interrupt was de facto; ineffective, so that collection stayed always until the timeout expired; (default: 5 minutes). Should solve some of the cases were slow response; was experienced.; Fix a problem with log path transmission when the node dies early or; not even starts. The log path was empty and wrong was filled in when; retrieving the log buffers, disorienting debugging.; F",MatchSource.DOCS,proof/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html:7109,Testability,log,log,7109," when the start time is within 1; second.; Fix worker name in TSlaveLite.; Fix problem with enabling packages with option 'notOnClient' in; PROOF-Lite .; Make sure the log file is flushed at the end of startup to avoid; spurious log messages on next commands .; In CreateSession(), fix an issue with the validity check for existing; sessions .; In TProofLite: fix problem with passing the 'varexp' and 'selection'; strings for processing, preventing correct usage of the operators '|'; and '||' in TTreeFormula.; In the TProofOutputFile constructor, remove the 'localroot' prefix; only if present in the path. Fixes possible truncation problems; occuring when the paths are not under the localroot scope.; In TXSocket and TXSlave: fix problem with the way collection over a; socket just marked as 'bad' was interrupted; the interrupt was de facto; ineffective, so that collection stayed always until the timeout expired; (default: 5 minutes). Should solve some of the cases were slow response; was experienced.; Fix a problem with log path transmission when the node dies early or; not even starts. The log path was empty and wrong was filled in when; retrieving the log buffers, disorienting debugging.; Fix a bug checking the first event which rendered ineffective the; request for processing a subset of events in a given dataset or; chain.; In pq2-ana-dist, fix problem with the labels of the distribution; histo occuring when machines are represented by IPs instead of; names.; Add missing calls to closedir() and TSystem::FreeDirectory, cuasing a; large number of filedescriptors remaining opened after xproofd; initialization.; Fix a problem with the final update of the progress information; affecting occasionally cases with skipped events.; Fix merging of TproofOutputFile when using submergers (the; intermediate files were not correctly handled).; Fix the way TChain weights are transmitted to TProofDraw in; DrawSelect operations. AoB; ; The class TFileMerger has been moved to 'io/io'. ",MatchSource.DOCS,proof/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html:7181,Testability,log,log,7181," when the start time is within 1; second.; Fix worker name in TSlaveLite.; Fix problem with enabling packages with option 'notOnClient' in; PROOF-Lite .; Make sure the log file is flushed at the end of startup to avoid; spurious log messages on next commands .; In CreateSession(), fix an issue with the validity check for existing; sessions .; In TProofLite: fix problem with passing the 'varexp' and 'selection'; strings for processing, preventing correct usage of the operators '|'; and '||' in TTreeFormula.; In the TProofOutputFile constructor, remove the 'localroot' prefix; only if present in the path. Fixes possible truncation problems; occuring when the paths are not under the localroot scope.; In TXSocket and TXSlave: fix problem with the way collection over a; socket just marked as 'bad' was interrupted; the interrupt was de facto; ineffective, so that collection stayed always until the timeout expired; (default: 5 minutes). Should solve some of the cases were slow response; was experienced.; Fix a problem with log path transmission when the node dies early or; not even starts. The log path was empty and wrong was filled in when; retrieving the log buffers, disorienting debugging.; Fix a bug checking the first event which rendered ineffective the; request for processing a subset of events in a given dataset or; chain.; In pq2-ana-dist, fix problem with the labels of the distribution; histo occuring when machines are represented by IPs instead of; names.; Add missing calls to closedir() and TSystem::FreeDirectory, cuasing a; large number of filedescriptors remaining opened after xproofd; initialization.; Fix a problem with the final update of the progress information; affecting occasionally cases with skipped events.; Fix merging of TproofOutputFile when using submergers (the; intermediate files were not correctly handled).; Fix the way TChain weights are transmitted to TProofDraw in; DrawSelect operations. AoB; ; The class TFileMerger has been moved to 'io/io'. ",MatchSource.DOCS,proof/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html:7245,Testability,log,log,7245," when the start time is within 1; second.; Fix worker name in TSlaveLite.; Fix problem with enabling packages with option 'notOnClient' in; PROOF-Lite .; Make sure the log file is flushed at the end of startup to avoid; spurious log messages on next commands .; In CreateSession(), fix an issue with the validity check for existing; sessions .; In TProofLite: fix problem with passing the 'varexp' and 'selection'; strings for processing, preventing correct usage of the operators '|'; and '||' in TTreeFormula.; In the TProofOutputFile constructor, remove the 'localroot' prefix; only if present in the path. Fixes possible truncation problems; occuring when the paths are not under the localroot scope.; In TXSocket and TXSlave: fix problem with the way collection over a; socket just marked as 'bad' was interrupted; the interrupt was de facto; ineffective, so that collection stayed always until the timeout expired; (default: 5 minutes). Should solve some of the cases were slow response; was experienced.; Fix a problem with log path transmission when the node dies early or; not even starts. The log path was empty and wrong was filled in when; retrieving the log buffers, disorienting debugging.; Fix a bug checking the first event which rendered ineffective the; request for processing a subset of events in a given dataset or; chain.; In pq2-ana-dist, fix problem with the labels of the distribution; histo occuring when machines are represented by IPs instead of; names.; Add missing calls to closedir() and TSystem::FreeDirectory, cuasing a; large number of filedescriptors remaining opened after xproofd; initialization.; Fix a problem with the final update of the progress information; affecting occasionally cases with skipped events.; Fix merging of TproofOutputFile when using submergers (the; intermediate files were not correctly handled).; Fix the way TChain weights are transmitted to TProofDraw in; DrawSelect operations. AoB; ; The class TFileMerger has been moved to 'io/io'. ",MatchSource.DOCS,proof/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v532/index.html:285,Availability,avail,available,285,". PROOF System; NB: Starting with version 5.32/00, Xrootd; is not distributed any longer with ROOT but has become an external package.; If not avaibable the PROOF modules 'proofx' and 'proofd' will not be built.; The PROOF core modules, however, are built. Namely, PROOF-Lite will be; available even when Xrootd is not.; New functionality. Creating PAR packages from ROOT data files: it is now possible to; use TFile::MakeProject to create a PAR file to read the file.; Add support for backend-dependent record formatting of PROOF monitoring.; This is achieved by introducing a new layer, described by the abstract; interface TProofMonSender, with the record format defined in the backend; implemenation (currently TProofMonSenderML, for MonaLisa, and; TProofMonSenderSQL, for SQL backends). Currently three types of records; are sent: 'summary' (derived from what was currently posted), 'dataset',; with entries per dataset processed in the query, and 'files', with; entries per file processed in the query. In SQL terms, each of this; records corresponds to a different table. Sending of any of the three; records can be toggled independently.; In TProofMgr, add 'ping' functionality to test in non-blocking way if; a PROOF service is listening at a given port of a given host.; Improvements. In PROOF-Bench, file generation, add the possibility to change; only the generating function, passed as TMacro. Add also check on the; free space on the device and skip file generation if less than 10% or; less than 1 GB.; Record in TStatus also the max memory usage on the master and printed; via TStatus::Print; this allow a quick visualisation of the overall; memory usage at the end of the query.; Import version 0.9.6 of afdsmgrd; Make sure that the name(s) of the processed dataset(s) are registered; in the TFileInfo objects being processed, so that it can be used for; monitoring.; In XrdProofd, add possibility to skip the checks for the data; directories during session startup, as they may signi",MatchSource.DOCS,proof/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v532/index.html:1166,Availability,ping,ping,1166," The PROOF core modules, however, are built. Namely, PROOF-Lite will be; available even when Xrootd is not.; New functionality. Creating PAR packages from ROOT data files: it is now possible to; use TFile::MakeProject to create a PAR file to read the file.; Add support for backend-dependent record formatting of PROOF monitoring.; This is achieved by introducing a new layer, described by the abstract; interface TProofMonSender, with the record format defined in the backend; implemenation (currently TProofMonSenderML, for MonaLisa, and; TProofMonSenderSQL, for SQL backends). Currently three types of records; are sent: 'summary' (derived from what was currently posted), 'dataset',; with entries per dataset processed in the query, and 'files', with; entries per file processed in the query. In SQL terms, each of this; records corresponds to a different table. Sending of any of the three; records can be toggled independently.; In TProofMgr, add 'ping' functionality to test in non-blocking way if; a PROOF service is listening at a given port of a given host.; Improvements. In PROOF-Bench, file generation, add the possibility to change; only the generating function, passed as TMacro. Add also check on the; free space on the device and skip file generation if less than 10% or; less than 1 GB.; Record in TStatus also the max memory usage on the master and printed; via TStatus::Print; this allow a quick visualisation of the overall; memory usage at the end of the query.; Import version 0.9.6 of afdsmgrd; Make sure that the name(s) of the processed dataset(s) are registered; in the TFileInfo objects being processed, so that it can be used for; monitoring.; In XrdProofd, add possibility to skip the checks for the data; directories during session startup, as they may significantly slowdown; the startup process is the medium is busy. In such a case, admins; are responsible to create the directories in advance; the session; releated part fo the path is created by the session once u",MatchSource.DOCS,proof/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v532/index.html:2694,Availability,avail,available,2694,"t the end of the query.; Import version 0.9.6 of afdsmgrd; Make sure that the name(s) of the processed dataset(s) are registered; in the TFileInfo objects being processed, so that it can be used for; monitoring.; In XrdProofd, add possibility to skip the checks for the data; directories during session startup, as they may significantly slowdown; the startup process is the medium is busy. In such a case, admins; are responsible to create the directories in advance; the session; releated part fo the path is created by the session once up.; In XrdProofd, move the check for the username after authentication.; This is because authentication may run some credentials-to-user mapping; which can modify the requested username. This way we really check the; final username and not the one requested by the client, which may even; not exist on the machines. Side modification: when the mapping function; returns more usernames, the username specified by the client is used to; help choosing the effective username among the available choices; if not; match is found the handshake does any longer fail, the first mapped; username is chosen instead.; In XrdProofd, allow 'xpd.allowedgroups' to control also PROOF; groups, not only UNIX ones.In XrdProofd, simplify error; messages in case of login failure because of non-authorization.; Remove hardcoded additions of dirname(COMPILER) and of; '/bin:/usr/bin:/usr/local/bin' in front of PATH. These uncontrolled; additions could hide specific settings in PATH and be the source of; weird problems appearing in PROOF only.; Add more flexibility to the definition of the library path seen by; proofserv. So far to avoid ambiguites in some cases, $ROOTSYS/lib was; removed and the one of the ROOT version chosen was added later on in; front, which proved to be to aggressive in some cases.; All changes (and fixes) needed to build against the version of Xrootd,; now always installed as external.; Fixes. Fix GetSessionLogs in PROOF-Lite; Restore correct pars",MatchSource.DOCS,proof/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v532/index.html:2932,Availability,error,error,2932,"ries during session startup, as they may significantly slowdown; the startup process is the medium is busy. In such a case, admins; are responsible to create the directories in advance; the session; releated part fo the path is created by the session once up.; In XrdProofd, move the check for the username after authentication.; This is because authentication may run some credentials-to-user mapping; which can modify the requested username. This way we really check the; final username and not the one requested by the client, which may even; not exist on the machines. Side modification: when the mapping function; returns more usernames, the username specified by the client is used to; help choosing the effective username among the available choices; if not; match is found the handshake does any longer fail, the first mapped; username is chosen instead.; In XrdProofd, allow 'xpd.allowedgroups' to control also PROOF; groups, not only UNIX ones.In XrdProofd, simplify error; messages in case of login failure because of non-authorization.; Remove hardcoded additions of dirname(COMPILER) and of; '/bin:/usr/bin:/usr/local/bin' in front of PATH. These uncontrolled; additions could hide specific settings in PATH and be the source of; weird problems appearing in PROOF only.; Add more flexibility to the definition of the library path seen by; proofserv. So far to avoid ambiguites in some cases, $ROOTSYS/lib was; removed and the one of the ROOT version chosen was added later on in; front, which proved to be to aggressive in some cases.; All changes (and fixes) needed to build against the version of Xrootd,; now always installed as external.; Fixes. Fix GetSessionLogs in PROOF-Lite; Restore correct parsing of ""workers=N"" in PROOF-Lite; In Proof-Bench, make sure that it can be run from any directory; and no matter how ROOT was installed; Fix issue in TProofPlayer::HandleHistogram preventing proper; histogram cleaning right after merging when using TH1::Add; histogram; were still des",MatchSource.DOCS,proof/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v532/index.html:2965,Availability,failure,failure,2965,"ries during session startup, as they may significantly slowdown; the startup process is the medium is busy. In such a case, admins; are responsible to create the directories in advance; the session; releated part fo the path is created by the session once up.; In XrdProofd, move the check for the username after authentication.; This is because authentication may run some credentials-to-user mapping; which can modify the requested username. This way we really check the; final username and not the one requested by the client, which may even; not exist on the machines. Side modification: when the mapping function; returns more usernames, the username specified by the client is used to; help choosing the effective username among the available choices; if not; match is found the handshake does any longer fail, the first mapped; username is chosen instead.; In XrdProofd, allow 'xpd.allowedgroups' to control also PROOF; groups, not only UNIX ones.In XrdProofd, simplify error; messages in case of login failure because of non-authorization.; Remove hardcoded additions of dirname(COMPILER) and of; '/bin:/usr/bin:/usr/local/bin' in front of PATH. These uncontrolled; additions could hide specific settings in PATH and be the source of; weird problems appearing in PROOF only.; Add more flexibility to the definition of the library path seen by; proofserv. So far to avoid ambiguites in some cases, $ROOTSYS/lib was; removed and the one of the ROOT version chosen was added later on in; front, which proved to be to aggressive in some cases.; All changes (and fixes) needed to build against the version of Xrootd,; now always installed as external.; Fixes. Fix GetSessionLogs in PROOF-Lite; Restore correct parsing of ""workers=N"" in PROOF-Lite; In Proof-Bench, make sure that it can be run from any directory; and no matter how ROOT was installed; Fix issue in TProofPlayer::HandleHistogram preventing proper; histogram cleaning right after merging when using TH1::Add; histogram; were still des",MatchSource.DOCS,proof/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v532/index.html:1123,Deployability,toggle,toggled,1123,"me an external package.; If not avaibable the PROOF modules 'proofx' and 'proofd' will not be built.; The PROOF core modules, however, are built. Namely, PROOF-Lite will be; available even when Xrootd is not.; New functionality. Creating PAR packages from ROOT data files: it is now possible to; use TFile::MakeProject to create a PAR file to read the file.; Add support for backend-dependent record formatting of PROOF monitoring.; This is achieved by introducing a new layer, described by the abstract; interface TProofMonSender, with the record format defined in the backend; implemenation (currently TProofMonSenderML, for MonaLisa, and; TProofMonSenderSQL, for SQL backends). Currently three types of records; are sent: 'summary' (derived from what was currently posted), 'dataset',; with entries per dataset processed in the query, and 'files', with; entries per file processed in the query. In SQL terms, each of this; records corresponds to a different table. Sending of any of the three; records can be toggled independently.; In TProofMgr, add 'ping' functionality to test in non-blocking way if; a PROOF service is listening at a given port of a given host.; Improvements. In PROOF-Bench, file generation, add the possibility to change; only the generating function, passed as TMacro. Add also check on the; free space on the device and skip file generation if less than 10% or; less than 1 GB.; Record in TStatus also the max memory usage on the master and printed; via TStatus::Print; this allow a quick visualisation of the overall; memory usage at the end of the query.; Import version 0.9.6 of afdsmgrd; Make sure that the name(s) of the processed dataset(s) are registered; in the TFileInfo objects being processed, so that it can be used for; monitoring.; In XrdProofd, add possibility to skip the checks for the data; directories during session startup, as they may significantly slowdown; the startup process is the medium is busy. In such a case, admins; are responsible to create",MatchSource.DOCS,proof/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v532/index.html:3587,Deployability,install,installed,3587," mapping function; returns more usernames, the username specified by the client is used to; help choosing the effective username among the available choices; if not; match is found the handshake does any longer fail, the first mapped; username is chosen instead.; In XrdProofd, allow 'xpd.allowedgroups' to control also PROOF; groups, not only UNIX ones.In XrdProofd, simplify error; messages in case of login failure because of non-authorization.; Remove hardcoded additions of dirname(COMPILER) and of; '/bin:/usr/bin:/usr/local/bin' in front of PATH. These uncontrolled; additions could hide specific settings in PATH and be the source of; weird problems appearing in PROOF only.; Add more flexibility to the definition of the library path seen by; proofserv. So far to avoid ambiguites in some cases, $ROOTSYS/lib was; removed and the one of the ROOT version chosen was added later on in; front, which proved to be to aggressive in some cases.; All changes (and fixes) needed to build against the version of Xrootd,; now always installed as external.; Fixes. Fix GetSessionLogs in PROOF-Lite; Restore correct parsing of ""workers=N"" in PROOF-Lite; In Proof-Bench, make sure that it can be run from any directory; and no matter how ROOT was installed; Fix issue in TProofPlayer::HandleHistogram preventing proper; histogram cleaning right after merging when using TH1::Add; histogram; were still destroyed at the end of the query, but there was no; memory advantage in TH1::Add wrt TH1::Merge.; Make sure that the performance tree is removed from the output; list when saved to the output file. Solves a segv at quit.; Decouple from registered TChains in already TProof::Close(); allows; to avoid possible crash at exit ('.q') occuring after the recent; revision of the socket cleanup policy.; In XrdProofd, fix a few issues with option 'xpd.multiuser'.; In TXSocket::ProcessUnsolicitedMsg, fix an issue preventig server; messages to be displayed during setup, i.e. when the XrdClientConn; instance ",MatchSource.DOCS,proof/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v532/index.html:3798,Deployability,install,installed,3798,"ive username among the available choices; if not; match is found the handshake does any longer fail, the first mapped; username is chosen instead.; In XrdProofd, allow 'xpd.allowedgroups' to control also PROOF; groups, not only UNIX ones.In XrdProofd, simplify error; messages in case of login failure because of non-authorization.; Remove hardcoded additions of dirname(COMPILER) and of; '/bin:/usr/bin:/usr/local/bin' in front of PATH. These uncontrolled; additions could hide specific settings in PATH and be the source of; weird problems appearing in PROOF only.; Add more flexibility to the definition of the library path seen by; proofserv. So far to avoid ambiguites in some cases, $ROOTSYS/lib was; removed and the one of the ROOT version chosen was added later on in; front, which proved to be to aggressive in some cases.; All changes (and fixes) needed to build against the version of Xrootd,; now always installed as external.; Fixes. Fix GetSessionLogs in PROOF-Lite; Restore correct parsing of ""workers=N"" in PROOF-Lite; In Proof-Bench, make sure that it can be run from any directory; and no matter how ROOT was installed; Fix issue in TProofPlayer::HandleHistogram preventing proper; histogram cleaning right after merging when using TH1::Add; histogram; were still destroyed at the end of the query, but there was no; memory advantage in TH1::Add wrt TH1::Merge.; Make sure that the performance tree is removed from the output; list when saved to the output file. Solves a segv at quit.; Decouple from registered TChains in already TProof::Close(); allows; to avoid possible crash at exit ('.q') occuring after the recent; revision of the socket cleanup policy.; In XrdProofd, fix a few issues with option 'xpd.multiuser'.; In TXSocket::ProcessUnsolicitedMsg, fix an issue preventig server; messages to be displayed during setup, i.e. when the XrdClientConn; instance is not yet defined.; In XrdProofd, fix the behavior of the 'xpd.allowedusers' and; 'xpd.allowedgroups' directives. ",MatchSource.DOCS,proof/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v532/index.html:531,Energy Efficiency,monitor,monitoring,531,". PROOF System; NB: Starting with version 5.32/00, Xrootd; is not distributed any longer with ROOT but has become an external package.; If not avaibable the PROOF modules 'proofx' and 'proofd' will not be built.; The PROOF core modules, however, are built. Namely, PROOF-Lite will be; available even when Xrootd is not.; New functionality. Creating PAR packages from ROOT data files: it is now possible to; use TFile::MakeProject to create a PAR file to read the file.; Add support for backend-dependent record formatting of PROOF monitoring.; This is achieved by introducing a new layer, described by the abstract; interface TProofMonSender, with the record format defined in the backend; implemenation (currently TProofMonSenderML, for MonaLisa, and; TProofMonSenderSQL, for SQL backends). Currently three types of records; are sent: 'summary' (derived from what was currently posted), 'dataset',; with entries per dataset processed in the query, and 'files', with; entries per file processed in the query. In SQL terms, each of this; records corresponds to a different table. Sending of any of the three; records can be toggled independently.; In TProofMgr, add 'ping' functionality to test in non-blocking way if; a PROOF service is listening at a given port of a given host.; Improvements. In PROOF-Bench, file generation, add the possibility to change; only the generating function, passed as TMacro. Add also check on the; free space on the device and skip file generation if less than 10% or; less than 1 GB.; Record in TStatus also the max memory usage on the master and printed; via TStatus::Print; this allow a quick visualisation of the overall; memory usage at the end of the query.; Import version 0.9.6 of afdsmgrd; Make sure that the name(s) of the processed dataset(s) are registered; in the TFileInfo objects being processed, so that it can be used for; monitoring.; In XrdProofd, add possibility to skip the checks for the data; directories during session startup, as they may signi",MatchSource.DOCS,proof/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v532/index.html:1872,Energy Efficiency,monitor,monitoring,1872,"ly three types of records; are sent: 'summary' (derived from what was currently posted), 'dataset',; with entries per dataset processed in the query, and 'files', with; entries per file processed in the query. In SQL terms, each of this; records corresponds to a different table. Sending of any of the three; records can be toggled independently.; In TProofMgr, add 'ping' functionality to test in non-blocking way if; a PROOF service is listening at a given port of a given host.; Improvements. In PROOF-Bench, file generation, add the possibility to change; only the generating function, passed as TMacro. Add also check on the; free space on the device and skip file generation if less than 10% or; less than 1 GB.; Record in TStatus also the max memory usage on the master and printed; via TStatus::Print; this allow a quick visualisation of the overall; memory usage at the end of the query.; Import version 0.9.6 of afdsmgrd; Make sure that the name(s) of the processed dataset(s) are registered; in the TFileInfo objects being processed, so that it can be used for; monitoring.; In XrdProofd, add possibility to skip the checks for the data; directories during session startup, as they may significantly slowdown; the startup process is the medium is busy. In such a case, admins; are responsible to create the directories in advance; the session; releated part fo the path is created by the session once up.; In XrdProofd, move the check for the username after authentication.; This is because authentication may run some credentials-to-user mapping; which can modify the requested username. This way we really check the; final username and not the one requested by the client, which may even; not exist on the machines. Side modification: when the mapping function; returns more usernames, the username specified by the client is used to; help choosing the effective username among the available choices; if not; match is found the handshake does any longer fail, the first mapped; username i",MatchSource.DOCS,proof/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v532/index.html:494,Integrability,depend,dependent,494,". PROOF System; NB: Starting with version 5.32/00, Xrootd; is not distributed any longer with ROOT but has become an external package.; If not avaibable the PROOF modules 'proofx' and 'proofd' will not be built.; The PROOF core modules, however, are built. Namely, PROOF-Lite will be; available even when Xrootd is not.; New functionality. Creating PAR packages from ROOT data files: it is now possible to; use TFile::MakeProject to create a PAR file to read the file.; Add support for backend-dependent record formatting of PROOF monitoring.; This is achieved by introducing a new layer, described by the abstract; interface TProofMonSender, with the record format defined in the backend; implemenation (currently TProofMonSenderML, for MonaLisa, and; TProofMonSenderSQL, for SQL backends). Currently three types of records; are sent: 'summary' (derived from what was currently posted), 'dataset',; with entries per dataset processed in the query, and 'files', with; entries per file processed in the query. In SQL terms, each of this; records corresponds to a different table. Sending of any of the three; records can be toggled independently.; In TProofMgr, add 'ping' functionality to test in non-blocking way if; a PROOF service is listening at a given port of a given host.; Improvements. In PROOF-Bench, file generation, add the possibility to change; only the generating function, passed as TMacro. Add also check on the; free space on the device and skip file generation if less than 10% or; less than 1 GB.; Record in TStatus also the max memory usage on the master and printed; via TStatus::Print; this allow a quick visualisation of the overall; memory usage at the end of the query.; Import version 0.9.6 of afdsmgrd; Make sure that the name(s) of the processed dataset(s) are registered; in the TFileInfo objects being processed, so that it can be used for; monitoring.; In XrdProofd, add possibility to skip the checks for the data; directories during session startup, as they may signi",MatchSource.DOCS,proof/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v532/index.html:616,Integrability,interface,interface,616,". PROOF System; NB: Starting with version 5.32/00, Xrootd; is not distributed any longer with ROOT but has become an external package.; If not avaibable the PROOF modules 'proofx' and 'proofd' will not be built.; The PROOF core modules, however, are built. Namely, PROOF-Lite will be; available even when Xrootd is not.; New functionality. Creating PAR packages from ROOT data files: it is now possible to; use TFile::MakeProject to create a PAR file to read the file.; Add support for backend-dependent record formatting of PROOF monitoring.; This is achieved by introducing a new layer, described by the abstract; interface TProofMonSender, with the record format defined in the backend; implemenation (currently TProofMonSenderML, for MonaLisa, and; TProofMonSenderSQL, for SQL backends). Currently three types of records; are sent: 'summary' (derived from what was currently posted), 'dataset',; with entries per dataset processed in the query, and 'files', with; entries per file processed in the query. In SQL terms, each of this; records corresponds to a different table. Sending of any of the three; records can be toggled independently.; In TProofMgr, add 'ping' functionality to test in non-blocking way if; a PROOF service is listening at a given port of a given host.; Improvements. In PROOF-Bench, file generation, add the possibility to change; only the generating function, passed as TMacro. Add also check on the; free space on the device and skip file generation if less than 10% or; less than 1 GB.; Record in TStatus also the max memory usage on the master and printed; via TStatus::Print; this allow a quick visualisation of the overall; memory usage at the end of the query.; Import version 0.9.6 of afdsmgrd; Make sure that the name(s) of the processed dataset(s) are registered; in the TFileInfo objects being processed, so that it can be used for; monitoring.; In XrdProofd, add possibility to skip the checks for the data; directories during session startup, as they may signi",MatchSource.DOCS,proof/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v532/index.html:2939,Integrability,message,messages,2939,"ries during session startup, as they may significantly slowdown; the startup process is the medium is busy. In such a case, admins; are responsible to create the directories in advance; the session; releated part fo the path is created by the session once up.; In XrdProofd, move the check for the username after authentication.; This is because authentication may run some credentials-to-user mapping; which can modify the requested username. This way we really check the; final username and not the one requested by the client, which may even; not exist on the machines. Side modification: when the mapping function; returns more usernames, the username specified by the client is used to; help choosing the effective username among the available choices; if not; match is found the handshake does any longer fail, the first mapped; username is chosen instead.; In XrdProofd, allow 'xpd.allowedgroups' to control also PROOF; groups, not only UNIX ones.In XrdProofd, simplify error; messages in case of login failure because of non-authorization.; Remove hardcoded additions of dirname(COMPILER) and of; '/bin:/usr/bin:/usr/local/bin' in front of PATH. These uncontrolled; additions could hide specific settings in PATH and be the source of; weird problems appearing in PROOF only.; Add more flexibility to the definition of the library path seen by; proofserv. So far to avoid ambiguites in some cases, $ROOTSYS/lib was; removed and the one of the ROOT version chosen was added later on in; front, which proved to be to aggressive in some cases.; All changes (and fixes) needed to build against the version of Xrootd,; now always installed as external.; Fixes. Fix GetSessionLogs in PROOF-Lite; Restore correct parsing of ""workers=N"" in PROOF-Lite; In Proof-Bench, make sure that it can be run from any directory; and no matter how ROOT was installed; Fix issue in TProofPlayer::HandleHistogram preventing proper; histogram cleaning right after merging when using TH1::Add; histogram; were still des",MatchSource.DOCS,proof/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v532/index.html:4479,Integrability,message,messages,4479,"ive username among the available choices; if not; match is found the handshake does any longer fail, the first mapped; username is chosen instead.; In XrdProofd, allow 'xpd.allowedgroups' to control also PROOF; groups, not only UNIX ones.In XrdProofd, simplify error; messages in case of login failure because of non-authorization.; Remove hardcoded additions of dirname(COMPILER) and of; '/bin:/usr/bin:/usr/local/bin' in front of PATH. These uncontrolled; additions could hide specific settings in PATH and be the source of; weird problems appearing in PROOF only.; Add more flexibility to the definition of the library path seen by; proofserv. So far to avoid ambiguites in some cases, $ROOTSYS/lib was; removed and the one of the ROOT version chosen was added later on in; front, which proved to be to aggressive in some cases.; All changes (and fixes) needed to build against the version of Xrootd,; now always installed as external.; Fixes. Fix GetSessionLogs in PROOF-Lite; Restore correct parsing of ""workers=N"" in PROOF-Lite; In Proof-Bench, make sure that it can be run from any directory; and no matter how ROOT was installed; Fix issue in TProofPlayer::HandleHistogram preventing proper; histogram cleaning right after merging when using TH1::Add; histogram; were still destroyed at the end of the query, but there was no; memory advantage in TH1::Add wrt TH1::Merge.; Make sure that the performance tree is removed from the output; list when saved to the output file. Solves a segv at quit.; Decouple from registered TChains in already TProof::Close(); allows; to avoid possible crash at exit ('.q') occuring after the recent; revision of the socket cleanup policy.; In XrdProofd, fix a few issues with option 'xpd.multiuser'.; In TXSocket::ProcessUnsolicitedMsg, fix an issue preventig server; messages to be displayed during setup, i.e. when the XrdClientConn; instance is not yet defined.; In XrdProofd, fix the behavior of the 'xpd.allowedusers' and; 'xpd.allowedgroups' directives. ",MatchSource.DOCS,proof/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v532/index.html:4071,Performance,perform,performance,4071,"ive username among the available choices; if not; match is found the handshake does any longer fail, the first mapped; username is chosen instead.; In XrdProofd, allow 'xpd.allowedgroups' to control also PROOF; groups, not only UNIX ones.In XrdProofd, simplify error; messages in case of login failure because of non-authorization.; Remove hardcoded additions of dirname(COMPILER) and of; '/bin:/usr/bin:/usr/local/bin' in front of PATH. These uncontrolled; additions could hide specific settings in PATH and be the source of; weird problems appearing in PROOF only.; Add more flexibility to the definition of the library path seen by; proofserv. So far to avoid ambiguites in some cases, $ROOTSYS/lib was; removed and the one of the ROOT version chosen was added later on in; front, which proved to be to aggressive in some cases.; All changes (and fixes) needed to build against the version of Xrootd,; now always installed as external.; Fixes. Fix GetSessionLogs in PROOF-Lite; Restore correct parsing of ""workers=N"" in PROOF-Lite; In Proof-Bench, make sure that it can be run from any directory; and no matter how ROOT was installed; Fix issue in TProofPlayer::HandleHistogram preventing proper; histogram cleaning right after merging when using TH1::Add; histogram; were still destroyed at the end of the query, but there was no; memory advantage in TH1::Add wrt TH1::Merge.; Make sure that the performance tree is removed from the output; list when saved to the output file. Solves a segv at quit.; Decouple from registered TChains in already TProof::Close(); allows; to avoid possible crash at exit ('.q') occuring after the recent; revision of the socket cleanup policy.; In XrdProofd, fix a few issues with option 'xpd.multiuser'.; In TXSocket::ProcessUnsolicitedMsg, fix an issue preventig server; messages to be displayed during setup, i.e. when the XrdClientConn; instance is not yet defined.; In XrdProofd, fix the behavior of the 'xpd.allowedusers' and; 'xpd.allowedgroups' directives. ",MatchSource.DOCS,proof/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v532/index.html:3328,Safety,avoid,avoid,3328,"e really check the; final username and not the one requested by the client, which may even; not exist on the machines. Side modification: when the mapping function; returns more usernames, the username specified by the client is used to; help choosing the effective username among the available choices; if not; match is found the handshake does any longer fail, the first mapped; username is chosen instead.; In XrdProofd, allow 'xpd.allowedgroups' to control also PROOF; groups, not only UNIX ones.In XrdProofd, simplify error; messages in case of login failure because of non-authorization.; Remove hardcoded additions of dirname(COMPILER) and of; '/bin:/usr/bin:/usr/local/bin' in front of PATH. These uncontrolled; additions could hide specific settings in PATH and be the source of; weird problems appearing in PROOF only.; Add more flexibility to the definition of the library path seen by; proofserv. So far to avoid ambiguites in some cases, $ROOTSYS/lib was; removed and the one of the ROOT version chosen was added later on in; front, which proved to be to aggressive in some cases.; All changes (and fixes) needed to build against the version of Xrootd,; now always installed as external.; Fixes. Fix GetSessionLogs in PROOF-Lite; Restore correct parsing of ""workers=N"" in PROOF-Lite; In Proof-Bench, make sure that it can be run from any directory; and no matter how ROOT was installed; Fix issue in TProofPlayer::HandleHistogram preventing proper; histogram cleaning right after merging when using TH1::Add; histogram; were still destroyed at the end of the query, but there was no; memory advantage in TH1::Add wrt TH1::Merge.; Make sure that the performance tree is removed from the output; list when saved to the output file. Solves a segv at quit.; Decouple from registered TChains in already TProof::Close(); allows; to avoid possible crash at exit ('.q') occuring after the recent; revision of the socket cleanup policy.; In XrdProofd, fix a few issues with option 'xpd.multiuser'.",MatchSource.DOCS,proof/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v532/index.html:4248,Safety,avoid,avoid,4248,"ive username among the available choices; if not; match is found the handshake does any longer fail, the first mapped; username is chosen instead.; In XrdProofd, allow 'xpd.allowedgroups' to control also PROOF; groups, not only UNIX ones.In XrdProofd, simplify error; messages in case of login failure because of non-authorization.; Remove hardcoded additions of dirname(COMPILER) and of; '/bin:/usr/bin:/usr/local/bin' in front of PATH. These uncontrolled; additions could hide specific settings in PATH and be the source of; weird problems appearing in PROOF only.; Add more flexibility to the definition of the library path seen by; proofserv. So far to avoid ambiguites in some cases, $ROOTSYS/lib was; removed and the one of the ROOT version chosen was added later on in; front, which proved to be to aggressive in some cases.; All changes (and fixes) needed to build against the version of Xrootd,; now always installed as external.; Fixes. Fix GetSessionLogs in PROOF-Lite; Restore correct parsing of ""workers=N"" in PROOF-Lite; In Proof-Bench, make sure that it can be run from any directory; and no matter how ROOT was installed; Fix issue in TProofPlayer::HandleHistogram preventing proper; histogram cleaning right after merging when using TH1::Add; histogram; were still destroyed at the end of the query, but there was no; memory advantage in TH1::Add wrt TH1::Merge.; Make sure that the performance tree is removed from the output; list when saved to the output file. Solves a segv at quit.; Decouple from registered TChains in already TProof::Close(); allows; to avoid possible crash at exit ('.q') occuring after the recent; revision of the socket cleanup policy.; In XrdProofd, fix a few issues with option 'xpd.multiuser'.; In TXSocket::ProcessUnsolicitedMsg, fix an issue preventig server; messages to be displayed during setup, i.e. when the XrdClientConn; instance is not yet defined.; In XrdProofd, fix the behavior of the 'xpd.allowedusers' and; 'xpd.allowedgroups' directives. ",MatchSource.DOCS,proof/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v532/index.html:2268,Security,authenticat,authentication,2268,"t a given port of a given host.; Improvements. In PROOF-Bench, file generation, add the possibility to change; only the generating function, passed as TMacro. Add also check on the; free space on the device and skip file generation if less than 10% or; less than 1 GB.; Record in TStatus also the max memory usage on the master and printed; via TStatus::Print; this allow a quick visualisation of the overall; memory usage at the end of the query.; Import version 0.9.6 of afdsmgrd; Make sure that the name(s) of the processed dataset(s) are registered; in the TFileInfo objects being processed, so that it can be used for; monitoring.; In XrdProofd, add possibility to skip the checks for the data; directories during session startup, as they may significantly slowdown; the startup process is the medium is busy. In such a case, admins; are responsible to create the directories in advance; the session; releated part fo the path is created by the session once up.; In XrdProofd, move the check for the username after authentication.; This is because authentication may run some credentials-to-user mapping; which can modify the requested username. This way we really check the; final username and not the one requested by the client, which may even; not exist on the machines. Side modification: when the mapping function; returns more usernames, the username specified by the client is used to; help choosing the effective username among the available choices; if not; match is found the handshake does any longer fail, the first mapped; username is chosen instead.; In XrdProofd, allow 'xpd.allowedgroups' to control also PROOF; groups, not only UNIX ones.In XrdProofd, simplify error; messages in case of login failure because of non-authorization.; Remove hardcoded additions of dirname(COMPILER) and of; '/bin:/usr/bin:/usr/local/bin' in front of PATH. These uncontrolled; additions could hide specific settings in PATH and be the source of; weird problems appearing in PROOF only.; Add more f",MatchSource.DOCS,proof/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v532/index.html:2301,Security,authenticat,authentication,2301,"ibility to change; only the generating function, passed as TMacro. Add also check on the; free space on the device and skip file generation if less than 10% or; less than 1 GB.; Record in TStatus also the max memory usage on the master and printed; via TStatus::Print; this allow a quick visualisation of the overall; memory usage at the end of the query.; Import version 0.9.6 of afdsmgrd; Make sure that the name(s) of the processed dataset(s) are registered; in the TFileInfo objects being processed, so that it can be used for; monitoring.; In XrdProofd, add possibility to skip the checks for the data; directories during session startup, as they may significantly slowdown; the startup process is the medium is busy. In such a case, admins; are responsible to create the directories in advance; the session; releated part fo the path is created by the session once up.; In XrdProofd, move the check for the username after authentication.; This is because authentication may run some credentials-to-user mapping; which can modify the requested username. This way we really check the; final username and not the one requested by the client, which may even; not exist on the machines. Side modification: when the mapping function; returns more usernames, the username specified by the client is used to; help choosing the effective username among the available choices; if not; match is found the handshake does any longer fail, the first mapped; username is chosen instead.; In XrdProofd, allow 'xpd.allowedgroups' to control also PROOF; groups, not only UNIX ones.In XrdProofd, simplify error; messages in case of login failure because of non-authorization.; Remove hardcoded additions of dirname(COMPILER) and of; '/bin:/usr/bin:/usr/local/bin' in front of PATH. These uncontrolled; additions could hide specific settings in PATH and be the source of; weird problems appearing in PROOF only.; Add more flexibility to the definition of the library path seen by; proofserv. So far to avoid ambigui",MatchSource.DOCS,proof/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v532/index.html:2988,Security,authoriz,authorization,2988,"ries during session startup, as they may significantly slowdown; the startup process is the medium is busy. In such a case, admins; are responsible to create the directories in advance; the session; releated part fo the path is created by the session once up.; In XrdProofd, move the check for the username after authentication.; This is because authentication may run some credentials-to-user mapping; which can modify the requested username. This way we really check the; final username and not the one requested by the client, which may even; not exist on the machines. Side modification: when the mapping function; returns more usernames, the username specified by the client is used to; help choosing the effective username among the available choices; if not; match is found the handshake does any longer fail, the first mapped; username is chosen instead.; In XrdProofd, allow 'xpd.allowedgroups' to control also PROOF; groups, not only UNIX ones.In XrdProofd, simplify error; messages in case of login failure because of non-authorization.; Remove hardcoded additions of dirname(COMPILER) and of; '/bin:/usr/bin:/usr/local/bin' in front of PATH. These uncontrolled; additions could hide specific settings in PATH and be the source of; weird problems appearing in PROOF only.; Add more flexibility to the definition of the library path seen by; proofserv. So far to avoid ambiguites in some cases, $ROOTSYS/lib was; removed and the one of the ROOT version chosen was added later on in; front, which proved to be to aggressive in some cases.; All changes (and fixes) needed to build against the version of Xrootd,; now always installed as external.; Fixes. Fix GetSessionLogs in PROOF-Lite; Restore correct parsing of ""workers=N"" in PROOF-Lite; In Proof-Bench, make sure that it can be run from any directory; and no matter how ROOT was installed; Fix issue in TProofPlayer::HandleHistogram preventing proper; histogram cleaning right after merging when using TH1::Add; histogram; were still des",MatchSource.DOCS,proof/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v532/index.html:1189,Testability,test,test,1189," The PROOF core modules, however, are built. Namely, PROOF-Lite will be; available even when Xrootd is not.; New functionality. Creating PAR packages from ROOT data files: it is now possible to; use TFile::MakeProject to create a PAR file to read the file.; Add support for backend-dependent record formatting of PROOF monitoring.; This is achieved by introducing a new layer, described by the abstract; interface TProofMonSender, with the record format defined in the backend; implemenation (currently TProofMonSenderML, for MonaLisa, and; TProofMonSenderSQL, for SQL backends). Currently three types of records; are sent: 'summary' (derived from what was currently posted), 'dataset',; with entries per dataset processed in the query, and 'files', with; entries per file processed in the query. In SQL terms, each of this; records corresponds to a different table. Sending of any of the three; records can be toggled independently.; In TProofMgr, add 'ping' functionality to test in non-blocking way if; a PROOF service is listening at a given port of a given host.; Improvements. In PROOF-Bench, file generation, add the possibility to change; only the generating function, passed as TMacro. Add also check on the; free space on the device and skip file generation if less than 10% or; less than 1 GB.; Record in TStatus also the max memory usage on the master and printed; via TStatus::Print; this allow a quick visualisation of the overall; memory usage at the end of the query.; Import version 0.9.6 of afdsmgrd; Make sure that the name(s) of the processed dataset(s) are registered; in the TFileInfo objects being processed, so that it can be used for; monitoring.; In XrdProofd, add possibility to skip the checks for the data; directories during session startup, as they may significantly slowdown; the startup process is the medium is busy. In such a case, admins; are responsible to create the directories in advance; the session; releated part fo the path is created by the session once u",MatchSource.DOCS,proof/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v532/index.html:2959,Testability,log,login,2959,"ries during session startup, as they may significantly slowdown; the startup process is the medium is busy. In such a case, admins; are responsible to create the directories in advance; the session; releated part fo the path is created by the session once up.; In XrdProofd, move the check for the username after authentication.; This is because authentication may run some credentials-to-user mapping; which can modify the requested username. This way we really check the; final username and not the one requested by the client, which may even; not exist on the machines. Side modification: when the mapping function; returns more usernames, the username specified by the client is used to; help choosing the effective username among the available choices; if not; match is found the handshake does any longer fail, the first mapped; username is chosen instead.; In XrdProofd, allow 'xpd.allowedgroups' to control also PROOF; groups, not only UNIX ones.In XrdProofd, simplify error; messages in case of login failure because of non-authorization.; Remove hardcoded additions of dirname(COMPILER) and of; '/bin:/usr/bin:/usr/local/bin' in front of PATH. These uncontrolled; additions could hide specific settings in PATH and be the source of; weird problems appearing in PROOF only.; Add more flexibility to the definition of the library path seen by; proofserv. So far to avoid ambiguites in some cases, $ROOTSYS/lib was; removed and the one of the ROOT version chosen was added later on in; front, which proved to be to aggressive in some cases.; All changes (and fixes) needed to build against the version of Xrootd,; now always installed as external.; Fixes. Fix GetSessionLogs in PROOF-Lite; Restore correct parsing of ""workers=N"" in PROOF-Lite; In Proof-Bench, make sure that it can be run from any directory; and no matter how ROOT was installed; Fix issue in TProofPlayer::HandleHistogram preventing proper; histogram cleaning right after merging when using TH1::Add; histogram; were still des",MatchSource.DOCS,proof/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v532/index.html:2923,Usability,simpl,simplify,2923,"ries during session startup, as they may significantly slowdown; the startup process is the medium is busy. In such a case, admins; are responsible to create the directories in advance; the session; releated part fo the path is created by the session once up.; In XrdProofd, move the check for the username after authentication.; This is because authentication may run some credentials-to-user mapping; which can modify the requested username. This way we really check the; final username and not the one requested by the client, which may even; not exist on the machines. Side modification: when the mapping function; returns more usernames, the username specified by the client is used to; help choosing the effective username among the available choices; if not; match is found the handshake does any longer fail, the first mapped; username is chosen instead.; In XrdProofd, allow 'xpd.allowedgroups' to control also PROOF; groups, not only UNIX ones.In XrdProofd, simplify error; messages in case of login failure because of non-authorization.; Remove hardcoded additions of dirname(COMPILER) and of; '/bin:/usr/bin:/usr/local/bin' in front of PATH. These uncontrolled; additions could hide specific settings in PATH and be the source of; weird problems appearing in PROOF only.; Add more flexibility to the definition of the library path seen by; proofserv. So far to avoid ambiguites in some cases, $ROOTSYS/lib was; removed and the one of the ROOT version chosen was added later on in; front, which proved to be to aggressive in some cases.; All changes (and fixes) needed to build against the version of Xrootd,; now always installed as external.; Fixes. Fix GetSessionLogs in PROOF-Lite; Restore correct parsing of ""workers=N"" in PROOF-Lite; In Proof-Bench, make sure that it can be run from any directory; and no matter how ROOT was installed; Fix issue in TProofPlayer::HandleHistogram preventing proper; histogram cleaning right after merging when using TH1::Add; histogram; were still des",MatchSource.DOCS,proof/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v534/index.html:4361,Availability,failure,failure,4361,"equires much less memory. Merging in; one-go (the previous default) can be activated by passing 'H' in the; constructor options.; In ProofBench, add possibility to change the location of the; generated files via the third argument of TProofBench::MakeDataSet.; Several optimizations in the low level PROOF event loop; (TProofPlayer::Process),  allowing to reduce dramatically the; overhead introduced by the operations PROOF needs to perform during the; event loop. A measurement of the overhead can be obtained from a very; light computational task, for example, generating one random number and; filling one histogram; executing this task within a PROOF-Lite session; with 1 worker now takes only 1.8 times the time required by a straight; loop in the parent ROOT session; the same number before was about 13. ; In TDrawFeedback::Feedback, call method Draw() of objects not; identified as TH1 derivation. This allows user-defined objects; implementing Draw to be displayed via this utility class.; In TProof::LoadPackageOnClient, do not create a symlink; 'pack_name' to the package dir, but add directly the package dir to the; include path. This solves the longstanding annoying problem of failure; when a directory or file with the name of the package did already exist; in the local working directory. . Fixes; ; Fix merging issue affecting automatic dataset creation when; only one worker is active.; Fix the realtime reported by TProof::GetRealTime() for masters; (it was overwritten with the ones coming from workers).; Fix serious problem with TProof::Load: additional files were; not copied in the master sandbox but left in the cache. A workaround; for backward compatibility has also been implemented.; Fix a problem preventing actions requiring access to worker; nodes (log file retrieval, reset) to work on workers where the username; is different from the one o the master, e.g. PoD on gLite.; Fix issue with the specification of the working directory; template in 'xpd.multiuser'.; . ",MatchSource.DOCS,proof/doc/v534/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v534/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v534/index.html:3524,Energy Efficiency,reduce,reduce,3524,"re both called UploadFiles and differ in the first argument,; which is used to pass the files to be uploaded. These can be given as a; list (of TFileInfo or TObjString), a directory or specified in a text; file.; Add support for paralell dataset verification. This is; implemented via a dedicated TSelector (TSelVerifyDataSet) which is run; over the list of files in the dataset via TPacketizerFile. The file; order is preserved using the recently introduced index in TFileInfo.; In TProofOutputFile, add switch to control the way histograms; are merged by TFileMerger, i.e. one-by-one or all-in-one-go. The; default is one-by-one which requires much less memory. Merging in; one-go (the previous default) can be activated by passing 'H' in the; constructor options.; In ProofBench, add possibility to change the location of the; generated files via the third argument of TProofBench::MakeDataSet.; Several optimizations in the low level PROOF event loop; (TProofPlayer::Process),  allowing to reduce dramatically the; overhead introduced by the operations PROOF needs to perform during the; event loop. A measurement of the overhead can be obtained from a very; light computational task, for example, generating one random number and; filling one histogram; executing this task within a PROOF-Lite session; with 1 worker now takes only 1.8 times the time required by a straight; loop in the parent ROOT session; the same number before was about 13. ; In TDrawFeedback::Feedback, call method Draw() of objects not; identified as TH1 derivation. This allows user-defined objects; implementing Draw to be displayed via this utility class.; In TProof::LoadPackageOnClient, do not create a symlink; 'pack_name' to the package dir, but add directly the package dir to the; include path. This solves the longstanding annoying problem of failure; when a directory or file with the name of the package did already exist; in the local working directory. . Fixes; ; Fix merging issue affecting automatic datase",MatchSource.DOCS,proof/doc/v534/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v534/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v534/index.html:45,Integrability,interface,interface,45,". PROOF System. Added functionality; ; Added interface to simplify the creation of the performance; tree: two new methods TProof::SetPerfTree(""<file>"") and; TProof::SavePerfTree(""<file>"", ""<queryref>"") allow set; and/or save the information to a given file path. The perfomance tree; settim=ngs are diabled after each query, so they need to be enabled; each time.; Add support for a command line test run of 'proofserv'; this is; useful to test that the environment is setup correctly.; In TProofBench::DrawCPU, add possibility to extract of a couple; of numbers supposed to give an idea of the computing specs of the; cluster being benchmarked. These are the maximum rate for the standard; CPU intensive task and the normalized, per worker, rate. Both are; expressed in RNGPS (RaNdom Generation Per Second).; Add class TProofPerfAnalysis collecting a set of tools to; analyse the performance tree.; Add support for selector-by-object processing in PROOF. The; selector object, created and configured locally by the user, is added; to the input list and recuperated from there on the worker machines for; processing. Any input list setting in the selector itself is not; streamed but temporarly moved to then standard input list, so that user; can use the selector input list as container of processing information; if they find convenient to do so. Process(...) methods with the file; name argument replaced by 'TSelector *' have  introduced where; relevant (TProof, TProofPlayer and their derivatives, TDSet).  ; Add the possibility to force submerging at node level, i.e. one; submerger per physical machine. In this way the network traffic can be; minimized, for example when merging large output files. The new feature; is enabled by setting the Int_t parameter 'PROOF_MergersByHost' (or the; directive 'Proof.MergersByHost') to a non-null value.; Simplify enabling of basic feedback. In TProof::Process, add; support for switches ""fb=name1,name2,name3,... "" or; ""feedback=name1,name2,name3,... """,MatchSource.DOCS,proof/doc/v534/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v534/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v534/index.html:990,Modifiability,config,configured,990,"; ; Added interface to simplify the creation of the performance; tree: two new methods TProof::SetPerfTree(""<file>"") and; TProof::SavePerfTree(""<file>"", ""<queryref>"") allow set; and/or save the information to a given file path. The perfomance tree; settim=ngs are diabled after each query, so they need to be enabled; each time.; Add support for a command line test run of 'proofserv'; this is; useful to test that the environment is setup correctly.; In TProofBench::DrawCPU, add possibility to extract of a couple; of numbers supposed to give an idea of the computing specs of the; cluster being benchmarked. These are the maximum rate for the standard; CPU intensive task and the normalized, per worker, rate. Both are; expressed in RNGPS (RaNdom Generation Per Second).; Add class TProofPerfAnalysis collecting a set of tools to; analyse the performance tree.; Add support for selector-by-object processing in PROOF. The; selector object, created and configured locally by the user, is added; to the input list and recuperated from there on the worker machines for; processing. Any input list setting in the selector itself is not; streamed but temporarly moved to then standard input list, so that user; can use the selector input list as container of processing information; if they find convenient to do so. Process(...) methods with the file; name argument replaced by 'TSelector *' have  introduced where; relevant (TProof, TProofPlayer and their derivatives, TDSet).  ; Add the possibility to force submerging at node level, i.e. one; submerger per physical machine. In this way the network traffic can be; minimized, for example when merging large output files. The new feature; is enabled by setting the Int_t parameter 'PROOF_MergersByHost' (or the; directive 'Proof.MergersByHost') to a non-null value.; Simplify enabling of basic feedback. In TProof::Process, add; support for switches ""fb=name1,name2,name3,... "" or; ""feedback=name1,name2,name3,... "" in the option field. This enables;",MatchSource.DOCS,proof/doc/v534/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v534/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v534/index.html:4783,Modifiability,sandbox,sandbox,4783,"equires much less memory. Merging in; one-go (the previous default) can be activated by passing 'H' in the; constructor options.; In ProofBench, add possibility to change the location of the; generated files via the third argument of TProofBench::MakeDataSet.; Several optimizations in the low level PROOF event loop; (TProofPlayer::Process),  allowing to reduce dramatically the; overhead introduced by the operations PROOF needs to perform during the; event loop. A measurement of the overhead can be obtained from a very; light computational task, for example, generating one random number and; filling one histogram; executing this task within a PROOF-Lite session; with 1 worker now takes only 1.8 times the time required by a straight; loop in the parent ROOT session; the same number before was about 13. ; In TDrawFeedback::Feedback, call method Draw() of objects not; identified as TH1 derivation. This allows user-defined objects; implementing Draw to be displayed via this utility class.; In TProof::LoadPackageOnClient, do not create a symlink; 'pack_name' to the package dir, but add directly the package dir to the; include path. This solves the longstanding annoying problem of failure; when a directory or file with the name of the package did already exist; in the local working directory. . Fixes; ; Fix merging issue affecting automatic dataset creation when; only one worker is active.; Fix the realtime reported by TProof::GetRealTime() for masters; (it was overwritten with the ones coming from workers).; Fix serious problem with TProof::Load: additional files were; not copied in the master sandbox but left in the cache. A workaround; for backward compatibility has also been implemented.; Fix a problem preventing actions requiring access to worker; nodes (log file retrieval, reset) to work on workers where the username; is different from the one o the master, e.g. PoD on gLite.; Fix issue with the specification of the working directory; template in 'xpd.multiuser'.; . ",MatchSource.DOCS,proof/doc/v534/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v534/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v534/index.html:87,Performance,perform,performance,87,". PROOF System. Added functionality; ; Added interface to simplify the creation of the performance; tree: two new methods TProof::SetPerfTree(""<file>"") and; TProof::SavePerfTree(""<file>"", ""<queryref>"") allow set; and/or save the information to a given file path. The perfomance tree; settim=ngs are diabled after each query, so they need to be enabled; each time.; Add support for a command line test run of 'proofserv'; this is; useful to test that the environment is setup correctly.; In TProofBench::DrawCPU, add possibility to extract of a couple; of numbers supposed to give an idea of the computing specs of the; cluster being benchmarked. These are the maximum rate for the standard; CPU intensive task and the normalized, per worker, rate. Both are; expressed in RNGPS (RaNdom Generation Per Second).; Add class TProofPerfAnalysis collecting a set of tools to; analyse the performance tree.; Add support for selector-by-object processing in PROOF. The; selector object, created and configured locally by the user, is added; to the input list and recuperated from there on the worker machines for; processing. Any input list setting in the selector itself is not; streamed but temporarly moved to then standard input list, so that user; can use the selector input list as container of processing information; if they find convenient to do so. Process(...) methods with the file; name argument replaced by 'TSelector *' have  introduced where; relevant (TProof, TProofPlayer and their derivatives, TDSet).  ; Add the possibility to force submerging at node level, i.e. one; submerger per physical machine. In this way the network traffic can be; minimized, for example when merging large output files. The new feature; is enabled by setting the Int_t parameter 'PROOF_MergersByHost' (or the; directive 'Proof.MergersByHost') to a non-null value.; Simplify enabling of basic feedback. In TProof::Process, add; support for switches ""fb=name1,name2,name3,... "" or; ""feedback=name1,name2,name3,... """,MatchSource.DOCS,proof/doc/v534/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v534/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v534/index.html:881,Performance,perform,performance,881,". PROOF System. Added functionality; ; Added interface to simplify the creation of the performance; tree: two new methods TProof::SetPerfTree(""<file>"") and; TProof::SavePerfTree(""<file>"", ""<queryref>"") allow set; and/or save the information to a given file path. The perfomance tree; settim=ngs are diabled after each query, so they need to be enabled; each time.; Add support for a command line test run of 'proofserv'; this is; useful to test that the environment is setup correctly.; In TProofBench::DrawCPU, add possibility to extract of a couple; of numbers supposed to give an idea of the computing specs of the; cluster being benchmarked. These are the maximum rate for the standard; CPU intensive task and the normalized, per worker, rate. Both are; expressed in RNGPS (RaNdom Generation Per Second).; Add class TProofPerfAnalysis collecting a set of tools to; analyse the performance tree.; Add support for selector-by-object processing in PROOF. The; selector object, created and configured locally by the user, is added; to the input list and recuperated from there on the worker machines for; processing. Any input list setting in the selector itself is not; streamed but temporarly moved to then standard input list, so that user; can use the selector input list as container of processing information; if they find convenient to do so. Process(...) methods with the file; name argument replaced by 'TSelector *' have  introduced where; relevant (TProof, TProofPlayer and their derivatives, TDSet).  ; Add the possibility to force submerging at node level, i.e. one; submerger per physical machine. In this way the network traffic can be; minimized, for example when merging large output files. The new feature; is enabled by setting the Int_t parameter 'PROOF_MergersByHost' (or the; directive 'Proof.MergersByHost') to a non-null value.; Simplify enabling of basic feedback. In TProof::Process, add; support for switches ""fb=name1,name2,name3,... "" or; ""feedback=name1,name2,name3,... """,MatchSource.DOCS,proof/doc/v534/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v534/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v534/index.html:3437,Performance,optimiz,optimizations,3437,"re both called UploadFiles and differ in the first argument,; which is used to pass the files to be uploaded. These can be given as a; list (of TFileInfo or TObjString), a directory or specified in a text; file.; Add support for paralell dataset verification. This is; implemented via a dedicated TSelector (TSelVerifyDataSet) which is run; over the list of files in the dataset via TPacketizerFile. The file; order is preserved using the recently introduced index in TFileInfo.; In TProofOutputFile, add switch to control the way histograms; are merged by TFileMerger, i.e. one-by-one or all-in-one-go. The; default is one-by-one which requires much less memory. Merging in; one-go (the previous default) can be activated by passing 'H' in the; constructor options.; In ProofBench, add possibility to change the location of the; generated files via the third argument of TProofBench::MakeDataSet.; Several optimizations in the low level PROOF event loop; (TProofPlayer::Process),  allowing to reduce dramatically the; overhead introduced by the operations PROOF needs to perform during the; event loop. A measurement of the overhead can be obtained from a very; light computational task, for example, generating one random number and; filling one histogram; executing this task within a PROOF-Lite session; with 1 worker now takes only 1.8 times the time required by a straight; loop in the parent ROOT session; the same number before was about 13. ; In TDrawFeedback::Feedback, call method Draw() of objects not; identified as TH1 derivation. This allows user-defined objects; implementing Draw to be displayed via this utility class.; In TProof::LoadPackageOnClient, do not create a symlink; 'pack_name' to the package dir, but add directly the package dir to the; include path. This solves the longstanding annoying problem of failure; when a directory or file with the name of the package did already exist; in the local working directory. . Fixes; ; Fix merging issue affecting automatic datase",MatchSource.DOCS,proof/doc/v534/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v534/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v534/index.html:3602,Performance,perform,perform,3602,"re both called UploadFiles and differ in the first argument,; which is used to pass the files to be uploaded. These can be given as a; list (of TFileInfo or TObjString), a directory or specified in a text; file.; Add support for paralell dataset verification. This is; implemented via a dedicated TSelector (TSelVerifyDataSet) which is run; over the list of files in the dataset via TPacketizerFile. The file; order is preserved using the recently introduced index in TFileInfo.; In TProofOutputFile, add switch to control the way histograms; are merged by TFileMerger, i.e. one-by-one or all-in-one-go. The; default is one-by-one which requires much less memory. Merging in; one-go (the previous default) can be activated by passing 'H' in the; constructor options.; In ProofBench, add possibility to change the location of the; generated files via the third argument of TProofBench::MakeDataSet.; Several optimizations in the low level PROOF event loop; (TProofPlayer::Process),  allowing to reduce dramatically the; overhead introduced by the operations PROOF needs to perform during the; event loop. A measurement of the overhead can be obtained from a very; light computational task, for example, generating one random number and; filling one histogram; executing this task within a PROOF-Lite session; with 1 worker now takes only 1.8 times the time required by a straight; loop in the parent ROOT session; the same number before was about 13. ; In TDrawFeedback::Feedback, call method Draw() of objects not; identified as TH1 derivation. This allows user-defined objects; implementing Draw to be displayed via this utility class.; In TProof::LoadPackageOnClient, do not create a symlink; 'pack_name' to the package dir, but add directly the package dir to the; include path. This solves the longstanding annoying problem of failure; when a directory or file with the name of the package did already exist; in the local working directory. . Fixes; ; Fix merging issue affecting automatic datase",MatchSource.DOCS,proof/doc/v534/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v534/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v534/index.html:4807,Performance,cache,cache,4807,"equires much less memory. Merging in; one-go (the previous default) can be activated by passing 'H' in the; constructor options.; In ProofBench, add possibility to change the location of the; generated files via the third argument of TProofBench::MakeDataSet.; Several optimizations in the low level PROOF event loop; (TProofPlayer::Process),  allowing to reduce dramatically the; overhead introduced by the operations PROOF needs to perform during the; event loop. A measurement of the overhead can be obtained from a very; light computational task, for example, generating one random number and; filling one histogram; executing this task within a PROOF-Lite session; with 1 worker now takes only 1.8 times the time required by a straight; loop in the parent ROOT session; the same number before was about 13. ; In TDrawFeedback::Feedback, call method Draw() of objects not; identified as TH1 derivation. This allows user-defined objects; implementing Draw to be displayed via this utility class.; In TProof::LoadPackageOnClient, do not create a symlink; 'pack_name' to the package dir, but add directly the package dir to the; include path. This solves the longstanding annoying problem of failure; when a directory or file with the name of the package did already exist; in the local working directory. . Fixes; ; Fix merging issue affecting automatic dataset creation when; only one worker is active.; Fix the realtime reported by TProof::GetRealTime() for masters; (it was overwritten with the ones coming from workers).; Fix serious problem with TProof::Load: additional files were; not copied in the master sandbox but left in the cache. A workaround; for backward compatibility has also been implemented.; Fix a problem preventing actions requiring access to worker; nodes (log file retrieval, reset) to work on workers where the username; is different from the one o the master, e.g. PoD on gLite.; Fix issue with the specification of the working directory; template in 'xpd.multiuser'.; . ",MatchSource.DOCS,proof/doc/v534/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v534/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v534/index.html:4926,Security,access,access,4926,"equires much less memory. Merging in; one-go (the previous default) can be activated by passing 'H' in the; constructor options.; In ProofBench, add possibility to change the location of the; generated files via the third argument of TProofBench::MakeDataSet.; Several optimizations in the low level PROOF event loop; (TProofPlayer::Process),  allowing to reduce dramatically the; overhead introduced by the operations PROOF needs to perform during the; event loop. A measurement of the overhead can be obtained from a very; light computational task, for example, generating one random number and; filling one histogram; executing this task within a PROOF-Lite session; with 1 worker now takes only 1.8 times the time required by a straight; loop in the parent ROOT session; the same number before was about 13. ; In TDrawFeedback::Feedback, call method Draw() of objects not; identified as TH1 derivation. This allows user-defined objects; implementing Draw to be displayed via this utility class.; In TProof::LoadPackageOnClient, do not create a symlink; 'pack_name' to the package dir, but add directly the package dir to the; include path. This solves the longstanding annoying problem of failure; when a directory or file with the name of the package did already exist; in the local working directory. . Fixes; ; Fix merging issue affecting automatic dataset creation when; only one worker is active.; Fix the realtime reported by TProof::GetRealTime() for masters; (it was overwritten with the ones coming from workers).; Fix serious problem with TProof::Load: additional files were; not copied in the master sandbox but left in the cache. A workaround; for backward compatibility has also been implemented.; Fix a problem preventing actions requiring access to worker; nodes (log file retrieval, reset) to work on workers where the username; is different from the one o the master, e.g. PoD on gLite.; Fix issue with the specification of the working directory; template in 'xpd.multiuser'.; . ",MatchSource.DOCS,proof/doc/v534/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v534/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v534/index.html:396,Testability,test,test,396,". PROOF System. Added functionality; ; Added interface to simplify the creation of the performance; tree: two new methods TProof::SetPerfTree(""<file>"") and; TProof::SavePerfTree(""<file>"", ""<queryref>"") allow set; and/or save the information to a given file path. The perfomance tree; settim=ngs are diabled after each query, so they need to be enabled; each time.; Add support for a command line test run of 'proofserv'; this is; useful to test that the environment is setup correctly.; In TProofBench::DrawCPU, add possibility to extract of a couple; of numbers supposed to give an idea of the computing specs of the; cluster being benchmarked. These are the maximum rate for the standard; CPU intensive task and the normalized, per worker, rate. Both are; expressed in RNGPS (RaNdom Generation Per Second).; Add class TProofPerfAnalysis collecting a set of tools to; analyse the performance tree.; Add support for selector-by-object processing in PROOF. The; selector object, created and configured locally by the user, is added; to the input list and recuperated from there on the worker machines for; processing. Any input list setting in the selector itself is not; streamed but temporarly moved to then standard input list, so that user; can use the selector input list as container of processing information; if they find convenient to do so. Process(...) methods with the file; name argument replaced by 'TSelector *' have  introduced where; relevant (TProof, TProofPlayer and their derivatives, TDSet).  ; Add the possibility to force submerging at node level, i.e. one; submerger per physical machine. In this way the network traffic can be; minimized, for example when merging large output files. The new feature; is enabled by setting the Int_t parameter 'PROOF_MergersByHost' (or the; directive 'Proof.MergersByHost') to a non-null value.; Simplify enabling of basic feedback. In TProof::Process, add; support for switches ""fb=name1,name2,name3,... "" or; ""feedback=name1,name2,name3,... """,MatchSource.DOCS,proof/doc/v534/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v534/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v534/index.html:440,Testability,test,test,440,". PROOF System. Added functionality; ; Added interface to simplify the creation of the performance; tree: two new methods TProof::SetPerfTree(""<file>"") and; TProof::SavePerfTree(""<file>"", ""<queryref>"") allow set; and/or save the information to a given file path. The perfomance tree; settim=ngs are diabled after each query, so they need to be enabled; each time.; Add support for a command line test run of 'proofserv'; this is; useful to test that the environment is setup correctly.; In TProofBench::DrawCPU, add possibility to extract of a couple; of numbers supposed to give an idea of the computing specs of the; cluster being benchmarked. These are the maximum rate for the standard; CPU intensive task and the normalized, per worker, rate. Both are; expressed in RNGPS (RaNdom Generation Per Second).; Add class TProofPerfAnalysis collecting a set of tools to; analyse the performance tree.; Add support for selector-by-object processing in PROOF. The; selector object, created and configured locally by the user, is added; to the input list and recuperated from there on the worker machines for; processing. Any input list setting in the selector itself is not; streamed but temporarly moved to then standard input list, so that user; can use the selector input list as container of processing information; if they find convenient to do so. Process(...) methods with the file; name argument replaced by 'TSelector *' have  introduced where; relevant (TProof, TProofPlayer and their derivatives, TDSet).  ; Add the possibility to force submerging at node level, i.e. one; submerger per physical machine. In this way the network traffic can be; minimized, for example when merging large output files. The new feature; is enabled by setting the Int_t parameter 'PROOF_MergersByHost' (or the; directive 'Proof.MergersByHost') to a non-null value.; Simplify enabling of basic feedback. In TProof::Process, add; support for switches ""fb=name1,name2,name3,... "" or; ""feedback=name1,name2,name3,... """,MatchSource.DOCS,proof/doc/v534/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v534/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v534/index.html:633,Testability,benchmark,benchmarked,633,". PROOF System. Added functionality; ; Added interface to simplify the creation of the performance; tree: two new methods TProof::SetPerfTree(""<file>"") and; TProof::SavePerfTree(""<file>"", ""<queryref>"") allow set; and/or save the information to a given file path. The perfomance tree; settim=ngs are diabled after each query, so they need to be enabled; each time.; Add support for a command line test run of 'proofserv'; this is; useful to test that the environment is setup correctly.; In TProofBench::DrawCPU, add possibility to extract of a couple; of numbers supposed to give an idea of the computing specs of the; cluster being benchmarked. These are the maximum rate for the standard; CPU intensive task and the normalized, per worker, rate. Both are; expressed in RNGPS (RaNdom Generation Per Second).; Add class TProofPerfAnalysis collecting a set of tools to; analyse the performance tree.; Add support for selector-by-object processing in PROOF. The; selector object, created and configured locally by the user, is added; to the input list and recuperated from there on the worker machines for; processing. Any input list setting in the selector itself is not; streamed but temporarly moved to then standard input list, so that user; can use the selector input list as container of processing information; if they find convenient to do so. Process(...) methods with the file; name argument replaced by 'TSelector *' have  introduced where; relevant (TProof, TProofPlayer and their derivatives, TDSet).  ; Add the possibility to force submerging at node level, i.e. one; submerger per physical machine. In this way the network traffic can be; minimized, for example when merging large output files. The new feature; is enabled by setting the Int_t parameter 'PROOF_MergersByHost' (or the; directive 'Proof.MergersByHost') to a non-null value.; Simplify enabling of basic feedback. In TProof::Process, add; support for switches ""fb=name1,name2,name3,... "" or; ""feedback=name1,name2,name3,... """,MatchSource.DOCS,proof/doc/v534/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v534/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v534/index.html:4783,Testability,sandbox,sandbox,4783,"equires much less memory. Merging in; one-go (the previous default) can be activated by passing 'H' in the; constructor options.; In ProofBench, add possibility to change the location of the; generated files via the third argument of TProofBench::MakeDataSet.; Several optimizations in the low level PROOF event loop; (TProofPlayer::Process),  allowing to reduce dramatically the; overhead introduced by the operations PROOF needs to perform during the; event loop. A measurement of the overhead can be obtained from a very; light computational task, for example, generating one random number and; filling one histogram; executing this task within a PROOF-Lite session; with 1 worker now takes only 1.8 times the time required by a straight; loop in the parent ROOT session; the same number before was about 13. ; In TDrawFeedback::Feedback, call method Draw() of objects not; identified as TH1 derivation. This allows user-defined objects; implementing Draw to be displayed via this utility class.; In TProof::LoadPackageOnClient, do not create a symlink; 'pack_name' to the package dir, but add directly the package dir to the; include path. This solves the longstanding annoying problem of failure; when a directory or file with the name of the package did already exist; in the local working directory. . Fixes; ; Fix merging issue affecting automatic dataset creation when; only one worker is active.; Fix the realtime reported by TProof::GetRealTime() for masters; (it was overwritten with the ones coming from workers).; Fix serious problem with TProof::Load: additional files were; not copied in the master sandbox but left in the cache. A workaround; for backward compatibility has also been implemented.; Fix a problem preventing actions requiring access to worker; nodes (log file retrieval, reset) to work on workers where the username; is different from the one o the master, e.g. PoD on gLite.; Fix issue with the specification of the working directory; template in 'xpd.multiuser'.; . ",MatchSource.DOCS,proof/doc/v534/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v534/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v534/index.html:4951,Testability,log,log,4951,"equires much less memory. Merging in; one-go (the previous default) can be activated by passing 'H' in the; constructor options.; In ProofBench, add possibility to change the location of the; generated files via the third argument of TProofBench::MakeDataSet.; Several optimizations in the low level PROOF event loop; (TProofPlayer::Process),  allowing to reduce dramatically the; overhead introduced by the operations PROOF needs to perform during the; event loop. A measurement of the overhead can be obtained from a very; light computational task, for example, generating one random number and; filling one histogram; executing this task within a PROOF-Lite session; with 1 worker now takes only 1.8 times the time required by a straight; loop in the parent ROOT session; the same number before was about 13. ; In TDrawFeedback::Feedback, call method Draw() of objects not; identified as TH1 derivation. This allows user-defined objects; implementing Draw to be displayed via this utility class.; In TProof::LoadPackageOnClient, do not create a symlink; 'pack_name' to the package dir, but add directly the package dir to the; include path. This solves the longstanding annoying problem of failure; when a directory or file with the name of the package did already exist; in the local working directory. . Fixes; ; Fix merging issue affecting automatic dataset creation when; only one worker is active.; Fix the realtime reported by TProof::GetRealTime() for masters; (it was overwritten with the ones coming from workers).; Fix serious problem with TProof::Load: additional files were; not copied in the master sandbox but left in the cache. A workaround; for backward compatibility has also been implemented.; Fix a problem preventing actions requiring access to worker; nodes (log file retrieval, reset) to work on workers where the username; is different from the one o the master, e.g. PoD on gLite.; Fix issue with the specification of the working directory; template in 'xpd.multiuser'.; . ",MatchSource.DOCS,proof/doc/v534/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v534/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v534/index.html:58,Usability,simpl,simplify,58,". PROOF System. Added functionality; ; Added interface to simplify the creation of the performance; tree: two new methods TProof::SetPerfTree(""<file>"") and; TProof::SavePerfTree(""<file>"", ""<queryref>"") allow set; and/or save the information to a given file path. The perfomance tree; settim=ngs are diabled after each query, so they need to be enabled; each time.; Add support for a command line test run of 'proofserv'; this is; useful to test that the environment is setup correctly.; In TProofBench::DrawCPU, add possibility to extract of a couple; of numbers supposed to give an idea of the computing specs of the; cluster being benchmarked. These are the maximum rate for the standard; CPU intensive task and the normalized, per worker, rate. Both are; expressed in RNGPS (RaNdom Generation Per Second).; Add class TProofPerfAnalysis collecting a set of tools to; analyse the performance tree.; Add support for selector-by-object processing in PROOF. The; selector object, created and configured locally by the user, is added; to the input list and recuperated from there on the worker machines for; processing. Any input list setting in the selector itself is not; streamed but temporarly moved to then standard input list, so that user; can use the selector input list as container of processing information; if they find convenient to do so. Process(...) methods with the file; name argument replaced by 'TSelector *' have  introduced where; relevant (TProof, TProofPlayer and their derivatives, TDSet).  ; Add the possibility to force submerging at node level, i.e. one; submerger per physical machine. In this way the network traffic can be; minimized, for example when merging large output files. The new feature; is enabled by setting the Int_t parameter 'PROOF_MergersByHost' (or the; directive 'Proof.MergersByHost') to a non-null value.; Simplify enabling of basic feedback. In TProof::Process, add; support for switches ""fb=name1,name2,name3,... "" or; ""feedback=name1,name2,name3,... """,MatchSource.DOCS,proof/doc/v534/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v534/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v534/index.html:1880,Usability,feedback,feedback,1880,"nalyse the performance tree.; Add support for selector-by-object processing in PROOF. The; selector object, created and configured locally by the user, is added; to the input list and recuperated from there on the worker machines for; processing. Any input list setting in the selector itself is not; streamed but temporarly moved to then standard input list, so that user; can use the selector input list as container of processing information; if they find convenient to do so. Process(...) methods with the file; name argument replaced by 'TSelector *' have  introduced where; relevant (TProof, TProofPlayer and their derivatives, TDSet).  ; Add the possibility to force submerging at node level, i.e. one; submerger per physical machine. In this way the network traffic can be; minimized, for example when merging large output files. The new feature; is enabled by setting the Int_t parameter 'PROOF_MergersByHost' (or the; directive 'Proof.MergersByHost') to a non-null value.; Simplify enabling of basic feedback. In TProof::Process, add; support for switches ""fb=name1,name2,name3,... "" or; ""feedback=name1,name2,name3,... "" in the option field. This enables; feedback for the specified objects, creating a TDrawFeedback object; attached to the session. Feedback for the specified objects is disabled; at the end of the query and the created TDrawFeedback is destroyed. The; special name 'stats' enables the three feedback histograms required by; a dedicated new class TStatsFeedback, and uses a TStatsFeedback instead; of TDrawFeedback to display the feedback. . Improvements; ; Add to TProofMgr two static functions to upload files. These; functions are both called UploadFiles and differ in the first argument,; which is used to pass the files to be uploaded. These can be given as a; list (of TFileInfo or TObjString), a directory or specified in a text; file.; Add support for paralell dataset verification. This is; implemented via a dedicated TSelector (TSelVerifyDataSet) which is run;",MatchSource.DOCS,proof/doc/v534/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v534/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v534/index.html:1969,Usability,feedback,feedback,1969,"reated and configured locally by the user, is added; to the input list and recuperated from there on the worker machines for; processing. Any input list setting in the selector itself is not; streamed but temporarly moved to then standard input list, so that user; can use the selector input list as container of processing information; if they find convenient to do so. Process(...) methods with the file; name argument replaced by 'TSelector *' have  introduced where; relevant (TProof, TProofPlayer and their derivatives, TDSet).  ; Add the possibility to force submerging at node level, i.e. one; submerger per physical machine. In this way the network traffic can be; minimized, for example when merging large output files. The new feature; is enabled by setting the Int_t parameter 'PROOF_MergersByHost' (or the; directive 'Proof.MergersByHost') to a non-null value.; Simplify enabling of basic feedback. In TProof::Process, add; support for switches ""fb=name1,name2,name3,... "" or; ""feedback=name1,name2,name3,... "" in the option field. This enables; feedback for the specified objects, creating a TDrawFeedback object; attached to the session. Feedback for the specified objects is disabled; at the end of the query and the created TDrawFeedback is destroyed. The; special name 'stats' enables the three feedback histograms required by; a dedicated new class TStatsFeedback, and uses a TStatsFeedback instead; of TDrawFeedback to display the feedback. . Improvements; ; Add to TProofMgr two static functions to upload files. These; functions are both called UploadFiles and differ in the first argument,; which is used to pass the files to be uploaded. These can be given as a; list (of TFileInfo or TObjString), a directory or specified in a text; file.; Add support for paralell dataset verification. This is; implemented via a dedicated TSelector (TSelVerifyDataSet) which is run; over the list of files in the dataset via TPacketizerFile. The file; order is preserved using the recently i",MatchSource.DOCS,proof/doc/v534/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v534/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v534/index.html:2037,Usability,feedback,feedback,2037," on the worker machines for; processing. Any input list setting in the selector itself is not; streamed but temporarly moved to then standard input list, so that user; can use the selector input list as container of processing information; if they find convenient to do so. Process(...) methods with the file; name argument replaced by 'TSelector *' have  introduced where; relevant (TProof, TProofPlayer and their derivatives, TDSet).  ; Add the possibility to force submerging at node level, i.e. one; submerger per physical machine. In this way the network traffic can be; minimized, for example when merging large output files. The new feature; is enabled by setting the Int_t parameter 'PROOF_MergersByHost' (or the; directive 'Proof.MergersByHost') to a non-null value.; Simplify enabling of basic feedback. In TProof::Process, add; support for switches ""fb=name1,name2,name3,... "" or; ""feedback=name1,name2,name3,... "" in the option field. This enables; feedback for the specified objects, creating a TDrawFeedback object; attached to the session. Feedback for the specified objects is disabled; at the end of the query and the created TDrawFeedback is destroyed. The; special name 'stats' enables the three feedback histograms required by; a dedicated new class TStatsFeedback, and uses a TStatsFeedback instead; of TDrawFeedback to display the feedback. . Improvements; ; Add to TProofMgr two static functions to upload files. These; functions are both called UploadFiles and differ in the first argument,; which is used to pass the files to be uploaded. These can be given as a; list (of TFileInfo or TObjString), a directory or specified in a text; file.; Add support for paralell dataset verification. This is; implemented via a dedicated TSelector (TSelVerifyDataSet) which is run; over the list of files in the dataset via TPacketizerFile. The file; order is preserved using the recently introduced index in TFileInfo.; In TProofOutputFile, add switch to control the way histograms; are",MatchSource.DOCS,proof/doc/v534/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v534/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v534/index.html:2291,Usability,feedback,feedback,2291," do so. Process(...) methods with the file; name argument replaced by 'TSelector *' have  introduced where; relevant (TProof, TProofPlayer and their derivatives, TDSet).  ; Add the possibility to force submerging at node level, i.e. one; submerger per physical machine. In this way the network traffic can be; minimized, for example when merging large output files. The new feature; is enabled by setting the Int_t parameter 'PROOF_MergersByHost' (or the; directive 'Proof.MergersByHost') to a non-null value.; Simplify enabling of basic feedback. In TProof::Process, add; support for switches ""fb=name1,name2,name3,... "" or; ""feedback=name1,name2,name3,... "" in the option field. This enables; feedback for the specified objects, creating a TDrawFeedback object; attached to the session. Feedback for the specified objects is disabled; at the end of the query and the created TDrawFeedback is destroyed. The; special name 'stats' enables the three feedback histograms required by; a dedicated new class TStatsFeedback, and uses a TStatsFeedback instead; of TDrawFeedback to display the feedback. . Improvements; ; Add to TProofMgr two static functions to upload files. These; functions are both called UploadFiles and differ in the first argument,; which is used to pass the files to be uploaded. These can be given as a; list (of TFileInfo or TObjString), a directory or specified in a text; file.; Add support for paralell dataset verification. This is; implemented via a dedicated TSelector (TSelVerifyDataSet) which is run; over the list of files in the dataset via TPacketizerFile. The file; order is preserved using the recently introduced index in TFileInfo.; In TProofOutputFile, add switch to control the way histograms; are merged by TFileMerger, i.e. one-by-one or all-in-one-go. The; default is one-by-one which requires much less memory. Merging in; one-go (the previous default) can be activated by passing 'H' in the; constructor options.; In ProofBench, add possibility to change the",MatchSource.DOCS,proof/doc/v534/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v534/index.html
https://github.com/root-project/root/tree/v6-32-06/proof/doc/v534/index.html:2429,Usability,feedback,feedback,2429," do so. Process(...) methods with the file; name argument replaced by 'TSelector *' have  introduced where; relevant (TProof, TProofPlayer and their derivatives, TDSet).  ; Add the possibility to force submerging at node level, i.e. one; submerger per physical machine. In this way the network traffic can be; minimized, for example when merging large output files. The new feature; is enabled by setting the Int_t parameter 'PROOF_MergersByHost' (or the; directive 'Proof.MergersByHost') to a non-null value.; Simplify enabling of basic feedback. In TProof::Process, add; support for switches ""fb=name1,name2,name3,... "" or; ""feedback=name1,name2,name3,... "" in the option field. This enables; feedback for the specified objects, creating a TDrawFeedback object; attached to the session. Feedback for the specified objects is disabled; at the end of the query and the created TDrawFeedback is destroyed. The; special name 'stats' enables the three feedback histograms required by; a dedicated new class TStatsFeedback, and uses a TStatsFeedback instead; of TDrawFeedback to display the feedback. . Improvements; ; Add to TProofMgr two static functions to upload files. These; functions are both called UploadFiles and differ in the first argument,; which is used to pass the files to be uploaded. These can be given as a; list (of TFileInfo or TObjString), a directory or specified in a text; file.; Add support for paralell dataset verification. This is; implemented via a dedicated TSelector (TSelVerifyDataSet) which is run; over the list of files in the dataset via TPacketizerFile. The file; order is preserved using the recently introduced index in TFileInfo.; In TProofOutputFile, add switch to control the way histograms; are merged by TFileMerger, i.e. one-by-one or all-in-one-go. The; default is one-by-one which requires much less memory. Merging in; one-go (the previous default) can be activated by passing 'H' in the; constructor options.; In ProofBench, add possibility to change the",MatchSource.DOCS,proof/doc/v534/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/proof/doc/v534/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:30,Availability,avail,available,30,". RooFit; New tutorial macros available. A set of seventeen new tutorial macros has been added to $ROOTSYS/tutorials/roofit. rf01_basics.C - Basic fitting, plotting and event generation; rf02_composite.C - How to construct composite p.d.fs (sig plus bkg etc); rf03_multidim.C - How to construct multi-dimensional p.d.f.s; rf04_composition.C - Using composition techniques to adjust p.d.f building blocks; rf05_conditional.C - Construction of productions with conditional p.d.f.s; rf06_convolution.C - Convolution of p.d.fs f(x) (X) g(x); rf07_bphysics.C - B physics p.d.f.s with analytical convolution; rf08_intminuit.C - Interactive MINUIT demonstration; rf09_constraints.C - How to specify and use parameter constraints in fits; rf10_ranges.C - Working with sub ranges in observables in fitting and plotting; rf11_plotbinning.C - Variable and other non-uniform binnign specifications; rf12_mcstudy.C - Managing toy Monte Carlo studie; rf13_wspacewrite.C - Creating and persisting workspaces; rf14_wspaceread.C - Reading and using workspaces; rf15_simwstool.C - Automated tools for building of simulateneous p.d.f.s; rf16_normandint.C - Normalization, integration and cumulative distribution functions (1d); rf16_normandint2d.C - Normalization, integration and cumulative distribution functions (1d); ; Update of class documentation; ; The documentation in the code itself that is extracted by THtml to construct; the online class documentation has been updated for all classes. Now all classes; have (again) a short class description, as well as a (short) description of each member function; and most data members. An update to the users manual is foreseen shortly after the 5.20; release. RooWorkspace. A new feature has been added that allows to persist source code of RooFit classes that; are not in ROOT distribution inside a RooWorkspace to facilitate sharing; of custom code with others. To import code of custom classes call. RooWorkspace::importClassCode(). after importing the objects them",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:4393,Availability,error,error,4393,""",-10,10) ; // variable with fixed range [-10,10] ; RooRealVar y(""y"",""y"",0,20) ; // variable with fixed range [-10,10] ; ; RooFormulaVar x_lo(""x_lo"",""y-20"",y) ; ; RooFormulaVar x_hi(""x_hi"",""sin(y)*5"",y) ; ; x.setRange(x_lo,x_hi) ; // Change x to have variable range depending on y; ; It is also possible to define parameterized named ranges in the same way. x.setRange(""signalRegion"",x_lo,x_hi) ;. There are no fundamental limits to the complexity of the parameterized ranges; that can be defined as long as the problem is uniquely defined. For example, given three observables ; x, y and z, one can define a parameterized named range 'R' of x in terms of y and of y in terms of z; and ask to calculate the three dimensional integral of any function or p.d.f in terms of (x,y,z); over that range 'R' and it will be calculated correctly, taking recursive range dependencies into; account. A definition of a range 'R' on the other hand where the bounds of x depend on y and; the bounds of y depend on x is not allowed, and an error message will be printed to complain about; the ambiguity of the problem definition. Integrals over non-rectangular regions are created the; same way as integrals over rectangular regions using the RooAbsReal::createIntegral() function, the; chosen mode of operation depends on the shape of the requestion integration range. Note that in general integration over non (hyper)rectangular regions will be more computationally; intensive as only a subset of the observables can be integrated analytically (all of those that do not; have parameterized ranges plus those that have parameterized ranges but are not involved in the; parameterization of others (e.g. x and y in the example above). Running integrals and Cumulative distribution functions. It is now possible to create running integrals from any RooAbsReal function and; to create cumulative distribution functions from any RooAbsPdf using the following; methods:. // Create int[xlo,x] f(x') dx' from f(x); RooAbsRe",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:6569,Availability,reliab,reliably,6569,"y) normalized over (x,y); RooAbsReal* cdf = pdf.createCdf(x,y) ;. ; As with the similarly styled function createIntegral running integrals and c.d.f. can be created; over any number of observables, e.g createCdf(RooArgSet(x,y,z)) will create a three-dimensional; cumulative distribution function. C.d.f and running integrals that are calculated from p.d.fs that have; support for analytical integration are constructed from an appropriately reconnected RooRealIntegral.; If numeric integration is required, the c.d.f or running integral is calculated by a dedicated class; RooRunningIntegral that precalculates results for all observable values, which is more efficient; in most use cases. Cumulative distributions functions that are calculated numerically are handled slightly differently; that standard running integrals: their values is constructed to converge to exactly zero at the lower bound; and exactly 1 at the upper bound so that algorithms that make use of that property of c.d.f can do so reliably. Constraints management. New tools have been added to simplify studies with fits involving (external) constraints on parameters.; The general philosophy is that constraints on parameters can be represented as probability density functions; and can thus be modeled by RooAbsPdf classes (e.g. a RooGaussian for a simple Gaussian constraint on a parameter).; There are two modes of operation: you can add parameter constraints to your problem definition by multiplying; the constraint p.d.f.s with your 'master' p.d.f. or you specify them externally in each operation. The; first mode of operation keeps all information in your master p.d.f and may make the logistics of non-trivial; fitting problems easier. It works as follows: first you define your regular p.d.f, then you define your; constraint p.d.f and you multiply them with RooProdPdf. // Construct constraint; RooGaussian fconstraint(""fconstraint"",""fconstraint"",f,RooConst(0.8),RooConst(0.1)) ;. // Multiply constraint with p.d.f; Ro",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:14988,Availability,error,error,14988," any input p.d.f specified in its constructor. . By default a p.d.f is sampled and cached in all observables in any; given use context, with no need to specify what those are in advance.; The internal code has also been changed such that all cache; histograms now store pre-normalized p.d.f, which is more efficient; than 'raw' p.d.f histograms that are explicitly post-normalized; through integration. Multiple different use cases (e.g. definitions; of what are observables vs parameters) can be cached; simultaneously. Now it is also possible to specify that p.d.f.s; should be sampled and cached in one or more parameter dimensions; in addition to the automatically determined set of observables.; as well. Also a complete new line of classes with similar functionality has been added inheriting from RooAbsReal.; These are RooAbsCachedReal,RooAbsSelfCachedReal and RooCachedReal. A newly; added class RooHistFunc presents these shapes and is capable of handling negative entries. New PDF error handling structure. New infrastructure has been put into place to propagate and process p.d.f evaluation errors during fitting.; Previously evaluation errors were marked with a zero p.d.f value and propagated as a special condition; in RooAddPdf, RooProdPdf etc to result in a zero top-level p.d.f value that was caught by the RooFit minuit; interface as a special condition. Summary information on the value of the parameters and the observables; was printed for the first 10 occurrences of such conditions. . Now, each p.d.f component that generates an error; in its evaluation logs the error into a separate facility during fitting and the RooFit minuit interface; polls this error logging facility for problems. This allows much more detailed and accurate warning messages; during the minimization phase. The level of verbosity of this new error facility can be controlled with; a new . PrintEvalErrors(Int_t code). argument to fitTo(). . With code of -1, no errors are printed at all.; With a; cod",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:15099,Availability,error,errors,15099,"s in any; given use context, with no need to specify what those are in advance.; The internal code has also been changed such that all cache; histograms now store pre-normalized p.d.f, which is more efficient; than 'raw' p.d.f histograms that are explicitly post-normalized; through integration. Multiple different use cases (e.g. definitions; of what are observables vs parameters) can be cached; simultaneously. Now it is also possible to specify that p.d.f.s; should be sampled and cached in one or more parameter dimensions; in addition to the automatically determined set of observables.; as well. Also a complete new line of classes with similar functionality has been added inheriting from RooAbsReal.; These are RooAbsCachedReal,RooAbsSelfCachedReal and RooCachedReal. A newly; added class RooHistFunc presents these shapes and is capable of handling negative entries. New PDF error handling structure. New infrastructure has been put into place to propagate and process p.d.f evaluation errors during fitting.; Previously evaluation errors were marked with a zero p.d.f value and propagated as a special condition; in RooAddPdf, RooProdPdf etc to result in a zero top-level p.d.f value that was caught by the RooFit minuit; interface as a special condition. Summary information on the value of the parameters and the observables; was printed for the first 10 occurrences of such conditions. . Now, each p.d.f component that generates an error; in its evaluation logs the error into a separate facility during fitting and the RooFit minuit interface; polls this error logging facility for problems. This allows much more detailed and accurate warning messages; during the minimization phase. The level of verbosity of this new error facility can be controlled with; a new . PrintEvalErrors(Int_t code). argument to fitTo(). . With code of -1, no errors are printed at all.; With a; code of zero, one line is printed for each p.d.f component with problems summarizing the number of times; probl",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:15145,Availability,error,errors,15145,"pecify what those are in advance.; The internal code has also been changed such that all cache; histograms now store pre-normalized p.d.f, which is more efficient; than 'raw' p.d.f histograms that are explicitly post-normalized; through integration. Multiple different use cases (e.g. definitions; of what are observables vs parameters) can be cached; simultaneously. Now it is also possible to specify that p.d.f.s; should be sampled and cached in one or more parameter dimensions; in addition to the automatically determined set of observables.; as well. Also a complete new line of classes with similar functionality has been added inheriting from RooAbsReal.; These are RooAbsCachedReal,RooAbsSelfCachedReal and RooCachedReal. A newly; added class RooHistFunc presents these shapes and is capable of handling negative entries. New PDF error handling structure. New infrastructure has been put into place to propagate and process p.d.f evaluation errors during fitting.; Previously evaluation errors were marked with a zero p.d.f value and propagated as a special condition; in RooAddPdf, RooProdPdf etc to result in a zero top-level p.d.f value that was caught by the RooFit minuit; interface as a special condition. Summary information on the value of the parameters and the observables; was printed for the first 10 occurrences of such conditions. . Now, each p.d.f component that generates an error; in its evaluation logs the error into a separate facility during fitting and the RooFit minuit interface; polls this error logging facility for problems. This allows much more detailed and accurate warning messages; during the minimization phase. The level of verbosity of this new error facility can be controlled with; a new . PrintEvalErrors(Int_t code). argument to fitTo(). . With code of -1, no errors are printed at all.; With a; code of zero, one line is printed for each p.d.f component with problems summarizing the number of times; problems occurred during the likelihood evaluation.",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:15549,Availability,error,error,15549,"meter dimensions; in addition to the automatically determined set of observables.; as well. Also a complete new line of classes with similar functionality has been added inheriting from RooAbsReal.; These are RooAbsCachedReal,RooAbsSelfCachedReal and RooCachedReal. A newly; added class RooHistFunc presents these shapes and is capable of handling negative entries. New PDF error handling structure. New infrastructure has been put into place to propagate and process p.d.f evaluation errors during fitting.; Previously evaluation errors were marked with a zero p.d.f value and propagated as a special condition; in RooAddPdf, RooProdPdf etc to result in a zero top-level p.d.f value that was caught by the RooFit minuit; interface as a special condition. Summary information on the value of the parameters and the observables; was printed for the first 10 occurrences of such conditions. . Now, each p.d.f component that generates an error; in its evaluation logs the error into a separate facility during fitting and the RooFit minuit interface; polls this error logging facility for problems. This allows much more detailed and accurate warning messages; during the minimization phase. The level of verbosity of this new error facility can be controlled with; a new . PrintEvalErrors(Int_t code). argument to fitTo(). . With code of -1, no errors are printed at all.; With a; code of zero, one line is printed for each p.d.f component with problems summarizing the number of times; problems occurred during the likelihood evaluation. . [#0] WARNING:Minization -- RooFitGlue: Minimized function has error status. ; Returning maximum FCN so far (-1e+30) to force MIGRAD to back out of this region. Error log follows; Parameter values: m=-7.397; RooGaussian::gx[ x=x mean=m sigma=sx ] has 3 errors. A code greater than zero will generate even more detail and; print the details of each evaluation error as provided by the p.d.f (zero value, not-a-number, normalization zero etc..); and show the obser",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:15583,Availability,error,error,15583,"meter dimensions; in addition to the automatically determined set of observables.; as well. Also a complete new line of classes with similar functionality has been added inheriting from RooAbsReal.; These are RooAbsCachedReal,RooAbsSelfCachedReal and RooCachedReal. A newly; added class RooHistFunc presents these shapes and is capable of handling negative entries. New PDF error handling structure. New infrastructure has been put into place to propagate and process p.d.f evaluation errors during fitting.; Previously evaluation errors were marked with a zero p.d.f value and propagated as a special condition; in RooAddPdf, RooProdPdf etc to result in a zero top-level p.d.f value that was caught by the RooFit minuit; interface as a special condition. Summary information on the value of the parameters and the observables; was printed for the first 10 occurrences of such conditions. . Now, each p.d.f component that generates an error; in its evaluation logs the error into a separate facility during fitting and the RooFit minuit interface; polls this error logging facility for problems. This allows much more detailed and accurate warning messages; during the minimization phase. The level of verbosity of this new error facility can be controlled with; a new . PrintEvalErrors(Int_t code). argument to fitTo(). . With code of -1, no errors are printed at all.; With a; code of zero, one line is printed for each p.d.f component with problems summarizing the number of times; problems occurred during the likelihood evaluation. . [#0] WARNING:Minization -- RooFitGlue: Minimized function has error status. ; Returning maximum FCN so far (-1e+30) to force MIGRAD to back out of this region. Error log follows; Parameter values: m=-7.397; RooGaussian::gx[ x=x mean=m sigma=sx ] has 3 errors. A code greater than zero will generate even more detail and; print the details of each evaluation error as provided by the p.d.f (zero value, not-a-number, normalization zero etc..); and show the obser",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:15673,Availability,error,error,15673,"meter dimensions; in addition to the automatically determined set of observables.; as well. Also a complete new line of classes with similar functionality has been added inheriting from RooAbsReal.; These are RooAbsCachedReal,RooAbsSelfCachedReal and RooCachedReal. A newly; added class RooHistFunc presents these shapes and is capable of handling negative entries. New PDF error handling structure. New infrastructure has been put into place to propagate and process p.d.f evaluation errors during fitting.; Previously evaluation errors were marked with a zero p.d.f value and propagated as a special condition; in RooAddPdf, RooProdPdf etc to result in a zero top-level p.d.f value that was caught by the RooFit minuit; interface as a special condition. Summary information on the value of the parameters and the observables; was printed for the first 10 occurrences of such conditions. . Now, each p.d.f component that generates an error; in its evaluation logs the error into a separate facility during fitting and the RooFit minuit interface; polls this error logging facility for problems. This allows much more detailed and accurate warning messages; during the minimization phase. The level of verbosity of this new error facility can be controlled with; a new . PrintEvalErrors(Int_t code). argument to fitTo(). . With code of -1, no errors are printed at all.; With a; code of zero, one line is printed for each p.d.f component with problems summarizing the number of times; problems occurred during the likelihood evaluation. . [#0] WARNING:Minization -- RooFitGlue: Minimized function has error status. ; Returning maximum FCN so far (-1e+30) to force MIGRAD to back out of this region. Error log follows; Parameter values: m=-7.397; RooGaussian::gx[ x=x mean=m sigma=sx ] has 3 errors. A code greater than zero will generate even more detail and; print the details of each evaluation error as provided by the p.d.f (zero value, not-a-number, normalization zero etc..); and show the obser",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:15838,Availability,error,error,15838,"AbsSelfCachedReal and RooCachedReal. A newly; added class RooHistFunc presents these shapes and is capable of handling negative entries. New PDF error handling structure. New infrastructure has been put into place to propagate and process p.d.f evaluation errors during fitting.; Previously evaluation errors were marked with a zero p.d.f value and propagated as a special condition; in RooAddPdf, RooProdPdf etc to result in a zero top-level p.d.f value that was caught by the RooFit minuit; interface as a special condition. Summary information on the value of the parameters and the observables; was printed for the first 10 occurrences of such conditions. . Now, each p.d.f component that generates an error; in its evaluation logs the error into a separate facility during fitting and the RooFit minuit interface; polls this error logging facility for problems. This allows much more detailed and accurate warning messages; during the minimization phase. The level of verbosity of this new error facility can be controlled with; a new . PrintEvalErrors(Int_t code). argument to fitTo(). . With code of -1, no errors are printed at all.; With a; code of zero, one line is printed for each p.d.f component with problems summarizing the number of times; problems occurred during the likelihood evaluation. . [#0] WARNING:Minization -- RooFitGlue: Minimized function has error status. ; Returning maximum FCN so far (-1e+30) to force MIGRAD to back out of this region. Error log follows; Parameter values: m=-7.397; RooGaussian::gx[ x=x mean=m sigma=sx ] has 3 errors. A code greater than zero will generate even more detail and; print the details of each evaluation error as provided by the p.d.f (zero value, not-a-number, normalization zero etc..); and show the observable values at which this error occurred. At most N detailed messages per p.d.f component; are shown where N is the integral value of the 'code' argument. . [#0] WARNING:Minization -- RooFitGlue: Minimized function has error sta",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:15957,Availability,error,errors,15957,"ng negative entries. New PDF error handling structure. New infrastructure has been put into place to propagate and process p.d.f evaluation errors during fitting.; Previously evaluation errors were marked with a zero p.d.f value and propagated as a special condition; in RooAddPdf, RooProdPdf etc to result in a zero top-level p.d.f value that was caught by the RooFit minuit; interface as a special condition. Summary information on the value of the parameters and the observables; was printed for the first 10 occurrences of such conditions. . Now, each p.d.f component that generates an error; in its evaluation logs the error into a separate facility during fitting and the RooFit minuit interface; polls this error logging facility for problems. This allows much more detailed and accurate warning messages; during the minimization phase. The level of verbosity of this new error facility can be controlled with; a new . PrintEvalErrors(Int_t code). argument to fitTo(). . With code of -1, no errors are printed at all.; With a; code of zero, one line is printed for each p.d.f component with problems summarizing the number of times; problems occurred during the likelihood evaluation. . [#0] WARNING:Minization -- RooFitGlue: Minimized function has error status. ; Returning maximum FCN so far (-1e+30) to force MIGRAD to back out of this region. Error log follows; Parameter values: m=-7.397; RooGaussian::gx[ x=x mean=m sigma=sx ] has 3 errors. A code greater than zero will generate even more detail and; print the details of each evaluation error as provided by the p.d.f (zero value, not-a-number, normalization zero etc..); and show the observable values at which this error occurred. At most N detailed messages per p.d.f component; are shown where N is the integral value of the 'code' argument. . [#0] WARNING:Minization -- RooFitGlue: Minimized function has error status.; Returning maximum FCN so far (-1e+30) to force MIGRAD to back out of this region. Error log follows; Parameter ",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:16215,Availability,error,error,16215,"d propagated as a special condition; in RooAddPdf, RooProdPdf etc to result in a zero top-level p.d.f value that was caught by the RooFit minuit; interface as a special condition. Summary information on the value of the parameters and the observables; was printed for the first 10 occurrences of such conditions. . Now, each p.d.f component that generates an error; in its evaluation logs the error into a separate facility during fitting and the RooFit minuit interface; polls this error logging facility for problems. This allows much more detailed and accurate warning messages; during the minimization phase. The level of verbosity of this new error facility can be controlled with; a new . PrintEvalErrors(Int_t code). argument to fitTo(). . With code of -1, no errors are printed at all.; With a; code of zero, one line is printed for each p.d.f component with problems summarizing the number of times; problems occurred during the likelihood evaluation. . [#0] WARNING:Minization -- RooFitGlue: Minimized function has error status. ; Returning maximum FCN so far (-1e+30) to force MIGRAD to back out of this region. Error log follows; Parameter values: m=-7.397; RooGaussian::gx[ x=x mean=m sigma=sx ] has 3 errors. A code greater than zero will generate even more detail and; print the details of each evaluation error as provided by the p.d.f (zero value, not-a-number, normalization zero etc..); and show the observable values at which this error occurred. At most N detailed messages per p.d.f component; are shown where N is the integral value of the 'code' argument. . [#0] WARNING:Minization -- RooFitGlue: Minimized function has error status.; Returning maximum FCN so far (-1e+30) to force MIGRAD to back out of this region. Error log follows; Parameter values: m=-7.397; RooGaussian::gx[ x=x mean=m sigma=sx ]; getLogVal() top-level p.d.f evaluates to zero or negative number @ x=x=9.09989, mean=m=-7.39713, sigma=sx=0.1; getLogVal() top-level p.d.f evaluates to zero or negative num",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:16405,Availability,error,errors,16405,"mation on the value of the parameters and the observables; was printed for the first 10 occurrences of such conditions. . Now, each p.d.f component that generates an error; in its evaluation logs the error into a separate facility during fitting and the RooFit minuit interface; polls this error logging facility for problems. This allows much more detailed and accurate warning messages; during the minimization phase. The level of verbosity of this new error facility can be controlled with; a new . PrintEvalErrors(Int_t code). argument to fitTo(). . With code of -1, no errors are printed at all.; With a; code of zero, one line is printed for each p.d.f component with problems summarizing the number of times; problems occurred during the likelihood evaluation. . [#0] WARNING:Minization -- RooFitGlue: Minimized function has error status. ; Returning maximum FCN so far (-1e+30) to force MIGRAD to back out of this region. Error log follows; Parameter values: m=-7.397; RooGaussian::gx[ x=x mean=m sigma=sx ] has 3 errors. A code greater than zero will generate even more detail and; print the details of each evaluation error as provided by the p.d.f (zero value, not-a-number, normalization zero etc..); and show the observable values at which this error occurred. At most N detailed messages per p.d.f component; are shown where N is the integral value of the 'code' argument. . [#0] WARNING:Minization -- RooFitGlue: Minimized function has error status.; Returning maximum FCN so far (-1e+30) to force MIGRAD to back out of this region. Error log follows; Parameter values: m=-7.397; RooGaussian::gx[ x=x mean=m sigma=sx ]; getLogVal() top-level p.d.f evaluates to zero or negative number @ x=x=9.09989, mean=m=-7.39713, sigma=sx=0.1; getLogVal() top-level p.d.f evaluates to zero or negative number @ x=x=6.04652, mean=m=-7.39713, sigma=sx=0.1; getLogVal() top-level p.d.f evaluates to zero or negative number @ x=x=2.48563, mean=m=-7.39713, sigma=sx=0.1. The new-style error logging is ac",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:16511,Availability,error,error,16511,"rrences of such conditions. . Now, each p.d.f component that generates an error; in its evaluation logs the error into a separate facility during fitting and the RooFit minuit interface; polls this error logging facility for problems. This allows much more detailed and accurate warning messages; during the minimization phase. The level of verbosity of this new error facility can be controlled with; a new . PrintEvalErrors(Int_t code). argument to fitTo(). . With code of -1, no errors are printed at all.; With a; code of zero, one line is printed for each p.d.f component with problems summarizing the number of times; problems occurred during the likelihood evaluation. . [#0] WARNING:Minization -- RooFitGlue: Minimized function has error status. ; Returning maximum FCN so far (-1e+30) to force MIGRAD to back out of this region. Error log follows; Parameter values: m=-7.397; RooGaussian::gx[ x=x mean=m sigma=sx ] has 3 errors. A code greater than zero will generate even more detail and; print the details of each evaluation error as provided by the p.d.f (zero value, not-a-number, normalization zero etc..); and show the observable values at which this error occurred. At most N detailed messages per p.d.f component; are shown where N is the integral value of the 'code' argument. . [#0] WARNING:Minization -- RooFitGlue: Minimized function has error status.; Returning maximum FCN so far (-1e+30) to force MIGRAD to back out of this region. Error log follows; Parameter values: m=-7.397; RooGaussian::gx[ x=x mean=m sigma=sx ]; getLogVal() top-level p.d.f evaluates to zero or negative number @ x=x=9.09989, mean=m=-7.39713, sigma=sx=0.1; getLogVal() top-level p.d.f evaluates to zero or negative number @ x=x=6.04652, mean=m=-7.39713, sigma=sx=0.1; getLogVal() top-level p.d.f evaluates to zero or negative number @ x=x=2.48563, mean=m=-7.39713, sigma=sx=0.1. The new-style error logging is active whenever MINUIT is operating on such a p.d.f. The default value for N is 3.; Outside t",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:16641,Availability,error,error,16641,"ting and the RooFit minuit interface; polls this error logging facility for problems. This allows much more detailed and accurate warning messages; during the minimization phase. The level of verbosity of this new error facility can be controlled with; a new . PrintEvalErrors(Int_t code). argument to fitTo(). . With code of -1, no errors are printed at all.; With a; code of zero, one line is printed for each p.d.f component with problems summarizing the number of times; problems occurred during the likelihood evaluation. . [#0] WARNING:Minization -- RooFitGlue: Minimized function has error status. ; Returning maximum FCN so far (-1e+30) to force MIGRAD to back out of this region. Error log follows; Parameter values: m=-7.397; RooGaussian::gx[ x=x mean=m sigma=sx ] has 3 errors. A code greater than zero will generate even more detail and; print the details of each evaluation error as provided by the p.d.f (zero value, not-a-number, normalization zero etc..); and show the observable values at which this error occurred. At most N detailed messages per p.d.f component; are shown where N is the integral value of the 'code' argument. . [#0] WARNING:Minization -- RooFitGlue: Minimized function has error status.; Returning maximum FCN so far (-1e+30) to force MIGRAD to back out of this region. Error log follows; Parameter values: m=-7.397; RooGaussian::gx[ x=x mean=m sigma=sx ]; getLogVal() top-level p.d.f evaluates to zero or negative number @ x=x=9.09989, mean=m=-7.39713, sigma=sx=0.1; getLogVal() top-level p.d.f evaluates to zero or negative number @ x=x=6.04652, mean=m=-7.39713, sigma=sx=0.1; getLogVal() top-level p.d.f evaluates to zero or negative number @ x=x=2.48563, mean=m=-7.39713, sigma=sx=0.1. The new-style error logging is active whenever MINUIT is operating on such a p.d.f. The default value for N is 3.; Outside the MINUIT context the evaluation error each evualuation error will generate a separate message through; RooMsgService; Other new features. The RooAddP",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:16834,Availability,error,error,16834,"vel of verbosity of this new error facility can be controlled with; a new . PrintEvalErrors(Int_t code). argument to fitTo(). . With code of -1, no errors are printed at all.; With a; code of zero, one line is printed for each p.d.f component with problems summarizing the number of times; problems occurred during the likelihood evaluation. . [#0] WARNING:Minization -- RooFitGlue: Minimized function has error status. ; Returning maximum FCN so far (-1e+30) to force MIGRAD to back out of this region. Error log follows; Parameter values: m=-7.397; RooGaussian::gx[ x=x mean=m sigma=sx ] has 3 errors. A code greater than zero will generate even more detail and; print the details of each evaluation error as provided by the p.d.f (zero value, not-a-number, normalization zero etc..); and show the observable values at which this error occurred. At most N detailed messages per p.d.f component; are shown where N is the integral value of the 'code' argument. . [#0] WARNING:Minization -- RooFitGlue: Minimized function has error status.; Returning maximum FCN so far (-1e+30) to force MIGRAD to back out of this region. Error log follows; Parameter values: m=-7.397; RooGaussian::gx[ x=x mean=m sigma=sx ]; getLogVal() top-level p.d.f evaluates to zero or negative number @ x=x=9.09989, mean=m=-7.39713, sigma=sx=0.1; getLogVal() top-level p.d.f evaluates to zero or negative number @ x=x=6.04652, mean=m=-7.39713, sigma=sx=0.1; getLogVal() top-level p.d.f evaluates to zero or negative number @ x=x=2.48563, mean=m=-7.39713, sigma=sx=0.1. The new-style error logging is active whenever MINUIT is operating on such a p.d.f. The default value for N is 3.; Outside the MINUIT context the evaluation error each evualuation error will generate a separate message through; RooMsgService; Other new features. The RooAddPdf constructor has been augmented with an additional boolean argument that allows to; interpret the supplied fraction parameters as recursive fractions rather than plain fractions.; If",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:17365,Availability,error,error,17365,"gma=sx ] has 3 errors. A code greater than zero will generate even more detail and; print the details of each evaluation error as provided by the p.d.f (zero value, not-a-number, normalization zero etc..); and show the observable values at which this error occurred. At most N detailed messages per p.d.f component; are shown where N is the integral value of the 'code' argument. . [#0] WARNING:Minization -- RooFitGlue: Minimized function has error status.; Returning maximum FCN so far (-1e+30) to force MIGRAD to back out of this region. Error log follows; Parameter values: m=-7.397; RooGaussian::gx[ x=x mean=m sigma=sx ]; getLogVal() top-level p.d.f evaluates to zero or negative number @ x=x=9.09989, mean=m=-7.39713, sigma=sx=0.1; getLogVal() top-level p.d.f evaluates to zero or negative number @ x=x=6.04652, mean=m=-7.39713, sigma=sx=0.1; getLogVal() top-level p.d.f evaluates to zero or negative number @ x=x=2.48563, mean=m=-7.39713, sigma=sx=0.1. The new-style error logging is active whenever MINUIT is operating on such a p.d.f. The default value for N is 3.; Outside the MINUIT context the evaluation error each evualuation error will generate a separate message through; RooMsgService; Other new features. The RooAddPdf constructor has been augmented with an additional boolean argument that allows to; interpret the supplied fraction parameters as recursive fractions rather than plain fractions.; If activated, an example RooAddPdf with three input p.d.f. A,B,C and two fractions fA and fB will; result in the expression; fA*A + (1-fA)(fB*B + 1-fB*C) rather than fA*A + fB*B + (1-fA-fB)*C. Recursive fraction have the advantage that all fraction can be defined to be in the range [0-1]; without resulting in configuration where the sum of all fractions exceeds 1.; The low-level object printing interface printToStream() has been deprecated in favor of a new; printStream() method which allows much greater control over the information printed. ; The printing of almost all RooFit",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:17508,Availability,error,error,17508,"d.f (zero value, not-a-number, normalization zero etc..); and show the observable values at which this error occurred. At most N detailed messages per p.d.f component; are shown where N is the integral value of the 'code' argument. . [#0] WARNING:Minization -- RooFitGlue: Minimized function has error status.; Returning maximum FCN so far (-1e+30) to force MIGRAD to back out of this region. Error log follows; Parameter values: m=-7.397; RooGaussian::gx[ x=x mean=m sigma=sx ]; getLogVal() top-level p.d.f evaluates to zero or negative number @ x=x=9.09989, mean=m=-7.39713, sigma=sx=0.1; getLogVal() top-level p.d.f evaluates to zero or negative number @ x=x=6.04652, mean=m=-7.39713, sigma=sx=0.1; getLogVal() top-level p.d.f evaluates to zero or negative number @ x=x=2.48563, mean=m=-7.39713, sigma=sx=0.1. The new-style error logging is active whenever MINUIT is operating on such a p.d.f. The default value for N is 3.; Outside the MINUIT context the evaluation error each evualuation error will generate a separate message through; RooMsgService; Other new features. The RooAddPdf constructor has been augmented with an additional boolean argument that allows to; interpret the supplied fraction parameters as recursive fractions rather than plain fractions.; If activated, an example RooAddPdf with three input p.d.f. A,B,C and two fractions fA and fB will; result in the expression; fA*A + (1-fA)(fB*B + 1-fB*C) rather than fA*A + fB*B + (1-fA-fB)*C. Recursive fraction have the advantage that all fraction can be defined to be in the range [0-1]; without resulting in configuration where the sum of all fractions exceeds 1.; The low-level object printing interface printToStream() has been deprecated in favor of a new; printStream() method which allows much greater control over the information printed. ; The printing of almost all RooFit objects has been reworked to present a more uniform look and feel.; The standard one-line result of the high-level Print() method without option now",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:17531,Availability,error,error,17531,"d.f (zero value, not-a-number, normalization zero etc..); and show the observable values at which this error occurred. At most N detailed messages per p.d.f component; are shown where N is the integral value of the 'code' argument. . [#0] WARNING:Minization -- RooFitGlue: Minimized function has error status.; Returning maximum FCN so far (-1e+30) to force MIGRAD to back out of this region. Error log follows; Parameter values: m=-7.397; RooGaussian::gx[ x=x mean=m sigma=sx ]; getLogVal() top-level p.d.f evaluates to zero or negative number @ x=x=9.09989, mean=m=-7.39713, sigma=sx=0.1; getLogVal() top-level p.d.f evaluates to zero or negative number @ x=x=6.04652, mean=m=-7.39713, sigma=sx=0.1; getLogVal() top-level p.d.f evaluates to zero or negative number @ x=x=2.48563, mean=m=-7.39713, sigma=sx=0.1. The new-style error logging is active whenever MINUIT is operating on such a p.d.f. The default value for N is 3.; Outside the MINUIT context the evaluation error each evualuation error will generate a separate message through; RooMsgService; Other new features. The RooAddPdf constructor has been augmented with an additional boolean argument that allows to; interpret the supplied fraction parameters as recursive fractions rather than plain fractions.; If activated, an example RooAddPdf with three input p.d.f. A,B,C and two fractions fA and fB will; result in the expression; fA*A + (1-fA)(fB*B + 1-fB*C) rather than fA*A + fB*B + (1-fA-fB)*C. Recursive fraction have the advantage that all fraction can be defined to be in the range [0-1]; without resulting in configuration where the sum of all fractions exceeds 1.; The low-level object printing interface printToStream() has been deprecated in favor of a new; printStream() method which allows much greater control over the information printed. ; The printing of almost all RooFit objects has been reworked to present a more uniform look and feel.; The standard one-line result of the high-level Print() method without option now",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:1153,Deployability,integrat,integration,1153,"ation; rf02_composite.C - How to construct composite p.d.fs (sig plus bkg etc); rf03_multidim.C - How to construct multi-dimensional p.d.f.s; rf04_composition.C - Using composition techniques to adjust p.d.f building blocks; rf05_conditional.C - Construction of productions with conditional p.d.f.s; rf06_convolution.C - Convolution of p.d.fs f(x) (X) g(x); rf07_bphysics.C - B physics p.d.f.s with analytical convolution; rf08_intminuit.C - Interactive MINUIT demonstration; rf09_constraints.C - How to specify and use parameter constraints in fits; rf10_ranges.C - Working with sub ranges in observables in fitting and plotting; rf11_plotbinning.C - Variable and other non-uniform binnign specifications; rf12_mcstudy.C - Managing toy Monte Carlo studie; rf13_wspacewrite.C - Creating and persisting workspaces; rf14_wspaceread.C - Reading and using workspaces; rf15_simwstool.C - Automated tools for building of simulateneous p.d.f.s; rf16_normandint.C - Normalization, integration and cumulative distribution functions (1d); rf16_normandint2d.C - Normalization, integration and cumulative distribution functions (1d); ; Update of class documentation; ; The documentation in the code itself that is extracted by THtml to construct; the online class documentation has been updated for all classes. Now all classes; have (again) a short class description, as well as a (short) description of each member function; and most data members. An update to the users manual is foreseen shortly after the 5.20; release. RooWorkspace. A new feature has been added that allows to persist source code of RooFit classes that; are not in ROOT distribution inside a RooWorkspace to facilitate sharing; of custom code with others. To import code of custom classes call. RooWorkspace::importClassCode(). after importing the objects themselves into the workspace. For all classes; that are compiled with ACliC RooWorkspace can automatically find the source; code using the ROOT TClass interface. For custom classes th",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:1246,Deployability,integrat,integration,1246,"osition techniques to adjust p.d.f building blocks; rf05_conditional.C - Construction of productions with conditional p.d.f.s; rf06_convolution.C - Convolution of p.d.fs f(x) (X) g(x); rf07_bphysics.C - B physics p.d.f.s with analytical convolution; rf08_intminuit.C - Interactive MINUIT demonstration; rf09_constraints.C - How to specify and use parameter constraints in fits; rf10_ranges.C - Working with sub ranges in observables in fitting and plotting; rf11_plotbinning.C - Variable and other non-uniform binnign specifications; rf12_mcstudy.C - Managing toy Monte Carlo studie; rf13_wspacewrite.C - Creating and persisting workspaces; rf14_wspaceread.C - Reading and using workspaces; rf15_simwstool.C - Automated tools for building of simulateneous p.d.f.s; rf16_normandint.C - Normalization, integration and cumulative distribution functions (1d); rf16_normandint2d.C - Normalization, integration and cumulative distribution functions (1d); ; Update of class documentation; ; The documentation in the code itself that is extracted by THtml to construct; the online class documentation has been updated for all classes. Now all classes; have (again) a short class description, as well as a (short) description of each member function; and most data members. An update to the users manual is foreseen shortly after the 5.20; release. RooWorkspace. A new feature has been added that allows to persist source code of RooFit classes that; are not in ROOT distribution inside a RooWorkspace to facilitate sharing; of custom code with others. To import code of custom classes call. RooWorkspace::importClassCode(). after importing the objects themselves into the workspace. For all classes; that are compiled with ACliC RooWorkspace can automatically find the source; code using the ROOT TClass interface. For custom classes that are compiled; externally and loaded into ROOT as shared library it might be necessary to; provide the location of the source files manually using the static RooWorkspace",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:1455,Deployability,update,updated,1455,"osition techniques to adjust p.d.f building blocks; rf05_conditional.C - Construction of productions with conditional p.d.f.s; rf06_convolution.C - Convolution of p.d.fs f(x) (X) g(x); rf07_bphysics.C - B physics p.d.f.s with analytical convolution; rf08_intminuit.C - Interactive MINUIT demonstration; rf09_constraints.C - How to specify and use parameter constraints in fits; rf10_ranges.C - Working with sub ranges in observables in fitting and plotting; rf11_plotbinning.C - Variable and other non-uniform binnign specifications; rf12_mcstudy.C - Managing toy Monte Carlo studie; rf13_wspacewrite.C - Creating and persisting workspaces; rf14_wspaceread.C - Reading and using workspaces; rf15_simwstool.C - Automated tools for building of simulateneous p.d.f.s; rf16_normandint.C - Normalization, integration and cumulative distribution functions (1d); rf16_normandint2d.C - Normalization, integration and cumulative distribution functions (1d); ; Update of class documentation; ; The documentation in the code itself that is extracted by THtml to construct; the online class documentation has been updated for all classes. Now all classes; have (again) a short class description, as well as a (short) description of each member function; and most data members. An update to the users manual is foreseen shortly after the 5.20; release. RooWorkspace. A new feature has been added that allows to persist source code of RooFit classes that; are not in ROOT distribution inside a RooWorkspace to facilitate sharing; of custom code with others. To import code of custom classes call. RooWorkspace::importClassCode(). after importing the objects themselves into the workspace. For all classes; that are compiled with ACliC RooWorkspace can automatically find the source; code using the ROOT TClass interface. For custom classes that are compiled; externally and loaded into ROOT as shared library it might be necessary to; provide the location of the source files manually using the static RooWorkspace",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:1621,Deployability,update,update,1621,"ration; rf09_constraints.C - How to specify and use parameter constraints in fits; rf10_ranges.C - Working with sub ranges in observables in fitting and plotting; rf11_plotbinning.C - Variable and other non-uniform binnign specifications; rf12_mcstudy.C - Managing toy Monte Carlo studie; rf13_wspacewrite.C - Creating and persisting workspaces; rf14_wspaceread.C - Reading and using workspaces; rf15_simwstool.C - Automated tools for building of simulateneous p.d.f.s; rf16_normandint.C - Normalization, integration and cumulative distribution functions (1d); rf16_normandint2d.C - Normalization, integration and cumulative distribution functions (1d); ; Update of class documentation; ; The documentation in the code itself that is extracted by THtml to construct; the online class documentation has been updated for all classes. Now all classes; have (again) a short class description, as well as a (short) description of each member function; and most data members. An update to the users manual is foreseen shortly after the 5.20; release. RooWorkspace. A new feature has been added that allows to persist source code of RooFit classes that; are not in ROOT distribution inside a RooWorkspace to facilitate sharing; of custom code with others. To import code of custom classes call. RooWorkspace::importClassCode(). after importing the objects themselves into the workspace. For all classes; that are compiled with ACliC RooWorkspace can automatically find the source; code using the ROOT TClass interface. For custom classes that are compiled; externally and loaded into ROOT as shared library it might be necessary to; provide the location of the source files manually using the static RooWorkspace; member functions addClassDeclImportDir() and addClassImplImportDir().; ; When a TFile with a RooWorkspace containing source code is opened in a ROOT; session that does not have the class code already loaded for the classes; contained in the workspace, the code in the workspace is written to fi",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:1684,Deployability,release,release,1684,"ecify and use parameter constraints in fits; rf10_ranges.C - Working with sub ranges in observables in fitting and plotting; rf11_plotbinning.C - Variable and other non-uniform binnign specifications; rf12_mcstudy.C - Managing toy Monte Carlo studie; rf13_wspacewrite.C - Creating and persisting workspaces; rf14_wspaceread.C - Reading and using workspaces; rf15_simwstool.C - Automated tools for building of simulateneous p.d.f.s; rf16_normandint.C - Normalization, integration and cumulative distribution functions (1d); rf16_normandint2d.C - Normalization, integration and cumulative distribution functions (1d); ; Update of class documentation; ; The documentation in the code itself that is extracted by THtml to construct; the online class documentation has been updated for all classes. Now all classes; have (again) a short class description, as well as a (short) description of each member function; and most data members. An update to the users manual is foreseen shortly after the 5.20; release. RooWorkspace. A new feature has been added that allows to persist source code of RooFit classes that; are not in ROOT distribution inside a RooWorkspace to facilitate sharing; of custom code with others. To import code of custom classes call. RooWorkspace::importClassCode(). after importing the objects themselves into the workspace. For all classes; that are compiled with ACliC RooWorkspace can automatically find the source; code using the ROOT TClass interface. For custom classes that are compiled; externally and loaded into ROOT as shared library it might be necessary to; provide the location of the source files manually using the static RooWorkspace; member functions addClassDeclImportDir() and addClassImplImportDir().; ; When a TFile with a RooWorkspace containing source code is opened in a ROOT; session that does not have the class code already loaded for the classes; contained in the workspace, the code in the workspace is written to file,; compiled and loaded into the ROO",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:4704,Deployability,integrat,integration,4704," Change x to have variable range depending on y; ; It is also possible to define parameterized named ranges in the same way. x.setRange(""signalRegion"",x_lo,x_hi) ;. There are no fundamental limits to the complexity of the parameterized ranges; that can be defined as long as the problem is uniquely defined. For example, given three observables ; x, y and z, one can define a parameterized named range 'R' of x in terms of y and of y in terms of z; and ask to calculate the three dimensional integral of any function or p.d.f in terms of (x,y,z); over that range 'R' and it will be calculated correctly, taking recursive range dependencies into; account. A definition of a range 'R' on the other hand where the bounds of x depend on y and; the bounds of y depend on x is not allowed, and an error message will be printed to complain about; the ambiguity of the problem definition. Integrals over non-rectangular regions are created the; same way as integrals over rectangular regions using the RooAbsReal::createIntegral() function, the; chosen mode of operation depends on the shape of the requestion integration range. Note that in general integration over non (hyper)rectangular regions will be more computationally; intensive as only a subset of the observables can be integrated analytically (all of those that do not; have parameterized ranges plus those that have parameterized ranges but are not involved in the; parameterization of others (e.g. x and y in the example above). Running integrals and Cumulative distribution functions. It is now possible to create running integrals from any RooAbsReal function and; to create cumulative distribution functions from any RooAbsPdf using the following; methods:. // Create int[xlo,x] f(x') dx' from f(x); RooAbsReal* runInt = func.createRunningIntegral(x) ;. // Create int[xlo,x] f(x') dx' from p.d.f f(x) normalized over x; RooAbsReal* cdf = pdf.createCdf(x) ;. // Create int[xlo,x] f(x',y) dx' from p.d.f f(x,y) normalized over (x,y); RooAbsRea",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:4744,Deployability,integrat,integration,4744,"m is uniquely defined. For example, given three observables ; x, y and z, one can define a parameterized named range 'R' of x in terms of y and of y in terms of z; and ask to calculate the three dimensional integral of any function or p.d.f in terms of (x,y,z); over that range 'R' and it will be calculated correctly, taking recursive range dependencies into; account. A definition of a range 'R' on the other hand where the bounds of x depend on y and; the bounds of y depend on x is not allowed, and an error message will be printed to complain about; the ambiguity of the problem definition. Integrals over non-rectangular regions are created the; same way as integrals over rectangular regions using the RooAbsReal::createIntegral() function, the; chosen mode of operation depends on the shape of the requestion integration range. Note that in general integration over non (hyper)rectangular regions will be more computationally; intensive as only a subset of the observables can be integrated analytically (all of those that do not; have parameterized ranges plus those that have parameterized ranges but are not involved in the; parameterization of others (e.g. x and y in the example above). Running integrals and Cumulative distribution functions. It is now possible to create running integrals from any RooAbsReal function and; to create cumulative distribution functions from any RooAbsPdf using the following; methods:. // Create int[xlo,x] f(x') dx' from f(x); RooAbsReal* runInt = func.createRunningIntegral(x) ;. // Create int[xlo,x] f(x') dx' from p.d.f f(x) normalized over x; RooAbsReal* cdf = pdf.createCdf(x) ;. // Create int[xlo,x] f(x',y) dx' from p.d.f f(x,y) normalized over (x,y); RooAbsReal* cdf = pdf.createCdf(x,y) ;. ; As with the similarly styled function createIntegral running integrals and c.d.f. can be created; over any number of observables, e.g createCdf(RooArgSet(x,y,z)) will create a three-dimensional; cumulative distribution function. C.d.f and running integr",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:4875,Deployability,integrat,integrated,4875,"m is uniquely defined. For example, given three observables ; x, y and z, one can define a parameterized named range 'R' of x in terms of y and of y in terms of z; and ask to calculate the three dimensional integral of any function or p.d.f in terms of (x,y,z); over that range 'R' and it will be calculated correctly, taking recursive range dependencies into; account. A definition of a range 'R' on the other hand where the bounds of x depend on y and; the bounds of y depend on x is not allowed, and an error message will be printed to complain about; the ambiguity of the problem definition. Integrals over non-rectangular regions are created the; same way as integrals over rectangular regions using the RooAbsReal::createIntegral() function, the; chosen mode of operation depends on the shape of the requestion integration range. Note that in general integration over non (hyper)rectangular regions will be more computationally; intensive as only a subset of the observables can be integrated analytically (all of those that do not; have parameterized ranges plus those that have parameterized ranges but are not involved in the; parameterization of others (e.g. x and y in the example above). Running integrals and Cumulative distribution functions. It is now possible to create running integrals from any RooAbsReal function and; to create cumulative distribution functions from any RooAbsPdf using the following; methods:. // Create int[xlo,x] f(x') dx' from f(x); RooAbsReal* runInt = func.createRunningIntegral(x) ;. // Create int[xlo,x] f(x') dx' from p.d.f f(x) normalized over x; RooAbsReal* cdf = pdf.createCdf(x) ;. // Create int[xlo,x] f(x',y) dx' from p.d.f f(x,y) normalized over (x,y); RooAbsReal* cdf = pdf.createCdf(x,y) ;. ; As with the similarly styled function createIntegral running integrals and c.d.f. can be created; over any number of observables, e.g createCdf(RooArgSet(x,y,z)) will create a three-dimensional; cumulative distribution function. C.d.f and running integr",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:5958,Deployability,integrat,integration,5958,"eterized ranges but are not involved in the; parameterization of others (e.g. x and y in the example above). Running integrals and Cumulative distribution functions. It is now possible to create running integrals from any RooAbsReal function and; to create cumulative distribution functions from any RooAbsPdf using the following; methods:. // Create int[xlo,x] f(x') dx' from f(x); RooAbsReal* runInt = func.createRunningIntegral(x) ;. // Create int[xlo,x] f(x') dx' from p.d.f f(x) normalized over x; RooAbsReal* cdf = pdf.createCdf(x) ;. // Create int[xlo,x] f(x',y) dx' from p.d.f f(x,y) normalized over (x,y); RooAbsReal* cdf = pdf.createCdf(x,y) ;. ; As with the similarly styled function createIntegral running integrals and c.d.f. can be created; over any number of observables, e.g createCdf(RooArgSet(x,y,z)) will create a three-dimensional; cumulative distribution function. C.d.f and running integrals that are calculated from p.d.fs that have; support for analytical integration are constructed from an appropriately reconnected RooRealIntegral.; If numeric integration is required, the c.d.f or running integral is calculated by a dedicated class; RooRunningIntegral that precalculates results for all observable values, which is more efficient; in most use cases. Cumulative distributions functions that are calculated numerically are handled slightly differently; that standard running integrals: their values is constructed to converge to exactly zero at the lower bound; and exactly 1 at the upper bound so that algorithms that make use of that property of c.d.f can do so reliably. Constraints management. New tools have been added to simplify studies with fits involving (external) constraints on parameters.; The general philosophy is that constraints on parameters can be represented as probability density functions; and can thus be modeled by RooAbsPdf classes (e.g. a RooGaussian for a simple Gaussian constraint on a parameter).; There are two modes of operation: you can add",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:6049,Deployability,integrat,integration,6049,"and y in the example above). Running integrals and Cumulative distribution functions. It is now possible to create running integrals from any RooAbsReal function and; to create cumulative distribution functions from any RooAbsPdf using the following; methods:. // Create int[xlo,x] f(x') dx' from f(x); RooAbsReal* runInt = func.createRunningIntegral(x) ;. // Create int[xlo,x] f(x') dx' from p.d.f f(x) normalized over x; RooAbsReal* cdf = pdf.createCdf(x) ;. // Create int[xlo,x] f(x',y) dx' from p.d.f f(x,y) normalized over (x,y); RooAbsReal* cdf = pdf.createCdf(x,y) ;. ; As with the similarly styled function createIntegral running integrals and c.d.f. can be created; over any number of observables, e.g createCdf(RooArgSet(x,y,z)) will create a three-dimensional; cumulative distribution function. C.d.f and running integrals that are calculated from p.d.fs that have; support for analytical integration are constructed from an appropriately reconnected RooRealIntegral.; If numeric integration is required, the c.d.f or running integral is calculated by a dedicated class; RooRunningIntegral that precalculates results for all observable values, which is more efficient; in most use cases. Cumulative distributions functions that are calculated numerically are handled slightly differently; that standard running integrals: their values is constructed to converge to exactly zero at the lower bound; and exactly 1 at the upper bound so that algorithms that make use of that property of c.d.f can do so reliably. Constraints management. New tools have been added to simplify studies with fits involving (external) constraints on parameters.; The general philosophy is that constraints on parameters can be represented as probability density functions; and can thus be modeled by RooAbsPdf classes (e.g. a RooGaussian for a simple Gaussian constraint on a parameter).; There are two modes of operation: you can add parameter constraints to your problem definition by multiplying; the constrain",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:9815,Deployability,continuous,continuous,9815,"constrained parameter from the joint constraints; p.d.f and it will then generate the observables for that experiment with the thus obtained parameter values.; In this mode of operation the parameter values for each toy may thus be different. The actual parameter; for each toy can be obtained with the newly added RooMCStudy::genParDataSet() member function. The calculation; of the pull values for each parameter has been modified accordingly. Alternatively, it is possible to specify constraints to both RooAbsPdf::fitTo() and the RooMCStudy constructor; using the ExternalConstraint() named argument to supply constraint p.d.f.s that are not part of the 'master'; p.d.f but rather an ad-hoc supplied external constraint. The argument supplied to ExternalConstraint() should; be (a set of) constraint p.d.f(s), rather than (a set of) parameters for which internal constraint p.d.f.s should; be picked up. New operator class RooLinearMorph. A new numeric operator class RooLinearMorph has been added that provides a continuous; transformation between two p.d.f.s shapes in terms of a linear parameter alpha. The algorithm ; for histograms is described in the paper by Alex Read in NUM A 425 (1999) 357-369 ; 'Linear interpolation of histograms'. The implementation in RooLinearMorph is for; continuous functions. . // Observable and sampling binning to be used by RooLinearMorph (""cache""); RooRealVar x(""x"",""x"",-20,20) ;; x.setBins(1000,""cache"") ;. // End point shapes : a gaussian on one end, a polynomial on the other; RooGaussian f1(""f1"",""f1"",x,RooConst(-10),RooConst(2)) ;; RooPolynomial f2(""f2"",""f2"",x,RooArgSet(RooConst(-0.03),RooConst(-0.001))) ;. // Interpolation parameter: rlm=f1 at alpha=0, rlm=f2 at alpha=1; RooRealVar alpha(""alpha"",""alpha"",0,1.0) ;; RooLinearMorph rlm(""rlm"",""rlm"",g1,g2,x,alpha) ;. // Plot halfway shape; alpha=0.5; RooPlot* frame = x.frame() ;; rlm.plotOn(frame) ;. In short the algorithm works as follows: for both f1(x) and f2(x), the cumulative distribution; funct",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:10090,Deployability,continuous,continuous,10090,"n be obtained with the newly added RooMCStudy::genParDataSet() member function. The calculation; of the pull values for each parameter has been modified accordingly. Alternatively, it is possible to specify constraints to both RooAbsPdf::fitTo() and the RooMCStudy constructor; using the ExternalConstraint() named argument to supply constraint p.d.f.s that are not part of the 'master'; p.d.f but rather an ad-hoc supplied external constraint. The argument supplied to ExternalConstraint() should; be (a set of) constraint p.d.f(s), rather than (a set of) parameters for which internal constraint p.d.f.s should; be picked up. New operator class RooLinearMorph. A new numeric operator class RooLinearMorph has been added that provides a continuous; transformation between two p.d.f.s shapes in terms of a linear parameter alpha. The algorithm ; for histograms is described in the paper by Alex Read in NUM A 425 (1999) 357-369 ; 'Linear interpolation of histograms'. The implementation in RooLinearMorph is for; continuous functions. . // Observable and sampling binning to be used by RooLinearMorph (""cache""); RooRealVar x(""x"",""x"",-20,20) ;; x.setBins(1000,""cache"") ;. // End point shapes : a gaussian on one end, a polynomial on the other; RooGaussian f1(""f1"",""f1"",x,RooConst(-10),RooConst(2)) ;; RooPolynomial f2(""f2"",""f2"",x,RooArgSet(RooConst(-0.03),RooConst(-0.001))) ;. // Interpolation parameter: rlm=f1 at alpha=0, rlm=f2 at alpha=1; RooRealVar alpha(""alpha"",""alpha"",0,1.0) ;; RooLinearMorph rlm(""rlm"",""rlm"",g1,g2,x,alpha) ;. // Plot halfway shape; alpha=0.5; RooPlot* frame = x.frame() ;; rlm.plotOn(frame) ;. In short the algorithm works as follows: for both f1(x) and f2(x), the cumulative distribution; functions F1(x) and F2(x) are calculated. One finds takes a value 'y' of both c.d.fs and ; determines the corresponding x values x1,x2 at which F1(x1)=F2(x2)=y. The value of the interpolated ; p.d.f fbar(x) is then calculated as fbar(alpha*x1+(1-alpha)*x2) = f1(x1)*f2(x2) / ( alpha*f2",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:14386,Deployability,integrat,integration,14386,"Additional; functionality exists to work with multiple prototype p.d.f.s simultaneously. ; Improved infrastructure for caching p.d.f and functions. The infrastructure that exists for caching p.d.f.s, i.e. p.d.f that precalculate their value; for all observable values at one and cache those in a histogram that is returned as p.d.f shape; (with optional interpolation), has been expanded. This infrastructure comprises RooAbsCached; the base class for all caching p.d.fs, RooAbsSelfCachedPdf a base class for end-user; caching p.d.f implementations that simply cache the result of evaluate() and RooCachedPdf; that can wrap and cache any input p.d.f specified in its constructor. . By default a p.d.f is sampled and cached in all observables in any; given use context, with no need to specify what those are in advance.; The internal code has also been changed such that all cache; histograms now store pre-normalized p.d.f, which is more efficient; than 'raw' p.d.f histograms that are explicitly post-normalized; through integration. Multiple different use cases (e.g. definitions; of what are observables vs parameters) can be cached; simultaneously. Now it is also possible to specify that p.d.f.s; should be sampled and cached in one or more parameter dimensions; in addition to the automatically determined set of observables.; as well. Also a complete new line of classes with similar functionality has been added inheriting from RooAbsReal.; These are RooAbsCachedReal,RooAbsSelfCachedReal and RooCachedReal. A newly; added class RooHistFunc presents these shapes and is capable of handling negative entries. New PDF error handling structure. New infrastructure has been put into place to propagate and process p.d.f evaluation errors during fitting.; Previously evaluation errors were marked with a zero p.d.f value and propagated as a special condition; in RooAddPdf, RooProdPdf etc to result in a zero top-level p.d.f value that was caught by the RooFit minuit; interface as a special cond",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:18118,Deployability,configurat,configuration,18118,"=x=9.09989, mean=m=-7.39713, sigma=sx=0.1; getLogVal() top-level p.d.f evaluates to zero or negative number @ x=x=6.04652, mean=m=-7.39713, sigma=sx=0.1; getLogVal() top-level p.d.f evaluates to zero or negative number @ x=x=2.48563, mean=m=-7.39713, sigma=sx=0.1. The new-style error logging is active whenever MINUIT is operating on such a p.d.f. The default value for N is 3.; Outside the MINUIT context the evaluation error each evualuation error will generate a separate message through; RooMsgService; Other new features. The RooAddPdf constructor has been augmented with an additional boolean argument that allows to; interpret the supplied fraction parameters as recursive fractions rather than plain fractions.; If activated, an example RooAddPdf with three input p.d.f. A,B,C and two fractions fA and fB will; result in the expression; fA*A + (1-fA)(fB*B + 1-fB*C) rather than fA*A + fB*B + (1-fA-fB)*C. Recursive fraction have the advantage that all fraction can be defined to be in the range [0-1]; without resulting in configuration where the sum of all fractions exceeds 1.; The low-level object printing interface printToStream() has been deprecated in favor of a new; printStream() method which allows much greater control over the information printed. ; The printing of almost all RooFit objects has been reworked to present a more uniform look and feel.; The standard one-line result of the high-level Print() method without option now looks like. // Variable; x.Print() ;; RooRealVar::x = 0 L(-10 - 10) . // Function or p.d.f; gx.Print() ;; RooGaussian::gx[ x=x mean=m sigma=sx ] = 1. // Dataset; d.Print() ;; RooDataSet::gData[x,y] = 1000 entries. // RooPlot; frame.Print() ;; framex[x] = (RooHist::h_gData,RooCurve::g_Int[y]_Norm[x,y]_Comp[g]). Inside class RooPlot the default name of contained curves and histograms has been ; reworked in something more self descriptive as is shown in the above example. A usual,; a user supplied name can always be set by supplying the Name(c",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:6227,Energy Efficiency,efficient,efficient,6227,"ate running integrals from any RooAbsReal function and; to create cumulative distribution functions from any RooAbsPdf using the following; methods:. // Create int[xlo,x] f(x') dx' from f(x); RooAbsReal* runInt = func.createRunningIntegral(x) ;. // Create int[xlo,x] f(x') dx' from p.d.f f(x) normalized over x; RooAbsReal* cdf = pdf.createCdf(x) ;. // Create int[xlo,x] f(x',y) dx' from p.d.f f(x,y) normalized over (x,y); RooAbsReal* cdf = pdf.createCdf(x,y) ;. ; As with the similarly styled function createIntegral running integrals and c.d.f. can be created; over any number of observables, e.g createCdf(RooArgSet(x,y,z)) will create a three-dimensional; cumulative distribution function. C.d.f and running integrals that are calculated from p.d.fs that have; support for analytical integration are constructed from an appropriately reconnected RooRealIntegral.; If numeric integration is required, the c.d.f or running integral is calculated by a dedicated class; RooRunningIntegral that precalculates results for all observable values, which is more efficient; in most use cases. Cumulative distributions functions that are calculated numerically are handled slightly differently; that standard running integrals: their values is constructed to converge to exactly zero at the lower bound; and exactly 1 at the upper bound so that algorithms that make use of that property of c.d.f can do so reliably. Constraints management. New tools have been added to simplify studies with fits involving (external) constraints on parameters.; The general philosophy is that constraints on parameters can be represented as probability density functions; and can thus be modeled by RooAbsPdf classes (e.g. a RooGaussian for a simple Gaussian constraint on a parameter).; There are two modes of operation: you can add parameter constraints to your problem definition by multiplying; the constraint p.d.f.s with your 'master' p.d.f. or you specify them externally in each operation. The; first mode of operat",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:14302,Energy Efficiency,efficient,efficient,14302,"tate2 are the state names of the two spitting categories. Additional; functionality exists to work with multiple prototype p.d.f.s simultaneously. ; Improved infrastructure for caching p.d.f and functions. The infrastructure that exists for caching p.d.f.s, i.e. p.d.f that precalculate their value; for all observable values at one and cache those in a histogram that is returned as p.d.f shape; (with optional interpolation), has been expanded. This infrastructure comprises RooAbsCached; the base class for all caching p.d.fs, RooAbsSelfCachedPdf a base class for end-user; caching p.d.f implementations that simply cache the result of evaluate() and RooCachedPdf; that can wrap and cache any input p.d.f specified in its constructor. . By default a p.d.f is sampled and cached in all observables in any; given use context, with no need to specify what those are in advance.; The internal code has also been changed such that all cache; histograms now store pre-normalized p.d.f, which is more efficient; than 'raw' p.d.f histograms that are explicitly post-normalized; through integration. Multiple different use cases (e.g. definitions; of what are observables vs parameters) can be cached; simultaneously. Now it is also possible to specify that p.d.f.s; should be sampled and cached in one or more parameter dimensions; in addition to the automatically determined set of observables.; as well. Also a complete new line of classes with similar functionality has been added inheriting from RooAbsReal.; These are RooAbsCachedReal,RooAbsSelfCachedReal and RooCachedReal. A newly; added class RooHistFunc presents these shapes and is capable of handling negative entries. New PDF error handling structure. New infrastructure has been put into place to propagate and process p.d.f evaluation errors during fitting.; Previously evaluation errors were marked with a zero p.d.f value and propagated as a special condition; in RooAddPdf, RooProdPdf etc to result in a zero top-level p.d.f value that was",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:1153,Integrability,integrat,integration,1153,"ation; rf02_composite.C - How to construct composite p.d.fs (sig plus bkg etc); rf03_multidim.C - How to construct multi-dimensional p.d.f.s; rf04_composition.C - Using composition techniques to adjust p.d.f building blocks; rf05_conditional.C - Construction of productions with conditional p.d.f.s; rf06_convolution.C - Convolution of p.d.fs f(x) (X) g(x); rf07_bphysics.C - B physics p.d.f.s with analytical convolution; rf08_intminuit.C - Interactive MINUIT demonstration; rf09_constraints.C - How to specify and use parameter constraints in fits; rf10_ranges.C - Working with sub ranges in observables in fitting and plotting; rf11_plotbinning.C - Variable and other non-uniform binnign specifications; rf12_mcstudy.C - Managing toy Monte Carlo studie; rf13_wspacewrite.C - Creating and persisting workspaces; rf14_wspaceread.C - Reading and using workspaces; rf15_simwstool.C - Automated tools for building of simulateneous p.d.f.s; rf16_normandint.C - Normalization, integration and cumulative distribution functions (1d); rf16_normandint2d.C - Normalization, integration and cumulative distribution functions (1d); ; Update of class documentation; ; The documentation in the code itself that is extracted by THtml to construct; the online class documentation has been updated for all classes. Now all classes; have (again) a short class description, as well as a (short) description of each member function; and most data members. An update to the users manual is foreseen shortly after the 5.20; release. RooWorkspace. A new feature has been added that allows to persist source code of RooFit classes that; are not in ROOT distribution inside a RooWorkspace to facilitate sharing; of custom code with others. To import code of custom classes call. RooWorkspace::importClassCode(). after importing the objects themselves into the workspace. For all classes; that are compiled with ACliC RooWorkspace can automatically find the source; code using the ROOT TClass interface. For custom classes th",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:1246,Integrability,integrat,integration,1246,"osition techniques to adjust p.d.f building blocks; rf05_conditional.C - Construction of productions with conditional p.d.f.s; rf06_convolution.C - Convolution of p.d.fs f(x) (X) g(x); rf07_bphysics.C - B physics p.d.f.s with analytical convolution; rf08_intminuit.C - Interactive MINUIT demonstration; rf09_constraints.C - How to specify and use parameter constraints in fits; rf10_ranges.C - Working with sub ranges in observables in fitting and plotting; rf11_plotbinning.C - Variable and other non-uniform binnign specifications; rf12_mcstudy.C - Managing toy Monte Carlo studie; rf13_wspacewrite.C - Creating and persisting workspaces; rf14_wspaceread.C - Reading and using workspaces; rf15_simwstool.C - Automated tools for building of simulateneous p.d.f.s; rf16_normandint.C - Normalization, integration and cumulative distribution functions (1d); rf16_normandint2d.C - Normalization, integration and cumulative distribution functions (1d); ; Update of class documentation; ; The documentation in the code itself that is extracted by THtml to construct; the online class documentation has been updated for all classes. Now all classes; have (again) a short class description, as well as a (short) description of each member function; and most data members. An update to the users manual is foreseen shortly after the 5.20; release. RooWorkspace. A new feature has been added that allows to persist source code of RooFit classes that; are not in ROOT distribution inside a RooWorkspace to facilitate sharing; of custom code with others. To import code of custom classes call. RooWorkspace::importClassCode(). after importing the objects themselves into the workspace. For all classes; that are compiled with ACliC RooWorkspace can automatically find the source; code using the ROOT TClass interface. For custom classes that are compiled; externally and loaded into ROOT as shared library it might be necessary to; provide the location of the source files manually using the static RooWorkspace",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:2149,Integrability,interface,interface,2149,"f simulateneous p.d.f.s; rf16_normandint.C - Normalization, integration and cumulative distribution functions (1d); rf16_normandint2d.C - Normalization, integration and cumulative distribution functions (1d); ; Update of class documentation; ; The documentation in the code itself that is extracted by THtml to construct; the online class documentation has been updated for all classes. Now all classes; have (again) a short class description, as well as a (short) description of each member function; and most data members. An update to the users manual is foreseen shortly after the 5.20; release. RooWorkspace. A new feature has been added that allows to persist source code of RooFit classes that; are not in ROOT distribution inside a RooWorkspace to facilitate sharing; of custom code with others. To import code of custom classes call. RooWorkspace::importClassCode(). after importing the objects themselves into the workspace. For all classes; that are compiled with ACliC RooWorkspace can automatically find the source; code using the ROOT TClass interface. For custom classes that are compiled; externally and loaded into ROOT as shared library it might be necessary to; provide the location of the source files manually using the static RooWorkspace; member functions addClassDeclImportDir() and addClassImplImportDir().; ; When a TFile with a RooWorkspace containing source code is opened in a ROOT; session that does not have the class code already loaded for the classes; contained in the workspace, the code in the workspace is written to file,; compiled and loaded into the ROOT session on the fly. The code repository of RooWorkspace is designed to handle classes that; have either their own implementation and header file, or are part of a group; of classes that share a common header and implementation file. More complicated; structuring of source code into files is not supported. ; ; Also new accessors have been added for discrete-valued functions catfunc(); and stored categor",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:3635,Integrability,depend,depending,3635,"; compiled and loaded into the ROOT session on the fly. The code repository of RooWorkspace is designed to handle classes that; have either their own implementation and header file, or are part of a group; of classes that share a common header and implementation file. More complicated; structuring of source code into files is not supported. ; ; Also new accessors have been added for discrete-valued functions catfunc(); and stored category functions are now also printed under their own heading in Print(); Parameterized ranges. It is now possible to use RooAbsReal derived functions as range definition for variables; to construct ranges that vary as function of another variable. For example. RooRealVar x(""x"",""x"",-10,10) ; // variable with fixed range [-10,10] ; RooRealVar y(""y"",""y"",0,20) ; // variable with fixed range [-10,10] ; ; RooFormulaVar x_lo(""x_lo"",""y-20"",y) ; ; RooFormulaVar x_hi(""x_hi"",""sin(y)*5"",y) ; ; x.setRange(x_lo,x_hi) ; // Change x to have variable range depending on y; ; It is also possible to define parameterized named ranges in the same way. x.setRange(""signalRegion"",x_lo,x_hi) ;. There are no fundamental limits to the complexity of the parameterized ranges; that can be defined as long as the problem is uniquely defined. For example, given three observables ; x, y and z, one can define a parameterized named range 'R' of x in terms of y and of y in terms of z; and ask to calculate the three dimensional integral of any function or p.d.f in terms of (x,y,z); over that range 'R' and it will be calculated correctly, taking recursive range dependencies into; account. A definition of a range 'R' on the other hand where the bounds of x depend on y and; the bounds of y depend on x is not allowed, and an error message will be printed to complain about; the ambiguity of the problem definition. Integrals over non-rectangular regions are created the; same way as integrals over rectangular regions using the RooAbsReal::createIntegral() function, the; chosen mode ",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:4229,Integrability,depend,dependencies,4229,"ow possible to use RooAbsReal derived functions as range definition for variables; to construct ranges that vary as function of another variable. For example. RooRealVar x(""x"",""x"",-10,10) ; // variable with fixed range [-10,10] ; RooRealVar y(""y"",""y"",0,20) ; // variable with fixed range [-10,10] ; ; RooFormulaVar x_lo(""x_lo"",""y-20"",y) ; ; RooFormulaVar x_hi(""x_hi"",""sin(y)*5"",y) ; ; x.setRange(x_lo,x_hi) ; // Change x to have variable range depending on y; ; It is also possible to define parameterized named ranges in the same way. x.setRange(""signalRegion"",x_lo,x_hi) ;. There are no fundamental limits to the complexity of the parameterized ranges; that can be defined as long as the problem is uniquely defined. For example, given three observables ; x, y and z, one can define a parameterized named range 'R' of x in terms of y and of y in terms of z; and ask to calculate the three dimensional integral of any function or p.d.f in terms of (x,y,z); over that range 'R' and it will be calculated correctly, taking recursive range dependencies into; account. A definition of a range 'R' on the other hand where the bounds of x depend on y and; the bounds of y depend on x is not allowed, and an error message will be printed to complain about; the ambiguity of the problem definition. Integrals over non-rectangular regions are created the; same way as integrals over rectangular regions using the RooAbsReal::createIntegral() function, the; chosen mode of operation depends on the shape of the requestion integration range. Note that in general integration over non (hyper)rectangular regions will be more computationally; intensive as only a subset of the observables can be integrated analytically (all of those that do not; have parameterized ranges plus those that have parameterized ranges but are not involved in the; parameterization of others (e.g. x and y in the example above). Running integrals and Cumulative distribution functions. It is now possible to create running integrals ",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:4325,Integrability,depend,depend,4325,""",-10,10) ; // variable with fixed range [-10,10] ; RooRealVar y(""y"",""y"",0,20) ; // variable with fixed range [-10,10] ; ; RooFormulaVar x_lo(""x_lo"",""y-20"",y) ; ; RooFormulaVar x_hi(""x_hi"",""sin(y)*5"",y) ; ; x.setRange(x_lo,x_hi) ; // Change x to have variable range depending on y; ; It is also possible to define parameterized named ranges in the same way. x.setRange(""signalRegion"",x_lo,x_hi) ;. There are no fundamental limits to the complexity of the parameterized ranges; that can be defined as long as the problem is uniquely defined. For example, given three observables ; x, y and z, one can define a parameterized named range 'R' of x in terms of y and of y in terms of z; and ask to calculate the three dimensional integral of any function or p.d.f in terms of (x,y,z); over that range 'R' and it will be calculated correctly, taking recursive range dependencies into; account. A definition of a range 'R' on the other hand where the bounds of x depend on y and; the bounds of y depend on x is not allowed, and an error message will be printed to complain about; the ambiguity of the problem definition. Integrals over non-rectangular regions are created the; same way as integrals over rectangular regions using the RooAbsReal::createIntegral() function, the; chosen mode of operation depends on the shape of the requestion integration range. Note that in general integration over non (hyper)rectangular regions will be more computationally; intensive as only a subset of the observables can be integrated analytically (all of those that do not; have parameterized ranges plus those that have parameterized ranges but are not involved in the; parameterization of others (e.g. x and y in the example above). Running integrals and Cumulative distribution functions. It is now possible to create running integrals from any RooAbsReal function and; to create cumulative distribution functions from any RooAbsPdf using the following; methods:. // Create int[xlo,x] f(x') dx' from f(x); RooAbsRe",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:4358,Integrability,depend,depend,4358,""",-10,10) ; // variable with fixed range [-10,10] ; RooRealVar y(""y"",""y"",0,20) ; // variable with fixed range [-10,10] ; ; RooFormulaVar x_lo(""x_lo"",""y-20"",y) ; ; RooFormulaVar x_hi(""x_hi"",""sin(y)*5"",y) ; ; x.setRange(x_lo,x_hi) ; // Change x to have variable range depending on y; ; It is also possible to define parameterized named ranges in the same way. x.setRange(""signalRegion"",x_lo,x_hi) ;. There are no fundamental limits to the complexity of the parameterized ranges; that can be defined as long as the problem is uniquely defined. For example, given three observables ; x, y and z, one can define a parameterized named range 'R' of x in terms of y and of y in terms of z; and ask to calculate the three dimensional integral of any function or p.d.f in terms of (x,y,z); over that range 'R' and it will be calculated correctly, taking recursive range dependencies into; account. A definition of a range 'R' on the other hand where the bounds of x depend on y and; the bounds of y depend on x is not allowed, and an error message will be printed to complain about; the ambiguity of the problem definition. Integrals over non-rectangular regions are created the; same way as integrals over rectangular regions using the RooAbsReal::createIntegral() function, the; chosen mode of operation depends on the shape of the requestion integration range. Note that in general integration over non (hyper)rectangular regions will be more computationally; intensive as only a subset of the observables can be integrated analytically (all of those that do not; have parameterized ranges plus those that have parameterized ranges but are not involved in the; parameterization of others (e.g. x and y in the example above). Running integrals and Cumulative distribution functions. It is now possible to create running integrals from any RooAbsReal function and; to create cumulative distribution functions from any RooAbsPdf using the following; methods:. // Create int[xlo,x] f(x') dx' from f(x); RooAbsRe",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:4399,Integrability,message,message,4399,""",-10,10) ; // variable with fixed range [-10,10] ; RooRealVar y(""y"",""y"",0,20) ; // variable with fixed range [-10,10] ; ; RooFormulaVar x_lo(""x_lo"",""y-20"",y) ; ; RooFormulaVar x_hi(""x_hi"",""sin(y)*5"",y) ; ; x.setRange(x_lo,x_hi) ; // Change x to have variable range depending on y; ; It is also possible to define parameterized named ranges in the same way. x.setRange(""signalRegion"",x_lo,x_hi) ;. There are no fundamental limits to the complexity of the parameterized ranges; that can be defined as long as the problem is uniquely defined. For example, given three observables ; x, y and z, one can define a parameterized named range 'R' of x in terms of y and of y in terms of z; and ask to calculate the three dimensional integral of any function or p.d.f in terms of (x,y,z); over that range 'R' and it will be calculated correctly, taking recursive range dependencies into; account. A definition of a range 'R' on the other hand where the bounds of x depend on y and; the bounds of y depend on x is not allowed, and an error message will be printed to complain about; the ambiguity of the problem definition. Integrals over non-rectangular regions are created the; same way as integrals over rectangular regions using the RooAbsReal::createIntegral() function, the; chosen mode of operation depends on the shape of the requestion integration range. Note that in general integration over non (hyper)rectangular regions will be more computationally; intensive as only a subset of the observables can be integrated analytically (all of those that do not; have parameterized ranges plus those that have parameterized ranges but are not involved in the; parameterization of others (e.g. x and y in the example above). Running integrals and Cumulative distribution functions. It is now possible to create running integrals from any RooAbsReal function and; to create cumulative distribution functions from any RooAbsPdf using the following; methods:. // Create int[xlo,x] f(x') dx' from f(x); RooAbsRe",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:4665,Integrability,depend,depends,4665," Change x to have variable range depending on y; ; It is also possible to define parameterized named ranges in the same way. x.setRange(""signalRegion"",x_lo,x_hi) ;. There are no fundamental limits to the complexity of the parameterized ranges; that can be defined as long as the problem is uniquely defined. For example, given three observables ; x, y and z, one can define a parameterized named range 'R' of x in terms of y and of y in terms of z; and ask to calculate the three dimensional integral of any function or p.d.f in terms of (x,y,z); over that range 'R' and it will be calculated correctly, taking recursive range dependencies into; account. A definition of a range 'R' on the other hand where the bounds of x depend on y and; the bounds of y depend on x is not allowed, and an error message will be printed to complain about; the ambiguity of the problem definition. Integrals over non-rectangular regions are created the; same way as integrals over rectangular regions using the RooAbsReal::createIntegral() function, the; chosen mode of operation depends on the shape of the requestion integration range. Note that in general integration over non (hyper)rectangular regions will be more computationally; intensive as only a subset of the observables can be integrated analytically (all of those that do not; have parameterized ranges plus those that have parameterized ranges but are not involved in the; parameterization of others (e.g. x and y in the example above). Running integrals and Cumulative distribution functions. It is now possible to create running integrals from any RooAbsReal function and; to create cumulative distribution functions from any RooAbsPdf using the following; methods:. // Create int[xlo,x] f(x') dx' from f(x); RooAbsReal* runInt = func.createRunningIntegral(x) ;. // Create int[xlo,x] f(x') dx' from p.d.f f(x) normalized over x; RooAbsReal* cdf = pdf.createCdf(x) ;. // Create int[xlo,x] f(x',y) dx' from p.d.f f(x,y) normalized over (x,y); RooAbsRea",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:4704,Integrability,integrat,integration,4704," Change x to have variable range depending on y; ; It is also possible to define parameterized named ranges in the same way. x.setRange(""signalRegion"",x_lo,x_hi) ;. There are no fundamental limits to the complexity of the parameterized ranges; that can be defined as long as the problem is uniquely defined. For example, given three observables ; x, y and z, one can define a parameterized named range 'R' of x in terms of y and of y in terms of z; and ask to calculate the three dimensional integral of any function or p.d.f in terms of (x,y,z); over that range 'R' and it will be calculated correctly, taking recursive range dependencies into; account. A definition of a range 'R' on the other hand where the bounds of x depend on y and; the bounds of y depend on x is not allowed, and an error message will be printed to complain about; the ambiguity of the problem definition. Integrals over non-rectangular regions are created the; same way as integrals over rectangular regions using the RooAbsReal::createIntegral() function, the; chosen mode of operation depends on the shape of the requestion integration range. Note that in general integration over non (hyper)rectangular regions will be more computationally; intensive as only a subset of the observables can be integrated analytically (all of those that do not; have parameterized ranges plus those that have parameterized ranges but are not involved in the; parameterization of others (e.g. x and y in the example above). Running integrals and Cumulative distribution functions. It is now possible to create running integrals from any RooAbsReal function and; to create cumulative distribution functions from any RooAbsPdf using the following; methods:. // Create int[xlo,x] f(x') dx' from f(x); RooAbsReal* runInt = func.createRunningIntegral(x) ;. // Create int[xlo,x] f(x') dx' from p.d.f f(x) normalized over x; RooAbsReal* cdf = pdf.createCdf(x) ;. // Create int[xlo,x] f(x',y) dx' from p.d.f f(x,y) normalized over (x,y); RooAbsRea",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:4744,Integrability,integrat,integration,4744,"m is uniquely defined. For example, given three observables ; x, y and z, one can define a parameterized named range 'R' of x in terms of y and of y in terms of z; and ask to calculate the three dimensional integral of any function or p.d.f in terms of (x,y,z); over that range 'R' and it will be calculated correctly, taking recursive range dependencies into; account. A definition of a range 'R' on the other hand where the bounds of x depend on y and; the bounds of y depend on x is not allowed, and an error message will be printed to complain about; the ambiguity of the problem definition. Integrals over non-rectangular regions are created the; same way as integrals over rectangular regions using the RooAbsReal::createIntegral() function, the; chosen mode of operation depends on the shape of the requestion integration range. Note that in general integration over non (hyper)rectangular regions will be more computationally; intensive as only a subset of the observables can be integrated analytically (all of those that do not; have parameterized ranges plus those that have parameterized ranges but are not involved in the; parameterization of others (e.g. x and y in the example above). Running integrals and Cumulative distribution functions. It is now possible to create running integrals from any RooAbsReal function and; to create cumulative distribution functions from any RooAbsPdf using the following; methods:. // Create int[xlo,x] f(x') dx' from f(x); RooAbsReal* runInt = func.createRunningIntegral(x) ;. // Create int[xlo,x] f(x') dx' from p.d.f f(x) normalized over x; RooAbsReal* cdf = pdf.createCdf(x) ;. // Create int[xlo,x] f(x',y) dx' from p.d.f f(x,y) normalized over (x,y); RooAbsReal* cdf = pdf.createCdf(x,y) ;. ; As with the similarly styled function createIntegral running integrals and c.d.f. can be created; over any number of observables, e.g createCdf(RooArgSet(x,y,z)) will create a three-dimensional; cumulative distribution function. C.d.f and running integr",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:4875,Integrability,integrat,integrated,4875,"m is uniquely defined. For example, given three observables ; x, y and z, one can define a parameterized named range 'R' of x in terms of y and of y in terms of z; and ask to calculate the three dimensional integral of any function or p.d.f in terms of (x,y,z); over that range 'R' and it will be calculated correctly, taking recursive range dependencies into; account. A definition of a range 'R' on the other hand where the bounds of x depend on y and; the bounds of y depend on x is not allowed, and an error message will be printed to complain about; the ambiguity of the problem definition. Integrals over non-rectangular regions are created the; same way as integrals over rectangular regions using the RooAbsReal::createIntegral() function, the; chosen mode of operation depends on the shape of the requestion integration range. Note that in general integration over non (hyper)rectangular regions will be more computationally; intensive as only a subset of the observables can be integrated analytically (all of those that do not; have parameterized ranges plus those that have parameterized ranges but are not involved in the; parameterization of others (e.g. x and y in the example above). Running integrals and Cumulative distribution functions. It is now possible to create running integrals from any RooAbsReal function and; to create cumulative distribution functions from any RooAbsPdf using the following; methods:. // Create int[xlo,x] f(x') dx' from f(x); RooAbsReal* runInt = func.createRunningIntegral(x) ;. // Create int[xlo,x] f(x') dx' from p.d.f f(x) normalized over x; RooAbsReal* cdf = pdf.createCdf(x) ;. // Create int[xlo,x] f(x',y) dx' from p.d.f f(x,y) normalized over (x,y); RooAbsReal* cdf = pdf.createCdf(x,y) ;. ; As with the similarly styled function createIntegral running integrals and c.d.f. can be created; over any number of observables, e.g createCdf(RooArgSet(x,y,z)) will create a three-dimensional; cumulative distribution function. C.d.f and running integr",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:5958,Integrability,integrat,integration,5958,"eterized ranges but are not involved in the; parameterization of others (e.g. x and y in the example above). Running integrals and Cumulative distribution functions. It is now possible to create running integrals from any RooAbsReal function and; to create cumulative distribution functions from any RooAbsPdf using the following; methods:. // Create int[xlo,x] f(x') dx' from f(x); RooAbsReal* runInt = func.createRunningIntegral(x) ;. // Create int[xlo,x] f(x') dx' from p.d.f f(x) normalized over x; RooAbsReal* cdf = pdf.createCdf(x) ;. // Create int[xlo,x] f(x',y) dx' from p.d.f f(x,y) normalized over (x,y); RooAbsReal* cdf = pdf.createCdf(x,y) ;. ; As with the similarly styled function createIntegral running integrals and c.d.f. can be created; over any number of observables, e.g createCdf(RooArgSet(x,y,z)) will create a three-dimensional; cumulative distribution function. C.d.f and running integrals that are calculated from p.d.fs that have; support for analytical integration are constructed from an appropriately reconnected RooRealIntegral.; If numeric integration is required, the c.d.f or running integral is calculated by a dedicated class; RooRunningIntegral that precalculates results for all observable values, which is more efficient; in most use cases. Cumulative distributions functions that are calculated numerically are handled slightly differently; that standard running integrals: their values is constructed to converge to exactly zero at the lower bound; and exactly 1 at the upper bound so that algorithms that make use of that property of c.d.f can do so reliably. Constraints management. New tools have been added to simplify studies with fits involving (external) constraints on parameters.; The general philosophy is that constraints on parameters can be represented as probability density functions; and can thus be modeled by RooAbsPdf classes (e.g. a RooGaussian for a simple Gaussian constraint on a parameter).; There are two modes of operation: you can add",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:6049,Integrability,integrat,integration,6049,"and y in the example above). Running integrals and Cumulative distribution functions. It is now possible to create running integrals from any RooAbsReal function and; to create cumulative distribution functions from any RooAbsPdf using the following; methods:. // Create int[xlo,x] f(x') dx' from f(x); RooAbsReal* runInt = func.createRunningIntegral(x) ;. // Create int[xlo,x] f(x') dx' from p.d.f f(x) normalized over x; RooAbsReal* cdf = pdf.createCdf(x) ;. // Create int[xlo,x] f(x',y) dx' from p.d.f f(x,y) normalized over (x,y); RooAbsReal* cdf = pdf.createCdf(x,y) ;. ; As with the similarly styled function createIntegral running integrals and c.d.f. can be created; over any number of observables, e.g createCdf(RooArgSet(x,y,z)) will create a three-dimensional; cumulative distribution function. C.d.f and running integrals that are calculated from p.d.fs that have; support for analytical integration are constructed from an appropriately reconnected RooRealIntegral.; If numeric integration is required, the c.d.f or running integral is calculated by a dedicated class; RooRunningIntegral that precalculates results for all observable values, which is more efficient; in most use cases. Cumulative distributions functions that are calculated numerically are handled slightly differently; that standard running integrals: their values is constructed to converge to exactly zero at the lower bound; and exactly 1 at the upper bound so that algorithms that make use of that property of c.d.f can do so reliably. Constraints management. New tools have been added to simplify studies with fits involving (external) constraints on parameters.; The general philosophy is that constraints on parameters can be represented as probability density functions; and can thus be modeled by RooAbsPdf classes (e.g. a RooGaussian for a simple Gaussian constraint on a parameter).; There are two modes of operation: you can add parameter constraints to your problem definition by multiplying; the constrain",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:11642,Integrability,interface,interface,11642,"hape; alpha=0.5; RooPlot* frame = x.frame() ;; rlm.plotOn(frame) ;. In short the algorithm works as follows: for both f1(x) and f2(x), the cumulative distribution; functions F1(x) and F2(x) are calculated. One finds takes a value 'y' of both c.d.fs and ; determines the corresponding x values x1,x2 at which F1(x1)=F2(x2)=y. The value of the interpolated ; p.d.f fbar(x) is then calculated as fbar(alpha*x1+(1-alpha)*x2) = f1(x1)*f2(x2) / ( alpha*f2(x2) + ; (1-alpha)*f1(x1) ). Given that it is not easily possible to calculate the value of RooLinearMorph; at a given value of x, the value for all values of x are calculated in one by (through a scan over y); and stored in a cache. NB: The range of the interpolation parameter does not need to be [0,1], it can; be anything. New workspace tool RooSimWSTool. A new tool to clone and customize p.d.f.s into a RooSimultaneous p.d.f has been added. This new; tool succeeds the original RooSimPdfBuilder tool which had a similar functionality but; has a much cleaner interface, partly thanks to its use of the RooWorkspace class for both input; of prototype p.d.fs and output of built p.d.f.s. The simplest use case to to take a workspace p.d.f as prototype and 'split' a parameter of that p.d.f ; into two specialized parameters depending on a category in the dataset. ; For example, given a Gaussian p.d.f G(x,m,s) we want to construct a G_a(x,m_a,s) and a G_b(x,m_b,s); with different mean parameters to be fit to a dataset with observables; (x,c) where c is a category with states 'a' and 'b'.; Using RooSimWSTool one can create a simultaneous p.d.f from G_a and G_b; from G with the following command. RooSimWSTool wst(wspace) ;; wst.build(""G_sim"",""G"",SplitParam(""m"",""c"")) ;. From this simple example one can go to builds of arbitrary complexity; by specifying multiple SplitParam arguments on multiple parameters; involving multiple splitting categories. Splits can also be performed; in the product multiple categories, e.g. . SplitParam(""m"",""c,d"")",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:11905,Integrability,depend,depending,11905,"onding x values x1,x2 at which F1(x1)=F2(x2)=y. The value of the interpolated ; p.d.f fbar(x) is then calculated as fbar(alpha*x1+(1-alpha)*x2) = f1(x1)*f2(x2) / ( alpha*f2(x2) + ; (1-alpha)*f1(x1) ). Given that it is not easily possible to calculate the value of RooLinearMorph; at a given value of x, the value for all values of x are calculated in one by (through a scan over y); and stored in a cache. NB: The range of the interpolation parameter does not need to be [0,1], it can; be anything. New workspace tool RooSimWSTool. A new tool to clone and customize p.d.f.s into a RooSimultaneous p.d.f has been added. This new; tool succeeds the original RooSimPdfBuilder tool which had a similar functionality but; has a much cleaner interface, partly thanks to its use of the RooWorkspace class for both input; of prototype p.d.fs and output of built p.d.f.s. The simplest use case to to take a workspace p.d.f as prototype and 'split' a parameter of that p.d.f ; into two specialized parameters depending on a category in the dataset. ; For example, given a Gaussian p.d.f G(x,m,s) we want to construct a G_a(x,m_a,s) and a G_b(x,m_b,s); with different mean parameters to be fit to a dataset with observables; (x,c) where c is a category with states 'a' and 'b'.; Using RooSimWSTool one can create a simultaneous p.d.f from G_a and G_b; from G with the following command. RooSimWSTool wst(wspace) ;; wst.build(""G_sim"",""G"",SplitParam(""m"",""c"")) ;. From this simple example one can go to builds of arbitrary complexity; by specifying multiple SplitParam arguments on multiple parameters; involving multiple splitting categories. Splits can also be performed; in the product multiple categories, e.g. . SplitParam(""m"",""c,d"")) ;. splits parameter m in the product of states of c and d. Another possibility; is the 'constrained' split which clones the parameter for all but one state; and insert a formula specialization in a chosen state that evaluates; to 1 - sum_i(a_i) where a_i are all other specia",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:13982,Integrability,wrap,wrap,13982,"with state ""A"",""B"",""C"",""D"" the specification. SplitParamConstrained(""m"",""c"",""D""). will result in parameters m_A,m_B,m_C and a formula expression m_D; that evaluates to (1-(m_A+m_B+m_C)). Constrained split can also be; specified in product of categories. In that case the name of the; remainder state follows the syntax {State1;State2} where State1; and State2 are the state names of the two spitting categories. Additional; functionality exists to work with multiple prototype p.d.f.s simultaneously. ; Improved infrastructure for caching p.d.f and functions. The infrastructure that exists for caching p.d.f.s, i.e. p.d.f that precalculate their value; for all observable values at one and cache those in a histogram that is returned as p.d.f shape; (with optional interpolation), has been expanded. This infrastructure comprises RooAbsCached; the base class for all caching p.d.fs, RooAbsSelfCachedPdf a base class for end-user; caching p.d.f implementations that simply cache the result of evaluate() and RooCachedPdf; that can wrap and cache any input p.d.f specified in its constructor. . By default a p.d.f is sampled and cached in all observables in any; given use context, with no need to specify what those are in advance.; The internal code has also been changed such that all cache; histograms now store pre-normalized p.d.f, which is more efficient; than 'raw' p.d.f histograms that are explicitly post-normalized; through integration. Multiple different use cases (e.g. definitions; of what are observables vs parameters) can be cached; simultaneously. Now it is also possible to specify that p.d.f.s; should be sampled and cached in one or more parameter dimensions; in addition to the automatically determined set of observables.; as well. Also a complete new line of classes with similar functionality has been added inheriting from RooAbsReal.; These are RooAbsCachedReal,RooAbsSelfCachedReal and RooCachedReal. A newly; added class RooHistFunc presents these shapes and is capable of",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:14386,Integrability,integrat,integration,14386,"Additional; functionality exists to work with multiple prototype p.d.f.s simultaneously. ; Improved infrastructure for caching p.d.f and functions. The infrastructure that exists for caching p.d.f.s, i.e. p.d.f that precalculate their value; for all observable values at one and cache those in a histogram that is returned as p.d.f shape; (with optional interpolation), has been expanded. This infrastructure comprises RooAbsCached; the base class for all caching p.d.fs, RooAbsSelfCachedPdf a base class for end-user; caching p.d.f implementations that simply cache the result of evaluate() and RooCachedPdf; that can wrap and cache any input p.d.f specified in its constructor. . By default a p.d.f is sampled and cached in all observables in any; given use context, with no need to specify what those are in advance.; The internal code has also been changed such that all cache; histograms now store pre-normalized p.d.f, which is more efficient; than 'raw' p.d.f histograms that are explicitly post-normalized; through integration. Multiple different use cases (e.g. definitions; of what are observables vs parameters) can be cached; simultaneously. Now it is also possible to specify that p.d.f.s; should be sampled and cached in one or more parameter dimensions; in addition to the automatically determined set of observables.; as well. Also a complete new line of classes with similar functionality has been added inheriting from RooAbsReal.; These are RooAbsCachedReal,RooAbsSelfCachedReal and RooCachedReal. A newly; added class RooHistFunc presents these shapes and is capable of handling negative entries. New PDF error handling structure. New infrastructure has been put into place to propagate and process p.d.f evaluation errors during fitting.; Previously evaluation errors were marked with a zero p.d.f value and propagated as a special condition; in RooAddPdf, RooProdPdf etc to result in a zero top-level p.d.f value that was caught by the RooFit minuit; interface as a special cond",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:15336,Integrability,interface,interface,15336," histograms that are explicitly post-normalized; through integration. Multiple different use cases (e.g. definitions; of what are observables vs parameters) can be cached; simultaneously. Now it is also possible to specify that p.d.f.s; should be sampled and cached in one or more parameter dimensions; in addition to the automatically determined set of observables.; as well. Also a complete new line of classes with similar functionality has been added inheriting from RooAbsReal.; These are RooAbsCachedReal,RooAbsSelfCachedReal and RooCachedReal. A newly; added class RooHistFunc presents these shapes and is capable of handling negative entries. New PDF error handling structure. New infrastructure has been put into place to propagate and process p.d.f evaluation errors during fitting.; Previously evaluation errors were marked with a zero p.d.f value and propagated as a special condition; in RooAddPdf, RooProdPdf etc to result in a zero top-level p.d.f value that was caught by the RooFit minuit; interface as a special condition. Summary information on the value of the parameters and the observables; was printed for the first 10 occurrences of such conditions. . Now, each p.d.f component that generates an error; in its evaluation logs the error into a separate facility during fitting and the RooFit minuit interface; polls this error logging facility for problems. This allows much more detailed and accurate warning messages; during the minimization phase. The level of verbosity of this new error facility can be controlled with; a new . PrintEvalErrors(Int_t code). argument to fitTo(). . With code of -1, no errors are printed at all.; With a; code of zero, one line is printed for each p.d.f component with problems summarizing the number of times; problems occurred during the likelihood evaluation. . [#0] WARNING:Minization -- RooFitGlue: Minimized function has error status. ; Returning maximum FCN so far (-1e+30) to force MIGRAD to back out of this region. Error log follows",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:15651,Integrability,interface,interface,15651,"meter dimensions; in addition to the automatically determined set of observables.; as well. Also a complete new line of classes with similar functionality has been added inheriting from RooAbsReal.; These are RooAbsCachedReal,RooAbsSelfCachedReal and RooCachedReal. A newly; added class RooHistFunc presents these shapes and is capable of handling negative entries. New PDF error handling structure. New infrastructure has been put into place to propagate and process p.d.f evaluation errors during fitting.; Previously evaluation errors were marked with a zero p.d.f value and propagated as a special condition; in RooAddPdf, RooProdPdf etc to result in a zero top-level p.d.f value that was caught by the RooFit minuit; interface as a special condition. Summary information on the value of the parameters and the observables; was printed for the first 10 occurrences of such conditions. . Now, each p.d.f component that generates an error; in its evaluation logs the error into a separate facility during fitting and the RooFit minuit interface; polls this error logging facility for problems. This allows much more detailed and accurate warning messages; during the minimization phase. The level of verbosity of this new error facility can be controlled with; a new . PrintEvalErrors(Int_t code). argument to fitTo(). . With code of -1, no errors are printed at all.; With a; code of zero, one line is printed for each p.d.f component with problems summarizing the number of times; problems occurred during the likelihood evaluation. . [#0] WARNING:Minization -- RooFitGlue: Minimized function has error status. ; Returning maximum FCN so far (-1e+30) to force MIGRAD to back out of this region. Error log follows; Parameter values: m=-7.397; RooGaussian::gx[ x=x mean=m sigma=sx ] has 3 errors. A code greater than zero will generate even more detail and; print the details of each evaluation error as provided by the p.d.f (zero value, not-a-number, normalization zero etc..); and show the obser",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:15762,Integrability,message,messages,15762,"functionality has been added inheriting from RooAbsReal.; These are RooAbsCachedReal,RooAbsSelfCachedReal and RooCachedReal. A newly; added class RooHistFunc presents these shapes and is capable of handling negative entries. New PDF error handling structure. New infrastructure has been put into place to propagate and process p.d.f evaluation errors during fitting.; Previously evaluation errors were marked with a zero p.d.f value and propagated as a special condition; in RooAddPdf, RooProdPdf etc to result in a zero top-level p.d.f value that was caught by the RooFit minuit; interface as a special condition. Summary information on the value of the parameters and the observables; was printed for the first 10 occurrences of such conditions. . Now, each p.d.f component that generates an error; in its evaluation logs the error into a separate facility during fitting and the RooFit minuit interface; polls this error logging facility for problems. This allows much more detailed and accurate warning messages; during the minimization phase. The level of verbosity of this new error facility can be controlled with; a new . PrintEvalErrors(Int_t code). argument to fitTo(). . With code of -1, no errors are printed at all.; With a; code of zero, one line is printed for each p.d.f component with problems summarizing the number of times; problems occurred during the likelihood evaluation. . [#0] WARNING:Minization -- RooFitGlue: Minimized function has error status. ; Returning maximum FCN so far (-1e+30) to force MIGRAD to back out of this region. Error log follows; Parameter values: m=-7.397; RooGaussian::gx[ x=x mean=m sigma=sx ] has 3 errors. A code greater than zero will generate even more detail and; print the details of each evaluation error as provided by the p.d.f (zero value, not-a-number, normalization zero etc..); and show the observable values at which this error occurred. At most N detailed messages per p.d.f component; are shown where N is the integral value of the 'co",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:16676,Integrability,message,messages,16676,"error logging facility for problems. This allows much more detailed and accurate warning messages; during the minimization phase. The level of verbosity of this new error facility can be controlled with; a new . PrintEvalErrors(Int_t code). argument to fitTo(). . With code of -1, no errors are printed at all.; With a; code of zero, one line is printed for each p.d.f component with problems summarizing the number of times; problems occurred during the likelihood evaluation. . [#0] WARNING:Minization -- RooFitGlue: Minimized function has error status. ; Returning maximum FCN so far (-1e+30) to force MIGRAD to back out of this region. Error log follows; Parameter values: m=-7.397; RooGaussian::gx[ x=x mean=m sigma=sx ] has 3 errors. A code greater than zero will generate even more detail and; print the details of each evaluation error as provided by the p.d.f (zero value, not-a-number, normalization zero etc..); and show the observable values at which this error occurred. At most N detailed messages per p.d.f component; are shown where N is the integral value of the 'code' argument. . [#0] WARNING:Minization -- RooFitGlue: Minimized function has error status.; Returning maximum FCN so far (-1e+30) to force MIGRAD to back out of this region. Error log follows; Parameter values: m=-7.397; RooGaussian::gx[ x=x mean=m sigma=sx ]; getLogVal() top-level p.d.f evaluates to zero or negative number @ x=x=9.09989, mean=m=-7.39713, sigma=sx=0.1; getLogVal() top-level p.d.f evaluates to zero or negative number @ x=x=6.04652, mean=m=-7.39713, sigma=sx=0.1; getLogVal() top-level p.d.f evaluates to zero or negative number @ x=x=2.48563, mean=m=-7.39713, sigma=sx=0.1. The new-style error logging is active whenever MINUIT is operating on such a p.d.f. The default value for N is 3.; Outside the MINUIT context the evaluation error each evualuation error will generate a separate message through; RooMsgService; Other new features. The RooAddPdf constructor has been augmented with an additio",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:17562,Integrability,message,message,17562,"d.f (zero value, not-a-number, normalization zero etc..); and show the observable values at which this error occurred. At most N detailed messages per p.d.f component; are shown where N is the integral value of the 'code' argument. . [#0] WARNING:Minization -- RooFitGlue: Minimized function has error status.; Returning maximum FCN so far (-1e+30) to force MIGRAD to back out of this region. Error log follows; Parameter values: m=-7.397; RooGaussian::gx[ x=x mean=m sigma=sx ]; getLogVal() top-level p.d.f evaluates to zero or negative number @ x=x=9.09989, mean=m=-7.39713, sigma=sx=0.1; getLogVal() top-level p.d.f evaluates to zero or negative number @ x=x=6.04652, mean=m=-7.39713, sigma=sx=0.1; getLogVal() top-level p.d.f evaluates to zero or negative number @ x=x=2.48563, mean=m=-7.39713, sigma=sx=0.1. The new-style error logging is active whenever MINUIT is operating on such a p.d.f. The default value for N is 3.; Outside the MINUIT context the evaluation error each evualuation error will generate a separate message through; RooMsgService; Other new features. The RooAddPdf constructor has been augmented with an additional boolean argument that allows to; interpret the supplied fraction parameters as recursive fractions rather than plain fractions.; If activated, an example RooAddPdf with three input p.d.f. A,B,C and two fractions fA and fB will; result in the expression; fA*A + (1-fA)(fB*B + 1-fB*C) rather than fA*A + fB*B + (1-fA-fB)*C. Recursive fraction have the advantage that all fraction can be defined to be in the range [0-1]; without resulting in configuration where the sum of all fractions exceeds 1.; The low-level object printing interface printToStream() has been deprecated in favor of a new; printStream() method which allows much greater control over the information printed. ; The printing of almost all RooFit objects has been reworked to present a more uniform look and feel.; The standard one-line result of the high-level Print() method without option now",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:18205,Integrability,interface,interface,18205,".d.f evaluates to zero or negative number @ x=x=2.48563, mean=m=-7.39713, sigma=sx=0.1. The new-style error logging is active whenever MINUIT is operating on such a p.d.f. The default value for N is 3.; Outside the MINUIT context the evaluation error each evualuation error will generate a separate message through; RooMsgService; Other new features. The RooAddPdf constructor has been augmented with an additional boolean argument that allows to; interpret the supplied fraction parameters as recursive fractions rather than plain fractions.; If activated, an example RooAddPdf with three input p.d.f. A,B,C and two fractions fA and fB will; result in the expression; fA*A + (1-fA)(fB*B + 1-fB*C) rather than fA*A + fB*B + (1-fA-fB)*C. Recursive fraction have the advantage that all fraction can be defined to be in the range [0-1]; without resulting in configuration where the sum of all fractions exceeds 1.; The low-level object printing interface printToStream() has been deprecated in favor of a new; printStream() method which allows much greater control over the information printed. ; The printing of almost all RooFit objects has been reworked to present a more uniform look and feel.; The standard one-line result of the high-level Print() method without option now looks like. // Variable; x.Print() ;; RooRealVar::x = 0 L(-10 - 10) . // Function or p.d.f; gx.Print() ;; RooGaussian::gx[ x=x mean=m sigma=sx ] = 1. // Dataset; d.Print() ;; RooDataSet::gData[x,y] = 1000 entries. // RooPlot; frame.Print() ;; framex[x] = (RooHist::h_gData,RooCurve::g_Int[y]_Norm[x,y]_Comp[g]). Inside class RooPlot the default name of contained curves and histograms has been ; reworked in something more self descriptive as is shown in the above example. A usual,; a user supplied name can always be set by supplying the Name(const char*) argument; to plotOn(). Verbose printing with ""v"" options is mostly unchanged except for RooPlot. In addition; printing with the ""s"" option will show the 'old' standar",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:3263,Modifiability,variab,variables,3263," necessary to; provide the location of the source files manually using the static RooWorkspace; member functions addClassDeclImportDir() and addClassImplImportDir().; ; When a TFile with a RooWorkspace containing source code is opened in a ROOT; session that does not have the class code already loaded for the classes; contained in the workspace, the code in the workspace is written to file,; compiled and loaded into the ROOT session on the fly. The code repository of RooWorkspace is designed to handle classes that; have either their own implementation and header file, or are part of a group; of classes that share a common header and implementation file. More complicated; structuring of source code into files is not supported. ; ; Also new accessors have been added for discrete-valued functions catfunc(); and stored category functions are now also printed under their own heading in Print(); Parameterized ranges. It is now possible to use RooAbsReal derived functions as range definition for variables; to construct ranges that vary as function of another variable. For example. RooRealVar x(""x"",""x"",-10,10) ; // variable with fixed range [-10,10] ; RooRealVar y(""y"",""y"",0,20) ; // variable with fixed range [-10,10] ; ; RooFormulaVar x_lo(""x_lo"",""y-20"",y) ; ; RooFormulaVar x_hi(""x_hi"",""sin(y)*5"",y) ; ; x.setRange(x_lo,x_hi) ; // Change x to have variable range depending on y; ; It is also possible to define parameterized named ranges in the same way. x.setRange(""signalRegion"",x_lo,x_hi) ;. There are no fundamental limits to the complexity of the parameterized ranges; that can be defined as long as the problem is uniquely defined. For example, given three observables ; x, y and z, one can define a parameterized named range 'R' of x in terms of y and of y in terms of z; and ask to calculate the three dimensional integral of any function or p.d.f in terms of (x,y,z); over that range 'R' and it will be calculated correctly, taking recursive range dependencies into; account. A d",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:3327,Modifiability,variab,variable,3327," necessary to; provide the location of the source files manually using the static RooWorkspace; member functions addClassDeclImportDir() and addClassImplImportDir().; ; When a TFile with a RooWorkspace containing source code is opened in a ROOT; session that does not have the class code already loaded for the classes; contained in the workspace, the code in the workspace is written to file,; compiled and loaded into the ROOT session on the fly. The code repository of RooWorkspace is designed to handle classes that; have either their own implementation and header file, or are part of a group; of classes that share a common header and implementation file. More complicated; structuring of source code into files is not supported. ; ; Also new accessors have been added for discrete-valued functions catfunc(); and stored category functions are now also printed under their own heading in Print(); Parameterized ranges. It is now possible to use RooAbsReal derived functions as range definition for variables; to construct ranges that vary as function of another variable. For example. RooRealVar x(""x"",""x"",-10,10) ; // variable with fixed range [-10,10] ; RooRealVar y(""y"",""y"",0,20) ; // variable with fixed range [-10,10] ; ; RooFormulaVar x_lo(""x_lo"",""y-20"",y) ; ; RooFormulaVar x_hi(""x_hi"",""sin(y)*5"",y) ; ; x.setRange(x_lo,x_hi) ; // Change x to have variable range depending on y; ; It is also possible to define parameterized named ranges in the same way. x.setRange(""signalRegion"",x_lo,x_hi) ;. There are no fundamental limits to the complexity of the parameterized ranges; that can be defined as long as the problem is uniquely defined. For example, given three observables ; x, y and z, one can define a parameterized named range 'R' of x in terms of y and of y in terms of z; and ask to calculate the three dimensional integral of any function or p.d.f in terms of (x,y,z); over that range 'R' and it will be calculated correctly, taking recursive range dependencies into; account. A d",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:3384,Modifiability,variab,variable,3384,"ntaining source code is opened in a ROOT; session that does not have the class code already loaded for the classes; contained in the workspace, the code in the workspace is written to file,; compiled and loaded into the ROOT session on the fly. The code repository of RooWorkspace is designed to handle classes that; have either their own implementation and header file, or are part of a group; of classes that share a common header and implementation file. More complicated; structuring of source code into files is not supported. ; ; Also new accessors have been added for discrete-valued functions catfunc(); and stored category functions are now also printed under their own heading in Print(); Parameterized ranges. It is now possible to use RooAbsReal derived functions as range definition for variables; to construct ranges that vary as function of another variable. For example. RooRealVar x(""x"",""x"",-10,10) ; // variable with fixed range [-10,10] ; RooRealVar y(""y"",""y"",0,20) ; // variable with fixed range [-10,10] ; ; RooFormulaVar x_lo(""x_lo"",""y-20"",y) ; ; RooFormulaVar x_hi(""x_hi"",""sin(y)*5"",y) ; ; x.setRange(x_lo,x_hi) ; // Change x to have variable range depending on y; ; It is also possible to define parameterized named ranges in the same way. x.setRange(""signalRegion"",x_lo,x_hi) ;. There are no fundamental limits to the complexity of the parameterized ranges; that can be defined as long as the problem is uniquely defined. For example, given three observables ; x, y and z, one can define a parameterized named range 'R' of x in terms of y and of y in terms of z; and ask to calculate the three dimensional integral of any function or p.d.f in terms of (x,y,z); over that range 'R' and it will be calculated correctly, taking recursive range dependencies into; account. A definition of a range 'R' on the other hand where the bounds of x depend on y and; the bounds of y depend on x is not allowed, and an error message will be printed to complain about; the ambiguity of the p",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:3453,Modifiability,variab,variable,3453,"ntaining source code is opened in a ROOT; session that does not have the class code already loaded for the classes; contained in the workspace, the code in the workspace is written to file,; compiled and loaded into the ROOT session on the fly. The code repository of RooWorkspace is designed to handle classes that; have either their own implementation and header file, or are part of a group; of classes that share a common header and implementation file. More complicated; structuring of source code into files is not supported. ; ; Also new accessors have been added for discrete-valued functions catfunc(); and stored category functions are now also printed under their own heading in Print(); Parameterized ranges. It is now possible to use RooAbsReal derived functions as range definition for variables; to construct ranges that vary as function of another variable. For example. RooRealVar x(""x"",""x"",-10,10) ; // variable with fixed range [-10,10] ; RooRealVar y(""y"",""y"",0,20) ; // variable with fixed range [-10,10] ; ; RooFormulaVar x_lo(""x_lo"",""y-20"",y) ; ; RooFormulaVar x_hi(""x_hi"",""sin(y)*5"",y) ; ; x.setRange(x_lo,x_hi) ; // Change x to have variable range depending on y; ; It is also possible to define parameterized named ranges in the same way. x.setRange(""signalRegion"",x_lo,x_hi) ;. There are no fundamental limits to the complexity of the parameterized ranges; that can be defined as long as the problem is uniquely defined. For example, given three observables ; x, y and z, one can define a parameterized named range 'R' of x in terms of y and of y in terms of z; and ask to calculate the three dimensional integral of any function or p.d.f in terms of (x,y,z); over that range 'R' and it will be calculated correctly, taking recursive range dependencies into; account. A definition of a range 'R' on the other hand where the bounds of x depend on y and; the bounds of y depend on x is not allowed, and an error message will be printed to complain about; the ambiguity of the p",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:3620,Modifiability,variab,variable,3620,"; compiled and loaded into the ROOT session on the fly. The code repository of RooWorkspace is designed to handle classes that; have either their own implementation and header file, or are part of a group; of classes that share a common header and implementation file. More complicated; structuring of source code into files is not supported. ; ; Also new accessors have been added for discrete-valued functions catfunc(); and stored category functions are now also printed under their own heading in Print(); Parameterized ranges. It is now possible to use RooAbsReal derived functions as range definition for variables; to construct ranges that vary as function of another variable. For example. RooRealVar x(""x"",""x"",-10,10) ; // variable with fixed range [-10,10] ; RooRealVar y(""y"",""y"",0,20) ; // variable with fixed range [-10,10] ; ; RooFormulaVar x_lo(""x_lo"",""y-20"",y) ; ; RooFormulaVar x_hi(""x_hi"",""sin(y)*5"",y) ; ; x.setRange(x_lo,x_hi) ; // Change x to have variable range depending on y; ; It is also possible to define parameterized named ranges in the same way. x.setRange(""signalRegion"",x_lo,x_hi) ;. There are no fundamental limits to the complexity of the parameterized ranges; that can be defined as long as the problem is uniquely defined. For example, given three observables ; x, y and z, one can define a parameterized named range 'R' of x in terms of y and of y in terms of z; and ask to calculate the three dimensional integral of any function or p.d.f in terms of (x,y,z); over that range 'R' and it will be calculated correctly, taking recursive range dependencies into; account. A definition of a range 'R' on the other hand where the bounds of x depend on y and; the bounds of y depend on x is not allowed, and an error message will be printed to complain about; the ambiguity of the problem definition. Integrals over non-rectangular regions are created the; same way as integrals over rectangular regions using the RooAbsReal::createIntegral() function, the; chosen mode ",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:3683,Modifiability,parameteriz,parameterized,3683,"; compiled and loaded into the ROOT session on the fly. The code repository of RooWorkspace is designed to handle classes that; have either their own implementation and header file, or are part of a group; of classes that share a common header and implementation file. More complicated; structuring of source code into files is not supported. ; ; Also new accessors have been added for discrete-valued functions catfunc(); and stored category functions are now also printed under their own heading in Print(); Parameterized ranges. It is now possible to use RooAbsReal derived functions as range definition for variables; to construct ranges that vary as function of another variable. For example. RooRealVar x(""x"",""x"",-10,10) ; // variable with fixed range [-10,10] ; RooRealVar y(""y"",""y"",0,20) ; // variable with fixed range [-10,10] ; ; RooFormulaVar x_lo(""x_lo"",""y-20"",y) ; ; RooFormulaVar x_hi(""x_hi"",""sin(y)*5"",y) ; ; x.setRange(x_lo,x_hi) ; // Change x to have variable range depending on y; ; It is also possible to define parameterized named ranges in the same way. x.setRange(""signalRegion"",x_lo,x_hi) ;. There are no fundamental limits to the complexity of the parameterized ranges; that can be defined as long as the problem is uniquely defined. For example, given three observables ; x, y and z, one can define a parameterized named range 'R' of x in terms of y and of y in terms of z; and ask to calculate the three dimensional integral of any function or p.d.f in terms of (x,y,z); over that range 'R' and it will be calculated correctly, taking recursive range dependencies into; account. A definition of a range 'R' on the other hand where the bounds of x depend on y and; the bounds of y depend on x is not allowed, and an error message will be printed to complain about; the ambiguity of the problem definition. Integrals over non-rectangular regions are created the; same way as integrals over rectangular regions using the RooAbsReal::createIntegral() function, the; chosen mode ",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:3824,Modifiability,parameteriz,parameterized,3824,"are part of a group; of classes that share a common header and implementation file. More complicated; structuring of source code into files is not supported. ; ; Also new accessors have been added for discrete-valued functions catfunc(); and stored category functions are now also printed under their own heading in Print(); Parameterized ranges. It is now possible to use RooAbsReal derived functions as range definition for variables; to construct ranges that vary as function of another variable. For example. RooRealVar x(""x"",""x"",-10,10) ; // variable with fixed range [-10,10] ; RooRealVar y(""y"",""y"",0,20) ; // variable with fixed range [-10,10] ; ; RooFormulaVar x_lo(""x_lo"",""y-20"",y) ; ; RooFormulaVar x_hi(""x_hi"",""sin(y)*5"",y) ; ; x.setRange(x_lo,x_hi) ; // Change x to have variable range depending on y; ; It is also possible to define parameterized named ranges in the same way. x.setRange(""signalRegion"",x_lo,x_hi) ;. There are no fundamental limits to the complexity of the parameterized ranges; that can be defined as long as the problem is uniquely defined. For example, given three observables ; x, y and z, one can define a parameterized named range 'R' of x in terms of y and of y in terms of z; and ask to calculate the three dimensional integral of any function or p.d.f in terms of (x,y,z); over that range 'R' and it will be calculated correctly, taking recursive range dependencies into; account. A definition of a range 'R' on the other hand where the bounds of x depend on y and; the bounds of y depend on x is not allowed, and an error message will be printed to complain about; the ambiguity of the problem definition. Integrals over non-rectangular regions are created the; same way as integrals over rectangular regions using the RooAbsReal::createIntegral() function, the; chosen mode of operation depends on the shape of the requestion integration range. Note that in general integration over non (hyper)rectangular regions will be more computationally; intensive as onl",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:3978,Modifiability,parameteriz,parameterized,3978,"s have been added for discrete-valued functions catfunc(); and stored category functions are now also printed under their own heading in Print(); Parameterized ranges. It is now possible to use RooAbsReal derived functions as range definition for variables; to construct ranges that vary as function of another variable. For example. RooRealVar x(""x"",""x"",-10,10) ; // variable with fixed range [-10,10] ; RooRealVar y(""y"",""y"",0,20) ; // variable with fixed range [-10,10] ; ; RooFormulaVar x_lo(""x_lo"",""y-20"",y) ; ; RooFormulaVar x_hi(""x_hi"",""sin(y)*5"",y) ; ; x.setRange(x_lo,x_hi) ; // Change x to have variable range depending on y; ; It is also possible to define parameterized named ranges in the same way. x.setRange(""signalRegion"",x_lo,x_hi) ;. There are no fundamental limits to the complexity of the parameterized ranges; that can be defined as long as the problem is uniquely defined. For example, given three observables ; x, y and z, one can define a parameterized named range 'R' of x in terms of y and of y in terms of z; and ask to calculate the three dimensional integral of any function or p.d.f in terms of (x,y,z); over that range 'R' and it will be calculated correctly, taking recursive range dependencies into; account. A definition of a range 'R' on the other hand where the bounds of x depend on y and; the bounds of y depend on x is not allowed, and an error message will be printed to complain about; the ambiguity of the problem definition. Integrals over non-rectangular regions are created the; same way as integrals over rectangular regions using the RooAbsReal::createIntegral() function, the; chosen mode of operation depends on the shape of the requestion integration range. Note that in general integration over non (hyper)rectangular regions will be more computationally; intensive as only a subset of the observables can be integrated analytically (all of those that do not; have parameterized ranges plus those that have parameterized ranges but are not involved in",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:4931,Modifiability,parameteriz,parameterized,4931,"m is uniquely defined. For example, given three observables ; x, y and z, one can define a parameterized named range 'R' of x in terms of y and of y in terms of z; and ask to calculate the three dimensional integral of any function or p.d.f in terms of (x,y,z); over that range 'R' and it will be calculated correctly, taking recursive range dependencies into; account. A definition of a range 'R' on the other hand where the bounds of x depend on y and; the bounds of y depend on x is not allowed, and an error message will be printed to complain about; the ambiguity of the problem definition. Integrals over non-rectangular regions are created the; same way as integrals over rectangular regions using the RooAbsReal::createIntegral() function, the; chosen mode of operation depends on the shape of the requestion integration range. Note that in general integration over non (hyper)rectangular regions will be more computationally; intensive as only a subset of the observables can be integrated analytically (all of those that do not; have parameterized ranges plus those that have parameterized ranges but are not involved in the; parameterization of others (e.g. x and y in the example above). Running integrals and Cumulative distribution functions. It is now possible to create running integrals from any RooAbsReal function and; to create cumulative distribution functions from any RooAbsPdf using the following; methods:. // Create int[xlo,x] f(x') dx' from f(x); RooAbsReal* runInt = func.createRunningIntegral(x) ;. // Create int[xlo,x] f(x') dx' from p.d.f f(x) normalized over x; RooAbsReal* cdf = pdf.createCdf(x) ;. // Create int[xlo,x] f(x',y) dx' from p.d.f f(x,y) normalized over (x,y); RooAbsReal* cdf = pdf.createCdf(x,y) ;. ; As with the similarly styled function createIntegral running integrals and c.d.f. can be created; over any number of observables, e.g createCdf(RooArgSet(x,y,z)) will create a three-dimensional; cumulative distribution function. C.d.f and running integr",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:4973,Modifiability,parameteriz,parameterized,4973,"m is uniquely defined. For example, given three observables ; x, y and z, one can define a parameterized named range 'R' of x in terms of y and of y in terms of z; and ask to calculate the three dimensional integral of any function or p.d.f in terms of (x,y,z); over that range 'R' and it will be calculated correctly, taking recursive range dependencies into; account. A definition of a range 'R' on the other hand where the bounds of x depend on y and; the bounds of y depend on x is not allowed, and an error message will be printed to complain about; the ambiguity of the problem definition. Integrals over non-rectangular regions are created the; same way as integrals over rectangular regions using the RooAbsReal::createIntegral() function, the; chosen mode of operation depends on the shape of the requestion integration range. Note that in general integration over non (hyper)rectangular regions will be more computationally; intensive as only a subset of the observables can be integrated analytically (all of those that do not; have parameterized ranges plus those that have parameterized ranges but are not involved in the; parameterization of others (e.g. x and y in the example above). Running integrals and Cumulative distribution functions. It is now possible to create running integrals from any RooAbsReal function and; to create cumulative distribution functions from any RooAbsPdf using the following; methods:. // Create int[xlo,x] f(x') dx' from f(x); RooAbsReal* runInt = func.createRunningIntegral(x) ;. // Create int[xlo,x] f(x') dx' from p.d.f f(x) normalized over x; RooAbsReal* cdf = pdf.createCdf(x) ;. // Create int[xlo,x] f(x',y) dx' from p.d.f f(x,y) normalized over (x,y); RooAbsReal* cdf = pdf.createCdf(x,y) ;. ; As with the similarly styled function createIntegral running integrals and c.d.f. can be created; over any number of observables, e.g createCdf(RooArgSet(x,y,z)) will create a three-dimensional; cumulative distribution function. C.d.f and running integr",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:5023,Modifiability,parameteriz,parameterization,5023,"m is uniquely defined. For example, given three observables ; x, y and z, one can define a parameterized named range 'R' of x in terms of y and of y in terms of z; and ask to calculate the three dimensional integral of any function or p.d.f in terms of (x,y,z); over that range 'R' and it will be calculated correctly, taking recursive range dependencies into; account. A definition of a range 'R' on the other hand where the bounds of x depend on y and; the bounds of y depend on x is not allowed, and an error message will be printed to complain about; the ambiguity of the problem definition. Integrals over non-rectangular regions are created the; same way as integrals over rectangular regions using the RooAbsReal::createIntegral() function, the; chosen mode of operation depends on the shape of the requestion integration range. Note that in general integration over non (hyper)rectangular regions will be more computationally; intensive as only a subset of the observables can be integrated analytically (all of those that do not; have parameterized ranges plus those that have parameterized ranges but are not involved in the; parameterization of others (e.g. x and y in the example above). Running integrals and Cumulative distribution functions. It is now possible to create running integrals from any RooAbsReal function and; to create cumulative distribution functions from any RooAbsPdf using the following; methods:. // Create int[xlo,x] f(x') dx' from f(x); RooAbsReal* runInt = func.createRunningIntegral(x) ;. // Create int[xlo,x] f(x') dx' from p.d.f f(x) normalized over x; RooAbsReal* cdf = pdf.createCdf(x) ;. // Create int[xlo,x] f(x',y) dx' from p.d.f f(x,y) normalized over (x,y); RooAbsReal* cdf = pdf.createCdf(x,y) ;. ; As with the similarly styled function createIntegral running integrals and c.d.f. can be created; over any number of observables, e.g createCdf(RooArgSet(x,y,z)) will create a three-dimensional; cumulative distribution function. C.d.f and running integr",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:8478,Modifiability,extend,extended,8478,",RooConst(0.8),RooConst(0.1)) ;. // Multiply constraint with p.d.f; RooProdPdf pdfc(""pdfc"",""p.d.f with constraint"",RooArgSet(p.d.f,fconstraint)) ;. If your top level p.d.f is already a RooProdPdf it also fine to multiply all terms together in one go.; Constraints do not need to be specified a the top-level RooProdPdf, constraint p.d.f.s in any component; RooProdPdf lower in the expression tree are used as well. Constraints are not used by default in fitting; if present in a p.d.f. To activate the use of a constraint in fitting, use the Constrain() argument in fitTo(). // Fit with internal constraint; RooFitResult* r2 = pdfc.fitTo(*d,Constrain(f)) ;; ; This will instruct RooAbsPdf::fitTo() to included any constraint p.d.f on parameter f in the; definition of the likelihood. It is possible to add multiple constraints on the same parameter; to the 'master' p.d.f. If so, all constraints on a given parameter will be added to the likelihood. The RooMCStudy class has been extended to accept the Constrain() argument as well in its constructor.; If specified it will do two things: 1) it will pass the constrain argument to the fitting pass of; the toy study and 2) it will modify the generation step into a two-step procedure: for each toy; in the study it will first sample a value of each constrained parameter from the joint constraints; p.d.f and it will then generate the observables for that experiment with the thus obtained parameter values.; In this mode of operation the parameter values for each toy may thus be different. The actual parameter; for each toy can be obtained with the newly added RooMCStudy::genParDataSet() member function. The calculation; of the pull values for each parameter has been modified accordingly. Alternatively, it is possible to specify constraints to both RooAbsPdf::fitTo() and the RooMCStudy constructor; using the ExternalConstraint() named argument to supply constraint p.d.f.s that are not part of the 'master'; p.d.f but rather an ad-hoc suppli",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:14784,Modifiability,inherit,inheriting,14784,"nfrastructure comprises RooAbsCached; the base class for all caching p.d.fs, RooAbsSelfCachedPdf a base class for end-user; caching p.d.f implementations that simply cache the result of evaluate() and RooCachedPdf; that can wrap and cache any input p.d.f specified in its constructor. . By default a p.d.f is sampled and cached in all observables in any; given use context, with no need to specify what those are in advance.; The internal code has also been changed such that all cache; histograms now store pre-normalized p.d.f, which is more efficient; than 'raw' p.d.f histograms that are explicitly post-normalized; through integration. Multiple different use cases (e.g. definitions; of what are observables vs parameters) can be cached; simultaneously. Now it is also possible to specify that p.d.f.s; should be sampled and cached in one or more parameter dimensions; in addition to the automatically determined set of observables.; as well. Also a complete new line of classes with similar functionality has been added inheriting from RooAbsReal.; These are RooAbsCachedReal,RooAbsSelfCachedReal and RooCachedReal. A newly; added class RooHistFunc presents these shapes and is capable of handling negative entries. New PDF error handling structure. New infrastructure has been put into place to propagate and process p.d.f evaluation errors during fitting.; Previously evaluation errors were marked with a zero p.d.f value and propagated as a special condition; in RooAddPdf, RooProdPdf etc to result in a zero top-level p.d.f value that was caught by the RooFit minuit; interface as a special condition. Summary information on the value of the parameters and the observables; was printed for the first 10 occurrences of such conditions. . Now, each p.d.f component that generates an error; in its evaluation logs the error into a separate facility during fitting and the RooFit minuit interface; polls this error logging facility for problems. This allows much more detailed and accurate warn",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:18118,Modifiability,config,configuration,18118,"=x=9.09989, mean=m=-7.39713, sigma=sx=0.1; getLogVal() top-level p.d.f evaluates to zero or negative number @ x=x=6.04652, mean=m=-7.39713, sigma=sx=0.1; getLogVal() top-level p.d.f evaluates to zero or negative number @ x=x=2.48563, mean=m=-7.39713, sigma=sx=0.1. The new-style error logging is active whenever MINUIT is operating on such a p.d.f. The default value for N is 3.; Outside the MINUIT context the evaluation error each evualuation error will generate a separate message through; RooMsgService; Other new features. The RooAddPdf constructor has been augmented with an additional boolean argument that allows to; interpret the supplied fraction parameters as recursive fractions rather than plain fractions.; If activated, an example RooAddPdf with three input p.d.f. A,B,C and two fractions fA and fB will; result in the expression; fA*A + (1-fA)(fB*B + 1-fB*C) rather than fA*A + fB*B + (1-fA-fB)*C. Recursive fraction have the advantage that all fraction can be defined to be in the range [0-1]; without resulting in configuration where the sum of all fractions exceeds 1.; The low-level object printing interface printToStream() has been deprecated in favor of a new; printStream() method which allows much greater control over the information printed. ; The printing of almost all RooFit objects has been reworked to present a more uniform look and feel.; The standard one-line result of the high-level Print() method without option now looks like. // Variable; x.Print() ;; RooRealVar::x = 0 L(-10 - 10) . // Function or p.d.f; gx.Print() ;; RooGaussian::gx[ x=x mean=m sigma=sx ] = 1. // Dataset; d.Print() ;; RooDataSet::gData[x,y] = 1000 entries. // RooPlot; frame.Print() ;; framex[x] = (RooHist::h_gData,RooCurve::g_Int[y]_Norm[x,y]_Comp[g]). Inside class RooPlot the default name of contained curves and histograms has been ; reworked in something more self descriptive as is shown in the above example. A usual,; a user supplied name can always be set by supplying the Name(c",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:20053,Modifiability,variab,variables,20053,"oStream() has been deprecated in favor of a new; printStream() method which allows much greater control over the information printed. ; The printing of almost all RooFit objects has been reworked to present a more uniform look and feel.; The standard one-line result of the high-level Print() method without option now looks like. // Variable; x.Print() ;; RooRealVar::x = 0 L(-10 - 10) . // Function or p.d.f; gx.Print() ;; RooGaussian::gx[ x=x mean=m sigma=sx ] = 1. // Dataset; d.Print() ;; RooDataSet::gData[x,y] = 1000 entries. // RooPlot; frame.Print() ;; framex[x] = (RooHist::h_gData,RooCurve::g_Int[y]_Norm[x,y]_Comp[g]). Inside class RooPlot the default name of contained curves and histograms has been ; reworked in something more self descriptive as is shown in the above example. A usual,; a user supplied name can always be set by supplying the Name(const char*) argument; to plotOn(). Verbose printing with ""v"" options is mostly unchanged except for RooPlot. In addition; printing with the ""s"" option will show the 'old' standard printing mode, option ""t"" will show; tree structure printing (only for RooAbsArg), and option ""1"" will invoke inline printing, i.e; a one-line description without a trailing endl.; Data weighted projections of p.d.fs using the ProjWData() argument in RooAbsPdf::plotOn() are now calculated; with a new classes that derives from RooAbsOptTestStatistic and can thus implement the same evaluation; optimizations as are done for RooNLLVar and RooChi2Var. Specifically it is now possible to calculate projections; involving ProjWData() in parallel on multi-core hosts by adding the NumCPU(Int_t) argument to plotOn().; ; A new utility function has been added to allow cloning of entire tree expressions of; RooAbsArg objects, such as a composite p.d.f including component p.d.fs and; all its variables:. RooAbsArg* clonedTree = pdf.cloneTree() ;. All cloned leaf and branch nodes are owned by the returned head node of the expression.; Assorted minor fixes; ; ",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:2213,Performance,load,loaded,2213,"ions (1d); ; Update of class documentation; ; The documentation in the code itself that is extracted by THtml to construct; the online class documentation has been updated for all classes. Now all classes; have (again) a short class description, as well as a (short) description of each member function; and most data members. An update to the users manual is foreseen shortly after the 5.20; release. RooWorkspace. A new feature has been added that allows to persist source code of RooFit classes that; are not in ROOT distribution inside a RooWorkspace to facilitate sharing; of custom code with others. To import code of custom classes call. RooWorkspace::importClassCode(). after importing the objects themselves into the workspace. For all classes; that are compiled with ACliC RooWorkspace can automatically find the source; code using the ROOT TClass interface. For custom classes that are compiled; externally and loaded into ROOT as shared library it might be necessary to; provide the location of the source files manually using the static RooWorkspace; member functions addClassDeclImportDir() and addClassImplImportDir().; ; When a TFile with a RooWorkspace containing source code is opened in a ROOT; session that does not have the class code already loaded for the classes; contained in the workspace, the code in the workspace is written to file,; compiled and loaded into the ROOT session on the fly. The code repository of RooWorkspace is designed to handle classes that; have either their own implementation and header file, or are part of a group; of classes that share a common header and implementation file. More complicated; structuring of source code into files is not supported. ; ; Also new accessors have been added for discrete-valued functions catfunc(); and stored category functions are now also printed under their own heading in Print(); Parameterized ranges. It is now possible to use RooAbsReal derived functions as range definition for variables; to construct range",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:2555,Performance,load,loaded,2555,"tion of each member function; and most data members. An update to the users manual is foreseen shortly after the 5.20; release. RooWorkspace. A new feature has been added that allows to persist source code of RooFit classes that; are not in ROOT distribution inside a RooWorkspace to facilitate sharing; of custom code with others. To import code of custom classes call. RooWorkspace::importClassCode(). after importing the objects themselves into the workspace. For all classes; that are compiled with ACliC RooWorkspace can automatically find the source; code using the ROOT TClass interface. For custom classes that are compiled; externally and loaded into ROOT as shared library it might be necessary to; provide the location of the source files manually using the static RooWorkspace; member functions addClassDeclImportDir() and addClassImplImportDir().; ; When a TFile with a RooWorkspace containing source code is opened in a ROOT; session that does not have the class code already loaded for the classes; contained in the workspace, the code in the workspace is written to file,; compiled and loaded into the ROOT session on the fly. The code repository of RooWorkspace is designed to handle classes that; have either their own implementation and header file, or are part of a group; of classes that share a common header and implementation file. More complicated; structuring of source code into files is not supported. ; ; Also new accessors have been added for discrete-valued functions catfunc(); and stored category functions are now also printed under their own heading in Print(); Parameterized ranges. It is now possible to use RooAbsReal derived functions as range definition for variables; to construct ranges that vary as function of another variable. For example. RooRealVar x(""x"",""x"",-10,10) ; // variable with fixed range [-10,10] ; RooRealVar y(""y"",""y"",0,20) ; // variable with fixed range [-10,10] ; ; RooFormulaVar x_lo(""x_lo"",""y-20"",y) ; ; RooFormulaVar x_hi(""x_hi"",""sin(y)*",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:2667,Performance,load,loaded,2667,"tion of each member function; and most data members. An update to the users manual is foreseen shortly after the 5.20; release. RooWorkspace. A new feature has been added that allows to persist source code of RooFit classes that; are not in ROOT distribution inside a RooWorkspace to facilitate sharing; of custom code with others. To import code of custom classes call. RooWorkspace::importClassCode(). after importing the objects themselves into the workspace. For all classes; that are compiled with ACliC RooWorkspace can automatically find the source; code using the ROOT TClass interface. For custom classes that are compiled; externally and loaded into ROOT as shared library it might be necessary to; provide the location of the source files manually using the static RooWorkspace; member functions addClassDeclImportDir() and addClassImplImportDir().; ; When a TFile with a RooWorkspace containing source code is opened in a ROOT; session that does not have the class code already loaded for the classes; contained in the workspace, the code in the workspace is written to file,; compiled and loaded into the ROOT session on the fly. The code repository of RooWorkspace is designed to handle classes that; have either their own implementation and header file, or are part of a group; of classes that share a common header and implementation file. More complicated; structuring of source code into files is not supported. ; ; Also new accessors have been added for discrete-valued functions catfunc(); and stored category functions are now also printed under their own heading in Print(); Parameterized ranges. It is now possible to use RooAbsReal derived functions as range definition for variables; to construct ranges that vary as function of another variable. For example. RooRealVar x(""x"",""x"",-10,10) ; // variable with fixed range [-10,10] ; RooRealVar y(""y"",""y"",0,20) ; // variable with fixed range [-10,10] ; ; RooFormulaVar x_lo(""x_lo"",""y-20"",y) ; ; RooFormulaVar x_hi(""x_hi"",""sin(y)*",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:10180,Performance,cache,cache,10180,"tion; of the pull values for each parameter has been modified accordingly. Alternatively, it is possible to specify constraints to both RooAbsPdf::fitTo() and the RooMCStudy constructor; using the ExternalConstraint() named argument to supply constraint p.d.f.s that are not part of the 'master'; p.d.f but rather an ad-hoc supplied external constraint. The argument supplied to ExternalConstraint() should; be (a set of) constraint p.d.f(s), rather than (a set of) parameters for which internal constraint p.d.f.s should; be picked up. New operator class RooLinearMorph. A new numeric operator class RooLinearMorph has been added that provides a continuous; transformation between two p.d.f.s shapes in terms of a linear parameter alpha. The algorithm ; for histograms is described in the paper by Alex Read in NUM A 425 (1999) 357-369 ; 'Linear interpolation of histograms'. The implementation in RooLinearMorph is for; continuous functions. . // Observable and sampling binning to be used by RooLinearMorph (""cache""); RooRealVar x(""x"",""x"",-20,20) ;; x.setBins(1000,""cache"") ;. // End point shapes : a gaussian on one end, a polynomial on the other; RooGaussian f1(""f1"",""f1"",x,RooConst(-10),RooConst(2)) ;; RooPolynomial f2(""f2"",""f2"",x,RooArgSet(RooConst(-0.03),RooConst(-0.001))) ;. // Interpolation parameter: rlm=f1 at alpha=0, rlm=f2 at alpha=1; RooRealVar alpha(""alpha"",""alpha"",0,1.0) ;; RooLinearMorph rlm(""rlm"",""rlm"",g1,g2,x,alpha) ;. // Plot halfway shape; alpha=0.5; RooPlot* frame = x.frame() ;; rlm.plotOn(frame) ;. In short the algorithm works as follows: for both f1(x) and f2(x), the cumulative distribution; functions F1(x) and F2(x) are calculated. One finds takes a value 'y' of both c.d.fs and ; determines the corresponding x values x1,x2 at which F1(x1)=F2(x2)=y. The value of the interpolated ; p.d.f fbar(x) is then calculated as fbar(alpha*x1+(1-alpha)*x2) = f1(x1)*f2(x2) / ( alpha*f2(x2) + ; (1-alpha)*f1(x1) ). Given that it is not easily possible to calculate the value o",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:10237,Performance,cache,cache,10237,"dingly. Alternatively, it is possible to specify constraints to both RooAbsPdf::fitTo() and the RooMCStudy constructor; using the ExternalConstraint() named argument to supply constraint p.d.f.s that are not part of the 'master'; p.d.f but rather an ad-hoc supplied external constraint. The argument supplied to ExternalConstraint() should; be (a set of) constraint p.d.f(s), rather than (a set of) parameters for which internal constraint p.d.f.s should; be picked up. New operator class RooLinearMorph. A new numeric operator class RooLinearMorph has been added that provides a continuous; transformation between two p.d.f.s shapes in terms of a linear parameter alpha. The algorithm ; for histograms is described in the paper by Alex Read in NUM A 425 (1999) 357-369 ; 'Linear interpolation of histograms'. The implementation in RooLinearMorph is for; continuous functions. . // Observable and sampling binning to be used by RooLinearMorph (""cache""); RooRealVar x(""x"",""x"",-20,20) ;; x.setBins(1000,""cache"") ;. // End point shapes : a gaussian on one end, a polynomial on the other; RooGaussian f1(""f1"",""f1"",x,RooConst(-10),RooConst(2)) ;; RooPolynomial f2(""f2"",""f2"",x,RooArgSet(RooConst(-0.03),RooConst(-0.001))) ;. // Interpolation parameter: rlm=f1 at alpha=0, rlm=f2 at alpha=1; RooRealVar alpha(""alpha"",""alpha"",0,1.0) ;; RooLinearMorph rlm(""rlm"",""rlm"",g1,g2,x,alpha) ;. // Plot halfway shape; alpha=0.5; RooPlot* frame = x.frame() ;; rlm.plotOn(frame) ;. In short the algorithm works as follows: for both f1(x) and f2(x), the cumulative distribution; functions F1(x) and F2(x) are calculated. One finds takes a value 'y' of both c.d.fs and ; determines the corresponding x values x1,x2 at which F1(x1)=F2(x2)=y. The value of the interpolated ; p.d.f fbar(x) is then calculated as fbar(alpha*x1+(1-alpha)*x2) = f1(x1)*f2(x2) / ( alpha*f2(x2) + ; (1-alpha)*f1(x1) ). Given that it is not easily possible to calculate the value of RooLinearMorph; at a given value of x, the value for all values o",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:11305,Performance,cache,cache,11305,""",-20,20) ;; x.setBins(1000,""cache"") ;. // End point shapes : a gaussian on one end, a polynomial on the other; RooGaussian f1(""f1"",""f1"",x,RooConst(-10),RooConst(2)) ;; RooPolynomial f2(""f2"",""f2"",x,RooArgSet(RooConst(-0.03),RooConst(-0.001))) ;. // Interpolation parameter: rlm=f1 at alpha=0, rlm=f2 at alpha=1; RooRealVar alpha(""alpha"",""alpha"",0,1.0) ;; RooLinearMorph rlm(""rlm"",""rlm"",g1,g2,x,alpha) ;. // Plot halfway shape; alpha=0.5; RooPlot* frame = x.frame() ;; rlm.plotOn(frame) ;. In short the algorithm works as follows: for both f1(x) and f2(x), the cumulative distribution; functions F1(x) and F2(x) are calculated. One finds takes a value 'y' of both c.d.fs and ; determines the corresponding x values x1,x2 at which F1(x1)=F2(x2)=y. The value of the interpolated ; p.d.f fbar(x) is then calculated as fbar(alpha*x1+(1-alpha)*x2) = f1(x1)*f2(x2) / ( alpha*f2(x2) + ; (1-alpha)*f1(x1) ). Given that it is not easily possible to calculate the value of RooLinearMorph; at a given value of x, the value for all values of x are calculated in one by (through a scan over y); and stored in a cache. NB: The range of the interpolation parameter does not need to be [0,1], it can; be anything. New workspace tool RooSimWSTool. A new tool to clone and customize p.d.f.s into a RooSimultaneous p.d.f has been added. This new; tool succeeds the original RooSimPdfBuilder tool which had a similar functionality but; has a much cleaner interface, partly thanks to its use of the RooWorkspace class for both input; of prototype p.d.fs and output of built p.d.f.s. The simplest use case to to take a workspace p.d.f as prototype and 'split' a parameter of that p.d.f ; into two specialized parameters depending on a category in the dataset. ; For example, given a Gaussian p.d.f G(x,m,s) we want to construct a G_a(x,m_a,s) and a G_b(x,m_b,s); with different mean parameters to be fit to a dataset with observables; (x,c) where c is a category with states 'a' and 'b'.; Using RooSimWSTool one can create a",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:12555,Performance,perform,performed,12555,"dfBuilder tool which had a similar functionality but; has a much cleaner interface, partly thanks to its use of the RooWorkspace class for both input; of prototype p.d.fs and output of built p.d.f.s. The simplest use case to to take a workspace p.d.f as prototype and 'split' a parameter of that p.d.f ; into two specialized parameters depending on a category in the dataset. ; For example, given a Gaussian p.d.f G(x,m,s) we want to construct a G_a(x,m_a,s) and a G_b(x,m_b,s); with different mean parameters to be fit to a dataset with observables; (x,c) where c is a category with states 'a' and 'b'.; Using RooSimWSTool one can create a simultaneous p.d.f from G_a and G_b; from G with the following command. RooSimWSTool wst(wspace) ;; wst.build(""G_sim"",""G"",SplitParam(""m"",""c"")) ;. From this simple example one can go to builds of arbitrary complexity; by specifying multiple SplitParam arguments on multiple parameters; involving multiple splitting categories. Splits can also be performed; in the product multiple categories, e.g. . SplitParam(""m"",""c,d"")) ;. splits parameter m in the product of states of c and d. Another possibility; is the 'constrained' split which clones the parameter for all but one state; and insert a formula specialization in a chosen state that evaluates; to 1 - sum_i(a_i) where a_i are all other specializations. For example,; given a category c with state ""A"",""B"",""C"",""D"" the specification. SplitParamConstrained(""m"",""c"",""D""). will result in parameters m_A,m_B,m_C and a formula expression m_D; that evaluates to (1-(m_A+m_B+m_C)). Constrained split can also be; specified in product of categories. In that case the name of the; remainder state follows the syntax {State1;State2} where State1; and State2 are the state names of the two spitting categories. Additional; functionality exists to work with multiple prototype p.d.f.s simultaneously. ; Improved infrastructure for caching p.d.f and functions. The infrastructure that exists for caching p.d.f.s, i.e. p.",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:13642,Performance,cache,cache,13642," ;. splits parameter m in the product of states of c and d. Another possibility; is the 'constrained' split which clones the parameter for all but one state; and insert a formula specialization in a chosen state that evaluates; to 1 - sum_i(a_i) where a_i are all other specializations. For example,; given a category c with state ""A"",""B"",""C"",""D"" the specification. SplitParamConstrained(""m"",""c"",""D""). will result in parameters m_A,m_B,m_C and a formula expression m_D; that evaluates to (1-(m_A+m_B+m_C)). Constrained split can also be; specified in product of categories. In that case the name of the; remainder state follows the syntax {State1;State2} where State1; and State2 are the state names of the two spitting categories. Additional; functionality exists to work with multiple prototype p.d.f.s simultaneously. ; Improved infrastructure for caching p.d.f and functions. The infrastructure that exists for caching p.d.f.s, i.e. p.d.f that precalculate their value; for all observable values at one and cache those in a histogram that is returned as p.d.f shape; (with optional interpolation), has been expanded. This infrastructure comprises RooAbsCached; the base class for all caching p.d.fs, RooAbsSelfCachedPdf a base class for end-user; caching p.d.f implementations that simply cache the result of evaluate() and RooCachedPdf; that can wrap and cache any input p.d.f specified in its constructor. . By default a p.d.f is sampled and cached in all observables in any; given use context, with no need to specify what those are in advance.; The internal code has also been changed such that all cache; histograms now store pre-normalized p.d.f, which is more efficient; than 'raw' p.d.f histograms that are explicitly post-normalized; through integration. Multiple different use cases (e.g. definitions; of what are observables vs parameters) can be cached; simultaneously. Now it is also possible to specify that p.d.f.s; should be sampled and cached in one or more parameter dimensions; ",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:13924,Performance,cache,cache,13924,"with state ""A"",""B"",""C"",""D"" the specification. SplitParamConstrained(""m"",""c"",""D""). will result in parameters m_A,m_B,m_C and a formula expression m_D; that evaluates to (1-(m_A+m_B+m_C)). Constrained split can also be; specified in product of categories. In that case the name of the; remainder state follows the syntax {State1;State2} where State1; and State2 are the state names of the two spitting categories. Additional; functionality exists to work with multiple prototype p.d.f.s simultaneously. ; Improved infrastructure for caching p.d.f and functions. The infrastructure that exists for caching p.d.f.s, i.e. p.d.f that precalculate their value; for all observable values at one and cache those in a histogram that is returned as p.d.f shape; (with optional interpolation), has been expanded. This infrastructure comprises RooAbsCached; the base class for all caching p.d.fs, RooAbsSelfCachedPdf a base class for end-user; caching p.d.f implementations that simply cache the result of evaluate() and RooCachedPdf; that can wrap and cache any input p.d.f specified in its constructor. . By default a p.d.f is sampled and cached in all observables in any; given use context, with no need to specify what those are in advance.; The internal code has also been changed such that all cache; histograms now store pre-normalized p.d.f, which is more efficient; than 'raw' p.d.f histograms that are explicitly post-normalized; through integration. Multiple different use cases (e.g. definitions; of what are observables vs parameters) can be cached; simultaneously. Now it is also possible to specify that p.d.f.s; should be sampled and cached in one or more parameter dimensions; in addition to the automatically determined set of observables.; as well. Also a complete new line of classes with similar functionality has been added inheriting from RooAbsReal.; These are RooAbsCachedReal,RooAbsSelfCachedReal and RooCachedReal. A newly; added class RooHistFunc presents these shapes and is capable of",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:13991,Performance,cache,cache,13991,"with state ""A"",""B"",""C"",""D"" the specification. SplitParamConstrained(""m"",""c"",""D""). will result in parameters m_A,m_B,m_C and a formula expression m_D; that evaluates to (1-(m_A+m_B+m_C)). Constrained split can also be; specified in product of categories. In that case the name of the; remainder state follows the syntax {State1;State2} where State1; and State2 are the state names of the two spitting categories. Additional; functionality exists to work with multiple prototype p.d.f.s simultaneously. ; Improved infrastructure for caching p.d.f and functions. The infrastructure that exists for caching p.d.f.s, i.e. p.d.f that precalculate their value; for all observable values at one and cache those in a histogram that is returned as p.d.f shape; (with optional interpolation), has been expanded. This infrastructure comprises RooAbsCached; the base class for all caching p.d.fs, RooAbsSelfCachedPdf a base class for end-user; caching p.d.f implementations that simply cache the result of evaluate() and RooCachedPdf; that can wrap and cache any input p.d.f specified in its constructor. . By default a p.d.f is sampled and cached in all observables in any; given use context, with no need to specify what those are in advance.; The internal code has also been changed such that all cache; histograms now store pre-normalized p.d.f, which is more efficient; than 'raw' p.d.f histograms that are explicitly post-normalized; through integration. Multiple different use cases (e.g. definitions; of what are observables vs parameters) can be cached; simultaneously. Now it is also possible to specify that p.d.f.s; should be sampled and cached in one or more parameter dimensions; in addition to the automatically determined set of observables.; as well. Also a complete new line of classes with similar functionality has been added inheriting from RooAbsReal.; These are RooAbsCachedReal,RooAbsSelfCachedReal and RooCachedReal. A newly; added class RooHistFunc presents these shapes and is capable of",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:14079,Performance,cache,cached,14079,"(m_A+m_B+m_C)). Constrained split can also be; specified in product of categories. In that case the name of the; remainder state follows the syntax {State1;State2} where State1; and State2 are the state names of the two spitting categories. Additional; functionality exists to work with multiple prototype p.d.f.s simultaneously. ; Improved infrastructure for caching p.d.f and functions. The infrastructure that exists for caching p.d.f.s, i.e. p.d.f that precalculate their value; for all observable values at one and cache those in a histogram that is returned as p.d.f shape; (with optional interpolation), has been expanded. This infrastructure comprises RooAbsCached; the base class for all caching p.d.fs, RooAbsSelfCachedPdf a base class for end-user; caching p.d.f implementations that simply cache the result of evaluate() and RooCachedPdf; that can wrap and cache any input p.d.f specified in its constructor. . By default a p.d.f is sampled and cached in all observables in any; given use context, with no need to specify what those are in advance.; The internal code has also been changed such that all cache; histograms now store pre-normalized p.d.f, which is more efficient; than 'raw' p.d.f histograms that are explicitly post-normalized; through integration. Multiple different use cases (e.g. definitions; of what are observables vs parameters) can be cached; simultaneously. Now it is also possible to specify that p.d.f.s; should be sampled and cached in one or more parameter dimensions; in addition to the automatically determined set of observables.; as well. Also a complete new line of classes with similar functionality has been added inheriting from RooAbsReal.; These are RooAbsCachedReal,RooAbsSelfCachedReal and RooCachedReal. A newly; added class RooHistFunc presents these shapes and is capable of handling negative entries. New PDF error handling structure. New infrastructure has been put into place to propagate and process p.d.f evaluation errors during fitting.;",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:14238,Performance,cache,cache,14238,"e; remainder state follows the syntax {State1;State2} where State1; and State2 are the state names of the two spitting categories. Additional; functionality exists to work with multiple prototype p.d.f.s simultaneously. ; Improved infrastructure for caching p.d.f and functions. The infrastructure that exists for caching p.d.f.s, i.e. p.d.f that precalculate their value; for all observable values at one and cache those in a histogram that is returned as p.d.f shape; (with optional interpolation), has been expanded. This infrastructure comprises RooAbsCached; the base class for all caching p.d.fs, RooAbsSelfCachedPdf a base class for end-user; caching p.d.f implementations that simply cache the result of evaluate() and RooCachedPdf; that can wrap and cache any input p.d.f specified in its constructor. . By default a p.d.f is sampled and cached in all observables in any; given use context, with no need to specify what those are in advance.; The internal code has also been changed such that all cache; histograms now store pre-normalized p.d.f, which is more efficient; than 'raw' p.d.f histograms that are explicitly post-normalized; through integration. Multiple different use cases (e.g. definitions; of what are observables vs parameters) can be cached; simultaneously. Now it is also possible to specify that p.d.f.s; should be sampled and cached in one or more parameter dimensions; in addition to the automatically determined set of observables.; as well. Also a complete new line of classes with similar functionality has been added inheriting from RooAbsReal.; These are RooAbsCachedReal,RooAbsSelfCachedReal and RooCachedReal. A newly; added class RooHistFunc presents these shapes and is capable of handling negative entries. New PDF error handling structure. New infrastructure has been put into place to propagate and process p.d.f evaluation errors during fitting.; Previously evaluation errors were marked with a zero p.d.f value and propagated as a special condition; in Roo",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:14493,Performance,cache,cached,14493,"ure for caching p.d.f and functions. The infrastructure that exists for caching p.d.f.s, i.e. p.d.f that precalculate their value; for all observable values at one and cache those in a histogram that is returned as p.d.f shape; (with optional interpolation), has been expanded. This infrastructure comprises RooAbsCached; the base class for all caching p.d.fs, RooAbsSelfCachedPdf a base class for end-user; caching p.d.f implementations that simply cache the result of evaluate() and RooCachedPdf; that can wrap and cache any input p.d.f specified in its constructor. . By default a p.d.f is sampled and cached in all observables in any; given use context, with no need to specify what those are in advance.; The internal code has also been changed such that all cache; histograms now store pre-normalized p.d.f, which is more efficient; than 'raw' p.d.f histograms that are explicitly post-normalized; through integration. Multiple different use cases (e.g. definitions; of what are observables vs parameters) can be cached; simultaneously. Now it is also possible to specify that p.d.f.s; should be sampled and cached in one or more parameter dimensions; in addition to the automatically determined set of observables.; as well. Also a complete new line of classes with similar functionality has been added inheriting from RooAbsReal.; These are RooAbsCachedReal,RooAbsSelfCachedReal and RooCachedReal. A newly; added class RooHistFunc presents these shapes and is capable of handling negative entries. New PDF error handling structure. New infrastructure has been put into place to propagate and process p.d.f evaluation errors during fitting.; Previously evaluation errors were marked with a zero p.d.f value and propagated as a special condition; in RooAddPdf, RooProdPdf etc to result in a zero top-level p.d.f value that was caught by the RooFit minuit; interface as a special condition. Summary information on the value of the parameters and the observables; was printed for the first 10 occu",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:14588,Performance,cache,cached,14588,"s at one and cache those in a histogram that is returned as p.d.f shape; (with optional interpolation), has been expanded. This infrastructure comprises RooAbsCached; the base class for all caching p.d.fs, RooAbsSelfCachedPdf a base class for end-user; caching p.d.f implementations that simply cache the result of evaluate() and RooCachedPdf; that can wrap and cache any input p.d.f specified in its constructor. . By default a p.d.f is sampled and cached in all observables in any; given use context, with no need to specify what those are in advance.; The internal code has also been changed such that all cache; histograms now store pre-normalized p.d.f, which is more efficient; than 'raw' p.d.f histograms that are explicitly post-normalized; through integration. Multiple different use cases (e.g. definitions; of what are observables vs parameters) can be cached; simultaneously. Now it is also possible to specify that p.d.f.s; should be sampled and cached in one or more parameter dimensions; in addition to the automatically determined set of observables.; as well. Also a complete new line of classes with similar functionality has been added inheriting from RooAbsReal.; These are RooAbsCachedReal,RooAbsSelfCachedReal and RooCachedReal. A newly; added class RooHistFunc presents these shapes and is capable of handling negative entries. New PDF error handling structure. New infrastructure has been put into place to propagate and process p.d.f evaluation errors during fitting.; Previously evaluation errors were marked with a zero p.d.f value and propagated as a special condition; in RooAddPdf, RooProdPdf etc to result in a zero top-level p.d.f value that was caught by the RooFit minuit; interface as a special condition. Summary information on the value of the parameters and the observables; was printed for the first 10 occurrences of such conditions. . Now, each p.d.f component that generates an error; in its evaluation logs the error into a separate facility during fitting ",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:19661,Performance,optimiz,optimizations,19661,"oStream() has been deprecated in favor of a new; printStream() method which allows much greater control over the information printed. ; The printing of almost all RooFit objects has been reworked to present a more uniform look and feel.; The standard one-line result of the high-level Print() method without option now looks like. // Variable; x.Print() ;; RooRealVar::x = 0 L(-10 - 10) . // Function or p.d.f; gx.Print() ;; RooGaussian::gx[ x=x mean=m sigma=sx ] = 1. // Dataset; d.Print() ;; RooDataSet::gData[x,y] = 1000 entries. // RooPlot; frame.Print() ;; framex[x] = (RooHist::h_gData,RooCurve::g_Int[y]_Norm[x,y]_Comp[g]). Inside class RooPlot the default name of contained curves and histograms has been ; reworked in something more self descriptive as is shown in the above example. A usual,; a user supplied name can always be set by supplying the Name(const char*) argument; to plotOn(). Verbose printing with ""v"" options is mostly unchanged except for RooPlot. In addition; printing with the ""s"" option will show the 'old' standard printing mode, option ""t"" will show; tree structure printing (only for RooAbsArg), and option ""1"" will invoke inline printing, i.e; a one-line description without a trailing endl.; Data weighted projections of p.d.fs using the ProjWData() argument in RooAbsPdf::plotOn() are now calculated; with a new classes that derives from RooAbsOptTestStatistic and can thus implement the same evaluation; optimizations as are done for RooNLLVar and RooChi2Var. Specifically it is now possible to calculate projections; involving ProjWData() in parallel on multi-core hosts by adding the NumCPU(Int_t) argument to plotOn().; ; A new utility function has been added to allow cloning of entire tree expressions of; RooAbsArg objects, such as a composite p.d.f including component p.d.fs and; all its variables:. RooAbsArg* clonedTree = pdf.cloneTree() ;. All cloned leaf and branch nodes are owned by the returned head node of the expression.; Assorted minor fixes; ; ",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:3008,Security,access,accessors,3008,"an automatically find the source; code using the ROOT TClass interface. For custom classes that are compiled; externally and loaded into ROOT as shared library it might be necessary to; provide the location of the source files manually using the static RooWorkspace; member functions addClassDeclImportDir() and addClassImplImportDir().; ; When a TFile with a RooWorkspace containing source code is opened in a ROOT; session that does not have the class code already loaded for the classes; contained in the workspace, the code in the workspace is written to file,; compiled and loaded into the ROOT session on the fly. The code repository of RooWorkspace is designed to handle classes that; have either their own implementation and header file, or are part of a group; of classes that share a common header and implementation file. More complicated; structuring of source code into files is not supported. ; ; Also new accessors have been added for discrete-valued functions catfunc(); and stored category functions are now also printed under their own heading in Print(); Parameterized ranges. It is now possible to use RooAbsReal derived functions as range definition for variables; to construct ranges that vary as function of another variable. For example. RooRealVar x(""x"",""x"",-10,10) ; // variable with fixed range [-10,10] ; RooRealVar y(""y"",""y"",0,20) ; // variable with fixed range [-10,10] ; ; RooFormulaVar x_lo(""x_lo"",""y-20"",y) ; ; RooFormulaVar x_hi(""x_hi"",""sin(y)*5"",y) ; ; x.setRange(x_lo,x_hi) ; // Change x to have variable range depending on y; ; It is also possible to define parameterized named ranges in the same way. x.setRange(""signalRegion"",x_lo,x_hi) ;. There are no fundamental limits to the complexity of the parameterized ranges; that can be defined as long as the problem is uniquely defined. For example, given three observables ; x, y and z, one can define a parameterized named range 'R' of x in terms of y and of y in terms of z; and ask to calculate the three dimensi",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:7233,Testability,log,logistics,7233,"e cases. Cumulative distributions functions that are calculated numerically are handled slightly differently; that standard running integrals: their values is constructed to converge to exactly zero at the lower bound; and exactly 1 at the upper bound so that algorithms that make use of that property of c.d.f can do so reliably. Constraints management. New tools have been added to simplify studies with fits involving (external) constraints on parameters.; The general philosophy is that constraints on parameters can be represented as probability density functions; and can thus be modeled by RooAbsPdf classes (e.g. a RooGaussian for a simple Gaussian constraint on a parameter).; There are two modes of operation: you can add parameter constraints to your problem definition by multiplying; the constraint p.d.f.s with your 'master' p.d.f. or you specify them externally in each operation. The; first mode of operation keeps all information in your master p.d.f and may make the logistics of non-trivial; fitting problems easier. It works as follows: first you define your regular p.d.f, then you define your; constraint p.d.f and you multiply them with RooProdPdf. // Construct constraint; RooGaussian fconstraint(""fconstraint"",""fconstraint"",f,RooConst(0.8),RooConst(0.1)) ;. // Multiply constraint with p.d.f; RooProdPdf pdfc(""pdfc"",""p.d.f with constraint"",RooArgSet(p.d.f,fconstraint)) ;. If your top level p.d.f is already a RooProdPdf it also fine to multiply all terms together in one go.; Constraints do not need to be specified a the top-level RooProdPdf, constraint p.d.f.s in any component; RooProdPdf lower in the expression tree are used as well. Constraints are not used by default in fitting; if present in a p.d.f. To activate the use of a constraint in fitting, use the Constrain() argument in fitTo(). // Fit with internal constraint; RooFitResult* r2 = pdfc.fitTo(*d,Constrain(f)) ;; ; This will instruct RooAbsPdf::fitTo() to included any constraint p.d.f on parameter f in th",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:15574,Testability,log,logs,15574,"meter dimensions; in addition to the automatically determined set of observables.; as well. Also a complete new line of classes with similar functionality has been added inheriting from RooAbsReal.; These are RooAbsCachedReal,RooAbsSelfCachedReal and RooCachedReal. A newly; added class RooHistFunc presents these shapes and is capable of handling negative entries. New PDF error handling structure. New infrastructure has been put into place to propagate and process p.d.f evaluation errors during fitting.; Previously evaluation errors were marked with a zero p.d.f value and propagated as a special condition; in RooAddPdf, RooProdPdf etc to result in a zero top-level p.d.f value that was caught by the RooFit minuit; interface as a special condition. Summary information on the value of the parameters and the observables; was printed for the first 10 occurrences of such conditions. . Now, each p.d.f component that generates an error; in its evaluation logs the error into a separate facility during fitting and the RooFit minuit interface; polls this error logging facility for problems. This allows much more detailed and accurate warning messages; during the minimization phase. The level of verbosity of this new error facility can be controlled with; a new . PrintEvalErrors(Int_t code). argument to fitTo(). . With code of -1, no errors are printed at all.; With a; code of zero, one line is printed for each p.d.f component with problems summarizing the number of times; problems occurred during the likelihood evaluation. . [#0] WARNING:Minization -- RooFitGlue: Minimized function has error status. ; Returning maximum FCN so far (-1e+30) to force MIGRAD to back out of this region. Error log follows; Parameter values: m=-7.397; RooGaussian::gx[ x=x mean=m sigma=sx ] has 3 errors. A code greater than zero will generate even more detail and; print the details of each evaluation error as provided by the p.d.f (zero value, not-a-number, normalization zero etc..); and show the obser",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:15679,Testability,log,logging,15679,"meter dimensions; in addition to the automatically determined set of observables.; as well. Also a complete new line of classes with similar functionality has been added inheriting from RooAbsReal.; These are RooAbsCachedReal,RooAbsSelfCachedReal and RooCachedReal. A newly; added class RooHistFunc presents these shapes and is capable of handling negative entries. New PDF error handling structure. New infrastructure has been put into place to propagate and process p.d.f evaluation errors during fitting.; Previously evaluation errors were marked with a zero p.d.f value and propagated as a special condition; in RooAddPdf, RooProdPdf etc to result in a zero top-level p.d.f value that was caught by the RooFit minuit; interface as a special condition. Summary information on the value of the parameters and the observables; was printed for the first 10 occurrences of such conditions. . Now, each p.d.f component that generates an error; in its evaluation logs the error into a separate facility during fitting and the RooFit minuit interface; polls this error logging facility for problems. This allows much more detailed and accurate warning messages; during the minimization phase. The level of verbosity of this new error facility can be controlled with; a new . PrintEvalErrors(Int_t code). argument to fitTo(). . With code of -1, no errors are printed at all.; With a; code of zero, one line is printed for each p.d.f component with problems summarizing the number of times; problems occurred during the likelihood evaluation. . [#0] WARNING:Minization -- RooFitGlue: Minimized function has error status. ; Returning maximum FCN so far (-1e+30) to force MIGRAD to back out of this region. Error log follows; Parameter values: m=-7.397; RooGaussian::gx[ x=x mean=m sigma=sx ] has 3 errors. A code greater than zero will generate even more detail and; print the details of each evaluation error as provided by the p.d.f (zero value, not-a-number, normalization zero etc..); and show the obser",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:16319,Testability,log,log,16319,"t; interface as a special condition. Summary information on the value of the parameters and the observables; was printed for the first 10 occurrences of such conditions. . Now, each p.d.f component that generates an error; in its evaluation logs the error into a separate facility during fitting and the RooFit minuit interface; polls this error logging facility for problems. This allows much more detailed and accurate warning messages; during the minimization phase. The level of verbosity of this new error facility can be controlled with; a new . PrintEvalErrors(Int_t code). argument to fitTo(). . With code of -1, no errors are printed at all.; With a; code of zero, one line is printed for each p.d.f component with problems summarizing the number of times; problems occurred during the likelihood evaluation. . [#0] WARNING:Minization -- RooFitGlue: Minimized function has error status. ; Returning maximum FCN so far (-1e+30) to force MIGRAD to back out of this region. Error log follows; Parameter values: m=-7.397; RooGaussian::gx[ x=x mean=m sigma=sx ] has 3 errors. A code greater than zero will generate even more detail and; print the details of each evaluation error as provided by the p.d.f (zero value, not-a-number, normalization zero etc..); and show the observable values at which this error occurred. At most N detailed messages per p.d.f component; are shown where N is the integral value of the 'code' argument. . [#0] WARNING:Minization -- RooFitGlue: Minimized function has error status.; Returning maximum FCN so far (-1e+30) to force MIGRAD to back out of this region. Error log follows; Parameter values: m=-7.397; RooGaussian::gx[ x=x mean=m sigma=sx ]; getLogVal() top-level p.d.f evaluates to zero or negative number @ x=x=9.09989, mean=m=-7.39713, sigma=sx=0.1; getLogVal() top-level p.d.f evaluates to zero or negative number @ x=x=6.04652, mean=m=-7.39713, sigma=sx=0.1; getLogVal() top-level p.d.f evaluates to zero or negative number @ x=x=2.48563, mean=m=-7.3971",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:16937,Testability,log,log,16937,"1, no errors are printed at all.; With a; code of zero, one line is printed for each p.d.f component with problems summarizing the number of times; problems occurred during the likelihood evaluation. . [#0] WARNING:Minization -- RooFitGlue: Minimized function has error status. ; Returning maximum FCN so far (-1e+30) to force MIGRAD to back out of this region. Error log follows; Parameter values: m=-7.397; RooGaussian::gx[ x=x mean=m sigma=sx ] has 3 errors. A code greater than zero will generate even more detail and; print the details of each evaluation error as provided by the p.d.f (zero value, not-a-number, normalization zero etc..); and show the observable values at which this error occurred. At most N detailed messages per p.d.f component; are shown where N is the integral value of the 'code' argument. . [#0] WARNING:Minization -- RooFitGlue: Minimized function has error status.; Returning maximum FCN so far (-1e+30) to force MIGRAD to back out of this region. Error log follows; Parameter values: m=-7.397; RooGaussian::gx[ x=x mean=m sigma=sx ]; getLogVal() top-level p.d.f evaluates to zero or negative number @ x=x=9.09989, mean=m=-7.39713, sigma=sx=0.1; getLogVal() top-level p.d.f evaluates to zero or negative number @ x=x=6.04652, mean=m=-7.39713, sigma=sx=0.1; getLogVal() top-level p.d.f evaluates to zero or negative number @ x=x=2.48563, mean=m=-7.39713, sigma=sx=0.1. The new-style error logging is active whenever MINUIT is operating on such a p.d.f. The default value for N is 3.; Outside the MINUIT context the evaluation error each evualuation error will generate a separate message through; RooMsgService; Other new features. The RooAddPdf constructor has been augmented with an additional boolean argument that allows to; interpret the supplied fraction parameters as recursive fractions rather than plain fractions.; If activated, an example RooAddPdf with three input p.d.f. A,B,C and two fractions fA and fB will; result in the expression; fA*A + (1-fA)(fB*B +",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:17371,Testability,log,logging,17371,"gma=sx ] has 3 errors. A code greater than zero will generate even more detail and; print the details of each evaluation error as provided by the p.d.f (zero value, not-a-number, normalization zero etc..); and show the observable values at which this error occurred. At most N detailed messages per p.d.f component; are shown where N is the integral value of the 'code' argument. . [#0] WARNING:Minization -- RooFitGlue: Minimized function has error status.; Returning maximum FCN so far (-1e+30) to force MIGRAD to back out of this region. Error log follows; Parameter values: m=-7.397; RooGaussian::gx[ x=x mean=m sigma=sx ]; getLogVal() top-level p.d.f evaluates to zero or negative number @ x=x=9.09989, mean=m=-7.39713, sigma=sx=0.1; getLogVal() top-level p.d.f evaluates to zero or negative number @ x=x=6.04652, mean=m=-7.39713, sigma=sx=0.1; getLogVal() top-level p.d.f evaluates to zero or negative number @ x=x=2.48563, mean=m=-7.39713, sigma=sx=0.1. The new-style error logging is active whenever MINUIT is operating on such a p.d.f. The default value for N is 3.; Outside the MINUIT context the evaluation error each evualuation error will generate a separate message through; RooMsgService; Other new features. The RooAddPdf constructor has been augmented with an additional boolean argument that allows to; interpret the supplied fraction parameters as recursive fractions rather than plain fractions.; If activated, an example RooAddPdf with three input p.d.f. A,B,C and two fractions fA and fB will; result in the expression; fA*A + (1-fA)(fB*B + 1-fB*C) rather than fA*A + fB*B + (1-fA-fB)*C. Recursive fraction have the advantage that all fraction can be defined to be in the range [0-1]; without resulting in configuration where the sum of all fractions exceeds 1.; The low-level object printing interface printToStream() has been deprecated in favor of a new; printStream() method which allows much greater control over the information printed. ; The printing of almost all RooFit",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:6632,Usability,simpl,simplify,6632,"ly styled function createIntegral running integrals and c.d.f. can be created; over any number of observables, e.g createCdf(RooArgSet(x,y,z)) will create a three-dimensional; cumulative distribution function. C.d.f and running integrals that are calculated from p.d.fs that have; support for analytical integration are constructed from an appropriately reconnected RooRealIntegral.; If numeric integration is required, the c.d.f or running integral is calculated by a dedicated class; RooRunningIntegral that precalculates results for all observable values, which is more efficient; in most use cases. Cumulative distributions functions that are calculated numerically are handled slightly differently; that standard running integrals: their values is constructed to converge to exactly zero at the lower bound; and exactly 1 at the upper bound so that algorithms that make use of that property of c.d.f can do so reliably. Constraints management. New tools have been added to simplify studies with fits involving (external) constraints on parameters.; The general philosophy is that constraints on parameters can be represented as probability density functions; and can thus be modeled by RooAbsPdf classes (e.g. a RooGaussian for a simple Gaussian constraint on a parameter).; There are two modes of operation: you can add parameter constraints to your problem definition by multiplying; the constraint p.d.f.s with your 'master' p.d.f. or you specify them externally in each operation. The; first mode of operation keeps all information in your master p.d.f and may make the logistics of non-trivial; fitting problems easier. It works as follows: first you define your regular p.d.f, then you define your; constraint p.d.f and you multiply them with RooProdPdf. // Construct constraint; RooGaussian fconstraint(""fconstraint"",""fconstraint"",f,RooConst(0.8),RooConst(0.1)) ;. // Multiply constraint with p.d.f; RooProdPdf pdfc(""pdfc"",""p.d.f with constraint"",RooArgSet(p.d.f,fconstraint)) ;. If your ",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:6889,Usability,simpl,simple,6889," calculated from p.d.fs that have; support for analytical integration are constructed from an appropriately reconnected RooRealIntegral.; If numeric integration is required, the c.d.f or running integral is calculated by a dedicated class; RooRunningIntegral that precalculates results for all observable values, which is more efficient; in most use cases. Cumulative distributions functions that are calculated numerically are handled slightly differently; that standard running integrals: their values is constructed to converge to exactly zero at the lower bound; and exactly 1 at the upper bound so that algorithms that make use of that property of c.d.f can do so reliably. Constraints management. New tools have been added to simplify studies with fits involving (external) constraints on parameters.; The general philosophy is that constraints on parameters can be represented as probability density functions; and can thus be modeled by RooAbsPdf classes (e.g. a RooGaussian for a simple Gaussian constraint on a parameter).; There are two modes of operation: you can add parameter constraints to your problem definition by multiplying; the constraint p.d.f.s with your 'master' p.d.f. or you specify them externally in each operation. The; first mode of operation keeps all information in your master p.d.f and may make the logistics of non-trivial; fitting problems easier. It works as follows: first you define your regular p.d.f, then you define your; constraint p.d.f and you multiply them with RooProdPdf. // Construct constraint; RooGaussian fconstraint(""fconstraint"",""fconstraint"",f,RooConst(0.8),RooConst(0.1)) ;. // Multiply constraint with p.d.f; RooProdPdf pdfc(""pdfc"",""p.d.f with constraint"",RooArgSet(p.d.f,fconstraint)) ;. If your top level p.d.f is already a RooProdPdf it also fine to multiply all terms together in one go.; Constraints do not need to be specified a the top-level RooProdPdf, constraint p.d.f.s in any component; RooProdPdf lower in the expression tree are u",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:11773,Usability,simpl,simplest,11773," functions F1(x) and F2(x) are calculated. One finds takes a value 'y' of both c.d.fs and ; determines the corresponding x values x1,x2 at which F1(x1)=F2(x2)=y. The value of the interpolated ; p.d.f fbar(x) is then calculated as fbar(alpha*x1+(1-alpha)*x2) = f1(x1)*f2(x2) / ( alpha*f2(x2) + ; (1-alpha)*f1(x1) ). Given that it is not easily possible to calculate the value of RooLinearMorph; at a given value of x, the value for all values of x are calculated in one by (through a scan over y); and stored in a cache. NB: The range of the interpolation parameter does not need to be [0,1], it can; be anything. New workspace tool RooSimWSTool. A new tool to clone and customize p.d.f.s into a RooSimultaneous p.d.f has been added. This new; tool succeeds the original RooSimPdfBuilder tool which had a similar functionality but; has a much cleaner interface, partly thanks to its use of the RooWorkspace class for both input; of prototype p.d.fs and output of built p.d.f.s. The simplest use case to to take a workspace p.d.f as prototype and 'split' a parameter of that p.d.f ; into two specialized parameters depending on a category in the dataset. ; For example, given a Gaussian p.d.f G(x,m,s) we want to construct a G_a(x,m_a,s) and a G_b(x,m_b,s); with different mean parameters to be fit to a dataset with observables; (x,c) where c is a category with states 'a' and 'b'.; Using RooSimWSTool one can create a simultaneous p.d.f from G_a and G_b; from G with the following command. RooSimWSTool wst(wspace) ;; wst.build(""G_sim"",""G"",SplitParam(""m"",""c"")) ;. From this simple example one can go to builds of arbitrary complexity; by specifying multiple SplitParam arguments on multiple parameters; involving multiple splitting categories. Splits can also be performed; in the product multiple categories, e.g. . SplitParam(""m"",""c,d"")) ;. splits parameter m in the product of states of c and d. Another possibility; is the 'constrained' split which clones the parameter for all but one state; and",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:12366,Usability,simpl,simple,12366,"ool to clone and customize p.d.f.s into a RooSimultaneous p.d.f has been added. This new; tool succeeds the original RooSimPdfBuilder tool which had a similar functionality but; has a much cleaner interface, partly thanks to its use of the RooWorkspace class for both input; of prototype p.d.fs and output of built p.d.f.s. The simplest use case to to take a workspace p.d.f as prototype and 'split' a parameter of that p.d.f ; into two specialized parameters depending on a category in the dataset. ; For example, given a Gaussian p.d.f G(x,m,s) we want to construct a G_a(x,m_a,s) and a G_b(x,m_b,s); with different mean parameters to be fit to a dataset with observables; (x,c) where c is a category with states 'a' and 'b'.; Using RooSimWSTool one can create a simultaneous p.d.f from G_a and G_b; from G with the following command. RooSimWSTool wst(wspace) ;; wst.build(""G_sim"",""G"",SplitParam(""m"",""c"")) ;. From this simple example one can go to builds of arbitrary complexity; by specifying multiple SplitParam arguments on multiple parameters; involving multiple splitting categories. Splits can also be performed; in the product multiple categories, e.g. . SplitParam(""m"",""c,d"")) ;. splits parameter m in the product of states of c and d. Another possibility; is the 'constrained' split which clones the parameter for all but one state; and insert a formula specialization in a chosen state that evaluates; to 1 - sum_i(a_i) where a_i are all other specializations. For example,; given a category c with state ""A"",""B"",""C"",""D"" the specification. SplitParamConstrained(""m"",""c"",""D""). will result in parameters m_A,m_B,m_C and a formula expression m_D; that evaluates to (1-(m_A+m_B+m_C)). Constrained split can also be; specified in product of categories. In that case the name of the; remainder state follows the syntax {State1;State2} where State1; and State2 are the state names of the two spitting categories. Additional; functionality exists to work with multiple prototype p.d.f.s simultane",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html:13917,Usability,simpl,simply,13917,"with state ""A"",""B"",""C"",""D"" the specification. SplitParamConstrained(""m"",""c"",""D""). will result in parameters m_A,m_B,m_C and a formula expression m_D; that evaluates to (1-(m_A+m_B+m_C)). Constrained split can also be; specified in product of categories. In that case the name of the; remainder state follows the syntax {State1;State2} where State1; and State2 are the state names of the two spitting categories. Additional; functionality exists to work with multiple prototype p.d.f.s simultaneously. ; Improved infrastructure for caching p.d.f and functions. The infrastructure that exists for caching p.d.f.s, i.e. p.d.f that precalculate their value; for all observable values at one and cache those in a histogram that is returned as p.d.f shape; (with optional interpolation), has been expanded. This infrastructure comprises RooAbsCached; the base class for all caching p.d.fs, RooAbsSelfCachedPdf a base class for end-user; caching p.d.f implementations that simply cache the result of evaluate() and RooCachedPdf; that can wrap and cache any input p.d.f specified in its constructor. . By default a p.d.f is sampled and cached in all observables in any; given use context, with no need to specify what those are in advance.; The internal code has also been changed such that all cache; histograms now store pre-normalized p.d.f, which is more efficient; than 'raw' p.d.f histograms that are explicitly post-normalized; through integration. Multiple different use cases (e.g. definitions; of what are observables vs parameters) can be cached; simultaneously. Now it is also possible to specify that p.d.f.s; should be sampled and cached in one or more parameter dimensions; in addition to the automatically determined set of observables.; as well. Also a complete new line of classes with similar functionality has been added inheriting from RooAbsReal.; These are RooAbsCachedReal,RooAbsSelfCachedReal and RooCachedReal. A newly; added class RooHistFunc presents these shapes and is capable of",MatchSource.DOCS,roofit/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html:30,Availability,avail,available,30,". RooFit; New tutorial macros available. A completely new set of 70(!) tutorial macros is now available in $ROOTSYS/tutorials/roofit; These macros are divided in several subjects and are all referenced as iluustrations of concepts explained in the forthcoming edition on RooFit Users Manual.; All macros are extensively documented and each is fully functional standalone. The accompanying update; of the Manual is expected mid-September. ; ; BASIC FUNCTIONALITY. rf101_basics.C - Fitting, plotting, toy data generation on one-dimensional p.d.f ; rf102_dataimport.C - Importing data from ROOT TTrees and THx histograms; rf103_interprfuncs.C - Interpreted functions and p.d.f.s; rf104_classfactory.C - The class factory for functions and p.d.f.s; rf105_funcbinding.C - Demonstration of binding ROOT Math functions as RooFit functions and pdfs; rf106_plotdecoration.C - Adding boxes with parameters, statistics to RooPlots.; rf107_plotstyles.C - Demonstration of various plotting styles of data, functions; rf108_plotbinning.C - Plotting unbinned data with alternate and variable binnings; rf109_chi2residpull.C - Calculating chi^2 from histograms and curves in RooPlots,; rf110_normintegration.C - Examples on normalization & integration of p.d.f.s, construction of cumulative distribution functions.; rf111_numintconfig.C - Configuration and customization of how numeric (partial) integrals. ; ADDITION AND CONVOLUTION. rf201_composite.C - Composite p.d.f with signal and background component; rf202_extendedmlfit.C - Setting up an extended maximum likelihood fit; rf203_ranges.C - Fitting and plotting in sub ranges; rf204_extrangefit.C - Extended maximum likelihood fit with alternate range definition; rf205_compplot.C - Options for plotting components of composite p.d.f.s.; rf206_treevistools.C - Tools for visualization of RooAbsArg expression trees; rf207_comptools.C - Tools and utilities for manipulation of composite objects; rf208_convolution.C - One-dimensional numeric convolution; rf209_a",MatchSource.DOCS,roofit/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html:94,Availability,avail,available,94,". RooFit; New tutorial macros available. A completely new set of 70(!) tutorial macros is now available in $ROOTSYS/tutorials/roofit; These macros are divided in several subjects and are all referenced as iluustrations of concepts explained in the forthcoming edition on RooFit Users Manual.; All macros are extensively documented and each is fully functional standalone. The accompanying update; of the Manual is expected mid-September. ; ; BASIC FUNCTIONALITY. rf101_basics.C - Fitting, plotting, toy data generation on one-dimensional p.d.f ; rf102_dataimport.C - Importing data from ROOT TTrees and THx histograms; rf103_interprfuncs.C - Interpreted functions and p.d.f.s; rf104_classfactory.C - The class factory for functions and p.d.f.s; rf105_funcbinding.C - Demonstration of binding ROOT Math functions as RooFit functions and pdfs; rf106_plotdecoration.C - Adding boxes with parameters, statistics to RooPlots.; rf107_plotstyles.C - Demonstration of various plotting styles of data, functions; rf108_plotbinning.C - Plotting unbinned data with alternate and variable binnings; rf109_chi2residpull.C - Calculating chi^2 from histograms and curves in RooPlots,; rf110_normintegration.C - Examples on normalization & integration of p.d.f.s, construction of cumulative distribution functions.; rf111_numintconfig.C - Configuration and customization of how numeric (partial) integrals. ; ADDITION AND CONVOLUTION. rf201_composite.C - Composite p.d.f with signal and background component; rf202_extendedmlfit.C - Setting up an extended maximum likelihood fit; rf203_ranges.C - Fitting and plotting in sub ranges; rf204_extrangefit.C - Extended maximum likelihood fit with alternate range definition; rf205_compplot.C - Options for plotting components of composite p.d.f.s.; rf206_treevistools.C - Tools for visualization of RooAbsArg expression trees; rf207_comptools.C - Tools and utilities for manipulation of composite objects; rf208_convolution.C - One-dimensional numeric convolution; rf209_a",MatchSource.DOCS,roofit/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html:2288,Availability,avail,available,2288,"; rf111_numintconfig.C - Configuration and customization of how numeric (partial) integrals. ; ADDITION AND CONVOLUTION. rf201_composite.C - Composite p.d.f with signal and background component; rf202_extendedmlfit.C - Setting up an extended maximum likelihood fit; rf203_ranges.C - Fitting and plotting in sub ranges; rf204_extrangefit.C - Extended maximum likelihood fit with alternate range definition; rf205_compplot.C - Options for plotting components of composite p.d.f.s.; rf206_treevistools.C - Tools for visualization of RooAbsArg expression trees; rf207_comptools.C - Tools and utilities for manipulation of composite objects; rf208_convolution.C - One-dimensional numeric convolution; rf209_anaconv.C - Decay function p.d.fs with optional B physics. ; MULTIDIMENSIONAL MODELS. rf301_composition.C - Multi-dimensional p.d.f.s through composition, e.g. substituting a p.d.f parameter with a function that depends on other observables; rf302_utilfuncs.C - Utility functions classes available for use in tailoring; rf303_conditional.C - Use of tailored p.d.f as conditional p.d.fs.s; rf304_uncorrprod.C - Simple uncorrelated multi-dimensional p.d.f.s; rf305_condcorrprod.C - Multi-dimensional p.d.f.s with conditional p.d.fs in product; rf306_condpereventerrors.C - Complete example with use of conditional p.d.f. with per-event errors; rf307_fullpereventerrors.C -Complete example with use of full p.d.f. with per-event errors; rf308_normintegration2d.C - Examples on normalization of p.d.f.s in more than one dimension; rf309_ndimplot.C - Making 2 and 3 dimensional plots of p.d.f.s and datasets; rf310_sliceplot.C -Projecting p.d.f and data slices in discrete observables; rf311_rangeplot.C -Projecting p.d.f and data ranges in continuous observables; rf312_multirangefit.C - Performing fits in multiple (disjoint) ranges in one or more dimensions; rf313_paramranges.C - Working with parameterized ranges to define non-rectangular regions; rf314_paramfitrange.C - Working with parameterized",MatchSource.DOCS,roofit/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html:2634,Availability,error,errors,2634,"ended maximum likelihood fit with alternate range definition; rf205_compplot.C - Options for plotting components of composite p.d.f.s.; rf206_treevistools.C - Tools for visualization of RooAbsArg expression trees; rf207_comptools.C - Tools and utilities for manipulation of composite objects; rf208_convolution.C - One-dimensional numeric convolution; rf209_anaconv.C - Decay function p.d.fs with optional B physics. ; MULTIDIMENSIONAL MODELS. rf301_composition.C - Multi-dimensional p.d.f.s through composition, e.g. substituting a p.d.f parameter with a function that depends on other observables; rf302_utilfuncs.C - Utility functions classes available for use in tailoring; rf303_conditional.C - Use of tailored p.d.f as conditional p.d.fs.s; rf304_uncorrprod.C - Simple uncorrelated multi-dimensional p.d.f.s; rf305_condcorrprod.C - Multi-dimensional p.d.f.s with conditional p.d.fs in product; rf306_condpereventerrors.C - Complete example with use of conditional p.d.f. with per-event errors; rf307_fullpereventerrors.C -Complete example with use of full p.d.f. with per-event errors; rf308_normintegration2d.C - Examples on normalization of p.d.f.s in more than one dimension; rf309_ndimplot.C - Making 2 and 3 dimensional plots of p.d.f.s and datasets; rf310_sliceplot.C -Projecting p.d.f and data slices in discrete observables; rf311_rangeplot.C -Projecting p.d.f and data ranges in continuous observables; rf312_multirangefit.C - Performing fits in multiple (disjoint) ranges in one or more dimensions; rf313_paramranges.C - Working with parameterized ranges to define non-rectangular regions; rf314_paramfitrange.C - Working with parameterized ranges in a fit.; rf315_projectpdf.C - Marginizalization of multi-dimensional p.d.f.s through integration; rf316_llratioplot.C - Using the likelihood ratio technique to construct a signal enhanced 1-D projection of a multi-dimensional p.d.f.; ; DATA AND CATEGORIES. rf401_importttreethx.C -Overview of advanced option for importing data from RO",MatchSource.DOCS,roofit/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html:2726,Availability,error,errors,2726," plotting components of composite p.d.f.s.; rf206_treevistools.C - Tools for visualization of RooAbsArg expression trees; rf207_comptools.C - Tools and utilities for manipulation of composite objects; rf208_convolution.C - One-dimensional numeric convolution; rf209_anaconv.C - Decay function p.d.fs with optional B physics. ; MULTIDIMENSIONAL MODELS. rf301_composition.C - Multi-dimensional p.d.f.s through composition, e.g. substituting a p.d.f parameter with a function that depends on other observables; rf302_utilfuncs.C - Utility functions classes available for use in tailoring; rf303_conditional.C - Use of tailored p.d.f as conditional p.d.fs.s; rf304_uncorrprod.C - Simple uncorrelated multi-dimensional p.d.f.s; rf305_condcorrprod.C - Multi-dimensional p.d.f.s with conditional p.d.fs in product; rf306_condpereventerrors.C - Complete example with use of conditional p.d.f. with per-event errors; rf307_fullpereventerrors.C -Complete example with use of full p.d.f. with per-event errors; rf308_normintegration2d.C - Examples on normalization of p.d.f.s in more than one dimension; rf309_ndimplot.C - Making 2 and 3 dimensional plots of p.d.f.s and datasets; rf310_sliceplot.C -Projecting p.d.f and data slices in discrete observables; rf311_rangeplot.C -Projecting p.d.f and data ranges in continuous observables; rf312_multirangefit.C - Performing fits in multiple (disjoint) ranges in one or more dimensions; rf313_paramranges.C - Working with parameterized ranges to define non-rectangular regions; rf314_paramfitrange.C - Working with parameterized ranges in a fit.; rf315_projectpdf.C - Marginizalization of multi-dimensional p.d.f.s through integration; rf316_llratioplot.C - Using the likelihood ratio technique to construct a signal enhanced 1-D projection of a multi-dimensional p.d.f.; ; DATA AND CATEGORIES. rf401_importttreethx.C -Overview of advanced option for importing data from ROOT TTree and THx histograms; rf402_datahandling.C - Tools for manipulation of (un)binned da",MatchSource.DOCS,roofit/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html:5168,Availability,error,error,5168, - Using simultaneous p.d.f.s to describe simultaneous fits to multiple datasets; rf502_wspacewrite.C - Creating and writing a workspace; rf503_wspaceread.C - Reading and using a workspace; rf504_simwstool.C - Using RooSimWSTool to construct a simultaneous p.d.f that is built of variations of an input p.d.f; rf505_asciicfg.C - Reading and writing ASCII configuration files; rf506_msgservice.C - Tuning and customizing the RooFit message logging facility; rf507_debugtools.C - Using the RooFit memory tracing debug tool; rf508_listsetmanip.C - RooArgSet and RooArgList tools and tricks; ; LIKELIHOOD AND MINIMIZATION. rf601_intminuit.C - Interactive minimization with MINUIT; rf602_chi2fit.C - Setting up a binning chi^2 fit; rf603_multicpu.C - Setting up a multi-core parallelized unbinned maximum likelihood fit; rf604_constraints.C - Fitting with constraints; rf605_profilell.C - Working with the profile likelihood estimator; rf606_nllerrorhandling.C - Understanding and customizing error handling in likelihood evaluations; rf607_fitresult.C - Demonstration of options of the RooFitResult class; ; SPECIAL PDFS. rf701_efficiencyfit.C - Unbinned maximum likelihood fit of an efficiency eff(x) function; rf702_efficiencyfit_2D.C - Unbinned maximum likelihood fit of an efficiency eff(x) function to; rf703_effpdfprod.C - Using a product of an (acceptance) efficiency and a p.d.f as p.d.f.; rf704_amplitudefit.C - Using a p.d.f defined by a sum of real-valued amplitude components; rf705_linearmorph.C - Linear interpolation between p.d.f shapes using the 'Alex Read' algorithm; rf706_histpdf.C - Histogram based p.d.f.s and functions; rf707_kernelestimation.C - Using non-parametric (multi-dimensional) kernel estimation p.d.f.s; rf708_bphysics.C - Special decay pdf for B physics with mixing and/or CP violation; ; VALIDATION AND MC STUDIES. rf801_mcstudy.C - A Toy Monte Carlo study that perform cycles of event generation and fittting; rf802_mcstudy_addons.C - RooMCStudy: using separate fit a,MatchSource.DOCS,roofit/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html:7222,Availability,error,errors,7222,"r model; rf803_mcstudy_addons2.C - RooMCStudy: Using the randomizer and profile likelihood add-on models; rf804_mcstudy_constr.C - Using RooMCStudy on models with constrains; ; Miscellaneous small improvements. A very large number of small fixes and interface improvements have been made in the context of the systematic review of all methods for the new tutorial macros and updated Users Manual.; Listed below are the most significant functionality upgrades that were introduced in the process. ; Runtime binding of C++ functions - You can now trivially bind at run time any C++ functions as a RooFit function or p.d.f. objects, e.g. RooAbsReal* erfx = bindFunction(""erfx"",TMath::erf,x). See rf105_funcbinding.C for details; Runtime binding of TFx functions - You can now trivially bind at run time any ROOT TFx function as a RooFit function or p.d.f. objects, e.g. RooAbsReal* myFunc = bindFunction(myTF1,x). See rf105_funcbinding.C for details; RooAbsReal - The handling of -log(L) evaluation errors in plotting is now explicitly controllable, just like in fitting. See rf606_nllerrorhandling.C for details; RooDataHist - Add new named argument constructor that can collate multiple ROOT THn histgrams into a n+1 dimensional RooDataHist; RooDataSet - Add new named argument constructor that can collate multiple input RooDataSets into a n+1 dimensional RooDataSet.Add createHistogram() method for simplified plotting; RooFitResult - Add new method correlationHist() that returns a labeled TH2 with the contents of the fit correlation matrix; RooFFTConvPdf - Automatically put sampling windows of 'resolution model' p.d.f. centered around zero, even if fit range of convolution observable does not bracket zero. Improve internal efficiency; RooAbsData - Add ability to plot efficiency distribution with correct binomial errors given a RooRealVar and a RooCategory category observable encoding distribution and accept/reject state respectively. See rf701_efficiencyfit.C for details ; RooAbsPdf - Inc",MatchSource.DOCS,roofit/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html:8048,Availability,error,errors,8048,"oFit function or p.d.f. objects, e.g. RooAbsReal* myFunc = bindFunction(myTF1,x). See rf105_funcbinding.C for details; RooAbsReal - The handling of -log(L) evaluation errors in plotting is now explicitly controllable, just like in fitting. See rf606_nllerrorhandling.C for details; RooDataHist - Add new named argument constructor that can collate multiple ROOT THn histgrams into a n+1 dimensional RooDataHist; RooDataSet - Add new named argument constructor that can collate multiple input RooDataSets into a n+1 dimensional RooDataSet.Add createHistogram() method for simplified plotting; RooFitResult - Add new method correlationHist() that returns a labeled TH2 with the contents of the fit correlation matrix; RooFFTConvPdf - Automatically put sampling windows of 'resolution model' p.d.f. centered around zero, even if fit range of convolution observable does not bracket zero. Improve internal efficiency; RooAbsData - Add ability to plot efficiency distribution with correct binomial errors given a RooRealVar and a RooCategory category observable encoding distribution and accept/reject state respectively. See rf701_efficiencyfit.C for details ; RooAbsPdf - Included extended ML term by default in fit if p.d.f is extendable. You can still use Extended() to override default behavior. Do not run MINOS by default anymore if no fit options are provided.; RooProfileLL - Add option to always start minimization from global minimimum (takes more time, but improves reproducibility). Can now profile multi-core paralellized likelihoods as well.; RooRealSumPdf - Enable plotting of component p.d.f.s using same scheme as RooAddPdf, i.e. just use the Components() specified in plotOn().; RooExpensiveObjectCache - New cache manager for sharing and storing of expensive components cached by operator p.d.f.s ; RooMCStudy - Add Silence() argument to constructor to request minimal verbosity during running; RooMinuit - Improve contour() method to return RooPlots rather than drawing TGraphs straig",MatchSource.DOCS,roofit/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html:389,Deployability,update,update,389,". RooFit; New tutorial macros available. A completely new set of 70(!) tutorial macros is now available in $ROOTSYS/tutorials/roofit; These macros are divided in several subjects and are all referenced as iluustrations of concepts explained in the forthcoming edition on RooFit Users Manual.; All macros are extensively documented and each is fully functional standalone. The accompanying update; of the Manual is expected mid-September. ; ; BASIC FUNCTIONALITY. rf101_basics.C - Fitting, plotting, toy data generation on one-dimensional p.d.f ; rf102_dataimport.C - Importing data from ROOT TTrees and THx histograms; rf103_interprfuncs.C - Interpreted functions and p.d.f.s; rf104_classfactory.C - The class factory for functions and p.d.f.s; rf105_funcbinding.C - Demonstration of binding ROOT Math functions as RooFit functions and pdfs; rf106_plotdecoration.C - Adding boxes with parameters, statistics to RooPlots.; rf107_plotstyles.C - Demonstration of various plotting styles of data, functions; rf108_plotbinning.C - Plotting unbinned data with alternate and variable binnings; rf109_chi2residpull.C - Calculating chi^2 from histograms and curves in RooPlots,; rf110_normintegration.C - Examples on normalization & integration of p.d.f.s, construction of cumulative distribution functions.; rf111_numintconfig.C - Configuration and customization of how numeric (partial) integrals. ; ADDITION AND CONVOLUTION. rf201_composite.C - Composite p.d.f with signal and background component; rf202_extendedmlfit.C - Setting up an extended maximum likelihood fit; rf203_ranges.C - Fitting and plotting in sub ranges; rf204_extrangefit.C - Extended maximum likelihood fit with alternate range definition; rf205_compplot.C - Options for plotting components of composite p.d.f.s.; rf206_treevistools.C - Tools for visualization of RooAbsArg expression trees; rf207_comptools.C - Tools and utilities for manipulation of composite objects; rf208_convolution.C - One-dimensional numeric convolution; rf209_a",MatchSource.DOCS,roofit/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html:1224,Deployability,integrat,integration,1224,"ns of concepts explained in the forthcoming edition on RooFit Users Manual.; All macros are extensively documented and each is fully functional standalone. The accompanying update; of the Manual is expected mid-September. ; ; BASIC FUNCTIONALITY. rf101_basics.C - Fitting, plotting, toy data generation on one-dimensional p.d.f ; rf102_dataimport.C - Importing data from ROOT TTrees and THx histograms; rf103_interprfuncs.C - Interpreted functions and p.d.f.s; rf104_classfactory.C - The class factory for functions and p.d.f.s; rf105_funcbinding.C - Demonstration of binding ROOT Math functions as RooFit functions and pdfs; rf106_plotdecoration.C - Adding boxes with parameters, statistics to RooPlots.; rf107_plotstyles.C - Demonstration of various plotting styles of data, functions; rf108_plotbinning.C - Plotting unbinned data with alternate and variable binnings; rf109_chi2residpull.C - Calculating chi^2 from histograms and curves in RooPlots,; rf110_normintegration.C - Examples on normalization & integration of p.d.f.s, construction of cumulative distribution functions.; rf111_numintconfig.C - Configuration and customization of how numeric (partial) integrals. ; ADDITION AND CONVOLUTION. rf201_composite.C - Composite p.d.f with signal and background component; rf202_extendedmlfit.C - Setting up an extended maximum likelihood fit; rf203_ranges.C - Fitting and plotting in sub ranges; rf204_extrangefit.C - Extended maximum likelihood fit with alternate range definition; rf205_compplot.C - Options for plotting components of composite p.d.f.s.; rf206_treevistools.C - Tools for visualization of RooAbsArg expression trees; rf207_comptools.C - Tools and utilities for manipulation of composite objects; rf208_convolution.C - One-dimensional numeric convolution; rf209_anaconv.C - Decay function p.d.fs with optional B physics. ; MULTIDIMENSIONAL MODELS. rf301_composition.C - Multi-dimensional p.d.f.s through composition, e.g. substituting a p.d.f parameter with a function that depen",MatchSource.DOCS,roofit/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html:3036,Deployability,continuous,continuous,3036," B physics. ; MULTIDIMENSIONAL MODELS. rf301_composition.C - Multi-dimensional p.d.f.s through composition, e.g. substituting a p.d.f parameter with a function that depends on other observables; rf302_utilfuncs.C - Utility functions classes available for use in tailoring; rf303_conditional.C - Use of tailored p.d.f as conditional p.d.fs.s; rf304_uncorrprod.C - Simple uncorrelated multi-dimensional p.d.f.s; rf305_condcorrprod.C - Multi-dimensional p.d.f.s with conditional p.d.fs in product; rf306_condpereventerrors.C - Complete example with use of conditional p.d.f. with per-event errors; rf307_fullpereventerrors.C -Complete example with use of full p.d.f. with per-event errors; rf308_normintegration2d.C - Examples on normalization of p.d.f.s in more than one dimension; rf309_ndimplot.C - Making 2 and 3 dimensional plots of p.d.f.s and datasets; rf310_sliceplot.C -Projecting p.d.f and data slices in discrete observables; rf311_rangeplot.C -Projecting p.d.f and data ranges in continuous observables; rf312_multirangefit.C - Performing fits in multiple (disjoint) ranges in one or more dimensions; rf313_paramranges.C - Working with parameterized ranges to define non-rectangular regions; rf314_paramfitrange.C - Working with parameterized ranges in a fit.; rf315_projectpdf.C - Marginizalization of multi-dimensional p.d.f.s through integration; rf316_llratioplot.C - Using the likelihood ratio technique to construct a signal enhanced 1-D projection of a multi-dimensional p.d.f.; ; DATA AND CATEGORIES. rf401_importttreethx.C -Overview of advanced option for importing data from ROOT TTree and THx histograms; rf402_datahandling.C - Tools for manipulation of (un)binned datasets; rf403_weightedevts.C - Using weights in unbinned datasets; rf404_categories.C - Working with RooCategory objects to describe discrete variables; rf405_realtocatfuncs.C - Demonstration of real-->discrete mapping functions; rf406_cattocatfuncs.C - Demonstration of discrete-->discrete (invertable) functions;",MatchSource.DOCS,roofit/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html:3393,Deployability,integrat,integration,3393,od.C - Simple uncorrelated multi-dimensional p.d.f.s; rf305_condcorrprod.C - Multi-dimensional p.d.f.s with conditional p.d.fs in product; rf306_condpereventerrors.C - Complete example with use of conditional p.d.f. with per-event errors; rf307_fullpereventerrors.C -Complete example with use of full p.d.f. with per-event errors; rf308_normintegration2d.C - Examples on normalization of p.d.f.s in more than one dimension; rf309_ndimplot.C - Making 2 and 3 dimensional plots of p.d.f.s and datasets; rf310_sliceplot.C -Projecting p.d.f and data slices in discrete observables; rf311_rangeplot.C -Projecting p.d.f and data ranges in continuous observables; rf312_multirangefit.C - Performing fits in multiple (disjoint) ranges in one or more dimensions; rf313_paramranges.C - Working with parameterized ranges to define non-rectangular regions; rf314_paramfitrange.C - Working with parameterized ranges in a fit.; rf315_projectpdf.C - Marginizalization of multi-dimensional p.d.f.s through integration; rf316_llratioplot.C - Using the likelihood ratio technique to construct a signal enhanced 1-D projection of a multi-dimensional p.d.f.; ; DATA AND CATEGORIES. rf401_importttreethx.C -Overview of advanced option for importing data from ROOT TTree and THx histograms; rf402_datahandling.C - Tools for manipulation of (un)binned datasets; rf403_weightedevts.C - Using weights in unbinned datasets; rf404_categories.C - Working with RooCategory objects to describe discrete variables; rf405_realtocatfuncs.C - Demonstration of real-->discrete mapping functions; rf406_cattocatfuncs.C - Demonstration of discrete-->discrete (invertable) functions; rf407_latextables.C - Latex printing of lists and sets of RooArgSets; ; ORGANIZATION AND SIMULTANEOUS FITS. rf501_simultaneouspdf.C - Using simultaneous p.d.f.s to describe simultaneous fits to multiple datasets; rf502_wspacewrite.C - Creating and writing a workspace; rf503_wspaceread.C - Reading and using a workspace; rf504_simwstool.C - Using RooSimWS,MatchSource.DOCS,roofit/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html:4535,Deployability,configurat,configuration,4535,.; ; DATA AND CATEGORIES. rf401_importttreethx.C -Overview of advanced option for importing data from ROOT TTree and THx histograms; rf402_datahandling.C - Tools for manipulation of (un)binned datasets; rf403_weightedevts.C - Using weights in unbinned datasets; rf404_categories.C - Working with RooCategory objects to describe discrete variables; rf405_realtocatfuncs.C - Demonstration of real-->discrete mapping functions; rf406_cattocatfuncs.C - Demonstration of discrete-->discrete (invertable) functions; rf407_latextables.C - Latex printing of lists and sets of RooArgSets; ; ORGANIZATION AND SIMULTANEOUS FITS. rf501_simultaneouspdf.C - Using simultaneous p.d.f.s to describe simultaneous fits to multiple datasets; rf502_wspacewrite.C - Creating and writing a workspace; rf503_wspaceread.C - Reading and using a workspace; rf504_simwstool.C - Using RooSimWSTool to construct a simultaneous p.d.f that is built of variations of an input p.d.f; rf505_asciicfg.C - Reading and writing ASCII configuration files; rf506_msgservice.C - Tuning and customizing the RooFit message logging facility; rf507_debugtools.C - Using the RooFit memory tracing debug tool; rf508_listsetmanip.C - RooArgSet and RooArgList tools and tricks; ; LIKELIHOOD AND MINIMIZATION. rf601_intminuit.C - Interactive minimization with MINUIT; rf602_chi2fit.C - Setting up a binning chi^2 fit; rf603_multicpu.C - Setting up a multi-core parallelized unbinned maximum likelihood fit; rf604_constraints.C - Fitting with constraints; rf605_profilell.C - Working with the profile likelihood estimator; rf606_nllerrorhandling.C - Understanding and customizing error handling in likelihood evaluations; rf607_fitresult.C - Demonstration of options of the RooFitResult class; ; SPECIAL PDFS. rf701_efficiencyfit.C - Unbinned maximum likelihood fit of an efficiency eff(x) function; rf702_efficiencyfit_2D.C - Unbinned maximum likelihood fit of an efficiency eff(x) function to; rf703_effpdfprod.C - Using a product of an (acceptance),MatchSource.DOCS,roofit/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html:6601,Deployability,update,updated,6601,"cceptance) efficiency and a p.d.f as p.d.f.; rf704_amplitudefit.C - Using a p.d.f defined by a sum of real-valued amplitude components; rf705_linearmorph.C - Linear interpolation between p.d.f shapes using the 'Alex Read' algorithm; rf706_histpdf.C - Histogram based p.d.f.s and functions; rf707_kernelestimation.C - Using non-parametric (multi-dimensional) kernel estimation p.d.f.s; rf708_bphysics.C - Special decay pdf for B physics with mixing and/or CP violation; ; VALIDATION AND MC STUDIES. rf801_mcstudy.C - A Toy Monte Carlo study that perform cycles of event generation and fittting; rf802_mcstudy_addons.C - RooMCStudy: using separate fit and generator models, using the chi^2 calculator model; rf803_mcstudy_addons2.C - RooMCStudy: Using the randomizer and profile likelihood add-on models; rf804_mcstudy_constr.C - Using RooMCStudy on models with constrains; ; Miscellaneous small improvements. A very large number of small fixes and interface improvements have been made in the context of the systematic review of all methods for the new tutorial macros and updated Users Manual.; Listed below are the most significant functionality upgrades that were introduced in the process. ; Runtime binding of C++ functions - You can now trivially bind at run time any C++ functions as a RooFit function or p.d.f. objects, e.g. RooAbsReal* erfx = bindFunction(""erfx"",TMath::erf,x). See rf105_funcbinding.C for details; Runtime binding of TFx functions - You can now trivially bind at run time any ROOT TFx function as a RooFit function or p.d.f. objects, e.g. RooAbsReal* myFunc = bindFunction(myTF1,x). See rf105_funcbinding.C for details; RooAbsReal - The handling of -log(L) evaluation errors in plotting is now explicitly controllable, just like in fitting. See rf606_nllerrorhandling.C for details; RooDataHist - Add new named argument constructor that can collate multiple ROOT THn histgrams into a n+1 dimensional RooDataHist; RooDataSet - Add new named argument constructor that can colla",MatchSource.DOCS,roofit/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html:6676,Deployability,upgrade,upgrades,6676,"linearmorph.C - Linear interpolation between p.d.f shapes using the 'Alex Read' algorithm; rf706_histpdf.C - Histogram based p.d.f.s and functions; rf707_kernelestimation.C - Using non-parametric (multi-dimensional) kernel estimation p.d.f.s; rf708_bphysics.C - Special decay pdf for B physics with mixing and/or CP violation; ; VALIDATION AND MC STUDIES. rf801_mcstudy.C - A Toy Monte Carlo study that perform cycles of event generation and fittting; rf802_mcstudy_addons.C - RooMCStudy: using separate fit and generator models, using the chi^2 calculator model; rf803_mcstudy_addons2.C - RooMCStudy: Using the randomizer and profile likelihood add-on models; rf804_mcstudy_constr.C - Using RooMCStudy on models with constrains; ; Miscellaneous small improvements. A very large number of small fixes and interface improvements have been made in the context of the systematic review of all methods for the new tutorial macros and updated Users Manual.; Listed below are the most significant functionality upgrades that were introduced in the process. ; Runtime binding of C++ functions - You can now trivially bind at run time any C++ functions as a RooFit function or p.d.f. objects, e.g. RooAbsReal* erfx = bindFunction(""erfx"",TMath::erf,x). See rf105_funcbinding.C for details; Runtime binding of TFx functions - You can now trivially bind at run time any ROOT TFx function as a RooFit function or p.d.f. objects, e.g. RooAbsReal* myFunc = bindFunction(myTF1,x). See rf105_funcbinding.C for details; RooAbsReal - The handling of -log(L) evaluation errors in plotting is now explicitly controllable, just like in fitting. See rf606_nllerrorhandling.C for details; RooDataHist - Add new named argument constructor that can collate multiple ROOT THn histgrams into a n+1 dimensional RooDataHist; RooDataSet - Add new named argument constructor that can collate multiple input RooDataSets into a n+1 dimensional RooDataSet.Add createHistogram() method for simplified plotting; RooFitResult - Add new me",MatchSource.DOCS,roofit/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html:1224,Integrability,integrat,integration,1224,"ns of concepts explained in the forthcoming edition on RooFit Users Manual.; All macros are extensively documented and each is fully functional standalone. The accompanying update; of the Manual is expected mid-September. ; ; BASIC FUNCTIONALITY. rf101_basics.C - Fitting, plotting, toy data generation on one-dimensional p.d.f ; rf102_dataimport.C - Importing data from ROOT TTrees and THx histograms; rf103_interprfuncs.C - Interpreted functions and p.d.f.s; rf104_classfactory.C - The class factory for functions and p.d.f.s; rf105_funcbinding.C - Demonstration of binding ROOT Math functions as RooFit functions and pdfs; rf106_plotdecoration.C - Adding boxes with parameters, statistics to RooPlots.; rf107_plotstyles.C - Demonstration of various plotting styles of data, functions; rf108_plotbinning.C - Plotting unbinned data with alternate and variable binnings; rf109_chi2residpull.C - Calculating chi^2 from histograms and curves in RooPlots,; rf110_normintegration.C - Examples on normalization & integration of p.d.f.s, construction of cumulative distribution functions.; rf111_numintconfig.C - Configuration and customization of how numeric (partial) integrals. ; ADDITION AND CONVOLUTION. rf201_composite.C - Composite p.d.f with signal and background component; rf202_extendedmlfit.C - Setting up an extended maximum likelihood fit; rf203_ranges.C - Fitting and plotting in sub ranges; rf204_extrangefit.C - Extended maximum likelihood fit with alternate range definition; rf205_compplot.C - Options for plotting components of composite p.d.f.s.; rf206_treevistools.C - Tools for visualization of RooAbsArg expression trees; rf207_comptools.C - Tools and utilities for manipulation of composite objects; rf208_convolution.C - One-dimensional numeric convolution; rf209_anaconv.C - Decay function p.d.fs with optional B physics. ; MULTIDIMENSIONAL MODELS. rf301_composition.C - Multi-dimensional p.d.f.s through composition, e.g. substituting a p.d.f parameter with a function that depen",MatchSource.DOCS,roofit/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html:2212,Integrability,depend,depends,2212,"ion & integration of p.d.f.s, construction of cumulative distribution functions.; rf111_numintconfig.C - Configuration and customization of how numeric (partial) integrals. ; ADDITION AND CONVOLUTION. rf201_composite.C - Composite p.d.f with signal and background component; rf202_extendedmlfit.C - Setting up an extended maximum likelihood fit; rf203_ranges.C - Fitting and plotting in sub ranges; rf204_extrangefit.C - Extended maximum likelihood fit with alternate range definition; rf205_compplot.C - Options for plotting components of composite p.d.f.s.; rf206_treevistools.C - Tools for visualization of RooAbsArg expression trees; rf207_comptools.C - Tools and utilities for manipulation of composite objects; rf208_convolution.C - One-dimensional numeric convolution; rf209_anaconv.C - Decay function p.d.fs with optional B physics. ; MULTIDIMENSIONAL MODELS. rf301_composition.C - Multi-dimensional p.d.f.s through composition, e.g. substituting a p.d.f parameter with a function that depends on other observables; rf302_utilfuncs.C - Utility functions classes available for use in tailoring; rf303_conditional.C - Use of tailored p.d.f as conditional p.d.fs.s; rf304_uncorrprod.C - Simple uncorrelated multi-dimensional p.d.f.s; rf305_condcorrprod.C - Multi-dimensional p.d.f.s with conditional p.d.fs in product; rf306_condpereventerrors.C - Complete example with use of conditional p.d.f. with per-event errors; rf307_fullpereventerrors.C -Complete example with use of full p.d.f. with per-event errors; rf308_normintegration2d.C - Examples on normalization of p.d.f.s in more than one dimension; rf309_ndimplot.C - Making 2 and 3 dimensional plots of p.d.f.s and datasets; rf310_sliceplot.C -Projecting p.d.f and data slices in discrete observables; rf311_rangeplot.C -Projecting p.d.f and data ranges in continuous observables; rf312_multirangefit.C - Performing fits in multiple (disjoint) ranges in one or more dimensions; rf313_paramranges.C - Working with parameterized ranges to def",MatchSource.DOCS,roofit/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html:3393,Integrability,integrat,integration,3393,od.C - Simple uncorrelated multi-dimensional p.d.f.s; rf305_condcorrprod.C - Multi-dimensional p.d.f.s with conditional p.d.fs in product; rf306_condpereventerrors.C - Complete example with use of conditional p.d.f. with per-event errors; rf307_fullpereventerrors.C -Complete example with use of full p.d.f. with per-event errors; rf308_normintegration2d.C - Examples on normalization of p.d.f.s in more than one dimension; rf309_ndimplot.C - Making 2 and 3 dimensional plots of p.d.f.s and datasets; rf310_sliceplot.C -Projecting p.d.f and data slices in discrete observables; rf311_rangeplot.C -Projecting p.d.f and data ranges in continuous observables; rf312_multirangefit.C - Performing fits in multiple (disjoint) ranges in one or more dimensions; rf313_paramranges.C - Working with parameterized ranges to define non-rectangular regions; rf314_paramfitrange.C - Working with parameterized ranges in a fit.; rf315_projectpdf.C - Marginizalization of multi-dimensional p.d.f.s through integration; rf316_llratioplot.C - Using the likelihood ratio technique to construct a signal enhanced 1-D projection of a multi-dimensional p.d.f.; ; DATA AND CATEGORIES. rf401_importttreethx.C -Overview of advanced option for importing data from ROOT TTree and THx histograms; rf402_datahandling.C - Tools for manipulation of (un)binned datasets; rf403_weightedevts.C - Using weights in unbinned datasets; rf404_categories.C - Working with RooCategory objects to describe discrete variables; rf405_realtocatfuncs.C - Demonstration of real-->discrete mapping functions; rf406_cattocatfuncs.C - Demonstration of discrete-->discrete (invertable) functions; rf407_latextables.C - Latex printing of lists and sets of RooArgSets; ; ORGANIZATION AND SIMULTANEOUS FITS. rf501_simultaneouspdf.C - Using simultaneous p.d.f.s to describe simultaneous fits to multiple datasets; rf502_wspacewrite.C - Creating and writing a workspace; rf503_wspaceread.C - Reading and using a workspace; rf504_simwstool.C - Using RooSimWS,MatchSource.DOCS,roofit/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html:4611,Integrability,message,message,4611,ion for importing data from ROOT TTree and THx histograms; rf402_datahandling.C - Tools for manipulation of (un)binned datasets; rf403_weightedevts.C - Using weights in unbinned datasets; rf404_categories.C - Working with RooCategory objects to describe discrete variables; rf405_realtocatfuncs.C - Demonstration of real-->discrete mapping functions; rf406_cattocatfuncs.C - Demonstration of discrete-->discrete (invertable) functions; rf407_latextables.C - Latex printing of lists and sets of RooArgSets; ; ORGANIZATION AND SIMULTANEOUS FITS. rf501_simultaneouspdf.C - Using simultaneous p.d.f.s to describe simultaneous fits to multiple datasets; rf502_wspacewrite.C - Creating and writing a workspace; rf503_wspaceread.C - Reading and using a workspace; rf504_simwstool.C - Using RooSimWSTool to construct a simultaneous p.d.f that is built of variations of an input p.d.f; rf505_asciicfg.C - Reading and writing ASCII configuration files; rf506_msgservice.C - Tuning and customizing the RooFit message logging facility; rf507_debugtools.C - Using the RooFit memory tracing debug tool; rf508_listsetmanip.C - RooArgSet and RooArgList tools and tricks; ; LIKELIHOOD AND MINIMIZATION. rf601_intminuit.C - Interactive minimization with MINUIT; rf602_chi2fit.C - Setting up a binning chi^2 fit; rf603_multicpu.C - Setting up a multi-core parallelized unbinned maximum likelihood fit; rf604_constraints.C - Fitting with constraints; rf605_profilell.C - Working with the profile likelihood estimator; rf606_nllerrorhandling.C - Understanding and customizing error handling in likelihood evaluations; rf607_fitresult.C - Demonstration of options of the RooFitResult class; ; SPECIAL PDFS. rf701_efficiencyfit.C - Unbinned maximum likelihood fit of an efficiency eff(x) function; rf702_efficiencyfit_2D.C - Unbinned maximum likelihood fit of an efficiency eff(x) function to; rf703_effpdfprod.C - Using a product of an (acceptance) efficiency and a p.d.f as p.d.f.; rf704_amplitudefit.C - Using a p.d.f def,MatchSource.DOCS,roofit/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html:6476,Integrability,interface,interface,6476,"cceptance) efficiency and a p.d.f as p.d.f.; rf704_amplitudefit.C - Using a p.d.f defined by a sum of real-valued amplitude components; rf705_linearmorph.C - Linear interpolation between p.d.f shapes using the 'Alex Read' algorithm; rf706_histpdf.C - Histogram based p.d.f.s and functions; rf707_kernelestimation.C - Using non-parametric (multi-dimensional) kernel estimation p.d.f.s; rf708_bphysics.C - Special decay pdf for B physics with mixing and/or CP violation; ; VALIDATION AND MC STUDIES. rf801_mcstudy.C - A Toy Monte Carlo study that perform cycles of event generation and fittting; rf802_mcstudy_addons.C - RooMCStudy: using separate fit and generator models, using the chi^2 calculator model; rf803_mcstudy_addons2.C - RooMCStudy: Using the randomizer and profile likelihood add-on models; rf804_mcstudy_constr.C - Using RooMCStudy on models with constrains; ; Miscellaneous small improvements. A very large number of small fixes and interface improvements have been made in the context of the systematic review of all methods for the new tutorial macros and updated Users Manual.; Listed below are the most significant functionality upgrades that were introduced in the process. ; Runtime binding of C++ functions - You can now trivially bind at run time any C++ functions as a RooFit function or p.d.f. objects, e.g. RooAbsReal* erfx = bindFunction(""erfx"",TMath::erf,x). See rf105_funcbinding.C for details; Runtime binding of TFx functions - You can now trivially bind at run time any ROOT TFx function as a RooFit function or p.d.f. objects, e.g. RooAbsReal* myFunc = bindFunction(myTF1,x). See rf105_funcbinding.C for details; RooAbsReal - The handling of -log(L) evaluation errors in plotting is now explicitly controllable, just like in fitting. See rf606_nllerrorhandling.C for details; RooDataHist - Add new named argument constructor that can collate multiple ROOT THn histgrams into a n+1 dimensional RooDataHist; RooDataSet - Add new named argument constructor that can colla",MatchSource.DOCS,roofit/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html:9566,Integrability,interface,interfaces,9566,"able plotting of component p.d.f.s using same scheme as RooAddPdf, i.e. just use the Components() specified in plotOn().; RooExpensiveObjectCache - New cache manager for sharing and storing of expensive components cached by operator p.d.f.s ; RooMCStudy - Add Silence() argument to constructor to request minimal verbosity during running; RooMinuit - Improve contour() method to return RooPlots rather than drawing TGraphs straight on a canvas; RooWorkspace - Add private expensive object cache to workspace; RooBinningCategory - New real-to-category function that maps values of input RooRealVar to categories with labels that correspond to bins of input RooRealVar. See rf405_realtocatfuncs.C for details . RooStats; This is a new package introduced in this version for statistical tools built on top of RooFit. It is a joint effort between the LHC experiments and the ROOT team (see the RooStats Wiki page).; ; This version contains the interfaces for performing the statistical calculations and dealing with the obtained results and concrete classes implementing the statistical methods.; ; All the classes and functions in RooStats are provided in the namespace RooStats.; ; RooStats interfaces. ConfInterval: interface for describing a confidence interval. ; IntervalCalculator: interface for a statistical tool producing confidence intervals (class ConfInterval).; HypoTestResult: interface for representing results of a hypothesis test; HypoTestCalculator: interface for a statistical tool performing an hypothesis test. ; CombinedCalculator: interface for a statistical tool which can produce both hypothesis test results and confidence intervals. ; RooStats concrete classes. The concrete classes describing statistical tools implementing the above interfaces are:; ; ProfileLikelihoodCalculator: it is an implementation of a CombinedCalculator using the profile likelihood ratio as a test statistics. After configuring the calculator, one only needs to ask GetHypoTest() (which will return ",MatchSource.DOCS,roofit/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html:9815,Integrability,interface,interfaces,9815,"g of expensive components cached by operator p.d.f.s ; RooMCStudy - Add Silence() argument to constructor to request minimal verbosity during running; RooMinuit - Improve contour() method to return RooPlots rather than drawing TGraphs straight on a canvas; RooWorkspace - Add private expensive object cache to workspace; RooBinningCategory - New real-to-category function that maps values of input RooRealVar to categories with labels that correspond to bins of input RooRealVar. See rf405_realtocatfuncs.C for details . RooStats; This is a new package introduced in this version for statistical tools built on top of RooFit. It is a joint effort between the LHC experiments and the ROOT team (see the RooStats Wiki page).; ; This version contains the interfaces for performing the statistical calculations and dealing with the obtained results and concrete classes implementing the statistical methods.; ; All the classes and functions in RooStats are provided in the namespace RooStats.; ; RooStats interfaces. ConfInterval: interface for describing a confidence interval. ; IntervalCalculator: interface for a statistical tool producing confidence intervals (class ConfInterval).; HypoTestResult: interface for representing results of a hypothesis test; HypoTestCalculator: interface for a statistical tool performing an hypothesis test. ; CombinedCalculator: interface for a statistical tool which can produce both hypothesis test results and confidence intervals. ; RooStats concrete classes. The concrete classes describing statistical tools implementing the above interfaces are:; ; ProfileLikelihoodCalculator: it is an implementation of a CombinedCalculator using the profile likelihood ratio as a test statistics. After configuring the calculator, one only needs to ask GetHypoTest() (which will return a HypoTestResult pointer) or GetInterval() (which will return an ConfInterval pointer).; LikelihoodInterval: concrete implementation of a ConfInterval interface. It implements connected N",MatchSource.DOCS,roofit/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html:9841,Integrability,interface,interface,9841,"r p.d.f.s ; RooMCStudy - Add Silence() argument to constructor to request minimal verbosity during running; RooMinuit - Improve contour() method to return RooPlots rather than drawing TGraphs straight on a canvas; RooWorkspace - Add private expensive object cache to workspace; RooBinningCategory - New real-to-category function that maps values of input RooRealVar to categories with labels that correspond to bins of input RooRealVar. See rf405_realtocatfuncs.C for details . RooStats; This is a new package introduced in this version for statistical tools built on top of RooFit. It is a joint effort between the LHC experiments and the ROOT team (see the RooStats Wiki page).; ; This version contains the interfaces for performing the statistical calculations and dealing with the obtained results and concrete classes implementing the statistical methods.; ; All the classes and functions in RooStats are provided in the namespace RooStats.; ; RooStats interfaces. ConfInterval: interface for describing a confidence interval. ; IntervalCalculator: interface for a statistical tool producing confidence intervals (class ConfInterval).; HypoTestResult: interface for representing results of a hypothesis test; HypoTestCalculator: interface for a statistical tool performing an hypothesis test. ; CombinedCalculator: interface for a statistical tool which can produce both hypothesis test results and confidence intervals. ; RooStats concrete classes. The concrete classes describing statistical tools implementing the above interfaces are:; ; ProfileLikelihoodCalculator: it is an implementation of a CombinedCalculator using the profile likelihood ratio as a test statistics. After configuring the calculator, one only needs to ask GetHypoTest() (which will return a HypoTestResult pointer) or GetInterval() (which will return an ConfInterval pointer).; LikelihoodInterval: concrete implementation of a ConfInterval interface. It implements connected N-dimensional intervals based on the contour",MatchSource.DOCS,roofit/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html:9911,Integrability,interface,interface,9911,"bosity during running; RooMinuit - Improve contour() method to return RooPlots rather than drawing TGraphs straight on a canvas; RooWorkspace - Add private expensive object cache to workspace; RooBinningCategory - New real-to-category function that maps values of input RooRealVar to categories with labels that correspond to bins of input RooRealVar. See rf405_realtocatfuncs.C for details . RooStats; This is a new package introduced in this version for statistical tools built on top of RooFit. It is a joint effort between the LHC experiments and the ROOT team (see the RooStats Wiki page).; ; This version contains the interfaces for performing the statistical calculations and dealing with the obtained results and concrete classes implementing the statistical methods.; ; All the classes and functions in RooStats are provided in the namespace RooStats.; ; RooStats interfaces. ConfInterval: interface for describing a confidence interval. ; IntervalCalculator: interface for a statistical tool producing confidence intervals (class ConfInterval).; HypoTestResult: interface for representing results of a hypothesis test; HypoTestCalculator: interface for a statistical tool performing an hypothesis test. ; CombinedCalculator: interface for a statistical tool which can produce both hypothesis test results and confidence intervals. ; RooStats concrete classes. The concrete classes describing statistical tools implementing the above interfaces are:; ; ProfileLikelihoodCalculator: it is an implementation of a CombinedCalculator using the profile likelihood ratio as a test statistics. After configuring the calculator, one only needs to ask GetHypoTest() (which will return a HypoTestResult pointer) or GetInterval() (which will return an ConfInterval pointer).; LikelihoodInterval: concrete implementation of a ConfInterval interface. It implements connected N-dimensional intervals based on the contour of a likelihood ratio. The boundary of the interval is equivalent to a MINUIT/MINOS ",MatchSource.DOCS,roofit/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html:10014,Integrability,interface,interface,10014,"orkspace - Add private expensive object cache to workspace; RooBinningCategory - New real-to-category function that maps values of input RooRealVar to categories with labels that correspond to bins of input RooRealVar. See rf405_realtocatfuncs.C for details . RooStats; This is a new package introduced in this version for statistical tools built on top of RooFit. It is a joint effort between the LHC experiments and the ROOT team (see the RooStats Wiki page).; ; This version contains the interfaces for performing the statistical calculations and dealing with the obtained results and concrete classes implementing the statistical methods.; ; All the classes and functions in RooStats are provided in the namespace RooStats.; ; RooStats interfaces. ConfInterval: interface for describing a confidence interval. ; IntervalCalculator: interface for a statistical tool producing confidence intervals (class ConfInterval).; HypoTestResult: interface for representing results of a hypothesis test; HypoTestCalculator: interface for a statistical tool performing an hypothesis test. ; CombinedCalculator: interface for a statistical tool which can produce both hypothesis test results and confidence intervals. ; RooStats concrete classes. The concrete classes describing statistical tools implementing the above interfaces are:; ; ProfileLikelihoodCalculator: it is an implementation of a CombinedCalculator using the profile likelihood ratio as a test statistics. After configuring the calculator, one only needs to ask GetHypoTest() (which will return a HypoTestResult pointer) or GetInterval() (which will return an ConfInterval pointer).; LikelihoodInterval: concrete implementation of a ConfInterval interface. It implements connected N-dimensional intervals based on the contour of a likelihood ratio. The boundary of the interval is equivalent to a MINUIT/MINOS contour about the maximum likelihood estimator. . HybridCalculator: hypothesis test calculator using a Bayesian-frequentist hybrid me",MatchSource.DOCS,roofit/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html:10091,Integrability,interface,interface,10091,"orkspace - Add private expensive object cache to workspace; RooBinningCategory - New real-to-category function that maps values of input RooRealVar to categories with labels that correspond to bins of input RooRealVar. See rf405_realtocatfuncs.C for details . RooStats; This is a new package introduced in this version for statistical tools built on top of RooFit. It is a joint effort between the LHC experiments and the ROOT team (see the RooStats Wiki page).; ; This version contains the interfaces for performing the statistical calculations and dealing with the obtained results and concrete classes implementing the statistical methods.; ; All the classes and functions in RooStats are provided in the namespace RooStats.; ; RooStats interfaces. ConfInterval: interface for describing a confidence interval. ; IntervalCalculator: interface for a statistical tool producing confidence intervals (class ConfInterval).; HypoTestResult: interface for representing results of a hypothesis test; HypoTestCalculator: interface for a statistical tool performing an hypothesis test. ; CombinedCalculator: interface for a statistical tool which can produce both hypothesis test results and confidence intervals. ; RooStats concrete classes. The concrete classes describing statistical tools implementing the above interfaces are:; ; ProfileLikelihoodCalculator: it is an implementation of a CombinedCalculator using the profile likelihood ratio as a test statistics. After configuring the calculator, one only needs to ask GetHypoTest() (which will return a HypoTestResult pointer) or GetInterval() (which will return an ConfInterval pointer).; LikelihoodInterval: concrete implementation of a ConfInterval interface. It implements connected N-dimensional intervals based on the contour of a likelihood ratio. The boundary of the interval is equivalent to a MINUIT/MINOS contour about the maximum likelihood estimator. . HybridCalculator: hypothesis test calculator using a Bayesian-frequentist hybrid me",MatchSource.DOCS,roofit/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html:10177,Integrability,interface,interface,10177,"lVar to categories with labels that correspond to bins of input RooRealVar. See rf405_realtocatfuncs.C for details . RooStats; This is a new package introduced in this version for statistical tools built on top of RooFit. It is a joint effort between the LHC experiments and the ROOT team (see the RooStats Wiki page).; ; This version contains the interfaces for performing the statistical calculations and dealing with the obtained results and concrete classes implementing the statistical methods.; ; All the classes and functions in RooStats are provided in the namespace RooStats.; ; RooStats interfaces. ConfInterval: interface for describing a confidence interval. ; IntervalCalculator: interface for a statistical tool producing confidence intervals (class ConfInterval).; HypoTestResult: interface for representing results of a hypothesis test; HypoTestCalculator: interface for a statistical tool performing an hypothesis test. ; CombinedCalculator: interface for a statistical tool which can produce both hypothesis test results and confidence intervals. ; RooStats concrete classes. The concrete classes describing statistical tools implementing the above interfaces are:; ; ProfileLikelihoodCalculator: it is an implementation of a CombinedCalculator using the profile likelihood ratio as a test statistics. After configuring the calculator, one only needs to ask GetHypoTest() (which will return a HypoTestResult pointer) or GetInterval() (which will return an ConfInterval pointer).; LikelihoodInterval: concrete implementation of a ConfInterval interface. It implements connected N-dimensional intervals based on the contour of a likelihood ratio. The boundary of the interval is equivalent to a MINUIT/MINOS contour about the maximum likelihood estimator. . HybridCalculator: hypothesis test calculator using a Bayesian-frequentist hybrid method (often called in HEP as CLs method). This class extends the functionality of the TLimit class by taking advantage of the RooFit package. T",MatchSource.DOCS,roofit/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html:10385,Integrability,interface,interfaces,10385," top of RooFit. It is a joint effort between the LHC experiments and the ROOT team (see the RooStats Wiki page).; ; This version contains the interfaces for performing the statistical calculations and dealing with the obtained results and concrete classes implementing the statistical methods.; ; All the classes and functions in RooStats are provided in the namespace RooStats.; ; RooStats interfaces. ConfInterval: interface for describing a confidence interval. ; IntervalCalculator: interface for a statistical tool producing confidence intervals (class ConfInterval).; HypoTestResult: interface for representing results of a hypothesis test; HypoTestCalculator: interface for a statistical tool performing an hypothesis test. ; CombinedCalculator: interface for a statistical tool which can produce both hypothesis test results and confidence intervals. ; RooStats concrete classes. The concrete classes describing statistical tools implementing the above interfaces are:; ; ProfileLikelihoodCalculator: it is an implementation of a CombinedCalculator using the profile likelihood ratio as a test statistics. After configuring the calculator, one only needs to ask GetHypoTest() (which will return a HypoTestResult pointer) or GetInterval() (which will return an ConfInterval pointer).; LikelihoodInterval: concrete implementation of a ConfInterval interface. It implements connected N-dimensional intervals based on the contour of a likelihood ratio. The boundary of the interval is equivalent to a MINUIT/MINOS contour about the maximum likelihood estimator. . HybridCalculator: hypothesis test calculator using a Bayesian-frequentist hybrid method (often called in HEP as CLs method). This class extends the functionality of the TLimit class by taking advantage of the RooFit package. The result of the calculator is returned as an HybridResult pointer. HybridResult implements the HypoTestResult interface. The class HybridPlot allows for a graphical representation of a HybridResult.; ; Hyb",MatchSource.DOCS,roofit/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html:10778,Integrability,interface,interface,10778,"in RooStats are provided in the namespace RooStats.; ; RooStats interfaces. ConfInterval: interface for describing a confidence interval. ; IntervalCalculator: interface for a statistical tool producing confidence intervals (class ConfInterval).; HypoTestResult: interface for representing results of a hypothesis test; HypoTestCalculator: interface for a statistical tool performing an hypothesis test. ; CombinedCalculator: interface for a statistical tool which can produce both hypothesis test results and confidence intervals. ; RooStats concrete classes. The concrete classes describing statistical tools implementing the above interfaces are:; ; ProfileLikelihoodCalculator: it is an implementation of a CombinedCalculator using the profile likelihood ratio as a test statistics. After configuring the calculator, one only needs to ask GetHypoTest() (which will return a HypoTestResult pointer) or GetInterval() (which will return an ConfInterval pointer).; LikelihoodInterval: concrete implementation of a ConfInterval interface. It implements connected N-dimensional intervals based on the contour of a likelihood ratio. The boundary of the interval is equivalent to a MINUIT/MINOS contour about the maximum likelihood estimator. . HybridCalculator: hypothesis test calculator using a Bayesian-frequentist hybrid method (often called in HEP as CLs method). This class extends the functionality of the TLimit class by taking advantage of the RooFit package. The result of the calculator is returned as an HybridResult pointer. HybridResult implements the HypoTestResult interface. The class HybridPlot allows for a graphical representation of a HybridResult.; ; HybridCalculator implements the interface class HypoTestCalculator. A constructor exists taking as input the pdf's (expressed as RooAbsPdf instances) for the signal+background (alternate) and background only (null) hypothesis and the data set (as RooAbsData instance). One can provide optionally also the nuisance parameters and i",MatchSource.DOCS,roofit/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html:11329,Integrability,interface,interface,11329,"The concrete classes describing statistical tools implementing the above interfaces are:; ; ProfileLikelihoodCalculator: it is an implementation of a CombinedCalculator using the profile likelihood ratio as a test statistics. After configuring the calculator, one only needs to ask GetHypoTest() (which will return a HypoTestResult pointer) or GetInterval() (which will return an ConfInterval pointer).; LikelihoodInterval: concrete implementation of a ConfInterval interface. It implements connected N-dimensional intervals based on the contour of a likelihood ratio. The boundary of the interval is equivalent to a MINUIT/MINOS contour about the maximum likelihood estimator. . HybridCalculator: hypothesis test calculator using a Bayesian-frequentist hybrid method (often called in HEP as CLs method). This class extends the functionality of the TLimit class by taking advantage of the RooFit package. The result of the calculator is returned as an HybridResult pointer. HybridResult implements the HypoTestResult interface. The class HybridPlot allows for a graphical representation of a HybridResult.; ; HybridCalculator implements the interface class HypoTestCalculator. A constructor exists taking as input the pdf's (expressed as RooAbsPdf instances) for the signal+background (alternate) and background only (null) hypothesis and the data set (as RooAbsData instance). One can provide optionally also the nuisance parameters and its pdf which will be marginalized by the calculator. The HypoTestCalculator interface provides also the possibility of setting the model via a Rooworkspace class and names of the pdf. This possibility is not yet supported for the HybridCalculator class. ; ; . Additional classes or functions provided by RooStats are: ; ; NumberCountingUtils: a collection of number counting statistical utilities; 	NumberCountingPdfFactory: a factory for building ; 	the PDF and the data for a number counting combination and adding them in a RooWorkspace. ; 	SPlot: implementa",MatchSource.DOCS,roofit/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html:11453,Integrability,interface,interface,11453,"tion of a CombinedCalculator using the profile likelihood ratio as a test statistics. After configuring the calculator, one only needs to ask GetHypoTest() (which will return a HypoTestResult pointer) or GetInterval() (which will return an ConfInterval pointer).; LikelihoodInterval: concrete implementation of a ConfInterval interface. It implements connected N-dimensional intervals based on the contour of a likelihood ratio. The boundary of the interval is equivalent to a MINUIT/MINOS contour about the maximum likelihood estimator. . HybridCalculator: hypothesis test calculator using a Bayesian-frequentist hybrid method (often called in HEP as CLs method). This class extends the functionality of the TLimit class by taking advantage of the RooFit package. The result of the calculator is returned as an HybridResult pointer. HybridResult implements the HypoTestResult interface. The class HybridPlot allows for a graphical representation of a HybridResult.; ; HybridCalculator implements the interface class HypoTestCalculator. A constructor exists taking as input the pdf's (expressed as RooAbsPdf instances) for the signal+background (alternate) and background only (null) hypothesis and the data set (as RooAbsData instance). One can provide optionally also the nuisance parameters and its pdf which will be marginalized by the calculator. The HypoTestCalculator interface provides also the possibility of setting the model via a Rooworkspace class and names of the pdf. This possibility is not yet supported for the HybridCalculator class. ; ; . Additional classes or functions provided by RooStats are: ; ; NumberCountingUtils: a collection of number counting statistical utilities; 	NumberCountingPdfFactory: a factory for building ; 	the PDF and the data for a number counting combination and adding them in a RooWorkspace. ; 	SPlot: implementation of the SPlot statistical tool to unfold data distributions and based on RooFit. This class uses the same statistical algorithm used in t",MatchSource.DOCS,roofit/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html:11827,Integrability,interface,interface,11827,"ihood ratio. The boundary of the interval is equivalent to a MINUIT/MINOS contour about the maximum likelihood estimator. . HybridCalculator: hypothesis test calculator using a Bayesian-frequentist hybrid method (often called in HEP as CLs method). This class extends the functionality of the TLimit class by taking advantage of the RooFit package. The result of the calculator is returned as an HybridResult pointer. HybridResult implements the HypoTestResult interface. The class HybridPlot allows for a graphical representation of a HybridResult.; ; HybridCalculator implements the interface class HypoTestCalculator. A constructor exists taking as input the pdf's (expressed as RooAbsPdf instances) for the signal+background (alternate) and background only (null) hypothesis and the data set (as RooAbsData instance). One can provide optionally also the nuisance parameters and its pdf which will be marginalized by the calculator. The HypoTestCalculator interface provides also the possibility of setting the model via a Rooworkspace class and names of the pdf. This possibility is not yet supported for the HybridCalculator class. ; ; . Additional classes or functions provided by RooStats are: ; ; NumberCountingUtils: a collection of number counting statistical utilities; 	NumberCountingPdfFactory: a factory for building ; 	the PDF and the data for a number counting combination and adding them in a RooWorkspace. ; 	SPlot: implementation of the SPlot statistical tool to unfold data distributions and based on RooFit. This class uses the same statistical algorithm used in the class TSPlot, but in addition it provides the possibility to model the input distributions using RooFit model classes. This class can then be used in combination of a RooFit maximum likelihood fit. ; 	. RooStats tutorials macros; 	Tutorials are provided in the tutorials/roostats directory:. 	; rs100_numbercounting.C: an example of a combination of two searches using number counting with background uncertainty.",MatchSource.DOCS,roofit/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html:1068,Modifiability,variab,variable,1068," 70(!) tutorial macros is now available in $ROOTSYS/tutorials/roofit; These macros are divided in several subjects and are all referenced as iluustrations of concepts explained in the forthcoming edition on RooFit Users Manual.; All macros are extensively documented and each is fully functional standalone. The accompanying update; of the Manual is expected mid-September. ; ; BASIC FUNCTIONALITY. rf101_basics.C - Fitting, plotting, toy data generation on one-dimensional p.d.f ; rf102_dataimport.C - Importing data from ROOT TTrees and THx histograms; rf103_interprfuncs.C - Interpreted functions and p.d.f.s; rf104_classfactory.C - The class factory for functions and p.d.f.s; rf105_funcbinding.C - Demonstration of binding ROOT Math functions as RooFit functions and pdfs; rf106_plotdecoration.C - Adding boxes with parameters, statistics to RooPlots.; rf107_plotstyles.C - Demonstration of various plotting styles of data, functions; rf108_plotbinning.C - Plotting unbinned data with alternate and variable binnings; rf109_chi2residpull.C - Calculating chi^2 from histograms and curves in RooPlots,; rf110_normintegration.C - Examples on normalization & integration of p.d.f.s, construction of cumulative distribution functions.; rf111_numintconfig.C - Configuration and customization of how numeric (partial) integrals. ; ADDITION AND CONVOLUTION. rf201_composite.C - Composite p.d.f with signal and background component; rf202_extendedmlfit.C - Setting up an extended maximum likelihood fit; rf203_ranges.C - Fitting and plotting in sub ranges; rf204_extrangefit.C - Extended maximum likelihood fit with alternate range definition; rf205_compplot.C - Options for plotting components of composite p.d.f.s.; rf206_treevistools.C - Tools for visualization of RooAbsArg expression trees; rf207_comptools.C - Tools and utilities for manipulation of composite objects; rf208_convolution.C - One-dimensional numeric convolution; rf209_anaconv.C - Decay function p.d.fs with optional B physics. ; MULT",MatchSource.DOCS,roofit/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html:1531,Modifiability,extend,extended,1531," rf102_dataimport.C - Importing data from ROOT TTrees and THx histograms; rf103_interprfuncs.C - Interpreted functions and p.d.f.s; rf104_classfactory.C - The class factory for functions and p.d.f.s; rf105_funcbinding.C - Demonstration of binding ROOT Math functions as RooFit functions and pdfs; rf106_plotdecoration.C - Adding boxes with parameters, statistics to RooPlots.; rf107_plotstyles.C - Demonstration of various plotting styles of data, functions; rf108_plotbinning.C - Plotting unbinned data with alternate and variable binnings; rf109_chi2residpull.C - Calculating chi^2 from histograms and curves in RooPlots,; rf110_normintegration.C - Examples on normalization & integration of p.d.f.s, construction of cumulative distribution functions.; rf111_numintconfig.C - Configuration and customization of how numeric (partial) integrals. ; ADDITION AND CONVOLUTION. rf201_composite.C - Composite p.d.f with signal and background component; rf202_extendedmlfit.C - Setting up an extended maximum likelihood fit; rf203_ranges.C - Fitting and plotting in sub ranges; rf204_extrangefit.C - Extended maximum likelihood fit with alternate range definition; rf205_compplot.C - Options for plotting components of composite p.d.f.s.; rf206_treevistools.C - Tools for visualization of RooAbsArg expression trees; rf207_comptools.C - Tools and utilities for manipulation of composite objects; rf208_convolution.C - One-dimensional numeric convolution; rf209_anaconv.C - Decay function p.d.fs with optional B physics. ; MULTIDIMENSIONAL MODELS. rf301_composition.C - Multi-dimensional p.d.f.s through composition, e.g. substituting a p.d.f parameter with a function that depends on other observables; rf302_utilfuncs.C - Utility functions classes available for use in tailoring; rf303_conditional.C - Use of tailored p.d.f as conditional p.d.fs.s; rf304_uncorrprod.C - Simple uncorrelated multi-dimensional p.d.f.s; rf305_condcorrprod.C - Multi-dimensional p.d.f.s with conditional p.d.fs in product; rf3",MatchSource.DOCS,roofit/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html:3192,Modifiability,parameteriz,parameterized,3192,n other observables; rf302_utilfuncs.C - Utility functions classes available for use in tailoring; rf303_conditional.C - Use of tailored p.d.f as conditional p.d.fs.s; rf304_uncorrprod.C - Simple uncorrelated multi-dimensional p.d.f.s; rf305_condcorrprod.C - Multi-dimensional p.d.f.s with conditional p.d.fs in product; rf306_condpereventerrors.C - Complete example with use of conditional p.d.f. with per-event errors; rf307_fullpereventerrors.C -Complete example with use of full p.d.f. with per-event errors; rf308_normintegration2d.C - Examples on normalization of p.d.f.s in more than one dimension; rf309_ndimplot.C - Making 2 and 3 dimensional plots of p.d.f.s and datasets; rf310_sliceplot.C -Projecting p.d.f and data slices in discrete observables; rf311_rangeplot.C -Projecting p.d.f and data ranges in continuous observables; rf312_multirangefit.C - Performing fits in multiple (disjoint) ranges in one or more dimensions; rf313_paramranges.C - Working with parameterized ranges to define non-rectangular regions; rf314_paramfitrange.C - Working with parameterized ranges in a fit.; rf315_projectpdf.C - Marginizalization of multi-dimensional p.d.f.s through integration; rf316_llratioplot.C - Using the likelihood ratio technique to construct a signal enhanced 1-D projection of a multi-dimensional p.d.f.; ; DATA AND CATEGORIES. rf401_importttreethx.C -Overview of advanced option for importing data from ROOT TTree and THx histograms; rf402_datahandling.C - Tools for manipulation of (un)binned datasets; rf403_weightedevts.C - Using weights in unbinned datasets; rf404_categories.C - Working with RooCategory objects to describe discrete variables; rf405_realtocatfuncs.C - Demonstration of real-->discrete mapping functions; rf406_cattocatfuncs.C - Demonstration of discrete-->discrete (invertable) functions; rf407_latextables.C - Latex printing of lists and sets of RooArgSets; ; ORGANIZATION AND SIMULTANEOUS FITS. rf501_simultaneouspdf.C - Using simultaneous p.d.f.s to describe ,MatchSource.DOCS,roofit/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html:3285,Modifiability,parameteriz,parameterized,3285,ilable for use in tailoring; rf303_conditional.C - Use of tailored p.d.f as conditional p.d.fs.s; rf304_uncorrprod.C - Simple uncorrelated multi-dimensional p.d.f.s; rf305_condcorrprod.C - Multi-dimensional p.d.f.s with conditional p.d.fs in product; rf306_condpereventerrors.C - Complete example with use of conditional p.d.f. with per-event errors; rf307_fullpereventerrors.C -Complete example with use of full p.d.f. with per-event errors; rf308_normintegration2d.C - Examples on normalization of p.d.f.s in more than one dimension; rf309_ndimplot.C - Making 2 and 3 dimensional plots of p.d.f.s and datasets; rf310_sliceplot.C -Projecting p.d.f and data slices in discrete observables; rf311_rangeplot.C -Projecting p.d.f and data ranges in continuous observables; rf312_multirangefit.C - Performing fits in multiple (disjoint) ranges in one or more dimensions; rf313_paramranges.C - Working with parameterized ranges to define non-rectangular regions; rf314_paramfitrange.C - Working with parameterized ranges in a fit.; rf315_projectpdf.C - Marginizalization of multi-dimensional p.d.f.s through integration; rf316_llratioplot.C - Using the likelihood ratio technique to construct a signal enhanced 1-D projection of a multi-dimensional p.d.f.; ; DATA AND CATEGORIES. rf401_importttreethx.C -Overview of advanced option for importing data from ROOT TTree and THx histograms; rf402_datahandling.C - Tools for manipulation of (un)binned datasets; rf403_weightedevts.C - Using weights in unbinned datasets; rf404_categories.C - Working with RooCategory objects to describe discrete variables; rf405_realtocatfuncs.C - Demonstration of real-->discrete mapping functions; rf406_cattocatfuncs.C - Demonstration of discrete-->discrete (invertable) functions; rf407_latextables.C - Latex printing of lists and sets of RooArgSets; ; ORGANIZATION AND SIMULTANEOUS FITS. rf501_simultaneouspdf.C - Using simultaneous p.d.f.s to describe simultaneous fits to multiple datasets; rf502_wspacewrite.C - Creating,MatchSource.DOCS,roofit/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html:3487,Modifiability,enhance,enhanced,3487,Multi-dimensional p.d.f.s with conditional p.d.fs in product; rf306_condpereventerrors.C - Complete example with use of conditional p.d.f. with per-event errors; rf307_fullpereventerrors.C -Complete example with use of full p.d.f. with per-event errors; rf308_normintegration2d.C - Examples on normalization of p.d.f.s in more than one dimension; rf309_ndimplot.C - Making 2 and 3 dimensional plots of p.d.f.s and datasets; rf310_sliceplot.C -Projecting p.d.f and data slices in discrete observables; rf311_rangeplot.C -Projecting p.d.f and data ranges in continuous observables; rf312_multirangefit.C - Performing fits in multiple (disjoint) ranges in one or more dimensions; rf313_paramranges.C - Working with parameterized ranges to define non-rectangular regions; rf314_paramfitrange.C - Working with parameterized ranges in a fit.; rf315_projectpdf.C - Marginizalization of multi-dimensional p.d.f.s through integration; rf316_llratioplot.C - Using the likelihood ratio technique to construct a signal enhanced 1-D projection of a multi-dimensional p.d.f.; ; DATA AND CATEGORIES. rf401_importttreethx.C -Overview of advanced option for importing data from ROOT TTree and THx histograms; rf402_datahandling.C - Tools for manipulation of (un)binned datasets; rf403_weightedevts.C - Using weights in unbinned datasets; rf404_categories.C - Working with RooCategory objects to describe discrete variables; rf405_realtocatfuncs.C - Demonstration of real-->discrete mapping functions; rf406_cattocatfuncs.C - Demonstration of discrete-->discrete (invertable) functions; rf407_latextables.C - Latex printing of lists and sets of RooArgSets; ; ORGANIZATION AND SIMULTANEOUS FITS. rf501_simultaneouspdf.C - Using simultaneous p.d.f.s to describe simultaneous fits to multiple datasets; rf502_wspacewrite.C - Creating and writing a workspace; rf503_wspaceread.C - Reading and using a workspace; rf504_simwstool.C - Using RooSimWSTool to construct a simultaneous p.d.f that is built of variations of an inp,MatchSource.DOCS,roofit/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html:3876,Modifiability,variab,variables,3876,mensional plots of p.d.f.s and datasets; rf310_sliceplot.C -Projecting p.d.f and data slices in discrete observables; rf311_rangeplot.C -Projecting p.d.f and data ranges in continuous observables; rf312_multirangefit.C - Performing fits in multiple (disjoint) ranges in one or more dimensions; rf313_paramranges.C - Working with parameterized ranges to define non-rectangular regions; rf314_paramfitrange.C - Working with parameterized ranges in a fit.; rf315_projectpdf.C - Marginizalization of multi-dimensional p.d.f.s through integration; rf316_llratioplot.C - Using the likelihood ratio technique to construct a signal enhanced 1-D projection of a multi-dimensional p.d.f.; ; DATA AND CATEGORIES. rf401_importttreethx.C -Overview of advanced option for importing data from ROOT TTree and THx histograms; rf402_datahandling.C - Tools for manipulation of (un)binned datasets; rf403_weightedevts.C - Using weights in unbinned datasets; rf404_categories.C - Working with RooCategory objects to describe discrete variables; rf405_realtocatfuncs.C - Demonstration of real-->discrete mapping functions; rf406_cattocatfuncs.C - Demonstration of discrete-->discrete (invertable) functions; rf407_latextables.C - Latex printing of lists and sets of RooArgSets; ; ORGANIZATION AND SIMULTANEOUS FITS. rf501_simultaneouspdf.C - Using simultaneous p.d.f.s to describe simultaneous fits to multiple datasets; rf502_wspacewrite.C - Creating and writing a workspace; rf503_wspaceread.C - Reading and using a workspace; rf504_simwstool.C - Using RooSimWSTool to construct a simultaneous p.d.f that is built of variations of an input p.d.f; rf505_asciicfg.C - Reading and writing ASCII configuration files; rf506_msgservice.C - Tuning and customizing the RooFit message logging facility; rf507_debugtools.C - Using the RooFit memory tracing debug tool; rf508_listsetmanip.C - RooArgSet and RooArgList tools and tricks; ; LIKELIHOOD AND MINIMIZATION. rf601_intminuit.C - Interactive minimization with MINUIT; rf602_,MatchSource.DOCS,roofit/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html:4535,Modifiability,config,configuration,4535,.; ; DATA AND CATEGORIES. rf401_importttreethx.C -Overview of advanced option for importing data from ROOT TTree and THx histograms; rf402_datahandling.C - Tools for manipulation of (un)binned datasets; rf403_weightedevts.C - Using weights in unbinned datasets; rf404_categories.C - Working with RooCategory objects to describe discrete variables; rf405_realtocatfuncs.C - Demonstration of real-->discrete mapping functions; rf406_cattocatfuncs.C - Demonstration of discrete-->discrete (invertable) functions; rf407_latextables.C - Latex printing of lists and sets of RooArgSets; ; ORGANIZATION AND SIMULTANEOUS FITS. rf501_simultaneouspdf.C - Using simultaneous p.d.f.s to describe simultaneous fits to multiple datasets; rf502_wspacewrite.C - Creating and writing a workspace; rf503_wspaceread.C - Reading and using a workspace; rf504_simwstool.C - Using RooSimWSTool to construct a simultaneous p.d.f that is built of variations of an input p.d.f; rf505_asciicfg.C - Reading and writing ASCII configuration files; rf506_msgservice.C - Tuning and customizing the RooFit message logging facility; rf507_debugtools.C - Using the RooFit memory tracing debug tool; rf508_listsetmanip.C - RooArgSet and RooArgList tools and tricks; ; LIKELIHOOD AND MINIMIZATION. rf601_intminuit.C - Interactive minimization with MINUIT; rf602_chi2fit.C - Setting up a binning chi^2 fit; rf603_multicpu.C - Setting up a multi-core parallelized unbinned maximum likelihood fit; rf604_constraints.C - Fitting with constraints; rf605_profilell.C - Working with the profile likelihood estimator; rf606_nllerrorhandling.C - Understanding and customizing error handling in likelihood evaluations; rf607_fitresult.C - Demonstration of options of the RooFitResult class; ; SPECIAL PDFS. rf701_efficiencyfit.C - Unbinned maximum likelihood fit of an efficiency eff(x) function; rf702_efficiencyfit_2D.C - Unbinned maximum likelihood fit of an efficiency eff(x) function to; rf703_effpdfprod.C - Using a product of an (acceptance),MatchSource.DOCS,roofit/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html:8233,Modifiability,extend,extended,8233,"otting is now explicitly controllable, just like in fitting. See rf606_nllerrorhandling.C for details; RooDataHist - Add new named argument constructor that can collate multiple ROOT THn histgrams into a n+1 dimensional RooDataHist; RooDataSet - Add new named argument constructor that can collate multiple input RooDataSets into a n+1 dimensional RooDataSet.Add createHistogram() method for simplified plotting; RooFitResult - Add new method correlationHist() that returns a labeled TH2 with the contents of the fit correlation matrix; RooFFTConvPdf - Automatically put sampling windows of 'resolution model' p.d.f. centered around zero, even if fit range of convolution observable does not bracket zero. Improve internal efficiency; RooAbsData - Add ability to plot efficiency distribution with correct binomial errors given a RooRealVar and a RooCategory category observable encoding distribution and accept/reject state respectively. See rf701_efficiencyfit.C for details ; RooAbsPdf - Included extended ML term by default in fit if p.d.f is extendable. You can still use Extended() to override default behavior. Do not run MINOS by default anymore if no fit options are provided.; RooProfileLL - Add option to always start minimization from global minimimum (takes more time, but improves reproducibility). Can now profile multi-core paralellized likelihoods as well.; RooRealSumPdf - Enable plotting of component p.d.f.s using same scheme as RooAddPdf, i.e. just use the Components() specified in plotOn().; RooExpensiveObjectCache - New cache manager for sharing and storing of expensive components cached by operator p.d.f.s ; RooMCStudy - Add Silence() argument to constructor to request minimal verbosity during running; RooMinuit - Improve contour() method to return RooPlots rather than drawing TGraphs straight on a canvas; RooWorkspace - Add private expensive object cache to workspace; RooBinningCategory - New real-to-category function that maps values of input RooRealVar to categorie",MatchSource.DOCS,roofit/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html:8280,Modifiability,extend,extendable,8280,"in fitting. See rf606_nllerrorhandling.C for details; RooDataHist - Add new named argument constructor that can collate multiple ROOT THn histgrams into a n+1 dimensional RooDataHist; RooDataSet - Add new named argument constructor that can collate multiple input RooDataSets into a n+1 dimensional RooDataSet.Add createHistogram() method for simplified plotting; RooFitResult - Add new method correlationHist() that returns a labeled TH2 with the contents of the fit correlation matrix; RooFFTConvPdf - Automatically put sampling windows of 'resolution model' p.d.f. centered around zero, even if fit range of convolution observable does not bracket zero. Improve internal efficiency; RooAbsData - Add ability to plot efficiency distribution with correct binomial errors given a RooRealVar and a RooCategory category observable encoding distribution and accept/reject state respectively. See rf701_efficiencyfit.C for details ; RooAbsPdf - Included extended ML term by default in fit if p.d.f is extendable. You can still use Extended() to override default behavior. Do not run MINOS by default anymore if no fit options are provided.; RooProfileLL - Add option to always start minimization from global minimimum (takes more time, but improves reproducibility). Can now profile multi-core paralellized likelihoods as well.; RooRealSumPdf - Enable plotting of component p.d.f.s using same scheme as RooAddPdf, i.e. just use the Components() specified in plotOn().; RooExpensiveObjectCache - New cache manager for sharing and storing of expensive components cached by operator p.d.f.s ; RooMCStudy - Add Silence() argument to constructor to request minimal verbosity during running; RooMinuit - Improve contour() method to return RooPlots rather than drawing TGraphs straight on a canvas; RooWorkspace - Add private expensive object cache to workspace; RooBinningCategory - New real-to-category function that maps values of input RooRealVar to categories with labels that correspond to bins of input R",MatchSource.DOCS,roofit/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html:10544,Modifiability,config,configuring,10544,"dealing with the obtained results and concrete classes implementing the statistical methods.; ; All the classes and functions in RooStats are provided in the namespace RooStats.; ; RooStats interfaces. ConfInterval: interface for describing a confidence interval. ; IntervalCalculator: interface for a statistical tool producing confidence intervals (class ConfInterval).; HypoTestResult: interface for representing results of a hypothesis test; HypoTestCalculator: interface for a statistical tool performing an hypothesis test. ; CombinedCalculator: interface for a statistical tool which can produce both hypothesis test results and confidence intervals. ; RooStats concrete classes. The concrete classes describing statistical tools implementing the above interfaces are:; ; ProfileLikelihoodCalculator: it is an implementation of a CombinedCalculator using the profile likelihood ratio as a test statistics. After configuring the calculator, one only needs to ask GetHypoTest() (which will return a HypoTestResult pointer) or GetInterval() (which will return an ConfInterval pointer).; LikelihoodInterval: concrete implementation of a ConfInterval interface. It implements connected N-dimensional intervals based on the contour of a likelihood ratio. The boundary of the interval is equivalent to a MINUIT/MINOS contour about the maximum likelihood estimator. . HybridCalculator: hypothesis test calculator using a Bayesian-frequentist hybrid method (often called in HEP as CLs method). This class extends the functionality of the TLimit class by taking advantage of the RooFit package. The result of the calculator is returned as an HybridResult pointer. HybridResult implements the HypoTestResult interface. The class HybridPlot allows for a graphical representation of a HybridResult.; ; HybridCalculator implements the interface class HypoTestCalculator. A constructor exists taking as input the pdf's (expressed as RooAbsPdf instances) for the signal+background (alternate) and background on",MatchSource.DOCS,roofit/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html:11128,Modifiability,extend,extends,11128,"alculator: interface for a statistical tool which can produce both hypothesis test results and confidence intervals. ; RooStats concrete classes. The concrete classes describing statistical tools implementing the above interfaces are:; ; ProfileLikelihoodCalculator: it is an implementation of a CombinedCalculator using the profile likelihood ratio as a test statistics. After configuring the calculator, one only needs to ask GetHypoTest() (which will return a HypoTestResult pointer) or GetInterval() (which will return an ConfInterval pointer).; LikelihoodInterval: concrete implementation of a ConfInterval interface. It implements connected N-dimensional intervals based on the contour of a likelihood ratio. The boundary of the interval is equivalent to a MINUIT/MINOS contour about the maximum likelihood estimator. . HybridCalculator: hypothesis test calculator using a Bayesian-frequentist hybrid method (often called in HEP as CLs method). This class extends the functionality of the TLimit class by taking advantage of the RooFit package. The result of the calculator is returned as an HybridResult pointer. HybridResult implements the HypoTestResult interface. The class HybridPlot allows for a graphical representation of a HybridResult.; ; HybridCalculator implements the interface class HypoTestCalculator. A constructor exists taking as input the pdf's (expressed as RooAbsPdf instances) for the signal+background (alternate) and background only (null) hypothesis and the data set (as RooAbsData instance). One can provide optionally also the nuisance parameters and its pdf which will be marginalized by the calculator. The HypoTestCalculator interface provides also the possibility of setting the model via a Rooworkspace class and names of the pdf. This possibility is not yet supported for the HybridCalculator class. ; ; . Additional classes or functions provided by RooStats are: ; ; NumberCountingUtils: a collection of number counting statistical utilities; 	NumberCountingPd",MatchSource.DOCS,roofit/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html:6074,Performance,perform,perform,6074,"elihood estimator; rf606_nllerrorhandling.C - Understanding and customizing error handling in likelihood evaluations; rf607_fitresult.C - Demonstration of options of the RooFitResult class; ; SPECIAL PDFS. rf701_efficiencyfit.C - Unbinned maximum likelihood fit of an efficiency eff(x) function; rf702_efficiencyfit_2D.C - Unbinned maximum likelihood fit of an efficiency eff(x) function to; rf703_effpdfprod.C - Using a product of an (acceptance) efficiency and a p.d.f as p.d.f.; rf704_amplitudefit.C - Using a p.d.f defined by a sum of real-valued amplitude components; rf705_linearmorph.C - Linear interpolation between p.d.f shapes using the 'Alex Read' algorithm; rf706_histpdf.C - Histogram based p.d.f.s and functions; rf707_kernelestimation.C - Using non-parametric (multi-dimensional) kernel estimation p.d.f.s; rf708_bphysics.C - Special decay pdf for B physics with mixing and/or CP violation; ; VALIDATION AND MC STUDIES. rf801_mcstudy.C - A Toy Monte Carlo study that perform cycles of event generation and fittting; rf802_mcstudy_addons.C - RooMCStudy: using separate fit and generator models, using the chi^2 calculator model; rf803_mcstudy_addons2.C - RooMCStudy: Using the randomizer and profile likelihood add-on models; rf804_mcstudy_constr.C - Using RooMCStudy on models with constrains; ; Miscellaneous small improvements. A very large number of small fixes and interface improvements have been made in the context of the systematic review of all methods for the new tutorial macros and updated Users Manual.; Listed below are the most significant functionality upgrades that were introduced in the process. ; Runtime binding of C++ functions - You can now trivially bind at run time any C++ functions as a RooFit function or p.d.f. objects, e.g. RooAbsReal* erfx = bindFunction(""erfx"",TMath::erf,x). See rf105_funcbinding.C for details; Runtime binding of TFx functions - You can now trivially bind at run time any ROOT TFx function as a RooFit function or p.d.f. objects, e.g. ",MatchSource.DOCS,roofit/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html:8778,Performance,cache,cache,8778,"t sampling windows of 'resolution model' p.d.f. centered around zero, even if fit range of convolution observable does not bracket zero. Improve internal efficiency; RooAbsData - Add ability to plot efficiency distribution with correct binomial errors given a RooRealVar and a RooCategory category observable encoding distribution and accept/reject state respectively. See rf701_efficiencyfit.C for details ; RooAbsPdf - Included extended ML term by default in fit if p.d.f is extendable. You can still use Extended() to override default behavior. Do not run MINOS by default anymore if no fit options are provided.; RooProfileLL - Add option to always start minimization from global minimimum (takes more time, but improves reproducibility). Can now profile multi-core paralellized likelihoods as well.; RooRealSumPdf - Enable plotting of component p.d.f.s using same scheme as RooAddPdf, i.e. just use the Components() specified in plotOn().; RooExpensiveObjectCache - New cache manager for sharing and storing of expensive components cached by operator p.d.f.s ; RooMCStudy - Add Silence() argument to constructor to request minimal verbosity during running; RooMinuit - Improve contour() method to return RooPlots rather than drawing TGraphs straight on a canvas; RooWorkspace - Add private expensive object cache to workspace; RooBinningCategory - New real-to-category function that maps values of input RooRealVar to categories with labels that correspond to bins of input RooRealVar. See rf405_realtocatfuncs.C for details . RooStats; This is a new package introduced in this version for statistical tools built on top of RooFit. It is a joint effort between the LHC experiments and the ROOT team (see the RooStats Wiki page).; ; This version contains the interfaces for performing the statistical calculations and dealing with the obtained results and concrete classes implementing the statistical methods.; ; All the classes and functions in RooStats are provided in the namespace RooStats.; ",MatchSource.DOCS,roofit/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html:8840,Performance,cache,cached,8840,"t sampling windows of 'resolution model' p.d.f. centered around zero, even if fit range of convolution observable does not bracket zero. Improve internal efficiency; RooAbsData - Add ability to plot efficiency distribution with correct binomial errors given a RooRealVar and a RooCategory category observable encoding distribution and accept/reject state respectively. See rf701_efficiencyfit.C for details ; RooAbsPdf - Included extended ML term by default in fit if p.d.f is extendable. You can still use Extended() to override default behavior. Do not run MINOS by default anymore if no fit options are provided.; RooProfileLL - Add option to always start minimization from global minimimum (takes more time, but improves reproducibility). Can now profile multi-core paralellized likelihoods as well.; RooRealSumPdf - Enable plotting of component p.d.f.s using same scheme as RooAddPdf, i.e. just use the Components() specified in plotOn().; RooExpensiveObjectCache - New cache manager for sharing and storing of expensive components cached by operator p.d.f.s ; RooMCStudy - Add Silence() argument to constructor to request minimal verbosity during running; RooMinuit - Improve contour() method to return RooPlots rather than drawing TGraphs straight on a canvas; RooWorkspace - Add private expensive object cache to workspace; RooBinningCategory - New real-to-category function that maps values of input RooRealVar to categories with labels that correspond to bins of input RooRealVar. See rf405_realtocatfuncs.C for details . RooStats; This is a new package introduced in this version for statistical tools built on top of RooFit. It is a joint effort between the LHC experiments and the ROOT team (see the RooStats Wiki page).; ; This version contains the interfaces for performing the statistical calculations and dealing with the obtained results and concrete classes implementing the statistical methods.; ; All the classes and functions in RooStats are provided in the namespace RooStats.; ",MatchSource.DOCS,roofit/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html:9115,Performance,cache,cache,9115," RooCategory category observable encoding distribution and accept/reject state respectively. See rf701_efficiencyfit.C for details ; RooAbsPdf - Included extended ML term by default in fit if p.d.f is extendable. You can still use Extended() to override default behavior. Do not run MINOS by default anymore if no fit options are provided.; RooProfileLL - Add option to always start minimization from global minimimum (takes more time, but improves reproducibility). Can now profile multi-core paralellized likelihoods as well.; RooRealSumPdf - Enable plotting of component p.d.f.s using same scheme as RooAddPdf, i.e. just use the Components() specified in plotOn().; RooExpensiveObjectCache - New cache manager for sharing and storing of expensive components cached by operator p.d.f.s ; RooMCStudy - Add Silence() argument to constructor to request minimal verbosity during running; RooMinuit - Improve contour() method to return RooPlots rather than drawing TGraphs straight on a canvas; RooWorkspace - Add private expensive object cache to workspace; RooBinningCategory - New real-to-category function that maps values of input RooRealVar to categories with labels that correspond to bins of input RooRealVar. See rf405_realtocatfuncs.C for details . RooStats; This is a new package introduced in this version for statistical tools built on top of RooFit. It is a joint effort between the LHC experiments and the ROOT team (see the RooStats Wiki page).; ; This version contains the interfaces for performing the statistical calculations and dealing with the obtained results and concrete classes implementing the statistical methods.; ; All the classes and functions in RooStats are provided in the namespace RooStats.; ; RooStats interfaces. ConfInterval: interface for describing a confidence interval. ; IntervalCalculator: interface for a statistical tool producing confidence intervals (class ConfInterval).; HypoTestResult: interface for representing results of a hypothesis test; HypoTest",MatchSource.DOCS,roofit/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html:9581,Performance,perform,performing,9581,"able plotting of component p.d.f.s using same scheme as RooAddPdf, i.e. just use the Components() specified in plotOn().; RooExpensiveObjectCache - New cache manager for sharing and storing of expensive components cached by operator p.d.f.s ; RooMCStudy - Add Silence() argument to constructor to request minimal verbosity during running; RooMinuit - Improve contour() method to return RooPlots rather than drawing TGraphs straight on a canvas; RooWorkspace - Add private expensive object cache to workspace; RooBinningCategory - New real-to-category function that maps values of input RooRealVar to categories with labels that correspond to bins of input RooRealVar. See rf405_realtocatfuncs.C for details . RooStats; This is a new package introduced in this version for statistical tools built on top of RooFit. It is a joint effort between the LHC experiments and the ROOT team (see the RooStats Wiki page).; ; This version contains the interfaces for performing the statistical calculations and dealing with the obtained results and concrete classes implementing the statistical methods.; ; All the classes and functions in RooStats are provided in the namespace RooStats.; ; RooStats interfaces. ConfInterval: interface for describing a confidence interval. ; IntervalCalculator: interface for a statistical tool producing confidence intervals (class ConfInterval).; HypoTestResult: interface for representing results of a hypothesis test; HypoTestCalculator: interface for a statistical tool performing an hypothesis test. ; CombinedCalculator: interface for a statistical tool which can produce both hypothesis test results and confidence intervals. ; RooStats concrete classes. The concrete classes describing statistical tools implementing the above interfaces are:; ; ProfileLikelihoodCalculator: it is an implementation of a CombinedCalculator using the profile likelihood ratio as a test statistics. After configuring the calculator, one only needs to ask GetHypoTest() (which will return ",MatchSource.DOCS,roofit/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html:10124,Performance,perform,performing,10124,"orkspace - Add private expensive object cache to workspace; RooBinningCategory - New real-to-category function that maps values of input RooRealVar to categories with labels that correspond to bins of input RooRealVar. See rf405_realtocatfuncs.C for details . RooStats; This is a new package introduced in this version for statistical tools built on top of RooFit. It is a joint effort between the LHC experiments and the ROOT team (see the RooStats Wiki page).; ; This version contains the interfaces for performing the statistical calculations and dealing with the obtained results and concrete classes implementing the statistical methods.; ; All the classes and functions in RooStats are provided in the namespace RooStats.; ; RooStats interfaces. ConfInterval: interface for describing a confidence interval. ; IntervalCalculator: interface for a statistical tool producing confidence intervals (class ConfInterval).; HypoTestResult: interface for representing results of a hypothesis test; HypoTestCalculator: interface for a statistical tool performing an hypothesis test. ; CombinedCalculator: interface for a statistical tool which can produce both hypothesis test results and confidence intervals. ; RooStats concrete classes. The concrete classes describing statistical tools implementing the above interfaces are:; ; ProfileLikelihoodCalculator: it is an implementation of a CombinedCalculator using the profile likelihood ratio as a test statistics. After configuring the calculator, one only needs to ask GetHypoTest() (which will return a HypoTestResult pointer) or GetInterval() (which will return an ConfInterval pointer).; LikelihoodInterval: concrete implementation of a ConfInterval interface. It implements connected N-dimensional intervals based on the contour of a likelihood ratio. The boundary of the interval is equivalent to a MINUIT/MINOS contour about the maximum likelihood estimator. . HybridCalculator: hypothesis test calculator using a Bayesian-frequentist hybrid me",MatchSource.DOCS,roofit/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html:4619,Testability,log,logging,4619,ion for importing data from ROOT TTree and THx histograms; rf402_datahandling.C - Tools for manipulation of (un)binned datasets; rf403_weightedevts.C - Using weights in unbinned datasets; rf404_categories.C - Working with RooCategory objects to describe discrete variables; rf405_realtocatfuncs.C - Demonstration of real-->discrete mapping functions; rf406_cattocatfuncs.C - Demonstration of discrete-->discrete (invertable) functions; rf407_latextables.C - Latex printing of lists and sets of RooArgSets; ; ORGANIZATION AND SIMULTANEOUS FITS. rf501_simultaneouspdf.C - Using simultaneous p.d.f.s to describe simultaneous fits to multiple datasets; rf502_wspacewrite.C - Creating and writing a workspace; rf503_wspaceread.C - Reading and using a workspace; rf504_simwstool.C - Using RooSimWSTool to construct a simultaneous p.d.f that is built of variations of an input p.d.f; rf505_asciicfg.C - Reading and writing ASCII configuration files; rf506_msgservice.C - Tuning and customizing the RooFit message logging facility; rf507_debugtools.C - Using the RooFit memory tracing debug tool; rf508_listsetmanip.C - RooArgSet and RooArgList tools and tricks; ; LIKELIHOOD AND MINIMIZATION. rf601_intminuit.C - Interactive minimization with MINUIT; rf602_chi2fit.C - Setting up a binning chi^2 fit; rf603_multicpu.C - Setting up a multi-core parallelized unbinned maximum likelihood fit; rf604_constraints.C - Fitting with constraints; rf605_profilell.C - Working with the profile likelihood estimator; rf606_nllerrorhandling.C - Understanding and customizing error handling in likelihood evaluations; rf607_fitresult.C - Demonstration of options of the RooFitResult class; ; SPECIAL PDFS. rf701_efficiencyfit.C - Unbinned maximum likelihood fit of an efficiency eff(x) function; rf702_efficiencyfit_2D.C - Unbinned maximum likelihood fit of an efficiency eff(x) function to; rf703_effpdfprod.C - Using a product of an (acceptance) efficiency and a p.d.f as p.d.f.; rf704_amplitudefit.C - Using a p.d.f def,MatchSource.DOCS,roofit/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html:7204,Testability,log,log,7204,"r model; rf803_mcstudy_addons2.C - RooMCStudy: Using the randomizer and profile likelihood add-on models; rf804_mcstudy_constr.C - Using RooMCStudy on models with constrains; ; Miscellaneous small improvements. A very large number of small fixes and interface improvements have been made in the context of the systematic review of all methods for the new tutorial macros and updated Users Manual.; Listed below are the most significant functionality upgrades that were introduced in the process. ; Runtime binding of C++ functions - You can now trivially bind at run time any C++ functions as a RooFit function or p.d.f. objects, e.g. RooAbsReal* erfx = bindFunction(""erfx"",TMath::erf,x). See rf105_funcbinding.C for details; Runtime binding of TFx functions - You can now trivially bind at run time any ROOT TFx function as a RooFit function or p.d.f. objects, e.g. RooAbsReal* myFunc = bindFunction(myTF1,x). See rf105_funcbinding.C for details; RooAbsReal - The handling of -log(L) evaluation errors in plotting is now explicitly controllable, just like in fitting. See rf606_nllerrorhandling.C for details; RooDataHist - Add new named argument constructor that can collate multiple ROOT THn histgrams into a n+1 dimensional RooDataHist; RooDataSet - Add new named argument constructor that can collate multiple input RooDataSets into a n+1 dimensional RooDataSet.Add createHistogram() method for simplified plotting; RooFitResult - Add new method correlationHist() that returns a labeled TH2 with the contents of the fit correlation matrix; RooFFTConvPdf - Automatically put sampling windows of 'resolution model' p.d.f. centered around zero, even if fit range of convolution observable does not bracket zero. Improve internal efficiency; RooAbsData - Add ability to plot efficiency distribution with correct binomial errors given a RooRealVar and a RooCategory category observable encoding distribution and accept/reject state respectively. See rf701_efficiencyfit.C for details ; RooAbsPdf - Inc",MatchSource.DOCS,roofit/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html:10065,Testability,test,test,10065,"orkspace - Add private expensive object cache to workspace; RooBinningCategory - New real-to-category function that maps values of input RooRealVar to categories with labels that correspond to bins of input RooRealVar. See rf405_realtocatfuncs.C for details . RooStats; This is a new package introduced in this version for statistical tools built on top of RooFit. It is a joint effort between the LHC experiments and the ROOT team (see the RooStats Wiki page).; ; This version contains the interfaces for performing the statistical calculations and dealing with the obtained results and concrete classes implementing the statistical methods.; ; All the classes and functions in RooStats are provided in the namespace RooStats.; ; RooStats interfaces. ConfInterval: interface for describing a confidence interval. ; IntervalCalculator: interface for a statistical tool producing confidence intervals (class ConfInterval).; HypoTestResult: interface for representing results of a hypothesis test; HypoTestCalculator: interface for a statistical tool performing an hypothesis test. ; CombinedCalculator: interface for a statistical tool which can produce both hypothesis test results and confidence intervals. ; RooStats concrete classes. The concrete classes describing statistical tools implementing the above interfaces are:; ; ProfileLikelihoodCalculator: it is an implementation of a CombinedCalculator using the profile likelihood ratio as a test statistics. After configuring the calculator, one only needs to ask GetHypoTest() (which will return a HypoTestResult pointer) or GetInterval() (which will return an ConfInterval pointer).; LikelihoodInterval: concrete implementation of a ConfInterval interface. It implements connected N-dimensional intervals based on the contour of a likelihood ratio. The boundary of the interval is equivalent to a MINUIT/MINOS contour about the maximum likelihood estimator. . HybridCalculator: hypothesis test calculator using a Bayesian-frequentist hybrid me",MatchSource.DOCS,roofit/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html:10149,Testability,test,test,10149,"orkspace - Add private expensive object cache to workspace; RooBinningCategory - New real-to-category function that maps values of input RooRealVar to categories with labels that correspond to bins of input RooRealVar. See rf405_realtocatfuncs.C for details . RooStats; This is a new package introduced in this version for statistical tools built on top of RooFit. It is a joint effort between the LHC experiments and the ROOT team (see the RooStats Wiki page).; ; This version contains the interfaces for performing the statistical calculations and dealing with the obtained results and concrete classes implementing the statistical methods.; ; All the classes and functions in RooStats are provided in the namespace RooStats.; ; RooStats interfaces. ConfInterval: interface for describing a confidence interval. ; IntervalCalculator: interface for a statistical tool producing confidence intervals (class ConfInterval).; HypoTestResult: interface for representing results of a hypothesis test; HypoTestCalculator: interface for a statistical tool performing an hypothesis test. ; CombinedCalculator: interface for a statistical tool which can produce both hypothesis test results and confidence intervals. ; RooStats concrete classes. The concrete classes describing statistical tools implementing the above interfaces are:; ; ProfileLikelihoodCalculator: it is an implementation of a CombinedCalculator using the profile likelihood ratio as a test statistics. After configuring the calculator, one only needs to ask GetHypoTest() (which will return a HypoTestResult pointer) or GetInterval() (which will return an ConfInterval pointer).; LikelihoodInterval: concrete implementation of a ConfInterval interface. It implements connected N-dimensional intervals based on the contour of a likelihood ratio. The boundary of the interval is equivalent to a MINUIT/MINOS contour about the maximum likelihood estimator. . HybridCalculator: hypothesis test calculator using a Bayesian-frequentist hybrid me",MatchSource.DOCS,roofit/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html:10244,Testability,test,test,10244,"lVar to categories with labels that correspond to bins of input RooRealVar. See rf405_realtocatfuncs.C for details . RooStats; This is a new package introduced in this version for statistical tools built on top of RooFit. It is a joint effort between the LHC experiments and the ROOT team (see the RooStats Wiki page).; ; This version contains the interfaces for performing the statistical calculations and dealing with the obtained results and concrete classes implementing the statistical methods.; ; All the classes and functions in RooStats are provided in the namespace RooStats.; ; RooStats interfaces. ConfInterval: interface for describing a confidence interval. ; IntervalCalculator: interface for a statistical tool producing confidence intervals (class ConfInterval).; HypoTestResult: interface for representing results of a hypothesis test; HypoTestCalculator: interface for a statistical tool performing an hypothesis test. ; CombinedCalculator: interface for a statistical tool which can produce both hypothesis test results and confidence intervals. ; RooStats concrete classes. The concrete classes describing statistical tools implementing the above interfaces are:; ; ProfileLikelihoodCalculator: it is an implementation of a CombinedCalculator using the profile likelihood ratio as a test statistics. After configuring the calculator, one only needs to ask GetHypoTest() (which will return a HypoTestResult pointer) or GetInterval() (which will return an ConfInterval pointer).; LikelihoodInterval: concrete implementation of a ConfInterval interface. It implements connected N-dimensional intervals based on the contour of a likelihood ratio. The boundary of the interval is equivalent to a MINUIT/MINOS contour about the maximum likelihood estimator. . HybridCalculator: hypothesis test calculator using a Bayesian-frequentist hybrid method (often called in HEP as CLs method). This class extends the functionality of the TLimit class by taking advantage of the RooFit package. T",MatchSource.DOCS,roofit/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html:10521,Testability,test,test,10521," top of RooFit. It is a joint effort between the LHC experiments and the ROOT team (see the RooStats Wiki page).; ; This version contains the interfaces for performing the statistical calculations and dealing with the obtained results and concrete classes implementing the statistical methods.; ; All the classes and functions in RooStats are provided in the namespace RooStats.; ; RooStats interfaces. ConfInterval: interface for describing a confidence interval. ; IntervalCalculator: interface for a statistical tool producing confidence intervals (class ConfInterval).; HypoTestResult: interface for representing results of a hypothesis test; HypoTestCalculator: interface for a statistical tool performing an hypothesis test. ; CombinedCalculator: interface for a statistical tool which can produce both hypothesis test results and confidence intervals. ; RooStats concrete classes. The concrete classes describing statistical tools implementing the above interfaces are:; ; ProfileLikelihoodCalculator: it is an implementation of a CombinedCalculator using the profile likelihood ratio as a test statistics. After configuring the calculator, one only needs to ask GetHypoTest() (which will return a HypoTestResult pointer) or GetInterval() (which will return an ConfInterval pointer).; LikelihoodInterval: concrete implementation of a ConfInterval interface. It implements connected N-dimensional intervals based on the contour of a likelihood ratio. The boundary of the interval is equivalent to a MINUIT/MINOS contour about the maximum likelihood estimator. . HybridCalculator: hypothesis test calculator using a Bayesian-frequentist hybrid method (often called in HEP as CLs method). This class extends the functionality of the TLimit class by taking advantage of the RooFit package. The result of the calculator is returned as an HybridResult pointer. HybridResult implements the HypoTestResult interface. The class HybridPlot allows for a graphical representation of a HybridResult.; ; Hyb",MatchSource.DOCS,roofit/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html:11021,Testability,test,test,11021," hypothesis test; HypoTestCalculator: interface for a statistical tool performing an hypothesis test. ; CombinedCalculator: interface for a statistical tool which can produce both hypothesis test results and confidence intervals. ; RooStats concrete classes. The concrete classes describing statistical tools implementing the above interfaces are:; ; ProfileLikelihoodCalculator: it is an implementation of a CombinedCalculator using the profile likelihood ratio as a test statistics. After configuring the calculator, one only needs to ask GetHypoTest() (which will return a HypoTestResult pointer) or GetInterval() (which will return an ConfInterval pointer).; LikelihoodInterval: concrete implementation of a ConfInterval interface. It implements connected N-dimensional intervals based on the contour of a likelihood ratio. The boundary of the interval is equivalent to a MINUIT/MINOS contour about the maximum likelihood estimator. . HybridCalculator: hypothesis test calculator using a Bayesian-frequentist hybrid method (often called in HEP as CLs method). This class extends the functionality of the TLimit class by taking advantage of the RooFit package. The result of the calculator is returned as an HybridResult pointer. HybridResult implements the HypoTestResult interface. The class HybridPlot allows for a graphical representation of a HybridResult.; ; HybridCalculator implements the interface class HypoTestCalculator. A constructor exists taking as input the pdf's (expressed as RooAbsPdf instances) for the signal+background (alternate) and background only (null) hypothesis and the data set (as RooAbsData instance). One can provide optionally also the nuisance parameters and its pdf which will be marginalized by the calculator. The HypoTestCalculator interface provides also the possibility of setting the model via a Rooworkspace class and names of the pdf. This possibility is not yet supported for the HybridCalculator class. ; ; . Additional classes or functions provided by",MatchSource.DOCS,roofit/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html:12968,Testability,test,test,12968,"Ls method). This class extends the functionality of the TLimit class by taking advantage of the RooFit package. The result of the calculator is returned as an HybridResult pointer. HybridResult implements the HypoTestResult interface. The class HybridPlot allows for a graphical representation of a HybridResult.; ; HybridCalculator implements the interface class HypoTestCalculator. A constructor exists taking as input the pdf's (expressed as RooAbsPdf instances) for the signal+background (alternate) and background only (null) hypothesis and the data set (as RooAbsData instance). One can provide optionally also the nuisance parameters and its pdf which will be marginalized by the calculator. The HypoTestCalculator interface provides also the possibility of setting the model via a Rooworkspace class and names of the pdf. This possibility is not yet supported for the HybridCalculator class. ; ; . Additional classes or functions provided by RooStats are: ; ; NumberCountingUtils: a collection of number counting statistical utilities; 	NumberCountingPdfFactory: a factory for building ; 	the PDF and the data for a number counting combination and adding them in a RooWorkspace. ; 	SPlot: implementation of the SPlot statistical tool to unfold data distributions and based on RooFit. This class uses the same statistical algorithm used in the class TSPlot, but in addition it provides the possibility to model the input distributions using RooFit model classes. This class can then be used in combination of a RooFit maximum likelihood fit. ; 	. RooStats tutorials macros; 	Tutorials are provided in the tutorials/roostats directory:. 	; rs100_numbercounting.C: an example of a combination of two searches using number counting with background uncertainty.; 	 rs102_hypotestwithshapes.C: example of usage of ProfileLikleihoodCalculator to do a hypothesis test of the background-only and signal+background hypotheses.; 	 rs201_hybridcalculator.C: example how to use the HybridCalculator. ; 	; ",MatchSource.DOCS,roofit/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html:7626,Usability,simpl,simplified,7626,"s. ; Runtime binding of C++ functions - You can now trivially bind at run time any C++ functions as a RooFit function or p.d.f. objects, e.g. RooAbsReal* erfx = bindFunction(""erfx"",TMath::erf,x). See rf105_funcbinding.C for details; Runtime binding of TFx functions - You can now trivially bind at run time any ROOT TFx function as a RooFit function or p.d.f. objects, e.g. RooAbsReal* myFunc = bindFunction(myTF1,x). See rf105_funcbinding.C for details; RooAbsReal - The handling of -log(L) evaluation errors in plotting is now explicitly controllable, just like in fitting. See rf606_nllerrorhandling.C for details; RooDataHist - Add new named argument constructor that can collate multiple ROOT THn histgrams into a n+1 dimensional RooDataHist; RooDataSet - Add new named argument constructor that can collate multiple input RooDataSets into a n+1 dimensional RooDataSet.Add createHistogram() method for simplified plotting; RooFitResult - Add new method correlationHist() that returns a labeled TH2 with the contents of the fit correlation matrix; RooFFTConvPdf - Automatically put sampling windows of 'resolution model' p.d.f. centered around zero, even if fit range of convolution observable does not bracket zero. Improve internal efficiency; RooAbsData - Add ability to plot efficiency distribution with correct binomial errors given a RooRealVar and a RooCategory category observable encoding distribution and accept/reject state respectively. See rf701_efficiencyfit.C for details ; RooAbsPdf - Included extended ML term by default in fit if p.d.f is extendable. You can still use Extended() to override default behavior. Do not run MINOS by default anymore if no fit options are provided.; RooProfileLL - Add option to always start minimization from global minimimum (takes more time, but improves reproducibility). Can now profile multi-core paralellized likelihoods as well.; RooRealSumPdf - Enable plotting of component p.d.f.s using same scheme as RooAddPdf, i.e. just use the Component",MatchSource.DOCS,roofit/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:643,Availability,error,error,643,". RooFit. This release of ROOT contains RooFit version 3.00. A summary of new features is listed below. RooFit Web documentation moved to ROOT web site; The starting point for online RooFit documentation (Users Manual,; tutorials, slides etc) is now moved to the ROOT website; https://root.cern/topical/#roofit; Error visualization; It is now possible to visualize the effect of the uncertainties on parameters from a fit; on any p.d.f. or function projection. To do so use the new VisualizeError() argument; in a plotOn call. RooFitResult* fr = pdf->fitTo(*data,Save(),...) ;; pdf->plotOn(frame,VisualizeError(*fr),...) ;. Two techniques for error visualization are implemented. The default is; linear error propagation, and results in an error band that is by; construction symmetric. The linear error is calculated as. error(x) = Z* F_a(x) * Corr(a,a') F_a'(x). where F_a(x) = [ f(x,a+da) - f(x,a-da) ] / 2,. with f(x) = the plotted curve; 'da' = error taken from the fit result; Corr(a,a') = the correlation matrix from the fit result; Z = requested significance 'Z sigma band'. The linear method is fast (requires 2*N evaluations of the curve,; where N is the number of parameters), but may not be accurate in the; presence of strong correlations (~>0.9) and at Z>2 due to linear and; Gaussian approximations made. Alternatively, errors can be visualized using a sampling method. In; this method a number of curves is calculated with variations of the; parameter values, as sampled from a multi-variate Gaussian p.d.f. that; is constructed from the fit results covariance matrix. The error(x); is determined by calculating a central interval that capture N% of the; variations for each value of x, where N% is controlled by Z (i.e. Z=1; gives N=68%). The number of sampling curves is chosen to be such that; at least 100 curves are expected to be outside the N% interval. Intervals from; the sampling method can be asymmetric, and may perform better in the; presence of strong correlations, but m",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:703,Availability,error,error,703,". RooFit. This release of ROOT contains RooFit version 3.00. A summary of new features is listed below. RooFit Web documentation moved to ROOT web site; The starting point for online RooFit documentation (Users Manual,; tutorials, slides etc) is now moved to the ROOT website; https://root.cern/topical/#roofit; Error visualization; It is now possible to visualize the effect of the uncertainties on parameters from a fit; on any p.d.f. or function projection. To do so use the new VisualizeError() argument; in a plotOn call. RooFitResult* fr = pdf->fitTo(*data,Save(),...) ;; pdf->plotOn(frame,VisualizeError(*fr),...) ;. Two techniques for error visualization are implemented. The default is; linear error propagation, and results in an error band that is by; construction symmetric. The linear error is calculated as. error(x) = Z* F_a(x) * Corr(a,a') F_a'(x). where F_a(x) = [ f(x,a+da) - f(x,a-da) ] / 2,. with f(x) = the plotted curve; 'da' = error taken from the fit result; Corr(a,a') = the correlation matrix from the fit result; Z = requested significance 'Z sigma band'. The linear method is fast (requires 2*N evaluations of the curve,; where N is the number of parameters), but may not be accurate in the; presence of strong correlations (~>0.9) and at Z>2 due to linear and; Gaussian approximations made. Alternatively, errors can be visualized using a sampling method. In; this method a number of curves is calculated with variations of the; parameter values, as sampled from a multi-variate Gaussian p.d.f. that; is constructed from the fit results covariance matrix. The error(x); is determined by calculating a central interval that capture N% of the; variations for each value of x, where N% is controlled by Z (i.e. Z=1; gives N=68%). The number of sampling curves is chosen to be such that; at least 100 curves are expected to be outside the N% interval. Intervals from; the sampling method can be asymmetric, and may perform better in the; presence of strong correlations, but m",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:740,Availability,error,error,740,". RooFit. This release of ROOT contains RooFit version 3.00. A summary of new features is listed below. RooFit Web documentation moved to ROOT web site; The starting point for online RooFit documentation (Users Manual,; tutorials, slides etc) is now moved to the ROOT website; https://root.cern/topical/#roofit; Error visualization; It is now possible to visualize the effect of the uncertainties on parameters from a fit; on any p.d.f. or function projection. To do so use the new VisualizeError() argument; in a plotOn call. RooFitResult* fr = pdf->fitTo(*data,Save(),...) ;; pdf->plotOn(frame,VisualizeError(*fr),...) ;. Two techniques for error visualization are implemented. The default is; linear error propagation, and results in an error band that is by; construction symmetric. The linear error is calculated as. error(x) = Z* F_a(x) * Corr(a,a') F_a'(x). where F_a(x) = [ f(x,a+da) - f(x,a-da) ] / 2,. with f(x) = the plotted curve; 'da' = error taken from the fit result; Corr(a,a') = the correlation matrix from the fit result; Z = requested significance 'Z sigma band'. The linear method is fast (requires 2*N evaluations of the curve,; where N is the number of parameters), but may not be accurate in the; presence of strong correlations (~>0.9) and at Z>2 due to linear and; Gaussian approximations made. Alternatively, errors can be visualized using a sampling method. In; this method a number of curves is calculated with variations of the; parameter values, as sampled from a multi-variate Gaussian p.d.f. that; is constructed from the fit results covariance matrix. The error(x); is determined by calculating a central interval that capture N% of the; variations for each value of x, where N% is controlled by Z (i.e. Z=1; gives N=68%). The number of sampling curves is chosen to be such that; at least 100 curves are expected to be outside the N% interval. Intervals from; the sampling method can be asymmetric, and may perform better in the; presence of strong correlations, but m",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:798,Availability,error,error,798,". RooFit. This release of ROOT contains RooFit version 3.00. A summary of new features is listed below. RooFit Web documentation moved to ROOT web site; The starting point for online RooFit documentation (Users Manual,; tutorials, slides etc) is now moved to the ROOT website; https://root.cern/topical/#roofit; Error visualization; It is now possible to visualize the effect of the uncertainties on parameters from a fit; on any p.d.f. or function projection. To do so use the new VisualizeError() argument; in a plotOn call. RooFitResult* fr = pdf->fitTo(*data,Save(),...) ;; pdf->plotOn(frame,VisualizeError(*fr),...) ;. Two techniques for error visualization are implemented. The default is; linear error propagation, and results in an error band that is by; construction symmetric. The linear error is calculated as. error(x) = Z* F_a(x) * Corr(a,a') F_a'(x). where F_a(x) = [ f(x,a+da) - f(x,a-da) ] / 2,. with f(x) = the plotted curve; 'da' = error taken from the fit result; Corr(a,a') = the correlation matrix from the fit result; Z = requested significance 'Z sigma band'. The linear method is fast (requires 2*N evaluations of the curve,; where N is the number of parameters), but may not be accurate in the; presence of strong correlations (~>0.9) and at Z>2 due to linear and; Gaussian approximations made. Alternatively, errors can be visualized using a sampling method. In; this method a number of curves is calculated with variations of the; parameter values, as sampled from a multi-variate Gaussian p.d.f. that; is constructed from the fit results covariance matrix. The error(x); is determined by calculating a central interval that capture N% of the; variations for each value of x, where N% is controlled by Z (i.e. Z=1; gives N=68%). The number of sampling curves is chosen to be such that; at least 100 curves are expected to be outside the N% interval. Intervals from; the sampling method can be asymmetric, and may perform better in the; presence of strong correlations, but m",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:822,Availability,error,error,822,". RooFit. This release of ROOT contains RooFit version 3.00. A summary of new features is listed below. RooFit Web documentation moved to ROOT web site; The starting point for online RooFit documentation (Users Manual,; tutorials, slides etc) is now moved to the ROOT website; https://root.cern/topical/#roofit; Error visualization; It is now possible to visualize the effect of the uncertainties on parameters from a fit; on any p.d.f. or function projection. To do so use the new VisualizeError() argument; in a plotOn call. RooFitResult* fr = pdf->fitTo(*data,Save(),...) ;; pdf->plotOn(frame,VisualizeError(*fr),...) ;. Two techniques for error visualization are implemented. The default is; linear error propagation, and results in an error band that is by; construction symmetric. The linear error is calculated as. error(x) = Z* F_a(x) * Corr(a,a') F_a'(x). where F_a(x) = [ f(x,a+da) - f(x,a-da) ] / 2,. with f(x) = the plotted curve; 'da' = error taken from the fit result; Corr(a,a') = the correlation matrix from the fit result; Z = requested significance 'Z sigma band'. The linear method is fast (requires 2*N evaluations of the curve,; where N is the number of parameters), but may not be accurate in the; presence of strong correlations (~>0.9) and at Z>2 due to linear and; Gaussian approximations made. Alternatively, errors can be visualized using a sampling method. In; this method a number of curves is calculated with variations of the; parameter values, as sampled from a multi-variate Gaussian p.d.f. that; is constructed from the fit results covariance matrix. The error(x); is determined by calculating a central interval that capture N% of the; variations for each value of x, where N% is controlled by Z (i.e. Z=1; gives N=68%). The number of sampling curves is chosen to be such that; at least 100 curves are expected to be outside the N% interval. Intervals from; the sampling method can be asymmetric, and may perform better in the; presence of strong correlations, but m",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:950,Availability,error,error,950,". RooFit. This release of ROOT contains RooFit version 3.00. A summary of new features is listed below. RooFit Web documentation moved to ROOT web site; The starting point for online RooFit documentation (Users Manual,; tutorials, slides etc) is now moved to the ROOT website; https://root.cern/topical/#roofit; Error visualization; It is now possible to visualize the effect of the uncertainties on parameters from a fit; on any p.d.f. or function projection. To do so use the new VisualizeError() argument; in a plotOn call. RooFitResult* fr = pdf->fitTo(*data,Save(),...) ;; pdf->plotOn(frame,VisualizeError(*fr),...) ;. Two techniques for error visualization are implemented. The default is; linear error propagation, and results in an error band that is by; construction symmetric. The linear error is calculated as. error(x) = Z* F_a(x) * Corr(a,a') F_a'(x). where F_a(x) = [ f(x,a+da) - f(x,a-da) ] / 2,. with f(x) = the plotted curve; 'da' = error taken from the fit result; Corr(a,a') = the correlation matrix from the fit result; Z = requested significance 'Z sigma band'. The linear method is fast (requires 2*N evaluations of the curve,; where N is the number of parameters), but may not be accurate in the; presence of strong correlations (~>0.9) and at Z>2 due to linear and; Gaussian approximations made. Alternatively, errors can be visualized using a sampling method. In; this method a number of curves is calculated with variations of the; parameter values, as sampled from a multi-variate Gaussian p.d.f. that; is constructed from the fit results covariance matrix. The error(x); is determined by calculating a central interval that capture N% of the; variations for each value of x, where N% is controlled by Z (i.e. Z=1; gives N=68%). The number of sampling curves is chosen to be such that; at least 100 curves are expected to be outside the N% interval. Intervals from; the sampling method can be asymmetric, and may perform better in the; presence of strong correlations, but m",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:1335,Availability,error,errors,1335," to visualize the effect of the uncertainties on parameters from a fit; on any p.d.f. or function projection. To do so use the new VisualizeError() argument; in a plotOn call. RooFitResult* fr = pdf->fitTo(*data,Save(),...) ;; pdf->plotOn(frame,VisualizeError(*fr),...) ;. Two techniques for error visualization are implemented. The default is; linear error propagation, and results in an error band that is by; construction symmetric. The linear error is calculated as. error(x) = Z* F_a(x) * Corr(a,a') F_a'(x). where F_a(x) = [ f(x,a+da) - f(x,a-da) ] / 2,. with f(x) = the plotted curve; 'da' = error taken from the fit result; Corr(a,a') = the correlation matrix from the fit result; Z = requested significance 'Z sigma band'. The linear method is fast (requires 2*N evaluations of the curve,; where N is the number of parameters), but may not be accurate in the; presence of strong correlations (~>0.9) and at Z>2 due to linear and; Gaussian approximations made. Alternatively, errors can be visualized using a sampling method. In; this method a number of curves is calculated with variations of the; parameter values, as sampled from a multi-variate Gaussian p.d.f. that; is constructed from the fit results covariance matrix. The error(x); is determined by calculating a central interval that capture N% of the; variations for each value of x, where N% is controlled by Z (i.e. Z=1; gives N=68%). The number of sampling curves is chosen to be such that; at least 100 curves are expected to be outside the N% interval. Intervals from; the sampling method can be asymmetric, and may perform better in the; presence of strong correlations, but may take (much) longer to; calculate. The sampling method also assumes that the uncertainty on the; parameters can modeled by a multi-variate Gaussian distribution. A complete example is provided in a new tutorial macro rf610_visualerror.C,; the output of which is shown below. It is also possible to visualize partial errors (from a subset of the para",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:1589,Availability,error,error,1589,"ion are implemented. The default is; linear error propagation, and results in an error band that is by; construction symmetric. The linear error is calculated as. error(x) = Z* F_a(x) * Corr(a,a') F_a'(x). where F_a(x) = [ f(x,a+da) - f(x,a-da) ] / 2,. with f(x) = the plotted curve; 'da' = error taken from the fit result; Corr(a,a') = the correlation matrix from the fit result; Z = requested significance 'Z sigma band'. The linear method is fast (requires 2*N evaluations of the curve,; where N is the number of parameters), but may not be accurate in the; presence of strong correlations (~>0.9) and at Z>2 due to linear and; Gaussian approximations made. Alternatively, errors can be visualized using a sampling method. In; this method a number of curves is calculated with variations of the; parameter values, as sampled from a multi-variate Gaussian p.d.f. that; is constructed from the fit results covariance matrix. The error(x); is determined by calculating a central interval that capture N% of the; variations for each value of x, where N% is controlled by Z (i.e. Z=1; gives N=68%). The number of sampling curves is chosen to be such that; at least 100 curves are expected to be outside the N% interval. Intervals from; the sampling method can be asymmetric, and may perform better in the; presence of strong correlations, but may take (much) longer to; calculate. The sampling method also assumes that the uncertainty on the; parameters can modeled by a multi-variate Gaussian distribution. A complete example is provided in a new tutorial macro rf610_visualerror.C,; the output of which is shown below. It is also possible to visualize partial errors (from a subset of the parameters),; as shown above. Binned dataset generation. A new method RooAbsPdf::generateBinned() has been implemented; that samples binned datasets (RooDataHist) from any; p.d.f. RooDataHist* data = pdf.generateBinned(x,10000) ;. This binned generation interface samples the p.d.f. at each bin; center and appl",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:2319,Availability,error,errors,2319,"tively, errors can be visualized using a sampling method. In; this method a number of curves is calculated with variations of the; parameter values, as sampled from a multi-variate Gaussian p.d.f. that; is constructed from the fit results covariance matrix. The error(x); is determined by calculating a central interval that capture N% of the; variations for each value of x, where N% is controlled by Z (i.e. Z=1; gives N=68%). The number of sampling curves is chosen to be such that; at least 100 curves are expected to be outside the N% interval. Intervals from; the sampling method can be asymmetric, and may perform better in the; presence of strong correlations, but may take (much) longer to; calculate. The sampling method also assumes that the uncertainty on the; parameters can modeled by a multi-variate Gaussian distribution. A complete example is provided in a new tutorial macro rf610_visualerror.C,; the output of which is shown below. It is also possible to visualize partial errors (from a subset of the parameters),; as shown above. Binned dataset generation. A new method RooAbsPdf::generateBinned() has been implemented; that samples binned datasets (RooDataHist) from any; p.d.f. RooDataHist* data = pdf.generateBinned(x,10000) ;. This binned generation interface samples the p.d.f. at each bin; center and applies a Poisson fluctuation to each sampled value.; The binning of the returned RooDataHist is controlled by the default; binning associated with the observables generated. To set the number; of bins in x to 200, do e.g. x.setBins(200) prior to the call; to generateBinned(). The binned dataset generation method does not (yet) support the concept of; prototype datasets. New minimizer interface to Minuit2, GSLMinimizer etc... A new minimizer interface, RooMinimizer has been added (contribution; from Alfio Lazarro). The new minimizer is similar in functionality to; the existing class RooMinuit, but supports the new ROOT abstract; minimizer interface and supports mu",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:4507,Availability,error,error,4507,"l to that of RooMinuit; with two extensions. The setMinimizer(const char*) method allows to choose between ""minuit"" and ""minuit2""); as implementation for migrad(),hesse(),minos() etc...; The minimizer(const char* package, const char* alg) provides a completely generic interface; to all minimizers, where package is the package (minuit,GSLminimizer) and alg is the algorithm (migrad) to be used. By default, RooMinuit is still used when RooAbsPdf::fitTo() is called, but can be overridden with; a Minimizer() named argument. // Minimization with MINUIT/MIGRAD through RooMinuit; pdf->fitTo(data) ;. // Minimization with MINUIT/MIGRAD through RooMinimizer; pdf->fitTo(data,Minimizer(""minuit"")) ;. // Minimization with MINUIT2/MIGRAD through RooMinimizer; pdf->fitTo(data,Minimizer(""minuit2"")) ;. // Minimization with GSLMultiMin/conjugatefr through RooMinimizer; pdf->fitTo(data,Minimizer(""GSLMultiMin"",""conjugatefr"")) ;. Note that installation of GSL and the ROOT MathMore package is needed to access the GSL Minimizers and that the GSL; Minimizer do not implement error analysis. New numeric integration algorithms available; RooFit can now interface all MathCore numeric integration; algorithms. In this release ROOT::Math::AdaptiveIntegratorMultiDim,; which implements the 'Genz & Malik' algorithm has been interfaced; in RooAdaptiveIntegratorND and is now the default numeric integrator; for numeric integrations in two or more dimensions. This new default integrator has much improved stability and speed; for relatively smooth p.d.f.s in two or three dimensions and can; generally be used well for p.d.f. normalization integrals without; causing MINUIT converge problems due to numeric precision issues. In future release some more numeric integrators will be migrated to; a MathCore implementation. Interface to TFoam adaptive MC sampler added; RooFit can now use the TFoam adaptive MC sampler for event generation of p.d.f.s that; do not have an internal generator. The TFoam generator adapti",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:4558,Availability,avail,available,4558,"lementation for migrad(),hesse(),minos() etc...; The minimizer(const char* package, const char* alg) provides a completely generic interface; to all minimizers, where package is the package (minuit,GSLminimizer) and alg is the algorithm (migrad) to be used. By default, RooMinuit is still used when RooAbsPdf::fitTo() is called, but can be overridden with; a Minimizer() named argument. // Minimization with MINUIT/MIGRAD through RooMinuit; pdf->fitTo(data) ;. // Minimization with MINUIT/MIGRAD through RooMinimizer; pdf->fitTo(data,Minimizer(""minuit"")) ;. // Minimization with MINUIT2/MIGRAD through RooMinimizer; pdf->fitTo(data,Minimizer(""minuit2"")) ;. // Minimization with GSLMultiMin/conjugatefr through RooMinimizer; pdf->fitTo(data,Minimizer(""GSLMultiMin"",""conjugatefr"")) ;. Note that installation of GSL and the ROOT MathMore package is needed to access the GSL Minimizers and that the GSL; Minimizer do not implement error analysis. New numeric integration algorithms available; RooFit can now interface all MathCore numeric integration; algorithms. In this release ROOT::Math::AdaptiveIntegratorMultiDim,; which implements the 'Genz & Malik' algorithm has been interfaced; in RooAdaptiveIntegratorND and is now the default numeric integrator; for numeric integrations in two or more dimensions. This new default integrator has much improved stability and speed; for relatively smooth p.d.f.s in two or three dimensions and can; generally be used well for p.d.f. normalization integrals without; causing MINUIT converge problems due to numeric precision issues. In future release some more numeric integrators will be migrated to; a MathCore implementation. Interface to TFoam adaptive MC sampler added; RooFit can now use the TFoam adaptive MC sampler for event generation of p.d.f.s that; do not have an internal generator. The TFoam generator adaptively subdivides the; observable space and is generally more efficient both warmup and generation than the original; RooAcceptReject algorit",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:6440,Availability,avail,available,6440,"erator adaptively subdivides the; observable space and is generally more efficient both warmup and generation than the original; RooAcceptReject algorithm. In its current interface in RooFit, TFoam cannot; handle problems yet with discrete observables or conditional observables. For those problems; the original RooAcceptReject generator is still used. The choice of MC sampling algorithm can be steered through class RooNumGenConfig, which; is similar in style and structure, to RooNumIntConfig which configures the choice of; numeric integration algorithm. A new tutorial macro rf902_numgenconfig.C has been added to $ROOTSYS/tutorials/roofit; to illustrate the use of the steering. A macro that demonstrates of the power of these newly interface numeric algorithms is provided at the; end of the RooFit section of the release notes. Optional persistent caching of numeric integrals; For p.d.f.s with numeric integrals that remain difficult or very time consuming,; a new persistent caching technique is now available that allows to precalculate; these integrals and store their values for future use. This technique works transparently; for any p.d.f. stored in a RooWorkspace. One can store numeric integral values for problems with zero, one or two floating parameters.; In the first case, the value is simply stored. In cases with one or two floating parameters; a grid (histogram) of integral values is stored, which are interpolated to return integral; values for each value of the parameters. A new tutorial macro rf903_numintcache.C has been added to $ROOTSYS/tutorials/roofit; to illustrate the use of this feature. Representation of function and p.d.f. derivatives; A new class has been added that can represent the derivative of any p.d.f or function w.r.t. any; parameter or observable. To construct e.g. a first order derivative of a Gaussian p.d.f, do. RooAbsReal* dgdx = gauss.derivative(x,1) ;. A more complete example is available in the new tutorial macro rf111_derivatives.C. Imp",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:7370,Availability,avail,available,7370,"me consuming,; a new persistent caching technique is now available that allows to precalculate; these integrals and store their values for future use. This technique works transparently; for any p.d.f. stored in a RooWorkspace. One can store numeric integral values for problems with zero, one or two floating parameters.; In the first case, the value is simply stored. In cases with one or two floating parameters; a grid (histogram) of integral values is stored, which are interpolated to return integral; values for each value of the parameters. A new tutorial macro rf903_numintcache.C has been added to $ROOTSYS/tutorials/roofit; to illustrate the use of this feature. Representation of function and p.d.f. derivatives; A new class has been added that can represent the derivative of any p.d.f or function w.r.t. any; parameter or observable. To construct e.g. a first order derivative of a Gaussian p.d.f, do. RooAbsReal* dgdx = gauss.derivative(x,1) ;. A more complete example is available in the new tutorial macro rf111_derivatives.C. Improved handling of chi-squared fits; Chi-squared fits can now be performed through the same style of interface as likelihood fits,; through the newly added method RooAbsReal::chi2FitTo(const RooDataHist&,...). Functions that can be fitted with chi-squared minimization are any RooAbsReal based function; as well as RooAbsPdf based p.d.f.s. In case of non-extended p.d.f.s the probability density; calculated by the p.d.f. is multiplied with the number of events in the histogram to adjust; the scale of the function. In case of extended p.d.f.s, the adjustment is made with the expected; number of events, rather than the observed number of events. Tutorial macro rf602_chi2fit.C has been updated to use this new interface. Chi-squared fits to X-Y datasets now possible; In addition to the ability to perform chi-squared fits to histograms it is now also possible; to perform chi-squared fits to unbinned datasets containing a series of X and Y values; w",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:8398,Availability,error,errors,8398,".f, do. RooAbsReal* dgdx = gauss.derivative(x,1) ;. A more complete example is available in the new tutorial macro rf111_derivatives.C. Improved handling of chi-squared fits; Chi-squared fits can now be performed through the same style of interface as likelihood fits,; through the newly added method RooAbsReal::chi2FitTo(const RooDataHist&,...). Functions that can be fitted with chi-squared minimization are any RooAbsReal based function; as well as RooAbsPdf based p.d.f.s. In case of non-extended p.d.f.s the probability density; calculated by the p.d.f. is multiplied with the number of events in the histogram to adjust; the scale of the function. In case of extended p.d.f.s, the adjustment is made with the expected; number of events, rather than the observed number of events. Tutorial macro rf602_chi2fit.C has been updated to use this new interface. Chi-squared fits to X-Y datasets now possible; In addition to the ability to perform chi-squared fits to histograms it is now also possible; to perform chi-squared fits to unbinned datasets containing a series of X and Y values; with associated errors on Y and optionally on X. These 'X-Y' chi-squared fits are interfaced through newly added method; RooAbsReal::chi2FitTo(const RooDataSet&,...). By default the event weight is; interpreted as the 'Y' value, but an YVar() argument can designate any other; dataset column as Y value. If X errors are defined, one can choose to integrate the fitted; function over the range of the X errors, rather than taking the central value by adding; an Integrate(true) argument to chi2FitTo(); Two new arguments, StoreError(const RooArgSet&) and StoreAsymError(const RooArgSet&); have been added to the RooDataSet constructor to simplify the process of storing the errors; of X and Y variables along with their values in a dataset. The newly added tutorial macro rf609_xychi2fit.C illustrates the use of all this; new functionality. Uniform interface for creation of (profile likelihoods) and chi-squa",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:8691,Availability,error,errors,8691,"gram to adjust; the scale of the function. In case of extended p.d.f.s, the adjustment is made with the expected; number of events, rather than the observed number of events. Tutorial macro rf602_chi2fit.C has been updated to use this new interface. Chi-squared fits to X-Y datasets now possible; In addition to the ability to perform chi-squared fits to histograms it is now also possible; to perform chi-squared fits to unbinned datasets containing a series of X and Y values; with associated errors on Y and optionally on X. These 'X-Y' chi-squared fits are interfaced through newly added method; RooAbsReal::chi2FitTo(const RooDataSet&,...). By default the event weight is; interpreted as the 'Y' value, but an YVar() argument can designate any other; dataset column as Y value. If X errors are defined, one can choose to integrate the fitted; function over the range of the X errors, rather than taking the central value by adding; an Integrate(true) argument to chi2FitTo(); Two new arguments, StoreError(const RooArgSet&) and StoreAsymError(const RooArgSet&); have been added to the RooDataSet constructor to simplify the process of storing the errors; of X and Y variables along with their values in a dataset. The newly added tutorial macro rf609_xychi2fit.C illustrates the use of all this; new functionality. Uniform interface for creation of (profile likelihoods) and chi-squared from p.d.f.s; It is now recommended to use the method RooAbsPdf::createNLL(RooAbsData&,...) to; create a likelihood from a p.d.f and a dataset rather than constructing a RooNLLVar; object directly. This is because part of the likelihood construction functionality such a using; multiple Range()s, or the inclusion for constraint terms are only available through; createNLL(). To promote the consistency of this interface, a similar method RooAbsReal::createChi2(); has been added to construct chi-squared functions of a dataset and a function or p.d.f. Along the same lines, it is recommended to use RooAbsRe",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:8784,Availability,error,errors,8784,"gram to adjust; the scale of the function. In case of extended p.d.f.s, the adjustment is made with the expected; number of events, rather than the observed number of events. Tutorial macro rf602_chi2fit.C has been updated to use this new interface. Chi-squared fits to X-Y datasets now possible; In addition to the ability to perform chi-squared fits to histograms it is now also possible; to perform chi-squared fits to unbinned datasets containing a series of X and Y values; with associated errors on Y and optionally on X. These 'X-Y' chi-squared fits are interfaced through newly added method; RooAbsReal::chi2FitTo(const RooDataSet&,...). By default the event weight is; interpreted as the 'Y' value, but an YVar() argument can designate any other; dataset column as Y value. If X errors are defined, one can choose to integrate the fitted; function over the range of the X errors, rather than taking the central value by adding; an Integrate(true) argument to chi2FitTo(); Two new arguments, StoreError(const RooArgSet&) and StoreAsymError(const RooArgSet&); have been added to the RooDataSet constructor to simplify the process of storing the errors; of X and Y variables along with their values in a dataset. The newly added tutorial macro rf609_xychi2fit.C illustrates the use of all this; new functionality. Uniform interface for creation of (profile likelihoods) and chi-squared from p.d.f.s; It is now recommended to use the method RooAbsPdf::createNLL(RooAbsData&,...) to; create a likelihood from a p.d.f and a dataset rather than constructing a RooNLLVar; object directly. This is because part of the likelihood construction functionality such a using; multiple Range()s, or the inclusion for constraint terms are only available through; createNLL(). To promote the consistency of this interface, a similar method RooAbsReal::createChi2(); has been added to construct chi-squared functions of a dataset and a function or p.d.f. Along the same lines, it is recommended to use RooAbsRe",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:9055,Availability,error,errors,9055,"gram to adjust; the scale of the function. In case of extended p.d.f.s, the adjustment is made with the expected; number of events, rather than the observed number of events. Tutorial macro rf602_chi2fit.C has been updated to use this new interface. Chi-squared fits to X-Y datasets now possible; In addition to the ability to perform chi-squared fits to histograms it is now also possible; to perform chi-squared fits to unbinned datasets containing a series of X and Y values; with associated errors on Y and optionally on X. These 'X-Y' chi-squared fits are interfaced through newly added method; RooAbsReal::chi2FitTo(const RooDataSet&,...). By default the event weight is; interpreted as the 'Y' value, but an YVar() argument can designate any other; dataset column as Y value. If X errors are defined, one can choose to integrate the fitted; function over the range of the X errors, rather than taking the central value by adding; an Integrate(true) argument to chi2FitTo(); Two new arguments, StoreError(const RooArgSet&) and StoreAsymError(const RooArgSet&); have been added to the RooDataSet constructor to simplify the process of storing the errors; of X and Y variables along with their values in a dataset. The newly added tutorial macro rf609_xychi2fit.C illustrates the use of all this; new functionality. Uniform interface for creation of (profile likelihoods) and chi-squared from p.d.f.s; It is now recommended to use the method RooAbsPdf::createNLL(RooAbsData&,...) to; create a likelihood from a p.d.f and a dataset rather than constructing a RooNLLVar; object directly. This is because part of the likelihood construction functionality such a using; multiple Range()s, or the inclusion for constraint terms are only available through; createNLL(). To promote the consistency of this interface, a similar method RooAbsReal::createChi2(); has been added to construct chi-squared functions of a dataset and a function or p.d.f. Along the same lines, it is recommended to use RooAbsRe",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:9639,Availability,avail,available,9639,"interpreted as the 'Y' value, but an YVar() argument can designate any other; dataset column as Y value. If X errors are defined, one can choose to integrate the fitted; function over the range of the X errors, rather than taking the central value by adding; an Integrate(true) argument to chi2FitTo(); Two new arguments, StoreError(const RooArgSet&) and StoreAsymError(const RooArgSet&); have been added to the RooDataSet constructor to simplify the process of storing the errors; of X and Y variables along with their values in a dataset. The newly added tutorial macro rf609_xychi2fit.C illustrates the use of all this; new functionality. Uniform interface for creation of (profile likelihoods) and chi-squared from p.d.f.s; It is now recommended to use the method RooAbsPdf::createNLL(RooAbsData&,...) to; create a likelihood from a p.d.f and a dataset rather than constructing a RooNLLVar; object directly. This is because part of the likelihood construction functionality such a using; multiple Range()s, or the inclusion for constraint terms are only available through; createNLL(). To promote the consistency of this interface, a similar method RooAbsReal::createChi2(); has been added to construct chi-squared functions of a dataset and a function or p.d.f. Along the same lines, it is recommended to use RooAbsReal::createProfile() rather; than constructing a RooProfileLL object directly as the former will efficiently; recast a profile of a profile into a single profile object. Multivariate Gaussian modeling of parameters estimates from a fit; You can now construct a multivariate Gaussian p.d.f on the parameters of a model that; represents the result of a fit, from any RooFitResult object. RooAbsPdf* paramPdf = fitresult->createHessePdf(RooArgSet(a,b)) ;. The returned object is an instance of the newly added class RooMultiVarGaussian, that can; model correlated Gaussian distributions in an arbitrary number of dimensions, given a; vector of mean values and a covariance matrix. C",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:12396,Availability,error,errors,12396,"ower bound of the convolution observable (the previous default); Mirror the p.d.f. over the boundary. The new default algorithm provides a more sensible result for p.d.f.s with significant; spillover issues, provided that the p.d.f. can be continuated beyond its original domain.; Convolution in non-observables is also explicitly supported now. One can e.g. construct a p.d.f; of the form G(x) = Int[dy] ( F(x,y) (*) H(y) ). A new tutorial macro rf211_paramconv illustrates; how such convolutions can be constructed; It is now also possible to express FFT convolutions in terms of other observables than the; convolution observable itself. A common occurrence of that situation is a (circular) convolution a polar; angle theta, for a p.d.f. that is ultimately expressed in terms of cos(theta).; A new tutorial macro rf210_angularconv illustrates how to convolutions of angular observable; with or without an optional cosine transformation for the final observable. Option for improved calculation of errors in weighted likelihood fits. A new option SumW2Error() has been added to RooAbsPdf::fitTo() that will; perform an improved error calculation for weighted unbinned likelihood fits. In their unmodified; form, an ML fit to a weighted dataset will correctly estimate the parameters, but the errors will; scale with the sum of the weights, rather than the number of the events in the dataset (i.e.; if you double all event weights, all parameter errors will go down with sqrt(2)). In chi-squared; fits event weights can processed correctly by using both the sum of the weights and the; sum of the weights-squared for each bin. The newly added option SumW2Error() implements a similar; strategy for (unbinned) weighted ML fits by applying a correction to the covariance matrix; as follows. V' = V C-1 V. where V is the covariance matrix from the fit to weighted data, and C-1 is the inverse of the; covariance matrix calculated from a similar likelihood that constructed with the event weights appli",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:12526,Availability,error,error,12526,"efault algorithm provides a more sensible result for p.d.f.s with significant; spillover issues, provided that the p.d.f. can be continuated beyond its original domain.; Convolution in non-observables is also explicitly supported now. One can e.g. construct a p.d.f; of the form G(x) = Int[dy] ( F(x,y) (*) H(y) ). A new tutorial macro rf211_paramconv illustrates; how such convolutions can be constructed; It is now also possible to express FFT convolutions in terms of other observables than the; convolution observable itself. A common occurrence of that situation is a (circular) convolution a polar; angle theta, for a p.d.f. that is ultimately expressed in terms of cos(theta).; A new tutorial macro rf210_angularconv illustrates how to convolutions of angular observable; with or without an optional cosine transformation for the final observable. Option for improved calculation of errors in weighted likelihood fits. A new option SumW2Error() has been added to RooAbsPdf::fitTo() that will; perform an improved error calculation for weighted unbinned likelihood fits. In their unmodified; form, an ML fit to a weighted dataset will correctly estimate the parameters, but the errors will; scale with the sum of the weights, rather than the number of the events in the dataset (i.e.; if you double all event weights, all parameter errors will go down with sqrt(2)). In chi-squared; fits event weights can processed correctly by using both the sum of the weights and the; sum of the weights-squared for each bin. The newly added option SumW2Error() implements a similar; strategy for (unbinned) weighted ML fits by applying a correction to the covariance matrix; as follows. V' = V C-1 V. where V is the covariance matrix from the fit to weighted data, and C-1 is the inverse of the; covariance matrix calculated from a similar likelihood that constructed with the event weights applied squared. Redesign of RooFit dataset class structure. The original class structure of RooFit featured an abst",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:12690,Availability,error,errors,12690," in non-observables is also explicitly supported now. One can e.g. construct a p.d.f; of the form G(x) = Int[dy] ( F(x,y) (*) H(y) ). A new tutorial macro rf211_paramconv illustrates; how such convolutions can be constructed; It is now also possible to express FFT convolutions in terms of other observables than the; convolution observable itself. A common occurrence of that situation is a (circular) convolution a polar; angle theta, for a p.d.f. that is ultimately expressed in terms of cos(theta).; A new tutorial macro rf210_angularconv illustrates how to convolutions of angular observable; with or without an optional cosine transformation for the final observable. Option for improved calculation of errors in weighted likelihood fits. A new option SumW2Error() has been added to RooAbsPdf::fitTo() that will; perform an improved error calculation for weighted unbinned likelihood fits. In their unmodified; form, an ML fit to a weighted dataset will correctly estimate the parameters, but the errors will; scale with the sum of the weights, rather than the number of the events in the dataset (i.e.; if you double all event weights, all parameter errors will go down with sqrt(2)). In chi-squared; fits event weights can processed correctly by using both the sum of the weights and the; sum of the weights-squared for each bin. The newly added option SumW2Error() implements a similar; strategy for (unbinned) weighted ML fits by applying a correction to the covariance matrix; as follows. V' = V C-1 V. where V is the covariance matrix from the fit to weighted data, and C-1 is the inverse of the; covariance matrix calculated from a similar likelihood that constructed with the event weights applied squared. Redesign of RooFit dataset class structure. The original class structure of RooFit featured an abstract dataset; class RooAbsData. Inheriting from that was a single class; RooTreeData, which implemented datasets with a ROOT; TTree-based storage implementation, and inheriting from",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:12844,Availability,error,errors,12844,"macro rf211_paramconv illustrates; how such convolutions can be constructed; It is now also possible to express FFT convolutions in terms of other observables than the; convolution observable itself. A common occurrence of that situation is a (circular) convolution a polar; angle theta, for a p.d.f. that is ultimately expressed in terms of cos(theta).; A new tutorial macro rf210_angularconv illustrates how to convolutions of angular observable; with or without an optional cosine transformation for the final observable. Option for improved calculation of errors in weighted likelihood fits. A new option SumW2Error() has been added to RooAbsPdf::fitTo() that will; perform an improved error calculation for weighted unbinned likelihood fits. In their unmodified; form, an ML fit to a weighted dataset will correctly estimate the parameters, but the errors will; scale with the sum of the weights, rather than the number of the events in the dataset (i.e.; if you double all event weights, all parameter errors will go down with sqrt(2)). In chi-squared; fits event weights can processed correctly by using both the sum of the weights and the; sum of the weights-squared for each bin. The newly added option SumW2Error() implements a similar; strategy for (unbinned) weighted ML fits by applying a correction to the covariance matrix; as follows. V' = V C-1 V. where V is the covariance matrix from the fit to weighted data, and C-1 is the inverse of the; covariance matrix calculated from a similar likelihood that constructed with the event weights applied squared. Redesign of RooFit dataset class structure. The original class structure of RooFit featured an abstract dataset; class RooAbsData. Inheriting from that was a single class; RooTreeData, which implemented datasets with a ROOT; TTree-based storage implementation, and inheriting from that; two classes RooDataSet , representing unbinned data, and; RooDataHist, representing binned data. A main problem with; this structure was that ",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:12859,Availability,down,down,12859,"macro rf211_paramconv illustrates; how such convolutions can be constructed; It is now also possible to express FFT convolutions in terms of other observables than the; convolution observable itself. A common occurrence of that situation is a (circular) convolution a polar; angle theta, for a p.d.f. that is ultimately expressed in terms of cos(theta).; A new tutorial macro rf210_angularconv illustrates how to convolutions of angular observable; with or without an optional cosine transformation for the final observable. Option for improved calculation of errors in weighted likelihood fits. A new option SumW2Error() has been added to RooAbsPdf::fitTo() that will; perform an improved error calculation for weighted unbinned likelihood fits. In their unmodified; form, an ML fit to a weighted dataset will correctly estimate the parameters, but the errors will; scale with the sum of the weights, rather than the number of the events in the dataset (i.e.; if you double all event weights, all parameter errors will go down with sqrt(2)). In chi-squared; fits event weights can processed correctly by using both the sum of the weights and the; sum of the weights-squared for each bin. The newly added option SumW2Error() implements a similar; strategy for (unbinned) weighted ML fits by applying a correction to the covariance matrix; as follows. V' = V C-1 V. where V is the covariance matrix from the fit to weighted data, and C-1 is the inverse of the; covariance matrix calculated from a similar likelihood that constructed with the event weights applied squared. Redesign of RooFit dataset class structure. The original class structure of RooFit featured an abstract dataset; class RooAbsData. Inheriting from that was a single class; RooTreeData, which implemented datasets with a ROOT; TTree-based storage implementation, and inheriting from that; two classes RooDataSet , representing unbinned data, and; RooDataHist, representing binned data. A main problem with; this structure was that ",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:17036,Availability,avail,available,17036,"r and larger improvements has been made to the RooWorkspace class. Direct interactive access to contents from CINT -; One can now directly access the contents of any RooWorkspace; on the ROOT commandline through CINT if the RooWorkspace::exportToCint() call is made.; In CINT, all workspace objects will appear as correctly typed references to workspace objects in; a C++ namespace with the same name as the RooWorkspace object. Given e.g. a workspace w, with a Gaussian p.d.f gauss in terms of variables; x,m,s one can now do. RooWorkspace w(""w"",true) ; // workspace with CINT interface activated; // ... fill workspace with RooGaussian gauss(x,m,s) ...; RooPlot* frame = w::x.frame() ;; w::gauss.plotOn(frame) ;. to access the workspace contents. Each reference has the correct type, e.g. w::gauss is; a RooGaussian&. If a workspace is deleted from memory, the corresponding CINT namespace; is removed as well. Note that this feature is strictly available in interpreted C++ only; A new tutorial macro has been added to illustrate this functionality in more detail: rf509_wsinteractive.C.; writeToFile -- A new utility method RooWorkspace::writeToFile() has been added; to simplify the process of saving a workspace to file; Named sets and parameter snapshots -- It is now possible to define and retrieve; named RooArgSets of objects that live in the workspace through methods; defineSet() and set(). While named sets merely group objects logically, methods loadSnapshot and; saveSnapshot allow to make copies of the values, errors and 'constant' status of; sets of variable objects that live in the workspace. A newly added tutorial macro rf510_namedsets.C illustrates the functionality of both; of these features.; Improved printing of contents -- Many operator p.d.f. and function components now show; a more intuitive natural representation of their contents (these changes are mostly in the; respective p.d.f.s, but are most relevant in the context of a workspace). New object factory interfac",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:17615,Availability,error,errors,17615,",m,s one can now do. RooWorkspace w(""w"",true) ; // workspace with CINT interface activated; // ... fill workspace with RooGaussian gauss(x,m,s) ...; RooPlot* frame = w::x.frame() ;; w::gauss.plotOn(frame) ;. to access the workspace contents. Each reference has the correct type, e.g. w::gauss is; a RooGaussian&. If a workspace is deleted from memory, the corresponding CINT namespace; is removed as well. Note that this feature is strictly available in interpreted C++ only; A new tutorial macro has been added to illustrate this functionality in more detail: rf509_wsinteractive.C.; writeToFile -- A new utility method RooWorkspace::writeToFile() has been added; to simplify the process of saving a workspace to file; Named sets and parameter snapshots -- It is now possible to define and retrieve; named RooArgSets of objects that live in the workspace through methods; defineSet() and set(). While named sets merely group objects logically, methods loadSnapshot and; saveSnapshot allow to make copies of the values, errors and 'constant' status of; sets of variable objects that live in the workspace. A newly added tutorial macro rf510_namedsets.C illustrates the functionality of both; of these features.; Improved printing of contents -- Many operator p.d.f. and function components now show; a more intuitive natural representation of their contents (these changes are mostly in the; respective p.d.f.s, but are most relevant in the context of a workspace). New object factory interface to workspace to facilitate script driven model definition; A object factory has been added to RooFit to simplify the process of creating p.d.f.; and function expressions consisting of multiple objects. The factory has two goals:; the first is to provide a back-end for higher level factories and tools to process; the creation of objects. The second is to provide a simple end-user language to; populate a RooWorkspace with function and p.d.f. objects. For the latter purpose the object creation language ",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:21039,Availability,error,error,21039,"]' and a constant width of 3. ""SUM::model( f[0.5,0,1] * Gaussian( x[-10,10], m[0], 3] ),; Chebychev( x, {a0[0.1],a1[0.2],a2[-0.3]}))"". Create a RooAddPdf model of a RooGaussian and a RooChebychev (which; are implicitly named model_0 and model_1), its observable x and its; parameters m,a0,a1,a2,Nsig and Nbkg; Note that each object may be created only once (with [] or () brackets) but may be referenced multiple; times in the expression by just giving the name. Here is a much more complicated example:. ""PROD::sig(BMixDecay::sig_t( dt[-20,20], mixState[mixed=1,unmix=-1], tagFlav[B0=1,B0bar=-1],; tau[1.54], dm[0.472], w[0.05], dw[0],; AddModel({GaussModel(dt,biasC[-10,10],sigmaC[0.1,3],dterr[0.01,0.2]),; GaussModel(dt,0,sigmaT[3,10]),; GaussModel(dt,0,20)},{fracC[0,1],fracT[0,1]}),; DoubleSided ),; Gaussian::sig_m( mes[5.20,5.30], mB0[5.20,5.30], sigmB0[0.01,0.05] )"". This create a double-sided Bmixing decay p.d.f. with observables dt,; per-event error dterr and all its parameters, convoluted with a triple; gaussian resolution model and multiplied with a Gaussian p.d.f. in the; energy substituted mass. (In plain RooFit this would have required at; least 23 lines of code). A series of three new tutorial macros has been added to illustrate the; various features of the object factory. rf511_wsfactory_basic.C - Basic factory concepts; rf512_wsfactory_oper.C - Using operator p.d.f.s in the factory; rf513_wsfactory_tools.C - Advanced example using interfaced high level tools. A formal transaction model is used to commit composite objects into; the workspace. If an error is detected in the expression, no objects; will be committed to the workspace, thus leaving no 'partial builds'. Compact demo of several new major features. The macro below demonstrates in a couple of lines a number of major new features in RooFit 3.00: Use of. workspace factory to quickly create and store (compiled) models; workspace CINT interface to easily access contents in a typesafe way; new adaptive ND n",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:21663,Availability,error,error,21663,",; AddModel({GaussModel(dt,biasC[-10,10],sigmaC[0.1,3],dterr[0.01,0.2]),; GaussModel(dt,0,sigmaT[3,10]),; GaussModel(dt,0,20)},{fracC[0,1],fracT[0,1]}),; DoubleSided ),; Gaussian::sig_m( mes[5.20,5.30], mB0[5.20,5.30], sigmB0[0.01,0.05] )"". This create a double-sided Bmixing decay p.d.f. with observables dt,; per-event error dterr and all its parameters, convoluted with a triple; gaussian resolution model and multiplied with a Gaussian p.d.f. in the; energy substituted mass. (In plain RooFit this would have required at; least 23 lines of code). A series of three new tutorial macros has been added to illustrate the; various features of the object factory. rf511_wsfactory_basic.C - Basic factory concepts; rf512_wsfactory_oper.C - Using operator p.d.f.s in the factory; rf513_wsfactory_tools.C - Advanced example using interfaced high level tools. A formal transaction model is used to commit composite objects into; the workspace. If an error is detected in the expression, no objects; will be committed to the workspace, thus leaving no 'partial builds'. Compact demo of several new major features. The macro below demonstrates in a couple of lines a number of major new features in RooFit 3.00: Use of. workspace factory to quickly create and store (compiled) models; workspace CINT interface to easily access contents in a typesafe way; new adaptive ND numeric integration technique to normalize arbitrary p.d.f. in fast; and reliable way; new adaptive TFoam sampling technique to efficiently generate toy MC data from strongly; peaked datasets; parallel processing in likelihood construction and use of profile likelihood operator; to represent profile likelihoods as regular RooFit functions. void demo(); {; // Construct compiled 2-D model that requires numeric integration for normalization; RooWorkspace w(""w"",1) ;; w.factory(""CEXPR::model('1/((x-a)*(x-a)+0.001)+1/((y-b)*(y-b)+0.001)',x[-1,1],y[-1,1],a[-5,5],b[-5,5])"") ;. // Generate data from model (using TFoam adaptive sampling al",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:22155,Availability,reliab,reliable,22155,"hree new tutorial macros has been added to illustrate the; various features of the object factory. rf511_wsfactory_basic.C - Basic factory concepts; rf512_wsfactory_oper.C - Using operator p.d.f.s in the factory; rf513_wsfactory_tools.C - Advanced example using interfaced high level tools. A formal transaction model is used to commit composite objects into; the workspace. If an error is detected in the expression, no objects; will be committed to the workspace, thus leaving no 'partial builds'. Compact demo of several new major features. The macro below demonstrates in a couple of lines a number of major new features in RooFit 3.00: Use of. workspace factory to quickly create and store (compiled) models; workspace CINT interface to easily access contents in a typesafe way; new adaptive ND numeric integration technique to normalize arbitrary p.d.f. in fast; and reliable way; new adaptive TFoam sampling technique to efficiently generate toy MC data from strongly; peaked datasets; parallel processing in likelihood construction and use of profile likelihood operator; to represent profile likelihoods as regular RooFit functions. void demo(); {; // Construct compiled 2-D model that requires numeric integration for normalization; RooWorkspace w(""w"",1) ;; w.factory(""CEXPR::model('1/((x-a)*(x-a)+0.001)+1/((y-b)*(y-b)+0.001)',x[-1,1],y[-1,1],a[-5,5],b[-5,5])"") ;. // Generate data from model (using TFoam adaptive sampling algorithm); RooDataSet* d = w::model.generate(RooArgSet(w::x,w::y),1000) ;; w::model.fitTo(*d) ;. // Make 2D plot on (x,y); TH2* hh = w::model.createHistogram(""x,y"",40,40) ;; hh->SetLineColor(kBlue) ;. // Make Projection on x (integrate over y); RooPlot* framex = w::x.frame(Title(""Data and p.d.f. projected on X"")) ;; d->plotOn(framex) ;; w::model.plotOn(framex) ;. // Construct likelihood, profile likelihood in a, and draw the latter; RooAbsReal* nll = w::model.createNLL(*d,NumCPU(2)) ;; RooAbsReal* pll = nll->createProfile(w::a) ;; RooPlot* framea = w::a.fram",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:26201,Availability,avail,available,26201,"; rs301_splot.C Demonstrates use of RooStats sPlot; implementation; rs401c_FeldmanCousins.C Demonstrates use of; FeldmanCousins interval calculator with a Poisson problem, reproduces; results from table IV and V of the original; paper�Phys.Rev.D57:3873-3889,1998.; rs401d_FeldmanCousins.C Demonstrates use of; FeldmanCousins interval calculator with the neutrino oscillation toy; example described in the original paper�Phys.Rev.D57:3873-3889,1998.; Reproduces figure 12.; rs_bernsteinCorrection.C Demonstrates use of; BernsteinCorrection class, which corrects a nominal PDF with a polynomial; to agree with observed or simulated data. TestStatistic interface and implementations; We added a new interface class called TestStatistic. It defines the; method Evaluate(data, parameterPoint), which returns a double. �This; class can be used in�conjunction�with the ToyMCSampler class to generate; sampling distributions for a user-defined test statistic. �; The following concrete implementations of the TestStatistic interface; are currently available. ProfileLikelihoodTestStatReturns the log of profile; likelihood ratio. �Generally a powerful test statistic. ; NumEventsTestStatReturns the number of events in the; dataset. �Useful for number counting experiments.; DebuggingTestStat Simply returns a uniform random number; between 0,1. �Useful for debugging. SamplingDistribution and the�TestStatSampler interface and; implementations; We introduced a ``result'' or data model class called; SamplingDistribution, which holds the sampling distribution of an; arbitrary real valued test statistic. �The class also can return the; inverse of the cumulative distribution function (with or without; interpolation). �; We introduced an interface for any tool that can produce a; SamplingDistribution, called TestStatSampler. �The interface is; essentially GetSamplingDistribution(parameterPoint) which returns a; SamplingDistribution based on a given probability density function. �We; foresee a few versi",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:27339,Availability,avail,available,27339,"rful test statistic. ; NumEventsTestStatReturns the number of events in the; dataset. �Useful for number counting experiments.; DebuggingTestStat Simply returns a uniform random number; between 0,1. �Useful for debugging. SamplingDistribution and the�TestStatSampler interface and; implementations; We introduced a ``result'' or data model class called; SamplingDistribution, which holds the sampling distribution of an; arbitrary real valued test statistic. �The class also can return the; inverse of the cumulative distribution function (with or without; interpolation). �; We introduced an interface for any tool that can produce a; SamplingDistribution, called TestStatSampler. �The interface is; essentially GetSamplingDistribution(parameterPoint) which returns a; SamplingDistribution based on a given probability density function. �We; foresee a few versions of this tool based on toy Monte Carlo, importance; sampling, Fourier transforms, etc. �The following concrete implementation; of the TestStatSampler interface are currently available. ToyMCSamplerUses a Toy Monte Carlo approach to build the; sampling distribution. �The pdf's generate method to generate is used to; generate toy data, and then the test statistic is evaluated at the; requested parameter point. ; DebuggingSampler Simply returns a uniform distribution; between 0,1. �Useful for debugging. NeymanConstruction and FeldmanCousins; A flexible framework for the Neyman Construction was added in this; release. The NeymanConstruction is a concrete implementation of the; IntervalCalculator interface, but it needs several; additional components�to be specified before use. The design; factorizes the choice of the parameter points to be tested,�the choice of; the test statistic, and the generation of sampling distribution into; separate parts (described above). �Finally, the NeymanConstruction class; is simply in charge of using these parts (strategies) and constructing; the confidence belt and confidence intervals. �T",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:30521,Availability,avail,available,30521,"Chain Monte Carlo was added in this; release. The MCMCCalculator is a concrete implementation of the; IntervalCalculator interface. To use it one needs to specify the ProposalFunction.; There is a base class for ProposalFunctions and one concrete implementation: UniformProposal.; Support for other proposal functions will be added in the next release.; The MCMCCalculator scans the space of the parameters of interest and nuisance parameters and; produces a Bayesian posterior. In this version, the prior must be added to the model initially,; otherwise a flat prior is assumed. The MCMCCalculator returns an MCMCInterval, which produces; the smallest interval by taking a contour of the posterior. This first version only supports; 1,2, and 3 dimensional intervals, but will be generalized in the next release. In addition to the MCMC implementation in RooStats, one can export their model and dataset into a workspace,; and then use the Bayesian Analysis Toolkit (BAT) for the MCMC. There is a wrapper available. Redesigned SPlot class; The RooStats SPlot implementation works with any RooAbsPdf. The class has been redesigned for more; convenient use. It also adds some helper functions to check that the sum of sWeights over species is 1 for each event and; the sum over events for a given species equals the yield for that species. Plotting classes; We have added new plotting classes: SamplingDistPlot and LikelihoodIntervalPlot.; In 1-d LikelihoodIntervalPlot shows the profile likelihood ratio and the upper/lower limits; of the interval for the parameter of interest. In 2-d, the LikelihoodIntervalPlot shows; the contour of the profile likelihood ratio for the parameters of interest. Bernstein Correction. BernsteinCorrection is a utility in RooStats to augment a nominal PDF; with a polynomial�; correction term. �This is useful for incorporating systematic variations; to the nominal PDF. �; The Bernstein basis polynomails are particularly appropriate because they; are positive defini",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:32805,Availability,error,error,32805,"ratio for the parameters of interest. Bernstein Correction. BernsteinCorrection is a utility in RooStats to augment a nominal PDF; with a polynomial�; correction term. �This is useful for incorporating systematic variations; to the nominal PDF. �; The Bernstein basis polynomails are particularly appropriate because they; are positive definite.�. This tool was inspired by the work of Glen Cowan together with Stephan; Horner, Sascha Caron,�; Eilam Gross, and others. �; The initial implementation is independent work. �The major step forward; in the approach was�; to provide a well defined algorithm that specifies the order of; polynomial to be included�; in the correction. �This is an empirical algorithm, so in addition to the; nominal model it�; needs either a real data set or a simulated one. �In the early work, the; nominal model was taken; to be a histogram from Monte Carlo simulations, but in this; implementation it is generalized to an; arbitrary PDF (which includes a RooHistPdf). �The algorithm basically; consists of a�; hypothesis test of an nth-order correction (null) against a n+1-th order; correction (alternate).�; The quantity q = -2 log LR is used to determine whether the n+1-th order; correction is a major�; improvement to the n-th order correction. �The distribution of q is; expected to be roughly�; \chi^2 with one degree of freedom if the n-th order correction is a good; model for the data.�; �Thus, one only moves to the n+1-th order correction of q is relatively; large. �The chance that�; one moves from the n-th to the n+1-th order correction when the n-th; order correction�; (eg. a type 1 error) is sufficient is given by the Prob(\chi^2_1 >; threshold). �The constructor�; of this class allows you to directly set this tolerance (in terms of; probability that the n+1-th; �term is added unnecessarily). HybridCalculator; Add as a new test statistics the profile likelihood ratio. Will be redesigned to use TestStatSampler and TestStatistic in next release. ",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:32936,Availability,toler,tolerance,32936,"ratio for the parameters of interest. Bernstein Correction. BernsteinCorrection is a utility in RooStats to augment a nominal PDF; with a polynomial�; correction term. �This is useful for incorporating systematic variations; to the nominal PDF. �; The Bernstein basis polynomails are particularly appropriate because they; are positive definite.�. This tool was inspired by the work of Glen Cowan together with Stephan; Horner, Sascha Caron,�; Eilam Gross, and others. �; The initial implementation is independent work. �The major step forward; in the approach was�; to provide a well defined algorithm that specifies the order of; polynomial to be included�; in the correction. �This is an empirical algorithm, so in addition to the; nominal model it�; needs either a real data set or a simulated one. �In the early work, the; nominal model was taken; to be a histogram from Monte Carlo simulations, but in this; implementation it is generalized to an; arbitrary PDF (which includes a RooHistPdf). �The algorithm basically; consists of a�; hypothesis test of an nth-order correction (null) against a n+1-th order; correction (alternate).�; The quantity q = -2 log LR is used to determine whether the n+1-th order; correction is a major�; improvement to the n-th order correction. �The distribution of q is; expected to be roughly�; \chi^2 with one degree of freedom if the n-th order correction is a good; model for the data.�; �Thus, one only moves to the n+1-th order correction of q is relatively; large. �The chance that�; one moves from the n-th to the n+1-th order correction when the n-th; order correction�; (eg. a type 1 error) is sufficient is given by the Prob(\chi^2_1 >; threshold). �The constructor�; of this class allows you to directly set this tolerance (in terms of; probability that the n+1-th; �term is added unnecessarily). HybridCalculator; Add as a new test statistics the profile likelihood ratio. Will be redesigned to use TestStatSampler and TestStatistic in next release. ",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:15,Deployability,release,release,15,". RooFit. This release of ROOT contains RooFit version 3.00. A summary of new features is listed below. RooFit Web documentation moved to ROOT web site; The starting point for online RooFit documentation (Users Manual,; tutorials, slides etc) is now moved to the ROOT website; https://root.cern/topical/#roofit; Error visualization; It is now possible to visualize the effect of the uncertainties on parameters from a fit; on any p.d.f. or function projection. To do so use the new VisualizeError() argument; in a plotOn call. RooFitResult* fr = pdf->fitTo(*data,Save(),...) ;; pdf->plotOn(frame,VisualizeError(*fr),...) ;. Two techniques for error visualization are implemented. The default is; linear error propagation, and results in an error band that is by; construction symmetric. The linear error is calculated as. error(x) = Z* F_a(x) * Corr(a,a') F_a'(x). where F_a(x) = [ f(x,a+da) - f(x,a-da) ] / 2,. with f(x) = the plotted curve; 'da' = error taken from the fit result; Corr(a,a') = the correlation matrix from the fit result; Z = requested significance 'Z sigma band'. The linear method is fast (requires 2*N evaluations of the curve,; where N is the number of parameters), but may not be accurate in the; presence of strong correlations (~>0.9) and at Z>2 due to linear and; Gaussian approximations made. Alternatively, errors can be visualized using a sampling method. In; this method a number of curves is calculated with variations of the; parameter values, as sampled from a multi-variate Gaussian p.d.f. that; is constructed from the fit results covariance matrix. The error(x); is determined by calculating a central interval that capture N% of the; variations for each value of x, where N% is controlled by Z (i.e. Z=1; gives N=68%). The number of sampling curves is chosen to be such that; at least 100 curves are expected to be outside the N% interval. Intervals from; the sampling method can be asymmetric, and may perform better in the; presence of strong correlations, but m",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:4373,Deployability,install,installation,4373,"l to that of RooMinuit; with two extensions. The setMinimizer(const char*) method allows to choose between ""minuit"" and ""minuit2""); as implementation for migrad(),hesse(),minos() etc...; The minimizer(const char* package, const char* alg) provides a completely generic interface; to all minimizers, where package is the package (minuit,GSLminimizer) and alg is the algorithm (migrad) to be used. By default, RooMinuit is still used when RooAbsPdf::fitTo() is called, but can be overridden with; a Minimizer() named argument. // Minimization with MINUIT/MIGRAD through RooMinuit; pdf->fitTo(data) ;. // Minimization with MINUIT/MIGRAD through RooMinimizer; pdf->fitTo(data,Minimizer(""minuit"")) ;. // Minimization with MINUIT2/MIGRAD through RooMinimizer; pdf->fitTo(data,Minimizer(""minuit2"")) ;. // Minimization with GSLMultiMin/conjugatefr through RooMinimizer; pdf->fitTo(data,Minimizer(""GSLMultiMin"",""conjugatefr"")) ;. Note that installation of GSL and the ROOT MathMore package is needed to access the GSL Minimizers and that the GSL; Minimizer do not implement error analysis. New numeric integration algorithms available; RooFit can now interface all MathCore numeric integration; algorithms. In this release ROOT::Math::AdaptiveIntegratorMultiDim,; which implements the 'Genz & Malik' algorithm has been interfaced; in RooAdaptiveIntegratorND and is now the default numeric integrator; for numeric integrations in two or more dimensions. This new default integrator has much improved stability and speed; for relatively smooth p.d.f.s in two or three dimensions and can; generally be used well for p.d.f. normalization integrals without; causing MINUIT converge problems due to numeric precision issues. In future release some more numeric integrators will be migrated to; a MathCore implementation. Interface to TFoam adaptive MC sampler added; RooFit can now use the TFoam adaptive MC sampler for event generation of p.d.f.s that; do not have an internal generator. The TFoam generator adapti",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:4535,Deployability,integrat,integration,4535,"lementation for migrad(),hesse(),minos() etc...; The minimizer(const char* package, const char* alg) provides a completely generic interface; to all minimizers, where package is the package (minuit,GSLminimizer) and alg is the algorithm (migrad) to be used. By default, RooMinuit is still used when RooAbsPdf::fitTo() is called, but can be overridden with; a Minimizer() named argument. // Minimization with MINUIT/MIGRAD through RooMinuit; pdf->fitTo(data) ;. // Minimization with MINUIT/MIGRAD through RooMinimizer; pdf->fitTo(data,Minimizer(""minuit"")) ;. // Minimization with MINUIT2/MIGRAD through RooMinimizer; pdf->fitTo(data,Minimizer(""minuit2"")) ;. // Minimization with GSLMultiMin/conjugatefr through RooMinimizer; pdf->fitTo(data,Minimizer(""GSLMultiMin"",""conjugatefr"")) ;. Note that installation of GSL and the ROOT MathMore package is needed to access the GSL Minimizers and that the GSL; Minimizer do not implement error analysis. New numeric integration algorithms available; RooFit can now interface all MathCore numeric integration; algorithms. In this release ROOT::Math::AdaptiveIntegratorMultiDim,; which implements the 'Genz & Malik' algorithm has been interfaced; in RooAdaptiveIntegratorND and is now the default numeric integrator; for numeric integrations in two or more dimensions. This new default integrator has much improved stability and speed; for relatively smooth p.d.f.s in two or three dimensions and can; generally be used well for p.d.f. normalization integrals without; causing MINUIT converge problems due to numeric precision issues. In future release some more numeric integrators will be migrated to; a MathCore implementation. Interface to TFoam adaptive MC sampler added; RooFit can now use the TFoam adaptive MC sampler for event generation of p.d.f.s that; do not have an internal generator. The TFoam generator adaptively subdivides the; observable space and is generally more efficient both warmup and generation than the original; RooAcceptReject algorit",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:4615,Deployability,integrat,integration,4615,"lementation for migrad(),hesse(),minos() etc...; The minimizer(const char* package, const char* alg) provides a completely generic interface; to all minimizers, where package is the package (minuit,GSLminimizer) and alg is the algorithm (migrad) to be used. By default, RooMinuit is still used when RooAbsPdf::fitTo() is called, but can be overridden with; a Minimizer() named argument. // Minimization with MINUIT/MIGRAD through RooMinuit; pdf->fitTo(data) ;. // Minimization with MINUIT/MIGRAD through RooMinimizer; pdf->fitTo(data,Minimizer(""minuit"")) ;. // Minimization with MINUIT2/MIGRAD through RooMinimizer; pdf->fitTo(data,Minimizer(""minuit2"")) ;. // Minimization with GSLMultiMin/conjugatefr through RooMinimizer; pdf->fitTo(data,Minimizer(""GSLMultiMin"",""conjugatefr"")) ;. Note that installation of GSL and the ROOT MathMore package is needed to access the GSL Minimizers and that the GSL; Minimizer do not implement error analysis. New numeric integration algorithms available; RooFit can now interface all MathCore numeric integration; algorithms. In this release ROOT::Math::AdaptiveIntegratorMultiDim,; which implements the 'Genz & Malik' algorithm has been interfaced; in RooAdaptiveIntegratorND and is now the default numeric integrator; for numeric integrations in two or more dimensions. This new default integrator has much improved stability and speed; for relatively smooth p.d.f.s in two or three dimensions and can; generally be used well for p.d.f. normalization integrals without; causing MINUIT converge problems due to numeric precision issues. In future release some more numeric integrators will be migrated to; a MathCore implementation. Interface to TFoam adaptive MC sampler added; RooFit can now use the TFoam adaptive MC sampler for event generation of p.d.f.s that; do not have an internal generator. The TFoam generator adaptively subdivides the; observable space and is generally more efficient both warmup and generation than the original; RooAcceptReject algorit",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:4648,Deployability,release,release,4648,"package (minuit,GSLminimizer) and alg is the algorithm (migrad) to be used. By default, RooMinuit is still used when RooAbsPdf::fitTo() is called, but can be overridden with; a Minimizer() named argument. // Minimization with MINUIT/MIGRAD through RooMinuit; pdf->fitTo(data) ;. // Minimization with MINUIT/MIGRAD through RooMinimizer; pdf->fitTo(data,Minimizer(""minuit"")) ;. // Minimization with MINUIT2/MIGRAD through RooMinimizer; pdf->fitTo(data,Minimizer(""minuit2"")) ;. // Minimization with GSLMultiMin/conjugatefr through RooMinimizer; pdf->fitTo(data,Minimizer(""GSLMultiMin"",""conjugatefr"")) ;. Note that installation of GSL and the ROOT MathMore package is needed to access the GSL Minimizers and that the GSL; Minimizer do not implement error analysis. New numeric integration algorithms available; RooFit can now interface all MathCore numeric integration; algorithms. In this release ROOT::Math::AdaptiveIntegratorMultiDim,; which implements the 'Genz & Malik' algorithm has been interfaced; in RooAdaptiveIntegratorND and is now the default numeric integrator; for numeric integrations in two or more dimensions. This new default integrator has much improved stability and speed; for relatively smooth p.d.f.s in two or three dimensions and can; generally be used well for p.d.f. normalization integrals without; causing MINUIT converge problems due to numeric precision issues. In future release some more numeric integrators will be migrated to; a MathCore implementation. Interface to TFoam adaptive MC sampler added; RooFit can now use the TFoam adaptive MC sampler for event generation of p.d.f.s that; do not have an internal generator. The TFoam generator adaptively subdivides the; observable space and is generally more efficient both warmup and generation than the original; RooAcceptReject algorithm. In its current interface in RooFit, TFoam cannot; handle problems yet with discrete observables or conditional observables. For those problems; the original RooAcceptReject gene",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:4822,Deployability,integrat,integrator,4822,"package (minuit,GSLminimizer) and alg is the algorithm (migrad) to be used. By default, RooMinuit is still used when RooAbsPdf::fitTo() is called, but can be overridden with; a Minimizer() named argument. // Minimization with MINUIT/MIGRAD through RooMinuit; pdf->fitTo(data) ;. // Minimization with MINUIT/MIGRAD through RooMinimizer; pdf->fitTo(data,Minimizer(""minuit"")) ;. // Minimization with MINUIT2/MIGRAD through RooMinimizer; pdf->fitTo(data,Minimizer(""minuit2"")) ;. // Minimization with GSLMultiMin/conjugatefr through RooMinimizer; pdf->fitTo(data,Minimizer(""GSLMultiMin"",""conjugatefr"")) ;. Note that installation of GSL and the ROOT MathMore package is needed to access the GSL Minimizers and that the GSL; Minimizer do not implement error analysis. New numeric integration algorithms available; RooFit can now interface all MathCore numeric integration; algorithms. In this release ROOT::Math::AdaptiveIntegratorMultiDim,; which implements the 'Genz & Malik' algorithm has been interfaced; in RooAdaptiveIntegratorND and is now the default numeric integrator; for numeric integrations in two or more dimensions. This new default integrator has much improved stability and speed; for relatively smooth p.d.f.s in two or three dimensions and can; generally be used well for p.d.f. normalization integrals without; causing MINUIT converge problems due to numeric precision issues. In future release some more numeric integrators will be migrated to; a MathCore implementation. Interface to TFoam adaptive MC sampler added; RooFit can now use the TFoam adaptive MC sampler for event generation of p.d.f.s that; do not have an internal generator. The TFoam generator adaptively subdivides the; observable space and is generally more efficient both warmup and generation than the original; RooAcceptReject algorithm. In its current interface in RooFit, TFoam cannot; handle problems yet with discrete observables or conditional observables. For those problems; the original RooAcceptReject gene",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:4846,Deployability,integrat,integrations,4846,"package (minuit,GSLminimizer) and alg is the algorithm (migrad) to be used. By default, RooMinuit is still used when RooAbsPdf::fitTo() is called, but can be overridden with; a Minimizer() named argument. // Minimization with MINUIT/MIGRAD through RooMinuit; pdf->fitTo(data) ;. // Minimization with MINUIT/MIGRAD through RooMinimizer; pdf->fitTo(data,Minimizer(""minuit"")) ;. // Minimization with MINUIT2/MIGRAD through RooMinimizer; pdf->fitTo(data,Minimizer(""minuit2"")) ;. // Minimization with GSLMultiMin/conjugatefr through RooMinimizer; pdf->fitTo(data,Minimizer(""GSLMultiMin"",""conjugatefr"")) ;. Note that installation of GSL and the ROOT MathMore package is needed to access the GSL Minimizers and that the GSL; Minimizer do not implement error analysis. New numeric integration algorithms available; RooFit can now interface all MathCore numeric integration; algorithms. In this release ROOT::Math::AdaptiveIntegratorMultiDim,; which implements the 'Genz & Malik' algorithm has been interfaced; in RooAdaptiveIntegratorND and is now the default numeric integrator; for numeric integrations in two or more dimensions. This new default integrator has much improved stability and speed; for relatively smooth p.d.f.s in two or three dimensions and can; generally be used well for p.d.f. normalization integrals without; causing MINUIT converge problems due to numeric precision issues. In future release some more numeric integrators will be migrated to; a MathCore implementation. Interface to TFoam adaptive MC sampler added; RooFit can now use the TFoam adaptive MC sampler for event generation of p.d.f.s that; do not have an internal generator. The TFoam generator adaptively subdivides the; observable space and is generally more efficient both warmup and generation than the original; RooAcceptReject algorithm. In its current interface in RooFit, TFoam cannot; handle problems yet with discrete observables or conditional observables. For those problems; the original RooAcceptReject gene",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:4903,Deployability,integrat,integrator,4903,"with; a Minimizer() named argument. // Minimization with MINUIT/MIGRAD through RooMinuit; pdf->fitTo(data) ;. // Minimization with MINUIT/MIGRAD through RooMinimizer; pdf->fitTo(data,Minimizer(""minuit"")) ;. // Minimization with MINUIT2/MIGRAD through RooMinimizer; pdf->fitTo(data,Minimizer(""minuit2"")) ;. // Minimization with GSLMultiMin/conjugatefr through RooMinimizer; pdf->fitTo(data,Minimizer(""GSLMultiMin"",""conjugatefr"")) ;. Note that installation of GSL and the ROOT MathMore package is needed to access the GSL Minimizers and that the GSL; Minimizer do not implement error analysis. New numeric integration algorithms available; RooFit can now interface all MathCore numeric integration; algorithms. In this release ROOT::Math::AdaptiveIntegratorMultiDim,; which implements the 'Genz & Malik' algorithm has been interfaced; in RooAdaptiveIntegratorND and is now the default numeric integrator; for numeric integrations in two or more dimensions. This new default integrator has much improved stability and speed; for relatively smooth p.d.f.s in two or three dimensions and can; generally be used well for p.d.f. normalization integrals without; causing MINUIT converge problems due to numeric precision issues. In future release some more numeric integrators will be migrated to; a MathCore implementation. Interface to TFoam adaptive MC sampler added; RooFit can now use the TFoam adaptive MC sampler for event generation of p.d.f.s that; do not have an internal generator. The TFoam generator adaptively subdivides the; observable space and is generally more efficient both warmup and generation than the original; RooAcceptReject algorithm. In its current interface in RooFit, TFoam cannot; handle problems yet with discrete observables or conditional observables. For those problems; the original RooAcceptReject generator is still used. The choice of MC sampling algorithm can be steered through class RooNumGenConfig, which; is similar in style and structure, to RooNumIntConfig which",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:5162,Deployability,release,release,5162,"->fitTo(data,Minimizer(""minuit2"")) ;. // Minimization with GSLMultiMin/conjugatefr through RooMinimizer; pdf->fitTo(data,Minimizer(""GSLMultiMin"",""conjugatefr"")) ;. Note that installation of GSL and the ROOT MathMore package is needed to access the GSL Minimizers and that the GSL; Minimizer do not implement error analysis. New numeric integration algorithms available; RooFit can now interface all MathCore numeric integration; algorithms. In this release ROOT::Math::AdaptiveIntegratorMultiDim,; which implements the 'Genz & Malik' algorithm has been interfaced; in RooAdaptiveIntegratorND and is now the default numeric integrator; for numeric integrations in two or more dimensions. This new default integrator has much improved stability and speed; for relatively smooth p.d.f.s in two or three dimensions and can; generally be used well for p.d.f. normalization integrals without; causing MINUIT converge problems due to numeric precision issues. In future release some more numeric integrators will be migrated to; a MathCore implementation. Interface to TFoam adaptive MC sampler added; RooFit can now use the TFoam adaptive MC sampler for event generation of p.d.f.s that; do not have an internal generator. The TFoam generator adaptively subdivides the; observable space and is generally more efficient both warmup and generation than the original; RooAcceptReject algorithm. In its current interface in RooFit, TFoam cannot; handle problems yet with discrete observables or conditional observables. For those problems; the original RooAcceptReject generator is still used. The choice of MC sampling algorithm can be steered through class RooNumGenConfig, which; is similar in style and structure, to RooNumIntConfig which configures the choice of; numeric integration algorithm. A new tutorial macro rf902_numgenconfig.C has been added to $ROOTSYS/tutorials/roofit; to illustrate the use of the steering. A macro that demonstrates of the power of these newly interface numeric algorithms i",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:5188,Deployability,integrat,integrators,5188,"->fitTo(data,Minimizer(""minuit2"")) ;. // Minimization with GSLMultiMin/conjugatefr through RooMinimizer; pdf->fitTo(data,Minimizer(""GSLMultiMin"",""conjugatefr"")) ;. Note that installation of GSL and the ROOT MathMore package is needed to access the GSL Minimizers and that the GSL; Minimizer do not implement error analysis. New numeric integration algorithms available; RooFit can now interface all MathCore numeric integration; algorithms. In this release ROOT::Math::AdaptiveIntegratorMultiDim,; which implements the 'Genz & Malik' algorithm has been interfaced; in RooAdaptiveIntegratorND and is now the default numeric integrator; for numeric integrations in two or more dimensions. This new default integrator has much improved stability and speed; for relatively smooth p.d.f.s in two or three dimensions and can; generally be used well for p.d.f. normalization integrals without; causing MINUIT converge problems due to numeric precision issues. In future release some more numeric integrators will be migrated to; a MathCore implementation. Interface to TFoam adaptive MC sampler added; RooFit can now use the TFoam adaptive MC sampler for event generation of p.d.f.s that; do not have an internal generator. The TFoam generator adaptively subdivides the; observable space and is generally more efficient both warmup and generation than the original; RooAcceptReject algorithm. In its current interface in RooFit, TFoam cannot; handle problems yet with discrete observables or conditional observables. For those problems; the original RooAcceptReject generator is still used. The choice of MC sampling algorithm can be steered through class RooNumGenConfig, which; is similar in style and structure, to RooNumIntConfig which configures the choice of; numeric integration algorithm. A new tutorial macro rf902_numgenconfig.C has been added to $ROOTSYS/tutorials/roofit; to illustrate the use of the steering. A macro that demonstrates of the power of these newly interface numeric algorithms i",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:5966,Deployability,integrat,integration,5966," This new default integrator has much improved stability and speed; for relatively smooth p.d.f.s in two or three dimensions and can; generally be used well for p.d.f. normalization integrals without; causing MINUIT converge problems due to numeric precision issues. In future release some more numeric integrators will be migrated to; a MathCore implementation. Interface to TFoam adaptive MC sampler added; RooFit can now use the TFoam adaptive MC sampler for event generation of p.d.f.s that; do not have an internal generator. The TFoam generator adaptively subdivides the; observable space and is generally more efficient both warmup and generation than the original; RooAcceptReject algorithm. In its current interface in RooFit, TFoam cannot; handle problems yet with discrete observables or conditional observables. For those problems; the original RooAcceptReject generator is still used. The choice of MC sampling algorithm can be steered through class RooNumGenConfig, which; is similar in style and structure, to RooNumIntConfig which configures the choice of; numeric integration algorithm. A new tutorial macro rf902_numgenconfig.C has been added to $ROOTSYS/tutorials/roofit; to illustrate the use of the steering. A macro that demonstrates of the power of these newly interface numeric algorithms is provided at the; end of the RooFit section of the release notes. Optional persistent caching of numeric integrals; For p.d.f.s with numeric integrals that remain difficult or very time consuming,; a new persistent caching technique is now available that allows to precalculate; these integrals and store their values for future use. This technique works transparently; for any p.d.f. stored in a RooWorkspace. One can store numeric integral values for problems with zero, one or two floating parameters.; In the first case, the value is simply stored. In cases with one or two floating parameters; a grid (histogram) of integral values is stored, which are interpolated to return inte",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:6251,Deployability,release,release,6251,"ntegrators will be migrated to; a MathCore implementation. Interface to TFoam adaptive MC sampler added; RooFit can now use the TFoam adaptive MC sampler for event generation of p.d.f.s that; do not have an internal generator. The TFoam generator adaptively subdivides the; observable space and is generally more efficient both warmup and generation than the original; RooAcceptReject algorithm. In its current interface in RooFit, TFoam cannot; handle problems yet with discrete observables or conditional observables. For those problems; the original RooAcceptReject generator is still used. The choice of MC sampling algorithm can be steered through class RooNumGenConfig, which; is similar in style and structure, to RooNumIntConfig which configures the choice of; numeric integration algorithm. A new tutorial macro rf902_numgenconfig.C has been added to $ROOTSYS/tutorials/roofit; to illustrate the use of the steering. A macro that demonstrates of the power of these newly interface numeric algorithms is provided at the; end of the RooFit section of the release notes. Optional persistent caching of numeric integrals; For p.d.f.s with numeric integrals that remain difficult or very time consuming,; a new persistent caching technique is now available that allows to precalculate; these integrals and store their values for future use. This technique works transparently; for any p.d.f. stored in a RooWorkspace. One can store numeric integral values for problems with zero, one or two floating parameters.; In the first case, the value is simply stored. In cases with one or two floating parameters; a grid (histogram) of integral values is stored, which are interpolated to return integral; values for each value of the parameters. A new tutorial macro rf903_numintcache.C has been added to $ROOTSYS/tutorials/roofit; to illustrate the use of this feature. Representation of function and p.d.f. derivatives; A new class has been added that can represent the derivative of any p.d.f or funct",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:8118,Deployability,update,updated,8118,"added that can represent the derivative of any p.d.f or function w.r.t. any; parameter or observable. To construct e.g. a first order derivative of a Gaussian p.d.f, do. RooAbsReal* dgdx = gauss.derivative(x,1) ;. A more complete example is available in the new tutorial macro rf111_derivatives.C. Improved handling of chi-squared fits; Chi-squared fits can now be performed through the same style of interface as likelihood fits,; through the newly added method RooAbsReal::chi2FitTo(const RooDataHist&,...). Functions that can be fitted with chi-squared minimization are any RooAbsReal based function; as well as RooAbsPdf based p.d.f.s. In case of non-extended p.d.f.s the probability density; calculated by the p.d.f. is multiplied with the number of events in the histogram to adjust; the scale of the function. In case of extended p.d.f.s, the adjustment is made with the expected; number of events, rather than the observed number of events. Tutorial macro rf602_chi2fit.C has been updated to use this new interface. Chi-squared fits to X-Y datasets now possible; In addition to the ability to perform chi-squared fits to histograms it is now also possible; to perform chi-squared fits to unbinned datasets containing a series of X and Y values; with associated errors on Y and optionally on X. These 'X-Y' chi-squared fits are interfaced through newly added method; RooAbsReal::chi2FitTo(const RooDataSet&,...). By default the event weight is; interpreted as the 'Y' value, but an YVar() argument can designate any other; dataset column as Y value. If X errors are defined, one can choose to integrate the fitted; function over the range of the X errors, rather than taking the central value by adding; an Integrate(true) argument to chi2FitTo(); Two new arguments, StoreError(const RooArgSet&) and StoreAsymError(const RooArgSet&); have been added to the RooDataSet constructor to simplify the process of storing the errors; of X and Y variables along with their values in a dataset. The newl",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:8729,Deployability,integrat,integrate,8729,"gram to adjust; the scale of the function. In case of extended p.d.f.s, the adjustment is made with the expected; number of events, rather than the observed number of events. Tutorial macro rf602_chi2fit.C has been updated to use this new interface. Chi-squared fits to X-Y datasets now possible; In addition to the ability to perform chi-squared fits to histograms it is now also possible; to perform chi-squared fits to unbinned datasets containing a series of X and Y values; with associated errors on Y and optionally on X. These 'X-Y' chi-squared fits are interfaced through newly added method; RooAbsReal::chi2FitTo(const RooDataSet&,...). By default the event weight is; interpreted as the 'Y' value, but an YVar() argument can designate any other; dataset column as Y value. If X errors are defined, one can choose to integrate the fitted; function over the range of the X errors, rather than taking the central value by adding; an Integrate(true) argument to chi2FitTo(); Two new arguments, StoreError(const RooArgSet&) and StoreAsymError(const RooArgSet&); have been added to the RooDataSet constructor to simplify the process of storing the errors; of X and Y variables along with their values in a dataset. The newly added tutorial macro rf609_xychi2fit.C illustrates the use of all this; new functionality. Uniform interface for creation of (profile likelihoods) and chi-squared from p.d.f.s; It is now recommended to use the method RooAbsPdf::createNLL(RooAbsData&,...) to; create a likelihood from a p.d.f and a dataset rather than constructing a RooNLLVar; object directly. This is because part of the likelihood construction functionality such a using; multiple Range()s, or the inclusion for constraint terms are only available through; createNLL(). To promote the consistency of this interface, a similar method RooAbsReal::createChi2(); has been added to construct chi-squared functions of a dataset and a function or p.d.f. Along the same lines, it is recommended to use RooAbsRe",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:10629,Deployability,integrat,integration,10629,"ncy of this interface, a similar method RooAbsReal::createChi2(); has been added to construct chi-squared functions of a dataset and a function or p.d.f. Along the same lines, it is recommended to use RooAbsReal::createProfile() rather; than constructing a RooProfileLL object directly as the former will efficiently; recast a profile of a profile into a single profile object. Multivariate Gaussian modeling of parameters estimates from a fit; You can now construct a multivariate Gaussian p.d.f on the parameters of a model that; represents the result of a fit, from any RooFitResult object. RooAbsPdf* paramPdf = fitresult->createHessePdf(RooArgSet(a,b)) ;. The returned object is an instance of the newly added class RooMultiVarGaussian, that can; model correlated Gaussian distributions in an arbitrary number of dimensions, given a; vector of mean values and a covariance matrix. Class RooMultivarGaussian implements analytical; integration as well as analytical partial integrals over the first 31 dimensions (if you have; that many) and implements in effect internal generation strategy for its observables. A new tutorial macro rf608_fitresultaspdf.C has been added to illustrate the use MV Gaussians constructed from a RooFitResult; Improved functionality of RooFFTConvPdf; The FFT convolution operator p.d.f. class RooFFTConvPdf has been substantially upgraded; for improved performance has several new options. For the overflow buffering, which aims to reduce cylical spillover from the FFT convolution,; a choice of three algorithms is now provided:. Extend the p.d.f. somewhat beyond its original domain (the new default); Fill the buffer 50/50 with the value of the p.d.f at the upper/lower bound of the convolution observable (the previous default); Mirror the p.d.f. over the boundary. The new default algorithm provides a more sensible result for p.d.f.s with significant; spillover issues, provided that the p.d.f. can be continuated beyond its original domain.; Convolution in non",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:11057,Deployability,upgrade,upgraded,11057,"object. Multivariate Gaussian modeling of parameters estimates from a fit; You can now construct a multivariate Gaussian p.d.f on the parameters of a model that; represents the result of a fit, from any RooFitResult object. RooAbsPdf* paramPdf = fitresult->createHessePdf(RooArgSet(a,b)) ;. The returned object is an instance of the newly added class RooMultiVarGaussian, that can; model correlated Gaussian distributions in an arbitrary number of dimensions, given a; vector of mean values and a covariance matrix. Class RooMultivarGaussian implements analytical; integration as well as analytical partial integrals over the first 31 dimensions (if you have; that many) and implements in effect internal generation strategy for its observables. A new tutorial macro rf608_fitresultaspdf.C has been added to illustrate the use MV Gaussians constructed from a RooFitResult; Improved functionality of RooFFTConvPdf; The FFT convolution operator p.d.f. class RooFFTConvPdf has been substantially upgraded; for improved performance has several new options. For the overflow buffering, which aims to reduce cylical spillover from the FFT convolution,; a choice of three algorithms is now provided:. Extend the p.d.f. somewhat beyond its original domain (the new default); Fill the buffer 50/50 with the value of the p.d.f at the upper/lower bound of the convolution observable (the previous default); Mirror the p.d.f. over the boundary. The new default algorithm provides a more sensible result for p.d.f.s with significant; spillover issues, provided that the p.d.f. can be continuated beyond its original domain.; Convolution in non-observables is also explicitly supported now. One can e.g. construct a p.d.f; of the form G(x) = Int[dy] ( F(x,y) (*) H(y) ). A new tutorial macro rf211_paramconv illustrates; how such convolutions can be constructed; It is now also possible to express FFT convolutions in terms of other observables than the; convolution observable itself. A common occurrence of that s",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:15353,Deployability,release,releases,15353,"merly implement in class RooTreeData. Methods in class RooTreeData; that were not specific to the storage technology have been moved to; class RooAbsData. If your user code only uses the classes RooDataSet,RooDataHist and RooAbsData; nothing will change: Existing RooDataSets and RooDataHists; (that inherit from RooTreeData) can be read in without problems in; RooFit 3.00 and will be converted on the fly to the new dataset structure; in memory. User code that explicitly uses RooTreeData pointers should; be changed to RooAbsData pointers. This change should be transparent; for all uses, with the exception of the RooTreeData::tree() method.; Explicit access to tree implementation can still be obtained; through the RooTreeDataStore::tree() method. (A pointer to the datastore; can be obtained through the RooAbsData::store() method.); Note that in future releases it is no longer guaranteed that all datasets are implemented; with a plain TTree implementation, so any user code that uses the tree; implementation directly should implement checks that the implementation; is indeed tree-based (data->store()->InheritsFrom(RooTreeDataStore::Class())==true)). In future release additional implementations of RooAbsDataStore will; be provided that will support new dataset functionality such as the; ability to construct 'joint' dataset from two input datasets without; the need to copy the input data and 'filtered' datasets that represent; a reduced view (in dimensions or by selecting events) of a dataset; without the need to copy content. Various workspace improvements. A number of smaller and larger improvements has been made to the RooWorkspace class. Direct interactive access to contents from CINT -; One can now directly access the contents of any RooWorkspace; on the ROOT commandline through CINT if the RooWorkspace::exportToCint() call is made.; In CINT, all workspace objects will appear as correctly typed references to workspace objects in; a C++ namespace with the same name as ",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:15665,Deployability,release,release,15665,"lems in; RooFit 3.00 and will be converted on the fly to the new dataset structure; in memory. User code that explicitly uses RooTreeData pointers should; be changed to RooAbsData pointers. This change should be transparent; for all uses, with the exception of the RooTreeData::tree() method.; Explicit access to tree implementation can still be obtained; through the RooTreeDataStore::tree() method. (A pointer to the datastore; can be obtained through the RooAbsData::store() method.); Note that in future releases it is no longer guaranteed that all datasets are implemented; with a plain TTree implementation, so any user code that uses the tree; implementation directly should implement checks that the implementation; is indeed tree-based (data->store()->InheritsFrom(RooTreeDataStore::Class())==true)). In future release additional implementations of RooAbsDataStore will; be provided that will support new dataset functionality such as the; ability to construct 'joint' dataset from two input datasets without; the need to copy the input data and 'filtered' datasets that represent; a reduced view (in dimensions or by selecting events) of a dataset; without the need to copy content. Various workspace improvements. A number of smaller and larger improvements has been made to the RooWorkspace class. Direct interactive access to contents from CINT -; One can now directly access the contents of any RooWorkspace; on the ROOT commandline through CINT if the RooWorkspace::exportToCint() call is made.; In CINT, all workspace objects will appear as correctly typed references to workspace objects in; a C++ namespace with the same name as the RooWorkspace object. Given e.g. a workspace w, with a Gaussian p.d.f gauss in terms of variables; x,m,s one can now do. RooWorkspace w(""w"",true) ; // workspace with CINT interface activated; // ... fill workspace with RooGaussian gauss(x,m,s) ...; RooPlot* frame = w::x.frame() ;; w::gauss.plotOn(frame) ;. to access the workspace contents. Each refe",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:18863,Deployability,continuous,continuous,18863," -- Many operator p.d.f. and function components now show; a more intuitive natural representation of their contents (these changes are mostly in the; respective p.d.f.s, but are most relevant in the context of a workspace). New object factory interface to workspace to facilitate script driven model definition; A object factory has been added to RooFit to simplify the process of creating p.d.f.; and function expressions consisting of multiple objects. The factory has two goals:; the first is to provide a back-end for higher level factories and tools to process; the creation of objects. The second is to provide a simple end-user language to; populate a RooWorkspace with function and p.d.f. objects. For the latter purpose the object creation language is executed through the factory() method; of a workspace object. RooWorkspace w(""w"") ;; RooAbsArg* arg = w.factory(""expression_goes_here"") ;. Basic Syntax; The rules at its simplest level are as follows. Expressions with square brackets create variables (discrete and continuous). ""m[-10,10]"" - Creates a RooRealVar named 'm' with range [-10,10]; ""m[5,-10,10]"" - Idem, but with initial value 5; ""m[5]"" - Creates a constant RooRealVar with name 'm' and value 5. ""tagCat[Lep,Kao,NT1,NT2]"" -- Creates a RooCategory with name tagCat and labeled states Lep,Kao,NT1,NT2; ""b0flav[B0=1,B0bar=-1]"" -- Creates a RooCategory with name b0flav and states B0 and B0bar with explicit index assignments. Expressions with parentheses create RooAbsArg function objects of any type. ""RooGaussian::g(x,m,s)"" -- Create a RooGaussian named g with variables x,m,s; This expression maps 1-1 to a createArg() call. ""Gaussian::g(x,m,s)"" -- Idem. The 'Roo' prefix on any class may be omitted. ""Gaussian(x,m,s)"" -- Create a RooGaussian with an automatically assigned name with variables x,m,s. Expressions with curly brackets creates RooArgSets or RooArgLists ""{x,y,z}"". Compound expressions; The real power of this language is that all these expressions may be nested t",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:22090,Deployability,integrat,integration,22090,"event error dterr and all its parameters, convoluted with a triple; gaussian resolution model and multiplied with a Gaussian p.d.f. in the; energy substituted mass. (In plain RooFit this would have required at; least 23 lines of code). A series of three new tutorial macros has been added to illustrate the; various features of the object factory. rf511_wsfactory_basic.C - Basic factory concepts; rf512_wsfactory_oper.C - Using operator p.d.f.s in the factory; rf513_wsfactory_tools.C - Advanced example using interfaced high level tools. A formal transaction model is used to commit composite objects into; the workspace. If an error is detected in the expression, no objects; will be committed to the workspace, thus leaving no 'partial builds'. Compact demo of several new major features. The macro below demonstrates in a couple of lines a number of major new features in RooFit 3.00: Use of. workspace factory to quickly create and store (compiled) models; workspace CINT interface to easily access contents in a typesafe way; new adaptive ND numeric integration technique to normalize arbitrary p.d.f. in fast; and reliable way; new adaptive TFoam sampling technique to efficiently generate toy MC data from strongly; peaked datasets; parallel processing in likelihood construction and use of profile likelihood operator; to represent profile likelihoods as regular RooFit functions. void demo(); {; // Construct compiled 2-D model that requires numeric integration for normalization; RooWorkspace w(""w"",1) ;; w.factory(""CEXPR::model('1/((x-a)*(x-a)+0.001)+1/((y-b)*(y-b)+0.001)',x[-1,1],y[-1,1],a[-5,5],b[-5,5])"") ;. // Generate data from model (using TFoam adaptive sampling algorithm); RooDataSet* d = w::model.generate(RooArgSet(w::x,w::y),1000) ;; w::model.fitTo(*d) ;. // Make 2D plot on (x,y); TH2* hh = w::model.createHistogram(""x,y"",40,40) ;; hh->SetLineColor(kBlue) ;. // Make Projection on x (integrate over y); RooPlot* framex = w::x.frame(Title(""Data and p.d.f. projected on X"")) ;",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:22494,Deployability,integrat,integration,22494,"actory; rf513_wsfactory_tools.C - Advanced example using interfaced high level tools. A formal transaction model is used to commit composite objects into; the workspace. If an error is detected in the expression, no objects; will be committed to the workspace, thus leaving no 'partial builds'. Compact demo of several new major features. The macro below demonstrates in a couple of lines a number of major new features in RooFit 3.00: Use of. workspace factory to quickly create and store (compiled) models; workspace CINT interface to easily access contents in a typesafe way; new adaptive ND numeric integration technique to normalize arbitrary p.d.f. in fast; and reliable way; new adaptive TFoam sampling technique to efficiently generate toy MC data from strongly; peaked datasets; parallel processing in likelihood construction and use of profile likelihood operator; to represent profile likelihoods as regular RooFit functions. void demo(); {; // Construct compiled 2-D model that requires numeric integration for normalization; RooWorkspace w(""w"",1) ;; w.factory(""CEXPR::model('1/((x-a)*(x-a)+0.001)+1/((y-b)*(y-b)+0.001)',x[-1,1],y[-1,1],a[-5,5],b[-5,5])"") ;. // Generate data from model (using TFoam adaptive sampling algorithm); RooDataSet* d = w::model.generate(RooArgSet(w::x,w::y),1000) ;; w::model.fitTo(*d) ;. // Make 2D plot on (x,y); TH2* hh = w::model.createHistogram(""x,y"",40,40) ;; hh->SetLineColor(kBlue) ;. // Make Projection on x (integrate over y); RooPlot* framex = w::x.frame(Title(""Data and p.d.f. projected on X"")) ;; d->plotOn(framex) ;; w::model.plotOn(framex) ;. // Construct likelihood, profile likelihood in a, and draw the latter; RooAbsReal* nll = w::model.createNLL(*d,NumCPU(2)) ;; RooAbsReal* pll = nll->createProfile(w::a) ;; RooPlot* framea = w::a.frame(Title(""Profile likelihood in parameter a"")) ;; pll->plotOn(framea) ;. // Construct 2D cumulative distribution function from p.d.f.; RooAbsReal* cdfxy = w::model.createCdf(RooArgSet(w::x,w::y),ScanNoCdf())",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:22944,Deployability,integrat,integrate,22944,"quickly create and store (compiled) models; workspace CINT interface to easily access contents in a typesafe way; new adaptive ND numeric integration technique to normalize arbitrary p.d.f. in fast; and reliable way; new adaptive TFoam sampling technique to efficiently generate toy MC data from strongly; peaked datasets; parallel processing in likelihood construction and use of profile likelihood operator; to represent profile likelihoods as regular RooFit functions. void demo(); {; // Construct compiled 2-D model that requires numeric integration for normalization; RooWorkspace w(""w"",1) ;; w.factory(""CEXPR::model('1/((x-a)*(x-a)+0.001)+1/((y-b)*(y-b)+0.001)',x[-1,1],y[-1,1],a[-5,5],b[-5,5])"") ;. // Generate data from model (using TFoam adaptive sampling algorithm); RooDataSet* d = w::model.generate(RooArgSet(w::x,w::y),1000) ;; w::model.fitTo(*d) ;. // Make 2D plot on (x,y); TH2* hh = w::model.createHistogram(""x,y"",40,40) ;; hh->SetLineColor(kBlue) ;. // Make Projection on x (integrate over y); RooPlot* framex = w::x.frame(Title(""Data and p.d.f. projected on X"")) ;; d->plotOn(framex) ;; w::model.plotOn(framex) ;. // Construct likelihood, profile likelihood in a, and draw the latter; RooAbsReal* nll = w::model.createNLL(*d,NumCPU(2)) ;; RooAbsReal* pll = nll->createProfile(w::a) ;; RooPlot* framea = w::a.frame(Title(""Profile likelihood in parameter a"")) ;; pll->plotOn(framea) ;. // Construct 2D cumulative distribution function from p.d.f.; RooAbsReal* cdfxy = w::model.createCdf(RooArgSet(w::x,w::y),ScanNoCdf()) ;; TH2* hhcdf = cdfxy->createHistogram(""x,y"",40,40) ;; hhcdf->SetLineColor(kRed) ;. TCanvas* c = new TCanvas(""c"",""c"",650,650) ; c->Divide(2,2) ;; c->cd(1) ; hh->Draw(""surf"") ; c->cd(2) ; framex->Draw() ;; c->cd(3) ; framea->Draw() ; c->cd(4) ; hhcdf->Draw(""surf"") ;; }. Plot that results from above macro. Miscellaneous small improvements. Utility function bindFunction() and bindPdf that can bind; external C++ functions as RooFit functions or p.d.f.s now can al",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:27778,Deployability,release,release,27778,"ry real valued test statistic. �The class also can return the; inverse of the cumulative distribution function (with or without; interpolation). �; We introduced an interface for any tool that can produce a; SamplingDistribution, called TestStatSampler. �The interface is; essentially GetSamplingDistribution(parameterPoint) which returns a; SamplingDistribution based on a given probability density function. �We; foresee a few versions of this tool based on toy Monte Carlo, importance; sampling, Fourier transforms, etc. �The following concrete implementation; of the TestStatSampler interface are currently available. ToyMCSamplerUses a Toy Monte Carlo approach to build the; sampling distribution. �The pdf's generate method to generate is used to; generate toy data, and then the test statistic is evaluated at the; requested parameter point. ; DebuggingSampler Simply returns a uniform distribution; between 0,1. �Useful for debugging. NeymanConstruction and FeldmanCousins; A flexible framework for the Neyman Construction was added in this; release. The NeymanConstruction is a concrete implementation of the; IntervalCalculator interface, but it needs several; additional components�to be specified before use. The design; factorizes the choice of the parameter points to be tested,�the choice of; the test statistic, and the generation of sampling distribution into; separate parts (described above). �Finally, the NeymanConstruction class; is simply in charge of using these parts (strategies) and constructing; the confidence belt and confidence intervals. �The ConfidenceBelt class; is still under development, but the current version works fine for; producing ConfidenceIntervals. �We are also working to make this class; work with parallelization approaches, which is not yet complete.; The FeldmanCousins class is a separate concrete implementation of the; IntervalCalculator interface. �It uses the NeymanConstruction internally,; and�enforces�specific choices of the test statistic",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:29553,Deployability,release,release,29553,"hich is not yet complete.; The FeldmanCousins class is a separate concrete implementation of the; IntervalCalculator interface. �It uses the NeymanConstruction internally,; and�enforces�specific choices of the test statistic and ordering; principle to realize the Unified intervals described by Feldman and; Cousins in their paper�Phys.Rev.D57:3873-3889,1998. In an extension to the technique discussed in Feldman and Cousins paper,; the FeldmanCousins class also performs a ""profile construction"" if their are nuisance parameters.; In this case, the parameters of interest are scanned in a regular grid. For each point in the grid; the calculator finds the best fit value of the nuisance parameters (given the data). The construction; is then only performed in this subspace of the parameters. As a result, the number of points in the; construction only scales in the number of parameters of interest, not in the number of nuisance parameters. Markov Chain Monte Carlo Interval; A flexible framework for Markov Chain Monte Carlo was added in this; release. The MCMCCalculator is a concrete implementation of the; IntervalCalculator interface. To use it one needs to specify the ProposalFunction.; There is a base class for ProposalFunctions and one concrete implementation: UniformProposal.; Support for other proposal functions will be added in the next release.; The MCMCCalculator scans the space of the parameters of interest and nuisance parameters and; produces a Bayesian posterior. In this version, the prior must be added to the model initially,; otherwise a flat prior is assumed. The MCMCCalculator returns an MCMCInterval, which produces; the smallest interval by taking a contour of the posterior. This first version only supports; 1,2, and 3 dimensional intervals, but will be generalized in the next release. In addition to the MCMC implementation in RooStats, one can export their model and dataset into a workspace,; and then use the Bayesian Analysis Toolkit (BAT) for the MCMC. The",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:29860,Deployability,release,release,29860,"per�Phys.Rev.D57:3873-3889,1998. In an extension to the technique discussed in Feldman and Cousins paper,; the FeldmanCousins class also performs a ""profile construction"" if their are nuisance parameters.; In this case, the parameters of interest are scanned in a regular grid. For each point in the grid; the calculator finds the best fit value of the nuisance parameters (given the data). The construction; is then only performed in this subspace of the parameters. As a result, the number of points in the; construction only scales in the number of parameters of interest, not in the number of nuisance parameters. Markov Chain Monte Carlo Interval; A flexible framework for Markov Chain Monte Carlo was added in this; release. The MCMCCalculator is a concrete implementation of the; IntervalCalculator interface. To use it one needs to specify the ProposalFunction.; There is a base class for ProposalFunctions and one concrete implementation: UniformProposal.; Support for other proposal functions will be added in the next release.; The MCMCCalculator scans the space of the parameters of interest and nuisance parameters and; produces a Bayesian posterior. In this version, the prior must be added to the model initially,; otherwise a flat prior is assumed. The MCMCCalculator returns an MCMCInterval, which produces; the smallest interval by taking a contour of the posterior. This first version only supports; 1,2, and 3 dimensional intervals, but will be generalized in the next release. In addition to the MCMC implementation in RooStats, one can export their model and dataset into a workspace,; and then use the Bayesian Analysis Toolkit (BAT) for the MCMC. There is a wrapper available. Redesigned SPlot class; The RooStats SPlot implementation works with any RooAbsPdf. The class has been redesigned for more; convenient use. It also adds some helper functions to check that the sum of sWeights over species is 1 for each event and; the sum over events for a given species equals the yi",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:30320,Deployability,release,release,30320,"subspace of the parameters. As a result, the number of points in the; construction only scales in the number of parameters of interest, not in the number of nuisance parameters. Markov Chain Monte Carlo Interval; A flexible framework for Markov Chain Monte Carlo was added in this; release. The MCMCCalculator is a concrete implementation of the; IntervalCalculator interface. To use it one needs to specify the ProposalFunction.; There is a base class for ProposalFunctions and one concrete implementation: UniformProposal.; Support for other proposal functions will be added in the next release.; The MCMCCalculator scans the space of the parameters of interest and nuisance parameters and; produces a Bayesian posterior. In this version, the prior must be added to the model initially,; otherwise a flat prior is assumed. The MCMCCalculator returns an MCMCInterval, which produces; the smallest interval by taking a contour of the posterior. This first version only supports; 1,2, and 3 dimensional intervals, but will be generalized in the next release. In addition to the MCMC implementation in RooStats, one can export their model and dataset into a workspace,; and then use the Bayesian Analysis Toolkit (BAT) for the MCMC. There is a wrapper available. Redesigned SPlot class; The RooStats SPlot implementation works with any RooAbsPdf. The class has been redesigned for more; convenient use. It also adds some helper functions to check that the sum of sWeights over species is 1 for each event and; the sum over events for a given species equals the yield for that species. Plotting classes; We have added new plotting classes: SamplingDistPlot and LikelihoodIntervalPlot.; In 1-d LikelihoodIntervalPlot shows the profile likelihood ratio and the upper/lower limits; of the interval for the parameter of interest. In 2-d, the LikelihoodIntervalPlot shows; the contour of the profile likelihood ratio for the parameters of interest. Bernstein Correction. BernsteinCorrection is a utility in Ro",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:33165,Deployability,release,release,33165,"ratio for the parameters of interest. Bernstein Correction. BernsteinCorrection is a utility in RooStats to augment a nominal PDF; with a polynomial�; correction term. �This is useful for incorporating systematic variations; to the nominal PDF. �; The Bernstein basis polynomails are particularly appropriate because they; are positive definite.�. This tool was inspired by the work of Glen Cowan together with Stephan; Horner, Sascha Caron,�; Eilam Gross, and others. �; The initial implementation is independent work. �The major step forward; in the approach was�; to provide a well defined algorithm that specifies the order of; polynomial to be included�; in the correction. �This is an empirical algorithm, so in addition to the; nominal model it�; needs either a real data set or a simulated one. �In the early work, the; nominal model was taken; to be a histogram from Monte Carlo simulations, but in this; implementation it is generalized to an; arbitrary PDF (which includes a RooHistPdf). �The algorithm basically; consists of a�; hypothesis test of an nth-order correction (null) against a n+1-th order; correction (alternate).�; The quantity q = -2 log LR is used to determine whether the n+1-th order; correction is a major�; improvement to the n-th order correction. �The distribution of q is; expected to be roughly�; \chi^2 with one degree of freedom if the n-th order correction is a good; model for the data.�; �Thus, one only moves to the n+1-th order correction of q is relatively; large. �The chance that�; one moves from the n-th to the n+1-th order correction when the n-th; order correction�; (eg. a type 1 error) is sufficient is given by the Prob(\chi^2_1 >; threshold). �The constructor�; of this class allows you to directly set this tolerance (in terms of; probability that the n+1-th; �term is added unnecessarily). HybridCalculator; Add as a new test statistics the profile likelihood ratio. Will be redesigned to use TestStatSampler and TestStatistic in next release. ",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:5267,Energy Efficiency,adapt,adaptive,5267,">fitTo(data,Minimizer(""GSLMultiMin"",""conjugatefr"")) ;. Note that installation of GSL and the ROOT MathMore package is needed to access the GSL Minimizers and that the GSL; Minimizer do not implement error analysis. New numeric integration algorithms available; RooFit can now interface all MathCore numeric integration; algorithms. In this release ROOT::Math::AdaptiveIntegratorMultiDim,; which implements the 'Genz & Malik' algorithm has been interfaced; in RooAdaptiveIntegratorND and is now the default numeric integrator; for numeric integrations in two or more dimensions. This new default integrator has much improved stability and speed; for relatively smooth p.d.f.s in two or three dimensions and can; generally be used well for p.d.f. normalization integrals without; causing MINUIT converge problems due to numeric precision issues. In future release some more numeric integrators will be migrated to; a MathCore implementation. Interface to TFoam adaptive MC sampler added; RooFit can now use the TFoam adaptive MC sampler for event generation of p.d.f.s that; do not have an internal generator. The TFoam generator adaptively subdivides the; observable space and is generally more efficient both warmup and generation than the original; RooAcceptReject algorithm. In its current interface in RooFit, TFoam cannot; handle problems yet with discrete observables or conditional observables. For those problems; the original RooAcceptReject generator is still used. The choice of MC sampling algorithm can be steered through class RooNumGenConfig, which; is similar in style and structure, to RooNumIntConfig which configures the choice of; numeric integration algorithm. A new tutorial macro rf902_numgenconfig.C has been added to $ROOTSYS/tutorials/roofit; to illustrate the use of the steering. A macro that demonstrates of the power of these newly interface numeric algorithms is provided at the; end of the RooFit section of the release notes. Optional persistent caching of numeric int",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:5323,Energy Efficiency,adapt,adaptive,5323,">fitTo(data,Minimizer(""GSLMultiMin"",""conjugatefr"")) ;. Note that installation of GSL and the ROOT MathMore package is needed to access the GSL Minimizers and that the GSL; Minimizer do not implement error analysis. New numeric integration algorithms available; RooFit can now interface all MathCore numeric integration; algorithms. In this release ROOT::Math::AdaptiveIntegratorMultiDim,; which implements the 'Genz & Malik' algorithm has been interfaced; in RooAdaptiveIntegratorND and is now the default numeric integrator; for numeric integrations in two or more dimensions. This new default integrator has much improved stability and speed; for relatively smooth p.d.f.s in two or three dimensions and can; generally be used well for p.d.f. normalization integrals without; causing MINUIT converge problems due to numeric precision issues. In future release some more numeric integrators will be migrated to; a MathCore implementation. Interface to TFoam adaptive MC sampler added; RooFit can now use the TFoam adaptive MC sampler for event generation of p.d.f.s that; do not have an internal generator. The TFoam generator adaptively subdivides the; observable space and is generally more efficient both warmup and generation than the original; RooAcceptReject algorithm. In its current interface in RooFit, TFoam cannot; handle problems yet with discrete observables or conditional observables. For those problems; the original RooAcceptReject generator is still used. The choice of MC sampling algorithm can be steered through class RooNumGenConfig, which; is similar in style and structure, to RooNumIntConfig which configures the choice of; numeric integration algorithm. A new tutorial macro rf902_numgenconfig.C has been added to $ROOTSYS/tutorials/roofit; to illustrate the use of the steering. A macro that demonstrates of the power of these newly interface numeric algorithms is provided at the; end of the RooFit section of the release notes. Optional persistent caching of numeric int",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:5436,Energy Efficiency,adapt,adaptively,5436,"plement error analysis. New numeric integration algorithms available; RooFit can now interface all MathCore numeric integration; algorithms. In this release ROOT::Math::AdaptiveIntegratorMultiDim,; which implements the 'Genz & Malik' algorithm has been interfaced; in RooAdaptiveIntegratorND and is now the default numeric integrator; for numeric integrations in two or more dimensions. This new default integrator has much improved stability and speed; for relatively smooth p.d.f.s in two or three dimensions and can; generally be used well for p.d.f. normalization integrals without; causing MINUIT converge problems due to numeric precision issues. In future release some more numeric integrators will be migrated to; a MathCore implementation. Interface to TFoam adaptive MC sampler added; RooFit can now use the TFoam adaptive MC sampler for event generation of p.d.f.s that; do not have an internal generator. The TFoam generator adaptively subdivides the; observable space and is generally more efficient both warmup and generation than the original; RooAcceptReject algorithm. In its current interface in RooFit, TFoam cannot; handle problems yet with discrete observables or conditional observables. For those problems; the original RooAcceptReject generator is still used. The choice of MC sampling algorithm can be steered through class RooNumGenConfig, which; is similar in style and structure, to RooNumIntConfig which configures the choice of; numeric integration algorithm. A new tutorial macro rf902_numgenconfig.C has been added to $ROOTSYS/tutorials/roofit; to illustrate the use of the steering. A macro that demonstrates of the power of these newly interface numeric algorithms is provided at the; end of the RooFit section of the release notes. Optional persistent caching of numeric integrals; For p.d.f.s with numeric integrals that remain difficult or very time consuming,; a new persistent caching technique is now available that allows to precalculate; these integrals and s",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:5502,Energy Efficiency,efficient,efficient,5502,"plement error analysis. New numeric integration algorithms available; RooFit can now interface all MathCore numeric integration; algorithms. In this release ROOT::Math::AdaptiveIntegratorMultiDim,; which implements the 'Genz & Malik' algorithm has been interfaced; in RooAdaptiveIntegratorND and is now the default numeric integrator; for numeric integrations in two or more dimensions. This new default integrator has much improved stability and speed; for relatively smooth p.d.f.s in two or three dimensions and can; generally be used well for p.d.f. normalization integrals without; causing MINUIT converge problems due to numeric precision issues. In future release some more numeric integrators will be migrated to; a MathCore implementation. Interface to TFoam adaptive MC sampler added; RooFit can now use the TFoam adaptive MC sampler for event generation of p.d.f.s that; do not have an internal generator. The TFoam generator adaptively subdivides the; observable space and is generally more efficient both warmup and generation than the original; RooAcceptReject algorithm. In its current interface in RooFit, TFoam cannot; handle problems yet with discrete observables or conditional observables. For those problems; the original RooAcceptReject generator is still used. The choice of MC sampling algorithm can be steered through class RooNumGenConfig, which; is similar in style and structure, to RooNumIntConfig which configures the choice of; numeric integration algorithm. A new tutorial macro rf902_numgenconfig.C has been added to $ROOTSYS/tutorials/roofit; to illustrate the use of the steering. A macro that demonstrates of the power of these newly interface numeric algorithms is provided at the; end of the RooFit section of the release notes. Optional persistent caching of numeric integrals; For p.d.f.s with numeric integrals that remain difficult or very time consuming,; a new persistent caching technique is now available that allows to precalculate; these integrals and s",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:6148,Energy Efficiency,power,power,6148,"ntegrators will be migrated to; a MathCore implementation. Interface to TFoam adaptive MC sampler added; RooFit can now use the TFoam adaptive MC sampler for event generation of p.d.f.s that; do not have an internal generator. The TFoam generator adaptively subdivides the; observable space and is generally more efficient both warmup and generation than the original; RooAcceptReject algorithm. In its current interface in RooFit, TFoam cannot; handle problems yet with discrete observables or conditional observables. For those problems; the original RooAcceptReject generator is still used. The choice of MC sampling algorithm can be steered through class RooNumGenConfig, which; is similar in style and structure, to RooNumIntConfig which configures the choice of; numeric integration algorithm. A new tutorial macro rf902_numgenconfig.C has been added to $ROOTSYS/tutorials/roofit; to illustrate the use of the steering. A macro that demonstrates of the power of these newly interface numeric algorithms is provided at the; end of the RooFit section of the release notes. Optional persistent caching of numeric integrals; For p.d.f.s with numeric integrals that remain difficult or very time consuming,; a new persistent caching technique is now available that allows to precalculate; these integrals and store their values for future use. This technique works transparently; for any p.d.f. stored in a RooWorkspace. One can store numeric integral values for problems with zero, one or two floating parameters.; In the first case, the value is simply stored. In cases with one or two floating parameters; a grid (histogram) of integral values is stored, which are interpolated to return integral; values for each value of the parameters. A new tutorial macro rf903_numintcache.C has been added to $ROOTSYS/tutorials/roofit; to illustrate the use of this feature. Representation of function and p.d.f. derivatives; A new class has been added that can represent the derivative of any p.d.f or funct",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:9999,Energy Efficiency,efficient,efficiently,9999,"oArgSet&); have been added to the RooDataSet constructor to simplify the process of storing the errors; of X and Y variables along with their values in a dataset. The newly added tutorial macro rf609_xychi2fit.C illustrates the use of all this; new functionality. Uniform interface for creation of (profile likelihoods) and chi-squared from p.d.f.s; It is now recommended to use the method RooAbsPdf::createNLL(RooAbsData&,...) to; create a likelihood from a p.d.f and a dataset rather than constructing a RooNLLVar; object directly. This is because part of the likelihood construction functionality such a using; multiple Range()s, or the inclusion for constraint terms are only available through; createNLL(). To promote the consistency of this interface, a similar method RooAbsReal::createChi2(); has been added to construct chi-squared functions of a dataset and a function or p.d.f. Along the same lines, it is recommended to use RooAbsReal::createProfile() rather; than constructing a RooProfileLL object directly as the former will efficiently; recast a profile of a profile into a single profile object. Multivariate Gaussian modeling of parameters estimates from a fit; You can now construct a multivariate Gaussian p.d.f on the parameters of a model that; represents the result of a fit, from any RooFitResult object. RooAbsPdf* paramPdf = fitresult->createHessePdf(RooArgSet(a,b)) ;. The returned object is an instance of the newly added class RooMultiVarGaussian, that can; model correlated Gaussian distributions in an arbitrary number of dimensions, given a; vector of mean values and a covariance matrix. Class RooMultivarGaussian implements analytical; integration as well as analytical partial integrals over the first 31 dimensions (if you have; that many) and implements in effect internal generation strategy for its observables. A new tutorial macro rf608_fitresultaspdf.C has been added to illustrate the use MV Gaussians constructed from a RooFitResult; Improved functionality",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:11159,Energy Efficiency,reduce,reduce,11159,".d.f on the parameters of a model that; represents the result of a fit, from any RooFitResult object. RooAbsPdf* paramPdf = fitresult->createHessePdf(RooArgSet(a,b)) ;. The returned object is an instance of the newly added class RooMultiVarGaussian, that can; model correlated Gaussian distributions in an arbitrary number of dimensions, given a; vector of mean values and a covariance matrix. Class RooMultivarGaussian implements analytical; integration as well as analytical partial integrals over the first 31 dimensions (if you have; that many) and implements in effect internal generation strategy for its observables. A new tutorial macro rf608_fitresultaspdf.C has been added to illustrate the use MV Gaussians constructed from a RooFitResult; Improved functionality of RooFFTConvPdf; The FFT convolution operator p.d.f. class RooFFTConvPdf has been substantially upgraded; for improved performance has several new options. For the overflow buffering, which aims to reduce cylical spillover from the FFT convolution,; a choice of three algorithms is now provided:. Extend the p.d.f. somewhat beyond its original domain (the new default); Fill the buffer 50/50 with the value of the p.d.f at the upper/lower bound of the convolution observable (the previous default); Mirror the p.d.f. over the boundary. The new default algorithm provides a more sensible result for p.d.f.s with significant; spillover issues, provided that the p.d.f. can be continuated beyond its original domain.; Convolution in non-observables is also explicitly supported now. One can e.g. construct a p.d.f; of the form G(x) = Int[dy] ( F(x,y) (*) H(y) ). A new tutorial macro rf211_paramconv illustrates; how such convolutions can be constructed; It is now also possible to express FFT convolutions in terms of other observables than the; convolution observable itself. A common occurrence of that situation is a (circular) convolution a polar; angle theta, for a p.d.f. that is ultimately expressed in terms of cos(theta",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:14312,Energy Efficiency,efficient,efficiently,14312,"event weights applied squared. Redesign of RooFit dataset class structure. The original class structure of RooFit featured an abstract dataset; class RooAbsData. Inheriting from that was a single class; RooTreeData, which implemented datasets with a ROOT; TTree-based storage implementation, and inheriting from that; two classes RooDataSet , representing unbinned data, and; RooDataHist, representing binned data. A main problem with; this structure was that the implementation of the storage technology; (TTree) and the data representation (binned vs unbinned) were; intertwined. Starting with version 3.00, the class structure has been; rearranged: Now classes RooDataSet and RooDataHist inherit directly; from class RooAbsData, and class RooAbsData now owns an object that; inherits from RooAbsDataStore that implements the storage of the; data. This new class structure allows multiple data storage implementations to; be applied efficiently to both RooDataSet and RooDataHist; At present a single implementation of RooAbsDataStore exists,; class RooTreeDataStore, that contains the storage implementation; formerly implement in class RooTreeData. Methods in class RooTreeData; that were not specific to the storage technology have been moved to; class RooAbsData. If your user code only uses the classes RooDataSet,RooDataHist and RooAbsData; nothing will change: Existing RooDataSets and RooDataHists; (that inherit from RooTreeData) can be read in without problems in; RooFit 3.00 and will be converted on the fly to the new dataset structure; in memory. User code that explicitly uses RooTreeData pointers should; be changed to RooAbsData pointers. This change should be transparent; for all uses, with the exception of the RooTreeData::tree() method.; Explicit access to tree implementation can still be obtained; through the RooTreeDataStore::tree() method. (A pointer to the datastore; can be obtained through the RooAbsData::store() method.); Note that in future releases it is no longer ",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:15938,Energy Efficiency,reduce,reduced,15938,"lems in; RooFit 3.00 and will be converted on the fly to the new dataset structure; in memory. User code that explicitly uses RooTreeData pointers should; be changed to RooAbsData pointers. This change should be transparent; for all uses, with the exception of the RooTreeData::tree() method.; Explicit access to tree implementation can still be obtained; through the RooTreeDataStore::tree() method. (A pointer to the datastore; can be obtained through the RooAbsData::store() method.); Note that in future releases it is no longer guaranteed that all datasets are implemented; with a plain TTree implementation, so any user code that uses the tree; implementation directly should implement checks that the implementation; is indeed tree-based (data->store()->InheritsFrom(RooTreeDataStore::Class())==true)). In future release additional implementations of RooAbsDataStore will; be provided that will support new dataset functionality such as the; ability to construct 'joint' dataset from two input datasets without; the need to copy the input data and 'filtered' datasets that represent; a reduced view (in dimensions or by selecting events) of a dataset; without the need to copy content. Various workspace improvements. A number of smaller and larger improvements has been made to the RooWorkspace class. Direct interactive access to contents from CINT -; One can now directly access the contents of any RooWorkspace; on the ROOT commandline through CINT if the RooWorkspace::exportToCint() call is made.; In CINT, all workspace objects will appear as correctly typed references to workspace objects in; a C++ namespace with the same name as the RooWorkspace object. Given e.g. a workspace w, with a Gaussian p.d.f gauss in terms of variables; x,m,s one can now do. RooWorkspace w(""w"",true) ; // workspace with CINT interface activated; // ... fill workspace with RooGaussian gauss(x,m,s) ...; RooPlot* frame = w::x.frame() ;; w::gauss.plotOn(frame) ;. to access the workspace contents. Each refe",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:19769,Energy Efficiency,power,power,19769,"brackets create variables (discrete and continuous). ""m[-10,10]"" - Creates a RooRealVar named 'm' with range [-10,10]; ""m[5,-10,10]"" - Idem, but with initial value 5; ""m[5]"" - Creates a constant RooRealVar with name 'm' and value 5. ""tagCat[Lep,Kao,NT1,NT2]"" -- Creates a RooCategory with name tagCat and labeled states Lep,Kao,NT1,NT2; ""b0flav[B0=1,B0bar=-1]"" -- Creates a RooCategory with name b0flav and states B0 and B0bar with explicit index assignments. Expressions with parentheses create RooAbsArg function objects of any type. ""RooGaussian::g(x,m,s)"" -- Create a RooGaussian named g with variables x,m,s; This expression maps 1-1 to a createArg() call. ""Gaussian::g(x,m,s)"" -- Idem. The 'Roo' prefix on any class may be omitted. ""Gaussian(x,m,s)"" -- Create a RooGaussian with an automatically assigned name with variables x,m,s. Expressions with curly brackets creates RooArgSets or RooArgLists ""{x,y,z}"". Compound expressions; The real power of this language is that all these expressions may be nested to result in a compact; and readable expression that creates an entire p.d.f. and its components. ""Gaussian::g(x[-10,10],m[-10,10],3)"". Creates a RooGaussian named 'g', its observables 'x' with range [-10,10],; its parameter 'm' with range [-10,10]' and a constant width of 3. ""SUM::model( f[0.5,0,1] * Gaussian( x[-10,10], m[0], 3] ),; Chebychev( x, {a0[0.1],a1[0.2],a2[-0.3]}))"". Create a RooAddPdf model of a RooGaussian and a RooChebychev (which; are implicitly named model_0 and model_1), its observable x and its; parameters m,a0,a1,a2,Nsig and Nbkg; Note that each object may be created only once (with [] or () brackets) but may be referenced multiple; times in the expression by just giving the name. Here is a much more complicated example:. ""PROD::sig(BMixDecay::sig_t( dt[-20,20], mixState[mixed=1,unmix=-1], tagFlav[B0=1,B0bar=-1],; tau[1.54], dm[0.472], w[0.05], dw[0],; AddModel({GaussModel(dt,biasC[-10,10],sigmaC[0.1,3],dterr[0.01,0.2]),; GaussModel(dt,0,sigmaT[3,10]),;",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:21173,Energy Efficiency,energy,energy,21173,"ev( x, {a0[0.1],a1[0.2],a2[-0.3]}))"". Create a RooAddPdf model of a RooGaussian and a RooChebychev (which; are implicitly named model_0 and model_1), its observable x and its; parameters m,a0,a1,a2,Nsig and Nbkg; Note that each object may be created only once (with [] or () brackets) but may be referenced multiple; times in the expression by just giving the name. Here is a much more complicated example:. ""PROD::sig(BMixDecay::sig_t( dt[-20,20], mixState[mixed=1,unmix=-1], tagFlav[B0=1,B0bar=-1],; tau[1.54], dm[0.472], w[0.05], dw[0],; AddModel({GaussModel(dt,biasC[-10,10],sigmaC[0.1,3],dterr[0.01,0.2]),; GaussModel(dt,0,sigmaT[3,10]),; GaussModel(dt,0,20)},{fracC[0,1],fracT[0,1]}),; DoubleSided ),; Gaussian::sig_m( mes[5.20,5.30], mB0[5.20,5.30], sigmB0[0.01,0.05] )"". This create a double-sided Bmixing decay p.d.f. with observables dt,; per-event error dterr and all its parameters, convoluted with a triple; gaussian resolution model and multiplied with a Gaussian p.d.f. in the; energy substituted mass. (In plain RooFit this would have required at; least 23 lines of code). A series of three new tutorial macros has been added to illustrate the; various features of the object factory. rf511_wsfactory_basic.C - Basic factory concepts; rf512_wsfactory_oper.C - Using operator p.d.f.s in the factory; rf513_wsfactory_tools.C - Advanced example using interfaced high level tools. A formal transaction model is used to commit composite objects into; the workspace. If an error is detected in the expression, no objects; will be committed to the workspace, thus leaving no 'partial builds'. Compact demo of several new major features. The macro below demonstrates in a couple of lines a number of major new features in RooFit 3.00: Use of. workspace factory to quickly create and store (compiled) models; workspace CINT interface to easily access contents in a typesafe way; new adaptive ND numeric integration technique to normalize arbitrary p.d.f. in fast; and reliable way; new adaptive",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:22070,Energy Efficiency,adapt,adaptive,22070,"event error dterr and all its parameters, convoluted with a triple; gaussian resolution model and multiplied with a Gaussian p.d.f. in the; energy substituted mass. (In plain RooFit this would have required at; least 23 lines of code). A series of three new tutorial macros has been added to illustrate the; various features of the object factory. rf511_wsfactory_basic.C - Basic factory concepts; rf512_wsfactory_oper.C - Using operator p.d.f.s in the factory; rf513_wsfactory_tools.C - Advanced example using interfaced high level tools. A formal transaction model is used to commit composite objects into; the workspace. If an error is detected in the expression, no objects; will be committed to the workspace, thus leaving no 'partial builds'. Compact demo of several new major features. The macro below demonstrates in a couple of lines a number of major new features in RooFit 3.00: Use of. workspace factory to quickly create and store (compiled) models; workspace CINT interface to easily access contents in a typesafe way; new adaptive ND numeric integration technique to normalize arbitrary p.d.f. in fast; and reliable way; new adaptive TFoam sampling technique to efficiently generate toy MC data from strongly; peaked datasets; parallel processing in likelihood construction and use of profile likelihood operator; to represent profile likelihoods as regular RooFit functions. void demo(); {; // Construct compiled 2-D model that requires numeric integration for normalization; RooWorkspace w(""w"",1) ;; w.factory(""CEXPR::model('1/((x-a)*(x-a)+0.001)+1/((y-b)*(y-b)+0.001)',x[-1,1],y[-1,1],a[-5,5],b[-5,5])"") ;. // Generate data from model (using TFoam adaptive sampling algorithm); RooDataSet* d = w::model.generate(RooArgSet(w::x,w::y),1000) ;; w::model.fitTo(*d) ;. // Make 2D plot on (x,y); TH2* hh = w::model.createHistogram(""x,y"",40,40) ;; hh->SetLineColor(kBlue) ;. // Make Projection on x (integrate over y); RooPlot* framex = w::x.frame(Title(""Data and p.d.f. projected on X"")) ;",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:22173,Energy Efficiency,adapt,adaptive,22173,"hree new tutorial macros has been added to illustrate the; various features of the object factory. rf511_wsfactory_basic.C - Basic factory concepts; rf512_wsfactory_oper.C - Using operator p.d.f.s in the factory; rf513_wsfactory_tools.C - Advanced example using interfaced high level tools. A formal transaction model is used to commit composite objects into; the workspace. If an error is detected in the expression, no objects; will be committed to the workspace, thus leaving no 'partial builds'. Compact demo of several new major features. The macro below demonstrates in a couple of lines a number of major new features in RooFit 3.00: Use of. workspace factory to quickly create and store (compiled) models; workspace CINT interface to easily access contents in a typesafe way; new adaptive ND numeric integration technique to normalize arbitrary p.d.f. in fast; and reliable way; new adaptive TFoam sampling technique to efficiently generate toy MC data from strongly; peaked datasets; parallel processing in likelihood construction and use of profile likelihood operator; to represent profile likelihoods as regular RooFit functions. void demo(); {; // Construct compiled 2-D model that requires numeric integration for normalization; RooWorkspace w(""w"",1) ;; w.factory(""CEXPR::model('1/((x-a)*(x-a)+0.001)+1/((y-b)*(y-b)+0.001)',x[-1,1],y[-1,1],a[-5,5],b[-5,5])"") ;. // Generate data from model (using TFoam adaptive sampling algorithm); RooDataSet* d = w::model.generate(RooArgSet(w::x,w::y),1000) ;; w::model.fitTo(*d) ;. // Make 2D plot on (x,y); TH2* hh = w::model.createHistogram(""x,y"",40,40) ;; hh->SetLineColor(kBlue) ;. // Make Projection on x (integrate over y); RooPlot* framex = w::x.frame(Title(""Data and p.d.f. projected on X"")) ;; d->plotOn(framex) ;; w::model.plotOn(framex) ;. // Construct likelihood, profile likelihood in a, and draw the latter; RooAbsReal* nll = w::model.createNLL(*d,NumCPU(2)) ;; RooAbsReal* pll = nll->createProfile(w::a) ;; RooPlot* framea = w::a.fram",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:22210,Energy Efficiency,efficient,efficiently,22210,"hree new tutorial macros has been added to illustrate the; various features of the object factory. rf511_wsfactory_basic.C - Basic factory concepts; rf512_wsfactory_oper.C - Using operator p.d.f.s in the factory; rf513_wsfactory_tools.C - Advanced example using interfaced high level tools. A formal transaction model is used to commit composite objects into; the workspace. If an error is detected in the expression, no objects; will be committed to the workspace, thus leaving no 'partial builds'. Compact demo of several new major features. The macro below demonstrates in a couple of lines a number of major new features in RooFit 3.00: Use of. workspace factory to quickly create and store (compiled) models; workspace CINT interface to easily access contents in a typesafe way; new adaptive ND numeric integration technique to normalize arbitrary p.d.f. in fast; and reliable way; new adaptive TFoam sampling technique to efficiently generate toy MC data from strongly; peaked datasets; parallel processing in likelihood construction and use of profile likelihood operator; to represent profile likelihoods as regular RooFit functions. void demo(); {; // Construct compiled 2-D model that requires numeric integration for normalization; RooWorkspace w(""w"",1) ;; w.factory(""CEXPR::model('1/((x-a)*(x-a)+0.001)+1/((y-b)*(y-b)+0.001)',x[-1,1],y[-1,1],a[-5,5],b[-5,5])"") ;. // Generate data from model (using TFoam adaptive sampling algorithm); RooDataSet* d = w::model.generate(RooArgSet(w::x,w::y),1000) ;; w::model.fitTo(*d) ;. // Make 2D plot on (x,y); TH2* hh = w::model.createHistogram(""x,y"",40,40) ;; hh->SetLineColor(kBlue) ;. // Make Projection on x (integrate over y); RooPlot* framex = w::x.frame(Title(""Data and p.d.f. projected on X"")) ;; d->plotOn(framex) ;; w::model.plotOn(framex) ;. // Construct likelihood, profile likelihood in a, and draw the latter; RooAbsReal* nll = w::model.createNLL(*d,NumCPU(2)) ;; RooAbsReal* pll = nll->createProfile(w::a) ;; RooPlot* framea = w::a.fram",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:22699,Energy Efficiency,adapt,adaptive,22699,"jects; will be committed to the workspace, thus leaving no 'partial builds'. Compact demo of several new major features. The macro below demonstrates in a couple of lines a number of major new features in RooFit 3.00: Use of. workspace factory to quickly create and store (compiled) models; workspace CINT interface to easily access contents in a typesafe way; new adaptive ND numeric integration technique to normalize arbitrary p.d.f. in fast; and reliable way; new adaptive TFoam sampling technique to efficiently generate toy MC data from strongly; peaked datasets; parallel processing in likelihood construction and use of profile likelihood operator; to represent profile likelihoods as regular RooFit functions. void demo(); {; // Construct compiled 2-D model that requires numeric integration for normalization; RooWorkspace w(""w"",1) ;; w.factory(""CEXPR::model('1/((x-a)*(x-a)+0.001)+1/((y-b)*(y-b)+0.001)',x[-1,1],y[-1,1],a[-5,5],b[-5,5])"") ;. // Generate data from model (using TFoam adaptive sampling algorithm); RooDataSet* d = w::model.generate(RooArgSet(w::x,w::y),1000) ;; w::model.fitTo(*d) ;. // Make 2D plot on (x,y); TH2* hh = w::model.createHistogram(""x,y"",40,40) ;; hh->SetLineColor(kBlue) ;. // Make Projection on x (integrate over y); RooPlot* framex = w::x.frame(Title(""Data and p.d.f. projected on X"")) ;; d->plotOn(framex) ;; w::model.plotOn(framex) ;. // Construct likelihood, profile likelihood in a, and draw the latter; RooAbsReal* nll = w::model.createNLL(*d,NumCPU(2)) ;; RooAbsReal* pll = nll->createProfile(w::a) ;; RooPlot* framea = w::a.frame(Title(""Profile likelihood in parameter a"")) ;; pll->plotOn(framea) ;. // Construct 2D cumulative distribution function from p.d.f.; RooAbsReal* cdfxy = w::model.createCdf(RooArgSet(w::x,w::y),ScanNoCdf()) ;; TH2* hhcdf = cdfxy->createHistogram(""x,y"",40,40) ;; hhcdf->SetLineColor(kRed) ;. TCanvas* c = new TCanvas(""c"",""c"",650,650) ; c->Divide(2,2) ;; c->cd(1) ; hh->Draw(""surf"") ; c->cd(2) ; framex->Draw() ;; c->cd(3) ; f",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:26296,Energy Efficiency,power,powerful,26296,"culator with a Poisson problem, reproduces; results from table IV and V of the original; paper�Phys.Rev.D57:3873-3889,1998.; rs401d_FeldmanCousins.C Demonstrates use of; FeldmanCousins interval calculator with the neutrino oscillation toy; example described in the original paper�Phys.Rev.D57:3873-3889,1998.; Reproduces figure 12.; rs_bernsteinCorrection.C Demonstrates use of; BernsteinCorrection class, which corrects a nominal PDF with a polynomial; to agree with observed or simulated data. TestStatistic interface and implementations; We added a new interface class called TestStatistic. It defines the; method Evaluate(data, parameterPoint), which returns a double. �This; class can be used in�conjunction�with the ToyMCSampler class to generate; sampling distributions for a user-defined test statistic. �; The following concrete implementations of the TestStatistic interface; are currently available. ProfileLikelihoodTestStatReturns the log of profile; likelihood ratio. �Generally a powerful test statistic. ; NumEventsTestStatReturns the number of events in the; dataset. �Useful for number counting experiments.; DebuggingTestStat Simply returns a uniform random number; between 0,1. �Useful for debugging. SamplingDistribution and the�TestStatSampler interface and; implementations; We introduced a ``result'' or data model class called; SamplingDistribution, which holds the sampling distribution of an; arbitrary real valued test statistic. �The class also can return the; inverse of the cumulative distribution function (with or without; interpolation). �; We introduced an interface for any tool that can produce a; SamplingDistribution, called TestStatSampler. �The interface is; essentially GetSamplingDistribution(parameterPoint) which returns a; SamplingDistribution based on a given probability density function. �We; foresee a few versions of this tool based on toy Monte Carlo, importance; sampling, Fourier transforms, etc. �The following concrete implementation; of the Te",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:28193,Energy Efficiency,charge,charge,28193,"ampling, Fourier transforms, etc. �The following concrete implementation; of the TestStatSampler interface are currently available. ToyMCSamplerUses a Toy Monte Carlo approach to build the; sampling distribution. �The pdf's generate method to generate is used to; generate toy data, and then the test statistic is evaluated at the; requested parameter point. ; DebuggingSampler Simply returns a uniform distribution; between 0,1. �Useful for debugging. NeymanConstruction and FeldmanCousins; A flexible framework for the Neyman Construction was added in this; release. The NeymanConstruction is a concrete implementation of the; IntervalCalculator interface, but it needs several; additional components�to be specified before use. The design; factorizes the choice of the parameter points to be tested,�the choice of; the test statistic, and the generation of sampling distribution into; separate parts (described above). �Finally, the NeymanConstruction class; is simply in charge of using these parts (strategies) and constructing; the confidence belt and confidence intervals. �The ConfidenceBelt class; is still under development, but the current version works fine for; producing ConfidenceIntervals. �We are also working to make this class; work with parallelization approaches, which is not yet complete.; The FeldmanCousins class is a separate concrete implementation of the; IntervalCalculator interface. �It uses the NeymanConstruction internally,; and�enforces�specific choices of the test statistic and ordering; principle to realize the Unified intervals described by Feldman and; Cousins in their paper�Phys.Rev.D57:3873-3889,1998. In an extension to the technique discussed in Feldman and Cousins paper,; the FeldmanCousins class also performs a ""profile construction"" if their are nuisance parameters.; In this case, the parameters of interest are scanned in a regular grid. For each point in the grid; the calculator finds the best fit value of the nuisance parameters (given the dat",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:2602,Integrability,interface,interface,2602,"determined by calculating a central interval that capture N% of the; variations for each value of x, where N% is controlled by Z (i.e. Z=1; gives N=68%). The number of sampling curves is chosen to be such that; at least 100 curves are expected to be outside the N% interval. Intervals from; the sampling method can be asymmetric, and may perform better in the; presence of strong correlations, but may take (much) longer to; calculate. The sampling method also assumes that the uncertainty on the; parameters can modeled by a multi-variate Gaussian distribution. A complete example is provided in a new tutorial macro rf610_visualerror.C,; the output of which is shown below. It is also possible to visualize partial errors (from a subset of the parameters),; as shown above. Binned dataset generation. A new method RooAbsPdf::generateBinned() has been implemented; that samples binned datasets (RooDataHist) from any; p.d.f. RooDataHist* data = pdf.generateBinned(x,10000) ;. This binned generation interface samples the p.d.f. at each bin; center and applies a Poisson fluctuation to each sampled value.; The binning of the returned RooDataHist is controlled by the default; binning associated with the observables generated. To set the number; of bins in x to 200, do e.g. x.setBins(200) prior to the call; to generateBinned(). The binned dataset generation method does not (yet) support the concept of; prototype datasets. New minimizer interface to Minuit2, GSLMinimizer etc... A new minimizer interface, RooMinimizer has been added (contribution; from Alfio Lazarro). The new minimizer is similar in functionality to; the existing class RooMinuit, but supports the new ROOT abstract; minimizer interface and supports multiple minimizer packages and algorithms; through that interface. The present interface of RooMinimizer is identical to that of RooMinuit; with two extensions. The setMinimizer(const char*) method allows to choose between ""minuit"" and ""minuit2""); as implementation for migrad",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:3043,Integrability,interface,interface,3043,"od also assumes that the uncertainty on the; parameters can modeled by a multi-variate Gaussian distribution. A complete example is provided in a new tutorial macro rf610_visualerror.C,; the output of which is shown below. It is also possible to visualize partial errors (from a subset of the parameters),; as shown above. Binned dataset generation. A new method RooAbsPdf::generateBinned() has been implemented; that samples binned datasets (RooDataHist) from any; p.d.f. RooDataHist* data = pdf.generateBinned(x,10000) ;. This binned generation interface samples the p.d.f. at each bin; center and applies a Poisson fluctuation to each sampled value.; The binning of the returned RooDataHist is controlled by the default; binning associated with the observables generated. To set the number; of bins in x to 200, do e.g. x.setBins(200) prior to the call; to generateBinned(). The binned dataset generation method does not (yet) support the concept of; prototype datasets. New minimizer interface to Minuit2, GSLMinimizer etc... A new minimizer interface, RooMinimizer has been added (contribution; from Alfio Lazarro). The new minimizer is similar in functionality to; the existing class RooMinuit, but supports the new ROOT abstract; minimizer interface and supports multiple minimizer packages and algorithms; through that interface. The present interface of RooMinimizer is identical to that of RooMinuit; with two extensions. The setMinimizer(const char*) method allows to choose between ""minuit"" and ""minuit2""); as implementation for migrad(),hesse(),minos() etc...; The minimizer(const char* package, const char* alg) provides a completely generic interface; to all minimizers, where package is the package (minuit,GSLminimizer) and alg is the algorithm (migrad) to be used. By default, RooMinuit is still used when RooAbsPdf::fitTo() is called, but can be overridden with; a Minimizer() named argument. // Minimization with MINUIT/MIGRAD through RooMinuit; pdf->fitTo(data) ;. // Minimizatio",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:3101,Integrability,interface,interface,3101,"ulti-variate Gaussian distribution. A complete example is provided in a new tutorial macro rf610_visualerror.C,; the output of which is shown below. It is also possible to visualize partial errors (from a subset of the parameters),; as shown above. Binned dataset generation. A new method RooAbsPdf::generateBinned() has been implemented; that samples binned datasets (RooDataHist) from any; p.d.f. RooDataHist* data = pdf.generateBinned(x,10000) ;. This binned generation interface samples the p.d.f. at each bin; center and applies a Poisson fluctuation to each sampled value.; The binning of the returned RooDataHist is controlled by the default; binning associated with the observables generated. To set the number; of bins in x to 200, do e.g. x.setBins(200) prior to the call; to generateBinned(). The binned dataset generation method does not (yet) support the concept of; prototype datasets. New minimizer interface to Minuit2, GSLMinimizer etc... A new minimizer interface, RooMinimizer has been added (contribution; from Alfio Lazarro). The new minimizer is similar in functionality to; the existing class RooMinuit, but supports the new ROOT abstract; minimizer interface and supports multiple minimizer packages and algorithms; through that interface. The present interface of RooMinimizer is identical to that of RooMinuit; with two extensions. The setMinimizer(const char*) method allows to choose between ""minuit"" and ""minuit2""); as implementation for migrad(),hesse(),minos() etc...; The minimizer(const char* package, const char* alg) provides a completely generic interface; to all minimizers, where package is the package (minuit,GSLminimizer) and alg is the algorithm (migrad) to be used. By default, RooMinuit is still used when RooAbsPdf::fitTo() is called, but can be overridden with; a Minimizer() named argument. // Minimization with MINUIT/MIGRAD through RooMinuit; pdf->fitTo(data) ;. // Minimization with MINUIT/MIGRAD through RooMinimizer; pdf->fitTo(data,Minimizer(""minui",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:3302,Integrability,interface,interface,3302," also possible to visualize partial errors (from a subset of the parameters),; as shown above. Binned dataset generation. A new method RooAbsPdf::generateBinned() has been implemented; that samples binned datasets (RooDataHist) from any; p.d.f. RooDataHist* data = pdf.generateBinned(x,10000) ;. This binned generation interface samples the p.d.f. at each bin; center and applies a Poisson fluctuation to each sampled value.; The binning of the returned RooDataHist is controlled by the default; binning associated with the observables generated. To set the number; of bins in x to 200, do e.g. x.setBins(200) prior to the call; to generateBinned(). The binned dataset generation method does not (yet) support the concept of; prototype datasets. New minimizer interface to Minuit2, GSLMinimizer etc... A new minimizer interface, RooMinimizer has been added (contribution; from Alfio Lazarro). The new minimizer is similar in functionality to; the existing class RooMinuit, but supports the new ROOT abstract; minimizer interface and supports multiple minimizer packages and algorithms; through that interface. The present interface of RooMinimizer is identical to that of RooMinuit; with two extensions. The setMinimizer(const char*) method allows to choose between ""minuit"" and ""minuit2""); as implementation for migrad(),hesse(),minos() etc...; The minimizer(const char* package, const char* alg) provides a completely generic interface; to all minimizers, where package is the package (minuit,GSLminimizer) and alg is the algorithm (migrad) to be used. By default, RooMinuit is still used when RooAbsPdf::fitTo() is called, but can be overridden with; a Minimizer() named argument. // Minimization with MINUIT/MIGRAD through RooMinuit; pdf->fitTo(data) ;. // Minimization with MINUIT/MIGRAD through RooMinimizer; pdf->fitTo(data,Minimizer(""minuit"")) ;. // Minimization with MINUIT2/MIGRAD through RooMinimizer; pdf->fitTo(data,Minimizer(""minuit2"")) ;. // Minimization with GSLMultiMin/conjugatefr th",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:3382,Integrability,interface,interface,3382," also possible to visualize partial errors (from a subset of the parameters),; as shown above. Binned dataset generation. A new method RooAbsPdf::generateBinned() has been implemented; that samples binned datasets (RooDataHist) from any; p.d.f. RooDataHist* data = pdf.generateBinned(x,10000) ;. This binned generation interface samples the p.d.f. at each bin; center and applies a Poisson fluctuation to each sampled value.; The binning of the returned RooDataHist is controlled by the default; binning associated with the observables generated. To set the number; of bins in x to 200, do e.g. x.setBins(200) prior to the call; to generateBinned(). The binned dataset generation method does not (yet) support the concept of; prototype datasets. New minimizer interface to Minuit2, GSLMinimizer etc... A new minimizer interface, RooMinimizer has been added (contribution; from Alfio Lazarro). The new minimizer is similar in functionality to; the existing class RooMinuit, but supports the new ROOT abstract; minimizer interface and supports multiple minimizer packages and algorithms; through that interface. The present interface of RooMinimizer is identical to that of RooMinuit; with two extensions. The setMinimizer(const char*) method allows to choose between ""minuit"" and ""minuit2""); as implementation for migrad(),hesse(),minos() etc...; The minimizer(const char* package, const char* alg) provides a completely generic interface; to all minimizers, where package is the package (minuit,GSLminimizer) and alg is the algorithm (migrad) to be used. By default, RooMinuit is still used when RooAbsPdf::fitTo() is called, but can be overridden with; a Minimizer() named argument. // Minimization with MINUIT/MIGRAD through RooMinuit; pdf->fitTo(data) ;. // Minimization with MINUIT/MIGRAD through RooMinimizer; pdf->fitTo(data,Minimizer(""minuit"")) ;. // Minimization with MINUIT2/MIGRAD through RooMinimizer; pdf->fitTo(data,Minimizer(""minuit2"")) ;. // Minimization with GSLMultiMin/conjugatefr th",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:3405,Integrability,interface,interface,3405,"nned() has been implemented; that samples binned datasets (RooDataHist) from any; p.d.f. RooDataHist* data = pdf.generateBinned(x,10000) ;. This binned generation interface samples the p.d.f. at each bin; center and applies a Poisson fluctuation to each sampled value.; The binning of the returned RooDataHist is controlled by the default; binning associated with the observables generated. To set the number; of bins in x to 200, do e.g. x.setBins(200) prior to the call; to generateBinned(). The binned dataset generation method does not (yet) support the concept of; prototype datasets. New minimizer interface to Minuit2, GSLMinimizer etc... A new minimizer interface, RooMinimizer has been added (contribution; from Alfio Lazarro). The new minimizer is similar in functionality to; the existing class RooMinuit, but supports the new ROOT abstract; minimizer interface and supports multiple minimizer packages and algorithms; through that interface. The present interface of RooMinimizer is identical to that of RooMinuit; with two extensions. The setMinimizer(const char*) method allows to choose between ""minuit"" and ""minuit2""); as implementation for migrad(),hesse(),minos() etc...; The minimizer(const char* package, const char* alg) provides a completely generic interface; to all minimizers, where package is the package (minuit,GSLminimizer) and alg is the algorithm (migrad) to be used. By default, RooMinuit is still used when RooAbsPdf::fitTo() is called, but can be overridden with; a Minimizer() named argument. // Minimization with MINUIT/MIGRAD through RooMinuit; pdf->fitTo(data) ;. // Minimization with MINUIT/MIGRAD through RooMinimizer; pdf->fitTo(data,Minimizer(""minuit"")) ;. // Minimization with MINUIT2/MIGRAD through RooMinimizer; pdf->fitTo(data,Minimizer(""minuit2"")) ;. // Minimization with GSLMultiMin/conjugatefr through RooMinimizer; pdf->fitTo(data,Minimizer(""GSLMultiMin"",""conjugatefr"")) ;. Note that installation of GSL and the ROOT MathMore package is needed to acc",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:3711,Integrability,interface,interface,3711,"rned RooDataHist is controlled by the default; binning associated with the observables generated. To set the number; of bins in x to 200, do e.g. x.setBins(200) prior to the call; to generateBinned(). The binned dataset generation method does not (yet) support the concept of; prototype datasets. New minimizer interface to Minuit2, GSLMinimizer etc... A new minimizer interface, RooMinimizer has been added (contribution; from Alfio Lazarro). The new minimizer is similar in functionality to; the existing class RooMinuit, but supports the new ROOT abstract; minimizer interface and supports multiple minimizer packages and algorithms; through that interface. The present interface of RooMinimizer is identical to that of RooMinuit; with two extensions. The setMinimizer(const char*) method allows to choose between ""minuit"" and ""minuit2""); as implementation for migrad(),hesse(),minos() etc...; The minimizer(const char* package, const char* alg) provides a completely generic interface; to all minimizers, where package is the package (minuit,GSLminimizer) and alg is the algorithm (migrad) to be used. By default, RooMinuit is still used when RooAbsPdf::fitTo() is called, but can be overridden with; a Minimizer() named argument. // Minimization with MINUIT/MIGRAD through RooMinuit; pdf->fitTo(data) ;. // Minimization with MINUIT/MIGRAD through RooMinimizer; pdf->fitTo(data,Minimizer(""minuit"")) ;. // Minimization with MINUIT2/MIGRAD through RooMinimizer; pdf->fitTo(data,Minimizer(""minuit2"")) ;. // Minimization with GSLMultiMin/conjugatefr through RooMinimizer; pdf->fitTo(data,Minimizer(""GSLMultiMin"",""conjugatefr"")) ;. Note that installation of GSL and the ROOT MathMore package is needed to access the GSL Minimizers and that the GSL; Minimizer do not implement error analysis. New numeric integration algorithms available; RooFit can now interface all MathCore numeric integration; algorithms. In this release ROOT::Math::AdaptiveIntegratorMultiDim,; which implements the 'Genz & Malik'",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:4535,Integrability,integrat,integration,4535,"lementation for migrad(),hesse(),minos() etc...; The minimizer(const char* package, const char* alg) provides a completely generic interface; to all minimizers, where package is the package (minuit,GSLminimizer) and alg is the algorithm (migrad) to be used. By default, RooMinuit is still used when RooAbsPdf::fitTo() is called, but can be overridden with; a Minimizer() named argument. // Minimization with MINUIT/MIGRAD through RooMinuit; pdf->fitTo(data) ;. // Minimization with MINUIT/MIGRAD through RooMinimizer; pdf->fitTo(data,Minimizer(""minuit"")) ;. // Minimization with MINUIT2/MIGRAD through RooMinimizer; pdf->fitTo(data,Minimizer(""minuit2"")) ;. // Minimization with GSLMultiMin/conjugatefr through RooMinimizer; pdf->fitTo(data,Minimizer(""GSLMultiMin"",""conjugatefr"")) ;. Note that installation of GSL and the ROOT MathMore package is needed to access the GSL Minimizers and that the GSL; Minimizer do not implement error analysis. New numeric integration algorithms available; RooFit can now interface all MathCore numeric integration; algorithms. In this release ROOT::Math::AdaptiveIntegratorMultiDim,; which implements the 'Genz & Malik' algorithm has been interfaced; in RooAdaptiveIntegratorND and is now the default numeric integrator; for numeric integrations in two or more dimensions. This new default integrator has much improved stability and speed; for relatively smooth p.d.f.s in two or three dimensions and can; generally be used well for p.d.f. normalization integrals without; causing MINUIT converge problems due to numeric precision issues. In future release some more numeric integrators will be migrated to; a MathCore implementation. Interface to TFoam adaptive MC sampler added; RooFit can now use the TFoam adaptive MC sampler for event generation of p.d.f.s that; do not have an internal generator. The TFoam generator adaptively subdivides the; observable space and is generally more efficient both warmup and generation than the original; RooAcceptReject algorit",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:4584,Integrability,interface,interface,4584,"lementation for migrad(),hesse(),minos() etc...; The minimizer(const char* package, const char* alg) provides a completely generic interface; to all minimizers, where package is the package (minuit,GSLminimizer) and alg is the algorithm (migrad) to be used. By default, RooMinuit is still used when RooAbsPdf::fitTo() is called, but can be overridden with; a Minimizer() named argument. // Minimization with MINUIT/MIGRAD through RooMinuit; pdf->fitTo(data) ;. // Minimization with MINUIT/MIGRAD through RooMinimizer; pdf->fitTo(data,Minimizer(""minuit"")) ;. // Minimization with MINUIT2/MIGRAD through RooMinimizer; pdf->fitTo(data,Minimizer(""minuit2"")) ;. // Minimization with GSLMultiMin/conjugatefr through RooMinimizer; pdf->fitTo(data,Minimizer(""GSLMultiMin"",""conjugatefr"")) ;. Note that installation of GSL and the ROOT MathMore package is needed to access the GSL Minimizers and that the GSL; Minimizer do not implement error analysis. New numeric integration algorithms available; RooFit can now interface all MathCore numeric integration; algorithms. In this release ROOT::Math::AdaptiveIntegratorMultiDim,; which implements the 'Genz & Malik' algorithm has been interfaced; in RooAdaptiveIntegratorND and is now the default numeric integrator; for numeric integrations in two or more dimensions. This new default integrator has much improved stability and speed; for relatively smooth p.d.f.s in two or three dimensions and can; generally be used well for p.d.f. normalization integrals without; causing MINUIT converge problems due to numeric precision issues. In future release some more numeric integrators will be migrated to; a MathCore implementation. Interface to TFoam adaptive MC sampler added; RooFit can now use the TFoam adaptive MC sampler for event generation of p.d.f.s that; do not have an internal generator. The TFoam generator adaptively subdivides the; observable space and is generally more efficient both warmup and generation than the original; RooAcceptReject algorit",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:4615,Integrability,integrat,integration,4615,"lementation for migrad(),hesse(),minos() etc...; The minimizer(const char* package, const char* alg) provides a completely generic interface; to all minimizers, where package is the package (minuit,GSLminimizer) and alg is the algorithm (migrad) to be used. By default, RooMinuit is still used when RooAbsPdf::fitTo() is called, but can be overridden with; a Minimizer() named argument. // Minimization with MINUIT/MIGRAD through RooMinuit; pdf->fitTo(data) ;. // Minimization with MINUIT/MIGRAD through RooMinimizer; pdf->fitTo(data,Minimizer(""minuit"")) ;. // Minimization with MINUIT2/MIGRAD through RooMinimizer; pdf->fitTo(data,Minimizer(""minuit2"")) ;. // Minimization with GSLMultiMin/conjugatefr through RooMinimizer; pdf->fitTo(data,Minimizer(""GSLMultiMin"",""conjugatefr"")) ;. Note that installation of GSL and the ROOT MathMore package is needed to access the GSL Minimizers and that the GSL; Minimizer do not implement error analysis. New numeric integration algorithms available; RooFit can now interface all MathCore numeric integration; algorithms. In this release ROOT::Math::AdaptiveIntegratorMultiDim,; which implements the 'Genz & Malik' algorithm has been interfaced; in RooAdaptiveIntegratorND and is now the default numeric integrator; for numeric integrations in two or more dimensions. This new default integrator has much improved stability and speed; for relatively smooth p.d.f.s in two or three dimensions and can; generally be used well for p.d.f. normalization integrals without; causing MINUIT converge problems due to numeric precision issues. In future release some more numeric integrators will be migrated to; a MathCore implementation. Interface to TFoam adaptive MC sampler added; RooFit can now use the TFoam adaptive MC sampler for event generation of p.d.f.s that; do not have an internal generator. The TFoam generator adaptively subdivides the; observable space and is generally more efficient both warmup and generation than the original; RooAcceptReject algorit",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:4752,Integrability,interface,interfaced,4752,"package (minuit,GSLminimizer) and alg is the algorithm (migrad) to be used. By default, RooMinuit is still used when RooAbsPdf::fitTo() is called, but can be overridden with; a Minimizer() named argument. // Minimization with MINUIT/MIGRAD through RooMinuit; pdf->fitTo(data) ;. // Minimization with MINUIT/MIGRAD through RooMinimizer; pdf->fitTo(data,Minimizer(""minuit"")) ;. // Minimization with MINUIT2/MIGRAD through RooMinimizer; pdf->fitTo(data,Minimizer(""minuit2"")) ;. // Minimization with GSLMultiMin/conjugatefr through RooMinimizer; pdf->fitTo(data,Minimizer(""GSLMultiMin"",""conjugatefr"")) ;. Note that installation of GSL and the ROOT MathMore package is needed to access the GSL Minimizers and that the GSL; Minimizer do not implement error analysis. New numeric integration algorithms available; RooFit can now interface all MathCore numeric integration; algorithms. In this release ROOT::Math::AdaptiveIntegratorMultiDim,; which implements the 'Genz & Malik' algorithm has been interfaced; in RooAdaptiveIntegratorND and is now the default numeric integrator; for numeric integrations in two or more dimensions. This new default integrator has much improved stability and speed; for relatively smooth p.d.f.s in two or three dimensions and can; generally be used well for p.d.f. normalization integrals without; causing MINUIT converge problems due to numeric precision issues. In future release some more numeric integrators will be migrated to; a MathCore implementation. Interface to TFoam adaptive MC sampler added; RooFit can now use the TFoam adaptive MC sampler for event generation of p.d.f.s that; do not have an internal generator. The TFoam generator adaptively subdivides the; observable space and is generally more efficient both warmup and generation than the original; RooAcceptReject algorithm. In its current interface in RooFit, TFoam cannot; handle problems yet with discrete observables or conditional observables. For those problems; the original RooAcceptReject gene",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:4822,Integrability,integrat,integrator,4822,"package (minuit,GSLminimizer) and alg is the algorithm (migrad) to be used. By default, RooMinuit is still used when RooAbsPdf::fitTo() is called, but can be overridden with; a Minimizer() named argument. // Minimization with MINUIT/MIGRAD through RooMinuit; pdf->fitTo(data) ;. // Minimization with MINUIT/MIGRAD through RooMinimizer; pdf->fitTo(data,Minimizer(""minuit"")) ;. // Minimization with MINUIT2/MIGRAD through RooMinimizer; pdf->fitTo(data,Minimizer(""minuit2"")) ;. // Minimization with GSLMultiMin/conjugatefr through RooMinimizer; pdf->fitTo(data,Minimizer(""GSLMultiMin"",""conjugatefr"")) ;. Note that installation of GSL and the ROOT MathMore package is needed to access the GSL Minimizers and that the GSL; Minimizer do not implement error analysis. New numeric integration algorithms available; RooFit can now interface all MathCore numeric integration; algorithms. In this release ROOT::Math::AdaptiveIntegratorMultiDim,; which implements the 'Genz & Malik' algorithm has been interfaced; in RooAdaptiveIntegratorND and is now the default numeric integrator; for numeric integrations in two or more dimensions. This new default integrator has much improved stability and speed; for relatively smooth p.d.f.s in two or three dimensions and can; generally be used well for p.d.f. normalization integrals without; causing MINUIT converge problems due to numeric precision issues. In future release some more numeric integrators will be migrated to; a MathCore implementation. Interface to TFoam adaptive MC sampler added; RooFit can now use the TFoam adaptive MC sampler for event generation of p.d.f.s that; do not have an internal generator. The TFoam generator adaptively subdivides the; observable space and is generally more efficient both warmup and generation than the original; RooAcceptReject algorithm. In its current interface in RooFit, TFoam cannot; handle problems yet with discrete observables or conditional observables. For those problems; the original RooAcceptReject gene",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:4846,Integrability,integrat,integrations,4846,"package (minuit,GSLminimizer) and alg is the algorithm (migrad) to be used. By default, RooMinuit is still used when RooAbsPdf::fitTo() is called, but can be overridden with; a Minimizer() named argument. // Minimization with MINUIT/MIGRAD through RooMinuit; pdf->fitTo(data) ;. // Minimization with MINUIT/MIGRAD through RooMinimizer; pdf->fitTo(data,Minimizer(""minuit"")) ;. // Minimization with MINUIT2/MIGRAD through RooMinimizer; pdf->fitTo(data,Minimizer(""minuit2"")) ;. // Minimization with GSLMultiMin/conjugatefr through RooMinimizer; pdf->fitTo(data,Minimizer(""GSLMultiMin"",""conjugatefr"")) ;. Note that installation of GSL and the ROOT MathMore package is needed to access the GSL Minimizers and that the GSL; Minimizer do not implement error analysis. New numeric integration algorithms available; RooFit can now interface all MathCore numeric integration; algorithms. In this release ROOT::Math::AdaptiveIntegratorMultiDim,; which implements the 'Genz & Malik' algorithm has been interfaced; in RooAdaptiveIntegratorND and is now the default numeric integrator; for numeric integrations in two or more dimensions. This new default integrator has much improved stability and speed; for relatively smooth p.d.f.s in two or three dimensions and can; generally be used well for p.d.f. normalization integrals without; causing MINUIT converge problems due to numeric precision issues. In future release some more numeric integrators will be migrated to; a MathCore implementation. Interface to TFoam adaptive MC sampler added; RooFit can now use the TFoam adaptive MC sampler for event generation of p.d.f.s that; do not have an internal generator. The TFoam generator adaptively subdivides the; observable space and is generally more efficient both warmup and generation than the original; RooAcceptReject algorithm. In its current interface in RooFit, TFoam cannot; handle problems yet with discrete observables or conditional observables. For those problems; the original RooAcceptReject gene",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:4903,Integrability,integrat,integrator,4903,"with; a Minimizer() named argument. // Minimization with MINUIT/MIGRAD through RooMinuit; pdf->fitTo(data) ;. // Minimization with MINUIT/MIGRAD through RooMinimizer; pdf->fitTo(data,Minimizer(""minuit"")) ;. // Minimization with MINUIT2/MIGRAD through RooMinimizer; pdf->fitTo(data,Minimizer(""minuit2"")) ;. // Minimization with GSLMultiMin/conjugatefr through RooMinimizer; pdf->fitTo(data,Minimizer(""GSLMultiMin"",""conjugatefr"")) ;. Note that installation of GSL and the ROOT MathMore package is needed to access the GSL Minimizers and that the GSL; Minimizer do not implement error analysis. New numeric integration algorithms available; RooFit can now interface all MathCore numeric integration; algorithms. In this release ROOT::Math::AdaptiveIntegratorMultiDim,; which implements the 'Genz & Malik' algorithm has been interfaced; in RooAdaptiveIntegratorND and is now the default numeric integrator; for numeric integrations in two or more dimensions. This new default integrator has much improved stability and speed; for relatively smooth p.d.f.s in two or three dimensions and can; generally be used well for p.d.f. normalization integrals without; causing MINUIT converge problems due to numeric precision issues. In future release some more numeric integrators will be migrated to; a MathCore implementation. Interface to TFoam adaptive MC sampler added; RooFit can now use the TFoam adaptive MC sampler for event generation of p.d.f.s that; do not have an internal generator. The TFoam generator adaptively subdivides the; observable space and is generally more efficient both warmup and generation than the original; RooAcceptReject algorithm. In its current interface in RooFit, TFoam cannot; handle problems yet with discrete observables or conditional observables. For those problems; the original RooAcceptReject generator is still used. The choice of MC sampling algorithm can be steered through class RooNumGenConfig, which; is similar in style and structure, to RooNumIntConfig which",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:5188,Integrability,integrat,integrators,5188,"->fitTo(data,Minimizer(""minuit2"")) ;. // Minimization with GSLMultiMin/conjugatefr through RooMinimizer; pdf->fitTo(data,Minimizer(""GSLMultiMin"",""conjugatefr"")) ;. Note that installation of GSL and the ROOT MathMore package is needed to access the GSL Minimizers and that the GSL; Minimizer do not implement error analysis. New numeric integration algorithms available; RooFit can now interface all MathCore numeric integration; algorithms. In this release ROOT::Math::AdaptiveIntegratorMultiDim,; which implements the 'Genz & Malik' algorithm has been interfaced; in RooAdaptiveIntegratorND and is now the default numeric integrator; for numeric integrations in two or more dimensions. This new default integrator has much improved stability and speed; for relatively smooth p.d.f.s in two or three dimensions and can; generally be used well for p.d.f. normalization integrals without; causing MINUIT converge problems due to numeric precision issues. In future release some more numeric integrators will be migrated to; a MathCore implementation. Interface to TFoam adaptive MC sampler added; RooFit can now use the TFoam adaptive MC sampler for event generation of p.d.f.s that; do not have an internal generator. The TFoam generator adaptively subdivides the; observable space and is generally more efficient both warmup and generation than the original; RooAcceptReject algorithm. In its current interface in RooFit, TFoam cannot; handle problems yet with discrete observables or conditional observables. For those problems; the original RooAcceptReject generator is still used. The choice of MC sampling algorithm can be steered through class RooNumGenConfig, which; is similar in style and structure, to RooNumIntConfig which configures the choice of; numeric integration algorithm. A new tutorial macro rf902_numgenconfig.C has been added to $ROOTSYS/tutorials/roofit; to illustrate the use of the steering. A macro that demonstrates of the power of these newly interface numeric algorithms i",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:5600,Integrability,interface,interface,5600,"s release ROOT::Math::AdaptiveIntegratorMultiDim,; which implements the 'Genz & Malik' algorithm has been interfaced; in RooAdaptiveIntegratorND and is now the default numeric integrator; for numeric integrations in two or more dimensions. This new default integrator has much improved stability and speed; for relatively smooth p.d.f.s in two or three dimensions and can; generally be used well for p.d.f. normalization integrals without; causing MINUIT converge problems due to numeric precision issues. In future release some more numeric integrators will be migrated to; a MathCore implementation. Interface to TFoam adaptive MC sampler added; RooFit can now use the TFoam adaptive MC sampler for event generation of p.d.f.s that; do not have an internal generator. The TFoam generator adaptively subdivides the; observable space and is generally more efficient both warmup and generation than the original; RooAcceptReject algorithm. In its current interface in RooFit, TFoam cannot; handle problems yet with discrete observables or conditional observables. For those problems; the original RooAcceptReject generator is still used. The choice of MC sampling algorithm can be steered through class RooNumGenConfig, which; is similar in style and structure, to RooNumIntConfig which configures the choice of; numeric integration algorithm. A new tutorial macro rf902_numgenconfig.C has been added to $ROOTSYS/tutorials/roofit; to illustrate the use of the steering. A macro that demonstrates of the power of these newly interface numeric algorithms is provided at the; end of the RooFit section of the release notes. Optional persistent caching of numeric integrals; For p.d.f.s with numeric integrals that remain difficult or very time consuming,; a new persistent caching technique is now available that allows to precalculate; these integrals and store their values for future use. This technique works transparently; for any p.d.f. stored in a RooWorkspace. One can store numeric integral valu",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:5966,Integrability,integrat,integration,5966," This new default integrator has much improved stability and speed; for relatively smooth p.d.f.s in two or three dimensions and can; generally be used well for p.d.f. normalization integrals without; causing MINUIT converge problems due to numeric precision issues. In future release some more numeric integrators will be migrated to; a MathCore implementation. Interface to TFoam adaptive MC sampler added; RooFit can now use the TFoam adaptive MC sampler for event generation of p.d.f.s that; do not have an internal generator. The TFoam generator adaptively subdivides the; observable space and is generally more efficient both warmup and generation than the original; RooAcceptReject algorithm. In its current interface in RooFit, TFoam cannot; handle problems yet with discrete observables or conditional observables. For those problems; the original RooAcceptReject generator is still used. The choice of MC sampling algorithm can be steered through class RooNumGenConfig, which; is similar in style and structure, to RooNumIntConfig which configures the choice of; numeric integration algorithm. A new tutorial macro rf902_numgenconfig.C has been added to $ROOTSYS/tutorials/roofit; to illustrate the use of the steering. A macro that demonstrates of the power of these newly interface numeric algorithms is provided at the; end of the RooFit section of the release notes. Optional persistent caching of numeric integrals; For p.d.f.s with numeric integrals that remain difficult or very time consuming,; a new persistent caching technique is now available that allows to precalculate; these integrals and store their values for future use. This technique works transparently; for any p.d.f. stored in a RooWorkspace. One can store numeric integral values for problems with zero, one or two floating parameters.; In the first case, the value is simply stored. In cases with one or two floating parameters; a grid (histogram) of integral values is stored, which are interpolated to return inte",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:6169,Integrability,interface,interface,6169,"ntegrators will be migrated to; a MathCore implementation. Interface to TFoam adaptive MC sampler added; RooFit can now use the TFoam adaptive MC sampler for event generation of p.d.f.s that; do not have an internal generator. The TFoam generator adaptively subdivides the; observable space and is generally more efficient both warmup and generation than the original; RooAcceptReject algorithm. In its current interface in RooFit, TFoam cannot; handle problems yet with discrete observables or conditional observables. For those problems; the original RooAcceptReject generator is still used. The choice of MC sampling algorithm can be steered through class RooNumGenConfig, which; is similar in style and structure, to RooNumIntConfig which configures the choice of; numeric integration algorithm. A new tutorial macro rf902_numgenconfig.C has been added to $ROOTSYS/tutorials/roofit; to illustrate the use of the steering. A macro that demonstrates of the power of these newly interface numeric algorithms is provided at the; end of the RooFit section of the release notes. Optional persistent caching of numeric integrals; For p.d.f.s with numeric integrals that remain difficult or very time consuming,; a new persistent caching technique is now available that allows to precalculate; these integrals and store their values for future use. This technique works transparently; for any p.d.f. stored in a RooWorkspace. One can store numeric integral values for problems with zero, one or two floating parameters.; In the first case, the value is simply stored. In cases with one or two floating parameters; a grid (histogram) of integral values is stored, which are interpolated to return integral; values for each value of the parameters. A new tutorial macro rf903_numintcache.C has been added to $ROOTSYS/tutorials/roofit; to illustrate the use of this feature. Representation of function and p.d.f. derivatives; A new class has been added that can represent the derivative of any p.d.f or funct",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:7530,Integrability,interface,interface,7530,"se. This technique works transparently; for any p.d.f. stored in a RooWorkspace. One can store numeric integral values for problems with zero, one or two floating parameters.; In the first case, the value is simply stored. In cases with one or two floating parameters; a grid (histogram) of integral values is stored, which are interpolated to return integral; values for each value of the parameters. A new tutorial macro rf903_numintcache.C has been added to $ROOTSYS/tutorials/roofit; to illustrate the use of this feature. Representation of function and p.d.f. derivatives; A new class has been added that can represent the derivative of any p.d.f or function w.r.t. any; parameter or observable. To construct e.g. a first order derivative of a Gaussian p.d.f, do. RooAbsReal* dgdx = gauss.derivative(x,1) ;. A more complete example is available in the new tutorial macro rf111_derivatives.C. Improved handling of chi-squared fits; Chi-squared fits can now be performed through the same style of interface as likelihood fits,; through the newly added method RooAbsReal::chi2FitTo(const RooDataHist&,...). Functions that can be fitted with chi-squared minimization are any RooAbsReal based function; as well as RooAbsPdf based p.d.f.s. In case of non-extended p.d.f.s the probability density; calculated by the p.d.f. is multiplied with the number of events in the histogram to adjust; the scale of the function. In case of extended p.d.f.s, the adjustment is made with the expected; number of events, rather than the observed number of events. Tutorial macro rf602_chi2fit.C has been updated to use this new interface. Chi-squared fits to X-Y datasets now possible; In addition to the ability to perform chi-squared fits to histograms it is now also possible; to perform chi-squared fits to unbinned datasets containing a series of X and Y values; with associated errors on Y and optionally on X. These 'X-Y' chi-squared fits are interfaced through newly added method; RooAbsReal::chi2FitTo(const",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:8142,Integrability,interface,interface,8142,"added that can represent the derivative of any p.d.f or function w.r.t. any; parameter or observable. To construct e.g. a first order derivative of a Gaussian p.d.f, do. RooAbsReal* dgdx = gauss.derivative(x,1) ;. A more complete example is available in the new tutorial macro rf111_derivatives.C. Improved handling of chi-squared fits; Chi-squared fits can now be performed through the same style of interface as likelihood fits,; through the newly added method RooAbsReal::chi2FitTo(const RooDataHist&,...). Functions that can be fitted with chi-squared minimization are any RooAbsReal based function; as well as RooAbsPdf based p.d.f.s. In case of non-extended p.d.f.s the probability density; calculated by the p.d.f. is multiplied with the number of events in the histogram to adjust; the scale of the function. In case of extended p.d.f.s, the adjustment is made with the expected; number of events, rather than the observed number of events. Tutorial macro rf602_chi2fit.C has been updated to use this new interface. Chi-squared fits to X-Y datasets now possible; In addition to the ability to perform chi-squared fits to histograms it is now also possible; to perform chi-squared fits to unbinned datasets containing a series of X and Y values; with associated errors on Y and optionally on X. These 'X-Y' chi-squared fits are interfaced through newly added method; RooAbsReal::chi2FitTo(const RooDataSet&,...). By default the event weight is; interpreted as the 'Y' value, but an YVar() argument can designate any other; dataset column as Y value. If X errors are defined, one can choose to integrate the fitted; function over the range of the X errors, rather than taking the central value by adding; an Integrate(true) argument to chi2FitTo(); Two new arguments, StoreError(const RooArgSet&) and StoreAsymError(const RooArgSet&); have been added to the RooDataSet constructor to simplify the process of storing the errors; of X and Y variables along with their values in a dataset. The newl",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:8464,Integrability,interface,interfaced,8464,"now be performed through the same style of interface as likelihood fits,; through the newly added method RooAbsReal::chi2FitTo(const RooDataHist&,...). Functions that can be fitted with chi-squared minimization are any RooAbsReal based function; as well as RooAbsPdf based p.d.f.s. In case of non-extended p.d.f.s the probability density; calculated by the p.d.f. is multiplied with the number of events in the histogram to adjust; the scale of the function. In case of extended p.d.f.s, the adjustment is made with the expected; number of events, rather than the observed number of events. Tutorial macro rf602_chi2fit.C has been updated to use this new interface. Chi-squared fits to X-Y datasets now possible; In addition to the ability to perform chi-squared fits to histograms it is now also possible; to perform chi-squared fits to unbinned datasets containing a series of X and Y values; with associated errors on Y and optionally on X. These 'X-Y' chi-squared fits are interfaced through newly added method; RooAbsReal::chi2FitTo(const RooDataSet&,...). By default the event weight is; interpreted as the 'Y' value, but an YVar() argument can designate any other; dataset column as Y value. If X errors are defined, one can choose to integrate the fitted; function over the range of the X errors, rather than taking the central value by adding; an Integrate(true) argument to chi2FitTo(); Two new arguments, StoreError(const RooArgSet&) and StoreAsymError(const RooArgSet&); have been added to the RooDataSet constructor to simplify the process of storing the errors; of X and Y variables along with their values in a dataset. The newly added tutorial macro rf609_xychi2fit.C illustrates the use of all this; new functionality. Uniform interface for creation of (profile likelihoods) and chi-squared from p.d.f.s; It is now recommended to use the method RooAbsPdf::createNLL(RooAbsData&,...) to; create a likelihood from a p.d.f and a dataset rather than constructing a RooNLLVar; object dire",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:8729,Integrability,integrat,integrate,8729,"gram to adjust; the scale of the function. In case of extended p.d.f.s, the adjustment is made with the expected; number of events, rather than the observed number of events. Tutorial macro rf602_chi2fit.C has been updated to use this new interface. Chi-squared fits to X-Y datasets now possible; In addition to the ability to perform chi-squared fits to histograms it is now also possible; to perform chi-squared fits to unbinned datasets containing a series of X and Y values; with associated errors on Y and optionally on X. These 'X-Y' chi-squared fits are interfaced through newly added method; RooAbsReal::chi2FitTo(const RooDataSet&,...). By default the event weight is; interpreted as the 'Y' value, but an YVar() argument can designate any other; dataset column as Y value. If X errors are defined, one can choose to integrate the fitted; function over the range of the X errors, rather than taking the central value by adding; an Integrate(true) argument to chi2FitTo(); Two new arguments, StoreError(const RooArgSet&) and StoreAsymError(const RooArgSet&); have been added to the RooDataSet constructor to simplify the process of storing the errors; of X and Y variables along with their values in a dataset. The newly added tutorial macro rf609_xychi2fit.C illustrates the use of all this; new functionality. Uniform interface for creation of (profile likelihoods) and chi-squared from p.d.f.s; It is now recommended to use the method RooAbsPdf::createNLL(RooAbsData&,...) to; create a likelihood from a p.d.f and a dataset rather than constructing a RooNLLVar; object directly. This is because part of the likelihood construction functionality such a using; multiple Range()s, or the inclusion for constraint terms are only available through; createNLL(). To promote the consistency of this interface, a similar method RooAbsReal::createChi2(); has been added to construct chi-squared functions of a dataset and a function or p.d.f. Along the same lines, it is recommended to use RooAbsRe",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:9231,Integrability,interface,interface,9231,"ograms it is now also possible; to perform chi-squared fits to unbinned datasets containing a series of X and Y values; with associated errors on Y and optionally on X. These 'X-Y' chi-squared fits are interfaced through newly added method; RooAbsReal::chi2FitTo(const RooDataSet&,...). By default the event weight is; interpreted as the 'Y' value, but an YVar() argument can designate any other; dataset column as Y value. If X errors are defined, one can choose to integrate the fitted; function over the range of the X errors, rather than taking the central value by adding; an Integrate(true) argument to chi2FitTo(); Two new arguments, StoreError(const RooArgSet&) and StoreAsymError(const RooArgSet&); have been added to the RooDataSet constructor to simplify the process of storing the errors; of X and Y variables along with their values in a dataset. The newly added tutorial macro rf609_xychi2fit.C illustrates the use of all this; new functionality. Uniform interface for creation of (profile likelihoods) and chi-squared from p.d.f.s; It is now recommended to use the method RooAbsPdf::createNLL(RooAbsData&,...) to; create a likelihood from a p.d.f and a dataset rather than constructing a RooNLLVar; object directly. This is because part of the likelihood construction functionality such a using; multiple Range()s, or the inclusion for constraint terms are only available through; createNLL(). To promote the consistency of this interface, a similar method RooAbsReal::createChi2(); has been added to construct chi-squared functions of a dataset and a function or p.d.f. Along the same lines, it is recommended to use RooAbsReal::createProfile() rather; than constructing a RooProfileLL object directly as the former will efficiently; recast a profile of a profile into a single profile object. Multivariate Gaussian modeling of parameters estimates from a fit; You can now construct a multivariate Gaussian p.d.f on the parameters of a model that; represents the result of a fit, from",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:9706,Integrability,interface,interface,9706,"ion over the range of the X errors, rather than taking the central value by adding; an Integrate(true) argument to chi2FitTo(); Two new arguments, StoreError(const RooArgSet&) and StoreAsymError(const RooArgSet&); have been added to the RooDataSet constructor to simplify the process of storing the errors; of X and Y variables along with their values in a dataset. The newly added tutorial macro rf609_xychi2fit.C illustrates the use of all this; new functionality. Uniform interface for creation of (profile likelihoods) and chi-squared from p.d.f.s; It is now recommended to use the method RooAbsPdf::createNLL(RooAbsData&,...) to; create a likelihood from a p.d.f and a dataset rather than constructing a RooNLLVar; object directly. This is because part of the likelihood construction functionality such a using; multiple Range()s, or the inclusion for constraint terms are only available through; createNLL(). To promote the consistency of this interface, a similar method RooAbsReal::createChi2(); has been added to construct chi-squared functions of a dataset and a function or p.d.f. Along the same lines, it is recommended to use RooAbsReal::createProfile() rather; than constructing a RooProfileLL object directly as the former will efficiently; recast a profile of a profile into a single profile object. Multivariate Gaussian modeling of parameters estimates from a fit; You can now construct a multivariate Gaussian p.d.f on the parameters of a model that; represents the result of a fit, from any RooFitResult object. RooAbsPdf* paramPdf = fitresult->createHessePdf(RooArgSet(a,b)) ;. The returned object is an instance of the newly added class RooMultiVarGaussian, that can; model correlated Gaussian distributions in an arbitrary number of dimensions, given a; vector of mean values and a covariance matrix. Class RooMultivarGaussian implements analytical; integration as well as analytical partial integrals over the first 31 dimensions (if you have; that many) and implements in effe",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:10629,Integrability,integrat,integration,10629,"ncy of this interface, a similar method RooAbsReal::createChi2(); has been added to construct chi-squared functions of a dataset and a function or p.d.f. Along the same lines, it is recommended to use RooAbsReal::createProfile() rather; than constructing a RooProfileLL object directly as the former will efficiently; recast a profile of a profile into a single profile object. Multivariate Gaussian modeling of parameters estimates from a fit; You can now construct a multivariate Gaussian p.d.f on the parameters of a model that; represents the result of a fit, from any RooFitResult object. RooAbsPdf* paramPdf = fitresult->createHessePdf(RooArgSet(a,b)) ;. The returned object is an instance of the newly added class RooMultiVarGaussian, that can; model correlated Gaussian distributions in an arbitrary number of dimensions, given a; vector of mean values and a covariance matrix. Class RooMultivarGaussian implements analytical; integration as well as analytical partial integrals over the first 31 dimensions (if you have; that many) and implements in effect internal generation strategy for its observables. A new tutorial macro rf608_fitresultaspdf.C has been added to illustrate the use MV Gaussians constructed from a RooFitResult; Improved functionality of RooFFTConvPdf; The FFT convolution operator p.d.f. class RooFFTConvPdf has been substantially upgraded; for improved performance has several new options. For the overflow buffering, which aims to reduce cylical spillover from the FFT convolution,; a choice of three algorithms is now provided:. Extend the p.d.f. somewhat beyond its original domain (the new default); Fill the buffer 50/50 with the value of the p.d.f at the upper/lower bound of the convolution observable (the previous default); Mirror the p.d.f. over the boundary. The new default algorithm provides a more sensible result for p.d.f.s with significant; spillover issues, provided that the p.d.f. can be continuated beyond its original domain.; Convolution in non",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:16666,Integrability,interface,interface,16666,". In future release additional implementations of RooAbsDataStore will; be provided that will support new dataset functionality such as the; ability to construct 'joint' dataset from two input datasets without; the need to copy the input data and 'filtered' datasets that represent; a reduced view (in dimensions or by selecting events) of a dataset; without the need to copy content. Various workspace improvements. A number of smaller and larger improvements has been made to the RooWorkspace class. Direct interactive access to contents from CINT -; One can now directly access the contents of any RooWorkspace; on the ROOT commandline through CINT if the RooWorkspace::exportToCint() call is made.; In CINT, all workspace objects will appear as correctly typed references to workspace objects in; a C++ namespace with the same name as the RooWorkspace object. Given e.g. a workspace w, with a Gaussian p.d.f gauss in terms of variables; x,m,s one can now do. RooWorkspace w(""w"",true) ; // workspace with CINT interface activated; // ... fill workspace with RooGaussian gauss(x,m,s) ...; RooPlot* frame = w::x.frame() ;; w::gauss.plotOn(frame) ;. to access the workspace contents. Each reference has the correct type, e.g. w::gauss is; a RooGaussian&. If a workspace is deleted from memory, the corresponding CINT namespace; is removed as well. Note that this feature is strictly available in interpreted C++ only; A new tutorial macro has been added to illustrate this functionality in more detail: rf509_wsinteractive.C.; writeToFile -- A new utility method RooWorkspace::writeToFile() has been added; to simplify the process of saving a workspace to file; Named sets and parameter snapshots -- It is now possible to define and retrieve; named RooArgSets of objects that live in the workspace through methods; defineSet() and set(). While named sets merely group objects logically, methods loadSnapshot and; saveSnapshot allow to make copies of the values, errors and 'constant' status of; sets ",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:18080,Integrability,interface,interface,18080,"ore detail: rf509_wsinteractive.C.; writeToFile -- A new utility method RooWorkspace::writeToFile() has been added; to simplify the process of saving a workspace to file; Named sets and parameter snapshots -- It is now possible to define and retrieve; named RooArgSets of objects that live in the workspace through methods; defineSet() and set(). While named sets merely group objects logically, methods loadSnapshot and; saveSnapshot allow to make copies of the values, errors and 'constant' status of; sets of variable objects that live in the workspace. A newly added tutorial macro rf510_namedsets.C illustrates the functionality of both; of these features.; Improved printing of contents -- Many operator p.d.f. and function components now show; a more intuitive natural representation of their contents (these changes are mostly in the; respective p.d.f.s, but are most relevant in the context of a workspace). New object factory interface to workspace to facilitate script driven model definition; A object factory has been added to RooFit to simplify the process of creating p.d.f.; and function expressions consisting of multiple objects. The factory has two goals:; the first is to provide a back-end for higher level factories and tools to process; the creation of objects. The second is to provide a simple end-user language to; populate a RooWorkspace with function and p.d.f. objects. For the latter purpose the object creation language is executed through the factory() method; of a workspace object. RooWorkspace w(""w"") ;; RooAbsArg* arg = w.factory(""expression_goes_here"") ;. Basic Syntax; The rules at its simplest level are as follows. Expressions with square brackets create variables (discrete and continuous). ""m[-10,10]"" - Creates a RooRealVar named 'm' with range [-10,10]; ""m[5,-10,10]"" - Idem, but with initial value 5; ""m[5]"" - Creates a constant RooRealVar with name 'm' and value 5. ""tagCat[Lep,Kao,NT1,NT2]"" -- Creates a RooCategory with name tagCat and labeled states Le",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:21544,Integrability,interface,interfaced,21544,". Here is a much more complicated example:. ""PROD::sig(BMixDecay::sig_t( dt[-20,20], mixState[mixed=1,unmix=-1], tagFlav[B0=1,B0bar=-1],; tau[1.54], dm[0.472], w[0.05], dw[0],; AddModel({GaussModel(dt,biasC[-10,10],sigmaC[0.1,3],dterr[0.01,0.2]),; GaussModel(dt,0,sigmaT[3,10]),; GaussModel(dt,0,20)},{fracC[0,1],fracT[0,1]}),; DoubleSided ),; Gaussian::sig_m( mes[5.20,5.30], mB0[5.20,5.30], sigmB0[0.01,0.05] )"". This create a double-sided Bmixing decay p.d.f. with observables dt,; per-event error dterr and all its parameters, convoluted with a triple; gaussian resolution model and multiplied with a Gaussian p.d.f. in the; energy substituted mass. (In plain RooFit this would have required at; least 23 lines of code). A series of three new tutorial macros has been added to illustrate the; various features of the object factory. rf511_wsfactory_basic.C - Basic factory concepts; rf512_wsfactory_oper.C - Using operator p.d.f.s in the factory; rf513_wsfactory_tools.C - Advanced example using interfaced high level tools. A formal transaction model is used to commit composite objects into; the workspace. If an error is detected in the expression, no objects; will be committed to the workspace, thus leaving no 'partial builds'. Compact demo of several new major features. The macro below demonstrates in a couple of lines a number of major new features in RooFit 3.00: Use of. workspace factory to quickly create and store (compiled) models; workspace CINT interface to easily access contents in a typesafe way; new adaptive ND numeric integration technique to normalize arbitrary p.d.f. in fast; and reliable way; new adaptive TFoam sampling technique to efficiently generate toy MC data from strongly; peaked datasets; parallel processing in likelihood construction and use of profile likelihood operator; to represent profile likelihoods as regular RooFit functions. void demo(); {; // Construct compiled 2-D model that requires numeric integration for normalization; RooWorkspace w(""w"",1",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:22011,Integrability,interface,interface,22011,"event error dterr and all its parameters, convoluted with a triple; gaussian resolution model and multiplied with a Gaussian p.d.f. in the; energy substituted mass. (In plain RooFit this would have required at; least 23 lines of code). A series of three new tutorial macros has been added to illustrate the; various features of the object factory. rf511_wsfactory_basic.C - Basic factory concepts; rf512_wsfactory_oper.C - Using operator p.d.f.s in the factory; rf513_wsfactory_tools.C - Advanced example using interfaced high level tools. A formal transaction model is used to commit composite objects into; the workspace. If an error is detected in the expression, no objects; will be committed to the workspace, thus leaving no 'partial builds'. Compact demo of several new major features. The macro below demonstrates in a couple of lines a number of major new features in RooFit 3.00: Use of. workspace factory to quickly create and store (compiled) models; workspace CINT interface to easily access contents in a typesafe way; new adaptive ND numeric integration technique to normalize arbitrary p.d.f. in fast; and reliable way; new adaptive TFoam sampling technique to efficiently generate toy MC data from strongly; peaked datasets; parallel processing in likelihood construction and use of profile likelihood operator; to represent profile likelihoods as regular RooFit functions. void demo(); {; // Construct compiled 2-D model that requires numeric integration for normalization; RooWorkspace w(""w"",1) ;; w.factory(""CEXPR::model('1/((x-a)*(x-a)+0.001)+1/((y-b)*(y-b)+0.001)',x[-1,1],y[-1,1],a[-5,5],b[-5,5])"") ;. // Generate data from model (using TFoam adaptive sampling algorithm); RooDataSet* d = w::model.generate(RooArgSet(w::x,w::y),1000) ;; w::model.fitTo(*d) ;. // Make 2D plot on (x,y); TH2* hh = w::model.createHistogram(""x,y"",40,40) ;; hh->SetLineColor(kBlue) ;. // Make Projection on x (integrate over y); RooPlot* framex = w::x.frame(Title(""Data and p.d.f. projected on X"")) ;",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:22090,Integrability,integrat,integration,22090,"event error dterr and all its parameters, convoluted with a triple; gaussian resolution model and multiplied with a Gaussian p.d.f. in the; energy substituted mass. (In plain RooFit this would have required at; least 23 lines of code). A series of three new tutorial macros has been added to illustrate the; various features of the object factory. rf511_wsfactory_basic.C - Basic factory concepts; rf512_wsfactory_oper.C - Using operator p.d.f.s in the factory; rf513_wsfactory_tools.C - Advanced example using interfaced high level tools. A formal transaction model is used to commit composite objects into; the workspace. If an error is detected in the expression, no objects; will be committed to the workspace, thus leaving no 'partial builds'. Compact demo of several new major features. The macro below demonstrates in a couple of lines a number of major new features in RooFit 3.00: Use of. workspace factory to quickly create and store (compiled) models; workspace CINT interface to easily access contents in a typesafe way; new adaptive ND numeric integration technique to normalize arbitrary p.d.f. in fast; and reliable way; new adaptive TFoam sampling technique to efficiently generate toy MC data from strongly; peaked datasets; parallel processing in likelihood construction and use of profile likelihood operator; to represent profile likelihoods as regular RooFit functions. void demo(); {; // Construct compiled 2-D model that requires numeric integration for normalization; RooWorkspace w(""w"",1) ;; w.factory(""CEXPR::model('1/((x-a)*(x-a)+0.001)+1/((y-b)*(y-b)+0.001)',x[-1,1],y[-1,1],a[-5,5],b[-5,5])"") ;. // Generate data from model (using TFoam adaptive sampling algorithm); RooDataSet* d = w::model.generate(RooArgSet(w::x,w::y),1000) ;; w::model.fitTo(*d) ;. // Make 2D plot on (x,y); TH2* hh = w::model.createHistogram(""x,y"",40,40) ;; hh->SetLineColor(kBlue) ;. // Make Projection on x (integrate over y); RooPlot* framex = w::x.frame(Title(""Data and p.d.f. projected on X"")) ;",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:22494,Integrability,integrat,integration,22494,"actory; rf513_wsfactory_tools.C - Advanced example using interfaced high level tools. A formal transaction model is used to commit composite objects into; the workspace. If an error is detected in the expression, no objects; will be committed to the workspace, thus leaving no 'partial builds'. Compact demo of several new major features. The macro below demonstrates in a couple of lines a number of major new features in RooFit 3.00: Use of. workspace factory to quickly create and store (compiled) models; workspace CINT interface to easily access contents in a typesafe way; new adaptive ND numeric integration technique to normalize arbitrary p.d.f. in fast; and reliable way; new adaptive TFoam sampling technique to efficiently generate toy MC data from strongly; peaked datasets; parallel processing in likelihood construction and use of profile likelihood operator; to represent profile likelihoods as regular RooFit functions. void demo(); {; // Construct compiled 2-D model that requires numeric integration for normalization; RooWorkspace w(""w"",1) ;; w.factory(""CEXPR::model('1/((x-a)*(x-a)+0.001)+1/((y-b)*(y-b)+0.001)',x[-1,1],y[-1,1],a[-5,5],b[-5,5])"") ;. // Generate data from model (using TFoam adaptive sampling algorithm); RooDataSet* d = w::model.generate(RooArgSet(w::x,w::y),1000) ;; w::model.fitTo(*d) ;. // Make 2D plot on (x,y); TH2* hh = w::model.createHistogram(""x,y"",40,40) ;; hh->SetLineColor(kBlue) ;. // Make Projection on x (integrate over y); RooPlot* framex = w::x.frame(Title(""Data and p.d.f. projected on X"")) ;; d->plotOn(framex) ;; w::model.plotOn(framex) ;. // Construct likelihood, profile likelihood in a, and draw the latter; RooAbsReal* nll = w::model.createNLL(*d,NumCPU(2)) ;; RooAbsReal* pll = nll->createProfile(w::a) ;; RooPlot* framea = w::a.frame(Title(""Profile likelihood in parameter a"")) ;; pll->plotOn(framea) ;. // Construct 2D cumulative distribution function from p.d.f.; RooAbsReal* cdfxy = w::model.createCdf(RooArgSet(w::x,w::y),ScanNoCdf())",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:22944,Integrability,integrat,integrate,22944,"quickly create and store (compiled) models; workspace CINT interface to easily access contents in a typesafe way; new adaptive ND numeric integration technique to normalize arbitrary p.d.f. in fast; and reliable way; new adaptive TFoam sampling technique to efficiently generate toy MC data from strongly; peaked datasets; parallel processing in likelihood construction and use of profile likelihood operator; to represent profile likelihoods as regular RooFit functions. void demo(); {; // Construct compiled 2-D model that requires numeric integration for normalization; RooWorkspace w(""w"",1) ;; w.factory(""CEXPR::model('1/((x-a)*(x-a)+0.001)+1/((y-b)*(y-b)+0.001)',x[-1,1],y[-1,1],a[-5,5],b[-5,5])"") ;. // Generate data from model (using TFoam adaptive sampling algorithm); RooDataSet* d = w::model.generate(RooArgSet(w::x,w::y),1000) ;; w::model.fitTo(*d) ;. // Make 2D plot on (x,y); TH2* hh = w::model.createHistogram(""x,y"",40,40) ;; hh->SetLineColor(kBlue) ;. // Make Projection on x (integrate over y); RooPlot* framex = w::x.frame(Title(""Data and p.d.f. projected on X"")) ;; d->plotOn(framex) ;; w::model.plotOn(framex) ;. // Construct likelihood, profile likelihood in a, and draw the latter; RooAbsReal* nll = w::model.createNLL(*d,NumCPU(2)) ;; RooAbsReal* pll = nll->createProfile(w::a) ;; RooPlot* framea = w::a.frame(Title(""Profile likelihood in parameter a"")) ;; pll->plotOn(framea) ;. // Construct 2D cumulative distribution function from p.d.f.; RooAbsReal* cdfxy = w::model.createCdf(RooArgSet(w::x,w::y),ScanNoCdf()) ;; TH2* hhcdf = cdfxy->createHistogram(""x,y"",40,40) ;; hhcdf->SetLineColor(kRed) ;. TCanvas* c = new TCanvas(""c"",""c"",650,650) ; c->Divide(2,2) ;; c->cd(1) ; hh->Draw(""surf"") ; c->cd(2) ; framex->Draw() ;; c->cd(3) ; framea->Draw() ; c->cd(4) ; hhcdf->Draw(""surf"") ;; }. Plot that results from above macro. Miscellaneous small improvements. Utility function bindFunction() and bindPdf that can bind; external C++ functions as RooFit functions or p.d.f.s now can al",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:25811,Integrability,interface,interface,25811,"f datasets that; will speedup certain data intensive operations. RooStats; New Tutorials. Several new tutorials were added for RooStats. rs101_limitexample.C Demonstrates use of Frequentist,; Bayesian, and Likelihood intervals for a simple number counting experiment; with uncertainty on signal and background rates.; rs301_splot.C Demonstrates use of RooStats sPlot; implementation; rs401c_FeldmanCousins.C Demonstrates use of; FeldmanCousins interval calculator with a Poisson problem, reproduces; results from table IV and V of the original; paper�Phys.Rev.D57:3873-3889,1998.; rs401d_FeldmanCousins.C Demonstrates use of; FeldmanCousins interval calculator with the neutrino oscillation toy; example described in the original paper�Phys.Rev.D57:3873-3889,1998.; Reproduces figure 12.; rs_bernsteinCorrection.C Demonstrates use of; BernsteinCorrection class, which corrects a nominal PDF with a polynomial; to agree with observed or simulated data. TestStatistic interface and implementations; We added a new interface class called TestStatistic. It defines the; method Evaluate(data, parameterPoint), which returns a double. �This; class can be used in�conjunction�with the ToyMCSampler class to generate; sampling distributions for a user-defined test statistic. �; The following concrete implementations of the TestStatistic interface; are currently available. ProfileLikelihoodTestStatReturns the log of profile; likelihood ratio. �Generally a powerful test statistic. ; NumEventsTestStatReturns the number of events in the; dataset. �Useful for number counting experiments.; DebuggingTestStat Simply returns a uniform random number; between 0,1. �Useful for debugging. SamplingDistribution and the�TestStatSampler interface and; implementations; We introduced a ``result'' or data model class called; SamplingDistribution, which holds the sampling distribution of an; arbitrary real valued test statistic. �The class also can return the; inverse of the cumulative distribution function (with ",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:25857,Integrability,interface,interface,25857,"f datasets that; will speedup certain data intensive operations. RooStats; New Tutorials. Several new tutorials were added for RooStats. rs101_limitexample.C Demonstrates use of Frequentist,; Bayesian, and Likelihood intervals for a simple number counting experiment; with uncertainty on signal and background rates.; rs301_splot.C Demonstrates use of RooStats sPlot; implementation; rs401c_FeldmanCousins.C Demonstrates use of; FeldmanCousins interval calculator with a Poisson problem, reproduces; results from table IV and V of the original; paper�Phys.Rev.D57:3873-3889,1998.; rs401d_FeldmanCousins.C Demonstrates use of; FeldmanCousins interval calculator with the neutrino oscillation toy; example described in the original paper�Phys.Rev.D57:3873-3889,1998.; Reproduces figure 12.; rs_bernsteinCorrection.C Demonstrates use of; BernsteinCorrection class, which corrects a nominal PDF with a polynomial; to agree with observed or simulated data. TestStatistic interface and implementations; We added a new interface class called TestStatistic. It defines the; method Evaluate(data, parameterPoint), which returns a double. �This; class can be used in�conjunction�with the ToyMCSampler class to generate; sampling distributions for a user-defined test statistic. �; The following concrete implementations of the TestStatistic interface; are currently available. ProfileLikelihoodTestStatReturns the log of profile; likelihood ratio. �Generally a powerful test statistic. ; NumEventsTestStatReturns the number of events in the; dataset. �Useful for number counting experiments.; DebuggingTestStat Simply returns a uniform random number; between 0,1. �Useful for debugging. SamplingDistribution and the�TestStatSampler interface and; implementations; We introduced a ``result'' or data model class called; SamplingDistribution, which holds the sampling distribution of an; arbitrary real valued test statistic. �The class also can return the; inverse of the cumulative distribution function (with ",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:26176,Integrability,interface,interface,26176,"; rs301_splot.C Demonstrates use of RooStats sPlot; implementation; rs401c_FeldmanCousins.C Demonstrates use of; FeldmanCousins interval calculator with a Poisson problem, reproduces; results from table IV and V of the original; paper�Phys.Rev.D57:3873-3889,1998.; rs401d_FeldmanCousins.C Demonstrates use of; FeldmanCousins interval calculator with the neutrino oscillation toy; example described in the original paper�Phys.Rev.D57:3873-3889,1998.; Reproduces figure 12.; rs_bernsteinCorrection.C Demonstrates use of; BernsteinCorrection class, which corrects a nominal PDF with a polynomial; to agree with observed or simulated data. TestStatistic interface and implementations; We added a new interface class called TestStatistic. It defines the; method Evaluate(data, parameterPoint), which returns a double. �This; class can be used in�conjunction�with the ToyMCSampler class to generate; sampling distributions for a user-defined test statistic. �; The following concrete implementations of the TestStatistic interface; are currently available. ProfileLikelihoodTestStatReturns the log of profile; likelihood ratio. �Generally a powerful test statistic. ; NumEventsTestStatReturns the number of events in the; dataset. �Useful for number counting experiments.; DebuggingTestStat Simply returns a uniform random number; between 0,1. �Useful for debugging. SamplingDistribution and the�TestStatSampler interface and; implementations; We introduced a ``result'' or data model class called; SamplingDistribution, which holds the sampling distribution of an; arbitrary real valued test statistic. �The class also can return the; inverse of the cumulative distribution function (with or without; interpolation). �; We introduced an interface for any tool that can produce a; SamplingDistribution, called TestStatSampler. �The interface is; essentially GetSamplingDistribution(parameterPoint) which returns a; SamplingDistribution based on a given probability density function. �We; foresee a few versi",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:26567,Integrability,interface,interface,26567,"rnsteinCorrection.C Demonstrates use of; BernsteinCorrection class, which corrects a nominal PDF with a polynomial; to agree with observed or simulated data. TestStatistic interface and implementations; We added a new interface class called TestStatistic. It defines the; method Evaluate(data, parameterPoint), which returns a double. �This; class can be used in�conjunction�with the ToyMCSampler class to generate; sampling distributions for a user-defined test statistic. �; The following concrete implementations of the TestStatistic interface; are currently available. ProfileLikelihoodTestStatReturns the log of profile; likelihood ratio. �Generally a powerful test statistic. ; NumEventsTestStatReturns the number of events in the; dataset. �Useful for number counting experiments.; DebuggingTestStat Simply returns a uniform random number; between 0,1. �Useful for debugging. SamplingDistribution and the�TestStatSampler interface and; implementations; We introduced a ``result'' or data model class called; SamplingDistribution, which holds the sampling distribution of an; arbitrary real valued test statistic. �The class also can return the; inverse of the cumulative distribution function (with or without; interpolation). �; We introduced an interface for any tool that can produce a; SamplingDistribution, called TestStatSampler. �The interface is; essentially GetSamplingDistribution(parameterPoint) which returns a; SamplingDistribution based on a given probability density function. �We; foresee a few versions of this tool based on toy Monte Carlo, importance; sampling, Fourier transforms, etc. �The following concrete implementation; of the TestStatSampler interface are currently available. ToyMCSamplerUses a Toy Monte Carlo approach to build the; sampling distribution. �The pdf's generate method to generate is used to; generate toy data, and then the test statistic is evaluated at the; requested parameter point. ; DebuggingSampler Simply returns a uniform distribution; betwe",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:26893,Integrability,interface,interface,26893,"(data, parameterPoint), which returns a double. �This; class can be used in�conjunction�with the ToyMCSampler class to generate; sampling distributions for a user-defined test statistic. �; The following concrete implementations of the TestStatistic interface; are currently available. ProfileLikelihoodTestStatReturns the log of profile; likelihood ratio. �Generally a powerful test statistic. ; NumEventsTestStatReturns the number of events in the; dataset. �Useful for number counting experiments.; DebuggingTestStat Simply returns a uniform random number; between 0,1. �Useful for debugging. SamplingDistribution and the�TestStatSampler interface and; implementations; We introduced a ``result'' or data model class called; SamplingDistribution, which holds the sampling distribution of an; arbitrary real valued test statistic. �The class also can return the; inverse of the cumulative distribution function (with or without; interpolation). �; We introduced an interface for any tool that can produce a; SamplingDistribution, called TestStatSampler. �The interface is; essentially GetSamplingDistribution(parameterPoint) which returns a; SamplingDistribution based on a given probability density function. �We; foresee a few versions of this tool based on toy Monte Carlo, importance; sampling, Fourier transforms, etc. �The following concrete implementation; of the TestStatSampler interface are currently available. ToyMCSamplerUses a Toy Monte Carlo approach to build the; sampling distribution. �The pdf's generate method to generate is used to; generate toy data, and then the test statistic is evaluated at the; requested parameter point. ; DebuggingSampler Simply returns a uniform distribution; between 0,1. �Useful for debugging. NeymanConstruction and FeldmanCousins; A flexible framework for the Neyman Construction was added in this; release. The NeymanConstruction is a concrete implementation of the; IntervalCalculator interface, but it needs several; additional components�to be ",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:26987,Integrability,interface,interface,26987,"ling distributions for a user-defined test statistic. �; The following concrete implementations of the TestStatistic interface; are currently available. ProfileLikelihoodTestStatReturns the log of profile; likelihood ratio. �Generally a powerful test statistic. ; NumEventsTestStatReturns the number of events in the; dataset. �Useful for number counting experiments.; DebuggingTestStat Simply returns a uniform random number; between 0,1. �Useful for debugging. SamplingDistribution and the�TestStatSampler interface and; implementations; We introduced a ``result'' or data model class called; SamplingDistribution, which holds the sampling distribution of an; arbitrary real valued test statistic. �The class also can return the; inverse of the cumulative distribution function (with or without; interpolation). �; We introduced an interface for any tool that can produce a; SamplingDistribution, called TestStatSampler. �The interface is; essentially GetSamplingDistribution(parameterPoint) which returns a; SamplingDistribution based on a given probability density function. �We; foresee a few versions of this tool based on toy Monte Carlo, importance; sampling, Fourier transforms, etc. �The following concrete implementation; of the TestStatSampler interface are currently available. ToyMCSamplerUses a Toy Monte Carlo approach to build the; sampling distribution. �The pdf's generate method to generate is used to; generate toy data, and then the test statistic is evaluated at the; requested parameter point. ; DebuggingSampler Simply returns a uniform distribution; between 0,1. �Useful for debugging. NeymanConstruction and FeldmanCousins; A flexible framework for the Neyman Construction was added in this; release. The NeymanConstruction is a concrete implementation of the; IntervalCalculator interface, but it needs several; additional components�to be specified before use. The design; factorizes the choice of the parameter points to be tested,�the choice of; the test statistic, and",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:27315,Integrability,interface,interface,27315,"rful test statistic. ; NumEventsTestStatReturns the number of events in the; dataset. �Useful for number counting experiments.; DebuggingTestStat Simply returns a uniform random number; between 0,1. �Useful for debugging. SamplingDistribution and the�TestStatSampler interface and; implementations; We introduced a ``result'' or data model class called; SamplingDistribution, which holds the sampling distribution of an; arbitrary real valued test statistic. �The class also can return the; inverse of the cumulative distribution function (with or without; interpolation). �; We introduced an interface for any tool that can produce a; SamplingDistribution, called TestStatSampler. �The interface is; essentially GetSamplingDistribution(parameterPoint) which returns a; SamplingDistribution based on a given probability density function. �We; foresee a few versions of this tool based on toy Monte Carlo, importance; sampling, Fourier transforms, etc. �The following concrete implementation; of the TestStatSampler interface are currently available. ToyMCSamplerUses a Toy Monte Carlo approach to build the; sampling distribution. �The pdf's generate method to generate is used to; generate toy data, and then the test statistic is evaluated at the; requested parameter point. ; DebuggingSampler Simply returns a uniform distribution; between 0,1. �Useful for debugging. NeymanConstruction and FeldmanCousins; A flexible framework for the Neyman Construction was added in this; release. The NeymanConstruction is a concrete implementation of the; IntervalCalculator interface, but it needs several; additional components�to be specified before use. The design; factorizes the choice of the parameter points to be tested,�the choice of; the test statistic, and the generation of sampling distribution into; separate parts (described above). �Finally, the NeymanConstruction class; is simply in charge of using these parts (strategies) and constructing; the confidence belt and confidence intervals. �T",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:27866,Integrability,interface,interface,27866,"ion). �; We introduced an interface for any tool that can produce a; SamplingDistribution, called TestStatSampler. �The interface is; essentially GetSamplingDistribution(parameterPoint) which returns a; SamplingDistribution based on a given probability density function. �We; foresee a few versions of this tool based on toy Monte Carlo, importance; sampling, Fourier transforms, etc. �The following concrete implementation; of the TestStatSampler interface are currently available. ToyMCSamplerUses a Toy Monte Carlo approach to build the; sampling distribution. �The pdf's generate method to generate is used to; generate toy data, and then the test statistic is evaluated at the; requested parameter point. ; DebuggingSampler Simply returns a uniform distribution; between 0,1. �Useful for debugging. NeymanConstruction and FeldmanCousins; A flexible framework for the Neyman Construction was added in this; release. The NeymanConstruction is a concrete implementation of the; IntervalCalculator interface, but it needs several; additional components�to be specified before use. The design; factorizes the choice of the parameter points to be tested,�the choice of; the test statistic, and the generation of sampling distribution into; separate parts (described above). �Finally, the NeymanConstruction class; is simply in charge of using these parts (strategies) and constructing; the confidence belt and confidence intervals. �The ConfidenceBelt class; is still under development, but the current version works fine for; producing ConfidenceIntervals. �We are also working to make this class; work with parallelization approaches, which is not yet complete.; The FeldmanCousins class is a separate concrete implementation of the; IntervalCalculator interface. �It uses the NeymanConstruction internally,; and�enforces�specific choices of the test statistic and ordering; principle to realize the Unified intervals described by Feldman and; Cousins in their paper�Phys.Rev.D57:3873-3889,1998. In ",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:28621,Integrability,interface,interface,28621,"ebuggingSampler Simply returns a uniform distribution; between 0,1. �Useful for debugging. NeymanConstruction and FeldmanCousins; A flexible framework for the Neyman Construction was added in this; release. The NeymanConstruction is a concrete implementation of the; IntervalCalculator interface, but it needs several; additional components�to be specified before use. The design; factorizes the choice of the parameter points to be tested,�the choice of; the test statistic, and the generation of sampling distribution into; separate parts (described above). �Finally, the NeymanConstruction class; is simply in charge of using these parts (strategies) and constructing; the confidence belt and confidence intervals. �The ConfidenceBelt class; is still under development, but the current version works fine for; producing ConfidenceIntervals. �We are also working to make this class; work with parallelization approaches, which is not yet complete.; The FeldmanCousins class is a separate concrete implementation of the; IntervalCalculator interface. �It uses the NeymanConstruction internally,; and�enforces�specific choices of the test statistic and ordering; principle to realize the Unified intervals described by Feldman and; Cousins in their paper�Phys.Rev.D57:3873-3889,1998. In an extension to the technique discussed in Feldman and Cousins paper,; the FeldmanCousins class also performs a ""profile construction"" if their are nuisance parameters.; In this case, the parameters of interest are scanned in a regular grid. For each point in the grid; the calculator finds the best fit value of the nuisance parameters (given the data). The construction; is then only performed in this subspace of the parameters. As a result, the number of points in the; construction only scales in the number of parameters of interest, not in the number of nuisance parameters. Markov Chain Monte Carlo Interval; A flexible framework for Markov Chain Monte Carlo was added in this; release. The MCMCCalculator",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:29637,Integrability,interface,interface,29637,"tervalCalculator interface. �It uses the NeymanConstruction internally,; and�enforces�specific choices of the test statistic and ordering; principle to realize the Unified intervals described by Feldman and; Cousins in their paper�Phys.Rev.D57:3873-3889,1998. In an extension to the technique discussed in Feldman and Cousins paper,; the FeldmanCousins class also performs a ""profile construction"" if their are nuisance parameters.; In this case, the parameters of interest are scanned in a regular grid. For each point in the grid; the calculator finds the best fit value of the nuisance parameters (given the data). The construction; is then only performed in this subspace of the parameters. As a result, the number of points in the; construction only scales in the number of parameters of interest, not in the number of nuisance parameters. Markov Chain Monte Carlo Interval; A flexible framework for Markov Chain Monte Carlo was added in this; release. The MCMCCalculator is a concrete implementation of the; IntervalCalculator interface. To use it one needs to specify the ProposalFunction.; There is a base class for ProposalFunctions and one concrete implementation: UniformProposal.; Support for other proposal functions will be added in the next release.; The MCMCCalculator scans the space of the parameters of interest and nuisance parameters and; produces a Bayesian posterior. In this version, the prior must be added to the model initially,; otherwise a flat prior is assumed. The MCMCCalculator returns an MCMCInterval, which produces; the smallest interval by taking a contour of the posterior. This first version only supports; 1,2, and 3 dimensional intervals, but will be generalized in the next release. In addition to the MCMC implementation in RooStats, one can export their model and dataset into a workspace,; and then use the Bayesian Analysis Toolkit (BAT) for the MCMC. There is a wrapper available. Redesigned SPlot class; The RooStats SPlot implementation works with any",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:30513,Integrability,wrap,wrapper,30513,"Chain Monte Carlo was added in this; release. The MCMCCalculator is a concrete implementation of the; IntervalCalculator interface. To use it one needs to specify the ProposalFunction.; There is a base class for ProposalFunctions and one concrete implementation: UniformProposal.; Support for other proposal functions will be added in the next release.; The MCMCCalculator scans the space of the parameters of interest and nuisance parameters and; produces a Bayesian posterior. In this version, the prior must be added to the model initially,; otherwise a flat prior is assumed. The MCMCCalculator returns an MCMCInterval, which produces; the smallest interval by taking a contour of the posterior. This first version only supports; 1,2, and 3 dimensional intervals, but will be generalized in the next release. In addition to the MCMC implementation in RooStats, one can export their model and dataset into a workspace,; and then use the Bayesian Analysis Toolkit (BAT) for the MCMC. There is a wrapper available. Redesigned SPlot class; The RooStats SPlot implementation works with any RooAbsPdf. The class has been redesigned for more; convenient use. It also adds some helper functions to check that the sum of sWeights over species is 1 for each event and; the sum over events for a given species equals the yield for that species. Plotting classes; We have added new plotting classes: SamplingDistPlot and LikelihoodIntervalPlot.; In 1-d LikelihoodIntervalPlot shows the profile likelihood ratio and the upper/lower limits; of the interval for the parameter of interest. In 2-d, the LikelihoodIntervalPlot shows; the contour of the profile likelihood ratio for the parameters of interest. Bernstein Correction. BernsteinCorrection is a utility in RooStats to augment a nominal PDF; with a polynomial�; correction term. �This is useful for incorporating systematic variations; to the nominal PDF. �; The Bernstein basis polynomails are particularly appropriate because they; are positive defini",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:5267,Modifiability,adapt,adaptive,5267,">fitTo(data,Minimizer(""GSLMultiMin"",""conjugatefr"")) ;. Note that installation of GSL and the ROOT MathMore package is needed to access the GSL Minimizers and that the GSL; Minimizer do not implement error analysis. New numeric integration algorithms available; RooFit can now interface all MathCore numeric integration; algorithms. In this release ROOT::Math::AdaptiveIntegratorMultiDim,; which implements the 'Genz & Malik' algorithm has been interfaced; in RooAdaptiveIntegratorND and is now the default numeric integrator; for numeric integrations in two or more dimensions. This new default integrator has much improved stability and speed; for relatively smooth p.d.f.s in two or three dimensions and can; generally be used well for p.d.f. normalization integrals without; causing MINUIT converge problems due to numeric precision issues. In future release some more numeric integrators will be migrated to; a MathCore implementation. Interface to TFoam adaptive MC sampler added; RooFit can now use the TFoam adaptive MC sampler for event generation of p.d.f.s that; do not have an internal generator. The TFoam generator adaptively subdivides the; observable space and is generally more efficient both warmup and generation than the original; RooAcceptReject algorithm. In its current interface in RooFit, TFoam cannot; handle problems yet with discrete observables or conditional observables. For those problems; the original RooAcceptReject generator is still used. The choice of MC sampling algorithm can be steered through class RooNumGenConfig, which; is similar in style and structure, to RooNumIntConfig which configures the choice of; numeric integration algorithm. A new tutorial macro rf902_numgenconfig.C has been added to $ROOTSYS/tutorials/roofit; to illustrate the use of the steering. A macro that demonstrates of the power of these newly interface numeric algorithms is provided at the; end of the RooFit section of the release notes. Optional persistent caching of numeric int",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:5323,Modifiability,adapt,adaptive,5323,">fitTo(data,Minimizer(""GSLMultiMin"",""conjugatefr"")) ;. Note that installation of GSL and the ROOT MathMore package is needed to access the GSL Minimizers and that the GSL; Minimizer do not implement error analysis. New numeric integration algorithms available; RooFit can now interface all MathCore numeric integration; algorithms. In this release ROOT::Math::AdaptiveIntegratorMultiDim,; which implements the 'Genz & Malik' algorithm has been interfaced; in RooAdaptiveIntegratorND and is now the default numeric integrator; for numeric integrations in two or more dimensions. This new default integrator has much improved stability and speed; for relatively smooth p.d.f.s in two or three dimensions and can; generally be used well for p.d.f. normalization integrals without; causing MINUIT converge problems due to numeric precision issues. In future release some more numeric integrators will be migrated to; a MathCore implementation. Interface to TFoam adaptive MC sampler added; RooFit can now use the TFoam adaptive MC sampler for event generation of p.d.f.s that; do not have an internal generator. The TFoam generator adaptively subdivides the; observable space and is generally more efficient both warmup and generation than the original; RooAcceptReject algorithm. In its current interface in RooFit, TFoam cannot; handle problems yet with discrete observables or conditional observables. For those problems; the original RooAcceptReject generator is still used. The choice of MC sampling algorithm can be steered through class RooNumGenConfig, which; is similar in style and structure, to RooNumIntConfig which configures the choice of; numeric integration algorithm. A new tutorial macro rf902_numgenconfig.C has been added to $ROOTSYS/tutorials/roofit; to illustrate the use of the steering. A macro that demonstrates of the power of these newly interface numeric algorithms is provided at the; end of the RooFit section of the release notes. Optional persistent caching of numeric int",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:5436,Modifiability,adapt,adaptively,5436,"plement error analysis. New numeric integration algorithms available; RooFit can now interface all MathCore numeric integration; algorithms. In this release ROOT::Math::AdaptiveIntegratorMultiDim,; which implements the 'Genz & Malik' algorithm has been interfaced; in RooAdaptiveIntegratorND and is now the default numeric integrator; for numeric integrations in two or more dimensions. This new default integrator has much improved stability and speed; for relatively smooth p.d.f.s in two or three dimensions and can; generally be used well for p.d.f. normalization integrals without; causing MINUIT converge problems due to numeric precision issues. In future release some more numeric integrators will be migrated to; a MathCore implementation. Interface to TFoam adaptive MC sampler added; RooFit can now use the TFoam adaptive MC sampler for event generation of p.d.f.s that; do not have an internal generator. The TFoam generator adaptively subdivides the; observable space and is generally more efficient both warmup and generation than the original; RooAcceptReject algorithm. In its current interface in RooFit, TFoam cannot; handle problems yet with discrete observables or conditional observables. For those problems; the original RooAcceptReject generator is still used. The choice of MC sampling algorithm can be steered through class RooNumGenConfig, which; is similar in style and structure, to RooNumIntConfig which configures the choice of; numeric integration algorithm. A new tutorial macro rf902_numgenconfig.C has been added to $ROOTSYS/tutorials/roofit; to illustrate the use of the steering. A macro that demonstrates of the power of these newly interface numeric algorithms is provided at the; end of the RooFit section of the release notes. Optional persistent caching of numeric integrals; For p.d.f.s with numeric integrals that remain difficult or very time consuming,; a new persistent caching technique is now available that allows to precalculate; these integrals and s",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:5932,Modifiability,config,configures,5932," This new default integrator has much improved stability and speed; for relatively smooth p.d.f.s in two or three dimensions and can; generally be used well for p.d.f. normalization integrals without; causing MINUIT converge problems due to numeric precision issues. In future release some more numeric integrators will be migrated to; a MathCore implementation. Interface to TFoam adaptive MC sampler added; RooFit can now use the TFoam adaptive MC sampler for event generation of p.d.f.s that; do not have an internal generator. The TFoam generator adaptively subdivides the; observable space and is generally more efficient both warmup and generation than the original; RooAcceptReject algorithm. In its current interface in RooFit, TFoam cannot; handle problems yet with discrete observables or conditional observables. For those problems; the original RooAcceptReject generator is still used. The choice of MC sampling algorithm can be steered through class RooNumGenConfig, which; is similar in style and structure, to RooNumIntConfig which configures the choice of; numeric integration algorithm. A new tutorial macro rf902_numgenconfig.C has been added to $ROOTSYS/tutorials/roofit; to illustrate the use of the steering. A macro that demonstrates of the power of these newly interface numeric algorithms is provided at the; end of the RooFit section of the release notes. Optional persistent caching of numeric integrals; For p.d.f.s with numeric integrals that remain difficult or very time consuming,; a new persistent caching technique is now available that allows to precalculate; these integrals and store their values for future use. This technique works transparently; for any p.d.f. stored in a RooWorkspace. One can store numeric integral values for problems with zero, one or two floating parameters.; In the first case, the value is simply stored. In cases with one or two floating parameters; a grid (histogram) of integral values is stored, which are interpolated to return inte",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:7784,Modifiability,extend,extended,7784,"ating parameters; a grid (histogram) of integral values is stored, which are interpolated to return integral; values for each value of the parameters. A new tutorial macro rf903_numintcache.C has been added to $ROOTSYS/tutorials/roofit; to illustrate the use of this feature. Representation of function and p.d.f. derivatives; A new class has been added that can represent the derivative of any p.d.f or function w.r.t. any; parameter or observable. To construct e.g. a first order derivative of a Gaussian p.d.f, do. RooAbsReal* dgdx = gauss.derivative(x,1) ;. A more complete example is available in the new tutorial macro rf111_derivatives.C. Improved handling of chi-squared fits; Chi-squared fits can now be performed through the same style of interface as likelihood fits,; through the newly added method RooAbsReal::chi2FitTo(const RooDataHist&,...). Functions that can be fitted with chi-squared minimization are any RooAbsReal based function; as well as RooAbsPdf based p.d.f.s. In case of non-extended p.d.f.s the probability density; calculated by the p.d.f. is multiplied with the number of events in the histogram to adjust; the scale of the function. In case of extended p.d.f.s, the adjustment is made with the expected; number of events, rather than the observed number of events. Tutorial macro rf602_chi2fit.C has been updated to use this new interface. Chi-squared fits to X-Y datasets now possible; In addition to the ability to perform chi-squared fits to histograms it is now also possible; to perform chi-squared fits to unbinned datasets containing a series of X and Y values; with associated errors on Y and optionally on X. These 'X-Y' chi-squared fits are interfaced through newly added method; RooAbsReal::chi2FitTo(const RooDataSet&,...). By default the event weight is; interpreted as the 'Y' value, but an YVar() argument can designate any other; dataset column as Y value. If X errors are defined, one can choose to integrate the fitted; function over the range of the ",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:7957,Modifiability,extend,extended,7957,"03_numintcache.C has been added to $ROOTSYS/tutorials/roofit; to illustrate the use of this feature. Representation of function and p.d.f. derivatives; A new class has been added that can represent the derivative of any p.d.f or function w.r.t. any; parameter or observable. To construct e.g. a first order derivative of a Gaussian p.d.f, do. RooAbsReal* dgdx = gauss.derivative(x,1) ;. A more complete example is available in the new tutorial macro rf111_derivatives.C. Improved handling of chi-squared fits; Chi-squared fits can now be performed through the same style of interface as likelihood fits,; through the newly added method RooAbsReal::chi2FitTo(const RooDataHist&,...). Functions that can be fitted with chi-squared minimization are any RooAbsReal based function; as well as RooAbsPdf based p.d.f.s. In case of non-extended p.d.f.s the probability density; calculated by the p.d.f. is multiplied with the number of events in the histogram to adjust; the scale of the function. In case of extended p.d.f.s, the adjustment is made with the expected; number of events, rather than the observed number of events. Tutorial macro rf602_chi2fit.C has been updated to use this new interface. Chi-squared fits to X-Y datasets now possible; In addition to the ability to perform chi-squared fits to histograms it is now also possible; to perform chi-squared fits to unbinned datasets containing a series of X and Y values; with associated errors on Y and optionally on X. These 'X-Y' chi-squared fits are interfaced through newly added method; RooAbsReal::chi2FitTo(const RooDataSet&,...). By default the event weight is; interpreted as the 'Y' value, but an YVar() argument can designate any other; dataset column as Y value. If X errors are defined, one can choose to integrate the fitted; function over the range of the X errors, rather than taking the central value by adding; an Integrate(true) argument to chi2FitTo(); Two new arguments, StoreError(const RooArgSet&) and StoreAsymError(const ",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:9074,Modifiability,variab,variables,9074,"gram to adjust; the scale of the function. In case of extended p.d.f.s, the adjustment is made with the expected; number of events, rather than the observed number of events. Tutorial macro rf602_chi2fit.C has been updated to use this new interface. Chi-squared fits to X-Y datasets now possible; In addition to the ability to perform chi-squared fits to histograms it is now also possible; to perform chi-squared fits to unbinned datasets containing a series of X and Y values; with associated errors on Y and optionally on X. These 'X-Y' chi-squared fits are interfaced through newly added method; RooAbsReal::chi2FitTo(const RooDataSet&,...). By default the event weight is; interpreted as the 'Y' value, but an YVar() argument can designate any other; dataset column as Y value. If X errors are defined, one can choose to integrate the fitted; function over the range of the X errors, rather than taking the central value by adding; an Integrate(true) argument to chi2FitTo(); Two new arguments, StoreError(const RooArgSet&) and StoreAsymError(const RooArgSet&); have been added to the RooDataSet constructor to simplify the process of storing the errors; of X and Y variables along with their values in a dataset. The newly added tutorial macro rf609_xychi2fit.C illustrates the use of all this; new functionality. Uniform interface for creation of (profile likelihoods) and chi-squared from p.d.f.s; It is now recommended to use the method RooAbsPdf::createNLL(RooAbsData&,...) to; create a likelihood from a p.d.f and a dataset rather than constructing a RooNLLVar; object directly. This is because part of the likelihood construction functionality such a using; multiple Range()s, or the inclusion for constraint terms are only available through; createNLL(). To promote the consistency of this interface, a similar method RooAbsReal::createChi2(); has been added to construct chi-squared functions of a dataset and a function or p.d.f. Along the same lines, it is recommended to use RooAbsRe",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:13673,Modifiability,inherit,inheriting,13673,"e the parameters, but the errors will; scale with the sum of the weights, rather than the number of the events in the dataset (i.e.; if you double all event weights, all parameter errors will go down with sqrt(2)). In chi-squared; fits event weights can processed correctly by using both the sum of the weights and the; sum of the weights-squared for each bin. The newly added option SumW2Error() implements a similar; strategy for (unbinned) weighted ML fits by applying a correction to the covariance matrix; as follows. V' = V C-1 V. where V is the covariance matrix from the fit to weighted data, and C-1 is the inverse of the; covariance matrix calculated from a similar likelihood that constructed with the event weights applied squared. Redesign of RooFit dataset class structure. The original class structure of RooFit featured an abstract dataset; class RooAbsData. Inheriting from that was a single class; RooTreeData, which implemented datasets with a ROOT; TTree-based storage implementation, and inheriting from that; two classes RooDataSet , representing unbinned data, and; RooDataHist, representing binned data. A main problem with; this structure was that the implementation of the storage technology; (TTree) and the data representation (binned vs unbinned) were; intertwined. Starting with version 3.00, the class structure has been; rearranged: Now classes RooDataSet and RooDataHist inherit directly; from class RooAbsData, and class RooAbsData now owns an object that; inherits from RooAbsDataStore that implements the storage of the; data. This new class structure allows multiple data storage implementations to; be applied efficiently to both RooDataSet and RooDataHist; At present a single implementation of RooAbsDataStore exists,; class RooTreeDataStore, that contains the storage implementation; formerly implement in class RooTreeData. Methods in class RooTreeData; that were not specific to the storage technology have been moved to; class RooAbsData. If your user code ",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:14068,Modifiability,inherit,inherit,14068,"d) weighted ML fits by applying a correction to the covariance matrix; as follows. V' = V C-1 V. where V is the covariance matrix from the fit to weighted data, and C-1 is the inverse of the; covariance matrix calculated from a similar likelihood that constructed with the event weights applied squared. Redesign of RooFit dataset class structure. The original class structure of RooFit featured an abstract dataset; class RooAbsData. Inheriting from that was a single class; RooTreeData, which implemented datasets with a ROOT; TTree-based storage implementation, and inheriting from that; two classes RooDataSet , representing unbinned data, and; RooDataHist, representing binned data. A main problem with; this structure was that the implementation of the storage technology; (TTree) and the data representation (binned vs unbinned) were; intertwined. Starting with version 3.00, the class structure has been; rearranged: Now classes RooDataSet and RooDataHist inherit directly; from class RooAbsData, and class RooAbsData now owns an object that; inherits from RooAbsDataStore that implements the storage of the; data. This new class structure allows multiple data storage implementations to; be applied efficiently to both RooDataSet and RooDataHist; At present a single implementation of RooAbsDataStore exists,; class RooTreeDataStore, that contains the storage implementation; formerly implement in class RooTreeData. Methods in class RooTreeData; that were not specific to the storage technology have been moved to; class RooAbsData. If your user code only uses the classes RooDataSet,RooDataHist and RooAbsData; nothing will change: Existing RooDataSets and RooDataHists; (that inherit from RooTreeData) can be read in without problems in; RooFit 3.00 and will be converted on the fly to the new dataset structure; in memory. User code that explicitly uses RooTreeData pointers should; be changed to RooAbsData pointers. This change should be transparent; for all uses, with the exception of",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:14155,Modifiability,inherit,inherits,14155,"d) weighted ML fits by applying a correction to the covariance matrix; as follows. V' = V C-1 V. where V is the covariance matrix from the fit to weighted data, and C-1 is the inverse of the; covariance matrix calculated from a similar likelihood that constructed with the event weights applied squared. Redesign of RooFit dataset class structure. The original class structure of RooFit featured an abstract dataset; class RooAbsData. Inheriting from that was a single class; RooTreeData, which implemented datasets with a ROOT; TTree-based storage implementation, and inheriting from that; two classes RooDataSet , representing unbinned data, and; RooDataHist, representing binned data. A main problem with; this structure was that the implementation of the storage technology; (TTree) and the data representation (binned vs unbinned) were; intertwined. Starting with version 3.00, the class structure has been; rearranged: Now classes RooDataSet and RooDataHist inherit directly; from class RooAbsData, and class RooAbsData now owns an object that; inherits from RooAbsDataStore that implements the storage of the; data. This new class structure allows multiple data storage implementations to; be applied efficiently to both RooDataSet and RooDataHist; At present a single implementation of RooAbsDataStore exists,; class RooTreeDataStore, that contains the storage implementation; formerly implement in class RooTreeData. Methods in class RooTreeData; that were not specific to the storage technology have been moved to; class RooAbsData. If your user code only uses the classes RooDataSet,RooDataHist and RooAbsData; nothing will change: Existing RooDataSets and RooDataHists; (that inherit from RooTreeData) can be read in without problems in; RooFit 3.00 and will be converted on the fly to the new dataset structure; in memory. User code that explicitly uses RooTreeData pointers should; be changed to RooAbsData pointers. This change should be transparent; for all uses, with the exception of",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:14792,Modifiability,inherit,inherit,14792,"ooDataHist, representing binned data. A main problem with; this structure was that the implementation of the storage technology; (TTree) and the data representation (binned vs unbinned) were; intertwined. Starting with version 3.00, the class structure has been; rearranged: Now classes RooDataSet and RooDataHist inherit directly; from class RooAbsData, and class RooAbsData now owns an object that; inherits from RooAbsDataStore that implements the storage of the; data. This new class structure allows multiple data storage implementations to; be applied efficiently to both RooDataSet and RooDataHist; At present a single implementation of RooAbsDataStore exists,; class RooTreeDataStore, that contains the storage implementation; formerly implement in class RooTreeData. Methods in class RooTreeData; that were not specific to the storage technology have been moved to; class RooAbsData. If your user code only uses the classes RooDataSet,RooDataHist and RooAbsData; nothing will change: Existing RooDataSets and RooDataHists; (that inherit from RooTreeData) can be read in without problems in; RooFit 3.00 and will be converted on the fly to the new dataset structure; in memory. User code that explicitly uses RooTreeData pointers should; be changed to RooAbsData pointers. This change should be transparent; for all uses, with the exception of the RooTreeData::tree() method.; Explicit access to tree implementation can still be obtained; through the RooTreeDataStore::tree() method. (A pointer to the datastore; can be obtained through the RooAbsData::store() method.); Note that in future releases it is no longer guaranteed that all datasets are implemented; with a plain TTree implementation, so any user code that uses the tree; implementation directly should implement checks that the implementation; is indeed tree-based (data->store()->InheritsFrom(RooTreeDataStore::Class())==true)). In future release additional implementations of RooAbsDataStore will; be provided that will support ",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:16583,Modifiability,variab,variables,16583," (data->store()->InheritsFrom(RooTreeDataStore::Class())==true)). In future release additional implementations of RooAbsDataStore will; be provided that will support new dataset functionality such as the; ability to construct 'joint' dataset from two input datasets without; the need to copy the input data and 'filtered' datasets that represent; a reduced view (in dimensions or by selecting events) of a dataset; without the need to copy content. Various workspace improvements. A number of smaller and larger improvements has been made to the RooWorkspace class. Direct interactive access to contents from CINT -; One can now directly access the contents of any RooWorkspace; on the ROOT commandline through CINT if the RooWorkspace::exportToCint() call is made.; In CINT, all workspace objects will appear as correctly typed references to workspace objects in; a C++ namespace with the same name as the RooWorkspace object. Given e.g. a workspace w, with a Gaussian p.d.f gauss in terms of variables; x,m,s one can now do. RooWorkspace w(""w"",true) ; // workspace with CINT interface activated; // ... fill workspace with RooGaussian gauss(x,m,s) ...; RooPlot* frame = w::x.frame() ;; w::gauss.plotOn(frame) ;. to access the workspace contents. Each reference has the correct type, e.g. w::gauss is; a RooGaussian&. If a workspace is deleted from memory, the corresponding CINT namespace; is removed as well. Note that this feature is strictly available in interpreted C++ only; A new tutorial macro has been added to illustrate this functionality in more detail: rf509_wsinteractive.C.; writeToFile -- A new utility method RooWorkspace::writeToFile() has been added; to simplify the process of saving a workspace to file; Named sets and parameter snapshots -- It is now possible to define and retrieve; named RooArgSets of objects that live in the workspace through methods; defineSet() and set(). While named sets merely group objects logically, methods loadSnapshot and; saveSnapshot allow to m",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:17656,Modifiability,variab,variable,17656,",m,s one can now do. RooWorkspace w(""w"",true) ; // workspace with CINT interface activated; // ... fill workspace with RooGaussian gauss(x,m,s) ...; RooPlot* frame = w::x.frame() ;; w::gauss.plotOn(frame) ;. to access the workspace contents. Each reference has the correct type, e.g. w::gauss is; a RooGaussian&. If a workspace is deleted from memory, the corresponding CINT namespace; is removed as well. Note that this feature is strictly available in interpreted C++ only; A new tutorial macro has been added to illustrate this functionality in more detail: rf509_wsinteractive.C.; writeToFile -- A new utility method RooWorkspace::writeToFile() has been added; to simplify the process of saving a workspace to file; Named sets and parameter snapshots -- It is now possible to define and retrieve; named RooArgSets of objects that live in the workspace through methods; defineSet() and set(). While named sets merely group objects logically, methods loadSnapshot and; saveSnapshot allow to make copies of the values, errors and 'constant' status of; sets of variable objects that live in the workspace. A newly added tutorial macro rf510_namedsets.C illustrates the functionality of both; of these features.; Improved printing of contents -- Many operator p.d.f. and function components now show; a more intuitive natural representation of their contents (these changes are mostly in the; respective p.d.f.s, but are most relevant in the context of a workspace). New object factory interface to workspace to facilitate script driven model definition; A object factory has been added to RooFit to simplify the process of creating p.d.f.; and function expressions consisting of multiple objects. The factory has two goals:; the first is to provide a back-end for higher level factories and tools to process; the creation of objects. The second is to provide a simple end-user language to; populate a RooWorkspace with function and p.d.f. objects. For the latter purpose the object creation language ",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:18839,Modifiability,variab,variables,18839," -- Many operator p.d.f. and function components now show; a more intuitive natural representation of their contents (these changes are mostly in the; respective p.d.f.s, but are most relevant in the context of a workspace). New object factory interface to workspace to facilitate script driven model definition; A object factory has been added to RooFit to simplify the process of creating p.d.f.; and function expressions consisting of multiple objects. The factory has two goals:; the first is to provide a back-end for higher level factories and tools to process; the creation of objects. The second is to provide a simple end-user language to; populate a RooWorkspace with function and p.d.f. objects. For the latter purpose the object creation language is executed through the factory() method; of a workspace object. RooWorkspace w(""w"") ;; RooAbsArg* arg = w.factory(""expression_goes_here"") ;. Basic Syntax; The rules at its simplest level are as follows. Expressions with square brackets create variables (discrete and continuous). ""m[-10,10]"" - Creates a RooRealVar named 'm' with range [-10,10]; ""m[5,-10,10]"" - Idem, but with initial value 5; ""m[5]"" - Creates a constant RooRealVar with name 'm' and value 5. ""tagCat[Lep,Kao,NT1,NT2]"" -- Creates a RooCategory with name tagCat and labeled states Lep,Kao,NT1,NT2; ""b0flav[B0=1,B0bar=-1]"" -- Creates a RooCategory with name b0flav and states B0 and B0bar with explicit index assignments. Expressions with parentheses create RooAbsArg function objects of any type. ""RooGaussian::g(x,m,s)"" -- Create a RooGaussian named g with variables x,m,s; This expression maps 1-1 to a createArg() call. ""Gaussian::g(x,m,s)"" -- Idem. The 'Roo' prefix on any class may be omitted. ""Gaussian(x,m,s)"" -- Create a RooGaussian with an automatically assigned name with variables x,m,s. Expressions with curly brackets creates RooArgSets or RooArgLists ""{x,y,z}"". Compound expressions; The real power of this language is that all these expressions may be nested t",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:19420,Modifiability,variab,variables,19420,"bjects. The second is to provide a simple end-user language to; populate a RooWorkspace with function and p.d.f. objects. For the latter purpose the object creation language is executed through the factory() method; of a workspace object. RooWorkspace w(""w"") ;; RooAbsArg* arg = w.factory(""expression_goes_here"") ;. Basic Syntax; The rules at its simplest level are as follows. Expressions with square brackets create variables (discrete and continuous). ""m[-10,10]"" - Creates a RooRealVar named 'm' with range [-10,10]; ""m[5,-10,10]"" - Idem, but with initial value 5; ""m[5]"" - Creates a constant RooRealVar with name 'm' and value 5. ""tagCat[Lep,Kao,NT1,NT2]"" -- Creates a RooCategory with name tagCat and labeled states Lep,Kao,NT1,NT2; ""b0flav[B0=1,B0bar=-1]"" -- Creates a RooCategory with name b0flav and states B0 and B0bar with explicit index assignments. Expressions with parentheses create RooAbsArg function objects of any type. ""RooGaussian::g(x,m,s)"" -- Create a RooGaussian named g with variables x,m,s; This expression maps 1-1 to a createArg() call. ""Gaussian::g(x,m,s)"" -- Idem. The 'Roo' prefix on any class may be omitted. ""Gaussian(x,m,s)"" -- Create a RooGaussian with an automatically assigned name with variables x,m,s. Expressions with curly brackets creates RooArgSets or RooArgLists ""{x,y,z}"". Compound expressions; The real power of this language is that all these expressions may be nested to result in a compact; and readable expression that creates an entire p.d.f. and its components. ""Gaussian::g(x[-10,10],m[-10,10],3)"". Creates a RooGaussian named 'g', its observables 'x' with range [-10,10],; its parameter 'm' with range [-10,10]' and a constant width of 3. ""SUM::model( f[0.5,0,1] * Gaussian( x[-10,10], m[0], 3] ),; Chebychev( x, {a0[0.1],a1[0.2],a2[-0.3]}))"". Create a RooAddPdf model of a RooGaussian and a RooChebychev (which; are implicitly named model_0 and model_1), its observable x and its; parameters m,a0,a1,a2,Nsig and Nbkg; Note that each object may be",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:19644,Modifiability,variab,variables,19644,"ough the factory() method; of a workspace object. RooWorkspace w(""w"") ;; RooAbsArg* arg = w.factory(""expression_goes_here"") ;. Basic Syntax; The rules at its simplest level are as follows. Expressions with square brackets create variables (discrete and continuous). ""m[-10,10]"" - Creates a RooRealVar named 'm' with range [-10,10]; ""m[5,-10,10]"" - Idem, but with initial value 5; ""m[5]"" - Creates a constant RooRealVar with name 'm' and value 5. ""tagCat[Lep,Kao,NT1,NT2]"" -- Creates a RooCategory with name tagCat and labeled states Lep,Kao,NT1,NT2; ""b0flav[B0=1,B0bar=-1]"" -- Creates a RooCategory with name b0flav and states B0 and B0bar with explicit index assignments. Expressions with parentheses create RooAbsArg function objects of any type. ""RooGaussian::g(x,m,s)"" -- Create a RooGaussian named g with variables x,m,s; This expression maps 1-1 to a createArg() call. ""Gaussian::g(x,m,s)"" -- Idem. The 'Roo' prefix on any class may be omitted. ""Gaussian(x,m,s)"" -- Create a RooGaussian with an automatically assigned name with variables x,m,s. Expressions with curly brackets creates RooArgSets or RooArgLists ""{x,y,z}"". Compound expressions; The real power of this language is that all these expressions may be nested to result in a compact; and readable expression that creates an entire p.d.f. and its components. ""Gaussian::g(x[-10,10],m[-10,10],3)"". Creates a RooGaussian named 'g', its observables 'x' with range [-10,10],; its parameter 'm' with range [-10,10]' and a constant width of 3. ""SUM::model( f[0.5,0,1] * Gaussian( x[-10,10], m[0], 3] ),; Chebychev( x, {a0[0.1],a1[0.2],a2[-0.3]}))"". Create a RooAddPdf model of a RooGaussian and a RooChebychev (which; are implicitly named model_0 and model_1), its observable x and its; parameters m,a0,a1,a2,Nsig and Nbkg; Note that each object may be created only once (with [] or () brackets) but may be referenced multiple; times in the expression by just giving the name. Here is a much more complicated example:. ""PROD::sig(BMixDecay::",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:22070,Modifiability,adapt,adaptive,22070,"event error dterr and all its parameters, convoluted with a triple; gaussian resolution model and multiplied with a Gaussian p.d.f. in the; energy substituted mass. (In plain RooFit this would have required at; least 23 lines of code). A series of three new tutorial macros has been added to illustrate the; various features of the object factory. rf511_wsfactory_basic.C - Basic factory concepts; rf512_wsfactory_oper.C - Using operator p.d.f.s in the factory; rf513_wsfactory_tools.C - Advanced example using interfaced high level tools. A formal transaction model is used to commit composite objects into; the workspace. If an error is detected in the expression, no objects; will be committed to the workspace, thus leaving no 'partial builds'. Compact demo of several new major features. The macro below demonstrates in a couple of lines a number of major new features in RooFit 3.00: Use of. workspace factory to quickly create and store (compiled) models; workspace CINT interface to easily access contents in a typesafe way; new adaptive ND numeric integration technique to normalize arbitrary p.d.f. in fast; and reliable way; new adaptive TFoam sampling technique to efficiently generate toy MC data from strongly; peaked datasets; parallel processing in likelihood construction and use of profile likelihood operator; to represent profile likelihoods as regular RooFit functions. void demo(); {; // Construct compiled 2-D model that requires numeric integration for normalization; RooWorkspace w(""w"",1) ;; w.factory(""CEXPR::model('1/((x-a)*(x-a)+0.001)+1/((y-b)*(y-b)+0.001)',x[-1,1],y[-1,1],a[-5,5],b[-5,5])"") ;. // Generate data from model (using TFoam adaptive sampling algorithm); RooDataSet* d = w::model.generate(RooArgSet(w::x,w::y),1000) ;; w::model.fitTo(*d) ;. // Make 2D plot on (x,y); TH2* hh = w::model.createHistogram(""x,y"",40,40) ;; hh->SetLineColor(kBlue) ;. // Make Projection on x (integrate over y); RooPlot* framex = w::x.frame(Title(""Data and p.d.f. projected on X"")) ;",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:22173,Modifiability,adapt,adaptive,22173,"hree new tutorial macros has been added to illustrate the; various features of the object factory. rf511_wsfactory_basic.C - Basic factory concepts; rf512_wsfactory_oper.C - Using operator p.d.f.s in the factory; rf513_wsfactory_tools.C - Advanced example using interfaced high level tools. A formal transaction model is used to commit composite objects into; the workspace. If an error is detected in the expression, no objects; will be committed to the workspace, thus leaving no 'partial builds'. Compact demo of several new major features. The macro below demonstrates in a couple of lines a number of major new features in RooFit 3.00: Use of. workspace factory to quickly create and store (compiled) models; workspace CINT interface to easily access contents in a typesafe way; new adaptive ND numeric integration technique to normalize arbitrary p.d.f. in fast; and reliable way; new adaptive TFoam sampling technique to efficiently generate toy MC data from strongly; peaked datasets; parallel processing in likelihood construction and use of profile likelihood operator; to represent profile likelihoods as regular RooFit functions. void demo(); {; // Construct compiled 2-D model that requires numeric integration for normalization; RooWorkspace w(""w"",1) ;; w.factory(""CEXPR::model('1/((x-a)*(x-a)+0.001)+1/((y-b)*(y-b)+0.001)',x[-1,1],y[-1,1],a[-5,5],b[-5,5])"") ;. // Generate data from model (using TFoam adaptive sampling algorithm); RooDataSet* d = w::model.generate(RooArgSet(w::x,w::y),1000) ;; w::model.fitTo(*d) ;. // Make 2D plot on (x,y); TH2* hh = w::model.createHistogram(""x,y"",40,40) ;; hh->SetLineColor(kBlue) ;. // Make Projection on x (integrate over y); RooPlot* framex = w::x.frame(Title(""Data and p.d.f. projected on X"")) ;; d->plotOn(framex) ;; w::model.plotOn(framex) ;. // Construct likelihood, profile likelihood in a, and draw the latter; RooAbsReal* nll = w::model.createNLL(*d,NumCPU(2)) ;; RooAbsReal* pll = nll->createProfile(w::a) ;; RooPlot* framea = w::a.fram",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:22699,Modifiability,adapt,adaptive,22699,"jects; will be committed to the workspace, thus leaving no 'partial builds'. Compact demo of several new major features. The macro below demonstrates in a couple of lines a number of major new features in RooFit 3.00: Use of. workspace factory to quickly create and store (compiled) models; workspace CINT interface to easily access contents in a typesafe way; new adaptive ND numeric integration technique to normalize arbitrary p.d.f. in fast; and reliable way; new adaptive TFoam sampling technique to efficiently generate toy MC data from strongly; peaked datasets; parallel processing in likelihood construction and use of profile likelihood operator; to represent profile likelihoods as regular RooFit functions. void demo(); {; // Construct compiled 2-D model that requires numeric integration for normalization; RooWorkspace w(""w"",1) ;; w.factory(""CEXPR::model('1/((x-a)*(x-a)+0.001)+1/((y-b)*(y-b)+0.001)',x[-1,1],y[-1,1],a[-5,5],b[-5,5])"") ;. // Generate data from model (using TFoam adaptive sampling algorithm); RooDataSet* d = w::model.generate(RooArgSet(w::x,w::y),1000) ;; w::model.fitTo(*d) ;. // Make 2D plot on (x,y); TH2* hh = w::model.createHistogram(""x,y"",40,40) ;; hh->SetLineColor(kBlue) ;. // Make Projection on x (integrate over y); RooPlot* framex = w::x.frame(Title(""Data and p.d.f. projected on X"")) ;; d->plotOn(framex) ;; w::model.plotOn(framex) ;. // Construct likelihood, profile likelihood in a, and draw the latter; RooAbsReal* nll = w::model.createNLL(*d,NumCPU(2)) ;; RooAbsReal* pll = nll->createProfile(w::a) ;; RooPlot* framea = w::a.frame(Title(""Profile likelihood in parameter a"")) ;; pll->plotOn(framea) ;. // Construct 2D cumulative distribution function from p.d.f.; RooAbsReal* cdfxy = w::model.createCdf(RooArgSet(w::x,w::y),ScanNoCdf()) ;; TH2* hhcdf = cdfxy->createHistogram(""x,y"",40,40) ;; hhcdf->SetLineColor(kRed) ;. TCanvas* c = new TCanvas(""c"",""c"",650,650) ; c->Divide(2,2) ;; c->cd(1) ; hh->Draw(""surf"") ; c->cd(2) ; framex->Draw() ;; c->cd(3) ; f",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:27712,Modifiability,flexible,flexible,27712,"ry real valued test statistic. �The class also can return the; inverse of the cumulative distribution function (with or without; interpolation). �; We introduced an interface for any tool that can produce a; SamplingDistribution, called TestStatSampler. �The interface is; essentially GetSamplingDistribution(parameterPoint) which returns a; SamplingDistribution based on a given probability density function. �We; foresee a few versions of this tool based on toy Monte Carlo, importance; sampling, Fourier transforms, etc. �The following concrete implementation; of the TestStatSampler interface are currently available. ToyMCSamplerUses a Toy Monte Carlo approach to build the; sampling distribution. �The pdf's generate method to generate is used to; generate toy data, and then the test statistic is evaluated at the; requested parameter point. ; DebuggingSampler Simply returns a uniform distribution; between 0,1. �Useful for debugging. NeymanConstruction and FeldmanCousins; A flexible framework for the Neyman Construction was added in this; release. The NeymanConstruction is a concrete implementation of the; IntervalCalculator interface, but it needs several; additional components�to be specified before use. The design; factorizes the choice of the parameter points to be tested,�the choice of; the test statistic, and the generation of sampling distribution into; separate parts (described above). �Finally, the NeymanConstruction class; is simply in charge of using these parts (strategies) and constructing; the confidence belt and confidence intervals. �The ConfidenceBelt class; is still under development, but the current version works fine for; producing ConfidenceIntervals. �We are also working to make this class; work with parallelization approaches, which is not yet complete.; The FeldmanCousins class is a separate concrete implementation of the; IntervalCalculator interface. �It uses the NeymanConstruction internally,; and�enforces�specific choices of the test statistic",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:29486,Modifiability,flexible,flexible,29486,"hich is not yet complete.; The FeldmanCousins class is a separate concrete implementation of the; IntervalCalculator interface. �It uses the NeymanConstruction internally,; and�enforces�specific choices of the test statistic and ordering; principle to realize the Unified intervals described by Feldman and; Cousins in their paper�Phys.Rev.D57:3873-3889,1998. In an extension to the technique discussed in Feldman and Cousins paper,; the FeldmanCousins class also performs a ""profile construction"" if their are nuisance parameters.; In this case, the parameters of interest are scanned in a regular grid. For each point in the grid; the calculator finds the best fit value of the nuisance parameters (given the data). The construction; is then only performed in this subspace of the parameters. As a result, the number of points in the; construction only scales in the number of parameters of interest, not in the number of nuisance parameters. Markov Chain Monte Carlo Interval; A flexible framework for Markov Chain Monte Carlo was added in this; release. The MCMCCalculator is a concrete implementation of the; IntervalCalculator interface. To use it one needs to specify the ProposalFunction.; There is a base class for ProposalFunctions and one concrete implementation: UniformProposal.; Support for other proposal functions will be added in the next release.; The MCMCCalculator scans the space of the parameters of interest and nuisance parameters and; produces a Bayesian posterior. In this version, the prior must be added to the model initially,; otherwise a flat prior is assumed. The MCMCCalculator returns an MCMCInterval, which produces; the smallest interval by taking a contour of the posterior. This first version only supports; 1,2, and 3 dimensional intervals, but will be generalized in the next release. In addition to the MCMC implementation in RooStats, one can export their model and dataset into a workspace,; and then use the Bayesian Analysis Toolkit (BAT) for the MCMC. The",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:1940,Performance,perform,perform,1940,"taken from the fit result; Corr(a,a') = the correlation matrix from the fit result; Z = requested significance 'Z sigma band'. The linear method is fast (requires 2*N evaluations of the curve,; where N is the number of parameters), but may not be accurate in the; presence of strong correlations (~>0.9) and at Z>2 due to linear and; Gaussian approximations made. Alternatively, errors can be visualized using a sampling method. In; this method a number of curves is calculated with variations of the; parameter values, as sampled from a multi-variate Gaussian p.d.f. that; is constructed from the fit results covariance matrix. The error(x); is determined by calculating a central interval that capture N% of the; variations for each value of x, where N% is controlled by Z (i.e. Z=1; gives N=68%). The number of sampling curves is chosen to be such that; at least 100 curves are expected to be outside the N% interval. Intervals from; the sampling method can be asymmetric, and may perform better in the; presence of strong correlations, but may take (much) longer to; calculate. The sampling method also assumes that the uncertainty on the; parameters can modeled by a multi-variate Gaussian distribution. A complete example is provided in a new tutorial macro rf610_visualerror.C,; the output of which is shown below. It is also possible to visualize partial errors (from a subset of the parameters),; as shown above. Binned dataset generation. A new method RooAbsPdf::generateBinned() has been implemented; that samples binned datasets (RooDataHist) from any; p.d.f. RooDataHist* data = pdf.generateBinned(x,10000) ;. This binned generation interface samples the p.d.f. at each bin; center and applies a Poisson fluctuation to each sampled value.; The binning of the returned RooDataHist is controlled by the default; binning associated with the observables generated. To set the number; of bins in x to 200, do e.g. x.setBins(200) prior to the call; to generateBinned(). The binned dataset gener",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:7494,Performance,perform,performed,7494,"se. This technique works transparently; for any p.d.f. stored in a RooWorkspace. One can store numeric integral values for problems with zero, one or two floating parameters.; In the first case, the value is simply stored. In cases with one or two floating parameters; a grid (histogram) of integral values is stored, which are interpolated to return integral; values for each value of the parameters. A new tutorial macro rf903_numintcache.C has been added to $ROOTSYS/tutorials/roofit; to illustrate the use of this feature. Representation of function and p.d.f. derivatives; A new class has been added that can represent the derivative of any p.d.f or function w.r.t. any; parameter or observable. To construct e.g. a first order derivative of a Gaussian p.d.f, do. RooAbsReal* dgdx = gauss.derivative(x,1) ;. A more complete example is available in the new tutorial macro rf111_derivatives.C. Improved handling of chi-squared fits; Chi-squared fits can now be performed through the same style of interface as likelihood fits,; through the newly added method RooAbsReal::chi2FitTo(const RooDataHist&,...). Functions that can be fitted with chi-squared minimization are any RooAbsReal based function; as well as RooAbsPdf based p.d.f.s. In case of non-extended p.d.f.s the probability density; calculated by the p.d.f. is multiplied with the number of events in the histogram to adjust; the scale of the function. In case of extended p.d.f.s, the adjustment is made with the expected; number of events, rather than the observed number of events. Tutorial macro rf602_chi2fit.C has been updated to use this new interface. Chi-squared fits to X-Y datasets now possible; In addition to the ability to perform chi-squared fits to histograms it is now also possible; to perform chi-squared fits to unbinned datasets containing a series of X and Y values; with associated errors on Y and optionally on X. These 'X-Y' chi-squared fits are interfaced through newly added method; RooAbsReal::chi2FitTo(const",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:8230,Performance,perform,perform,8230,".f, do. RooAbsReal* dgdx = gauss.derivative(x,1) ;. A more complete example is available in the new tutorial macro rf111_derivatives.C. Improved handling of chi-squared fits; Chi-squared fits can now be performed through the same style of interface as likelihood fits,; through the newly added method RooAbsReal::chi2FitTo(const RooDataHist&,...). Functions that can be fitted with chi-squared minimization are any RooAbsReal based function; as well as RooAbsPdf based p.d.f.s. In case of non-extended p.d.f.s the probability density; calculated by the p.d.f. is multiplied with the number of events in the histogram to adjust; the scale of the function. In case of extended p.d.f.s, the adjustment is made with the expected; number of events, rather than the observed number of events. Tutorial macro rf602_chi2fit.C has been updated to use this new interface. Chi-squared fits to X-Y datasets now possible; In addition to the ability to perform chi-squared fits to histograms it is now also possible; to perform chi-squared fits to unbinned datasets containing a series of X and Y values; with associated errors on Y and optionally on X. These 'X-Y' chi-squared fits are interfaced through newly added method; RooAbsReal::chi2FitTo(const RooDataSet&,...). By default the event weight is; interpreted as the 'Y' value, but an YVar() argument can designate any other; dataset column as Y value. If X errors are defined, one can choose to integrate the fitted; function over the range of the X errors, rather than taking the central value by adding; an Integrate(true) argument to chi2FitTo(); Two new arguments, StoreError(const RooArgSet&) and StoreAsymError(const RooArgSet&); have been added to the RooDataSet constructor to simplify the process of storing the errors; of X and Y variables along with their values in a dataset. The newly added tutorial macro rf609_xychi2fit.C illustrates the use of all this; new functionality. Uniform interface for creation of (profile likelihoods) and chi-squa",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:8297,Performance,perform,perform,8297,".f, do. RooAbsReal* dgdx = gauss.derivative(x,1) ;. A more complete example is available in the new tutorial macro rf111_derivatives.C. Improved handling of chi-squared fits; Chi-squared fits can now be performed through the same style of interface as likelihood fits,; through the newly added method RooAbsReal::chi2FitTo(const RooDataHist&,...). Functions that can be fitted with chi-squared minimization are any RooAbsReal based function; as well as RooAbsPdf based p.d.f.s. In case of non-extended p.d.f.s the probability density; calculated by the p.d.f. is multiplied with the number of events in the histogram to adjust; the scale of the function. In case of extended p.d.f.s, the adjustment is made with the expected; number of events, rather than the observed number of events. Tutorial macro rf602_chi2fit.C has been updated to use this new interface. Chi-squared fits to X-Y datasets now possible; In addition to the ability to perform chi-squared fits to histograms it is now also possible; to perform chi-squared fits to unbinned datasets containing a series of X and Y values; with associated errors on Y and optionally on X. These 'X-Y' chi-squared fits are interfaced through newly added method; RooAbsReal::chi2FitTo(const RooDataSet&,...). By default the event weight is; interpreted as the 'Y' value, but an YVar() argument can designate any other; dataset column as Y value. If X errors are defined, one can choose to integrate the fitted; function over the range of the X errors, rather than taking the central value by adding; an Integrate(true) argument to chi2FitTo(); Two new arguments, StoreError(const RooArgSet&) and StoreAsymError(const RooArgSet&); have been added to the RooDataSet constructor to simplify the process of storing the errors; of X and Y variables along with their values in a dataset. The newly added tutorial macro rf609_xychi2fit.C illustrates the use of all this; new functionality. Uniform interface for creation of (profile likelihoods) and chi-squa",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:11080,Performance,perform,performance,11080,"object. Multivariate Gaussian modeling of parameters estimates from a fit; You can now construct a multivariate Gaussian p.d.f on the parameters of a model that; represents the result of a fit, from any RooFitResult object. RooAbsPdf* paramPdf = fitresult->createHessePdf(RooArgSet(a,b)) ;. The returned object is an instance of the newly added class RooMultiVarGaussian, that can; model correlated Gaussian distributions in an arbitrary number of dimensions, given a; vector of mean values and a covariance matrix. Class RooMultivarGaussian implements analytical; integration as well as analytical partial integrals over the first 31 dimensions (if you have; that many) and implements in effect internal generation strategy for its observables. A new tutorial macro rf608_fitresultaspdf.C has been added to illustrate the use MV Gaussians constructed from a RooFitResult; Improved functionality of RooFFTConvPdf; The FFT convolution operator p.d.f. class RooFFTConvPdf has been substantially upgraded; for improved performance has several new options. For the overflow buffering, which aims to reduce cylical spillover from the FFT convolution,; a choice of three algorithms is now provided:. Extend the p.d.f. somewhat beyond its original domain (the new default); Fill the buffer 50/50 with the value of the p.d.f at the upper/lower bound of the convolution observable (the previous default); Mirror the p.d.f. over the boundary. The new default algorithm provides a more sensible result for p.d.f.s with significant; spillover issues, provided that the p.d.f. can be continuated beyond its original domain.; Convolution in non-observables is also explicitly supported now. One can e.g. construct a p.d.f; of the form G(x) = Int[dy] ( F(x,y) (*) H(y) ). A new tutorial macro rf211_paramconv illustrates; how such convolutions can be constructed; It is now also possible to express FFT convolutions in terms of other observables than the; convolution observable itself. A common occurrence of that s",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:12506,Performance,perform,perform,12506,"efault algorithm provides a more sensible result for p.d.f.s with significant; spillover issues, provided that the p.d.f. can be continuated beyond its original domain.; Convolution in non-observables is also explicitly supported now. One can e.g. construct a p.d.f; of the form G(x) = Int[dy] ( F(x,y) (*) H(y) ). A new tutorial macro rf211_paramconv illustrates; how such convolutions can be constructed; It is now also possible to express FFT convolutions in terms of other observables than the; convolution observable itself. A common occurrence of that situation is a (circular) convolution a polar; angle theta, for a p.d.f. that is ultimately expressed in terms of cos(theta).; A new tutorial macro rf210_angularconv illustrates how to convolutions of angular observable; with or without an optional cosine transformation for the final observable. Option for improved calculation of errors in weighted likelihood fits. A new option SumW2Error() has been added to RooAbsPdf::fitTo() that will; perform an improved error calculation for weighted unbinned likelihood fits. In their unmodified; form, an ML fit to a weighted dataset will correctly estimate the parameters, but the errors will; scale with the sum of the weights, rather than the number of the events in the dataset (i.e.; if you double all event weights, all parameter errors will go down with sqrt(2)). In chi-squared; fits event weights can processed correctly by using both the sum of the weights and the; sum of the weights-squared for each bin. The newly added option SumW2Error() implements a similar; strategy for (unbinned) weighted ML fits by applying a correction to the covariance matrix; as follows. V' = V C-1 V. where V is the covariance matrix from the fit to weighted data, and C-1 is the inverse of the; covariance matrix calculated from a similar likelihood that constructed with the event weights applied squared. Redesign of RooFit dataset class structure. The original class structure of RooFit featured an abst",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:17548,Performance,load,loadSnapshot,17548,",m,s one can now do. RooWorkspace w(""w"",true) ; // workspace with CINT interface activated; // ... fill workspace with RooGaussian gauss(x,m,s) ...; RooPlot* frame = w::x.frame() ;; w::gauss.plotOn(frame) ;. to access the workspace contents. Each reference has the correct type, e.g. w::gauss is; a RooGaussian&. If a workspace is deleted from memory, the corresponding CINT namespace; is removed as well. Note that this feature is strictly available in interpreted C++ only; A new tutorial macro has been added to illustrate this functionality in more detail: rf509_wsinteractive.C.; writeToFile -- A new utility method RooWorkspace::writeToFile() has been added; to simplify the process of saving a workspace to file; Named sets and parameter snapshots -- It is now possible to define and retrieve; named RooArgSets of objects that live in the workspace through methods; defineSet() and set(). While named sets merely group objects logically, methods loadSnapshot and; saveSnapshot allow to make copies of the values, errors and 'constant' status of; sets of variable objects that live in the workspace. A newly added tutorial macro rf510_namedsets.C illustrates the functionality of both; of these features.; Improved printing of contents -- Many operator p.d.f. and function components now show; a more intuitive natural representation of their contents (these changes are mostly in the; respective p.d.f.s, but are most relevant in the context of a workspace). New object factory interface to workspace to facilitate script driven model definition; A object factory has been added to RooFit to simplify the process of creating p.d.f.; and function expressions consisting of multiple objects. The factory has two goals:; the first is to provide a back-end for higher level factories and tools to process; the creation of objects. The second is to provide a simple end-user language to; populate a RooWorkspace with function and p.d.f. objects. For the latter purpose the object creation language ",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:28968,Performance,perform,performs,28968,"The design; factorizes the choice of the parameter points to be tested,�the choice of; the test statistic, and the generation of sampling distribution into; separate parts (described above). �Finally, the NeymanConstruction class; is simply in charge of using these parts (strategies) and constructing; the confidence belt and confidence intervals. �The ConfidenceBelt class; is still under development, but the current version works fine for; producing ConfidenceIntervals. �We are also working to make this class; work with parallelization approaches, which is not yet complete.; The FeldmanCousins class is a separate concrete implementation of the; IntervalCalculator interface. �It uses the NeymanConstruction internally,; and�enforces�specific choices of the test statistic and ordering; principle to realize the Unified intervals described by Feldman and; Cousins in their paper�Phys.Rev.D57:3873-3889,1998. In an extension to the technique discussed in Feldman and Cousins paper,; the FeldmanCousins class also performs a ""profile construction"" if their are nuisance parameters.; In this case, the parameters of interest are scanned in a regular grid. For each point in the grid; the calculator finds the best fit value of the nuisance parameters (given the data). The construction; is then only performed in this subspace of the parameters. As a result, the number of points in the; construction only scales in the number of parameters of interest, not in the number of nuisance parameters. Markov Chain Monte Carlo Interval; A flexible framework for Markov Chain Monte Carlo was added in this; release. The MCMCCalculator is a concrete implementation of the; IntervalCalculator interface. To use it one needs to specify the ProposalFunction.; There is a base class for ProposalFunctions and one concrete implementation: UniformProposal.; Support for other proposal functions will be added in the next release.; The MCMCCalculator scans the space of the parameters of interest and nuisance p",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:29253,Performance,perform,performed,29253,"fidence belt and confidence intervals. �The ConfidenceBelt class; is still under development, but the current version works fine for; producing ConfidenceIntervals. �We are also working to make this class; work with parallelization approaches, which is not yet complete.; The FeldmanCousins class is a separate concrete implementation of the; IntervalCalculator interface. �It uses the NeymanConstruction internally,; and�enforces�specific choices of the test statistic and ordering; principle to realize the Unified intervals described by Feldman and; Cousins in their paper�Phys.Rev.D57:3873-3889,1998. In an extension to the technique discussed in Feldman and Cousins paper,; the FeldmanCousins class also performs a ""profile construction"" if their are nuisance parameters.; In this case, the parameters of interest are scanned in a regular grid. For each point in the grid; the calculator finds the best fit value of the nuisance parameters (given the data). The construction; is then only performed in this subspace of the parameters. As a result, the number of points in the; construction only scales in the number of parameters of interest, not in the number of nuisance parameters. Markov Chain Monte Carlo Interval; A flexible framework for Markov Chain Monte Carlo was added in this; release. The MCMCCalculator is a concrete implementation of the; IntervalCalculator interface. To use it one needs to specify the ProposalFunction.; There is a base class for ProposalFunctions and one concrete implementation: UniformProposal.; Support for other proposal functions will be added in the next release.; The MCMCCalculator scans the space of the parameters of interest and nuisance parameters and; produces a Bayesian posterior. In this version, the prior must be added to the model initially,; otherwise a flat prior is assumed. The MCMCCalculator returns an MCMCInterval, which produces; the smallest interval by taking a contour of the posterior. This first version only supports; 1,2, and 3",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:21672,Safety,detect,detected,21672,",; AddModel({GaussModel(dt,biasC[-10,10],sigmaC[0.1,3],dterr[0.01,0.2]),; GaussModel(dt,0,sigmaT[3,10]),; GaussModel(dt,0,20)},{fracC[0,1],fracT[0,1]}),; DoubleSided ),; Gaussian::sig_m( mes[5.20,5.30], mB0[5.20,5.30], sigmB0[0.01,0.05] )"". This create a double-sided Bmixing decay p.d.f. with observables dt,; per-event error dterr and all its parameters, convoluted with a triple; gaussian resolution model and multiplied with a Gaussian p.d.f. in the; energy substituted mass. (In plain RooFit this would have required at; least 23 lines of code). A series of three new tutorial macros has been added to illustrate the; various features of the object factory. rf511_wsfactory_basic.C - Basic factory concepts; rf512_wsfactory_oper.C - Using operator p.d.f.s in the factory; rf513_wsfactory_tools.C - Advanced example using interfaced high level tools. A formal transaction model is used to commit composite objects into; the workspace. If an error is detected in the expression, no objects; will be committed to the workspace, thus leaving no 'partial builds'. Compact demo of several new major features. The macro below demonstrates in a couple of lines a number of major new features in RooFit 3.00: Use of. workspace factory to quickly create and store (compiled) models; workspace CINT interface to easily access contents in a typesafe way; new adaptive ND numeric integration technique to normalize arbitrary p.d.f. in fast; and reliable way; new adaptive TFoam sampling technique to efficiently generate toy MC data from strongly; peaked datasets; parallel processing in likelihood construction and use of profile likelihood operator; to represent profile likelihoods as regular RooFit functions. void demo(); {; // Construct compiled 2-D model that requires numeric integration for normalization; RooWorkspace w(""w"",1) ;; w.factory(""CEXPR::model('1/((x-a)*(x-a)+0.001)+1/((y-b)*(y-b)+0.001)',x[-1,1],y[-1,1],a[-5,5],b[-5,5])"") ;. // Generate data from model (using TFoam adaptive sampling al",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:4436,Security,access,access,4436,"l to that of RooMinuit; with two extensions. The setMinimizer(const char*) method allows to choose between ""minuit"" and ""minuit2""); as implementation for migrad(),hesse(),minos() etc...; The minimizer(const char* package, const char* alg) provides a completely generic interface; to all minimizers, where package is the package (minuit,GSLminimizer) and alg is the algorithm (migrad) to be used. By default, RooMinuit is still used when RooAbsPdf::fitTo() is called, but can be overridden with; a Minimizer() named argument. // Minimization with MINUIT/MIGRAD through RooMinuit; pdf->fitTo(data) ;. // Minimization with MINUIT/MIGRAD through RooMinimizer; pdf->fitTo(data,Minimizer(""minuit"")) ;. // Minimization with MINUIT2/MIGRAD through RooMinimizer; pdf->fitTo(data,Minimizer(""minuit2"")) ;. // Minimization with GSLMultiMin/conjugatefr through RooMinimizer; pdf->fitTo(data,Minimizer(""GSLMultiMin"",""conjugatefr"")) ;. Note that installation of GSL and the ROOT MathMore package is needed to access the GSL Minimizers and that the GSL; Minimizer do not implement error analysis. New numeric integration algorithms available; RooFit can now interface all MathCore numeric integration; algorithms. In this release ROOT::Math::AdaptiveIntegratorMultiDim,; which implements the 'Genz & Malik' algorithm has been interfaced; in RooAdaptiveIntegratorND and is now the default numeric integrator; for numeric integrations in two or more dimensions. This new default integrator has much improved stability and speed; for relatively smooth p.d.f.s in two or three dimensions and can; generally be used well for p.d.f. normalization integrals without; causing MINUIT converge problems due to numeric precision issues. In future release some more numeric integrators will be migrated to; a MathCore implementation. Interface to TFoam adaptive MC sampler added; RooFit can now use the TFoam adaptive MC sampler for event generation of p.d.f.s that; do not have an internal generator. The TFoam generator adapti",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:15148,Security,access,access,15148,"mplements the storage of the; data. This new class structure allows multiple data storage implementations to; be applied efficiently to both RooDataSet and RooDataHist; At present a single implementation of RooAbsDataStore exists,; class RooTreeDataStore, that contains the storage implementation; formerly implement in class RooTreeData. Methods in class RooTreeData; that were not specific to the storage technology have been moved to; class RooAbsData. If your user code only uses the classes RooDataSet,RooDataHist and RooAbsData; nothing will change: Existing RooDataSets and RooDataHists; (that inherit from RooTreeData) can be read in without problems in; RooFit 3.00 and will be converted on the fly to the new dataset structure; in memory. User code that explicitly uses RooTreeData pointers should; be changed to RooAbsData pointers. This change should be transparent; for all uses, with the exception of the RooTreeData::tree() method.; Explicit access to tree implementation can still be obtained; through the RooTreeDataStore::tree() method. (A pointer to the datastore; can be obtained through the RooAbsData::store() method.); Note that in future releases it is no longer guaranteed that all datasets are implemented; with a plain TTree implementation, so any user code that uses the tree; implementation directly should implement checks that the implementation; is indeed tree-based (data->store()->InheritsFrom(RooTreeDataStore::Class())==true)). In future release additional implementations of RooAbsDataStore will; be provided that will support new dataset functionality such as the; ability to construct 'joint' dataset from two input datasets without; the need to copy the input data and 'filtered' datasets that represent; a reduced view (in dimensions or by selecting events) of a dataset; without the need to copy content. Various workspace improvements. A number of smaller and larger improvements has been made to the RooWorkspace class. Direct interactive access to content",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:16174,Security,access,access,16174,"er to the datastore; can be obtained through the RooAbsData::store() method.); Note that in future releases it is no longer guaranteed that all datasets are implemented; with a plain TTree implementation, so any user code that uses the tree; implementation directly should implement checks that the implementation; is indeed tree-based (data->store()->InheritsFrom(RooTreeDataStore::Class())==true)). In future release additional implementations of RooAbsDataStore will; be provided that will support new dataset functionality such as the; ability to construct 'joint' dataset from two input datasets without; the need to copy the input data and 'filtered' datasets that represent; a reduced view (in dimensions or by selecting events) of a dataset; without the need to copy content. Various workspace improvements. A number of smaller and larger improvements has been made to the RooWorkspace class. Direct interactive access to contents from CINT -; One can now directly access the contents of any RooWorkspace; on the ROOT commandline through CINT if the RooWorkspace::exportToCint() call is made.; In CINT, all workspace objects will appear as correctly typed references to workspace objects in; a C++ namespace with the same name as the RooWorkspace object. Given e.g. a workspace w, with a Gaussian p.d.f gauss in terms of variables; x,m,s one can now do. RooWorkspace w(""w"",true) ; // workspace with CINT interface activated; // ... fill workspace with RooGaussian gauss(x,m,s) ...; RooPlot* frame = w::x.frame() ;; w::gauss.plotOn(frame) ;. to access the workspace contents. Each reference has the correct type, e.g. w::gauss is; a RooGaussian&. If a workspace is deleted from memory, the corresponding CINT namespace; is removed as well. Note that this feature is strictly available in interpreted C++ only; A new tutorial macro has been added to illustrate this functionality in more detail: rf509_wsinteractive.C.; writeToFile -- A new utility method RooWorkspace::writeToFile() has been a",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:16227,Security,access,access,16227,"er to the datastore; can be obtained through the RooAbsData::store() method.); Note that in future releases it is no longer guaranteed that all datasets are implemented; with a plain TTree implementation, so any user code that uses the tree; implementation directly should implement checks that the implementation; is indeed tree-based (data->store()->InheritsFrom(RooTreeDataStore::Class())==true)). In future release additional implementations of RooAbsDataStore will; be provided that will support new dataset functionality such as the; ability to construct 'joint' dataset from two input datasets without; the need to copy the input data and 'filtered' datasets that represent; a reduced view (in dimensions or by selecting events) of a dataset; without the need to copy content. Various workspace improvements. A number of smaller and larger improvements has been made to the RooWorkspace class. Direct interactive access to contents from CINT -; One can now directly access the contents of any RooWorkspace; on the ROOT commandline through CINT if the RooWorkspace::exportToCint() call is made.; In CINT, all workspace objects will appear as correctly typed references to workspace objects in; a C++ namespace with the same name as the RooWorkspace object. Given e.g. a workspace w, with a Gaussian p.d.f gauss in terms of variables; x,m,s one can now do. RooWorkspace w(""w"",true) ; // workspace with CINT interface activated; // ... fill workspace with RooGaussian gauss(x,m,s) ...; RooPlot* frame = w::x.frame() ;; w::gauss.plotOn(frame) ;. to access the workspace contents. Each reference has the correct type, e.g. w::gauss is; a RooGaussian&. If a workspace is deleted from memory, the corresponding CINT namespace; is removed as well. Note that this feature is strictly available in interpreted C++ only; A new tutorial macro has been added to illustrate this functionality in more detail: rf509_wsinteractive.C.; writeToFile -- A new utility method RooWorkspace::writeToFile() has been a",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:16806,Security,access,access,16806,"nt' dataset from two input datasets without; the need to copy the input data and 'filtered' datasets that represent; a reduced view (in dimensions or by selecting events) of a dataset; without the need to copy content. Various workspace improvements. A number of smaller and larger improvements has been made to the RooWorkspace class. Direct interactive access to contents from CINT -; One can now directly access the contents of any RooWorkspace; on the ROOT commandline through CINT if the RooWorkspace::exportToCint() call is made.; In CINT, all workspace objects will appear as correctly typed references to workspace objects in; a C++ namespace with the same name as the RooWorkspace object. Given e.g. a workspace w, with a Gaussian p.d.f gauss in terms of variables; x,m,s one can now do. RooWorkspace w(""w"",true) ; // workspace with CINT interface activated; // ... fill workspace with RooGaussian gauss(x,m,s) ...; RooPlot* frame = w::x.frame() ;; w::gauss.plotOn(frame) ;. to access the workspace contents. Each reference has the correct type, e.g. w::gauss is; a RooGaussian&. If a workspace is deleted from memory, the corresponding CINT namespace; is removed as well. Note that this feature is strictly available in interpreted C++ only; A new tutorial macro has been added to illustrate this functionality in more detail: rf509_wsinteractive.C.; writeToFile -- A new utility method RooWorkspace::writeToFile() has been added; to simplify the process of saving a workspace to file; Named sets and parameter snapshots -- It is now possible to define and retrieve; named RooArgSets of objects that live in the workspace through methods; defineSet() and set(). While named sets merely group objects logically, methods loadSnapshot and; saveSnapshot allow to make copies of the values, errors and 'constant' status of; sets of variable objects that live in the workspace. A newly added tutorial macro rf510_namedsets.C illustrates the functionality of both; of these features.; Improved pri",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:22031,Security,access,access,22031,"event error dterr and all its parameters, convoluted with a triple; gaussian resolution model and multiplied with a Gaussian p.d.f. in the; energy substituted mass. (In plain RooFit this would have required at; least 23 lines of code). A series of three new tutorial macros has been added to illustrate the; various features of the object factory. rf511_wsfactory_basic.C - Basic factory concepts; rf512_wsfactory_oper.C - Using operator p.d.f.s in the factory; rf513_wsfactory_tools.C - Advanced example using interfaced high level tools. A formal transaction model is used to commit composite objects into; the workspace. If an error is detected in the expression, no objects; will be committed to the workspace, thus leaving no 'partial builds'. Compact demo of several new major features. The macro below demonstrates in a couple of lines a number of major new features in RooFit 3.00: Use of. workspace factory to quickly create and store (compiled) models; workspace CINT interface to easily access contents in a typesafe way; new adaptive ND numeric integration technique to normalize arbitrary p.d.f. in fast; and reliable way; new adaptive TFoam sampling technique to efficiently generate toy MC data from strongly; peaked datasets; parallel processing in likelihood construction and use of profile likelihood operator; to represent profile likelihoods as regular RooFit functions. void demo(); {; // Construct compiled 2-D model that requires numeric integration for normalization; RooWorkspace w(""w"",1) ;; w.factory(""CEXPR::model('1/((x-a)*(x-a)+0.001)+1/((y-b)*(y-b)+0.001)',x[-1,1],y[-1,1],a[-5,5],b[-5,5])"") ;. // Generate data from model (using TFoam adaptive sampling algorithm); RooDataSet* d = w::model.generate(RooArgSet(w::x,w::y),1000) ;; w::model.fitTo(*d) ;. // Make 2D plot on (x,y); TH2* hh = w::model.createHistogram(""x,y"",40,40) ;; hh->SetLineColor(kBlue) ;. // Make Projection on x (integrate over y); RooPlot* framex = w::x.frame(Title(""Data and p.d.f. projected on X"")) ;",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:17529,Testability,log,logically,17529,",m,s one can now do. RooWorkspace w(""w"",true) ; // workspace with CINT interface activated; // ... fill workspace with RooGaussian gauss(x,m,s) ...; RooPlot* frame = w::x.frame() ;; w::gauss.plotOn(frame) ;. to access the workspace contents. Each reference has the correct type, e.g. w::gauss is; a RooGaussian&. If a workspace is deleted from memory, the corresponding CINT namespace; is removed as well. Note that this feature is strictly available in interpreted C++ only; A new tutorial macro has been added to illustrate this functionality in more detail: rf509_wsinteractive.C.; writeToFile -- A new utility method RooWorkspace::writeToFile() has been added; to simplify the process of saving a workspace to file; Named sets and parameter snapshots -- It is now possible to define and retrieve; named RooArgSets of objects that live in the workspace through methods; defineSet() and set(). While named sets merely group objects logically, methods loadSnapshot and; saveSnapshot allow to make copies of the values, errors and 'constant' status of; sets of variable objects that live in the workspace. A newly added tutorial macro rf510_namedsets.C illustrates the functionality of both; of these features.; Improved printing of contents -- Many operator p.d.f. and function components now show; a more intuitive natural representation of their contents (these changes are mostly in the; respective p.d.f.s, but are most relevant in the context of a workspace). New object factory interface to workspace to facilitate script driven model definition; A object factory has been added to RooFit to simplify the process of creating p.d.f.; and function expressions consisting of multiple objects. The factory has two goals:; the first is to provide a back-end for higher level factories and tools to process; the creation of objects. The second is to provide a simple end-user language to; populate a RooWorkspace with function and p.d.f. objects. For the latter purpose the object creation language ",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:26097,Testability,test,test,26097,"ian, and Likelihood intervals for a simple number counting experiment; with uncertainty on signal and background rates.; rs301_splot.C Demonstrates use of RooStats sPlot; implementation; rs401c_FeldmanCousins.C Demonstrates use of; FeldmanCousins interval calculator with a Poisson problem, reproduces; results from table IV and V of the original; paper�Phys.Rev.D57:3873-3889,1998.; rs401d_FeldmanCousins.C Demonstrates use of; FeldmanCousins interval calculator with the neutrino oscillation toy; example described in the original paper�Phys.Rev.D57:3873-3889,1998.; Reproduces figure 12.; rs_bernsteinCorrection.C Demonstrates use of; BernsteinCorrection class, which corrects a nominal PDF with a polynomial; to agree with observed or simulated data. TestStatistic interface and implementations; We added a new interface class called TestStatistic. It defines the; method Evaluate(data, parameterPoint), which returns a double. �This; class can be used in�conjunction�with the ToyMCSampler class to generate; sampling distributions for a user-defined test statistic. �; The following concrete implementations of the TestStatistic interface; are currently available. ProfileLikelihoodTestStatReturns the log of profile; likelihood ratio. �Generally a powerful test statistic. ; NumEventsTestStatReturns the number of events in the; dataset. �Useful for number counting experiments.; DebuggingTestStat Simply returns a uniform random number; between 0,1. �Useful for debugging. SamplingDistribution and the�TestStatSampler interface and; implementations; We introduced a ``result'' or data model class called; SamplingDistribution, which holds the sampling distribution of an; arbitrary real valued test statistic. �The class also can return the; inverse of the cumulative distribution function (with or without; interpolation). �; We introduced an interface for any tool that can produce a; SamplingDistribution, called TestStatSampler. �The interface is; essentially GetSamplingDistribution(parame",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:26249,Testability,log,log,26249,"sins.C Demonstrates use of; FeldmanCousins interval calculator with a Poisson problem, reproduces; results from table IV and V of the original; paper�Phys.Rev.D57:3873-3889,1998.; rs401d_FeldmanCousins.C Demonstrates use of; FeldmanCousins interval calculator with the neutrino oscillation toy; example described in the original paper�Phys.Rev.D57:3873-3889,1998.; Reproduces figure 12.; rs_bernsteinCorrection.C Demonstrates use of; BernsteinCorrection class, which corrects a nominal PDF with a polynomial; to agree with observed or simulated data. TestStatistic interface and implementations; We added a new interface class called TestStatistic. It defines the; method Evaluate(data, parameterPoint), which returns a double. �This; class can be used in�conjunction�with the ToyMCSampler class to generate; sampling distributions for a user-defined test statistic. �; The following concrete implementations of the TestStatistic interface; are currently available. ProfileLikelihoodTestStatReturns the log of profile; likelihood ratio. �Generally a powerful test statistic. ; NumEventsTestStatReturns the number of events in the; dataset. �Useful for number counting experiments.; DebuggingTestStat Simply returns a uniform random number; between 0,1. �Useful for debugging. SamplingDistribution and the�TestStatSampler interface and; implementations; We introduced a ``result'' or data model class called; SamplingDistribution, which holds the sampling distribution of an; arbitrary real valued test statistic. �The class also can return the; inverse of the cumulative distribution function (with or without; interpolation). �; We introduced an interface for any tool that can produce a; SamplingDistribution, called TestStatSampler. �The interface is; essentially GetSamplingDistribution(parameterPoint) which returns a; SamplingDistribution based on a given probability density function. �We; foresee a few versions of this tool based on toy Monte Carlo, importance; sampling, Fourier transforms, ",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:26305,Testability,test,test,26305,"culator with a Poisson problem, reproduces; results from table IV and V of the original; paper�Phys.Rev.D57:3873-3889,1998.; rs401d_FeldmanCousins.C Demonstrates use of; FeldmanCousins interval calculator with the neutrino oscillation toy; example described in the original paper�Phys.Rev.D57:3873-3889,1998.; Reproduces figure 12.; rs_bernsteinCorrection.C Demonstrates use of; BernsteinCorrection class, which corrects a nominal PDF with a polynomial; to agree with observed or simulated data. TestStatistic interface and implementations; We added a new interface class called TestStatistic. It defines the; method Evaluate(data, parameterPoint), which returns a double. �This; class can be used in�conjunction�with the ToyMCSampler class to generate; sampling distributions for a user-defined test statistic. �; The following concrete implementations of the TestStatistic interface; are currently available. ProfileLikelihoodTestStatReturns the log of profile; likelihood ratio. �Generally a powerful test statistic. ; NumEventsTestStatReturns the number of events in the; dataset. �Useful for number counting experiments.; DebuggingTestStat Simply returns a uniform random number; between 0,1. �Useful for debugging. SamplingDistribution and the�TestStatSampler interface and; implementations; We introduced a ``result'' or data model class called; SamplingDistribution, which holds the sampling distribution of an; arbitrary real valued test statistic. �The class also can return the; inverse of the cumulative distribution function (with or without; interpolation). �; We introduced an interface for any tool that can produce a; SamplingDistribution, called TestStatSampler. �The interface is; essentially GetSamplingDistribution(parameterPoint) which returns a; SamplingDistribution based on a given probability density function. �We; foresee a few versions of this tool based on toy Monte Carlo, importance; sampling, Fourier transforms, etc. �The following concrete implementation; of the Te",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:26743,Testability,test,test,26743,"rnsteinCorrection.C Demonstrates use of; BernsteinCorrection class, which corrects a nominal PDF with a polynomial; to agree with observed or simulated data. TestStatistic interface and implementations; We added a new interface class called TestStatistic. It defines the; method Evaluate(data, parameterPoint), which returns a double. �This; class can be used in�conjunction�with the ToyMCSampler class to generate; sampling distributions for a user-defined test statistic. �; The following concrete implementations of the TestStatistic interface; are currently available. ProfileLikelihoodTestStatReturns the log of profile; likelihood ratio. �Generally a powerful test statistic. ; NumEventsTestStatReturns the number of events in the; dataset. �Useful for number counting experiments.; DebuggingTestStat Simply returns a uniform random number; between 0,1. �Useful for debugging. SamplingDistribution and the�TestStatSampler interface and; implementations; We introduced a ``result'' or data model class called; SamplingDistribution, which holds the sampling distribution of an; arbitrary real valued test statistic. �The class also can return the; inverse of the cumulative distribution function (with or without; interpolation). �; We introduced an interface for any tool that can produce a; SamplingDistribution, called TestStatSampler. �The interface is; essentially GetSamplingDistribution(parameterPoint) which returns a; SamplingDistribution based on a given probability density function. �We; foresee a few versions of this tool based on toy Monte Carlo, importance; sampling, Fourier transforms, etc. �The following concrete implementation; of the TestStatSampler interface are currently available. ToyMCSamplerUses a Toy Monte Carlo approach to build the; sampling distribution. �The pdf's generate method to generate is used to; generate toy data, and then the test statistic is evaluated at the; requested parameter point. ; DebuggingSampler Simply returns a uniform distribution; betwe",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:27514,Testability,test,test,27514,"ful for debugging. SamplingDistribution and the�TestStatSampler interface and; implementations; We introduced a ``result'' or data model class called; SamplingDistribution, which holds the sampling distribution of an; arbitrary real valued test statistic. �The class also can return the; inverse of the cumulative distribution function (with or without; interpolation). �; We introduced an interface for any tool that can produce a; SamplingDistribution, called TestStatSampler. �The interface is; essentially GetSamplingDistribution(parameterPoint) which returns a; SamplingDistribution based on a given probability density function. �We; foresee a few versions of this tool based on toy Monte Carlo, importance; sampling, Fourier transforms, etc. �The following concrete implementation; of the TestStatSampler interface are currently available. ToyMCSamplerUses a Toy Monte Carlo approach to build the; sampling distribution. �The pdf's generate method to generate is used to; generate toy data, and then the test statistic is evaluated at the; requested parameter point. ; DebuggingSampler Simply returns a uniform distribution; between 0,1. �Useful for debugging. NeymanConstruction and FeldmanCousins; A flexible framework for the Neyman Construction was added in this; release. The NeymanConstruction is a concrete implementation of the; IntervalCalculator interface, but it needs several; additional components�to be specified before use. The design; factorizes the choice of the parameter points to be tested,�the choice of; the test statistic, and the generation of sampling distribution into; separate parts (described above). �Finally, the NeymanConstruction class; is simply in charge of using these parts (strategies) and constructing; the confidence belt and confidence intervals. �The ConfidenceBelt class; is still under development, but the current version works fine for; producing ConfidenceIntervals. �We are also working to make this class; work with parallelization approaches, ",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:28013,Testability,test,tested,28013,"terPoint) which returns a; SamplingDistribution based on a given probability density function. �We; foresee a few versions of this tool based on toy Monte Carlo, importance; sampling, Fourier transforms, etc. �The following concrete implementation; of the TestStatSampler interface are currently available. ToyMCSamplerUses a Toy Monte Carlo approach to build the; sampling distribution. �The pdf's generate method to generate is used to; generate toy data, and then the test statistic is evaluated at the; requested parameter point. ; DebuggingSampler Simply returns a uniform distribution; between 0,1. �Useful for debugging. NeymanConstruction and FeldmanCousins; A flexible framework for the Neyman Construction was added in this; release. The NeymanConstruction is a concrete implementation of the; IntervalCalculator interface, but it needs several; additional components�to be specified before use. The design; factorizes the choice of the parameter points to be tested,�the choice of; the test statistic, and the generation of sampling distribution into; separate parts (described above). �Finally, the NeymanConstruction class; is simply in charge of using these parts (strategies) and constructing; the confidence belt and confidence intervals. �The ConfidenceBelt class; is still under development, but the current version works fine for; producing ConfidenceIntervals. �We are also working to make this class; work with parallelization approaches, which is not yet complete.; The FeldmanCousins class is a separate concrete implementation of the; IntervalCalculator interface. �It uses the NeymanConstruction internally,; and�enforces�specific choices of the test statistic and ordering; principle to realize the Unified intervals described by Feldman and; Cousins in their paper�Phys.Rev.D57:3873-3889,1998. In an extension to the technique discussed in Feldman and Cousins paper,; the FeldmanCousins class also performs a ""profile construction"" if their are nuisance parameters.; In this",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:28040,Testability,test,test,28040,"terPoint) which returns a; SamplingDistribution based on a given probability density function. �We; foresee a few versions of this tool based on toy Monte Carlo, importance; sampling, Fourier transforms, etc. �The following concrete implementation; of the TestStatSampler interface are currently available. ToyMCSamplerUses a Toy Monte Carlo approach to build the; sampling distribution. �The pdf's generate method to generate is used to; generate toy data, and then the test statistic is evaluated at the; requested parameter point. ; DebuggingSampler Simply returns a uniform distribution; between 0,1. �Useful for debugging. NeymanConstruction and FeldmanCousins; A flexible framework for the Neyman Construction was added in this; release. The NeymanConstruction is a concrete implementation of the; IntervalCalculator interface, but it needs several; additional components�to be specified before use. The design; factorizes the choice of the parameter points to be tested,�the choice of; the test statistic, and the generation of sampling distribution into; separate parts (described above). �Finally, the NeymanConstruction class; is simply in charge of using these parts (strategies) and constructing; the confidence belt and confidence intervals. �The ConfidenceBelt class; is still under development, but the current version works fine for; producing ConfidenceIntervals. �We are also working to make this class; work with parallelization approaches, which is not yet complete.; The FeldmanCousins class is a separate concrete implementation of the; IntervalCalculator interface. �It uses the NeymanConstruction internally,; and�enforces�specific choices of the test statistic and ordering; principle to realize the Unified intervals described by Feldman and; Cousins in their paper�Phys.Rev.D57:3873-3889,1998. In an extension to the technique discussed in Feldman and Cousins paper,; the FeldmanCousins class also performs a ""profile construction"" if their are nuisance parameters.; In this",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:28714,Testability,test,test,28714,"the Neyman Construction was added in this; release. The NeymanConstruction is a concrete implementation of the; IntervalCalculator interface, but it needs several; additional components�to be specified before use. The design; factorizes the choice of the parameter points to be tested,�the choice of; the test statistic, and the generation of sampling distribution into; separate parts (described above). �Finally, the NeymanConstruction class; is simply in charge of using these parts (strategies) and constructing; the confidence belt and confidence intervals. �The ConfidenceBelt class; is still under development, but the current version works fine for; producing ConfidenceIntervals. �We are also working to make this class; work with parallelization approaches, which is not yet complete.; The FeldmanCousins class is a separate concrete implementation of the; IntervalCalculator interface. �It uses the NeymanConstruction internally,; and�enforces�specific choices of the test statistic and ordering; principle to realize the Unified intervals described by Feldman and; Cousins in their paper�Phys.Rev.D57:3873-3889,1998. In an extension to the technique discussed in Feldman and Cousins paper,; the FeldmanCousins class also performs a ""profile construction"" if their are nuisance parameters.; In this case, the parameters of interest are scanned in a regular grid. For each point in the grid; the calculator finds the best fit value of the nuisance parameters (given the data). The construction; is then only performed in this subspace of the parameters. As a result, the number of points in the; construction only scales in the number of parameters of interest, not in the number of nuisance parameters. Markov Chain Monte Carlo Interval; A flexible framework for Markov Chain Monte Carlo was added in this; release. The MCMCCalculator is a concrete implementation of the; IntervalCalculator interface. To use it one needs to specify the ProposalFunction.; There is a base class for Proposal",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:32226,Testability,test,test,32226,"ratio for the parameters of interest. Bernstein Correction. BernsteinCorrection is a utility in RooStats to augment a nominal PDF; with a polynomial�; correction term. �This is useful for incorporating systematic variations; to the nominal PDF. �; The Bernstein basis polynomails are particularly appropriate because they; are positive definite.�. This tool was inspired by the work of Glen Cowan together with Stephan; Horner, Sascha Caron,�; Eilam Gross, and others. �; The initial implementation is independent work. �The major step forward; in the approach was�; to provide a well defined algorithm that specifies the order of; polynomial to be included�; in the correction. �This is an empirical algorithm, so in addition to the; nominal model it�; needs either a real data set or a simulated one. �In the early work, the; nominal model was taken; to be a histogram from Monte Carlo simulations, but in this; implementation it is generalized to an; arbitrary PDF (which includes a RooHistPdf). �The algorithm basically; consists of a�; hypothesis test of an nth-order correction (null) against a n+1-th order; correction (alternate).�; The quantity q = -2 log LR is used to determine whether the n+1-th order; correction is a major�; improvement to the n-th order correction. �The distribution of q is; expected to be roughly�; \chi^2 with one degree of freedom if the n-th order correction is a good; model for the data.�; �Thus, one only moves to the n+1-th order correction of q is relatively; large. �The chance that�; one moves from the n-th to the n+1-th order correction when the n-th; order correction�; (eg. a type 1 error) is sufficient is given by the Prob(\chi^2_1 >; threshold). �The constructor�; of this class allows you to directly set this tolerance (in terms of; probability that the n+1-th; �term is added unnecessarily). HybridCalculator; Add as a new test statistics the profile likelihood ratio. Will be redesigned to use TestStatSampler and TestStatistic in next release. ",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:32335,Testability,log,log,32335,"ratio for the parameters of interest. Bernstein Correction. BernsteinCorrection is a utility in RooStats to augment a nominal PDF; with a polynomial�; correction term. �This is useful for incorporating systematic variations; to the nominal PDF. �; The Bernstein basis polynomails are particularly appropriate because they; are positive definite.�. This tool was inspired by the work of Glen Cowan together with Stephan; Horner, Sascha Caron,�; Eilam Gross, and others. �; The initial implementation is independent work. �The major step forward; in the approach was�; to provide a well defined algorithm that specifies the order of; polynomial to be included�; in the correction. �This is an empirical algorithm, so in addition to the; nominal model it�; needs either a real data set or a simulated one. �In the early work, the; nominal model was taken; to be a histogram from Monte Carlo simulations, but in this; implementation it is generalized to an; arbitrary PDF (which includes a RooHistPdf). �The algorithm basically; consists of a�; hypothesis test of an nth-order correction (null) against a n+1-th order; correction (alternate).�; The quantity q = -2 log LR is used to determine whether the n+1-th order; correction is a major�; improvement to the n-th order correction. �The distribution of q is; expected to be roughly�; \chi^2 with one degree of freedom if the n-th order correction is a good; model for the data.�; �Thus, one only moves to the n+1-th order correction of q is relatively; large. �The chance that�; one moves from the n-th to the n+1-th order correction when the n-th; order correction�; (eg. a type 1 error) is sufficient is given by the Prob(\chi^2_1 >; threshold). �The constructor�; of this class allows you to directly set this tolerance (in terms of; probability that the n+1-th; �term is added unnecessarily). HybridCalculator; Add as a new test statistics the profile likelihood ratio. Will be redesigned to use TestStatSampler and TestStatistic in next release. ",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:33051,Testability,test,test,33051,"ratio for the parameters of interest. Bernstein Correction. BernsteinCorrection is a utility in RooStats to augment a nominal PDF; with a polynomial�; correction term. �This is useful for incorporating systematic variations; to the nominal PDF. �; The Bernstein basis polynomails are particularly appropriate because they; are positive definite.�. This tool was inspired by the work of Glen Cowan together with Stephan; Horner, Sascha Caron,�; Eilam Gross, and others. �; The initial implementation is independent work. �The major step forward; in the approach was�; to provide a well defined algorithm that specifies the order of; polynomial to be included�; in the correction. �This is an empirical algorithm, so in addition to the; nominal model it�; needs either a real data set or a simulated one. �In the early work, the; nominal model was taken; to be a histogram from Monte Carlo simulations, but in this; implementation it is generalized to an; arbitrary PDF (which includes a RooHistPdf). �The algorithm basically; consists of a�; hypothesis test of an nth-order correction (null) against a n+1-th order; correction (alternate).�; The quantity q = -2 log LR is used to determine whether the n+1-th order; correction is a major�; improvement to the n-th order correction. �The distribution of q is; expected to be roughly�; \chi^2 with one degree of freedom if the n-th order correction is a good; model for the data.�; �Thus, one only moves to the n+1-th order correction of q is relatively; large. �The chance that�; one moves from the n-th to the n+1-th order correction when the n-th; order correction�; (eg. a type 1 error) is sufficient is given by the Prob(\chi^2_1 >; threshold). �The constructor�; of this class allows you to directly set this tolerance (in terms of; probability that the n+1-th; �term is added unnecessarily). HybridCalculator; Add as a new test statistics the profile likelihood ratio. Will be redesigned to use TestStatSampler and TestStatistic in next release. ",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:6738,Usability,simpl,simply,6738," the original RooAcceptReject generator is still used. The choice of MC sampling algorithm can be steered through class RooNumGenConfig, which; is similar in style and structure, to RooNumIntConfig which configures the choice of; numeric integration algorithm. A new tutorial macro rf902_numgenconfig.C has been added to $ROOTSYS/tutorials/roofit; to illustrate the use of the steering. A macro that demonstrates of the power of these newly interface numeric algorithms is provided at the; end of the RooFit section of the release notes. Optional persistent caching of numeric integrals; For p.d.f.s with numeric integrals that remain difficult or very time consuming,; a new persistent caching technique is now available that allows to precalculate; these integrals and store their values for future use. This technique works transparently; for any p.d.f. stored in a RooWorkspace. One can store numeric integral values for problems with zero, one or two floating parameters.; In the first case, the value is simply stored. In cases with one or two floating parameters; a grid (histogram) of integral values is stored, which are interpolated to return integral; values for each value of the parameters. A new tutorial macro rf903_numintcache.C has been added to $ROOTSYS/tutorials/roofit; to illustrate the use of this feature. Representation of function and p.d.f. derivatives; A new class has been added that can represent the derivative of any p.d.f or function w.r.t. any; parameter or observable. To construct e.g. a first order derivative of a Gaussian p.d.f, do. RooAbsReal* dgdx = gauss.derivative(x,1) ;. A more complete example is available in the new tutorial macro rf111_derivatives.C. Improved handling of chi-squared fits; Chi-squared fits can now be performed through the same style of interface as likelihood fits,; through the newly added method RooAbsReal::chi2FitTo(const RooDataHist&,...). Functions that can be fitted with chi-squared minimization are any RooAbsReal based funct",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:9019,Usability,simpl,simplify,9019,"gram to adjust; the scale of the function. In case of extended p.d.f.s, the adjustment is made with the expected; number of events, rather than the observed number of events. Tutorial macro rf602_chi2fit.C has been updated to use this new interface. Chi-squared fits to X-Y datasets now possible; In addition to the ability to perform chi-squared fits to histograms it is now also possible; to perform chi-squared fits to unbinned datasets containing a series of X and Y values; with associated errors on Y and optionally on X. These 'X-Y' chi-squared fits are interfaced through newly added method; RooAbsReal::chi2FitTo(const RooDataSet&,...). By default the event weight is; interpreted as the 'Y' value, but an YVar() argument can designate any other; dataset column as Y value. If X errors are defined, one can choose to integrate the fitted; function over the range of the X errors, rather than taking the central value by adding; an Integrate(true) argument to chi2FitTo(); Two new arguments, StoreError(const RooArgSet&) and StoreAsymError(const RooArgSet&); have been added to the RooDataSet constructor to simplify the process of storing the errors; of X and Y variables along with their values in a dataset. The newly added tutorial macro rf609_xychi2fit.C illustrates the use of all this; new functionality. Uniform interface for creation of (profile likelihoods) and chi-squared from p.d.f.s; It is now recommended to use the method RooAbsPdf::createNLL(RooAbsData&,...) to; create a likelihood from a p.d.f and a dataset rather than constructing a RooNLLVar; object directly. This is because part of the likelihood construction functionality such a using; multiple Range()s, or the inclusion for constraint terms are only available through; createNLL(). To promote the consistency of this interface, a similar method RooAbsReal::createChi2(); has been added to construct chi-squared functions of a dataset and a function or p.d.f. Along the same lines, it is recommended to use RooAbsRe",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:17263,Usability,simpl,simplify,17263,"Cint() call is made.; In CINT, all workspace objects will appear as correctly typed references to workspace objects in; a C++ namespace with the same name as the RooWorkspace object. Given e.g. a workspace w, with a Gaussian p.d.f gauss in terms of variables; x,m,s one can now do. RooWorkspace w(""w"",true) ; // workspace with CINT interface activated; // ... fill workspace with RooGaussian gauss(x,m,s) ...; RooPlot* frame = w::x.frame() ;; w::gauss.plotOn(frame) ;. to access the workspace contents. Each reference has the correct type, e.g. w::gauss is; a RooGaussian&. If a workspace is deleted from memory, the corresponding CINT namespace; is removed as well. Note that this feature is strictly available in interpreted C++ only; A new tutorial macro has been added to illustrate this functionality in more detail: rf509_wsinteractive.C.; writeToFile -- A new utility method RooWorkspace::writeToFile() has been added; to simplify the process of saving a workspace to file; Named sets and parameter snapshots -- It is now possible to define and retrieve; named RooArgSets of objects that live in the workspace through methods; defineSet() and set(). While named sets merely group objects logically, methods loadSnapshot and; saveSnapshot allow to make copies of the values, errors and 'constant' status of; sets of variable objects that live in the workspace. A newly added tutorial macro rf510_namedsets.C illustrates the functionality of both; of these features.; Improved printing of contents -- Many operator p.d.f. and function components now show; a more intuitive natural representation of their contents (these changes are mostly in the; respective p.d.f.s, but are most relevant in the context of a workspace). New object factory interface to workspace to facilitate script driven model definition; A object factory has been added to RooFit to simplify the process of creating p.d.f.; and function expressions consisting of multiple objects. The factory has two goals:; the first is t",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:17902,Usability,intuit,intuitive,17902,"ted from memory, the corresponding CINT namespace; is removed as well. Note that this feature is strictly available in interpreted C++ only; A new tutorial macro has been added to illustrate this functionality in more detail: rf509_wsinteractive.C.; writeToFile -- A new utility method RooWorkspace::writeToFile() has been added; to simplify the process of saving a workspace to file; Named sets and parameter snapshots -- It is now possible to define and retrieve; named RooArgSets of objects that live in the workspace through methods; defineSet() and set(). While named sets merely group objects logically, methods loadSnapshot and; saveSnapshot allow to make copies of the values, errors and 'constant' status of; sets of variable objects that live in the workspace. A newly added tutorial macro rf510_namedsets.C illustrates the functionality of both; of these features.; Improved printing of contents -- Many operator p.d.f. and function components now show; a more intuitive natural representation of their contents (these changes are mostly in the; respective p.d.f.s, but are most relevant in the context of a workspace). New object factory interface to workspace to facilitate script driven model definition; A object factory has been added to RooFit to simplify the process of creating p.d.f.; and function expressions consisting of multiple objects. The factory has two goals:; the first is to provide a back-end for higher level factories and tools to process; the creation of objects. The second is to provide a simple end-user language to; populate a RooWorkspace with function and p.d.f. objects. For the latter purpose the object creation language is executed through the factory() method; of a workspace object. RooWorkspace w(""w"") ;; RooAbsArg* arg = w.factory(""expression_goes_here"") ;. Basic Syntax; The rules at its simplest level are as follows. Expressions with square brackets create variables (discrete and continuous). ""m[-10,10]"" - Creates a RooRealVar named 'm' with rang",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:18194,Usability,simpl,simplify,18194,"ore detail: rf509_wsinteractive.C.; writeToFile -- A new utility method RooWorkspace::writeToFile() has been added; to simplify the process of saving a workspace to file; Named sets and parameter snapshots -- It is now possible to define and retrieve; named RooArgSets of objects that live in the workspace through methods; defineSet() and set(). While named sets merely group objects logically, methods loadSnapshot and; saveSnapshot allow to make copies of the values, errors and 'constant' status of; sets of variable objects that live in the workspace. A newly added tutorial macro rf510_namedsets.C illustrates the functionality of both; of these features.; Improved printing of contents -- Many operator p.d.f. and function components now show; a more intuitive natural representation of their contents (these changes are mostly in the; respective p.d.f.s, but are most relevant in the context of a workspace). New object factory interface to workspace to facilitate script driven model definition; A object factory has been added to RooFit to simplify the process of creating p.d.f.; and function expressions consisting of multiple objects. The factory has two goals:; the first is to provide a back-end for higher level factories and tools to process; the creation of objects. The second is to provide a simple end-user language to; populate a RooWorkspace with function and p.d.f. objects. For the latter purpose the object creation language is executed through the factory() method; of a workspace object. RooWorkspace w(""w"") ;; RooAbsArg* arg = w.factory(""expression_goes_here"") ;. Basic Syntax; The rules at its simplest level are as follows. Expressions with square brackets create variables (discrete and continuous). ""m[-10,10]"" - Creates a RooRealVar named 'm' with range [-10,10]; ""m[5,-10,10]"" - Idem, but with initial value 5; ""m[5]"" - Creates a constant RooRealVar with name 'm' and value 5. ""tagCat[Lep,Kao,NT1,NT2]"" -- Creates a RooCategory with name tagCat and labeled states Le",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:18456,Usability,simpl,simple,18456,") and set(). While named sets merely group objects logically, methods loadSnapshot and; saveSnapshot allow to make copies of the values, errors and 'constant' status of; sets of variable objects that live in the workspace. A newly added tutorial macro rf510_namedsets.C illustrates the functionality of both; of these features.; Improved printing of contents -- Many operator p.d.f. and function components now show; a more intuitive natural representation of their contents (these changes are mostly in the; respective p.d.f.s, but are most relevant in the context of a workspace). New object factory interface to workspace to facilitate script driven model definition; A object factory has been added to RooFit to simplify the process of creating p.d.f.; and function expressions consisting of multiple objects. The factory has two goals:; the first is to provide a back-end for higher level factories and tools to process; the creation of objects. The second is to provide a simple end-user language to; populate a RooWorkspace with function and p.d.f. objects. For the latter purpose the object creation language is executed through the factory() method; of a workspace object. RooWorkspace w(""w"") ;; RooAbsArg* arg = w.factory(""expression_goes_here"") ;. Basic Syntax; The rules at its simplest level are as follows. Expressions with square brackets create variables (discrete and continuous). ""m[-10,10]"" - Creates a RooRealVar named 'm' with range [-10,10]; ""m[5,-10,10]"" - Idem, but with initial value 5; ""m[5]"" - Creates a constant RooRealVar with name 'm' and value 5. ""tagCat[Lep,Kao,NT1,NT2]"" -- Creates a RooCategory with name tagCat and labeled states Lep,Kao,NT1,NT2; ""b0flav[B0=1,B0bar=-1]"" -- Creates a RooCategory with name b0flav and states B0 and B0bar with explicit index assignments. Expressions with parentheses create RooAbsArg function objects of any type. ""RooGaussian::g(x,m,s)"" -- Create a RooGaussian named g with variables x,m,s; This expression maps 1-1 to a createArg() ",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:18768,Usability,simpl,simplest,18768,"ctionality of both; of these features.; Improved printing of contents -- Many operator p.d.f. and function components now show; a more intuitive natural representation of their contents (these changes are mostly in the; respective p.d.f.s, but are most relevant in the context of a workspace). New object factory interface to workspace to facilitate script driven model definition; A object factory has been added to RooFit to simplify the process of creating p.d.f.; and function expressions consisting of multiple objects. The factory has two goals:; the first is to provide a back-end for higher level factories and tools to process; the creation of objects. The second is to provide a simple end-user language to; populate a RooWorkspace with function and p.d.f. objects. For the latter purpose the object creation language is executed through the factory() method; of a workspace object. RooWorkspace w(""w"") ;; RooAbsArg* arg = w.factory(""expression_goes_here"") ;. Basic Syntax; The rules at its simplest level are as follows. Expressions with square brackets create variables (discrete and continuous). ""m[-10,10]"" - Creates a RooRealVar named 'm' with range [-10,10]; ""m[5,-10,10]"" - Idem, but with initial value 5; ""m[5]"" - Creates a constant RooRealVar with name 'm' and value 5. ""tagCat[Lep,Kao,NT1,NT2]"" -- Creates a RooCategory with name tagCat and labeled states Lep,Kao,NT1,NT2; ""b0flav[B0=1,B0bar=-1]"" -- Creates a RooCategory with name b0flav and states B0 and B0bar with explicit index assignments. Expressions with parentheses create RooAbsArg function objects of any type. ""RooGaussian::g(x,m,s)"" -- Create a RooGaussian named g with variables x,m,s; This expression maps 1-1 to a createArg() call. ""Gaussian::g(x,m,s)"" -- Idem. The 'Roo' prefix on any class may be omitted. ""Gaussian(x,m,s)"" -- Create a RooGaussian with an automatically assigned name with variables x,m,s. Expressions with curly brackets creates RooArgSets or RooArgLists ""{x,y,z}"". Compound expressions; The rea",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:25078,Usability,simpl,simple,25078,"tasets are no cloned for fit operations to save time and memory.; This change in procedure should save some time and memory, especially in toy MC; studies where the overhead in setting up the likelihood can dominate the total; time spent in fitting. The data cloning behavior of RooAbsPdf::fitTo(); and RooAbsPdf::createNLL() can be explicitly set through the CloneData(); named argument; It is now possible to construct a RooSimultaneous p.d.f. from other; RooSimultaneous p.d.f.s, provided the constructor form is used that takes; all input p.d.f.s. In this constructor simultaneous-of-simultaneous p.d.f.s are automatically; recast to an equivalent top-level simultaneous p.d.f; Sim of sim now possible; Several improvements were made in the internal handling of datasets that; will speedup certain data intensive operations. RooStats; New Tutorials. Several new tutorials were added for RooStats. rs101_limitexample.C Demonstrates use of Frequentist,; Bayesian, and Likelihood intervals for a simple number counting experiment; with uncertainty on signal and background rates.; rs301_splot.C Demonstrates use of RooStats sPlot; implementation; rs401c_FeldmanCousins.C Demonstrates use of; FeldmanCousins interval calculator with a Poisson problem, reproduces; results from table IV and V of the original; paper�Phys.Rev.D57:3873-3889,1998.; rs401d_FeldmanCousins.C Demonstrates use of; FeldmanCousins interval calculator with the neutrino oscillation toy; example described in the original paper�Phys.Rev.D57:3873-3889,1998.; Reproduces figure 12.; rs_bernsteinCorrection.C Demonstrates use of; BernsteinCorrection class, which corrects a nominal PDF with a polynomial; to agree with observed or simulated data. TestStatistic interface and implementations; We added a new interface class called TestStatistic. It defines the; method Evaluate(data, parameterPoint), which returns a double. �This; class can be used in�conjunction�with the ToyMCSampler class to generate; sampling distributions for",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html:28183,Usability,simpl,simply,28183,"ampling, Fourier transforms, etc. �The following concrete implementation; of the TestStatSampler interface are currently available. ToyMCSamplerUses a Toy Monte Carlo approach to build the; sampling distribution. �The pdf's generate method to generate is used to; generate toy data, and then the test statistic is evaluated at the; requested parameter point. ; DebuggingSampler Simply returns a uniform distribution; between 0,1. �Useful for debugging. NeymanConstruction and FeldmanCousins; A flexible framework for the Neyman Construction was added in this; release. The NeymanConstruction is a concrete implementation of the; IntervalCalculator interface, but it needs several; additional components�to be specified before use. The design; factorizes the choice of the parameter points to be tested,�the choice of; the test statistic, and the generation of sampling distribution into; separate parts (described above). �Finally, the NeymanConstruction class; is simply in charge of using these parts (strategies) and constructing; the confidence belt and confidence intervals. �The ConfidenceBelt class; is still under development, but the current version works fine for; producing ConfidenceIntervals. �We are also working to make this class; work with parallelization approaches, which is not yet complete.; The FeldmanCousins class is a separate concrete implementation of the; IntervalCalculator interface. �It uses the NeymanConstruction internally,; and�enforces�specific choices of the test statistic and ordering; principle to realize the Unified intervals described by Feldman and; Cousins in their paper�Phys.Rev.D57:3873-3889,1998. In an extension to the technique discussed in Feldman and Cousins paper,; the FeldmanCousins class also performs a ""profile construction"" if their are nuisance parameters.; In this case, the parameters of interest are scanned in a regular grid. For each point in the grid; the calculator finds the best fit value of the nuisance parameters (given the dat",MatchSource.DOCS,roofit/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:5587,Availability,error,error,5587,"29; RooPolynomial::mllBkgPdf[ x=mll coefList=(mbkg_slope) ] = 0.775; RooEfficiency::effBkgPdf[ cat=cut effFunc=effBkg ] = 0.76916; RooFormulaVar::effBkg[ actualVars=(pt,ab,mb,sb) formula=""0.5*@1*(1+TMath::Erf((@0-@2)/@3))"" ] = 0.76916. The workspace factory can now access all objects in the generic object store of the workspace, e.g. TMatrixDSym* cov ; RooWorkspace w(""w"") ;; w.import(*cov,""cov"") ;; w.factory(""MultiVarGaussian::mvg({x[-10,10],y[-10,10]},{3,5},cov)"") ;. The workspace factory now correctly identifies and matches typedef-ed names in factory constructor; specifications.; All objects created by the factory and inserted by the workspace get a string attribute ""factory_tag"",; that contains the reduced factory string that was used to create that object, e.g. RooWorkspace w(""w"") ;; w.factory(""Gaussian::g(x[-10,10],m[0],s[3])"") ;; cout << w.pdf(""g"")->getStringAttribute(""factory_tag"") << endl ;; RooGaussian::g(x,m,s). Previously all factory orders that would create objects with names of objects that already existed always; resulted in an error. Now, this will only happen if the factory tag of the existing object is different; from the tag of the existing object. w.factory(""Gaussian::g(x[-10,10],m[0],s[3])"") ;; w.factory(""Chebychev::g(x[-10,10],{0,1,2})"") ; // Now OK, x has identical spec, existing x will be used. Improvements to functions and pdfs. Addition to, reorganization of morphing operator classes. The existing class RooLinearMorph which; implements 'Alex Read' morphing has been renamed RooIntegralMorph. A new class RooMomentMorph; has been added (contribution from Max Baak and Stefan Gadatsch) that implements a different morphing algorithm ; based on shifting the mean and variance of the input pdfs. The new moment morphing class can also interpolate ; between multiple input templates and works with multi-dimensional input pdfs. One of the appealing features; is that no expensive calculations are required to calculate in the interpolated pdfs shapes after",MatchSource.DOCS,roofit/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:10266,Availability,error,errors,10266,"),Import(""B"",*d2)). //-----------------------------------------------------------------------------; // NEW: make virtual composite dataset (input data is linked, no data is copied); RooDataSet d12a(""d12a"",""d12a"",w::x,Index(w::index),Link(""S"",*d1),Link(""B"",*d2)); //-----------------------------------------------------------------------------. // Fit composite dataset to dummy model; w->factory(""SUM::model(fsig[0,1]*g,u)""); w::model.fitTo(d12a). For virtual composite dataset it is also possible to join a mix of binned and unbinned datasets; (representation as a RooDataSet with weights). The setWeightVar() method has been deprecated as it is very difficult to support on-the-fly redefinition; of the event weight variable in the new data store scheme. To declare a data set weighed,; use the WeightVar() modifier of the constructor instead,e.g.:. RooDataSet wdata(""wdata"",""wdata"",RooArgSet(x,y,wgt),WeightVar(wgt)) ;. The RooHist class that represents data as a histogram in a RooPlot has been modified; so that it can show approximate Poisson errors for non-integer data. These approximate; errors are calculated from interpolation of the error bars of the nearest integers. NB: A weighted dataset; plotted with RooAbsData::plotOn() will be default show sum-of-weights-squared errors. Only; when Poisson error are forced through a DataError(RooAbsData::Poisson) argument these; approximate Poisson error bars are shown. Miscellaneous improvements other. The RooFit messagee service class RooMsgService has been augmented with a stack that; can store its configurate state information. A call to saveState() will save the; present configuration, which can be restored through a subsequent call to restoreState().; In addition to the method RooAbsArg::printCompactTree() which is mostly intende for; debugging, a new method RooAbsArg::printComponentTree() has been added that prints; the tree structure of a pdf in a more user-friendly content oriented way. The printing ; of the leaf nodes (the ",MatchSource.DOCS,roofit/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:10314,Availability,error,errors,10314,"te dataset (input data is linked, no data is copied); RooDataSet d12a(""d12a"",""d12a"",w::x,Index(w::index),Link(""S"",*d1),Link(""B"",*d2)); //-----------------------------------------------------------------------------. // Fit composite dataset to dummy model; w->factory(""SUM::model(fsig[0,1]*g,u)""); w::model.fitTo(d12a). For virtual composite dataset it is also possible to join a mix of binned and unbinned datasets; (representation as a RooDataSet with weights). The setWeightVar() method has been deprecated as it is very difficult to support on-the-fly redefinition; of the event weight variable in the new data store scheme. To declare a data set weighed,; use the WeightVar() modifier of the constructor instead,e.g.:. RooDataSet wdata(""wdata"",""wdata"",RooArgSet(x,y,wgt),WeightVar(wgt)) ;. The RooHist class that represents data as a histogram in a RooPlot has been modified; so that it can show approximate Poisson errors for non-integer data. These approximate; errors are calculated from interpolation of the error bars of the nearest integers. NB: A weighted dataset; plotted with RooAbsData::plotOn() will be default show sum-of-weights-squared errors. Only; when Poisson error are forced through a DataError(RooAbsData::Poisson) argument these; approximate Poisson error bars are shown. Miscellaneous improvements other. The RooFit messagee service class RooMsgService has been augmented with a stack that; can store its configurate state information. A call to saveState() will save the; present configuration, which can be restored through a subsequent call to restoreState().; In addition to the method RooAbsArg::printCompactTree() which is mostly intende for; debugging, a new method RooAbsArg::printComponentTree() has been added that prints; the tree structure of a pdf in a more user-friendly content oriented way. The printing ; of the leaf nodes (the variables) is omitted in this method to keep the output compact. RooStats. This release contains significant bug fixes and it is ",MatchSource.DOCS,roofit/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:10362,Availability,error,error,10362,"te dataset (input data is linked, no data is copied); RooDataSet d12a(""d12a"",""d12a"",w::x,Index(w::index),Link(""S"",*d1),Link(""B"",*d2)); //-----------------------------------------------------------------------------. // Fit composite dataset to dummy model; w->factory(""SUM::model(fsig[0,1]*g,u)""); w::model.fitTo(d12a). For virtual composite dataset it is also possible to join a mix of binned and unbinned datasets; (representation as a RooDataSet with weights). The setWeightVar() method has been deprecated as it is very difficult to support on-the-fly redefinition; of the event weight variable in the new data store scheme. To declare a data set weighed,; use the WeightVar() modifier of the constructor instead,e.g.:. RooDataSet wdata(""wdata"",""wdata"",RooArgSet(x,y,wgt),WeightVar(wgt)) ;. The RooHist class that represents data as a histogram in a RooPlot has been modified; so that it can show approximate Poisson errors for non-integer data. These approximate; errors are calculated from interpolation of the error bars of the nearest integers. NB: A weighted dataset; plotted with RooAbsData::plotOn() will be default show sum-of-weights-squared errors. Only; when Poisson error are forced through a DataError(RooAbsData::Poisson) argument these; approximate Poisson error bars are shown. Miscellaneous improvements other. The RooFit messagee service class RooMsgService has been augmented with a stack that; can store its configurate state information. A call to saveState() will save the; present configuration, which can be restored through a subsequent call to restoreState().; In addition to the method RooAbsArg::printCompactTree() which is mostly intende for; debugging, a new method RooAbsArg::printComponentTree() has been added that prints; the tree structure of a pdf in a more user-friendly content oriented way. The printing ; of the leaf nodes (the variables) is omitted in this method to keep the output compact. RooStats. This release contains significant bug fixes and it is ",MatchSource.DOCS,roofit/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:10500,Availability,error,errors,10500,"nk(""S"",*d1),Link(""B"",*d2)); //-----------------------------------------------------------------------------. // Fit composite dataset to dummy model; w->factory(""SUM::model(fsig[0,1]*g,u)""); w::model.fitTo(d12a). For virtual composite dataset it is also possible to join a mix of binned and unbinned datasets; (representation as a RooDataSet with weights). The setWeightVar() method has been deprecated as it is very difficult to support on-the-fly redefinition; of the event weight variable in the new data store scheme. To declare a data set weighed,; use the WeightVar() modifier of the constructor instead,e.g.:. RooDataSet wdata(""wdata"",""wdata"",RooArgSet(x,y,wgt),WeightVar(wgt)) ;. The RooHist class that represents data as a histogram in a RooPlot has been modified; so that it can show approximate Poisson errors for non-integer data. These approximate; errors are calculated from interpolation of the error bars of the nearest integers. NB: A weighted dataset; plotted with RooAbsData::plotOn() will be default show sum-of-weights-squared errors. Only; when Poisson error are forced through a DataError(RooAbsData::Poisson) argument these; approximate Poisson error bars are shown. Miscellaneous improvements other. The RooFit messagee service class RooMsgService has been augmented with a stack that; can store its configurate state information. A call to saveState() will save the; present configuration, which can be restored through a subsequent call to restoreState().; In addition to the method RooAbsArg::printCompactTree() which is mostly intende for; debugging, a new method RooAbsArg::printComponentTree() has been added that prints; the tree structure of a pdf in a more user-friendly content oriented way. The printing ; of the leaf nodes (the variables) is omitted in this method to keep the output compact. RooStats. This release contains significant bug fixes and it is strongly; recommended to update to this version if using older ones. . Major Changes in LimitCalculator an",MatchSource.DOCS,roofit/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:10527,Availability,error,error,10527,"ite dataset to dummy model; w->factory(""SUM::model(fsig[0,1]*g,u)""); w::model.fitTo(d12a). For virtual composite dataset it is also possible to join a mix of binned and unbinned datasets; (representation as a RooDataSet with weights). The setWeightVar() method has been deprecated as it is very difficult to support on-the-fly redefinition; of the event weight variable in the new data store scheme. To declare a data set weighed,; use the WeightVar() modifier of the constructor instead,e.g.:. RooDataSet wdata(""wdata"",""wdata"",RooArgSet(x,y,wgt),WeightVar(wgt)) ;. The RooHist class that represents data as a histogram in a RooPlot has been modified; so that it can show approximate Poisson errors for non-integer data. These approximate; errors are calculated from interpolation of the error bars of the nearest integers. NB: A weighted dataset; plotted with RooAbsData::plotOn() will be default show sum-of-weights-squared errors. Only; when Poisson error are forced through a DataError(RooAbsData::Poisson) argument these; approximate Poisson error bars are shown. Miscellaneous improvements other. The RooFit messagee service class RooMsgService has been augmented with a stack that; can store its configurate state information. A call to saveState() will save the; present configuration, which can be restored through a subsequent call to restoreState().; In addition to the method RooAbsArg::printCompactTree() which is mostly intende for; debugging, a new method RooAbsArg::printComponentTree() has been added that prints; the tree structure of a pdf in a more user-friendly content oriented way. The printing ; of the leaf nodes (the variables) is omitted in this method to keep the output compact. RooStats. This release contains significant bug fixes and it is strongly; recommended to update to this version if using older ones. . Major Changes in LimitCalculator and HypoTestCalculator classes: usage of ModelConfig class. The RooStats calculator interfaces have been changed to use the M",MatchSource.DOCS,roofit/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:10621,Availability,error,error,10621,"ite dataset to dummy model; w->factory(""SUM::model(fsig[0,1]*g,u)""); w::model.fitTo(d12a). For virtual composite dataset it is also possible to join a mix of binned and unbinned datasets; (representation as a RooDataSet with weights). The setWeightVar() method has been deprecated as it is very difficult to support on-the-fly redefinition; of the event weight variable in the new data store scheme. To declare a data set weighed,; use the WeightVar() modifier of the constructor instead,e.g.:. RooDataSet wdata(""wdata"",""wdata"",RooArgSet(x,y,wgt),WeightVar(wgt)) ;. The RooHist class that represents data as a histogram in a RooPlot has been modified; so that it can show approximate Poisson errors for non-integer data. These approximate; errors are calculated from interpolation of the error bars of the nearest integers. NB: A weighted dataset; plotted with RooAbsData::plotOn() will be default show sum-of-weights-squared errors. Only; when Poisson error are forced through a DataError(RooAbsData::Poisson) argument these; approximate Poisson error bars are shown. Miscellaneous improvements other. The RooFit messagee service class RooMsgService has been augmented with a stack that; can store its configurate state information. A call to saveState() will save the; present configuration, which can be restored through a subsequent call to restoreState().; In addition to the method RooAbsArg::printCompactTree() which is mostly intende for; debugging, a new method RooAbsArg::printComponentTree() has been added that prints; the tree structure of a pdf in a more user-friendly content oriented way. The printing ; of the leaf nodes (the variables) is omitted in this method to keep the output compact. RooStats. This release contains significant bug fixes and it is strongly; recommended to update to this version if using older ones. . Major Changes in LimitCalculator and HypoTestCalculator classes: usage of ModelConfig class. The RooStats calculator interfaces have been changed to use the M",MatchSource.DOCS,roofit/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:14199,Availability,error,error,14199,"nds, and GetContourPoints to find the 2D contour points defining the likelihood interval. GetContourPoints is now used by the LikelihoodIntervalPlot class to draw the 2D contour.; ; New tutorials have been added: rs501_ProfileLikelihoodCalculator_limit.C and rs502_ProfileLikelihoodCalculator_significance.C for getting the interval limits and significance using the ProfileLikelihoodCalculator. The tutorials can be run on a set of Poisson data or Gaussian over flat with model considering optionally the nuisance parameters. The data can be generated with the rs500 tutorials. HybridCalculator. In the constructor the signature passing a name and a title string has been removed, for being consistent with all the other calculator classes. Name and title can be set optionally using the SetName and SetTitle methods. Please note that this change is not backward compatible.; Add the option to use binned generation (via SetGenerateBinned).; An estimated of the error in the obtained p values is now computed in the HybridResult class thanks to Matthias Wolf. The errors can be obtained with HybridResult::CLbError(), HybridResult::CLsplusbError() or HybridResult::CLsError().; A new tutorial has been added for showing the usage of the hybrid calculator: rs505_HybridCalculator_significance.C. new class HypoTestInverter. New class for performing an hypothesis test inversion by scanning; the hypothesis test results of the HybridCalculator for; various values of the parameter of interest. An upper (or lower) limit can be derived by looking at the; confidence level curve of the result as function of the parameter of; interest, where it intersects the desired confidence level. The class implements the IntervalCalculator interface and returns an HypoTestInverterResult class. The result is a SimpleInterval, which via the method UpperLimit returns to the user the upper limit value. The HypoTestInverter implements various option for performing the scan. HypoTestInverter::RunFixedScan will scan",MatchSource.DOCS,roofit/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:14301,Availability,error,errors,14301," by the LikelihoodIntervalPlot class to draw the 2D contour.; ; New tutorials have been added: rs501_ProfileLikelihoodCalculator_limit.C and rs502_ProfileLikelihoodCalculator_significance.C for getting the interval limits and significance using the ProfileLikelihoodCalculator. The tutorials can be run on a set of Poisson data or Gaussian over flat with model considering optionally the nuisance parameters. The data can be generated with the rs500 tutorials. HybridCalculator. In the constructor the signature passing a name and a title string has been removed, for being consistent with all the other calculator classes. Name and title can be set optionally using the SetName and SetTitle methods. Please note that this change is not backward compatible.; Add the option to use binned generation (via SetGenerateBinned).; An estimated of the error in the obtained p values is now computed in the HybridResult class thanks to Matthias Wolf. The errors can be obtained with HybridResult::CLbError(), HybridResult::CLsplusbError() or HybridResult::CLsError().; A new tutorial has been added for showing the usage of the hybrid calculator: rs505_HybridCalculator_significance.C. new class HypoTestInverter. New class for performing an hypothesis test inversion by scanning; the hypothesis test results of the HybridCalculator for; various values of the parameter of interest. An upper (or lower) limit can be derived by looking at the; confidence level curve of the result as function of the parameter of; interest, where it intersects the desired confidence level. The class implements the IntervalCalculator interface and returns an HypoTestInverterResult class. The result is a SimpleInterval, which via the method UpperLimit returns to the user the upper limit value. The HypoTestInverter implements various option for performing the scan. HypoTestInverter::RunFixedScan will scan using a fixed grid the parameter of interest. HypoTestInverter::RunAutoScan will perform an automatic scan to find op",MatchSource.DOCS,roofit/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:15669,Availability,error,error,15669,"ower) limit can be derived by looking at the; confidence level curve of the result as function of the parameter of; interest, where it intersects the desired confidence level. The class implements the IntervalCalculator interface and returns an HypoTestInverterResult class. The result is a SimpleInterval, which via the method UpperLimit returns to the user the upper limit value. The HypoTestInverter implements various option for performing the scan. HypoTestInverter::RunFixedScan will scan using a fixed grid the parameter of interest. HypoTestInverter::RunAutoScan will perform an automatic scan to find optimally the curve and it will stop when the desired precision is obtained.; The confidence level value at a given point can also be done via HypoTestInverter::RunOnePoint.; The class can scan the CLs+b values (default) or alternatively CLs (if the; method HypoTestInverter::UseCLs has been called).; The estimated error due to the MC toys statistics from the HybridCalculator is propagated into the limits obtained from the HypoTestResult; A new tutorial rs801_HypoTestInverter.C has been added in the tutorials/roostats directory to show the usage of this class. New class BayesianCalculator. New class for calculating Bayesian interval using numerical integration. It implements the IntervalCalculator interface and returns as result a SimpleInterval. . The BayesianCalculator::GetInterval() method returns a SimpleInterval which contains the lower and upper value of the bayesian interval obtained from the posterior probability for the given confidence level.; The class return also the posterior pdf (BayesianCalculator::GetPosteriorPdf()) obtained from integrating (marginalizing) on the nuisance parameters.; It works currently only for one-dimensional problems by relying on RooFit for performing analytical or numerical integration.; A plot of the posterior and the desired interval can be obtained using BayesianCalculator::GetPosteriorPlot().; A new tutorial rs701_BayesianCalc",MatchSource.DOCS,roofit/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:200,Deployability,release,release,200,". RooFit; New infrastructure for toy MC studies. A new class RooStudyManager has been added that is intended; to replace the present RooMCStudy framework for toy MC; studies on the time scale of ROOT release 5.26. The present RooMCStudy is a small monolithic driver to; execute 'generate-and-fit' style MC studies for a given pdf. It; provides some room for customization, through modules inheriting from; RooAbsMCStudyModule that can modify the standard behavior, but its; design limits the amount of flexibility.; In the new RooStudyManager design, the functionality of; RooMCStudy has been split into two classes: class; RooStudyManager which manages the logistics of running; repetitive studies and class RooGenFitStudy which implements; the functionality of the 'generate-and-fit'-style study of RooMCStudy.; The new design has two big advantages:. Complete freedom in the design of studies, either by tailoring the behavior of RooGenFitStudy or; by using another study module that inherits from RooAbsStudy, and the data that they return.; More flexibility in the mode of execution. The new study manager can execute all study; modules inlines, as was done in RooMCStudy), but also parallelized through PROOF (at present; only PROOF-lite is support, as well as in batch. The code fragment below illustrates the use of the new study manager. // Create workspace with p.d.f; RooWorkspace* ww = new RooWorkspace(""ww"") ;; ww->factory(""Gaussian::g(x[-10,10],mean[-10,10],sigma[3,0.1,10])"") ;. RooGenFitStudy gfs ;; gfs.setGenConfig(""g"",""x"",NumEvents(1000)) ;; gfs.setFitConfig(""g"",""x"",PrintLevel(-1)) ;. RooStudyManager mgr(*ww,gfs) ;. mgr.run(1000) ; // execute 1000 toys inline; mgr.runProof(10000,"""") ; // execute 10000 toys through PROOF-lite. gfs.summaryData()->Print() ;. Workspace and factory improvements. The workspace class RooWorkspace has been augmented with several; new features. The import() method now supports a new argument RenameAllVariablesExcept(const char* suffix, const char ke",MatchSource.DOCS,roofit/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:6637,Deployability,release,release,6637,"this will only happen if the factory tag of the existing object is different; from the tag of the existing object. w.factory(""Gaussian::g(x[-10,10],m[0],s[3])"") ;; w.factory(""Chebychev::g(x[-10,10],{0,1,2})"") ; // Now OK, x has identical spec, existing x will be used. Improvements to functions and pdfs. Addition to, reorganization of morphing operator classes. The existing class RooLinearMorph which; implements 'Alex Read' morphing has been renamed RooIntegralMorph. A new class RooMomentMorph; has been added (contribution from Max Baak and Stefan Gadatsch) that implements a different morphing algorithm ; based on shifting the mean and variance of the input pdfs. The new moment morphing class can also interpolate ; between multiple input templates and works with multi-dimensional input pdfs. One of the appealing features; is that no expensive calculations are required to calculate in the interpolated pdfs shapes after the pdf; initialization. An extension that allows morphing in two parameters is foreseen for the next root release.; Progress indication in plot projections; The RooAbsReal::plotOn() now accepts a new argument ShowProgress() that will print a dot for every; function evaluation performed in the process of creating the plot. This can be useful when plotting very expensive; functions such as profile likelihoods; Automatic handling of constraint terms; It is no longer necessary to add a Constrain() argument to fitTo() calls to have internal constraints; applied. Any pdf term appearing in a product that does not contain an observable and shares one or more parameters; with another pdf term in the same product that does contain an observable is automatically picked up as a constraint term.; For example given a dataset D(x) which defines variable x as observable, the default logic works out as follows. F(x,a,b)*G(a,a0,a1) --> G is constraint term (a also appears in F(x)); F(x,a,b)*G(y,c,d) --> G is dropped (factorizing term). A Constrain(y) term in the above ex",MatchSource.DOCS,roofit/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:7758,Deployability,integrat,integrations,7758,"() now accepts a new argument ShowProgress() that will print a dot for every; function evaluation performed in the process of creating the plot. This can be useful when plotting very expensive; functions such as profile likelihoods; Automatic handling of constraint terms; It is no longer necessary to add a Constrain() argument to fitTo() calls to have internal constraints; applied. Any pdf term appearing in a product that does not contain an observable and shares one or more parameters; with another pdf term in the same product that does contain an observable is automatically picked up as a constraint term.; For example given a dataset D(x) which defines variable x as observable, the default logic works out as follows. F(x,a,b)*G(a,a0,a1) --> G is constraint term (a also appears in F(x)); F(x,a,b)*G(y,c,d) --> G is dropped (factorizing term). A Constrain(y) term in the above example will still force term G(y,c,d) to be interpreted as constraint term; Automatic caching of numeric integral calculations; Integrals that require numeric integrations in two of more dimensions are now automatically cached in the expensive object store.; The expensive object store allows to cache such values between difference instance of integral objects that represent the; same configuration. If integrals are created from an object (function or pdf) that live in a RooWorkspace the ; expensive object cache of the workspace will be used instead of the global store instance, and values stored in the workspace; store will also be persisted if the workspace is persisted. The global caching behavior of integral objects can be ; controlled through RooRealIntegral::setCacheAllNumeric(Int_t nDimNumMin). Miscellaneous improvements data classes. The RooAbsData::tree() method has been restored. It will only return a TTree* pointer for datasets; that are based on a RooTreeDataStore implementation, i.e. not for the composite datasets mentioned below; A new composite data storage class RooCompositeDataS",MatchSource.DOCS,roofit/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:7986,Deployability,configurat,configuration,7986,"e likelihoods; Automatic handling of constraint terms; It is no longer necessary to add a Constrain() argument to fitTo() calls to have internal constraints; applied. Any pdf term appearing in a product that does not contain an observable and shares one or more parameters; with another pdf term in the same product that does contain an observable is automatically picked up as a constraint term.; For example given a dataset D(x) which defines variable x as observable, the default logic works out as follows. F(x,a,b)*G(a,a0,a1) --> G is constraint term (a also appears in F(x)); F(x,a,b)*G(y,c,d) --> G is dropped (factorizing term). A Constrain(y) term in the above example will still force term G(y,c,d) to be interpreted as constraint term; Automatic caching of numeric integral calculations; Integrals that require numeric integrations in two of more dimensions are now automatically cached in the expensive object store.; The expensive object store allows to cache such values between difference instance of integral objects that represent the; same configuration. If integrals are created from an object (function or pdf) that live in a RooWorkspace the ; expensive object cache of the workspace will be used instead of the global store instance, and values stored in the workspace; store will also be persisted if the workspace is persisted. The global caching behavior of integral objects can be ; controlled through RooRealIntegral::setCacheAllNumeric(Int_t nDimNumMin). Miscellaneous improvements data classes. The RooAbsData::tree() method has been restored. It will only return a TTree* pointer for datasets; that are based on a RooTreeDataStore implementation, i.e. not for the composite datasets mentioned below; A new composite data storage class RooCompositeDataStore has been added that allows to construct composite; RooDataSet objects without copying the input data. . // Make 2 input datasets and an index category; RooWorkspace w(""w"",true) ;; w->factory(""Gaussian::g(x[-10,10]",MatchSource.DOCS,roofit/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:10777,Deployability,configurat,configurate,10777,"d unbinned datasets; (representation as a RooDataSet with weights). The setWeightVar() method has been deprecated as it is very difficult to support on-the-fly redefinition; of the event weight variable in the new data store scheme. To declare a data set weighed,; use the WeightVar() modifier of the constructor instead,e.g.:. RooDataSet wdata(""wdata"",""wdata"",RooArgSet(x,y,wgt),WeightVar(wgt)) ;. The RooHist class that represents data as a histogram in a RooPlot has been modified; so that it can show approximate Poisson errors for non-integer data. These approximate; errors are calculated from interpolation of the error bars of the nearest integers. NB: A weighted dataset; plotted with RooAbsData::plotOn() will be default show sum-of-weights-squared errors. Only; when Poisson error are forced through a DataError(RooAbsData::Poisson) argument these; approximate Poisson error bars are shown. Miscellaneous improvements other. The RooFit messagee service class RooMsgService has been augmented with a stack that; can store its configurate state information. A call to saveState() will save the; present configuration, which can be restored through a subsequent call to restoreState().; In addition to the method RooAbsArg::printCompactTree() which is mostly intende for; debugging, a new method RooAbsArg::printComponentTree() has been added that prints; the tree structure of a pdf in a more user-friendly content oriented way. The printing ; of the leaf nodes (the variables) is omitted in this method to keep the output compact. RooStats. This release contains significant bug fixes and it is strongly; recommended to update to this version if using older ones. . Major Changes in LimitCalculator and HypoTestCalculator classes: usage of ModelConfig class. The RooStats calculator interfaces have been changed to use the ModelConfig class.; All the setter methods with the parameter lists, pdf instances and name have been removed from the interfaces.; The SetWorkspace(RooWorkspace & ) ha",MatchSource.DOCS,roofit/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:10853,Deployability,configurat,configuration,10853,"ifficult to support on-the-fly redefinition; of the event weight variable in the new data store scheme. To declare a data set weighed,; use the WeightVar() modifier of the constructor instead,e.g.:. RooDataSet wdata(""wdata"",""wdata"",RooArgSet(x,y,wgt),WeightVar(wgt)) ;. The RooHist class that represents data as a histogram in a RooPlot has been modified; so that it can show approximate Poisson errors for non-integer data. These approximate; errors are calculated from interpolation of the error bars of the nearest integers. NB: A weighted dataset; plotted with RooAbsData::plotOn() will be default show sum-of-weights-squared errors. Only; when Poisson error are forced through a DataError(RooAbsData::Poisson) argument these; approximate Poisson error bars are shown. Miscellaneous improvements other. The RooFit messagee service class RooMsgService has been augmented with a stack that; can store its configurate state information. A call to saveState() will save the; present configuration, which can be restored through a subsequent call to restoreState().; In addition to the method RooAbsArg::printCompactTree() which is mostly intende for; debugging, a new method RooAbsArg::printComponentTree() has been added that prints; the tree structure of a pdf in a more user-friendly content oriented way. The printing ; of the leaf nodes (the variables) is omitted in this method to keep the output compact. RooStats. This release contains significant bug fixes and it is strongly; recommended to update to this version if using older ones. . Major Changes in LimitCalculator and HypoTestCalculator classes: usage of ModelConfig class. The RooStats calculator interfaces have been changed to use the ModelConfig class.; All the setter methods with the parameter lists, pdf instances and name have been removed from the interfaces.; The SetWorkspace(RooWorkspace & ) has also been removed, while a SetModel(const ModelConfig &); function is introduced. Users are supposed to pass all the model info",MatchSource.DOCS,roofit/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:11297,Deployability,release,release,11297,"on of the error bars of the nearest integers. NB: A weighted dataset; plotted with RooAbsData::plotOn() will be default show sum-of-weights-squared errors. Only; when Poisson error are forced through a DataError(RooAbsData::Poisson) argument these; approximate Poisson error bars are shown. Miscellaneous improvements other. The RooFit messagee service class RooMsgService has been augmented with a stack that; can store its configurate state information. A call to saveState() will save the; present configuration, which can be restored through a subsequent call to restoreState().; In addition to the method RooAbsArg::printCompactTree() which is mostly intende for; debugging, a new method RooAbsArg::printComponentTree() has been added that prints; the tree structure of a pdf in a more user-friendly content oriented way. The printing ; of the leaf nodes (the variables) is omitted in this method to keep the output compact. RooStats. This release contains significant bug fixes and it is strongly; recommended to update to this version if using older ones. . Major Changes in LimitCalculator and HypoTestCalculator classes: usage of ModelConfig class. The RooStats calculator interfaces have been changed to use the ModelConfig class.; All the setter methods with the parameter lists, pdf instances and name have been removed from the interfaces.; The SetWorkspace(RooWorkspace & ) has also been removed, while a SetModel(const ModelConfig &); function is introduced. Users are supposed to pass all the model information using the; ModelConfig class rather than via the; RooWorkspace or specifying directly the pdf and parameter; objects in the constructors. ; Setter methods using pdf instances and parameter lists are maintained in the derived classes, like the ProfileLikelihoodCalculator or the HybridCalculator, but those passing a string for the name of the pdf have been removed. ; All the calculator classes do not keep anymore a pointer to the workspace, but they contain pointers to th",MatchSource.DOCS,roofit/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:11371,Deployability,update,update,11371,"on of the error bars of the nearest integers. NB: A weighted dataset; plotted with RooAbsData::plotOn() will be default show sum-of-weights-squared errors. Only; when Poisson error are forced through a DataError(RooAbsData::Poisson) argument these; approximate Poisson error bars are shown. Miscellaneous improvements other. The RooFit messagee service class RooMsgService has been augmented with a stack that; can store its configurate state information. A call to saveState() will save the; present configuration, which can be restored through a subsequent call to restoreState().; In addition to the method RooAbsArg::printCompactTree() which is mostly intende for; debugging, a new method RooAbsArg::printComponentTree() has been added that prints; the tree structure of a pdf in a more user-friendly content oriented way. The printing ; of the leaf nodes (the variables) is omitted in this method to keep the output compact. RooStats. This release contains significant bug fixes and it is strongly; recommended to update to this version if using older ones. . Major Changes in LimitCalculator and HypoTestCalculator classes: usage of ModelConfig class. The RooStats calculator interfaces have been changed to use the ModelConfig class.; All the setter methods with the parameter lists, pdf instances and name have been removed from the interfaces.; The SetWorkspace(RooWorkspace & ) has also been removed, while a SetModel(const ModelConfig &); function is introduced. Users are supposed to pass all the model information using the; ModelConfig class rather than via the; RooWorkspace or specifying directly the pdf and parameter; objects in the constructors. ; Setter methods using pdf instances and parameter lists are maintained in the derived classes, like the ProfileLikelihoodCalculator or the HybridCalculator, but those passing a string for the name of the pdf have been removed. ; All the calculator classes do not keep anymore a pointer to the workspace, but they contain pointers to th",MatchSource.DOCS,roofit/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:16009,Deployability,integrat,integration,16009," an HypoTestInverterResult class. The result is a SimpleInterval, which via the method UpperLimit returns to the user the upper limit value. The HypoTestInverter implements various option for performing the scan. HypoTestInverter::RunFixedScan will scan using a fixed grid the parameter of interest. HypoTestInverter::RunAutoScan will perform an automatic scan to find optimally the curve and it will stop when the desired precision is obtained.; The confidence level value at a given point can also be done via HypoTestInverter::RunOnePoint.; The class can scan the CLs+b values (default) or alternatively CLs (if the; method HypoTestInverter::UseCLs has been called).; The estimated error due to the MC toys statistics from the HybridCalculator is propagated into the limits obtained from the HypoTestResult; A new tutorial rs801_HypoTestInverter.C has been added in the tutorials/roostats directory to show the usage of this class. New class BayesianCalculator. New class for calculating Bayesian interval using numerical integration. It implements the IntervalCalculator interface and returns as result a SimpleInterval. . The BayesianCalculator::GetInterval() method returns a SimpleInterval which contains the lower and upper value of the bayesian interval obtained from the posterior probability for the given confidence level.; The class return also the posterior pdf (BayesianCalculator::GetPosteriorPdf()) obtained from integrating (marginalizing) on the nuisance parameters.; It works currently only for one-dimensional problems by relying on RooFit for performing analytical or numerical integration.; A plot of the posterior and the desired interval can be obtained using BayesianCalculator::GetPosteriorPlot().; A new tutorial rs701_BayesianCalculator.C has been added in the tutorials/roostats directory to show the usage of this class. MCMCCalculator. Add possibility to specify the prior function in the constructor of the class to have a signature similar to the BayesianCalculator c",MatchSource.DOCS,roofit/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:16414,Deployability,integrat,integrating,16414,"n the desired precision is obtained.; The confidence level value at a given point can also be done via HypoTestInverter::RunOnePoint.; The class can scan the CLs+b values (default) or alternatively CLs (if the; method HypoTestInverter::UseCLs has been called).; The estimated error due to the MC toys statistics from the HybridCalculator is propagated into the limits obtained from the HypoTestResult; A new tutorial rs801_HypoTestInverter.C has been added in the tutorials/roostats directory to show the usage of this class. New class BayesianCalculator. New class for calculating Bayesian interval using numerical integration. It implements the IntervalCalculator interface and returns as result a SimpleInterval. . The BayesianCalculator::GetInterval() method returns a SimpleInterval which contains the lower and upper value of the bayesian interval obtained from the posterior probability for the given confidence level.; The class return also the posterior pdf (BayesianCalculator::GetPosteriorPdf()) obtained from integrating (marginalizing) on the nuisance parameters.; It works currently only for one-dimensional problems by relying on RooFit for performing analytical or numerical integration.; A plot of the posterior and the desired interval can be obtained using BayesianCalculator::GetPosteriorPlot().; A new tutorial rs701_BayesianCalculator.C has been added in the tutorials/roostats directory to show the usage of this class. MCMCCalculator. Add possibility to specify the prior function in the constructor of the class to have a signature similar to the BayesianCalculator class. When no prior is specified it is assumed is part of the global model (pdf) passed to the class. Improvements and Bug fixes. Various improvements and fixes have been applied also to all the calculator classes. Internally now the RooArgSet objects are used by value instead of a pointer.; All the calculator have a consistent way for being constructed, either by passing pdf pointers and the set defining ",MatchSource.DOCS,roofit/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:16584,Deployability,integrat,integration,16584,"class can scan the CLs+b values (default) or alternatively CLs (if the; method HypoTestInverter::UseCLs has been called).; The estimated error due to the MC toys statistics from the HybridCalculator is propagated into the limits obtained from the HypoTestResult; A new tutorial rs801_HypoTestInverter.C has been added in the tutorials/roostats directory to show the usage of this class. New class BayesianCalculator. New class for calculating Bayesian interval using numerical integration. It implements the IntervalCalculator interface and returns as result a SimpleInterval. . The BayesianCalculator::GetInterval() method returns a SimpleInterval which contains the lower and upper value of the bayesian interval obtained from the posterior probability for the given confidence level.; The class return also the posterior pdf (BayesianCalculator::GetPosteriorPdf()) obtained from integrating (marginalizing) on the nuisance parameters.; It works currently only for one-dimensional problems by relying on RooFit for performing analytical or numerical integration.; A plot of the posterior and the desired interval can be obtained using BayesianCalculator::GetPosteriorPlot().; A new tutorial rs701_BayesianCalculator.C has been added in the tutorials/roostats directory to show the usage of this class. MCMCCalculator. Add possibility to specify the prior function in the constructor of the class to have a signature similar to the BayesianCalculator class. When no prior is specified it is assumed is part of the global model (pdf) passed to the class. Improvements and Bug fixes. Various improvements and fixes have been applied also to all the calculator classes. Internally now the RooArgSet objects are used by value instead of a pointer.; All the calculator have a consistent way for being constructed, either by passing pdf pointers and the set defining the parameters or by passing a reference to a ModelConfig class.; The result classes are now more consistent and have similar constructors.",MatchSource.DOCS,roofit/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:5240,Energy Efficiency,reduce,reduced,5240,"mean sigma=msig_sigma ] = 1; RooEfficiency::effSigPdf[ cat=cut effFunc=effSig ] = 0.899817; RooFormulaVar::effSig[ actualVars=(pt,as,ms,ss) formula=""0.5*@1*(1+TMath::Erf((@0-@2)/@3))"" ] = 0.899817; RooProdPdf::bkg[ ptBkgPdf * mllBkgPdf * effBkgPdf|pt ] = 0.267845; RooExponential::ptBkgPdf[ x=pt c=pbkg_slope ] = 0.449329; RooPolynomial::mllBkgPdf[ x=mll coefList=(mbkg_slope) ] = 0.775; RooEfficiency::effBkgPdf[ cat=cut effFunc=effBkg ] = 0.76916; RooFormulaVar::effBkg[ actualVars=(pt,ab,mb,sb) formula=""0.5*@1*(1+TMath::Erf((@0-@2)/@3))"" ] = 0.76916. The workspace factory can now access all objects in the generic object store of the workspace, e.g. TMatrixDSym* cov ; RooWorkspace w(""w"") ;; w.import(*cov,""cov"") ;; w.factory(""MultiVarGaussian::mvg({x[-10,10],y[-10,10]},{3,5},cov)"") ;. The workspace factory now correctly identifies and matches typedef-ed names in factory constructor; specifications.; All objects created by the factory and inserted by the workspace get a string attribute ""factory_tag"",; that contains the reduced factory string that was used to create that object, e.g. RooWorkspace w(""w"") ;; w.factory(""Gaussian::g(x[-10,10],m[0],s[3])"") ;; cout << w.pdf(""g"")->getStringAttribute(""factory_tag"") << endl ;; RooGaussian::g(x,m,s). Previously all factory orders that would create objects with names of objects that already existed always; resulted in an error. Now, this will only happen if the factory tag of the existing object is different; from the tag of the existing object. w.factory(""Gaussian::g(x[-10,10],m[0],s[3])"") ;; w.factory(""Chebychev::g(x[-10,10],{0,1,2})"") ; // Now OK, x has identical spec, existing x will be used. Improvements to functions and pdfs. Addition to, reorganization of morphing operator classes. The existing class RooLinearMorph which; implements 'Alex Read' morphing has been renamed RooIntegralMorph. A new class RooMomentMorph; has been added (contribution from Max Baak and Stefan Gadatsch) that implements a different morphing algorithm ",MatchSource.DOCS,roofit/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:7758,Integrability,integrat,integrations,7758,"() now accepts a new argument ShowProgress() that will print a dot for every; function evaluation performed in the process of creating the plot. This can be useful when plotting very expensive; functions such as profile likelihoods; Automatic handling of constraint terms; It is no longer necessary to add a Constrain() argument to fitTo() calls to have internal constraints; applied. Any pdf term appearing in a product that does not contain an observable and shares one or more parameters; with another pdf term in the same product that does contain an observable is automatically picked up as a constraint term.; For example given a dataset D(x) which defines variable x as observable, the default logic works out as follows. F(x,a,b)*G(a,a0,a1) --> G is constraint term (a also appears in F(x)); F(x,a,b)*G(y,c,d) --> G is dropped (factorizing term). A Constrain(y) term in the above example will still force term G(y,c,d) to be interpreted as constraint term; Automatic caching of numeric integral calculations; Integrals that require numeric integrations in two of more dimensions are now automatically cached in the expensive object store.; The expensive object store allows to cache such values between difference instance of integral objects that represent the; same configuration. If integrals are created from an object (function or pdf) that live in a RooWorkspace the ; expensive object cache of the workspace will be used instead of the global store instance, and values stored in the workspace; store will also be persisted if the workspace is persisted. The global caching behavior of integral objects can be ; controlled through RooRealIntegral::setCacheAllNumeric(Int_t nDimNumMin). Miscellaneous improvements data classes. The RooAbsData::tree() method has been restored. It will only return a TTree* pointer for datasets; that are based on a RooTreeDataStore implementation, i.e. not for the composite datasets mentioned below; A new composite data storage class RooCompositeDataS",MatchSource.DOCS,roofit/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:10688,Integrability,message,messagee,10688,"d unbinned datasets; (representation as a RooDataSet with weights). The setWeightVar() method has been deprecated as it is very difficult to support on-the-fly redefinition; of the event weight variable in the new data store scheme. To declare a data set weighed,; use the WeightVar() modifier of the constructor instead,e.g.:. RooDataSet wdata(""wdata"",""wdata"",RooArgSet(x,y,wgt),WeightVar(wgt)) ;. The RooHist class that represents data as a histogram in a RooPlot has been modified; so that it can show approximate Poisson errors for non-integer data. These approximate; errors are calculated from interpolation of the error bars of the nearest integers. NB: A weighted dataset; plotted with RooAbsData::plotOn() will be default show sum-of-weights-squared errors. Only; when Poisson error are forced through a DataError(RooAbsData::Poisson) argument these; approximate Poisson error bars are shown. Miscellaneous improvements other. The RooFit messagee service class RooMsgService has been augmented with a stack that; can store its configurate state information. A call to saveState() will save the; present configuration, which can be restored through a subsequent call to restoreState().; In addition to the method RooAbsArg::printCompactTree() which is mostly intende for; debugging, a new method RooAbsArg::printComponentTree() has been added that prints; the tree structure of a pdf in a more user-friendly content oriented way. The printing ; of the leaf nodes (the variables) is omitted in this method to keep the output compact. RooStats. This release contains significant bug fixes and it is strongly; recommended to update to this version if using older ones. . Major Changes in LimitCalculator and HypoTestCalculator classes: usage of ModelConfig class. The RooStats calculator interfaces have been changed to use the ModelConfig class.; All the setter methods with the parameter lists, pdf instances and name have been removed from the interfaces.; The SetWorkspace(RooWorkspace & ) ha",MatchSource.DOCS,roofit/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:11534,Integrability,interface,interfaces,11534,"h a DataError(RooAbsData::Poisson) argument these; approximate Poisson error bars are shown. Miscellaneous improvements other. The RooFit messagee service class RooMsgService has been augmented with a stack that; can store its configurate state information. A call to saveState() will save the; present configuration, which can be restored through a subsequent call to restoreState().; In addition to the method RooAbsArg::printCompactTree() which is mostly intende for; debugging, a new method RooAbsArg::printComponentTree() has been added that prints; the tree structure of a pdf in a more user-friendly content oriented way. The printing ; of the leaf nodes (the variables) is omitted in this method to keep the output compact. RooStats. This release contains significant bug fixes and it is strongly; recommended to update to this version if using older ones. . Major Changes in LimitCalculator and HypoTestCalculator classes: usage of ModelConfig class. The RooStats calculator interfaces have been changed to use the ModelConfig class.; All the setter methods with the parameter lists, pdf instances and name have been removed from the interfaces.; The SetWorkspace(RooWorkspace & ) has also been removed, while a SetModel(const ModelConfig &); function is introduced. Users are supposed to pass all the model information using the; ModelConfig class rather than via the; RooWorkspace or specifying directly the pdf and parameter; objects in the constructors. ; Setter methods using pdf instances and parameter lists are maintained in the derived classes, like the ProfileLikelihoodCalculator or the HybridCalculator, but those passing a string for the name of the pdf have been removed. ; All the calculator classes do not keep anymore a pointer to the workspace, but they contain pointers to the pdf, the data and the parameters required to run the calculator. These pointers are managed outside by the users or by the RooWorkspace. They can be passed either directly to the classes, for exam",MatchSource.DOCS,roofit/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:11693,Integrability,interface,interfaces,11693,"llaneous improvements other. The RooFit messagee service class RooMsgService has been augmented with a stack that; can store its configurate state information. A call to saveState() will save the; present configuration, which can be restored through a subsequent call to restoreState().; In addition to the method RooAbsArg::printCompactTree() which is mostly intende for; debugging, a new method RooAbsArg::printComponentTree() has been added that prints; the tree structure of a pdf in a more user-friendly content oriented way. The printing ; of the leaf nodes (the variables) is omitted in this method to keep the output compact. RooStats. This release contains significant bug fixes and it is strongly; recommended to update to this version if using older ones. . Major Changes in LimitCalculator and HypoTestCalculator classes: usage of ModelConfig class. The RooStats calculator interfaces have been changed to use the ModelConfig class.; All the setter methods with the parameter lists, pdf instances and name have been removed from the interfaces.; The SetWorkspace(RooWorkspace & ) has also been removed, while a SetModel(const ModelConfig &); function is introduced. Users are supposed to pass all the model information using the; ModelConfig class rather than via the; RooWorkspace or specifying directly the pdf and parameter; objects in the constructors. ; Setter methods using pdf instances and parameter lists are maintained in the derived classes, like the ProfileLikelihoodCalculator or the HybridCalculator, but those passing a string for the name of the pdf have been removed. ; All the calculator classes do not keep anymore a pointer to the workspace, but they contain pointers to the pdf, the data and the parameters required to run the calculator. These pointers are managed outside by the users or by the RooWorkspace. They can be passed either directly to the classes, for example via the constructor, or by using the ModelConfig class. The ModelConfig class acts as an inte",MatchSource.DOCS,roofit/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:12644,Integrability,interface,interface,12644,"ve been removed from the interfaces.; The SetWorkspace(RooWorkspace & ) has also been removed, while a SetModel(const ModelConfig &); function is introduced. Users are supposed to pass all the model information using the; ModelConfig class rather than via the; RooWorkspace or specifying directly the pdf and parameter; objects in the constructors. ; Setter methods using pdf instances and parameter lists are maintained in the derived classes, like the ProfileLikelihoodCalculator or the HybridCalculator, but those passing a string for the name of the pdf have been removed. ; All the calculator classes do not keep anymore a pointer to the workspace, but they contain pointers to the pdf, the data and the parameters required to run the calculator. These pointers are managed outside by the users or by the RooWorkspace. They can be passed either directly to the classes, for example via the constructor, or by using the ModelConfig class. The ModelConfig class acts as an interface to the Workspace in order to load and store all the; needed information. . ProfileLikelihoodCalculator, LikelihoodInterval. The Minos algorithm of Minuit is used now to find the limit of the likelihood intervals instead of searching directly the roots of the RooProfileLL class. Minos is used via the ROOT::Math::Minimizer interface. By default TMinuit is used, one can also use Minuit2 by doing ROOT::Math::MinimizerOptions::SetDefaultMinimizer(""Minuit2"").; The LikelihoodInterval class now provides now two new methods, FindLimits which finds both the upper and lower interval bounds, and GetContourPoints to find the 2D contour points defining the likelihood interval. GetContourPoints is now used by the LikelihoodIntervalPlot class to draw the 2D contour.; ; New tutorials have been added: rs501_ProfileLikelihoodCalculator_limit.C and rs502_ProfileLikelihoodCalculator_significance.C for getting the interval limits and significance using the ProfileLikelihoodCalculator. The tutorials can be run on a set of",MatchSource.DOCS,roofit/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:12977,Integrability,interface,interface,12977,"ectly the pdf and parameter; objects in the constructors. ; Setter methods using pdf instances and parameter lists are maintained in the derived classes, like the ProfileLikelihoodCalculator or the HybridCalculator, but those passing a string for the name of the pdf have been removed. ; All the calculator classes do not keep anymore a pointer to the workspace, but they contain pointers to the pdf, the data and the parameters required to run the calculator. These pointers are managed outside by the users or by the RooWorkspace. They can be passed either directly to the classes, for example via the constructor, or by using the ModelConfig class. The ModelConfig class acts as an interface to the Workspace in order to load and store all the; needed information. . ProfileLikelihoodCalculator, LikelihoodInterval. The Minos algorithm of Minuit is used now to find the limit of the likelihood intervals instead of searching directly the roots of the RooProfileLL class. Minos is used via the ROOT::Math::Minimizer interface. By default TMinuit is used, one can also use Minuit2 by doing ROOT::Math::MinimizerOptions::SetDefaultMinimizer(""Minuit2"").; The LikelihoodInterval class now provides now two new methods, FindLimits which finds both the upper and lower interval bounds, and GetContourPoints to find the 2D contour points defining the likelihood interval. GetContourPoints is now used by the LikelihoodIntervalPlot class to draw the 2D contour.; ; New tutorials have been added: rs501_ProfileLikelihoodCalculator_limit.C and rs502_ProfileLikelihoodCalculator_significance.C for getting the interval limits and significance using the ProfileLikelihoodCalculator. The tutorials can be run on a set of Poisson data or Gaussian over flat with model considering optionally the nuisance parameters. The data can be generated with the rs500 tutorials. HybridCalculator. In the constructor the signature passing a name and a title string has been removed, for being consistent with all the other ca",MatchSource.DOCS,roofit/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:14963,Integrability,interface,interface,14963,"r classes. Name and title can be set optionally using the SetName and SetTitle methods. Please note that this change is not backward compatible.; Add the option to use binned generation (via SetGenerateBinned).; An estimated of the error in the obtained p values is now computed in the HybridResult class thanks to Matthias Wolf. The errors can be obtained with HybridResult::CLbError(), HybridResult::CLsplusbError() or HybridResult::CLsError().; A new tutorial has been added for showing the usage of the hybrid calculator: rs505_HybridCalculator_significance.C. new class HypoTestInverter. New class for performing an hypothesis test inversion by scanning; the hypothesis test results of the HybridCalculator for; various values of the parameter of interest. An upper (or lower) limit can be derived by looking at the; confidence level curve of the result as function of the parameter of; interest, where it intersects the desired confidence level. The class implements the IntervalCalculator interface and returns an HypoTestInverterResult class. The result is a SimpleInterval, which via the method UpperLimit returns to the user the upper limit value. The HypoTestInverter implements various option for performing the scan. HypoTestInverter::RunFixedScan will scan using a fixed grid the parameter of interest. HypoTestInverter::RunAutoScan will perform an automatic scan to find optimally the curve and it will stop when the desired precision is obtained.; The confidence level value at a given point can also be done via HypoTestInverter::RunOnePoint.; The class can scan the CLs+b values (default) or alternatively CLs (if the; method HypoTestInverter::UseCLs has been called).; The estimated error due to the MC toys statistics from the HybridCalculator is propagated into the limits obtained from the HypoTestResult; A new tutorial rs801_HypoTestInverter.C has been added in the tutorials/roostats directory to show the usage of this class. New class BayesianCalculator. New class for calcu",MatchSource.DOCS,roofit/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:16009,Integrability,integrat,integration,16009," an HypoTestInverterResult class. The result is a SimpleInterval, which via the method UpperLimit returns to the user the upper limit value. The HypoTestInverter implements various option for performing the scan. HypoTestInverter::RunFixedScan will scan using a fixed grid the parameter of interest. HypoTestInverter::RunAutoScan will perform an automatic scan to find optimally the curve and it will stop when the desired precision is obtained.; The confidence level value at a given point can also be done via HypoTestInverter::RunOnePoint.; The class can scan the CLs+b values (default) or alternatively CLs (if the; method HypoTestInverter::UseCLs has been called).; The estimated error due to the MC toys statistics from the HybridCalculator is propagated into the limits obtained from the HypoTestResult; A new tutorial rs801_HypoTestInverter.C has been added in the tutorials/roostats directory to show the usage of this class. New class BayesianCalculator. New class for calculating Bayesian interval using numerical integration. It implements the IntervalCalculator interface and returns as result a SimpleInterval. . The BayesianCalculator::GetInterval() method returns a SimpleInterval which contains the lower and upper value of the bayesian interval obtained from the posterior probability for the given confidence level.; The class return also the posterior pdf (BayesianCalculator::GetPosteriorPdf()) obtained from integrating (marginalizing) on the nuisance parameters.; It works currently only for one-dimensional problems by relying on RooFit for performing analytical or numerical integration.; A plot of the posterior and the desired interval can be obtained using BayesianCalculator::GetPosteriorPlot().; A new tutorial rs701_BayesianCalculator.C has been added in the tutorials/roostats directory to show the usage of this class. MCMCCalculator. Add possibility to specify the prior function in the constructor of the class to have a signature similar to the BayesianCalculator c",MatchSource.DOCS,roofit/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:16059,Integrability,interface,interface,16059,method UpperLimit returns to the user the upper limit value. The HypoTestInverter implements various option for performing the scan. HypoTestInverter::RunFixedScan will scan using a fixed grid the parameter of interest. HypoTestInverter::RunAutoScan will perform an automatic scan to find optimally the curve and it will stop when the desired precision is obtained.; The confidence level value at a given point can also be done via HypoTestInverter::RunOnePoint.; The class can scan the CLs+b values (default) or alternatively CLs (if the; method HypoTestInverter::UseCLs has been called).; The estimated error due to the MC toys statistics from the HybridCalculator is propagated into the limits obtained from the HypoTestResult; A new tutorial rs801_HypoTestInverter.C has been added in the tutorials/roostats directory to show the usage of this class. New class BayesianCalculator. New class for calculating Bayesian interval using numerical integration. It implements the IntervalCalculator interface and returns as result a SimpleInterval. . The BayesianCalculator::GetInterval() method returns a SimpleInterval which contains the lower and upper value of the bayesian interval obtained from the posterior probability for the given confidence level.; The class return also the posterior pdf (BayesianCalculator::GetPosteriorPdf()) obtained from integrating (marginalizing) on the nuisance parameters.; It works currently only for one-dimensional problems by relying on RooFit for performing analytical or numerical integration.; A plot of the posterior and the desired interval can be obtained using BayesianCalculator::GetPosteriorPlot().; A new tutorial rs701_BayesianCalculator.C has been added in the tutorials/roostats directory to show the usage of this class. MCMCCalculator. Add possibility to specify the prior function in the constructor of the class to have a signature similar to the BayesianCalculator class. When no prior is specified it is assumed is part of the global model (pdf),MatchSource.DOCS,roofit/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:16414,Integrability,integrat,integrating,16414,"n the desired precision is obtained.; The confidence level value at a given point can also be done via HypoTestInverter::RunOnePoint.; The class can scan the CLs+b values (default) or alternatively CLs (if the; method HypoTestInverter::UseCLs has been called).; The estimated error due to the MC toys statistics from the HybridCalculator is propagated into the limits obtained from the HypoTestResult; A new tutorial rs801_HypoTestInverter.C has been added in the tutorials/roostats directory to show the usage of this class. New class BayesianCalculator. New class for calculating Bayesian interval using numerical integration. It implements the IntervalCalculator interface and returns as result a SimpleInterval. . The BayesianCalculator::GetInterval() method returns a SimpleInterval which contains the lower and upper value of the bayesian interval obtained from the posterior probability for the given confidence level.; The class return also the posterior pdf (BayesianCalculator::GetPosteriorPdf()) obtained from integrating (marginalizing) on the nuisance parameters.; It works currently only for one-dimensional problems by relying on RooFit for performing analytical or numerical integration.; A plot of the posterior and the desired interval can be obtained using BayesianCalculator::GetPosteriorPlot().; A new tutorial rs701_BayesianCalculator.C has been added in the tutorials/roostats directory to show the usage of this class. MCMCCalculator. Add possibility to specify the prior function in the constructor of the class to have a signature similar to the BayesianCalculator class. When no prior is specified it is assumed is part of the global model (pdf) passed to the class. Improvements and Bug fixes. Various improvements and fixes have been applied also to all the calculator classes. Internally now the RooArgSet objects are used by value instead of a pointer.; All the calculator have a consistent way for being constructed, either by passing pdf pointers and the set defining ",MatchSource.DOCS,roofit/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:16584,Integrability,integrat,integration,16584,"class can scan the CLs+b values (default) or alternatively CLs (if the; method HypoTestInverter::UseCLs has been called).; The estimated error due to the MC toys statistics from the HybridCalculator is propagated into the limits obtained from the HypoTestResult; A new tutorial rs801_HypoTestInverter.C has been added in the tutorials/roostats directory to show the usage of this class. New class BayesianCalculator. New class for calculating Bayesian interval using numerical integration. It implements the IntervalCalculator interface and returns as result a SimpleInterval. . The BayesianCalculator::GetInterval() method returns a SimpleInterval which contains the lower and upper value of the bayesian interval obtained from the posterior probability for the given confidence level.; The class return also the posterior pdf (BayesianCalculator::GetPosteriorPdf()) obtained from integrating (marginalizing) on the nuisance parameters.; It works currently only for one-dimensional problems by relying on RooFit for performing analytical or numerical integration.; A plot of the posterior and the desired interval can be obtained using BayesianCalculator::GetPosteriorPlot().; A new tutorial rs701_BayesianCalculator.C has been added in the tutorials/roostats directory to show the usage of this class. MCMCCalculator. Add possibility to specify the prior function in the constructor of the class to have a signature similar to the BayesianCalculator class. When no prior is specified it is assumed is part of the global model (pdf) passed to the class. Improvements and Bug fixes. Various improvements and fixes have been applied also to all the calculator classes. Internally now the RooArgSet objects are used by value instead of a pointer.; All the calculator have a consistent way for being constructed, either by passing pdf pointers and the set defining the parameters or by passing a reference to a ModelConfig class.; The result classes are now more consistent and have similar constructors.",MatchSource.DOCS,roofit/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:389,Modifiability,inherit,inheriting,389,". RooFit; New infrastructure for toy MC studies. A new class RooStudyManager has been added that is intended; to replace the present RooMCStudy framework for toy MC; studies on the time scale of ROOT release 5.26. The present RooMCStudy is a small monolithic driver to; execute 'generate-and-fit' style MC studies for a given pdf. It; provides some room for customization, through modules inheriting from; RooAbsMCStudyModule that can modify the standard behavior, but its; design limits the amount of flexibility.; In the new RooStudyManager design, the functionality of; RooMCStudy has been split into two classes: class; RooStudyManager which manages the logistics of running; repetitive studies and class RooGenFitStudy which implements; the functionality of the 'generate-and-fit'-style study of RooMCStudy.; The new design has two big advantages:. Complete freedom in the design of studies, either by tailoring the behavior of RooGenFitStudy or; by using another study module that inherits from RooAbsStudy, and the data that they return.; More flexibility in the mode of execution. The new study manager can execute all study; modules inlines, as was done in RooMCStudy), but also parallelized through PROOF (at present; only PROOF-lite is support, as well as in batch. The code fragment below illustrates the use of the new study manager. // Create workspace with p.d.f; RooWorkspace* ww = new RooWorkspace(""ww"") ;; ww->factory(""Gaussian::g(x[-10,10],mean[-10,10],sigma[3,0.1,10])"") ;. RooGenFitStudy gfs ;; gfs.setGenConfig(""g"",""x"",NumEvents(1000)) ;; gfs.setFitConfig(""g"",""x"",PrintLevel(-1)) ;. RooStudyManager mgr(*ww,gfs) ;. mgr.run(1000) ; // execute 1000 toys inline; mgr.runProof(10000,"""") ; // execute 10000 toys through PROOF-lite. gfs.summaryData()->Print() ;. Workspace and factory improvements. The workspace class RooWorkspace has been augmented with several; new features. The import() method now supports a new argument RenameAllVariablesExcept(const char* suffix, const char ke",MatchSource.DOCS,roofit/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:987,Modifiability,inherit,inherits,987,". RooFit; New infrastructure for toy MC studies. A new class RooStudyManager has been added that is intended; to replace the present RooMCStudy framework for toy MC; studies on the time scale of ROOT release 5.26. The present RooMCStudy is a small monolithic driver to; execute 'generate-and-fit' style MC studies for a given pdf. It; provides some room for customization, through modules inheriting from; RooAbsMCStudyModule that can modify the standard behavior, but its; design limits the amount of flexibility.; In the new RooStudyManager design, the functionality of; RooMCStudy has been split into two classes: class; RooStudyManager which manages the logistics of running; repetitive studies and class RooGenFitStudy which implements; the functionality of the 'generate-and-fit'-style study of RooMCStudy.; The new design has two big advantages:. Complete freedom in the design of studies, either by tailoring the behavior of RooGenFitStudy or; by using another study module that inherits from RooAbsStudy, and the data that they return.; More flexibility in the mode of execution. The new study manager can execute all study; modules inlines, as was done in RooMCStudy), but also parallelized through PROOF (at present; only PROOF-lite is support, as well as in batch. The code fragment below illustrates the use of the new study manager. // Create workspace with p.d.f; RooWorkspace* ww = new RooWorkspace(""ww"") ;; ww->factory(""Gaussian::g(x[-10,10],mean[-10,10],sigma[3,0.1,10])"") ;. RooGenFitStudy gfs ;; gfs.setGenConfig(""g"",""x"",NumEvents(1000)) ;; gfs.setFitConfig(""g"",""x"",PrintLevel(-1)) ;. RooStudyManager mgr(*ww,gfs) ;. mgr.run(1000) ; // execute 1000 toys inline; mgr.runProof(10000,"""") ; // execute 10000 toys through PROOF-lite. gfs.summaryData()->Print() ;. Workspace and factory improvements. The workspace class RooWorkspace has been augmented with several; new features. The import() method now supports a new argument RenameAllVariablesExcept(const char* suffix, const char ke",MatchSource.DOCS,roofit/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:2032,Modifiability,variab,variables,2032," they return.; More flexibility in the mode of execution. The new study manager can execute all study; modules inlines, as was done in RooMCStudy), but also parallelized through PROOF (at present; only PROOF-lite is support, as well as in batch. The code fragment below illustrates the use of the new study manager. // Create workspace with p.d.f; RooWorkspace* ww = new RooWorkspace(""ww"") ;; ww->factory(""Gaussian::g(x[-10,10],mean[-10,10],sigma[3,0.1,10])"") ;. RooGenFitStudy gfs ;; gfs.setGenConfig(""g"",""x"",NumEvents(1000)) ;; gfs.setFitConfig(""g"",""x"",PrintLevel(-1)) ;. RooStudyManager mgr(*ww,gfs) ;. mgr.run(1000) ; // execute 1000 toys inline; mgr.runProof(10000,"""") ; // execute 10000 toys through PROOF-lite. gfs.summaryData()->Print() ;. Workspace and factory improvements. The workspace class RooWorkspace has been augmented with several; new features. The import() method now supports a new argument RenameAllVariablesExcept(const char* suffix, const char keepList) which; will rename all variables of the imported function by extended them with a supplied suffix,; except for a given list of variables, which are not renamed.; A new utility function importFromFile() has been added, which is similar to import, except that it take a string; specifier for the object to be imported rather than a reference. The string is expected to be of the form ; fileName:workspaceName:objectName and simplifies import of objects from other workspaces on file. The importFromFile; accepts all arguments accepted by the standard import() method.; Generic objects (inheriting from TObject) can now also be stored in the workspace under an alias name, rather; under their own name, which simplifies management of objects of types like TMatrixD that do not have a settable name. ws.import(matrix,""cov_matrix"") ;. New accessors have been added that return a RooArgSet of all elements of the workspace of a given type, e.g.; allVars(), allPdfs(). The Print() method now accepts option ""t"", which prints the c",MatchSource.DOCS,roofit/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:2070,Modifiability,extend,extended,2070," they return.; More flexibility in the mode of execution. The new study manager can execute all study; modules inlines, as was done in RooMCStudy), but also parallelized through PROOF (at present; only PROOF-lite is support, as well as in batch. The code fragment below illustrates the use of the new study manager. // Create workspace with p.d.f; RooWorkspace* ww = new RooWorkspace(""ww"") ;; ww->factory(""Gaussian::g(x[-10,10],mean[-10,10],sigma[3,0.1,10])"") ;. RooGenFitStudy gfs ;; gfs.setGenConfig(""g"",""x"",NumEvents(1000)) ;; gfs.setFitConfig(""g"",""x"",PrintLevel(-1)) ;. RooStudyManager mgr(*ww,gfs) ;. mgr.run(1000) ; // execute 1000 toys inline; mgr.runProof(10000,"""") ; // execute 10000 toys through PROOF-lite. gfs.summaryData()->Print() ;. Workspace and factory improvements. The workspace class RooWorkspace has been augmented with several; new features. The import() method now supports a new argument RenameAllVariablesExcept(const char* suffix, const char keepList) which; will rename all variables of the imported function by extended them with a supplied suffix,; except for a given list of variables, which are not renamed.; A new utility function importFromFile() has been added, which is similar to import, except that it take a string; specifier for the object to be imported rather than a reference. The string is expected to be of the form ; fileName:workspaceName:objectName and simplifies import of objects from other workspaces on file. The importFromFile; accepts all arguments accepted by the standard import() method.; Generic objects (inheriting from TObject) can now also be stored in the workspace under an alias name, rather; under their own name, which simplifies management of objects of types like TMatrixD that do not have a settable name. ws.import(matrix,""cov_matrix"") ;. New accessors have been added that return a RooArgSet of all elements of the workspace of a given type, e.g.; allVars(), allPdfs(). The Print() method now accepts option ""t"", which prints the c",MatchSource.DOCS,roofit/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:2136,Modifiability,variab,variables,2136," they return.; More flexibility in the mode of execution. The new study manager can execute all study; modules inlines, as was done in RooMCStudy), but also parallelized through PROOF (at present; only PROOF-lite is support, as well as in batch. The code fragment below illustrates the use of the new study manager. // Create workspace with p.d.f; RooWorkspace* ww = new RooWorkspace(""ww"") ;; ww->factory(""Gaussian::g(x[-10,10],mean[-10,10],sigma[3,0.1,10])"") ;. RooGenFitStudy gfs ;; gfs.setGenConfig(""g"",""x"",NumEvents(1000)) ;; gfs.setFitConfig(""g"",""x"",PrintLevel(-1)) ;. RooStudyManager mgr(*ww,gfs) ;. mgr.run(1000) ; // execute 1000 toys inline; mgr.runProof(10000,"""") ; // execute 10000 toys through PROOF-lite. gfs.summaryData()->Print() ;. Workspace and factory improvements. The workspace class RooWorkspace has been augmented with several; new features. The import() method now supports a new argument RenameAllVariablesExcept(const char* suffix, const char keepList) which; will rename all variables of the imported function by extended them with a supplied suffix,; except for a given list of variables, which are not renamed.; A new utility function importFromFile() has been added, which is similar to import, except that it take a string; specifier for the object to be imported rather than a reference. The string is expected to be of the form ; fileName:workspaceName:objectName and simplifies import of objects from other workspaces on file. The importFromFile; accepts all arguments accepted by the standard import() method.; Generic objects (inheriting from TObject) can now also be stored in the workspace under an alias name, rather; under their own name, which simplifies management of objects of types like TMatrixD that do not have a settable name. ws.import(matrix,""cov_matrix"") ;. New accessors have been added that return a RooArgSet of all elements of the workspace of a given type, e.g.; allVars(), allPdfs(). The Print() method now accepts option ""t"", which prints the c",MatchSource.DOCS,roofit/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:2593,Modifiability,inherit,inheriting,2593,"Proof(10000,"""") ; // execute 10000 toys through PROOF-lite. gfs.summaryData()->Print() ;. Workspace and factory improvements. The workspace class RooWorkspace has been augmented with several; new features. The import() method now supports a new argument RenameAllVariablesExcept(const char* suffix, const char keepList) which; will rename all variables of the imported function by extended them with a supplied suffix,; except for a given list of variables, which are not renamed.; A new utility function importFromFile() has been added, which is similar to import, except that it take a string; specifier for the object to be imported rather than a reference. The string is expected to be of the form ; fileName:workspaceName:objectName and simplifies import of objects from other workspaces on file. The importFromFile; accepts all arguments accepted by the standard import() method.; Generic objects (inheriting from TObject) can now also be stored in the workspace under an alias name, rather; under their own name, which simplifies management of objects of types like TMatrixD that do not have a settable name. ws.import(matrix,""cov_matrix"") ;. New accessors have been added that return a RooArgSet of all elements of the workspace of a given type, e.g.; allVars(), allPdfs(). The Print() method now accepts option ""t"", which prints the contents tree-style instead of a flat list of components,; as illustrated below. *** Print() ***. p.d.f.s; -------; RooProdPdf::bkg[ ptBkgPdf * mllBkgPdf * effBkgPdf|pt ] = 0.267845; RooEfficiency::effBkgPdf[ cat=cut effFunc=effBkg ] = 0.76916; RooEfficiency::effSigPdf[ cat=cut effFunc=effSig ] = 0.899817; RooAddPdf::genmodel[ Nsig * sig + Nbkg * bkg ] = 0.502276; RooPolynomial::mllBkgPdf[ x=mll coefList=(mbkg_slope) ] = 0.775; RooGaussian::mllSigPdf[ x=mll mean=msig_mean sigma=msig_sigma ] = 1; RooExponential::ptBkgPdf[ x=pt c=pbkg_slope ] = 0.449329; RooExponential::ptSigPdf[ x=pt c=psig_slope ] = 0.818731; RooProdPdf::sig[ ptSigPdf * mllSigPdf * e",MatchSource.DOCS,roofit/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:7373,Modifiability,variab,variable,7373,"nsional input pdfs. One of the appealing features; is that no expensive calculations are required to calculate in the interpolated pdfs shapes after the pdf; initialization. An extension that allows morphing in two parameters is foreseen for the next root release.; Progress indication in plot projections; The RooAbsReal::plotOn() now accepts a new argument ShowProgress() that will print a dot for every; function evaluation performed in the process of creating the plot. This can be useful when plotting very expensive; functions such as profile likelihoods; Automatic handling of constraint terms; It is no longer necessary to add a Constrain() argument to fitTo() calls to have internal constraints; applied. Any pdf term appearing in a product that does not contain an observable and shares one or more parameters; with another pdf term in the same product that does contain an observable is automatically picked up as a constraint term.; For example given a dataset D(x) which defines variable x as observable, the default logic works out as follows. F(x,a,b)*G(a,a0,a1) --> G is constraint term (a also appears in F(x)); F(x,a,b)*G(y,c,d) --> G is dropped (factorizing term). A Constrain(y) term in the above example will still force term G(y,c,d) to be interpreted as constraint term; Automatic caching of numeric integral calculations; Integrals that require numeric integrations in two of more dimensions are now automatically cached in the expensive object store.; The expensive object store allows to cache such values between difference instance of integral objects that represent the; same configuration. If integrals are created from an object (function or pdf) that live in a RooWorkspace the ; expensive object cache of the workspace will be used instead of the global store instance, and values stored in the workspace; store will also be persisted if the workspace is persisted. The global caching behavior of integral objects can be ; controlled through RooRealIntegral::setCache",MatchSource.DOCS,roofit/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:7986,Modifiability,config,configuration,7986,"e likelihoods; Automatic handling of constraint terms; It is no longer necessary to add a Constrain() argument to fitTo() calls to have internal constraints; applied. Any pdf term appearing in a product that does not contain an observable and shares one or more parameters; with another pdf term in the same product that does contain an observable is automatically picked up as a constraint term.; For example given a dataset D(x) which defines variable x as observable, the default logic works out as follows. F(x,a,b)*G(a,a0,a1) --> G is constraint term (a also appears in F(x)); F(x,a,b)*G(y,c,d) --> G is dropped (factorizing term). A Constrain(y) term in the above example will still force term G(y,c,d) to be interpreted as constraint term; Automatic caching of numeric integral calculations; Integrals that require numeric integrations in two of more dimensions are now automatically cached in the expensive object store.; The expensive object store allows to cache such values between difference instance of integral objects that represent the; same configuration. If integrals are created from an object (function or pdf) that live in a RooWorkspace the ; expensive object cache of the workspace will be used instead of the global store instance, and values stored in the workspace; store will also be persisted if the workspace is persisted. The global caching behavior of integral objects can be ; controlled through RooRealIntegral::setCacheAllNumeric(Int_t nDimNumMin). Miscellaneous improvements data classes. The RooAbsData::tree() method has been restored. It will only return a TTree* pointer for datasets; that are based on a RooTreeDataStore implementation, i.e. not for the composite datasets mentioned below; A new composite data storage class RooCompositeDataStore has been added that allows to construct composite; RooDataSet objects without copying the input data. . // Make 2 input datasets and an index category; RooWorkspace w(""w"",true) ;; w->factory(""Gaussian::g(x[-10,10]",MatchSource.DOCS,roofit/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:9935,Modifiability,variab,variable,9935,") ;; w->factory(""Gaussian::g(x[-10,10],m[-10,10],s[3,0.1,10])""); w->factory(""Uniform::u(x)""); w->factory(""index[S,B]""); RooDataSet* d1 = w::g.generate(w::x,1000); RooDataSet* d2 = w::u.generate(w::x,1000). // Make monolithic composite dataset (copies input data); RooDataSet d12(""d12"",""d12"",w::x,Index(w::index),Import(""S"",*d1),Import(""B"",*d2)). //-----------------------------------------------------------------------------; // NEW: make virtual composite dataset (input data is linked, no data is copied); RooDataSet d12a(""d12a"",""d12a"",w::x,Index(w::index),Link(""S"",*d1),Link(""B"",*d2)); //-----------------------------------------------------------------------------. // Fit composite dataset to dummy model; w->factory(""SUM::model(fsig[0,1]*g,u)""); w::model.fitTo(d12a). For virtual composite dataset it is also possible to join a mix of binned and unbinned datasets; (representation as a RooDataSet with weights). The setWeightVar() method has been deprecated as it is very difficult to support on-the-fly redefinition; of the event weight variable in the new data store scheme. To declare a data set weighed,; use the WeightVar() modifier of the constructor instead,e.g.:. RooDataSet wdata(""wdata"",""wdata"",RooArgSet(x,y,wgt),WeightVar(wgt)) ;. The RooHist class that represents data as a histogram in a RooPlot has been modified; so that it can show approximate Poisson errors for non-integer data. These approximate; errors are calculated from interpolation of the error bars of the nearest integers. NB: A weighted dataset; plotted with RooAbsData::plotOn() will be default show sum-of-weights-squared errors. Only; when Poisson error are forced through a DataError(RooAbsData::Poisson) argument these; approximate Poisson error bars are shown. Miscellaneous improvements other. The RooFit messagee service class RooMsgService has been augmented with a stack that; can store its configurate state information. A call to saveState() will save the; present configuration, which can be restored t",MatchSource.DOCS,roofit/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:10777,Modifiability,config,configurate,10777,"d unbinned datasets; (representation as a RooDataSet with weights). The setWeightVar() method has been deprecated as it is very difficult to support on-the-fly redefinition; of the event weight variable in the new data store scheme. To declare a data set weighed,; use the WeightVar() modifier of the constructor instead,e.g.:. RooDataSet wdata(""wdata"",""wdata"",RooArgSet(x,y,wgt),WeightVar(wgt)) ;. The RooHist class that represents data as a histogram in a RooPlot has been modified; so that it can show approximate Poisson errors for non-integer data. These approximate; errors are calculated from interpolation of the error bars of the nearest integers. NB: A weighted dataset; plotted with RooAbsData::plotOn() will be default show sum-of-weights-squared errors. Only; when Poisson error are forced through a DataError(RooAbsData::Poisson) argument these; approximate Poisson error bars are shown. Miscellaneous improvements other. The RooFit messagee service class RooMsgService has been augmented with a stack that; can store its configurate state information. A call to saveState() will save the; present configuration, which can be restored through a subsequent call to restoreState().; In addition to the method RooAbsArg::printCompactTree() which is mostly intende for; debugging, a new method RooAbsArg::printComponentTree() has been added that prints; the tree structure of a pdf in a more user-friendly content oriented way. The printing ; of the leaf nodes (the variables) is omitted in this method to keep the output compact. RooStats. This release contains significant bug fixes and it is strongly; recommended to update to this version if using older ones. . Major Changes in LimitCalculator and HypoTestCalculator classes: usage of ModelConfig class. The RooStats calculator interfaces have been changed to use the ModelConfig class.; All the setter methods with the parameter lists, pdf instances and name have been removed from the interfaces.; The SetWorkspace(RooWorkspace & ) ha",MatchSource.DOCS,roofit/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:10853,Modifiability,config,configuration,10853,"ifficult to support on-the-fly redefinition; of the event weight variable in the new data store scheme. To declare a data set weighed,; use the WeightVar() modifier of the constructor instead,e.g.:. RooDataSet wdata(""wdata"",""wdata"",RooArgSet(x,y,wgt),WeightVar(wgt)) ;. The RooHist class that represents data as a histogram in a RooPlot has been modified; so that it can show approximate Poisson errors for non-integer data. These approximate; errors are calculated from interpolation of the error bars of the nearest integers. NB: A weighted dataset; plotted with RooAbsData::plotOn() will be default show sum-of-weights-squared errors. Only; when Poisson error are forced through a DataError(RooAbsData::Poisson) argument these; approximate Poisson error bars are shown. Miscellaneous improvements other. The RooFit messagee service class RooMsgService has been augmented with a stack that; can store its configurate state information. A call to saveState() will save the; present configuration, which can be restored through a subsequent call to restoreState().; In addition to the method RooAbsArg::printCompactTree() which is mostly intende for; debugging, a new method RooAbsArg::printComponentTree() has been added that prints; the tree structure of a pdf in a more user-friendly content oriented way. The printing ; of the leaf nodes (the variables) is omitted in this method to keep the output compact. RooStats. This release contains significant bug fixes and it is strongly; recommended to update to this version if using older ones. . Major Changes in LimitCalculator and HypoTestCalculator classes: usage of ModelConfig class. The RooStats calculator interfaces have been changed to use the ModelConfig class.; All the setter methods with the parameter lists, pdf instances and name have been removed from the interfaces.; The SetWorkspace(RooWorkspace & ) has also been removed, while a SetModel(const ModelConfig &); function is introduced. Users are supposed to pass all the model info",MatchSource.DOCS,roofit/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:11217,Modifiability,variab,variables,11217,"that it can show approximate Poisson errors for non-integer data. These approximate; errors are calculated from interpolation of the error bars of the nearest integers. NB: A weighted dataset; plotted with RooAbsData::plotOn() will be default show sum-of-weights-squared errors. Only; when Poisson error are forced through a DataError(RooAbsData::Poisson) argument these; approximate Poisson error bars are shown. Miscellaneous improvements other. The RooFit messagee service class RooMsgService has been augmented with a stack that; can store its configurate state information. A call to saveState() will save the; present configuration, which can be restored through a subsequent call to restoreState().; In addition to the method RooAbsArg::printCompactTree() which is mostly intende for; debugging, a new method RooAbsArg::printComponentTree() has been added that prints; the tree structure of a pdf in a more user-friendly content oriented way. The printing ; of the leaf nodes (the variables) is omitted in this method to keep the output compact. RooStats. This release contains significant bug fixes and it is strongly; recommended to update to this version if using older ones. . Major Changes in LimitCalculator and HypoTestCalculator classes: usage of ModelConfig class. The RooStats calculator interfaces have been changed to use the ModelConfig class.; All the setter methods with the parameter lists, pdf instances and name have been removed from the interfaces.; The SetWorkspace(RooWorkspace & ) has also been removed, while a SetModel(const ModelConfig &); function is introduced. Users are supposed to pass all the model information using the; ModelConfig class rather than via the; RooWorkspace or specifying directly the pdf and parameter; objects in the constructors. ; Setter methods using pdf instances and parameter lists are maintained in the derived classes, like the ProfileLikelihoodCalculator or the HybridCalculator, but those passing a string for the name of the pdf have",MatchSource.DOCS,roofit/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:17770,Modifiability,inherit,inherited,17770,"; A new tutorial rs801_HypoTestInverter.C has been added in the tutorials/roostats directory to show the usage of this class. New class BayesianCalculator. New class for calculating Bayesian interval using numerical integration. It implements the IntervalCalculator interface and returns as result a SimpleInterval. . The BayesianCalculator::GetInterval() method returns a SimpleInterval which contains the lower and upper value of the bayesian interval obtained from the posterior probability for the given confidence level.; The class return also the posterior pdf (BayesianCalculator::GetPosteriorPdf()) obtained from integrating (marginalizing) on the nuisance parameters.; It works currently only for one-dimensional problems by relying on RooFit for performing analytical or numerical integration.; A plot of the posterior and the desired interval can be obtained using BayesianCalculator::GetPosteriorPlot().; A new tutorial rs701_BayesianCalculator.C has been added in the tutorials/roostats directory to show the usage of this class. MCMCCalculator. Add possibility to specify the prior function in the constructor of the class to have a signature similar to the BayesianCalculator class. When no prior is specified it is assumed is part of the global model (pdf) passed to the class. Improvements and Bug fixes. Various improvements and fixes have been applied also to all the calculator classes. Internally now the RooArgSet objects are used by value instead of a pointer.; All the calculator have a consistent way for being constructed, either by passing pdf pointers and the set defining the parameters or by passing a reference to a ModelConfig class.; The result classes are now more consistent and have similar constructors. In addition to a default constructor, all of them can be constructed by passing first a name and then all the quantities (objects or values) needed for the specific result type. The title can eventually be set using the SetTitle method inherited from TNamed. ",MatchSource.DOCS,roofit/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:6808,Performance,perform,performed,6808,"0],s[3])"") ;; w.factory(""Chebychev::g(x[-10,10],{0,1,2})"") ; // Now OK, x has identical spec, existing x will be used. Improvements to functions and pdfs. Addition to, reorganization of morphing operator classes. The existing class RooLinearMorph which; implements 'Alex Read' morphing has been renamed RooIntegralMorph. A new class RooMomentMorph; has been added (contribution from Max Baak and Stefan Gadatsch) that implements a different morphing algorithm ; based on shifting the mean and variance of the input pdfs. The new moment morphing class can also interpolate ; between multiple input templates and works with multi-dimensional input pdfs. One of the appealing features; is that no expensive calculations are required to calculate in the interpolated pdfs shapes after the pdf; initialization. An extension that allows morphing in two parameters is foreseen for the next root release.; Progress indication in plot projections; The RooAbsReal::plotOn() now accepts a new argument ShowProgress() that will print a dot for every; function evaluation performed in the process of creating the plot. This can be useful when plotting very expensive; functions such as profile likelihoods; Automatic handling of constraint terms; It is no longer necessary to add a Constrain() argument to fitTo() calls to have internal constraints; applied. Any pdf term appearing in a product that does not contain an observable and shares one or more parameters; with another pdf term in the same product that does contain an observable is automatically picked up as a constraint term.; For example given a dataset D(x) which defines variable x as observable, the default logic works out as follows. F(x,a,b)*G(a,a0,a1) --> G is constraint term (a also appears in F(x)); F(x,a,b)*G(y,c,d) --> G is dropped (factorizing term). A Constrain(y) term in the above example will still force term G(y,c,d) to be interpreted as constraint term; Automatic caching of numeric integral calculations; Integrals that require ",MatchSource.DOCS,roofit/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:7819,Performance,cache,cached,7819,"() now accepts a new argument ShowProgress() that will print a dot for every; function evaluation performed in the process of creating the plot. This can be useful when plotting very expensive; functions such as profile likelihoods; Automatic handling of constraint terms; It is no longer necessary to add a Constrain() argument to fitTo() calls to have internal constraints; applied. Any pdf term appearing in a product that does not contain an observable and shares one or more parameters; with another pdf term in the same product that does contain an observable is automatically picked up as a constraint term.; For example given a dataset D(x) which defines variable x as observable, the default logic works out as follows. F(x,a,b)*G(a,a0,a1) --> G is constraint term (a also appears in F(x)); F(x,a,b)*G(y,c,d) --> G is dropped (factorizing term). A Constrain(y) term in the above example will still force term G(y,c,d) to be interpreted as constraint term; Automatic caching of numeric integral calculations; Integrals that require numeric integrations in two of more dimensions are now automatically cached in the expensive object store.; The expensive object store allows to cache such values between difference instance of integral objects that represent the; same configuration. If integrals are created from an object (function or pdf) that live in a RooWorkspace the ; expensive object cache of the workspace will be used instead of the global store instance, and values stored in the workspace; store will also be persisted if the workspace is persisted. The global caching behavior of integral objects can be ; controlled through RooRealIntegral::setCacheAllNumeric(Int_t nDimNumMin). Miscellaneous improvements data classes. The RooAbsData::tree() method has been restored. It will only return a TTree* pointer for datasets; that are based on a RooTreeDataStore implementation, i.e. not for the composite datasets mentioned below; A new composite data storage class RooCompositeDataS",MatchSource.DOCS,roofit/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:7895,Performance,cache,cache,7895,"e likelihoods; Automatic handling of constraint terms; It is no longer necessary to add a Constrain() argument to fitTo() calls to have internal constraints; applied. Any pdf term appearing in a product that does not contain an observable and shares one or more parameters; with another pdf term in the same product that does contain an observable is automatically picked up as a constraint term.; For example given a dataset D(x) which defines variable x as observable, the default logic works out as follows. F(x,a,b)*G(a,a0,a1) --> G is constraint term (a also appears in F(x)); F(x,a,b)*G(y,c,d) --> G is dropped (factorizing term). A Constrain(y) term in the above example will still force term G(y,c,d) to be interpreted as constraint term; Automatic caching of numeric integral calculations; Integrals that require numeric integrations in two of more dimensions are now automatically cached in the expensive object store.; The expensive object store allows to cache such values between difference instance of integral objects that represent the; same configuration. If integrals are created from an object (function or pdf) that live in a RooWorkspace the ; expensive object cache of the workspace will be used instead of the global store instance, and values stored in the workspace; store will also be persisted if the workspace is persisted. The global caching behavior of integral objects can be ; controlled through RooRealIntegral::setCacheAllNumeric(Int_t nDimNumMin). Miscellaneous improvements data classes. The RooAbsData::tree() method has been restored. It will only return a TTree* pointer for datasets; that are based on a RooTreeDataStore implementation, i.e. not for the composite datasets mentioned below; A new composite data storage class RooCompositeDataStore has been added that allows to construct composite; RooDataSet objects without copying the input data. . // Make 2 input datasets and an index category; RooWorkspace w(""w"",true) ;; w->factory(""Gaussian::g(x[-10,10]",MatchSource.DOCS,roofit/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:8110,Performance,cache,cache,8110,"s not contain an observable and shares one or more parameters; with another pdf term in the same product that does contain an observable is automatically picked up as a constraint term.; For example given a dataset D(x) which defines variable x as observable, the default logic works out as follows. F(x,a,b)*G(a,a0,a1) --> G is constraint term (a also appears in F(x)); F(x,a,b)*G(y,c,d) --> G is dropped (factorizing term). A Constrain(y) term in the above example will still force term G(y,c,d) to be interpreted as constraint term; Automatic caching of numeric integral calculations; Integrals that require numeric integrations in two of more dimensions are now automatically cached in the expensive object store.; The expensive object store allows to cache such values between difference instance of integral objects that represent the; same configuration. If integrals are created from an object (function or pdf) that live in a RooWorkspace the ; expensive object cache of the workspace will be used instead of the global store instance, and values stored in the workspace; store will also be persisted if the workspace is persisted. The global caching behavior of integral objects can be ; controlled through RooRealIntegral::setCacheAllNumeric(Int_t nDimNumMin). Miscellaneous improvements data classes. The RooAbsData::tree() method has been restored. It will only return a TTree* pointer for datasets; that are based on a RooTreeDataStore implementation, i.e. not for the composite datasets mentioned below; A new composite data storage class RooCompositeDataStore has been added that allows to construct composite; RooDataSet objects without copying the input data. . // Make 2 input datasets and an index category; RooWorkspace w(""w"",true) ;; w->factory(""Gaussian::g(x[-10,10],m[-10,10],s[3,0.1,10])""); w->factory(""Uniform::u(x)""); w->factory(""index[S,B]""); RooDataSet* d1 = w::g.generate(w::x,1000); RooDataSet* d2 = w::u.generate(w::x,1000). // Make monolithic composite dataset (copies",MatchSource.DOCS,roofit/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:12683,Performance,load,load,12683,"ve been removed from the interfaces.; The SetWorkspace(RooWorkspace & ) has also been removed, while a SetModel(const ModelConfig &); function is introduced. Users are supposed to pass all the model information using the; ModelConfig class rather than via the; RooWorkspace or specifying directly the pdf and parameter; objects in the constructors. ; Setter methods using pdf instances and parameter lists are maintained in the derived classes, like the ProfileLikelihoodCalculator or the HybridCalculator, but those passing a string for the name of the pdf have been removed. ; All the calculator classes do not keep anymore a pointer to the workspace, but they contain pointers to the pdf, the data and the parameters required to run the calculator. These pointers are managed outside by the users or by the RooWorkspace. They can be passed either directly to the classes, for example via the constructor, or by using the ModelConfig class. The ModelConfig class acts as an interface to the Workspace in order to load and store all the; needed information. . ProfileLikelihoodCalculator, LikelihoodInterval. The Minos algorithm of Minuit is used now to find the limit of the likelihood intervals instead of searching directly the roots of the RooProfileLL class. Minos is used via the ROOT::Math::Minimizer interface. By default TMinuit is used, one can also use Minuit2 by doing ROOT::Math::MinimizerOptions::SetDefaultMinimizer(""Minuit2"").; The LikelihoodInterval class now provides now two new methods, FindLimits which finds both the upper and lower interval bounds, and GetContourPoints to find the 2D contour points defining the likelihood interval. GetContourPoints is now used by the LikelihoodIntervalPlot class to draw the 2D contour.; ; New tutorials have been added: rs501_ProfileLikelihoodCalculator_limit.C and rs502_ProfileLikelihoodCalculator_significance.C for getting the interval limits and significance using the ProfileLikelihoodCalculator. The tutorials can be run on a set of",MatchSource.DOCS,roofit/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:14574,Performance,perform,performing,14574,"ls can be run on a set of Poisson data or Gaussian over flat with model considering optionally the nuisance parameters. The data can be generated with the rs500 tutorials. HybridCalculator. In the constructor the signature passing a name and a title string has been removed, for being consistent with all the other calculator classes. Name and title can be set optionally using the SetName and SetTitle methods. Please note that this change is not backward compatible.; Add the option to use binned generation (via SetGenerateBinned).; An estimated of the error in the obtained p values is now computed in the HybridResult class thanks to Matthias Wolf. The errors can be obtained with HybridResult::CLbError(), HybridResult::CLsplusbError() or HybridResult::CLsError().; A new tutorial has been added for showing the usage of the hybrid calculator: rs505_HybridCalculator_significance.C. new class HypoTestInverter. New class for performing an hypothesis test inversion by scanning; the hypothesis test results of the HybridCalculator for; various values of the parameter of interest. An upper (or lower) limit can be derived by looking at the; confidence level curve of the result as function of the parameter of; interest, where it intersects the desired confidence level. The class implements the IntervalCalculator interface and returns an HypoTestInverterResult class. The result is a SimpleInterval, which via the method UpperLimit returns to the user the upper limit value. The HypoTestInverter implements various option for performing the scan. HypoTestInverter::RunFixedScan will scan using a fixed grid the parameter of interest. HypoTestInverter::RunAutoScan will perform an automatic scan to find optimally the curve and it will stop when the desired precision is obtained.; The confidence level value at a given point can also be done via HypoTestInverter::RunOnePoint.; The class can scan the CLs+b values (default) or alternatively CLs (if the; method HypoTestInverter::UseCLs has been",MatchSource.DOCS,roofit/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:15176,Performance,perform,performing,15176,"tGenerateBinned).; An estimated of the error in the obtained p values is now computed in the HybridResult class thanks to Matthias Wolf. The errors can be obtained with HybridResult::CLbError(), HybridResult::CLsplusbError() or HybridResult::CLsError().; A new tutorial has been added for showing the usage of the hybrid calculator: rs505_HybridCalculator_significance.C. new class HypoTestInverter. New class for performing an hypothesis test inversion by scanning; the hypothesis test results of the HybridCalculator for; various values of the parameter of interest. An upper (or lower) limit can be derived by looking at the; confidence level curve of the result as function of the parameter of; interest, where it intersects the desired confidence level. The class implements the IntervalCalculator interface and returns an HypoTestInverterResult class. The result is a SimpleInterval, which via the method UpperLimit returns to the user the upper limit value. The HypoTestInverter implements various option for performing the scan. HypoTestInverter::RunFixedScan will scan using a fixed grid the parameter of interest. HypoTestInverter::RunAutoScan will perform an automatic scan to find optimally the curve and it will stop when the desired precision is obtained.; The confidence level value at a given point can also be done via HypoTestInverter::RunOnePoint.; The class can scan the CLs+b values (default) or alternatively CLs (if the; method HypoTestInverter::UseCLs has been called).; The estimated error due to the MC toys statistics from the HybridCalculator is propagated into the limits obtained from the HypoTestResult; A new tutorial rs801_HypoTestInverter.C has been added in the tutorials/roostats directory to show the usage of this class. New class BayesianCalculator. New class for calculating Bayesian interval using numerical integration. It implements the IntervalCalculator interface and returns as result a SimpleInterval. . The BayesianCalculator::GetInterval() method retu",MatchSource.DOCS,roofit/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:15319,Performance,perform,perform,15319,"ybridResult::CLsplusbError() or HybridResult::CLsError().; A new tutorial has been added for showing the usage of the hybrid calculator: rs505_HybridCalculator_significance.C. new class HypoTestInverter. New class for performing an hypothesis test inversion by scanning; the hypothesis test results of the HybridCalculator for; various values of the parameter of interest. An upper (or lower) limit can be derived by looking at the; confidence level curve of the result as function of the parameter of; interest, where it intersects the desired confidence level. The class implements the IntervalCalculator interface and returns an HypoTestInverterResult class. The result is a SimpleInterval, which via the method UpperLimit returns to the user the upper limit value. The HypoTestInverter implements various option for performing the scan. HypoTestInverter::RunFixedScan will scan using a fixed grid the parameter of interest. HypoTestInverter::RunAutoScan will perform an automatic scan to find optimally the curve and it will stop when the desired precision is obtained.; The confidence level value at a given point can also be done via HypoTestInverter::RunOnePoint.; The class can scan the CLs+b values (default) or alternatively CLs (if the; method HypoTestInverter::UseCLs has been called).; The estimated error due to the MC toys statistics from the HybridCalculator is propagated into the limits obtained from the HypoTestResult; A new tutorial rs801_HypoTestInverter.C has been added in the tutorials/roostats directory to show the usage of this class. New class BayesianCalculator. New class for calculating Bayesian interval using numerical integration. It implements the IntervalCalculator interface and returns as result a SimpleInterval. . The BayesianCalculator::GetInterval() method returns a SimpleInterval which contains the lower and upper value of the bayesian interval obtained from the posterior probability for the given confidence level.; The class return also the posterior ",MatchSource.DOCS,roofit/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:16549,Performance,perform,performing,16549,"class can scan the CLs+b values (default) or alternatively CLs (if the; method HypoTestInverter::UseCLs has been called).; The estimated error due to the MC toys statistics from the HybridCalculator is propagated into the limits obtained from the HypoTestResult; A new tutorial rs801_HypoTestInverter.C has been added in the tutorials/roostats directory to show the usage of this class. New class BayesianCalculator. New class for calculating Bayesian interval using numerical integration. It implements the IntervalCalculator interface and returns as result a SimpleInterval. . The BayesianCalculator::GetInterval() method returns a SimpleInterval which contains the lower and upper value of the bayesian interval obtained from the posterior probability for the given confidence level.; The class return also the posterior pdf (BayesianCalculator::GetPosteriorPdf()) obtained from integrating (marginalizing) on the nuisance parameters.; It works currently only for one-dimensional problems by relying on RooFit for performing analytical or numerical integration.; A plot of the posterior and the desired interval can be obtained using BayesianCalculator::GetPosteriorPlot().; A new tutorial rs701_BayesianCalculator.C has been added in the tutorials/roostats directory to show the usage of this class. MCMCCalculator. Add possibility to specify the prior function in the constructor of the class to have a signature similar to the BayesianCalculator class. When no prior is specified it is assumed is part of the global model (pdf) passed to the class. Improvements and Bug fixes. Various improvements and fixes have been applied also to all the calculator classes. Internally now the RooArgSet objects are used by value instead of a pointer.; All the calculator have a consistent way for being constructed, either by passing pdf pointers and the set defining the parameters or by passing a reference to a ModelConfig class.; The result classes are now more consistent and have similar constructors.",MatchSource.DOCS,roofit/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:2843,Security,access,accessors,2843,"es. The import() method now supports a new argument RenameAllVariablesExcept(const char* suffix, const char keepList) which; will rename all variables of the imported function by extended them with a supplied suffix,; except for a given list of variables, which are not renamed.; A new utility function importFromFile() has been added, which is similar to import, except that it take a string; specifier for the object to be imported rather than a reference. The string is expected to be of the form ; fileName:workspaceName:objectName and simplifies import of objects from other workspaces on file. The importFromFile; accepts all arguments accepted by the standard import() method.; Generic objects (inheriting from TObject) can now also be stored in the workspace under an alias name, rather; under their own name, which simplifies management of objects of types like TMatrixD that do not have a settable name. ws.import(matrix,""cov_matrix"") ;. New accessors have been added that return a RooArgSet of all elements of the workspace of a given type, e.g.; allVars(), allPdfs(). The Print() method now accepts option ""t"", which prints the contents tree-style instead of a flat list of components,; as illustrated below. *** Print() ***. p.d.f.s; -------; RooProdPdf::bkg[ ptBkgPdf * mllBkgPdf * effBkgPdf|pt ] = 0.267845; RooEfficiency::effBkgPdf[ cat=cut effFunc=effBkg ] = 0.76916; RooEfficiency::effSigPdf[ cat=cut effFunc=effSig ] = 0.899817; RooAddPdf::genmodel[ Nsig * sig + Nbkg * bkg ] = 0.502276; RooPolynomial::mllBkgPdf[ x=mll coefList=(mbkg_slope) ] = 0.775; RooGaussian::mllSigPdf[ x=mll mean=msig_mean sigma=msig_sigma ] = 1; RooExponential::ptBkgPdf[ x=pt c=pbkg_slope ] = 0.449329; RooExponential::ptSigPdf[ x=pt c=psig_slope ] = 0.818731; RooProdPdf::sig[ ptSigPdf * mllSigPdf * effSigPdf|pt ] = 0.736708. functions; --------; RooFormulaVar::effBkg[ actualVars=(pt,ab,mb,sb) formula=""0.5*@1*(1+TMath::Erf((@0-@2)/@3))"" ] = 0.76916; RooFormulaVar::effSig[ actualVars=(pt,as,ms,ss) for",MatchSource.DOCS,roofit/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:4794,Security,access,access,4794,"f((@0-@2)/@3))"" ] = 0.76916; RooFormulaVar::effSig[ actualVars=(pt,as,ms,ss) formula=""0.5*@1*(1+TMath::Erf((@0-@2)/@3))"" ] = 0.899817. *** Print(""t"") ***. p.d.f.s; -------; RooAddPdf::genmodel[ Nsig * sig + Nbkg * bkg ] = 0.502276; RooProdPdf::sig[ ptSigPdf * mllSigPdf * effSigPdf|pt ] = 0.736708; RooExponential::ptSigPdf[ x=pt c=psig_slope ] = 0.818731; RooGaussian::mllSigPdf[ x=mll mean=msig_mean sigma=msig_sigma ] = 1; RooEfficiency::effSigPdf[ cat=cut effFunc=effSig ] = 0.899817; RooFormulaVar::effSig[ actualVars=(pt,as,ms,ss) formula=""0.5*@1*(1+TMath::Erf((@0-@2)/@3))"" ] = 0.899817; RooProdPdf::bkg[ ptBkgPdf * mllBkgPdf * effBkgPdf|pt ] = 0.267845; RooExponential::ptBkgPdf[ x=pt c=pbkg_slope ] = 0.449329; RooPolynomial::mllBkgPdf[ x=mll coefList=(mbkg_slope) ] = 0.775; RooEfficiency::effBkgPdf[ cat=cut effFunc=effBkg ] = 0.76916; RooFormulaVar::effBkg[ actualVars=(pt,ab,mb,sb) formula=""0.5*@1*(1+TMath::Erf((@0-@2)/@3))"" ] = 0.76916. The workspace factory can now access all objects in the generic object store of the workspace, e.g. TMatrixDSym* cov ; RooWorkspace w(""w"") ;; w.import(*cov,""cov"") ;; w.factory(""MultiVarGaussian::mvg({x[-10,10],y[-10,10]},{3,5},cov)"") ;. The workspace factory now correctly identifies and matches typedef-ed names in factory constructor; specifications.; All objects created by the factory and inserted by the workspace get a string attribute ""factory_tag"",; that contains the reduced factory string that was used to create that object, e.g. RooWorkspace w(""w"") ;; w.factory(""Gaussian::g(x[-10,10],m[0],s[3])"") ;; cout << w.pdf(""g"")->getStringAttribute(""factory_tag"") << endl ;; RooGaussian::g(x,m,s). Previously all factory orders that would create objects with names of objects that already existed always; resulted in an error. Now, this will only happen if the factory tag of the existing object is different; from the tag of the existing object. w.factory(""Gaussian::g(x[-10,10],m[0],s[3])"") ;; w.factory(""Chebychev::g(x[-10,10],{0,1,2})"") ; //",MatchSource.DOCS,roofit/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:658,Testability,log,logistics,658,". RooFit; New infrastructure for toy MC studies. A new class RooStudyManager has been added that is intended; to replace the present RooMCStudy framework for toy MC; studies on the time scale of ROOT release 5.26. The present RooMCStudy is a small monolithic driver to; execute 'generate-and-fit' style MC studies for a given pdf. It; provides some room for customization, through modules inheriting from; RooAbsMCStudyModule that can modify the standard behavior, but its; design limits the amount of flexibility.; In the new RooStudyManager design, the functionality of; RooMCStudy has been split into two classes: class; RooStudyManager which manages the logistics of running; repetitive studies and class RooGenFitStudy which implements; the functionality of the 'generate-and-fit'-style study of RooMCStudy.; The new design has two big advantages:. Complete freedom in the design of studies, either by tailoring the behavior of RooGenFitStudy or; by using another study module that inherits from RooAbsStudy, and the data that they return.; More flexibility in the mode of execution. The new study manager can execute all study; modules inlines, as was done in RooMCStudy), but also parallelized through PROOF (at present; only PROOF-lite is support, as well as in batch. The code fragment below illustrates the use of the new study manager. // Create workspace with p.d.f; RooWorkspace* ww = new RooWorkspace(""ww"") ;; ww->factory(""Gaussian::g(x[-10,10],mean[-10,10],sigma[3,0.1,10])"") ;. RooGenFitStudy gfs ;; gfs.setGenConfig(""g"",""x"",NumEvents(1000)) ;; gfs.setFitConfig(""g"",""x"",PrintLevel(-1)) ;. RooStudyManager mgr(*ww,gfs) ;. mgr.run(1000) ; // execute 1000 toys inline; mgr.runProof(10000,"""") ; // execute 10000 toys through PROOF-lite. gfs.summaryData()->Print() ;. Workspace and factory improvements. The workspace class RooWorkspace has been augmented with several; new features. The import() method now supports a new argument RenameAllVariablesExcept(const char* suffix, const char ke",MatchSource.DOCS,roofit/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:7411,Testability,log,logic,7411,"nsional input pdfs. One of the appealing features; is that no expensive calculations are required to calculate in the interpolated pdfs shapes after the pdf; initialization. An extension that allows morphing in two parameters is foreseen for the next root release.; Progress indication in plot projections; The RooAbsReal::plotOn() now accepts a new argument ShowProgress() that will print a dot for every; function evaluation performed in the process of creating the plot. This can be useful when plotting very expensive; functions such as profile likelihoods; Automatic handling of constraint terms; It is no longer necessary to add a Constrain() argument to fitTo() calls to have internal constraints; applied. Any pdf term appearing in a product that does not contain an observable and shares one or more parameters; with another pdf term in the same product that does contain an observable is automatically picked up as a constraint term.; For example given a dataset D(x) which defines variable x as observable, the default logic works out as follows. F(x,a,b)*G(a,a0,a1) --> G is constraint term (a also appears in F(x)); F(x,a,b)*G(y,c,d) --> G is dropped (factorizing term). A Constrain(y) term in the above example will still force term G(y,c,d) to be interpreted as constraint term; Automatic caching of numeric integral calculations; Integrals that require numeric integrations in two of more dimensions are now automatically cached in the expensive object store.; The expensive object store allows to cache such values between difference instance of integral objects that represent the; same configuration. If integrals are created from an object (function or pdf) that live in a RooWorkspace the ; expensive object cache of the workspace will be used instead of the global store instance, and values stored in the workspace; store will also be persisted if the workspace is persisted. The global caching behavior of integral objects can be ; controlled through RooRealIntegral::setCache",MatchSource.DOCS,roofit/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:14599,Testability,test,test,14599,"ls can be run on a set of Poisson data or Gaussian over flat with model considering optionally the nuisance parameters. The data can be generated with the rs500 tutorials. HybridCalculator. In the constructor the signature passing a name and a title string has been removed, for being consistent with all the other calculator classes. Name and title can be set optionally using the SetName and SetTitle methods. Please note that this change is not backward compatible.; Add the option to use binned generation (via SetGenerateBinned).; An estimated of the error in the obtained p values is now computed in the HybridResult class thanks to Matthias Wolf. The errors can be obtained with HybridResult::CLbError(), HybridResult::CLsplusbError() or HybridResult::CLsError().; A new tutorial has been added for showing the usage of the hybrid calculator: rs505_HybridCalculator_significance.C. new class HypoTestInverter. New class for performing an hypothesis test inversion by scanning; the hypothesis test results of the HybridCalculator for; various values of the parameter of interest. An upper (or lower) limit can be derived by looking at the; confidence level curve of the result as function of the parameter of; interest, where it intersects the desired confidence level. The class implements the IntervalCalculator interface and returns an HypoTestInverterResult class. The result is a SimpleInterval, which via the method UpperLimit returns to the user the upper limit value. The HypoTestInverter implements various option for performing the scan. HypoTestInverter::RunFixedScan will scan using a fixed grid the parameter of interest. HypoTestInverter::RunAutoScan will perform an automatic scan to find optimally the curve and it will stop when the desired precision is obtained.; The confidence level value at a given point can also be done via HypoTestInverter::RunOnePoint.; The class can scan the CLs+b values (default) or alternatively CLs (if the; method HypoTestInverter::UseCLs has been",MatchSource.DOCS,roofit/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:14642,Testability,test,test,14642,"ls can be run on a set of Poisson data or Gaussian over flat with model considering optionally the nuisance parameters. The data can be generated with the rs500 tutorials. HybridCalculator. In the constructor the signature passing a name and a title string has been removed, for being consistent with all the other calculator classes. Name and title can be set optionally using the SetName and SetTitle methods. Please note that this change is not backward compatible.; Add the option to use binned generation (via SetGenerateBinned).; An estimated of the error in the obtained p values is now computed in the HybridResult class thanks to Matthias Wolf. The errors can be obtained with HybridResult::CLbError(), HybridResult::CLsplusbError() or HybridResult::CLsError().; A new tutorial has been added for showing the usage of the hybrid calculator: rs505_HybridCalculator_significance.C. new class HypoTestInverter. New class for performing an hypothesis test inversion by scanning; the hypothesis test results of the HybridCalculator for; various values of the parameter of interest. An upper (or lower) limit can be derived by looking at the; confidence level curve of the result as function of the parameter of; interest, where it intersects the desired confidence level. The class implements the IntervalCalculator interface and returns an HypoTestInverterResult class. The result is a SimpleInterval, which via the method UpperLimit returns to the user the upper limit value. The HypoTestInverter implements various option for performing the scan. HypoTestInverter::RunFixedScan will scan using a fixed grid the parameter of interest. HypoTestInverter::RunAutoScan will perform an automatic scan to find optimally the curve and it will stop when the desired precision is obtained.; The confidence level value at a given point can also be done via HypoTestInverter::RunOnePoint.; The class can scan the CLs+b values (default) or alternatively CLs (if the; method HypoTestInverter::UseCLs has been",MatchSource.DOCS,roofit/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:2431,Usability,simpl,simplifies,2431,") ;; ww->factory(""Gaussian::g(x[-10,10],mean[-10,10],sigma[3,0.1,10])"") ;. RooGenFitStudy gfs ;; gfs.setGenConfig(""g"",""x"",NumEvents(1000)) ;; gfs.setFitConfig(""g"",""x"",PrintLevel(-1)) ;. RooStudyManager mgr(*ww,gfs) ;. mgr.run(1000) ; // execute 1000 toys inline; mgr.runProof(10000,"""") ; // execute 10000 toys through PROOF-lite. gfs.summaryData()->Print() ;. Workspace and factory improvements. The workspace class RooWorkspace has been augmented with several; new features. The import() method now supports a new argument RenameAllVariablesExcept(const char* suffix, const char keepList) which; will rename all variables of the imported function by extended them with a supplied suffix,; except for a given list of variables, which are not renamed.; A new utility function importFromFile() has been added, which is similar to import, except that it take a string; specifier for the object to be imported rather than a reference. The string is expected to be of the form ; fileName:workspaceName:objectName and simplifies import of objects from other workspaces on file. The importFromFile; accepts all arguments accepted by the standard import() method.; Generic objects (inheriting from TObject) can now also be stored in the workspace under an alias name, rather; under their own name, which simplifies management of objects of types like TMatrixD that do not have a settable name. ws.import(matrix,""cov_matrix"") ;. New accessors have been added that return a RooArgSet of all elements of the workspace of a given type, e.g.; allVars(), allPdfs(). The Print() method now accepts option ""t"", which prints the contents tree-style instead of a flat list of components,; as illustrated below. *** Print() ***. p.d.f.s; -------; RooProdPdf::bkg[ ptBkgPdf * mllBkgPdf * effBkgPdf|pt ] = 0.267845; RooEfficiency::effBkgPdf[ cat=cut effFunc=effBkg ] = 0.76916; RooEfficiency::effSigPdf[ cat=cut effFunc=effSig ] = 0.899817; RooAddPdf::genmodel[ Nsig * sig + Nbkg * bkg ] = 0.502276; RooPolynomial::mllBkgP",MatchSource.DOCS,roofit/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:2715,Usability,simpl,simplifies,2715,"Proof(10000,"""") ; // execute 10000 toys through PROOF-lite. gfs.summaryData()->Print() ;. Workspace and factory improvements. The workspace class RooWorkspace has been augmented with several; new features. The import() method now supports a new argument RenameAllVariablesExcept(const char* suffix, const char keepList) which; will rename all variables of the imported function by extended them with a supplied suffix,; except for a given list of variables, which are not renamed.; A new utility function importFromFile() has been added, which is similar to import, except that it take a string; specifier for the object to be imported rather than a reference. The string is expected to be of the form ; fileName:workspaceName:objectName and simplifies import of objects from other workspaces on file. The importFromFile; accepts all arguments accepted by the standard import() method.; Generic objects (inheriting from TObject) can now also be stored in the workspace under an alias name, rather; under their own name, which simplifies management of objects of types like TMatrixD that do not have a settable name. ws.import(matrix,""cov_matrix"") ;. New accessors have been added that return a RooArgSet of all elements of the workspace of a given type, e.g.; allVars(), allPdfs(). The Print() method now accepts option ""t"", which prints the contents tree-style instead of a flat list of components,; as illustrated below. *** Print() ***. p.d.f.s; -------; RooProdPdf::bkg[ ptBkgPdf * mllBkgPdf * effBkgPdf|pt ] = 0.267845; RooEfficiency::effBkgPdf[ cat=cut effFunc=effBkg ] = 0.76916; RooEfficiency::effSigPdf[ cat=cut effFunc=effSig ] = 0.899817; RooAddPdf::genmodel[ Nsig * sig + Nbkg * bkg ] = 0.502276; RooPolynomial::mllBkgPdf[ x=mll coefList=(mbkg_slope) ] = 0.775; RooGaussian::mllSigPdf[ x=mll mean=msig_mean sigma=msig_sigma ] = 1; RooExponential::ptBkgPdf[ x=pt c=pbkg_slope ] = 0.449329; RooExponential::ptSigPdf[ x=pt c=psig_slope ] = 0.818731; RooProdPdf::sig[ ptSigPdf * mllSigPdf * e",MatchSource.DOCS,roofit/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html:11143,Usability,user-friendly,user-friendly,11143,"stead,e.g.:. RooDataSet wdata(""wdata"",""wdata"",RooArgSet(x,y,wgt),WeightVar(wgt)) ;. The RooHist class that represents data as a histogram in a RooPlot has been modified; so that it can show approximate Poisson errors for non-integer data. These approximate; errors are calculated from interpolation of the error bars of the nearest integers. NB: A weighted dataset; plotted with RooAbsData::plotOn() will be default show sum-of-weights-squared errors. Only; when Poisson error are forced through a DataError(RooAbsData::Poisson) argument these; approximate Poisson error bars are shown. Miscellaneous improvements other. The RooFit messagee service class RooMsgService has been augmented with a stack that; can store its configurate state information. A call to saveState() will save the; present configuration, which can be restored through a subsequent call to restoreState().; In addition to the method RooAbsArg::printCompactTree() which is mostly intende for; debugging, a new method RooAbsArg::printComponentTree() has been added that prints; the tree structure of a pdf in a more user-friendly content oriented way. The printing ; of the leaf nodes (the variables) is omitted in this method to keep the output compact. RooStats. This release contains significant bug fixes and it is strongly; recommended to update to this version if using older ones. . Major Changes in LimitCalculator and HypoTestCalculator classes: usage of ModelConfig class. The RooStats calculator interfaces have been changed to use the ModelConfig class.; All the setter methods with the parameter lists, pdf instances and name have been removed from the interfaces.; The SetWorkspace(RooWorkspace & ) has also been removed, while a SetModel(const ModelConfig &); function is introduced. Users are supposed to pass all the model information using the; ModelConfig class rather than via the; RooWorkspace or specifying directly the pdf and parameter; objects in the constructors. ; Setter methods using pdf instances an",MatchSource.DOCS,roofit/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html:358,Availability,error,error,358,". RooFit. Assorted small bug fixes have been applied. No major new features have been introduced since 5.26; Normalization of RooRealSumPdf changed from sum of coefficients to sum of coefficients*integrals of input functions.; New PDF RooNonCentralChiSquare which is useful for asymptotic analysis of likelihood ratio tests -- like expected significance and error bands.; Ability to ""seal"" data in RooNLLVar, so that an experiment can publish likleihood functions without exposing the data necessary to evaluate the likelihood function. HistFactory. The ROOT release ships with a script prepareHistFactory and a binary hist2workspace in the $ROOTSYS/bin directories.; prepareHistFactory prepares a working area. It creates a results/, data/, and config/ directory. It also copies the HistFactorySchema.dtd and example XML files into the config/ directory. Additionally, it copies a root file into the data/ directory for use with the examples. Usage: hist2workspace input.xml; HistFactorySchema.dtd: This file is located in $ROOTSYS/etc/ specifies the XML schema. It is typically placed in the config/ direc-tory of a working area together with the top-level XML file and the individual channel XML files. The user should not modify this file. The HistFactorySchema.dtd is commented to specify exactly the meaning of the various options. Top-Level XML File. see for example $ROOTSYS/tutorials/histfactory/example.xml; This file is edited by the user. It specifies; ; A top level 'Combination' that is composed of:; 	; several 'Channels', which are described in separate XML files.; 	 several 'Measurements' (corresponding to a full fit of the model) each of which specifies; 	 ; a name for this measurement to be used in tables and files; what is the luminosity associated to the measurement in picobarns; which bins of the histogram should be used; what is the relative uncertainty on the luminosity; what is (are) the parameter(s) of interest that will be measured; which parameters should be fixed/",MatchSource.DOCS,roofit/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html:4234,Availability,failure,failure,4234,"s a reference to an; external workspace who manages all the objects being part of the model (pdf's and parameter sets). The user needs then to; set always a workspace pointer before setting the various objects.; . General Improvements. ModelConfig is now used extensively by the calculator tools. It encapsulates the configuration of a model to define a particular hypothesis.; ProfileLikelihood::GetInterval now returns LikleihoodInterval in the interface to avoid unnecessary casting; FeldmanCousins::GetInterval now returns PointSetInterval in the interface to avoid unnecessary casting. Profile Likelihood . When running ProfileLikelihoodCalculator::GetHypoTest; the user does not need anymore to clone the null parameter set. It; is done now inside the calculator; LikelihoodInterval::LowerLimit (and UpperLimit); returns now a boolean flag with the status of the limit search.; In case of a failure in finding the upper/lower limit a value of; zero is returned instead of the min/max of the variable range; LikelihoodIntervalPlot fix drawing of horizontal green; line when limits are outside the variable range . HybridCalculator. New re-written class based on the TestStatSampler and; TestStatistic interfaces. The new class is designed to provide; consistent use of a ModelConfig, specifying the Pdf and Prior. ; The old class remains, but with a new name: HybridCalculatorOriginal. ; The tutorial rs201b_hybridcalculator shows the usage of; the new class.; Note that the new class can be constructed only from a; ModelConfig; One can specify a TestStatSampler in the constructor (which implies a choice of a TestStatistic, or by default the tool will use the ToyMCSampler and the RatioOfProfiledLikelihoods; The interface of the new HybridCalculator class is now more uniform with the other calculator tools, which is different from the original; HybridCalculator's interface. Users wishing to run their old macro are advised to use ModelConfig, but if that is too time consuming one can jus",MatchSource.DOCS,roofit/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html:7052,Availability,robust,robustness,7052,"mented. In order to keep; logical consistency with other tools, the distribution being used; to smear the nuisance parameters should NOT be considered the prior in ; the model config. Instead, one should use HybridCalculator's; ForcePriorNuisanceNull and ForcePriorNuisanceAlt. HybridCalculatorOriginal. Apply a fix for test statistic = 3 (profile likelihood); Apply a fix for using non-extended pdf. TestStatSampler and TestStatistics. Cleanup of the interfaces.; TestStatistics now have a method PValueIsRightTail to specify the sign conventions for the test statistic. This is used when making plots and calculating p-values.; make clear that TestStatistic::Evaluate should take data and values of the parameters that define the null.; Add method TestStatSampler::SetParametersForTestStat that ; allows for greater control of parameters used for generating toy data; and parameters used for evaluating the test statistic.; ProfileLikelihoodTestStatUsing the raw profile likelihood while reviewing the old algorithm used to provide robustness in situations with local minima.; New test statistic classes:; ; SimpleLikelihoodRatioTestStat : log L_1 / L_0; RatioOfProfiledLikelihoodsTestStat: log L(mu_1, hat(nu_1))/L(mu_0,hat(nu_0)); MaxLikelihoodEstimateTestStat: the MLE of a specified parameter. ToyMCSampler. New version of ToyMCSampler which can smear the nuisance; parameters according to their distributions for use with; HybridCalculator; Updated class structure: ToyMCSampler is a particular implementation of a TestStatSampler and runs with any TestStatistic. It returns the result in an instance of SamplingDistribution.; Supports Importance Sampling: Improves sampling the tails of a distribution by generating toys from a user supplied importance density and a reweighing procedure of the result.; Supports Adaptive Sampling: extends the run until a given number of toys is reached in the tail(s).; Parallelization using PROOF(-Lite) is supported. It is enabled by supplying a ProofConfi",MatchSource.DOCS,roofit/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html:559,Deployability,release,release,559,". RooFit. Assorted small bug fixes have been applied. No major new features have been introduced since 5.26; Normalization of RooRealSumPdf changed from sum of coefficients to sum of coefficients*integrals of input functions.; New PDF RooNonCentralChiSquare which is useful for asymptotic analysis of likelihood ratio tests -- like expected significance and error bands.; Ability to ""seal"" data in RooNLLVar, so that an experiment can publish likleihood functions without exposing the data necessary to evaluate the likelihood function. HistFactory. The ROOT release ships with a script prepareHistFactory and a binary hist2workspace in the $ROOTSYS/bin directories.; prepareHistFactory prepares a working area. It creates a results/, data/, and config/ directory. It also copies the HistFactorySchema.dtd and example XML files into the config/ directory. Additionally, it copies a root file into the data/ directory for use with the examples. Usage: hist2workspace input.xml; HistFactorySchema.dtd: This file is located in $ROOTSYS/etc/ specifies the XML schema. It is typically placed in the config/ direc-tory of a working area together with the top-level XML file and the individual channel XML files. The user should not modify this file. The HistFactorySchema.dtd is commented to specify exactly the meaning of the various options. Top-Level XML File. see for example $ROOTSYS/tutorials/histfactory/example.xml; This file is edited by the user. It specifies; ; A top level 'Combination' that is composed of:; 	; several 'Channels', which are described in separate XML files.; 	 several 'Measurements' (corresponding to a full fit of the model) each of which specifies; 	 ; a name for this measurement to be used in tables and files; what is the luminosity associated to the measurement in picobarns; which bins of the histogram should be used; what is the relative uncertainty on the luminosity; what is (are) the parameter(s) of interest that will be measured; which parameters should be fixed/",MatchSource.DOCS,roofit/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html:3158,Deployability,configurat,configuration,3158,"ould export the model only and skip the default fit; 	 . Channel XML Files. see for example $ROOTSYS/tutorials/histfactory/example_channel.xml; This file is edited by the user. It specifies for each channel. observed data (if absent the tool will use the expectation, which is useful for expected sensitivity); several 'Samples' (eg. signal, bkg1, bkg2, ...), each of which has:; ; a name; if the sample is normalized by theory (eg N = L*sigma) or not (eg. data driven); a nominal expectation histogram; a named 'Normalization Factor' (which can be fixed or allowed to float in a fit); several 'Overall Systematics' in normalization with:; 	 ; a name; +/- 1 sigma variations (eg. 1.05 and 0.95 for a 5% uncertainty); 	 ; several 'Histogram Systematics' in shape with:; 	 ; a name (which can be shared with the OverallSyst if correlated); +/- 1 sigma variational histograms; 	 . RooStats; ModelConfig. This class is now used extensively by the calculator tools. It encapsulates the configuration of a model to define a particular hypothesis.; Various fixes by and improvements to make it usable with all; the existing calculator.; ModelConfig contains now always a reference to an; external workspace who manages all the objects being part of the model (pdf's and parameter sets). The user needs then to; set always a workspace pointer before setting the various objects.; . General Improvements. ModelConfig is now used extensively by the calculator tools. It encapsulates the configuration of a model to define a particular hypothesis.; ProfileLikelihood::GetInterval now returns LikleihoodInterval in the interface to avoid unnecessary casting; FeldmanCousins::GetInterval now returns PointSetInterval in the interface to avoid unnecessary casting. Profile Likelihood . When running ProfileLikelihoodCalculator::GetHypoTest; the user does not need anymore to clone the null parameter set. It; is done now inside the calculator; LikelihoodInterval::LowerLimit (and UpperLimit); returns now a boolean",MatchSource.DOCS,roofit/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html:3654,Deployability,configurat,configuration,3654,"togram; a named 'Normalization Factor' (which can be fixed or allowed to float in a fit); several 'Overall Systematics' in normalization with:; 	 ; a name; +/- 1 sigma variations (eg. 1.05 and 0.95 for a 5% uncertainty); 	 ; several 'Histogram Systematics' in shape with:; 	 ; a name (which can be shared with the OverallSyst if correlated); +/- 1 sigma variational histograms; 	 . RooStats; ModelConfig. This class is now used extensively by the calculator tools. It encapsulates the configuration of a model to define a particular hypothesis.; Various fixes by and improvements to make it usable with all; the existing calculator.; ModelConfig contains now always a reference to an; external workspace who manages all the objects being part of the model (pdf's and parameter sets). The user needs then to; set always a workspace pointer before setting the various objects.; . General Improvements. ModelConfig is now used extensively by the calculator tools. It encapsulates the configuration of a model to define a particular hypothesis.; ProfileLikelihood::GetInterval now returns LikleihoodInterval in the interface to avoid unnecessary casting; FeldmanCousins::GetInterval now returns PointSetInterval in the interface to avoid unnecessary casting. Profile Likelihood . When running ProfileLikelihoodCalculator::GetHypoTest; the user does not need anymore to clone the null parameter set. It; is done now inside the calculator; LikelihoodInterval::LowerLimit (and UpperLimit); returns now a boolean flag with the status of the limit search.; In case of a failure in finding the upper/lower limit a value of; zero is returned instead of the min/max of the variable range; LikelihoodIntervalPlot fix drawing of horizontal green; line when limits are outside the variable range . HybridCalculator. New re-written class based on the TestStatSampler and; TestStatistic interfaces. The new class is designed to provide; consistent use of a ModelConfig, specifying the Pdf and Prior. ; The old class r",MatchSource.DOCS,roofit/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html:5561,Deployability,release,release,5561,"tal green; line when limits are outside the variable range . HybridCalculator. New re-written class based on the TestStatSampler and; TestStatistic interfaces. The new class is designed to provide; consistent use of a ModelConfig, specifying the Pdf and Prior. ; The old class remains, but with a new name: HybridCalculatorOriginal. ; The tutorial rs201b_hybridcalculator shows the usage of; the new class.; Note that the new class can be constructed only from a; ModelConfig; One can specify a TestStatSampler in the constructor (which implies a choice of a TestStatistic, or by default the tool will use the ToyMCSampler and the RatioOfProfiledLikelihoods; The interface of the new HybridCalculator class is now more uniform with the other calculator tools, which is different from the original; HybridCalculator's interface. Users wishing to run their old macro are advised to use ModelConfig, but if that is too time consuming one can just change the; name of the class from HybridCalculator to; HybridCalculatorOriginal; Note also that with the new class no HybridResult is; returned but directly the base class HypoTestResult which; has been improved for this release.; The plot class, HybridPlot is not returned, but; the user can create an HypoTestPlot object from the; HypoTestResult.; The classes HybridResult and HybridPlot work only; with the HybridCalculatorOriginal and remain for maintaining; a backward compatibility. ; Given a ModelConfig, the tool will attempt to form the posterior pdf ; for the nuisance parameters based on the prior and the constraint terms ; in the pdf. However, this is not yet implemented. In order to keep; logical consistency with other tools, the distribution being used; to smear the nuisance parameters should NOT be considered the prior in ; the model config. Instead, one should use HybridCalculator's; ForcePriorNuisanceNull and ForcePriorNuisanceAlt. HybridCalculatorOriginal. Apply a fix for test statistic = 3 (profile likelihood); Apply a fix for u",MatchSource.DOCS,roofit/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html:8100,Deployability,integrat,integration,8100,"tatistic classes:; ; SimpleLikelihoodRatioTestStat : log L_1 / L_0; RatioOfProfiledLikelihoodsTestStat: log L(mu_1, hat(nu_1))/L(mu_0,hat(nu_0)); MaxLikelihoodEstimateTestStat: the MLE of a specified parameter. ToyMCSampler. New version of ToyMCSampler which can smear the nuisance; parameters according to their distributions for use with; HybridCalculator; Updated class structure: ToyMCSampler is a particular implementation of a TestStatSampler and runs with any TestStatistic. It returns the result in an instance of SamplingDistribution.; Supports Importance Sampling: Improves sampling the tails of a distribution by generating toys from a user supplied importance density and a reweighing procedure of the result.; Supports Adaptive Sampling: extends the run until a given number of toys is reached in the tail(s).; Parallelization using PROOF(-Lite) is supported. It is enabled by supplying a ProofConfig instance. BayesianCalculator. Improve the way the class performs the numerical integration to; find the interval and/or the posterior function.; In case of complex; numerical calculation add the method SetScanOfPosterior(nbins) for; scanning the posterior function in a givn number of nbins; Add possibility to compute lower/upper limits using the method; SetLeftSideTailFraction(fraction); Add possibility to compute shortest interval using; SetShortestInterval. MCMCCalculator. Various improvements including possibility to compute; lower/central/upper limits using; SetLeftSideTailFraction(fraction). New Tutorials. New Demos that take name for file, workspace, modelconfig, and data, then use the corresponding calculator tool. If the file is not specified it will read an file produced from running the HistFactory tutorial example. StandardProfileLikelihoodDemo.C: ; StandardFeldmanCousinsDemo.C: ; StandardBayesianMCMCDemo.C: ; StandardBayesianNumericalDemo.C: ; StandardProfileInspectorDemo.C: . Demonstrate some new PDFs. TestNonCentral.C: demonstrates non central chi-square; ",MatchSource.DOCS,roofit/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html:4399,Energy Efficiency,green,green,4399,"s a reference to an; external workspace who manages all the objects being part of the model (pdf's and parameter sets). The user needs then to; set always a workspace pointer before setting the various objects.; . General Improvements. ModelConfig is now used extensively by the calculator tools. It encapsulates the configuration of a model to define a particular hypothesis.; ProfileLikelihood::GetInterval now returns LikleihoodInterval in the interface to avoid unnecessary casting; FeldmanCousins::GetInterval now returns PointSetInterval in the interface to avoid unnecessary casting. Profile Likelihood . When running ProfileLikelihoodCalculator::GetHypoTest; the user does not need anymore to clone the null parameter set. It; is done now inside the calculator; LikelihoodInterval::LowerLimit (and UpperLimit); returns now a boolean flag with the status of the limit search.; In case of a failure in finding the upper/lower limit a value of; zero is returned instead of the min/max of the variable range; LikelihoodIntervalPlot fix drawing of horizontal green; line when limits are outside the variable range . HybridCalculator. New re-written class based on the TestStatSampler and; TestStatistic interfaces. The new class is designed to provide; consistent use of a ModelConfig, specifying the Pdf and Prior. ; The old class remains, but with a new name: HybridCalculatorOriginal. ; The tutorial rs201b_hybridcalculator shows the usage of; the new class.; Note that the new class can be constructed only from a; ModelConfig; One can specify a TestStatSampler in the constructor (which implies a choice of a TestStatistic, or by default the tool will use the ToyMCSampler and the RatioOfProfiledLikelihoods; The interface of the new HybridCalculator class is now more uniform with the other calculator tools, which is different from the original; HybridCalculator's interface. Users wishing to run their old macro are advised to use ModelConfig, but if that is too time consuming one can jus",MatchSource.DOCS,roofit/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html:3784,Integrability,interface,interface,3784," a name; +/- 1 sigma variations (eg. 1.05 and 0.95 for a 5% uncertainty); 	 ; several 'Histogram Systematics' in shape with:; 	 ; a name (which can be shared with the OverallSyst if correlated); +/- 1 sigma variational histograms; 	 . RooStats; ModelConfig. This class is now used extensively by the calculator tools. It encapsulates the configuration of a model to define a particular hypothesis.; Various fixes by and improvements to make it usable with all; the existing calculator.; ModelConfig contains now always a reference to an; external workspace who manages all the objects being part of the model (pdf's and parameter sets). The user needs then to; set always a workspace pointer before setting the various objects.; . General Improvements. ModelConfig is now used extensively by the calculator tools. It encapsulates the configuration of a model to define a particular hypothesis.; ProfileLikelihood::GetInterval now returns LikleihoodInterval in the interface to avoid unnecessary casting; FeldmanCousins::GetInterval now returns PointSetInterval in the interface to avoid unnecessary casting. Profile Likelihood . When running ProfileLikelihoodCalculator::GetHypoTest; the user does not need anymore to clone the null parameter set. It; is done now inside the calculator; LikelihoodInterval::LowerLimit (and UpperLimit); returns now a boolean flag with the status of the limit search.; In case of a failure in finding the upper/lower limit a value of; zero is returned instead of the min/max of the variable range; LikelihoodIntervalPlot fix drawing of horizontal green; line when limits are outside the variable range . HybridCalculator. New re-written class based on the TestStatSampler and; TestStatistic interfaces. The new class is designed to provide; consistent use of a ModelConfig, specifying the Pdf and Prior. ; The old class remains, but with a new name: HybridCalculatorOriginal. ; The tutorial rs201b_hybridcalculator shows the usage of; the new class.; Note that the new",MatchSource.DOCS,roofit/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html:3888,Integrability,interface,interface,3888," a name; +/- 1 sigma variations (eg. 1.05 and 0.95 for a 5% uncertainty); 	 ; several 'Histogram Systematics' in shape with:; 	 ; a name (which can be shared with the OverallSyst if correlated); +/- 1 sigma variational histograms; 	 . RooStats; ModelConfig. This class is now used extensively by the calculator tools. It encapsulates the configuration of a model to define a particular hypothesis.; Various fixes by and improvements to make it usable with all; the existing calculator.; ModelConfig contains now always a reference to an; external workspace who manages all the objects being part of the model (pdf's and parameter sets). The user needs then to; set always a workspace pointer before setting the various objects.; . General Improvements. ModelConfig is now used extensively by the calculator tools. It encapsulates the configuration of a model to define a particular hypothesis.; ProfileLikelihood::GetInterval now returns LikleihoodInterval in the interface to avoid unnecessary casting; FeldmanCousins::GetInterval now returns PointSetInterval in the interface to avoid unnecessary casting. Profile Likelihood . When running ProfileLikelihoodCalculator::GetHypoTest; the user does not need anymore to clone the null parameter set. It; is done now inside the calculator; LikelihoodInterval::LowerLimit (and UpperLimit); returns now a boolean flag with the status of the limit search.; In case of a failure in finding the upper/lower limit a value of; zero is returned instead of the min/max of the variable range; LikelihoodIntervalPlot fix drawing of horizontal green; line when limits are outside the variable range . HybridCalculator. New re-written class based on the TestStatSampler and; TestStatistic interfaces. The new class is designed to provide; consistent use of a ModelConfig, specifying the Pdf and Prior. ; The old class remains, but with a new name: HybridCalculatorOriginal. ; The tutorial rs201b_hybridcalculator shows the usage of; the new class.; Note that the new",MatchSource.DOCS,roofit/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html:4543,Integrability,interface,interfaces,4543,"efore setting the various objects.; . General Improvements. ModelConfig is now used extensively by the calculator tools. It encapsulates the configuration of a model to define a particular hypothesis.; ProfileLikelihood::GetInterval now returns LikleihoodInterval in the interface to avoid unnecessary casting; FeldmanCousins::GetInterval now returns PointSetInterval in the interface to avoid unnecessary casting. Profile Likelihood . When running ProfileLikelihoodCalculator::GetHypoTest; the user does not need anymore to clone the null parameter set. It; is done now inside the calculator; LikelihoodInterval::LowerLimit (and UpperLimit); returns now a boolean flag with the status of the limit search.; In case of a failure in finding the upper/lower limit a value of; zero is returned instead of the min/max of the variable range; LikelihoodIntervalPlot fix drawing of horizontal green; line when limits are outside the variable range . HybridCalculator. New re-written class based on the TestStatSampler and; TestStatistic interfaces. The new class is designed to provide; consistent use of a ModelConfig, specifying the Pdf and Prior. ; The old class remains, but with a new name: HybridCalculatorOriginal. ; The tutorial rs201b_hybridcalculator shows the usage of; the new class.; Note that the new class can be constructed only from a; ModelConfig; One can specify a TestStatSampler in the constructor (which implies a choice of a TestStatistic, or by default the tool will use the ToyMCSampler and the RatioOfProfiledLikelihoods; The interface of the new HybridCalculator class is now more uniform with the other calculator tools, which is different from the original; HybridCalculator's interface. Users wishing to run their old macro are advised to use ModelConfig, but if that is too time consuming one can just change the; name of the class from HybridCalculator to; HybridCalculatorOriginal; Note also that with the new class no HybridResult is; returned but directly the base class Hy",MatchSource.DOCS,roofit/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html:5058,Integrability,interface,interface,5058,"r does not need anymore to clone the null parameter set. It; is done now inside the calculator; LikelihoodInterval::LowerLimit (and UpperLimit); returns now a boolean flag with the status of the limit search.; In case of a failure in finding the upper/lower limit a value of; zero is returned instead of the min/max of the variable range; LikelihoodIntervalPlot fix drawing of horizontal green; line when limits are outside the variable range . HybridCalculator. New re-written class based on the TestStatSampler and; TestStatistic interfaces. The new class is designed to provide; consistent use of a ModelConfig, specifying the Pdf and Prior. ; The old class remains, but with a new name: HybridCalculatorOriginal. ; The tutorial rs201b_hybridcalculator shows the usage of; the new class.; Note that the new class can be constructed only from a; ModelConfig; One can specify a TestStatSampler in the constructor (which implies a choice of a TestStatistic, or by default the tool will use the ToyMCSampler and the RatioOfProfiledLikelihoods; The interface of the new HybridCalculator class is now more uniform with the other calculator tools, which is different from the original; HybridCalculator's interface. Users wishing to run their old macro are advised to use ModelConfig, but if that is too time consuming one can just change the; name of the class from HybridCalculator to; HybridCalculatorOriginal; Note also that with the new class no HybridResult is; returned but directly the base class HypoTestResult which; has been improved for this release.; The plot class, HybridPlot is not returned, but; the user can create an HypoTestPlot object from the; HypoTestResult.; The classes HybridResult and HybridPlot work only; with the HybridCalculatorOriginal and remain for maintaining; a backward compatibility. ; Given a ModelConfig, the tool will attempt to form the posterior pdf ; for the nuisance parameters based on the prior and the constraint terms ; in the pdf. However, this is not yet",MatchSource.DOCS,roofit/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html:5212,Integrability,interface,interface,5212,"r does not need anymore to clone the null parameter set. It; is done now inside the calculator; LikelihoodInterval::LowerLimit (and UpperLimit); returns now a boolean flag with the status of the limit search.; In case of a failure in finding the upper/lower limit a value of; zero is returned instead of the min/max of the variable range; LikelihoodIntervalPlot fix drawing of horizontal green; line when limits are outside the variable range . HybridCalculator. New re-written class based on the TestStatSampler and; TestStatistic interfaces. The new class is designed to provide; consistent use of a ModelConfig, specifying the Pdf and Prior. ; The old class remains, but with a new name: HybridCalculatorOriginal. ; The tutorial rs201b_hybridcalculator shows the usage of; the new class.; Note that the new class can be constructed only from a; ModelConfig; One can specify a TestStatSampler in the constructor (which implies a choice of a TestStatistic, or by default the tool will use the ToyMCSampler and the RatioOfProfiledLikelihoods; The interface of the new HybridCalculator class is now more uniform with the other calculator tools, which is different from the original; HybridCalculator's interface. Users wishing to run their old macro are advised to use ModelConfig, but if that is too time consuming one can just change the; name of the class from HybridCalculator to; HybridCalculatorOriginal; Note also that with the new class no HybridResult is; returned but directly the base class HypoTestResult which; has been improved for this release.; The plot class, HybridPlot is not returned, but; the user can create an HypoTestPlot object from the; HypoTestResult.; The classes HybridResult and HybridPlot work only; with the HybridCalculatorOriginal and remain for maintaining; a backward compatibility. ; Given a ModelConfig, the tool will attempt to form the posterior pdf ; for the nuisance parameters based on the prior and the constraint terms ; in the pdf. However, this is not yet",MatchSource.DOCS,roofit/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html:6470,Integrability,interface,interfaces,6470,"ult is; returned but directly the base class HypoTestResult which; has been improved for this release.; The plot class, HybridPlot is not returned, but; the user can create an HypoTestPlot object from the; HypoTestResult.; The classes HybridResult and HybridPlot work only; with the HybridCalculatorOriginal and remain for maintaining; a backward compatibility. ; Given a ModelConfig, the tool will attempt to form the posterior pdf ; for the nuisance parameters based on the prior and the constraint terms ; in the pdf. However, this is not yet implemented. In order to keep; logical consistency with other tools, the distribution being used; to smear the nuisance parameters should NOT be considered the prior in ; the model config. Instead, one should use HybridCalculator's; ForcePriorNuisanceNull and ForcePriorNuisanceAlt. HybridCalculatorOriginal. Apply a fix for test statistic = 3 (profile likelihood); Apply a fix for using non-extended pdf. TestStatSampler and TestStatistics. Cleanup of the interfaces.; TestStatistics now have a method PValueIsRightTail to specify the sign conventions for the test statistic. This is used when making plots and calculating p-values.; make clear that TestStatistic::Evaluate should take data and values of the parameters that define the null.; Add method TestStatSampler::SetParametersForTestStat that ; allows for greater control of parameters used for generating toy data; and parameters used for evaluating the test statistic.; ProfileLikelihoodTestStatUsing the raw profile likelihood while reviewing the old algorithm used to provide robustness in situations with local minima.; New test statistic classes:; ; SimpleLikelihoodRatioTestStat : log L_1 / L_0; RatioOfProfiledLikelihoodsTestStat: log L(mu_1, hat(nu_1))/L(mu_0,hat(nu_0)); MaxLikelihoodEstimateTestStat: the MLE of a specified parameter. ToyMCSampler. New version of ToyMCSampler which can smear the nuisance; parameters according to their distributions for use with; HybridCalculator; Up",MatchSource.DOCS,roofit/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html:8100,Integrability,integrat,integration,8100,"tatistic classes:; ; SimpleLikelihoodRatioTestStat : log L_1 / L_0; RatioOfProfiledLikelihoodsTestStat: log L(mu_1, hat(nu_1))/L(mu_0,hat(nu_0)); MaxLikelihoodEstimateTestStat: the MLE of a specified parameter. ToyMCSampler. New version of ToyMCSampler which can smear the nuisance; parameters according to their distributions for use with; HybridCalculator; Updated class structure: ToyMCSampler is a particular implementation of a TestStatSampler and runs with any TestStatistic. It returns the result in an instance of SamplingDistribution.; Supports Importance Sampling: Improves sampling the tails of a distribution by generating toys from a user supplied importance density and a reweighing procedure of the result.; Supports Adaptive Sampling: extends the run until a given number of toys is reached in the tail(s).; Parallelization using PROOF(-Lite) is supported. It is enabled by supplying a ProofConfig instance. BayesianCalculator. Improve the way the class performs the numerical integration to; find the interval and/or the posterior function.; In case of complex; numerical calculation add the method SetScanOfPosterior(nbins) for; scanning the posterior function in a givn number of nbins; Add possibility to compute lower/upper limits using the method; SetLeftSideTailFraction(fraction); Add possibility to compute shortest interval using; SetShortestInterval. MCMCCalculator. Various improvements including possibility to compute; lower/central/upper limits using; SetLeftSideTailFraction(fraction). New Tutorials. New Demos that take name for file, workspace, modelconfig, and data, then use the corresponding calculator tool. If the file is not specified it will read an file produced from running the HistFactory tutorial example. StandardProfileLikelihoodDemo.C: ; StandardFeldmanCousinsDemo.C: ; StandardBayesianMCMCDemo.C: ; StandardBayesianNumericalDemo.C: ; StandardProfileInspectorDemo.C: . Demonstrate some new PDFs. TestNonCentral.C: demonstrates non central chi-square; ",MatchSource.DOCS,roofit/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html:746,Modifiability,config,config,746,". RooFit. Assorted small bug fixes have been applied. No major new features have been introduced since 5.26; Normalization of RooRealSumPdf changed from sum of coefficients to sum of coefficients*integrals of input functions.; New PDF RooNonCentralChiSquare which is useful for asymptotic analysis of likelihood ratio tests -- like expected significance and error bands.; Ability to ""seal"" data in RooNLLVar, so that an experiment can publish likleihood functions without exposing the data necessary to evaluate the likelihood function. HistFactory. The ROOT release ships with a script prepareHistFactory and a binary hist2workspace in the $ROOTSYS/bin directories.; prepareHistFactory prepares a working area. It creates a results/, data/, and config/ directory. It also copies the HistFactorySchema.dtd and example XML files into the config/ directory. Additionally, it copies a root file into the data/ directory for use with the examples. Usage: hist2workspace input.xml; HistFactorySchema.dtd: This file is located in $ROOTSYS/etc/ specifies the XML schema. It is typically placed in the config/ direc-tory of a working area together with the top-level XML file and the individual channel XML files. The user should not modify this file. The HistFactorySchema.dtd is commented to specify exactly the meaning of the various options. Top-Level XML File. see for example $ROOTSYS/tutorials/histfactory/example.xml; This file is edited by the user. It specifies; ; A top level 'Combination' that is composed of:; 	; several 'Channels', which are described in separate XML files.; 	 several 'Measurements' (corresponding to a full fit of the model) each of which specifies; 	 ; a name for this measurement to be used in tables and files; what is the luminosity associated to the measurement in picobarns; which bins of the histogram should be used; what is the relative uncertainty on the luminosity; what is (are) the parameter(s) of interest that will be measured; which parameters should be fixed/",MatchSource.DOCS,roofit/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html:837,Modifiability,config,config,837,". RooFit. Assorted small bug fixes have been applied. No major new features have been introduced since 5.26; Normalization of RooRealSumPdf changed from sum of coefficients to sum of coefficients*integrals of input functions.; New PDF RooNonCentralChiSquare which is useful for asymptotic analysis of likelihood ratio tests -- like expected significance and error bands.; Ability to ""seal"" data in RooNLLVar, so that an experiment can publish likleihood functions without exposing the data necessary to evaluate the likelihood function. HistFactory. The ROOT release ships with a script prepareHistFactory and a binary hist2workspace in the $ROOTSYS/bin directories.; prepareHistFactory prepares a working area. It creates a results/, data/, and config/ directory. It also copies the HistFactorySchema.dtd and example XML files into the config/ directory. Additionally, it copies a root file into the data/ directory for use with the examples. Usage: hist2workspace input.xml; HistFactorySchema.dtd: This file is located in $ROOTSYS/etc/ specifies the XML schema. It is typically placed in the config/ direc-tory of a working area together with the top-level XML file and the individual channel XML files. The user should not modify this file. The HistFactorySchema.dtd is commented to specify exactly the meaning of the various options. Top-Level XML File. see for example $ROOTSYS/tutorials/histfactory/example.xml; This file is edited by the user. It specifies; ; A top level 'Combination' that is composed of:; 	; several 'Channels', which are described in separate XML files.; 	 several 'Measurements' (corresponding to a full fit of the model) each of which specifies; 	 ; a name for this measurement to be used in tables and files; what is the luminosity associated to the measurement in picobarns; which bins of the histogram should be used; what is the relative uncertainty on the luminosity; what is (are) the parameter(s) of interest that will be measured; which parameters should be fixed/",MatchSource.DOCS,roofit/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html:1094,Modifiability,config,config,1094,"umPdf changed from sum of coefficients to sum of coefficients*integrals of input functions.; New PDF RooNonCentralChiSquare which is useful for asymptotic analysis of likelihood ratio tests -- like expected significance and error bands.; Ability to ""seal"" data in RooNLLVar, so that an experiment can publish likleihood functions without exposing the data necessary to evaluate the likelihood function. HistFactory. The ROOT release ships with a script prepareHistFactory and a binary hist2workspace in the $ROOTSYS/bin directories.; prepareHistFactory prepares a working area. It creates a results/, data/, and config/ directory. It also copies the HistFactorySchema.dtd and example XML files into the config/ directory. Additionally, it copies a root file into the data/ directory for use with the examples. Usage: hist2workspace input.xml; HistFactorySchema.dtd: This file is located in $ROOTSYS/etc/ specifies the XML schema. It is typically placed in the config/ direc-tory of a working area together with the top-level XML file and the individual channel XML files. The user should not modify this file. The HistFactorySchema.dtd is commented to specify exactly the meaning of the various options. Top-Level XML File. see for example $ROOTSYS/tutorials/histfactory/example.xml; This file is edited by the user. It specifies; ; A top level 'Combination' that is composed of:; 	; several 'Channels', which are described in separate XML files.; 	 several 'Measurements' (corresponding to a full fit of the model) each of which specifies; 	 ; a name for this measurement to be used in tables and files; what is the luminosity associated to the measurement in picobarns; which bins of the histogram should be used; what is the relative uncertainty on the luminosity; what is (are) the parameter(s) of interest that will be measured; which parameters should be fixed/floating (eg. nuisance parameters); which type of constraints are desired; 		; Gaussian by default ; 		 Gamma, LogNormal, and Uniform",MatchSource.DOCS,roofit/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html:3158,Modifiability,config,configuration,3158,"ould export the model only and skip the default fit; 	 . Channel XML Files. see for example $ROOTSYS/tutorials/histfactory/example_channel.xml; This file is edited by the user. It specifies for each channel. observed data (if absent the tool will use the expectation, which is useful for expected sensitivity); several 'Samples' (eg. signal, bkg1, bkg2, ...), each of which has:; ; a name; if the sample is normalized by theory (eg N = L*sigma) or not (eg. data driven); a nominal expectation histogram; a named 'Normalization Factor' (which can be fixed or allowed to float in a fit); several 'Overall Systematics' in normalization with:; 	 ; a name; +/- 1 sigma variations (eg. 1.05 and 0.95 for a 5% uncertainty); 	 ; several 'Histogram Systematics' in shape with:; 	 ; a name (which can be shared with the OverallSyst if correlated); +/- 1 sigma variational histograms; 	 . RooStats; ModelConfig. This class is now used extensively by the calculator tools. It encapsulates the configuration of a model to define a particular hypothesis.; Various fixes by and improvements to make it usable with all; the existing calculator.; ModelConfig contains now always a reference to an; external workspace who manages all the objects being part of the model (pdf's and parameter sets). The user needs then to; set always a workspace pointer before setting the various objects.; . General Improvements. ModelConfig is now used extensively by the calculator tools. It encapsulates the configuration of a model to define a particular hypothesis.; ProfileLikelihood::GetInterval now returns LikleihoodInterval in the interface to avoid unnecessary casting; FeldmanCousins::GetInterval now returns PointSetInterval in the interface to avoid unnecessary casting. Profile Likelihood . When running ProfileLikelihoodCalculator::GetHypoTest; the user does not need anymore to clone the null parameter set. It; is done now inside the calculator; LikelihoodInterval::LowerLimit (and UpperLimit); returns now a boolean",MatchSource.DOCS,roofit/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html:3654,Modifiability,config,configuration,3654,"togram; a named 'Normalization Factor' (which can be fixed or allowed to float in a fit); several 'Overall Systematics' in normalization with:; 	 ; a name; +/- 1 sigma variations (eg. 1.05 and 0.95 for a 5% uncertainty); 	 ; several 'Histogram Systematics' in shape with:; 	 ; a name (which can be shared with the OverallSyst if correlated); +/- 1 sigma variational histograms; 	 . RooStats; ModelConfig. This class is now used extensively by the calculator tools. It encapsulates the configuration of a model to define a particular hypothesis.; Various fixes by and improvements to make it usable with all; the existing calculator.; ModelConfig contains now always a reference to an; external workspace who manages all the objects being part of the model (pdf's and parameter sets). The user needs then to; set always a workspace pointer before setting the various objects.; . General Improvements. ModelConfig is now used extensively by the calculator tools. It encapsulates the configuration of a model to define a particular hypothesis.; ProfileLikelihood::GetInterval now returns LikleihoodInterval in the interface to avoid unnecessary casting; FeldmanCousins::GetInterval now returns PointSetInterval in the interface to avoid unnecessary casting. Profile Likelihood . When running ProfileLikelihoodCalculator::GetHypoTest; the user does not need anymore to clone the null parameter set. It; is done now inside the calculator; LikelihoodInterval::LowerLimit (and UpperLimit); returns now a boolean flag with the status of the limit search.; In case of a failure in finding the upper/lower limit a value of; zero is returned instead of the min/max of the variable range; LikelihoodIntervalPlot fix drawing of horizontal green; line when limits are outside the variable range . HybridCalculator. New re-written class based on the TestStatSampler and; TestStatistic interfaces. The new class is designed to provide; consistent use of a ModelConfig, specifying the Pdf and Prior. ; The old class r",MatchSource.DOCS,roofit/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html:4334,Modifiability,variab,variable,4334,"s a reference to an; external workspace who manages all the objects being part of the model (pdf's and parameter sets). The user needs then to; set always a workspace pointer before setting the various objects.; . General Improvements. ModelConfig is now used extensively by the calculator tools. It encapsulates the configuration of a model to define a particular hypothesis.; ProfileLikelihood::GetInterval now returns LikleihoodInterval in the interface to avoid unnecessary casting; FeldmanCousins::GetInterval now returns PointSetInterval in the interface to avoid unnecessary casting. Profile Likelihood . When running ProfileLikelihoodCalculator::GetHypoTest; the user does not need anymore to clone the null parameter set. It; is done now inside the calculator; LikelihoodInterval::LowerLimit (and UpperLimit); returns now a boolean flag with the status of the limit search.; In case of a failure in finding the upper/lower limit a value of; zero is returned instead of the min/max of the variable range; LikelihoodIntervalPlot fix drawing of horizontal green; line when limits are outside the variable range . HybridCalculator. New re-written class based on the TestStatSampler and; TestStatistic interfaces. The new class is designed to provide; consistent use of a ModelConfig, specifying the Pdf and Prior. ; The old class remains, but with a new name: HybridCalculatorOriginal. ; The tutorial rs201b_hybridcalculator shows the usage of; the new class.; Note that the new class can be constructed only from a; ModelConfig; One can specify a TestStatSampler in the constructor (which implies a choice of a TestStatistic, or by default the tool will use the ToyMCSampler and the RatioOfProfiledLikelihoods; The interface of the new HybridCalculator class is now more uniform with the other calculator tools, which is different from the original; HybridCalculator's interface. Users wishing to run their old macro are advised to use ModelConfig, but if that is too time consuming one can jus",MatchSource.DOCS,roofit/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html:4439,Modifiability,variab,variable,4439,"s a reference to an; external workspace who manages all the objects being part of the model (pdf's and parameter sets). The user needs then to; set always a workspace pointer before setting the various objects.; . General Improvements. ModelConfig is now used extensively by the calculator tools. It encapsulates the configuration of a model to define a particular hypothesis.; ProfileLikelihood::GetInterval now returns LikleihoodInterval in the interface to avoid unnecessary casting; FeldmanCousins::GetInterval now returns PointSetInterval in the interface to avoid unnecessary casting. Profile Likelihood . When running ProfileLikelihoodCalculator::GetHypoTest; the user does not need anymore to clone the null parameter set. It; is done now inside the calculator; LikelihoodInterval::LowerLimit (and UpperLimit); returns now a boolean flag with the status of the limit search.; In case of a failure in finding the upper/lower limit a value of; zero is returned instead of the min/max of the variable range; LikelihoodIntervalPlot fix drawing of horizontal green; line when limits are outside the variable range . HybridCalculator. New re-written class based on the TestStatSampler and; TestStatistic interfaces. The new class is designed to provide; consistent use of a ModelConfig, specifying the Pdf and Prior. ; The old class remains, but with a new name: HybridCalculatorOriginal. ; The tutorial rs201b_hybridcalculator shows the usage of; the new class.; Note that the new class can be constructed only from a; ModelConfig; One can specify a TestStatSampler in the constructor (which implies a choice of a TestStatistic, or by default the tool will use the ToyMCSampler and the RatioOfProfiledLikelihoods; The interface of the new HybridCalculator class is now more uniform with the other calculator tools, which is different from the original; HybridCalculator's interface. Users wishing to run their old macro are advised to use ModelConfig, but if that is too time consuming one can jus",MatchSource.DOCS,roofit/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html:6194,Modifiability,config,config,6194," uniform with the other calculator tools, which is different from the original; HybridCalculator's interface. Users wishing to run their old macro are advised to use ModelConfig, but if that is too time consuming one can just change the; name of the class from HybridCalculator to; HybridCalculatorOriginal; Note also that with the new class no HybridResult is; returned but directly the base class HypoTestResult which; has been improved for this release.; The plot class, HybridPlot is not returned, but; the user can create an HypoTestPlot object from the; HypoTestResult.; The classes HybridResult and HybridPlot work only; with the HybridCalculatorOriginal and remain for maintaining; a backward compatibility. ; Given a ModelConfig, the tool will attempt to form the posterior pdf ; for the nuisance parameters based on the prior and the constraint terms ; in the pdf. However, this is not yet implemented. In order to keep; logical consistency with other tools, the distribution being used; to smear the nuisance parameters should NOT be considered the prior in ; the model config. Instead, one should use HybridCalculator's; ForcePriorNuisanceNull and ForcePriorNuisanceAlt. HybridCalculatorOriginal. Apply a fix for test statistic = 3 (profile likelihood); Apply a fix for using non-extended pdf. TestStatSampler and TestStatistics. Cleanup of the interfaces.; TestStatistics now have a method PValueIsRightTail to specify the sign conventions for the test statistic. This is used when making plots and calculating p-values.; make clear that TestStatistic::Evaluate should take data and values of the parameters that define the null.; Add method TestStatSampler::SetParametersForTestStat that ; allows for greater control of parameters used for generating toy data; and parameters used for evaluating the test statistic.; ProfileLikelihoodTestStatUsing the raw profile likelihood while reviewing the old algorithm used to provide robustness in situations with local minima.; New test statist",MatchSource.DOCS,roofit/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html:6405,Modifiability,extend,extended,6405,"from HybridCalculator to; HybridCalculatorOriginal; Note also that with the new class no HybridResult is; returned but directly the base class HypoTestResult which; has been improved for this release.; The plot class, HybridPlot is not returned, but; the user can create an HypoTestPlot object from the; HypoTestResult.; The classes HybridResult and HybridPlot work only; with the HybridCalculatorOriginal and remain for maintaining; a backward compatibility. ; Given a ModelConfig, the tool will attempt to form the posterior pdf ; for the nuisance parameters based on the prior and the constraint terms ; in the pdf. However, this is not yet implemented. In order to keep; logical consistency with other tools, the distribution being used; to smear the nuisance parameters should NOT be considered the prior in ; the model config. Instead, one should use HybridCalculator's; ForcePriorNuisanceNull and ForcePriorNuisanceAlt. HybridCalculatorOriginal. Apply a fix for test statistic = 3 (profile likelihood); Apply a fix for using non-extended pdf. TestStatSampler and TestStatistics. Cleanup of the interfaces.; TestStatistics now have a method PValueIsRightTail to specify the sign conventions for the test statistic. This is used when making plots and calculating p-values.; make clear that TestStatistic::Evaluate should take data and values of the parameters that define the null.; Add method TestStatSampler::SetParametersForTestStat that ; allows for greater control of parameters used for generating toy data; and parameters used for evaluating the test statistic.; ProfileLikelihoodTestStatUsing the raw profile likelihood while reviewing the old algorithm used to provide robustness in situations with local minima.; New test statistic classes:; ; SimpleLikelihoodRatioTestStat : log L_1 / L_0; RatioOfProfiledLikelihoodsTestStat: log L(mu_1, hat(nu_1))/L(mu_0,hat(nu_0)); MaxLikelihoodEstimateTestStat: the MLE of a specified parameter. ToyMCSampler. New version of ToyMCSampler which can ",MatchSource.DOCS,roofit/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html:7858,Modifiability,extend,extends,7858,"toy data; and parameters used for evaluating the test statistic.; ProfileLikelihoodTestStatUsing the raw profile likelihood while reviewing the old algorithm used to provide robustness in situations with local minima.; New test statistic classes:; ; SimpleLikelihoodRatioTestStat : log L_1 / L_0; RatioOfProfiledLikelihoodsTestStat: log L(mu_1, hat(nu_1))/L(mu_0,hat(nu_0)); MaxLikelihoodEstimateTestStat: the MLE of a specified parameter. ToyMCSampler. New version of ToyMCSampler which can smear the nuisance; parameters according to their distributions for use with; HybridCalculator; Updated class structure: ToyMCSampler is a particular implementation of a TestStatSampler and runs with any TestStatistic. It returns the result in an instance of SamplingDistribution.; Supports Importance Sampling: Improves sampling the tails of a distribution by generating toys from a user supplied importance density and a reweighing procedure of the result.; Supports Adaptive Sampling: extends the run until a given number of toys is reached in the tail(s).; Parallelization using PROOF(-Lite) is supported. It is enabled by supplying a ProofConfig instance. BayesianCalculator. Improve the way the class performs the numerical integration to; find the interval and/or the posterior function.; In case of complex; numerical calculation add the method SetScanOfPosterior(nbins) for; scanning the posterior function in a givn number of nbins; Add possibility to compute lower/upper limits using the method; SetLeftSideTailFraction(fraction); Add possibility to compute shortest interval using; SetShortestInterval. MCMCCalculator. Various improvements including possibility to compute; lower/central/upper limits using; SetLeftSideTailFraction(fraction). New Tutorials. New Demos that take name for file, workspace, modelconfig, and data, then use the corresponding calculator tool. If the file is not specified it will read an file produced from running the HistFactory tutorial example. StandardProfileLikel",MatchSource.DOCS,roofit/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html:8077,Performance,perform,performs,8077,"tatistic classes:; ; SimpleLikelihoodRatioTestStat : log L_1 / L_0; RatioOfProfiledLikelihoodsTestStat: log L(mu_1, hat(nu_1))/L(mu_0,hat(nu_0)); MaxLikelihoodEstimateTestStat: the MLE of a specified parameter. ToyMCSampler. New version of ToyMCSampler which can smear the nuisance; parameters according to their distributions for use with; HybridCalculator; Updated class structure: ToyMCSampler is a particular implementation of a TestStatSampler and runs with any TestStatistic. It returns the result in an instance of SamplingDistribution.; Supports Importance Sampling: Improves sampling the tails of a distribution by generating toys from a user supplied importance density and a reweighing procedure of the result.; Supports Adaptive Sampling: extends the run until a given number of toys is reached in the tail(s).; Parallelization using PROOF(-Lite) is supported. It is enabled by supplying a ProofConfig instance. BayesianCalculator. Improve the way the class performs the numerical integration to; find the interval and/or the posterior function.; In case of complex; numerical calculation add the method SetScanOfPosterior(nbins) for; scanning the posterior function in a givn number of nbins; Add possibility to compute lower/upper limits using the method; SetLeftSideTailFraction(fraction); Add possibility to compute shortest interval using; SetShortestInterval. MCMCCalculator. Various improvements including possibility to compute; lower/central/upper limits using; SetLeftSideTailFraction(fraction). New Tutorials. New Demos that take name for file, workspace, modelconfig, and data, then use the corresponding calculator tool. If the file is not specified it will read an file produced from running the HistFactory tutorial example. StandardProfileLikelihoodDemo.C: ; StandardFeldmanCousinsDemo.C: ; StandardBayesianMCMCDemo.C: ; StandardBayesianNumericalDemo.C: ; StandardProfileInspectorDemo.C: . Demonstrate some new PDFs. TestNonCentral.C: demonstrates non central chi-square; ",MatchSource.DOCS,roofit/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html:3797,Safety,avoid,avoid,3797," a name; +/- 1 sigma variations (eg. 1.05 and 0.95 for a 5% uncertainty); 	 ; several 'Histogram Systematics' in shape with:; 	 ; a name (which can be shared with the OverallSyst if correlated); +/- 1 sigma variational histograms; 	 . RooStats; ModelConfig. This class is now used extensively by the calculator tools. It encapsulates the configuration of a model to define a particular hypothesis.; Various fixes by and improvements to make it usable with all; the existing calculator.; ModelConfig contains now always a reference to an; external workspace who manages all the objects being part of the model (pdf's and parameter sets). The user needs then to; set always a workspace pointer before setting the various objects.; . General Improvements. ModelConfig is now used extensively by the calculator tools. It encapsulates the configuration of a model to define a particular hypothesis.; ProfileLikelihood::GetInterval now returns LikleihoodInterval in the interface to avoid unnecessary casting; FeldmanCousins::GetInterval now returns PointSetInterval in the interface to avoid unnecessary casting. Profile Likelihood . When running ProfileLikelihoodCalculator::GetHypoTest; the user does not need anymore to clone the null parameter set. It; is done now inside the calculator; LikelihoodInterval::LowerLimit (and UpperLimit); returns now a boolean flag with the status of the limit search.; In case of a failure in finding the upper/lower limit a value of; zero is returned instead of the min/max of the variable range; LikelihoodIntervalPlot fix drawing of horizontal green; line when limits are outside the variable range . HybridCalculator. New re-written class based on the TestStatSampler and; TestStatistic interfaces. The new class is designed to provide; consistent use of a ModelConfig, specifying the Pdf and Prior. ; The old class remains, but with a new name: HybridCalculatorOriginal. ; The tutorial rs201b_hybridcalculator shows the usage of; the new class.; Note that the new",MatchSource.DOCS,roofit/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html:3901,Safety,avoid,avoid,3901," a name; +/- 1 sigma variations (eg. 1.05 and 0.95 for a 5% uncertainty); 	 ; several 'Histogram Systematics' in shape with:; 	 ; a name (which can be shared with the OverallSyst if correlated); +/- 1 sigma variational histograms; 	 . RooStats; ModelConfig. This class is now used extensively by the calculator tools. It encapsulates the configuration of a model to define a particular hypothesis.; Various fixes by and improvements to make it usable with all; the existing calculator.; ModelConfig contains now always a reference to an; external workspace who manages all the objects being part of the model (pdf's and parameter sets). The user needs then to; set always a workspace pointer before setting the various objects.; . General Improvements. ModelConfig is now used extensively by the calculator tools. It encapsulates the configuration of a model to define a particular hypothesis.; ProfileLikelihood::GetInterval now returns LikleihoodInterval in the interface to avoid unnecessary casting; FeldmanCousins::GetInterval now returns PointSetInterval in the interface to avoid unnecessary casting. Profile Likelihood . When running ProfileLikelihoodCalculator::GetHypoTest; the user does not need anymore to clone the null parameter set. It; is done now inside the calculator; LikelihoodInterval::LowerLimit (and UpperLimit); returns now a boolean flag with the status of the limit search.; In case of a failure in finding the upper/lower limit a value of; zero is returned instead of the min/max of the variable range; LikelihoodIntervalPlot fix drawing of horizontal green; line when limits are outside the variable range . HybridCalculator. New re-written class based on the TestStatSampler and; TestStatistic interfaces. The new class is designed to provide; consistent use of a ModelConfig, specifying the Pdf and Prior. ; The old class remains, but with a new name: HybridCalculatorOriginal. ; The tutorial rs201b_hybridcalculator shows the usage of; the new class.; Note that the new",MatchSource.DOCS,roofit/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html:9583,Security,validat,validation,9583,"istribution.; Supports Importance Sampling: Improves sampling the tails of a distribution by generating toys from a user supplied importance density and a reweighing procedure of the result.; Supports Adaptive Sampling: extends the run until a given number of toys is reached in the tail(s).; Parallelization using PROOF(-Lite) is supported. It is enabled by supplying a ProofConfig instance. BayesianCalculator. Improve the way the class performs the numerical integration to; find the interval and/or the posterior function.; In case of complex; numerical calculation add the method SetScanOfPosterior(nbins) for; scanning the posterior function in a givn number of nbins; Add possibility to compute lower/upper limits using the method; SetLeftSideTailFraction(fraction); Add possibility to compute shortest interval using; SetShortestInterval. MCMCCalculator. Various improvements including possibility to compute; lower/central/upper limits using; SetLeftSideTailFraction(fraction). New Tutorials. New Demos that take name for file, workspace, modelconfig, and data, then use the corresponding calculator tool. If the file is not specified it will read an file produced from running the HistFactory tutorial example. StandardProfileLikelihoodDemo.C: ; StandardFeldmanCousinsDemo.C: ; StandardBayesianMCMCDemo.C: ; StandardBayesianNumericalDemo.C: ; StandardProfileInspectorDemo.C: . Demonstrate some new PDFs. TestNonCentral.C: demonstrates non central chi-square; JeffreysPriorDemo.C: demonstrates Jeffreys Prior. Instructional Examples. IntervalExamples.C: Standard Gaussian with known answer using 4 techniques; FourBinInstructional.C: Example of a standard data-driven approach for estimating backgrounds. A lot of discussion.; HybridInstructional.C: Example of prototype on/off problem with a data-driven background estimate. A lot of discussion; HybridStandardForm.C: Variant on above in 'standard form'; MultivariateGaussianTest.C: A validation example with an N-D multivariate Gaussian . ",MatchSource.DOCS,roofit/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html:318,Testability,test,tests,318,". RooFit. Assorted small bug fixes have been applied. No major new features have been introduced since 5.26; Normalization of RooRealSumPdf changed from sum of coefficients to sum of coefficients*integrals of input functions.; New PDF RooNonCentralChiSquare which is useful for asymptotic analysis of likelihood ratio tests -- like expected significance and error bands.; Ability to ""seal"" data in RooNLLVar, so that an experiment can publish likleihood functions without exposing the data necessary to evaluate the likelihood function. HistFactory. The ROOT release ships with a script prepareHistFactory and a binary hist2workspace in the $ROOTSYS/bin directories.; prepareHistFactory prepares a working area. It creates a results/, data/, and config/ directory. It also copies the HistFactorySchema.dtd and example XML files into the config/ directory. Additionally, it copies a root file into the data/ directory for use with the examples. Usage: hist2workspace input.xml; HistFactorySchema.dtd: This file is located in $ROOTSYS/etc/ specifies the XML schema. It is typically placed in the config/ direc-tory of a working area together with the top-level XML file and the individual channel XML files. The user should not modify this file. The HistFactorySchema.dtd is commented to specify exactly the meaning of the various options. Top-Level XML File. see for example $ROOTSYS/tutorials/histfactory/example.xml; This file is edited by the user. It specifies; ; A top level 'Combination' that is composed of:; 	; several 'Channels', which are described in separate XML files.; 	 several 'Measurements' (corresponding to a full fit of the model) each of which specifies; 	 ; a name for this measurement to be used in tables and files; what is the luminosity associated to the measurement in picobarns; which bins of the histogram should be used; what is the relative uncertainty on the luminosity; what is (are) the parameter(s) of interest that will be measured; which parameters should be fixed/",MatchSource.DOCS,roofit/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html:6044,Testability,log,logical,6044," uniform with the other calculator tools, which is different from the original; HybridCalculator's interface. Users wishing to run their old macro are advised to use ModelConfig, but if that is too time consuming one can just change the; name of the class from HybridCalculator to; HybridCalculatorOriginal; Note also that with the new class no HybridResult is; returned but directly the base class HypoTestResult which; has been improved for this release.; The plot class, HybridPlot is not returned, but; the user can create an HypoTestPlot object from the; HypoTestResult.; The classes HybridResult and HybridPlot work only; with the HybridCalculatorOriginal and remain for maintaining; a backward compatibility. ; Given a ModelConfig, the tool will attempt to form the posterior pdf ; for the nuisance parameters based on the prior and the constraint terms ; in the pdf. However, this is not yet implemented. In order to keep; logical consistency with other tools, the distribution being used; to smear the nuisance parameters should NOT be considered the prior in ; the model config. Instead, one should use HybridCalculator's; ForcePriorNuisanceNull and ForcePriorNuisanceAlt. HybridCalculatorOriginal. Apply a fix for test statistic = 3 (profile likelihood); Apply a fix for using non-extended pdf. TestStatSampler and TestStatistics. Cleanup of the interfaces.; TestStatistics now have a method PValueIsRightTail to specify the sign conventions for the test statistic. This is used when making plots and calculating p-values.; make clear that TestStatistic::Evaluate should take data and values of the parameters that define the null.; Add method TestStatSampler::SetParametersForTestStat that ; allows for greater control of parameters used for generating toy data; and parameters used for evaluating the test statistic.; ProfileLikelihoodTestStatUsing the raw profile likelihood while reviewing the old algorithm used to provide robustness in situations with local minima.; New test statist",MatchSource.DOCS,roofit/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html:6338,Testability,test,test,6338,"from HybridCalculator to; HybridCalculatorOriginal; Note also that with the new class no HybridResult is; returned but directly the base class HypoTestResult which; has been improved for this release.; The plot class, HybridPlot is not returned, but; the user can create an HypoTestPlot object from the; HypoTestResult.; The classes HybridResult and HybridPlot work only; with the HybridCalculatorOriginal and remain for maintaining; a backward compatibility. ; Given a ModelConfig, the tool will attempt to form the posterior pdf ; for the nuisance parameters based on the prior and the constraint terms ; in the pdf. However, this is not yet implemented. In order to keep; logical consistency with other tools, the distribution being used; to smear the nuisance parameters should NOT be considered the prior in ; the model config. Instead, one should use HybridCalculator's; ForcePriorNuisanceNull and ForcePriorNuisanceAlt. HybridCalculatorOriginal. Apply a fix for test statistic = 3 (profile likelihood); Apply a fix for using non-extended pdf. TestStatSampler and TestStatistics. Cleanup of the interfaces.; TestStatistics now have a method PValueIsRightTail to specify the sign conventions for the test statistic. This is used when making plots and calculating p-values.; make clear that TestStatistic::Evaluate should take data and values of the parameters that define the null.; Add method TestStatSampler::SetParametersForTestStat that ; allows for greater control of parameters used for generating toy data; and parameters used for evaluating the test statistic.; ProfileLikelihoodTestStatUsing the raw profile likelihood while reviewing the old algorithm used to provide robustness in situations with local minima.; New test statistic classes:; ; SimpleLikelihoodRatioTestStat : log L_1 / L_0; RatioOfProfiledLikelihoodsTestStat: log L(mu_1, hat(nu_1))/L(mu_0,hat(nu_0)); MaxLikelihoodEstimateTestStat: the MLE of a specified parameter. ToyMCSampler. New version of ToyMCSampler which can ",MatchSource.DOCS,roofit/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html:6574,Testability,test,test,6574,"as been improved for this release.; The plot class, HybridPlot is not returned, but; the user can create an HypoTestPlot object from the; HypoTestResult.; The classes HybridResult and HybridPlot work only; with the HybridCalculatorOriginal and remain for maintaining; a backward compatibility. ; Given a ModelConfig, the tool will attempt to form the posterior pdf ; for the nuisance parameters based on the prior and the constraint terms ; in the pdf. However, this is not yet implemented. In order to keep; logical consistency with other tools, the distribution being used; to smear the nuisance parameters should NOT be considered the prior in ; the model config. Instead, one should use HybridCalculator's; ForcePriorNuisanceNull and ForcePriorNuisanceAlt. HybridCalculatorOriginal. Apply a fix for test statistic = 3 (profile likelihood); Apply a fix for using non-extended pdf. TestStatSampler and TestStatistics. Cleanup of the interfaces.; TestStatistics now have a method PValueIsRightTail to specify the sign conventions for the test statistic. This is used when making plots and calculating p-values.; make clear that TestStatistic::Evaluate should take data and values of the parameters that define the null.; Add method TestStatSampler::SetParametersForTestStat that ; allows for greater control of parameters used for generating toy data; and parameters used for evaluating the test statistic.; ProfileLikelihoodTestStatUsing the raw profile likelihood while reviewing the old algorithm used to provide robustness in situations with local minima.; New test statistic classes:; ; SimpleLikelihoodRatioTestStat : log L_1 / L_0; RatioOfProfiledLikelihoodsTestStat: log L(mu_1, hat(nu_1))/L(mu_0,hat(nu_0)); MaxLikelihoodEstimateTestStat: the MLE of a specified parameter. ToyMCSampler. New version of ToyMCSampler which can smear the nuisance; parameters according to their distributions for use with; HybridCalculator; Updated class structure: ToyMCSampler is a particular implementation ",MatchSource.DOCS,roofit/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html:6927,Testability,test,test,6927,"ig, the tool will attempt to form the posterior pdf ; for the nuisance parameters based on the prior and the constraint terms ; in the pdf. However, this is not yet implemented. In order to keep; logical consistency with other tools, the distribution being used; to smear the nuisance parameters should NOT be considered the prior in ; the model config. Instead, one should use HybridCalculator's; ForcePriorNuisanceNull and ForcePriorNuisanceAlt. HybridCalculatorOriginal. Apply a fix for test statistic = 3 (profile likelihood); Apply a fix for using non-extended pdf. TestStatSampler and TestStatistics. Cleanup of the interfaces.; TestStatistics now have a method PValueIsRightTail to specify the sign conventions for the test statistic. This is used when making plots and calculating p-values.; make clear that TestStatistic::Evaluate should take data and values of the parameters that define the null.; Add method TestStatSampler::SetParametersForTestStat that ; allows for greater control of parameters used for generating toy data; and parameters used for evaluating the test statistic.; ProfileLikelihoodTestStatUsing the raw profile likelihood while reviewing the old algorithm used to provide robustness in situations with local minima.; New test statistic classes:; ; SimpleLikelihoodRatioTestStat : log L_1 / L_0; RatioOfProfiledLikelihoodsTestStat: log L(mu_1, hat(nu_1))/L(mu_0,hat(nu_0)); MaxLikelihoodEstimateTestStat: the MLE of a specified parameter. ToyMCSampler. New version of ToyMCSampler which can smear the nuisance; parameters according to their distributions for use with; HybridCalculator; Updated class structure: ToyMCSampler is a particular implementation of a TestStatSampler and runs with any TestStatistic. It returns the result in an instance of SamplingDistribution.; Supports Importance Sampling: Improves sampling the tails of a distribution by generating toys from a user supplied importance density and a reweighing procedure of the result.; Supports Adaptive S",MatchSource.DOCS,roofit/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html:7101,Testability,test,test,7101,"ead, one should use HybridCalculator's; ForcePriorNuisanceNull and ForcePriorNuisanceAlt. HybridCalculatorOriginal. Apply a fix for test statistic = 3 (profile likelihood); Apply a fix for using non-extended pdf. TestStatSampler and TestStatistics. Cleanup of the interfaces.; TestStatistics now have a method PValueIsRightTail to specify the sign conventions for the test statistic. This is used when making plots and calculating p-values.; make clear that TestStatistic::Evaluate should take data and values of the parameters that define the null.; Add method TestStatSampler::SetParametersForTestStat that ; allows for greater control of parameters used for generating toy data; and parameters used for evaluating the test statistic.; ProfileLikelihoodTestStatUsing the raw profile likelihood while reviewing the old algorithm used to provide robustness in situations with local minima.; New test statistic classes:; ; SimpleLikelihoodRatioTestStat : log L_1 / L_0; RatioOfProfiledLikelihoodsTestStat: log L(mu_1, hat(nu_1))/L(mu_0,hat(nu_0)); MaxLikelihoodEstimateTestStat: the MLE of a specified parameter. ToyMCSampler. New version of ToyMCSampler which can smear the nuisance; parameters according to their distributions for use with; HybridCalculator; Updated class structure: ToyMCSampler is a particular implementation of a TestStatSampler and runs with any TestStatistic. It returns the result in an instance of SamplingDistribution.; Supports Importance Sampling: Improves sampling the tails of a distribution by generating toys from a user supplied importance density and a reweighing procedure of the result.; Supports Adaptive Sampling: extends the run until a given number of toys is reached in the tail(s).; Parallelization using PROOF(-Lite) is supported. It is enabled by supplying a ProofConfig instance. BayesianCalculator. Improve the way the class performs the numerical integration to; find the interval and/or the posterior function.; In case of complex; numerical calculatio",MatchSource.DOCS,roofit/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html:7160,Testability,log,log,7160,"ead, one should use HybridCalculator's; ForcePriorNuisanceNull and ForcePriorNuisanceAlt. HybridCalculatorOriginal. Apply a fix for test statistic = 3 (profile likelihood); Apply a fix for using non-extended pdf. TestStatSampler and TestStatistics. Cleanup of the interfaces.; TestStatistics now have a method PValueIsRightTail to specify the sign conventions for the test statistic. This is used when making plots and calculating p-values.; make clear that TestStatistic::Evaluate should take data and values of the parameters that define the null.; Add method TestStatSampler::SetParametersForTestStat that ; allows for greater control of parameters used for generating toy data; and parameters used for evaluating the test statistic.; ProfileLikelihoodTestStatUsing the raw profile likelihood while reviewing the old algorithm used to provide robustness in situations with local minima.; New test statistic classes:; ; SimpleLikelihoodRatioTestStat : log L_1 / L_0; RatioOfProfiledLikelihoodsTestStat: log L(mu_1, hat(nu_1))/L(mu_0,hat(nu_0)); MaxLikelihoodEstimateTestStat: the MLE of a specified parameter. ToyMCSampler. New version of ToyMCSampler which can smear the nuisance; parameters according to their distributions for use with; HybridCalculator; Updated class structure: ToyMCSampler is a particular implementation of a TestStatSampler and runs with any TestStatistic. It returns the result in an instance of SamplingDistribution.; Supports Importance Sampling: Improves sampling the tails of a distribution by generating toys from a user supplied importance density and a reweighing procedure of the result.; Supports Adaptive Sampling: extends the run until a given number of toys is reached in the tail(s).; Parallelization using PROOF(-Lite) is supported. It is enabled by supplying a ProofConfig instance. BayesianCalculator. Improve the way the class performs the numerical integration to; find the interval and/or the posterior function.; In case of complex; numerical calculatio",MatchSource.DOCS,roofit/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html:7211,Testability,log,log,7211,"ead, one should use HybridCalculator's; ForcePriorNuisanceNull and ForcePriorNuisanceAlt. HybridCalculatorOriginal. Apply a fix for test statistic = 3 (profile likelihood); Apply a fix for using non-extended pdf. TestStatSampler and TestStatistics. Cleanup of the interfaces.; TestStatistics now have a method PValueIsRightTail to specify the sign conventions for the test statistic. This is used when making plots and calculating p-values.; make clear that TestStatistic::Evaluate should take data and values of the parameters that define the null.; Add method TestStatSampler::SetParametersForTestStat that ; allows for greater control of parameters used for generating toy data; and parameters used for evaluating the test statistic.; ProfileLikelihoodTestStatUsing the raw profile likelihood while reviewing the old algorithm used to provide robustness in situations with local minima.; New test statistic classes:; ; SimpleLikelihoodRatioTestStat : log L_1 / L_0; RatioOfProfiledLikelihoodsTestStat: log L(mu_1, hat(nu_1))/L(mu_0,hat(nu_0)); MaxLikelihoodEstimateTestStat: the MLE of a specified parameter. ToyMCSampler. New version of ToyMCSampler which can smear the nuisance; parameters according to their distributions for use with; HybridCalculator; Updated class structure: ToyMCSampler is a particular implementation of a TestStatSampler and runs with any TestStatistic. It returns the result in an instance of SamplingDistribution.; Supports Importance Sampling: Improves sampling the tails of a distribution by generating toys from a user supplied importance density and a reweighing procedure of the result.; Supports Adaptive Sampling: extends the run until a given number of toys is reached in the tail(s).; Parallelization using PROOF(-Lite) is supported. It is enabled by supplying a ProofConfig instance. BayesianCalculator. Improve the way the class performs the numerical integration to; find the interval and/or the posterior function.; In case of complex; numerical calculatio",MatchSource.DOCS,roofit/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html:3264,Usability,usab,usable,3264,"example $ROOTSYS/tutorials/histfactory/example_channel.xml; This file is edited by the user. It specifies for each channel. observed data (if absent the tool will use the expectation, which is useful for expected sensitivity); several 'Samples' (eg. signal, bkg1, bkg2, ...), each of which has:; ; a name; if the sample is normalized by theory (eg N = L*sigma) or not (eg. data driven); a nominal expectation histogram; a named 'Normalization Factor' (which can be fixed or allowed to float in a fit); several 'Overall Systematics' in normalization with:; 	 ; a name; +/- 1 sigma variations (eg. 1.05 and 0.95 for a 5% uncertainty); 	 ; several 'Histogram Systematics' in shape with:; 	 ; a name (which can be shared with the OverallSyst if correlated); +/- 1 sigma variational histograms; 	 . RooStats; ModelConfig. This class is now used extensively by the calculator tools. It encapsulates the configuration of a model to define a particular hypothesis.; Various fixes by and improvements to make it usable with all; the existing calculator.; ModelConfig contains now always a reference to an; external workspace who manages all the objects being part of the model (pdf's and parameter sets). The user needs then to; set always a workspace pointer before setting the various objects.; . General Improvements. ModelConfig is now used extensively by the calculator tools. It encapsulates the configuration of a model to define a particular hypothesis.; ProfileLikelihood::GetInterval now returns LikleihoodInterval in the interface to avoid unnecessary casting; FeldmanCousins::GetInterval now returns PointSetInterval in the interface to avoid unnecessary casting. Profile Likelihood . When running ProfileLikelihoodCalculator::GetHypoTest; the user does not need anymore to clone the null parameter set. It; is done now inside the calculator; LikelihoodInterval::LowerLimit (and UpperLimit); returns now a boolean flag with the status of the limit search.; In case of a failure in finding the uppe",MatchSource.DOCS,roofit/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html:6653,Usability,clear,clear,6653,"s HybridResult and HybridPlot work only; with the HybridCalculatorOriginal and remain for maintaining; a backward compatibility. ; Given a ModelConfig, the tool will attempt to form the posterior pdf ; for the nuisance parameters based on the prior and the constraint terms ; in the pdf. However, this is not yet implemented. In order to keep; logical consistency with other tools, the distribution being used; to smear the nuisance parameters should NOT be considered the prior in ; the model config. Instead, one should use HybridCalculator's; ForcePriorNuisanceNull and ForcePriorNuisanceAlt. HybridCalculatorOriginal. Apply a fix for test statistic = 3 (profile likelihood); Apply a fix for using non-extended pdf. TestStatSampler and TestStatistics. Cleanup of the interfaces.; TestStatistics now have a method PValueIsRightTail to specify the sign conventions for the test statistic. This is used when making plots and calculating p-values.; make clear that TestStatistic::Evaluate should take data and values of the parameters that define the null.; Add method TestStatSampler::SetParametersForTestStat that ; allows for greater control of parameters used for generating toy data; and parameters used for evaluating the test statistic.; ProfileLikelihoodTestStatUsing the raw profile likelihood while reviewing the old algorithm used to provide robustness in situations with local minima.; New test statistic classes:; ; SimpleLikelihoodRatioTestStat : log L_1 / L_0; RatioOfProfiledLikelihoodsTestStat: log L(mu_1, hat(nu_1))/L(mu_0,hat(nu_0)); MaxLikelihoodEstimateTestStat: the MLE of a specified parameter. ToyMCSampler. New version of ToyMCSampler which can smear the nuisance; parameters according to their distributions for use with; HybridCalculator; Updated class structure: ToyMCSampler is a particular implementation of a TestStatSampler and runs with any TestStatistic. It returns the result in an instance of SamplingDistribution.; Supports Importance Sampling: Improves sampling t",MatchSource.DOCS,roofit/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html:6672,Availability,avail,available,6672,"call SetFixedScan(npoints, xmin, xmax), while for running an autoscan use; the function SetAutoScan. The result is returned in the GetInterval function as an; HypoTestInverterResult class. If a fixed grid is used the upper limit is obtained by using a interpolation on; the scanned points. The interpolation can be linear or a spline (if; result.SetInterpolationOption(HypoTestInverterResult::kSpline) is called).; The upper limit, the expected P value distributions and also the upper limit distributions can be obtained from the; result class. . HypoTestInverterResult * result = inverter.GetInterval();; double upperLimit = result->UpperLimit();; double expectedLimit = result->GetExpectedUpperLimit(0);. The limit values, p values and bands can be drawn using the HypoTestInverterPlot class. Example:. HypoTestInverterPlot * plot = new HypoTestInverterPlot(""Result"",""POI Scan Result"",result);; plot->Draw(""2CL CLb"");. Where the Draw option ""2CL CLb"" draws in addition to the observed limit and bands, the observed CLs+b and CLb.; The result is shown in this figure:. FrequentistCalculator; This is a HypoTestCalculator that returns a HypoTestResult similar to the HybridCalculator. The primary difference is that this tool profiles the nuisance parameters for the null model and uses those fixed values of the nuisance parameters for generating the pseudo-experiments, where the HybridCalculator smears/randomizes/marginalizes the nuisance parameters. BayesianCalculator; Several improvements have been put in the class. In particular the possibility to set different integration types. One; can set the different integration types available in the ROOT integration routines; (ADAPTIVE, VEGAS, MISER, PLAIN for multi-dimension). In addition one can use an integration types by generating nuisance; toy MC (method TOYMC). If the nuisance parameters are uncorrelated, this last method can scale up for a large number of; nuisance parameters. It has been tested to work up to 50-100 parameters. ; ; ",MatchSource.DOCS,roofit/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html:1395,Deployability,release,release,1395,"n, avoids kink for asymmetric uncert). The piece-wise logarithmic interpolation paired with a Gaussian constraint is equivalent to a log-normal constraint in a transformed version of the nuisance parameter. The benefit of this approach is that it is easy to avoid the normalization from taking on unphysical negative values. This is the prescription used by the CMS Higgs group, and agreed upon by the LHC Higgs Combination Group. There is not yet XML-based steering for the different interpolation types, but there is a simple script to modify it. . results/example_combined_GaussExample_model.root . Near term goals for HistFactory. Utilities for dealing with Monte Carlo statistical uncertainty in the template histograms; Support for N-D histograms; A new style of histogram variations without a constraint term attached (for shapes determined from control samples); XML steering for interpolation types. RooStats; General Improvements. This release brings several speed improvements to the RooStats tools and improved stability and performance with PROOF. This comes mainly through changes to the ToyMCSampler. In addition the HypoTestInverter tool has been rewritten, leading to some changes in the HypoTestResult. Finally, a new hypothesis test new called FrequentistCalculator was written, which plays the same role as the HybridCalculator but eliminates nuisance parameters in a frequentist way. ToyMCSampler. The primary interface for this class is to return a SamplingDistribution of a given TestStatistic.; The ToyMCSampler had a number of internal changes for improved performance with PROOF. These should be transparent. In addition, a new method was added RooAbsData* GenerateToyData(RooArgSet& paramPoint) that gives public access to the generation of toy data with all the same options for the treatment of nuisance parameters, binned or unbinned data, treatment of the global observables, importance sampling, etc. This is new method particularly useful for producing the expected l",MatchSource.DOCS,roofit/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html:6608,Deployability,integrat,integration,6608,"call SetFixedScan(npoints, xmin, xmax), while for running an autoscan use; the function SetAutoScan. The result is returned in the GetInterval function as an; HypoTestInverterResult class. If a fixed grid is used the upper limit is obtained by using a interpolation on; the scanned points. The interpolation can be linear or a spline (if; result.SetInterpolationOption(HypoTestInverterResult::kSpline) is called).; The upper limit, the expected P value distributions and also the upper limit distributions can be obtained from the; result class. . HypoTestInverterResult * result = inverter.GetInterval();; double upperLimit = result->UpperLimit();; double expectedLimit = result->GetExpectedUpperLimit(0);. The limit values, p values and bands can be drawn using the HypoTestInverterPlot class. Example:. HypoTestInverterPlot * plot = new HypoTestInverterPlot(""Result"",""POI Scan Result"",result);; plot->Draw(""2CL CLb"");. Where the Draw option ""2CL CLb"" draws in addition to the observed limit and bands, the observed CLs+b and CLb.; The result is shown in this figure:. FrequentistCalculator; This is a HypoTestCalculator that returns a HypoTestResult similar to the HybridCalculator. The primary difference is that this tool profiles the nuisance parameters for the null model and uses those fixed values of the nuisance parameters for generating the pseudo-experiments, where the HybridCalculator smears/randomizes/marginalizes the nuisance parameters. BayesianCalculator; Several improvements have been put in the class. In particular the possibility to set different integration types. One; can set the different integration types available in the ROOT integration routines; (ADAPTIVE, VEGAS, MISER, PLAIN for multi-dimension). In addition one can use an integration types by generating nuisance; toy MC (method TOYMC). If the nuisance parameters are uncorrelated, this last method can scale up for a large number of; nuisance parameters. It has been tested to work up to 50-100 parameters. ; ; ",MatchSource.DOCS,roofit/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html:6654,Deployability,integrat,integration,6654,"call SetFixedScan(npoints, xmin, xmax), while for running an autoscan use; the function SetAutoScan. The result is returned in the GetInterval function as an; HypoTestInverterResult class. If a fixed grid is used the upper limit is obtained by using a interpolation on; the scanned points. The interpolation can be linear or a spline (if; result.SetInterpolationOption(HypoTestInverterResult::kSpline) is called).; The upper limit, the expected P value distributions and also the upper limit distributions can be obtained from the; result class. . HypoTestInverterResult * result = inverter.GetInterval();; double upperLimit = result->UpperLimit();; double expectedLimit = result->GetExpectedUpperLimit(0);. The limit values, p values and bands can be drawn using the HypoTestInverterPlot class. Example:. HypoTestInverterPlot * plot = new HypoTestInverterPlot(""Result"",""POI Scan Result"",result);; plot->Draw(""2CL CLb"");. Where the Draw option ""2CL CLb"" draws in addition to the observed limit and bands, the observed CLs+b and CLb.; The result is shown in this figure:. FrequentistCalculator; This is a HypoTestCalculator that returns a HypoTestResult similar to the HybridCalculator. The primary difference is that this tool profiles the nuisance parameters for the null model and uses those fixed values of the nuisance parameters for generating the pseudo-experiments, where the HybridCalculator smears/randomizes/marginalizes the nuisance parameters. BayesianCalculator; Several improvements have been put in the class. In particular the possibility to set different integration types. One; can set the different integration types available in the ROOT integration routines; (ADAPTIVE, VEGAS, MISER, PLAIN for multi-dimension). In addition one can use an integration types by generating nuisance; toy MC (method TOYMC). If the nuisance parameters are uncorrelated, this last method can scale up for a large number of; nuisance parameters. It has been tested to work up to 50-100 parameters. ; ; ",MatchSource.DOCS,roofit/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html:6694,Deployability,integrat,integration,6694,"call SetFixedScan(npoints, xmin, xmax), while for running an autoscan use; the function SetAutoScan. The result is returned in the GetInterval function as an; HypoTestInverterResult class. If a fixed grid is used the upper limit is obtained by using a interpolation on; the scanned points. The interpolation can be linear or a spline (if; result.SetInterpolationOption(HypoTestInverterResult::kSpline) is called).; The upper limit, the expected P value distributions and also the upper limit distributions can be obtained from the; result class. . HypoTestInverterResult * result = inverter.GetInterval();; double upperLimit = result->UpperLimit();; double expectedLimit = result->GetExpectedUpperLimit(0);. The limit values, p values and bands can be drawn using the HypoTestInverterPlot class. Example:. HypoTestInverterPlot * plot = new HypoTestInverterPlot(""Result"",""POI Scan Result"",result);; plot->Draw(""2CL CLb"");. Where the Draw option ""2CL CLb"" draws in addition to the observed limit and bands, the observed CLs+b and CLb.; The result is shown in this figure:. FrequentistCalculator; This is a HypoTestCalculator that returns a HypoTestResult similar to the HybridCalculator. The primary difference is that this tool profiles the nuisance parameters for the null model and uses those fixed values of the nuisance parameters for generating the pseudo-experiments, where the HybridCalculator smears/randomizes/marginalizes the nuisance parameters. BayesianCalculator; Several improvements have been put in the class. In particular the possibility to set different integration types. One; can set the different integration types available in the ROOT integration routines; (ADAPTIVE, VEGAS, MISER, PLAIN for multi-dimension). In addition one can use an integration types by generating nuisance; toy MC (method TOYMC). If the nuisance parameters are uncorrelated, this last method can scale up for a large number of; nuisance parameters. It has been tested to work up to 50-100 parameters. ; ; ",MatchSource.DOCS,roofit/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html:6796,Deployability,integrat,integration,6796,"call SetFixedScan(npoints, xmin, xmax), while for running an autoscan use; the function SetAutoScan. The result is returned in the GetInterval function as an; HypoTestInverterResult class. If a fixed grid is used the upper limit is obtained by using a interpolation on; the scanned points. The interpolation can be linear or a spline (if; result.SetInterpolationOption(HypoTestInverterResult::kSpline) is called).; The upper limit, the expected P value distributions and also the upper limit distributions can be obtained from the; result class. . HypoTestInverterResult * result = inverter.GetInterval();; double upperLimit = result->UpperLimit();; double expectedLimit = result->GetExpectedUpperLimit(0);. The limit values, p values and bands can be drawn using the HypoTestInverterPlot class. Example:. HypoTestInverterPlot * plot = new HypoTestInverterPlot(""Result"",""POI Scan Result"",result);; plot->Draw(""2CL CLb"");. Where the Draw option ""2CL CLb"" draws in addition to the observed limit and bands, the observed CLs+b and CLb.; The result is shown in this figure:. FrequentistCalculator; This is a HypoTestCalculator that returns a HypoTestResult similar to the HybridCalculator. The primary difference is that this tool profiles the nuisance parameters for the null model and uses those fixed values of the nuisance parameters for generating the pseudo-experiments, where the HybridCalculator smears/randomizes/marginalizes the nuisance parameters. BayesianCalculator; Several improvements have been put in the class. In particular the possibility to set different integration types. One; can set the different integration types available in the ROOT integration routines; (ADAPTIVE, VEGAS, MISER, PLAIN for multi-dimension). In addition one can use an integration types by generating nuisance; toy MC (method TOYMC). If the nuisance parameters are uncorrelated, this last method can scale up for a large number of; nuisance parameters. It has been tested to work up to 50-100 parameters. ; ; ",MatchSource.DOCS,roofit/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html:1880,Integrability,interface,interface,1880,"for the different interpolation types, but there is a simple script to modify it. . results/example_combined_GaussExample_model.root . Near term goals for HistFactory. Utilities for dealing with Monte Carlo statistical uncertainty in the template histograms; Support for N-D histograms; A new style of histogram variations without a constraint term attached (for shapes determined from control samples); XML steering for interpolation types. RooStats; General Improvements. This release brings several speed improvements to the RooStats tools and improved stability and performance with PROOF. This comes mainly through changes to the ToyMCSampler. In addition the HypoTestInverter tool has been rewritten, leading to some changes in the HypoTestResult. Finally, a new hypothesis test new called FrequentistCalculator was written, which plays the same role as the HybridCalculator but eliminates nuisance parameters in a frequentist way. ToyMCSampler. The primary interface for this class is to return a SamplingDistribution of a given TestStatistic.; The ToyMCSampler had a number of internal changes for improved performance with PROOF. These should be transparent. In addition, a new method was added RooAbsData* GenerateToyData(RooArgSet& paramPoint) that gives public access to the generation of toy data with all the same options for the treatment of nuisance parameters, binned or unbinned data, treatment of the global observables, importance sampling, etc. This is new method particularly useful for producing the expected limit bands where one needs to generate background-only pseudo-experiments in the same way that was used for the primary limit calculation. HypoTestResult. In the process of writing the new HypoTestInverter the conventions for p-values, CLb, CLs+b, and CLs were revisited. The situation is complicated by the fact that when performing a hypothesis test for discovery the null is background-only, but when performing an inverted hypothesis test the null is a signal+back",MatchSource.DOCS,roofit/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html:6608,Integrability,integrat,integration,6608,"call SetFixedScan(npoints, xmin, xmax), while for running an autoscan use; the function SetAutoScan. The result is returned in the GetInterval function as an; HypoTestInverterResult class. If a fixed grid is used the upper limit is obtained by using a interpolation on; the scanned points. The interpolation can be linear or a spline (if; result.SetInterpolationOption(HypoTestInverterResult::kSpline) is called).; The upper limit, the expected P value distributions and also the upper limit distributions can be obtained from the; result class. . HypoTestInverterResult * result = inverter.GetInterval();; double upperLimit = result->UpperLimit();; double expectedLimit = result->GetExpectedUpperLimit(0);. The limit values, p values and bands can be drawn using the HypoTestInverterPlot class. Example:. HypoTestInverterPlot * plot = new HypoTestInverterPlot(""Result"",""POI Scan Result"",result);; plot->Draw(""2CL CLb"");. Where the Draw option ""2CL CLb"" draws in addition to the observed limit and bands, the observed CLs+b and CLb.; The result is shown in this figure:. FrequentistCalculator; This is a HypoTestCalculator that returns a HypoTestResult similar to the HybridCalculator. The primary difference is that this tool profiles the nuisance parameters for the null model and uses those fixed values of the nuisance parameters for generating the pseudo-experiments, where the HybridCalculator smears/randomizes/marginalizes the nuisance parameters. BayesianCalculator; Several improvements have been put in the class. In particular the possibility to set different integration types. One; can set the different integration types available in the ROOT integration routines; (ADAPTIVE, VEGAS, MISER, PLAIN for multi-dimension). In addition one can use an integration types by generating nuisance; toy MC (method TOYMC). If the nuisance parameters are uncorrelated, this last method can scale up for a large number of; nuisance parameters. It has been tested to work up to 50-100 parameters. ; ; ",MatchSource.DOCS,roofit/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html:6654,Integrability,integrat,integration,6654,"call SetFixedScan(npoints, xmin, xmax), while for running an autoscan use; the function SetAutoScan. The result is returned in the GetInterval function as an; HypoTestInverterResult class. If a fixed grid is used the upper limit is obtained by using a interpolation on; the scanned points. The interpolation can be linear or a spline (if; result.SetInterpolationOption(HypoTestInverterResult::kSpline) is called).; The upper limit, the expected P value distributions and also the upper limit distributions can be obtained from the; result class. . HypoTestInverterResult * result = inverter.GetInterval();; double upperLimit = result->UpperLimit();; double expectedLimit = result->GetExpectedUpperLimit(0);. The limit values, p values and bands can be drawn using the HypoTestInverterPlot class. Example:. HypoTestInverterPlot * plot = new HypoTestInverterPlot(""Result"",""POI Scan Result"",result);; plot->Draw(""2CL CLb"");. Where the Draw option ""2CL CLb"" draws in addition to the observed limit and bands, the observed CLs+b and CLb.; The result is shown in this figure:. FrequentistCalculator; This is a HypoTestCalculator that returns a HypoTestResult similar to the HybridCalculator. The primary difference is that this tool profiles the nuisance parameters for the null model and uses those fixed values of the nuisance parameters for generating the pseudo-experiments, where the HybridCalculator smears/randomizes/marginalizes the nuisance parameters. BayesianCalculator; Several improvements have been put in the class. In particular the possibility to set different integration types. One; can set the different integration types available in the ROOT integration routines; (ADAPTIVE, VEGAS, MISER, PLAIN for multi-dimension). In addition one can use an integration types by generating nuisance; toy MC (method TOYMC). If the nuisance parameters are uncorrelated, this last method can scale up for a large number of; nuisance parameters. It has been tested to work up to 50-100 parameters. ; ; ",MatchSource.DOCS,roofit/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html:6694,Integrability,integrat,integration,6694,"call SetFixedScan(npoints, xmin, xmax), while for running an autoscan use; the function SetAutoScan. The result is returned in the GetInterval function as an; HypoTestInverterResult class. If a fixed grid is used the upper limit is obtained by using a interpolation on; the scanned points. The interpolation can be linear or a spline (if; result.SetInterpolationOption(HypoTestInverterResult::kSpline) is called).; The upper limit, the expected P value distributions and also the upper limit distributions can be obtained from the; result class. . HypoTestInverterResult * result = inverter.GetInterval();; double upperLimit = result->UpperLimit();; double expectedLimit = result->GetExpectedUpperLimit(0);. The limit values, p values and bands can be drawn using the HypoTestInverterPlot class. Example:. HypoTestInverterPlot * plot = new HypoTestInverterPlot(""Result"",""POI Scan Result"",result);; plot->Draw(""2CL CLb"");. Where the Draw option ""2CL CLb"" draws in addition to the observed limit and bands, the observed CLs+b and CLb.; The result is shown in this figure:. FrequentistCalculator; This is a HypoTestCalculator that returns a HypoTestResult similar to the HybridCalculator. The primary difference is that this tool profiles the nuisance parameters for the null model and uses those fixed values of the nuisance parameters for generating the pseudo-experiments, where the HybridCalculator smears/randomizes/marginalizes the nuisance parameters. BayesianCalculator; Several improvements have been put in the class. In particular the possibility to set different integration types. One; can set the different integration types available in the ROOT integration routines; (ADAPTIVE, VEGAS, MISER, PLAIN for multi-dimension). In addition one can use an integration types by generating nuisance; toy MC (method TOYMC). If the nuisance parameters are uncorrelated, this last method can scale up for a large number of; nuisance parameters. It has been tested to work up to 50-100 parameters. ; ; ",MatchSource.DOCS,roofit/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html:6706,Integrability,rout,routines,6706,"call SetFixedScan(npoints, xmin, xmax), while for running an autoscan use; the function SetAutoScan. The result is returned in the GetInterval function as an; HypoTestInverterResult class. If a fixed grid is used the upper limit is obtained by using a interpolation on; the scanned points. The interpolation can be linear or a spline (if; result.SetInterpolationOption(HypoTestInverterResult::kSpline) is called).; The upper limit, the expected P value distributions and also the upper limit distributions can be obtained from the; result class. . HypoTestInverterResult * result = inverter.GetInterval();; double upperLimit = result->UpperLimit();; double expectedLimit = result->GetExpectedUpperLimit(0);. The limit values, p values and bands can be drawn using the HypoTestInverterPlot class. Example:. HypoTestInverterPlot * plot = new HypoTestInverterPlot(""Result"",""POI Scan Result"",result);; plot->Draw(""2CL CLb"");. Where the Draw option ""2CL CLb"" draws in addition to the observed limit and bands, the observed CLs+b and CLb.; The result is shown in this figure:. FrequentistCalculator; This is a HypoTestCalculator that returns a HypoTestResult similar to the HybridCalculator. The primary difference is that this tool profiles the nuisance parameters for the null model and uses those fixed values of the nuisance parameters for generating the pseudo-experiments, where the HybridCalculator smears/randomizes/marginalizes the nuisance parameters. BayesianCalculator; Several improvements have been put in the class. In particular the possibility to set different integration types. One; can set the different integration types available in the ROOT integration routines; (ADAPTIVE, VEGAS, MISER, PLAIN for multi-dimension). In addition one can use an integration types by generating nuisance; toy MC (method TOYMC). If the nuisance parameters are uncorrelated, this last method can scale up for a large number of; nuisance parameters. It has been tested to work up to 50-100 parameters. ; ; ",MatchSource.DOCS,roofit/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html:6796,Integrability,integrat,integration,6796,"call SetFixedScan(npoints, xmin, xmax), while for running an autoscan use; the function SetAutoScan. The result is returned in the GetInterval function as an; HypoTestInverterResult class. If a fixed grid is used the upper limit is obtained by using a interpolation on; the scanned points. The interpolation can be linear or a spline (if; result.SetInterpolationOption(HypoTestInverterResult::kSpline) is called).; The upper limit, the expected P value distributions and also the upper limit distributions can be obtained from the; result class. . HypoTestInverterResult * result = inverter.GetInterval();; double upperLimit = result->UpperLimit();; double expectedLimit = result->GetExpectedUpperLimit(0);. The limit values, p values and bands can be drawn using the HypoTestInverterPlot class. Example:. HypoTestInverterPlot * plot = new HypoTestInverterPlot(""Result"",""POI Scan Result"",result);; plot->Draw(""2CL CLb"");. Where the Draw option ""2CL CLb"" draws in addition to the observed limit and bands, the observed CLs+b and CLb.; The result is shown in this figure:. FrequentistCalculator; This is a HypoTestCalculator that returns a HypoTestResult similar to the HybridCalculator. The primary difference is that this tool profiles the nuisance parameters for the null model and uses those fixed values of the nuisance parameters for generating the pseudo-experiments, where the HybridCalculator smears/randomizes/marginalizes the nuisance parameters. BayesianCalculator; Several improvements have been put in the class. In particular the possibility to set different integration types. One; can set the different integration types available in the ROOT integration routines; (ADAPTIVE, VEGAS, MISER, PLAIN for multi-dimension). In addition one can use an integration types by generating nuisance; toy MC (method TOYMC). If the nuisance parameters are uncorrelated, this last method can scale up for a large number of; nuisance parameters. It has been tested to work up to 50-100 parameters. ; ; ",MatchSource.DOCS,roofit/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html:3809,Modifiability,config,configure,3809,"kground-only, but when performing an inverted hypothesis test the null is a signal+background model. The new convention is that the p-value for both the null and the alternate are taken from the same tail (as specified by the test statistic). Both CLs+b and CLb are equivalent to these p-values, and the HypoTestResult has a simple switch SetBackgroundIsAlt() to specify the pairing between (null p-value, alternate p-value) and (CLb, CLs+b). HypoTestInverter, HypoTestInverterResult, HypoTestInverterPlot. These classes have been rewritten for using them with the new hypothesis test calculators. The HypoTestInverter; class can now be constructed by any generic HypoTestCalculator, and both the HybridCalculator and the new; FrequentistCalculator are supported. The HypoTestInverter class can be constructed in two ways: either passing an; HypoTestCalculator and a data set or by passing the model for the signal, for the background and a data set.; In the first case the user configure the HypoTestCalculator before passing to the HypoTestInverter.; It must be configured using as null model the signal plus background model as alternate model the background; model. Optionally the user can pass the parameter to scan, if it is not passed, the first parameter of interest of the; null model will be used. In the second case (when passing directly the model and the data) the HypoTestInverter; can be configured to use either the frequentist or the hybrid calculator. The user can then configure the class; afterwards. For example set the test statistic to use via the method SetTestStatistic, number of toys to run; for each hypothesis, by retrieving the contained HypoTestCalculator:. HypoTestInverter inverter(obsData, model_B, model_SB, parameterToScan, HypoTestInverter::kFrequentist);; ProfileLikelihoodRatioTestStat profLR( *model_SB->GetPdf() );; inverter.SetTestStatistic(&profLR);; FrequentistCalculator * htcalc = (FrequentistCalculator*) inverter.GetHypoTestCalculator();; htcalc->SetToy",MatchSource.DOCS,roofit/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html:3894,Modifiability,config,configured,3894,"onvention is that the p-value for both the null and the alternate are taken from the same tail (as specified by the test statistic). Both CLs+b and CLb are equivalent to these p-values, and the HypoTestResult has a simple switch SetBackgroundIsAlt() to specify the pairing between (null p-value, alternate p-value) and (CLb, CLs+b). HypoTestInverter, HypoTestInverterResult, HypoTestInverterPlot. These classes have been rewritten for using them with the new hypothesis test calculators. The HypoTestInverter; class can now be constructed by any generic HypoTestCalculator, and both the HybridCalculator and the new; FrequentistCalculator are supported. The HypoTestInverter class can be constructed in two ways: either passing an; HypoTestCalculator and a data set or by passing the model for the signal, for the background and a data set.; In the first case the user configure the HypoTestCalculator before passing to the HypoTestInverter.; It must be configured using as null model the signal plus background model as alternate model the background; model. Optionally the user can pass the parameter to scan, if it is not passed, the first parameter of interest of the; null model will be used. In the second case (when passing directly the model and the data) the HypoTestInverter; can be configured to use either the frequentist or the hybrid calculator. The user can then configure the class; afterwards. For example set the test statistic to use via the method SetTestStatistic, number of toys to run; for each hypothesis, by retrieving the contained HypoTestCalculator:. HypoTestInverter inverter(obsData, model_B, model_SB, parameterToScan, HypoTestInverter::kFrequentist);; ProfileLikelihoodRatioTestStat profLR( *model_SB->GetPdf() );; inverter.SetTestStatistic(&profLR);; FrequentistCalculator * htcalc = (FrequentistCalculator*) inverter.GetHypoTestCalculator();; htcalc->SetToys( ntoySB, ntoyB);. The Inverter can then run using a fixed grid of npoint between xmin and xmax or by using ",MatchSource.DOCS,roofit/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html:4233,Modifiability,config,configured,4233,"en (null p-value, alternate p-value) and (CLb, CLs+b). HypoTestInverter, HypoTestInverterResult, HypoTestInverterPlot. These classes have been rewritten for using them with the new hypothesis test calculators. The HypoTestInverter; class can now be constructed by any generic HypoTestCalculator, and both the HybridCalculator and the new; FrequentistCalculator are supported. The HypoTestInverter class can be constructed in two ways: either passing an; HypoTestCalculator and a data set or by passing the model for the signal, for the background and a data set.; In the first case the user configure the HypoTestCalculator before passing to the HypoTestInverter.; It must be configured using as null model the signal plus background model as alternate model the background; model. Optionally the user can pass the parameter to scan, if it is not passed, the first parameter of interest of the; null model will be used. In the second case (when passing directly the model and the data) the HypoTestInverter; can be configured to use either the frequentist or the hybrid calculator. The user can then configure the class; afterwards. For example set the test statistic to use via the method SetTestStatistic, number of toys to run; for each hypothesis, by retrieving the contained HypoTestCalculator:. HypoTestInverter inverter(obsData, model_B, model_SB, parameterToScan, HypoTestInverter::kFrequentist);; ProfileLikelihoodRatioTestStat profLR( *model_SB->GetPdf() );; inverter.SetTestStatistic(&profLR);; FrequentistCalculator * htcalc = (FrequentistCalculator*) inverter.GetHypoTestCalculator();; htcalc->SetToys( ntoySB, ntoyB);. The Inverter can then run using a fixed grid of npoint between xmin and xmax or by using an automatic scan, where a; bisection algorithm is used.; For running a fixed grid one needs to call SetFixedScan(npoints, xmin, xmax), while for running an autoscan use; the function SetAutoScan. The result is returned in the GetInterval function as an; HypoTestInverterResult ",MatchSource.DOCS,roofit/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html:4318,Modifiability,config,configure,4318,"nverterPlot. These classes have been rewritten for using them with the new hypothesis test calculators. The HypoTestInverter; class can now be constructed by any generic HypoTestCalculator, and both the HybridCalculator and the new; FrequentistCalculator are supported. The HypoTestInverter class can be constructed in two ways: either passing an; HypoTestCalculator and a data set or by passing the model for the signal, for the background and a data set.; In the first case the user configure the HypoTestCalculator before passing to the HypoTestInverter.; It must be configured using as null model the signal plus background model as alternate model the background; model. Optionally the user can pass the parameter to scan, if it is not passed, the first parameter of interest of the; null model will be used. In the second case (when passing directly the model and the data) the HypoTestInverter; can be configured to use either the frequentist or the hybrid calculator. The user can then configure the class; afterwards. For example set the test statistic to use via the method SetTestStatistic, number of toys to run; for each hypothesis, by retrieving the contained HypoTestCalculator:. HypoTestInverter inverter(obsData, model_B, model_SB, parameterToScan, HypoTestInverter::kFrequentist);; ProfileLikelihoodRatioTestStat profLR( *model_SB->GetPdf() );; inverter.SetTestStatistic(&profLR);; FrequentistCalculator * htcalc = (FrequentistCalculator*) inverter.GetHypoTestCalculator();; htcalc->SetToys( ntoySB, ntoyB);. The Inverter can then run using a fixed grid of npoint between xmin and xmax or by using an automatic scan, where a; bisection algorithm is used.; For running a fixed grid one needs to call SetFixedScan(npoints, xmin, xmax), while for running an autoscan use; the function SetAutoScan. The result is returned in the GetInterval function as an; HypoTestInverterResult class. If a fixed grid is used the upper limit is obtained by using a interpolation on; the scanned points.",MatchSource.DOCS,roofit/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html:1486,Performance,perform,performance,1486,"n, avoids kink for asymmetric uncert). The piece-wise logarithmic interpolation paired with a Gaussian constraint is equivalent to a log-normal constraint in a transformed version of the nuisance parameter. The benefit of this approach is that it is easy to avoid the normalization from taking on unphysical negative values. This is the prescription used by the CMS Higgs group, and agreed upon by the LHC Higgs Combination Group. There is not yet XML-based steering for the different interpolation types, but there is a simple script to modify it. . results/example_combined_GaussExample_model.root . Near term goals for HistFactory. Utilities for dealing with Monte Carlo statistical uncertainty in the template histograms; Support for N-D histograms; A new style of histogram variations without a constraint term attached (for shapes determined from control samples); XML steering for interpolation types. RooStats; General Improvements. This release brings several speed improvements to the RooStats tools and improved stability and performance with PROOF. This comes mainly through changes to the ToyMCSampler. In addition the HypoTestInverter tool has been rewritten, leading to some changes in the HypoTestResult. Finally, a new hypothesis test new called FrequentistCalculator was written, which plays the same role as the HybridCalculator but eliminates nuisance parameters in a frequentist way. ToyMCSampler. The primary interface for this class is to return a SamplingDistribution of a given TestStatistic.; The ToyMCSampler had a number of internal changes for improved performance with PROOF. These should be transparent. In addition, a new method was added RooAbsData* GenerateToyData(RooArgSet& paramPoint) that gives public access to the generation of toy data with all the same options for the treatment of nuisance parameters, binned or unbinned data, treatment of the global observables, importance sampling, etc. This is new method particularly useful for producing the expected l",MatchSource.DOCS,roofit/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html:2031,Performance,perform,performance,2031,"ample_combined_GaussExample_model.root . Near term goals for HistFactory. Utilities for dealing with Monte Carlo statistical uncertainty in the template histograms; Support for N-D histograms; A new style of histogram variations without a constraint term attached (for shapes determined from control samples); XML steering for interpolation types. RooStats; General Improvements. This release brings several speed improvements to the RooStats tools and improved stability and performance with PROOF. This comes mainly through changes to the ToyMCSampler. In addition the HypoTestInverter tool has been rewritten, leading to some changes in the HypoTestResult. Finally, a new hypothesis test new called FrequentistCalculator was written, which plays the same role as the HybridCalculator but eliminates nuisance parameters in a frequentist way. ToyMCSampler. The primary interface for this class is to return a SamplingDistribution of a given TestStatistic.; The ToyMCSampler had a number of internal changes for improved performance with PROOF. These should be transparent. In addition, a new method was added RooAbsData* GenerateToyData(RooArgSet& paramPoint) that gives public access to the generation of toy data with all the same options for the treatment of nuisance parameters, binned or unbinned data, treatment of the global observables, importance sampling, etc. This is new method particularly useful for producing the expected limit bands where one needs to generate background-only pseudo-experiments in the same way that was used for the primary limit calculation. HypoTestResult. In the process of writing the new HypoTestInverter the conventions for p-values, CLb, CLs+b, and CLs were revisited. The situation is complicated by the fact that when performing a hypothesis test for discovery the null is background-only, but when performing an inverted hypothesis test the null is a signal+background model. The new convention is that the p-value for both the null and the alternate are ",MatchSource.DOCS,roofit/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html:2772,Performance,perform,performing,2772,"meters in a frequentist way. ToyMCSampler. The primary interface for this class is to return a SamplingDistribution of a given TestStatistic.; The ToyMCSampler had a number of internal changes for improved performance with PROOF. These should be transparent. In addition, a new method was added RooAbsData* GenerateToyData(RooArgSet& paramPoint) that gives public access to the generation of toy data with all the same options for the treatment of nuisance parameters, binned or unbinned data, treatment of the global observables, importance sampling, etc. This is new method particularly useful for producing the expected limit bands where one needs to generate background-only pseudo-experiments in the same way that was used for the primary limit calculation. HypoTestResult. In the process of writing the new HypoTestInverter the conventions for p-values, CLb, CLs+b, and CLs were revisited. The situation is complicated by the fact that when performing a hypothesis test for discovery the null is background-only, but when performing an inverted hypothesis test the null is a signal+background model. The new convention is that the p-value for both the null and the alternate are taken from the same tail (as specified by the test statistic). Both CLs+b and CLb are equivalent to these p-values, and the HypoTestResult has a simple switch SetBackgroundIsAlt() to specify the pairing between (null p-value, alternate p-value) and (CLb, CLs+b). HypoTestInverter, HypoTestInverterResult, HypoTestInverterPlot. These classes have been rewritten for using them with the new hypothesis test calculators. The HypoTestInverter; class can now be constructed by any generic HypoTestCalculator, and both the HybridCalculator and the new; FrequentistCalculator are supported. The HypoTestInverter class can be constructed in two ways: either passing an; HypoTestCalculator and a data set or by passing the model for the signal, for the background and a data set.; In the first case the user configure the Hy",MatchSource.DOCS,roofit/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html:2853,Performance,perform,performing,2853,"meters in a frequentist way. ToyMCSampler. The primary interface for this class is to return a SamplingDistribution of a given TestStatistic.; The ToyMCSampler had a number of internal changes for improved performance with PROOF. These should be transparent. In addition, a new method was added RooAbsData* GenerateToyData(RooArgSet& paramPoint) that gives public access to the generation of toy data with all the same options for the treatment of nuisance parameters, binned or unbinned data, treatment of the global observables, importance sampling, etc. This is new method particularly useful for producing the expected limit bands where one needs to generate background-only pseudo-experiments in the same way that was used for the primary limit calculation. HypoTestResult. In the process of writing the new HypoTestInverter the conventions for p-values, CLb, CLs+b, and CLs were revisited. The situation is complicated by the fact that when performing a hypothesis test for discovery the null is background-only, but when performing an inverted hypothesis test the null is a signal+background model. The new convention is that the p-value for both the null and the alternate are taken from the same tail (as specified by the test statistic). Both CLs+b and CLb are equivalent to these p-values, and the HypoTestResult has a simple switch SetBackgroundIsAlt() to specify the pairing between (null p-value, alternate p-value) and (CLb, CLs+b). HypoTestInverter, HypoTestInverterResult, HypoTestInverterPlot. These classes have been rewritten for using them with the new hypothesis test calculators. The HypoTestInverter; class can now be constructed by any generic HypoTestCalculator, and both the HybridCalculator and the new; FrequentistCalculator are supported. The HypoTestInverter class can be constructed in two ways: either passing an; HypoTestCalculator and a data set or by passing the model for the signal, for the background and a data set.; In the first case the user configure the Hy",MatchSource.DOCS,roofit/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html:452,Safety,avoid,avoids,452,". RooFit. HistFactory. One of the core classes used by HistFactory models (RooRealSumPdf) was modified leading to substantial speed improvements (for models that use the default -standard_form option). . This new version supports a few types of interpolation for the normalization of the histograms:. code = 0: piece-wise linear (old default); code = 1: piece-wise log (new default); code = 2: parabolic interp with linear extrap ( common at tevatron, avoids kink for asymmetric uncert). The piece-wise logarithmic interpolation paired with a Gaussian constraint is equivalent to a log-normal constraint in a transformed version of the nuisance parameter. The benefit of this approach is that it is easy to avoid the normalization from taking on unphysical negative values. This is the prescription used by the CMS Higgs group, and agreed upon by the LHC Higgs Combination Group. There is not yet XML-based steering for the different interpolation types, but there is a simple script to modify it. . results/example_combined_GaussExample_model.root . Near term goals for HistFactory. Utilities for dealing with Monte Carlo statistical uncertainty in the template histograms; Support for N-D histograms; A new style of histogram variations without a constraint term attached (for shapes determined from control samples); XML steering for interpolation types. RooStats; General Improvements. This release brings several speed improvements to the RooStats tools and improved stability and performance with PROOF. This comes mainly through changes to the ToyMCSampler. In addition the HypoTestInverter tool has been rewritten, leading to some changes in the HypoTestResult. Finally, a new hypothesis test new called FrequentistCalculator was written, which plays the same role as the HybridCalculator but eliminates nuisance parameters in a frequentist way. ToyMCSampler. The primary interface for this class is to return a SamplingDistribution of a given TestStatistic.; The ToyMCSampler had a number of ",MatchSource.DOCS,roofit/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html:707,Safety,avoid,avoid,707,". RooFit. HistFactory. One of the core classes used by HistFactory models (RooRealSumPdf) was modified leading to substantial speed improvements (for models that use the default -standard_form option). . This new version supports a few types of interpolation for the normalization of the histograms:. code = 0: piece-wise linear (old default); code = 1: piece-wise log (new default); code = 2: parabolic interp with linear extrap ( common at tevatron, avoids kink for asymmetric uncert). The piece-wise logarithmic interpolation paired with a Gaussian constraint is equivalent to a log-normal constraint in a transformed version of the nuisance parameter. The benefit of this approach is that it is easy to avoid the normalization from taking on unphysical negative values. This is the prescription used by the CMS Higgs group, and agreed upon by the LHC Higgs Combination Group. There is not yet XML-based steering for the different interpolation types, but there is a simple script to modify it. . results/example_combined_GaussExample_model.root . Near term goals for HistFactory. Utilities for dealing with Monte Carlo statistical uncertainty in the template histograms; Support for N-D histograms; A new style of histogram variations without a constraint term attached (for shapes determined from control samples); XML steering for interpolation types. RooStats; General Improvements. This release brings several speed improvements to the RooStats tools and improved stability and performance with PROOF. This comes mainly through changes to the ToyMCSampler. In addition the HypoTestInverter tool has been rewritten, leading to some changes in the HypoTestResult. Finally, a new hypothesis test new called FrequentistCalculator was written, which plays the same role as the HybridCalculator but eliminates nuisance parameters in a frequentist way. ToyMCSampler. The primary interface for this class is to return a SamplingDistribution of a given TestStatistic.; The ToyMCSampler had a number of ",MatchSource.DOCS,roofit/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html:2189,Security,access,access,2189,"ations without a constraint term attached (for shapes determined from control samples); XML steering for interpolation types. RooStats; General Improvements. This release brings several speed improvements to the RooStats tools and improved stability and performance with PROOF. This comes mainly through changes to the ToyMCSampler. In addition the HypoTestInverter tool has been rewritten, leading to some changes in the HypoTestResult. Finally, a new hypothesis test new called FrequentistCalculator was written, which plays the same role as the HybridCalculator but eliminates nuisance parameters in a frequentist way. ToyMCSampler. The primary interface for this class is to return a SamplingDistribution of a given TestStatistic.; The ToyMCSampler had a number of internal changes for improved performance with PROOF. These should be transparent. In addition, a new method was added RooAbsData* GenerateToyData(RooArgSet& paramPoint) that gives public access to the generation of toy data with all the same options for the treatment of nuisance parameters, binned or unbinned data, treatment of the global observables, importance sampling, etc. This is new method particularly useful for producing the expected limit bands where one needs to generate background-only pseudo-experiments in the same way that was used for the primary limit calculation. HypoTestResult. In the process of writing the new HypoTestInverter the conventions for p-values, CLb, CLs+b, and CLs were revisited. The situation is complicated by the fact that when performing a hypothesis test for discovery the null is background-only, but when performing an inverted hypothesis test the null is a signal+background model. The new convention is that the p-value for both the null and the alternate are taken from the same tail (as specified by the test statistic). Both CLs+b and CLb are equivalent to these p-values, and the HypoTestResult has a simple switch SetBackgroundIsAlt() to specify the pairing between (null p-val",MatchSource.DOCS,roofit/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html:365,Testability,log,log,365,". RooFit. HistFactory. One of the core classes used by HistFactory models (RooRealSumPdf) was modified leading to substantial speed improvements (for models that use the default -standard_form option). . This new version supports a few types of interpolation for the normalization of the histograms:. code = 0: piece-wise linear (old default); code = 1: piece-wise log (new default); code = 2: parabolic interp with linear extrap ( common at tevatron, avoids kink for asymmetric uncert). The piece-wise logarithmic interpolation paired with a Gaussian constraint is equivalent to a log-normal constraint in a transformed version of the nuisance parameter. The benefit of this approach is that it is easy to avoid the normalization from taking on unphysical negative values. This is the prescription used by the CMS Higgs group, and agreed upon by the LHC Higgs Combination Group. There is not yet XML-based steering for the different interpolation types, but there is a simple script to modify it. . results/example_combined_GaussExample_model.root . Near term goals for HistFactory. Utilities for dealing with Monte Carlo statistical uncertainty in the template histograms; Support for N-D histograms; A new style of histogram variations without a constraint term attached (for shapes determined from control samples); XML steering for interpolation types. RooStats; General Improvements. This release brings several speed improvements to the RooStats tools and improved stability and performance with PROOF. This comes mainly through changes to the ToyMCSampler. In addition the HypoTestInverter tool has been rewritten, leading to some changes in the HypoTestResult. Finally, a new hypothesis test new called FrequentistCalculator was written, which plays the same role as the HybridCalculator but eliminates nuisance parameters in a frequentist way. ToyMCSampler. The primary interface for this class is to return a SamplingDistribution of a given TestStatistic.; The ToyMCSampler had a number of ",MatchSource.DOCS,roofit/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html:503,Testability,log,logarithmic,503,". RooFit. HistFactory. One of the core classes used by HistFactory models (RooRealSumPdf) was modified leading to substantial speed improvements (for models that use the default -standard_form option). . This new version supports a few types of interpolation for the normalization of the histograms:. code = 0: piece-wise linear (old default); code = 1: piece-wise log (new default); code = 2: parabolic interp with linear extrap ( common at tevatron, avoids kink for asymmetric uncert). The piece-wise logarithmic interpolation paired with a Gaussian constraint is equivalent to a log-normal constraint in a transformed version of the nuisance parameter. The benefit of this approach is that it is easy to avoid the normalization from taking on unphysical negative values. This is the prescription used by the CMS Higgs group, and agreed upon by the LHC Higgs Combination Group. There is not yet XML-based steering for the different interpolation types, but there is a simple script to modify it. . results/example_combined_GaussExample_model.root . Near term goals for HistFactory. Utilities for dealing with Monte Carlo statistical uncertainty in the template histograms; Support for N-D histograms; A new style of histogram variations without a constraint term attached (for shapes determined from control samples); XML steering for interpolation types. RooStats; General Improvements. This release brings several speed improvements to the RooStats tools and improved stability and performance with PROOF. This comes mainly through changes to the ToyMCSampler. In addition the HypoTestInverter tool has been rewritten, leading to some changes in the HypoTestResult. Finally, a new hypothesis test new called FrequentistCalculator was written, which plays the same role as the HybridCalculator but eliminates nuisance parameters in a frequentist way. ToyMCSampler. The primary interface for this class is to return a SamplingDistribution of a given TestStatistic.; The ToyMCSampler had a number of ",MatchSource.DOCS,roofit/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html:582,Testability,log,log-normal,582,". RooFit. HistFactory. One of the core classes used by HistFactory models (RooRealSumPdf) was modified leading to substantial speed improvements (for models that use the default -standard_form option). . This new version supports a few types of interpolation for the normalization of the histograms:. code = 0: piece-wise linear (old default); code = 1: piece-wise log (new default); code = 2: parabolic interp with linear extrap ( common at tevatron, avoids kink for asymmetric uncert). The piece-wise logarithmic interpolation paired with a Gaussian constraint is equivalent to a log-normal constraint in a transformed version of the nuisance parameter. The benefit of this approach is that it is easy to avoid the normalization from taking on unphysical negative values. This is the prescription used by the CMS Higgs group, and agreed upon by the LHC Higgs Combination Group. There is not yet XML-based steering for the different interpolation types, but there is a simple script to modify it. . results/example_combined_GaussExample_model.root . Near term goals for HistFactory. Utilities for dealing with Monte Carlo statistical uncertainty in the template histograms; Support for N-D histograms; A new style of histogram variations without a constraint term attached (for shapes determined from control samples); XML steering for interpolation types. RooStats; General Improvements. This release brings several speed improvements to the RooStats tools and improved stability and performance with PROOF. This comes mainly through changes to the ToyMCSampler. In addition the HypoTestInverter tool has been rewritten, leading to some changes in the HypoTestResult. Finally, a new hypothesis test new called FrequentistCalculator was written, which plays the same role as the HybridCalculator but eliminates nuisance parameters in a frequentist way. ToyMCSampler. The primary interface for this class is to return a SamplingDistribution of a given TestStatistic.; The ToyMCSampler had a number of ",MatchSource.DOCS,roofit/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html:1696,Testability,test,test,1696,"tive values. This is the prescription used by the CMS Higgs group, and agreed upon by the LHC Higgs Combination Group. There is not yet XML-based steering for the different interpolation types, but there is a simple script to modify it. . results/example_combined_GaussExample_model.root . Near term goals for HistFactory. Utilities for dealing with Monte Carlo statistical uncertainty in the template histograms; Support for N-D histograms; A new style of histogram variations without a constraint term attached (for shapes determined from control samples); XML steering for interpolation types. RooStats; General Improvements. This release brings several speed improvements to the RooStats tools and improved stability and performance with PROOF. This comes mainly through changes to the ToyMCSampler. In addition the HypoTestInverter tool has been rewritten, leading to some changes in the HypoTestResult. Finally, a new hypothesis test new called FrequentistCalculator was written, which plays the same role as the HybridCalculator but eliminates nuisance parameters in a frequentist way. ToyMCSampler. The primary interface for this class is to return a SamplingDistribution of a given TestStatistic.; The ToyMCSampler had a number of internal changes for improved performance with PROOF. These should be transparent. In addition, a new method was added RooAbsData* GenerateToyData(RooArgSet& paramPoint) that gives public access to the generation of toy data with all the same options for the treatment of nuisance parameters, binned or unbinned data, treatment of the global observables, importance sampling, etc. This is new method particularly useful for producing the expected limit bands where one needs to generate background-only pseudo-experiments in the same way that was used for the primary limit calculation. HypoTestResult. In the process of writing the new HypoTestInverter the conventions for p-values, CLb, CLs+b, and CLs were revisited. The situation is complicated by the fact",MatchSource.DOCS,roofit/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html:2796,Testability,test,test,2796,"meters in a frequentist way. ToyMCSampler. The primary interface for this class is to return a SamplingDistribution of a given TestStatistic.; The ToyMCSampler had a number of internal changes for improved performance with PROOF. These should be transparent. In addition, a new method was added RooAbsData* GenerateToyData(RooArgSet& paramPoint) that gives public access to the generation of toy data with all the same options for the treatment of nuisance parameters, binned or unbinned data, treatment of the global observables, importance sampling, etc. This is new method particularly useful for producing the expected limit bands where one needs to generate background-only pseudo-experiments in the same way that was used for the primary limit calculation. HypoTestResult. In the process of writing the new HypoTestInverter the conventions for p-values, CLb, CLs+b, and CLs were revisited. The situation is complicated by the fact that when performing a hypothesis test for discovery the null is background-only, but when performing an inverted hypothesis test the null is a signal+background model. The new convention is that the p-value for both the null and the alternate are taken from the same tail (as specified by the test statistic). Both CLs+b and CLb are equivalent to these p-values, and the HypoTestResult has a simple switch SetBackgroundIsAlt() to specify the pairing between (null p-value, alternate p-value) and (CLb, CLs+b). HypoTestInverter, HypoTestInverterResult, HypoTestInverterPlot. These classes have been rewritten for using them with the new hypothesis test calculators. The HypoTestInverter; class can now be constructed by any generic HypoTestCalculator, and both the HybridCalculator and the new; FrequentistCalculator are supported. The HypoTestInverter class can be constructed in two ways: either passing an; HypoTestCalculator and a data set or by passing the model for the signal, for the background and a data set.; In the first case the user configure the Hy",MatchSource.DOCS,roofit/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html:2887,Testability,test,test,2887,"meters in a frequentist way. ToyMCSampler. The primary interface for this class is to return a SamplingDistribution of a given TestStatistic.; The ToyMCSampler had a number of internal changes for improved performance with PROOF. These should be transparent. In addition, a new method was added RooAbsData* GenerateToyData(RooArgSet& paramPoint) that gives public access to the generation of toy data with all the same options for the treatment of nuisance parameters, binned or unbinned data, treatment of the global observables, importance sampling, etc. This is new method particularly useful for producing the expected limit bands where one needs to generate background-only pseudo-experiments in the same way that was used for the primary limit calculation. HypoTestResult. In the process of writing the new HypoTestInverter the conventions for p-values, CLb, CLs+b, and CLs were revisited. The situation is complicated by the fact that when performing a hypothesis test for discovery the null is background-only, but when performing an inverted hypothesis test the null is a signal+background model. The new convention is that the p-value for both the null and the alternate are taken from the same tail (as specified by the test statistic). Both CLs+b and CLb are equivalent to these p-values, and the HypoTestResult has a simple switch SetBackgroundIsAlt() to specify the pairing between (null p-value, alternate p-value) and (CLb, CLs+b). HypoTestInverter, HypoTestInverterResult, HypoTestInverterPlot. These classes have been rewritten for using them with the new hypothesis test calculators. The HypoTestInverter; class can now be constructed by any generic HypoTestCalculator, and both the HybridCalculator and the new; FrequentistCalculator are supported. The HypoTestInverter class can be constructed in two ways: either passing an; HypoTestCalculator and a data set or by passing the model for the signal, for the background and a data set.; In the first case the user configure the Hy",MatchSource.DOCS,roofit/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html:3056,Testability,test,test,3056,"internal changes for improved performance with PROOF. These should be transparent. In addition, a new method was added RooAbsData* GenerateToyData(RooArgSet& paramPoint) that gives public access to the generation of toy data with all the same options for the treatment of nuisance parameters, binned or unbinned data, treatment of the global observables, importance sampling, etc. This is new method particularly useful for producing the expected limit bands where one needs to generate background-only pseudo-experiments in the same way that was used for the primary limit calculation. HypoTestResult. In the process of writing the new HypoTestInverter the conventions for p-values, CLb, CLs+b, and CLs were revisited. The situation is complicated by the fact that when performing a hypothesis test for discovery the null is background-only, but when performing an inverted hypothesis test the null is a signal+background model. The new convention is that the p-value for both the null and the alternate are taken from the same tail (as specified by the test statistic). Both CLs+b and CLb are equivalent to these p-values, and the HypoTestResult has a simple switch SetBackgroundIsAlt() to specify the pairing between (null p-value, alternate p-value) and (CLb, CLs+b). HypoTestInverter, HypoTestInverterResult, HypoTestInverterPlot. These classes have been rewritten for using them with the new hypothesis test calculators. The HypoTestInverter; class can now be constructed by any generic HypoTestCalculator, and both the HybridCalculator and the new; FrequentistCalculator are supported. The HypoTestInverter class can be constructed in two ways: either passing an; HypoTestCalculator and a data set or by passing the model for the signal, for the background and a data set.; In the first case the user configure the HypoTestCalculator before passing to the HypoTestInverter.; It must be configured using as null model the signal plus background model as alternate model the background; model. O",MatchSource.DOCS,roofit/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html:3410,Testability,test,test,3410," This is new method particularly useful for producing the expected limit bands where one needs to generate background-only pseudo-experiments in the same way that was used for the primary limit calculation. HypoTestResult. In the process of writing the new HypoTestInverter the conventions for p-values, CLb, CLs+b, and CLs were revisited. The situation is complicated by the fact that when performing a hypothesis test for discovery the null is background-only, but when performing an inverted hypothesis test the null is a signal+background model. The new convention is that the p-value for both the null and the alternate are taken from the same tail (as specified by the test statistic). Both CLs+b and CLb are equivalent to these p-values, and the HypoTestResult has a simple switch SetBackgroundIsAlt() to specify the pairing between (null p-value, alternate p-value) and (CLb, CLs+b). HypoTestInverter, HypoTestInverterResult, HypoTestInverterPlot. These classes have been rewritten for using them with the new hypothesis test calculators. The HypoTestInverter; class can now be constructed by any generic HypoTestCalculator, and both the HybridCalculator and the new; FrequentistCalculator are supported. The HypoTestInverter class can be constructed in two ways: either passing an; HypoTestCalculator and a data set or by passing the model for the signal, for the background and a data set.; In the first case the user configure the HypoTestCalculator before passing to the HypoTestInverter.; It must be configured using as null model the signal plus background model as alternate model the background; model. Optionally the user can pass the parameter to scan, if it is not passed, the first parameter of interest of the; null model will be used. In the second case (when passing directly the model and the data) the HypoTestInverter; can be configured to use either the frequentist or the hybrid calculator. The user can then configure the class; afterwards. For example set the test statis",MatchSource.DOCS,roofit/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html:4371,Testability,test,test,4371,"poTestInverter; class can now be constructed by any generic HypoTestCalculator, and both the HybridCalculator and the new; FrequentistCalculator are supported. The HypoTestInverter class can be constructed in two ways: either passing an; HypoTestCalculator and a data set or by passing the model for the signal, for the background and a data set.; In the first case the user configure the HypoTestCalculator before passing to the HypoTestInverter.; It must be configured using as null model the signal plus background model as alternate model the background; model. Optionally the user can pass the parameter to scan, if it is not passed, the first parameter of interest of the; null model will be used. In the second case (when passing directly the model and the data) the HypoTestInverter; can be configured to use either the frequentist or the hybrid calculator. The user can then configure the class; afterwards. For example set the test statistic to use via the method SetTestStatistic, number of toys to run; for each hypothesis, by retrieving the contained HypoTestCalculator:. HypoTestInverter inverter(obsData, model_B, model_SB, parameterToScan, HypoTestInverter::kFrequentist);; ProfileLikelihoodRatioTestStat profLR( *model_SB->GetPdf() );; inverter.SetTestStatistic(&profLR);; FrequentistCalculator * htcalc = (FrequentistCalculator*) inverter.GetHypoTestCalculator();; htcalc->SetToys( ntoySB, ntoyB);. The Inverter can then run using a fixed grid of npoint between xmin and xmax or by using an automatic scan, where a; bisection algorithm is used.; For running a fixed grid one needs to call SetFixedScan(npoints, xmin, xmax), while for running an autoscan use; the function SetAutoScan. The result is returned in the GetInterval function as an; HypoTestInverterResult class. If a fixed grid is used the upper limit is obtained by using a interpolation on; the scanned points. The interpolation can be linear or a spline (if; result.SetInterpolationOption(HypoTestInverterResult::kSpli",MatchSource.DOCS,roofit/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html:6992,Testability,test,tested,6992,"call SetFixedScan(npoints, xmin, xmax), while for running an autoscan use; the function SetAutoScan. The result is returned in the GetInterval function as an; HypoTestInverterResult class. If a fixed grid is used the upper limit is obtained by using a interpolation on; the scanned points. The interpolation can be linear or a spline (if; result.SetInterpolationOption(HypoTestInverterResult::kSpline) is called).; The upper limit, the expected P value distributions and also the upper limit distributions can be obtained from the; result class. . HypoTestInverterResult * result = inverter.GetInterval();; double upperLimit = result->UpperLimit();; double expectedLimit = result->GetExpectedUpperLimit(0);. The limit values, p values and bands can be drawn using the HypoTestInverterPlot class. Example:. HypoTestInverterPlot * plot = new HypoTestInverterPlot(""Result"",""POI Scan Result"",result);; plot->Draw(""2CL CLb"");. Where the Draw option ""2CL CLb"" draws in addition to the observed limit and bands, the observed CLs+b and CLb.; The result is shown in this figure:. FrequentistCalculator; This is a HypoTestCalculator that returns a HypoTestResult similar to the HybridCalculator. The primary difference is that this tool profiles the nuisance parameters for the null model and uses those fixed values of the nuisance parameters for generating the pseudo-experiments, where the HybridCalculator smears/randomizes/marginalizes the nuisance parameters. BayesianCalculator; Several improvements have been put in the class. In particular the possibility to set different integration types. One; can set the different integration types available in the ROOT integration routines; (ADAPTIVE, VEGAS, MISER, PLAIN for multi-dimension). In addition one can use an integration types by generating nuisance; toy MC (method TOYMC). If the nuisance parameters are uncorrelated, this last method can scale up for a large number of; nuisance parameters. It has been tested to work up to 50-100 parameters. ; ; ",MatchSource.DOCS,roofit/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html:970,Usability,simpl,simple,970,". RooFit. HistFactory. One of the core classes used by HistFactory models (RooRealSumPdf) was modified leading to substantial speed improvements (for models that use the default -standard_form option). . This new version supports a few types of interpolation for the normalization of the histograms:. code = 0: piece-wise linear (old default); code = 1: piece-wise log (new default); code = 2: parabolic interp with linear extrap ( common at tevatron, avoids kink for asymmetric uncert). The piece-wise logarithmic interpolation paired with a Gaussian constraint is equivalent to a log-normal constraint in a transformed version of the nuisance parameter. The benefit of this approach is that it is easy to avoid the normalization from taking on unphysical negative values. This is the prescription used by the CMS Higgs group, and agreed upon by the LHC Higgs Combination Group. There is not yet XML-based steering for the different interpolation types, but there is a simple script to modify it. . results/example_combined_GaussExample_model.root . Near term goals for HistFactory. Utilities for dealing with Monte Carlo statistical uncertainty in the template histograms; Support for N-D histograms; A new style of histogram variations without a constraint term attached (for shapes determined from control samples); XML steering for interpolation types. RooStats; General Improvements. This release brings several speed improvements to the RooStats tools and improved stability and performance with PROOF. This comes mainly through changes to the ToyMCSampler. In addition the HypoTestInverter tool has been rewritten, leading to some changes in the HypoTestResult. Finally, a new hypothesis test new called FrequentistCalculator was written, which plays the same role as the HybridCalculator but eliminates nuisance parameters in a frequentist way. ToyMCSampler. The primary interface for this class is to return a SamplingDistribution of a given TestStatistic.; The ToyMCSampler had a number of ",MatchSource.DOCS,roofit/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html:3155,Usability,simpl,simple,3155,"hat gives public access to the generation of toy data with all the same options for the treatment of nuisance parameters, binned or unbinned data, treatment of the global observables, importance sampling, etc. This is new method particularly useful for producing the expected limit bands where one needs to generate background-only pseudo-experiments in the same way that was used for the primary limit calculation. HypoTestResult. In the process of writing the new HypoTestInverter the conventions for p-values, CLb, CLs+b, and CLs were revisited. The situation is complicated by the fact that when performing a hypothesis test for discovery the null is background-only, but when performing an inverted hypothesis test the null is a signal+background model. The new convention is that the p-value for both the null and the alternate are taken from the same tail (as specified by the test statistic). Both CLs+b and CLb are equivalent to these p-values, and the HypoTestResult has a simple switch SetBackgroundIsAlt() to specify the pairing between (null p-value, alternate p-value) and (CLb, CLs+b). HypoTestInverter, HypoTestInverterResult, HypoTestInverterPlot. These classes have been rewritten for using them with the new hypothesis test calculators. The HypoTestInverter; class can now be constructed by any generic HypoTestCalculator, and both the HybridCalculator and the new; FrequentistCalculator are supported. The HypoTestInverter class can be constructed in two ways: either passing an; HypoTestCalculator and a data set or by passing the model for the signal, for the background and a data set.; In the first case the user configure the HypoTestCalculator before passing to the HypoTestInverter.; It must be configured using as null model the signal plus background model as alternate model the background; model. Optionally the user can pass the parameter to scan, if it is not passed, the first parameter of interest of the; null model will be used. In the second case (when passing d",MatchSource.DOCS,roofit/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html:8946,Availability,robust,robust,8946,"ata and then; it is used to evaluate the likelihood. ; ; This class implements the HypoTestCalculatorGeneric interface and can be used as an alternative Hypothesis test; calculator in the HypoTestInverter class. It can then plugged in the HypoTestInverter for computing asymptotic CLs and CLs+b; limits. In this way the limits will be computed by just performing a fit for each test parameter value and without; generating any toys. . The class can be used via the StandardHypothesisTest.C tutorial passing a value of 2 for the; calculator type. . RooStats Utils. Add a utility function (from G. Petrucciani), RooStats::MakeNuisancePdf, which given a model configuration (or the global pdf and the; observables), factorizes from the model pdf the constraint probability density functions for the nuisance parameters; and builds a global nuisance pdf. This function can then be used in the HybridCalculator or in the BayesianCalculator; with the option ""TOYMC"".; . HypotestInverter and HypoTestInverterResult. Several improvements and bug fixes in merging results and in computing the observed and expected limits.; Provide support now for using the AsympoticCalculator. MCMCCalculator. Add now possibility to store in the chain only the parameter of interested via the method MCMCCalculator::SetChainParameters. This saves memory in case of models with a; large number of nuisance parameters. . Test Statistics classes. Make a more robust evaluation of the ProfileLikelihoodTestStat. Use RooMinimizer and give possibility to use; different minimizer, via ProfileLikelihoodTestStat::SetMinimizer. The print level of minimization can also be; controlled via ProfileLikelihoodTestStat::SetPrintLevel. Activate also the RooFit cache optimizations when; evaluating the NLL ; The same optimizations are applied also to the RatioOfProfilesLikelihood test statistic; Fix a bug in reusing the NLL object in the SimpleLikelihoodCalculator. This makes now the evaluation of this test; statistics much faster. . ",MatchSource.DOCS,roofit/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html:2784,Deployability,update,updated,2784,"ew algorithmic optimization in the caching of pdfs. So far - in the likelihood - two classes of; objects are identified: those that change with every event (i.e. the pdf) and those that change; only with the parameters (typically pdf normalization integrals). Pdfs are always recalculated; for every event, whereas integrals are only evaluated when needed. The exception to the first type are pdfs; that only depend on constant parameters (or no parameters) - these are identified at the beginning, and precalculated once ; to avoid recalculating an expression with the same outcome for every iteration of the likelihood calculation. For composite pdfs a further optimization has been included: for a M(x,a,b) = f*F(x,a)+(1-f)G(x,b) ; it is e.g. not needed to recalculate G(x,b) if only parameter a has changed w.r.t to the previous likelihood; calculation. This optimization is now implemented by extending the value caching originally designed; for constant terms to be usable for non-constant terms, with a check executed at the beginning of each; likelihood evaluation if selected columns need to be updated because parameters have changed. The speed gain; of this optimization depends much on the structure of the pdf: in models with many free parameters most of the; likelihood evaluations are executed when MINUIT calculates numerical likelihood derivatives which vary ; one parameter at a time and the speedup is potentially larger. In models with few free parameters the; effect will be smaller. The new per-component caching strategy is enabled by default for all pdfs that are a component of; a RooAddPdf or a RooRealSumPdf, unless that component is a RooProdPdf or a RooProduct, in that; case the components of the product are cached instead of the product itself. You can disable this; new optimization by adding Optimize(1) to the RooAbsPdf::fitTo() command line (0 = no caching,; 1 = cache constant terms only, 2 = cache also variable terms according to above mentioned strategy (DEFAUL",MatchSource.DOCS,roofit/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html:8171,Deployability,configurat,configuration,8171,"value for the null and also for the alternate using the Asimov data set. In this; differs form the ProfileLikelihoodCalculator which computes only the p-values for the null hypothesis.; The Asimov data set is generated with the utility function AsymptoticCalculator::MakeAsimovData and then; it is used to evaluate the likelihood. ; ; This class implements the HypoTestCalculatorGeneric interface and can be used as an alternative Hypothesis test; calculator in the HypoTestInverter class. It can then plugged in the HypoTestInverter for computing asymptotic CLs and CLs+b; limits. In this way the limits will be computed by just performing a fit for each test parameter value and without; generating any toys. . The class can be used via the StandardHypothesisTest.C tutorial passing a value of 2 for the; calculator type. . RooStats Utils. Add a utility function (from G. Petrucciani), RooStats::MakeNuisancePdf, which given a model configuration (or the global pdf and the; observables), factorizes from the model pdf the constraint probability density functions for the nuisance parameters; and builds a global nuisance pdf. This function can then be used in the HybridCalculator or in the BayesianCalculator; with the option ""TOYMC"".; . HypotestInverter and HypoTestInverterResult. Several improvements and bug fixes in merging results and in computing the observed and expected limits.; Provide support now for using the AsympoticCalculator. MCMCCalculator. Add now possibility to store in the chain only the parameter of interested via the method MCMCCalculator::SetChainParameters. This saves memory in case of models with a; large number of nuisance parameters. . Test Statistics classes. Make a more robust evaluation of the ProfileLikelihoodTestStat. Use RooMinimizer and give possibility to use; different minimizer, via ProfileLikelihoodTestStat::SetMinimizer. The print level of minimization can also be; controlled via ProfileLikelihoodTestStat::SetPrintLevel. Activate also the RooFit ",MatchSource.DOCS,roofit/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html:6694,Energy Efficiency,reduce,reduce,6694,"ibly binned by adding GenBinned(tagname); to generate(). In that case all component pdfs labeled with pdf->setAttribute(tagname) will be generated; binned. To generate all component binned, the shorthand method AllBinned() can be used. All binned; datasets made by generate are represented as weighted unbinned datasets (of type RooDataSet) rather; than binned datasets of type RooDataHist so that mixed binned/unbinned data is always represented; through a uniform interface. Fix in the optimization strategy of likelihoods constructed from simultaneous pdf. In the parameter; dependency analysis of the components of a simultaneous pdfs parameters originating from 'irrelevant'; constraint terms (i.e. those that don't relate to any of the parameters of that likelihood component) were; not ignored, which could result in a substantial loss of computational efficiency as likelihood; terms were erroneously recalculated even if no relevant parameters was changed. General performance tuning of RooFit to reduce computational overhead. Extensive profiling of; CPU times in call graphas and analysis heap memory use have been performed and many small ; changes have been made to make the code more efficient and use less memory. RooStats Package; AsymptoticCalculator. New Class for doing an hypothesis tests using the asymptotic likelihood formulae, described in the paper from; G. Cowan, K. Cranmer, E. Gross and O. Vitells, Asymptotic formulae for likelihood- based tests of new physics,; Eur. Phys. J., C71 (1), 2011.; The class computes the p-value for the null and also for the alternate using the Asimov data set. In this; differs form the ProfileLikelihoodCalculator which computes only the p-values for the null hypothesis.; The Asimov data set is generated with the utility function AsymptoticCalculator::MakeAsimovData and then; it is used to evaluate the likelihood. ; ; This class implements the HypoTestCalculatorGeneric interface and can be used as an alternative Hypothesis test; calcu",MatchSource.DOCS,roofit/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html:6886,Energy Efficiency,efficient,efficient,6886,"l be generated; binned. To generate all component binned, the shorthand method AllBinned() can be used. All binned; datasets made by generate are represented as weighted unbinned datasets (of type RooDataSet) rather; than binned datasets of type RooDataHist so that mixed binned/unbinned data is always represented; through a uniform interface. Fix in the optimization strategy of likelihoods constructed from simultaneous pdf. In the parameter; dependency analysis of the components of a simultaneous pdfs parameters originating from 'irrelevant'; constraint terms (i.e. those that don't relate to any of the parameters of that likelihood component) were; not ignored, which could result in a substantial loss of computational efficiency as likelihood; terms were erroneously recalculated even if no relevant parameters was changed. General performance tuning of RooFit to reduce computational overhead. Extensive profiling of; CPU times in call graphas and analysis heap memory use have been performed and many small ; changes have been made to make the code more efficient and use less memory. RooStats Package; AsymptoticCalculator. New Class for doing an hypothesis tests using the asymptotic likelihood formulae, described in the paper from; G. Cowan, K. Cranmer, E. Gross and O. Vitells, Asymptotic formulae for likelihood- based tests of new physics,; Eur. Phys. J., C71 (1), 2011.; The class computes the p-value for the null and also for the alternate using the Asimov data set. In this; differs form the ProfileLikelihoodCalculator which computes only the p-values for the null hypothesis.; The Asimov data set is generated with the utility function AsymptoticCalculator::MakeAsimovData and then; it is used to evaluate the likelihood. ; ; This class implements the HypoTestCalculatorGeneric interface and can be used as an alternative Hypothesis test; calculator in the HypoTestInverter class. It can then plugged in the HypoTestInverter for computing asymptotic CLs and CLs+b; limits. In",MatchSource.DOCS,roofit/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html:2089,Integrability,depend,depend,2089,"ng constant-term precalculation optimization in roofit likelihoods as these are now; also stored in vectors rather than trees. The faster access speed of vectors make that the constant; term optimization inside likelihoods results in a larger speed increase. This is particulatly noticeable in pdfs with; many constant expressions from pdfs that were moderately fast to begin with (e.g. RooHistPdf).; The second advantages allows new types of algorithmic likelihood optimization in RooFit detailed below. New algorithmic optimization in the caching of pdfs. So far - in the likelihood - two classes of; objects are identified: those that change with every event (i.e. the pdf) and those that change; only with the parameters (typically pdf normalization integrals). Pdfs are always recalculated; for every event, whereas integrals are only evaluated when needed. The exception to the first type are pdfs; that only depend on constant parameters (or no parameters) - these are identified at the beginning, and precalculated once ; to avoid recalculating an expression with the same outcome for every iteration of the likelihood calculation. For composite pdfs a further optimization has been included: for a M(x,a,b) = f*F(x,a)+(1-f)G(x,b) ; it is e.g. not needed to recalculate G(x,b) if only parameter a has changed w.r.t to the previous likelihood; calculation. This optimization is now implemented by extending the value caching originally designed; for constant terms to be usable for non-constant terms, with a check executed at the beginning of each; likelihood evaluation if selected columns need to be updated because parameters have changed. The speed gain; of this optimization depends much on the structure of the pdf: in models with many free parameters most of the; likelihood evaluations are executed when MINUIT calculates numerical likelihood derivatives which vary ; one parameter at a time and the speedup is potentially larger. In models with few free parameters the; effect will be",MatchSource.DOCS,roofit/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html:2862,Integrability,depend,depends,2862,"r every event, whereas integrals are only evaluated when needed. The exception to the first type are pdfs; that only depend on constant parameters (or no parameters) - these are identified at the beginning, and precalculated once ; to avoid recalculating an expression with the same outcome for every iteration of the likelihood calculation. For composite pdfs a further optimization has been included: for a M(x,a,b) = f*F(x,a)+(1-f)G(x,b) ; it is e.g. not needed to recalculate G(x,b) if only parameter a has changed w.r.t to the previous likelihood; calculation. This optimization is now implemented by extending the value caching originally designed; for constant terms to be usable for non-constant terms, with a check executed at the beginning of each; likelihood evaluation if selected columns need to be updated because parameters have changed. The speed gain; of this optimization depends much on the structure of the pdf: in models with many free parameters most of the; likelihood evaluations are executed when MINUIT calculates numerical likelihood derivatives which vary ; one parameter at a time and the speedup is potentially larger. In models with few free parameters the; effect will be smaller. The new per-component caching strategy is enabled by default for all pdfs that are a component of; a RooAddPdf or a RooRealSumPdf, unless that component is a RooProdPdf or a RooProduct, in that; case the components of the product are cached instead of the product itself. You can disable this; new optimization by adding Optimize(1) to the RooAbsPdf::fitTo() command line (0 = no caching,; 1 = cache constant terms only, 2 = cache also variable terms according to above mentioned strategy (DEFAULT)). It is also possible to tune this 'cache-and-track' optimization to perform a more fine-grained caching; of components than Optimize(2) implements: to do so, call arg->setAttribute(""CacheAndTrack"") on each; pdf component that you'd like to be cache-and-tracked individually. New pdf/data",MatchSource.DOCS,roofit/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html:6154,Integrability,interface,interface,6154,"bin smaller than nevent). The optimization is also exact: the likelihood of a binned ; data using a binned pdf is identical to that of an unbinned dataset with a binned pdf. Nevertheless you can ; switch off this feature by passing AutoBinned(false) to RooAbsPdf::generate(). Mixed binned/unbinned generation from simultaneous pdf. For a RooSimultaneous consisting of exclusively; extended terms it is now possible to generate a mixed binned/unbinned datasets. Components defined; by a binned pdf at the top level are automatically generated binned (unless AutoBinned(false) is set); but it is also possible to generate other component pdfs forcibly binned by adding GenBinned(tagname); to generate(). In that case all component pdfs labeled with pdf->setAttribute(tagname) will be generated; binned. To generate all component binned, the shorthand method AllBinned() can be used. All binned; datasets made by generate are represented as weighted unbinned datasets (of type RooDataSet) rather; than binned datasets of type RooDataHist so that mixed binned/unbinned data is always represented; through a uniform interface. Fix in the optimization strategy of likelihoods constructed from simultaneous pdf. In the parameter; dependency analysis of the components of a simultaneous pdfs parameters originating from 'irrelevant'; constraint terms (i.e. those that don't relate to any of the parameters of that likelihood component) were; not ignored, which could result in a substantial loss of computational efficiency as likelihood; terms were erroneously recalculated even if no relevant parameters was changed. General performance tuning of RooFit to reduce computational overhead. Extensive profiling of; CPU times in call graphas and analysis heap memory use have been performed and many small ; changes have been made to make the code more efficient and use less memory. RooStats Package; AsymptoticCalculator. New Class for doing an hypothesis tests using the asymptotic likelihood formulae, descr",MatchSource.DOCS,roofit/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html:6266,Integrability,depend,dependency,6266," Mixed binned/unbinned generation from simultaneous pdf. For a RooSimultaneous consisting of exclusively; extended terms it is now possible to generate a mixed binned/unbinned datasets. Components defined; by a binned pdf at the top level are automatically generated binned (unless AutoBinned(false) is set); but it is also possible to generate other component pdfs forcibly binned by adding GenBinned(tagname); to generate(). In that case all component pdfs labeled with pdf->setAttribute(tagname) will be generated; binned. To generate all component binned, the shorthand method AllBinned() can be used. All binned; datasets made by generate are represented as weighted unbinned datasets (of type RooDataSet) rather; than binned datasets of type RooDataHist so that mixed binned/unbinned data is always represented; through a uniform interface. Fix in the optimization strategy of likelihoods constructed from simultaneous pdf. In the parameter; dependency analysis of the components of a simultaneous pdfs parameters originating from 'irrelevant'; constraint terms (i.e. those that don't relate to any of the parameters of that likelihood component) were; not ignored, which could result in a substantial loss of computational efficiency as likelihood; terms were erroneously recalculated even if no relevant parameters was changed. General performance tuning of RooFit to reduce computational overhead. Extensive profiling of; CPU times in call graphas and analysis heap memory use have been performed and many small ; changes have been made to make the code more efficient and use less memory. RooStats Package; AsymptoticCalculator. New Class for doing an hypothesis tests using the asymptotic likelihood formulae, described in the paper from; G. Cowan, K. Cranmer, E. Gross and O. Vitells, Asymptotic formulae for likelihood- based tests of new physics,; Eur. Phys. J., C71 (1), 2011.; The class computes the p-value for the null and also for the alternate using the Asimov data set. In this; ",MatchSource.DOCS,roofit/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html:7623,Integrability,interface,interface,7623,"changed. General performance tuning of RooFit to reduce computational overhead. Extensive profiling of; CPU times in call graphas and analysis heap memory use have been performed and many small ; changes have been made to make the code more efficient and use less memory. RooStats Package; AsymptoticCalculator. New Class for doing an hypothesis tests using the asymptotic likelihood formulae, described in the paper from; G. Cowan, K. Cranmer, E. Gross and O. Vitells, Asymptotic formulae for likelihood- based tests of new physics,; Eur. Phys. J., C71 (1), 2011.; The class computes the p-value for the null and also for the alternate using the Asimov data set. In this; differs form the ProfileLikelihoodCalculator which computes only the p-values for the null hypothesis.; The Asimov data set is generated with the utility function AsymptoticCalculator::MakeAsimovData and then; it is used to evaluate the likelihood. ; ; This class implements the HypoTestCalculatorGeneric interface and can be used as an alternative Hypothesis test; calculator in the HypoTestInverter class. It can then plugged in the HypoTestInverter for computing asymptotic CLs and CLs+b; limits. In this way the limits will be computed by just performing a fit for each test parameter value and without; generating any toys. . The class can be used via the StandardHypothesisTest.C tutorial passing a value of 2 for the; calculator type. . RooStats Utils. Add a utility function (from G. Petrucciani), RooStats::MakeNuisancePdf, which given a model configuration (or the global pdf and the; observables), factorizes from the model pdf the constraint probability density functions for the nuisance parameters; and builds a global nuisance pdf. This function can then be used in the HybridCalculator or in the BayesianCalculator; with the option ""TOYMC"".; . HypotestInverter and HypoTestInverterResult. Several improvements and bug fixes in merging results and in computing the observed and expected limits.; Provide support n",MatchSource.DOCS,roofit/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html:1098,Modifiability,rewrite,rewrite,1098,". RooFit Package. RooFit 3.50 has undergone a substantial amount of core engineering to improve computational efficiency; and improve algorithmic likelihood optimizations. The expected increases in execution speed range from; roughly 20% (for problems that were already implemented in a close-to optimal form) to more than 2000%; for certain type of problems. Below is a summary of the changes made. All of these changes are; transparent to end-use cases ; ; ; New implementation of RooFit data types. The implementation of data stored in RooDataSet and RooDataHist; was historically handled by ROOT TTrees (though class RooTreeDataStore). The default storage type; has now been changed to class RooVectorDataStore which stores the information in STL arrays. Existing; datasets based on trees can be read in transparently, and are converted to vector form in the ; persistent-to-transient conversion (the datafile is not modified in this operation); ; The vector store has two important advantages: 1) faster data access (raw data access times are 70 times ; faster than for TTrees), 2) ability to rewrite columns on the fly. The first advantage is important; for the existing constant-term precalculation optimization in roofit likelihoods as these are now; also stored in vectors rather than trees. The faster access speed of vectors make that the constant; term optimization inside likelihoods results in a larger speed increase. This is particulatly noticeable in pdfs with; many constant expressions from pdfs that were moderately fast to begin with (e.g. RooHistPdf).; The second advantages allows new types of algorithmic likelihood optimization in RooFit detailed below. New algorithmic optimization in the caching of pdfs. So far - in the likelihood - two classes of; objects are identified: those that change with every event (i.e. the pdf) and those that change; only with the parameters (typically pdf normalization integrals). Pdfs are always recalculated; for every event, whereas integr",MatchSource.DOCS,roofit/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html:2578,Modifiability,extend,extending,2578,"ew algorithmic optimization in the caching of pdfs. So far - in the likelihood - two classes of; objects are identified: those that change with every event (i.e. the pdf) and those that change; only with the parameters (typically pdf normalization integrals). Pdfs are always recalculated; for every event, whereas integrals are only evaluated when needed. The exception to the first type are pdfs; that only depend on constant parameters (or no parameters) - these are identified at the beginning, and precalculated once ; to avoid recalculating an expression with the same outcome for every iteration of the likelihood calculation. For composite pdfs a further optimization has been included: for a M(x,a,b) = f*F(x,a)+(1-f)G(x,b) ; it is e.g. not needed to recalculate G(x,b) if only parameter a has changed w.r.t to the previous likelihood; calculation. This optimization is now implemented by extending the value caching originally designed; for constant terms to be usable for non-constant terms, with a check executed at the beginning of each; likelihood evaluation if selected columns need to be updated because parameters have changed. The speed gain; of this optimization depends much on the structure of the pdf: in models with many free parameters most of the; likelihood evaluations are executed when MINUIT calculates numerical likelihood derivatives which vary ; one parameter at a time and the speedup is potentially larger. In models with few free parameters the; effect will be smaller. The new per-component caching strategy is enabled by default for all pdfs that are a component of; a RooAddPdf or a RooRealSumPdf, unless that component is a RooProdPdf or a RooProduct, in that; case the components of the product are cached instead of the product itself. You can disable this; new optimization by adding Optimize(1) to the RooAbsPdf::fitTo() command line (0 = no caching,; 1 = cache constant terms only, 2 = cache also variable terms according to above mentioned strategy (DEFAUL",MatchSource.DOCS,roofit/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html:3621,Modifiability,variab,variable,3621,"nted by extending the value caching originally designed; for constant terms to be usable for non-constant terms, with a check executed at the beginning of each; likelihood evaluation if selected columns need to be updated because parameters have changed. The speed gain; of this optimization depends much on the structure of the pdf: in models with many free parameters most of the; likelihood evaluations are executed when MINUIT calculates numerical likelihood derivatives which vary ; one parameter at a time and the speedup is potentially larger. In models with few free parameters the; effect will be smaller. The new per-component caching strategy is enabled by default for all pdfs that are a component of; a RooAddPdf or a RooRealSumPdf, unless that component is a RooProdPdf or a RooProduct, in that; case the components of the product are cached instead of the product itself. You can disable this; new optimization by adding Optimize(1) to the RooAbsPdf::fitTo() command line (0 = no caching,; 1 = cache constant terms only, 2 = cache also variable terms according to above mentioned strategy (DEFAULT)). It is also possible to tune this 'cache-and-track' optimization to perform a more fine-grained caching; of components than Optimize(2) implements: to do so, call arg->setAttribute(""CacheAndTrack"") on each; pdf component that you'd like to be cache-and-tracked individually. New pdf/data attach mechanism in likelihood objects (RooAbsOptTestStatistic). The new mechanism only; reattaches the dataset branch buffers and not the RooRealVars representing the data. This new designs; allows for a much faster RooAbsTestStatistic::setData() implementation, which changes the dataset in; an existing likelihood object. This will speed up RooStats tools based on 'simple' likelihood models; substantially. Automatic detections of 'binned' pdfs and automatic generation of binned data in generate(). RooFit will; now automatically generate binned pdf shapes. Binned pdfs shapes are fundamentall",MatchSource.DOCS,roofit/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html:5424,Modifiability,extend,extended,5424,"neration of binned data in generate(). RooFit will; now automatically generate binned pdf shapes. Binned pdfs shapes are fundamentally RooHistPdf and RooHistFuncs; (with interpolation order set to zero). Products and sums of exclusively binned shapes are also recognized; as binned shapes. For such binned shapes generate() will now by default follow the 'binned' strategy ; -- that is, take the expectation value in each bin and sample a Poisson distribution from that -- rather; than follow the unbinned strategy. The rationale is that such datasets result in much faster likelihood; calculations (for nbin smaller than nevent). The optimization is also exact: the likelihood of a binned ; data using a binned pdf is identical to that of an unbinned dataset with a binned pdf. Nevertheless you can ; switch off this feature by passing AutoBinned(false) to RooAbsPdf::generate(). Mixed binned/unbinned generation from simultaneous pdf. For a RooSimultaneous consisting of exclusively; extended terms it is now possible to generate a mixed binned/unbinned datasets. Components defined; by a binned pdf at the top level are automatically generated binned (unless AutoBinned(false) is set); but it is also possible to generate other component pdfs forcibly binned by adding GenBinned(tagname); to generate(). In that case all component pdfs labeled with pdf->setAttribute(tagname) will be generated; binned. To generate all component binned, the shorthand method AllBinned() can be used. All binned; datasets made by generate are represented as weighted unbinned datasets (of type RooDataSet) rather; than binned datasets of type RooDataHist so that mixed binned/unbinned data is always represented; through a uniform interface. Fix in the optimization strategy of likelihoods constructed from simultaneous pdf. In the parameter; dependency analysis of the components of a simultaneous pdfs parameters originating from 'irrelevant'; constraint terms (i.e. those that don't relate to any of the parameter",MatchSource.DOCS,roofit/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html:8171,Modifiability,config,configuration,8171,"value for the null and also for the alternate using the Asimov data set. In this; differs form the ProfileLikelihoodCalculator which computes only the p-values for the null hypothesis.; The Asimov data set is generated with the utility function AsymptoticCalculator::MakeAsimovData and then; it is used to evaluate the likelihood. ; ; This class implements the HypoTestCalculatorGeneric interface and can be used as an alternative Hypothesis test; calculator in the HypoTestInverter class. It can then plugged in the HypoTestInverter for computing asymptotic CLs and CLs+b; limits. In this way the limits will be computed by just performing a fit for each test parameter value and without; generating any toys. . The class can be used via the StandardHypothesisTest.C tutorial passing a value of 2 for the; calculator type. . RooStats Utils. Add a utility function (from G. Petrucciani), RooStats::MakeNuisancePdf, which given a model configuration (or the global pdf and the; observables), factorizes from the model pdf the constraint probability density functions for the nuisance parameters; and builds a global nuisance pdf. This function can then be used in the HybridCalculator or in the BayesianCalculator; with the option ""TOYMC"".; . HypotestInverter and HypoTestInverterResult. Several improvements and bug fixes in merging results and in computing the observed and expected limits.; Provide support now for using the AsympoticCalculator. MCMCCalculator. Add now possibility to store in the chain only the parameter of interested via the method MCMCCalculator::SetChainParameters. This saves memory in case of models with a; large number of nuisance parameters. . Test Statistics classes. Make a more robust evaluation of the ProfileLikelihoodTestStat. Use RooMinimizer and give possibility to use; different minimizer, via ProfileLikelihoodTestStat::SetMinimizer. The print level of minimization can also be; controlled via ProfileLikelihoodTestStat::SetPrintLevel. Activate also the RooFit ",MatchSource.DOCS,roofit/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html:157,Performance,optimiz,optimizations,157,". RooFit Package. RooFit 3.50 has undergone a substantial amount of core engineering to improve computational efficiency; and improve algorithmic likelihood optimizations. The expected increases in execution speed range from; roughly 20% (for problems that were already implemented in a close-to optimal form) to more than 2000%; for certain type of problems. Below is a summary of the changes made. All of these changes are; transparent to end-use cases ; ; ; New implementation of RooFit data types. The implementation of data stored in RooDataSet and RooDataHist; was historically handled by ROOT TTrees (though class RooTreeDataStore). The default storage type; has now been changed to class RooVectorDataStore which stores the information in STL arrays. Existing; datasets based on trees can be read in transparently, and are converted to vector form in the ; persistent-to-transient conversion (the datafile is not modified in this operation); ; The vector store has two important advantages: 1) faster data access (raw data access times are 70 times ; faster than for TTrees), 2) ability to rewrite columns on the fly. The first advantage is important; for the existing constant-term precalculation optimization in roofit likelihoods as these are now; also stored in vectors rather than trees. The faster access speed of vectors make that the constant; term optimization inside likelihoods results in a larger speed increase. This is particulatly noticeable in pdfs with; many constant expressions from pdfs that were moderately fast to begin with (e.g. RooHistPdf).; The second advantages allows new types of algorithmic likelihood optimization in RooFit detailed below. New algorithmic optimization in the caching of pdfs. So far - in the likelihood - two classes of; objects are identified: those that change with every event (i.e. the pdf) and those that change; only with the parameters (typically pdf normalization integrals). Pdfs are always recalculated; for every event, whereas integr",MatchSource.DOCS,roofit/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html:1206,Performance,optimiz,optimization,1206,"d range from; roughly 20% (for problems that were already implemented in a close-to optimal form) to more than 2000%; for certain type of problems. Below is a summary of the changes made. All of these changes are; transparent to end-use cases ; ; ; New implementation of RooFit data types. The implementation of data stored in RooDataSet and RooDataHist; was historically handled by ROOT TTrees (though class RooTreeDataStore). The default storage type; has now been changed to class RooVectorDataStore which stores the information in STL arrays. Existing; datasets based on trees can be read in transparently, and are converted to vector form in the ; persistent-to-transient conversion (the datafile is not modified in this operation); ; The vector store has two important advantages: 1) faster data access (raw data access times are 70 times ; faster than for TTrees), 2) ability to rewrite columns on the fly. The first advantage is important; for the existing constant-term precalculation optimization in roofit likelihoods as these are now; also stored in vectors rather than trees. The faster access speed of vectors make that the constant; term optimization inside likelihoods results in a larger speed increase. This is particulatly noticeable in pdfs with; many constant expressions from pdfs that were moderately fast to begin with (e.g. RooHistPdf).; The second advantages allows new types of algorithmic likelihood optimization in RooFit detailed below. New algorithmic optimization in the caching of pdfs. So far - in the likelihood - two classes of; objects are identified: those that change with every event (i.e. the pdf) and those that change; only with the parameters (typically pdf normalization integrals). Pdfs are always recalculated; for every event, whereas integrals are only evaluated when needed. The exception to the first type are pdfs; that only depend on constant parameters (or no parameters) - these are identified at the beginning, and precalculated once ; to avoid ",MatchSource.DOCS,roofit/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html:1365,Performance,optimiz,optimization,1365,"is a summary of the changes made. All of these changes are; transparent to end-use cases ; ; ; New implementation of RooFit data types. The implementation of data stored in RooDataSet and RooDataHist; was historically handled by ROOT TTrees (though class RooTreeDataStore). The default storage type; has now been changed to class RooVectorDataStore which stores the information in STL arrays. Existing; datasets based on trees can be read in transparently, and are converted to vector form in the ; persistent-to-transient conversion (the datafile is not modified in this operation); ; The vector store has two important advantages: 1) faster data access (raw data access times are 70 times ; faster than for TTrees), 2) ability to rewrite columns on the fly. The first advantage is important; for the existing constant-term precalculation optimization in roofit likelihoods as these are now; also stored in vectors rather than trees. The faster access speed of vectors make that the constant; term optimization inside likelihoods results in a larger speed increase. This is particulatly noticeable in pdfs with; many constant expressions from pdfs that were moderately fast to begin with (e.g. RooHistPdf).; The second advantages allows new types of algorithmic likelihood optimization in RooFit detailed below. New algorithmic optimization in the caching of pdfs. So far - in the likelihood - two classes of; objects are identified: those that change with every event (i.e. the pdf) and those that change; only with the parameters (typically pdf normalization integrals). Pdfs are always recalculated; for every event, whereas integrals are only evaluated when needed. The exception to the first type are pdfs; that only depend on constant parameters (or no parameters) - these are identified at the beginning, and precalculated once ; to avoid recalculating an expression with the same outcome for every iteration of the likelihood calculation. For composite pdfs a further optimization has been i",MatchSource.DOCS,roofit/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html:1640,Performance,optimiz,optimization,1640,"reeDataStore). The default storage type; has now been changed to class RooVectorDataStore which stores the information in STL arrays. Existing; datasets based on trees can be read in transparently, and are converted to vector form in the ; persistent-to-transient conversion (the datafile is not modified in this operation); ; The vector store has two important advantages: 1) faster data access (raw data access times are 70 times ; faster than for TTrees), 2) ability to rewrite columns on the fly. The first advantage is important; for the existing constant-term precalculation optimization in roofit likelihoods as these are now; also stored in vectors rather than trees. The faster access speed of vectors make that the constant; term optimization inside likelihoods results in a larger speed increase. This is particulatly noticeable in pdfs with; many constant expressions from pdfs that were moderately fast to begin with (e.g. RooHistPdf).; The second advantages allows new types of algorithmic likelihood optimization in RooFit detailed below. New algorithmic optimization in the caching of pdfs. So far - in the likelihood - two classes of; objects are identified: those that change with every event (i.e. the pdf) and those that change; only with the parameters (typically pdf normalization integrals). Pdfs are always recalculated; for every event, whereas integrals are only evaluated when needed. The exception to the first type are pdfs; that only depend on constant parameters (or no parameters) - these are identified at the beginning, and precalculated once ; to avoid recalculating an expression with the same outcome for every iteration of the likelihood calculation. For composite pdfs a further optimization has been included: for a M(x,a,b) = f*F(x,a)+(1-f)G(x,b) ; it is e.g. not needed to recalculate G(x,b) if only parameter a has changed w.r.t to the previous likelihood; calculation. This optimization is now implemented by extending the value caching originally designed;",MatchSource.DOCS,roofit/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html:1695,Performance,optimiz,optimization,1695,"rDataStore which stores the information in STL arrays. Existing; datasets based on trees can be read in transparently, and are converted to vector form in the ; persistent-to-transient conversion (the datafile is not modified in this operation); ; The vector store has two important advantages: 1) faster data access (raw data access times are 70 times ; faster than for TTrees), 2) ability to rewrite columns on the fly. The first advantage is important; for the existing constant-term precalculation optimization in roofit likelihoods as these are now; also stored in vectors rather than trees. The faster access speed of vectors make that the constant; term optimization inside likelihoods results in a larger speed increase. This is particulatly noticeable in pdfs with; many constant expressions from pdfs that were moderately fast to begin with (e.g. RooHistPdf).; The second advantages allows new types of algorithmic likelihood optimization in RooFit detailed below. New algorithmic optimization in the caching of pdfs. So far - in the likelihood - two classes of; objects are identified: those that change with every event (i.e. the pdf) and those that change; only with the parameters (typically pdf normalization integrals). Pdfs are always recalculated; for every event, whereas integrals are only evaluated when needed. The exception to the first type are pdfs; that only depend on constant parameters (or no parameters) - these are identified at the beginning, and precalculated once ; to avoid recalculating an expression with the same outcome for every iteration of the likelihood calculation. For composite pdfs a further optimization has been included: for a M(x,a,b) = f*F(x,a)+(1-f)G(x,b) ; it is e.g. not needed to recalculate G(x,b) if only parameter a has changed w.r.t to the previous likelihood; calculation. This optimization is now implemented by extending the value caching originally designed; for constant terms to be usable for non-constant terms, with a check executed ",MatchSource.DOCS,roofit/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html:2343,Performance,optimiz,optimization,2343,"imization inside likelihoods results in a larger speed increase. This is particulatly noticeable in pdfs with; many constant expressions from pdfs that were moderately fast to begin with (e.g. RooHistPdf).; The second advantages allows new types of algorithmic likelihood optimization in RooFit detailed below. New algorithmic optimization in the caching of pdfs. So far - in the likelihood - two classes of; objects are identified: those that change with every event (i.e. the pdf) and those that change; only with the parameters (typically pdf normalization integrals). Pdfs are always recalculated; for every event, whereas integrals are only evaluated when needed. The exception to the first type are pdfs; that only depend on constant parameters (or no parameters) - these are identified at the beginning, and precalculated once ; to avoid recalculating an expression with the same outcome for every iteration of the likelihood calculation. For composite pdfs a further optimization has been included: for a M(x,a,b) = f*F(x,a)+(1-f)G(x,b) ; it is e.g. not needed to recalculate G(x,b) if only parameter a has changed w.r.t to the previous likelihood; calculation. This optimization is now implemented by extending the value caching originally designed; for constant terms to be usable for non-constant terms, with a check executed at the beginning of each; likelihood evaluation if selected columns need to be updated because parameters have changed. The speed gain; of this optimization depends much on the structure of the pdf: in models with many free parameters most of the; likelihood evaluations are executed when MINUIT calculates numerical likelihood derivatives which vary ; one parameter at a time and the speedup is potentially larger. In models with few free parameters the; effect will be smaller. The new per-component caching strategy is enabled by default for all pdfs that are a component of; a RooAddPdf or a RooRealSumPdf, unless that component is a RooProdPdf or a RooProduc",MatchSource.DOCS,roofit/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html:2543,Performance,optimiz,optimization,2543,"ew algorithmic optimization in the caching of pdfs. So far - in the likelihood - two classes of; objects are identified: those that change with every event (i.e. the pdf) and those that change; only with the parameters (typically pdf normalization integrals). Pdfs are always recalculated; for every event, whereas integrals are only evaluated when needed. The exception to the first type are pdfs; that only depend on constant parameters (or no parameters) - these are identified at the beginning, and precalculated once ; to avoid recalculating an expression with the same outcome for every iteration of the likelihood calculation. For composite pdfs a further optimization has been included: for a M(x,a,b) = f*F(x,a)+(1-f)G(x,b) ; it is e.g. not needed to recalculate G(x,b) if only parameter a has changed w.r.t to the previous likelihood; calculation. This optimization is now implemented by extending the value caching originally designed; for constant terms to be usable for non-constant terms, with a check executed at the beginning of each; likelihood evaluation if selected columns need to be updated because parameters have changed. The speed gain; of this optimization depends much on the structure of the pdf: in models with many free parameters most of the; likelihood evaluations are executed when MINUIT calculates numerical likelihood derivatives which vary ; one parameter at a time and the speedup is potentially larger. In models with few free parameters the; effect will be smaller. The new per-component caching strategy is enabled by default for all pdfs that are a component of; a RooAddPdf or a RooRealSumPdf, unless that component is a RooProdPdf or a RooProduct, in that; case the components of the product are cached instead of the product itself. You can disable this; new optimization by adding Optimize(1) to the RooAbsPdf::fitTo() command line (0 = no caching,; 1 = cache constant terms only, 2 = cache also variable terms according to above mentioned strategy (DEFAUL",MatchSource.DOCS,roofit/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html:2849,Performance,optimiz,optimization,2849,"r every event, whereas integrals are only evaluated when needed. The exception to the first type are pdfs; that only depend on constant parameters (or no parameters) - these are identified at the beginning, and precalculated once ; to avoid recalculating an expression with the same outcome for every iteration of the likelihood calculation. For composite pdfs a further optimization has been included: for a M(x,a,b) = f*F(x,a)+(1-f)G(x,b) ; it is e.g. not needed to recalculate G(x,b) if only parameter a has changed w.r.t to the previous likelihood; calculation. This optimization is now implemented by extending the value caching originally designed; for constant terms to be usable for non-constant terms, with a check executed at the beginning of each; likelihood evaluation if selected columns need to be updated because parameters have changed. The speed gain; of this optimization depends much on the structure of the pdf: in models with many free parameters most of the; likelihood evaluations are executed when MINUIT calculates numerical likelihood derivatives which vary ; one parameter at a time and the speedup is potentially larger. In models with few free parameters the; effect will be smaller. The new per-component caching strategy is enabled by default for all pdfs that are a component of; a RooAddPdf or a RooRealSumPdf, unless that component is a RooProdPdf or a RooProduct, in that; case the components of the product are cached instead of the product itself. You can disable this; new optimization by adding Optimize(1) to the RooAbsPdf::fitTo() command line (0 = no caching,; 1 = cache constant terms only, 2 = cache also variable terms according to above mentioned strategy (DEFAULT)). It is also possible to tune this 'cache-and-track' optimization to perform a more fine-grained caching; of components than Optimize(2) implements: to do so, call arg->setAttribute(""CacheAndTrack"") on each; pdf component that you'd like to be cache-and-tracked individually. New pdf/data",MatchSource.DOCS,roofit/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html:3419,Performance,cache,cached,3419,"mposite pdfs a further optimization has been included: for a M(x,a,b) = f*F(x,a)+(1-f)G(x,b) ; it is e.g. not needed to recalculate G(x,b) if only parameter a has changed w.r.t to the previous likelihood; calculation. This optimization is now implemented by extending the value caching originally designed; for constant terms to be usable for non-constant terms, with a check executed at the beginning of each; likelihood evaluation if selected columns need to be updated because parameters have changed. The speed gain; of this optimization depends much on the structure of the pdf: in models with many free parameters most of the; likelihood evaluations are executed when MINUIT calculates numerical likelihood derivatives which vary ; one parameter at a time and the speedup is potentially larger. In models with few free parameters the; effect will be smaller. The new per-component caching strategy is enabled by default for all pdfs that are a component of; a RooAddPdf or a RooRealSumPdf, unless that component is a RooProdPdf or a RooProduct, in that; case the components of the product are cached instead of the product itself. You can disable this; new optimization by adding Optimize(1) to the RooAbsPdf::fitTo() command line (0 = no caching,; 1 = cache constant terms only, 2 = cache also variable terms according to above mentioned strategy (DEFAULT)). It is also possible to tune this 'cache-and-track' optimization to perform a more fine-grained caching; of components than Optimize(2) implements: to do so, call arg->setAttribute(""CacheAndTrack"") on each; pdf component that you'd like to be cache-and-tracked individually. New pdf/data attach mechanism in likelihood objects (RooAbsOptTestStatistic). The new mechanism only; reattaches the dataset branch buffers and not the RooRealVars representing the data. This new designs; allows for a much faster RooAbsTestStatistic::setData() implementation, which changes the dataset in; an existing likelihood object. This will speed up Roo",MatchSource.DOCS,roofit/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html:3483,Performance,optimiz,optimization,3483,"nted by extending the value caching originally designed; for constant terms to be usable for non-constant terms, with a check executed at the beginning of each; likelihood evaluation if selected columns need to be updated because parameters have changed. The speed gain; of this optimization depends much on the structure of the pdf: in models with many free parameters most of the; likelihood evaluations are executed when MINUIT calculates numerical likelihood derivatives which vary ; one parameter at a time and the speedup is potentially larger. In models with few free parameters the; effect will be smaller. The new per-component caching strategy is enabled by default for all pdfs that are a component of; a RooAddPdf or a RooRealSumPdf, unless that component is a RooProdPdf or a RooProduct, in that; case the components of the product are cached instead of the product itself. You can disable this; new optimization by adding Optimize(1) to the RooAbsPdf::fitTo() command line (0 = no caching,; 1 = cache constant terms only, 2 = cache also variable terms according to above mentioned strategy (DEFAULT)). It is also possible to tune this 'cache-and-track' optimization to perform a more fine-grained caching; of components than Optimize(2) implements: to do so, call arg->setAttribute(""CacheAndTrack"") on each; pdf component that you'd like to be cache-and-tracked individually. New pdf/data attach mechanism in likelihood objects (RooAbsOptTestStatistic). The new mechanism only; reattaches the dataset branch buffers and not the RooRealVars representing the data. This new designs; allows for a much faster RooAbsTestStatistic::setData() implementation, which changes the dataset in; an existing likelihood object. This will speed up RooStats tools based on 'simple' likelihood models; substantially. Automatic detections of 'binned' pdfs and automatic generation of binned data in generate(). RooFit will; now automatically generate binned pdf shapes. Binned pdfs shapes are fundamentall",MatchSource.DOCS,roofit/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html:3579,Performance,cache,cache,3579,"nted by extending the value caching originally designed; for constant terms to be usable for non-constant terms, with a check executed at the beginning of each; likelihood evaluation if selected columns need to be updated because parameters have changed. The speed gain; of this optimization depends much on the structure of the pdf: in models with many free parameters most of the; likelihood evaluations are executed when MINUIT calculates numerical likelihood derivatives which vary ; one parameter at a time and the speedup is potentially larger. In models with few free parameters the; effect will be smaller. The new per-component caching strategy is enabled by default for all pdfs that are a component of; a RooAddPdf or a RooRealSumPdf, unless that component is a RooProdPdf or a RooProduct, in that; case the components of the product are cached instead of the product itself. You can disable this; new optimization by adding Optimize(1) to the RooAbsPdf::fitTo() command line (0 = no caching,; 1 = cache constant terms only, 2 = cache also variable terms according to above mentioned strategy (DEFAULT)). It is also possible to tune this 'cache-and-track' optimization to perform a more fine-grained caching; of components than Optimize(2) implements: to do so, call arg->setAttribute(""CacheAndTrack"") on each; pdf component that you'd like to be cache-and-tracked individually. New pdf/data attach mechanism in likelihood objects (RooAbsOptTestStatistic). The new mechanism only; reattaches the dataset branch buffers and not the RooRealVars representing the data. This new designs; allows for a much faster RooAbsTestStatistic::setData() implementation, which changes the dataset in; an existing likelihood object. This will speed up RooStats tools based on 'simple' likelihood models; substantially. Automatic detections of 'binned' pdfs and automatic generation of binned data in generate(). RooFit will; now automatically generate binned pdf shapes. Binned pdfs shapes are fundamentall",MatchSource.DOCS,roofit/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html:3610,Performance,cache,cache,3610,"nted by extending the value caching originally designed; for constant terms to be usable for non-constant terms, with a check executed at the beginning of each; likelihood evaluation if selected columns need to be updated because parameters have changed. The speed gain; of this optimization depends much on the structure of the pdf: in models with many free parameters most of the; likelihood evaluations are executed when MINUIT calculates numerical likelihood derivatives which vary ; one parameter at a time and the speedup is potentially larger. In models with few free parameters the; effect will be smaller. The new per-component caching strategy is enabled by default for all pdfs that are a component of; a RooAddPdf or a RooRealSumPdf, unless that component is a RooProdPdf or a RooProduct, in that; case the components of the product are cached instead of the product itself. You can disable this; new optimization by adding Optimize(1) to the RooAbsPdf::fitTo() command line (0 = no caching,; 1 = cache constant terms only, 2 = cache also variable terms according to above mentioned strategy (DEFAULT)). It is also possible to tune this 'cache-and-track' optimization to perform a more fine-grained caching; of components than Optimize(2) implements: to do so, call arg->setAttribute(""CacheAndTrack"") on each; pdf component that you'd like to be cache-and-tracked individually. New pdf/data attach mechanism in likelihood objects (RooAbsOptTestStatistic). The new mechanism only; reattaches the dataset branch buffers and not the RooRealVars representing the data. This new designs; allows for a much faster RooAbsTestStatistic::setData() implementation, which changes the dataset in; an existing likelihood object. This will speed up RooStats tools based on 'simple' likelihood models; substantially. Automatic detections of 'binned' pdfs and automatic generation of binned data in generate(). RooFit will; now automatically generate binned pdf shapes. Binned pdfs shapes are fundamentall",MatchSource.DOCS,roofit/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html:3709,Performance,tune,tune,3709,"d. The speed gain; of this optimization depends much on the structure of the pdf: in models with many free parameters most of the; likelihood evaluations are executed when MINUIT calculates numerical likelihood derivatives which vary ; one parameter at a time and the speedup is potentially larger. In models with few free parameters the; effect will be smaller. The new per-component caching strategy is enabled by default for all pdfs that are a component of; a RooAddPdf or a RooRealSumPdf, unless that component is a RooProdPdf or a RooProduct, in that; case the components of the product are cached instead of the product itself. You can disable this; new optimization by adding Optimize(1) to the RooAbsPdf::fitTo() command line (0 = no caching,; 1 = cache constant terms only, 2 = cache also variable terms according to above mentioned strategy (DEFAULT)). It is also possible to tune this 'cache-and-track' optimization to perform a more fine-grained caching; of components than Optimize(2) implements: to do so, call arg->setAttribute(""CacheAndTrack"") on each; pdf component that you'd like to be cache-and-tracked individually. New pdf/data attach mechanism in likelihood objects (RooAbsOptTestStatistic). The new mechanism only; reattaches the dataset branch buffers and not the RooRealVars representing the data. This new designs; allows for a much faster RooAbsTestStatistic::setData() implementation, which changes the dataset in; an existing likelihood object. This will speed up RooStats tools based on 'simple' likelihood models; substantially. Automatic detections of 'binned' pdfs and automatic generation of binned data in generate(). RooFit will; now automatically generate binned pdf shapes. Binned pdfs shapes are fundamentally RooHistPdf and RooHistFuncs; (with interpolation order set to zero). Products and sums of exclusively binned shapes are also recognized; as binned shapes. For such binned shapes generate() will now by default follow the 'binned' strategy ; -- that i",MatchSource.DOCS,roofit/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html:3720,Performance,cache,cache-and-track,3720,"d. The speed gain; of this optimization depends much on the structure of the pdf: in models with many free parameters most of the; likelihood evaluations are executed when MINUIT calculates numerical likelihood derivatives which vary ; one parameter at a time and the speedup is potentially larger. In models with few free parameters the; effect will be smaller. The new per-component caching strategy is enabled by default for all pdfs that are a component of; a RooAddPdf or a RooRealSumPdf, unless that component is a RooProdPdf or a RooProduct, in that; case the components of the product are cached instead of the product itself. You can disable this; new optimization by adding Optimize(1) to the RooAbsPdf::fitTo() command line (0 = no caching,; 1 = cache constant terms only, 2 = cache also variable terms according to above mentioned strategy (DEFAULT)). It is also possible to tune this 'cache-and-track' optimization to perform a more fine-grained caching; of components than Optimize(2) implements: to do so, call arg->setAttribute(""CacheAndTrack"") on each; pdf component that you'd like to be cache-and-tracked individually. New pdf/data attach mechanism in likelihood objects (RooAbsOptTestStatistic). The new mechanism only; reattaches the dataset branch buffers and not the RooRealVars representing the data. This new designs; allows for a much faster RooAbsTestStatistic::setData() implementation, which changes the dataset in; an existing likelihood object. This will speed up RooStats tools based on 'simple' likelihood models; substantially. Automatic detections of 'binned' pdfs and automatic generation of binned data in generate(). RooFit will; now automatically generate binned pdf shapes. Binned pdfs shapes are fundamentally RooHistPdf and RooHistFuncs; (with interpolation order set to zero). Products and sums of exclusively binned shapes are also recognized; as binned shapes. For such binned shapes generate() will now by default follow the 'binned' strategy ; -- that i",MatchSource.DOCS,roofit/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html:3737,Performance,optimiz,optimization,3737,"d. The speed gain; of this optimization depends much on the structure of the pdf: in models with many free parameters most of the; likelihood evaluations are executed when MINUIT calculates numerical likelihood derivatives which vary ; one parameter at a time and the speedup is potentially larger. In models with few free parameters the; effect will be smaller. The new per-component caching strategy is enabled by default for all pdfs that are a component of; a RooAddPdf or a RooRealSumPdf, unless that component is a RooProdPdf or a RooProduct, in that; case the components of the product are cached instead of the product itself. You can disable this; new optimization by adding Optimize(1) to the RooAbsPdf::fitTo() command line (0 = no caching,; 1 = cache constant terms only, 2 = cache also variable terms according to above mentioned strategy (DEFAULT)). It is also possible to tune this 'cache-and-track' optimization to perform a more fine-grained caching; of components than Optimize(2) implements: to do so, call arg->setAttribute(""CacheAndTrack"") on each; pdf component that you'd like to be cache-and-tracked individually. New pdf/data attach mechanism in likelihood objects (RooAbsOptTestStatistic). The new mechanism only; reattaches the dataset branch buffers and not the RooRealVars representing the data. This new designs; allows for a much faster RooAbsTestStatistic::setData() implementation, which changes the dataset in; an existing likelihood object. This will speed up RooStats tools based on 'simple' likelihood models; substantially. Automatic detections of 'binned' pdfs and automatic generation of binned data in generate(). RooFit will; now automatically generate binned pdf shapes. Binned pdfs shapes are fundamentally RooHistPdf and RooHistFuncs; (with interpolation order set to zero). Products and sums of exclusively binned shapes are also recognized; as binned shapes. For such binned shapes generate() will now by default follow the 'binned' strategy ; -- that i",MatchSource.DOCS,roofit/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html:3753,Performance,perform,perform,3753,"d. The speed gain; of this optimization depends much on the structure of the pdf: in models with many free parameters most of the; likelihood evaluations are executed when MINUIT calculates numerical likelihood derivatives which vary ; one parameter at a time and the speedup is potentially larger. In models with few free parameters the; effect will be smaller. The new per-component caching strategy is enabled by default for all pdfs that are a component of; a RooAddPdf or a RooRealSumPdf, unless that component is a RooProdPdf or a RooProduct, in that; case the components of the product are cached instead of the product itself. You can disable this; new optimization by adding Optimize(1) to the RooAbsPdf::fitTo() command line (0 = no caching,; 1 = cache constant terms only, 2 = cache also variable terms according to above mentioned strategy (DEFAULT)). It is also possible to tune this 'cache-and-track' optimization to perform a more fine-grained caching; of components than Optimize(2) implements: to do so, call arg->setAttribute(""CacheAndTrack"") on each; pdf component that you'd like to be cache-and-tracked individually. New pdf/data attach mechanism in likelihood objects (RooAbsOptTestStatistic). The new mechanism only; reattaches the dataset branch buffers and not the RooRealVars representing the data. This new designs; allows for a much faster RooAbsTestStatistic::setData() implementation, which changes the dataset in; an existing likelihood object. This will speed up RooStats tools based on 'simple' likelihood models; substantially. Automatic detections of 'binned' pdfs and automatic generation of binned data in generate(). RooFit will; now automatically generate binned pdf shapes. Binned pdfs shapes are fundamentally RooHistPdf and RooHistFuncs; (with interpolation order set to zero). Products and sums of exclusively binned shapes are also recognized; as binned shapes. For such binned shapes generate() will now by default follow the 'binned' strategy ; -- that i",MatchSource.DOCS,roofit/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html:3928,Performance,cache,cache-and-tracked,3928,"d. The speed gain; of this optimization depends much on the structure of the pdf: in models with many free parameters most of the; likelihood evaluations are executed when MINUIT calculates numerical likelihood derivatives which vary ; one parameter at a time and the speedup is potentially larger. In models with few free parameters the; effect will be smaller. The new per-component caching strategy is enabled by default for all pdfs that are a component of; a RooAddPdf or a RooRealSumPdf, unless that component is a RooProdPdf or a RooProduct, in that; case the components of the product are cached instead of the product itself. You can disable this; new optimization by adding Optimize(1) to the RooAbsPdf::fitTo() command line (0 = no caching,; 1 = cache constant terms only, 2 = cache also variable terms according to above mentioned strategy (DEFAULT)). It is also possible to tune this 'cache-and-track' optimization to perform a more fine-grained caching; of components than Optimize(2) implements: to do so, call arg->setAttribute(""CacheAndTrack"") on each; pdf component that you'd like to be cache-and-tracked individually. New pdf/data attach mechanism in likelihood objects (RooAbsOptTestStatistic). The new mechanism only; reattaches the dataset branch buffers and not the RooRealVars representing the data. This new designs; allows for a much faster RooAbsTestStatistic::setData() implementation, which changes the dataset in; an existing likelihood object. This will speed up RooStats tools based on 'simple' likelihood models; substantially. Automatic detections of 'binned' pdfs and automatic generation of binned data in generate(). RooFit will; now automatically generate binned pdf shapes. Binned pdfs shapes are fundamentally RooHistPdf and RooHistFuncs; (with interpolation order set to zero). Products and sums of exclusively binned shapes are also recognized; as binned shapes. For such binned shapes generate() will now by default follow the 'binned' strategy ; -- that i",MatchSource.DOCS,roofit/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html:5073,Performance,optimiz,optimization,5073,"ata. This new designs; allows for a much faster RooAbsTestStatistic::setData() implementation, which changes the dataset in; an existing likelihood object. This will speed up RooStats tools based on 'simple' likelihood models; substantially. Automatic detections of 'binned' pdfs and automatic generation of binned data in generate(). RooFit will; now automatically generate binned pdf shapes. Binned pdfs shapes are fundamentally RooHistPdf and RooHistFuncs; (with interpolation order set to zero). Products and sums of exclusively binned shapes are also recognized; as binned shapes. For such binned shapes generate() will now by default follow the 'binned' strategy ; -- that is, take the expectation value in each bin and sample a Poisson distribution from that -- rather; than follow the unbinned strategy. The rationale is that such datasets result in much faster likelihood; calculations (for nbin smaller than nevent). The optimization is also exact: the likelihood of a binned ; data using a binned pdf is identical to that of an unbinned dataset with a binned pdf. Nevertheless you can ; switch off this feature by passing AutoBinned(false) to RooAbsPdf::generate(). Mixed binned/unbinned generation from simultaneous pdf. For a RooSimultaneous consisting of exclusively; extended terms it is now possible to generate a mixed binned/unbinned datasets. Components defined; by a binned pdf at the top level are automatically generated binned (unless AutoBinned(false) is set); but it is also possible to generate other component pdfs forcibly binned by adding GenBinned(tagname); to generate(). In that case all component pdfs labeled with pdf->setAttribute(tagname) will be generated; binned. To generate all component binned, the shorthand method AllBinned() can be used. All binned; datasets made by generate are represented as weighted unbinned datasets (of type RooDataSet) rather; than binned datasets of type RooDataHist so that mixed binned/unbinned data is always represented; throug",MatchSource.DOCS,roofit/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html:6176,Performance,optimiz,optimization,6176,"binned pdf. Nevertheless you can ; switch off this feature by passing AutoBinned(false) to RooAbsPdf::generate(). Mixed binned/unbinned generation from simultaneous pdf. For a RooSimultaneous consisting of exclusively; extended terms it is now possible to generate a mixed binned/unbinned datasets. Components defined; by a binned pdf at the top level are automatically generated binned (unless AutoBinned(false) is set); but it is also possible to generate other component pdfs forcibly binned by adding GenBinned(tagname); to generate(). In that case all component pdfs labeled with pdf->setAttribute(tagname) will be generated; binned. To generate all component binned, the shorthand method AllBinned() can be used. All binned; datasets made by generate are represented as weighted unbinned datasets (of type RooDataSet) rather; than binned datasets of type RooDataHist so that mixed binned/unbinned data is always represented; through a uniform interface. Fix in the optimization strategy of likelihoods constructed from simultaneous pdf. In the parameter; dependency analysis of the components of a simultaneous pdfs parameters originating from 'irrelevant'; constraint terms (i.e. those that don't relate to any of the parameters of that likelihood component) were; not ignored, which could result in a substantial loss of computational efficiency as likelihood; terms were erroneously recalculated even if no relevant parameters was changed. General performance tuning of RooFit to reduce computational overhead. Extensive profiling of; CPU times in call graphas and analysis heap memory use have been performed and many small ; changes have been made to make the code more efficient and use less memory. RooStats Package; AsymptoticCalculator. New Class for doing an hypothesis tests using the asymptotic likelihood formulae, described in the paper from; G. Cowan, K. Cranmer, E. Gross and O. Vitells, Asymptotic formulae for likelihood- based tests of new physics,; Eur. Phys. J., C71 (1), 20",MatchSource.DOCS,roofit/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html:6662,Performance,perform,performance,6662,"ibly binned by adding GenBinned(tagname); to generate(). In that case all component pdfs labeled with pdf->setAttribute(tagname) will be generated; binned. To generate all component binned, the shorthand method AllBinned() can be used. All binned; datasets made by generate are represented as weighted unbinned datasets (of type RooDataSet) rather; than binned datasets of type RooDataHist so that mixed binned/unbinned data is always represented; through a uniform interface. Fix in the optimization strategy of likelihoods constructed from simultaneous pdf. In the parameter; dependency analysis of the components of a simultaneous pdfs parameters originating from 'irrelevant'; constraint terms (i.e. those that don't relate to any of the parameters of that likelihood component) were; not ignored, which could result in a substantial loss of computational efficiency as likelihood; terms were erroneously recalculated even if no relevant parameters was changed. General performance tuning of RooFit to reduce computational overhead. Extensive profiling of; CPU times in call graphas and analysis heap memory use have been performed and many small ; changes have been made to make the code more efficient and use less memory. RooStats Package; AsymptoticCalculator. New Class for doing an hypothesis tests using the asymptotic likelihood formulae, described in the paper from; G. Cowan, K. Cranmer, E. Gross and O. Vitells, Asymptotic formulae for likelihood- based tests of new physics,; Eur. Phys. J., C71 (1), 2011.; The class computes the p-value for the null and also for the alternate using the Asimov data set. In this; differs form the ProfileLikelihoodCalculator which computes only the p-values for the null hypothesis.; The Asimov data set is generated with the utility function AsymptoticCalculator::MakeAsimovData and then; it is used to evaluate the likelihood. ; ; This class implements the HypoTestCalculatorGeneric interface and can be used as an alternative Hypothesis test; calcu",MatchSource.DOCS,roofit/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html:6814,Performance,perform,performed,6814,"l be generated; binned. To generate all component binned, the shorthand method AllBinned() can be used. All binned; datasets made by generate are represented as weighted unbinned datasets (of type RooDataSet) rather; than binned datasets of type RooDataHist so that mixed binned/unbinned data is always represented; through a uniform interface. Fix in the optimization strategy of likelihoods constructed from simultaneous pdf. In the parameter; dependency analysis of the components of a simultaneous pdfs parameters originating from 'irrelevant'; constraint terms (i.e. those that don't relate to any of the parameters of that likelihood component) were; not ignored, which could result in a substantial loss of computational efficiency as likelihood; terms were erroneously recalculated even if no relevant parameters was changed. General performance tuning of RooFit to reduce computational overhead. Extensive profiling of; CPU times in call graphas and analysis heap memory use have been performed and many small ; changes have been made to make the code more efficient and use less memory. RooStats Package; AsymptoticCalculator. New Class for doing an hypothesis tests using the asymptotic likelihood formulae, described in the paper from; G. Cowan, K. Cranmer, E. Gross and O. Vitells, Asymptotic formulae for likelihood- based tests of new physics,; Eur. Phys. J., C71 (1), 2011.; The class computes the p-value for the null and also for the alternate using the Asimov data set. In this; differs form the ProfileLikelihoodCalculator which computes only the p-values for the null hypothesis.; The Asimov data set is generated with the utility function AsymptoticCalculator::MakeAsimovData and then; it is used to evaluate the likelihood. ; ; This class implements the HypoTestCalculatorGeneric interface and can be used as an alternative Hypothesis test; calculator in the HypoTestInverter class. It can then plugged in the HypoTestInverter for computing asymptotic CLs and CLs+b; limits. In",MatchSource.DOCS,roofit/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html:7866,Performance,perform,performing,7866,"more efficient and use less memory. RooStats Package; AsymptoticCalculator. New Class for doing an hypothesis tests using the asymptotic likelihood formulae, described in the paper from; G. Cowan, K. Cranmer, E. Gross and O. Vitells, Asymptotic formulae for likelihood- based tests of new physics,; Eur. Phys. J., C71 (1), 2011.; The class computes the p-value for the null and also for the alternate using the Asimov data set. In this; differs form the ProfileLikelihoodCalculator which computes only the p-values for the null hypothesis.; The Asimov data set is generated with the utility function AsymptoticCalculator::MakeAsimovData and then; it is used to evaluate the likelihood. ; ; This class implements the HypoTestCalculatorGeneric interface and can be used as an alternative Hypothesis test; calculator in the HypoTestInverter class. It can then plugged in the HypoTestInverter for computing asymptotic CLs and CLs+b; limits. In this way the limits will be computed by just performing a fit for each test parameter value and without; generating any toys. . The class can be used via the StandardHypothesisTest.C tutorial passing a value of 2 for the; calculator type. . RooStats Utils. Add a utility function (from G. Petrucciani), RooStats::MakeNuisancePdf, which given a model configuration (or the global pdf and the; observables), factorizes from the model pdf the constraint probability density functions for the nuisance parameters; and builds a global nuisance pdf. This function can then be used in the HybridCalculator or in the BayesianCalculator; with the option ""TOYMC"".; . HypotestInverter and HypoTestInverterResult. Several improvements and bug fixes in merging results and in computing the observed and expected limits.; Provide support now for using the AsympoticCalculator. MCMCCalculator. Add now possibility to store in the chain only the parameter of interested via the method MCMCCalculator::SetChainParameters. This saves memory in case of models with a; large number",MatchSource.DOCS,roofit/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html:9237,Performance,cache,cache,9237,"ata and then; it is used to evaluate the likelihood. ; ; This class implements the HypoTestCalculatorGeneric interface and can be used as an alternative Hypothesis test; calculator in the HypoTestInverter class. It can then plugged in the HypoTestInverter for computing asymptotic CLs and CLs+b; limits. In this way the limits will be computed by just performing a fit for each test parameter value and without; generating any toys. . The class can be used via the StandardHypothesisTest.C tutorial passing a value of 2 for the; calculator type. . RooStats Utils. Add a utility function (from G. Petrucciani), RooStats::MakeNuisancePdf, which given a model configuration (or the global pdf and the; observables), factorizes from the model pdf the constraint probability density functions for the nuisance parameters; and builds a global nuisance pdf. This function can then be used in the HybridCalculator or in the BayesianCalculator; with the option ""TOYMC"".; . HypotestInverter and HypoTestInverterResult. Several improvements and bug fixes in merging results and in computing the observed and expected limits.; Provide support now for using the AsympoticCalculator. MCMCCalculator. Add now possibility to store in the chain only the parameter of interested via the method MCMCCalculator::SetChainParameters. This saves memory in case of models with a; large number of nuisance parameters. . Test Statistics classes. Make a more robust evaluation of the ProfileLikelihoodTestStat. Use RooMinimizer and give possibility to use; different minimizer, via ProfileLikelihoodTestStat::SetMinimizer. The print level of minimization can also be; controlled via ProfileLikelihoodTestStat::SetPrintLevel. Activate also the RooFit cache optimizations when; evaluating the NLL ; The same optimizations are applied also to the RatioOfProfilesLikelihood test statistic; Fix a bug in reusing the NLL object in the SimpleLikelihoodCalculator. This makes now the evaluation of this test; statistics much faster. . ",MatchSource.DOCS,roofit/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html:9243,Performance,optimiz,optimizations,9243,"ata and then; it is used to evaluate the likelihood. ; ; This class implements the HypoTestCalculatorGeneric interface and can be used as an alternative Hypothesis test; calculator in the HypoTestInverter class. It can then plugged in the HypoTestInverter for computing asymptotic CLs and CLs+b; limits. In this way the limits will be computed by just performing a fit for each test parameter value and without; generating any toys. . The class can be used via the StandardHypothesisTest.C tutorial passing a value of 2 for the; calculator type. . RooStats Utils. Add a utility function (from G. Petrucciani), RooStats::MakeNuisancePdf, which given a model configuration (or the global pdf and the; observables), factorizes from the model pdf the constraint probability density functions for the nuisance parameters; and builds a global nuisance pdf. This function can then be used in the HybridCalculator or in the BayesianCalculator; with the option ""TOYMC"".; . HypotestInverter and HypoTestInverterResult. Several improvements and bug fixes in merging results and in computing the observed and expected limits.; Provide support now for using the AsympoticCalculator. MCMCCalculator. Add now possibility to store in the chain only the parameter of interested via the method MCMCCalculator::SetChainParameters. This saves memory in case of models with a; large number of nuisance parameters. . Test Statistics classes. Make a more robust evaluation of the ProfileLikelihoodTestStat. Use RooMinimizer and give possibility to use; different minimizer, via ProfileLikelihoodTestStat::SetMinimizer. The print level of minimization can also be; controlled via ProfileLikelihoodTestStat::SetPrintLevel. Activate also the RooFit cache optimizations when; evaluating the NLL ; The same optimizations are applied also to the RatioOfProfilesLikelihood test statistic; Fix a bug in reusing the NLL object in the SimpleLikelihoodCalculator. This makes now the evaluation of this test; statistics much faster. . ",MatchSource.DOCS,roofit/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html:9293,Performance,optimiz,optimizations,9293,"ata and then; it is used to evaluate the likelihood. ; ; This class implements the HypoTestCalculatorGeneric interface and can be used as an alternative Hypothesis test; calculator in the HypoTestInverter class. It can then plugged in the HypoTestInverter for computing asymptotic CLs and CLs+b; limits. In this way the limits will be computed by just performing a fit for each test parameter value and without; generating any toys. . The class can be used via the StandardHypothesisTest.C tutorial passing a value of 2 for the; calculator type. . RooStats Utils. Add a utility function (from G. Petrucciani), RooStats::MakeNuisancePdf, which given a model configuration (or the global pdf and the; observables), factorizes from the model pdf the constraint probability density functions for the nuisance parameters; and builds a global nuisance pdf. This function can then be used in the HybridCalculator or in the BayesianCalculator; with the option ""TOYMC"".; . HypotestInverter and HypoTestInverterResult. Several improvements and bug fixes in merging results and in computing the observed and expected limits.; Provide support now for using the AsympoticCalculator. MCMCCalculator. Add now possibility to store in the chain only the parameter of interested via the method MCMCCalculator::SetChainParameters. This saves memory in case of models with a; large number of nuisance parameters. . Test Statistics classes. Make a more robust evaluation of the ProfileLikelihoodTestStat. Use RooMinimizer and give possibility to use; different minimizer, via ProfileLikelihoodTestStat::SetMinimizer. The print level of minimization can also be; controlled via ProfileLikelihoodTestStat::SetPrintLevel. Activate also the RooFit cache optimizations when; evaluating the NLL ; The same optimizations are applied also to the RatioOfProfilesLikelihood test statistic; Fix a bug in reusing the NLL object in the SimpleLikelihoodCalculator. This makes now the evaluation of this test; statistics much faster. . ",MatchSource.DOCS,roofit/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html:2207,Safety,avoid,avoid,2207,"ng constant-term precalculation optimization in roofit likelihoods as these are now; also stored in vectors rather than trees. The faster access speed of vectors make that the constant; term optimization inside likelihoods results in a larger speed increase. This is particulatly noticeable in pdfs with; many constant expressions from pdfs that were moderately fast to begin with (e.g. RooHistPdf).; The second advantages allows new types of algorithmic likelihood optimization in RooFit detailed below. New algorithmic optimization in the caching of pdfs. So far - in the likelihood - two classes of; objects are identified: those that change with every event (i.e. the pdf) and those that change; only with the parameters (typically pdf normalization integrals). Pdfs are always recalculated; for every event, whereas integrals are only evaluated when needed. The exception to the first type are pdfs; that only depend on constant parameters (or no parameters) - these are identified at the beginning, and precalculated once ; to avoid recalculating an expression with the same outcome for every iteration of the likelihood calculation. For composite pdfs a further optimization has been included: for a M(x,a,b) = f*F(x,a)+(1-f)G(x,b) ; it is e.g. not needed to recalculate G(x,b) if only parameter a has changed w.r.t to the previous likelihood; calculation. This optimization is now implemented by extending the value caching originally designed; for constant terms to be usable for non-constant terms, with a check executed at the beginning of each; likelihood evaluation if selected columns need to be updated because parameters have changed. The speed gain; of this optimization depends much on the structure of the pdf: in models with many free parameters most of the; likelihood evaluations are executed when MINUIT calculates numerical likelihood derivatives which vary ; one parameter at a time and the speedup is potentially larger. In models with few free parameters the; effect will be",MatchSource.DOCS,roofit/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html:4394,Safety,detect,detections,4394,"tead of the product itself. You can disable this; new optimization by adding Optimize(1) to the RooAbsPdf::fitTo() command line (0 = no caching,; 1 = cache constant terms only, 2 = cache also variable terms according to above mentioned strategy (DEFAULT)). It is also possible to tune this 'cache-and-track' optimization to perform a more fine-grained caching; of components than Optimize(2) implements: to do so, call arg->setAttribute(""CacheAndTrack"") on each; pdf component that you'd like to be cache-and-tracked individually. New pdf/data attach mechanism in likelihood objects (RooAbsOptTestStatistic). The new mechanism only; reattaches the dataset branch buffers and not the RooRealVars representing the data. This new designs; allows for a much faster RooAbsTestStatistic::setData() implementation, which changes the dataset in; an existing likelihood object. This will speed up RooStats tools based on 'simple' likelihood models; substantially. Automatic detections of 'binned' pdfs and automatic generation of binned data in generate(). RooFit will; now automatically generate binned pdf shapes. Binned pdfs shapes are fundamentally RooHistPdf and RooHistFuncs; (with interpolation order set to zero). Products and sums of exclusively binned shapes are also recognized; as binned shapes. For such binned shapes generate() will now by default follow the 'binned' strategy ; -- that is, take the expectation value in each bin and sample a Poisson distribution from that -- rather; than follow the unbinned strategy. The rationale is that such datasets result in much faster likelihood; calculations (for nbin smaller than nevent). The optimization is also exact: the likelihood of a binned ; data using a binned pdf is identical to that of an unbinned dataset with a binned pdf. Nevertheless you can ; switch off this feature by passing AutoBinned(false) to RooAbsPdf::generate(). Mixed binned/unbinned generation from simultaneous pdf. For a RooSimultaneous consisting of exclusively; extend",MatchSource.DOCS,roofit/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html:1014,Security,access,access,1014,". RooFit Package. RooFit 3.50 has undergone a substantial amount of core engineering to improve computational efficiency; and improve algorithmic likelihood optimizations. The expected increases in execution speed range from; roughly 20% (for problems that were already implemented in a close-to optimal form) to more than 2000%; for certain type of problems. Below is a summary of the changes made. All of these changes are; transparent to end-use cases ; ; ; New implementation of RooFit data types. The implementation of data stored in RooDataSet and RooDataHist; was historically handled by ROOT TTrees (though class RooTreeDataStore). The default storage type; has now been changed to class RooVectorDataStore which stores the information in STL arrays. Existing; datasets based on trees can be read in transparently, and are converted to vector form in the ; persistent-to-transient conversion (the datafile is not modified in this operation); ; The vector store has two important advantages: 1) faster data access (raw data access times are 70 times ; faster than for TTrees), 2) ability to rewrite columns on the fly. The first advantage is important; for the existing constant-term precalculation optimization in roofit likelihoods as these are now; also stored in vectors rather than trees. The faster access speed of vectors make that the constant; term optimization inside likelihoods results in a larger speed increase. This is particulatly noticeable in pdfs with; many constant expressions from pdfs that were moderately fast to begin with (e.g. RooHistPdf).; The second advantages allows new types of algorithmic likelihood optimization in RooFit detailed below. New algorithmic optimization in the caching of pdfs. So far - in the likelihood - two classes of; objects are identified: those that change with every event (i.e. the pdf) and those that change; only with the parameters (typically pdf normalization integrals). Pdfs are always recalculated; for every event, whereas integr",MatchSource.DOCS,roofit/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html:1031,Security,access,access,1031,". RooFit Package. RooFit 3.50 has undergone a substantial amount of core engineering to improve computational efficiency; and improve algorithmic likelihood optimizations. The expected increases in execution speed range from; roughly 20% (for problems that were already implemented in a close-to optimal form) to more than 2000%; for certain type of problems. Below is a summary of the changes made. All of these changes are; transparent to end-use cases ; ; ; New implementation of RooFit data types. The implementation of data stored in RooDataSet and RooDataHist; was historically handled by ROOT TTrees (though class RooTreeDataStore). The default storage type; has now been changed to class RooVectorDataStore which stores the information in STL arrays. Existing; datasets based on trees can be read in transparently, and are converted to vector form in the ; persistent-to-transient conversion (the datafile is not modified in this operation); ; The vector store has two important advantages: 1) faster data access (raw data access times are 70 times ; faster than for TTrees), 2) ability to rewrite columns on the fly. The first advantage is important; for the existing constant-term precalculation optimization in roofit likelihoods as these are now; also stored in vectors rather than trees. The faster access speed of vectors make that the constant; term optimization inside likelihoods results in a larger speed increase. This is particulatly noticeable in pdfs with; many constant expressions from pdfs that were moderately fast to begin with (e.g. RooHistPdf).; The second advantages allows new types of algorithmic likelihood optimization in RooFit detailed below. New algorithmic optimization in the caching of pdfs. So far - in the likelihood - two classes of; objects are identified: those that change with every event (i.e. the pdf) and those that change; only with the parameters (typically pdf normalization integrals). Pdfs are always recalculated; for every event, whereas integr",MatchSource.DOCS,roofit/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html:1312,Security,access,access,1312,"is a summary of the changes made. All of these changes are; transparent to end-use cases ; ; ; New implementation of RooFit data types. The implementation of data stored in RooDataSet and RooDataHist; was historically handled by ROOT TTrees (though class RooTreeDataStore). The default storage type; has now been changed to class RooVectorDataStore which stores the information in STL arrays. Existing; datasets based on trees can be read in transparently, and are converted to vector form in the ; persistent-to-transient conversion (the datafile is not modified in this operation); ; The vector store has two important advantages: 1) faster data access (raw data access times are 70 times ; faster than for TTrees), 2) ability to rewrite columns on the fly. The first advantage is important; for the existing constant-term precalculation optimization in roofit likelihoods as these are now; also stored in vectors rather than trees. The faster access speed of vectors make that the constant; term optimization inside likelihoods results in a larger speed increase. This is particulatly noticeable in pdfs with; many constant expressions from pdfs that were moderately fast to begin with (e.g. RooHistPdf).; The second advantages allows new types of algorithmic likelihood optimization in RooFit detailed below. New algorithmic optimization in the caching of pdfs. So far - in the likelihood - two classes of; objects are identified: those that change with every event (i.e. the pdf) and those that change; only with the parameters (typically pdf normalization integrals). Pdfs are always recalculated; for every event, whereas integrals are only evaluated when needed. The exception to the first type are pdfs; that only depend on constant parameters (or no parameters) - these are identified at the beginning, and precalculated once ; to avoid recalculating an expression with the same outcome for every iteration of the likelihood calculation. For composite pdfs a further optimization has been i",MatchSource.DOCS,roofit/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html:6991,Testability,test,tests,6991,"ype RooDataSet) rather; than binned datasets of type RooDataHist so that mixed binned/unbinned data is always represented; through a uniform interface. Fix in the optimization strategy of likelihoods constructed from simultaneous pdf. In the parameter; dependency analysis of the components of a simultaneous pdfs parameters originating from 'irrelevant'; constraint terms (i.e. those that don't relate to any of the parameters of that likelihood component) were; not ignored, which could result in a substantial loss of computational efficiency as likelihood; terms were erroneously recalculated even if no relevant parameters was changed. General performance tuning of RooFit to reduce computational overhead. Extensive profiling of; CPU times in call graphas and analysis heap memory use have been performed and many small ; changes have been made to make the code more efficient and use less memory. RooStats Package; AsymptoticCalculator. New Class for doing an hypothesis tests using the asymptotic likelihood formulae, described in the paper from; G. Cowan, K. Cranmer, E. Gross and O. Vitells, Asymptotic formulae for likelihood- based tests of new physics,; Eur. Phys. J., C71 (1), 2011.; The class computes the p-value for the null and also for the alternate using the Asimov data set. In this; differs form the ProfileLikelihoodCalculator which computes only the p-values for the null hypothesis.; The Asimov data set is generated with the utility function AsymptoticCalculator::MakeAsimovData and then; it is used to evaluate the likelihood. ; ; This class implements the HypoTestCalculatorGeneric interface and can be used as an alternative Hypothesis test; calculator in the HypoTestInverter class. It can then plugged in the HypoTestInverter for computing asymptotic CLs and CLs+b; limits. In this way the limits will be computed by just performing a fit for each test parameter value and without; generating any toys. . The class can be used via the StandardHypothesisTest.C tutorial ",MatchSource.DOCS,roofit/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html:7157,Testability,test,tests,7157,"a uniform interface. Fix in the optimization strategy of likelihoods constructed from simultaneous pdf. In the parameter; dependency analysis of the components of a simultaneous pdfs parameters originating from 'irrelevant'; constraint terms (i.e. those that don't relate to any of the parameters of that likelihood component) were; not ignored, which could result in a substantial loss of computational efficiency as likelihood; terms were erroneously recalculated even if no relevant parameters was changed. General performance tuning of RooFit to reduce computational overhead. Extensive profiling of; CPU times in call graphas and analysis heap memory use have been performed and many small ; changes have been made to make the code more efficient and use less memory. RooStats Package; AsymptoticCalculator. New Class for doing an hypothesis tests using the asymptotic likelihood formulae, described in the paper from; G. Cowan, K. Cranmer, E. Gross and O. Vitells, Asymptotic formulae for likelihood- based tests of new physics,; Eur. Phys. J., C71 (1), 2011.; The class computes the p-value for the null and also for the alternate using the Asimov data set. In this; differs form the ProfileLikelihoodCalculator which computes only the p-values for the null hypothesis.; The Asimov data set is generated with the utility function AsymptoticCalculator::MakeAsimovData and then; it is used to evaluate the likelihood. ; ; This class implements the HypoTestCalculatorGeneric interface and can be used as an alternative Hypothesis test; calculator in the HypoTestInverter class. It can then plugged in the HypoTestInverter for computing asymptotic CLs and CLs+b; limits. In this way the limits will be computed by just performing a fit for each test parameter value and without; generating any toys. . The class can be used via the StandardHypothesisTest.C tutorial passing a value of 2 for the; calculator type. . RooStats Utils. Add a utility function (from G. Petrucciani), RooStats::MakeNuisanc",MatchSource.DOCS,roofit/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html:7678,Testability,test,test,7678,"changed. General performance tuning of RooFit to reduce computational overhead. Extensive profiling of; CPU times in call graphas and analysis heap memory use have been performed and many small ; changes have been made to make the code more efficient and use less memory. RooStats Package; AsymptoticCalculator. New Class for doing an hypothesis tests using the asymptotic likelihood formulae, described in the paper from; G. Cowan, K. Cranmer, E. Gross and O. Vitells, Asymptotic formulae for likelihood- based tests of new physics,; Eur. Phys. J., C71 (1), 2011.; The class computes the p-value for the null and also for the alternate using the Asimov data set. In this; differs form the ProfileLikelihoodCalculator which computes only the p-values for the null hypothesis.; The Asimov data set is generated with the utility function AsymptoticCalculator::MakeAsimovData and then; it is used to evaluate the likelihood. ; ; This class implements the HypoTestCalculatorGeneric interface and can be used as an alternative Hypothesis test; calculator in the HypoTestInverter class. It can then plugged in the HypoTestInverter for computing asymptotic CLs and CLs+b; limits. In this way the limits will be computed by just performing a fit for each test parameter value and without; generating any toys. . The class can be used via the StandardHypothesisTest.C tutorial passing a value of 2 for the; calculator type. . RooStats Utils. Add a utility function (from G. Petrucciani), RooStats::MakeNuisancePdf, which given a model configuration (or the global pdf and the; observables), factorizes from the model pdf the constraint probability density functions for the nuisance parameters; and builds a global nuisance pdf. This function can then be used in the HybridCalculator or in the BayesianCalculator; with the option ""TOYMC"".; . HypotestInverter and HypoTestInverterResult. Several improvements and bug fixes in merging results and in computing the observed and expected limits.; Provide support n",MatchSource.DOCS,roofit/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html:7892,Testability,test,test,7892,"more efficient and use less memory. RooStats Package; AsymptoticCalculator. New Class for doing an hypothesis tests using the asymptotic likelihood formulae, described in the paper from; G. Cowan, K. Cranmer, E. Gross and O. Vitells, Asymptotic formulae for likelihood- based tests of new physics,; Eur. Phys. J., C71 (1), 2011.; The class computes the p-value for the null and also for the alternate using the Asimov data set. In this; differs form the ProfileLikelihoodCalculator which computes only the p-values for the null hypothesis.; The Asimov data set is generated with the utility function AsymptoticCalculator::MakeAsimovData and then; it is used to evaluate the likelihood. ; ; This class implements the HypoTestCalculatorGeneric interface and can be used as an alternative Hypothesis test; calculator in the HypoTestInverter class. It can then plugged in the HypoTestInverter for computing asymptotic CLs and CLs+b; limits. In this way the limits will be computed by just performing a fit for each test parameter value and without; generating any toys. . The class can be used via the StandardHypothesisTest.C tutorial passing a value of 2 for the; calculator type. . RooStats Utils. Add a utility function (from G. Petrucciani), RooStats::MakeNuisancePdf, which given a model configuration (or the global pdf and the; observables), factorizes from the model pdf the constraint probability density functions for the nuisance parameters; and builds a global nuisance pdf. This function can then be used in the HybridCalculator or in the BayesianCalculator; with the option ""TOYMC"".; . HypotestInverter and HypoTestInverterResult. Several improvements and bug fixes in merging results and in computing the observed and expected limits.; Provide support now for using the AsympoticCalculator. MCMCCalculator. Add now possibility to store in the chain only the parameter of interested via the method MCMCCalculator::SetChainParameters. This saves memory in case of models with a; large number",MatchSource.DOCS,roofit/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html:9357,Testability,test,test,9357,"ata and then; it is used to evaluate the likelihood. ; ; This class implements the HypoTestCalculatorGeneric interface and can be used as an alternative Hypothesis test; calculator in the HypoTestInverter class. It can then plugged in the HypoTestInverter for computing asymptotic CLs and CLs+b; limits. In this way the limits will be computed by just performing a fit for each test parameter value and without; generating any toys. . The class can be used via the StandardHypothesisTest.C tutorial passing a value of 2 for the; calculator type. . RooStats Utils. Add a utility function (from G. Petrucciani), RooStats::MakeNuisancePdf, which given a model configuration (or the global pdf and the; observables), factorizes from the model pdf the constraint probability density functions for the nuisance parameters; and builds a global nuisance pdf. This function can then be used in the HybridCalculator or in the BayesianCalculator; with the option ""TOYMC"".; . HypotestInverter and HypoTestInverterResult. Several improvements and bug fixes in merging results and in computing the observed and expected limits.; Provide support now for using the AsympoticCalculator. MCMCCalculator. Add now possibility to store in the chain only the parameter of interested via the method MCMCCalculator::SetChainParameters. This saves memory in case of models with a; large number of nuisance parameters. . Test Statistics classes. Make a more robust evaluation of the ProfileLikelihoodTestStat. Use RooMinimizer and give possibility to use; different minimizer, via ProfileLikelihoodTestStat::SetMinimizer. The print level of minimization can also be; controlled via ProfileLikelihoodTestStat::SetPrintLevel. Activate also the RooFit cache optimizations when; evaluating the NLL ; The same optimizations are applied also to the RatioOfProfilesLikelihood test statistic; Fix a bug in reusing the NLL object in the SimpleLikelihoodCalculator. This makes now the evaluation of this test; statistics much faster. . ",MatchSource.DOCS,roofit/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html:9482,Testability,test,test,9482,"ata and then; it is used to evaluate the likelihood. ; ; This class implements the HypoTestCalculatorGeneric interface and can be used as an alternative Hypothesis test; calculator in the HypoTestInverter class. It can then plugged in the HypoTestInverter for computing asymptotic CLs and CLs+b; limits. In this way the limits will be computed by just performing a fit for each test parameter value and without; generating any toys. . The class can be used via the StandardHypothesisTest.C tutorial passing a value of 2 for the; calculator type. . RooStats Utils. Add a utility function (from G. Petrucciani), RooStats::MakeNuisancePdf, which given a model configuration (or the global pdf and the; observables), factorizes from the model pdf the constraint probability density functions for the nuisance parameters; and builds a global nuisance pdf. This function can then be used in the HybridCalculator or in the BayesianCalculator; with the option ""TOYMC"".; . HypotestInverter and HypoTestInverterResult. Several improvements and bug fixes in merging results and in computing the observed and expected limits.; Provide support now for using the AsympoticCalculator. MCMCCalculator. Add now possibility to store in the chain only the parameter of interested via the method MCMCCalculator::SetChainParameters. This saves memory in case of models with a; large number of nuisance parameters. . Test Statistics classes. Make a more robust evaluation of the ProfileLikelihoodTestStat. Use RooMinimizer and give possibility to use; different minimizer, via ProfileLikelihoodTestStat::SetMinimizer. The print level of minimization can also be; controlled via ProfileLikelihoodTestStat::SetPrintLevel. Activate also the RooFit cache optimizations when; evaluating the NLL ; The same optimizations are applied also to the RatioOfProfilesLikelihood test statistic; Fix a bug in reusing the NLL object in the SimpleLikelihoodCalculator. This makes now the evaluation of this test; statistics much faster. . ",MatchSource.DOCS,roofit/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html:2652,Usability,usab,usable,2652,"ew algorithmic optimization in the caching of pdfs. So far - in the likelihood - two classes of; objects are identified: those that change with every event (i.e. the pdf) and those that change; only with the parameters (typically pdf normalization integrals). Pdfs are always recalculated; for every event, whereas integrals are only evaluated when needed. The exception to the first type are pdfs; that only depend on constant parameters (or no parameters) - these are identified at the beginning, and precalculated once ; to avoid recalculating an expression with the same outcome for every iteration of the likelihood calculation. For composite pdfs a further optimization has been included: for a M(x,a,b) = f*F(x,a)+(1-f)G(x,b) ; it is e.g. not needed to recalculate G(x,b) if only parameter a has changed w.r.t to the previous likelihood; calculation. This optimization is now implemented by extending the value caching originally designed; for constant terms to be usable for non-constant terms, with a check executed at the beginning of each; likelihood evaluation if selected columns need to be updated because parameters have changed. The speed gain; of this optimization depends much on the structure of the pdf: in models with many free parameters most of the; likelihood evaluations are executed when MINUIT calculates numerical likelihood derivatives which vary ; one parameter at a time and the speedup is potentially larger. In models with few free parameters the; effect will be smaller. The new per-component caching strategy is enabled by default for all pdfs that are a component of; a RooAddPdf or a RooRealSumPdf, unless that component is a RooProdPdf or a RooProduct, in that; case the components of the product are cached instead of the product itself. You can disable this; new optimization by adding Optimize(1) to the RooAbsPdf::fitTo() command line (0 = no caching,; 1 = cache constant terms only, 2 = cache also variable terms according to above mentioned strategy (DEFAUL",MatchSource.DOCS,roofit/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html:4342,Usability,simpl,simple,4342," a RooProdPdf or a RooProduct, in that; case the components of the product are cached instead of the product itself. You can disable this; new optimization by adding Optimize(1) to the RooAbsPdf::fitTo() command line (0 = no caching,; 1 = cache constant terms only, 2 = cache also variable terms according to above mentioned strategy (DEFAULT)). It is also possible to tune this 'cache-and-track' optimization to perform a more fine-grained caching; of components than Optimize(2) implements: to do so, call arg->setAttribute(""CacheAndTrack"") on each; pdf component that you'd like to be cache-and-tracked individually. New pdf/data attach mechanism in likelihood objects (RooAbsOptTestStatistic). The new mechanism only; reattaches the dataset branch buffers and not the RooRealVars representing the data. This new designs; allows for a much faster RooAbsTestStatistic::setData() implementation, which changes the dataset in; an existing likelihood object. This will speed up RooStats tools based on 'simple' likelihood models; substantially. Automatic detections of 'binned' pdfs and automatic generation of binned data in generate(). RooFit will; now automatically generate binned pdf shapes. Binned pdfs shapes are fundamentally RooHistPdf and RooHistFuncs; (with interpolation order set to zero). Products and sums of exclusively binned shapes are also recognized; as binned shapes. For such binned shapes generate() will now by default follow the 'binned' strategy ; -- that is, take the expectation value in each bin and sample a Poisson distribution from that -- rather; than follow the unbinned strategy. The rationale is that such datasets result in much faster likelihood; calculations (for nbin smaller than nevent). The optimization is also exact: the likelihood of a binned ; data using a binned pdf is identical to that of an unbinned dataset with a binned pdf. Nevertheless you can ; switch off this feature by passing AutoBinned(false) to RooAbsPdf::generate(). Mixed binned/unbinned",MatchSource.DOCS,roofit/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/roofit/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v520/index.html:2556,Availability,avail,available,2556,"g in Cuts,FDA: Entirely new; Simulated Annealing (SA) algorithm for global minimisation; in presence of local minima (optionally used in cut; optimisation (MethodCuts) and the Function Discriminant; (MethodFDA)). The SA algorithm features two approaches,; one starting at minimal temperature (ie, from within a; local minimum), slowly increasing, and another one; starting at high temperature, slowly decreasing into a; minimum. Code developed and written by Kamil Bartlomiej; Kraszewski, Maciej Kruk and Krzysztof Danielowski from IFJ; and AGH/UJ, Krakow, Poland.; ; Cuts: Added printouts, quoting the explicit cut; application for given signal efficiency. In case of; transformations of the input variables, the full expressions; are given. Added warning to Fisher in case of variable; normalisation. ; ; Cuts: Added physical limits to min/max cuts if; smart option is used.; ; BDT: removed hard-coded weight file name; now,; paths and names of weight files are written as TObjStrings; into ROOT target file, and retrieved for plotting;; available weight files (corresponding to target used) can; be chosen from pop-up GUI.; ; BDT: Changes in handling negative weights in BDT; algorithm. Events with negative weights now get their; weight reduced (*= 1/boostweight) rather than increased; (*= boostweight) as the other events do. Otherwise these; events tend to receive increasingly stronger boosts,; because their effects on the separation gain are as if; background events were selected as signal and vice versa; (hence the events tend to be ""wanted"" in signal nodes, but; are boosted as if they were misclassified). In addition,; the separation indices are protected against negative S or; S+B returning 0.5 (no separation at all) in case that; occurs.; ; BDT: In addition there is a new BDT option to; ignore events with negative event weights for the; training. This option could be used as a cross check of a; ""worst case"" solution for Monte Carlo samples with; negative weights. Note that the",MatchSource.DOCS,tmva/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v520/index.html:2757,Energy Efficiency,reduce,reduced,2757,"starting at minimal temperature (ie, from within a; local minimum), slowly increasing, and another one; starting at high temperature, slowly decreasing into a; minimum. Code developed and written by Kamil Bartlomiej; Kraszewski, Maciej Kruk and Krzysztof Danielowski from IFJ; and AGH/UJ, Krakow, Poland.; ; Cuts: Added printouts, quoting the explicit cut; application for given signal efficiency. In case of; transformations of the input variables, the full expressions; are given. Added warning to Fisher in case of variable; normalisation. ; ; Cuts: Added physical limits to min/max cuts if; smart option is used.; ; BDT: removed hard-coded weight file name; now,; paths and names of weight files are written as TObjStrings; into ROOT target file, and retrieved for plotting;; available weight files (corresponding to target used) can; be chosen from pop-up GUI.; ; BDT: Changes in handling negative weights in BDT; algorithm. Events with negative weights now get their; weight reduced (*= 1/boostweight) rather than increased; (*= boostweight) as the other events do. Otherwise these; events tend to receive increasingly stronger boosts,; because their effects on the separation gain are as if; background events were selected as signal and vice versa; (hence the events tend to be ""wanted"" in signal nodes, but; are boosted as if they were misclassified). In addition,; the separation indices are protected against negative S or; S+B returning 0.5 (no separation at all) in case that; occurs.; ; BDT: In addition there is a new BDT option to; ignore events with negative event weights for the; training. This option could be used as a cross check of a; ""worst case"" solution for Monte Carlo samples with; negative weights. Note that the results of the testing; phase still include these events and are hence objective.; ; BDT: Added randomised trees: similar to the; ""Random Forests"" technique of Leo Breiman and Adele; Cutler, it uses the ""bagging"" algorithm and bases the; determination of the",MatchSource.DOCS,tmva/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v520/index.html:1206,Modifiability,variab,variables,1206,"ent to signal/background: Signal and; background trees can now be assigned individually to training; and test purposes. This is achieved by setting the third; parameter of the Factory::AddSignalTree/AddBackgroundTree(); methods to ""Train"" or ""Test"" (const string). The only; restriction is that either none or all signal (background); trees need to be specified with that option. It is possible to; mix the two modes, for instance one can assign individual; training and test trees for signal, but not for background.; ; Direct tree building: For increased flexibility,; users can also directly input signal and background,; training and test events to TMVA, instead of letting TMVA; interpret user-given trees. Note that either one of the; two approaches must be chosen (no mix). The syntax of the; new calls is described in the macros/TMVAnalysis.C test; macro. --> The User runs the event loop, copies for each; event the input variables into a std:vector, and ""adds""; them to TMVA, using the dedicated calls:; factory->AddSignalTrainingEvent( vars, signalWeight );; (and replacing ""Signal"" by ""Background"", and ""Training"" by; ""Test""). After the event loop, everything continues as in; the standard method.; . Methods:. Simulated Annealing in Cuts,FDA: Entirely new; Simulated Annealing (SA) algorithm for global minimisation; in presence of local minima (optionally used in cut; optimisation (MethodCuts) and the Function Discriminant; (MethodFDA)). The SA algorithm features two approaches,; one starting at minimal temperature (ie, from within a; local minimum), slowly increasing, and another one; starting at high temperature, slowly decreasing into a; minimum. Code developed and written by Kamil Bartlomiej; Kraszewski, Maciej Kruk and Krzysztof Danielowski from IFJ; and AGH/UJ, Krakow, Poland.; ; Cuts: Added printouts, quoting the explicit cut; application for given signal efficiency. In case of; transformations of the input variables, the full expressions; are given. Added warning to ",MatchSource.DOCS,tmva/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v520/index.html:2215,Modifiability,variab,variables,2215," into a std:vector, and ""adds""; them to TMVA, using the dedicated calls:; factory->AddSignalTrainingEvent( vars, signalWeight );; (and replacing ""Signal"" by ""Background"", and ""Training"" by; ""Test""). After the event loop, everything continues as in; the standard method.; . Methods:. Simulated Annealing in Cuts,FDA: Entirely new; Simulated Annealing (SA) algorithm for global minimisation; in presence of local minima (optionally used in cut; optimisation (MethodCuts) and the Function Discriminant; (MethodFDA)). The SA algorithm features two approaches,; one starting at minimal temperature (ie, from within a; local minimum), slowly increasing, and another one; starting at high temperature, slowly decreasing into a; minimum. Code developed and written by Kamil Bartlomiej; Kraszewski, Maciej Kruk and Krzysztof Danielowski from IFJ; and AGH/UJ, Krakow, Poland.; ; Cuts: Added printouts, quoting the explicit cut; application for given signal efficiency. In case of; transformations of the input variables, the full expressions; are given. Added warning to Fisher in case of variable; normalisation. ; ; Cuts: Added physical limits to min/max cuts if; smart option is used.; ; BDT: removed hard-coded weight file name; now,; paths and names of weight files are written as TObjStrings; into ROOT target file, and retrieved for plotting;; available weight files (corresponding to target used) can; be chosen from pop-up GUI.; ; BDT: Changes in handling negative weights in BDT; algorithm. Events with negative weights now get their; weight reduced (*= 1/boostweight) rather than increased; (*= boostweight) as the other events do. Otherwise these; events tend to receive increasingly stronger boosts,; because their effects on the separation gain are as if; background events were selected as signal and vice versa; (hence the events tend to be ""wanted"" in signal nodes, but; are boosted as if they were misclassified). In addition,; the separation indices are protected against negative S or; S+B r",MatchSource.DOCS,tmva/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v520/index.html:2294,Modifiability,variab,variable,2294," factory->AddSignalTrainingEvent( vars, signalWeight );; (and replacing ""Signal"" by ""Background"", and ""Training"" by; ""Test""). After the event loop, everything continues as in; the standard method.; . Methods:. Simulated Annealing in Cuts,FDA: Entirely new; Simulated Annealing (SA) algorithm for global minimisation; in presence of local minima (optionally used in cut; optimisation (MethodCuts) and the Function Discriminant; (MethodFDA)). The SA algorithm features two approaches,; one starting at minimal temperature (ie, from within a; local minimum), slowly increasing, and another one; starting at high temperature, slowly decreasing into a; minimum. Code developed and written by Kamil Bartlomiej; Kraszewski, Maciej Kruk and Krzysztof Danielowski from IFJ; and AGH/UJ, Krakow, Poland.; ; Cuts: Added printouts, quoting the explicit cut; application for given signal efficiency. In case of; transformations of the input variables, the full expressions; are given. Added warning to Fisher in case of variable; normalisation. ; ; Cuts: Added physical limits to min/max cuts if; smart option is used.; ; BDT: removed hard-coded weight file name; now,; paths and names of weight files are written as TObjStrings; into ROOT target file, and retrieved for plotting;; available weight files (corresponding to target used) can; be chosen from pop-up GUI.; ; BDT: Changes in handling negative weights in BDT; algorithm. Events with negative weights now get their; weight reduced (*= 1/boostweight) rather than increased; (*= boostweight) as the other events do. Otherwise these; events tend to receive increasingly stronger boosts,; because their effects on the separation gain are as if; background events were selected as signal and vice versa; (hence the events tend to be ""wanted"" in signal nodes, but; are boosted as if they were misclassified). In addition,; the separation indices are protected against negative S or; S+B returning 0.5 (no separation at all) in case that; occurs.; ; BDT: In add",MatchSource.DOCS,tmva/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v520/index.html:3836,Modifiability,variab,variables,3836,"; weight reduced (*= 1/boostweight) rather than increased; (*= boostweight) as the other events do. Otherwise these; events tend to receive increasingly stronger boosts,; because their effects on the separation gain are as if; background events were selected as signal and vice versa; (hence the events tend to be ""wanted"" in signal nodes, but; are boosted as if they were misclassified). In addition,; the separation indices are protected against negative S or; S+B returning 0.5 (no separation at all) in case that; occurs.; ; BDT: In addition there is a new BDT option to; ignore events with negative event weights for the; training. This option could be used as a cross check of a; ""worst case"" solution for Monte Carlo samples with; negative weights. Note that the results of the testing; phase still include these events and are hence objective.; ; BDT: Added randomised trees: similar to the; ""Random Forests"" technique of Leo Breiman and Adele; Cutler, it uses the ""bagging"" algorithm and bases the; determination of the best node-split during the training; on a random subset of variables only, which is; individually chosen for each split.; ; BDT: Move to TRandom2 for the ""bagging"" algorithm; and throw random weights according to Poisson; statistics. (This way the random weights are closer to a; resampling with replacement algorithm.); ; TMlpANN: Extended options to; TMultilayerPerceptron learning methods. Added example for; reader application: TMVApplication.py; . GUI:. Parallel Coordinates: New GUI button for Parallel; Coordinate plotting.; . Application:. Added Python example for reader application: TMVApplication.py; . Bug fixes:. TMlpANN: fixed crash with ROOT>=5.17 when using; large number of test events; also corrected bias in cross; validation: before the test events were used, which led to; an overestimated performance evaluation in case of a small; number of degrees of freedom; separate now training tree; in two parts for training and validation with configurable;",MatchSource.DOCS,tmva/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v520/index.html:4735,Modifiability,config,configurable,4735,"ing"" algorithm and bases the; determination of the best node-split during the training; on a random subset of variables only, which is; individually chosen for each split.; ; BDT: Move to TRandom2 for the ""bagging"" algorithm; and throw random weights according to Poisson; statistics. (This way the random weights are closer to a; resampling with replacement algorithm.); ; TMlpANN: Extended options to; TMultilayerPerceptron learning methods. Added example for; reader application: TMVApplication.py; . GUI:. Parallel Coordinates: New GUI button for Parallel; Coordinate plotting.; . Application:. Added Python example for reader application: TMVApplication.py; . Bug fixes:. TMlpANN: fixed crash with ROOT>=5.17 when using; large number of test events; also corrected bias in cross; validation: before the test events were used, which led to; an overestimated performance evaluation in case of a small; number of degrees of freedom; separate now training tree; in two parts for training and validation with configurable; ValidationFraction; ; Cuts: Corrected inconsistency in MethodCuts:; the signal efficiency written out into the weight file does; not correspond to the center of the bin within which the; background rejection is maximised (as before) but to the; lower left edge of it. This is because the cut optimisation; algorithm determines the best background rejection for all; signal efficiencies belonging into a bin. Since the best; background rejection is in general obtained for the lowest; possible signal efficiency, the reference signal efficiency; is the lowest value in the bin.; ; Cuts: Fixed Cuts (optimisaton) method -> event; with smallest value was not included in search for optimal; cut (thanks to Dimitris Varouchas, LAL-Orsay, for helping; us detecting the problem).; ; Genetic Algorithm: Corrected configurable random; seed in GeneticAlgorithm (thanks to David Gonzalez Maline,; CERN, for pointing this out); ; GUI: Fixes in input-variable and MVA plotting:; under/over-",MatchSource.DOCS,tmva/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v520/index.html:5555,Modifiability,config,configurable,5555,"dom2 for the ""bagging"" algorithm; and throw random weights according to Poisson; statistics. (This way the random weights are closer to a; resampling with replacement algorithm.); ; TMlpANN: Extended options to; TMultilayerPerceptron learning methods. Added example for; reader application: TMVApplication.py; . GUI:. Parallel Coordinates: New GUI button for Parallel; Coordinate plotting.; . Application:. Added Python example for reader application: TMVApplication.py; . Bug fixes:. TMlpANN: fixed crash with ROOT>=5.17 when using; large number of test events; also corrected bias in cross; validation: before the test events were used, which led to; an overestimated performance evaluation in case of a small; number of degrees of freedom; separate now training tree; in two parts for training and validation with configurable; ValidationFraction; ; Cuts: Corrected inconsistency in MethodCuts:; the signal efficiency written out into the weight file does; not correspond to the center of the bin within which the; background rejection is maximised (as before) but to the; lower left edge of it. This is because the cut optimisation; algorithm determines the best background rejection for all; signal efficiencies belonging into a bin. Since the best; background rejection is in general obtained for the lowest; possible signal efficiency, the reference signal efficiency; is the lowest value in the bin.; ; Cuts: Fixed Cuts (optimisaton) method -> event; with smallest value was not included in search for optimal; cut (thanks to Dimitris Varouchas, LAL-Orsay, for helping; us detecting the problem).; ; Genetic Algorithm: Corrected configurable random; seed in GeneticAlgorithm (thanks to David Gonzalez Maline,; CERN, for pointing this out); ; GUI: Fixes in input-variable and MVA plotting:; under/over-flow numbers given on plots were not properly; normalised; the maximum histogram ranges have been; increased to avoid cut-offs. Thanks to Andreas Wenger,; Zuerich, for pointing these out.; . ",MatchSource.DOCS,tmva/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v520/index.html:5688,Modifiability,variab,variable,5688,"dom2 for the ""bagging"" algorithm; and throw random weights according to Poisson; statistics. (This way the random weights are closer to a; resampling with replacement algorithm.); ; TMlpANN: Extended options to; TMultilayerPerceptron learning methods. Added example for; reader application: TMVApplication.py; . GUI:. Parallel Coordinates: New GUI button for Parallel; Coordinate plotting.; . Application:. Added Python example for reader application: TMVApplication.py; . Bug fixes:. TMlpANN: fixed crash with ROOT>=5.17 when using; large number of test events; also corrected bias in cross; validation: before the test events were used, which led to; an overestimated performance evaluation in case of a small; number of degrees of freedom; separate now training tree; in two parts for training and validation with configurable; ValidationFraction; ; Cuts: Corrected inconsistency in MethodCuts:; the signal efficiency written out into the weight file does; not correspond to the center of the bin within which the; background rejection is maximised (as before) but to the; lower left edge of it. This is because the cut optimisation; algorithm determines the best background rejection for all; signal efficiencies belonging into a bin. Since the best; background rejection is in general obtained for the lowest; possible signal efficiency, the reference signal efficiency; is the lowest value in the bin.; ; Cuts: Fixed Cuts (optimisaton) method -> event; with smallest value was not included in search for optimal; cut (thanks to Dimitris Varouchas, LAL-Orsay, for helping; us detecting the problem).; ; Genetic Algorithm: Corrected configurable random; seed in GeneticAlgorithm (thanks to David Gonzalez Maline,; CERN, for pointing this out); ; GUI: Fixes in input-variable and MVA plotting:; under/over-flow numbers given on plots were not properly; normalised; the maximum histogram ranges have been; increased to avoid cut-offs. Thanks to Andreas Wenger,; Zuerich, for pointing these out.; . ",MatchSource.DOCS,tmva/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v520/index.html:4588,Performance,perform,performance,4588,"ing"" algorithm and bases the; determination of the best node-split during the training; on a random subset of variables only, which is; individually chosen for each split.; ; BDT: Move to TRandom2 for the ""bagging"" algorithm; and throw random weights according to Poisson; statistics. (This way the random weights are closer to a; resampling with replacement algorithm.); ; TMlpANN: Extended options to; TMultilayerPerceptron learning methods. Added example for; reader application: TMVApplication.py; . GUI:. Parallel Coordinates: New GUI button for Parallel; Coordinate plotting.; . Application:. Added Python example for reader application: TMVApplication.py; . Bug fixes:. TMlpANN: fixed crash with ROOT>=5.17 when using; large number of test events; also corrected bias in cross; validation: before the test events were used, which led to; an overestimated performance evaluation in case of a small; number of degrees of freedom; separate now training tree; in two parts for training and validation with configurable; ValidationFraction; ; Cuts: Corrected inconsistency in MethodCuts:; the signal efficiency written out into the weight file does; not correspond to the center of the bin within which the; background rejection is maximised (as before) but to the; lower left edge of it. This is because the cut optimisation; algorithm determines the best background rejection for all; signal efficiencies belonging into a bin. Since the best; background rejection is in general obtained for the lowest; possible signal efficiency, the reference signal efficiency; is the lowest value in the bin.; ; Cuts: Fixed Cuts (optimisaton) method -> event; with smallest value was not included in search for optimal; cut (thanks to Dimitris Varouchas, LAL-Orsay, for helping; us detecting the problem).; ; Genetic Algorithm: Corrected configurable random; seed in GeneticAlgorithm (thanks to David Gonzalez Maline,; CERN, for pointing this out); ; GUI: Fixes in input-variable and MVA plotting:; under/over-",MatchSource.DOCS,tmva/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v520/index.html:5499,Safety,detect,detecting,5499,"dom2 for the ""bagging"" algorithm; and throw random weights according to Poisson; statistics. (This way the random weights are closer to a; resampling with replacement algorithm.); ; TMlpANN: Extended options to; TMultilayerPerceptron learning methods. Added example for; reader application: TMVApplication.py; . GUI:. Parallel Coordinates: New GUI button for Parallel; Coordinate plotting.; . Application:. Added Python example for reader application: TMVApplication.py; . Bug fixes:. TMlpANN: fixed crash with ROOT>=5.17 when using; large number of test events; also corrected bias in cross; validation: before the test events were used, which led to; an overestimated performance evaluation in case of a small; number of degrees of freedom; separate now training tree; in two parts for training and validation with configurable; ValidationFraction; ; Cuts: Corrected inconsistency in MethodCuts:; the signal efficiency written out into the weight file does; not correspond to the center of the bin within which the; background rejection is maximised (as before) but to the; lower left edge of it. This is because the cut optimisation; algorithm determines the best background rejection for all; signal efficiencies belonging into a bin. Since the best; background rejection is in general obtained for the lowest; possible signal efficiency, the reference signal efficiency; is the lowest value in the bin.; ; Cuts: Fixed Cuts (optimisaton) method -> event; with smallest value was not included in search for optimal; cut (thanks to Dimitris Varouchas, LAL-Orsay, for helping; us detecting the problem).; ; Genetic Algorithm: Corrected configurable random; seed in GeneticAlgorithm (thanks to David Gonzalez Maline,; CERN, for pointing this out); ; GUI: Fixes in input-variable and MVA plotting:; under/over-flow numbers given on plots were not properly; normalised; the maximum histogram ranges have been; increased to avoid cut-offs. Thanks to Andreas Wenger,; Zuerich, for pointing these out.; . ",MatchSource.DOCS,tmva/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v520/index.html:5839,Safety,avoid,avoid,5839,"dom2 for the ""bagging"" algorithm; and throw random weights according to Poisson; statistics. (This way the random weights are closer to a; resampling with replacement algorithm.); ; TMlpANN: Extended options to; TMultilayerPerceptron learning methods. Added example for; reader application: TMVApplication.py; . GUI:. Parallel Coordinates: New GUI button for Parallel; Coordinate plotting.; . Application:. Added Python example for reader application: TMVApplication.py; . Bug fixes:. TMlpANN: fixed crash with ROOT>=5.17 when using; large number of test events; also corrected bias in cross; validation: before the test events were used, which led to; an overestimated performance evaluation in case of a small; number of degrees of freedom; separate now training tree; in two parts for training and validation with configurable; ValidationFraction; ; Cuts: Corrected inconsistency in MethodCuts:; the signal efficiency written out into the weight file does; not correspond to the center of the bin within which the; background rejection is maximised (as before) but to the; lower left edge of it. This is because the cut optimisation; algorithm determines the best background rejection for all; signal efficiencies belonging into a bin. Since the best; background rejection is in general obtained for the lowest; possible signal efficiency, the reference signal efficiency; is the lowest value in the bin.; ; Cuts: Fixed Cuts (optimisaton) method -> event; with smallest value was not included in search for optimal; cut (thanks to Dimitris Varouchas, LAL-Orsay, for helping; us detecting the problem).; ; Genetic Algorithm: Corrected configurable random; seed in GeneticAlgorithm (thanks to David Gonzalez Maline,; CERN, for pointing this out); ; GUI: Fixes in input-variable and MVA plotting:; under/over-flow numbers given on plots were not properly; normalised; the maximum histogram ranges have been; increased to avoid cut-offs. Thanks to Andreas Wenger,; Zuerich, for pointing these out.; . ",MatchSource.DOCS,tmva/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v520/index.html:4511,Security,validat,validation,4511,"ing"" algorithm and bases the; determination of the best node-split during the training; on a random subset of variables only, which is; individually chosen for each split.; ; BDT: Move to TRandom2 for the ""bagging"" algorithm; and throw random weights according to Poisson; statistics. (This way the random weights are closer to a; resampling with replacement algorithm.); ; TMlpANN: Extended options to; TMultilayerPerceptron learning methods. Added example for; reader application: TMVApplication.py; . GUI:. Parallel Coordinates: New GUI button for Parallel; Coordinate plotting.; . Application:. Added Python example for reader application: TMVApplication.py; . Bug fixes:. TMlpANN: fixed crash with ROOT>=5.17 when using; large number of test events; also corrected bias in cross; validation: before the test events were used, which led to; an overestimated performance evaluation in case of a small; number of degrees of freedom; separate now training tree; in two parts for training and validation with configurable; ValidationFraction; ; Cuts: Corrected inconsistency in MethodCuts:; the signal efficiency written out into the weight file does; not correspond to the center of the bin within which the; background rejection is maximised (as before) but to the; lower left edge of it. This is because the cut optimisation; algorithm determines the best background rejection for all; signal efficiencies belonging into a bin. Since the best; background rejection is in general obtained for the lowest; possible signal efficiency, the reference signal efficiency; is the lowest value in the bin.; ; Cuts: Fixed Cuts (optimisaton) method -> event; with smallest value was not included in search for optimal; cut (thanks to Dimitris Varouchas, LAL-Orsay, for helping; us detecting the problem).; ; Genetic Algorithm: Corrected configurable random; seed in GeneticAlgorithm (thanks to David Gonzalez Maline,; CERN, for pointing this out); ; GUI: Fixes in input-variable and MVA plotting:; under/over-",MatchSource.DOCS,tmva/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v520/index.html:4719,Security,validat,validation,4719,"ing"" algorithm and bases the; determination of the best node-split during the training; on a random subset of variables only, which is; individually chosen for each split.; ; BDT: Move to TRandom2 for the ""bagging"" algorithm; and throw random weights according to Poisson; statistics. (This way the random weights are closer to a; resampling with replacement algorithm.); ; TMlpANN: Extended options to; TMultilayerPerceptron learning methods. Added example for; reader application: TMVApplication.py; . GUI:. Parallel Coordinates: New GUI button for Parallel; Coordinate plotting.; . Application:. Added Python example for reader application: TMVApplication.py; . Bug fixes:. TMlpANN: fixed crash with ROOT>=5.17 when using; large number of test events; also corrected bias in cross; validation: before the test events were used, which led to; an overestimated performance evaluation in case of a small; number of degrees of freedom; separate now training tree; in two parts for training and validation with configurable; ValidationFraction; ; Cuts: Corrected inconsistency in MethodCuts:; the signal efficiency written out into the weight file does; not correspond to the center of the bin within which the; background rejection is maximised (as before) but to the; lower left edge of it. This is because the cut optimisation; algorithm determines the best background rejection for all; signal efficiencies belonging into a bin. Since the best; background rejection is in general obtained for the lowest; possible signal efficiency, the reference signal efficiency; is the lowest value in the bin.; ; Cuts: Fixed Cuts (optimisaton) method -> event; with smallest value was not included in search for optimal; cut (thanks to Dimitris Varouchas, LAL-Orsay, for helping; us detecting the problem).; ; Genetic Algorithm: Corrected configurable random; seed in GeneticAlgorithm (thanks to David Gonzalez Maline,; CERN, for pointing this out); ; GUI: Fixes in input-variable and MVA plotting:; under/over-",MatchSource.DOCS,tmva/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v520/index.html:380,Testability,test,test,380,". TMVA. Dataset preparation:. Preselection: Preselection cuts now work on; arrays. Previously used TEventlists (only event wise; pass/fail) were replaced by TreeFormulas (sensitive to array; position). Thanks to Arnaud Robert (LPNHE) for his; contributions.; ; ; Tree assignment to signal/background: Signal and; background trees can now be assigned individually to training; and test purposes. This is achieved by setting the third; parameter of the Factory::AddSignalTree/AddBackgroundTree(); methods to ""Train"" or ""Test"" (const string). The only; restriction is that either none or all signal (background); trees need to be specified with that option. It is possible to; mix the two modes, for instance one can assign individual; training and test trees for signal, but not for background.; ; Direct tree building: For increased flexibility,; users can also directly input signal and background,; training and test events to TMVA, instead of letting TMVA; interpret user-given trees. Note that either one of the; two approaches must be chosen (no mix). The syntax of the; new calls is described in the macros/TMVAnalysis.C test; macro. --> The User runs the event loop, copies for each; event the input variables into a std:vector, and ""adds""; them to TMVA, using the dedicated calls:; factory->AddSignalTrainingEvent( vars, signalWeight );; (and replacing ""Signal"" by ""Background"", and ""Training"" by; ""Test""). After the event loop, everything continues as in; the standard method.; . Methods:. Simulated Annealing in Cuts,FDA: Entirely new; Simulated Annealing (SA) algorithm for global minimisation; in presence of local minima (optionally used in cut; optimisation (MethodCuts) and the Function Discriminant; (MethodFDA)). The SA algorithm features two approaches,; one starting at minimal temperature (ie, from within a; local minimum), slowly increasing, and another one; starting at high temperature, slowly decreasing into a; minimum. Code developed and written by Kamil Bartlomiej; Kraszews",MatchSource.DOCS,tmva/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v520/index.html:746,Testability,test,test,746,". TMVA. Dataset preparation:. Preselection: Preselection cuts now work on; arrays. Previously used TEventlists (only event wise; pass/fail) were replaced by TreeFormulas (sensitive to array; position). Thanks to Arnaud Robert (LPNHE) for his; contributions.; ; ; Tree assignment to signal/background: Signal and; background trees can now be assigned individually to training; and test purposes. This is achieved by setting the third; parameter of the Factory::AddSignalTree/AddBackgroundTree(); methods to ""Train"" or ""Test"" (const string). The only; restriction is that either none or all signal (background); trees need to be specified with that option. It is possible to; mix the two modes, for instance one can assign individual; training and test trees for signal, but not for background.; ; Direct tree building: For increased flexibility,; users can also directly input signal and background,; training and test events to TMVA, instead of letting TMVA; interpret user-given trees. Note that either one of the; two approaches must be chosen (no mix). The syntax of the; new calls is described in the macros/TMVAnalysis.C test; macro. --> The User runs the event loop, copies for each; event the input variables into a std:vector, and ""adds""; them to TMVA, using the dedicated calls:; factory->AddSignalTrainingEvent( vars, signalWeight );; (and replacing ""Signal"" by ""Background"", and ""Training"" by; ""Test""). After the event loop, everything continues as in; the standard method.; . Methods:. Simulated Annealing in Cuts,FDA: Entirely new; Simulated Annealing (SA) algorithm for global minimisation; in presence of local minima (optionally used in cut; optimisation (MethodCuts) and the Function Discriminant; (MethodFDA)). The SA algorithm features two approaches,; one starting at minimal temperature (ie, from within a; local minimum), slowly increasing, and another one; starting at high temperature, slowly decreasing into a; minimum. Code developed and written by Kamil Bartlomiej; Kraszews",MatchSource.DOCS,tmva/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v520/index.html:913,Testability,test,test,913,". TMVA. Dataset preparation:. Preselection: Preselection cuts now work on; arrays. Previously used TEventlists (only event wise; pass/fail) were replaced by TreeFormulas (sensitive to array; position). Thanks to Arnaud Robert (LPNHE) for his; contributions.; ; ; Tree assignment to signal/background: Signal and; background trees can now be assigned individually to training; and test purposes. This is achieved by setting the third; parameter of the Factory::AddSignalTree/AddBackgroundTree(); methods to ""Train"" or ""Test"" (const string). The only; restriction is that either none or all signal (background); trees need to be specified with that option. It is possible to; mix the two modes, for instance one can assign individual; training and test trees for signal, but not for background.; ; Direct tree building: For increased flexibility,; users can also directly input signal and background,; training and test events to TMVA, instead of letting TMVA; interpret user-given trees. Note that either one of the; two approaches must be chosen (no mix). The syntax of the; new calls is described in the macros/TMVAnalysis.C test; macro. --> The User runs the event loop, copies for each; event the input variables into a std:vector, and ""adds""; them to TMVA, using the dedicated calls:; factory->AddSignalTrainingEvent( vars, signalWeight );; (and replacing ""Signal"" by ""Background"", and ""Training"" by; ""Test""). After the event loop, everything continues as in; the standard method.; . Methods:. Simulated Annealing in Cuts,FDA: Entirely new; Simulated Annealing (SA) algorithm for global minimisation; in presence of local minima (optionally used in cut; optimisation (MethodCuts) and the Function Discriminant; (MethodFDA)). The SA algorithm features two approaches,; one starting at minimal temperature (ie, from within a; local minimum), slowly increasing, and another one; starting at high temperature, slowly decreasing into a; minimum. Code developed and written by Kamil Bartlomiej; Kraszews",MatchSource.DOCS,tmva/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v520/index.html:1126,Testability,test,test,1126,"ss/fail) were replaced by TreeFormulas (sensitive to array; position). Thanks to Arnaud Robert (LPNHE) for his; contributions.; ; ; Tree assignment to signal/background: Signal and; background trees can now be assigned individually to training; and test purposes. This is achieved by setting the third; parameter of the Factory::AddSignalTree/AddBackgroundTree(); methods to ""Train"" or ""Test"" (const string). The only; restriction is that either none or all signal (background); trees need to be specified with that option. It is possible to; mix the two modes, for instance one can assign individual; training and test trees for signal, but not for background.; ; Direct tree building: For increased flexibility,; users can also directly input signal and background,; training and test events to TMVA, instead of letting TMVA; interpret user-given trees. Note that either one of the; two approaches must be chosen (no mix). The syntax of the; new calls is described in the macros/TMVAnalysis.C test; macro. --> The User runs the event loop, copies for each; event the input variables into a std:vector, and ""adds""; them to TMVA, using the dedicated calls:; factory->AddSignalTrainingEvent( vars, signalWeight );; (and replacing ""Signal"" by ""Background"", and ""Training"" by; ""Test""). After the event loop, everything continues as in; the standard method.; . Methods:. Simulated Annealing in Cuts,FDA: Entirely new; Simulated Annealing (SA) algorithm for global minimisation; in presence of local minima (optionally used in cut; optimisation (MethodCuts) and the Function Discriminant; (MethodFDA)). The SA algorithm features two approaches,; one starting at minimal temperature (ie, from within a; local minimum), slowly increasing, and another one; starting at high temperature, slowly decreasing into a; minimum. Code developed and written by Kamil Bartlomiej; Kraszewski, Maciej Kruk and Krzysztof Danielowski from IFJ; and AGH/UJ, Krakow, Poland.; ; Cuts: Added printouts, quoting the explicit cut",MatchSource.DOCS,tmva/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v520/index.html:3533,Testability,test,testing,3533,"ng;; available weight files (corresponding to target used) can; be chosen from pop-up GUI.; ; BDT: Changes in handling negative weights in BDT; algorithm. Events with negative weights now get their; weight reduced (*= 1/boostweight) rather than increased; (*= boostweight) as the other events do. Otherwise these; events tend to receive increasingly stronger boosts,; because their effects on the separation gain are as if; background events were selected as signal and vice versa; (hence the events tend to be ""wanted"" in signal nodes, but; are boosted as if they were misclassified). In addition,; the separation indices are protected against negative S or; S+B returning 0.5 (no separation at all) in case that; occurs.; ; BDT: In addition there is a new BDT option to; ignore events with negative event weights for the; training. This option could be used as a cross check of a; ""worst case"" solution for Monte Carlo samples with; negative weights. Note that the results of the testing; phase still include these events and are hence objective.; ; BDT: Added randomised trees: similar to the; ""Random Forests"" technique of Leo Breiman and Adele; Cutler, it uses the ""bagging"" algorithm and bases the; determination of the best node-split during the training; on a random subset of variables only, which is; individually chosen for each split.; ; BDT: Move to TRandom2 for the ""bagging"" algorithm; and throw random weights according to Poisson; statistics. (This way the random weights are closer to a; resampling with replacement algorithm.); ; TMlpANN: Extended options to; TMultilayerPerceptron learning methods. Added example for; reader application: TMVApplication.py; . GUI:. Parallel Coordinates: New GUI button for Parallel; Coordinate plotting.; . Application:. Added Python example for reader application: TMVApplication.py; . Bug fixes:. TMlpANN: fixed crash with ROOT>=5.17 when using; large number of test events; also corrected bias in cross; validation: before the test events were ",MatchSource.DOCS,tmva/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v520/index.html:4468,Testability,test,test,4468,"ing"" algorithm and bases the; determination of the best node-split during the training; on a random subset of variables only, which is; individually chosen for each split.; ; BDT: Move to TRandom2 for the ""bagging"" algorithm; and throw random weights according to Poisson; statistics. (This way the random weights are closer to a; resampling with replacement algorithm.); ; TMlpANN: Extended options to; TMultilayerPerceptron learning methods. Added example for; reader application: TMVApplication.py; . GUI:. Parallel Coordinates: New GUI button for Parallel; Coordinate plotting.; . Application:. Added Python example for reader application: TMVApplication.py; . Bug fixes:. TMlpANN: fixed crash with ROOT>=5.17 when using; large number of test events; also corrected bias in cross; validation: before the test events were used, which led to; an overestimated performance evaluation in case of a small; number of degrees of freedom; separate now training tree; in two parts for training and validation with configurable; ValidationFraction; ; Cuts: Corrected inconsistency in MethodCuts:; the signal efficiency written out into the weight file does; not correspond to the center of the bin within which the; background rejection is maximised (as before) but to the; lower left edge of it. This is because the cut optimisation; algorithm determines the best background rejection for all; signal efficiencies belonging into a bin. Since the best; background rejection is in general obtained for the lowest; possible signal efficiency, the reference signal efficiency; is the lowest value in the bin.; ; Cuts: Fixed Cuts (optimisaton) method -> event; with smallest value was not included in search for optimal; cut (thanks to Dimitris Varouchas, LAL-Orsay, for helping; us detecting the problem).; ; Genetic Algorithm: Corrected configurable random; seed in GeneticAlgorithm (thanks to David Gonzalez Maline,; CERN, for pointing this out); ; GUI: Fixes in input-variable and MVA plotting:; under/over-",MatchSource.DOCS,tmva/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v520/index.html:4534,Testability,test,test,4534,"ing"" algorithm and bases the; determination of the best node-split during the training; on a random subset of variables only, which is; individually chosen for each split.; ; BDT: Move to TRandom2 for the ""bagging"" algorithm; and throw random weights according to Poisson; statistics. (This way the random weights are closer to a; resampling with replacement algorithm.); ; TMlpANN: Extended options to; TMultilayerPerceptron learning methods. Added example for; reader application: TMVApplication.py; . GUI:. Parallel Coordinates: New GUI button for Parallel; Coordinate plotting.; . Application:. Added Python example for reader application: TMVApplication.py; . Bug fixes:. TMlpANN: fixed crash with ROOT>=5.17 when using; large number of test events; also corrected bias in cross; validation: before the test events were used, which led to; an overestimated performance evaluation in case of a small; number of degrees of freedom; separate now training tree; in two parts for training and validation with configurable; ValidationFraction; ; Cuts: Corrected inconsistency in MethodCuts:; the signal efficiency written out into the weight file does; not correspond to the center of the bin within which the; background rejection is maximised (as before) but to the; lower left edge of it. This is because the cut optimisation; algorithm determines the best background rejection for all; signal efficiencies belonging into a bin. Since the best; background rejection is in general obtained for the lowest; possible signal efficiency, the reference signal efficiency; is the lowest value in the bin.; ; Cuts: Fixed Cuts (optimisaton) method -> event; with smallest value was not included in search for optimal; cut (thanks to Dimitris Varouchas, LAL-Orsay, for helping; us detecting the problem).; ; Genetic Algorithm: Corrected configurable random; seed in GeneticAlgorithm (thanks to David Gonzalez Maline,; CERN, for pointing this out); ; GUI: Fixes in input-variable and MVA plotting:; under/over-",MatchSource.DOCS,tmva/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v520/index.html:4152,Usability,learn,learning,4152,"ed). In addition,; the separation indices are protected against negative S or; S+B returning 0.5 (no separation at all) in case that; occurs.; ; BDT: In addition there is a new BDT option to; ignore events with negative event weights for the; training. This option could be used as a cross check of a; ""worst case"" solution for Monte Carlo samples with; negative weights. Note that the results of the testing; phase still include these events and are hence objective.; ; BDT: Added randomised trees: similar to the; ""Random Forests"" technique of Leo Breiman and Adele; Cutler, it uses the ""bagging"" algorithm and bases the; determination of the best node-split during the training; on a random subset of variables only, which is; individually chosen for each split.; ; BDT: Move to TRandom2 for the ""bagging"" algorithm; and throw random weights according to Poisson; statistics. (This way the random weights are closer to a; resampling with replacement algorithm.); ; TMlpANN: Extended options to; TMultilayerPerceptron learning methods. Added example for; reader application: TMVApplication.py; . GUI:. Parallel Coordinates: New GUI button for Parallel; Coordinate plotting.; . Application:. Added Python example for reader application: TMVApplication.py; . Bug fixes:. TMlpANN: fixed crash with ROOT>=5.17 when using; large number of test events; also corrected bias in cross; validation: before the test events were used, which led to; an overestimated performance evaluation in case of a small; number of degrees of freedom; separate now training tree; in two parts for training and validation with configurable; ValidationFraction; ; Cuts: Corrected inconsistency in MethodCuts:; the signal efficiency written out into the weight file does; not correspond to the center of the bin within which the; background rejection is maximised (as before) but to the; lower left edge of it. This is because the cut optimisation; algorithm determines the best background rejection for all; signal efficienci",MatchSource.DOCS,tmva/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v522/index.html:1093,Availability,error,error,1093,"iguration options The; page is automatically generated for each new release. Next to; the classifiers also exist information links for hints to; improve the classifier performance (click on the ""i""; button). Many thanks to Zhiyi Liu (Fraser U) for suggesting; this.; ; Methods:. BDT: New Decision Tree Pruning algorithm: Cost; Complexity Pruning a la CART. Written by Doug Schouten; (Fraser U.). It replaces the old CostComplexity and; CostComplexity2 algorithms.; . BDT: New no splitting option (choosable with; NCuts<0) that finds best split point by first sorting the; events for each variable and then looping through all; events, placing the cuts always in the middle between two; of the sorted events, and finding the true possible; maximum separation gain in the training sample by cutting; on this variable.; . BDT, AdaBoost The beta parameter is now an; option (default is 1).; . BDT: The node purity at which a node is; classified as signal (respective background node) for; determining the error fraction in the pruning became a; parameter that can be set via the option NodePurityLimit; (default is 0.5).; . Dataset preparation:. First implementation of a new preprocessing method: transformation of the; variables first into a Gaussian distribution, then performing a decorrelation of; the ""Gaussianised"" variables. The transformation is again done by default such that; (by default) the signal distributions become Gaussian and are decorrelated. Note ; that simultaneous Gaussianisation and decorrelation of signal and background is ; only possible (and done) for methods, such as Likelihood, which test both hypotheses.; . Bug fixes:. Fix in Expected error pruning: Rather than multiplying both sides, the error on ; the node and the sub-tree, with the prune strength, now only the expected error ; of the sub-tree is scaled.; . Fix in FDA parsing of the input formula. There were problems when treating; more than 10 parameters (thanks to Hugh Skottowe for reporting this).; . Calculat",MatchSource.DOCS,tmva/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v522/index.html:1758,Availability,error,error,1758,"h variable and then looping through all; events, placing the cuts always in the middle between two; of the sorted events, and finding the true possible; maximum separation gain in the training sample by cutting; on this variable.; . BDT, AdaBoost The beta parameter is now an; option (default is 1).; . BDT: The node purity at which a node is; classified as signal (respective background node) for; determining the error fraction in the pruning became a; parameter that can be set via the option NodePurityLimit; (default is 0.5).; . Dataset preparation:. First implementation of a new preprocessing method: transformation of the; variables first into a Gaussian distribution, then performing a decorrelation of; the ""Gaussianised"" variables. The transformation is again done by default such that; (by default) the signal distributions become Gaussian and are decorrelated. Note ; that simultaneous Gaussianisation and decorrelation of signal and background is ; only possible (and done) for methods, such as Likelihood, which test both hypotheses.; . Bug fixes:. Fix in Expected error pruning: Rather than multiplying both sides, the error on ; the node and the sub-tree, with the prune strength, now only the expected error ; of the sub-tree is scaled.; . Fix in FDA parsing of the input formula. There were problems when treating; more than 10 parameters (thanks to Hugh Skottowe for reporting this).; . Calculation of ""Separation"": fixed bin-shift and; normalisation bugs. Thanks to Dag Gillberg (Fraser U) for; spotting these.; . Fixed problem in ""SetSignal(Background)WeightExpression"":; signal (background weight expressions not existing in the; background (signal) tree led to an abort of the tree; reading (""Bad numerical expression""). Thanks to Alfio; Rizzo (Brussels) for pointing this out.; . Fixed problem when specifying train and test tree; explicitly. Some code was forgotten in the background; part, creating incompatibilities. Thanks to Zhiyi Liu; (Fraser U) for reporting this.; . ",MatchSource.DOCS,tmva/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v522/index.html:1813,Availability,error,error,1813,"h variable and then looping through all; events, placing the cuts always in the middle between two; of the sorted events, and finding the true possible; maximum separation gain in the training sample by cutting; on this variable.; . BDT, AdaBoost The beta parameter is now an; option (default is 1).; . BDT: The node purity at which a node is; classified as signal (respective background node) for; determining the error fraction in the pruning became a; parameter that can be set via the option NodePurityLimit; (default is 0.5).; . Dataset preparation:. First implementation of a new preprocessing method: transformation of the; variables first into a Gaussian distribution, then performing a decorrelation of; the ""Gaussianised"" variables. The transformation is again done by default such that; (by default) the signal distributions become Gaussian and are decorrelated. Note ; that simultaneous Gaussianisation and decorrelation of signal and background is ; only possible (and done) for methods, such as Likelihood, which test both hypotheses.; . Bug fixes:. Fix in Expected error pruning: Rather than multiplying both sides, the error on ; the node and the sub-tree, with the prune strength, now only the expected error ; of the sub-tree is scaled.; . Fix in FDA parsing of the input formula. There were problems when treating; more than 10 parameters (thanks to Hugh Skottowe for reporting this).; . Calculation of ""Separation"": fixed bin-shift and; normalisation bugs. Thanks to Dag Gillberg (Fraser U) for; spotting these.; . Fixed problem in ""SetSignal(Background)WeightExpression"":; signal (background weight expressions not existing in the; background (signal) tree led to an abort of the tree; reading (""Bad numerical expression""). Thanks to Alfio; Rizzo (Brussels) for pointing this out.; . Fixed problem when specifying train and test tree; explicitly. Some code was forgotten in the background; part, creating incompatibilities. Thanks to Zhiyi Liu; (Fraser U) for reporting this.; . ",MatchSource.DOCS,tmva/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v522/index.html:1898,Availability,error,error,1898,"h variable and then looping through all; events, placing the cuts always in the middle between two; of the sorted events, and finding the true possible; maximum separation gain in the training sample by cutting; on this variable.; . BDT, AdaBoost The beta parameter is now an; option (default is 1).; . BDT: The node purity at which a node is; classified as signal (respective background node) for; determining the error fraction in the pruning became a; parameter that can be set via the option NodePurityLimit; (default is 0.5).; . Dataset preparation:. First implementation of a new preprocessing method: transformation of the; variables first into a Gaussian distribution, then performing a decorrelation of; the ""Gaussianised"" variables. The transformation is again done by default such that; (by default) the signal distributions become Gaussian and are decorrelated. Note ; that simultaneous Gaussianisation and decorrelation of signal and background is ; only possible (and done) for methods, such as Likelihood, which test both hypotheses.; . Bug fixes:. Fix in Expected error pruning: Rather than multiplying both sides, the error on ; the node and the sub-tree, with the prune strength, now only the expected error ; of the sub-tree is scaled.; . Fix in FDA parsing of the input formula. There were problems when treating; more than 10 parameters (thanks to Hugh Skottowe for reporting this).; . Calculation of ""Separation"": fixed bin-shift and; normalisation bugs. Thanks to Dag Gillberg (Fraser U) for; spotting these.; . Fixed problem in ""SetSignal(Background)WeightExpression"":; signal (background weight expressions not existing in the; background (signal) tree led to an abort of the tree; reading (""Bad numerical expression""). Thanks to Alfio; Rizzo (Brussels) for pointing this out.; . Fixed problem when specifying train and test tree; explicitly. Some code was forgotten in the background; part, creating incompatibilities. Thanks to Zhiyi Liu; (Fraser U) for reporting this.; . ",MatchSource.DOCS,tmva/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v522/index.html:88,Deployability,configurat,configuration,88," . TMVA; ; This version corresponds to TMVA version 3.9.5.; ; . New; reference page for configuration options The; page is automatically generated for each new release. Next to; the classifiers also exist information links for hints to; improve the classifier performance (click on the ""i""; button). Many thanks to Zhiyi Liu (Fraser U) for suggesting; this.; ; Methods:. BDT: New Decision Tree Pruning algorithm: Cost; Complexity Pruning a la CART. Written by Doug Schouten; (Fraser U.). It replaces the old CostComplexity and; CostComplexity2 algorithms.; . BDT: New no splitting option (choosable with; NCuts<0) that finds best split point by first sorting the; events for each variable and then looping through all; events, placing the cuts always in the middle between two; of the sorted events, and finding the true possible; maximum separation gain in the training sample by cutting; on this variable.; . BDT, AdaBoost The beta parameter is now an; option (default is 1).; . BDT: The node purity at which a node is; classified as signal (respective background node) for; determining the error fraction in the pruning became a; parameter that can be set via the option NodePurityLimit; (default is 0.5).; . Dataset preparation:. First implementation of a new preprocessing method: transformation of the; variables first into a Gaussian distribution, then performing a decorrelation of; the ""Gaussianised"" variables. The transformation is again done by default such that; (by default) the signal distributions become Gaussian and are decorrelated. Note ; that simultaneous Gaussianisation and decorrelation of signal and background is ; only possible (and done) for methods, such as Likelihood, which test both hypotheses.; . Bug fixes:. Fix in Expected error pruning: Rather than multiplying both sides, the error on ; the node and the sub-tree, with the prune strength, now only the expected error ; of the sub-tree is scaled.; . Fix in FDA parsing of the input formula. There were problems when",MatchSource.DOCS,tmva/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v522/index.html:160,Deployability,release,release,160," . TMVA; ; This version corresponds to TMVA version 3.9.5.; ; . New; reference page for configuration options The; page is automatically generated for each new release. Next to; the classifiers also exist information links for hints to; improve the classifier performance (click on the ""i""; button). Many thanks to Zhiyi Liu (Fraser U) for suggesting; this.; ; Methods:. BDT: New Decision Tree Pruning algorithm: Cost; Complexity Pruning a la CART. Written by Doug Schouten; (Fraser U.). It replaces the old CostComplexity and; CostComplexity2 algorithms.; . BDT: New no splitting option (choosable with; NCuts<0) that finds best split point by first sorting the; events for each variable and then looping through all; events, placing the cuts always in the middle between two; of the sorted events, and finding the true possible; maximum separation gain in the training sample by cutting; on this variable.; . BDT, AdaBoost The beta parameter is now an; option (default is 1).; . BDT: The node purity at which a node is; classified as signal (respective background node) for; determining the error fraction in the pruning became a; parameter that can be set via the option NodePurityLimit; (default is 0.5).; . Dataset preparation:. First implementation of a new preprocessing method: transformation of the; variables first into a Gaussian distribution, then performing a decorrelation of; the ""Gaussianised"" variables. The transformation is again done by default such that; (by default) the signal distributions become Gaussian and are decorrelated. Note ; that simultaneous Gaussianisation and decorrelation of signal and background is ; only possible (and done) for methods, such as Likelihood, which test both hypotheses.; . Bug fixes:. Fix in Expected error pruning: Rather than multiplying both sides, the error on ; the node and the sub-tree, with the prune strength, now only the expected error ; of the sub-tree is scaled.; . Fix in FDA parsing of the input formula. There were problems when",MatchSource.DOCS,tmva/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v522/index.html:88,Modifiability,config,configuration,88," . TMVA; ; This version corresponds to TMVA version 3.9.5.; ; . New; reference page for configuration options The; page is automatically generated for each new release. Next to; the classifiers also exist information links for hints to; improve the classifier performance (click on the ""i""; button). Many thanks to Zhiyi Liu (Fraser U) for suggesting; this.; ; Methods:. BDT: New Decision Tree Pruning algorithm: Cost; Complexity Pruning a la CART. Written by Doug Schouten; (Fraser U.). It replaces the old CostComplexity and; CostComplexity2 algorithms.; . BDT: New no splitting option (choosable with; NCuts<0) that finds best split point by first sorting the; events for each variable and then looping through all; events, placing the cuts always in the middle between two; of the sorted events, and finding the true possible; maximum separation gain in the training sample by cutting; on this variable.; . BDT, AdaBoost The beta parameter is now an; option (default is 1).; . BDT: The node purity at which a node is; classified as signal (respective background node) for; determining the error fraction in the pruning became a; parameter that can be set via the option NodePurityLimit; (default is 0.5).; . Dataset preparation:. First implementation of a new preprocessing method: transformation of the; variables first into a Gaussian distribution, then performing a decorrelation of; the ""Gaussianised"" variables. The transformation is again done by default such that; (by default) the signal distributions become Gaussian and are decorrelated. Note ; that simultaneous Gaussianisation and decorrelation of signal and background is ; only possible (and done) for methods, such as Likelihood, which test both hypotheses.; . Bug fixes:. Fix in Expected error pruning: Rather than multiplying both sides, the error on ; the node and the sub-tree, with the prune strength, now only the expected error ; of the sub-tree is scaled.; . Fix in FDA parsing of the input formula. There were problems when",MatchSource.DOCS,tmva/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v522/index.html:680,Modifiability,variab,variable,680," . TMVA; ; This version corresponds to TMVA version 3.9.5.; ; . New; reference page for configuration options The; page is automatically generated for each new release. Next to; the classifiers also exist information links for hints to; improve the classifier performance (click on the ""i""; button). Many thanks to Zhiyi Liu (Fraser U) for suggesting; this.; ; Methods:. BDT: New Decision Tree Pruning algorithm: Cost; Complexity Pruning a la CART. Written by Doug Schouten; (Fraser U.). It replaces the old CostComplexity and; CostComplexity2 algorithms.; . BDT: New no splitting option (choosable with; NCuts<0) that finds best split point by first sorting the; events for each variable and then looping through all; events, placing the cuts always in the middle between two; of the sorted events, and finding the true possible; maximum separation gain in the training sample by cutting; on this variable.; . BDT, AdaBoost The beta parameter is now an; option (default is 1).; . BDT: The node purity at which a node is; classified as signal (respective background node) for; determining the error fraction in the pruning became a; parameter that can be set via the option NodePurityLimit; (default is 0.5).; . Dataset preparation:. First implementation of a new preprocessing method: transformation of the; variables first into a Gaussian distribution, then performing a decorrelation of; the ""Gaussianised"" variables. The transformation is again done by default such that; (by default) the signal distributions become Gaussian and are decorrelated. Note ; that simultaneous Gaussianisation and decorrelation of signal and background is ; only possible (and done) for methods, such as Likelihood, which test both hypotheses.; . Bug fixes:. Fix in Expected error pruning: Rather than multiplying both sides, the error on ; the node and the sub-tree, with the prune strength, now only the expected error ; of the sub-tree is scaled.; . Fix in FDA parsing of the input formula. There were problems when",MatchSource.DOCS,tmva/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v522/index.html:898,Modifiability,variab,variable,898," . TMVA; ; This version corresponds to TMVA version 3.9.5.; ; . New; reference page for configuration options The; page is automatically generated for each new release. Next to; the classifiers also exist information links for hints to; improve the classifier performance (click on the ""i""; button). Many thanks to Zhiyi Liu (Fraser U) for suggesting; this.; ; Methods:. BDT: New Decision Tree Pruning algorithm: Cost; Complexity Pruning a la CART. Written by Doug Schouten; (Fraser U.). It replaces the old CostComplexity and; CostComplexity2 algorithms.; . BDT: New no splitting option (choosable with; NCuts<0) that finds best split point by first sorting the; events for each variable and then looping through all; events, placing the cuts always in the middle between two; of the sorted events, and finding the true possible; maximum separation gain in the training sample by cutting; on this variable.; . BDT, AdaBoost The beta parameter is now an; option (default is 1).; . BDT: The node purity at which a node is; classified as signal (respective background node) for; determining the error fraction in the pruning became a; parameter that can be set via the option NodePurityLimit; (default is 0.5).; . Dataset preparation:. First implementation of a new preprocessing method: transformation of the; variables first into a Gaussian distribution, then performing a decorrelation of; the ""Gaussianised"" variables. The transformation is again done by default such that; (by default) the signal distributions become Gaussian and are decorrelated. Note ; that simultaneous Gaussianisation and decorrelation of signal and background is ; only possible (and done) for methods, such as Likelihood, which test both hypotheses.; . Bug fixes:. Fix in Expected error pruning: Rather than multiplying both sides, the error on ; the node and the sub-tree, with the prune strength, now only the expected error ; of the sub-tree is scaled.; . Fix in FDA parsing of the input formula. There were problems when",MatchSource.DOCS,tmva/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v522/index.html:1309,Modifiability,variab,variables,1309,"Fraser U) for suggesting; this.; ; Methods:. BDT: New Decision Tree Pruning algorithm: Cost; Complexity Pruning a la CART. Written by Doug Schouten; (Fraser U.). It replaces the old CostComplexity and; CostComplexity2 algorithms.; . BDT: New no splitting option (choosable with; NCuts<0) that finds best split point by first sorting the; events for each variable and then looping through all; events, placing the cuts always in the middle between two; of the sorted events, and finding the true possible; maximum separation gain in the training sample by cutting; on this variable.; . BDT, AdaBoost The beta parameter is now an; option (default is 1).; . BDT: The node purity at which a node is; classified as signal (respective background node) for; determining the error fraction in the pruning became a; parameter that can be set via the option NodePurityLimit; (default is 0.5).; . Dataset preparation:. First implementation of a new preprocessing method: transformation of the; variables first into a Gaussian distribution, then performing a decorrelation of; the ""Gaussianised"" variables. The transformation is again done by default such that; (by default) the signal distributions become Gaussian and are decorrelated. Note ; that simultaneous Gaussianisation and decorrelation of signal and background is ; only possible (and done) for methods, such as Likelihood, which test both hypotheses.; . Bug fixes:. Fix in Expected error pruning: Rather than multiplying both sides, the error on ; the node and the sub-tree, with the prune strength, now only the expected error ; of the sub-tree is scaled.; . Fix in FDA parsing of the input formula. There were problems when treating; more than 10 parameters (thanks to Hugh Skottowe for reporting this).; . Calculation of ""Separation"": fixed bin-shift and; normalisation bugs. Thanks to Dag Gillberg (Fraser U) for; spotting these.; . Fixed problem in ""SetSignal(Background)WeightExpression"":; signal (background weight expressions not existing in t",MatchSource.DOCS,tmva/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v522/index.html:1410,Modifiability,variab,variables,1410,"Fraser U) for suggesting; this.; ; Methods:. BDT: New Decision Tree Pruning algorithm: Cost; Complexity Pruning a la CART. Written by Doug Schouten; (Fraser U.). It replaces the old CostComplexity and; CostComplexity2 algorithms.; . BDT: New no splitting option (choosable with; NCuts<0) that finds best split point by first sorting the; events for each variable and then looping through all; events, placing the cuts always in the middle between two; of the sorted events, and finding the true possible; maximum separation gain in the training sample by cutting; on this variable.; . BDT, AdaBoost The beta parameter is now an; option (default is 1).; . BDT: The node purity at which a node is; classified as signal (respective background node) for; determining the error fraction in the pruning became a; parameter that can be set via the option NodePurityLimit; (default is 0.5).; . Dataset preparation:. First implementation of a new preprocessing method: transformation of the; variables first into a Gaussian distribution, then performing a decorrelation of; the ""Gaussianised"" variables. The transformation is again done by default such that; (by default) the signal distributions become Gaussian and are decorrelated. Note ; that simultaneous Gaussianisation and decorrelation of signal and background is ; only possible (and done) for methods, such as Likelihood, which test both hypotheses.; . Bug fixes:. Fix in Expected error pruning: Rather than multiplying both sides, the error on ; the node and the sub-tree, with the prune strength, now only the expected error ; of the sub-tree is scaled.; . Fix in FDA parsing of the input formula. There were problems when treating; more than 10 parameters (thanks to Hugh Skottowe for reporting this).; . Calculation of ""Separation"": fixed bin-shift and; normalisation bugs. Thanks to Dag Gillberg (Fraser U) for; spotting these.; . Fixed problem in ""SetSignal(Background)WeightExpression"":; signal (background weight expressions not existing in t",MatchSource.DOCS,tmva/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v522/index.html:260,Performance,perform,performance,260," . TMVA; ; This version corresponds to TMVA version 3.9.5.; ; . New; reference page for configuration options The; page is automatically generated for each new release. Next to; the classifiers also exist information links for hints to; improve the classifier performance (click on the ""i""; button). Many thanks to Zhiyi Liu (Fraser U) for suggesting; this.; ; Methods:. BDT: New Decision Tree Pruning algorithm: Cost; Complexity Pruning a la CART. Written by Doug Schouten; (Fraser U.). It replaces the old CostComplexity and; CostComplexity2 algorithms.; . BDT: New no splitting option (choosable with; NCuts<0) that finds best split point by first sorting the; events for each variable and then looping through all; events, placing the cuts always in the middle between two; of the sorted events, and finding the true possible; maximum separation gain in the training sample by cutting; on this variable.; . BDT, AdaBoost The beta parameter is now an; option (default is 1).; . BDT: The node purity at which a node is; classified as signal (respective background node) for; determining the error fraction in the pruning became a; parameter that can be set via the option NodePurityLimit; (default is 0.5).; . Dataset preparation:. First implementation of a new preprocessing method: transformation of the; variables first into a Gaussian distribution, then performing a decorrelation of; the ""Gaussianised"" variables. The transformation is again done by default such that; (by default) the signal distributions become Gaussian and are decorrelated. Note ; that simultaneous Gaussianisation and decorrelation of signal and background is ; only possible (and done) for methods, such as Likelihood, which test both hypotheses.; . Bug fixes:. Fix in Expected error pruning: Rather than multiplying both sides, the error on ; the node and the sub-tree, with the prune strength, now only the expected error ; of the sub-tree is scaled.; . Fix in FDA parsing of the input formula. There were problems when",MatchSource.DOCS,tmva/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v522/index.html:1360,Performance,perform,performing,1360,"Fraser U) for suggesting; this.; ; Methods:. BDT: New Decision Tree Pruning algorithm: Cost; Complexity Pruning a la CART. Written by Doug Schouten; (Fraser U.). It replaces the old CostComplexity and; CostComplexity2 algorithms.; . BDT: New no splitting option (choosable with; NCuts<0) that finds best split point by first sorting the; events for each variable and then looping through all; events, placing the cuts always in the middle between two; of the sorted events, and finding the true possible; maximum separation gain in the training sample by cutting; on this variable.; . BDT, AdaBoost The beta parameter is now an; option (default is 1).; . BDT: The node purity at which a node is; classified as signal (respective background node) for; determining the error fraction in the pruning became a; parameter that can be set via the option NodePurityLimit; (default is 0.5).; . Dataset preparation:. First implementation of a new preprocessing method: transformation of the; variables first into a Gaussian distribution, then performing a decorrelation of; the ""Gaussianised"" variables. The transformation is again done by default such that; (by default) the signal distributions become Gaussian and are decorrelated. Note ; that simultaneous Gaussianisation and decorrelation of signal and background is ; only possible (and done) for methods, such as Likelihood, which test both hypotheses.; . Bug fixes:. Fix in Expected error pruning: Rather than multiplying both sides, the error on ; the node and the sub-tree, with the prune strength, now only the expected error ; of the sub-tree is scaled.; . Fix in FDA parsing of the input formula. There were problems when treating; more than 10 parameters (thanks to Hugh Skottowe for reporting this).; . Calculation of ""Separation"": fixed bin-shift and; normalisation bugs. Thanks to Dag Gillberg (Fraser U) for; spotting these.; . Fixed problem in ""SetSignal(Background)WeightExpression"":; signal (background weight expressions not existing in t",MatchSource.DOCS,tmva/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v522/index.html:2366,Safety,abort,abort,2366,"h variable and then looping through all; events, placing the cuts always in the middle between two; of the sorted events, and finding the true possible; maximum separation gain in the training sample by cutting; on this variable.; . BDT, AdaBoost The beta parameter is now an; option (default is 1).; . BDT: The node purity at which a node is; classified as signal (respective background node) for; determining the error fraction in the pruning became a; parameter that can be set via the option NodePurityLimit; (default is 0.5).; . Dataset preparation:. First implementation of a new preprocessing method: transformation of the; variables first into a Gaussian distribution, then performing a decorrelation of; the ""Gaussianised"" variables. The transformation is again done by default such that; (by default) the signal distributions become Gaussian and are decorrelated. Note ; that simultaneous Gaussianisation and decorrelation of signal and background is ; only possible (and done) for methods, such as Likelihood, which test both hypotheses.; . Bug fixes:. Fix in Expected error pruning: Rather than multiplying both sides, the error on ; the node and the sub-tree, with the prune strength, now only the expected error ; of the sub-tree is scaled.; . Fix in FDA parsing of the input formula. There were problems when treating; more than 10 parameters (thanks to Hugh Skottowe for reporting this).; . Calculation of ""Separation"": fixed bin-shift and; normalisation bugs. Thanks to Dag Gillberg (Fraser U) for; spotting these.; . Fixed problem in ""SetSignal(Background)WeightExpression"":; signal (background weight expressions not existing in the; background (signal) tree led to an abort of the tree; reading (""Bad numerical expression""). Thanks to Alfio; Rizzo (Brussels) for pointing this out.; . Fixed problem when specifying train and test tree; explicitly. Some code was forgotten in the background; part, creating incompatibilities. Thanks to Zhiyi Liu; (Fraser U) for reporting this.; . ",MatchSource.DOCS,tmva/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v522/index.html:1705,Testability,test,test,1705,"int by first sorting the; events for each variable and then looping through all; events, placing the cuts always in the middle between two; of the sorted events, and finding the true possible; maximum separation gain in the training sample by cutting; on this variable.; . BDT, AdaBoost The beta parameter is now an; option (default is 1).; . BDT: The node purity at which a node is; classified as signal (respective background node) for; determining the error fraction in the pruning became a; parameter that can be set via the option NodePurityLimit; (default is 0.5).; . Dataset preparation:. First implementation of a new preprocessing method: transformation of the; variables first into a Gaussian distribution, then performing a decorrelation of; the ""Gaussianised"" variables. The transformation is again done by default such that; (by default) the signal distributions become Gaussian and are decorrelated. Note ; that simultaneous Gaussianisation and decorrelation of signal and background is ; only possible (and done) for methods, such as Likelihood, which test both hypotheses.; . Bug fixes:. Fix in Expected error pruning: Rather than multiplying both sides, the error on ; the node and the sub-tree, with the prune strength, now only the expected error ; of the sub-tree is scaled.; . Fix in FDA parsing of the input formula. There were problems when treating; more than 10 parameters (thanks to Hugh Skottowe for reporting this).; . Calculation of ""Separation"": fixed bin-shift and; normalisation bugs. Thanks to Dag Gillberg (Fraser U) for; spotting these.; . Fixed problem in ""SetSignal(Background)WeightExpression"":; signal (background weight expressions not existing in the; background (signal) tree led to an abort of the tree; reading (""Bad numerical expression""). Thanks to Alfio; Rizzo (Brussels) for pointing this out.; . Fixed problem when specifying train and test tree; explicitly. Some code was forgotten in the background; part, creating incompatibilities. Thanks to Zhiyi ",MatchSource.DOCS,tmva/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v522/index.html:2523,Testability,test,test,2523,"h variable and then looping through all; events, placing the cuts always in the middle between two; of the sorted events, and finding the true possible; maximum separation gain in the training sample by cutting; on this variable.; . BDT, AdaBoost The beta parameter is now an; option (default is 1).; . BDT: The node purity at which a node is; classified as signal (respective background node) for; determining the error fraction in the pruning became a; parameter that can be set via the option NodePurityLimit; (default is 0.5).; . Dataset preparation:. First implementation of a new preprocessing method: transformation of the; variables first into a Gaussian distribution, then performing a decorrelation of; the ""Gaussianised"" variables. The transformation is again done by default such that; (by default) the signal distributions become Gaussian and are decorrelated. Note ; that simultaneous Gaussianisation and decorrelation of signal and background is ; only possible (and done) for methods, such as Likelihood, which test both hypotheses.; . Bug fixes:. Fix in Expected error pruning: Rather than multiplying both sides, the error on ; the node and the sub-tree, with the prune strength, now only the expected error ; of the sub-tree is scaled.; . Fix in FDA parsing of the input formula. There were problems when treating; more than 10 parameters (thanks to Hugh Skottowe for reporting this).; . Calculation of ""Separation"": fixed bin-shift and; normalisation bugs. Thanks to Dag Gillberg (Fraser U) for; spotting these.; . Fixed problem in ""SetSignal(Background)WeightExpression"":; signal (background weight expressions not existing in the; background (signal) tree led to an abort of the tree; reading (""Bad numerical expression""). Thanks to Alfio; Rizzo (Brussels) for pointing this out.; . Fixed problem when specifying train and test tree; explicitly. Some code was forgotten in the background; part, creating incompatibilities. Thanks to Zhiyi Liu; (Fraser U) for reporting this.; . ",MatchSource.DOCS,tmva/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html:1322,Availability,avail,available,1322,"ultivariate multi-target regression; ; Any TMVA method can now be boosted (linearly or; non-linearly); ; Transformation of input variables can be chained as wished; ; Weight files are now in XML format; ; New MVA methods ""PDE-Foam"" and ""LD"", both featuring; classification and regression; ; ; Comments. On XML format:; ; The old text format is obsolete though still readable in the; application. Backward compatibility is NOT guaranteed. Please; contact the authors if you require the reading of old text weight; files in TMVA 4.; ; ; Standard macros:; ; The structure of the standard macros has changed: macros are; still in the ""$ROOTSYS/tmva/test"" directory, but distinguished for; classification and regression examples:; ; TMVAClassification.C, TMVAClassificationApplication.C TMVARegression.C, TMVARegressionApplication.C; ; Classification and regression analysis (training) is analysed as; usual via standard macros that can be called from dedicated; GUIs.; ; ; Regression:. Not yet available for all MVA methods. It exists for:; PDE-RS, PDE-Foam, K-NN, LD, FDA, MLP, BDT for single targets; (1D), and MLP for multiple targets (nD).; ; Not all transformation of input variables are available; (only ""Norm"" so far). Regression requires specific evaluation tools:. ; During the training we provide a ranking of input; variables, using various criteria: correlations, transposed; correlation, correlation ratio, and ""mutual information"" between; input variables and regression target. (Correlation ratio and; mutual information implmentations provided by Moritz Backes,; Geneva U); ; After the training, the trained MVA methods are ranked wrt.; the deviations between regression target and estimate.; ; Macros plot various deviation and correlation quantities.; A new GUI (macros/TMVARegGui.C) collects these macros.; . Improvements of / new features for MVA methods . Linear Discriminant:; Re-implementation of ""Fisher"" method as general linear discriminant (""LD""),; which is also regression capa",MatchSource.DOCS,tmva/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html:1521,Availability,avail,available,1521,"are now in XML format; ; New MVA methods ""PDE-Foam"" and ""LD"", both featuring; classification and regression; ; ; Comments. On XML format:; ; The old text format is obsolete though still readable in the; application. Backward compatibility is NOT guaranteed. Please; contact the authors if you require the reading of old text weight; files in TMVA 4.; ; ; Standard macros:; ; The structure of the standard macros has changed: macros are; still in the ""$ROOTSYS/tmva/test"" directory, but distinguished for; classification and regression examples:; ; TMVAClassification.C, TMVAClassificationApplication.C TMVARegression.C, TMVARegressionApplication.C; ; Classification and regression analysis (training) is analysed as; usual via standard macros that can be called from dedicated; GUIs.; ; ; Regression:. Not yet available for all MVA methods. It exists for:; PDE-RS, PDE-Foam, K-NN, LD, FDA, MLP, BDT for single targets; (1D), and MLP for multiple targets (nD).; ; Not all transformation of input variables are available; (only ""Norm"" so far). Regression requires specific evaluation tools:. ; During the training we provide a ranking of input; variables, using various criteria: correlations, transposed; correlation, correlation ratio, and ""mutual information"" between; input variables and regression target. (Correlation ratio and; mutual information implmentations provided by Moritz Backes,; Geneva U); ; After the training, the trained MVA methods are ranked wrt.; the deviations between regression target and estimate.; ; Macros plot various deviation and correlation quantities.; A new GUI (macros/TMVARegGui.C) collects these macros.; . Improvements of / new features for MVA methods . Linear Discriminant:; Re-implementation of ""Fisher"" method as general linear discriminant (""LD""),; which is also regression capable (so far: single-target only). PDEFoam:; PDE-Foam is a variation of the PDE-RS method using a self-adapting binning; method to divide the multi-dimensional variable space into ",MatchSource.DOCS,tmva/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html:6589,Availability,avail,available,6589,"tion, it is necessary for; regression. The inverse transformation of the normalization; transformation has been implemented. Started to extend the variable transformations to the; regression targets as well. MethodCuts now produces the 'optimal-cut' histograms needed; by macro mvaeffs.C. (macro 5a of TMVAGui.C); ; MsgLogger can be silenced in order to prevent excess output; during boosting. Third dataset type added centrally (Training, Validation; and Testing). The validation data is split off the original; training data set. Update of GUI and other Macros according to the new; features of PDF and the addition of MethodBoost.; ; Updates in TMVA 4.0.1. ""Spectator"" variables can be defined now which are computed; just as the input variables and which are written out into the; TestTree, but which don't participate in any MVA calculation; (useful for correlation studies).; ; New booking option ""IgnoreNegWeightsInTraining"" to test the; effect of events with negative weights on the training. This is; especially useful for methods, which do not properly deal with; such events. Note that this new option is not available for all; methods (a training interrupt is issued if not available). ; Bug fixes:. Fixed regression bug in VariableNormalizeTransform (Use; number of targets from Event instead of DataSet); ; Fixed Multitarget-Regression in PDEFoam, foam dimensions; were miscalculated. Added writing of targets to the weight files in regression; mode to fix problems in RegressionApplication. Added missing standard C++ header files missing to some; classes, which lead to compilation failures on some; architectures (thanks to Lucian Ancu, Nijmegen, for reporting; these). Added checks for unused options to Factory and; DataSetFactory configuration options interpretation. Will now; complain if wrong option labels are used. Fixed standard creation of correlation matrix plots. Fixed internal mapping problem giving a fatal error message; when destroying and recreating the Factory. ; ",MatchSource.DOCS,tmva/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html:6655,Availability,avail,available,6655,"tion, it is necessary for; regression. The inverse transformation of the normalization; transformation has been implemented. Started to extend the variable transformations to the; regression targets as well. MethodCuts now produces the 'optimal-cut' histograms needed; by macro mvaeffs.C. (macro 5a of TMVAGui.C); ; MsgLogger can be silenced in order to prevent excess output; during boosting. Third dataset type added centrally (Training, Validation; and Testing). The validation data is split off the original; training data set. Update of GUI and other Macros according to the new; features of PDF and the addition of MethodBoost.; ; Updates in TMVA 4.0.1. ""Spectator"" variables can be defined now which are computed; just as the input variables and which are written out into the; TestTree, but which don't participate in any MVA calculation; (useful for correlation studies).; ; New booking option ""IgnoreNegWeightsInTraining"" to test the; effect of events with negative weights on the training. This is; especially useful for methods, which do not properly deal with; such events. Note that this new option is not available for all; methods (a training interrupt is issued if not available). ; Bug fixes:. Fixed regression bug in VariableNormalizeTransform (Use; number of targets from Event instead of DataSet); ; Fixed Multitarget-Regression in PDEFoam, foam dimensions; were miscalculated. Added writing of targets to the weight files in regression; mode to fix problems in RegressionApplication. Added missing standard C++ header files missing to some; classes, which lead to compilation failures on some; architectures (thanks to Lucian Ancu, Nijmegen, for reporting; these). Added checks for unused options to Factory and; DataSetFactory configuration options interpretation. Will now; complain if wrong option labels are used. Fixed standard creation of correlation matrix plots. Fixed internal mapping problem giving a fatal error message; when destroying and recreating the Factory. ; ",MatchSource.DOCS,tmva/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html:7067,Availability,failure,failures,7067,"tion, it is necessary for; regression. The inverse transformation of the normalization; transformation has been implemented. Started to extend the variable transformations to the; regression targets as well. MethodCuts now produces the 'optimal-cut' histograms needed; by macro mvaeffs.C. (macro 5a of TMVAGui.C); ; MsgLogger can be silenced in order to prevent excess output; during boosting. Third dataset type added centrally (Training, Validation; and Testing). The validation data is split off the original; training data set. Update of GUI and other Macros according to the new; features of PDF and the addition of MethodBoost.; ; Updates in TMVA 4.0.1. ""Spectator"" variables can be defined now which are computed; just as the input variables and which are written out into the; TestTree, but which don't participate in any MVA calculation; (useful for correlation studies).; ; New booking option ""IgnoreNegWeightsInTraining"" to test the; effect of events with negative weights on the training. This is; especially useful for methods, which do not properly deal with; such events. Note that this new option is not available for all; methods (a training interrupt is issued if not available). ; Bug fixes:. Fixed regression bug in VariableNormalizeTransform (Use; number of targets from Event instead of DataSet); ; Fixed Multitarget-Regression in PDEFoam, foam dimensions; were miscalculated. Added writing of targets to the weight files in regression; mode to fix problems in RegressionApplication. Added missing standard C++ header files missing to some; classes, which lead to compilation failures on some; architectures (thanks to Lucian Ancu, Nijmegen, for reporting; these). Added checks for unused options to Factory and; DataSetFactory configuration options interpretation. Will now; complain if wrong option labels are used. Fixed standard creation of correlation matrix plots. Fixed internal mapping problem giving a fatal error message; when destroying and recreating the Factory. ; ",MatchSource.DOCS,tmva/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html:7408,Availability,error,error,7408,"tion, it is necessary for; regression. The inverse transformation of the normalization; transformation has been implemented. Started to extend the variable transformations to the; regression targets as well. MethodCuts now produces the 'optimal-cut' histograms needed; by macro mvaeffs.C. (macro 5a of TMVAGui.C); ; MsgLogger can be silenced in order to prevent excess output; during boosting. Third dataset type added centrally (Training, Validation; and Testing). The validation data is split off the original; training data set. Update of GUI and other Macros according to the new; features of PDF and the addition of MethodBoost.; ; Updates in TMVA 4.0.1. ""Spectator"" variables can be defined now which are computed; just as the input variables and which are written out into the; TestTree, but which don't participate in any MVA calculation; (useful for correlation studies).; ; New booking option ""IgnoreNegWeightsInTraining"" to test the; effect of events with negative weights on the training. This is; especially useful for methods, which do not properly deal with; such events. Note that this new option is not available for all; methods (a training interrupt is issued if not available). ; Bug fixes:. Fixed regression bug in VariableNormalizeTransform (Use; number of targets from Event instead of DataSet); ; Fixed Multitarget-Regression in PDEFoam, foam dimensions; were miscalculated. Added writing of targets to the weight files in regression; mode to fix problems in RegressionApplication. Added missing standard C++ header files missing to some; classes, which lead to compilation failures on some; architectures (thanks to Lucian Ancu, Nijmegen, for reporting; these). Added checks for unused options to Factory and; DataSetFactory configuration options interpretation. Will now; complain if wrong option labels are used. Fixed standard creation of correlation matrix plots. Fixed internal mapping problem giving a fatal error message; when destroying and recreating the Factory. ; ",MatchSource.DOCS,tmva/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html:52,Deployability,release,release,52,". TMVA. TMVA version 4.0.1 is included in this root release:. Main changes and new features introduced with TMVA 4. Reorganisation of internal data handling and constructors; of methods to allow to build arbitrary composite MVA methods,; and to deal with multi-class classification and multi-target; regression; ; Extended TMVA to multivariate multi-target regression; ; Any TMVA method can now be boosted (linearly or; non-linearly); ; Transformation of input variables can be chained as wished; ; Weight files are now in XML format; ; New MVA methods ""PDE-Foam"" and ""LD"", both featuring; classification and regression; ; ; Comments. On XML format:; ; The old text format is obsolete though still readable in the; application. Backward compatibility is NOT guaranteed. Please; contact the authors if you require the reading of old text weight; files in TMVA 4.; ; ; Standard macros:; ; The structure of the standard macros has changed: macros are; still in the ""$ROOTSYS/tmva/test"" directory, but distinguished for; classification and regression examples:; ; TMVAClassification.C, TMVAClassificationApplication.C TMVARegression.C, TMVARegressionApplication.C; ; Classification and regression analysis (training) is analysed as; usual via standard macros that can be called from dedicated; GUIs.; ; ; Regression:. Not yet available for all MVA methods. It exists for:; PDE-RS, PDE-Foam, K-NN, LD, FDA, MLP, BDT for single targets; (1D), and MLP for multiple targets (nD).; ; Not all transformation of input variables are available; (only ""Norm"" so far). Regression requires specific evaluation tools:. ; During the training we provide a ranking of input; variables, using various criteria: correlations, transposed; correlation, correlation ratio, and ""mutual information"" between; input variables and regression target. (Correlation ratio and; mutual information implmentations provided by Moritz Backes,; Geneva U); ; After the training, the trained MVA methods are ranked wrt.; the deviations betwe",MatchSource.DOCS,tmva/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html:4474,Deployability,configurat,configuration,4474,"ce to TMultiLayerPerceptron) now also uses event weights; and writes standalone C++ class. k-NN:; A new global knn search function has been added to NodekNN that searches for; k-nearest neighbor using event weights instead of raw event counts. ModulekNN; has been modified to allow searches using ""weight"" or ""count"" option, where; ""count"" is default. Added UseWeight option to MethodKNN to allow using of; ""weight"" or ""count"". ; (Work by Rustem Ospanov, CERN). . Likelihood (and general PDF treatment):; Adaptive smoothing the PDF class, allowing it to smooth between MinSmoothNum ; (for regions with more signal) and MaxSmoothNum (for regions with less signal). . Configuration of the PDF parameters from the option string moved to PDF class,; allowing the user to define all the PDF functionalities in every classifier; the PDF is used (i.e., also for the MVA PDFs). The reading of these variables; was removed from MethodBase and MethodLikelihood. This also allows improved ; (full) PDF configuration of MVA output via the ""CreateMvaPdf"" option.; (Work by Or Cohen, CERN & Weizmann); ; New generalisation methods:. ; MethodCompositeBase: combines more than one; classifier within one. MethodBoost: boosts/bags any classifier; type. A special booking procedure for it was added to; Factory class. MethodDT: a classifier composed of a single; decision tree, boosted using MethodBoost. Results are; compatible with BDT, but BDT remains the default for boosted; decision trees, because it has pruning (among other; additional features). . Other improvements . Improved handling of small Likelihood values such that; Likelihood performance increases in analyses with many variables; (~>10). Thanks to Ralph Schaefer (Bonn U.) for reporting this. Nicer plotting: custom variable titles and units can be; assigned in ""AddVariable"" call. Introduced the inverse transformation InverseTransform for; the variable transformations into the framework. While this is; not necessary for classification, it is ne",MatchSource.DOCS,tmva/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html:7219,Deployability,configurat,configuration,7219,"tion, it is necessary for; regression. The inverse transformation of the normalization; transformation has been implemented. Started to extend the variable transformations to the; regression targets as well. MethodCuts now produces the 'optimal-cut' histograms needed; by macro mvaeffs.C. (macro 5a of TMVAGui.C); ; MsgLogger can be silenced in order to prevent excess output; during boosting. Third dataset type added centrally (Training, Validation; and Testing). The validation data is split off the original; training data set. Update of GUI and other Macros according to the new; features of PDF and the addition of MethodBoost.; ; Updates in TMVA 4.0.1. ""Spectator"" variables can be defined now which are computed; just as the input variables and which are written out into the; TestTree, but which don't participate in any MVA calculation; (useful for correlation studies).; ; New booking option ""IgnoreNegWeightsInTraining"" to test the; effect of events with negative weights on the training. This is; especially useful for methods, which do not properly deal with; such events. Note that this new option is not available for all; methods (a training interrupt is issued if not available). ; Bug fixes:. Fixed regression bug in VariableNormalizeTransform (Use; number of targets from Event instead of DataSet); ; Fixed Multitarget-Regression in PDEFoam, foam dimensions; were miscalculated. Added writing of targets to the weight files in regression; mode to fix problems in RegressionApplication. Added missing standard C++ header files missing to some; classes, which lead to compilation failures on some; architectures (thanks to Lucian Ancu, Nijmegen, for reporting; these). Added checks for unused options to Factory and; DataSetFactory configuration options interpretation. Will now; complain if wrong option labels are used. Fixed standard creation of correlation matrix plots. Fixed internal mapping problem giving a fatal error message; when destroying and recreating the Factory. ; ",MatchSource.DOCS,tmva/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html:2435,Energy Efficiency,adapt,adapting,2435,"gets (nD).; ; Not all transformation of input variables are available; (only ""Norm"" so far). Regression requires specific evaluation tools:. ; During the training we provide a ranking of input; variables, using various criteria: correlations, transposed; correlation, correlation ratio, and ""mutual information"" between; input variables and regression target. (Correlation ratio and; mutual information implmentations provided by Moritz Backes,; Geneva U); ; After the training, the trained MVA methods are ranked wrt.; the deviations between regression target and estimate.; ; Macros plot various deviation and correlation quantities.; A new GUI (macros/TMVARegGui.C) collects these macros.; . Improvements of / new features for MVA methods . Linear Discriminant:; Re-implementation of ""Fisher"" method as general linear discriminant (""LD""),; which is also regression capable (so far: single-target only). PDEFoam:; PDE-Foam is a variation of the PDE-RS method using a self-adapting binning; method to divide the multi-dimensional variable space into a finite number; of hyper-rectangles (cells). The binning algorithm adjusts the size and; position of a predefined number of cells such that the variance of the; signal and background densities inside the cells reaches a minimum. BDT:; Introduced gradient boosting and stochastic gradient boosting for ; classification with BDT (as desribed by Friedman 1999). See ""BDTG"" ; example in TMVAClassification.C/cxx. A new option allows to restrict the maximum tree depth. This may be used to; avoid overtraining and often gives better performance than pruning. (The; pruning mechanism needs to be revisited). MLP:; Introduced recognition of convergence via general ConvergenceTest-class for; interrupting computations when convergence is reached. This feature has is; used now in MethodMLP. Improved treatment of event-weights in BFGS training. Implemented random and importance sampling of events in DataSet. Implemented; the usage of this feature for MLP",MatchSource.DOCS,tmva/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html:3476,Integrability,interface,interface,3476,"te number; of hyper-rectangles (cells). The binning algorithm adjusts the size and; position of a predefined number of cells such that the variance of the; signal and background densities inside the cells reaches a minimum. BDT:; Introduced gradient boosting and stochastic gradient boosting for ; classification with BDT (as desribed by Friedman 1999). See ""BDTG"" ; example in TMVAClassification.C/cxx. A new option allows to restrict the maximum tree depth. This may be used to; avoid overtraining and often gives better performance than pruning. (The; pruning mechanism needs to be revisited). MLP:; Introduced recognition of convergence via general ConvergenceTest-class for; interrupting computations when convergence is reached. This feature has is; used now in MethodMLP. Improved treatment of event-weights in BFGS training. Implemented random and importance sampling of events in DataSet. Implemented; the usage of this feature for MLP.; ; TMlpANN (interface to TMultiLayerPerceptron) now also uses event weights; and writes standalone C++ class. k-NN:; A new global knn search function has been added to NodekNN that searches for; k-nearest neighbor using event weights instead of raw event counts. ModulekNN; has been modified to allow searches using ""weight"" or ""count"" option, where; ""count"" is default. Added UseWeight option to MethodKNN to allow using of; ""weight"" or ""count"". ; (Work by Rustem Ospanov, CERN). . Likelihood (and general PDF treatment):; Adaptive smoothing the PDF class, allowing it to smooth between MinSmoothNum ; (for regions with more signal) and MaxSmoothNum (for regions with less signal). . Configuration of the PDF parameters from the option string moved to PDF class,; allowing the user to define all the PDF functionalities in every classifier; the PDF is used (i.e., also for the MVA PDFs). The reading of these variables; was removed from MethodBase and MethodLikelihood. This also allows improved ; (full) PDF configuration of MVA output via the ""CreateM",MatchSource.DOCS,tmva/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html:7414,Integrability,message,message,7414,"tion, it is necessary for; regression. The inverse transformation of the normalization; transformation has been implemented. Started to extend the variable transformations to the; regression targets as well. MethodCuts now produces the 'optimal-cut' histograms needed; by macro mvaeffs.C. (macro 5a of TMVAGui.C); ; MsgLogger can be silenced in order to prevent excess output; during boosting. Third dataset type added centrally (Training, Validation; and Testing). The validation data is split off the original; training data set. Update of GUI and other Macros according to the new; features of PDF and the addition of MethodBoost.; ; Updates in TMVA 4.0.1. ""Spectator"" variables can be defined now which are computed; just as the input variables and which are written out into the; TestTree, but which don't participate in any MVA calculation; (useful for correlation studies).; ; New booking option ""IgnoreNegWeightsInTraining"" to test the; effect of events with negative weights on the training. This is; especially useful for methods, which do not properly deal with; such events. Note that this new option is not available for all; methods (a training interrupt is issued if not available). ; Bug fixes:. Fixed regression bug in VariableNormalizeTransform (Use; number of targets from Event instead of DataSet); ; Fixed Multitarget-Regression in PDEFoam, foam dimensions; were miscalculated. Added writing of targets to the weight files in regression; mode to fix problems in RegressionApplication. Added missing standard C++ header files missing to some; classes, which lead to compilation failures on some; architectures (thanks to Lucian Ancu, Nijmegen, for reporting; these). Added checks for unused options to Factory and; DataSetFactory configuration options interpretation. Will now; complain if wrong option labels are used. Fixed standard creation of correlation matrix plots. Fixed internal mapping problem giving a fatal error message; when destroying and recreating the Factory. ; ",MatchSource.DOCS,tmva/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html:461,Modifiability,variab,variables,461,". TMVA. TMVA version 4.0.1 is included in this root release:. Main changes and new features introduced with TMVA 4. Reorganisation of internal data handling and constructors; of methods to allow to build arbitrary composite MVA methods,; and to deal with multi-class classification and multi-target; regression; ; Extended TMVA to multivariate multi-target regression; ; Any TMVA method can now be boosted (linearly or; non-linearly); ; Transformation of input variables can be chained as wished; ; Weight files are now in XML format; ; New MVA methods ""PDE-Foam"" and ""LD"", both featuring; classification and regression; ; ; Comments. On XML format:; ; The old text format is obsolete though still readable in the; application. Backward compatibility is NOT guaranteed. Please; contact the authors if you require the reading of old text weight; files in TMVA 4.; ; ; Standard macros:; ; The structure of the standard macros has changed: macros are; still in the ""$ROOTSYS/tmva/test"" directory, but distinguished for; classification and regression examples:; ; TMVAClassification.C, TMVAClassificationApplication.C TMVARegression.C, TMVARegressionApplication.C; ; Classification and regression analysis (training) is analysed as; usual via standard macros that can be called from dedicated; GUIs.; ; ; Regression:. Not yet available for all MVA methods. It exists for:; PDE-RS, PDE-Foam, K-NN, LD, FDA, MLP, BDT for single targets; (1D), and MLP for multiple targets (nD).; ; Not all transformation of input variables are available; (only ""Norm"" so far). Regression requires specific evaluation tools:. ; During the training we provide a ranking of input; variables, using various criteria: correlations, transposed; correlation, correlation ratio, and ""mutual information"" between; input variables and regression target. (Correlation ratio and; mutual information implmentations provided by Moritz Backes,; Geneva U); ; After the training, the trained MVA methods are ranked wrt.; the deviations betwe",MatchSource.DOCS,tmva/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html:1507,Modifiability,variab,variables,1507,"are now in XML format; ; New MVA methods ""PDE-Foam"" and ""LD"", both featuring; classification and regression; ; ; Comments. On XML format:; ; The old text format is obsolete though still readable in the; application. Backward compatibility is NOT guaranteed. Please; contact the authors if you require the reading of old text weight; files in TMVA 4.; ; ; Standard macros:; ; The structure of the standard macros has changed: macros are; still in the ""$ROOTSYS/tmva/test"" directory, but distinguished for; classification and regression examples:; ; TMVAClassification.C, TMVAClassificationApplication.C TMVARegression.C, TMVARegressionApplication.C; ; Classification and regression analysis (training) is analysed as; usual via standard macros that can be called from dedicated; GUIs.; ; ; Regression:. Not yet available for all MVA methods. It exists for:; PDE-RS, PDE-Foam, K-NN, LD, FDA, MLP, BDT for single targets; (1D), and MLP for multiple targets (nD).; ; Not all transformation of input variables are available; (only ""Norm"" so far). Regression requires specific evaluation tools:. ; During the training we provide a ranking of input; variables, using various criteria: correlations, transposed; correlation, correlation ratio, and ""mutual information"" between; input variables and regression target. (Correlation ratio and; mutual information implmentations provided by Moritz Backes,; Geneva U); ; After the training, the trained MVA methods are ranked wrt.; the deviations between regression target and estimate.; ; Macros plot various deviation and correlation quantities.; A new GUI (macros/TMVARegGui.C) collects these macros.; . Improvements of / new features for MVA methods . Linear Discriminant:; Re-implementation of ""Fisher"" method as general linear discriminant (""LD""),; which is also regression capable (so far: single-target only). PDEFoam:; PDE-Foam is a variation of the PDE-RS method using a self-adapting binning; method to divide the multi-dimensional variable space into ",MatchSource.DOCS,tmva/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html:1655,Modifiability,variab,variables,1655,"the; application. Backward compatibility is NOT guaranteed. Please; contact the authors if you require the reading of old text weight; files in TMVA 4.; ; ; Standard macros:; ; The structure of the standard macros has changed: macros are; still in the ""$ROOTSYS/tmva/test"" directory, but distinguished for; classification and regression examples:; ; TMVAClassification.C, TMVAClassificationApplication.C TMVARegression.C, TMVARegressionApplication.C; ; Classification and regression analysis (training) is analysed as; usual via standard macros that can be called from dedicated; GUIs.; ; ; Regression:. Not yet available for all MVA methods. It exists for:; PDE-RS, PDE-Foam, K-NN, LD, FDA, MLP, BDT for single targets; (1D), and MLP for multiple targets (nD).; ; Not all transformation of input variables are available; (only ""Norm"" so far). Regression requires specific evaluation tools:. ; During the training we provide a ranking of input; variables, using various criteria: correlations, transposed; correlation, correlation ratio, and ""mutual information"" between; input variables and regression target. (Correlation ratio and; mutual information implmentations provided by Moritz Backes,; Geneva U); ; After the training, the trained MVA methods are ranked wrt.; the deviations between regression target and estimate.; ; Macros plot various deviation and correlation quantities.; A new GUI (macros/TMVARegGui.C) collects these macros.; . Improvements of / new features for MVA methods . Linear Discriminant:; Re-implementation of ""Fisher"" method as general linear discriminant (""LD""),; which is also regression capable (so far: single-target only). PDEFoam:; PDE-Foam is a variation of the PDE-RS method using a self-adapting binning; method to divide the multi-dimensional variable space into a finite number; of hyper-rectangles (cells). The binning algorithm adjusts the size and; position of a predefined number of cells such that the variance of the; signal and background densities insid",MatchSource.DOCS,tmva/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html:1788,Modifiability,variab,variables,1788,"the; application. Backward compatibility is NOT guaranteed. Please; contact the authors if you require the reading of old text weight; files in TMVA 4.; ; ; Standard macros:; ; The structure of the standard macros has changed: macros are; still in the ""$ROOTSYS/tmva/test"" directory, but distinguished for; classification and regression examples:; ; TMVAClassification.C, TMVAClassificationApplication.C TMVARegression.C, TMVARegressionApplication.C; ; Classification and regression analysis (training) is analysed as; usual via standard macros that can be called from dedicated; GUIs.; ; ; Regression:. Not yet available for all MVA methods. It exists for:; PDE-RS, PDE-Foam, K-NN, LD, FDA, MLP, BDT for single targets; (1D), and MLP for multiple targets (nD).; ; Not all transformation of input variables are available; (only ""Norm"" so far). Regression requires specific evaluation tools:. ; During the training we provide a ranking of input; variables, using various criteria: correlations, transposed; correlation, correlation ratio, and ""mutual information"" between; input variables and regression target. (Correlation ratio and; mutual information implmentations provided by Moritz Backes,; Geneva U); ; After the training, the trained MVA methods are ranked wrt.; the deviations between regression target and estimate.; ; Macros plot various deviation and correlation quantities.; A new GUI (macros/TMVARegGui.C) collects these macros.; . Improvements of / new features for MVA methods . Linear Discriminant:; Re-implementation of ""Fisher"" method as general linear discriminant (""LD""),; which is also regression capable (so far: single-target only). PDEFoam:; PDE-Foam is a variation of the PDE-RS method using a self-adapting binning; method to divide the multi-dimensional variable space into a finite number; of hyper-rectangles (cells). The binning algorithm adjusts the size and; position of a predefined number of cells such that the variance of the; signal and background densities insid",MatchSource.DOCS,tmva/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html:2435,Modifiability,adapt,adapting,2435,"gets (nD).; ; Not all transformation of input variables are available; (only ""Norm"" so far). Regression requires specific evaluation tools:. ; During the training we provide a ranking of input; variables, using various criteria: correlations, transposed; correlation, correlation ratio, and ""mutual information"" between; input variables and regression target. (Correlation ratio and; mutual information implmentations provided by Moritz Backes,; Geneva U); ; After the training, the trained MVA methods are ranked wrt.; the deviations between regression target and estimate.; ; Macros plot various deviation and correlation quantities.; A new GUI (macros/TMVARegGui.C) collects these macros.; . Improvements of / new features for MVA methods . Linear Discriminant:; Re-implementation of ""Fisher"" method as general linear discriminant (""LD""),; which is also regression capable (so far: single-target only). PDEFoam:; PDE-Foam is a variation of the PDE-RS method using a self-adapting binning; method to divide the multi-dimensional variable space into a finite number; of hyper-rectangles (cells). The binning algorithm adjusts the size and; position of a predefined number of cells such that the variance of the; signal and background densities inside the cells reaches a minimum. BDT:; Introduced gradient boosting and stochastic gradient boosting for ; classification with BDT (as desribed by Friedman 1999). See ""BDTG"" ; example in TMVAClassification.C/cxx. A new option allows to restrict the maximum tree depth. This may be used to; avoid overtraining and often gives better performance than pruning. (The; pruning mechanism needs to be revisited). MLP:; Introduced recognition of convergence via general ConvergenceTest-class for; interrupting computations when convergence is reached. This feature has is; used now in MethodMLP. Improved treatment of event-weights in BFGS training. Implemented random and importance sampling of events in DataSet. Implemented; the usage of this feature for MLP",MatchSource.DOCS,tmva/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html:2492,Modifiability,variab,variable,2492,"gets (nD).; ; Not all transformation of input variables are available; (only ""Norm"" so far). Regression requires specific evaluation tools:. ; During the training we provide a ranking of input; variables, using various criteria: correlations, transposed; correlation, correlation ratio, and ""mutual information"" between; input variables and regression target. (Correlation ratio and; mutual information implmentations provided by Moritz Backes,; Geneva U); ; After the training, the trained MVA methods are ranked wrt.; the deviations between regression target and estimate.; ; Macros plot various deviation and correlation quantities.; A new GUI (macros/TMVARegGui.C) collects these macros.; . Improvements of / new features for MVA methods . Linear Discriminant:; Re-implementation of ""Fisher"" method as general linear discriminant (""LD""),; which is also regression capable (so far: single-target only). PDEFoam:; PDE-Foam is a variation of the PDE-RS method using a self-adapting binning; method to divide the multi-dimensional variable space into a finite number; of hyper-rectangles (cells). The binning algorithm adjusts the size and; position of a predefined number of cells such that the variance of the; signal and background densities inside the cells reaches a minimum. BDT:; Introduced gradient boosting and stochastic gradient boosting for ; classification with BDT (as desribed by Friedman 1999). See ""BDTG"" ; example in TMVAClassification.C/cxx. A new option allows to restrict the maximum tree depth. This may be used to; avoid overtraining and often gives better performance than pruning. (The; pruning mechanism needs to be revisited). MLP:; Introduced recognition of convergence via general ConvergenceTest-class for; interrupting computations when convergence is reached. This feature has is; used now in MethodMLP. Improved treatment of event-weights in BFGS training. Implemented random and importance sampling of events in DataSet. Implemented; the usage of this feature for MLP",MatchSource.DOCS,tmva/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html:4374,Modifiability,variab,variables,4374," of events in DataSet. Implemented; the usage of this feature for MLP.; ; TMlpANN (interface to TMultiLayerPerceptron) now also uses event weights; and writes standalone C++ class. k-NN:; A new global knn search function has been added to NodekNN that searches for; k-nearest neighbor using event weights instead of raw event counts. ModulekNN; has been modified to allow searches using ""weight"" or ""count"" option, where; ""count"" is default. Added UseWeight option to MethodKNN to allow using of; ""weight"" or ""count"". ; (Work by Rustem Ospanov, CERN). . Likelihood (and general PDF treatment):; Adaptive smoothing the PDF class, allowing it to smooth between MinSmoothNum ; (for regions with more signal) and MaxSmoothNum (for regions with less signal). . Configuration of the PDF parameters from the option string moved to PDF class,; allowing the user to define all the PDF functionalities in every classifier; the PDF is used (i.e., also for the MVA PDFs). The reading of these variables; was removed from MethodBase and MethodLikelihood. This also allows improved ; (full) PDF configuration of MVA output via the ""CreateMvaPdf"" option.; (Work by Or Cohen, CERN & Weizmann); ; New generalisation methods:. ; MethodCompositeBase: combines more than one; classifier within one. MethodBoost: boosts/bags any classifier; type. A special booking procedure for it was added to; Factory class. MethodDT: a classifier composed of a single; decision tree, boosted using MethodBoost. Results are; compatible with BDT, but BDT remains the default for boosted; decision trees, because it has pruning (among other; additional features). . Other improvements . Improved handling of small Likelihood values such that; Likelihood performance increases in analyses with many variables; (~>10). Thanks to Ralph Schaefer (Bonn U.) for reporting this. Nicer plotting: custom variable titles and units can be; assigned in ""AddVariable"" call. Introduced the inverse transformation InverseTransform for; the variable tra",MatchSource.DOCS,tmva/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html:4474,Modifiability,config,configuration,4474,"ce to TMultiLayerPerceptron) now also uses event weights; and writes standalone C++ class. k-NN:; A new global knn search function has been added to NodekNN that searches for; k-nearest neighbor using event weights instead of raw event counts. ModulekNN; has been modified to allow searches using ""weight"" or ""count"" option, where; ""count"" is default. Added UseWeight option to MethodKNN to allow using of; ""weight"" or ""count"". ; (Work by Rustem Ospanov, CERN). . Likelihood (and general PDF treatment):; Adaptive smoothing the PDF class, allowing it to smooth between MinSmoothNum ; (for regions with more signal) and MaxSmoothNum (for regions with less signal). . Configuration of the PDF parameters from the option string moved to PDF class,; allowing the user to define all the PDF functionalities in every classifier; the PDF is used (i.e., also for the MVA PDFs). The reading of these variables; was removed from MethodBase and MethodLikelihood. This also allows improved ; (full) PDF configuration of MVA output via the ""CreateMvaPdf"" option.; (Work by Or Cohen, CERN & Weizmann); ; New generalisation methods:. ; MethodCompositeBase: combines more than one; classifier within one. MethodBoost: boosts/bags any classifier; type. A special booking procedure for it was added to; Factory class. MethodDT: a classifier composed of a single; decision tree, boosted using MethodBoost. Results are; compatible with BDT, but BDT remains the default for boosted; decision trees, because it has pruning (among other; additional features). . Other improvements . Improved handling of small Likelihood values such that; Likelihood performance increases in analyses with many variables; (~>10). Thanks to Ralph Schaefer (Bonn U.) for reporting this. Nicer plotting: custom variable titles and units can be; assigned in ""AddVariable"" call. Introduced the inverse transformation InverseTransform for; the variable transformations into the framework. While this is; not necessary for classification, it is ne",MatchSource.DOCS,tmva/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html:5154,Modifiability,variab,variables,5154,"oothNum (for regions with less signal). . Configuration of the PDF parameters from the option string moved to PDF class,; allowing the user to define all the PDF functionalities in every classifier; the PDF is used (i.e., also for the MVA PDFs). The reading of these variables; was removed from MethodBase and MethodLikelihood. This also allows improved ; (full) PDF configuration of MVA output via the ""CreateMvaPdf"" option.; (Work by Or Cohen, CERN & Weizmann); ; New generalisation methods:. ; MethodCompositeBase: combines more than one; classifier within one. MethodBoost: boosts/bags any classifier; type. A special booking procedure for it was added to; Factory class. MethodDT: a classifier composed of a single; decision tree, boosted using MethodBoost. Results are; compatible with BDT, but BDT remains the default for boosted; decision trees, because it has pruning (among other; additional features). . Other improvements . Improved handling of small Likelihood values such that; Likelihood performance increases in analyses with many variables; (~>10). Thanks to Ralph Schaefer (Bonn U.) for reporting this. Nicer plotting: custom variable titles and units can be; assigned in ""AddVariable"" call. Introduced the inverse transformation InverseTransform for; the variable transformations into the framework. While this is; not necessary for classification, it is necessary for; regression. The inverse transformation of the normalization; transformation has been implemented. Started to extend the variable transformations to the; regression targets as well. MethodCuts now produces the 'optimal-cut' histograms needed; by macro mvaeffs.C. (macro 5a of TMVAGui.C); ; MsgLogger can be silenced in order to prevent excess output; during boosting. Third dataset type added centrally (Training, Validation; and Testing). The validation data is split off the original; training data set. Update of GUI and other Macros according to the new; features of PDF and the addition of MethodBoost.; ; U",MatchSource.DOCS,tmva/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html:5251,Modifiability,variab,variable,5251,"nctionalities in every classifier; the PDF is used (i.e., also for the MVA PDFs). The reading of these variables; was removed from MethodBase and MethodLikelihood. This also allows improved ; (full) PDF configuration of MVA output via the ""CreateMvaPdf"" option.; (Work by Or Cohen, CERN & Weizmann); ; New generalisation methods:. ; MethodCompositeBase: combines more than one; classifier within one. MethodBoost: boosts/bags any classifier; type. A special booking procedure for it was added to; Factory class. MethodDT: a classifier composed of a single; decision tree, boosted using MethodBoost. Results are; compatible with BDT, but BDT remains the default for boosted; decision trees, because it has pruning (among other; additional features). . Other improvements . Improved handling of small Likelihood values such that; Likelihood performance increases in analyses with many variables; (~>10). Thanks to Ralph Schaefer (Bonn U.) for reporting this. Nicer plotting: custom variable titles and units can be; assigned in ""AddVariable"" call. Introduced the inverse transformation InverseTransform for; the variable transformations into the framework. While this is; not necessary for classification, it is necessary for; regression. The inverse transformation of the normalization; transformation has been implemented. Started to extend the variable transformations to the; regression targets as well. MethodCuts now produces the 'optimal-cut' histograms needed; by macro mvaeffs.C. (macro 5a of TMVAGui.C); ; MsgLogger can be silenced in order to prevent excess output; during boosting. Third dataset type added centrally (Training, Validation; and Testing). The validation data is split off the original; training data set. Update of GUI and other Macros according to the new; features of PDF and the addition of MethodBoost.; ; Updates in TMVA 4.0.1. ""Spectator"" variables can be defined now which are computed; just as the input variables and which are written out into the; TestTree, but whic",MatchSource.DOCS,tmva/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html:5381,Modifiability,variab,variable,5381,"ese variables; was removed from MethodBase and MethodLikelihood. This also allows improved ; (full) PDF configuration of MVA output via the ""CreateMvaPdf"" option.; (Work by Or Cohen, CERN & Weizmann); ; New generalisation methods:. ; MethodCompositeBase: combines more than one; classifier within one. MethodBoost: boosts/bags any classifier; type. A special booking procedure for it was added to; Factory class. MethodDT: a classifier composed of a single; decision tree, boosted using MethodBoost. Results are; compatible with BDT, but BDT remains the default for boosted; decision trees, because it has pruning (among other; additional features). . Other improvements . Improved handling of small Likelihood values such that; Likelihood performance increases in analyses with many variables; (~>10). Thanks to Ralph Schaefer (Bonn U.) for reporting this. Nicer plotting: custom variable titles and units can be; assigned in ""AddVariable"" call. Introduced the inverse transformation InverseTransform for; the variable transformations into the framework. While this is; not necessary for classification, it is necessary for; regression. The inverse transformation of the normalization; transformation has been implemented. Started to extend the variable transformations to the; regression targets as well. MethodCuts now produces the 'optimal-cut' histograms needed; by macro mvaeffs.C. (macro 5a of TMVAGui.C); ; MsgLogger can be silenced in order to prevent excess output; during boosting. Third dataset type added centrally (Training, Validation; and Testing). The validation data is split off the original; training data set. Update of GUI and other Macros according to the new; features of PDF and the addition of MethodBoost.; ; Updates in TMVA 4.0.1. ""Spectator"" variables can be defined now which are computed; just as the input variables and which are written out into the; TestTree, but which don't participate in any MVA calculation; (useful for correlation studies).; ; New booking option",MatchSource.DOCS,tmva/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html:5605,Modifiability,extend,extend,5605,"more than one; classifier within one. MethodBoost: boosts/bags any classifier; type. A special booking procedure for it was added to; Factory class. MethodDT: a classifier composed of a single; decision tree, boosted using MethodBoost. Results are; compatible with BDT, but BDT remains the default for boosted; decision trees, because it has pruning (among other; additional features). . Other improvements . Improved handling of small Likelihood values such that; Likelihood performance increases in analyses with many variables; (~>10). Thanks to Ralph Schaefer (Bonn U.) for reporting this. Nicer plotting: custom variable titles and units can be; assigned in ""AddVariable"" call. Introduced the inverse transformation InverseTransform for; the variable transformations into the framework. While this is; not necessary for classification, it is necessary for; regression. The inverse transformation of the normalization; transformation has been implemented. Started to extend the variable transformations to the; regression targets as well. MethodCuts now produces the 'optimal-cut' histograms needed; by macro mvaeffs.C. (macro 5a of TMVAGui.C); ; MsgLogger can be silenced in order to prevent excess output; during boosting. Third dataset type added centrally (Training, Validation; and Testing). The validation data is split off the original; training data set. Update of GUI and other Macros according to the new; features of PDF and the addition of MethodBoost.; ; Updates in TMVA 4.0.1. ""Spectator"" variables can be defined now which are computed; just as the input variables and which are written out into the; TestTree, but which don't participate in any MVA calculation; (useful for correlation studies).; ; New booking option ""IgnoreNegWeightsInTraining"" to test the; effect of events with negative weights on the training. This is; especially useful for methods, which do not properly deal with; such events. Note that this new option is not available for all; methods (a training interru",MatchSource.DOCS,tmva/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html:5616,Modifiability,variab,variable,5616,"more than one; classifier within one. MethodBoost: boosts/bags any classifier; type. A special booking procedure for it was added to; Factory class. MethodDT: a classifier composed of a single; decision tree, boosted using MethodBoost. Results are; compatible with BDT, but BDT remains the default for boosted; decision trees, because it has pruning (among other; additional features). . Other improvements . Improved handling of small Likelihood values such that; Likelihood performance increases in analyses with many variables; (~>10). Thanks to Ralph Schaefer (Bonn U.) for reporting this. Nicer plotting: custom variable titles and units can be; assigned in ""AddVariable"" call. Introduced the inverse transformation InverseTransform for; the variable transformations into the framework. While this is; not necessary for classification, it is necessary for; regression. The inverse transformation of the normalization; transformation has been implemented. Started to extend the variable transformations to the; regression targets as well. MethodCuts now produces the 'optimal-cut' histograms needed; by macro mvaeffs.C. (macro 5a of TMVAGui.C); ; MsgLogger can be silenced in order to prevent excess output; during boosting. Third dataset type added centrally (Training, Validation; and Testing). The validation data is split off the original; training data set. Update of GUI and other Macros according to the new; features of PDF and the addition of MethodBoost.; ; Updates in TMVA 4.0.1. ""Spectator"" variables can be defined now which are computed; just as the input variables and which are written out into the; TestTree, but which don't participate in any MVA calculation; (useful for correlation studies).; ; New booking option ""IgnoreNegWeightsInTraining"" to test the; effect of events with negative weights on the training. This is; especially useful for methods, which do not properly deal with; such events. Note that this new option is not available for all; methods (a training interru",MatchSource.DOCS,tmva/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html:6141,Modifiability,variab,variables,6141,"ting: custom variable titles and units can be; assigned in ""AddVariable"" call. Introduced the inverse transformation InverseTransform for; the variable transformations into the framework. While this is; not necessary for classification, it is necessary for; regression. The inverse transformation of the normalization; transformation has been implemented. Started to extend the variable transformations to the; regression targets as well. MethodCuts now produces the 'optimal-cut' histograms needed; by macro mvaeffs.C. (macro 5a of TMVAGui.C); ; MsgLogger can be silenced in order to prevent excess output; during boosting. Third dataset type added centrally (Training, Validation; and Testing). The validation data is split off the original; training data set. Update of GUI and other Macros according to the new; features of PDF and the addition of MethodBoost.; ; Updates in TMVA 4.0.1. ""Spectator"" variables can be defined now which are computed; just as the input variables and which are written out into the; TestTree, but which don't participate in any MVA calculation; (useful for correlation studies).; ; New booking option ""IgnoreNegWeightsInTraining"" to test the; effect of events with negative weights on the training. This is; especially useful for methods, which do not properly deal with; such events. Note that this new option is not available for all; methods (a training interrupt is issued if not available). ; Bug fixes:. Fixed regression bug in VariableNormalizeTransform (Use; number of targets from Event instead of DataSet); ; Fixed Multitarget-Regression in PDEFoam, foam dimensions; were miscalculated. Added writing of targets to the weight files in regression; mode to fix problems in RegressionApplication. Added missing standard C++ header files missing to some; classes, which lead to compilation failures on some; architectures (thanks to Lucian Ancu, Nijmegen, for reporting; these). Added checks for unused options to Factory and; DataSetFactory configuration option",MatchSource.DOCS,tmva/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html:6208,Modifiability,variab,variables,6208,"ting: custom variable titles and units can be; assigned in ""AddVariable"" call. Introduced the inverse transformation InverseTransform for; the variable transformations into the framework. While this is; not necessary for classification, it is necessary for; regression. The inverse transformation of the normalization; transformation has been implemented. Started to extend the variable transformations to the; regression targets as well. MethodCuts now produces the 'optimal-cut' histograms needed; by macro mvaeffs.C. (macro 5a of TMVAGui.C); ; MsgLogger can be silenced in order to prevent excess output; during boosting. Third dataset type added centrally (Training, Validation; and Testing). The validation data is split off the original; training data set. Update of GUI and other Macros according to the new; features of PDF and the addition of MethodBoost.; ; Updates in TMVA 4.0.1. ""Spectator"" variables can be defined now which are computed; just as the input variables and which are written out into the; TestTree, but which don't participate in any MVA calculation; (useful for correlation studies).; ; New booking option ""IgnoreNegWeightsInTraining"" to test the; effect of events with negative weights on the training. This is; especially useful for methods, which do not properly deal with; such events. Note that this new option is not available for all; methods (a training interrupt is issued if not available). ; Bug fixes:. Fixed regression bug in VariableNormalizeTransform (Use; number of targets from Event instead of DataSet); ; Fixed Multitarget-Regression in PDEFoam, foam dimensions; were miscalculated. Added writing of targets to the weight files in regression; mode to fix problems in RegressionApplication. Added missing standard C++ header files missing to some; classes, which lead to compilation failures on some; architectures (thanks to Lucian Ancu, Nijmegen, for reporting; these). Added checks for unused options to Factory and; DataSetFactory configuration option",MatchSource.DOCS,tmva/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html:7219,Modifiability,config,configuration,7219,"tion, it is necessary for; regression. The inverse transformation of the normalization; transformation has been implemented. Started to extend the variable transformations to the; regression targets as well. MethodCuts now produces the 'optimal-cut' histograms needed; by macro mvaeffs.C. (macro 5a of TMVAGui.C); ; MsgLogger can be silenced in order to prevent excess output; during boosting. Third dataset type added centrally (Training, Validation; and Testing). The validation data is split off the original; training data set. Update of GUI and other Macros according to the new; features of PDF and the addition of MethodBoost.; ; Updates in TMVA 4.0.1. ""Spectator"" variables can be defined now which are computed; just as the input variables and which are written out into the; TestTree, but which don't participate in any MVA calculation; (useful for correlation studies).; ; New booking option ""IgnoreNegWeightsInTraining"" to test the; effect of events with negative weights on the training. This is; especially useful for methods, which do not properly deal with; such events. Note that this new option is not available for all; methods (a training interrupt is issued if not available). ; Bug fixes:. Fixed regression bug in VariableNormalizeTransform (Use; number of targets from Event instead of DataSet); ; Fixed Multitarget-Regression in PDEFoam, foam dimensions; were miscalculated. Added writing of targets to the weight files in regression; mode to fix problems in RegressionApplication. Added missing standard C++ header files missing to some; classes, which lead to compilation failures on some; architectures (thanks to Lucian Ancu, Nijmegen, for reporting; these). Added checks for unused options to Factory and; DataSetFactory configuration options interpretation. Will now; complain if wrong option labels are used. Fixed standard creation of correlation matrix plots. Fixed internal mapping problem giving a fatal error message; when destroying and recreating the Factory. ; ",MatchSource.DOCS,tmva/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html:3041,Performance,perform,performance,3041," and estimate.; ; Macros plot various deviation and correlation quantities.; A new GUI (macros/TMVARegGui.C) collects these macros.; . Improvements of / new features for MVA methods . Linear Discriminant:; Re-implementation of ""Fisher"" method as general linear discriminant (""LD""),; which is also regression capable (so far: single-target only). PDEFoam:; PDE-Foam is a variation of the PDE-RS method using a self-adapting binning; method to divide the multi-dimensional variable space into a finite number; of hyper-rectangles (cells). The binning algorithm adjusts the size and; position of a predefined number of cells such that the variance of the; signal and background densities inside the cells reaches a minimum. BDT:; Introduced gradient boosting and stochastic gradient boosting for ; classification with BDT (as desribed by Friedman 1999). See ""BDTG"" ; example in TMVAClassification.C/cxx. A new option allows to restrict the maximum tree depth. This may be used to; avoid overtraining and often gives better performance than pruning. (The; pruning mechanism needs to be revisited). MLP:; Introduced recognition of convergence via general ConvergenceTest-class for; interrupting computations when convergence is reached. This feature has is; used now in MethodMLP. Improved treatment of event-weights in BFGS training. Implemented random and importance sampling of events in DataSet. Implemented; the usage of this feature for MLP.; ; TMlpANN (interface to TMultiLayerPerceptron) now also uses event weights; and writes standalone C++ class. k-NN:; A new global knn search function has been added to NodekNN that searches for; k-nearest neighbor using event weights instead of raw event counts. ModulekNN; has been modified to allow searches using ""weight"" or ""count"" option, where; ""count"" is default. Added UseWeight option to MethodKNN to allow using of; ""weight"" or ""count"". ; (Work by Rustem Ospanov, CERN). . Likelihood (and general PDF treatment):; Adaptive smoothing the PDF class, ",MatchSource.DOCS,tmva/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html:5110,Performance,perform,performance,5110,"oothNum (for regions with less signal). . Configuration of the PDF parameters from the option string moved to PDF class,; allowing the user to define all the PDF functionalities in every classifier; the PDF is used (i.e., also for the MVA PDFs). The reading of these variables; was removed from MethodBase and MethodLikelihood. This also allows improved ; (full) PDF configuration of MVA output via the ""CreateMvaPdf"" option.; (Work by Or Cohen, CERN & Weizmann); ; New generalisation methods:. ; MethodCompositeBase: combines more than one; classifier within one. MethodBoost: boosts/bags any classifier; type. A special booking procedure for it was added to; Factory class. MethodDT: a classifier composed of a single; decision tree, boosted using MethodBoost. Results are; compatible with BDT, but BDT remains the default for boosted; decision trees, because it has pruning (among other; additional features). . Other improvements . Improved handling of small Likelihood values such that; Likelihood performance increases in analyses with many variables; (~>10). Thanks to Ralph Schaefer (Bonn U.) for reporting this. Nicer plotting: custom variable titles and units can be; assigned in ""AddVariable"" call. Introduced the inverse transformation InverseTransform for; the variable transformations into the framework. While this is; not necessary for classification, it is necessary for; regression. The inverse transformation of the normalization; transformation has been implemented. Started to extend the variable transformations to the; regression targets as well. MethodCuts now produces the 'optimal-cut' histograms needed; by macro mvaeffs.C. (macro 5a of TMVAGui.C); ; MsgLogger can be silenced in order to prevent excess output; during boosting. Third dataset type added centrally (Training, Validation; and Testing). The validation data is split off the original; training data set. Update of GUI and other Macros according to the new; features of PDF and the addition of MethodBoost.; ; U",MatchSource.DOCS,tmva/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html:2999,Safety,avoid,avoid,2999," and estimate.; ; Macros plot various deviation and correlation quantities.; A new GUI (macros/TMVARegGui.C) collects these macros.; . Improvements of / new features for MVA methods . Linear Discriminant:; Re-implementation of ""Fisher"" method as general linear discriminant (""LD""),; which is also regression capable (so far: single-target only). PDEFoam:; PDE-Foam is a variation of the PDE-RS method using a self-adapting binning; method to divide the multi-dimensional variable space into a finite number; of hyper-rectangles (cells). The binning algorithm adjusts the size and; position of a predefined number of cells such that the variance of the; signal and background densities inside the cells reaches a minimum. BDT:; Introduced gradient boosting and stochastic gradient boosting for ; classification with BDT (as desribed by Friedman 1999). See ""BDTG"" ; example in TMVAClassification.C/cxx. A new option allows to restrict the maximum tree depth. This may be used to; avoid overtraining and often gives better performance than pruning. (The; pruning mechanism needs to be revisited). MLP:; Introduced recognition of convergence via general ConvergenceTest-class for; interrupting computations when convergence is reached. This feature has is; used now in MethodMLP. Improved treatment of event-weights in BFGS training. Implemented random and importance sampling of events in DataSet. Implemented; the usage of this feature for MLP.; ; TMlpANN (interface to TMultiLayerPerceptron) now also uses event weights; and writes standalone C++ class. k-NN:; A new global knn search function has been added to NodekNN that searches for; k-nearest neighbor using event weights instead of raw event counts. ModulekNN; has been modified to allow searches using ""weight"" or ""count"" option, where; ""count"" is default. Added UseWeight option to MethodKNN to allow using of; ""weight"" or ""count"". ; (Work by Rustem Ospanov, CERN). . Likelihood (and general PDF treatment):; Adaptive smoothing the PDF class, ",MatchSource.DOCS,tmva/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html:5939,Security,validat,validation,5939,"e it has pruning (among other; additional features). . Other improvements . Improved handling of small Likelihood values such that; Likelihood performance increases in analyses with many variables; (~>10). Thanks to Ralph Schaefer (Bonn U.) for reporting this. Nicer plotting: custom variable titles and units can be; assigned in ""AddVariable"" call. Introduced the inverse transformation InverseTransform for; the variable transformations into the framework. While this is; not necessary for classification, it is necessary for; regression. The inverse transformation of the normalization; transformation has been implemented. Started to extend the variable transformations to the; regression targets as well. MethodCuts now produces the 'optimal-cut' histograms needed; by macro mvaeffs.C. (macro 5a of TMVAGui.C); ; MsgLogger can be silenced in order to prevent excess output; during boosting. Third dataset type added centrally (Training, Validation; and Testing). The validation data is split off the original; training data set. Update of GUI and other Macros according to the new; features of PDF and the addition of MethodBoost.; ; Updates in TMVA 4.0.1. ""Spectator"" variables can be defined now which are computed; just as the input variables and which are written out into the; TestTree, but which don't participate in any MVA calculation; (useful for correlation studies).; ; New booking option ""IgnoreNegWeightsInTraining"" to test the; effect of events with negative weights on the training. This is; especially useful for methods, which do not properly deal with; such events. Note that this new option is not available for all; methods (a training interrupt is issued if not available). ; Bug fixes:. Fixed regression bug in VariableNormalizeTransform (Use; number of targets from Event instead of DataSet); ; Fixed Multitarget-Regression in PDEFoam, foam dimensions; were miscalculated. Added writing of targets to the weight files in regression; mode to fix problems in RegressionAppli",MatchSource.DOCS,tmva/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html:977,Testability,test,test,977,". TMVA. TMVA version 4.0.1 is included in this root release:. Main changes and new features introduced with TMVA 4. Reorganisation of internal data handling and constructors; of methods to allow to build arbitrary composite MVA methods,; and to deal with multi-class classification and multi-target; regression; ; Extended TMVA to multivariate multi-target regression; ; Any TMVA method can now be boosted (linearly or; non-linearly); ; Transformation of input variables can be chained as wished; ; Weight files are now in XML format; ; New MVA methods ""PDE-Foam"" and ""LD"", both featuring; classification and regression; ; ; Comments. On XML format:; ; The old text format is obsolete though still readable in the; application. Backward compatibility is NOT guaranteed. Please; contact the authors if you require the reading of old text weight; files in TMVA 4.; ; ; Standard macros:; ; The structure of the standard macros has changed: macros are; still in the ""$ROOTSYS/tmva/test"" directory, but distinguished for; classification and regression examples:; ; TMVAClassification.C, TMVAClassificationApplication.C TMVARegression.C, TMVARegressionApplication.C; ; Classification and regression analysis (training) is analysed as; usual via standard macros that can be called from dedicated; GUIs.; ; ; Regression:. Not yet available for all MVA methods. It exists for:; PDE-RS, PDE-Foam, K-NN, LD, FDA, MLP, BDT for single targets; (1D), and MLP for multiple targets (nD).; ; Not all transformation of input variables are available; (only ""Norm"" so far). Regression requires specific evaluation tools:. ; During the training we provide a ranking of input; variables, using various criteria: correlations, transposed; correlation, correlation ratio, and ""mutual information"" between; input variables and regression target. (Correlation ratio and; mutual information implmentations provided by Moritz Backes,; Geneva U); ; After the training, the trained MVA methods are ranked wrt.; the deviations betwe",MatchSource.DOCS,tmva/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html:6404,Testability,test,test,6404,"o the framework. While this is; not necessary for classification, it is necessary for; regression. The inverse transformation of the normalization; transformation has been implemented. Started to extend the variable transformations to the; regression targets as well. MethodCuts now produces the 'optimal-cut' histograms needed; by macro mvaeffs.C. (macro 5a of TMVAGui.C); ; MsgLogger can be silenced in order to prevent excess output; during boosting. Third dataset type added centrally (Training, Validation; and Testing). The validation data is split off the original; training data set. Update of GUI and other Macros according to the new; features of PDF and the addition of MethodBoost.; ; Updates in TMVA 4.0.1. ""Spectator"" variables can be defined now which are computed; just as the input variables and which are written out into the; TestTree, but which don't participate in any MVA calculation; (useful for correlation studies).; ; New booking option ""IgnoreNegWeightsInTraining"" to test the; effect of events with negative weights on the training. This is; especially useful for methods, which do not properly deal with; such events. Note that this new option is not available for all; methods (a training interrupt is issued if not available). ; Bug fixes:. Fixed regression bug in VariableNormalizeTransform (Use; number of targets from Event instead of DataSet); ; Fixed Multitarget-Regression in PDEFoam, foam dimensions; were miscalculated. Added writing of targets to the weight files in regression; mode to fix problems in RegressionApplication. Added missing standard C++ header files missing to some; classes, which lead to compilation failures on some; architectures (thanks to Lucian Ancu, Nijmegen, for reporting; these). Added checks for unused options to Factory and; DataSetFactory configuration options interpretation. Will now; complain if wrong option labels are used. Fixed standard creation of correlation matrix plots. Fixed internal mapping problem giving a fatal e",MatchSource.DOCS,tmva/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html:3106,Availability,avail,available,3106,"o"" where TMVA tries to determine the most suitable analysis; type from the targets and classes the user has defined. Other; values are ""regression"", ""classification"" and ""multiclass"" for; the forthcoming multiclass classification.; Missing regression evaluation plots for training sample were; added. On Cut method:. Removed obsolete option ""FVerySmart"" from Cuts method. On MLP method:; ; Display of convergence information in the progress bar for MLP during training. Creation of animated gifs for MLP convergence monitoring (please; contact authors if you want to do this). On Datasets: . Checks are performed if events are unvoluntarily cut by using a; non-filled array entry (e.g. ""arr[4]"" is used, when the array; has not always at least 5 entries). A warning is given in that; case.; Bug fixes. Spectators and Targets could not be used with by-hand assignment of events.; Corrected types (training/testing) for assigning single events.; Changed message from FATAL to WARNING when the user requests more events for ; training or testing than available.; Fixed bug which caused TMVA to crash if the number of input variables exceeded ; the allowed maximum for generating scatter plots.; Prevent TMVA from crashing when running with an empty TTree or TChain.; A variable expression like ""Alt$(arr[3],0)"" can now be used; to give a default value for a variable if for some events the; array don't contain enough elements (e.g. in two jet events,; sometimes only one jet is found and thus, the array jetPt[] has; only one entry in that cases).; Plot ranges for scatter-plots showing the transformed events are now correct.; User defined training/testing-trees are now handled correctly.; Fix bug in correlation computation for regression.; Consistent use of variable labels (for the log output) and variable titles (in histograms).; Drawing of variable labels in network architecture display for regression mode has been added.; Bug fixes to Cuts which improves performance on datasets with many va",MatchSource.DOCS,tmva/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html:52,Deployability,release,release,52,". TMVA. TMVA version 4.0.4 is included in this root release. Methods. A new Category method allowing the user to; separate the training data (and accordingly the application; data) into disjoint sub-populations exhibiting significantly; different properties. The separation into phase space regions is; done by applying requirements on the input and/or spectator; variables. In each of these disjoint regions (each event must; belong to one and only one region), an independent training is; performed using the most appropriate MVA method, training; options and set of training variables in that zone. The division; into categories in presence of distinct sub-populations reduces; the correlations between the training variables, improves the; modelling, and hence increases the classification and regression; performance. Presently, the Category method works for; classification only, but regression will follow soon. Please; contact us if urgently needed. An example scripts and data files illustrating how the new; Category method is configured and used. Please check the macros; test/TMVAClassificationCategory.C and; test/TMVAClassificationCategoryApplication.C or the; corresponding executables.; Regression functionality for gradient boosted trees using a Huber loss function. Comments. On Input Data: . New TMVA event vector building. The code for splitting the input; data into training and test samples for all classes and the; mixing of those samples to one training and one test sample has; been rewritten completely. The new code is more performant and; has a clearer structure. This fixes several bugs which have been; reported by the TMVA users. On Minimization: . Variables, targets and spectators are now checked if they are; constant. (The execution of TMVA is stopped for variables and; targets, a warning is given for spectators.). On Regression:; ; The analysis type is no longer defined by calling a dedicated; TestAllMethods-member-function of the Factory, but with the; option ",MatchSource.DOCS,tmva/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html:672,Energy Efficiency,reduce,reduces,672,". TMVA. TMVA version 4.0.4 is included in this root release. Methods. A new Category method allowing the user to; separate the training data (and accordingly the application; data) into disjoint sub-populations exhibiting significantly; different properties. The separation into phase space regions is; done by applying requirements on the input and/or spectator; variables. In each of these disjoint regions (each event must; belong to one and only one region), an independent training is; performed using the most appropriate MVA method, training; options and set of training variables in that zone. The division; into categories in presence of distinct sub-populations reduces; the correlations between the training variables, improves the; modelling, and hence increases the classification and regression; performance. Presently, the Category method works for; classification only, but regression will follow soon. Please; contact us if urgently needed. An example scripts and data files illustrating how the new; Category method is configured and used. Please check the macros; test/TMVAClassificationCategory.C and; test/TMVAClassificationCategoryApplication.C or the; corresponding executables.; Regression functionality for gradient boosted trees using a Huber loss function. Comments. On Input Data: . New TMVA event vector building. The code for splitting the input; data into training and test samples for all classes and the; mixing of those samples to one training and one test sample has; been rewritten completely. The new code is more performant and; has a clearer structure. This fixes several bugs which have been; reported by the TMVA users. On Minimization: . Variables, targets and spectators are now checked if they are; constant. (The execution of TMVA is stopped for variables and; targets, a warning is given for spectators.). On Regression:; ; The analysis type is no longer defined by calling a dedicated; TestAllMethods-member-function of the Factory, but with the; option ",MatchSource.DOCS,tmva/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html:2574,Energy Efficiency,monitor,monitoring,2574," structure. This fixes several bugs which have been; reported by the TMVA users. On Minimization: . Variables, targets and spectators are now checked if they are; constant. (The execution of TMVA is stopped for variables and; targets, a warning is given for spectators.). On Regression:; ; The analysis type is no longer defined by calling a dedicated; TestAllMethods-member-function of the Factory, but with the; option ""AnalysisType"" in the Factory. The default value is; ""Auto"" where TMVA tries to determine the most suitable analysis; type from the targets and classes the user has defined. Other; values are ""regression"", ""classification"" and ""multiclass"" for; the forthcoming multiclass classification.; Missing regression evaluation plots for training sample were; added. On Cut method:. Removed obsolete option ""FVerySmart"" from Cuts method. On MLP method:; ; Display of convergence information in the progress bar for MLP during training. Creation of animated gifs for MLP convergence monitoring (please; contact authors if you want to do this). On Datasets: . Checks are performed if events are unvoluntarily cut by using a; non-filled array entry (e.g. ""arr[4]"" is used, when the array; has not always at least 5 entries). A warning is given in that; case.; Bug fixes. Spectators and Targets could not be used with by-hand assignment of events.; Corrected types (training/testing) for assigning single events.; Changed message from FATAL to WARNING when the user requests more events for ; training or testing than available.; Fixed bug which caused TMVA to crash if the number of input variables exceeded ; the allowed maximum for generating scatter plots.; Prevent TMVA from crashing when running with an empty TTree or TChain.; A variable expression like ""Alt$(arr[3],0)"" can now be used; to give a default value for a variable if for some events the; array don't contain enough elements (e.g. in two jet events,; sometimes only one jet is found and thus, the array jetPt[] has; only one",MatchSource.DOCS,tmva/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html:3010,Integrability,message,message,3010,"o"" where TMVA tries to determine the most suitable analysis; type from the targets and classes the user has defined. Other; values are ""regression"", ""classification"" and ""multiclass"" for; the forthcoming multiclass classification.; Missing regression evaluation plots for training sample were; added. On Cut method:. Removed obsolete option ""FVerySmart"" from Cuts method. On MLP method:; ; Display of convergence information in the progress bar for MLP during training. Creation of animated gifs for MLP convergence monitoring (please; contact authors if you want to do this). On Datasets: . Checks are performed if events are unvoluntarily cut by using a; non-filled array entry (e.g. ""arr[4]"" is used, when the array; has not always at least 5 entries). A warning is given in that; case.; Bug fixes. Spectators and Targets could not be used with by-hand assignment of events.; Corrected types (training/testing) for assigning single events.; Changed message from FATAL to WARNING when the user requests more events for ; training or testing than available.; Fixed bug which caused TMVA to crash if the number of input variables exceeded ; the allowed maximum for generating scatter plots.; Prevent TMVA from crashing when running with an empty TTree or TChain.; A variable expression like ""Alt$(arr[3],0)"" can now be used; to give a default value for a variable if for some events the; array don't contain enough elements (e.g. in two jet events,; sometimes only one jet is found and thus, the array jetPt[] has; only one entry in that cases).; Plot ranges for scatter-plots showing the transformed events are now correct.; User defined training/testing-trees are now handled correctly.; Fix bug in correlation computation for regression.; Consistent use of variable labels (for the log output) and variable titles (in histograms).; Drawing of variable labels in network architecture display for regression mode has been added.; Bug fixes to Cuts which improves performance on datasets with many va",MatchSource.DOCS,tmva/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html:364,Modifiability,variab,variables,364,". TMVA. TMVA version 4.0.4 is included in this root release. Methods. A new Category method allowing the user to; separate the training data (and accordingly the application; data) into disjoint sub-populations exhibiting significantly; different properties. The separation into phase space regions is; done by applying requirements on the input and/or spectator; variables. In each of these disjoint regions (each event must; belong to one and only one region), an independent training is; performed using the most appropriate MVA method, training; options and set of training variables in that zone. The division; into categories in presence of distinct sub-populations reduces; the correlations between the training variables, improves the; modelling, and hence increases the classification and regression; performance. Presently, the Category method works for; classification only, but regression will follow soon. Please; contact us if urgently needed. An example scripts and data files illustrating how the new; Category method is configured and used. Please check the macros; test/TMVAClassificationCategory.C and; test/TMVAClassificationCategoryApplication.C or the; corresponding executables.; Regression functionality for gradient boosted trees using a Huber loss function. Comments. On Input Data: . New TMVA event vector building. The code for splitting the input; data into training and test samples for all classes and the; mixing of those samples to one training and one test sample has; been rewritten completely. The new code is more performant and; has a clearer structure. This fixes several bugs which have been; reported by the TMVA users. On Minimization: . Variables, targets and spectators are now checked if they are; constant. (The execution of TMVA is stopped for variables and; targets, a warning is given for spectators.). On Regression:; ; The analysis type is no longer defined by calling a dedicated; TestAllMethods-member-function of the Factory, but with the; option ",MatchSource.DOCS,tmva/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html:578,Modifiability,variab,variables,578,". TMVA. TMVA version 4.0.4 is included in this root release. Methods. A new Category method allowing the user to; separate the training data (and accordingly the application; data) into disjoint sub-populations exhibiting significantly; different properties. The separation into phase space regions is; done by applying requirements on the input and/or spectator; variables. In each of these disjoint regions (each event must; belong to one and only one region), an independent training is; performed using the most appropriate MVA method, training; options and set of training variables in that zone. The division; into categories in presence of distinct sub-populations reduces; the correlations between the training variables, improves the; modelling, and hence increases the classification and regression; performance. Presently, the Category method works for; classification only, but regression will follow soon. Please; contact us if urgently needed. An example scripts and data files illustrating how the new; Category method is configured and used. Please check the macros; test/TMVAClassificationCategory.C and; test/TMVAClassificationCategoryApplication.C or the; corresponding executables.; Regression functionality for gradient boosted trees using a Huber loss function. Comments. On Input Data: . New TMVA event vector building. The code for splitting the input; data into training and test samples for all classes and the; mixing of those samples to one training and one test sample has; been rewritten completely. The new code is more performant and; has a clearer structure. This fixes several bugs which have been; reported by the TMVA users. On Minimization: . Variables, targets and spectators are now checked if they are; constant. (The execution of TMVA is stopped for variables and; targets, a warning is given for spectators.). On Regression:; ; The analysis type is no longer defined by calling a dedicated; TestAllMethods-member-function of the Factory, but with the; option ",MatchSource.DOCS,tmva/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html:719,Modifiability,variab,variables,719,". TMVA. TMVA version 4.0.4 is included in this root release. Methods. A new Category method allowing the user to; separate the training data (and accordingly the application; data) into disjoint sub-populations exhibiting significantly; different properties. The separation into phase space regions is; done by applying requirements on the input and/or spectator; variables. In each of these disjoint regions (each event must; belong to one and only one region), an independent training is; performed using the most appropriate MVA method, training; options and set of training variables in that zone. The division; into categories in presence of distinct sub-populations reduces; the correlations between the training variables, improves the; modelling, and hence increases the classification and regression; performance. Presently, the Category method works for; classification only, but regression will follow soon. Please; contact us if urgently needed. An example scripts and data files illustrating how the new; Category method is configured and used. Please check the macros; test/TMVAClassificationCategory.C and; test/TMVAClassificationCategoryApplication.C or the; corresponding executables.; Regression functionality for gradient boosted trees using a Huber loss function. Comments. On Input Data: . New TMVA event vector building. The code for splitting the input; data into training and test samples for all classes and the; mixing of those samples to one training and one test sample has; been rewritten completely. The new code is more performant and; has a clearer structure. This fixes several bugs which have been; reported by the TMVA users. On Minimization: . Variables, targets and spectators are now checked if they are; constant. (The execution of TMVA is stopped for variables and; targets, a warning is given for spectators.). On Regression:; ; The analysis type is no longer defined by calling a dedicated; TestAllMethods-member-function of the Factory, but with the; option ",MatchSource.DOCS,tmva/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html:1037,Modifiability,config,configured,1037," TMVA version 4.0.4 is included in this root release. Methods. A new Category method allowing the user to; separate the training data (and accordingly the application; data) into disjoint sub-populations exhibiting significantly; different properties. The separation into phase space regions is; done by applying requirements on the input and/or spectator; variables. In each of these disjoint regions (each event must; belong to one and only one region), an independent training is; performed using the most appropriate MVA method, training; options and set of training variables in that zone. The division; into categories in presence of distinct sub-populations reduces; the correlations between the training variables, improves the; modelling, and hence increases the classification and regression; performance. Presently, the Category method works for; classification only, but regression will follow soon. Please; contact us if urgently needed. An example scripts and data files illustrating how the new; Category method is configured and used. Please check the macros; test/TMVAClassificationCategory.C and; test/TMVAClassificationCategoryApplication.C or the; corresponding executables.; Regression functionality for gradient boosted trees using a Huber loss function. Comments. On Input Data: . New TMVA event vector building. The code for splitting the input; data into training and test samples for all classes and the; mixing of those samples to one training and one test sample has; been rewritten completely. The new code is more performant and; has a clearer structure. This fixes several bugs which have been; reported by the TMVA users. On Minimization: . Variables, targets and spectators are now checked if they are; constant. (The execution of TMVA is stopped for variables and; targets, a warning is given for spectators.). On Regression:; ; The analysis type is no longer defined by calling a dedicated; TestAllMethods-member-function of the Factory, but with the; option ""Analy",MatchSource.DOCS,tmva/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html:1791,Modifiability,variab,variables,1791,"gression; performance. Presently, the Category method works for; classification only, but regression will follow soon. Please; contact us if urgently needed. An example scripts and data files illustrating how the new; Category method is configured and used. Please check the macros; test/TMVAClassificationCategory.C and; test/TMVAClassificationCategoryApplication.C or the; corresponding executables.; Regression functionality for gradient boosted trees using a Huber loss function. Comments. On Input Data: . New TMVA event vector building. The code for splitting the input; data into training and test samples for all classes and the; mixing of those samples to one training and one test sample has; been rewritten completely. The new code is more performant and; has a clearer structure. This fixes several bugs which have been; reported by the TMVA users. On Minimization: . Variables, targets and spectators are now checked if they are; constant. (The execution of TMVA is stopped for variables and; targets, a warning is given for spectators.). On Regression:; ; The analysis type is no longer defined by calling a dedicated; TestAllMethods-member-function of the Factory, but with the; option ""AnalysisType"" in the Factory. The default value is; ""Auto"" where TMVA tries to determine the most suitable analysis; type from the targets and classes the user has defined. Other; values are ""regression"", ""classification"" and ""multiclass"" for; the forthcoming multiclass classification.; Missing regression evaluation plots for training sample were; added. On Cut method:. Removed obsolete option ""FVerySmart"" from Cuts method. On MLP method:; ; Display of convergence information in the progress bar for MLP during training. Creation of animated gifs for MLP convergence monitoring (please; contact authors if you want to do this). On Datasets: . Checks are performed if events are unvoluntarily cut by using a; non-filled array entry (e.g. ""arr[4]"" is used, when the array; has not always at least",MatchSource.DOCS,tmva/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html:3178,Modifiability,variab,variables,3178,"nd classes the user has defined. Other; values are ""regression"", ""classification"" and ""multiclass"" for; the forthcoming multiclass classification.; Missing regression evaluation plots for training sample were; added. On Cut method:. Removed obsolete option ""FVerySmart"" from Cuts method. On MLP method:; ; Display of convergence information in the progress bar for MLP during training. Creation of animated gifs for MLP convergence monitoring (please; contact authors if you want to do this). On Datasets: . Checks are performed if events are unvoluntarily cut by using a; non-filled array entry (e.g. ""arr[4]"" is used, when the array; has not always at least 5 entries). A warning is given in that; case.; Bug fixes. Spectators and Targets could not be used with by-hand assignment of events.; Corrected types (training/testing) for assigning single events.; Changed message from FATAL to WARNING when the user requests more events for ; training or testing than available.; Fixed bug which caused TMVA to crash if the number of input variables exceeded ; the allowed maximum for generating scatter plots.; Prevent TMVA from crashing when running with an empty TTree or TChain.; A variable expression like ""Alt$(arr[3],0)"" can now be used; to give a default value for a variable if for some events the; array don't contain enough elements (e.g. in two jet events,; sometimes only one jet is found and thus, the array jetPt[] has; only one entry in that cases).; Plot ranges for scatter-plots showing the transformed events are now correct.; User defined training/testing-trees are now handled correctly.; Fix bug in correlation computation for regression.; Consistent use of variable labels (for the log output) and variable titles (in histograms).; Drawing of variable labels in network architecture display for regression mode has been added.; Bug fixes to Cuts which improves performance on datasets with many variables.; Bug fix in GaussTransformation which improves handling of gaussian tails. ",MatchSource.DOCS,tmva/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html:3324,Modifiability,variab,variable,3324,"nd classes the user has defined. Other; values are ""regression"", ""classification"" and ""multiclass"" for; the forthcoming multiclass classification.; Missing regression evaluation plots for training sample were; added. On Cut method:. Removed obsolete option ""FVerySmart"" from Cuts method. On MLP method:; ; Display of convergence information in the progress bar for MLP during training. Creation of animated gifs for MLP convergence monitoring (please; contact authors if you want to do this). On Datasets: . Checks are performed if events are unvoluntarily cut by using a; non-filled array entry (e.g. ""arr[4]"" is used, when the array; has not always at least 5 entries). A warning is given in that; case.; Bug fixes. Spectators and Targets could not be used with by-hand assignment of events.; Corrected types (training/testing) for assigning single events.; Changed message from FATAL to WARNING when the user requests more events for ; training or testing than available.; Fixed bug which caused TMVA to crash if the number of input variables exceeded ; the allowed maximum for generating scatter plots.; Prevent TMVA from crashing when running with an empty TTree or TChain.; A variable expression like ""Alt$(arr[3],0)"" can now be used; to give a default value for a variable if for some events the; array don't contain enough elements (e.g. in two jet events,; sometimes only one jet is found and thus, the array jetPt[] has; only one entry in that cases).; Plot ranges for scatter-plots showing the transformed events are now correct.; User defined training/testing-trees are now handled correctly.; Fix bug in correlation computation for regression.; Consistent use of variable labels (for the log output) and variable titles (in histograms).; Drawing of variable labels in network architecture display for regression mode has been added.; Bug fixes to Cuts which improves performance on datasets with many variables.; Bug fix in GaussTransformation which improves handling of gaussian tails. ",MatchSource.DOCS,tmva/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html:3413,Modifiability,variab,variable,3413,"nd classes the user has defined. Other; values are ""regression"", ""classification"" and ""multiclass"" for; the forthcoming multiclass classification.; Missing regression evaluation plots for training sample were; added. On Cut method:. Removed obsolete option ""FVerySmart"" from Cuts method. On MLP method:; ; Display of convergence information in the progress bar for MLP during training. Creation of animated gifs for MLP convergence monitoring (please; contact authors if you want to do this). On Datasets: . Checks are performed if events are unvoluntarily cut by using a; non-filled array entry (e.g. ""arr[4]"" is used, when the array; has not always at least 5 entries). A warning is given in that; case.; Bug fixes. Spectators and Targets could not be used with by-hand assignment of events.; Corrected types (training/testing) for assigning single events.; Changed message from FATAL to WARNING when the user requests more events for ; training or testing than available.; Fixed bug which caused TMVA to crash if the number of input variables exceeded ; the allowed maximum for generating scatter plots.; Prevent TMVA from crashing when running with an empty TTree or TChain.; A variable expression like ""Alt$(arr[3],0)"" can now be used; to give a default value for a variable if for some events the; array don't contain enough elements (e.g. in two jet events,; sometimes only one jet is found and thus, the array jetPt[] has; only one entry in that cases).; Plot ranges for scatter-plots showing the transformed events are now correct.; User defined training/testing-trees are now handled correctly.; Fix bug in correlation computation for regression.; Consistent use of variable labels (for the log output) and variable titles (in histograms).; Drawing of variable labels in network architecture display for regression mode has been added.; Bug fixes to Cuts which improves performance on datasets with many variables.; Bug fix in GaussTransformation which improves handling of gaussian tails. ",MatchSource.DOCS,tmva/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html:3818,Modifiability,variab,variable,3818,"nd classes the user has defined. Other; values are ""regression"", ""classification"" and ""multiclass"" for; the forthcoming multiclass classification.; Missing regression evaluation plots for training sample were; added. On Cut method:. Removed obsolete option ""FVerySmart"" from Cuts method. On MLP method:; ; Display of convergence information in the progress bar for MLP during training. Creation of animated gifs for MLP convergence monitoring (please; contact authors if you want to do this). On Datasets: . Checks are performed if events are unvoluntarily cut by using a; non-filled array entry (e.g. ""arr[4]"" is used, when the array; has not always at least 5 entries). A warning is given in that; case.; Bug fixes. Spectators and Targets could not be used with by-hand assignment of events.; Corrected types (training/testing) for assigning single events.; Changed message from FATAL to WARNING when the user requests more events for ; training or testing than available.; Fixed bug which caused TMVA to crash if the number of input variables exceeded ; the allowed maximum for generating scatter plots.; Prevent TMVA from crashing when running with an empty TTree or TChain.; A variable expression like ""Alt$(arr[3],0)"" can now be used; to give a default value for a variable if for some events the; array don't contain enough elements (e.g. in two jet events,; sometimes only one jet is found and thus, the array jetPt[] has; only one entry in that cases).; Plot ranges for scatter-plots showing the transformed events are now correct.; User defined training/testing-trees are now handled correctly.; Fix bug in correlation computation for regression.; Consistent use of variable labels (for the log output) and variable titles (in histograms).; Drawing of variable labels in network architecture display for regression mode has been added.; Bug fixes to Cuts which improves performance on datasets with many variables.; Bug fix in GaussTransformation which improves handling of gaussian tails. ",MatchSource.DOCS,tmva/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html:3859,Modifiability,variab,variable,3859,"nd classes the user has defined. Other; values are ""regression"", ""classification"" and ""multiclass"" for; the forthcoming multiclass classification.; Missing regression evaluation plots for training sample were; added. On Cut method:. Removed obsolete option ""FVerySmart"" from Cuts method. On MLP method:; ; Display of convergence information in the progress bar for MLP during training. Creation of animated gifs for MLP convergence monitoring (please; contact authors if you want to do this). On Datasets: . Checks are performed if events are unvoluntarily cut by using a; non-filled array entry (e.g. ""arr[4]"" is used, when the array; has not always at least 5 entries). A warning is given in that; case.; Bug fixes. Spectators and Targets could not be used with by-hand assignment of events.; Corrected types (training/testing) for assigning single events.; Changed message from FATAL to WARNING when the user requests more events for ; training or testing than available.; Fixed bug which caused TMVA to crash if the number of input variables exceeded ; the allowed maximum for generating scatter plots.; Prevent TMVA from crashing when running with an empty TTree or TChain.; A variable expression like ""Alt$(arr[3],0)"" can now be used; to give a default value for a variable if for some events the; array don't contain enough elements (e.g. in two jet events,; sometimes only one jet is found and thus, the array jetPt[] has; only one entry in that cases).; Plot ranges for scatter-plots showing the transformed events are now correct.; User defined training/testing-trees are now handled correctly.; Fix bug in correlation computation for regression.; Consistent use of variable labels (for the log output) and variable titles (in histograms).; Drawing of variable labels in network architecture display for regression mode has been added.; Bug fixes to Cuts which improves performance on datasets with many variables.; Bug fix in GaussTransformation which improves handling of gaussian tails. ",MatchSource.DOCS,tmva/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html:3904,Modifiability,variab,variable,3904,"nd classes the user has defined. Other; values are ""regression"", ""classification"" and ""multiclass"" for; the forthcoming multiclass classification.; Missing regression evaluation plots for training sample were; added. On Cut method:. Removed obsolete option ""FVerySmart"" from Cuts method. On MLP method:; ; Display of convergence information in the progress bar for MLP during training. Creation of animated gifs for MLP convergence monitoring (please; contact authors if you want to do this). On Datasets: . Checks are performed if events are unvoluntarily cut by using a; non-filled array entry (e.g. ""arr[4]"" is used, when the array; has not always at least 5 entries). A warning is given in that; case.; Bug fixes. Spectators and Targets could not be used with by-hand assignment of events.; Corrected types (training/testing) for assigning single events.; Changed message from FATAL to WARNING when the user requests more events for ; training or testing than available.; Fixed bug which caused TMVA to crash if the number of input variables exceeded ; the allowed maximum for generating scatter plots.; Prevent TMVA from crashing when running with an empty TTree or TChain.; A variable expression like ""Alt$(arr[3],0)"" can now be used; to give a default value for a variable if for some events the; array don't contain enough elements (e.g. in two jet events,; sometimes only one jet is found and thus, the array jetPt[] has; only one entry in that cases).; Plot ranges for scatter-plots showing the transformed events are now correct.; User defined training/testing-trees are now handled correctly.; Fix bug in correlation computation for regression.; Consistent use of variable labels (for the log output) and variable titles (in histograms).; Drawing of variable labels in network architecture display for regression mode has been added.; Bug fixes to Cuts which improves performance on datasets with many variables.; Bug fix in GaussTransformation which improves handling of gaussian tails. ",MatchSource.DOCS,tmva/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html:4056,Modifiability,variab,variables,4056,"nd classes the user has defined. Other; values are ""regression"", ""classification"" and ""multiclass"" for; the forthcoming multiclass classification.; Missing regression evaluation plots for training sample were; added. On Cut method:. Removed obsolete option ""FVerySmart"" from Cuts method. On MLP method:; ; Display of convergence information in the progress bar for MLP during training. Creation of animated gifs for MLP convergence monitoring (please; contact authors if you want to do this). On Datasets: . Checks are performed if events are unvoluntarily cut by using a; non-filled array entry (e.g. ""arr[4]"" is used, when the array; has not always at least 5 entries). A warning is given in that; case.; Bug fixes. Spectators and Targets could not be used with by-hand assignment of events.; Corrected types (training/testing) for assigning single events.; Changed message from FATAL to WARNING when the user requests more events for ; training or testing than available.; Fixed bug which caused TMVA to crash if the number of input variables exceeded ; the allowed maximum for generating scatter plots.; Prevent TMVA from crashing when running with an empty TTree or TChain.; A variable expression like ""Alt$(arr[3],0)"" can now be used; to give a default value for a variable if for some events the; array don't contain enough elements (e.g. in two jet events,; sometimes only one jet is found and thus, the array jetPt[] has; only one entry in that cases).; Plot ranges for scatter-plots showing the transformed events are now correct.; User defined training/testing-trees are now handled correctly.; Fix bug in correlation computation for regression.; Consistent use of variable labels (for the log output) and variable titles (in histograms).; Drawing of variable labels in network architecture display for regression mode has been added.; Bug fixes to Cuts which improves performance on datasets with many variables.; Bug fix in GaussTransformation which improves handling of gaussian tails. ",MatchSource.DOCS,tmva/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html:491,Performance,perform,performed,491,". TMVA. TMVA version 4.0.4 is included in this root release. Methods. A new Category method allowing the user to; separate the training data (and accordingly the application; data) into disjoint sub-populations exhibiting significantly; different properties. The separation into phase space regions is; done by applying requirements on the input and/or spectator; variables. In each of these disjoint regions (each event must; belong to one and only one region), an independent training is; performed using the most appropriate MVA method, training; options and set of training variables in that zone. The division; into categories in presence of distinct sub-populations reduces; the correlations between the training variables, improves the; modelling, and hence increases the classification and regression; performance. Presently, the Category method works for; classification only, but regression will follow soon. Please; contact us if urgently needed. An example scripts and data files illustrating how the new; Category method is configured and used. Please check the macros; test/TMVAClassificationCategory.C and; test/TMVAClassificationCategoryApplication.C or the; corresponding executables.; Regression functionality for gradient boosted trees using a Huber loss function. Comments. On Input Data: . New TMVA event vector building. The code for splitting the input; data into training and test samples for all classes and the; mixing of those samples to one training and one test sample has; been rewritten completely. The new code is more performant and; has a clearer structure. This fixes several bugs which have been; reported by the TMVA users. On Minimization: . Variables, targets and spectators are now checked if they are; constant. (The execution of TMVA is stopped for variables and; targets, a warning is given for spectators.). On Regression:; ; The analysis type is no longer defined by calling a dedicated; TestAllMethods-member-function of the Factory, but with the; option ",MatchSource.DOCS,tmva/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html:810,Performance,perform,performance,810,". TMVA. TMVA version 4.0.4 is included in this root release. Methods. A new Category method allowing the user to; separate the training data (and accordingly the application; data) into disjoint sub-populations exhibiting significantly; different properties. The separation into phase space regions is; done by applying requirements on the input and/or spectator; variables. In each of these disjoint regions (each event must; belong to one and only one region), an independent training is; performed using the most appropriate MVA method, training; options and set of training variables in that zone. The division; into categories in presence of distinct sub-populations reduces; the correlations between the training variables, improves the; modelling, and hence increases the classification and regression; performance. Presently, the Category method works for; classification only, but regression will follow soon. Please; contact us if urgently needed. An example scripts and data files illustrating how the new; Category method is configured and used. Please check the macros; test/TMVAClassificationCategory.C and; test/TMVAClassificationCategoryApplication.C or the; corresponding executables.; Regression functionality for gradient boosted trees using a Huber loss function. Comments. On Input Data: . New TMVA event vector building. The code for splitting the input; data into training and test samples for all classes and the; mixing of those samples to one training and one test sample has; been rewritten completely. The new code is more performant and; has a clearer structure. This fixes several bugs which have been; reported by the TMVA users. On Minimization: . Variables, targets and spectators are now checked if they are; constant. (The execution of TMVA is stopped for variables and; targets, a warning is given for spectators.). On Regression:; ; The analysis type is no longer defined by calling a dedicated; TestAllMethods-member-function of the Factory, but with the; option ",MatchSource.DOCS,tmva/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html:1551,Performance,perform,performant,1551,"d set of training variables in that zone. The division; into categories in presence of distinct sub-populations reduces; the correlations between the training variables, improves the; modelling, and hence increases the classification and regression; performance. Presently, the Category method works for; classification only, but regression will follow soon. Please; contact us if urgently needed. An example scripts and data files illustrating how the new; Category method is configured and used. Please check the macros; test/TMVAClassificationCategory.C and; test/TMVAClassificationCategoryApplication.C or the; corresponding executables.; Regression functionality for gradient boosted trees using a Huber loss function. Comments. On Input Data: . New TMVA event vector building. The code for splitting the input; data into training and test samples for all classes and the; mixing of those samples to one training and one test sample has; been rewritten completely. The new code is more performant and; has a clearer structure. This fixes several bugs which have been; reported by the TMVA users. On Minimization: . Variables, targets and spectators are now checked if they are; constant. (The execution of TMVA is stopped for variables and; targets, a warning is given for spectators.). On Regression:; ; The analysis type is no longer defined by calling a dedicated; TestAllMethods-member-function of the Factory, but with the; option ""AnalysisType"" in the Factory. The default value is; ""Auto"" where TMVA tries to determine the most suitable analysis; type from the targets and classes the user has defined. Other; values are ""regression"", ""classification"" and ""multiclass"" for; the forthcoming multiclass classification.; Missing regression evaluation plots for training sample were; added. On Cut method:. Removed obsolete option ""FVerySmart"" from Cuts method. On MLP method:; ; Display of convergence information in the progress bar for MLP during training. Creation of animated gifs for ML",MatchSource.DOCS,tmva/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html:2661,Performance,perform,performed,2661,"ets and spectators are now checked if they are; constant. (The execution of TMVA is stopped for variables and; targets, a warning is given for spectators.). On Regression:; ; The analysis type is no longer defined by calling a dedicated; TestAllMethods-member-function of the Factory, but with the; option ""AnalysisType"" in the Factory. The default value is; ""Auto"" where TMVA tries to determine the most suitable analysis; type from the targets and classes the user has defined. Other; values are ""regression"", ""classification"" and ""multiclass"" for; the forthcoming multiclass classification.; Missing regression evaluation plots for training sample were; added. On Cut method:. Removed obsolete option ""FVerySmart"" from Cuts method. On MLP method:; ; Display of convergence information in the progress bar for MLP during training. Creation of animated gifs for MLP convergence monitoring (please; contact authors if you want to do this). On Datasets: . Checks are performed if events are unvoluntarily cut by using a; non-filled array entry (e.g. ""arr[4]"" is used, when the array; has not always at least 5 entries). A warning is given in that; case.; Bug fixes. Spectators and Targets could not be used with by-hand assignment of events.; Corrected types (training/testing) for assigning single events.; Changed message from FATAL to WARNING when the user requests more events for ; training or testing than available.; Fixed bug which caused TMVA to crash if the number of input variables exceeded ; the allowed maximum for generating scatter plots.; Prevent TMVA from crashing when running with an empty TTree or TChain.; A variable expression like ""Alt$(arr[3],0)"" can now be used; to give a default value for a variable if for some events the; array don't contain enough elements (e.g. in two jet events,; sometimes only one jet is found and thus, the array jetPt[] has; only one entry in that cases).; Plot ranges for scatter-plots showing the transformed events are now correct.; User define",MatchSource.DOCS,tmva/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html:4022,Performance,perform,performance,4022,"nd classes the user has defined. Other; values are ""regression"", ""classification"" and ""multiclass"" for; the forthcoming multiclass classification.; Missing regression evaluation plots for training sample were; added. On Cut method:. Removed obsolete option ""FVerySmart"" from Cuts method. On MLP method:; ; Display of convergence information in the progress bar for MLP during training. Creation of animated gifs for MLP convergence monitoring (please; contact authors if you want to do this). On Datasets: . Checks are performed if events are unvoluntarily cut by using a; non-filled array entry (e.g. ""arr[4]"" is used, when the array; has not always at least 5 entries). A warning is given in that; case.; Bug fixes. Spectators and Targets could not be used with by-hand assignment of events.; Corrected types (training/testing) for assigning single events.; Changed message from FATAL to WARNING when the user requests more events for ; training or testing than available.; Fixed bug which caused TMVA to crash if the number of input variables exceeded ; the allowed maximum for generating scatter plots.; Prevent TMVA from crashing when running with an empty TTree or TChain.; A variable expression like ""Alt$(arr[3],0)"" can now be used; to give a default value for a variable if for some events the; array don't contain enough elements (e.g. in two jet events,; sometimes only one jet is found and thus, the array jetPt[] has; only one entry in that cases).; Plot ranges for scatter-plots showing the transformed events are now correct.; User defined training/testing-trees are now handled correctly.; Fix bug in correlation computation for regression.; Consistent use of variable labels (for the log output) and variable titles (in histograms).; Drawing of variable labels in network architecture display for regression mode has been added.; Bug fixes to Cuts which improves performance on datasets with many variables.; Bug fix in GaussTransformation which improves handling of gaussian tails. ",MatchSource.DOCS,tmva/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html:1083,Testability,test,test,1083,"ethod allowing the user to; separate the training data (and accordingly the application; data) into disjoint sub-populations exhibiting significantly; different properties. The separation into phase space regions is; done by applying requirements on the input and/or spectator; variables. In each of these disjoint regions (each event must; belong to one and only one region), an independent training is; performed using the most appropriate MVA method, training; options and set of training variables in that zone. The division; into categories in presence of distinct sub-populations reduces; the correlations between the training variables, improves the; modelling, and hence increases the classification and regression; performance. Presently, the Category method works for; classification only, but regression will follow soon. Please; contact us if urgently needed. An example scripts and data files illustrating how the new; Category method is configured and used. Please check the macros; test/TMVAClassificationCategory.C and; test/TMVAClassificationCategoryApplication.C or the; corresponding executables.; Regression functionality for gradient boosted trees using a Huber loss function. Comments. On Input Data: . New TMVA event vector building. The code for splitting the input; data into training and test samples for all classes and the; mixing of those samples to one training and one test sample has; been rewritten completely. The new code is more performant and; has a clearer structure. This fixes several bugs which have been; reported by the TMVA users. On Minimization: . Variables, targets and spectators are now checked if they are; constant. (The execution of TMVA is stopped for variables and; targets, a warning is given for spectators.). On Regression:; ; The analysis type is no longer defined by calling a dedicated; TestAllMethods-member-function of the Factory, but with the; option ""AnalysisType"" in the Factory. The default value is; ""Auto"" where TMVA tries to deter",MatchSource.DOCS,tmva/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html:1122,Testability,test,test,1122," (and accordingly the application; data) into disjoint sub-populations exhibiting significantly; different properties. The separation into phase space regions is; done by applying requirements on the input and/or spectator; variables. In each of these disjoint regions (each event must; belong to one and only one region), an independent training is; performed using the most appropriate MVA method, training; options and set of training variables in that zone. The division; into categories in presence of distinct sub-populations reduces; the correlations between the training variables, improves the; modelling, and hence increases the classification and regression; performance. Presently, the Category method works for; classification only, but regression will follow soon. Please; contact us if urgently needed. An example scripts and data files illustrating how the new; Category method is configured and used. Please check the macros; test/TMVAClassificationCategory.C and; test/TMVAClassificationCategoryApplication.C or the; corresponding executables.; Regression functionality for gradient boosted trees using a Huber loss function. Comments. On Input Data: . New TMVA event vector building. The code for splitting the input; data into training and test samples for all classes and the; mixing of those samples to one training and one test sample has; been rewritten completely. The new code is more performant and; has a clearer structure. This fixes several bugs which have been; reported by the TMVA users. On Minimization: . Variables, targets and spectators are now checked if they are; constant. (The execution of TMVA is stopped for variables and; targets, a warning is given for spectators.). On Regression:; ; The analysis type is no longer defined by calling a dedicated; TestAllMethods-member-function of the Factory, but with the; option ""AnalysisType"" in the Factory. The default value is; ""Auto"" where TMVA tries to determine the most suitable analysis; type from the targets",MatchSource.DOCS,tmva/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html:1400,Testability,test,test,1400,"o one and only one region), an independent training is; performed using the most appropriate MVA method, training; options and set of training variables in that zone. The division; into categories in presence of distinct sub-populations reduces; the correlations between the training variables, improves the; modelling, and hence increases the classification and regression; performance. Presently, the Category method works for; classification only, but regression will follow soon. Please; contact us if urgently needed. An example scripts and data files illustrating how the new; Category method is configured and used. Please check the macros; test/TMVAClassificationCategory.C and; test/TMVAClassificationCategoryApplication.C or the; corresponding executables.; Regression functionality for gradient boosted trees using a Huber loss function. Comments. On Input Data: . New TMVA event vector building. The code for splitting the input; data into training and test samples for all classes and the; mixing of those samples to one training and one test sample has; been rewritten completely. The new code is more performant and; has a clearer structure. This fixes several bugs which have been; reported by the TMVA users. On Minimization: . Variables, targets and spectators are now checked if they are; constant. (The execution of TMVA is stopped for variables and; targets, a warning is given for spectators.). On Regression:; ; The analysis type is no longer defined by calling a dedicated; TestAllMethods-member-function of the Factory, but with the; option ""AnalysisType"" in the Factory. The default value is; ""Auto"" where TMVA tries to determine the most suitable analysis; type from the targets and classes the user has defined. Other; values are ""regression"", ""classification"" and ""multiclass"" for; the forthcoming multiclass classification.; Missing regression evaluation plots for training sample were; added. On Cut method:. Removed obsolete option ""FVerySmart"" from Cuts method. On MLP",MatchSource.DOCS,tmva/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html:1486,Testability,test,test,1486,"o one and only one region), an independent training is; performed using the most appropriate MVA method, training; options and set of training variables in that zone. The division; into categories in presence of distinct sub-populations reduces; the correlations between the training variables, improves the; modelling, and hence increases the classification and regression; performance. Presently, the Category method works for; classification only, but regression will follow soon. Please; contact us if urgently needed. An example scripts and data files illustrating how the new; Category method is configured and used. Please check the macros; test/TMVAClassificationCategory.C and; test/TMVAClassificationCategoryApplication.C or the; corresponding executables.; Regression functionality for gradient boosted trees using a Huber loss function. Comments. On Input Data: . New TMVA event vector building. The code for splitting the input; data into training and test samples for all classes and the; mixing of those samples to one training and one test sample has; been rewritten completely. The new code is more performant and; has a clearer structure. This fixes several bugs which have been; reported by the TMVA users. On Minimization: . Variables, targets and spectators are now checked if they are; constant. (The execution of TMVA is stopped for variables and; targets, a warning is given for spectators.). On Regression:; ; The analysis type is no longer defined by calling a dedicated; TestAllMethods-member-function of the Factory, but with the; option ""AnalysisType"" in the Factory. The default value is; ""Auto"" where TMVA tries to determine the most suitable analysis; type from the targets and classes the user has defined. Other; values are ""regression"", ""classification"" and ""multiclass"" for; the forthcoming multiclass classification.; Missing regression evaluation plots for training sample were; added. On Cut method:. Removed obsolete option ""FVerySmart"" from Cuts method. On MLP",MatchSource.DOCS,tmva/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html:2963,Testability,test,testing,2963,"the Factory, but with the; option ""AnalysisType"" in the Factory. The default value is; ""Auto"" where TMVA tries to determine the most suitable analysis; type from the targets and classes the user has defined. Other; values are ""regression"", ""classification"" and ""multiclass"" for; the forthcoming multiclass classification.; Missing regression evaluation plots for training sample were; added. On Cut method:. Removed obsolete option ""FVerySmart"" from Cuts method. On MLP method:; ; Display of convergence information in the progress bar for MLP during training. Creation of animated gifs for MLP convergence monitoring (please; contact authors if you want to do this). On Datasets: . Checks are performed if events are unvoluntarily cut by using a; non-filled array entry (e.g. ""arr[4]"" is used, when the array; has not always at least 5 entries). A warning is given in that; case.; Bug fixes. Spectators and Targets could not be used with by-hand assignment of events.; Corrected types (training/testing) for assigning single events.; Changed message from FATAL to WARNING when the user requests more events for ; training or testing than available.; Fixed bug which caused TMVA to crash if the number of input variables exceeded ; the allowed maximum for generating scatter plots.; Prevent TMVA from crashing when running with an empty TTree or TChain.; A variable expression like ""Alt$(arr[3],0)"" can now be used; to give a default value for a variable if for some events the; array don't contain enough elements (e.g. in two jet events,; sometimes only one jet is found and thus, the array jetPt[] has; only one entry in that cases).; Plot ranges for scatter-plots showing the transformed events are now correct.; User defined training/testing-trees are now handled correctly.; Fix bug in correlation computation for regression.; Consistent use of variable labels (for the log output) and variable titles (in histograms).; Drawing of variable labels in network architecture display for regression m",MatchSource.DOCS,tmva/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html:3093,Testability,test,testing,3093,"o"" where TMVA tries to determine the most suitable analysis; type from the targets and classes the user has defined. Other; values are ""regression"", ""classification"" and ""multiclass"" for; the forthcoming multiclass classification.; Missing regression evaluation plots for training sample were; added. On Cut method:. Removed obsolete option ""FVerySmart"" from Cuts method. On MLP method:; ; Display of convergence information in the progress bar for MLP during training. Creation of animated gifs for MLP convergence monitoring (please; contact authors if you want to do this). On Datasets: . Checks are performed if events are unvoluntarily cut by using a; non-filled array entry (e.g. ""arr[4]"" is used, when the array; has not always at least 5 entries). A warning is given in that; case.; Bug fixes. Spectators and Targets could not be used with by-hand assignment of events.; Corrected types (training/testing) for assigning single events.; Changed message from FATAL to WARNING when the user requests more events for ; training or testing than available.; Fixed bug which caused TMVA to crash if the number of input variables exceeded ; the allowed maximum for generating scatter plots.; Prevent TMVA from crashing when running with an empty TTree or TChain.; A variable expression like ""Alt$(arr[3],0)"" can now be used; to give a default value for a variable if for some events the; array don't contain enough elements (e.g. in two jet events,; sometimes only one jet is found and thus, the array jetPt[] has; only one entry in that cases).; Plot ranges for scatter-plots showing the transformed events are now correct.; User defined training/testing-trees are now handled correctly.; Fix bug in correlation computation for regression.; Consistent use of variable labels (for the log output) and variable titles (in histograms).; Drawing of variable labels in network architecture display for regression mode has been added.; Bug fixes to Cuts which improves performance on datasets with many va",MatchSource.DOCS,tmva/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html:3706,Testability,test,testing-trees,3706,"nd classes the user has defined. Other; values are ""regression"", ""classification"" and ""multiclass"" for; the forthcoming multiclass classification.; Missing regression evaluation plots for training sample were; added. On Cut method:. Removed obsolete option ""FVerySmart"" from Cuts method. On MLP method:; ; Display of convergence information in the progress bar for MLP during training. Creation of animated gifs for MLP convergence monitoring (please; contact authors if you want to do this). On Datasets: . Checks are performed if events are unvoluntarily cut by using a; non-filled array entry (e.g. ""arr[4]"" is used, when the array; has not always at least 5 entries). A warning is given in that; case.; Bug fixes. Spectators and Targets could not be used with by-hand assignment of events.; Corrected types (training/testing) for assigning single events.; Changed message from FATAL to WARNING when the user requests more events for ; training or testing than available.; Fixed bug which caused TMVA to crash if the number of input variables exceeded ; the allowed maximum for generating scatter plots.; Prevent TMVA from crashing when running with an empty TTree or TChain.; A variable expression like ""Alt$(arr[3],0)"" can now be used; to give a default value for a variable if for some events the; array don't contain enough elements (e.g. in two jet events,; sometimes only one jet is found and thus, the array jetPt[] has; only one entry in that cases).; Plot ranges for scatter-plots showing the transformed events are now correct.; User defined training/testing-trees are now handled correctly.; Fix bug in correlation computation for regression.; Consistent use of variable labels (for the log output) and variable titles (in histograms).; Drawing of variable labels in network architecture display for regression mode has been added.; Bug fixes to Cuts which improves performance on datasets with many variables.; Bug fix in GaussTransformation which improves handling of gaussian tails. ",MatchSource.DOCS,tmva/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html:3843,Testability,log,log,3843,"nd classes the user has defined. Other; values are ""regression"", ""classification"" and ""multiclass"" for; the forthcoming multiclass classification.; Missing regression evaluation plots for training sample were; added. On Cut method:. Removed obsolete option ""FVerySmart"" from Cuts method. On MLP method:; ; Display of convergence information in the progress bar for MLP during training. Creation of animated gifs for MLP convergence monitoring (please; contact authors if you want to do this). On Datasets: . Checks are performed if events are unvoluntarily cut by using a; non-filled array entry (e.g. ""arr[4]"" is used, when the array; has not always at least 5 entries). A warning is given in that; case.; Bug fixes. Spectators and Targets could not be used with by-hand assignment of events.; Corrected types (training/testing) for assigning single events.; Changed message from FATAL to WARNING when the user requests more events for ; training or testing than available.; Fixed bug which caused TMVA to crash if the number of input variables exceeded ; the allowed maximum for generating scatter plots.; Prevent TMVA from crashing when running with an empty TTree or TChain.; A variable expression like ""Alt$(arr[3],0)"" can now be used; to give a default value for a variable if for some events the; array don't contain enough elements (e.g. in two jet events,; sometimes only one jet is found and thus, the array jetPt[] has; only one entry in that cases).; Plot ranges for scatter-plots showing the transformed events are now correct.; User defined training/testing-trees are now handled correctly.; Fix bug in correlation computation for regression.; Consistent use of variable labels (for the log output) and variable titles (in histograms).; Drawing of variable labels in network architecture display for regression mode has been added.; Bug fixes to Cuts which improves performance on datasets with many variables.; Bug fix in GaussTransformation which improves handling of gaussian tails. ",MatchSource.DOCS,tmva/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html:1573,Usability,clear,clearer,1573,"d set of training variables in that zone. The division; into categories in presence of distinct sub-populations reduces; the correlations between the training variables, improves the; modelling, and hence increases the classification and regression; performance. Presently, the Category method works for; classification only, but regression will follow soon. Please; contact us if urgently needed. An example scripts and data files illustrating how the new; Category method is configured and used. Please check the macros; test/TMVAClassificationCategory.C and; test/TMVAClassificationCategoryApplication.C or the; corresponding executables.; Regression functionality for gradient boosted trees using a Huber loss function. Comments. On Input Data: . New TMVA event vector building. The code for splitting the input; data into training and test samples for all classes and the; mixing of those samples to one training and one test sample has; been rewritten completely. The new code is more performant and; has a clearer structure. This fixes several bugs which have been; reported by the TMVA users. On Minimization: . Variables, targets and spectators are now checked if they are; constant. (The execution of TMVA is stopped for variables and; targets, a warning is given for spectators.). On Regression:; ; The analysis type is no longer defined by calling a dedicated; TestAllMethods-member-function of the Factory, but with the; option ""AnalysisType"" in the Factory. The default value is; ""Auto"" where TMVA tries to determine the most suitable analysis; type from the targets and classes the user has defined. Other; values are ""regression"", ""classification"" and ""multiclass"" for; the forthcoming multiclass classification.; Missing regression evaluation plots for training sample were; added. On Cut method:. Removed obsolete option ""FVerySmart"" from Cuts method. On MLP method:; ; Display of convergence information in the progress bar for MLP during training. Creation of animated gifs for ML",MatchSource.DOCS,tmva/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html:2490,Usability,progress bar,progress bar,2490,"and one test sample has; been rewritten completely. The new code is more performant and; has a clearer structure. This fixes several bugs which have been; reported by the TMVA users. On Minimization: . Variables, targets and spectators are now checked if they are; constant. (The execution of TMVA is stopped for variables and; targets, a warning is given for spectators.). On Regression:; ; The analysis type is no longer defined by calling a dedicated; TestAllMethods-member-function of the Factory, but with the; option ""AnalysisType"" in the Factory. The default value is; ""Auto"" where TMVA tries to determine the most suitable analysis; type from the targets and classes the user has defined. Other; values are ""regression"", ""classification"" and ""multiclass"" for; the forthcoming multiclass classification.; Missing regression evaluation plots for training sample were; added. On Cut method:. Removed obsolete option ""FVerySmart"" from Cuts method. On MLP method:; ; Display of convergence information in the progress bar for MLP during training. Creation of animated gifs for MLP convergence monitoring (please; contact authors if you want to do this). On Datasets: . Checks are performed if events are unvoluntarily cut by using a; non-filled array entry (e.g. ""arr[4]"" is used, when the array; has not always at least 5 entries). A warning is given in that; case.; Bug fixes. Spectators and Targets could not be used with by-hand assignment of events.; Corrected types (training/testing) for assigning single events.; Changed message from FATAL to WARNING when the user requests more events for ; training or testing than available.; Fixed bug which caused TMVA to crash if the number of input variables exceeded ; the allowed maximum for generating scatter plots.; Prevent TMVA from crashing when running with an empty TTree or TChain.; A variable expression like ""Alt$(arr[3],0)"" can now be used; to give a default value for a variable if for some events the; array don't contain enough eleme",MatchSource.DOCS,tmva/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v528/index.html:294,Availability,robust,robustness,294," . TMVA. TMVA version 4.1.0 is included in this root release. The most; important new feature is the support for simulataneous classification ; of multiple output classes for several multi-variate methods. ; A lot of effort went into consolidation of the software,; i.e. method performance and robustness, and framework; stability. The changes with respect to ROOT 5.27 / TMVA 4.0.7 are; in detail:. Framework. Multi-class support. The support of multiple; output classes (i.e., more than a single background and signal; class) has been enabled for these methods: MLP (NN), BDTG,; FDA.; The multiclass; functionality can be enabled with the Factory option; ""AnalysisType=multiclass"". Training data is; specified with an additional classname, e.g. via; factory->AddTree(tree,""classname"");. After the; training a genetic algorithm is invoked to determine the best; cuts for selecting a specific class, based on the figure of; merit: purity*efficiency. TMVA comes with two examples in; $ROOTSYS/tmva/test: TMVAMulticlass.C; and TMVAMulticlassApplication.C. New TMVA event vector building. The code; for splitting the input data into training and test samples for; all classes and the mixing of those samples to one training and; one test sample has been rewritten completely. The new code is; more performant and has a clearer structure. This fixes several; bugs which have been reported by some users of TMVA.; Code and performance test framework: A unit; test framework for daily software and method performance; validation has been implemented.; . Methods. BDT Automatic parameter optimisation for building the; tree architecture: The optimisation procedure uses the; performance of the trained classifier on the ""test sample"" for; finding the set of optimal parameters. Two different methods to; traverse the parameter space are available (scanning, genetic; algorithm). Currently parameter optimization is implemented only; for these three parameters that influence the tree architectur:; the maximu",MatchSource.DOCS,tmva/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v528/index.html:1830,Availability,avail,available,1830,"lgorithm is invoked to determine the best; cuts for selecting a specific class, based on the figure of; merit: purity*efficiency. TMVA comes with two examples in; $ROOTSYS/tmva/test: TMVAMulticlass.C; and TMVAMulticlassApplication.C. New TMVA event vector building. The code; for splitting the input data into training and test samples for; all classes and the mixing of those samples to one training and; one test sample has been rewritten completely. The new code is; more performant and has a clearer structure. This fixes several; bugs which have been reported by some users of TMVA.; Code and performance test framework: A unit; test framework for daily software and method performance; validation has been implemented.; . Methods. BDT Automatic parameter optimisation for building the; tree architecture: The optimisation procedure uses the; performance of the trained classifier on the ""test sample"" for; finding the set of optimal parameters. Two different methods to; traverse the parameter space are available (scanning, genetic; algorithm). Currently parameter optimization is implemented only; for these three parameters that influence the tree architectur:; the maximum depth of a tree, MaxDepth, the minimum; number of events in each node, NodeMinEvents, and; the number of tress, NTrees. Optimization can; is invoked by calling; factory->OptimizeAllMethods(); prior to the call; factory->TrainAllMethods();. Automated and configurable parameter optimization is soon to; be enabled for all methods (for those parameters where; optimization is applicable).; . BDT node splitting: While Decision Trees; typically have only univariate splits, in TMVA one can now; also opt for multivariate splits that use a ""Fisher; Discriminant"" (option: UseFisherCuts), built from all; observables that show correlations larger than some threshold; (MinLinCorrForFisher). The training will then test at each; split a cut on this fisher discriminant in addition to all; univariate cuts on the variables (o",MatchSource.DOCS,tmva/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v528/index.html:53,Deployability,release,release,53," . TMVA. TMVA version 4.1.0 is included in this root release. The most; important new feature is the support for simulataneous classification ; of multiple output classes for several multi-variate methods. ; A lot of effort went into consolidation of the software,; i.e. method performance and robustness, and framework; stability. The changes with respect to ROOT 5.27 / TMVA 4.0.7 are; in detail:. Framework. Multi-class support. The support of multiple; output classes (i.e., more than a single background and signal; class) has been enabled for these methods: MLP (NN), BDTG,; FDA.; The multiclass; functionality can be enabled with the Factory option; ""AnalysisType=multiclass"". Training data is; specified with an additional classname, e.g. via; factory->AddTree(tree,""classname"");. After the; training a genetic algorithm is invoked to determine the best; cuts for selecting a specific class, based on the figure of; merit: purity*efficiency. TMVA comes with two examples in; $ROOTSYS/tmva/test: TMVAMulticlass.C; and TMVAMulticlassApplication.C. New TMVA event vector building. The code; for splitting the input data into training and test samples for; all classes and the mixing of those samples to one training and; one test sample has been rewritten completely. The new code is; more performant and has a clearer structure. This fixes several; bugs which have been reported by some users of TMVA.; Code and performance test framework: A unit; test framework for daily software and method performance; validation has been implemented.; . Methods. BDT Automatic parameter optimisation for building the; tree architecture: The optimisation procedure uses the; performance of the trained classifier on the ""test sample"" for; finding the set of optimal parameters. Two different methods to; traverse the parameter space are available (scanning, genetic; algorithm). Currently parameter optimization is implemented only; for these three parameters that influence the tree architectur:; the maximu",MatchSource.DOCS,tmva/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v528/index.html:2257,Modifiability,config,configurable,2257," clearer structure. This fixes several; bugs which have been reported by some users of TMVA.; Code and performance test framework: A unit; test framework for daily software and method performance; validation has been implemented.; . Methods. BDT Automatic parameter optimisation for building the; tree architecture: The optimisation procedure uses the; performance of the trained classifier on the ""test sample"" for; finding the set of optimal parameters. Two different methods to; traverse the parameter space are available (scanning, genetic; algorithm). Currently parameter optimization is implemented only; for these three parameters that influence the tree architectur:; the maximum depth of a tree, MaxDepth, the minimum; number of events in each node, NodeMinEvents, and; the number of tress, NTrees. Optimization can; is invoked by calling; factory->OptimizeAllMethods(); prior to the call; factory->TrainAllMethods();. Automated and configurable parameter optimization is soon to; be enabled for all methods (for those parameters where; optimization is applicable).; . BDT node splitting: While Decision Trees; typically have only univariate splits, in TMVA one can now; also opt for multivariate splits that use a ""Fisher; Discriminant"" (option: UseFisherCuts), built from all; observables that show correlations larger than some threshold; (MinLinCorrForFisher). The training will then test at each; split a cut on this fisher discriminant in addition to all; univariate cuts on the variables (or only on those variables; that have not been used in the Fisher discriminant, option; UseExcusiveVars). No obvious improvement betwen very simple; decision trees after boosting has been observed so far, but; only a limited number of studies has been performed concerning; potiential benenfit of these simple multivariate splits.; . Bug fixes. A problem in the BDTG has been fixed, leading to a much; improved regression performance.; A problem in the TMVA::Reader has been fixed.; With the new ",MatchSource.DOCS,tmva/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v528/index.html:2809,Modifiability,variab,variables,2809,"ftware and method performance; validation has been implemented.; . Methods. BDT Automatic parameter optimisation for building the; tree architecture: The optimisation procedure uses the; performance of the trained classifier on the ""test sample"" for; finding the set of optimal parameters. Two different methods to; traverse the parameter space are available (scanning, genetic; algorithm). Currently parameter optimization is implemented only; for these three parameters that influence the tree architectur:; the maximum depth of a tree, MaxDepth, the minimum; number of events in each node, NodeMinEvents, and; the number of tress, NTrees. Optimization can; is invoked by calling; factory->OptimizeAllMethods(); prior to the call; factory->TrainAllMethods();. Automated and configurable parameter optimization is soon to; be enabled for all methods (for those parameters where; optimization is applicable).; . BDT node splitting: While Decision Trees; typically have only univariate splits, in TMVA one can now; also opt for multivariate splits that use a ""Fisher; Discriminant"" (option: UseFisherCuts), built from all; observables that show correlations larger than some threshold; (MinLinCorrForFisher). The training will then test at each; split a cut on this fisher discriminant in addition to all; univariate cuts on the variables (or only on those variables; that have not been used in the Fisher discriminant, option; UseExcusiveVars). No obvious improvement betwen very simple; decision trees after boosting has been observed so far, but; only a limited number of studies has been performed concerning; potiential benenfit of these simple multivariate splits.; . Bug fixes. A problem in the BDTG has been fixed, leading to a much; improved regression performance.; A problem in the TMVA::Reader has been fixed.; With the new test framework and the coverity checks of ROOT; a number of bugs were discovered and fixed. They mainly concerned; memory leaks, and did not affect the performance. ",MatchSource.DOCS,tmva/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v528/index.html:2837,Modifiability,variab,variables,2837,"ftware and method performance; validation has been implemented.; . Methods. BDT Automatic parameter optimisation for building the; tree architecture: The optimisation procedure uses the; performance of the trained classifier on the ""test sample"" for; finding the set of optimal parameters. Two different methods to; traverse the parameter space are available (scanning, genetic; algorithm). Currently parameter optimization is implemented only; for these three parameters that influence the tree architectur:; the maximum depth of a tree, MaxDepth, the minimum; number of events in each node, NodeMinEvents, and; the number of tress, NTrees. Optimization can; is invoked by calling; factory->OptimizeAllMethods(); prior to the call; factory->TrainAllMethods();. Automated and configurable parameter optimization is soon to; be enabled for all methods (for those parameters where; optimization is applicable).; . BDT node splitting: While Decision Trees; typically have only univariate splits, in TMVA one can now; also opt for multivariate splits that use a ""Fisher; Discriminant"" (option: UseFisherCuts), built from all; observables that show correlations larger than some threshold; (MinLinCorrForFisher). The training will then test at each; split a cut on this fisher discriminant in addition to all; univariate cuts on the variables (or only on those variables; that have not been used in the Fisher discriminant, option; UseExcusiveVars). No obvious improvement betwen very simple; decision trees after boosting has been observed so far, but; only a limited number of studies has been performed concerning; potiential benenfit of these simple multivariate splits.; . Bug fixes. A problem in the BDTG has been fixed, leading to a much; improved regression performance.; A problem in the TMVA::Reader has been fixed.; With the new test framework and the coverity checks of ROOT; a number of bugs were discovered and fixed. They mainly concerned; memory leaks, and did not affect the performance. ",MatchSource.DOCS,tmva/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v528/index.html:278,Performance,perform,performance,278," . TMVA. TMVA version 4.1.0 is included in this root release. The most; important new feature is the support for simulataneous classification ; of multiple output classes for several multi-variate methods. ; A lot of effort went into consolidation of the software,; i.e. method performance and robustness, and framework; stability. The changes with respect to ROOT 5.27 / TMVA 4.0.7 are; in detail:. Framework. Multi-class support. The support of multiple; output classes (i.e., more than a single background and signal; class) has been enabled for these methods: MLP (NN), BDTG,; FDA.; The multiclass; functionality can be enabled with the Factory option; ""AnalysisType=multiclass"". Training data is; specified with an additional classname, e.g. via; factory->AddTree(tree,""classname"");. After the; training a genetic algorithm is invoked to determine the best; cuts for selecting a specific class, based on the figure of; merit: purity*efficiency. TMVA comes with two examples in; $ROOTSYS/tmva/test: TMVAMulticlass.C; and TMVAMulticlassApplication.C. New TMVA event vector building. The code; for splitting the input data into training and test samples for; all classes and the mixing of those samples to one training and; one test sample has been rewritten completely. The new code is; more performant and has a clearer structure. This fixes several; bugs which have been reported by some users of TMVA.; Code and performance test framework: A unit; test framework for daily software and method performance; validation has been implemented.; . Methods. BDT Automatic parameter optimisation for building the; tree architecture: The optimisation procedure uses the; performance of the trained classifier on the ""test sample"" for; finding the set of optimal parameters. Two different methods to; traverse the parameter space are available (scanning, genetic; algorithm). Currently parameter optimization is implemented only; for these three parameters that influence the tree architectur:; the maximu",MatchSource.DOCS,tmva/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v528/index.html:1295,Performance,perform,performant,1295,"s, and framework; stability. The changes with respect to ROOT 5.27 / TMVA 4.0.7 are; in detail:. Framework. Multi-class support. The support of multiple; output classes (i.e., more than a single background and signal; class) has been enabled for these methods: MLP (NN), BDTG,; FDA.; The multiclass; functionality can be enabled with the Factory option; ""AnalysisType=multiclass"". Training data is; specified with an additional classname, e.g. via; factory->AddTree(tree,""classname"");. After the; training a genetic algorithm is invoked to determine the best; cuts for selecting a specific class, based on the figure of; merit: purity*efficiency. TMVA comes with two examples in; $ROOTSYS/tmva/test: TMVAMulticlass.C; and TMVAMulticlassApplication.C. New TMVA event vector building. The code; for splitting the input data into training and test samples for; all classes and the mixing of those samples to one training and; one test sample has been rewritten completely. The new code is; more performant and has a clearer structure. This fixes several; bugs which have been reported by some users of TMVA.; Code and performance test framework: A unit; test framework for daily software and method performance; validation has been implemented.; . Methods. BDT Automatic parameter optimisation for building the; tree architecture: The optimisation procedure uses the; performance of the trained classifier on the ""test sample"" for; finding the set of optimal parameters. Two different methods to; traverse the parameter space are available (scanning, genetic; algorithm). Currently parameter optimization is implemented only; for these three parameters that influence the tree architectur:; the maximum depth of a tree, MaxDepth, the minimum; number of events in each node, NodeMinEvents, and; the number of tress, NTrees. Optimization can; is invoked by calling; factory->OptimizeAllMethods(); prior to the call; factory->TrainAllMethods();. Automated and configurable parameter optimization is soon to",MatchSource.DOCS,tmva/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v528/index.html:1418,Performance,perform,performance,1418,"e., more than a single background and signal; class) has been enabled for these methods: MLP (NN), BDTG,; FDA.; The multiclass; functionality can be enabled with the Factory option; ""AnalysisType=multiclass"". Training data is; specified with an additional classname, e.g. via; factory->AddTree(tree,""classname"");. After the; training a genetic algorithm is invoked to determine the best; cuts for selecting a specific class, based on the figure of; merit: purity*efficiency. TMVA comes with two examples in; $ROOTSYS/tmva/test: TMVAMulticlass.C; and TMVAMulticlassApplication.C. New TMVA event vector building. The code; for splitting the input data into training and test samples for; all classes and the mixing of those samples to one training and; one test sample has been rewritten completely. The new code is; more performant and has a clearer structure. This fixes several; bugs which have been reported by some users of TMVA.; Code and performance test framework: A unit; test framework for daily software and method performance; validation has been implemented.; . Methods. BDT Automatic parameter optimisation for building the; tree architecture: The optimisation procedure uses the; performance of the trained classifier on the ""test sample"" for; finding the set of optimal parameters. Two different methods to; traverse the parameter space are available (scanning, genetic; algorithm). Currently parameter optimization is implemented only; for these three parameters that influence the tree architectur:; the maximum depth of a tree, MaxDepth, the minimum; number of events in each node, NodeMinEvents, and; the number of tress, NTrees. Optimization can; is invoked by calling; factory->OptimizeAllMethods(); prior to the call; factory->TrainAllMethods();. Automated and configurable parameter optimization is soon to; be enabled for all methods (for those parameters where; optimization is applicable).; . BDT node splitting: While Decision Trees; typically have only univariate splits, in",MatchSource.DOCS,tmva/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v528/index.html:1499,Performance,perform,performance,1499,"e., more than a single background and signal; class) has been enabled for these methods: MLP (NN), BDTG,; FDA.; The multiclass; functionality can be enabled with the Factory option; ""AnalysisType=multiclass"". Training data is; specified with an additional classname, e.g. via; factory->AddTree(tree,""classname"");. After the; training a genetic algorithm is invoked to determine the best; cuts for selecting a specific class, based on the figure of; merit: purity*efficiency. TMVA comes with two examples in; $ROOTSYS/tmva/test: TMVAMulticlass.C; and TMVAMulticlassApplication.C. New TMVA event vector building. The code; for splitting the input data into training and test samples for; all classes and the mixing of those samples to one training and; one test sample has been rewritten completely. The new code is; more performant and has a clearer structure. This fixes several; bugs which have been reported by some users of TMVA.; Code and performance test framework: A unit; test framework for daily software and method performance; validation has been implemented.; . Methods. BDT Automatic parameter optimisation for building the; tree architecture: The optimisation procedure uses the; performance of the trained classifier on the ""test sample"" for; finding the set of optimal parameters. Two different methods to; traverse the parameter space are available (scanning, genetic; algorithm). Currently parameter optimization is implemented only; for these three parameters that influence the tree architectur:; the maximum depth of a tree, MaxDepth, the minimum; number of events in each node, NodeMinEvents, and; the number of tress, NTrees. Optimization can; is invoked by calling; factory->OptimizeAllMethods(); prior to the call; factory->TrainAllMethods();. Automated and configurable parameter optimization is soon to; be enabled for all methods (for those parameters where; optimization is applicable).; . BDT node splitting: While Decision Trees; typically have only univariate splits, in",MatchSource.DOCS,tmva/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v528/index.html:1668,Performance,perform,performance,1668,"sisType=multiclass"". Training data is; specified with an additional classname, e.g. via; factory->AddTree(tree,""classname"");. After the; training a genetic algorithm is invoked to determine the best; cuts for selecting a specific class, based on the figure of; merit: purity*efficiency. TMVA comes with two examples in; $ROOTSYS/tmva/test: TMVAMulticlass.C; and TMVAMulticlassApplication.C. New TMVA event vector building. The code; for splitting the input data into training and test samples for; all classes and the mixing of those samples to one training and; one test sample has been rewritten completely. The new code is; more performant and has a clearer structure. This fixes several; bugs which have been reported by some users of TMVA.; Code and performance test framework: A unit; test framework for daily software and method performance; validation has been implemented.; . Methods. BDT Automatic parameter optimisation for building the; tree architecture: The optimisation procedure uses the; performance of the trained classifier on the ""test sample"" for; finding the set of optimal parameters. Two different methods to; traverse the parameter space are available (scanning, genetic; algorithm). Currently parameter optimization is implemented only; for these three parameters that influence the tree architectur:; the maximum depth of a tree, MaxDepth, the minimum; number of events in each node, NodeMinEvents, and; the number of tress, NTrees. Optimization can; is invoked by calling; factory->OptimizeAllMethods(); prior to the call; factory->TrainAllMethods();. Automated and configurable parameter optimization is soon to; be enabled for all methods (for those parameters where; optimization is applicable).; . BDT node splitting: While Decision Trees; typically have only univariate splits, in TMVA one can now; also opt for multivariate splits that use a ""Fisher; Discriminant"" (option: UseFisherCuts), built from all; observables that show correlations larger than some threshol",MatchSource.DOCS,tmva/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v528/index.html:1892,Performance,optimiz,optimization,1892,"/test: TMVAMulticlass.C; and TMVAMulticlassApplication.C. New TMVA event vector building. The code; for splitting the input data into training and test samples for; all classes and the mixing of those samples to one training and; one test sample has been rewritten completely. The new code is; more performant and has a clearer structure. This fixes several; bugs which have been reported by some users of TMVA.; Code and performance test framework: A unit; test framework for daily software and method performance; validation has been implemented.; . Methods. BDT Automatic parameter optimisation for building the; tree architecture: The optimisation procedure uses the; performance of the trained classifier on the ""test sample"" for; finding the set of optimal parameters. Two different methods to; traverse the parameter space are available (scanning, genetic; algorithm). Currently parameter optimization is implemented only; for these three parameters that influence the tree architectur:; the maximum depth of a tree, MaxDepth, the minimum; number of events in each node, NodeMinEvents, and; the number of tress, NTrees. Optimization can; is invoked by calling; factory->OptimizeAllMethods(); prior to the call; factory->TrainAllMethods();. Automated and configurable parameter optimization is soon to; be enabled for all methods (for those parameters where; optimization is applicable).; . BDT node splitting: While Decision Trees; typically have only univariate splits, in TMVA one can now; also opt for multivariate splits that use a ""Fisher; Discriminant"" (option: UseFisherCuts), built from all; observables that show correlations larger than some threshold; (MinLinCorrForFisher). The training will then test at each; split a cut on this fisher discriminant in addition to all; univariate cuts on the variables (or only on those variables; that have not been used in the Fisher discriminant, option; UseExcusiveVars). No obvious improvement betwen very simple; decision trees after boostin",MatchSource.DOCS,tmva/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v528/index.html:2280,Performance,optimiz,optimization,2280," clearer structure. This fixes several; bugs which have been reported by some users of TMVA.; Code and performance test framework: A unit; test framework for daily software and method performance; validation has been implemented.; . Methods. BDT Automatic parameter optimisation for building the; tree architecture: The optimisation procedure uses the; performance of the trained classifier on the ""test sample"" for; finding the set of optimal parameters. Two different methods to; traverse the parameter space are available (scanning, genetic; algorithm). Currently parameter optimization is implemented only; for these three parameters that influence the tree architectur:; the maximum depth of a tree, MaxDepth, the minimum; number of events in each node, NodeMinEvents, and; the number of tress, NTrees. Optimization can; is invoked by calling; factory->OptimizeAllMethods(); prior to the call; factory->TrainAllMethods();. Automated and configurable parameter optimization is soon to; be enabled for all methods (for those parameters where; optimization is applicable).; . BDT node splitting: While Decision Trees; typically have only univariate splits, in TMVA one can now; also opt for multivariate splits that use a ""Fisher; Discriminant"" (option: UseFisherCuts), built from all; observables that show correlations larger than some threshold; (MinLinCorrForFisher). The training will then test at each; split a cut on this fisher discriminant in addition to all; univariate cuts on the variables (or only on those variables; that have not been used in the Fisher discriminant, option; UseExcusiveVars). No obvious improvement betwen very simple; decision trees after boosting has been observed so far, but; only a limited number of studies has been performed concerning; potiential benenfit of these simple multivariate splits.; . Bug fixes. A problem in the BDTG has been fixed, leading to a much; improved regression performance.; A problem in the TMVA::Reader has been fixed.; With the new ",MatchSource.DOCS,tmva/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v528/index.html:2361,Performance,optimiz,optimization,2361," clearer structure. This fixes several; bugs which have been reported by some users of TMVA.; Code and performance test framework: A unit; test framework for daily software and method performance; validation has been implemented.; . Methods. BDT Automatic parameter optimisation for building the; tree architecture: The optimisation procedure uses the; performance of the trained classifier on the ""test sample"" for; finding the set of optimal parameters. Two different methods to; traverse the parameter space are available (scanning, genetic; algorithm). Currently parameter optimization is implemented only; for these three parameters that influence the tree architectur:; the maximum depth of a tree, MaxDepth, the minimum; number of events in each node, NodeMinEvents, and; the number of tress, NTrees. Optimization can; is invoked by calling; factory->OptimizeAllMethods(); prior to the call; factory->TrainAllMethods();. Automated and configurable parameter optimization is soon to; be enabled for all methods (for those parameters where; optimization is applicable).; . BDT node splitting: While Decision Trees; typically have only univariate splits, in TMVA one can now; also opt for multivariate splits that use a ""Fisher; Discriminant"" (option: UseFisherCuts), built from all; observables that show correlations larger than some threshold; (MinLinCorrForFisher). The training will then test at each; split a cut on this fisher discriminant in addition to all; univariate cuts on the variables (or only on those variables; that have not been used in the Fisher discriminant, option; UseExcusiveVars). No obvious improvement betwen very simple; decision trees after boosting has been observed so far, but; only a limited number of studies has been performed concerning; potiential benenfit of these simple multivariate splits.; . Bug fixes. A problem in the BDTG has been fixed, leading to a much; improved regression performance.; A problem in the TMVA::Reader has been fixed.; With the new ",MatchSource.DOCS,tmva/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v528/index.html:3072,Performance,perform,performed,3072,"ftware and method performance; validation has been implemented.; . Methods. BDT Automatic parameter optimisation for building the; tree architecture: The optimisation procedure uses the; performance of the trained classifier on the ""test sample"" for; finding the set of optimal parameters. Two different methods to; traverse the parameter space are available (scanning, genetic; algorithm). Currently parameter optimization is implemented only; for these three parameters that influence the tree architectur:; the maximum depth of a tree, MaxDepth, the minimum; number of events in each node, NodeMinEvents, and; the number of tress, NTrees. Optimization can; is invoked by calling; factory->OptimizeAllMethods(); prior to the call; factory->TrainAllMethods();. Automated and configurable parameter optimization is soon to; be enabled for all methods (for those parameters where; optimization is applicable).; . BDT node splitting: While Decision Trees; typically have only univariate splits, in TMVA one can now; also opt for multivariate splits that use a ""Fisher; Discriminant"" (option: UseFisherCuts), built from all; observables that show correlations larger than some threshold; (MinLinCorrForFisher). The training will then test at each; split a cut on this fisher discriminant in addition to all; univariate cuts on the variables (or only on those variables; that have not been used in the Fisher discriminant, option; UseExcusiveVars). No obvious improvement betwen very simple; decision trees after boosting has been observed so far, but; only a limited number of studies has been performed concerning; potiential benenfit of these simple multivariate splits.; . Bug fixes. A problem in the BDTG has been fixed, leading to a much; improved regression performance.; A problem in the TMVA::Reader has been fixed.; With the new test framework and the coverity checks of ROOT; a number of bugs were discovered and fixed. They mainly concerned; memory leaks, and did not affect the performance. ",MatchSource.DOCS,tmva/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v528/index.html:3242,Performance,perform,performance,3242,"ftware and method performance; validation has been implemented.; . Methods. BDT Automatic parameter optimisation for building the; tree architecture: The optimisation procedure uses the; performance of the trained classifier on the ""test sample"" for; finding the set of optimal parameters. Two different methods to; traverse the parameter space are available (scanning, genetic; algorithm). Currently parameter optimization is implemented only; for these three parameters that influence the tree architectur:; the maximum depth of a tree, MaxDepth, the minimum; number of events in each node, NodeMinEvents, and; the number of tress, NTrees. Optimization can; is invoked by calling; factory->OptimizeAllMethods(); prior to the call; factory->TrainAllMethods();. Automated and configurable parameter optimization is soon to; be enabled for all methods (for those parameters where; optimization is applicable).; . BDT node splitting: While Decision Trees; typically have only univariate splits, in TMVA one can now; also opt for multivariate splits that use a ""Fisher; Discriminant"" (option: UseFisherCuts), built from all; observables that show correlations larger than some threshold; (MinLinCorrForFisher). The training will then test at each; split a cut on this fisher discriminant in addition to all; univariate cuts on the variables (or only on those variables; that have not been used in the Fisher discriminant, option; UseExcusiveVars). No obvious improvement betwen very simple; decision trees after boosting has been observed so far, but; only a limited number of studies has been performed concerning; potiential benenfit of these simple multivariate splits.; . Bug fixes. A problem in the BDTG has been fixed, leading to a much; improved regression performance.; A problem in the TMVA::Reader has been fixed.; With the new test framework and the coverity checks of ROOT; a number of bugs were discovered and fixed. They mainly concerned; memory leaks, and did not affect the performance. ",MatchSource.DOCS,tmva/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v528/index.html:3468,Performance,perform,performance,3468,"ftware and method performance; validation has been implemented.; . Methods. BDT Automatic parameter optimisation for building the; tree architecture: The optimisation procedure uses the; performance of the trained classifier on the ""test sample"" for; finding the set of optimal parameters. Two different methods to; traverse the parameter space are available (scanning, genetic; algorithm). Currently parameter optimization is implemented only; for these three parameters that influence the tree architectur:; the maximum depth of a tree, MaxDepth, the minimum; number of events in each node, NodeMinEvents, and; the number of tress, NTrees. Optimization can; is invoked by calling; factory->OptimizeAllMethods(); prior to the call; factory->TrainAllMethods();. Automated and configurable parameter optimization is soon to; be enabled for all methods (for those parameters where; optimization is applicable).; . BDT node splitting: While Decision Trees; typically have only univariate splits, in TMVA one can now; also opt for multivariate splits that use a ""Fisher; Discriminant"" (option: UseFisherCuts), built from all; observables that show correlations larger than some threshold; (MinLinCorrForFisher). The training will then test at each; split a cut on this fisher discriminant in addition to all; univariate cuts on the variables (or only on those variables; that have not been used in the Fisher discriminant, option; UseExcusiveVars). No obvious improvement betwen very simple; decision trees after boosting has been observed so far, but; only a limited number of studies has been performed concerning; potiential benenfit of these simple multivariate splits.; . Bug fixes. A problem in the BDTG has been fixed, leading to a much; improved regression performance.; A problem in the TMVA::Reader has been fixed.; With the new test framework and the coverity checks of ROOT; a number of bugs were discovered and fixed. They mainly concerned; memory leaks, and did not affect the performance. ",MatchSource.DOCS,tmva/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v528/index.html:1512,Security,validat,validation,1512,"e., more than a single background and signal; class) has been enabled for these methods: MLP (NN), BDTG,; FDA.; The multiclass; functionality can be enabled with the Factory option; ""AnalysisType=multiclass"". Training data is; specified with an additional classname, e.g. via; factory->AddTree(tree,""classname"");. After the; training a genetic algorithm is invoked to determine the best; cuts for selecting a specific class, based on the figure of; merit: purity*efficiency. TMVA comes with two examples in; $ROOTSYS/tmva/test: TMVAMulticlass.C; and TMVAMulticlassApplication.C. New TMVA event vector building. The code; for splitting the input data into training and test samples for; all classes and the mixing of those samples to one training and; one test sample has been rewritten completely. The new code is; more performant and has a clearer structure. This fixes several; bugs which have been reported by some users of TMVA.; Code and performance test framework: A unit; test framework for daily software and method performance; validation has been implemented.; . Methods. BDT Automatic parameter optimisation for building the; tree architecture: The optimisation procedure uses the; performance of the trained classifier on the ""test sample"" for; finding the set of optimal parameters. Two different methods to; traverse the parameter space are available (scanning, genetic; algorithm). Currently parameter optimization is implemented only; for these three parameters that influence the tree architectur:; the maximum depth of a tree, MaxDepth, the minimum; number of events in each node, NodeMinEvents, and; the number of tress, NTrees. Optimization can; is invoked by calling; factory->OptimizeAllMethods(); prior to the call; factory->TrainAllMethods();. Automated and configurable parameter optimization is soon to; be enabled for all methods (for those parameters where; optimization is applicable).; . BDT node splitting: While Decision Trees; typically have only univariate splits, in",MatchSource.DOCS,tmva/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v528/index.html:997,Testability,test,test,997," . TMVA. TMVA version 4.1.0 is included in this root release. The most; important new feature is the support for simulataneous classification ; of multiple output classes for several multi-variate methods. ; A lot of effort went into consolidation of the software,; i.e. method performance and robustness, and framework; stability. The changes with respect to ROOT 5.27 / TMVA 4.0.7 are; in detail:. Framework. Multi-class support. The support of multiple; output classes (i.e., more than a single background and signal; class) has been enabled for these methods: MLP (NN), BDTG,; FDA.; The multiclass; functionality can be enabled with the Factory option; ""AnalysisType=multiclass"". Training data is; specified with an additional classname, e.g. via; factory->AddTree(tree,""classname"");. After the; training a genetic algorithm is invoked to determine the best; cuts for selecting a specific class, based on the figure of; merit: purity*efficiency. TMVA comes with two examples in; $ROOTSYS/tmva/test: TMVAMulticlass.C; and TMVAMulticlassApplication.C. New TMVA event vector building. The code; for splitting the input data into training and test samples for; all classes and the mixing of those samples to one training and; one test sample has been rewritten completely. The new code is; more performant and has a clearer structure. This fixes several; bugs which have been reported by some users of TMVA.; Code and performance test framework: A unit; test framework for daily software and method performance; validation has been implemented.; . Methods. BDT Automatic parameter optimisation for building the; tree architecture: The optimisation procedure uses the; performance of the trained classifier on the ""test sample"" for; finding the set of optimal parameters. Two different methods to; traverse the parameter space are available (scanning, genetic; algorithm). Currently parameter optimization is implemented only; for these three parameters that influence the tree architectur:; the maximu",MatchSource.DOCS,tmva/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v528/index.html:1143,Testability,test,test,1143,"eral multi-variate methods. ; A lot of effort went into consolidation of the software,; i.e. method performance and robustness, and framework; stability. The changes with respect to ROOT 5.27 / TMVA 4.0.7 are; in detail:. Framework. Multi-class support. The support of multiple; output classes (i.e., more than a single background and signal; class) has been enabled for these methods: MLP (NN), BDTG,; FDA.; The multiclass; functionality can be enabled with the Factory option; ""AnalysisType=multiclass"". Training data is; specified with an additional classname, e.g. via; factory->AddTree(tree,""classname"");. After the; training a genetic algorithm is invoked to determine the best; cuts for selecting a specific class, based on the figure of; merit: purity*efficiency. TMVA comes with two examples in; $ROOTSYS/tmva/test: TMVAMulticlass.C; and TMVAMulticlassApplication.C. New TMVA event vector building. The code; for splitting the input data into training and test samples for; all classes and the mixing of those samples to one training and; one test sample has been rewritten completely. The new code is; more performant and has a clearer structure. This fixes several; bugs which have been reported by some users of TMVA.; Code and performance test framework: A unit; test framework for daily software and method performance; validation has been implemented.; . Methods. BDT Automatic parameter optimisation for building the; tree architecture: The optimisation procedure uses the; performance of the trained classifier on the ""test sample"" for; finding the set of optimal parameters. Two different methods to; traverse the parameter space are available (scanning, genetic; algorithm). Currently parameter optimization is implemented only; for these three parameters that influence the tree architectur:; the maximum depth of a tree, MaxDepth, the minimum; number of events in each node, NodeMinEvents, and; the number of tress, NTrees. Optimization can; is invoked by calling; factory->Optimi",MatchSource.DOCS,tmva/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v528/index.html:1230,Testability,test,test,1230,"eral multi-variate methods. ; A lot of effort went into consolidation of the software,; i.e. method performance and robustness, and framework; stability. The changes with respect to ROOT 5.27 / TMVA 4.0.7 are; in detail:. Framework. Multi-class support. The support of multiple; output classes (i.e., more than a single background and signal; class) has been enabled for these methods: MLP (NN), BDTG,; FDA.; The multiclass; functionality can be enabled with the Factory option; ""AnalysisType=multiclass"". Training data is; specified with an additional classname, e.g. via; factory->AddTree(tree,""classname"");. After the; training a genetic algorithm is invoked to determine the best; cuts for selecting a specific class, based on the figure of; merit: purity*efficiency. TMVA comes with two examples in; $ROOTSYS/tmva/test: TMVAMulticlass.C; and TMVAMulticlassApplication.C. New TMVA event vector building. The code; for splitting the input data into training and test samples for; all classes and the mixing of those samples to one training and; one test sample has been rewritten completely. The new code is; more performant and has a clearer structure. This fixes several; bugs which have been reported by some users of TMVA.; Code and performance test framework: A unit; test framework for daily software and method performance; validation has been implemented.; . Methods. BDT Automatic parameter optimisation for building the; tree architecture: The optimisation procedure uses the; performance of the trained classifier on the ""test sample"" for; finding the set of optimal parameters. Two different methods to; traverse the parameter space are available (scanning, genetic; algorithm). Currently parameter optimization is implemented only; for these three parameters that influence the tree architectur:; the maximum depth of a tree, MaxDepth, the minimum; number of events in each node, NodeMinEvents, and; the number of tress, NTrees. Optimization can; is invoked by calling; factory->Optimi",MatchSource.DOCS,tmva/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v528/index.html:1430,Testability,test,test,1430,"e., more than a single background and signal; class) has been enabled for these methods: MLP (NN), BDTG,; FDA.; The multiclass; functionality can be enabled with the Factory option; ""AnalysisType=multiclass"". Training data is; specified with an additional classname, e.g. via; factory->AddTree(tree,""classname"");. After the; training a genetic algorithm is invoked to determine the best; cuts for selecting a specific class, based on the figure of; merit: purity*efficiency. TMVA comes with two examples in; $ROOTSYS/tmva/test: TMVAMulticlass.C; and TMVAMulticlassApplication.C. New TMVA event vector building. The code; for splitting the input data into training and test samples for; all classes and the mixing of those samples to one training and; one test sample has been rewritten completely. The new code is; more performant and has a clearer structure. This fixes several; bugs which have been reported by some users of TMVA.; Code and performance test framework: A unit; test framework for daily software and method performance; validation has been implemented.; . Methods. BDT Automatic parameter optimisation for building the; tree architecture: The optimisation procedure uses the; performance of the trained classifier on the ""test sample"" for; finding the set of optimal parameters. Two different methods to; traverse the parameter space are available (scanning, genetic; algorithm). Currently parameter optimization is implemented only; for these three parameters that influence the tree architectur:; the maximum depth of a tree, MaxDepth, the minimum; number of events in each node, NodeMinEvents, and; the number of tress, NTrees. Optimization can; is invoked by calling; factory->OptimizeAllMethods(); prior to the call; factory->TrainAllMethods();. Automated and configurable parameter optimization is soon to; be enabled for all methods (for those parameters where; optimization is applicable).; . BDT node splitting: While Decision Trees; typically have only univariate splits, in",MatchSource.DOCS,tmva/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v528/index.html:1454,Testability,test,test,1454,"e., more than a single background and signal; class) has been enabled for these methods: MLP (NN), BDTG,; FDA.; The multiclass; functionality can be enabled with the Factory option; ""AnalysisType=multiclass"". Training data is; specified with an additional classname, e.g. via; factory->AddTree(tree,""classname"");. After the; training a genetic algorithm is invoked to determine the best; cuts for selecting a specific class, based on the figure of; merit: purity*efficiency. TMVA comes with two examples in; $ROOTSYS/tmva/test: TMVAMulticlass.C; and TMVAMulticlassApplication.C. New TMVA event vector building. The code; for splitting the input data into training and test samples for; all classes and the mixing of those samples to one training and; one test sample has been rewritten completely. The new code is; more performant and has a clearer structure. This fixes several; bugs which have been reported by some users of TMVA.; Code and performance test framework: A unit; test framework for daily software and method performance; validation has been implemented.; . Methods. BDT Automatic parameter optimisation for building the; tree architecture: The optimisation procedure uses the; performance of the trained classifier on the ""test sample"" for; finding the set of optimal parameters. Two different methods to; traverse the parameter space are available (scanning, genetic; algorithm). Currently parameter optimization is implemented only; for these three parameters that influence the tree architectur:; the maximum depth of a tree, MaxDepth, the minimum; number of events in each node, NodeMinEvents, and; the number of tress, NTrees. Optimization can; is invoked by calling; factory->OptimizeAllMethods(); prior to the call; factory->TrainAllMethods();. Automated and configurable parameter optimization is soon to; be enabled for all methods (for those parameters where; optimization is applicable).; . BDT node splitting: While Decision Trees; typically have only univariate splits, in",MatchSource.DOCS,tmva/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v528/index.html:1714,Testability,test,test,1714,"sisType=multiclass"". Training data is; specified with an additional classname, e.g. via; factory->AddTree(tree,""classname"");. After the; training a genetic algorithm is invoked to determine the best; cuts for selecting a specific class, based on the figure of; merit: purity*efficiency. TMVA comes with two examples in; $ROOTSYS/tmva/test: TMVAMulticlass.C; and TMVAMulticlassApplication.C. New TMVA event vector building. The code; for splitting the input data into training and test samples for; all classes and the mixing of those samples to one training and; one test sample has been rewritten completely. The new code is; more performant and has a clearer structure. This fixes several; bugs which have been reported by some users of TMVA.; Code and performance test framework: A unit; test framework for daily software and method performance; validation has been implemented.; . Methods. BDT Automatic parameter optimisation for building the; tree architecture: The optimisation procedure uses the; performance of the trained classifier on the ""test sample"" for; finding the set of optimal parameters. Two different methods to; traverse the parameter space are available (scanning, genetic; algorithm). Currently parameter optimization is implemented only; for these three parameters that influence the tree architectur:; the maximum depth of a tree, MaxDepth, the minimum; number of events in each node, NodeMinEvents, and; the number of tress, NTrees. Optimization can; is invoked by calling; factory->OptimizeAllMethods(); prior to the call; factory->TrainAllMethods();. Automated and configurable parameter optimization is soon to; be enabled for all methods (for those parameters where; optimization is applicable).; . BDT node splitting: While Decision Trees; typically have only univariate splits, in TMVA one can now; also opt for multivariate splits that use a ""Fisher; Discriminant"" (option: UseFisherCuts), built from all; observables that show correlations larger than some threshol",MatchSource.DOCS,tmva/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v528/index.html:2712,Testability,test,test,2712,"ftware and method performance; validation has been implemented.; . Methods. BDT Automatic parameter optimisation for building the; tree architecture: The optimisation procedure uses the; performance of the trained classifier on the ""test sample"" for; finding the set of optimal parameters. Two different methods to; traverse the parameter space are available (scanning, genetic; algorithm). Currently parameter optimization is implemented only; for these three parameters that influence the tree architectur:; the maximum depth of a tree, MaxDepth, the minimum; number of events in each node, NodeMinEvents, and; the number of tress, NTrees. Optimization can; is invoked by calling; factory->OptimizeAllMethods(); prior to the call; factory->TrainAllMethods();. Automated and configurable parameter optimization is soon to; be enabled for all methods (for those parameters where; optimization is applicable).; . BDT node splitting: While Decision Trees; typically have only univariate splits, in TMVA one can now; also opt for multivariate splits that use a ""Fisher; Discriminant"" (option: UseFisherCuts), built from all; observables that show correlations larger than some threshold; (MinLinCorrForFisher). The training will then test at each; split a cut on this fisher discriminant in addition to all; univariate cuts on the variables (or only on those variables; that have not been used in the Fisher discriminant, option; UseExcusiveVars). No obvious improvement betwen very simple; decision trees after boosting has been observed so far, but; only a limited number of studies has been performed concerning; potiential benenfit of these simple multivariate splits.; . Bug fixes. A problem in the BDTG has been fixed, leading to a much; improved regression performance.; A problem in the TMVA::Reader has been fixed.; With the new test framework and the coverity checks of ROOT; a number of bugs were discovered and fixed. They mainly concerned; memory leaks, and did not affect the performance. ",MatchSource.DOCS,tmva/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v528/index.html:3316,Testability,test,test,3316,"ftware and method performance; validation has been implemented.; . Methods. BDT Automatic parameter optimisation for building the; tree architecture: The optimisation procedure uses the; performance of the trained classifier on the ""test sample"" for; finding the set of optimal parameters. Two different methods to; traverse the parameter space are available (scanning, genetic; algorithm). Currently parameter optimization is implemented only; for these three parameters that influence the tree architectur:; the maximum depth of a tree, MaxDepth, the minimum; number of events in each node, NodeMinEvents, and; the number of tress, NTrees. Optimization can; is invoked by calling; factory->OptimizeAllMethods(); prior to the call; factory->TrainAllMethods();. Automated and configurable parameter optimization is soon to; be enabled for all methods (for those parameters where; optimization is applicable).; . BDT node splitting: While Decision Trees; typically have only univariate splits, in TMVA one can now; also opt for multivariate splits that use a ""Fisher; Discriminant"" (option: UseFisherCuts), built from all; observables that show correlations larger than some threshold; (MinLinCorrForFisher). The training will then test at each; split a cut on this fisher discriminant in addition to all; univariate cuts on the variables (or only on those variables; that have not been used in the Fisher discriminant, option; UseExcusiveVars). No obvious improvement betwen very simple; decision trees after boosting has been observed so far, but; only a limited number of studies has been performed concerning; potiential benenfit of these simple multivariate splits.; . Bug fixes. A problem in the BDTG has been fixed, leading to a much; improved regression performance.; A problem in the TMVA::Reader has been fixed.; With the new test framework and the coverity checks of ROOT; a number of bugs were discovered and fixed. They mainly concerned; memory leaks, and did not affect the performance. ",MatchSource.DOCS,tmva/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v528/index.html:1316,Usability,clear,clearer,1316,"s, and framework; stability. The changes with respect to ROOT 5.27 / TMVA 4.0.7 are; in detail:. Framework. Multi-class support. The support of multiple; output classes (i.e., more than a single background and signal; class) has been enabled for these methods: MLP (NN), BDTG,; FDA.; The multiclass; functionality can be enabled with the Factory option; ""AnalysisType=multiclass"". Training data is; specified with an additional classname, e.g. via; factory->AddTree(tree,""classname"");. After the; training a genetic algorithm is invoked to determine the best; cuts for selecting a specific class, based on the figure of; merit: purity*efficiency. TMVA comes with two examples in; $ROOTSYS/tmva/test: TMVAMulticlass.C; and TMVAMulticlassApplication.C. New TMVA event vector building. The code; for splitting the input data into training and test samples for; all classes and the mixing of those samples to one training and; one test sample has been rewritten completely. The new code is; more performant and has a clearer structure. This fixes several; bugs which have been reported by some users of TMVA.; Code and performance test framework: A unit; test framework for daily software and method performance; validation has been implemented.; . Methods. BDT Automatic parameter optimisation for building the; tree architecture: The optimisation procedure uses the; performance of the trained classifier on the ""test sample"" for; finding the set of optimal parameters. Two different methods to; traverse the parameter space are available (scanning, genetic; algorithm). Currently parameter optimization is implemented only; for these three parameters that influence the tree architectur:; the maximum depth of a tree, MaxDepth, the minimum; number of events in each node, NodeMinEvents, and; the number of tress, NTrees. Optimization can; is invoked by calling; factory->OptimizeAllMethods(); prior to the call; factory->TrainAllMethods();. Automated and configurable parameter optimization is soon to",MatchSource.DOCS,tmva/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v528/index.html:2961,Usability,simpl,simple,2961,"ftware and method performance; validation has been implemented.; . Methods. BDT Automatic parameter optimisation for building the; tree architecture: The optimisation procedure uses the; performance of the trained classifier on the ""test sample"" for; finding the set of optimal parameters. Two different methods to; traverse the parameter space are available (scanning, genetic; algorithm). Currently parameter optimization is implemented only; for these three parameters that influence the tree architectur:; the maximum depth of a tree, MaxDepth, the minimum; number of events in each node, NodeMinEvents, and; the number of tress, NTrees. Optimization can; is invoked by calling; factory->OptimizeAllMethods(); prior to the call; factory->TrainAllMethods();. Automated and configurable parameter optimization is soon to; be enabled for all methods (for those parameters where; optimization is applicable).; . BDT node splitting: While Decision Trees; typically have only univariate splits, in TMVA one can now; also opt for multivariate splits that use a ""Fisher; Discriminant"" (option: UseFisherCuts), built from all; observables that show correlations larger than some threshold; (MinLinCorrForFisher). The training will then test at each; split a cut on this fisher discriminant in addition to all; univariate cuts on the variables (or only on those variables; that have not been used in the Fisher discriminant, option; UseExcusiveVars). No obvious improvement betwen very simple; decision trees after boosting has been observed so far, but; only a limited number of studies has been performed concerning; potiential benenfit of these simple multivariate splits.; . Bug fixes. A problem in the BDTG has been fixed, leading to a much; improved regression performance.; A problem in the TMVA::Reader has been fixed.; With the new test framework and the coverity checks of ROOT; a number of bugs were discovered and fixed. They mainly concerned; memory leaks, and did not affect the performance. ",MatchSource.DOCS,tmva/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v528/index.html:3123,Usability,simpl,simple,3123,"ftware and method performance; validation has been implemented.; . Methods. BDT Automatic parameter optimisation for building the; tree architecture: The optimisation procedure uses the; performance of the trained classifier on the ""test sample"" for; finding the set of optimal parameters. Two different methods to; traverse the parameter space are available (scanning, genetic; algorithm). Currently parameter optimization is implemented only; for these three parameters that influence the tree architectur:; the maximum depth of a tree, MaxDepth, the minimum; number of events in each node, NodeMinEvents, and; the number of tress, NTrees. Optimization can; is invoked by calling; factory->OptimizeAllMethods(); prior to the call; factory->TrainAllMethods();. Automated and configurable parameter optimization is soon to; be enabled for all methods (for those parameters where; optimization is applicable).; . BDT node splitting: While Decision Trees; typically have only univariate splits, in TMVA one can now; also opt for multivariate splits that use a ""Fisher; Discriminant"" (option: UseFisherCuts), built from all; observables that show correlations larger than some threshold; (MinLinCorrForFisher). The training will then test at each; split a cut on this fisher discriminant in addition to all; univariate cuts on the variables (or only on those variables; that have not been used in the Fisher discriminant, option; UseExcusiveVars). No obvious improvement betwen very simple; decision trees after boosting has been observed so far, but; only a limited number of studies has been performed concerning; potiential benenfit of these simple multivariate splits.; . Bug fixes. A problem in the BDTG has been fixed, leading to a much; improved regression performance.; A problem in the TMVA::Reader has been fixed.; With the new test framework and the coverity checks of ROOT; a number of bugs were discovered and fixed. They mainly concerned; memory leaks, and did not affect the performance. ",MatchSource.DOCS,tmva/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v530/index.html:52,Deployability,release,release,52,". TMVA. TMVA version 4.1.2 is included in this root release. The changes with respect; to ROOT 5.28 / TMVA 4.1.0 are in detail:. Variable transformations. Variable transformations can now be applied to a user-defined subset; of variables (and regression targets).; Enable variable transformations for general boosting; Extended PDEFoam functionality:. Multiclass classification by training of one discriminator foam for each; variable.; The cell tree can now be plotted from the macro test/PlotFoams. This makes; it easyer to compare the PDEFoam structure to a decision tree.; Variable importance ranking by counting the number of cuts made in each; dimension. The variable, for which the most cuts were done is ranked highest. Fixed the size of the sampling box in PDEFoam:; In TMVA 4.1.0 the size of the PDEFoam sampling box in each dimension was; 2*VolFrac times the foam size. This was contrary to the intention and the; documentation in the UserGuide and is now corrected: In TMVA 4.1.1 the size; of the PDEFoam sampling box in each dimension is now VolFrac times the foam; size. This implies that in TMVA 4.1.1 the VolFrac value for training a PDEFoam; must be doubled in order to give the same results as in TMVA 4.1.0. The default; VolFrac value was also changed from 0.0333 to 0.0666.; New configuration variable ""NbinsMVAoutput"" defining the bins of the MVA output; variables in the TMVA training plots produced via the GUI. As always, Config; settings can be modified in the training script via, eg, the command. (TMVA::gConfig().GetVariablePlotting()).fNbinsMVAoutput = 50;. to be called AFTER initialising the TMVA Factory object. Bug fixes. Requested number of training and testing events was not; correct when pre-selection cuts were applied. Now the number of; requested events scales with the preselection efficiency and hence; does not need to be adjusted with the pre-selection. This also; corrects the problems seen in the Category classifierm, where; pre-selection is used to buil",MatchSource.DOCS,tmva/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v530/index.html:1299,Deployability,configurat,configuration,1299,"classification by training of one discriminator foam for each; variable.; The cell tree can now be plotted from the macro test/PlotFoams. This makes; it easyer to compare the PDEFoam structure to a decision tree.; Variable importance ranking by counting the number of cuts made in each; dimension. The variable, for which the most cuts were done is ranked highest. Fixed the size of the sampling box in PDEFoam:; In TMVA 4.1.0 the size of the PDEFoam sampling box in each dimension was; 2*VolFrac times the foam size. This was contrary to the intention and the; documentation in the UserGuide and is now corrected: In TMVA 4.1.1 the size; of the PDEFoam sampling box in each dimension is now VolFrac times the foam; size. This implies that in TMVA 4.1.1 the VolFrac value for training a PDEFoam; must be doubled in order to give the same results as in TMVA 4.1.0. The default; VolFrac value was also changed from 0.0333 to 0.0666.; New configuration variable ""NbinsMVAoutput"" defining the bins of the MVA output; variables in the TMVA training plots produced via the GUI. As always, Config; settings can be modified in the training script via, eg, the command. (TMVA::gConfig().GetVariablePlotting()).fNbinsMVAoutput = 50;. to be called AFTER initialising the TMVA Factory object. Bug fixes. Requested number of training and testing events was not; correct when pre-selection cuts were applied. Now the number of; requested events scales with the preselection efficiency and hence; does not need to be adjusted with the pre-selection. This also; corrects the problems seen in the Category classifierm, where; pre-selection is used to build the categories.; Correct histogram boundaries in PlotVariable.; Correct scanning procedure in OptimizeTuningParameters.; Print the significance formula that is actually used; Small speed improvement for PDEFoam functions.; Fix for MethodBoost which ensures that the method options for the boosted; classifier are handled correctly during boosting.; Fixed proble",MatchSource.DOCS,tmva/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v530/index.html:228,Modifiability,variab,variables,228,". TMVA. TMVA version 4.1.2 is included in this root release. The changes with respect; to ROOT 5.28 / TMVA 4.1.0 are in detail:. Variable transformations. Variable transformations can now be applied to a user-defined subset; of variables (and regression targets).; Enable variable transformations for general boosting; Extended PDEFoam functionality:. Multiclass classification by training of one discriminator foam for each; variable.; The cell tree can now be plotted from the macro test/PlotFoams. This makes; it easyer to compare the PDEFoam structure to a decision tree.; Variable importance ranking by counting the number of cuts made in each; dimension. The variable, for which the most cuts were done is ranked highest. Fixed the size of the sampling box in PDEFoam:; In TMVA 4.1.0 the size of the PDEFoam sampling box in each dimension was; 2*VolFrac times the foam size. This was contrary to the intention and the; documentation in the UserGuide and is now corrected: In TMVA 4.1.1 the size; of the PDEFoam sampling box in each dimension is now VolFrac times the foam; size. This implies that in TMVA 4.1.1 the VolFrac value for training a PDEFoam; must be doubled in order to give the same results as in TMVA 4.1.0. The default; VolFrac value was also changed from 0.0333 to 0.0666.; New configuration variable ""NbinsMVAoutput"" defining the bins of the MVA output; variables in the TMVA training plots produced via the GUI. As always, Config; settings can be modified in the training script via, eg, the command. (TMVA::gConfig().GetVariablePlotting()).fNbinsMVAoutput = 50;. to be called AFTER initialising the TMVA Factory object. Bug fixes. Requested number of training and testing events was not; correct when pre-selection cuts were applied. Now the number of; requested events scales with the preselection efficiency and hence; does not need to be adjusted with the pre-selection. This also; corrects the problems seen in the Category classifierm, where; pre-selection is used to buil",MatchSource.DOCS,tmva/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v530/index.html:272,Modifiability,variab,variable,272,". TMVA. TMVA version 4.1.2 is included in this root release. The changes with respect; to ROOT 5.28 / TMVA 4.1.0 are in detail:. Variable transformations. Variable transformations can now be applied to a user-defined subset; of variables (and regression targets).; Enable variable transformations for general boosting; Extended PDEFoam functionality:. Multiclass classification by training of one discriminator foam for each; variable.; The cell tree can now be plotted from the macro test/PlotFoams. This makes; it easyer to compare the PDEFoam structure to a decision tree.; Variable importance ranking by counting the number of cuts made in each; dimension. The variable, for which the most cuts were done is ranked highest. Fixed the size of the sampling box in PDEFoam:; In TMVA 4.1.0 the size of the PDEFoam sampling box in each dimension was; 2*VolFrac times the foam size. This was contrary to the intention and the; documentation in the UserGuide and is now corrected: In TMVA 4.1.1 the size; of the PDEFoam sampling box in each dimension is now VolFrac times the foam; size. This implies that in TMVA 4.1.1 the VolFrac value for training a PDEFoam; must be doubled in order to give the same results as in TMVA 4.1.0. The default; VolFrac value was also changed from 0.0333 to 0.0666.; New configuration variable ""NbinsMVAoutput"" defining the bins of the MVA output; variables in the TMVA training plots produced via the GUI. As always, Config; settings can be modified in the training script via, eg, the command. (TMVA::gConfig().GetVariablePlotting()).fNbinsMVAoutput = 50;. to be called AFTER initialising the TMVA Factory object. Bug fixes. Requested number of training and testing events was not; correct when pre-selection cuts were applied. Now the number of; requested events scales with the preselection efficiency and hence; does not need to be adjusted with the pre-selection. This also; corrects the problems seen in the Category classifierm, where; pre-selection is used to buil",MatchSource.DOCS,tmva/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v530/index.html:426,Modifiability,variab,variable,426,". TMVA. TMVA version 4.1.2 is included in this root release. The changes with respect; to ROOT 5.28 / TMVA 4.1.0 are in detail:. Variable transformations. Variable transformations can now be applied to a user-defined subset; of variables (and regression targets).; Enable variable transformations for general boosting; Extended PDEFoam functionality:. Multiclass classification by training of one discriminator foam for each; variable.; The cell tree can now be plotted from the macro test/PlotFoams. This makes; it easyer to compare the PDEFoam structure to a decision tree.; Variable importance ranking by counting the number of cuts made in each; dimension. The variable, for which the most cuts were done is ranked highest. Fixed the size of the sampling box in PDEFoam:; In TMVA 4.1.0 the size of the PDEFoam sampling box in each dimension was; 2*VolFrac times the foam size. This was contrary to the intention and the; documentation in the UserGuide and is now corrected: In TMVA 4.1.1 the size; of the PDEFoam sampling box in each dimension is now VolFrac times the foam; size. This implies that in TMVA 4.1.1 the VolFrac value for training a PDEFoam; must be doubled in order to give the same results as in TMVA 4.1.0. The default; VolFrac value was also changed from 0.0333 to 0.0666.; New configuration variable ""NbinsMVAoutput"" defining the bins of the MVA output; variables in the TMVA training plots produced via the GUI. As always, Config; settings can be modified in the training script via, eg, the command. (TMVA::gConfig().GetVariablePlotting()).fNbinsMVAoutput = 50;. to be called AFTER initialising the TMVA Factory object. Bug fixes. Requested number of training and testing events was not; correct when pre-selection cuts were applied. Now the number of; requested events scales with the preselection efficiency and hence; does not need to be adjusted with the pre-selection. This also; corrects the problems seen in the Category classifierm, where; pre-selection is used to buil",MatchSource.DOCS,tmva/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v530/index.html:665,Modifiability,variab,variable,665,". TMVA. TMVA version 4.1.2 is included in this root release. The changes with respect; to ROOT 5.28 / TMVA 4.1.0 are in detail:. Variable transformations. Variable transformations can now be applied to a user-defined subset; of variables (and regression targets).; Enable variable transformations for general boosting; Extended PDEFoam functionality:. Multiclass classification by training of one discriminator foam for each; variable.; The cell tree can now be plotted from the macro test/PlotFoams. This makes; it easyer to compare the PDEFoam structure to a decision tree.; Variable importance ranking by counting the number of cuts made in each; dimension. The variable, for which the most cuts were done is ranked highest. Fixed the size of the sampling box in PDEFoam:; In TMVA 4.1.0 the size of the PDEFoam sampling box in each dimension was; 2*VolFrac times the foam size. This was contrary to the intention and the; documentation in the UserGuide and is now corrected: In TMVA 4.1.1 the size; of the PDEFoam sampling box in each dimension is now VolFrac times the foam; size. This implies that in TMVA 4.1.1 the VolFrac value for training a PDEFoam; must be doubled in order to give the same results as in TMVA 4.1.0. The default; VolFrac value was also changed from 0.0333 to 0.0666.; New configuration variable ""NbinsMVAoutput"" defining the bins of the MVA output; variables in the TMVA training plots produced via the GUI. As always, Config; settings can be modified in the training script via, eg, the command. (TMVA::gConfig().GetVariablePlotting()).fNbinsMVAoutput = 50;. to be called AFTER initialising the TMVA Factory object. Bug fixes. Requested number of training and testing events was not; correct when pre-selection cuts were applied. Now the number of; requested events scales with the preselection efficiency and hence; does not need to be adjusted with the pre-selection. This also; corrects the problems seen in the Category classifierm, where; pre-selection is used to buil",MatchSource.DOCS,tmva/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v530/index.html:1299,Modifiability,config,configuration,1299,"classification by training of one discriminator foam for each; variable.; The cell tree can now be plotted from the macro test/PlotFoams. This makes; it easyer to compare the PDEFoam structure to a decision tree.; Variable importance ranking by counting the number of cuts made in each; dimension. The variable, for which the most cuts were done is ranked highest. Fixed the size of the sampling box in PDEFoam:; In TMVA 4.1.0 the size of the PDEFoam sampling box in each dimension was; 2*VolFrac times the foam size. This was contrary to the intention and the; documentation in the UserGuide and is now corrected: In TMVA 4.1.1 the size; of the PDEFoam sampling box in each dimension is now VolFrac times the foam; size. This implies that in TMVA 4.1.1 the VolFrac value for training a PDEFoam; must be doubled in order to give the same results as in TMVA 4.1.0. The default; VolFrac value was also changed from 0.0333 to 0.0666.; New configuration variable ""NbinsMVAoutput"" defining the bins of the MVA output; variables in the TMVA training plots produced via the GUI. As always, Config; settings can be modified in the training script via, eg, the command. (TMVA::gConfig().GetVariablePlotting()).fNbinsMVAoutput = 50;. to be called AFTER initialising the TMVA Factory object. Bug fixes. Requested number of training and testing events was not; correct when pre-selection cuts were applied. Now the number of; requested events scales with the preselection efficiency and hence; does not need to be adjusted with the pre-selection. This also; corrects the problems seen in the Category classifierm, where; pre-selection is used to build the categories.; Correct histogram boundaries in PlotVariable.; Correct scanning procedure in OptimizeTuningParameters.; Print the significance formula that is actually used; Small speed improvement for PDEFoam functions.; Fix for MethodBoost which ensures that the method options for the boosted; classifier are handled correctly during boosting.; Fixed proble",MatchSource.DOCS,tmva/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v530/index.html:1313,Modifiability,variab,variable,1313,"classification by training of one discriminator foam for each; variable.; The cell tree can now be plotted from the macro test/PlotFoams. This makes; it easyer to compare the PDEFoam structure to a decision tree.; Variable importance ranking by counting the number of cuts made in each; dimension. The variable, for which the most cuts were done is ranked highest. Fixed the size of the sampling box in PDEFoam:; In TMVA 4.1.0 the size of the PDEFoam sampling box in each dimension was; 2*VolFrac times the foam size. This was contrary to the intention and the; documentation in the UserGuide and is now corrected: In TMVA 4.1.1 the size; of the PDEFoam sampling box in each dimension is now VolFrac times the foam; size. This implies that in TMVA 4.1.1 the VolFrac value for training a PDEFoam; must be doubled in order to give the same results as in TMVA 4.1.0. The default; VolFrac value was also changed from 0.0333 to 0.0666.; New configuration variable ""NbinsMVAoutput"" defining the bins of the MVA output; variables in the TMVA training plots produced via the GUI. As always, Config; settings can be modified in the training script via, eg, the command. (TMVA::gConfig().GetVariablePlotting()).fNbinsMVAoutput = 50;. to be called AFTER initialising the TMVA Factory object. Bug fixes. Requested number of training and testing events was not; correct when pre-selection cuts were applied. Now the number of; requested events scales with the preselection efficiency and hence; does not need to be adjusted with the pre-selection. This also; corrects the problems seen in the Category classifierm, where; pre-selection is used to build the categories.; Correct histogram boundaries in PlotVariable.; Correct scanning procedure in OptimizeTuningParameters.; Print the significance formula that is actually used; Small speed improvement for PDEFoam functions.; Fix for MethodBoost which ensures that the method options for the boosted; classifier are handled correctly during boosting.; Fixed proble",MatchSource.DOCS,tmva/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v530/index.html:1376,Modifiability,variab,variables,1376,"classification by training of one discriminator foam for each; variable.; The cell tree can now be plotted from the macro test/PlotFoams. This makes; it easyer to compare the PDEFoam structure to a decision tree.; Variable importance ranking by counting the number of cuts made in each; dimension. The variable, for which the most cuts were done is ranked highest. Fixed the size of the sampling box in PDEFoam:; In TMVA 4.1.0 the size of the PDEFoam sampling box in each dimension was; 2*VolFrac times the foam size. This was contrary to the intention and the; documentation in the UserGuide and is now corrected: In TMVA 4.1.1 the size; of the PDEFoam sampling box in each dimension is now VolFrac times the foam; size. This implies that in TMVA 4.1.1 the VolFrac value for training a PDEFoam; must be doubled in order to give the same results as in TMVA 4.1.0. The default; VolFrac value was also changed from 0.0333 to 0.0666.; New configuration variable ""NbinsMVAoutput"" defining the bins of the MVA output; variables in the TMVA training plots produced via the GUI. As always, Config; settings can be modified in the training script via, eg, the command. (TMVA::gConfig().GetVariablePlotting()).fNbinsMVAoutput = 50;. to be called AFTER initialising the TMVA Factory object. Bug fixes. Requested number of training and testing events was not; correct when pre-selection cuts were applied. Now the number of; requested events scales with the preselection efficiency and hence; does not need to be adjusted with the pre-selection. This also; corrects the problems seen in the Category classifierm, where; pre-selection is used to build the categories.; Correct histogram boundaries in PlotVariable.; Correct scanning procedure in OptimizeTuningParameters.; Print the significance formula that is actually used; Small speed improvement for PDEFoam functions.; Fix for MethodBoost which ensures that the method options for the boosted; classifier are handled correctly during boosting.; Fixed proble",MatchSource.DOCS,tmva/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v530/index.html:485,Testability,test,test,485,". TMVA. TMVA version 4.1.2 is included in this root release. The changes with respect; to ROOT 5.28 / TMVA 4.1.0 are in detail:. Variable transformations. Variable transformations can now be applied to a user-defined subset; of variables (and regression targets).; Enable variable transformations for general boosting; Extended PDEFoam functionality:. Multiclass classification by training of one discriminator foam for each; variable.; The cell tree can now be plotted from the macro test/PlotFoams. This makes; it easyer to compare the PDEFoam structure to a decision tree.; Variable importance ranking by counting the number of cuts made in each; dimension. The variable, for which the most cuts were done is ranked highest. Fixed the size of the sampling box in PDEFoam:; In TMVA 4.1.0 the size of the PDEFoam sampling box in each dimension was; 2*VolFrac times the foam size. This was contrary to the intention and the; documentation in the UserGuide and is now corrected: In TMVA 4.1.1 the size; of the PDEFoam sampling box in each dimension is now VolFrac times the foam; size. This implies that in TMVA 4.1.1 the VolFrac value for training a PDEFoam; must be doubled in order to give the same results as in TMVA 4.1.0. The default; VolFrac value was also changed from 0.0333 to 0.0666.; New configuration variable ""NbinsMVAoutput"" defining the bins of the MVA output; variables in the TMVA training plots produced via the GUI. As always, Config; settings can be modified in the training script via, eg, the command. (TMVA::gConfig().GetVariablePlotting()).fNbinsMVAoutput = 50;. to be called AFTER initialising the TMVA Factory object. Bug fixes. Requested number of training and testing events was not; correct when pre-selection cuts were applied. Now the number of; requested events scales with the preselection efficiency and hence; does not need to be adjusted with the pre-selection. This also; corrects the problems seen in the Category classifierm, where; pre-selection is used to buil",MatchSource.DOCS,tmva/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v530/index.html:1688,Testability,test,testing,1688,"e to a decision tree.; Variable importance ranking by counting the number of cuts made in each; dimension. The variable, for which the most cuts were done is ranked highest. Fixed the size of the sampling box in PDEFoam:; In TMVA 4.1.0 the size of the PDEFoam sampling box in each dimension was; 2*VolFrac times the foam size. This was contrary to the intention and the; documentation in the UserGuide and is now corrected: In TMVA 4.1.1 the size; of the PDEFoam sampling box in each dimension is now VolFrac times the foam; size. This implies that in TMVA 4.1.1 the VolFrac value for training a PDEFoam; must be doubled in order to give the same results as in TMVA 4.1.0. The default; VolFrac value was also changed from 0.0333 to 0.0666.; New configuration variable ""NbinsMVAoutput"" defining the bins of the MVA output; variables in the TMVA training plots produced via the GUI. As always, Config; settings can be modified in the training script via, eg, the command. (TMVA::gConfig().GetVariablePlotting()).fNbinsMVAoutput = 50;. to be called AFTER initialising the TMVA Factory object. Bug fixes. Requested number of training and testing events was not; correct when pre-selection cuts were applied. Now the number of; requested events scales with the preselection efficiency and hence; does not need to be adjusted with the pre-selection. This also; corrects the problems seen in the Category classifierm, where; pre-selection is used to build the categories.; Correct histogram boundaries in PlotVariable.; Correct scanning procedure in OptimizeTuningParameters.; Print the significance formula that is actually used; Small speed improvement for PDEFoam functions.; Fix for MethodBoost which ensures that the method options for the boosted; classifier are handled correctly during boosting.; Fixed problems in classification of some methods when booking background; training tree before signal one.; Fixed preprocessing transformation bug in HMatrix; Several minor bug fixes for version 4.1.2. ",MatchSource.DOCS,tmva/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tmva/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html:537,Energy Efficiency,allocate,allocated,537,". Tree. Branch creation enhancement and clarifications. Make the leaflist optional if the address points to a single numerical variable:; Int_t value;; tree->Branch(branchname, &value);. Introduce a way to create branch using directly; an object:; MyClass object;; TBranch *branch = tree->Branch(branchname, &object, bufsize, splitlevel); Clarify the ownership rules of user objects in a TTree. This clarification (and the improved auto-add-to-directory behavior; of the TH1*) allows for the TTree to now delete the memory that; its has allocated and whose ownsership was _not_ transfer back; to the user (this is happens any time the user give the TTree; the address of a pointer):. For a top-level branch the meaning of addr is as follows:. If addr is zero, then we allocate a branch object; internally and the branch is the owner of the allocated; object, not the caller. However the caller may obtain; a pointer to the branch object with GetObject(). Example:. branch->SetAddress(0);; Event* event = branch->GetObject();; ... Do some work. If addr is not zero, but the pointer addr points at is; zero, then we allocate a branch object and set the passed; pointer to point at the allocated object. The caller; owns the allocated object and is responsible for deleting; it when it is no longer needed. Example:. Event* event = 0;; branch->SetAddress(&event);; ... Do some work.; delete event;; event = 0;. If addr is not zero and the pointer addr points at is; also not zero, then the caller has allocated a branch; object and is asking us to use it. The caller owns it; and must delete it when it is no longer needed. Example:. Event* event = new Event();; branch->SetAddress(&event);; ... Do some work.; delete event;; event = 0;. These rules affect users of TTree::Branch(),; TTree::SetBranchAddress(), and TChain::SetBranchAddress(); as well because those routines call this one. An example of a tree with branches with objects allocated; and owned by us:. TFile* f1 = new TFile(""myfile_original",MatchSource.DOCS,tree/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html:768,Energy Efficiency,allocate,allocate,768,". Tree. Branch creation enhancement and clarifications. Make the leaflist optional if the address points to a single numerical variable:; Int_t value;; tree->Branch(branchname, &value);. Introduce a way to create branch using directly; an object:; MyClass object;; TBranch *branch = tree->Branch(branchname, &object, bufsize, splitlevel); Clarify the ownership rules of user objects in a TTree. This clarification (and the improved auto-add-to-directory behavior; of the TH1*) allows for the TTree to now delete the memory that; its has allocated and whose ownsership was _not_ transfer back; to the user (this is happens any time the user give the TTree; the address of a pointer):. For a top-level branch the meaning of addr is as follows:. If addr is zero, then we allocate a branch object; internally and the branch is the owner of the allocated; object, not the caller. However the caller may obtain; a pointer to the branch object with GetObject(). Example:. branch->SetAddress(0);; Event* event = branch->GetObject();; ... Do some work. If addr is not zero, but the pointer addr points at is; zero, then we allocate a branch object and set the passed; pointer to point at the allocated object. The caller; owns the allocated object and is responsible for deleting; it when it is no longer needed. Example:. Event* event = 0;; branch->SetAddress(&event);; ... Do some work.; delete event;; event = 0;. If addr is not zero and the pointer addr points at is; also not zero, then the caller has allocated a branch; object and is asking us to use it. The caller owns it; and must delete it when it is no longer needed. Example:. Event* event = new Event();; branch->SetAddress(&event);; ... Do some work.; delete event;; event = 0;. These rules affect users of TTree::Branch(),; TTree::SetBranchAddress(), and TChain::SetBranchAddress(); as well because those routines call this one. An example of a tree with branches with objects allocated; and owned by us:. TFile* f1 = new TFile(""myfile_original",MatchSource.DOCS,tree/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html:840,Energy Efficiency,allocate,allocated,840,". Tree. Branch creation enhancement and clarifications. Make the leaflist optional if the address points to a single numerical variable:; Int_t value;; tree->Branch(branchname, &value);. Introduce a way to create branch using directly; an object:; MyClass object;; TBranch *branch = tree->Branch(branchname, &object, bufsize, splitlevel); Clarify the ownership rules of user objects in a TTree. This clarification (and the improved auto-add-to-directory behavior; of the TH1*) allows for the TTree to now delete the memory that; its has allocated and whose ownsership was _not_ transfer back; to the user (this is happens any time the user give the TTree; the address of a pointer):. For a top-level branch the meaning of addr is as follows:. If addr is zero, then we allocate a branch object; internally and the branch is the owner of the allocated; object, not the caller. However the caller may obtain; a pointer to the branch object with GetObject(). Example:. branch->SetAddress(0);; Event* event = branch->GetObject();; ... Do some work. If addr is not zero, but the pointer addr points at is; zero, then we allocate a branch object and set the passed; pointer to point at the allocated object. The caller; owns the allocated object and is responsible for deleting; it when it is no longer needed. Example:. Event* event = 0;; branch->SetAddress(&event);; ... Do some work.; delete event;; event = 0;. If addr is not zero and the pointer addr points at is; also not zero, then the caller has allocated a branch; object and is asking us to use it. The caller owns it; and must delete it when it is no longer needed. Example:. Event* event = new Event();; branch->SetAddress(&event);; ... Do some work.; delete event;; event = 0;. These rules affect users of TTree::Branch(),; TTree::SetBranchAddress(), and TChain::SetBranchAddress(); as well because those routines call this one. An example of a tree with branches with objects allocated; and owned by us:. TFile* f1 = new TFile(""myfile_original",MatchSource.DOCS,tree/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html:1114,Energy Efficiency,allocate,allocate,1114,"rical variable:; Int_t value;; tree->Branch(branchname, &value);. Introduce a way to create branch using directly; an object:; MyClass object;; TBranch *branch = tree->Branch(branchname, &object, bufsize, splitlevel); Clarify the ownership rules of user objects in a TTree. This clarification (and the improved auto-add-to-directory behavior; of the TH1*) allows for the TTree to now delete the memory that; its has allocated and whose ownsership was _not_ transfer back; to the user (this is happens any time the user give the TTree; the address of a pointer):. For a top-level branch the meaning of addr is as follows:. If addr is zero, then we allocate a branch object; internally and the branch is the owner of the allocated; object, not the caller. However the caller may obtain; a pointer to the branch object with GetObject(). Example:. branch->SetAddress(0);; Event* event = branch->GetObject();; ... Do some work. If addr is not zero, but the pointer addr points at is; zero, then we allocate a branch object and set the passed; pointer to point at the allocated object. The caller; owns the allocated object and is responsible for deleting; it when it is no longer needed. Example:. Event* event = 0;; branch->SetAddress(&event);; ... Do some work.; delete event;; event = 0;. If addr is not zero and the pointer addr points at is; also not zero, then the caller has allocated a branch; object and is asking us to use it. The caller owns it; and must delete it when it is no longer needed. Example:. Event* event = new Event();; branch->SetAddress(&event);; ... Do some work.; delete event;; event = 0;. These rules affect users of TTree::Branch(),; TTree::SetBranchAddress(), and TChain::SetBranchAddress(); as well because those routines call this one. An example of a tree with branches with objects allocated; and owned by us:. TFile* f1 = new TFile(""myfile_original.root"");; TTree* t1 = (TTree*) f->Get(""MyTree"");; TFile* f2 = new TFile(""myfile_copy.root"", ""recreate"");; TTree* t2 = t1-",MatchSource.DOCS,tree/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html:1183,Energy Efficiency,allocate,allocated,1183,"rical variable:; Int_t value;; tree->Branch(branchname, &value);. Introduce a way to create branch using directly; an object:; MyClass object;; TBranch *branch = tree->Branch(branchname, &object, bufsize, splitlevel); Clarify the ownership rules of user objects in a TTree. This clarification (and the improved auto-add-to-directory behavior; of the TH1*) allows for the TTree to now delete the memory that; its has allocated and whose ownsership was _not_ transfer back; to the user (this is happens any time the user give the TTree; the address of a pointer):. For a top-level branch the meaning of addr is as follows:. If addr is zero, then we allocate a branch object; internally and the branch is the owner of the allocated; object, not the caller. However the caller may obtain; a pointer to the branch object with GetObject(). Example:. branch->SetAddress(0);; Event* event = branch->GetObject();; ... Do some work. If addr is not zero, but the pointer addr points at is; zero, then we allocate a branch object and set the passed; pointer to point at the allocated object. The caller; owns the allocated object and is responsible for deleting; it when it is no longer needed. Example:. Event* event = 0;; branch->SetAddress(&event);; ... Do some work.; delete event;; event = 0;. If addr is not zero and the pointer addr points at is; also not zero, then the caller has allocated a branch; object and is asking us to use it. The caller owns it; and must delete it when it is no longer needed. Example:. Event* event = new Event();; branch->SetAddress(&event);; ... Do some work.; delete event;; event = 0;. These rules affect users of TTree::Branch(),; TTree::SetBranchAddress(), and TChain::SetBranchAddress(); as well because those routines call this one. An example of a tree with branches with objects allocated; and owned by us:. TFile* f1 = new TFile(""myfile_original.root"");; TTree* t1 = (TTree*) f->Get(""MyTree"");; TFile* f2 = new TFile(""myfile_copy.root"", ""recreate"");; TTree* t2 = t1-",MatchSource.DOCS,tree/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html:1222,Energy Efficiency,allocate,allocated,1222,"lass object;; TBranch *branch = tree->Branch(branchname, &object, bufsize, splitlevel); Clarify the ownership rules of user objects in a TTree. This clarification (and the improved auto-add-to-directory behavior; of the TH1*) allows for the TTree to now delete the memory that; its has allocated and whose ownsership was _not_ transfer back; to the user (this is happens any time the user give the TTree; the address of a pointer):. For a top-level branch the meaning of addr is as follows:. If addr is zero, then we allocate a branch object; internally and the branch is the owner of the allocated; object, not the caller. However the caller may obtain; a pointer to the branch object with GetObject(). Example:. branch->SetAddress(0);; Event* event = branch->GetObject();; ... Do some work. If addr is not zero, but the pointer addr points at is; zero, then we allocate a branch object and set the passed; pointer to point at the allocated object. The caller; owns the allocated object and is responsible for deleting; it when it is no longer needed. Example:. Event* event = 0;; branch->SetAddress(&event);; ... Do some work.; delete event;; event = 0;. If addr is not zero and the pointer addr points at is; also not zero, then the caller has allocated a branch; object and is asking us to use it. The caller owns it; and must delete it when it is no longer needed. Example:. Event* event = new Event();; branch->SetAddress(&event);; ... Do some work.; delete event;; event = 0;. These rules affect users of TTree::Branch(),; TTree::SetBranchAddress(), and TChain::SetBranchAddress(); as well because those routines call this one. An example of a tree with branches with objects allocated; and owned by us:. TFile* f1 = new TFile(""myfile_original.root"");; TTree* t1 = (TTree*) f->Get(""MyTree"");; TFile* f2 = new TFile(""myfile_copy.root"", ""recreate"");; TTree* t2 = t1->Clone(0);; for (Int_t i = 0; i < 10; ++i) {; t1->GetEntry(i);; t2->Fill();; }; t2->Write(); delete f2;; f2 = 0;; delete f1;; f1 =",MatchSource.DOCS,tree/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html:1498,Energy Efficiency,allocate,allocated,1498,"lows for the TTree to now delete the memory that; its has allocated and whose ownsership was _not_ transfer back; to the user (this is happens any time the user give the TTree; the address of a pointer):. For a top-level branch the meaning of addr is as follows:. If addr is zero, then we allocate a branch object; internally and the branch is the owner of the allocated; object, not the caller. However the caller may obtain; a pointer to the branch object with GetObject(). Example:. branch->SetAddress(0);; Event* event = branch->GetObject();; ... Do some work. If addr is not zero, but the pointer addr points at is; zero, then we allocate a branch object and set the passed; pointer to point at the allocated object. The caller; owns the allocated object and is responsible for deleting; it when it is no longer needed. Example:. Event* event = 0;; branch->SetAddress(&event);; ... Do some work.; delete event;; event = 0;. If addr is not zero and the pointer addr points at is; also not zero, then the caller has allocated a branch; object and is asking us to use it. The caller owns it; and must delete it when it is no longer needed. Example:. Event* event = new Event();; branch->SetAddress(&event);; ... Do some work.; delete event;; event = 0;. These rules affect users of TTree::Branch(),; TTree::SetBranchAddress(), and TChain::SetBranchAddress(); as well because those routines call this one. An example of a tree with branches with objects allocated; and owned by us:. TFile* f1 = new TFile(""myfile_original.root"");; TTree* t1 = (TTree*) f->Get(""MyTree"");; TFile* f2 = new TFile(""myfile_copy.root"", ""recreate"");; TTree* t2 = t1->Clone(0);; for (Int_t i = 0; i < 10; ++i) {; t1->GetEntry(i);; t2->Fill();; }; t2->Write(); delete f2;; f2 = 0;; delete f1;; f1 = 0;. An example of a branch with an object allocated by us,; but owned by the caller:. TFile* f = new TFile(""myfile.root"", ""recreate"");; TTree* t = new TTree(""t"", ""A test tree.""); Event* event = 0;; TBranchElement* br = t->Branc",MatchSource.DOCS,tree/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html:1934,Energy Efficiency,allocate,allocated,1934,"branch object with GetObject(). Example:. branch->SetAddress(0);; Event* event = branch->GetObject();; ... Do some work. If addr is not zero, but the pointer addr points at is; zero, then we allocate a branch object and set the passed; pointer to point at the allocated object. The caller; owns the allocated object and is responsible for deleting; it when it is no longer needed. Example:. Event* event = 0;; branch->SetAddress(&event);; ... Do some work.; delete event;; event = 0;. If addr is not zero and the pointer addr points at is; also not zero, then the caller has allocated a branch; object and is asking us to use it. The caller owns it; and must delete it when it is no longer needed. Example:. Event* event = new Event();; branch->SetAddress(&event);; ... Do some work.; delete event;; event = 0;. These rules affect users of TTree::Branch(),; TTree::SetBranchAddress(), and TChain::SetBranchAddress(); as well because those routines call this one. An example of a tree with branches with objects allocated; and owned by us:. TFile* f1 = new TFile(""myfile_original.root"");; TTree* t1 = (TTree*) f->Get(""MyTree"");; TFile* f2 = new TFile(""myfile_copy.root"", ""recreate"");; TTree* t2 = t1->Clone(0);; for (Int_t i = 0; i < 10; ++i) {; t1->GetEntry(i);; t2->Fill();; }; t2->Write(); delete f2;; f2 = 0;; delete f1;; f1 = 0;. An example of a branch with an object allocated by us,; but owned by the caller:. TFile* f = new TFile(""myfile.root"", ""recreate"");; TTree* t = new TTree(""t"", ""A test tree.""); Event* event = 0;; TBranchElement* br = t->Branch(""event."", &event);; for (Int_t i = 0; i < 10; ++i) {; ... Fill event with meaningful data in some way.; t->Fill();; }; t->Write();; delete event;; event = 0;; delete f;; f = 0;. Notice that the only difference between this example; and the following example is that the event pointer; is zero when the branch is created. An example of a branch with an object allocated and; owned by the caller:. TFile* f = new TFile(""myfile.root"", ""recreate""",MatchSource.DOCS,tree/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html:2295,Energy Efficiency,allocate,allocated,2295,"eeded. Example:. Event* event = 0;; branch->SetAddress(&event);; ... Do some work.; delete event;; event = 0;. If addr is not zero and the pointer addr points at is; also not zero, then the caller has allocated a branch; object and is asking us to use it. The caller owns it; and must delete it when it is no longer needed. Example:. Event* event = new Event();; branch->SetAddress(&event);; ... Do some work.; delete event;; event = 0;. These rules affect users of TTree::Branch(),; TTree::SetBranchAddress(), and TChain::SetBranchAddress(); as well because those routines call this one. An example of a tree with branches with objects allocated; and owned by us:. TFile* f1 = new TFile(""myfile_original.root"");; TTree* t1 = (TTree*) f->Get(""MyTree"");; TFile* f2 = new TFile(""myfile_copy.root"", ""recreate"");; TTree* t2 = t1->Clone(0);; for (Int_t i = 0; i < 10; ++i) {; t1->GetEntry(i);; t2->Fill();; }; t2->Write(); delete f2;; f2 = 0;; delete f1;; f1 = 0;. An example of a branch with an object allocated by us,; but owned by the caller:. TFile* f = new TFile(""myfile.root"", ""recreate"");; TTree* t = new TTree(""t"", ""A test tree.""); Event* event = 0;; TBranchElement* br = t->Branch(""event."", &event);; for (Int_t i = 0; i < 10; ++i) {; ... Fill event with meaningful data in some way.; t->Fill();; }; t->Write();; delete event;; event = 0;; delete f;; f = 0;. Notice that the only difference between this example; and the following example is that the event pointer; is zero when the branch is created. An example of a branch with an object allocated and; owned by the caller:. TFile* f = new TFile(""myfile.root"", ""recreate"");; TTree* t = new TTree(""t"", ""A test tree.""); Event* event = new Event();; TBranchElement* br = t->Branch(""event."", &event);; for (Int_t i = 0; i < 10; ++i) {; ... Fill event with meaningful data in some way.; t->Fill();; }; t->Write();; delete event;; event = 0;; delete f;; f = 0;. TTreeFormula (TTree::Draw, TTree::Scan). Fix CollectionTree->Scan(""reco_ee_et[][2]:reco_",MatchSource.DOCS,tree/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html:2841,Energy Efficiency,allocate,allocated,2841," as well because those routines call this one. An example of a tree with branches with objects allocated; and owned by us:. TFile* f1 = new TFile(""myfile_original.root"");; TTree* t1 = (TTree*) f->Get(""MyTree"");; TFile* f2 = new TFile(""myfile_copy.root"", ""recreate"");; TTree* t2 = t1->Clone(0);; for (Int_t i = 0; i < 10; ++i) {; t1->GetEntry(i);; t2->Fill();; }; t2->Write(); delete f2;; f2 = 0;; delete f1;; f1 = 0;. An example of a branch with an object allocated by us,; but owned by the caller:. TFile* f = new TFile(""myfile.root"", ""recreate"");; TTree* t = new TTree(""t"", ""A test tree.""); Event* event = 0;; TBranchElement* br = t->Branch(""event."", &event);; for (Int_t i = 0; i < 10; ++i) {; ... Fill event with meaningful data in some way.; t->Fill();; }; t->Write();; delete event;; event = 0;; delete f;; f = 0;. Notice that the only difference between this example; and the following example is that the event pointer; is zero when the branch is created. An example of a branch with an object allocated and; owned by the caller:. TFile* f = new TFile(""myfile.root"", ""recreate"");; TTree* t = new TTree(""t"", ""A test tree.""); Event* event = new Event();; TBranchElement* br = t->Branch(""event."", &event);; for (Int_t i = 0; i < 10; ++i) {; ... Fill event with meaningful data in some way.; t->Fill();; }; t->Write();; delete event;; event = 0;; delete f;; f = 0;. TTreeFormula (TTree::Draw, TTree::Scan). Fix CollectionTree->Scan(""reco_ee_et[][2]:reco_ee_et[0][2]""); where reco_ee_et is a vector<vector<double> > See http://root.cern/phpBB2/viewtopic.php?t=6536; Insure that the formula that are used as indices or as argument to special functions have their branch(es) loaded once. This fixes http://root.cern/phpBB2/viewtopic.php?p=27080#27080; Correct the drawing of ""X[1]:X[5]"" when X is a vector< vector<float> >; and X[1].size()!=X[5].size(). (reported at http://root.cern/phpBB2/viewtopic.php?p=27070); Correct the passing of NaN to function being called by TTree::Draw. Splitting STL col",MatchSource.DOCS,tree/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html:1862,Integrability,rout,routines,1862,"the branch is the owner of the allocated; object, not the caller. However the caller may obtain; a pointer to the branch object with GetObject(). Example:. branch->SetAddress(0);; Event* event = branch->GetObject();; ... Do some work. If addr is not zero, but the pointer addr points at is; zero, then we allocate a branch object and set the passed; pointer to point at the allocated object. The caller; owns the allocated object and is responsible for deleting; it when it is no longer needed. Example:. Event* event = 0;; branch->SetAddress(&event);; ... Do some work.; delete event;; event = 0;. If addr is not zero and the pointer addr points at is; also not zero, then the caller has allocated a branch; object and is asking us to use it. The caller owns it; and must delete it when it is no longer needed. Example:. Event* event = new Event();; branch->SetAddress(&event);; ... Do some work.; delete event;; event = 0;. These rules affect users of TTree::Branch(),; TTree::SetBranchAddress(), and TChain::SetBranchAddress(); as well because those routines call this one. An example of a tree with branches with objects allocated; and owned by us:. TFile* f1 = new TFile(""myfile_original.root"");; TTree* t1 = (TTree*) f->Get(""MyTree"");; TFile* f2 = new TFile(""myfile_copy.root"", ""recreate"");; TTree* t2 = t1->Clone(0);; for (Int_t i = 0; i < 10; ++i) {; t1->GetEntry(i);; t2->Fill();; }; t2->Write(); delete f2;; f2 = 0;; delete f1;; f1 = 0;. An example of a branch with an object allocated by us,; but owned by the caller:. TFile* f = new TFile(""myfile.root"", ""recreate"");; TTree* t = new TTree(""t"", ""A test tree.""); Event* event = 0;; TBranchElement* br = t->Branch(""event."", &event);; for (Int_t i = 0; i < 10; ++i) {; ... Fill event with meaningful data in some way.; t->Fill();; }; t->Write();; delete event;; event = 0;; delete f;; f = 0;. Notice that the only difference between this example; and the following example is that the event pointer; is zero when the branch is created. An exam",MatchSource.DOCS,tree/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html:5249,Integrability,synchroniz,synchronization,5249,"0 then the collection; will be written in split mode. Ie. if it contains objects of any; types deriving from TTrack this function will sort the objects; basing on their type and store them in separate branches in split; mode.; The ROOT test example in ROOTSYS/test/bench.cxx shows many examples of collections; and storage in a TTree when using split mode or not. This program illustrates the important; gain in space and time when using this new facility. Parallel unzipping. Introducing a parallel unzipping algorithm for pre-fetched buffers. Since we already know what buffers are going to be read, we can decompress a few of them in advance in an additional thread and give the impression that the data decompression comes for free (we gain up to 30% in reading intensive jobs). The size of this unzipping cache is 20% the size of the TTreeCache and can be modified with TTreeCache::SetUnzipBufferSize(Long64_t bufferSize). Theoretically, we only need one buffer in advance but in practice we might fall short if the unzipping cache is too small (synchronization costs). This experimental feature is disabled by default, to activate it use the static function TTreeCache::SetParallelUnzip(TTreeCacheUnzip::EParUnzipMode option = TTreeCacheUnzip::kEnable). The possible values to pass are: TTreeCacheUnzip::kEnable to enable itTTreeCacheUnzip::kDisable to disable itTTreeCacheUnzip::kForce to force it.The TTreeCacheUnzip is actived; only if you have more than one core. To activate it with only one core useTTreeCacheUnzip::kForce option (for example to measure the overhead). Disk and Memory Space Gain. In ROOT older than v5.20/00, the branches' last basket, also known as the write basket, was always saved in the same ""key"" as the TTree object and was always present in memory when reading or writing.; When reading this write basket was always present in memory even if the branch was never accessed. Starting in v5.20/00, TTree::Write closes out, compresses (when requested) and writes to di",MatchSource.DOCS,tree/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html:24,Modifiability,enhance,enhancement,24,". Tree. Branch creation enhancement and clarifications. Make the leaflist optional if the address points to a single numerical variable:; Int_t value;; tree->Branch(branchname, &value);. Introduce a way to create branch using directly; an object:; MyClass object;; TBranch *branch = tree->Branch(branchname, &object, bufsize, splitlevel); Clarify the ownership rules of user objects in a TTree. This clarification (and the improved auto-add-to-directory behavior; of the TH1*) allows for the TTree to now delete the memory that; its has allocated and whose ownsership was _not_ transfer back; to the user (this is happens any time the user give the TTree; the address of a pointer):. For a top-level branch the meaning of addr is as follows:. If addr is zero, then we allocate a branch object; internally and the branch is the owner of the allocated; object, not the caller. However the caller may obtain; a pointer to the branch object with GetObject(). Example:. branch->SetAddress(0);; Event* event = branch->GetObject();; ... Do some work. If addr is not zero, but the pointer addr points at is; zero, then we allocate a branch object and set the passed; pointer to point at the allocated object. The caller; owns the allocated object and is responsible for deleting; it when it is no longer needed. Example:. Event* event = 0;; branch->SetAddress(&event);; ... Do some work.; delete event;; event = 0;. If addr is not zero and the pointer addr points at is; also not zero, then the caller has allocated a branch; object and is asking us to use it. The caller owns it; and must delete it when it is no longer needed. Example:. Event* event = new Event();; branch->SetAddress(&event);; ... Do some work.; delete event;; event = 0;. These rules affect users of TTree::Branch(),; TTree::SetBranchAddress(), and TChain::SetBranchAddress(); as well because those routines call this one. An example of a tree with branches with objects allocated; and owned by us:. TFile* f1 = new TFile(""myfile_original",MatchSource.DOCS,tree/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html:127,Modifiability,variab,variable,127,". Tree. Branch creation enhancement and clarifications. Make the leaflist optional if the address points to a single numerical variable:; Int_t value;; tree->Branch(branchname, &value);. Introduce a way to create branch using directly; an object:; MyClass object;; TBranch *branch = tree->Branch(branchname, &object, bufsize, splitlevel); Clarify the ownership rules of user objects in a TTree. This clarification (and the improved auto-add-to-directory behavior; of the TH1*) allows for the TTree to now delete the memory that; its has allocated and whose ownsership was _not_ transfer back; to the user (this is happens any time the user give the TTree; the address of a pointer):. For a top-level branch the meaning of addr is as follows:. If addr is zero, then we allocate a branch object; internally and the branch is the owner of the allocated; object, not the caller. However the caller may obtain; a pointer to the branch object with GetObject(). Example:. branch->SetAddress(0);; Event* event = branch->GetObject();; ... Do some work. If addr is not zero, but the pointer addr points at is; zero, then we allocate a branch object and set the passed; pointer to point at the allocated object. The caller; owns the allocated object and is responsible for deleting; it when it is no longer needed. Example:. Event* event = 0;; branch->SetAddress(&event);; ... Do some work.; delete event;; event = 0;. If addr is not zero and the pointer addr points at is; also not zero, then the caller has allocated a branch; object and is asking us to use it. The caller owns it; and must delete it when it is no longer needed. Example:. Event* event = new Event();; branch->SetAddress(&event);; ... Do some work.; delete event;; event = 0;. These rules affect users of TTree::Branch(),; TTree::SetBranchAddress(), and TChain::SetBranchAddress(); as well because those routines call this one. An example of a tree with branches with objects allocated; and owned by us:. TFile* f1 = new TFile(""myfile_original",MatchSource.DOCS,tree/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html:7450,Modifiability,enhance,enhanced,7450," the TTree object. Benefits. Flushing the write baskets has several advantages:. Reduce the file size of the TTree object (it not longer contains the last basket), improving read time of the TTree object; Reduce memory footprint of the TTree object.; In a TTree which ""flushed"" buffer, there is now usually only zero or one buffer in memory.; Previously each branch always had at least one basket in memory and usually 2 (the write basket and one read basket).; Now only the basket of the branches actually read are loaded in memory. allow for the basket to be compressed and stored separated, increasing the compression factor. Note: Calling FlushBaskets too often (either directly of via AutoSave(""FlushBaskets"")) can lead to unnecessary fragmentation of the ROOT file,; since it write the baskets to disk (and a new basket will be started at the next fill) whether or not the content was close to filling the basket or not. Others. The fast tree cloning (TTreeCloner) was enhanced to support copying in-memory TTrees (that have been save as a single key on file). This issue was preventing hadd to fast clone files containing any 'in-memory' tree. Re-enabled the splitting of TVector3 and of any classes starting by TVector; that is not a TVectorT.; Fix the list of StreamerInfo stored in the TFile in the case of a slow; CloneTree, previously some of the classes whose named contained '::' and any; of the STL container names was inadvertently omitted (in case of classes; that are part of the TTree but had only a base and no member or in some; cases where it had only object data members.; Prevent storing a 2nd time an object non derived from TObject in the case; where the object is both the top level object of branch and has; some of it sub-object containing a pointer back to the object. (This was; actually activated in v5.18).; ; void TBranch::DeleteBaskets(Option_t* option); new function which loops on all branch baskets. If the file where branch buffers reside is writable, free the ",MatchSource.DOCS,tree/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html:3515,Performance,load,loaded,3515,"ment* br = t->Branch(""event."", &event);; for (Int_t i = 0; i < 10; ++i) {; ... Fill event with meaningful data in some way.; t->Fill();; }; t->Write();; delete event;; event = 0;; delete f;; f = 0;. Notice that the only difference between this example; and the following example is that the event pointer; is zero when the branch is created. An example of a branch with an object allocated and; owned by the caller:. TFile* f = new TFile(""myfile.root"", ""recreate"");; TTree* t = new TTree(""t"", ""A test tree.""); Event* event = new Event();; TBranchElement* br = t->Branch(""event."", &event);; for (Int_t i = 0; i < 10; ++i) {; ... Fill event with meaningful data in some way.; t->Fill();; }; t->Write();; delete event;; event = 0;; delete f;; f = 0;. TTreeFormula (TTree::Draw, TTree::Scan). Fix CollectionTree->Scan(""reco_ee_et[][2]:reco_ee_et[0][2]""); where reco_ee_et is a vector<vector<double> > See http://root.cern/phpBB2/viewtopic.php?t=6536; Insure that the formula that are used as indices or as argument to special functions have their branch(es) loaded once. This fixes http://root.cern/phpBB2/viewtopic.php?p=27080#27080; Correct the drawing of ""X[1]:X[5]"" when X is a vector< vector<float> >; and X[1].size()!=X[5].size(). (reported at http://root.cern/phpBB2/viewtopic.php?p=27070); Correct the passing of NaN to function being called by TTree::Draw. Splitting STL collections of pointers; STL collection of pointers can now be split by calling. TBranch *branch = tree->Branch( branchname, STLcollection, buffsize, splitlevel ). where STLcollection is the address of a pointer to std::vector, std::list,; std::deque, std::set or std::multiset containing pointers to objects.; and where the splitlevel is a value bigger than 100 then the collection; will be written in split mode. Ie. if it contains objects of any; types deriving from TTrack this function will sort the objects; basing on their type and store them in separate branches in split; mode.; The ROOT test example in ROOTSYS/test",MatchSource.DOCS,tree/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html:5008,Performance,cache,cache,5008,"std::vector, std::list,; std::deque, std::set or std::multiset containing pointers to objects.; and where the splitlevel is a value bigger than 100 then the collection; will be written in split mode. Ie. if it contains objects of any; types deriving from TTrack this function will sort the objects; basing on their type and store them in separate branches in split; mode.; The ROOT test example in ROOTSYS/test/bench.cxx shows many examples of collections; and storage in a TTree when using split mode or not. This program illustrates the important; gain in space and time when using this new facility. Parallel unzipping. Introducing a parallel unzipping algorithm for pre-fetched buffers. Since we already know what buffers are going to be read, we can decompress a few of them in advance in an additional thread and give the impression that the data decompression comes for free (we gain up to 30% in reading intensive jobs). The size of this unzipping cache is 20% the size of the TTreeCache and can be modified with TTreeCache::SetUnzipBufferSize(Long64_t bufferSize). Theoretically, we only need one buffer in advance but in practice we might fall short if the unzipping cache is too small (synchronization costs). This experimental feature is disabled by default, to activate it use the static function TTreeCache::SetParallelUnzip(TTreeCacheUnzip::EParUnzipMode option = TTreeCacheUnzip::kEnable). The possible values to pass are: TTreeCacheUnzip::kEnable to enable itTTreeCacheUnzip::kDisable to disable itTTreeCacheUnzip::kForce to force it.The TTreeCacheUnzip is actived; only if you have more than one core. To activate it with only one core useTTreeCacheUnzip::kForce option (for example to measure the overhead). Disk and Memory Space Gain. In ROOT older than v5.20/00, the branches' last basket, also known as the write basket, was always saved in the same ""key"" as the TTree object and was always present in memory when reading or writing.; When reading this write basket was always pr",MatchSource.DOCS,tree/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html:5229,Performance,cache,cache,5229,"0 then the collection; will be written in split mode. Ie. if it contains objects of any; types deriving from TTrack this function will sort the objects; basing on their type and store them in separate branches in split; mode.; The ROOT test example in ROOTSYS/test/bench.cxx shows many examples of collections; and storage in a TTree when using split mode or not. This program illustrates the important; gain in space and time when using this new facility. Parallel unzipping. Introducing a parallel unzipping algorithm for pre-fetched buffers. Since we already know what buffers are going to be read, we can decompress a few of them in advance in an additional thread and give the impression that the data decompression comes for free (we gain up to 30% in reading intensive jobs). The size of this unzipping cache is 20% the size of the TTreeCache and can be modified with TTreeCache::SetUnzipBufferSize(Long64_t bufferSize). Theoretically, we only need one buffer in advance but in practice we might fall short if the unzipping cache is too small (synchronization costs). This experimental feature is disabled by default, to activate it use the static function TTreeCache::SetParallelUnzip(TTreeCacheUnzip::EParUnzipMode option = TTreeCacheUnzip::kEnable). The possible values to pass are: TTreeCacheUnzip::kEnable to enable itTTreeCacheUnzip::kDisable to disable itTTreeCacheUnzip::kForce to force it.The TTreeCacheUnzip is actived; only if you have more than one core. To activate it with only one core useTTreeCacheUnzip::kForce option (for example to measure the overhead). Disk and Memory Space Gain. In ROOT older than v5.20/00, the branches' last basket, also known as the write basket, was always saved in the same ""key"" as the TTree object and was always present in memory when reading or writing.; When reading this write basket was always present in memory even if the branch was never accessed. Starting in v5.20/00, TTree::Write closes out, compresses (when requested) and writes to di",MatchSource.DOCS,tree/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html:6991,Performance,load,loaded,6991,"t in memory when reading or writing.; When reading this write basket was always present in memory even if the branch was never accessed. Starting in v5.20/00, TTree::Write closes out, compresses (when requested) and writes to disk in their own file record the write baskets of all the branches.; (This is implemented via the new function TTree::FlushBaskets, TBranch::FlushBaskets, TBranch::FlushOneBaskets). TTree::AutoSave supports a new option ""FlushBaskets"" which will call FlushBaskets before saving the TTree object. Benefits. Flushing the write baskets has several advantages:. Reduce the file size of the TTree object (it not longer contains the last basket), improving read time of the TTree object; Reduce memory footprint of the TTree object.; In a TTree which ""flushed"" buffer, there is now usually only zero or one buffer in memory.; Previously each branch always had at least one basket in memory and usually 2 (the write basket and one read basket).; Now only the basket of the branches actually read are loaded in memory. allow for the basket to be compressed and stored separated, increasing the compression factor. Note: Calling FlushBaskets too often (either directly of via AutoSave(""FlushBaskets"")) can lead to unnecessary fragmentation of the ROOT file,; since it write the baskets to disk (and a new basket will be started at the next fill) whether or not the content was close to filling the basket or not. Others. The fast tree cloning (TTreeCloner) was enhanced to support copying in-memory TTrees (that have been save as a single key on file). This issue was preventing hadd to fast clone files containing any 'in-memory' tree. Re-enabled the splitting of TVector3 and of any classes starting by TVector; that is not a TVectorT.; Fix the list of StreamerInfo stored in the TFile in the case of a slow; CloneTree, previously some of the classes whose named contained '::' and any; of the STL container names was inadvertently omitted (in case of classes; that are part of the",MatchSource.DOCS,tree/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html:9169,Performance,perform,performance,9169,"d '::' and any; of the STL container names was inadvertently omitted (in case of classes; that are part of the TTree but had only a base and no member or in some; cases where it had only object data members.; Prevent storing a 2nd time an object non derived from TObject in the case; where the object is both the top level object of branch and has; some of it sub-object containing a pointer back to the object. (This was; actually activated in v5.18).; ; void TBranch::DeleteBaskets(Option_t* option); new function which loops on all branch baskets. If the file where branch buffers reside is writable, free the disk space associated to the baskets of the branch, then call Reset(). If the option contains ""all"", delete also the baskets for the subbranches. The branch is reset.; NOTE that this function must be used with extreme care. Deleting branch baskets; fragments the file and may introduce inefficiencies when adding new entries; in the Tree or later on when reading the Tree. Protect TTree::GetCurrentFile in case the current directory is gROOT.; This case may happen when a TChain calls TChain::Process and no files have been; connected to the chain yet, but a TFile has been opened meanwhile.; Remove the calls to MapObject introduce in revision 21384 when; are unnecessary hence restoring lost performance in case where; the TTree contains many simple type (double, int, etc.); In TBranchElement::Streamer when writing, call ForceWriteInfo; not only for the TStreamerInfo directly concerning this branch; but also (in the case of the top level branch of a split TClonesArray; or a split STL container) call ForceWriteInfo for the class of; the value. This omission meant that slow CloneTree was (fataly) missing in; some cases the copy of the TStreamerInfo for class that are part; part of the TTree but had only a base and no member or in; some cases where it had only object data members.; Fix the return value of the lookup in TChainIndex; when the value searched for does not exist. ",MatchSource.DOCS,tree/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html:6098,Security,access,accessed,6098,"e modified with TTreeCache::SetUnzipBufferSize(Long64_t bufferSize). Theoretically, we only need one buffer in advance but in practice we might fall short if the unzipping cache is too small (synchronization costs). This experimental feature is disabled by default, to activate it use the static function TTreeCache::SetParallelUnzip(TTreeCacheUnzip::EParUnzipMode option = TTreeCacheUnzip::kEnable). The possible values to pass are: TTreeCacheUnzip::kEnable to enable itTTreeCacheUnzip::kDisable to disable itTTreeCacheUnzip::kForce to force it.The TTreeCacheUnzip is actived; only if you have more than one core. To activate it with only one core useTTreeCacheUnzip::kForce option (for example to measure the overhead). Disk and Memory Space Gain. In ROOT older than v5.20/00, the branches' last basket, also known as the write basket, was always saved in the same ""key"" as the TTree object and was always present in memory when reading or writing.; When reading this write basket was always present in memory even if the branch was never accessed. Starting in v5.20/00, TTree::Write closes out, compresses (when requested) and writes to disk in their own file record the write baskets of all the branches.; (This is implemented via the new function TTree::FlushBaskets, TBranch::FlushBaskets, TBranch::FlushOneBaskets). TTree::AutoSave supports a new option ""FlushBaskets"" which will call FlushBaskets before saving the TTree object. Benefits. Flushing the write baskets has several advantages:. Reduce the file size of the TTree object (it not longer contains the last basket), improving read time of the TTree object; Reduce memory footprint of the TTree object.; In a TTree which ""flushed"" buffer, there is now usually only zero or one buffer in memory.; Previously each branch always had at least one basket in memory and usually 2 (the write basket and one read basket).; Now only the basket of the branches actually read are loaded in memory. allow for the basket to be compressed and stored",MatchSource.DOCS,tree/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html:2418,Testability,test,test,2418,"ent = 0;. If addr is not zero and the pointer addr points at is; also not zero, then the caller has allocated a branch; object and is asking us to use it. The caller owns it; and must delete it when it is no longer needed. Example:. Event* event = new Event();; branch->SetAddress(&event);; ... Do some work.; delete event;; event = 0;. These rules affect users of TTree::Branch(),; TTree::SetBranchAddress(), and TChain::SetBranchAddress(); as well because those routines call this one. An example of a tree with branches with objects allocated; and owned by us:. TFile* f1 = new TFile(""myfile_original.root"");; TTree* t1 = (TTree*) f->Get(""MyTree"");; TFile* f2 = new TFile(""myfile_copy.root"", ""recreate"");; TTree* t2 = t1->Clone(0);; for (Int_t i = 0; i < 10; ++i) {; t1->GetEntry(i);; t2->Fill();; }; t2->Write(); delete f2;; f2 = 0;; delete f1;; f1 = 0;. An example of a branch with an object allocated by us,; but owned by the caller:. TFile* f = new TFile(""myfile.root"", ""recreate"");; TTree* t = new TTree(""t"", ""A test tree.""); Event* event = 0;; TBranchElement* br = t->Branch(""event."", &event);; for (Int_t i = 0; i < 10; ++i) {; ... Fill event with meaningful data in some way.; t->Fill();; }; t->Write();; delete event;; event = 0;; delete f;; f = 0;. Notice that the only difference between this example; and the following example is that the event pointer; is zero when the branch is created. An example of a branch with an object allocated and; owned by the caller:. TFile* f = new TFile(""myfile.root"", ""recreate"");; TTree* t = new TTree(""t"", ""A test tree.""); Event* event = new Event();; TBranchElement* br = t->Branch(""event."", &event);; for (Int_t i = 0; i < 10; ++i) {; ... Fill event with meaningful data in some way.; t->Fill();; }; t->Write();; delete event;; event = 0;; delete f;; f = 0;. TTreeFormula (TTree::Draw, TTree::Scan). Fix CollectionTree->Scan(""reco_ee_et[][2]:reco_ee_et[0][2]""); where reco_ee_et is a vector<vector<double> > See http://root.cern/phpBB2/viewtopic.ph",MatchSource.DOCS,tree/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html:2957,Testability,test,test,2957,"ocated; and owned by us:. TFile* f1 = new TFile(""myfile_original.root"");; TTree* t1 = (TTree*) f->Get(""MyTree"");; TFile* f2 = new TFile(""myfile_copy.root"", ""recreate"");; TTree* t2 = t1->Clone(0);; for (Int_t i = 0; i < 10; ++i) {; t1->GetEntry(i);; t2->Fill();; }; t2->Write(); delete f2;; f2 = 0;; delete f1;; f1 = 0;. An example of a branch with an object allocated by us,; but owned by the caller:. TFile* f = new TFile(""myfile.root"", ""recreate"");; TTree* t = new TTree(""t"", ""A test tree.""); Event* event = 0;; TBranchElement* br = t->Branch(""event."", &event);; for (Int_t i = 0; i < 10; ++i) {; ... Fill event with meaningful data in some way.; t->Fill();; }; t->Write();; delete event;; event = 0;; delete f;; f = 0;. Notice that the only difference between this example; and the following example is that the event pointer; is zero when the branch is created. An example of a branch with an object allocated and; owned by the caller:. TFile* f = new TFile(""myfile.root"", ""recreate"");; TTree* t = new TTree(""t"", ""A test tree.""); Event* event = new Event();; TBranchElement* br = t->Branch(""event."", &event);; for (Int_t i = 0; i < 10; ++i) {; ... Fill event with meaningful data in some way.; t->Fill();; }; t->Write();; delete event;; event = 0;; delete f;; f = 0;. TTreeFormula (TTree::Draw, TTree::Scan). Fix CollectionTree->Scan(""reco_ee_et[][2]:reco_ee_et[0][2]""); where reco_ee_et is a vector<vector<double> > See http://root.cern/phpBB2/viewtopic.php?t=6536; Insure that the formula that are used as indices or as argument to special functions have their branch(es) loaded once. This fixes http://root.cern/phpBB2/viewtopic.php?p=27080#27080; Correct the drawing of ""X[1]:X[5]"" when X is a vector< vector<float> >; and X[1].size()!=X[5].size(). (reported at http://root.cern/phpBB2/viewtopic.php?p=27070); Correct the passing of NaN to function being called by TTree::Draw. Splitting STL collections of pointers; STL collection of pointers can now be split by calling. TBranch *branch = t",MatchSource.DOCS,tree/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html:4434,Testability,test,test,4434,"as indices or as argument to special functions have their branch(es) loaded once. This fixes http://root.cern/phpBB2/viewtopic.php?p=27080#27080; Correct the drawing of ""X[1]:X[5]"" when X is a vector< vector<float> >; and X[1].size()!=X[5].size(). (reported at http://root.cern/phpBB2/viewtopic.php?p=27070); Correct the passing of NaN to function being called by TTree::Draw. Splitting STL collections of pointers; STL collection of pointers can now be split by calling. TBranch *branch = tree->Branch( branchname, STLcollection, buffsize, splitlevel ). where STLcollection is the address of a pointer to std::vector, std::list,; std::deque, std::set or std::multiset containing pointers to objects.; and where the splitlevel is a value bigger than 100 then the collection; will be written in split mode. Ie. if it contains objects of any; types deriving from TTrack this function will sort the objects; basing on their type and store them in separate branches in split; mode.; The ROOT test example in ROOTSYS/test/bench.cxx shows many examples of collections; and storage in a TTree when using split mode or not. This program illustrates the important; gain in space and time when using this new facility. Parallel unzipping. Introducing a parallel unzipping algorithm for pre-fetched buffers. Since we already know what buffers are going to be read, we can decompress a few of them in advance in an additional thread and give the impression that the data decompression comes for free (we gain up to 30% in reading intensive jobs). The size of this unzipping cache is 20% the size of the TTreeCache and can be modified with TTreeCache::SetUnzipBufferSize(Long64_t bufferSize). Theoretically, we only need one buffer in advance but in practice we might fall short if the unzipping cache is too small (synchronization costs). This experimental feature is disabled by default, to activate it use the static function TTreeCache::SetParallelUnzip(TTreeCacheUnzip::EParUnzipMode option = TTreeCacheUnzip",MatchSource.DOCS,tree/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html:4458,Testability,test,test,4458,"as indices or as argument to special functions have their branch(es) loaded once. This fixes http://root.cern/phpBB2/viewtopic.php?p=27080#27080; Correct the drawing of ""X[1]:X[5]"" when X is a vector< vector<float> >; and X[1].size()!=X[5].size(). (reported at http://root.cern/phpBB2/viewtopic.php?p=27070); Correct the passing of NaN to function being called by TTree::Draw. Splitting STL collections of pointers; STL collection of pointers can now be split by calling. TBranch *branch = tree->Branch( branchname, STLcollection, buffsize, splitlevel ). where STLcollection is the address of a pointer to std::vector, std::list,; std::deque, std::set or std::multiset containing pointers to objects.; and where the splitlevel is a value bigger than 100 then the collection; will be written in split mode. Ie. if it contains objects of any; types deriving from TTrack this function will sort the objects; basing on their type and store them in separate branches in split; mode.; The ROOT test example in ROOTSYS/test/bench.cxx shows many examples of collections; and storage in a TTree when using split mode or not. This program illustrates the important; gain in space and time when using this new facility. Parallel unzipping. Introducing a parallel unzipping algorithm for pre-fetched buffers. Since we already know what buffers are going to be read, we can decompress a few of them in advance in an additional thread and give the impression that the data decompression comes for free (we gain up to 30% in reading intensive jobs). The size of this unzipping cache is 20% the size of the TTreeCache and can be modified with TTreeCache::SetUnzipBufferSize(Long64_t bufferSize). Theoretically, we only need one buffer in advance but in practice we might fall short if the unzipping cache is too small (synchronization costs). This experimental feature is disabled by default, to activate it use the static function TTreeCache::SetParallelUnzip(TTreeCacheUnzip::EParUnzipMode option = TTreeCacheUnzip",MatchSource.DOCS,tree/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html:9220,Usability,simpl,simple,9220,"d '::' and any; of the STL container names was inadvertently omitted (in case of classes; that are part of the TTree but had only a base and no member or in some; cases where it had only object data members.; Prevent storing a 2nd time an object non derived from TObject in the case; where the object is both the top level object of branch and has; some of it sub-object containing a pointer back to the object. (This was; actually activated in v5.18).; ; void TBranch::DeleteBaskets(Option_t* option); new function which loops on all branch baskets. If the file where branch buffers reside is writable, free the disk space associated to the baskets of the branch, then call Reset(). If the option contains ""all"", delete also the baskets for the subbranches. The branch is reset.; NOTE that this function must be used with extreme care. Deleting branch baskets; fragments the file and may introduce inefficiencies when adding new entries; in the Tree or later on when reading the Tree. Protect TTree::GetCurrentFile in case the current directory is gROOT.; This case may happen when a TChain calls TChain::Process and no files have been; connected to the chain yet, but a TFile has been opened meanwhile.; Remove the calls to MapObject introduce in revision 21384 when; are unnecessary hence restoring lost performance in case where; the TTree contains many simple type (double, int, etc.); In TBranchElement::Streamer when writing, call ForceWriteInfo; not only for the TStreamerInfo directly concerning this branch; but also (in the case of the top level branch of a split TClonesArray; or a split STL container) call ForceWriteInfo for the class of; the value. This omission meant that slow CloneTree was (fataly) missing in; some cases the copy of the TStreamerInfo for class that are part; part of the TTree but had only a base and no member or in; some cases where it had only object data members.; Fix the return value of the lookup in TChainIndex; when the value searched for does not exist. ",MatchSource.DOCS,tree/doc/v520/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v520/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v522/index.html:531,Availability,error,error,531,". Tree. Restore support for IsAutoDelete in a TBranchElement (IsAutoDelete is an explicit request by the user to have the object deleted/newed each time GetEntry is called).; Allow .root in the name of directory in TChain::Add and TChain::AddFile (however in this case the root file must be ending .root.); Improve support for circular TTree friendship in LoadTree.; Insure that the in-memory tree (not attached to a file) are saved in their new style (i.e. each basket saved separately) and prevent the printing of the misleading error message:; Error in : Cannot create key without file ; Repaired TTreeSQL:; The existing code was not compatible with the change made in TTree to reduce the number of baskets in memory.; If the TreeFriend is entered via a TTree*, properly detect that it is in the same file and do not record the filename (since we will alway know where to find it.); Add "","" in the list of special characters replaced by ""_"" in the TTree::MakeClass; and TTree::MakeCode functions.; The fast cloning now explicitly rejects trying to merge TTrees with different split level; The fast cloning now supports the case where one of the branch in the output tree in; not present and also supports the case where branch are not the same order.; New bit flag kMapObject [mybranch->ResetBit(kMapObject)] to explicitly disable the; object registration during streaming within a branch (Use only if you are sure that there; is not a pointer pointing back to the nesting object within this branch). Fix tree->Draw(""s1.value"");; when the top level branch does not have a trailing dot; (and hence the real branch name is only 'value'). Fixed support for vector<bool> and vector<string> ; Added support for top level object that do not inherit from TObject _AND_ have a custom streamer (like std::string and TString);; Tree Viewer. In TParallelCoordVar the ""average marker"" for candle plots was not painted at; the right place in case of horizontal view.; Protection added in:; TParallelCoord::TPara",MatchSource.DOCS,tree/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v522/index.html:681,Energy Efficiency,reduce,reduce,681,". Tree. Restore support for IsAutoDelete in a TBranchElement (IsAutoDelete is an explicit request by the user to have the object deleted/newed each time GetEntry is called).; Allow .root in the name of directory in TChain::Add and TChain::AddFile (however in this case the root file must be ending .root.); Improve support for circular TTree friendship in LoadTree.; Insure that the in-memory tree (not attached to a file) are saved in their new style (i.e. each basket saved separately) and prevent the printing of the misleading error message:; Error in : Cannot create key without file ; Repaired TTreeSQL:; The existing code was not compatible with the change made in TTree to reduce the number of baskets in memory.; If the TreeFriend is entered via a TTree*, properly detect that it is in the same file and do not record the filename (since we will alway know where to find it.); Add "","" in the list of special characters replaced by ""_"" in the TTree::MakeClass; and TTree::MakeCode functions.; The fast cloning now explicitly rejects trying to merge TTrees with different split level; The fast cloning now supports the case where one of the branch in the output tree in; not present and also supports the case where branch are not the same order.; New bit flag kMapObject [mybranch->ResetBit(kMapObject)] to explicitly disable the; object registration during streaming within a branch (Use only if you are sure that there; is not a pointer pointing back to the nesting object within this branch). Fix tree->Draw(""s1.value"");; when the top level branch does not have a trailing dot; (and hence the real branch name is only 'value'). Fixed support for vector<bool> and vector<string> ; Added support for top level object that do not inherit from TObject _AND_ have a custom streamer (like std::string and TString);; Tree Viewer. In TParallelCoordVar the ""average marker"" for candle plots was not painted at; the right place in case of horizontal view.; Protection added in:; TParallelCoord::TPara",MatchSource.DOCS,tree/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v522/index.html:537,Integrability,message,message,537,". Tree. Restore support for IsAutoDelete in a TBranchElement (IsAutoDelete is an explicit request by the user to have the object deleted/newed each time GetEntry is called).; Allow .root in the name of directory in TChain::Add and TChain::AddFile (however in this case the root file must be ending .root.); Improve support for circular TTree friendship in LoadTree.; Insure that the in-memory tree (not attached to a file) are saved in their new style (i.e. each basket saved separately) and prevent the printing of the misleading error message:; Error in : Cannot create key without file ; Repaired TTreeSQL:; The existing code was not compatible with the change made in TTree to reduce the number of baskets in memory.; If the TreeFriend is entered via a TTree*, properly detect that it is in the same file and do not record the filename (since we will alway know where to find it.); Add "","" in the list of special characters replaced by ""_"" in the TTree::MakeClass; and TTree::MakeCode functions.; The fast cloning now explicitly rejects trying to merge TTrees with different split level; The fast cloning now supports the case where one of the branch in the output tree in; not present and also supports the case where branch are not the same order.; New bit flag kMapObject [mybranch->ResetBit(kMapObject)] to explicitly disable the; object registration during streaming within a branch (Use only if you are sure that there; is not a pointer pointing back to the nesting object within this branch). Fix tree->Draw(""s1.value"");; when the top level branch does not have a trailing dot; (and hence the real branch name is only 'value'). Fixed support for vector<bool> and vector<string> ; Added support for top level object that do not inherit from TObject _AND_ have a custom streamer (like std::string and TString);; Tree Viewer. In TParallelCoordVar the ""average marker"" for candle plots was not painted at; the right place in case of horizontal view.; Protection added in:; TParallelCoord::TPara",MatchSource.DOCS,tree/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v522/index.html:1738,Modifiability,inherit,inherit,1738,"t in the name of directory in TChain::Add and TChain::AddFile (however in this case the root file must be ending .root.); Improve support for circular TTree friendship in LoadTree.; Insure that the in-memory tree (not attached to a file) are saved in their new style (i.e. each basket saved separately) and prevent the printing of the misleading error message:; Error in : Cannot create key without file ; Repaired TTreeSQL:; The existing code was not compatible with the change made in TTree to reduce the number of baskets in memory.; If the TreeFriend is entered via a TTree*, properly detect that it is in the same file and do not record the filename (since we will alway know where to find it.); Add "","" in the list of special characters replaced by ""_"" in the TTree::MakeClass; and TTree::MakeCode functions.; The fast cloning now explicitly rejects trying to merge TTrees with different split level; The fast cloning now supports the case where one of the branch in the output tree in; not present and also supports the case where branch are not the same order.; New bit flag kMapObject [mybranch->ResetBit(kMapObject)] to explicitly disable the; object registration during streaming within a branch (Use only if you are sure that there; is not a pointer pointing back to the nesting object within this branch). Fix tree->Draw(""s1.value"");; when the top level branch does not have a trailing dot; (and hence the real branch name is only 'value'). Fixed support for vector<bool> and vector<string> ; Added support for top level object that do not inherit from TObject _AND_ have a custom streamer (like std::string and TString);; Tree Viewer. In TParallelCoordVar the ""average marker"" for candle plots was not painted at; the right place in case of horizontal view.; Protection added in:; TParallelCoord::TParallelCoord(TTree* tree, Long64_t nentries); in case nentries > tree->GetEstimate(); in such case a warning is printed and fNentries is set to; tree->GetEstimate(); instead of nentries. ",MatchSource.DOCS,tree/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v522/index.html:774,Safety,detect,detect,774,". Tree. Restore support for IsAutoDelete in a TBranchElement (IsAutoDelete is an explicit request by the user to have the object deleted/newed each time GetEntry is called).; Allow .root in the name of directory in TChain::Add and TChain::AddFile (however in this case the root file must be ending .root.); Improve support for circular TTree friendship in LoadTree.; Insure that the in-memory tree (not attached to a file) are saved in their new style (i.e. each basket saved separately) and prevent the printing of the misleading error message:; Error in : Cannot create key without file ; Repaired TTreeSQL:; The existing code was not compatible with the change made in TTree to reduce the number of baskets in memory.; If the TreeFriend is entered via a TTree*, properly detect that it is in the same file and do not record the filename (since we will alway know where to find it.); Add "","" in the list of special characters replaced by ""_"" in the TTree::MakeClass; and TTree::MakeCode functions.; The fast cloning now explicitly rejects trying to merge TTrees with different split level; The fast cloning now supports the case where one of the branch in the output tree in; not present and also supports the case where branch are not the same order.; New bit flag kMapObject [mybranch->ResetBit(kMapObject)] to explicitly disable the; object registration during streaming within a branch (Use only if you are sure that there; is not a pointer pointing back to the nesting object within this branch). Fix tree->Draw(""s1.value"");; when the top level branch does not have a trailing dot; (and hence the real branch name is only 'value'). Fixed support for vector<bool> and vector<string> ; Added support for top level object that do not inherit from TObject _AND_ have a custom streamer (like std::string and TString);; Tree Viewer. In TParallelCoordVar the ""average marker"" for candle plots was not painted at; the right place in case of horizontal view.; Protection added in:; TParallelCoord::TPara",MatchSource.DOCS,tree/doc/v522/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v522/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v524/index.html:528,Availability,recover,recover,528,". Tree. Significantly improve performance of TTree Proxy.; Improve read performance of sub-branch containing vector of single types.; Fix TTree::LoadBasket to properly handle the (new) case where no basket is stored with the TTree object.; Fix the axis used for an histogram created by TTree::Draw for a branch of TString or std::string objects.; MakeProxy now correctly support branches that created with a leaflist with more than one leaf; (usually used for C-struct).; TTree::CloneTree and TChain::Merge in fast mode now can recover from some mismatch errors between; the input and output TTrees by falling back to using the 'slow' mode. In particular this allow; a 'fast cloning' to handle files that requires schema evolution (albeit it is of course much slower).; Make sure that the TTreeCache is not attempting to cache (wrongly) the content of branches that are in an auxiliary files.; Make sure that FillBuffer does it work when the learning phase is over even if the entry number is 'low' for the 'current' file of a chain.; If TTree::SetEventList is called, TTree::GetEntryList no longer relinquish ownership of the automatically created TEntryList; Add the ability to see the TTree UserInfo list from the TBrowser; Fix the case of reading a TTree containing an 'old' class layout that contained a std::vector that is no longer part of the current class layout; Implement direct interfaces from TTree to the result of TSelector::Draw; TTree:GetVal(int) and TTree::GetVar(int); In TTree::ReadFile add the possibility to read multiple input files and add support for large/wide Trees definition.; Added support for ""5-D"" plotting.; Added support for std::bitset; Reduce the memory used by the mechanism keeping track of the entry of variables sizes within a basket (fEntryOffset).; The memory used now automatically decrease if the number of entries in the basket is less than 1/4 oflength of fEntryOffset.; Also the default length fEntryOffset can be set via TTree::SetDefaultEntryOffsetLen ",MatchSource.DOCS,tree/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v524/index.html:555,Availability,error,errors,555,". Tree. Significantly improve performance of TTree Proxy.; Improve read performance of sub-branch containing vector of single types.; Fix TTree::LoadBasket to properly handle the (new) case where no basket is stored with the TTree object.; Fix the axis used for an histogram created by TTree::Draw for a branch of TString or std::string objects.; MakeProxy now correctly support branches that created with a leaflist with more than one leaf; (usually used for C-struct).; TTree::CloneTree and TChain::Merge in fast mode now can recover from some mismatch errors between; the input and output TTrees by falling back to using the 'slow' mode. In particular this allow; a 'fast cloning' to handle files that requires schema evolution (albeit it is of course much slower).; Make sure that the TTreeCache is not attempting to cache (wrongly) the content of branches that are in an auxiliary files.; Make sure that FillBuffer does it work when the learning phase is over even if the entry number is 'low' for the 'current' file of a chain.; If TTree::SetEventList is called, TTree::GetEntryList no longer relinquish ownership of the automatically created TEntryList; Add the ability to see the TTree UserInfo list from the TBrowser; Fix the case of reading a TTree containing an 'old' class layout that contained a std::vector that is no longer part of the current class layout; Implement direct interfaces from TTree to the result of TSelector::Draw; TTree:GetVal(int) and TTree::GetVar(int); In TTree::ReadFile add the possibility to read multiple input files and add support for large/wide Trees definition.; Added support for ""5-D"" plotting.; Added support for std::bitset; Reduce the memory used by the mechanism keeping track of the entry of variables sizes within a basket (fEntryOffset).; The memory used now automatically decrease if the number of entries in the basket is less than 1/4 oflength of fEntryOffset.; Also the default length fEntryOffset can be set via TTree::SetDefaultEntryOffsetLen ",MatchSource.DOCS,tree/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v524/index.html:1390,Integrability,interface,interfaces,1390,"ere no basket is stored with the TTree object.; Fix the axis used for an histogram created by TTree::Draw for a branch of TString or std::string objects.; MakeProxy now correctly support branches that created with a leaflist with more than one leaf; (usually used for C-struct).; TTree::CloneTree and TChain::Merge in fast mode now can recover from some mismatch errors between; the input and output TTrees by falling back to using the 'slow' mode. In particular this allow; a 'fast cloning' to handle files that requires schema evolution (albeit it is of course much slower).; Make sure that the TTreeCache is not attempting to cache (wrongly) the content of branches that are in an auxiliary files.; Make sure that FillBuffer does it work when the learning phase is over even if the entry number is 'low' for the 'current' file of a chain.; If TTree::SetEventList is called, TTree::GetEntryList no longer relinquish ownership of the automatically created TEntryList; Add the ability to see the TTree UserInfo list from the TBrowser; Fix the case of reading a TTree containing an 'old' class layout that contained a std::vector that is no longer part of the current class layout; Implement direct interfaces from TTree to the result of TSelector::Draw; TTree:GetVal(int) and TTree::GetVar(int); In TTree::ReadFile add the possibility to read multiple input files and add support for large/wide Trees definition.; Added support for ""5-D"" plotting.; Added support for std::bitset; Reduce the memory used by the mechanism keeping track of the entry of variables sizes within a basket (fEntryOffset).; The memory used now automatically decrease if the number of entries in the basket is less than 1/4 oflength of fEntryOffset.; Also the default length fEntryOffset can be set via TTree::SetDefaultEntryOffsetLen which can be optionially applied to the; existing branches. Parallel Coordinates. Fix a memory leak. The TParallelCoord destructor was not called; when the canvas used to draw it was closed. ",MatchSource.DOCS,tree/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v524/index.html:1742,Modifiability,variab,variables,1742,"ere no basket is stored with the TTree object.; Fix the axis used for an histogram created by TTree::Draw for a branch of TString or std::string objects.; MakeProxy now correctly support branches that created with a leaflist with more than one leaf; (usually used for C-struct).; TTree::CloneTree and TChain::Merge in fast mode now can recover from some mismatch errors between; the input and output TTrees by falling back to using the 'slow' mode. In particular this allow; a 'fast cloning' to handle files that requires schema evolution (albeit it is of course much slower).; Make sure that the TTreeCache is not attempting to cache (wrongly) the content of branches that are in an auxiliary files.; Make sure that FillBuffer does it work when the learning phase is over even if the entry number is 'low' for the 'current' file of a chain.; If TTree::SetEventList is called, TTree::GetEntryList no longer relinquish ownership of the automatically created TEntryList; Add the ability to see the TTree UserInfo list from the TBrowser; Fix the case of reading a TTree containing an 'old' class layout that contained a std::vector that is no longer part of the current class layout; Implement direct interfaces from TTree to the result of TSelector::Draw; TTree:GetVal(int) and TTree::GetVar(int); In TTree::ReadFile add the possibility to read multiple input files and add support for large/wide Trees definition.; Added support for ""5-D"" plotting.; Added support for std::bitset; Reduce the memory used by the mechanism keeping track of the entry of variables sizes within a basket (fEntryOffset).; The memory used now automatically decrease if the number of entries in the basket is less than 1/4 oflength of fEntryOffset.; Also the default length fEntryOffset can be set via TTree::SetDefaultEntryOffsetLen which can be optionially applied to the; existing branches. Parallel Coordinates. Fix a memory leak. The TParallelCoord destructor was not called; when the canvas used to draw it was closed. ",MatchSource.DOCS,tree/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v524/index.html:30,Performance,perform,performance,30,". Tree. Significantly improve performance of TTree Proxy.; Improve read performance of sub-branch containing vector of single types.; Fix TTree::LoadBasket to properly handle the (new) case where no basket is stored with the TTree object.; Fix the axis used for an histogram created by TTree::Draw for a branch of TString or std::string objects.; MakeProxy now correctly support branches that created with a leaflist with more than one leaf; (usually used for C-struct).; TTree::CloneTree and TChain::Merge in fast mode now can recover from some mismatch errors between; the input and output TTrees by falling back to using the 'slow' mode. In particular this allow; a 'fast cloning' to handle files that requires schema evolution (albeit it is of course much slower).; Make sure that the TTreeCache is not attempting to cache (wrongly) the content of branches that are in an auxiliary files.; Make sure that FillBuffer does it work when the learning phase is over even if the entry number is 'low' for the 'current' file of a chain.; If TTree::SetEventList is called, TTree::GetEntryList no longer relinquish ownership of the automatically created TEntryList; Add the ability to see the TTree UserInfo list from the TBrowser; Fix the case of reading a TTree containing an 'old' class layout that contained a std::vector that is no longer part of the current class layout; Implement direct interfaces from TTree to the result of TSelector::Draw; TTree:GetVal(int) and TTree::GetVar(int); In TTree::ReadFile add the possibility to read multiple input files and add support for large/wide Trees definition.; Added support for ""5-D"" plotting.; Added support for std::bitset; Reduce the memory used by the mechanism keeping track of the entry of variables sizes within a basket (fEntryOffset).; The memory used now automatically decrease if the number of entries in the basket is less than 1/4 oflength of fEntryOffset.; Also the default length fEntryOffset can be set via TTree::SetDefaultEntryOffsetLen ",MatchSource.DOCS,tree/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v524/index.html:72,Performance,perform,performance,72,". Tree. Significantly improve performance of TTree Proxy.; Improve read performance of sub-branch containing vector of single types.; Fix TTree::LoadBasket to properly handle the (new) case where no basket is stored with the TTree object.; Fix the axis used for an histogram created by TTree::Draw for a branch of TString or std::string objects.; MakeProxy now correctly support branches that created with a leaflist with more than one leaf; (usually used for C-struct).; TTree::CloneTree and TChain::Merge in fast mode now can recover from some mismatch errors between; the input and output TTrees by falling back to using the 'slow' mode. In particular this allow; a 'fast cloning' to handle files that requires schema evolution (albeit it is of course much slower).; Make sure that the TTreeCache is not attempting to cache (wrongly) the content of branches that are in an auxiliary files.; Make sure that FillBuffer does it work when the learning phase is over even if the entry number is 'low' for the 'current' file of a chain.; If TTree::SetEventList is called, TTree::GetEntryList no longer relinquish ownership of the automatically created TEntryList; Add the ability to see the TTree UserInfo list from the TBrowser; Fix the case of reading a TTree containing an 'old' class layout that contained a std::vector that is no longer part of the current class layout; Implement direct interfaces from TTree to the result of TSelector::Draw; TTree:GetVal(int) and TTree::GetVar(int); In TTree::ReadFile add the possibility to read multiple input files and add support for large/wide Trees definition.; Added support for ""5-D"" plotting.; Added support for std::bitset; Reduce the memory used by the mechanism keeping track of the entry of variables sizes within a basket (fEntryOffset).; The memory used now automatically decrease if the number of entries in the basket is less than 1/4 oflength of fEntryOffset.; Also the default length fEntryOffset can be set via TTree::SetDefaultEntryOffsetLen ",MatchSource.DOCS,tree/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v524/index.html:821,Performance,cache,cache,821,". Tree. Significantly improve performance of TTree Proxy.; Improve read performance of sub-branch containing vector of single types.; Fix TTree::LoadBasket to properly handle the (new) case where no basket is stored with the TTree object.; Fix the axis used for an histogram created by TTree::Draw for a branch of TString or std::string objects.; MakeProxy now correctly support branches that created with a leaflist with more than one leaf; (usually used for C-struct).; TTree::CloneTree and TChain::Merge in fast mode now can recover from some mismatch errors between; the input and output TTrees by falling back to using the 'slow' mode. In particular this allow; a 'fast cloning' to handle files that requires schema evolution (albeit it is of course much slower).; Make sure that the TTreeCache is not attempting to cache (wrongly) the content of branches that are in an auxiliary files.; Make sure that FillBuffer does it work when the learning phase is over even if the entry number is 'low' for the 'current' file of a chain.; If TTree::SetEventList is called, TTree::GetEntryList no longer relinquish ownership of the automatically created TEntryList; Add the ability to see the TTree UserInfo list from the TBrowser; Fix the case of reading a TTree containing an 'old' class layout that contained a std::vector that is no longer part of the current class layout; Implement direct interfaces from TTree to the result of TSelector::Draw; TTree:GetVal(int) and TTree::GetVar(int); In TTree::ReadFile add the possibility to read multiple input files and add support for large/wide Trees definition.; Added support for ""5-D"" plotting.; Added support for std::bitset; Reduce the memory used by the mechanism keeping track of the entry of variables sizes within a basket (fEntryOffset).; The memory used now automatically decrease if the number of entries in the basket is less than 1/4 oflength of fEntryOffset.; Also the default length fEntryOffset can be set via TTree::SetDefaultEntryOffsetLen ",MatchSource.DOCS,tree/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v524/index.html:528,Safety,recover,recover,528,". Tree. Significantly improve performance of TTree Proxy.; Improve read performance of sub-branch containing vector of single types.; Fix TTree::LoadBasket to properly handle the (new) case where no basket is stored with the TTree object.; Fix the axis used for an histogram created by TTree::Draw for a branch of TString or std::string objects.; MakeProxy now correctly support branches that created with a leaflist with more than one leaf; (usually used for C-struct).; TTree::CloneTree and TChain::Merge in fast mode now can recover from some mismatch errors between; the input and output TTrees by falling back to using the 'slow' mode. In particular this allow; a 'fast cloning' to handle files that requires schema evolution (albeit it is of course much slower).; Make sure that the TTreeCache is not attempting to cache (wrongly) the content of branches that are in an auxiliary files.; Make sure that FillBuffer does it work when the learning phase is over even if the entry number is 'low' for the 'current' file of a chain.; If TTree::SetEventList is called, TTree::GetEntryList no longer relinquish ownership of the automatically created TEntryList; Add the ability to see the TTree UserInfo list from the TBrowser; Fix the case of reading a TTree containing an 'old' class layout that contained a std::vector that is no longer part of the current class layout; Implement direct interfaces from TTree to the result of TSelector::Draw; TTree:GetVal(int) and TTree::GetVar(int); In TTree::ReadFile add the possibility to read multiple input files and add support for large/wide Trees definition.; Added support for ""5-D"" plotting.; Added support for std::bitset; Reduce the memory used by the mechanism keeping track of the entry of variables sizes within a basket (fEntryOffset).; The memory used now automatically decrease if the number of entries in the basket is less than 1/4 oflength of fEntryOffset.; Also the default length fEntryOffset can be set via TTree::SetDefaultEntryOffsetLen ",MatchSource.DOCS,tree/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v524/index.html:942,Usability,learn,learning,942,". Tree. Significantly improve performance of TTree Proxy.; Improve read performance of sub-branch containing vector of single types.; Fix TTree::LoadBasket to properly handle the (new) case where no basket is stored with the TTree object.; Fix the axis used for an histogram created by TTree::Draw for a branch of TString or std::string objects.; MakeProxy now correctly support branches that created with a leaflist with more than one leaf; (usually used for C-struct).; TTree::CloneTree and TChain::Merge in fast mode now can recover from some mismatch errors between; the input and output TTrees by falling back to using the 'slow' mode. In particular this allow; a 'fast cloning' to handle files that requires schema evolution (albeit it is of course much slower).; Make sure that the TTreeCache is not attempting to cache (wrongly) the content of branches that are in an auxiliary files.; Make sure that FillBuffer does it work when the learning phase is over even if the entry number is 'low' for the 'current' file of a chain.; If TTree::SetEventList is called, TTree::GetEntryList no longer relinquish ownership of the automatically created TEntryList; Add the ability to see the TTree UserInfo list from the TBrowser; Fix the case of reading a TTree containing an 'old' class layout that contained a std::vector that is no longer part of the current class layout; Implement direct interfaces from TTree to the result of TSelector::Draw; TTree:GetVal(int) and TTree::GetVar(int); In TTree::ReadFile add the possibility to read multiple input files and add support for large/wide Trees definition.; Added support for ""5-D"" plotting.; Added support for std::bitset; Reduce the memory used by the mechanism keeping track of the entry of variables sizes within a basket (fEntryOffset).; The memory used now automatically decrease if the number of entries in the basket is less than 1/4 oflength of fEntryOffset.; Also the default length fEntryOffset can be set via TTree::SetDefaultEntryOffsetLen ",MatchSource.DOCS,tree/doc/v524/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v524/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v526/index.html:1344,Availability,failure,failure,1344,"he; elements of the formula given as a parameter.; MinIf$(formula,condition),MaxIf$(formula,condition):return the minimum (maximum) (within one TTree entry); of the value of the elements of the formula given as a parameter; if they match the condition. If not element match the condition, the result is zero. To avoid the; the result is zero. To avoid the consequent peak a zero, use the; pattern:; tree->Draw(""MinIf$(formula,condition)"",""condition"");; which will avoid calculation MinIf$ for the entries that have no match; for the condition. Add support in TTreeFormula (and hence TTree::Draw and TTree::Scan) for the ternary condition operator ( cond ? if_expr : else_expr ).; Significantly (by 2 order of magnitude) improved the performance of TTree::Draw calling C++ functions.; Replace the function TSelectorDraw::MakeIndex and TSelectorDraw::GetNameByIndex; with the function TSelectorDraw::SplitNames. ; Add a return value to SetBranchAddress, a return value greater or equal to zero indicate success, a negative; value indicates failure (in both case, the address is still updated). Example:; if (tree->SetBranchAddress(mybranch,&myvar) < 0) {; cerr << ""Something went wrong\n"";; return;; }; The possible return values are:; kMissingBranch (-5) : Missing branch; kInternalError (-4) : Internal error (could not find the type corresponding to a data type number.; kMissingCompiledCollectionProxy (-3) : Missing compiled collection proxy for a compiled collection.; kMismatch (-2) : Non-Class Pointer type given does not match the type expected by the branch.; kClassMismatch (-1) : Class Pointer type given does not match the type expected by the branch.; kMatch (0) : perfect match.; kMatchConversion (1) : match with (I/O) conversion.; kMatchConversionCollection (2) : match with (I/O) conversion of the content of a collection.; kMakeClass (3) : MakeClass mode so we can not check.; kVoidPtr (4) : void* passed so no check was made.; kNoCheck (5) : Underlying TBranch not yet available so ",MatchSource.DOCS,tree/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v526/index.html:1609,Availability,error,error,1609,"y match the condition. If not element match the condition, the result is zero. To avoid the; the result is zero. To avoid the consequent peak a zero, use the; pattern:; tree->Draw(""MinIf$(formula,condition)"",""condition"");; which will avoid calculation MinIf$ for the entries that have no match; for the condition. Add support in TTreeFormula (and hence TTree::Draw and TTree::Scan) for the ternary condition operator ( cond ? if_expr : else_expr ).; Significantly (by 2 order of magnitude) improved the performance of TTree::Draw calling C++ functions.; Replace the function TSelectorDraw::MakeIndex and TSelectorDraw::GetNameByIndex; with the function TSelectorDraw::SplitNames. ; Add a return value to SetBranchAddress, a return value greater or equal to zero indicate success, a negative; value indicates failure (in both case, the address is still updated). Example:; if (tree->SetBranchAddress(mybranch,&myvar) < 0) {; cerr << ""Something went wrong\n"";; return;; }; The possible return values are:; kMissingBranch (-5) : Missing branch; kInternalError (-4) : Internal error (could not find the type corresponding to a data type number.; kMissingCompiledCollectionProxy (-3) : Missing compiled collection proxy for a compiled collection.; kMismatch (-2) : Non-Class Pointer type given does not match the type expected by the branch.; kClassMismatch (-1) : Class Pointer type given does not match the type expected by the branch.; kMatch (0) : perfect match.; kMatchConversion (1) : match with (I/O) conversion.; kMatchConversionCollection (2) : match with (I/O) conversion of the content of a collection.; kMakeClass (3) : MakeClass mode so we can not check.; kVoidPtr (4) : void* passed so no check was made.; kNoCheck (5) : Underlying TBranch not yet available so no check was made. Insure that the TTreeCloner (fast merging) is able to also copy 'uninitialized' TStreamerInfo describing abstract classes.; Repair several use case of splitting collection of pointers (especially when their split",MatchSource.DOCS,tree/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v526/index.html:2293,Availability,avail,available,2293,"ual to zero indicate success, a negative; value indicates failure (in both case, the address is still updated). Example:; if (tree->SetBranchAddress(mybranch,&myvar) < 0) {; cerr << ""Something went wrong\n"";; return;; }; The possible return values are:; kMissingBranch (-5) : Missing branch; kInternalError (-4) : Internal error (could not find the type corresponding to a data type number.; kMissingCompiledCollectionProxy (-3) : Missing compiled collection proxy for a compiled collection.; kMismatch (-2) : Non-Class Pointer type given does not match the type expected by the branch.; kClassMismatch (-1) : Class Pointer type given does not match the type expected by the branch.; kMatch (0) : perfect match.; kMatchConversion (1) : match with (I/O) conversion.; kMatchConversionCollection (2) : match with (I/O) conversion of the content of a collection.; kMakeClass (3) : MakeClass mode so we can not check.; kVoidPtr (4) : void* passed so no check was made.; kNoCheck (5) : Underlying TBranch not yet available so no check was made. Insure that the TTreeCloner (fast merging) is able to also copy 'uninitialized' TStreamerInfo describing abstract classes.; Repair several use case of splitting collection of pointers (especially when their split level is 1).; Several run-time performance improvements.; In TTree::Fill use fZipBytes instead of fTotBytes for deciding when to flush or autosave.; Properly handle TTree aliases containing array indices.; Fix the default sorting order of baskets when the TTree is an older in-memory TTree.; Enhance the sort order to use the 'entry number' when the seek position are equal.; Consequently the default sort order for an older in-memory TTree is now; essentially kSortBasketsByEntry rather than kSortBasketsByBranch (old 'correct' sort; order) or 'random' (the 'broken' sort order prior to this release). IMPORTANT enhancement in TTree::Fill:; Slides from a recent seminar describing the main features of ROOT IO and Trees and the recent; improvements",MatchSource.DOCS,tree/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v526/index.html:3308,Availability,avail,available,3308,"ck was made.; kNoCheck (5) : Underlying TBranch not yet available so no check was made. Insure that the TTreeCloner (fast merging) is able to also copy 'uninitialized' TStreamerInfo describing abstract classes.; Repair several use case of splitting collection of pointers (especially when their split level is 1).; Several run-time performance improvements.; In TTree::Fill use fZipBytes instead of fTotBytes for deciding when to flush or autosave.; Properly handle TTree aliases containing array indices.; Fix the default sorting order of baskets when the TTree is an older in-memory TTree.; Enhance the sort order to use the 'entry number' when the seek position are equal.; Consequently the default sort order for an older in-memory TTree is now; essentially kSortBasketsByEntry rather than kSortBasketsByBranch (old 'correct' sort; order) or 'random' (the 'broken' sort order prior to this release). IMPORTANT enhancement in TTree::Fill:; Slides from a recent seminar describing the main features of ROOT IO and Trees and the recent; improvements described below are available at; http://root.cern/files/brun_lcgapp09.pptx ; or; http://root.cern/files/brun_lcgapp09.pdf .; The baskets are flushed and the Tree header saved at regular intervals (See AutoFlush and OptimizeBaskets); When the amount of data written so far (fTotBytes) is greater than fAutoFlush (see SetAutoFlush) all the baskets are flushed to disk.; This makes future reading faster as it guarantees that baskets belonging to nearby entries will be on the same disk region.; When the first call to flush the baskets happens, we also take this opportunity to optimize the baskets buffers.; We also check if the number of bytes written is greater than fAutoSave (see SetAutoSave).; In this case we also write the Tree header. This makes the Tree recoverable up to this point in case the program writing the Tree crashes.; Note that the user can also decide to call FlushBaskets and AutoSave in her event loop on the base of the numb",MatchSource.DOCS,tree/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v526/index.html:4051,Availability,recover,recoverable,4051,"r) or 'random' (the 'broken' sort order prior to this release). IMPORTANT enhancement in TTree::Fill:; Slides from a recent seminar describing the main features of ROOT IO and Trees and the recent; improvements described below are available at; http://root.cern/files/brun_lcgapp09.pptx ; or; http://root.cern/files/brun_lcgapp09.pdf .; The baskets are flushed and the Tree header saved at regular intervals (See AutoFlush and OptimizeBaskets); When the amount of data written so far (fTotBytes) is greater than fAutoFlush (see SetAutoFlush) all the baskets are flushed to disk.; This makes future reading faster as it guarantees that baskets belonging to nearby entries will be on the same disk region.; When the first call to flush the baskets happens, we also take this opportunity to optimize the baskets buffers.; We also check if the number of bytes written is greater than fAutoSave (see SetAutoSave).; In this case we also write the Tree header. This makes the Tree recoverable up to this point in case the program writing the Tree crashes.; Note that the user can also decide to call FlushBaskets and AutoSave in her event loop on the base of the number of events written instead of the number of bytes written.; New function TTree::OptimizeBaskets. void TTree::OptimizeBaskets(Int_t maxMemory, Float_t minComp, Option_t *option). This function may be called after having filled some entries in a Tree; using the information in the existing branch buffers, it will reassign; new branch buffer sizes to optimize time and memory.; The function computes the best values for branch buffer sizes such that; the total buffer sizes is less than maxMemory and nearby entries written; at the same time.; In case the branch compression factor for the data written so far is less; than compMin, the compression is disabled. if option =""d"" an analysis report is printed.; This function may also be called on an existing Tree to figure out the best values; given the information in the Tree header. TFile ",MatchSource.DOCS,tree/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v526/index.html:1388,Deployability,update,updated,1388,"he; elements of the formula given as a parameter.; MinIf$(formula,condition),MaxIf$(formula,condition):return the minimum (maximum) (within one TTree entry); of the value of the elements of the formula given as a parameter; if they match the condition. If not element match the condition, the result is zero. To avoid the; the result is zero. To avoid the consequent peak a zero, use the; pattern:; tree->Draw(""MinIf$(formula,condition)"",""condition"");; which will avoid calculation MinIf$ for the entries that have no match; for the condition. Add support in TTreeFormula (and hence TTree::Draw and TTree::Scan) for the ternary condition operator ( cond ? if_expr : else_expr ).; Significantly (by 2 order of magnitude) improved the performance of TTree::Draw calling C++ functions.; Replace the function TSelectorDraw::MakeIndex and TSelectorDraw::GetNameByIndex; with the function TSelectorDraw::SplitNames. ; Add a return value to SetBranchAddress, a return value greater or equal to zero indicate success, a negative; value indicates failure (in both case, the address is still updated). Example:; if (tree->SetBranchAddress(mybranch,&myvar) < 0) {; cerr << ""Something went wrong\n"";; return;; }; The possible return values are:; kMissingBranch (-5) : Missing branch; kInternalError (-4) : Internal error (could not find the type corresponding to a data type number.; kMissingCompiledCollectionProxy (-3) : Missing compiled collection proxy for a compiled collection.; kMismatch (-2) : Non-Class Pointer type given does not match the type expected by the branch.; kClassMismatch (-1) : Class Pointer type given does not match the type expected by the branch.; kMatch (0) : perfect match.; kMatchConversion (1) : match with (I/O) conversion.; kMatchConversionCollection (2) : match with (I/O) conversion of the content of a collection.; kMakeClass (3) : MakeClass mode so we can not check.; kVoidPtr (4) : void* passed so no check was made.; kNoCheck (5) : Underlying TBranch not yet available so ",MatchSource.DOCS,tree/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v526/index.html:3131,Deployability,release,release,3131,"h with (I/O) conversion.; kMatchConversionCollection (2) : match with (I/O) conversion of the content of a collection.; kMakeClass (3) : MakeClass mode so we can not check.; kVoidPtr (4) : void* passed so no check was made.; kNoCheck (5) : Underlying TBranch not yet available so no check was made. Insure that the TTreeCloner (fast merging) is able to also copy 'uninitialized' TStreamerInfo describing abstract classes.; Repair several use case of splitting collection of pointers (especially when their split level is 1).; Several run-time performance improvements.; In TTree::Fill use fZipBytes instead of fTotBytes for deciding when to flush or autosave.; Properly handle TTree aliases containing array indices.; Fix the default sorting order of baskets when the TTree is an older in-memory TTree.; Enhance the sort order to use the 'entry number' when the seek position are equal.; Consequently the default sort order for an older in-memory TTree is now; essentially kSortBasketsByEntry rather than kSortBasketsByBranch (old 'correct' sort; order) or 'random' (the 'broken' sort order prior to this release). IMPORTANT enhancement in TTree::Fill:; Slides from a recent seminar describing the main features of ROOT IO and Trees and the recent; improvements described below are available at; http://root.cern/files/brun_lcgapp09.pptx ; or; http://root.cern/files/brun_lcgapp09.pdf .; The baskets are flushed and the Tree header saved at regular intervals (See AutoFlush and OptimizeBaskets); When the amount of data written so far (fTotBytes) is greater than fAutoFlush (see SetAutoFlush) all the baskets are flushed to disk.; This makes future reading faster as it guarantees that baskets belonging to nearby entries will be on the same disk region.; When the first call to flush the baskets happens, we also take this opportunity to optimize the baskets buffers.; We also check if the number of bytes written is greater than fAutoSave (see SetAutoSave).; In this case we also write the Tree hea",MatchSource.DOCS,tree/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v526/index.html:5306,Integrability,interface,interface,5306,"branch buffer sizes to optimize time and memory.; The function computes the best values for branch buffer sizes such that; the total buffer sizes is less than maxMemory and nearby entries written; at the same time.; In case the branch compression factor for the data written so far is less; than compMin, the compression is disabled. if option =""d"" an analysis report is printed.; This function may also be called on an existing Tree to figure out the best values; given the information in the Tree header. TFile f(""myfile.root"");; TTree *T = (TTree*)f.Get(""mytreename"");; T->Print(); //show the branch buffer sizes before optimization; T->OptimizeBaskets(10000000,1,""d"");; T->Print(); //show the branch buffer sizes after optimization. New interface functions to customize the TreeCache; virtual void AddBranchToCache(const char *bname, Bool_t subbranches = kFALSE);; virtual void AddBranchToCache(TBranch *branch, Bool_t subbranches = kFALSE);; virtual void PrintCacheStats(Option_t* option = """") const;; virtual void SetParallelUnzip(Bool_t opt=kTRUE);; virtual void SetCacheEntryRange(Long64_t first, Long64_t last);; virtual void SetCacheLearnEntries(Int_t n=10);; virtual void StopCacheLearningPhase();; New functionality AutoFlush (and changes to AutoSave). Implement a new member fAutoFlush in TTree with its getter and setter:. void TTree::SetAutoFlush(Long64_t autof). The logic of the AutoFlush mechanism is optimized such that the TreeCache; will read always up to the point where FlushBaskets has been called.; This minimizes the number of cases where one has to seek backward when reading. This function may be called at the start of a program to change; the default value for fAutoFlush. CASE 1 : autof > 0. autof is the number of consecutive entries after which TTree::Fill will; flush all branch buffers to disk. CASE 2 : autof < 0. When filling the Tree the branch buffers will be flushed to disk when; more than autof bytes have been written to the file. At the first FlushBaskets;",MatchSource.DOCS,tree/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v526/index.html:3151,Modifiability,enhance,enhancement,3151,"ck was made.; kNoCheck (5) : Underlying TBranch not yet available so no check was made. Insure that the TTreeCloner (fast merging) is able to also copy 'uninitialized' TStreamerInfo describing abstract classes.; Repair several use case of splitting collection of pointers (especially when their split level is 1).; Several run-time performance improvements.; In TTree::Fill use fZipBytes instead of fTotBytes for deciding when to flush or autosave.; Properly handle TTree aliases containing array indices.; Fix the default sorting order of baskets when the TTree is an older in-memory TTree.; Enhance the sort order to use the 'entry number' when the seek position are equal.; Consequently the default sort order for an older in-memory TTree is now; essentially kSortBasketsByEntry rather than kSortBasketsByBranch (old 'correct' sort; order) or 'random' (the 'broken' sort order prior to this release). IMPORTANT enhancement in TTree::Fill:; Slides from a recent seminar describing the main features of ROOT IO and Trees and the recent; improvements described below are available at; http://root.cern/files/brun_lcgapp09.pptx ; or; http://root.cern/files/brun_lcgapp09.pdf .; The baskets are flushed and the Tree header saved at regular intervals (See AutoFlush and OptimizeBaskets); When the amount of data written so far (fTotBytes) is greater than fAutoFlush (see SetAutoFlush) all the baskets are flushed to disk.; This makes future reading faster as it guarantees that baskets belonging to nearby entries will be on the same disk region.; When the first call to flush the baskets happens, we also take this opportunity to optimize the baskets buffers.; We also check if the number of bytes written is greater than fAutoSave (see SetAutoSave).; In this case we also write the Tree header. This makes the Tree recoverable up to this point in case the program writing the Tree crashes.; Note that the user can also decide to call FlushBaskets and AutoSave in her event loop on the base of the numb",MatchSource.DOCS,tree/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v526/index.html:1039,Performance,perform,performance,1039,"ult from 1.9 GBytes to 100 GBytes.; Add new special functions in TTreeFormula (and hence TTree::Draw and TTree::Scan) to calculate the minimun and maximum with an entry:; ; Min$(formula),Max$(formula):return the minimun/maximum (within one TTree entry) of the value of the; elements of the formula given as a parameter.; MinIf$(formula,condition),MaxIf$(formula,condition):return the minimum (maximum) (within one TTree entry); of the value of the elements of the formula given as a parameter; if they match the condition. If not element match the condition, the result is zero. To avoid the; the result is zero. To avoid the consequent peak a zero, use the; pattern:; tree->Draw(""MinIf$(formula,condition)"",""condition"");; which will avoid calculation MinIf$ for the entries that have no match; for the condition. Add support in TTreeFormula (and hence TTree::Draw and TTree::Scan) for the ternary condition operator ( cond ? if_expr : else_expr ).; Significantly (by 2 order of magnitude) improved the performance of TTree::Draw calling C++ functions.; Replace the function TSelectorDraw::MakeIndex and TSelectorDraw::GetNameByIndex; with the function TSelectorDraw::SplitNames. ; Add a return value to SetBranchAddress, a return value greater or equal to zero indicate success, a negative; value indicates failure (in both case, the address is still updated). Example:; if (tree->SetBranchAddress(mybranch,&myvar) < 0) {; cerr << ""Something went wrong\n"";; return;; }; The possible return values are:; kMissingBranch (-5) : Missing branch; kInternalError (-4) : Internal error (could not find the type corresponding to a data type number.; kMissingCompiledCollectionProxy (-3) : Missing compiled collection proxy for a compiled collection.; kMismatch (-2) : Non-Class Pointer type given does not match the type expected by the branch.; kClassMismatch (-1) : Class Pointer type given does not match the type expected by the branch.; kMatch (0) : perfect match.; kMatchConversion (1) : match with (I/",MatchSource.DOCS,tree/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v526/index.html:2569,Performance,perform,performance,2569,anch; kInternalError (-4) : Internal error (could not find the type corresponding to a data type number.; kMissingCompiledCollectionProxy (-3) : Missing compiled collection proxy for a compiled collection.; kMismatch (-2) : Non-Class Pointer type given does not match the type expected by the branch.; kClassMismatch (-1) : Class Pointer type given does not match the type expected by the branch.; kMatch (0) : perfect match.; kMatchConversion (1) : match with (I/O) conversion.; kMatchConversionCollection (2) : match with (I/O) conversion of the content of a collection.; kMakeClass (3) : MakeClass mode so we can not check.; kVoidPtr (4) : void* passed so no check was made.; kNoCheck (5) : Underlying TBranch not yet available so no check was made. Insure that the TTreeCloner (fast merging) is able to also copy 'uninitialized' TStreamerInfo describing abstract classes.; Repair several use case of splitting collection of pointers (especially when their split level is 1).; Several run-time performance improvements.; In TTree::Fill use fZipBytes instead of fTotBytes for deciding when to flush or autosave.; Properly handle TTree aliases containing array indices.; Fix the default sorting order of baskets when the TTree is an older in-memory TTree.; Enhance the sort order to use the 'entry number' when the seek position are equal.; Consequently the default sort order for an older in-memory TTree is now; essentially kSortBasketsByEntry rather than kSortBasketsByBranch (old 'correct' sort; order) or 'random' (the 'broken' sort order prior to this release). IMPORTANT enhancement in TTree::Fill:; Slides from a recent seminar describing the main features of ROOT IO and Trees and the recent; improvements described below are available at; http://root.cern/files/brun_lcgapp09.pptx ; or; http://root.cern/files/brun_lcgapp09.pdf .; The baskets are flushed and the Tree header saved at regular intervals (See AutoFlush and OptimizeBaskets); When the amount of data written so far (fTotBytes),MatchSource.DOCS,tree/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v526/index.html:3865,Performance,optimiz,optimize,3865," the sort order to use the 'entry number' when the seek position are equal.; Consequently the default sort order for an older in-memory TTree is now; essentially kSortBasketsByEntry rather than kSortBasketsByBranch (old 'correct' sort; order) or 'random' (the 'broken' sort order prior to this release). IMPORTANT enhancement in TTree::Fill:; Slides from a recent seminar describing the main features of ROOT IO and Trees and the recent; improvements described below are available at; http://root.cern/files/brun_lcgapp09.pptx ; or; http://root.cern/files/brun_lcgapp09.pdf .; The baskets are flushed and the Tree header saved at regular intervals (See AutoFlush and OptimizeBaskets); When the amount of data written so far (fTotBytes) is greater than fAutoFlush (see SetAutoFlush) all the baskets are flushed to disk.; This makes future reading faster as it guarantees that baskets belonging to nearby entries will be on the same disk region.; When the first call to flush the baskets happens, we also take this opportunity to optimize the baskets buffers.; We also check if the number of bytes written is greater than fAutoSave (see SetAutoSave).; In this case we also write the Tree header. This makes the Tree recoverable up to this point in case the program writing the Tree crashes.; Note that the user can also decide to call FlushBaskets and AutoSave in her event loop on the base of the number of events written instead of the number of bytes written.; New function TTree::OptimizeBaskets. void TTree::OptimizeBaskets(Int_t maxMemory, Float_t minComp, Option_t *option). This function may be called after having filled some entries in a Tree; using the information in the existing branch buffers, it will reassign; new branch buffer sizes to optimize time and memory.; The function computes the best values for branch buffer sizes such that; the total buffer sizes is less than maxMemory and nearby entries written; at the same time.; In case the branch compression factor for the data writt",MatchSource.DOCS,tree/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v526/index.html:4588,Performance,optimiz,optimize,4588,"skets); When the amount of data written so far (fTotBytes) is greater than fAutoFlush (see SetAutoFlush) all the baskets are flushed to disk.; This makes future reading faster as it guarantees that baskets belonging to nearby entries will be on the same disk region.; When the first call to flush the baskets happens, we also take this opportunity to optimize the baskets buffers.; We also check if the number of bytes written is greater than fAutoSave (see SetAutoSave).; In this case we also write the Tree header. This makes the Tree recoverable up to this point in case the program writing the Tree crashes.; Note that the user can also decide to call FlushBaskets and AutoSave in her event loop on the base of the number of events written instead of the number of bytes written.; New function TTree::OptimizeBaskets. void TTree::OptimizeBaskets(Int_t maxMemory, Float_t minComp, Option_t *option). This function may be called after having filled some entries in a Tree; using the information in the existing branch buffers, it will reassign; new branch buffer sizes to optimize time and memory.; The function computes the best values for branch buffer sizes such that; the total buffer sizes is less than maxMemory and nearby entries written; at the same time.; In case the branch compression factor for the data written so far is less; than compMin, the compression is disabled. if option =""d"" an analysis report is printed.; This function may also be called on an existing Tree to figure out the best values; given the information in the Tree header. TFile f(""myfile.root"");; TTree *T = (TTree*)f.Get(""mytreename"");; T->Print(); //show the branch buffer sizes before optimization; T->OptimizeBaskets(10000000,1,""d"");; T->Print(); //show the branch buffer sizes after optimization. New interface functions to customize the TreeCache; virtual void AddBranchToCache(const char *bname, Bool_t subbranches = kFALSE);; virtual void AddBranchToCache(TBranch *branch, Bool_t subbranches = kFALSE);; vir",MatchSource.DOCS,tree/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v526/index.html:5188,Performance,optimiz,optimization,5188,"loop on the base of the number of events written instead of the number of bytes written.; New function TTree::OptimizeBaskets. void TTree::OptimizeBaskets(Int_t maxMemory, Float_t minComp, Option_t *option). This function may be called after having filled some entries in a Tree; using the information in the existing branch buffers, it will reassign; new branch buffer sizes to optimize time and memory.; The function computes the best values for branch buffer sizes such that; the total buffer sizes is less than maxMemory and nearby entries written; at the same time.; In case the branch compression factor for the data written so far is less; than compMin, the compression is disabled. if option =""d"" an analysis report is printed.; This function may also be called on an existing Tree to figure out the best values; given the information in the Tree header. TFile f(""myfile.root"");; TTree *T = (TTree*)f.Get(""mytreename"");; T->Print(); //show the branch buffer sizes before optimization; T->OptimizeBaskets(10000000,1,""d"");; T->Print(); //show the branch buffer sizes after optimization. New interface functions to customize the TreeCache; virtual void AddBranchToCache(const char *bname, Bool_t subbranches = kFALSE);; virtual void AddBranchToCache(TBranch *branch, Bool_t subbranches = kFALSE);; virtual void PrintCacheStats(Option_t* option = """") const;; virtual void SetParallelUnzip(Bool_t opt=kTRUE);; virtual void SetCacheEntryRange(Long64_t first, Long64_t last);; virtual void SetCacheLearnEntries(Int_t n=10);; virtual void StopCacheLearningPhase();; New functionality AutoFlush (and changes to AutoSave). Implement a new member fAutoFlush in TTree with its getter and setter:. void TTree::SetAutoFlush(Long64_t autof). The logic of the AutoFlush mechanism is optimized such that the TreeCache; will read always up to the point where FlushBaskets has been called.; This minimizes the number of cases where one has to seek backward when reading. This function may be called at the start ",MatchSource.DOCS,tree/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v526/index.html:5288,Performance,optimiz,optimization,5288,"loop on the base of the number of events written instead of the number of bytes written.; New function TTree::OptimizeBaskets. void TTree::OptimizeBaskets(Int_t maxMemory, Float_t minComp, Option_t *option). This function may be called after having filled some entries in a Tree; using the information in the existing branch buffers, it will reassign; new branch buffer sizes to optimize time and memory.; The function computes the best values for branch buffer sizes such that; the total buffer sizes is less than maxMemory and nearby entries written; at the same time.; In case the branch compression factor for the data written so far is less; than compMin, the compression is disabled. if option =""d"" an analysis report is printed.; This function may also be called on an existing Tree to figure out the best values; given the information in the Tree header. TFile f(""myfile.root"");; TTree *T = (TTree*)f.Get(""mytreename"");; T->Print(); //show the branch buffer sizes before optimization; T->OptimizeBaskets(10000000,1,""d"");; T->Print(); //show the branch buffer sizes after optimization. New interface functions to customize the TreeCache; virtual void AddBranchToCache(const char *bname, Bool_t subbranches = kFALSE);; virtual void AddBranchToCache(TBranch *branch, Bool_t subbranches = kFALSE);; virtual void PrintCacheStats(Option_t* option = """") const;; virtual void SetParallelUnzip(Bool_t opt=kTRUE);; virtual void SetCacheEntryRange(Long64_t first, Long64_t last);; virtual void SetCacheLearnEntries(Int_t n=10);; virtual void StopCacheLearningPhase();; New functionality AutoFlush (and changes to AutoSave). Implement a new member fAutoFlush in TTree with its getter and setter:. void TTree::SetAutoFlush(Long64_t autof). The logic of the AutoFlush mechanism is optimized such that the TreeCache; will read always up to the point where FlushBaskets has been called.; This minimizes the number of cases where one has to seek backward when reading. This function may be called at the start ",MatchSource.DOCS,tree/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v526/index.html:5984,Performance,optimiz,optimized,5984,"e best values; given the information in the Tree header. TFile f(""myfile.root"");; TTree *T = (TTree*)f.Get(""mytreename"");; T->Print(); //show the branch buffer sizes before optimization; T->OptimizeBaskets(10000000,1,""d"");; T->Print(); //show the branch buffer sizes after optimization. New interface functions to customize the TreeCache; virtual void AddBranchToCache(const char *bname, Bool_t subbranches = kFALSE);; virtual void AddBranchToCache(TBranch *branch, Bool_t subbranches = kFALSE);; virtual void PrintCacheStats(Option_t* option = """") const;; virtual void SetParallelUnzip(Bool_t opt=kTRUE);; virtual void SetCacheEntryRange(Long64_t first, Long64_t last);; virtual void SetCacheLearnEntries(Int_t n=10);; virtual void StopCacheLearningPhase();; New functionality AutoFlush (and changes to AutoSave). Implement a new member fAutoFlush in TTree with its getter and setter:. void TTree::SetAutoFlush(Long64_t autof). The logic of the AutoFlush mechanism is optimized such that the TreeCache; will read always up to the point where FlushBaskets has been called.; This minimizes the number of cases where one has to seek backward when reading. This function may be called at the start of a program to change; the default value for fAutoFlush. CASE 1 : autof > 0. autof is the number of consecutive entries after which TTree::Fill will; flush all branch buffers to disk. CASE 2 : autof < 0. When filling the Tree the branch buffers will be flushed to disk when; more than autof bytes have been written to the file. At the first FlushBaskets; TTree::Fill will replace fAutoFlush by the current value of fEntries. Calling this function with autof < 0 is interesting when it is hard to estimate; the size of one entry. This value is also independent of the Tree. When calling SetAutoFlush with no arguments, the; default value is -30000000, ie that the first AutoFlush will be done when; 30 MBytes of data are written to the file. CASE 3 : autof = 0; The AutoFlush mechanism is disabled. Flushi",MatchSource.DOCS,tree/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v526/index.html:7051,Performance,optimiz,optimize,7051,"FlushBaskets has been called.; This minimizes the number of cases where one has to seek backward when reading. This function may be called at the start of a program to change; the default value for fAutoFlush. CASE 1 : autof > 0. autof is the number of consecutive entries after which TTree::Fill will; flush all branch buffers to disk. CASE 2 : autof < 0. When filling the Tree the branch buffers will be flushed to disk when; more than autof bytes have been written to the file. At the first FlushBaskets; TTree::Fill will replace fAutoFlush by the current value of fEntries. Calling this function with autof < 0 is interesting when it is hard to estimate; the size of one entry. This value is also independent of the Tree. When calling SetAutoFlush with no arguments, the; default value is -30000000, ie that the first AutoFlush will be done when; 30 MBytes of data are written to the file. CASE 3 : autof = 0; The AutoFlush mechanism is disabled. Flushing the buffers at regular intervals optimize the location of; consecutive entries on the disk. Changed the default value of AutoSave from 10 to 30 MBytes. New class TTreePerfStats; This new class is an important tool to measure the I/O performance of a Tree.; It shows the locations in the file when reading a Tree. In particular it is easy; to see the performance of the Tree Cache. The results can be:. drawn in a canvas.; printed on standard output.; saved to a file for processing later. Example of use; {; TFile *f = TFile::Open(""RelValMinBias-GEN-SIM-RECO.root"");; T = (TTree*)f->Get(""Events"");; Long64_t nentries = T->GetEntries();; T->SetCacheSize(10000000);; T->AddBranchToCache(""*"");. TTreePerfStats *ps= new TTreePerfStats(""ioperf"",T);. for (Int_t i=0;i<nentries;i++) {; T->GetEntry(i);; }; ps->SaveAs(""atlas_perf.root"");; }. then, in a root interactive session, one can do:. root > TFile f(""atlas_perf.root"");; root > ioperf->Draw();; root > ioperf->Print();. The Draw or Print functions print the following information:. TreeCache ",MatchSource.DOCS,tree/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v526/index.html:7251,Performance,perform,performance,7251,"m to change; the default value for fAutoFlush. CASE 1 : autof > 0. autof is the number of consecutive entries after which TTree::Fill will; flush all branch buffers to disk. CASE 2 : autof < 0. When filling the Tree the branch buffers will be flushed to disk when; more than autof bytes have been written to the file. At the first FlushBaskets; TTree::Fill will replace fAutoFlush by the current value of fEntries. Calling this function with autof < 0 is interesting when it is hard to estimate; the size of one entry. This value is also independent of the Tree. When calling SetAutoFlush with no arguments, the; default value is -30000000, ie that the first AutoFlush will be done when; 30 MBytes of data are written to the file. CASE 3 : autof = 0; The AutoFlush mechanism is disabled. Flushing the buffers at regular intervals optimize the location of; consecutive entries on the disk. Changed the default value of AutoSave from 10 to 30 MBytes. New class TTreePerfStats; This new class is an important tool to measure the I/O performance of a Tree.; It shows the locations in the file when reading a Tree. In particular it is easy; to see the performance of the Tree Cache. The results can be:. drawn in a canvas.; printed on standard output.; saved to a file for processing later. Example of use; {; TFile *f = TFile::Open(""RelValMinBias-GEN-SIM-RECO.root"");; T = (TTree*)f->Get(""Events"");; Long64_t nentries = T->GetEntries();; T->SetCacheSize(10000000);; T->AddBranchToCache(""*"");. TTreePerfStats *ps= new TTreePerfStats(""ioperf"",T);. for (Int_t i=0;i<nentries;i++) {; T->GetEntry(i);; }; ps->SaveAs(""atlas_perf.root"");; }. then, in a root interactive session, one can do:. root > TFile f(""atlas_perf.root"");; root > ioperf->Draw();; root > ioperf->Print();. The Draw or Print functions print the following information:. TreeCache = TTree cache size in MBytes; N leaves = Number of leaves in the TTree; ReadTotal = Total number of zipped bytes read; ReadUnZip = Total number of unzipped bytes ",MatchSource.DOCS,tree/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v526/index.html:7368,Performance,perform,performance,7368,"sh all branch buffers to disk. CASE 2 : autof < 0. When filling the Tree the branch buffers will be flushed to disk when; more than autof bytes have been written to the file. At the first FlushBaskets; TTree::Fill will replace fAutoFlush by the current value of fEntries. Calling this function with autof < 0 is interesting when it is hard to estimate; the size of one entry. This value is also independent of the Tree. When calling SetAutoFlush with no arguments, the; default value is -30000000, ie that the first AutoFlush will be done when; 30 MBytes of data are written to the file. CASE 3 : autof = 0; The AutoFlush mechanism is disabled. Flushing the buffers at regular intervals optimize the location of; consecutive entries on the disk. Changed the default value of AutoSave from 10 to 30 MBytes. New class TTreePerfStats; This new class is an important tool to measure the I/O performance of a Tree.; It shows the locations in the file when reading a Tree. In particular it is easy; to see the performance of the Tree Cache. The results can be:. drawn in a canvas.; printed on standard output.; saved to a file for processing later. Example of use; {; TFile *f = TFile::Open(""RelValMinBias-GEN-SIM-RECO.root"");; T = (TTree*)f->Get(""Events"");; Long64_t nentries = T->GetEntries();; T->SetCacheSize(10000000);; T->AddBranchToCache(""*"");. TTreePerfStats *ps= new TTreePerfStats(""ioperf"",T);. for (Int_t i=0;i<nentries;i++) {; T->GetEntry(i);; }; ps->SaveAs(""atlas_perf.root"");; }. then, in a root interactive session, one can do:. root > TFile f(""atlas_perf.root"");; root > ioperf->Draw();; root > ioperf->Print();. The Draw or Print functions print the following information:. TreeCache = TTree cache size in MBytes; N leaves = Number of leaves in the TTree; ReadTotal = Total number of zipped bytes read; ReadUnZip = Total number of unzipped bytes read; ReadCalls = Total number of disk reads; ReadSize = Average read size in KBytes; Readahead = Readahead size in KBytes; Readextra = Readahe",MatchSource.DOCS,tree/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v526/index.html:8067,Performance,cache,cache,8067," file. CASE 3 : autof = 0; The AutoFlush mechanism is disabled. Flushing the buffers at regular intervals optimize the location of; consecutive entries on the disk. Changed the default value of AutoSave from 10 to 30 MBytes. New class TTreePerfStats; This new class is an important tool to measure the I/O performance of a Tree.; It shows the locations in the file when reading a Tree. In particular it is easy; to see the performance of the Tree Cache. The results can be:. drawn in a canvas.; printed on standard output.; saved to a file for processing later. Example of use; {; TFile *f = TFile::Open(""RelValMinBias-GEN-SIM-RECO.root"");; T = (TTree*)f->Get(""Events"");; Long64_t nentries = T->GetEntries();; T->SetCacheSize(10000000);; T->AddBranchToCache(""*"");. TTreePerfStats *ps= new TTreePerfStats(""ioperf"",T);. for (Int_t i=0;i<nentries;i++) {; T->GetEntry(i);; }; ps->SaveAs(""atlas_perf.root"");; }. then, in a root interactive session, one can do:. root > TFile f(""atlas_perf.root"");; root > ioperf->Draw();; root > ioperf->Print();. The Draw or Print functions print the following information:. TreeCache = TTree cache size in MBytes; N leaves = Number of leaves in the TTree; ReadTotal = Total number of zipped bytes read; ReadUnZip = Total number of unzipped bytes read; ReadCalls = Total number of disk reads; ReadSize = Average read size in KBytes; Readahead = Readahead size in KBytes; Readextra = Readahead overhead in percent; Real Time = Real Time in seconds; CPU Time = CPU Time in seconds; Disk Time = Real Time spent in pure raw disk IO; Disk IO = Raw disk IO speed in MBytes/second; ReadUZRT = Unzipped MBytes per RT second; ReadUZCP = Unipped MBytes per CP second; ReadRT = Zipped MBytes per RT second; ReadCP = Zipped MBytes per CP second. The Figure below shows the result for an original non optimized file when; the Tree Cache is not used. The Figure below shows the result for the above data file written with the; new version of ROOT and when the Tree cache is activated. ",MatchSource.DOCS,tree/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v526/index.html:8762,Performance,optimiz,optimized,8762," file. CASE 3 : autof = 0; The AutoFlush mechanism is disabled. Flushing the buffers at regular intervals optimize the location of; consecutive entries on the disk. Changed the default value of AutoSave from 10 to 30 MBytes. New class TTreePerfStats; This new class is an important tool to measure the I/O performance of a Tree.; It shows the locations in the file when reading a Tree. In particular it is easy; to see the performance of the Tree Cache. The results can be:. drawn in a canvas.; printed on standard output.; saved to a file for processing later. Example of use; {; TFile *f = TFile::Open(""RelValMinBias-GEN-SIM-RECO.root"");; T = (TTree*)f->Get(""Events"");; Long64_t nentries = T->GetEntries();; T->SetCacheSize(10000000);; T->AddBranchToCache(""*"");. TTreePerfStats *ps= new TTreePerfStats(""ioperf"",T);. for (Int_t i=0;i<nentries;i++) {; T->GetEntry(i);; }; ps->SaveAs(""atlas_perf.root"");; }. then, in a root interactive session, one can do:. root > TFile f(""atlas_perf.root"");; root > ioperf->Draw();; root > ioperf->Print();. The Draw or Print functions print the following information:. TreeCache = TTree cache size in MBytes; N leaves = Number of leaves in the TTree; ReadTotal = Total number of zipped bytes read; ReadUnZip = Total number of unzipped bytes read; ReadCalls = Total number of disk reads; ReadSize = Average read size in KBytes; Readahead = Readahead size in KBytes; Readextra = Readahead overhead in percent; Real Time = Real Time in seconds; CPU Time = CPU Time in seconds; Disk Time = Real Time spent in pure raw disk IO; Disk IO = Raw disk IO speed in MBytes/second; ReadUZRT = Unzipped MBytes per RT second; ReadUZCP = Unipped MBytes per CP second; ReadRT = Zipped MBytes per RT second; ReadCP = Zipped MBytes per CP second. The Figure below shows the result for an original non optimized file when; the Tree Cache is not used. The Figure below shows the result for the above data file written with the; new version of ROOT and when the Tree cache is activated. ",MatchSource.DOCS,tree/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v526/index.html:8925,Performance,cache,cache,8925," file. CASE 3 : autof = 0; The AutoFlush mechanism is disabled. Flushing the buffers at regular intervals optimize the location of; consecutive entries on the disk. Changed the default value of AutoSave from 10 to 30 MBytes. New class TTreePerfStats; This new class is an important tool to measure the I/O performance of a Tree.; It shows the locations in the file when reading a Tree. In particular it is easy; to see the performance of the Tree Cache. The results can be:. drawn in a canvas.; printed on standard output.; saved to a file for processing later. Example of use; {; TFile *f = TFile::Open(""RelValMinBias-GEN-SIM-RECO.root"");; T = (TTree*)f->Get(""Events"");; Long64_t nentries = T->GetEntries();; T->SetCacheSize(10000000);; T->AddBranchToCache(""*"");. TTreePerfStats *ps= new TTreePerfStats(""ioperf"",T);. for (Int_t i=0;i<nentries;i++) {; T->GetEntry(i);; }; ps->SaveAs(""atlas_perf.root"");; }. then, in a root interactive session, one can do:. root > TFile f(""atlas_perf.root"");; root > ioperf->Draw();; root > ioperf->Print();. The Draw or Print functions print the following information:. TreeCache = TTree cache size in MBytes; N leaves = Number of leaves in the TTree; ReadTotal = Total number of zipped bytes read; ReadUnZip = Total number of unzipped bytes read; ReadCalls = Total number of disk reads; ReadSize = Average read size in KBytes; Readahead = Readahead size in KBytes; Readextra = Readahead overhead in percent; Real Time = Real Time in seconds; CPU Time = CPU Time in seconds; Disk Time = Real Time spent in pure raw disk IO; Disk IO = Raw disk IO speed in MBytes/second; ReadUZRT = Unzipped MBytes per RT second; ReadUZCP = Unipped MBytes per CP second; ReadRT = Zipped MBytes per RT second; ReadCP = Zipped MBytes per CP second. The Figure below shows the result for an original non optimized file when; the Tree Cache is not used. The Figure below shows the result for the above data file written with the; new version of ROOT and when the Tree cache is activated. ",MatchSource.DOCS,tree/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v526/index.html:618,Safety,avoid,avoid,618,". Tree. Changed the MaxTreeSize default from 1.9 GBytes to 100 GBytes.; Add new special functions in TTreeFormula (and hence TTree::Draw and TTree::Scan) to calculate the minimun and maximum with an entry:; ; Min$(formula),Max$(formula):return the minimun/maximum (within one TTree entry) of the value of the; elements of the formula given as a parameter.; MinIf$(formula,condition),MaxIf$(formula,condition):return the minimum (maximum) (within one TTree entry); of the value of the elements of the formula given as a parameter; if they match the condition. If not element match the condition, the result is zero. To avoid the; the result is zero. To avoid the consequent peak a zero, use the; pattern:; tree->Draw(""MinIf$(formula,condition)"",""condition"");; which will avoid calculation MinIf$ for the entries that have no match; for the condition. Add support in TTreeFormula (and hence TTree::Draw and TTree::Scan) for the ternary condition operator ( cond ? if_expr : else_expr ).; Significantly (by 2 order of magnitude) improved the performance of TTree::Draw calling C++ functions.; Replace the function TSelectorDraw::MakeIndex and TSelectorDraw::GetNameByIndex; with the function TSelectorDraw::SplitNames. ; Add a return value to SetBranchAddress, a return value greater or equal to zero indicate success, a negative; value indicates failure (in both case, the address is still updated). Example:; if (tree->SetBranchAddress(mybranch,&myvar) < 0) {; cerr << ""Something went wrong\n"";; return;; }; The possible return values are:; kMissingBranch (-5) : Missing branch; kInternalError (-4) : Internal error (could not find the type corresponding to a data type number.; kMissingCompiledCollectionProxy (-3) : Missing compiled collection proxy for a compiled collection.; kMismatch (-2) : Non-Class Pointer type given does not match the type expected by the branch.; kClassMismatch (-1) : Class Pointer type given does not match the type expected by the branch.; kMatch (0) : perfect match.; kM",MatchSource.DOCS,tree/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v526/index.html:652,Safety,avoid,avoid,652,". Tree. Changed the MaxTreeSize default from 1.9 GBytes to 100 GBytes.; Add new special functions in TTreeFormula (and hence TTree::Draw and TTree::Scan) to calculate the minimun and maximum with an entry:; ; Min$(formula),Max$(formula):return the minimun/maximum (within one TTree entry) of the value of the; elements of the formula given as a parameter.; MinIf$(formula,condition),MaxIf$(formula,condition):return the minimum (maximum) (within one TTree entry); of the value of the elements of the formula given as a parameter; if they match the condition. If not element match the condition, the result is zero. To avoid the; the result is zero. To avoid the consequent peak a zero, use the; pattern:; tree->Draw(""MinIf$(formula,condition)"",""condition"");; which will avoid calculation MinIf$ for the entries that have no match; for the condition. Add support in TTreeFormula (and hence TTree::Draw and TTree::Scan) for the ternary condition operator ( cond ? if_expr : else_expr ).; Significantly (by 2 order of magnitude) improved the performance of TTree::Draw calling C++ functions.; Replace the function TSelectorDraw::MakeIndex and TSelectorDraw::GetNameByIndex; with the function TSelectorDraw::SplitNames. ; Add a return value to SetBranchAddress, a return value greater or equal to zero indicate success, a negative; value indicates failure (in both case, the address is still updated). Example:; if (tree->SetBranchAddress(mybranch,&myvar) < 0) {; cerr << ""Something went wrong\n"";; return;; }; The possible return values are:; kMissingBranch (-5) : Missing branch; kInternalError (-4) : Internal error (could not find the type corresponding to a data type number.; kMissingCompiledCollectionProxy (-3) : Missing compiled collection proxy for a compiled collection.; kMismatch (-2) : Non-Class Pointer type given does not match the type expected by the branch.; kClassMismatch (-1) : Class Pointer type given does not match the type expected by the branch.; kMatch (0) : perfect match.; kM",MatchSource.DOCS,tree/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v526/index.html:770,Safety,avoid,avoid,770,". Tree. Changed the MaxTreeSize default from 1.9 GBytes to 100 GBytes.; Add new special functions in TTreeFormula (and hence TTree::Draw and TTree::Scan) to calculate the minimun and maximum with an entry:; ; Min$(formula),Max$(formula):return the minimun/maximum (within one TTree entry) of the value of the; elements of the formula given as a parameter.; MinIf$(formula,condition),MaxIf$(formula,condition):return the minimum (maximum) (within one TTree entry); of the value of the elements of the formula given as a parameter; if they match the condition. If not element match the condition, the result is zero. To avoid the; the result is zero. To avoid the consequent peak a zero, use the; pattern:; tree->Draw(""MinIf$(formula,condition)"",""condition"");; which will avoid calculation MinIf$ for the entries that have no match; for the condition. Add support in TTreeFormula (and hence TTree::Draw and TTree::Scan) for the ternary condition operator ( cond ? if_expr : else_expr ).; Significantly (by 2 order of magnitude) improved the performance of TTree::Draw calling C++ functions.; Replace the function TSelectorDraw::MakeIndex and TSelectorDraw::GetNameByIndex; with the function TSelectorDraw::SplitNames. ; Add a return value to SetBranchAddress, a return value greater or equal to zero indicate success, a negative; value indicates failure (in both case, the address is still updated). Example:; if (tree->SetBranchAddress(mybranch,&myvar) < 0) {; cerr << ""Something went wrong\n"";; return;; }; The possible return values are:; kMissingBranch (-5) : Missing branch; kInternalError (-4) : Internal error (could not find the type corresponding to a data type number.; kMissingCompiledCollectionProxy (-3) : Missing compiled collection proxy for a compiled collection.; kMismatch (-2) : Non-Class Pointer type given does not match the type expected by the branch.; kClassMismatch (-1) : Class Pointer type given does not match the type expected by the branch.; kMatch (0) : perfect match.; kM",MatchSource.DOCS,tree/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v526/index.html:4051,Safety,recover,recoverable,4051,"r) or 'random' (the 'broken' sort order prior to this release). IMPORTANT enhancement in TTree::Fill:; Slides from a recent seminar describing the main features of ROOT IO and Trees and the recent; improvements described below are available at; http://root.cern/files/brun_lcgapp09.pptx ; or; http://root.cern/files/brun_lcgapp09.pdf .; The baskets are flushed and the Tree header saved at regular intervals (See AutoFlush and OptimizeBaskets); When the amount of data written so far (fTotBytes) is greater than fAutoFlush (see SetAutoFlush) all the baskets are flushed to disk.; This makes future reading faster as it guarantees that baskets belonging to nearby entries will be on the same disk region.; When the first call to flush the baskets happens, we also take this opportunity to optimize the baskets buffers.; We also check if the number of bytes written is greater than fAutoSave (see SetAutoSave).; In this case we also write the Tree header. This makes the Tree recoverable up to this point in case the program writing the Tree crashes.; Note that the user can also decide to call FlushBaskets and AutoSave in her event loop on the base of the number of events written instead of the number of bytes written.; New function TTree::OptimizeBaskets. void TTree::OptimizeBaskets(Int_t maxMemory, Float_t minComp, Option_t *option). This function may be called after having filled some entries in a Tree; using the information in the existing branch buffers, it will reassign; new branch buffer sizes to optimize time and memory.; The function computes the best values for branch buffer sizes such that; the total buffer sizes is less than maxMemory and nearby entries written; at the same time.; In case the branch compression factor for the data written so far is less; than compMin, the compression is disabled. if option =""d"" an analysis report is printed.; This function may also be called on an existing Tree to figure out the best values; given the information in the Tree header. TFile ",MatchSource.DOCS,tree/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v526/index.html:5948,Testability,log,logic,5948,"e best values; given the information in the Tree header. TFile f(""myfile.root"");; TTree *T = (TTree*)f.Get(""mytreename"");; T->Print(); //show the branch buffer sizes before optimization; T->OptimizeBaskets(10000000,1,""d"");; T->Print(); //show the branch buffer sizes after optimization. New interface functions to customize the TreeCache; virtual void AddBranchToCache(const char *bname, Bool_t subbranches = kFALSE);; virtual void AddBranchToCache(TBranch *branch, Bool_t subbranches = kFALSE);; virtual void PrintCacheStats(Option_t* option = """") const;; virtual void SetParallelUnzip(Bool_t opt=kTRUE);; virtual void SetCacheEntryRange(Long64_t first, Long64_t last);; virtual void SetCacheLearnEntries(Int_t n=10);; virtual void StopCacheLearningPhase();; New functionality AutoFlush (and changes to AutoSave). Implement a new member fAutoFlush in TTree with its getter and setter:. void TTree::SetAutoFlush(Long64_t autof). The logic of the AutoFlush mechanism is optimized such that the TreeCache; will read always up to the point where FlushBaskets has been called.; This minimizes the number of cases where one has to seek backward when reading. This function may be called at the start of a program to change; the default value for fAutoFlush. CASE 1 : autof > 0. autof is the number of consecutive entries after which TTree::Fill will; flush all branch buffers to disk. CASE 2 : autof < 0. When filling the Tree the branch buffers will be flushed to disk when; more than autof bytes have been written to the file. At the first FlushBaskets; TTree::Fill will replace fAutoFlush by the current value of fEntries. Calling this function with autof < 0 is interesting when it is hard to estimate; the size of one entry. This value is also independent of the Tree. When calling SetAutoFlush with no arguments, the; default value is -30000000, ie that the first AutoFlush will be done when; 30 MBytes of data are written to the file. CASE 3 : autof = 0; The AutoFlush mechanism is disabled. Flushi",MatchSource.DOCS,tree/doc/v526/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v526/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v528/index.html:1172,Availability,failure,failure,1172,"ion appropriately (to and from; the MakeClass mode (also known as the decomposed object mode)). This can also be; used to reset the mode of some branch with a MakeClass/MakeSelector file. Dramatically reduce the amount of memory allocation induces by the management of the TBasket and TBuffer; for each branch. Instead of creating one TBasket object and one TBuffer object and its associated memory buffer; for each onfile basket of each branch, we now create only one TBasket and one TBuffer object for the lifetime of; each branch. The memory buffer associated with the TBuffer object is also created once and rarely reallocated;; it is reallocated only when the buffer size is reset (for example by the AutoFlush mechanism) and when the user; object do not fit in the currently allocated memory (but we do not shrink it after that. The same minization; is applied to the scratch area used to read the compressed version of a basket from the file.; In TTree and TChain's LoadTree fReadEntry is now set to -1 in case of failure to find the proper row.; In TTree::CloneTree, TChain::Merge and TTree::CopyEntries introduces more flexibility; in the handling of the case where a TTreeIndex is 'missing' in one or more of the; TTree objects being collated. If the tree or any of the underlying tree of the chain has an index,; that index and any index in the subsequent underlying TTree objects will be merged. There are currently three 'options'; to control this merging:; ; NoIndex : all the TTreeIndex object are dropped.; DropIndexOnError : if any of the underlying TTree object do no have a TTreeIndex,; they are all dropped.; AsIsIndexOnError [default]: In case of missing TTreeIndex, the resulting TTree index has gaps.; BuildIndexOnError : If any of the underlying TTree object do no have a TTreeIndex,; all TTreeIndex are 'ignored' and the mising piece are rebuilt. Previously the index were kept only if the first files had an index and if there was any missing index,; the resulting index had ",MatchSource.DOCS,tree/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v528/index.html:6719,Availability,avail,available,6719,"20 : Total Size= 582 bytes File Size = 92 *; *Baskets : 1 : Basket Size= 16000 bytes Compression= 1.00 *. Add a new function TBranch::SetStatus It is much faster to call this function in case of a Tree with many branches; instead of calling TTree::SetBranchStatus.; Implement TTreeCache::Print that shows information like:; // ******TreeCache statistics for file: cms2.root ******; // Number of branches in the cache ...: 1093; // Cache Efficiency ..................: 0.997372; // Cache Efficiency Rel...............: 1.000000; // Learn entries......................: 100; // Reading............................: 72761843 bytes in 7 transactions; // Readahead..........................: 256000 bytes with overhead = 0 bytes; // Average transaction................: 10394.549000 Kbytes; // Number of blocks in current cache..: 210, total size: 6280352; This function can be called directly from TTree: T->PrintCacheStats();. Add support for variable size array of object in a TTree (when the owner of the array is split.); And many other bug fixes, security fixes, thread safety and performance improvements ; see the svn log for details. TTree Scan and Draw. Insured that the generated histogram as an integral bin width when plotting a string or integer.; Improved the output of TTree::Scan by inserting a blank space whenever a value is not available because there is no proper row in a friend.; (Previously it was re-printing the previous value). This required changes in ; When the draw option to TTree::Draw contains ""norm"" the output histogram is normalized to 1.; Improve the selection of the leaf used for size of an array in a leaflist by giving preference; for the leaf inside the same branch and by adding support for explicit full path name. For example the following now works properly:; tree->Branch(""JET1"", &JET1, ""njets/I:et[njets]/F:pt[njets]/F"");; tree->BranchBranch(""JET2"", &JET2, ""njets/I:et[njets]/F:pt[njets]/F"");; ...; tree->Scan(""njets/I:et[JETS1.njets]/F:pt[JETS1.njets]"");. ",MatchSource.DOCS,tree/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v528/index.html:352,Energy Efficiency,reduce,reduce,352,". Tree. Introduce TBranch::Set/GetMakeClass to independently set each branch in MakeClass mode; and to have a good place to switch the ReadLeaves function appropriately (to and from; the MakeClass mode (also known as the decomposed object mode)). This can also be; used to reset the mode of some branch with a MakeClass/MakeSelector file. Dramatically reduce the amount of memory allocation induces by the management of the TBasket and TBuffer; for each branch. Instead of creating one TBasket object and one TBuffer object and its associated memory buffer; for each onfile basket of each branch, we now create only one TBasket and one TBuffer object for the lifetime of; each branch. The memory buffer associated with the TBuffer object is also created once and rarely reallocated;; it is reallocated only when the buffer size is reset (for example by the AutoFlush mechanism) and when the user; object do not fit in the currently allocated memory (but we do not shrink it after that. The same minization; is applied to the scratch area used to read the compressed version of a basket from the file.; In TTree and TChain's LoadTree fReadEntry is now set to -1 in case of failure to find the proper row.; In TTree::CloneTree, TChain::Merge and TTree::CopyEntries introduces more flexibility; in the handling of the case where a TTreeIndex is 'missing' in one or more of the; TTree objects being collated. If the tree or any of the underlying tree of the chain has an index,; that index and any index in the subsequent underlying TTree objects will be merged. There are currently three 'options'; to control this merging:; ; NoIndex : all the TTreeIndex object are dropped.; DropIndexOnError : if any of the underlying TTree object do no have a TTreeIndex,; they are all dropped.; AsIsIndexOnError [default]: In case of missing TTreeIndex, the resulting TTree index has gaps.; BuildIndexOnError : If any of the underlying TTree object do no have a TTreeIndex,; all TTreeIndex are 'ignored' and the misi",MatchSource.DOCS,tree/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v528/index.html:932,Energy Efficiency,allocate,allocated,932,". Tree. Introduce TBranch::Set/GetMakeClass to independently set each branch in MakeClass mode; and to have a good place to switch the ReadLeaves function appropriately (to and from; the MakeClass mode (also known as the decomposed object mode)). This can also be; used to reset the mode of some branch with a MakeClass/MakeSelector file. Dramatically reduce the amount of memory allocation induces by the management of the TBasket and TBuffer; for each branch. Instead of creating one TBasket object and one TBuffer object and its associated memory buffer; for each onfile basket of each branch, we now create only one TBasket and one TBuffer object for the lifetime of; each branch. The memory buffer associated with the TBuffer object is also created once and rarely reallocated;; it is reallocated only when the buffer size is reset (for example by the AutoFlush mechanism) and when the user; object do not fit in the currently allocated memory (but we do not shrink it after that. The same minization; is applied to the scratch area used to read the compressed version of a basket from the file.; In TTree and TChain's LoadTree fReadEntry is now set to -1 in case of failure to find the proper row.; In TTree::CloneTree, TChain::Merge and TTree::CopyEntries introduces more flexibility; in the handling of the case where a TTreeIndex is 'missing' in one or more of the; TTree objects being collated. If the tree or any of the underlying tree of the chain has an index,; that index and any index in the subsequent underlying TTree objects will be merged. There are currently three 'options'; to control this merging:; ; NoIndex : all the TTreeIndex object are dropped.; DropIndexOnError : if any of the underlying TTree object do no have a TTreeIndex,; they are all dropped.; AsIsIndexOnError [default]: In case of missing TTreeIndex, the resulting TTree index has gaps.; BuildIndexOnError : If any of the underlying TTree object do no have a TTreeIndex,; all TTreeIndex are 'ignored' and the misi",MatchSource.DOCS,tree/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v528/index.html:2591,Energy Efficiency,allocate,allocated,2591,"ntrol this merging:; ; NoIndex : all the TTreeIndex object are dropped.; DropIndexOnError : if any of the underlying TTree object do no have a TTreeIndex,; they are all dropped.; AsIsIndexOnError [default]: In case of missing TTreeIndex, the resulting TTree index has gaps.; BuildIndexOnError : If any of the underlying TTree object do no have a TTreeIndex,; all TTreeIndex are 'ignored' and the mising piece are rebuilt. Previously the index were kept only if the first files had an index and if there was any missing index,; the resulting index had gaps (the default was similar to AsIsIndexOnError). The new default is BuildIndexOnError ; i.e.; we now attempt by default to build the missing indices. In TBranch CopyAddress (and hence indirectly in the fast cloning); avoid having to read the first entry just to get the address set; and do the address setting directly. In TTree::CopyAddress when copying the addresses of a branch created by a leaflist; and where the memory buffer was allocated automatically (as opposed to set by the user); avoid deleting the memory allocated by the tree each time CopyAddress is called.; (This effectively prevented cloning more than once a TTree with a branch created by a leaflist.). Warning: The TTreeCache is no longer enabled by default in a TChain to align the behavior with a TTree. You need to call; TTree::SetCacheSize to enable the TTreeCache.; Correct and clarify the relationship between AutoFlush and AutoSave:; ; Both the AutoFlush and AutoSave interval can be specified in; terms of bytes (a negative value for fAutoFlush or fAutoSave); or in terms of the number of entries (positive values).; An AutoFlush is always done with an AutoSave.; If the interval specified for AutoSave is less than that for; AutoFlush, the AutoSave interval is used for both.; If the AutoFlush interval is less than the AutoSave interval,; the AutoSave interval is adjusted to the largest integer; multiple of the AutoFlush interval that is less than or equal; to th",MatchSource.DOCS,tree/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v528/index.html:2674,Energy Efficiency,allocate,allocated,2674,"ntrol this merging:; ; NoIndex : all the TTreeIndex object are dropped.; DropIndexOnError : if any of the underlying TTree object do no have a TTreeIndex,; they are all dropped.; AsIsIndexOnError [default]: In case of missing TTreeIndex, the resulting TTree index has gaps.; BuildIndexOnError : If any of the underlying TTree object do no have a TTreeIndex,; all TTreeIndex are 'ignored' and the mising piece are rebuilt. Previously the index were kept only if the first files had an index and if there was any missing index,; the resulting index had gaps (the default was similar to AsIsIndexOnError). The new default is BuildIndexOnError ; i.e.; we now attempt by default to build the missing indices. In TBranch CopyAddress (and hence indirectly in the fast cloning); avoid having to read the first entry just to get the address set; and do the address setting directly. In TTree::CopyAddress when copying the addresses of a branch created by a leaflist; and where the memory buffer was allocated automatically (as opposed to set by the user); avoid deleting the memory allocated by the tree each time CopyAddress is called.; (This effectively prevented cloning more than once a TTree with a branch created by a leaflist.). Warning: The TTreeCache is no longer enabled by default in a TChain to align the behavior with a TTree. You need to call; TTree::SetCacheSize to enable the TTreeCache.; Correct and clarify the relationship between AutoFlush and AutoSave:; ; Both the AutoFlush and AutoSave interval can be specified in; terms of bytes (a negative value for fAutoFlush or fAutoSave); or in terms of the number of entries (positive values).; An AutoFlush is always done with an AutoSave.; If the interval specified for AutoSave is less than that for; AutoFlush, the AutoSave interval is used for both.; If the AutoFlush interval is less than the AutoSave interval,; the AutoSave interval is adjusted to the largest integer; multiple of the AutoFlush interval that is less than or equal; to th",MatchSource.DOCS,tree/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v528/index.html:4008,Integrability,depend,depending,4008,"in to align the behavior with a TTree. You need to call; TTree::SetCacheSize to enable the TTreeCache.; Correct and clarify the relationship between AutoFlush and AutoSave:; ; Both the AutoFlush and AutoSave interval can be specified in; terms of bytes (a negative value for fAutoFlush or fAutoSave); or in terms of the number of entries (positive values).; An AutoFlush is always done with an AutoSave.; If the interval specified for AutoSave is less than that for; AutoFlush, the AutoSave interval is used for both.; If the AutoFlush interval is less than the AutoSave interval,; the AutoSave interval is adjusted to the largest integer; multiple of the AutoFlush interval that is less than or equal; to the original value of the AutoSave interval. Update MakeProxy so that the resulting skeleton is useable with Proof.; Update MakeProxy, MakeClass and MakeSelector to support more cases of branches names (that includes characters illegal in a C++ symbol); Replace the ReadLeaves virtual function by a fReadLeaves pointer to member function,; this allows the customization of the ReadLeaves function at run-time depending on the; underlying user class layout in TBranchElement. This removes many if statements whose; 'answer' is known at initialization time. Add support for 'array' formula in TTree::Query.; Set the initial value of fCacheSize to zero to indicate clearly that the TreeCache is disabled.; In TChain::SetEntryList use only the treename to lookup the (sub)entryList (instead subdir/treename).; Add support for the branch creation syntax:; TString rootString;; t->Branch(""rootString"",""TString"",&rootString, 1600, 0);; which is 'natural' as it uses the legacy syntax (branch_name,class_name, user_data); but did not work because 'rootString' is an object rather than a pointer to an; object. (However the simplier form:; t->Branch(""rootString"",&rootString, 1600, 0);; works/worked fine). Add type information to the result of TTree::Print in the case of; TBranchElement:; *Br 17 :fH : ",MatchSource.DOCS,tree/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v528/index.html:6316,Modifiability,variab,variable,6316,"Valid : Bool_t *; *Entries : 20 : Total Size= 582 bytes File Size = 92 *; *Baskets : 1 : Basket Size= 16000 bytes Compression= 1.00 *. Add a new function TBranch::SetStatus It is much faster to call this function in case of a Tree with many branches; instead of calling TTree::SetBranchStatus.; Implement TTreeCache::Print that shows information like:; // ******TreeCache statistics for file: cms2.root ******; // Number of branches in the cache ...: 1093; // Cache Efficiency ..................: 0.997372; // Cache Efficiency Rel...............: 1.000000; // Learn entries......................: 100; // Reading............................: 72761843 bytes in 7 transactions; // Readahead..........................: 256000 bytes with overhead = 0 bytes; // Average transaction................: 10394.549000 Kbytes; // Number of blocks in current cache..: 210, total size: 6280352; This function can be called directly from TTree: T->PrintCacheStats();. Add support for variable size array of object in a TTree (when the owner of the array is split.); And many other bug fixes, security fixes, thread safety and performance improvements ; see the svn log for details. TTree Scan and Draw. Insured that the generated histogram as an integral bin width when plotting a string or integer.; Improved the output of TTree::Scan by inserting a blank space whenever a value is not available because there is no proper row in a friend.; (Previously it was re-printing the previous value). This required changes in ; When the draw option to TTree::Draw contains ""norm"" the output histogram is normalized to 1.; Improve the selection of the leaf used for size of an array in a leaflist by giving preference; for the leaf inside the same branch and by adding support for explicit full path name. For example the following now works properly:; tree->Branch(""JET1"", &JET1, ""njets/I:et[njets]/F:pt[njets]/F"");; tree->BranchBranch(""JET2"", &JET2, ""njets/I:et[njets]/F:pt[njets]/F"");; ...; tree->Scan(""njets/I:et[JETS1.",MatchSource.DOCS,tree/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v528/index.html:5787,Performance,cache,cache,5787,"0, 0);; works/worked fine). Add type information to the result of TTree::Print in the case of; TBranchElement:; *Br 17 :fH : TH1F* *; *Entries : 20 : Total Size= 19334 bytes File Size = 1671 *; *Baskets : 2 : Basket Size= 16000 bytes Compression= 11.29 *; *............................................................................*; *Br 18 :fTriggerBits : TBits *; *Entries : 20 : Total Size= 1398 bytes File Size = 400 *; *Baskets : 1 : Basket Size= 16000 bytes Compression= 2.23 *; *............................................................................*; *Br 19 :fIsValid : Bool_t *; *Entries : 20 : Total Size= 582 bytes File Size = 92 *; *Baskets : 1 : Basket Size= 16000 bytes Compression= 1.00 *. Add a new function TBranch::SetStatus It is much faster to call this function in case of a Tree with many branches; instead of calling TTree::SetBranchStatus.; Implement TTreeCache::Print that shows information like:; // ******TreeCache statistics for file: cms2.root ******; // Number of branches in the cache ...: 1093; // Cache Efficiency ..................: 0.997372; // Cache Efficiency Rel...............: 1.000000; // Learn entries......................: 100; // Reading............................: 72761843 bytes in 7 transactions; // Readahead..........................: 256000 bytes with overhead = 0 bytes; // Average transaction................: 10394.549000 Kbytes; // Number of blocks in current cache..: 210, total size: 6280352; This function can be called directly from TTree: T->PrintCacheStats();. Add support for variable size array of object in a TTree (when the owner of the array is split.); And many other bug fixes, security fixes, thread safety and performance improvements ; see the svn log for details. TTree Scan and Draw. Insured that the generated histogram as an integral bin width when plotting a string or integer.; Improved the output of TTree::Scan by inserting a blank space whenever a value is not available because there is no proper row in a frien",MatchSource.DOCS,tree/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v528/index.html:6193,Performance,cache,cache,6193,"es File Size = 400 *; *Baskets : 1 : Basket Size= 16000 bytes Compression= 2.23 *; *............................................................................*; *Br 19 :fIsValid : Bool_t *; *Entries : 20 : Total Size= 582 bytes File Size = 92 *; *Baskets : 1 : Basket Size= 16000 bytes Compression= 1.00 *. Add a new function TBranch::SetStatus It is much faster to call this function in case of a Tree with many branches; instead of calling TTree::SetBranchStatus.; Implement TTreeCache::Print that shows information like:; // ******TreeCache statistics for file: cms2.root ******; // Number of branches in the cache ...: 1093; // Cache Efficiency ..................: 0.997372; // Cache Efficiency Rel...............: 1.000000; // Learn entries......................: 100; // Reading............................: 72761843 bytes in 7 transactions; // Readahead..........................: 256000 bytes with overhead = 0 bytes; // Average transaction................: 10394.549000 Kbytes; // Number of blocks in current cache..: 210, total size: 6280352; This function can be called directly from TTree: T->PrintCacheStats();. Add support for variable size array of object in a TTree (when the owner of the array is split.); And many other bug fixes, security fixes, thread safety and performance improvements ; see the svn log for details. TTree Scan and Draw. Insured that the generated histogram as an integral bin width when plotting a string or integer.; Improved the output of TTree::Scan by inserting a blank space whenever a value is not available because there is no proper row in a friend.; (Previously it was re-printing the previous value). This required changes in ; When the draw option to TTree::Draw contains ""norm"" the output histogram is normalized to 1.; Improve the selection of the leaf used for size of an array in a leaflist by giving preference; for the leaf inside the same branch and by adding support for explicit full path name. For example the following now works properl",MatchSource.DOCS,tree/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v528/index.html:6458,Performance,perform,performance,6458,"20 : Total Size= 582 bytes File Size = 92 *; *Baskets : 1 : Basket Size= 16000 bytes Compression= 1.00 *. Add a new function TBranch::SetStatus It is much faster to call this function in case of a Tree with many branches; instead of calling TTree::SetBranchStatus.; Implement TTreeCache::Print that shows information like:; // ******TreeCache statistics for file: cms2.root ******; // Number of branches in the cache ...: 1093; // Cache Efficiency ..................: 0.997372; // Cache Efficiency Rel...............: 1.000000; // Learn entries......................: 100; // Reading............................: 72761843 bytes in 7 transactions; // Readahead..........................: 256000 bytes with overhead = 0 bytes; // Average transaction................: 10394.549000 Kbytes; // Number of blocks in current cache..: 210, total size: 6280352; This function can be called directly from TTree: T->PrintCacheStats();. Add support for variable size array of object in a TTree (when the owner of the array is split.); And many other bug fixes, security fixes, thread safety and performance improvements ; see the svn log for details. TTree Scan and Draw. Insured that the generated histogram as an integral bin width when plotting a string or integer.; Improved the output of TTree::Scan by inserting a blank space whenever a value is not available because there is no proper row in a friend.; (Previously it was re-printing the previous value). This required changes in ; When the draw option to TTree::Draw contains ""norm"" the output histogram is normalized to 1.; Improve the selection of the leaf used for size of an array in a leaflist by giving preference; for the leaf inside the same branch and by adding support for explicit full path name. For example the following now works properly:; tree->Branch(""JET1"", &JET1, ""njets/I:et[njets]/F:pt[njets]/F"");; tree->BranchBranch(""JET2"", &JET2, ""njets/I:et[njets]/F:pt[njets]/F"");; ...; tree->Scan(""njets/I:et[JETS1.njets]/F:pt[JETS1.njets]"");. ",MatchSource.DOCS,tree/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v528/index.html:2372,Safety,avoid,avoid,2372,"being collated. If the tree or any of the underlying tree of the chain has an index,; that index and any index in the subsequent underlying TTree objects will be merged. There are currently three 'options'; to control this merging:; ; NoIndex : all the TTreeIndex object are dropped.; DropIndexOnError : if any of the underlying TTree object do no have a TTreeIndex,; they are all dropped.; AsIsIndexOnError [default]: In case of missing TTreeIndex, the resulting TTree index has gaps.; BuildIndexOnError : If any of the underlying TTree object do no have a TTreeIndex,; all TTreeIndex are 'ignored' and the mising piece are rebuilt. Previously the index were kept only if the first files had an index and if there was any missing index,; the resulting index had gaps (the default was similar to AsIsIndexOnError). The new default is BuildIndexOnError ; i.e.; we now attempt by default to build the missing indices. In TBranch CopyAddress (and hence indirectly in the fast cloning); avoid having to read the first entry just to get the address set; and do the address setting directly. In TTree::CopyAddress when copying the addresses of a branch created by a leaflist; and where the memory buffer was allocated automatically (as opposed to set by the user); avoid deleting the memory allocated by the tree each time CopyAddress is called.; (This effectively prevented cloning more than once a TTree with a branch created by a leaflist.). Warning: The TTreeCache is no longer enabled by default in a TChain to align the behavior with a TTree. You need to call; TTree::SetCacheSize to enable the TTreeCache.; Correct and clarify the relationship between AutoFlush and AutoSave:; ; Both the AutoFlush and AutoSave interval can be specified in; terms of bytes (a negative value for fAutoFlush or fAutoSave); or in terms of the number of entries (positive values).; An AutoFlush is always done with an AutoSave.; If the interval specified for AutoSave is less than that for; AutoFlush, the AutoSave inter",MatchSource.DOCS,tree/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v528/index.html:2648,Safety,avoid,avoid,2648,"ntrol this merging:; ; NoIndex : all the TTreeIndex object are dropped.; DropIndexOnError : if any of the underlying TTree object do no have a TTreeIndex,; they are all dropped.; AsIsIndexOnError [default]: In case of missing TTreeIndex, the resulting TTree index has gaps.; BuildIndexOnError : If any of the underlying TTree object do no have a TTreeIndex,; all TTreeIndex are 'ignored' and the mising piece are rebuilt. Previously the index were kept only if the first files had an index and if there was any missing index,; the resulting index had gaps (the default was similar to AsIsIndexOnError). The new default is BuildIndexOnError ; i.e.; we now attempt by default to build the missing indices. In TBranch CopyAddress (and hence indirectly in the fast cloning); avoid having to read the first entry just to get the address set; and do the address setting directly. In TTree::CopyAddress when copying the addresses of a branch created by a leaflist; and where the memory buffer was allocated automatically (as opposed to set by the user); avoid deleting the memory allocated by the tree each time CopyAddress is called.; (This effectively prevented cloning more than once a TTree with a branch created by a leaflist.). Warning: The TTreeCache is no longer enabled by default in a TChain to align the behavior with a TTree. You need to call; TTree::SetCacheSize to enable the TTreeCache.; Correct and clarify the relationship between AutoFlush and AutoSave:; ; Both the AutoFlush and AutoSave interval can be specified in; terms of bytes (a negative value for fAutoFlush or fAutoSave); or in terms of the number of entries (positive values).; An AutoFlush is always done with an AutoSave.; If the interval specified for AutoSave is less than that for; AutoFlush, the AutoSave interval is used for both.; If the AutoFlush interval is less than the AutoSave interval,; the AutoSave interval is adjusted to the largest integer; multiple of the AutoFlush interval that is less than or equal; to th",MatchSource.DOCS,tree/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v528/index.html:6447,Safety,safe,safety,6447,"20 : Total Size= 582 bytes File Size = 92 *; *Baskets : 1 : Basket Size= 16000 bytes Compression= 1.00 *. Add a new function TBranch::SetStatus It is much faster to call this function in case of a Tree with many branches; instead of calling TTree::SetBranchStatus.; Implement TTreeCache::Print that shows information like:; // ******TreeCache statistics for file: cms2.root ******; // Number of branches in the cache ...: 1093; // Cache Efficiency ..................: 0.997372; // Cache Efficiency Rel...............: 1.000000; // Learn entries......................: 100; // Reading............................: 72761843 bytes in 7 transactions; // Readahead..........................: 256000 bytes with overhead = 0 bytes; // Average transaction................: 10394.549000 Kbytes; // Number of blocks in current cache..: 210, total size: 6280352; This function can be called directly from TTree: T->PrintCacheStats();. Add support for variable size array of object in a TTree (when the owner of the array is split.); And many other bug fixes, security fixes, thread safety and performance improvements ; see the svn log for details. TTree Scan and Draw. Insured that the generated histogram as an integral bin width when plotting a string or integer.; Improved the output of TTree::Scan by inserting a blank space whenever a value is not available because there is no proper row in a friend.; (Previously it was re-printing the previous value). This required changes in ; When the draw option to TTree::Draw contains ""norm"" the output histogram is normalized to 1.; Improve the selection of the leaf used for size of an array in a leaflist by giving preference; for the leaf inside the same branch and by adding support for explicit full path name. For example the following now works properly:; tree->Branch(""JET1"", &JET1, ""njets/I:et[njets]/F:pt[njets]/F"");; tree->BranchBranch(""JET2"", &JET2, ""njets/I:et[njets]/F:pt[njets]/F"");; ...; tree->Scan(""njets/I:et[JETS1.njets]/F:pt[JETS1.njets]"");. ",MatchSource.DOCS,tree/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v528/index.html:6424,Security,secur,security,6424,"20 : Total Size= 582 bytes File Size = 92 *; *Baskets : 1 : Basket Size= 16000 bytes Compression= 1.00 *. Add a new function TBranch::SetStatus It is much faster to call this function in case of a Tree with many branches; instead of calling TTree::SetBranchStatus.; Implement TTreeCache::Print that shows information like:; // ******TreeCache statistics for file: cms2.root ******; // Number of branches in the cache ...: 1093; // Cache Efficiency ..................: 0.997372; // Cache Efficiency Rel...............: 1.000000; // Learn entries......................: 100; // Reading............................: 72761843 bytes in 7 transactions; // Readahead..........................: 256000 bytes with overhead = 0 bytes; // Average transaction................: 10394.549000 Kbytes; // Number of blocks in current cache..: 210, total size: 6280352; This function can be called directly from TTree: T->PrintCacheStats();. Add support for variable size array of object in a TTree (when the owner of the array is split.); And many other bug fixes, security fixes, thread safety and performance improvements ; see the svn log for details. TTree Scan and Draw. Insured that the generated histogram as an integral bin width when plotting a string or integer.; Improved the output of TTree::Scan by inserting a blank space whenever a value is not available because there is no proper row in a friend.; (Previously it was re-printing the previous value). This required changes in ; When the draw option to TTree::Draw contains ""norm"" the output histogram is normalized to 1.; Improve the selection of the leaf used for size of an array in a leaflist by giving preference; for the leaf inside the same branch and by adding support for explicit full path name. For example the following now works properly:; tree->Branch(""JET1"", &JET1, ""njets/I:et[njets]/F:pt[njets]/F"");; tree->BranchBranch(""JET2"", &JET2, ""njets/I:et[njets]/F:pt[njets]/F"");; ...; tree->Scan(""njets/I:et[JETS1.njets]/F:pt[JETS1.njets]"");. ",MatchSource.DOCS,tree/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v528/index.html:6497,Testability,log,log,6497,"20 : Total Size= 582 bytes File Size = 92 *; *Baskets : 1 : Basket Size= 16000 bytes Compression= 1.00 *. Add a new function TBranch::SetStatus It is much faster to call this function in case of a Tree with many branches; instead of calling TTree::SetBranchStatus.; Implement TTreeCache::Print that shows information like:; // ******TreeCache statistics for file: cms2.root ******; // Number of branches in the cache ...: 1093; // Cache Efficiency ..................: 0.997372; // Cache Efficiency Rel...............: 1.000000; // Learn entries......................: 100; // Reading............................: 72761843 bytes in 7 transactions; // Readahead..........................: 256000 bytes with overhead = 0 bytes; // Average transaction................: 10394.549000 Kbytes; // Number of blocks in current cache..: 210, total size: 6280352; This function can be called directly from TTree: T->PrintCacheStats();. Add support for variable size array of object in a TTree (when the owner of the array is split.); And many other bug fixes, security fixes, thread safety and performance improvements ; see the svn log for details. TTree Scan and Draw. Insured that the generated histogram as an integral bin width when plotting a string or integer.; Improved the output of TTree::Scan by inserting a blank space whenever a value is not available because there is no proper row in a friend.; (Previously it was re-printing the previous value). This required changes in ; When the draw option to TTree::Draw contains ""norm"" the output histogram is normalized to 1.; Improve the selection of the leaf used for size of an array in a leaflist by giving preference; for the leaf inside the same branch and by adding support for explicit full path name. For example the following now works properly:; tree->Branch(""JET1"", &JET1, ""njets/I:et[njets]/F:pt[njets]/F"");; tree->BranchBranch(""JET2"", &JET2, ""njets/I:et[njets]/F:pt[njets]/F"");; ...; tree->Scan(""njets/I:et[JETS1.njets]/F:pt[JETS1.njets]"");. ",MatchSource.DOCS,tree/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v528/index.html:4261,Usability,clear,clearly,4261,"An AutoFlush is always done with an AutoSave.; If the interval specified for AutoSave is less than that for; AutoFlush, the AutoSave interval is used for both.; If the AutoFlush interval is less than the AutoSave interval,; the AutoSave interval is adjusted to the largest integer; multiple of the AutoFlush interval that is less than or equal; to the original value of the AutoSave interval. Update MakeProxy so that the resulting skeleton is useable with Proof.; Update MakeProxy, MakeClass and MakeSelector to support more cases of branches names (that includes characters illegal in a C++ symbol); Replace the ReadLeaves virtual function by a fReadLeaves pointer to member function,; this allows the customization of the ReadLeaves function at run-time depending on the; underlying user class layout in TBranchElement. This removes many if statements whose; 'answer' is known at initialization time. Add support for 'array' formula in TTree::Query.; Set the initial value of fCacheSize to zero to indicate clearly that the TreeCache is disabled.; In TChain::SetEntryList use only the treename to lookup the (sub)entryList (instead subdir/treename).; Add support for the branch creation syntax:; TString rootString;; t->Branch(""rootString"",""TString"",&rootString, 1600, 0);; which is 'natural' as it uses the legacy syntax (branch_name,class_name, user_data); but did not work because 'rootString' is an object rather than a pointer to an; object. (However the simplier form:; t->Branch(""rootString"",&rootString, 1600, 0);; works/worked fine). Add type information to the result of TTree::Print in the case of; TBranchElement:; *Br 17 :fH : TH1F* *; *Entries : 20 : Total Size= 19334 bytes File Size = 1671 *; *Baskets : 2 : Basket Size= 16000 bytes Compression= 11.29 *; *............................................................................*; *Br 18 :fTriggerBits : TBits *; *Entries : 20 : Total Size= 1398 bytes File Size = 400 *; *Baskets : 1 : Basket Size= 16000 bytes Compression= 2.23",MatchSource.DOCS,tree/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v528/index.html:4714,Usability,simpl,simplier,4714,"MakeSelector to support more cases of branches names (that includes characters illegal in a C++ symbol); Replace the ReadLeaves virtual function by a fReadLeaves pointer to member function,; this allows the customization of the ReadLeaves function at run-time depending on the; underlying user class layout in TBranchElement. This removes many if statements whose; 'answer' is known at initialization time. Add support for 'array' formula in TTree::Query.; Set the initial value of fCacheSize to zero to indicate clearly that the TreeCache is disabled.; In TChain::SetEntryList use only the treename to lookup the (sub)entryList (instead subdir/treename).; Add support for the branch creation syntax:; TString rootString;; t->Branch(""rootString"",""TString"",&rootString, 1600, 0);; which is 'natural' as it uses the legacy syntax (branch_name,class_name, user_data); but did not work because 'rootString' is an object rather than a pointer to an; object. (However the simplier form:; t->Branch(""rootString"",&rootString, 1600, 0);; works/worked fine). Add type information to the result of TTree::Print in the case of; TBranchElement:; *Br 17 :fH : TH1F* *; *Entries : 20 : Total Size= 19334 bytes File Size = 1671 *; *Baskets : 2 : Basket Size= 16000 bytes Compression= 11.29 *; *............................................................................*; *Br 18 :fTriggerBits : TBits *; *Entries : 20 : Total Size= 1398 bytes File Size = 400 *; *Baskets : 1 : Basket Size= 16000 bytes Compression= 2.23 *; *............................................................................*; *Br 19 :fIsValid : Bool_t *; *Entries : 20 : Total Size= 582 bytes File Size = 92 *; *Baskets : 1 : Basket Size= 16000 bytes Compression= 1.00 *. Add a new function TBranch::SetStatus It is much faster to call this function in case of a Tree with many branches; instead of calling TTree::SetBranchStatus.; Implement TTreeCache::Print that shows information like:; // ******TreeCache statistics for file: cms2.roo",MatchSource.DOCS,tree/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v530/index.html:1111,Energy Efficiency,reduce,reduced,1111,"ee::TClusterIterator (i.e. this replaces += fAutoFlush):. TTree::TClusterIterator clusterIter = tree->GetClusterIterator(which_entry_to_start_from);; Long64_t clusterStart;; while( (clusterStart = clusterIter()) < tree-<GetEntries()) {; printf(""The cluster starts at %lld and ends at %lld\n"",clusterStart,clusterIter.GetNextEntry()-1);; }; See TTreeCache::FillBuffer for a concrete usage example. Significant improvement of the performance of SetBranchAddress/SetAddress (by a factor 3 to 10 depending on the length/complexity of the classname).; Prevent the unlimited growth of the TBasket's buffer even if the basket is reused.; When the basket is Reset (this happens when it is written and will be reused),; if the TBuffer size is greater than. - twice the data in the current basket; and - twice the average data in each basket (of this branch); and - twice the requeste basket size (TBranch::GetBasketSize).; the size of the buffer is reduced to the max of; 'the data in the current basket' and 'the average' and the requested; buffer size and aligned to next highest multiple of 512.; In TBranchRef distinguish between the entry we need (now called RequestedEntry) and the; entry we have read (fReadEntry) so that we can avoid re-reading the same entry too many; times when executing TRef::GetObject.; Reduce by 40% the time taken GetEntry for a branch created using a leaflist (exclusive of the decompression time).; Introduce TVirtualPerfStats::FileUnzipEvent to be able to keep track of the cost of unzipping and use this in TTreePerfStats and TBasket ... This give a good picture of where the time in unzip or in unstreaming; Add more clusters to the TTreeCache buffer until fBufferMinSize is hit to avoid severely underfilled buffer when; a low number of branches is selected/used.; When reading backwards, make sure to load a full (new) cluster and several other fixes to TTreeCache.; Reduce the memory used by a TTree in half. Refactor the code reading and writing the TBasket data.; A si",MatchSource.DOCS,tree/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v530/index.html:663,Integrability,depend,depending,663,". Tree; Performance. Introduce support for TTree with variable cluster size (i.e. value of fAutoFlush).; Iterating through the cluster should be done via the new class TTree::TClusterIterator (i.e. this replaces += fAutoFlush):. TTree::TClusterIterator clusterIter = tree->GetClusterIterator(which_entry_to_start_from);; Long64_t clusterStart;; while( (clusterStart = clusterIter()) < tree-<GetEntries()) {; printf(""The cluster starts at %lld and ends at %lld\n"",clusterStart,clusterIter.GetNextEntry()-1);; }; See TTreeCache::FillBuffer for a concrete usage example. Significant improvement of the performance of SetBranchAddress/SetAddress (by a factor 3 to 10 depending on the length/complexity of the classname).; Prevent the unlimited growth of the TBasket's buffer even if the basket is reused.; When the basket is Reset (this happens when it is written and will be reused),; if the TBuffer size is greater than. - twice the data in the current basket; and - twice the average data in each basket (of this branch); and - twice the requeste basket size (TBranch::GetBasketSize).; the size of the buffer is reduced to the max of; 'the data in the current basket' and 'the average' and the requested; buffer size and aligned to next highest multiple of 512.; In TBranchRef distinguish between the entry we need (now called RequestedEntry) and the; entry we have read (fReadEntry) so that we can avoid re-reading the same entry too many; times when executing TRef::GetObject.; Reduce by 40% the time taken GetEntry for a branch created using a leaflist (exclusive of the decompression time).; Introduce TVirtualPerfStats::FileUnzipEvent to be able to keep track of the cost of unzipping and use this in TTreePerfStats and TBasket ... This give a good picture of where the time in unzip or in unstreaming; Add more clusters to the TTreeCache buffer until fBufferMinSize is hit to avoid severely underfilled buffer when; a low number of branches is selected/used.; When reading backwards, make sure to",MatchSource.DOCS,tree/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v530/index.html:54,Modifiability,variab,variable,54,". Tree; Performance. Introduce support for TTree with variable cluster size (i.e. value of fAutoFlush).; Iterating through the cluster should be done via the new class TTree::TClusterIterator (i.e. this replaces += fAutoFlush):. TTree::TClusterIterator clusterIter = tree->GetClusterIterator(which_entry_to_start_from);; Long64_t clusterStart;; while( (clusterStart = clusterIter()) < tree-<GetEntries()) {; printf(""The cluster starts at %lld and ends at %lld\n"",clusterStart,clusterIter.GetNextEntry()-1);; }; See TTreeCache::FillBuffer for a concrete usage example. Significant improvement of the performance of SetBranchAddress/SetAddress (by a factor 3 to 10 depending on the length/complexity of the classname).; Prevent the unlimited growth of the TBasket's buffer even if the basket is reused.; When the basket is Reset (this happens when it is written and will be reused),; if the TBuffer size is greater than. - twice the data in the current basket; and - twice the average data in each basket (of this branch); and - twice the requeste basket size (TBranch::GetBasketSize).; the size of the buffer is reduced to the max of; 'the data in the current basket' and 'the average' and the requested; buffer size and aligned to next highest multiple of 512.; In TBranchRef distinguish between the entry we need (now called RequestedEntry) and the; entry we have read (fReadEntry) so that we can avoid re-reading the same entry too many; times when executing TRef::GetObject.; Reduce by 40% the time taken GetEntry for a branch created using a leaflist (exclusive of the decompression time).; Introduce TVirtualPerfStats::FileUnzipEvent to be able to keep track of the cost of unzipping and use this in TTreePerfStats and TBasket ... This give a good picture of where the time in unzip or in unstreaming; Add more clusters to the TTreeCache buffer until fBufferMinSize is hit to avoid severely underfilled buffer when; a low number of branches is selected/used.; When reading backwards, make sure to",MatchSource.DOCS,tree/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v530/index.html:599,Performance,perform,performance,599,". Tree; Performance. Introduce support for TTree with variable cluster size (i.e. value of fAutoFlush).; Iterating through the cluster should be done via the new class TTree::TClusterIterator (i.e. this replaces += fAutoFlush):. TTree::TClusterIterator clusterIter = tree->GetClusterIterator(which_entry_to_start_from);; Long64_t clusterStart;; while( (clusterStart = clusterIter()) < tree-<GetEntries()) {; printf(""The cluster starts at %lld and ends at %lld\n"",clusterStart,clusterIter.GetNextEntry()-1);; }; See TTreeCache::FillBuffer for a concrete usage example. Significant improvement of the performance of SetBranchAddress/SetAddress (by a factor 3 to 10 depending on the length/complexity of the classname).; Prevent the unlimited growth of the TBasket's buffer even if the basket is reused.; When the basket is Reset (this happens when it is written and will be reused),; if the TBuffer size is greater than. - twice the data in the current basket; and - twice the average data in each basket (of this branch); and - twice the requeste basket size (TBranch::GetBasketSize).; the size of the buffer is reduced to the max of; 'the data in the current basket' and 'the average' and the requested; buffer size and aligned to next highest multiple of 512.; In TBranchRef distinguish between the entry we need (now called RequestedEntry) and the; entry we have read (fReadEntry) so that we can avoid re-reading the same entry too many; times when executing TRef::GetObject.; Reduce by 40% the time taken GetEntry for a branch created using a leaflist (exclusive of the decompression time).; Introduce TVirtualPerfStats::FileUnzipEvent to be able to keep track of the cost of unzipping and use this in TTreePerfStats and TBasket ... This give a good picture of where the time in unzip or in unstreaming; Add more clusters to the TTreeCache buffer until fBufferMinSize is hit to avoid severely underfilled buffer when; a low number of branches is selected/used.; When reading backwards, make sure to",MatchSource.DOCS,tree/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v530/index.html:2002,Performance,load,load,2002,"anch); and - twice the requeste basket size (TBranch::GetBasketSize).; the size of the buffer is reduced to the max of; 'the data in the current basket' and 'the average' and the requested; buffer size and aligned to next highest multiple of 512.; In TBranchRef distinguish between the entry we need (now called RequestedEntry) and the; entry we have read (fReadEntry) so that we can avoid re-reading the same entry too many; times when executing TRef::GetObject.; Reduce by 40% the time taken GetEntry for a branch created using a leaflist (exclusive of the decompression time).; Introduce TVirtualPerfStats::FileUnzipEvent to be able to keep track of the cost of unzipping and use this in TTreePerfStats and TBasket ... This give a good picture of where the time in unzip or in unstreaming; Add more clusters to the TTreeCache buffer until fBufferMinSize is hit to avoid severely underfilled buffer when; a low number of branches is selected/used.; When reading backwards, make sure to load a full (new) cluster and several other fixes to TTreeCache.; Reduce the memory used by a TTree in half. Refactor the code reading and writing the TBasket data.; A single transient buffer holding the compressed data is now managed by TTree (and could be made thread local); rather than having one per TBranch.; In TTree::Fill, call FlushBasket before calling OptimizeBaskets so that we have a correct; and accurate value of fTotBytes to use as the requested memory.; In TTree::OptimizeBasket enforces hard minimun for the basket size (no lower than the; estimate size of one entry in the branch and no lower than 8 bytes). TTree::Process. Add support for the flag TSelector::kAbortFile. TTree::Draw. The line width setting was missing in a few places.; Namely support the option 'a' for TGraphs in TTree::Draw (delegate the axis management to the TGraph object). TTreeSQL. Allow TTreeSQL to see temporary tables.; Avoid creating the unnecessary array fEntryOffset ... which when its content is always set to z",MatchSource.DOCS,tree/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v530/index.html:3154,Performance,load,loading,3154," A single transient buffer holding the compressed data is now managed by TTree (and could be made thread local); rather than having one per TBranch.; In TTree::Fill, call FlushBasket before calling OptimizeBaskets so that we have a correct; and accurate value of fTotBytes to use as the requested memory.; In TTree::OptimizeBasket enforces hard minimun for the basket size (no lower than the; estimate size of one entry in the branch and no lower than 8 bytes). TTree::Process. Add support for the flag TSelector::kAbortFile. TTree::Draw. The line width setting was missing in a few places.; Namely support the option 'a' for TGraphs in TTree::Draw (delegate the axis management to the TGraph object). TTreeSQL. Allow TTreeSQL to see temporary tables.; Avoid creating the unnecessary array fEntryOffset ... which when its content is always set to zero actually prevent reading text field with TTreeSQL.; Properly find the column even if they were not created by TTreeSQL itself. Fix the loading of data for the last column. Other. Update the branch split mechanism to no longer split a base class; that can not be split (i.e. respect the information returned; by TStreamerElement::CannotSplit (and thus TClass::CanSplit).; In TChain::ls, print the name of the chain and indent the list of files (this fixes #79909).; When setting fBranch in the loaded basket, make sure to set it also for the first/only basket ; this prevents a crash when calling SetBasketSize for a split top level branch in a file produced by v4.00/08.; In TTree::Streamer, if the object we are reading in was already attached to a directory, let's make sure to unregister the object before setting fDirectory to zero.; Prevent TChainIndex and TTreeIndex from finding the branches from the friend tree when looking up the value in the master/parent TTree. This fixes #79166.; Update GetEntryNumberFriend and related functions to retun a Long64_t as needed.; Fix the case of a split collection which contains a class with one; data ",MatchSource.DOCS,tree/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v530/index.html:3512,Performance,load,loaded,3512,"ntry in the branch and no lower than 8 bytes). TTree::Process. Add support for the flag TSelector::kAbortFile. TTree::Draw. The line width setting was missing in a few places.; Namely support the option 'a' for TGraphs in TTree::Draw (delegate the axis management to the TGraph object). TTreeSQL. Allow TTreeSQL to see temporary tables.; Avoid creating the unnecessary array fEntryOffset ... which when its content is always set to zero actually prevent reading text field with TTreeSQL.; Properly find the column even if they were not created by TTreeSQL itself. Fix the loading of data for the last column. Other. Update the branch split mechanism to no longer split a base class; that can not be split (i.e. respect the information returned; by TStreamerElement::CannotSplit (and thus TClass::CanSplit).; In TChain::ls, print the name of the chain and indent the list of files (this fixes #79909).; When setting fBranch in the loaded basket, make sure to set it also for the first/only basket ; this prevents a crash when calling SetBasketSize for a split top level branch in a file produced by v4.00/08.; In TTree::Streamer, if the object we are reading in was already attached to a directory, let's make sure to unregister the object before setting fDirectory to zero.; Prevent TChainIndex and TTreeIndex from finding the branches from the friend tree when looking up the value in the master/parent TTree. This fixes #79166.; Update GetEntryNumberFriend and related functions to retun a Long64_t as needed.; Fix the case of a split collection which contains a class with one; data member which is an instance of a class with more than one base; class some of which are not split (for example if one the base class; is std::vector<int>).; Fix the problem reported at #11890; by making sure that TChain::ResetBranchAddress(TBranch*) also record the reset in the; chain's meta information about branches.; Allow the output name passed to MakeProxy to be either a classname (to which will be added .h",MatchSource.DOCS,tree/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v530/index.html:1398,Safety,avoid,avoid,1398,"clusterIter()) < tree-<GetEntries()) {; printf(""The cluster starts at %lld and ends at %lld\n"",clusterStart,clusterIter.GetNextEntry()-1);; }; See TTreeCache::FillBuffer for a concrete usage example. Significant improvement of the performance of SetBranchAddress/SetAddress (by a factor 3 to 10 depending on the length/complexity of the classname).; Prevent the unlimited growth of the TBasket's buffer even if the basket is reused.; When the basket is Reset (this happens when it is written and will be reused),; if the TBuffer size is greater than. - twice the data in the current basket; and - twice the average data in each basket (of this branch); and - twice the requeste basket size (TBranch::GetBasketSize).; the size of the buffer is reduced to the max of; 'the data in the current basket' and 'the average' and the requested; buffer size and aligned to next highest multiple of 512.; In TBranchRef distinguish between the entry we need (now called RequestedEntry) and the; entry we have read (fReadEntry) so that we can avoid re-reading the same entry too many; times when executing TRef::GetObject.; Reduce by 40% the time taken GetEntry for a branch created using a leaflist (exclusive of the decompression time).; Introduce TVirtualPerfStats::FileUnzipEvent to be able to keep track of the cost of unzipping and use this in TTreePerfStats and TBasket ... This give a good picture of where the time in unzip or in unstreaming; Add more clusters to the TTreeCache buffer until fBufferMinSize is hit to avoid severely underfilled buffer when; a low number of branches is selected/used.; When reading backwards, make sure to load a full (new) cluster and several other fixes to TTreeCache.; Reduce the memory used by a TTree in half. Refactor the code reading and writing the TBasket data.; A single transient buffer holding the compressed data is now managed by TTree (and could be made thread local); rather than having one per TBranch.; In TTree::Fill, call FlushBasket before calling Opti",MatchSource.DOCS,tree/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v530/index.html:1881,Safety,avoid,avoid,1881,"is written and will be reused),; if the TBuffer size is greater than. - twice the data in the current basket; and - twice the average data in each basket (of this branch); and - twice the requeste basket size (TBranch::GetBasketSize).; the size of the buffer is reduced to the max of; 'the data in the current basket' and 'the average' and the requested; buffer size and aligned to next highest multiple of 512.; In TBranchRef distinguish between the entry we need (now called RequestedEntry) and the; entry we have read (fReadEntry) so that we can avoid re-reading the same entry too many; times when executing TRef::GetObject.; Reduce by 40% the time taken GetEntry for a branch created using a leaflist (exclusive of the decompression time).; Introduce TVirtualPerfStats::FileUnzipEvent to be able to keep track of the cost of unzipping and use this in TTreePerfStats and TBasket ... This give a good picture of where the time in unzip or in unstreaming; Add more clusters to the TTreeCache buffer until fBufferMinSize is hit to avoid severely underfilled buffer when; a low number of branches is selected/used.; When reading backwards, make sure to load a full (new) cluster and several other fixes to TTreeCache.; Reduce the memory used by a TTree in half. Refactor the code reading and writing the TBasket data.; A single transient buffer holding the compressed data is now managed by TTree (and could be made thread local); rather than having one per TBranch.; In TTree::Fill, call FlushBasket before calling OptimizeBaskets so that we have a correct; and accurate value of fTotBytes to use as the requested memory.; In TTree::OptimizeBasket enforces hard minimun for the basket size (no lower than the; estimate size of one entry in the branch and no lower than 8 bytes). TTree::Process. Add support for the flag TSelector::kAbortFile. TTree::Draw. The line width setting was missing in a few places.; Namely support the option 'a' for TGraphs in TTree::Draw (delegate the axis management to ",MatchSource.DOCS,tree/doc/v530/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v530/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v532/index.html:2341,Modifiability,refactor,refactoring,2341,"on. Additions with respect to TEntryList ; Data members:; fSubLists: a container to hold the sublists; fEntry: the entry number if the list is used to hold subentries; fLastSubListQueried and fSubListIter: a pointer to the last sublist queried and an iterator to resume the loop from the last sublist queried (to speed up selection and insertion in TTree::Draw); Public methods:; Contains, Enter and Remove with subentry as argument; GetSubListForEntry: to return the sublist corresponding to the given entry; Protected methods:; AddEntriesAndSubLists: called by Add when adding two TEntryList arrays with sublists; ConvertToTEntryListArray: convert TEntryList to TEntryListArray; RemoveSubList: to remove the given sublist; RemoveSubListForEntry: to remove the sublist corresponding to the given entry; SetEntry: to get / set a sublist for the given entry. Others changes. Reduced the memory used by a TTree in half by refactoring the code reading and writing the TBasket data;; A single transient buffer holding the compressed data is now managed by TTree (and could be made thread local); rather than having one per TBranch. Updated TBranchElement::Unroll to no longer split a base class; that can not be split (i.e. respect the information returned; by TStreamerElement::CannotSplit (and thus TClass::CanSplit). This disabling is currently _not_ done automatically for backward compatibility reasons and because; ; Without TClass::SetCanSplit there was no way to; force the splitting (short of setting the split level lower); Some classes still requires a custom streamer solely to; read older data files (for example for file written before; the advent of StreamerInfo) and are such not necessary to; be used when writting (and schema evolution rules can not; yet be used in this case). Allowed removing branches when cloning a TNtuple. Added an option value (""cachedbranches"") to the Print() function of TTreeCache to be able to print the list of cached branches. Made the ownership of the TBra",MatchSource.DOCS,tree/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v532/index.html:551,Performance,perform,performance,551,". Tree Libraries; TEntryListArray: a list of entries and subentries in a TTree or TChain. TEntryListArray is an extension of TEntryList, used to hold selected entries and subentries (sublists) for when the user has a TTree with containers (vectors, arrays, ...). Usage with TTree::Draw to select entries and subentries . To fill a list elist :; ; tree->Draw("">> elist"", ""x > 0"", ""entrylistarray"");; . To use a list to select entries and subentries:. tree->SetEntryList(elist);; tree->Draw(""y"");; tree->Draw(""z"");; . Its main purpose is to improve the performance of a code that needs to apply complex cuts on TTree::Draw multiple times. After the first call above to TTree::Draw, a TEntryListArray is created and filled with the entries and the indices of the arrays that satisfied the selection cut (x > 0). In the subsequent calls to TTree::Draw, only these entries / subentries are used to fill histograms. About the class . The class derives from TEntryList and can be used basically in the same way. This same class is used to keep entries and subentries, so there are two types of TEntryListArray's:. The ones that only hold subentries; fEntry is set to the entry# for which the subentries correspond; fSubLists must be 0; The ones that hold entries and eventually lists with subentries in fSubLists.; fEntry = -1 for those; If there are no sublists for a given entry, all the subentries will be used in the selection. Additions with respect to TEntryList ; Data members:; fSubLists: a container to hold the sublists; fEntry: the entry number if the list is used to hold subentries; fLastSubListQueried and fSubListIter: a pointer to the last sublist queried and an iterator to resume the loop from the last sublist queried (to speed up selection and insertion in TTree::Draw); Public methods:; Contains, Enter and Remove with subentry as argument; GetSubListForEntry: to return the sublist corresponding to the given entry; Protected methods:; AddEntriesAndSubLists: called by Add when adding t",MatchSource.DOCS,tree/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v532/index.html:3287,Performance,cache,cachedbranches,3287,"ree in half by refactoring the code reading and writing the TBasket data;; A single transient buffer holding the compressed data is now managed by TTree (and could be made thread local); rather than having one per TBranch. Updated TBranchElement::Unroll to no longer split a base class; that can not be split (i.e. respect the information returned; by TStreamerElement::CannotSplit (and thus TClass::CanSplit). This disabling is currently _not_ done automatically for backward compatibility reasons and because; ; Without TClass::SetCanSplit there was no way to; force the splitting (short of setting the split level lower); Some classes still requires a custom streamer solely to; read older data files (for example for file written before; the advent of StreamerInfo) and are such not necessary to; be used when writting (and schema evolution rules can not; yet be used in this case). Allowed removing branches when cloning a TNtuple. Added an option value (""cachedbranches"") to the Print() function of TTreeCache to be able to print the list of cached branches. Made the ownership of the TBranch by fBranch clearer (and thus allow the 'reuse' of TTree object without memory leak). Introduced GetLeaf(branchname,leafname) used in TTreeFormula to avoid ambiguity in the syntax introduced by too many slashes. Improved performance of TTree::GetEntry. With this changes the 'overhead'; compare to protobuf goes from 48% to 24%. (This does not include the; cost of the file opening which can be comparatively large for small; files. For the example used in the comparison the cost TFile::Open is 8% of the cost; of 100000 calls to TTree::GetEntry). Prevented the use of non-existent memory when reading in an object that is part of an STL collection and which used; to contains an embedded object (and this data member has been removed). Now properly recognize a TClonesArray data member even if the requested type was a typedef (to TClonesArray) that is in a namespace (for example edm::Event::Contaie",MatchSource.DOCS,tree/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v532/index.html:3374,Performance,cache,cached,3374,"ree in half by refactoring the code reading and writing the TBasket data;; A single transient buffer holding the compressed data is now managed by TTree (and could be made thread local); rather than having one per TBranch. Updated TBranchElement::Unroll to no longer split a base class; that can not be split (i.e. respect the information returned; by TStreamerElement::CannotSplit (and thus TClass::CanSplit). This disabling is currently _not_ done automatically for backward compatibility reasons and because; ; Without TClass::SetCanSplit there was no way to; force the splitting (short of setting the split level lower); Some classes still requires a custom streamer solely to; read older data files (for example for file written before; the advent of StreamerInfo) and are such not necessary to; be used when writting (and schema evolution rules can not; yet be used in this case). Allowed removing branches when cloning a TNtuple. Added an option value (""cachedbranches"") to the Print() function of TTreeCache to be able to print the list of cached branches. Made the ownership of the TBranch by fBranch clearer (and thus allow the 'reuse' of TTree object without memory leak). Introduced GetLeaf(branchname,leafname) used in TTreeFormula to avoid ambiguity in the syntax introduced by too many slashes. Improved performance of TTree::GetEntry. With this changes the 'overhead'; compare to protobuf goes from 48% to 24%. (This does not include the; cost of the file opening which can be comparatively large for small; files. For the example used in the comparison the cost TFile::Open is 8% of the cost; of 100000 calls to TTree::GetEntry). Prevented the use of non-existent memory when reading in an object that is part of an STL collection and which used; to contains an embedded object (and this data member has been removed). Now properly recognize a TClonesArray data member even if the requested type was a typedef (to TClonesArray) that is in a namespace (for example edm::Event::Contaie",MatchSource.DOCS,tree/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v532/index.html:3645,Performance,perform,performance,3645,"alf by refactoring the code reading and writing the TBasket data;; A single transient buffer holding the compressed data is now managed by TTree (and could be made thread local); rather than having one per TBranch. Updated TBranchElement::Unroll to no longer split a base class; that can not be split (i.e. respect the information returned; by TStreamerElement::CannotSplit (and thus TClass::CanSplit). This disabling is currently _not_ done automatically for backward compatibility reasons and because; ; Without TClass::SetCanSplit there was no way to; force the splitting (short of setting the split level lower); Some classes still requires a custom streamer solely to; read older data files (for example for file written before; the advent of StreamerInfo) and are such not necessary to; be used when writting (and schema evolution rules can not; yet be used in this case). Allowed removing branches when cloning a TNtuple. Added an option value (""cachedbranches"") to the Print() function of TTreeCache to be able to print the list of cached branches. Made the ownership of the TBranch by fBranch clearer (and thus allow the 'reuse' of TTree object without memory leak). Introduced GetLeaf(branchname,leafname) used in TTreeFormula to avoid ambiguity in the syntax introduced by too many slashes. Improved performance of TTree::GetEntry. With this changes the 'overhead'; compare to protobuf goes from 48% to 24%. (This does not include the; cost of the file opening which can be comparatively large for small; files. For the example used in the comparison the cost TFile::Open is 8% of the cost; of 100000 calls to TTree::GetEntry). Prevented the use of non-existent memory when reading in an object that is part of an STL collection and which used; to contains an embedded object (and this data member has been removed). Now properly recognize a TClonesArray data member even if the requested type was a typedef (to TClonesArray) that is in a namespace (for example edm::Event::ContaierType). ",MatchSource.DOCS,tree/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v532/index.html:3574,Safety,avoid,avoid,3574,"alf by refactoring the code reading and writing the TBasket data;; A single transient buffer holding the compressed data is now managed by TTree (and could be made thread local); rather than having one per TBranch. Updated TBranchElement::Unroll to no longer split a base class; that can not be split (i.e. respect the information returned; by TStreamerElement::CannotSplit (and thus TClass::CanSplit). This disabling is currently _not_ done automatically for backward compatibility reasons and because; ; Without TClass::SetCanSplit there was no way to; force the splitting (short of setting the split level lower); Some classes still requires a custom streamer solely to; read older data files (for example for file written before; the advent of StreamerInfo) and are such not necessary to; be used when writting (and schema evolution rules can not; yet be used in this case). Allowed removing branches when cloning a TNtuple. Added an option value (""cachedbranches"") to the Print() function of TTreeCache to be able to print the list of cached branches. Made the ownership of the TBranch by fBranch clearer (and thus allow the 'reuse' of TTree object without memory leak). Introduced GetLeaf(branchname,leafname) used in TTreeFormula to avoid ambiguity in the syntax introduced by too many slashes. Improved performance of TTree::GetEntry. With this changes the 'overhead'; compare to protobuf goes from 48% to 24%. (This does not include the; cost of the file opening which can be comparatively large for small; files. For the example used in the comparison the cost TFile::Open is 8% of the cost; of 100000 calls to TTree::GetEntry). Prevented the use of non-existent memory when reading in an object that is part of an STL collection and which used; to contains an embedded object (and this data member has been removed). Now properly recognize a TClonesArray data member even if the requested type was a typedef (to TClonesArray) that is in a namespace (for example edm::Event::ContaierType). ",MatchSource.DOCS,tree/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v532/index.html:1684,Usability,resume,resume,1684,"ly these entries / subentries are used to fill histograms. About the class . The class derives from TEntryList and can be used basically in the same way. This same class is used to keep entries and subentries, so there are two types of TEntryListArray's:. The ones that only hold subentries; fEntry is set to the entry# for which the subentries correspond; fSubLists must be 0; The ones that hold entries and eventually lists with subentries in fSubLists.; fEntry = -1 for those; If there are no sublists for a given entry, all the subentries will be used in the selection. Additions with respect to TEntryList ; Data members:; fSubLists: a container to hold the sublists; fEntry: the entry number if the list is used to hold subentries; fLastSubListQueried and fSubListIter: a pointer to the last sublist queried and an iterator to resume the loop from the last sublist queried (to speed up selection and insertion in TTree::Draw); Public methods:; Contains, Enter and Remove with subentry as argument; GetSubListForEntry: to return the sublist corresponding to the given entry; Protected methods:; AddEntriesAndSubLists: called by Add when adding two TEntryList arrays with sublists; ConvertToTEntryListArray: convert TEntryList to TEntryListArray; RemoveSubList: to remove the given sublist; RemoveSubListForEntry: to remove the sublist corresponding to the given entry; SetEntry: to get / set a sublist for the given entry. Others changes. Reduced the memory used by a TTree in half by refactoring the code reading and writing the TBasket data;; A single transient buffer holding the compressed data is now managed by TTree (and could be made thread local); rather than having one per TBranch. Updated TBranchElement::Unroll to no longer split a base class; that can not be split (i.e. respect the information returned; by TStreamerElement::CannotSplit (and thus TClass::CanSplit). This disabling is currently _not_ done automatically for backward compatibility reasons and because; ; Without TCl",MatchSource.DOCS,tree/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v532/index.html:3436,Usability,clear,clearer,3436,"alf by refactoring the code reading and writing the TBasket data;; A single transient buffer holding the compressed data is now managed by TTree (and could be made thread local); rather than having one per TBranch. Updated TBranchElement::Unroll to no longer split a base class; that can not be split (i.e. respect the information returned; by TStreamerElement::CannotSplit (and thus TClass::CanSplit). This disabling is currently _not_ done automatically for backward compatibility reasons and because; ; Without TClass::SetCanSplit there was no way to; force the splitting (short of setting the split level lower); Some classes still requires a custom streamer solely to; read older data files (for example for file written before; the advent of StreamerInfo) and are such not necessary to; be used when writting (and schema evolution rules can not; yet be used in this case). Allowed removing branches when cloning a TNtuple. Added an option value (""cachedbranches"") to the Print() function of TTreeCache to be able to print the list of cached branches. Made the ownership of the TBranch by fBranch clearer (and thus allow the 'reuse' of TTree object without memory leak). Introduced GetLeaf(branchname,leafname) used in TTreeFormula to avoid ambiguity in the syntax introduced by too many slashes. Improved performance of TTree::GetEntry. With this changes the 'overhead'; compare to protobuf goes from 48% to 24%. (This does not include the; cost of the file opening which can be comparatively large for small; files. For the example used in the comparison the cost TFile::Open is 8% of the cost; of 100000 calls to TTree::GetEntry). Prevented the use of non-existent memory when reading in an object that is part of an STL collection and which used; to contains an embedded object (and this data member has been removed). Now properly recognize a TClonesArray data member even if the requested type was a typedef (to TClonesArray) that is in a namespace (for example edm::Event::ContaierType). ",MatchSource.DOCS,tree/doc/v532/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v532/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v534/index.html:1686,Availability,error,error,1686,"ted in the buffer (i. no less than the value of TBuffer::Length). In TBranch::SetBasketSize, instead of using the hard minimum of 100, use; 100 + the length of the branch name (as 100 is too small to hold the; basket's key information for any branch name larger than 30 characters). Reading form text file. Reworked TTree::ReadStream and TTree::ReadFile mainly to fix delimited reading of string columns:. TLeaf::ReadValue now takes an optional delimiter argument that is ignored for all but TLeafC. Here, input stops when reading this character, instead of at the first whitespace.; Use that in TTree::ReadStream() to delimit reading of TLeafC.; TTree::ReadStream now tokenizes the row itself, and passes a stringstream containing nothing but the current column to TLeaf::ReadValue.; Separate concepts of number of input line (for communication with user) and number of good lines (as returned).; Fix windows files leaving '\n' in branch names when reading them from the file.; Add error message for TLeaf::ReadValue(), i.e. if ReadValue() is called on a derived class that doesn't implement it.; Updated and clarified the documentation. TEntryList. Add new methods to find the base location of files and to modify it.; This allows to relocate the entry-lists to be able to use them of a; system where the files have a different absolute path.; The most relevant new methods are:. TEntryList::Scan(const char *fn); Shows the root common paths for the files of the TEntryLists in 'fn'; TEntryList::Relocate(const char *fn, const char *newroot,; const char *oldroot = 0, const char *enlnm = 0); Relocates all paths starting with 'oldroot' to 'newroot' for the; entry-list 'enlnm' in file 'fn'. Remove 'protocol+server' from file tagging and matching, i.e. use; only filepath+anchor; in this way a list is valid even after re-staging; of the dataset files, which typically changes the end-point data servers.; Entry-lists created with the full path should still be matched correctly. Miscellaneous. Rep",MatchSource.DOCS,tree/doc/v534/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v534/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v534/index.html:3131,Deployability,patch,patch,3131,"of the TEntryLists in 'fn'; TEntryList::Relocate(const char *fn, const char *newroot,; const char *oldroot = 0, const char *enlnm = 0); Relocates all paths starting with 'oldroot' to 'newroot' for the; entry-list 'enlnm' in file 'fn'. Remove 'protocol+server' from file tagging and matching, i.e. use; only filepath+anchor; in this way a list is valid even after re-staging; of the dataset files, which typically changes the end-point data servers.; Entry-lists created with the full path should still be matched correctly. Miscellaneous. Repaired the behavior of TTreeCache when the TTree has a dramatic dynamic range with a lots of very small entriesat the beginning and very large entries at the end, the size in bytes of the cluster for the later entries will be very large (because of the cluster size in entries is large!). TTreeCache::FillBuffer was always attempting to load complete clusters not matter the; size (even with the size was larger than 2GB!). This patch resolves the issue by limiting the amount of memory used to:. The requested size if more than one cluster fits in the cache.; Twice the requested size if at least one basket per branch fits in the cache.; Four time the requested size in the case where the cache can not even hold one basket per branch. The filling will restart at the next cluster boundary in the case a) and will; restart at the maximum of entry number read in the cache in the case b) and c).; Baskets that are below this boundary and did not fit in the cache will be read; individually.; Repaired the basket flushing frequency when the TTree has already more than one cluster size.; Repaired binning of string histogram generated by TTree::Draw.; Many bug fixes and fix for issues discovery by Coverity, see change log for more details.; In TTree::MakeProxy add proper support for top level stl collection of objects and for stl collection of objects that are 'empty' in the file (and thus we know nothing about its content).; Avoid deficiency in hadd whe",MatchSource.DOCS,tree/doc/v534/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v534/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v534/index.html:193,Integrability,interface,interface,193,". Tree Libraries; Performance. Automatic support for multiple TTreeCache per TFile.; Multiple TTreeCache per TFile for reading are supported by using the existing TTree::SetCacheSize(Long64_t) interface.; In addition, a TTreeCache for a TTree can be added using TFile::SetCacheRead(TFileCacheRead*, TObject*), where the second (optional) argument is a pointer to the TTree. The cache can be removed by setting the pointer to 0. In that case the user will have to take ownership for the cache.; Similarily, a pointer to the TTreeCache for a TTree can be obtained using TFile::GetCacheRead(TObject*). In TBuffer::Expand, when shrinking the buffer do not shrink below the size of the; data already accumulated in the buffer (i. no less than the value of TBuffer::Length). In TBranch::SetBasketSize, instead of using the hard minimum of 100, use; 100 + the length of the branch name (as 100 is too small to hold the; basket's key information for any branch name larger than 30 characters). Reading form text file. Reworked TTree::ReadStream and TTree::ReadFile mainly to fix delimited reading of string columns:. TLeaf::ReadValue now takes an optional delimiter argument that is ignored for all but TLeafC. Here, input stops when reading this character, instead of at the first whitespace.; Use that in TTree::ReadStream() to delimit reading of TLeafC.; TTree::ReadStream now tokenizes the row itself, and passes a stringstream containing nothing but the current column to TLeaf::ReadValue.; Separate concepts of number of input line (for communication with user) and number of good lines (as returned).; Fix windows files leaving '\n' in branch names when reading them from the file.; Add error message for TLeaf::ReadValue(), i.e. if ReadValue() is called on a derived class that doesn't implement it.; Updated and clarified the documentation. TEntryList. Add new methods to find the base location of files and to modify it.; This allows to relocate the entry-lists to be able to use them of a; system w",MatchSource.DOCS,tree/doc/v534/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v534/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v534/index.html:1692,Integrability,message,message,1692,"ted in the buffer (i. no less than the value of TBuffer::Length). In TBranch::SetBasketSize, instead of using the hard minimum of 100, use; 100 + the length of the branch name (as 100 is too small to hold the; basket's key information for any branch name larger than 30 characters). Reading form text file. Reworked TTree::ReadStream and TTree::ReadFile mainly to fix delimited reading of string columns:. TLeaf::ReadValue now takes an optional delimiter argument that is ignored for all but TLeafC. Here, input stops when reading this character, instead of at the first whitespace.; Use that in TTree::ReadStream() to delimit reading of TLeafC.; TTree::ReadStream now tokenizes the row itself, and passes a stringstream containing nothing but the current column to TLeaf::ReadValue.; Separate concepts of number of input line (for communication with user) and number of good lines (as returned).; Fix windows files leaving '\n' in branch names when reading them from the file.; Add error message for TLeaf::ReadValue(), i.e. if ReadValue() is called on a derived class that doesn't implement it.; Updated and clarified the documentation. TEntryList. Add new methods to find the base location of files and to modify it.; This allows to relocate the entry-lists to be able to use them of a; system where the files have a different absolute path.; The most relevant new methods are:. TEntryList::Scan(const char *fn); Shows the root common paths for the files of the TEntryLists in 'fn'; TEntryList::Relocate(const char *fn, const char *newroot,; const char *oldroot = 0, const char *enlnm = 0); Relocates all paths starting with 'oldroot' to 'newroot' for the; entry-list 'enlnm' in file 'fn'. Remove 'protocol+server' from file tagging and matching, i.e. use; only filepath+anchor; in this way a list is valid even after re-staging; of the dataset files, which typically changes the end-point data servers.; Entry-lists created with the full path should still be matched correctly. Miscellaneous. Rep",MatchSource.DOCS,tree/doc/v534/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v534/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v534/index.html:2404,Integrability,protocol,protocol,2404,"ontaining nothing but the current column to TLeaf::ReadValue.; Separate concepts of number of input line (for communication with user) and number of good lines (as returned).; Fix windows files leaving '\n' in branch names when reading them from the file.; Add error message for TLeaf::ReadValue(), i.e. if ReadValue() is called on a derived class that doesn't implement it.; Updated and clarified the documentation. TEntryList. Add new methods to find the base location of files and to modify it.; This allows to relocate the entry-lists to be able to use them of a; system where the files have a different absolute path.; The most relevant new methods are:. TEntryList::Scan(const char *fn); Shows the root common paths for the files of the TEntryLists in 'fn'; TEntryList::Relocate(const char *fn, const char *newroot,; const char *oldroot = 0, const char *enlnm = 0); Relocates all paths starting with 'oldroot' to 'newroot' for the; entry-list 'enlnm' in file 'fn'. Remove 'protocol+server' from file tagging and matching, i.e. use; only filepath+anchor; in this way a list is valid even after re-staging; of the dataset files, which typically changes the end-point data servers.; Entry-lists created with the full path should still be matched correctly. Miscellaneous. Repaired the behavior of TTreeCache when the TTree has a dramatic dynamic range with a lots of very small entriesat the beginning and very large entries at the end, the size in bytes of the cluster for the later entries will be very large (because of the cluster size in entries is large!). TTreeCache::FillBuffer was always attempting to load complete clusters not matter the; size (even with the size was larger than 2GB!). This patch resolves the issue by limiting the amount of memory used to:. The requested size if more than one cluster fits in the cache.; Twice the requested size if at least one basket per branch fits in the cache.; Four time the requested size in the case where the cache can not even hold one bask",MatchSource.DOCS,tree/doc/v534/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v534/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v534/index.html:4849,Modifiability,evolve,evolved,4849,"lete clusters not matter the; size (even with the size was larger than 2GB!). This patch resolves the issue by limiting the amount of memory used to:. The requested size if more than one cluster fits in the cache.; Twice the requested size if at least one basket per branch fits in the cache.; Four time the requested size in the case where the cache can not even hold one basket per branch. The filling will restart at the next cluster boundary in the case a) and will; restart at the maximum of entry number read in the cache in the case b) and c).; Baskets that are below this boundary and did not fit in the cache will be read; individually.; Repaired the basket flushing frequency when the TTree has already more than one cluster size.; Repaired binning of string histogram generated by TTree::Draw.; Many bug fixes and fix for issues discovery by Coverity, see change log for more details.; In TTree::MakeProxy add proper support for top level stl collection of objects and for stl collection of objects that are 'empty' in the file (and thus we know nothing about its content).; Avoid deficiency in hadd when the resulting TTree is longer than the AutoSave length *and* the TFileMerger needs to handle the input files in more than one pass for example when there is more than 1000 input files or the -n option is passed to hadd.; Fix support for emulated class that derived from an abstract class.; This can happen when reading a file containing an ancient; class layout where the derived class is no longer provided in the; compiled code but the abstract base class is still provided. It also happens when using schema evolution rules on a class derived; from an abstract base class (in which case the system introduce; implicitly an emulated class deriving from the same base classes; as the evolved from class). To fix the issue, we introduce the TClass::GetStreamerInfoAbstractEmulated; which will return a StreamerInfo representing an emulated version of the; class even if it is loaded. ",MatchSource.DOCS,tree/doc/v534/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v534/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v534/index.html:378,Performance,cache,cache,378,". Tree Libraries; Performance. Automatic support for multiple TTreeCache per TFile.; Multiple TTreeCache per TFile for reading are supported by using the existing TTree::SetCacheSize(Long64_t) interface.; In addition, a TTreeCache for a TTree can be added using TFile::SetCacheRead(TFileCacheRead*, TObject*), where the second (optional) argument is a pointer to the TTree. The cache can be removed by setting the pointer to 0. In that case the user will have to take ownership for the cache.; Similarily, a pointer to the TTreeCache for a TTree can be obtained using TFile::GetCacheRead(TObject*). In TBuffer::Expand, when shrinking the buffer do not shrink below the size of the; data already accumulated in the buffer (i. no less than the value of TBuffer::Length). In TBranch::SetBasketSize, instead of using the hard minimum of 100, use; 100 + the length of the branch name (as 100 is too small to hold the; basket's key information for any branch name larger than 30 characters). Reading form text file. Reworked TTree::ReadStream and TTree::ReadFile mainly to fix delimited reading of string columns:. TLeaf::ReadValue now takes an optional delimiter argument that is ignored for all but TLeafC. Here, input stops when reading this character, instead of at the first whitespace.; Use that in TTree::ReadStream() to delimit reading of TLeafC.; TTree::ReadStream now tokenizes the row itself, and passes a stringstream containing nothing but the current column to TLeaf::ReadValue.; Separate concepts of number of input line (for communication with user) and number of good lines (as returned).; Fix windows files leaving '\n' in branch names when reading them from the file.; Add error message for TLeaf::ReadValue(), i.e. if ReadValue() is called on a derived class that doesn't implement it.; Updated and clarified the documentation. TEntryList. Add new methods to find the base location of files and to modify it.; This allows to relocate the entry-lists to be able to use them of a; system w",MatchSource.DOCS,tree/doc/v534/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v534/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v534/index.html:486,Performance,cache,cache,486,". Tree Libraries; Performance. Automatic support for multiple TTreeCache per TFile.; Multiple TTreeCache per TFile for reading are supported by using the existing TTree::SetCacheSize(Long64_t) interface.; In addition, a TTreeCache for a TTree can be added using TFile::SetCacheRead(TFileCacheRead*, TObject*), where the second (optional) argument is a pointer to the TTree. The cache can be removed by setting the pointer to 0. In that case the user will have to take ownership for the cache.; Similarily, a pointer to the TTreeCache for a TTree can be obtained using TFile::GetCacheRead(TObject*). In TBuffer::Expand, when shrinking the buffer do not shrink below the size of the; data already accumulated in the buffer (i. no less than the value of TBuffer::Length). In TBranch::SetBasketSize, instead of using the hard minimum of 100, use; 100 + the length of the branch name (as 100 is too small to hold the; basket's key information for any branch name larger than 30 characters). Reading form text file. Reworked TTree::ReadStream and TTree::ReadFile mainly to fix delimited reading of string columns:. TLeaf::ReadValue now takes an optional delimiter argument that is ignored for all but TLeafC. Here, input stops when reading this character, instead of at the first whitespace.; Use that in TTree::ReadStream() to delimit reading of TLeafC.; TTree::ReadStream now tokenizes the row itself, and passes a stringstream containing nothing but the current column to TLeaf::ReadValue.; Separate concepts of number of input line (for communication with user) and number of good lines (as returned).; Fix windows files leaving '\n' in branch names when reading them from the file.; Add error message for TLeaf::ReadValue(), i.e. if ReadValue() is called on a derived class that doesn't implement it.; Updated and clarified the documentation. TEntryList. Add new methods to find the base location of files and to modify it.; This allows to relocate the entry-lists to be able to use them of a; system w",MatchSource.DOCS,tree/doc/v534/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v534/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v534/index.html:3039,Performance,load,load,3039," relevant new methods are:. TEntryList::Scan(const char *fn); Shows the root common paths for the files of the TEntryLists in 'fn'; TEntryList::Relocate(const char *fn, const char *newroot,; const char *oldroot = 0, const char *enlnm = 0); Relocates all paths starting with 'oldroot' to 'newroot' for the; entry-list 'enlnm' in file 'fn'. Remove 'protocol+server' from file tagging and matching, i.e. use; only filepath+anchor; in this way a list is valid even after re-staging; of the dataset files, which typically changes the end-point data servers.; Entry-lists created with the full path should still be matched correctly. Miscellaneous. Repaired the behavior of TTreeCache when the TTree has a dramatic dynamic range with a lots of very small entriesat the beginning and very large entries at the end, the size in bytes of the cluster for the later entries will be very large (because of the cluster size in entries is large!). TTreeCache::FillBuffer was always attempting to load complete clusters not matter the; size (even with the size was larger than 2GB!). This patch resolves the issue by limiting the amount of memory used to:. The requested size if more than one cluster fits in the cache.; Twice the requested size if at least one basket per branch fits in the cache.; Four time the requested size in the case where the cache can not even hold one basket per branch. The filling will restart at the next cluster boundary in the case a) and will; restart at the maximum of entry number read in the cache in the case b) and c).; Baskets that are below this boundary and did not fit in the cache will be read; individually.; Repaired the basket flushing frequency when the TTree has already more than one cluster size.; Repaired binning of string histogram generated by TTree::Draw.; Many bug fixes and fix for issues discovery by Coverity, see change log for more details.; In TTree::MakeProxy add proper support for top level stl collection of objects and for stl collection of objects ",MatchSource.DOCS,tree/doc/v534/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v534/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v534/index.html:3255,Performance,cache,cache,3255,"st char *newroot,; const char *oldroot = 0, const char *enlnm = 0); Relocates all paths starting with 'oldroot' to 'newroot' for the; entry-list 'enlnm' in file 'fn'. Remove 'protocol+server' from file tagging and matching, i.e. use; only filepath+anchor; in this way a list is valid even after re-staging; of the dataset files, which typically changes the end-point data servers.; Entry-lists created with the full path should still be matched correctly. Miscellaneous. Repaired the behavior of TTreeCache when the TTree has a dramatic dynamic range with a lots of very small entriesat the beginning and very large entries at the end, the size in bytes of the cluster for the later entries will be very large (because of the cluster size in entries is large!). TTreeCache::FillBuffer was always attempting to load complete clusters not matter the; size (even with the size was larger than 2GB!). This patch resolves the issue by limiting the amount of memory used to:. The requested size if more than one cluster fits in the cache.; Twice the requested size if at least one basket per branch fits in the cache.; Four time the requested size in the case where the cache can not even hold one basket per branch. The filling will restart at the next cluster boundary in the case a) and will; restart at the maximum of entry number read in the cache in the case b) and c).; Baskets that are below this boundary and did not fit in the cache will be read; individually.; Repaired the basket flushing frequency when the TTree has already more than one cluster size.; Repaired binning of string histogram generated by TTree::Draw.; Many bug fixes and fix for issues discovery by Coverity, see change log for more details.; In TTree::MakeProxy add proper support for top level stl collection of objects and for stl collection of objects that are 'empty' in the file (and thus we know nothing about its content).; Avoid deficiency in hadd when the resulting TTree is longer than the AutoSave length *and* the T",MatchSource.DOCS,tree/doc/v534/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v534/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v534/index.html:3334,Performance,cache,cache,3334,"ocates all paths starting with 'oldroot' to 'newroot' for the; entry-list 'enlnm' in file 'fn'. Remove 'protocol+server' from file tagging and matching, i.e. use; only filepath+anchor; in this way a list is valid even after re-staging; of the dataset files, which typically changes the end-point data servers.; Entry-lists created with the full path should still be matched correctly. Miscellaneous. Repaired the behavior of TTreeCache when the TTree has a dramatic dynamic range with a lots of very small entriesat the beginning and very large entries at the end, the size in bytes of the cluster for the later entries will be very large (because of the cluster size in entries is large!). TTreeCache::FillBuffer was always attempting to load complete clusters not matter the; size (even with the size was larger than 2GB!). This patch resolves the issue by limiting the amount of memory used to:. The requested size if more than one cluster fits in the cache.; Twice the requested size if at least one basket per branch fits in the cache.; Four time the requested size in the case where the cache can not even hold one basket per branch. The filling will restart at the next cluster boundary in the case a) and will; restart at the maximum of entry number read in the cache in the case b) and c).; Baskets that are below this boundary and did not fit in the cache will be read; individually.; Repaired the basket flushing frequency when the TTree has already more than one cluster size.; Repaired binning of string histogram generated by TTree::Draw.; Many bug fixes and fix for issues discovery by Coverity, see change log for more details.; In TTree::MakeProxy add proper support for top level stl collection of objects and for stl collection of objects that are 'empty' in the file (and thus we know nothing about its content).; Avoid deficiency in hadd when the resulting TTree is longer than the AutoSave length *and* the TFileMerger needs to handle the input files in more than one pass for ex",MatchSource.DOCS,tree/doc/v534/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v534/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v534/index.html:3393,Performance,cache,cache,3393," 'fn'. Remove 'protocol+server' from file tagging and matching, i.e. use; only filepath+anchor; in this way a list is valid even after re-staging; of the dataset files, which typically changes the end-point data servers.; Entry-lists created with the full path should still be matched correctly. Miscellaneous. Repaired the behavior of TTreeCache when the TTree has a dramatic dynamic range with a lots of very small entriesat the beginning and very large entries at the end, the size in bytes of the cluster for the later entries will be very large (because of the cluster size in entries is large!). TTreeCache::FillBuffer was always attempting to load complete clusters not matter the; size (even with the size was larger than 2GB!). This patch resolves the issue by limiting the amount of memory used to:. The requested size if more than one cluster fits in the cache.; Twice the requested size if at least one basket per branch fits in the cache.; Four time the requested size in the case where the cache can not even hold one basket per branch. The filling will restart at the next cluster boundary in the case a) and will; restart at the maximum of entry number read in the cache in the case b) and c).; Baskets that are below this boundary and did not fit in the cache will be read; individually.; Repaired the basket flushing frequency when the TTree has already more than one cluster size.; Repaired binning of string histogram generated by TTree::Draw.; Many bug fixes and fix for issues discovery by Coverity, see change log for more details.; In TTree::MakeProxy add proper support for top level stl collection of objects and for stl collection of objects that are 'empty' in the file (and thus we know nothing about its content).; Avoid deficiency in hadd when the resulting TTree is longer than the AutoSave length *and* the TFileMerger needs to handle the input files in more than one pass for example when there is more than 1000 input files or the -n option is passed to hadd.; Fix s",MatchSource.DOCS,tree/doc/v534/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v534/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v534/index.html:3570,Performance,cache,cache,3570,"after re-staging; of the dataset files, which typically changes the end-point data servers.; Entry-lists created with the full path should still be matched correctly. Miscellaneous. Repaired the behavior of TTreeCache when the TTree has a dramatic dynamic range with a lots of very small entriesat the beginning and very large entries at the end, the size in bytes of the cluster for the later entries will be very large (because of the cluster size in entries is large!). TTreeCache::FillBuffer was always attempting to load complete clusters not matter the; size (even with the size was larger than 2GB!). This patch resolves the issue by limiting the amount of memory used to:. The requested size if more than one cluster fits in the cache.; Twice the requested size if at least one basket per branch fits in the cache.; Four time the requested size in the case where the cache can not even hold one basket per branch. The filling will restart at the next cluster boundary in the case a) and will; restart at the maximum of entry number read in the cache in the case b) and c).; Baskets that are below this boundary and did not fit in the cache will be read; individually.; Repaired the basket flushing frequency when the TTree has already more than one cluster size.; Repaired binning of string histogram generated by TTree::Draw.; Many bug fixes and fix for issues discovery by Coverity, see change log for more details.; In TTree::MakeProxy add proper support for top level stl collection of objects and for stl collection of objects that are 'empty' in the file (and thus we know nothing about its content).; Avoid deficiency in hadd when the resulting TTree is longer than the AutoSave length *and* the TFileMerger needs to handle the input files in more than one pass for example when there is more than 1000 input files or the -n option is passed to hadd.; Fix support for emulated class that derived from an abstract class.; This can happen when reading a file containing an ancient; class ",MatchSource.DOCS,tree/doc/v534/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v534/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v534/index.html:3660,Performance,cache,cache,3660,"path should still be matched correctly. Miscellaneous. Repaired the behavior of TTreeCache when the TTree has a dramatic dynamic range with a lots of very small entriesat the beginning and very large entries at the end, the size in bytes of the cluster for the later entries will be very large (because of the cluster size in entries is large!). TTreeCache::FillBuffer was always attempting to load complete clusters not matter the; size (even with the size was larger than 2GB!). This patch resolves the issue by limiting the amount of memory used to:. The requested size if more than one cluster fits in the cache.; Twice the requested size if at least one basket per branch fits in the cache.; Four time the requested size in the case where the cache can not even hold one basket per branch. The filling will restart at the next cluster boundary in the case a) and will; restart at the maximum of entry number read in the cache in the case b) and c).; Baskets that are below this boundary and did not fit in the cache will be read; individually.; Repaired the basket flushing frequency when the TTree has already more than one cluster size.; Repaired binning of string histogram generated by TTree::Draw.; Many bug fixes and fix for issues discovery by Coverity, see change log for more details.; In TTree::MakeProxy add proper support for top level stl collection of objects and for stl collection of objects that are 'empty' in the file (and thus we know nothing about its content).; Avoid deficiency in hadd when the resulting TTree is longer than the AutoSave length *and* the TFileMerger needs to handle the input files in more than one pass for example when there is more than 1000 input files or the -n option is passed to hadd.; Fix support for emulated class that derived from an abstract class.; This can happen when reading a file containing an ancient; class layout where the derived class is no longer provided in the; compiled code but the abstract base class is still provided. It al",MatchSource.DOCS,tree/doc/v534/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v534/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v534/index.html:5040,Performance,load,loaded,5040,"lete clusters not matter the; size (even with the size was larger than 2GB!). This patch resolves the issue by limiting the amount of memory used to:. The requested size if more than one cluster fits in the cache.; Twice the requested size if at least one basket per branch fits in the cache.; Four time the requested size in the case where the cache can not even hold one basket per branch. The filling will restart at the next cluster boundary in the case a) and will; restart at the maximum of entry number read in the cache in the case b) and c).; Baskets that are below this boundary and did not fit in the cache will be read; individually.; Repaired the basket flushing frequency when the TTree has already more than one cluster size.; Repaired binning of string histogram generated by TTree::Draw.; Many bug fixes and fix for issues discovery by Coverity, see change log for more details.; In TTree::MakeProxy add proper support for top level stl collection of objects and for stl collection of objects that are 'empty' in the file (and thus we know nothing about its content).; Avoid deficiency in hadd when the resulting TTree is longer than the AutoSave length *and* the TFileMerger needs to handle the input files in more than one pass for example when there is more than 1000 input files or the -n option is passed to hadd.; Fix support for emulated class that derived from an abstract class.; This can happen when reading a file containing an ancient; class layout where the derived class is no longer provided in the; compiled code but the abstract base class is still provided. It also happens when using schema evolution rules on a class derived; from an abstract base class (in which case the system introduce; implicitly an emulated class deriving from the same base classes; as the evolved from class). To fix the issue, we introduce the TClass::GetStreamerInfoAbstractEmulated; which will return a StreamerInfo representing an emulated version of the; class even if it is loaded. ",MatchSource.DOCS,tree/doc/v534/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v534/index.html
https://github.com/root-project/root/tree/v6-32-06/tree/doc/v534/index.html:3922,Testability,log,log,3922," for the later entries will be very large (because of the cluster size in entries is large!). TTreeCache::FillBuffer was always attempting to load complete clusters not matter the; size (even with the size was larger than 2GB!). This patch resolves the issue by limiting the amount of memory used to:. The requested size if more than one cluster fits in the cache.; Twice the requested size if at least one basket per branch fits in the cache.; Four time the requested size in the case where the cache can not even hold one basket per branch. The filling will restart at the next cluster boundary in the case a) and will; restart at the maximum of entry number read in the cache in the case b) and c).; Baskets that are below this boundary and did not fit in the cache will be read; individually.; Repaired the basket flushing frequency when the TTree has already more than one cluster size.; Repaired binning of string histogram generated by TTree::Draw.; Many bug fixes and fix for issues discovery by Coverity, see change log for more details.; In TTree::MakeProxy add proper support for top level stl collection of objects and for stl collection of objects that are 'empty' in the file (and thus we know nothing about its content).; Avoid deficiency in hadd when the resulting TTree is longer than the AutoSave length *and* the TFileMerger needs to handle the input files in more than one pass for example when there is more than 1000 input files or the -n option is passed to hadd.; Fix support for emulated class that derived from an abstract class.; This can happen when reading a file containing an ancient; class layout where the derived class is no longer provided in the; compiled code but the abstract base class is still provided. It also happens when using schema evolution rules on a class derived; from an abstract base class (in which case the system introduce; implicitly an emulated class deriving from the same base classes; as the evolved from class). To fix the issue, we introdu",MatchSource.DOCS,tree/doc/v534/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/doc/v534/index.html
https://github.com/root-project/root/tree/v6-32-06/tutorials/doc/v528/index.html:319,Integrability,interface,interface,319,". Tutorials. New tutorial $ROOTSYS/tutorials/graphics/mass_spectrum.C. It; produces the following output:; . New tutorial $ROOTSYS/math/goftest.C showing the example; usage of the new ROOT::Math::GoFTest class. New tutorial $ROOTSYS/math/multiDimSampling.C showing the example; usage of the new ROOT::Math::DistSampler interface for; random generation from arbitrary functions using Unuran or Foam. New tutorial $ROOTSYS/math/kdTreeBinning.C showing the example; usage of the new TKDTreeBinning class. New tutorial $ROOTSYS/fit/NumericalMinimization.C showing; a minimization example (Rosenbrock function) using the; ROOT::Math::Minimizer interface. New tutorial $ROOTSYS/fit/exampleFit3D.C showing; a simple fit example of 3D points with a 3D function. New tutorial $ROOTSYS/fit/TSVDUnfoldExample.C showing; an example of the new TSVDUnfold class. New Roostats tutorials:. New Demos that take name for file, workspace, modelconfig, and data, then use the corresponding calculator tool. If the file is not specified it will read an file produced from running the HistFactory tutorial example. StandardProfileLikelihoodDemo.C: ; StandardFeldmanCousinsDemo.C: ; StandardBayesianMCMCDemo.C: ; StandardBayesianNumericalDemo.C: ; StandardProfileInspectorDemo.C: . Demonstrate some new PDFs. TestNonCentral.C: demonstrates non central chi-square; JeffreysPriorDemo.C: demonstrates Jeffreys Prior. Instructional Examples. IntervalExamples.C: Standard Gaussian with known answer using 4 techniques; FourBinInstructional.C: Example of a standard data-driven approach for estimating backgrounds. A lot of discussion.; HybridInstructional.C: Example of protoype on/off problem with a data-driven background estimate. A lot of discussion; HybridStandardForm.C: Variant on above in 'standard form'; MultivariateGaussianTest.C: A validation example with an N-D multivariate Gaussian . Renamed the rs201_hybridcalculator.C to; HybridOriginalDemo.C; Removed some obsolete roostats tutorials (all the rs500 types). ",MatchSource.DOCS,tutorials/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/tutorials/doc/v528/index.html:639,Integrability,interface,interface,639,". Tutorials. New tutorial $ROOTSYS/tutorials/graphics/mass_spectrum.C. It; produces the following output:; . New tutorial $ROOTSYS/math/goftest.C showing the example; usage of the new ROOT::Math::GoFTest class. New tutorial $ROOTSYS/math/multiDimSampling.C showing the example; usage of the new ROOT::Math::DistSampler interface for; random generation from arbitrary functions using Unuran or Foam. New tutorial $ROOTSYS/math/kdTreeBinning.C showing the example; usage of the new TKDTreeBinning class. New tutorial $ROOTSYS/fit/NumericalMinimization.C showing; a minimization example (Rosenbrock function) using the; ROOT::Math::Minimizer interface. New tutorial $ROOTSYS/fit/exampleFit3D.C showing; a simple fit example of 3D points with a 3D function. New tutorial $ROOTSYS/fit/TSVDUnfoldExample.C showing; an example of the new TSVDUnfold class. New Roostats tutorials:. New Demos that take name for file, workspace, modelconfig, and data, then use the corresponding calculator tool. If the file is not specified it will read an file produced from running the HistFactory tutorial example. StandardProfileLikelihoodDemo.C: ; StandardFeldmanCousinsDemo.C: ; StandardBayesianMCMCDemo.C: ; StandardBayesianNumericalDemo.C: ; StandardProfileInspectorDemo.C: . Demonstrate some new PDFs. TestNonCentral.C: demonstrates non central chi-square; JeffreysPriorDemo.C: demonstrates Jeffreys Prior. Instructional Examples. IntervalExamples.C: Standard Gaussian with known answer using 4 techniques; FourBinInstructional.C: Example of a standard data-driven approach for estimating backgrounds. A lot of discussion.; HybridInstructional.C: Example of protoype on/off problem with a data-driven background estimate. A lot of discussion; HybridStandardForm.C: Variant on above in 'standard form'; MultivariateGaussianTest.C: A validation example with an N-D multivariate Gaussian . Renamed the rs201_hybridcalculator.C to; HybridOriginalDemo.C; Removed some obsolete roostats tutorials (all the rs500 types). ",MatchSource.DOCS,tutorials/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/tutorials/doc/v528/index.html:1816,Security,validat,validation,1816,". Tutorials. New tutorial $ROOTSYS/tutorials/graphics/mass_spectrum.C. It; produces the following output:; . New tutorial $ROOTSYS/math/goftest.C showing the example; usage of the new ROOT::Math::GoFTest class. New tutorial $ROOTSYS/math/multiDimSampling.C showing the example; usage of the new ROOT::Math::DistSampler interface for; random generation from arbitrary functions using Unuran or Foam. New tutorial $ROOTSYS/math/kdTreeBinning.C showing the example; usage of the new TKDTreeBinning class. New tutorial $ROOTSYS/fit/NumericalMinimization.C showing; a minimization example (Rosenbrock function) using the; ROOT::Math::Minimizer interface. New tutorial $ROOTSYS/fit/exampleFit3D.C showing; a simple fit example of 3D points with a 3D function. New tutorial $ROOTSYS/fit/TSVDUnfoldExample.C showing; an example of the new TSVDUnfold class. New Roostats tutorials:. New Demos that take name for file, workspace, modelconfig, and data, then use the corresponding calculator tool. If the file is not specified it will read an file produced from running the HistFactory tutorial example. StandardProfileLikelihoodDemo.C: ; StandardFeldmanCousinsDemo.C: ; StandardBayesianMCMCDemo.C: ; StandardBayesianNumericalDemo.C: ; StandardProfileInspectorDemo.C: . Demonstrate some new PDFs. TestNonCentral.C: demonstrates non central chi-square; JeffreysPriorDemo.C: demonstrates Jeffreys Prior. Instructional Examples. IntervalExamples.C: Standard Gaussian with known answer using 4 techniques; FourBinInstructional.C: Example of a standard data-driven approach for estimating backgrounds. A lot of discussion.; HybridInstructional.C: Example of protoype on/off problem with a data-driven background estimate. A lot of discussion; HybridStandardForm.C: Variant on above in 'standard form'; MultivariateGaussianTest.C: A validation example with an N-D multivariate Gaussian . Renamed the rs201_hybridcalculator.C to; HybridOriginalDemo.C; Removed some obsolete roostats tutorials (all the rs500 types). ",MatchSource.DOCS,tutorials/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/tutorials/doc/v528/index.html:702,Usability,simpl,simple,702,". Tutorials. New tutorial $ROOTSYS/tutorials/graphics/mass_spectrum.C. It; produces the following output:; . New tutorial $ROOTSYS/math/goftest.C showing the example; usage of the new ROOT::Math::GoFTest class. New tutorial $ROOTSYS/math/multiDimSampling.C showing the example; usage of the new ROOT::Math::DistSampler interface for; random generation from arbitrary functions using Unuran or Foam. New tutorial $ROOTSYS/math/kdTreeBinning.C showing the example; usage of the new TKDTreeBinning class. New tutorial $ROOTSYS/fit/NumericalMinimization.C showing; a minimization example (Rosenbrock function) using the; ROOT::Math::Minimizer interface. New tutorial $ROOTSYS/fit/exampleFit3D.C showing; a simple fit example of 3D points with a 3D function. New tutorial $ROOTSYS/fit/TSVDUnfoldExample.C showing; an example of the new TSVDUnfold class. New Roostats tutorials:. New Demos that take name for file, workspace, modelconfig, and data, then use the corresponding calculator tool. If the file is not specified it will read an file produced from running the HistFactory tutorial example. StandardProfileLikelihoodDemo.C: ; StandardFeldmanCousinsDemo.C: ; StandardBayesianMCMCDemo.C: ; StandardBayesianNumericalDemo.C: ; StandardProfileInspectorDemo.C: . Demonstrate some new PDFs. TestNonCentral.C: demonstrates non central chi-square; JeffreysPriorDemo.C: demonstrates Jeffreys Prior. Instructional Examples. IntervalExamples.C: Standard Gaussian with known answer using 4 techniques; FourBinInstructional.C: Example of a standard data-driven approach for estimating backgrounds. A lot of discussion.; HybridInstructional.C: Example of protoype on/off problem with a data-driven background estimate. A lot of discussion; HybridStandardForm.C: Variant on above in 'standard form'; MultivariateGaussianTest.C: A validation example with an N-D multivariate Gaussian . Renamed the rs201_hybridcalculator.C to; HybridOriginalDemo.C; Removed some obsolete roostats tutorials (all the rs500 types). ",MatchSource.DOCS,tutorials/doc/v528/index.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/doc/v528/index.html
https://github.com/root-project/root/tree/v6-32-06/tutorials/webgui/ping/ping.html:13,Performance,latency,latency,13,. RWebWindow latency test. Halt; Draw; Main: Msg. ,MatchSource.DOCS,tutorials/webgui/ping/ping.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/webgui/ping/ping.html
https://github.com/root-project/root/tree/v6-32-06/tutorials/webgui/ping/ping.html:21,Testability,test,test,21,. RWebWindow latency test. Halt; Draw; Main: Msg. ,MatchSource.DOCS,tutorials/webgui/ping/ping.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/webgui/ping/ping.html
https://github.com/root-project/root/tree/v6-32-06/tutorials/webgui/webwindow/webwindow.html:13,Testability,test,test,13,. RWebWindow test. Text; Binary; Halt. ,MatchSource.DOCS,tutorials/webgui/webwindow/webwindow.html,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/webgui/webwindow/webwindow.html
