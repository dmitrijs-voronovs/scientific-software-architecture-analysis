id,quality_attribute,keyword,matched_word,match_idx,sentence,source,filename,author,repo,version,wiki,url
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:43543,Energy Efficiency,schedul,scheduling,43543,"d barrier to execute. A load/store barrier is; ""executed"" when it becomes the oldest entry in the load/store queue(s). That; also means, by construction, all of the older loads/stores have been executed. In conclusion, the full set of load/store consistency rules are:. #. A store may not pass a previous store.; #. A store may not pass a previous load (regardless of ``-noalias``).; #. A store has to wait until an older store barrier is fully executed.; #. A load may pass a previous load.; #. A load may not pass a previous store unless ``-noalias`` is set.; #. A load has to wait until an older load barrier is fully executed. In-order Issue and Execute; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; In-order processors are modelled as a single ``InOrderIssueStage`` stage. It; bypasses Dispatch, Scheduler and Load/Store unit. Instructions are issued as; soon as their operand registers are available and resource requirements are; met. Multiple instructions can be issued in one cycle according to the value of; the ``IssueWidth`` parameter in LLVM's scheduling model. Once issued, an instruction is moved to ``IssuedInst`` set until it is ready to; retire. :program:`llvm-mca` ensures that writes are committed in-order. However,; an instruction is allowed to commit writes and retire out-of-order if; ``RetireOOO`` property is true for at least one of its writes. Custom Behaviour; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; Due to certain instructions not being expressed perfectly within their; scheduling model, :program:`llvm-mca` isn't always able to simulate them; perfectly. Modifying the scheduling model isn't always a viable; option though (maybe because the instruction is modeled incorrectly on; purpose or the instruction's behaviour is quite complex). The; CustomBehaviour class can be used in these cases to enforce proper; instruction modeling (often by customizing data dependencies and detecting; hazards that :program:`llvm-mca` has no way of knowing about). :program:`llvm-mca` comes w",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:43986,Energy Efficiency,schedul,scheduling,43986,"pass a previous load.; #. A load may not pass a previous store unless ``-noalias`` is set.; #. A load has to wait until an older load barrier is fully executed. In-order Issue and Execute; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; In-order processors are modelled as a single ``InOrderIssueStage`` stage. It; bypasses Dispatch, Scheduler and Load/Store unit. Instructions are issued as; soon as their operand registers are available and resource requirements are; met. Multiple instructions can be issued in one cycle according to the value of; the ``IssueWidth`` parameter in LLVM's scheduling model. Once issued, an instruction is moved to ``IssuedInst`` set until it is ready to; retire. :program:`llvm-mca` ensures that writes are committed in-order. However,; an instruction is allowed to commit writes and retire out-of-order if; ``RetireOOO`` property is true for at least one of its writes. Custom Behaviour; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; Due to certain instructions not being expressed perfectly within their; scheduling model, :program:`llvm-mca` isn't always able to simulate them; perfectly. Modifying the scheduling model isn't always a viable; option though (maybe because the instruction is modeled incorrectly on; purpose or the instruction's behaviour is quite complex). The; CustomBehaviour class can be used in these cases to enforce proper; instruction modeling (often by customizing data dependencies and detecting; hazards that :program:`llvm-mca` has no way of knowing about). :program:`llvm-mca` comes with one generic and multiple target specific; CustomBehaviour classes. The generic class will be used if the ``-disable-cb``; flag is used or if a target specific CustomBehaviour class doesn't exist for; that target. (The generic class does nothing.) Currently, the CustomBehaviour; class is only a part of the in-order pipeline, but there are plans to add it; to the out-of-order pipeline in the future. CustomBehaviour's main method is `checkCustomHazard()` which uses",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:44085,Energy Efficiency,schedul,scheduling,44085,"""""""""""""""""""""""""""""""""""""""""""""""""""""; In-order processors are modelled as a single ``InOrderIssueStage`` stage. It; bypasses Dispatch, Scheduler and Load/Store unit. Instructions are issued as; soon as their operand registers are available and resource requirements are; met. Multiple instructions can be issued in one cycle according to the value of; the ``IssueWidth`` parameter in LLVM's scheduling model. Once issued, an instruction is moved to ``IssuedInst`` set until it is ready to; retire. :program:`llvm-mca` ensures that writes are committed in-order. However,; an instruction is allowed to commit writes and retire out-of-order if; ``RetireOOO`` property is true for at least one of its writes. Custom Behaviour; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; Due to certain instructions not being expressed perfectly within their; scheduling model, :program:`llvm-mca` isn't always able to simulate them; perfectly. Modifying the scheduling model isn't always a viable; option though (maybe because the instruction is modeled incorrectly on; purpose or the instruction's behaviour is quite complex). The; CustomBehaviour class can be used in these cases to enforce proper; instruction modeling (often by customizing data dependencies and detecting; hazards that :program:`llvm-mca` has no way of knowing about). :program:`llvm-mca` comes with one generic and multiple target specific; CustomBehaviour classes. The generic class will be used if the ``-disable-cb``; flag is used or if a target specific CustomBehaviour class doesn't exist for; that target. (The generic class does nothing.) Currently, the CustomBehaviour; class is only a part of the in-order pipeline, but there are plans to add it; to the out-of-order pipeline in the future. CustomBehaviour's main method is `checkCustomHazard()` which uses the; current instruction and a list of all instructions still executing within; the pipeline to determine if the current instruction should be dispatched.; As output, the method returns an integer ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:45732,Energy Efficiency,schedul,scheduling,45732,"CustomBehaviour; class is only a part of the in-order pipeline, but there are plans to add it; to the out-of-order pipeline in the future. CustomBehaviour's main method is `checkCustomHazard()` which uses the; current instruction and a list of all instructions still executing within; the pipeline to determine if the current instruction should be dispatched.; As output, the method returns an integer representing the number of cycles; that the current instruction must stall for (this can be an underestimate; if you don't know the exact number and a value of 0 represents no stall). If you'd like to add a CustomBehaviour class for a target that doesn't; already have one, refer to an existing implementation to see how to set it; up. The classes are implemented within the target specific backend (for; example `/llvm/lib/Target/AMDGPU/MCA/`) so that they can access backend symbols. Instrument Manager; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; On certain architectures, scheduling information for certain instructions; do not contain all of the information required to identify the most precise; schedule class. For example, data that can have an impact on scheduling can; be stored in CSR registers. One example of this is on RISCV, where values in registers such as `vtype`; and `vl` change the scheduling behaviour of vector instructions. Since MCA; does not keep track of the values in registers, instrument comments can; be used to specify these values. InstrumentManager's main function is `getSchedClassID()` which has access; to the MCInst and all of the instruments that are active for that MCInst.; This function can use the instruments to override the schedule class of; the MCInst. On RISCV, instrument comments containing LMUL information are used; by `getSchedClassID()` to map a vector instruction and the active; LMUL to the scheduling class of the pseudo-instruction that describes; that base instruction and the active LMUL. Custom Views; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; :pr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:45858,Energy Efficiency,schedul,schedule,45858,"CustomBehaviour; class is only a part of the in-order pipeline, but there are plans to add it; to the out-of-order pipeline in the future. CustomBehaviour's main method is `checkCustomHazard()` which uses the; current instruction and a list of all instructions still executing within; the pipeline to determine if the current instruction should be dispatched.; As output, the method returns an integer representing the number of cycles; that the current instruction must stall for (this can be an underestimate; if you don't know the exact number and a value of 0 represents no stall). If you'd like to add a CustomBehaviour class for a target that doesn't; already have one, refer to an existing implementation to see how to set it; up. The classes are implemented within the target specific backend (for; example `/llvm/lib/Target/AMDGPU/MCA/`) so that they can access backend symbols. Instrument Manager; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; On certain architectures, scheduling information for certain instructions; do not contain all of the information required to identify the most precise; schedule class. For example, data that can have an impact on scheduling can; be stored in CSR registers. One example of this is on RISCV, where values in registers such as `vtype`; and `vl` change the scheduling behaviour of vector instructions. Since MCA; does not keep track of the values in registers, instrument comments can; be used to specify these values. InstrumentManager's main function is `getSchedClassID()` which has access; to the MCInst and all of the instruments that are active for that MCInst.; This function can use the instruments to override the schedule class of; the MCInst. On RISCV, instrument comments containing LMUL information are used; by `getSchedClassID()` to map a vector instruction and the active; LMUL to the scheduling class of the pseudo-instruction that describes; that base instruction and the active LMUL. Custom Views; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; :pr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:45919,Energy Efficiency,schedul,scheduling,45919,"main method is `checkCustomHazard()` which uses the; current instruction and a list of all instructions still executing within; the pipeline to determine if the current instruction should be dispatched.; As output, the method returns an integer representing the number of cycles; that the current instruction must stall for (this can be an underestimate; if you don't know the exact number and a value of 0 represents no stall). If you'd like to add a CustomBehaviour class for a target that doesn't; already have one, refer to an existing implementation to see how to set it; up. The classes are implemented within the target specific backend (for; example `/llvm/lib/Target/AMDGPU/MCA/`) so that they can access backend symbols. Instrument Manager; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; On certain architectures, scheduling information for certain instructions; do not contain all of the information required to identify the most precise; schedule class. For example, data that can have an impact on scheduling can; be stored in CSR registers. One example of this is on RISCV, where values in registers such as `vtype`; and `vl` change the scheduling behaviour of vector instructions. Since MCA; does not keep track of the values in registers, instrument comments can; be used to specify these values. InstrumentManager's main function is `getSchedClassID()` which has access; to the MCInst and all of the instruments that are active for that MCInst.; This function can use the instruments to override the schedule class of; the MCInst. On RISCV, instrument comments containing LMUL information are used; by `getSchedClassID()` to map a vector instruction and the active; LMUL to the scheduling class of the pseudo-instruction that describes; that base instruction and the active LMUL. Custom Views; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; :program:`llvm-mca` comes with several Views such as the Timeline View and; Summary View. These Views are generic and can work with most (if not all); targets. I",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:46059,Energy Efficiency,schedul,scheduling,46059,"ting within; the pipeline to determine if the current instruction should be dispatched.; As output, the method returns an integer representing the number of cycles; that the current instruction must stall for (this can be an underestimate; if you don't know the exact number and a value of 0 represents no stall). If you'd like to add a CustomBehaviour class for a target that doesn't; already have one, refer to an existing implementation to see how to set it; up. The classes are implemented within the target specific backend (for; example `/llvm/lib/Target/AMDGPU/MCA/`) so that they can access backend symbols. Instrument Manager; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; On certain architectures, scheduling information for certain instructions; do not contain all of the information required to identify the most precise; schedule class. For example, data that can have an impact on scheduling can; be stored in CSR registers. One example of this is on RISCV, where values in registers such as `vtype`; and `vl` change the scheduling behaviour of vector instructions. Since MCA; does not keep track of the values in registers, instrument comments can; be used to specify these values. InstrumentManager's main function is `getSchedClassID()` which has access; to the MCInst and all of the instruments that are active for that MCInst.; This function can use the instruments to override the schedule class of; the MCInst. On RISCV, instrument comments containing LMUL information are used; by `getSchedClassID()` to map a vector instruction and the active; LMUL to the scheduling class of the pseudo-instruction that describes; that base instruction and the active LMUL. Custom Views; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; :program:`llvm-mca` comes with several Views such as the Timeline View and; Summary View. These Views are generic and can work with most (if not all); targets. If you wish to add a new View to :program:`llvm-mca` and it does not; require any backend functionality that is not ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:46425,Energy Efficiency,schedul,schedule,46425,"sn't; already have one, refer to an existing implementation to see how to set it; up. The classes are implemented within the target specific backend (for; example `/llvm/lib/Target/AMDGPU/MCA/`) so that they can access backend symbols. Instrument Manager; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; On certain architectures, scheduling information for certain instructions; do not contain all of the information required to identify the most precise; schedule class. For example, data that can have an impact on scheduling can; be stored in CSR registers. One example of this is on RISCV, where values in registers such as `vtype`; and `vl` change the scheduling behaviour of vector instructions. Since MCA; does not keep track of the values in registers, instrument comments can; be used to specify these values. InstrumentManager's main function is `getSchedClassID()` which has access; to the MCInst and all of the instruments that are active for that MCInst.; This function can use the instruments to override the schedule class of; the MCInst. On RISCV, instrument comments containing LMUL information are used; by `getSchedClassID()` to map a vector instruction and the active; LMUL to the scheduling class of the pseudo-instruction that describes; that base instruction and the active LMUL. Custom Views; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; :program:`llvm-mca` comes with several Views such as the Timeline View and; Summary View. These Views are generic and can work with most (if not all); targets. If you wish to add a new View to :program:`llvm-mca` and it does not; require any backend functionality that is not already exposed through MC layer; classes (MCSubtargetInfo, MCInstrInfo, etc.), please add it to the; `/tools/llvm-mca/View/` directory. However, if your new View is target specific; AND requires unexposed backend symbols or functionality, you can define it in; the `/lib/Target/<TargetName>/MCA/` directory. To enable this target specific View, you will have to use this target'",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:46603,Energy Efficiency,schedul,scheduling,46603,"vm/lib/Target/AMDGPU/MCA/`) so that they can access backend symbols. Instrument Manager; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; On certain architectures, scheduling information for certain instructions; do not contain all of the information required to identify the most precise; schedule class. For example, data that can have an impact on scheduling can; be stored in CSR registers. One example of this is on RISCV, where values in registers such as `vtype`; and `vl` change the scheduling behaviour of vector instructions. Since MCA; does not keep track of the values in registers, instrument comments can; be used to specify these values. InstrumentManager's main function is `getSchedClassID()` which has access; to the MCInst and all of the instruments that are active for that MCInst.; This function can use the instruments to override the schedule class of; the MCInst. On RISCV, instrument comments containing LMUL information are used; by `getSchedClassID()` to map a vector instruction and the active; LMUL to the scheduling class of the pseudo-instruction that describes; that base instruction and the active LMUL. Custom Views; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; :program:`llvm-mca` comes with several Views such as the Timeline View and; Summary View. These Views are generic and can work with most (if not all); targets. If you wish to add a new View to :program:`llvm-mca` and it does not; require any backend functionality that is not already exposed through MC layer; classes (MCSubtargetInfo, MCInstrInfo, etc.), please add it to the; `/tools/llvm-mca/View/` directory. However, if your new View is target specific; AND requires unexposed backend symbols or functionality, you can define it in; the `/lib/Target/<TargetName>/MCA/` directory. To enable this target specific View, you will have to use this target's; CustomBehaviour class to override the `CustomBehaviour::getViews()` methods.; There are 3 variations of these methods based on where you want your View to; appear in",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:8020,Integrability,message,message,8020," format. The instructions and the; processor resources are printed as members of special top level JSON objects.; The individual views refer to them by index. However, not all views are; currently supported. For example, the report from the bottleneck analysis is; not printed out in JSON. All the default views are currently supported. .. option:: -disable-cb. Force usage of the generic CustomBehaviour and InstrPostProcess classes rather; than using the target specific implementation. The generic classes never; detect any custom hazards or make any post processing modifications to; instructions. .. option:: -disable-im. Force usage of the generic InstrumentManager rather than using the target; specific implementation. The generic class creates Instruments that provide; no extra information, and InstrumentManager never overrides the default; schedule class for a given instruction. EXIT STATUS; -----------. :program:`llvm-mca` returns 0 on success. Otherwise, an error message is printed; to standard error, and the tool returns 1. USING MARKERS TO ANALYZE SPECIFIC CODE BLOCKS; ---------------------------------------------; :program:`llvm-mca` allows for the optional usage of special code comments to; mark regions of the assembly code to be analyzed. A comment starting with; substring ``LLVM-MCA-BEGIN`` marks the beginning of an analysis region. A; comment starting with substring ``LLVM-MCA-END`` marks the end of a region.; For example:. .. code-block:: none. # LLVM-MCA-BEGIN; ...; # LLVM-MCA-END. If no user-defined region is specified, then :program:`llvm-mca` assumes a; default region which contains every instruction in the input file. Every region; is analyzed in isolation, and the final performance report is the union of all; the reports generated for every analysis region. Analysis regions can have names. For example:. .. code-block:: none. # LLVM-MCA-BEGIN A simple example; add %eax, %eax; # LLVM-MCA-END. The code from the example above defines a region named ""A sim",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:12065,Integrability,depend,depending,12065,"`. A comment starting with substring `LLVM-MCA-<INSTRUMENT_TYPE>`; brings data into scope for llvm-mca to use in its analysis for; all following instructions. If a comment with the same `INSTRUMENT_TYPE` is found later in the; instruction list, then the original InstrumentRegion will be; automatically ended, and a new InstrumentRegion will begin. If there are comments containing the different `INSTRUMENT_TYPE`,; then both data sets remain available. In contrast with an AnalysisRegion,; an InstrumentRegion does not need a comment to end the region. Comments that are prefixed with `LLVM-MCA-` but do not correspond to; a valid `INSTRUMENT_TYPE` for the target cause an error, except for; `BEGIN` and `END`, since those correspond to AnalysisRegions. Comments; that do not start with `LLVM-MCA-` are ignored by :program `llvm-mca`. An instruction (a MCInst) is added to an InstrumentRegion R only; if its location is in range [R.RangeStart, R.RangeEnd]. On RISCV targets, vector instructions have different behaviour depending; on the LMUL. Code can be instrumented with a comment that takes the; following form:. .. code-block:: none. # LLVM-MCA-RISCV-LMUL <M1|M2|M4|M8|MF2|MF4|MF8>. The RISCV InstrumentManager will override the schedule class for vector; instructions to use the scheduling behaviour of its pseudo-instruction; which is LMUL dependent. It makes sense to place RISCV instrument; comments directly after `vset{i}vl{i}` instructions, although; they can be placed anywhere in the program. Example of program with no call to `vset{i}vl{i}`:. .. code-block:: none. # LLVM-MCA-RISCV-LMUL M2; vadd.vv v2, v2, v2. Example of program with call to `vset{i}vl{i}`:. .. code-block:: none. vsetvli zero, a0, e8, m1, tu, mu; # LLVM-MCA-RISCV-LMUL M1; vadd.vv v2, v2, v2. Example of program with multiple calls to `vset{i}vl{i}`:. .. code-block:: none. vsetvli zero, a0, e8, m1, tu, mu; # LLVM-MCA-RISCV-LMUL M1; vadd.vv v2, v2, v2; vsetvli zero, a0, e8, m8, tu, mu; # LLVM-MCA-RISCV-LMUL M8; v",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:12392,Integrability,depend,dependent,12392,"Region will be; automatically ended, and a new InstrumentRegion will begin. If there are comments containing the different `INSTRUMENT_TYPE`,; then both data sets remain available. In contrast with an AnalysisRegion,; an InstrumentRegion does not need a comment to end the region. Comments that are prefixed with `LLVM-MCA-` but do not correspond to; a valid `INSTRUMENT_TYPE` for the target cause an error, except for; `BEGIN` and `END`, since those correspond to AnalysisRegions. Comments; that do not start with `LLVM-MCA-` are ignored by :program `llvm-mca`. An instruction (a MCInst) is added to an InstrumentRegion R only; if its location is in range [R.RangeStart, R.RangeEnd]. On RISCV targets, vector instructions have different behaviour depending; on the LMUL. Code can be instrumented with a comment that takes the; following form:. .. code-block:: none. # LLVM-MCA-RISCV-LMUL <M1|M2|M4|M8|MF2|MF4|MF8>. The RISCV InstrumentManager will override the schedule class for vector; instructions to use the scheduling behaviour of its pseudo-instruction; which is LMUL dependent. It makes sense to place RISCV instrument; comments directly after `vset{i}vl{i}` instructions, although; they can be placed anywhere in the program. Example of program with no call to `vset{i}vl{i}`:. .. code-block:: none. # LLVM-MCA-RISCV-LMUL M2; vadd.vv v2, v2, v2. Example of program with call to `vset{i}vl{i}`:. .. code-block:: none. vsetvli zero, a0, e8, m1, tu, mu; # LLVM-MCA-RISCV-LMUL M1; vadd.vv v2, v2, v2. Example of program with multiple calls to `vset{i}vl{i}`:. .. code-block:: none. vsetvli zero, a0, e8, m1, tu, mu; # LLVM-MCA-RISCV-LMUL M1; vadd.vv v2, v2, v2; vsetvli zero, a0, e8, m8, tu, mu; # LLVM-MCA-RISCV-LMUL M8; vadd.vv v2, v2, v2. Example of program with call to `vsetvl`:. .. code-block:: none. vsetvl rd, rs1, rs2; # LLVM-MCA-RISCV-LMUL M1; vadd.vv v12, v12, v12; vsetvl rd, rs1, rs2; # LLVM-MCA-RISCV-LMUL M4; vadd.vv v12, v12, v12. HOW LLVM-MCA WORKS; ------------------. :program",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:16529,Integrability,depend,dependencies,16529,"900 simulated instructions. The total number of simulated micro; opcodes (uOps) is also 900. The report is structured in three main sections. The first section collects a; few performance numbers; the goal of this section is to give a very quick; overview of the performance throughput. Important performance indicators are; **IPC**, **uOps Per Cycle**, and **Block RThroughput** (Block Reciprocal; Throughput). Field *DispatchWidth* is the maximum number of micro opcodes that are dispatched; to the out-of-order backend every simulated cycle. For processors with an; in-order backend, *DispatchWidth* is the maximum number of micro opcodes issued; to the backend every simulated cycle. IPC is computed dividing the total number of simulated instructions by the total; number of cycles. Field *Block RThroughput* is the reciprocal of the block throughput. Block; throughput is a theoretical quantity computed as the maximum number of blocks; (i.e. iterations) that can be executed per simulated clock cycle in the absence; of loop carried dependencies. Block throughput is superiorly limited by the; dispatch rate, and the availability of hardware resources. In the absence of loop-carried data dependencies, the observed IPC tends to a; theoretical maximum which can be computed by dividing the number of instructions; of a single iteration by the `Block RThroughput`. Field 'uOps Per Cycle' is computed dividing the total number of simulated micro; opcodes by the total number of cycles. A delta between Dispatch Width and this; field is an indicator of a performance issue. In the absence of loop-carried; data dependencies, the observed 'uOps Per Cycle' should tend to a theoretical; maximum throughput which can be computed by dividing the number of uOps of a; single iteration by the `Block RThroughput`. Field *uOps Per Cycle* is bounded from above by the dispatch width. That is; because the dispatch width limits the maximum size of a dispatch group. Both IPC; and 'uOps Per Cycle' are limit",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:16685,Integrability,depend,dependencies,16685,"erformance throughput. Important performance indicators are; **IPC**, **uOps Per Cycle**, and **Block RThroughput** (Block Reciprocal; Throughput). Field *DispatchWidth* is the maximum number of micro opcodes that are dispatched; to the out-of-order backend every simulated cycle. For processors with an; in-order backend, *DispatchWidth* is the maximum number of micro opcodes issued; to the backend every simulated cycle. IPC is computed dividing the total number of simulated instructions by the total; number of cycles. Field *Block RThroughput* is the reciprocal of the block throughput. Block; throughput is a theoretical quantity computed as the maximum number of blocks; (i.e. iterations) that can be executed per simulated clock cycle in the absence; of loop carried dependencies. Block throughput is superiorly limited by the; dispatch rate, and the availability of hardware resources. In the absence of loop-carried data dependencies, the observed IPC tends to a; theoretical maximum which can be computed by dividing the number of instructions; of a single iteration by the `Block RThroughput`. Field 'uOps Per Cycle' is computed dividing the total number of simulated micro; opcodes by the total number of cycles. A delta between Dispatch Width and this; field is an indicator of a performance issue. In the absence of loop-carried; data dependencies, the observed 'uOps Per Cycle' should tend to a theoretical; maximum throughput which can be computed by dividing the number of uOps of a; single iteration by the `Block RThroughput`. Field *uOps Per Cycle* is bounded from above by the dispatch width. That is; because the dispatch width limits the maximum size of a dispatch group. Both IPC; and 'uOps Per Cycle' are limited by the amount of hardware parallelism. The; availability of hardware resources affects the resource pressure distribution,; and it limits the number of instructions that can be executed in parallel every; cycle. A delta between Dispatch Width and the theoretica",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:17104,Integrability,depend,dependencies,17104," computed dividing the total number of simulated instructions by the total; number of cycles. Field *Block RThroughput* is the reciprocal of the block throughput. Block; throughput is a theoretical quantity computed as the maximum number of blocks; (i.e. iterations) that can be executed per simulated clock cycle in the absence; of loop carried dependencies. Block throughput is superiorly limited by the; dispatch rate, and the availability of hardware resources. In the absence of loop-carried data dependencies, the observed IPC tends to a; theoretical maximum which can be computed by dividing the number of instructions; of a single iteration by the `Block RThroughput`. Field 'uOps Per Cycle' is computed dividing the total number of simulated micro; opcodes by the total number of cycles. A delta between Dispatch Width and this; field is an indicator of a performance issue. In the absence of loop-carried; data dependencies, the observed 'uOps Per Cycle' should tend to a theoretical; maximum throughput which can be computed by dividing the number of uOps of a; single iteration by the `Block RThroughput`. Field *uOps Per Cycle* is bounded from above by the dispatch width. That is; because the dispatch width limits the maximum size of a dispatch group. Both IPC; and 'uOps Per Cycle' are limited by the amount of hardware parallelism. The; availability of hardware resources affects the resource pressure distribution,; and it limits the number of instructions that can be executed in parallel every; cycle. A delta between Dispatch Width and the theoretical maximum uOps per; Cycle (computed by dividing the number of uOps of a single iteration by the; `Block RThroughput`) is an indicator of a performance bottleneck caused by the; lack of hardware resources.; In general, the lower the Block RThroughput, the better. In this example, ``uOps per iteration/Block RThroughput`` is 1.50. Since there; are no loop-carried dependencies, the observed `uOps Per Cycle` is expected to; approa",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:18117,Integrability,depend,dependencies,18117,"s Per Cycle' should tend to a theoretical; maximum throughput which can be computed by dividing the number of uOps of a; single iteration by the `Block RThroughput`. Field *uOps Per Cycle* is bounded from above by the dispatch width. That is; because the dispatch width limits the maximum size of a dispatch group. Both IPC; and 'uOps Per Cycle' are limited by the amount of hardware parallelism. The; availability of hardware resources affects the resource pressure distribution,; and it limits the number of instructions that can be executed in parallel every; cycle. A delta between Dispatch Width and the theoretical maximum uOps per; Cycle (computed by dividing the number of uOps of a single iteration by the; `Block RThroughput`) is an indicator of a performance bottleneck caused by the; lack of hardware resources.; In general, the lower the Block RThroughput, the better. In this example, ``uOps per iteration/Block RThroughput`` is 1.50. Since there; are no loop-carried dependencies, the observed `uOps Per Cycle` is expected to; approach 1.50 when the number of iterations tends to infinity. The delta between; the Dispatch Width (2.00), and the theoretical maximum uOp throughput (1.50) is; an indicator of a performance bottleneck caused by the lack of hardware; resources, and the *Resource pressure view* can help to identify the problematic; resource usage. The second section of the report is the `instruction info view`. It shows the; latency and reciprocal throughput of every instruction in the sequence. It also; reports extra information related to the number of micro opcodes, and opcode; properties (i.e., 'MayLoad', 'MayStore', and 'HasSideEffects'). Field *RThroughput* is the reciprocal of the instruction throughput. Throughput; is computed as the maximum number of instructions of a same type that can be; executed per clock cycle in the absence of operand dependencies. In this; example, the reciprocal throughput of a vector float multiply is 1; cycles/instruction. Th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:19023,Integrability,depend,dependencies,19023,"; In general, the lower the Block RThroughput, the better. In this example, ``uOps per iteration/Block RThroughput`` is 1.50. Since there; are no loop-carried dependencies, the observed `uOps Per Cycle` is expected to; approach 1.50 when the number of iterations tends to infinity. The delta between; the Dispatch Width (2.00), and the theoretical maximum uOp throughput (1.50) is; an indicator of a performance bottleneck caused by the lack of hardware; resources, and the *Resource pressure view* can help to identify the problematic; resource usage. The second section of the report is the `instruction info view`. It shows the; latency and reciprocal throughput of every instruction in the sequence. It also; reports extra information related to the number of micro opcodes, and opcode; properties (i.e., 'MayLoad', 'MayStore', and 'HasSideEffects'). Field *RThroughput* is the reciprocal of the instruction throughput. Throughput; is computed as the maximum number of instructions of a same type that can be; executed per clock cycle in the absence of operand dependencies. In this; example, the reciprocal throughput of a vector float multiply is 1; cycles/instruction. That is because the FP multiplier JFPM is only available; from pipeline JFPU1. Instruction encodings are displayed within the instruction info view when flag; `-show-encoding` is specified. Below is an example of `-show-encoding` output for the dot-product kernel:. .. code-block:: none. Instruction Info:; [1]: #uOps; [2]: Latency; [3]: RThroughput; [4]: MayLoad; [5]: MayStore; [6]: HasSideEffects (U); [7]: Encoding Size. [1] [2] [3] [4] [5] [6] [7] Encodings: Instructions:; 1 2 1.00 4 c5 f0 59 d0 vmulps	%xmm0, %xmm1, %xmm2; 1 4 1.00 4 c5 eb 7c da vhaddps	%xmm2, %xmm2, %xmm3; 1 4 1.00 4 c5 e3 7c e3 vhaddps	%xmm3, %xmm3, %xmm4. The `Encoding Size` column shows the size in bytes of instructions. The; `Encodings` column shows the actual instruction encodings (byte sequences in; hex). The third section is the *Resource",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:23404,Integrability,depend,dependencies,23404," [2,0] . DeeE-----R . vmulps	%xmm0, %xmm1, %xmm2; [2,1] . D====eeeER . vhaddps	%xmm2, %xmm2, %xmm3; [2,2] . D======eeeER vhaddps	%xmm3, %xmm3, %xmm4. Average Wait times (based on the timeline view):; [0]: Executions; [1]: Average time spent waiting in a scheduler's queue; [2]: Average time spent waiting in a scheduler's queue while ready; [3]: Average time elapsed from WB until retire stage. [0] [1] [2] [3]; 0. 3 1.0 1.0 3.3 vmulps	%xmm0, %xmm1, %xmm2; 1. 3 3.3 0.7 1.0 vhaddps	%xmm2, %xmm2, %xmm3; 2. 3 5.7 0.0 0.0 vhaddps	%xmm3, %xmm3, %xmm4; 3 3.3 0.5 1.4 <total>. The timeline view is interesting because it shows instruction state changes; during execution. It also gives an idea of how the tool processes instructions; executed on the target, and how their timing information might be calculated. The timeline view is structured in two tables. The first table shows; instructions changing state over time (measured in cycles); the second table; (named *Average Wait times*) reports useful timing statistics, which should; help diagnose performance bottlenecks caused by long data dependencies and; sub-optimal usage of hardware resources. An instruction in the timeline view is identified by a pair of indices, where; the first index identifies an iteration, and the second index is the; instruction index (i.e., where it appears in the code sequence). Since this; example was generated using 3 iterations: ``-iterations=3``, the iteration; indices range from 0-2 inclusively. Excluding the first and last column, the remaining columns are in cycles.; Cycles are numbered sequentially starting from 0. From the example output above, we know the following:. * Instruction [1,0] was dispatched at cycle 1.; * Instruction [1,0] started executing at cycle 2.; * Instruction [1,0] reached the write back stage at cycle 4.; * Instruction [1,0] was retired at cycle 10. Instruction [1,0] (i.e., vmulps from iteration #1) does not have to wait in the; scheduler's queue for the operands to become av",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:24909,Integrability,depend,dependency,24909,"e numbered sequentially starting from 0. From the example output above, we know the following:. * Instruction [1,0] was dispatched at cycle 1.; * Instruction [1,0] started executing at cycle 2.; * Instruction [1,0] reached the write back stage at cycle 4.; * Instruction [1,0] was retired at cycle 10. Instruction [1,0] (i.e., vmulps from iteration #1) does not have to wait in the; scheduler's queue for the operands to become available. By the time vmulps is; dispatched, operands are already available, and pipeline JFPU1 is ready to; serve another instruction. So the instruction can be immediately issued on the; JFPU1 pipeline. That is demonstrated by the fact that the instruction only; spent 1cy in the scheduler's queue. There is a gap of 5 cycles between the write-back stage and the retire event.; That is because instructions must retire in program order, so [1,0] has to wait; for [0,2] to be retired first (i.e., it has to wait until cycle 10). In the example, all instructions are in a RAW (Read After Write) dependency; chain. Register %xmm2 written by vmulps is immediately used by the first; vhaddps, and register %xmm3 written by the first vhaddps is used by the second; vhaddps. Long data dependencies negatively impact the ILP (Instruction Level; Parallelism). In the dot-product example, there are anti-dependencies introduced by; instructions from different iterations. However, those dependencies can be; removed at register renaming stage (at the cost of allocating register aliases,; and therefore consuming physical registers). Table *Average Wait times* helps diagnose performance issues that are caused by; the presence of long latency instructions and potentially long data dependencies; which may limit the ILP. Last row, ``<total>``, shows a global average over all; instructions measured. Note that :program:`llvm-mca`, by default, assumes at; least 1cy between the dispatch event and the issue event. When the performance is limited by data dependencies and/or long ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:25094,Integrability,depend,dependencies,25094,"tage at cycle 4.; * Instruction [1,0] was retired at cycle 10. Instruction [1,0] (i.e., vmulps from iteration #1) does not have to wait in the; scheduler's queue for the operands to become available. By the time vmulps is; dispatched, operands are already available, and pipeline JFPU1 is ready to; serve another instruction. So the instruction can be immediately issued on the; JFPU1 pipeline. That is demonstrated by the fact that the instruction only; spent 1cy in the scheduler's queue. There is a gap of 5 cycles between the write-back stage and the retire event.; That is because instructions must retire in program order, so [1,0] has to wait; for [0,2] to be retired first (i.e., it has to wait until cycle 10). In the example, all instructions are in a RAW (Read After Write) dependency; chain. Register %xmm2 written by vmulps is immediately used by the first; vhaddps, and register %xmm3 written by the first vhaddps is used by the second; vhaddps. Long data dependencies negatively impact the ILP (Instruction Level; Parallelism). In the dot-product example, there are anti-dependencies introduced by; instructions from different iterations. However, those dependencies can be; removed at register renaming stage (at the cost of allocating register aliases,; and therefore consuming physical registers). Table *Average Wait times* helps diagnose performance issues that are caused by; the presence of long latency instructions and potentially long data dependencies; which may limit the ILP. Last row, ``<total>``, shows a global average over all; instructions measured. Note that :program:`llvm-mca`, by default, assumes at; least 1cy between the dispatch event and the issue event. When the performance is limited by data dependencies and/or long latency; instructions, the number of cycles spent while in the *ready* state is expected; to be very small when compared with the total number of cycles spent in the; scheduler's queue. The difference between the two counters is a good indi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:25210,Integrability,depend,dependencies,25210,"om iteration #1) does not have to wait in the; scheduler's queue for the operands to become available. By the time vmulps is; dispatched, operands are already available, and pipeline JFPU1 is ready to; serve another instruction. So the instruction can be immediately issued on the; JFPU1 pipeline. That is demonstrated by the fact that the instruction only; spent 1cy in the scheduler's queue. There is a gap of 5 cycles between the write-back stage and the retire event.; That is because instructions must retire in program order, so [1,0] has to wait; for [0,2] to be retired first (i.e., it has to wait until cycle 10). In the example, all instructions are in a RAW (Read After Write) dependency; chain. Register %xmm2 written by vmulps is immediately used by the first; vhaddps, and register %xmm3 written by the first vhaddps is used by the second; vhaddps. Long data dependencies negatively impact the ILP (Instruction Level; Parallelism). In the dot-product example, there are anti-dependencies introduced by; instructions from different iterations. However, those dependencies can be; removed at register renaming stage (at the cost of allocating register aliases,; and therefore consuming physical registers). Table *Average Wait times* helps diagnose performance issues that are caused by; the presence of long latency instructions and potentially long data dependencies; which may limit the ILP. Last row, ``<total>``, shows a global average over all; instructions measured. Note that :program:`llvm-mca`, by default, assumes at; least 1cy between the dispatch event and the issue event. When the performance is limited by data dependencies and/or long latency; instructions, the number of cycles spent while in the *ready* state is expected; to be very small when compared with the total number of cycles spent in the; scheduler's queue. The difference between the two counters is a good indicator; of how large of an impact data dependencies had on the execution of the; instructions. Whe",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:25293,Integrability,depend,dependencies,25293," operands are already available, and pipeline JFPU1 is ready to; serve another instruction. So the instruction can be immediately issued on the; JFPU1 pipeline. That is demonstrated by the fact that the instruction only; spent 1cy in the scheduler's queue. There is a gap of 5 cycles between the write-back stage and the retire event.; That is because instructions must retire in program order, so [1,0] has to wait; for [0,2] to be retired first (i.e., it has to wait until cycle 10). In the example, all instructions are in a RAW (Read After Write) dependency; chain. Register %xmm2 written by vmulps is immediately used by the first; vhaddps, and register %xmm3 written by the first vhaddps is used by the second; vhaddps. Long data dependencies negatively impact the ILP (Instruction Level; Parallelism). In the dot-product example, there are anti-dependencies introduced by; instructions from different iterations. However, those dependencies can be; removed at register renaming stage (at the cost of allocating register aliases,; and therefore consuming physical registers). Table *Average Wait times* helps diagnose performance issues that are caused by; the presence of long latency instructions and potentially long data dependencies; which may limit the ILP. Last row, ``<total>``, shows a global average over all; instructions measured. Note that :program:`llvm-mca`, by default, assumes at; least 1cy between the dispatch event and the issue event. When the performance is limited by data dependencies and/or long latency; instructions, the number of cycles spent while in the *ready* state is expected; to be very small when compared with the total number of cycles spent in the; scheduler's queue. The difference between the two counters is a good indicator; of how large of an impact data dependencies had on the execution of the; instructions. When performance is mostly limited by the lack of hardware; resources, the delta between the two counters is small. However, the number of;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:25589,Integrability,depend,dependencies,25589,"trated by the fact that the instruction only; spent 1cy in the scheduler's queue. There is a gap of 5 cycles between the write-back stage and the retire event.; That is because instructions must retire in program order, so [1,0] has to wait; for [0,2] to be retired first (i.e., it has to wait until cycle 10). In the example, all instructions are in a RAW (Read After Write) dependency; chain. Register %xmm2 written by vmulps is immediately used by the first; vhaddps, and register %xmm3 written by the first vhaddps is used by the second; vhaddps. Long data dependencies negatively impact the ILP (Instruction Level; Parallelism). In the dot-product example, there are anti-dependencies introduced by; instructions from different iterations. However, those dependencies can be; removed at register renaming stage (at the cost of allocating register aliases,; and therefore consuming physical registers). Table *Average Wait times* helps diagnose performance issues that are caused by; the presence of long latency instructions and potentially long data dependencies; which may limit the ILP. Last row, ``<total>``, shows a global average over all; instructions measured. Note that :program:`llvm-mca`, by default, assumes at; least 1cy between the dispatch event and the issue event. When the performance is limited by data dependencies and/or long latency; instructions, the number of cycles spent while in the *ready* state is expected; to be very small when compared with the total number of cycles spent in the; scheduler's queue. The difference between the two counters is a good indicator; of how large of an impact data dependencies had on the execution of the; instructions. When performance is mostly limited by the lack of hardware; resources, the delta between the two counters is small. However, the number of; cycles spent in the queue tends to be larger (i.e., more than 1-3cy),; especially when compared to other low latency instructions. Bottleneck Analysis; ^^^^^^^^^^^^^^^^^^^; T",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:25860,Integrability,depend,dependencies,25860,"ritten by vmulps is immediately used by the first; vhaddps, and register %xmm3 written by the first vhaddps is used by the second; vhaddps. Long data dependencies negatively impact the ILP (Instruction Level; Parallelism). In the dot-product example, there are anti-dependencies introduced by; instructions from different iterations. However, those dependencies can be; removed at register renaming stage (at the cost of allocating register aliases,; and therefore consuming physical registers). Table *Average Wait times* helps diagnose performance issues that are caused by; the presence of long latency instructions and potentially long data dependencies; which may limit the ILP. Last row, ``<total>``, shows a global average over all; instructions measured. Note that :program:`llvm-mca`, by default, assumes at; least 1cy between the dispatch event and the issue event. When the performance is limited by data dependencies and/or long latency; instructions, the number of cycles spent while in the *ready* state is expected; to be very small when compared with the total number of cycles spent in the; scheduler's queue. The difference between the two counters is a good indicator; of how large of an impact data dependencies had on the execution of the; instructions. When performance is mostly limited by the lack of hardware; resources, the delta between the two counters is small. However, the number of; cycles spent in the queue tends to be larger (i.e., more than 1-3cy),; especially when compared to other low latency instructions. Bottleneck Analysis; ^^^^^^^^^^^^^^^^^^^; The ``-bottleneck-analysis`` command line option enables the analysis of; performance bottlenecks. This analysis is potentially expensive. It attempts to correlate increases in; backend pressure (caused by pipeline resource pressure and data dependencies) to; dynamic dispatch stalls. Below is an example of ``-bottleneck-analysis`` output generated by; :program:`llvm-mca` for 500 iterations of the dot-product e",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:26163,Integrability,depend,dependencies,26163,"n Level; Parallelism). In the dot-product example, there are anti-dependencies introduced by; instructions from different iterations. However, those dependencies can be; removed at register renaming stage (at the cost of allocating register aliases,; and therefore consuming physical registers). Table *Average Wait times* helps diagnose performance issues that are caused by; the presence of long latency instructions and potentially long data dependencies; which may limit the ILP. Last row, ``<total>``, shows a global average over all; instructions measured. Note that :program:`llvm-mca`, by default, assumes at; least 1cy between the dispatch event and the issue event. When the performance is limited by data dependencies and/or long latency; instructions, the number of cycles spent while in the *ready* state is expected; to be very small when compared with the total number of cycles spent in the; scheduler's queue. The difference between the two counters is a good indicator; of how large of an impact data dependencies had on the execution of the; instructions. When performance is mostly limited by the lack of hardware; resources, the delta between the two counters is small. However, the number of; cycles spent in the queue tends to be larger (i.e., more than 1-3cy),; especially when compared to other low latency instructions. Bottleneck Analysis; ^^^^^^^^^^^^^^^^^^^; The ``-bottleneck-analysis`` command line option enables the analysis of; performance bottlenecks. This analysis is potentially expensive. It attempts to correlate increases in; backend pressure (caused by pipeline resource pressure and data dependencies) to; dynamic dispatch stalls. Below is an example of ``-bottleneck-analysis`` output generated by; :program:`llvm-mca` for 500 iterations of the dot-product example on btver2. .. code-block:: none. Cycles with backend pressure increase [ 48.07% ]; Throughput Bottlenecks:; Resource Pressure [ 47.77% ]; - JFPA [ 47.77% ]; - JFPU0 [ 47.77% ]; Data Dependenci",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:26774,Integrability,depend,dependencies,26774,"fault, assumes at; least 1cy between the dispatch event and the issue event. When the performance is limited by data dependencies and/or long latency; instructions, the number of cycles spent while in the *ready* state is expected; to be very small when compared with the total number of cycles spent in the; scheduler's queue. The difference between the two counters is a good indicator; of how large of an impact data dependencies had on the execution of the; instructions. When performance is mostly limited by the lack of hardware; resources, the delta between the two counters is small. However, the number of; cycles spent in the queue tends to be larger (i.e., more than 1-3cy),; especially when compared to other low latency instructions. Bottleneck Analysis; ^^^^^^^^^^^^^^^^^^^; The ``-bottleneck-analysis`` command line option enables the analysis of; performance bottlenecks. This analysis is potentially expensive. It attempts to correlate increases in; backend pressure (caused by pipeline resource pressure and data dependencies) to; dynamic dispatch stalls. Below is an example of ``-bottleneck-analysis`` output generated by; :program:`llvm-mca` for 500 iterations of the dot-product example on btver2. .. code-block:: none. Cycles with backend pressure increase [ 48.07% ]; Throughput Bottlenecks:; Resource Pressure [ 47.77% ]; - JFPA [ 47.77% ]; - JFPU0 [ 47.77% ]; Data Dependencies: [ 0.30% ]; - Register Dependencies [ 0.30% ]; - Memory Dependencies [ 0.00% ]. Critical sequence based on the simulation:. Instruction Dependency Information; +----< 2. vhaddps %xmm3, %xmm3, %xmm4; |; | < loop carried >; |; | 0. vmulps %xmm0, %xmm1, %xmm2; +----> 1. vhaddps %xmm2, %xmm2, %xmm3 ## RESOURCE interference: JFPA [ probability: 74% ]; +----> 2. vhaddps %xmm3, %xmm3, %xmm4 ## REGISTER dependency: %xmm3; |; | < loop carried >; |; +----> 1. vhaddps %xmm2, %xmm2, %xmm3 ## RESOURCE interference: JFPA [ probability: 74% ]. According to the analysis, throughput is limited by resource ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:27546,Integrability,depend,dependency,27546,"alysis`` command line option enables the analysis of; performance bottlenecks. This analysis is potentially expensive. It attempts to correlate increases in; backend pressure (caused by pipeline resource pressure and data dependencies) to; dynamic dispatch stalls. Below is an example of ``-bottleneck-analysis`` output generated by; :program:`llvm-mca` for 500 iterations of the dot-product example on btver2. .. code-block:: none. Cycles with backend pressure increase [ 48.07% ]; Throughput Bottlenecks:; Resource Pressure [ 47.77% ]; - JFPA [ 47.77% ]; - JFPU0 [ 47.77% ]; Data Dependencies: [ 0.30% ]; - Register Dependencies [ 0.30% ]; - Memory Dependencies [ 0.00% ]. Critical sequence based on the simulation:. Instruction Dependency Information; +----< 2. vhaddps %xmm3, %xmm3, %xmm4; |; | < loop carried >; |; | 0. vmulps %xmm0, %xmm1, %xmm2; +----> 1. vhaddps %xmm2, %xmm2, %xmm3 ## RESOURCE interference: JFPA [ probability: 74% ]; +----> 2. vhaddps %xmm3, %xmm3, %xmm4 ## REGISTER dependency: %xmm3; |; | < loop carried >; |; +----> 1. vhaddps %xmm2, %xmm2, %xmm3 ## RESOURCE interference: JFPA [ probability: 74% ]. According to the analysis, throughput is limited by resource pressure and not by; data dependencies. The analysis observed increases in backend pressure during; 48.07% of the simulated run. Almost all those pressure increase events were; caused by contention on processor resources JFPA/JFPU0. The `critical sequence` is the most expensive sequence of instructions according; to the simulation. It is annotated to provide extra information about critical; register dependencies and resource interferences between instructions. Instructions from the critical sequence are expected to significantly impact; performance. By construction, the accuracy of this analysis is strongly; dependent on the simulation and (as always) by the quality of the processor; model in llvm. Bottleneck analysis is currently not supported for processors with an in-order; backend. Extra Statis",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:27769,Integrability,depend,dependencies,27769,"sed by pipeline resource pressure and data dependencies) to; dynamic dispatch stalls. Below is an example of ``-bottleneck-analysis`` output generated by; :program:`llvm-mca` for 500 iterations of the dot-product example on btver2. .. code-block:: none. Cycles with backend pressure increase [ 48.07% ]; Throughput Bottlenecks:; Resource Pressure [ 47.77% ]; - JFPA [ 47.77% ]; - JFPU0 [ 47.77% ]; Data Dependencies: [ 0.30% ]; - Register Dependencies [ 0.30% ]; - Memory Dependencies [ 0.00% ]. Critical sequence based on the simulation:. Instruction Dependency Information; +----< 2. vhaddps %xmm3, %xmm3, %xmm4; |; | < loop carried >; |; | 0. vmulps %xmm0, %xmm1, %xmm2; +----> 1. vhaddps %xmm2, %xmm2, %xmm3 ## RESOURCE interference: JFPA [ probability: 74% ]; +----> 2. vhaddps %xmm3, %xmm3, %xmm4 ## REGISTER dependency: %xmm3; |; | < loop carried >; |; +----> 1. vhaddps %xmm2, %xmm2, %xmm3 ## RESOURCE interference: JFPA [ probability: 74% ]. According to the analysis, throughput is limited by resource pressure and not by; data dependencies. The analysis observed increases in backend pressure during; 48.07% of the simulated run. Almost all those pressure increase events were; caused by contention on processor resources JFPA/JFPU0. The `critical sequence` is the most expensive sequence of instructions according; to the simulation. It is annotated to provide extra information about critical; register dependencies and resource interferences between instructions. Instructions from the critical sequence are expected to significantly impact; performance. By construction, the accuracy of this analysis is strongly; dependent on the simulation and (as always) by the quality of the processor; model in llvm. Bottleneck analysis is currently not supported for processors with an in-order; backend. Extra Statistics to Further Diagnose Performance Issues; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; The ``-all-stats`` command line option enables extra statistics and performan",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:28147,Integrability,depend,dependencies,28147,"cies: [ 0.30% ]; - Register Dependencies [ 0.30% ]; - Memory Dependencies [ 0.00% ]. Critical sequence based on the simulation:. Instruction Dependency Information; +----< 2. vhaddps %xmm3, %xmm3, %xmm4; |; | < loop carried >; |; | 0. vmulps %xmm0, %xmm1, %xmm2; +----> 1. vhaddps %xmm2, %xmm2, %xmm3 ## RESOURCE interference: JFPA [ probability: 74% ]; +----> 2. vhaddps %xmm3, %xmm3, %xmm4 ## REGISTER dependency: %xmm3; |; | < loop carried >; |; +----> 1. vhaddps %xmm2, %xmm2, %xmm3 ## RESOURCE interference: JFPA [ probability: 74% ]. According to the analysis, throughput is limited by resource pressure and not by; data dependencies. The analysis observed increases in backend pressure during; 48.07% of the simulated run. Almost all those pressure increase events were; caused by contention on processor resources JFPA/JFPU0. The `critical sequence` is the most expensive sequence of instructions according; to the simulation. It is annotated to provide extra information about critical; register dependencies and resource interferences between instructions. Instructions from the critical sequence are expected to significantly impact; performance. By construction, the accuracy of this analysis is strongly; dependent on the simulation and (as always) by the quality of the processor; model in llvm. Bottleneck analysis is currently not supported for processors with an in-order; backend. Extra Statistics to Further Diagnose Performance Issues; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; The ``-all-stats`` command line option enables extra statistics and performance; counters for the dispatch logic, the reorder buffer, the retire control unit,; and the register file. Below is an example of ``-all-stats`` output generated by :program:`llvm-mca`; for 300 iterations of the dot-product example discussed in the previous; sections. .. code-block:: none. Dynamic Dispatch Stall Cycles:; RAT - Register unavailable: 0; RCU - Retire tokens unavailable: 0; SCHEDQ - Scheduler fu",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:28360,Integrability,depend,dependent,28360,". vmulps %xmm0, %xmm1, %xmm2; +----> 1. vhaddps %xmm2, %xmm2, %xmm3 ## RESOURCE interference: JFPA [ probability: 74% ]; +----> 2. vhaddps %xmm3, %xmm3, %xmm4 ## REGISTER dependency: %xmm3; |; | < loop carried >; |; +----> 1. vhaddps %xmm2, %xmm2, %xmm3 ## RESOURCE interference: JFPA [ probability: 74% ]. According to the analysis, throughput is limited by resource pressure and not by; data dependencies. The analysis observed increases in backend pressure during; 48.07% of the simulated run. Almost all those pressure increase events were; caused by contention on processor resources JFPA/JFPU0. The `critical sequence` is the most expensive sequence of instructions according; to the simulation. It is annotated to provide extra information about critical; register dependencies and resource interferences between instructions. Instructions from the critical sequence are expected to significantly impact; performance. By construction, the accuracy of this analysis is strongly; dependent on the simulation and (as always) by the quality of the processor; model in llvm. Bottleneck analysis is currently not supported for processors with an in-order; backend. Extra Statistics to Further Diagnose Performance Issues; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; The ``-all-stats`` command line option enables extra statistics and performance; counters for the dispatch logic, the reorder buffer, the retire control unit,; and the register file. Below is an example of ``-all-stats`` output generated by :program:`llvm-mca`; for 300 iterations of the dot-product example discussed in the previous; sections. .. code-block:: none. Dynamic Dispatch Stall Cycles:; RAT - Register unavailable: 0; RCU - Retire tokens unavailable: 0; SCHEDQ - Scheduler full: 272 (44.6%); LQ - Load queue full: 0; SQ - Store queue full: 0; GROUP - Static restrictions on the dispatch group: 0. Dispatch Logic - number of cycles where we saw N micro opcodes dispatched:; [# dispatched], [# cycles]; 0, 24 (",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:31941,Integrability,depend,dependency,31941," command option; ``-all-stats`` or ``-dispatch-stats``. The next table, *Schedulers*, presents a histogram displaying a count,; representing the number of micro opcodes issued on some number of cycles. In; this case, of the 610 simulated cycles, single opcodes were issued 306 times; (50.2%) and there were 7 cycles where no opcodes were issued. The *Scheduler's queue usage* table shows that the average and maximum number of; buffer entries (i.e., scheduler queue entries) used at runtime. Resource JFPU01; reached its maximum (18 of 18 queue entries). Note that AMD Jaguar implements; three schedulers:. * JALU01 - A scheduler for ALU instructions.; * JFPU01 - A scheduler floating point operations.; * JLSAGU - A scheduler for address generation. The dot-product is a kernel of three floating point instructions (a vector; multiply followed by two horizontal adds). That explains why only the floating; point scheduler appears to be used. A full scheduler queue is either caused by data dependency chains or by a; sub-optimal usage of hardware resources. Sometimes, resource pressure can be; mitigated by rewriting the kernel using different instructions that consume; different scheduler resources. Schedulers with a small queue are less resilient; to bottlenecks caused by the presence of long data dependencies. The scheduler; statistics are displayed by using the command option ``-all-stats`` or; ``-scheduler-stats``. The next table, *Retire Control Unit*, presents a histogram displaying a count,; representing the number of instructions retired on some number of cycles. In; this case, of the 610 simulated cycles, two instructions were retired during the; same cycle 399 times (65.4%) and there were 109 cycles where no instructions; were retired. The retire statistics are displayed by using the command option; ``-all-stats`` or ``-retire-stats``. The last table presented is *Register File statistics*. Each physical register; file (PRF) used by the pipeline is presented in this tabl",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:32255,Integrability,depend,dependencies,32255," were issued 306 times; (50.2%) and there were 7 cycles where no opcodes were issued. The *Scheduler's queue usage* table shows that the average and maximum number of; buffer entries (i.e., scheduler queue entries) used at runtime. Resource JFPU01; reached its maximum (18 of 18 queue entries). Note that AMD Jaguar implements; three schedulers:. * JALU01 - A scheduler for ALU instructions.; * JFPU01 - A scheduler floating point operations.; * JLSAGU - A scheduler for address generation. The dot-product is a kernel of three floating point instructions (a vector; multiply followed by two horizontal adds). That explains why only the floating; point scheduler appears to be used. A full scheduler queue is either caused by data dependency chains or by a; sub-optimal usage of hardware resources. Sometimes, resource pressure can be; mitigated by rewriting the kernel using different instructions that consume; different scheduler resources. Schedulers with a small queue are less resilient; to bottlenecks caused by the presence of long data dependencies. The scheduler; statistics are displayed by using the command option ``-all-stats`` or; ``-scheduler-stats``. The next table, *Retire Control Unit*, presents a histogram displaying a count,; representing the number of instructions retired on some number of cycles. In; this case, of the 610 simulated cycles, two instructions were retired during the; same cycle 399 times (65.4%) and there were 109 cycles where no instructions; were retired. The retire statistics are displayed by using the command option; ``-all-stats`` or ``-retire-stats``. The last table presented is *Register File statistics*. Each physical register; file (PRF) used by the pipeline is presented in this table. In the case of AMD; Jaguar, there are two register files, one for floating-point registers (JFpuPRF); and one for integer registers (JIntegerPRF). The table shows that of the 900; instructions processed, there were 900 mappings created. Since this dot-produc",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:33762,Integrability,depend,dependencies,33762," by using the command option; ``-all-stats`` or ``-retire-stats``. The last table presented is *Register File statistics*. Each physical register; file (PRF) used by the pipeline is presented in this table. In the case of AMD; Jaguar, there are two register files, one for floating-point registers (JFpuPRF); and one for integer registers (JIntegerPRF). The table shows that of the 900; instructions processed, there were 900 mappings created. Since this dot-product; example utilized only floating point registers, the JFPuPRF was responsible for; creating the 900 mappings. However, we see that the pipeline only used a; maximum of 35 of 72 available register slots at any given time. We can conclude; that the floating point PRF was the only register file used for the example, and; that it was never resource constrained. The register file statistics are; displayed by using the command option ``-all-stats`` or; ``-register-file-stats``. In this example, we can conclude that the IPC is mostly limited by data; dependencies, and not by resource pressure. Instruction Flow; ^^^^^^^^^^^^^^^^; This section describes the instruction flow through the default pipeline of; :program:`llvm-mca`, as well as the functional units involved in the process. The default pipeline implements the following sequence of stages used to; process instructions. * Dispatch (Instruction is dispatched to the schedulers).; * Issue (Instruction is issued to the processor pipelines).; * Write Back (Instruction is executed, and results are written back).; * Retire (Instruction is retired; writes are architecturally committed). The in-order pipeline implements the following sequence of stages:; * InOrderIssue (Instruction is issued to the processor pipelines).; * Retire (Instruction is retired; writes are architecturally committed). :program:`llvm-mca` assumes that instructions have all been decoded and placed; into a queue before the simulation start. Therefore, the instruction fetch and; decode stages are not",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:35129,Integrability,depend,depends,35129,"rs).; * Issue (Instruction is issued to the processor pipelines).; * Write Back (Instruction is executed, and results are written back).; * Retire (Instruction is retired; writes are architecturally committed). The in-order pipeline implements the following sequence of stages:; * InOrderIssue (Instruction is issued to the processor pipelines).; * Retire (Instruction is retired; writes are architecturally committed). :program:`llvm-mca` assumes that instructions have all been decoded and placed; into a queue before the simulation start. Therefore, the instruction fetch and; decode stages are not modeled. Performance bottlenecks in the frontend are not; diagnosed. Also, :program:`llvm-mca` does not model branch prediction. Instruction Dispatch; """"""""""""""""""""""""""""""""""""""""; During the dispatch stage, instructions are picked in program order from a; queue of already decoded instructions, and dispatched in groups to the; simulated hardware schedulers. The size of a dispatch group depends on the availability of the simulated; hardware resources. The processor dispatch width defaults to the value; of the ``IssueWidth`` in LLVM's scheduling model. An instruction can be dispatched if:. * The size of the dispatch group is smaller than processor's dispatch width.; * There are enough entries in the reorder buffer.; * There are enough physical registers to do register renaming.; * The schedulers are not full. Scheduling models can optionally specify which register files are available on; the processor. :program:`llvm-mca` uses that information to initialize register; file descriptors. Users can limit the number of physical registers that are; globally available for register renaming by using the command option; ``-register-file-size``. A value of zero for this option means *unbounded*. By; knowing how many registers are available for renaming, the tool can predict; dispatch stalls caused by the lack of physical registers. The number of reorder buffer entries consumed by an instruction d",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:36146,Integrability,depend,depends,36146,"imulated; hardware resources. The processor dispatch width defaults to the value; of the ``IssueWidth`` in LLVM's scheduling model. An instruction can be dispatched if:. * The size of the dispatch group is smaller than processor's dispatch width.; * There are enough entries in the reorder buffer.; * There are enough physical registers to do register renaming.; * The schedulers are not full. Scheduling models can optionally specify which register files are available on; the processor. :program:`llvm-mca` uses that information to initialize register; file descriptors. Users can limit the number of physical registers that are; globally available for register renaming by using the command option; ``-register-file-size``. A value of zero for this option means *unbounded*. By; knowing how many registers are available for renaming, the tool can predict; dispatch stalls caused by the lack of physical registers. The number of reorder buffer entries consumed by an instruction depends on the; number of micro-opcodes specified for that instruction by the target scheduling; model. The reorder buffer is responsible for tracking the progress of; instructions that are ""in-flight"", and retiring them in program order. The; number of entries in the reorder buffer defaults to the value specified by field; `MicroOpBufferSize` in the target scheduling model. Instructions that are dispatched to the schedulers consume scheduler buffer; entries. :program:`llvm-mca` queries the scheduling model to determine the set; of buffered resources consumed by an instruction. Buffered resources are; treated like scheduler resources. Instruction Issue; """"""""""""""""""""""""""""""""""; Each processor scheduler implements a buffer of instructions. An instruction; has to wait in the scheduler's buffer until input register operands become; available. Only at that point, does the instruction becomes eligible for; execution and may be issued (potentially out-of-order) for execution.; Instruction latencies are computed by :",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:37359,Integrability,depend,dependencies,37359,". The; number of entries in the reorder buffer defaults to the value specified by field; `MicroOpBufferSize` in the target scheduling model. Instructions that are dispatched to the schedulers consume scheduler buffer; entries. :program:`llvm-mca` queries the scheduling model to determine the set; of buffered resources consumed by an instruction. Buffered resources are; treated like scheduler resources. Instruction Issue; """"""""""""""""""""""""""""""""""; Each processor scheduler implements a buffer of instructions. An instruction; has to wait in the scheduler's buffer until input register operands become; available. Only at that point, does the instruction becomes eligible for; execution and may be issued (potentially out-of-order) for execution.; Instruction latencies are computed by :program:`llvm-mca` with the help of the; scheduling model. :program:`llvm-mca`'s scheduler is designed to simulate multiple processor; schedulers. The scheduler is responsible for tracking data dependencies, and; dynamically selecting which processor resources are consumed by instructions.; It delegates the management of processor resource units and resource groups to a; resource manager. The resource manager is responsible for selecting resource; units that are consumed by instructions. For example, if an instruction; consumes 1cy of a resource group, the resource manager selects one of the; available units from the group; by default, the resource manager uses a; round-robin selector to guarantee that resource usage is uniformly distributed; between all units of a group. :program:`llvm-mca`'s scheduler internally groups instructions into three sets:. * WaitSet: a set of instructions whose operands are not ready.; * ReadySet: a set of instructions ready to execute.; * IssuedSet: a set of instructions executing. Depending on the operands availability, instructions that are dispatched to the; scheduler are either placed into the WaitSet or into the ReadySet. Every cycle, the scheduler checks if instru",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:44376,Integrability,depend,dependencies,44376,"operand registers are available and resource requirements are; met. Multiple instructions can be issued in one cycle according to the value of; the ``IssueWidth`` parameter in LLVM's scheduling model. Once issued, an instruction is moved to ``IssuedInst`` set until it is ready to; retire. :program:`llvm-mca` ensures that writes are committed in-order. However,; an instruction is allowed to commit writes and retire out-of-order if; ``RetireOOO`` property is true for at least one of its writes. Custom Behaviour; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; Due to certain instructions not being expressed perfectly within their; scheduling model, :program:`llvm-mca` isn't always able to simulate them; perfectly. Modifying the scheduling model isn't always a viable; option though (maybe because the instruction is modeled incorrectly on; purpose or the instruction's behaviour is quite complex). The; CustomBehaviour class can be used in these cases to enforce proper; instruction modeling (often by customizing data dependencies and detecting; hazards that :program:`llvm-mca` has no way of knowing about). :program:`llvm-mca` comes with one generic and multiple target specific; CustomBehaviour classes. The generic class will be used if the ``-disable-cb``; flag is used or if a target specific CustomBehaviour class doesn't exist for; that target. (The generic class does nothing.) Currently, the CustomBehaviour; class is only a part of the in-order pipeline, but there are plans to add it; to the out-of-order pipeline in the future. CustomBehaviour's main method is `checkCustomHazard()` which uses the; current instruction and a list of all instructions still executing within; the pipeline to determine if the current instruction should be dispatched.; As output, the method returns an integer representing the number of cycles; that the current instruction must stall for (this can be an underestimate; if you don't know the exact number and a value of 0 represents no stall). If you'd like ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:47854,Integrability,depend,dependent,47854,"egisters, instrument comments can; be used to specify these values. InstrumentManager's main function is `getSchedClassID()` which has access; to the MCInst and all of the instruments that are active for that MCInst.; This function can use the instruments to override the schedule class of; the MCInst. On RISCV, instrument comments containing LMUL information are used; by `getSchedClassID()` to map a vector instruction and the active; LMUL to the scheduling class of the pseudo-instruction that describes; that base instruction and the active LMUL. Custom Views; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; :program:`llvm-mca` comes with several Views such as the Timeline View and; Summary View. These Views are generic and can work with most (if not all); targets. If you wish to add a new View to :program:`llvm-mca` and it does not; require any backend functionality that is not already exposed through MC layer; classes (MCSubtargetInfo, MCInstrInfo, etc.), please add it to the; `/tools/llvm-mca/View/` directory. However, if your new View is target specific; AND requires unexposed backend symbols or functionality, you can define it in; the `/lib/Target/<TargetName>/MCA/` directory. To enable this target specific View, you will have to use this target's; CustomBehaviour class to override the `CustomBehaviour::getViews()` methods.; There are 3 variations of these methods based on where you want your View to; appear in the output: `getStartViews()`, `getPostInstrInfoViews()`, and; `getEndViews()`. These methods returns a vector of Views so you will want to; return a vector containing all of the target specific Views for the target in; question. Because these target specific (and backend dependent) Views require the; `CustomBehaviour::getViews()` variants, these Views will not be enabled if; the `-disable-cb` flag is used. Enabling these custom Views does not affect the non-custom (generic) Views.; Continue to use the usual command line arguments to enable / disable those; Views.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:213,Performance,perform,performance,213,"llvm-mca - LLVM Machine Code Analyzer; =====================================. .. program:: llvm-mca. SYNOPSIS; --------. :program:`llvm-mca` [*options*] [input]. DESCRIPTION; -----------. :program:`llvm-mca` is a performance analysis tool that uses information; available in LLVM (e.g. scheduling models) to statically measure the performance; of machine code in a specific CPU. Performance is measured in terms of throughput as well as processor resource; consumption. The tool currently works for processors with a backend for which; there is a scheduling model available in LLVM. The main goal of this tool is not just to predict the performance of the code; when run on the target, but also help with diagnosing potential performance; issues. Given an assembly code sequence, :program:`llvm-mca` estimates the Instructions; Per Cycle (IPC), as well as hardware resource pressure. The analysis and; reporting style were inspired by the IACA tool from Intel. For example, you can compile code with clang, output assembly, and pipe it; directly into :program:`llvm-mca` for analysis:. .. code-block:: bash. $ clang foo.c -O2 --target=x86_64 -S -o - | llvm-mca -mcpu=btver2. Or for Intel syntax:. .. code-block:: bash. $ clang foo.c -O2 --target=x86_64 -masm=intel -S -o - | llvm-mca -mcpu=btver2. (:program:`llvm-mca` detects Intel syntax by the presence of an `.intel_syntax`; directive at the beginning of the input. By default its output syntax matches; that of its input.). Scheduling models are not just used to compute instruction latencies and; throughput, but also to understand what processor resources are available; and how to simulate them. By design, the quality of the analysis conducted by :program:`llvm-mca` is; inevitably affected by the quality of the scheduling models in LLVM. If you see that the performance report is not accurate for a processor,; please `file a bug <https://github.com/llvm/llvm-project/issues>`_; against the appropriate backend. OPTIONS; -------. If ``input",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:331,Performance,perform,performance,331,"llvm-mca - LLVM Machine Code Analyzer; =====================================. .. program:: llvm-mca. SYNOPSIS; --------. :program:`llvm-mca` [*options*] [input]. DESCRIPTION; -----------. :program:`llvm-mca` is a performance analysis tool that uses information; available in LLVM (e.g. scheduling models) to statically measure the performance; of machine code in a specific CPU. Performance is measured in terms of throughput as well as processor resource; consumption. The tool currently works for processors with a backend for which; there is a scheduling model available in LLVM. The main goal of this tool is not just to predict the performance of the code; when run on the target, but also help with diagnosing potential performance; issues. Given an assembly code sequence, :program:`llvm-mca` estimates the Instructions; Per Cycle (IPC), as well as hardware resource pressure. The analysis and; reporting style were inspired by the IACA tool from Intel. For example, you can compile code with clang, output assembly, and pipe it; directly into :program:`llvm-mca` for analysis:. .. code-block:: bash. $ clang foo.c -O2 --target=x86_64 -S -o - | llvm-mca -mcpu=btver2. Or for Intel syntax:. .. code-block:: bash. $ clang foo.c -O2 --target=x86_64 -masm=intel -S -o - | llvm-mca -mcpu=btver2. (:program:`llvm-mca` detects Intel syntax by the presence of an `.intel_syntax`; directive at the beginning of the input. By default its output syntax matches; that of its input.). Scheduling models are not just used to compute instruction latencies and; throughput, but also to understand what processor resources are available; and how to simulate them. By design, the quality of the analysis conducted by :program:`llvm-mca` is; inevitably affected by the quality of the scheduling models in LLVM. If you see that the performance report is not accurate for a processor,; please `file a bug <https://github.com/llvm/llvm-project/issues>`_; against the appropriate backend. OPTIONS; -------. If ``input",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:415,Performance,throughput,throughput,415,"llvm-mca - LLVM Machine Code Analyzer; =====================================. .. program:: llvm-mca. SYNOPSIS; --------. :program:`llvm-mca` [*options*] [input]. DESCRIPTION; -----------. :program:`llvm-mca` is a performance analysis tool that uses information; available in LLVM (e.g. scheduling models) to statically measure the performance; of machine code in a specific CPU. Performance is measured in terms of throughput as well as processor resource; consumption. The tool currently works for processors with a backend for which; there is a scheduling model available in LLVM. The main goal of this tool is not just to predict the performance of the code; when run on the target, but also help with diagnosing potential performance; issues. Given an assembly code sequence, :program:`llvm-mca` estimates the Instructions; Per Cycle (IPC), as well as hardware resource pressure. The analysis and; reporting style were inspired by the IACA tool from Intel. For example, you can compile code with clang, output assembly, and pipe it; directly into :program:`llvm-mca` for analysis:. .. code-block:: bash. $ clang foo.c -O2 --target=x86_64 -S -o - | llvm-mca -mcpu=btver2. Or for Intel syntax:. .. code-block:: bash. $ clang foo.c -O2 --target=x86_64 -masm=intel -S -o - | llvm-mca -mcpu=btver2. (:program:`llvm-mca` detects Intel syntax by the presence of an `.intel_syntax`; directive at the beginning of the input. By default its output syntax matches; that of its input.). Scheduling models are not just used to compute instruction latencies and; throughput, but also to understand what processor resources are available; and how to simulate them. By design, the quality of the analysis conducted by :program:`llvm-mca` is; inevitably affected by the quality of the scheduling models in LLVM. If you see that the performance report is not accurate for a processor,; please `file a bug <https://github.com/llvm/llvm-project/issues>`_; against the appropriate backend. OPTIONS; -------. If ``input",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:637,Performance,perform,performance,637,"llvm-mca - LLVM Machine Code Analyzer; =====================================. .. program:: llvm-mca. SYNOPSIS; --------. :program:`llvm-mca` [*options*] [input]. DESCRIPTION; -----------. :program:`llvm-mca` is a performance analysis tool that uses information; available in LLVM (e.g. scheduling models) to statically measure the performance; of machine code in a specific CPU. Performance is measured in terms of throughput as well as processor resource; consumption. The tool currently works for processors with a backend for which; there is a scheduling model available in LLVM. The main goal of this tool is not just to predict the performance of the code; when run on the target, but also help with diagnosing potential performance; issues. Given an assembly code sequence, :program:`llvm-mca` estimates the Instructions; Per Cycle (IPC), as well as hardware resource pressure. The analysis and; reporting style were inspired by the IACA tool from Intel. For example, you can compile code with clang, output assembly, and pipe it; directly into :program:`llvm-mca` for analysis:. .. code-block:: bash. $ clang foo.c -O2 --target=x86_64 -S -o - | llvm-mca -mcpu=btver2. Or for Intel syntax:. .. code-block:: bash. $ clang foo.c -O2 --target=x86_64 -masm=intel -S -o - | llvm-mca -mcpu=btver2. (:program:`llvm-mca` detects Intel syntax by the presence of an `.intel_syntax`; directive at the beginning of the input. By default its output syntax matches; that of its input.). Scheduling models are not just used to compute instruction latencies and; throughput, but also to understand what processor resources are available; and how to simulate them. By design, the quality of the analysis conducted by :program:`llvm-mca` is; inevitably affected by the quality of the scheduling models in LLVM. If you see that the performance report is not accurate for a processor,; please `file a bug <https://github.com/llvm/llvm-project/issues>`_; against the appropriate backend. OPTIONS; -------. If ``input",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:726,Performance,perform,performance,726,"llvm-mca - LLVM Machine Code Analyzer; =====================================. .. program:: llvm-mca. SYNOPSIS; --------. :program:`llvm-mca` [*options*] [input]. DESCRIPTION; -----------. :program:`llvm-mca` is a performance analysis tool that uses information; available in LLVM (e.g. scheduling models) to statically measure the performance; of machine code in a specific CPU. Performance is measured in terms of throughput as well as processor resource; consumption. The tool currently works for processors with a backend for which; there is a scheduling model available in LLVM. The main goal of this tool is not just to predict the performance of the code; when run on the target, but also help with diagnosing potential performance; issues. Given an assembly code sequence, :program:`llvm-mca` estimates the Instructions; Per Cycle (IPC), as well as hardware resource pressure. The analysis and; reporting style were inspired by the IACA tool from Intel. For example, you can compile code with clang, output assembly, and pipe it; directly into :program:`llvm-mca` for analysis:. .. code-block:: bash. $ clang foo.c -O2 --target=x86_64 -S -o - | llvm-mca -mcpu=btver2. Or for Intel syntax:. .. code-block:: bash. $ clang foo.c -O2 --target=x86_64 -masm=intel -S -o - | llvm-mca -mcpu=btver2. (:program:`llvm-mca` detects Intel syntax by the presence of an `.intel_syntax`; directive at the beginning of the input. By default its output syntax matches; that of its input.). Scheduling models are not just used to compute instruction latencies and; throughput, but also to understand what processor resources are available; and how to simulate them. By design, the quality of the analysis conducted by :program:`llvm-mca` is; inevitably affected by the quality of the scheduling models in LLVM. If you see that the performance report is not accurate for a processor,; please `file a bug <https://github.com/llvm/llvm-project/issues>`_; against the appropriate backend. OPTIONS; -------. If ``input",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:1553,Performance,throughput,throughput,1553,"vailable in LLVM. The main goal of this tool is not just to predict the performance of the code; when run on the target, but also help with diagnosing potential performance; issues. Given an assembly code sequence, :program:`llvm-mca` estimates the Instructions; Per Cycle (IPC), as well as hardware resource pressure. The analysis and; reporting style were inspired by the IACA tool from Intel. For example, you can compile code with clang, output assembly, and pipe it; directly into :program:`llvm-mca` for analysis:. .. code-block:: bash. $ clang foo.c -O2 --target=x86_64 -S -o - | llvm-mca -mcpu=btver2. Or for Intel syntax:. .. code-block:: bash. $ clang foo.c -O2 --target=x86_64 -masm=intel -S -o - | llvm-mca -mcpu=btver2. (:program:`llvm-mca` detects Intel syntax by the presence of an `.intel_syntax`; directive at the beginning of the input. By default its output syntax matches; that of its input.). Scheduling models are not just used to compute instruction latencies and; throughput, but also to understand what processor resources are available; and how to simulate them. By design, the quality of the analysis conducted by :program:`llvm-mca` is; inevitably affected by the quality of the scheduling models in LLVM. If you see that the performance report is not accurate for a processor,; please `file a bug <https://github.com/llvm/llvm-project/issues>`_; against the appropriate backend. OPTIONS; -------. If ``input`` is ""``-``"" or omitted, :program:`llvm-mca` reads from standard; input. Otherwise, it will read from the specified filename. If the :option:`-o` option is omitted, then :program:`llvm-mca` will send its output; to standard output if the input is from standard input. If the :option:`-o`; option specifies ""``-``"", then the output will also be sent to standard output. .. option:: -help. Print a summary of command line options. .. option:: -o <filename>. Use ``<filename>`` as the output filename. See the summary above for more; details. .. option:: -mtriple=<ta",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:1819,Performance,perform,performance,1819," as hardware resource pressure. The analysis and; reporting style were inspired by the IACA tool from Intel. For example, you can compile code with clang, output assembly, and pipe it; directly into :program:`llvm-mca` for analysis:. .. code-block:: bash. $ clang foo.c -O2 --target=x86_64 -S -o - | llvm-mca -mcpu=btver2. Or for Intel syntax:. .. code-block:: bash. $ clang foo.c -O2 --target=x86_64 -masm=intel -S -o - | llvm-mca -mcpu=btver2. (:program:`llvm-mca` detects Intel syntax by the presence of an `.intel_syntax`; directive at the beginning of the input. By default its output syntax matches; that of its input.). Scheduling models are not just used to compute instruction latencies and; throughput, but also to understand what processor resources are available; and how to simulate them. By design, the quality of the analysis conducted by :program:`llvm-mca` is; inevitably affected by the quality of the scheduling models in LLVM. If you see that the performance report is not accurate for a processor,; please `file a bug <https://github.com/llvm/llvm-project/issues>`_; against the appropriate backend. OPTIONS; -------. If ``input`` is ""``-``"" or omitted, :program:`llvm-mca` reads from standard; input. Otherwise, it will read from the specified filename. If the :option:`-o` option is omitted, then :program:`llvm-mca` will send its output; to standard output if the input is from standard input. If the :option:`-o`; option specifies ""``-``"", then the output will also be sent to standard output. .. option:: -help. Print a summary of command line options. .. option:: -o <filename>. Use ``<filename>`` as the output filename. See the summary above for more; details. .. option:: -mtriple=<target triple>. Specify a target triple string. .. option:: -march=<arch>. Specify the architecture for which to analyze the code. It defaults to the; host default target. .. option:: -mcpu=<cpuname>. Specify the processor for which to analyze the code. By default, the cpu name; is autode",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:4046,Performance,load,loads,4046,"(vic. 1) for this flag enables; the AT&T (vic. Intel) assembly format for the code printed out by the tool in; the analysis report. .. option:: -print-imm-hex. Prefer hex format for numeric literals in the output assembly printed as part; of the report. .. option:: -dispatch=<width>. Specify a different dispatch width for the processor. The dispatch width; defaults to field 'IssueWidth' in the processor scheduling model. If width is; zero, then the default dispatch width is used. .. option:: -register-file-size=<size>. Specify the size of the register file. When specified, this flag limits how; many physical registers are available for register renaming purposes. A value; of zero for this flag means ""unlimited number of physical registers"". .. option:: -iterations=<number of iterations>. Specify the number of iterations to run. If this flag is set to 0, then the; tool sets the number of iterations to a default value (i.e. 100). .. option:: -noalias=<bool>. If set, the tool assumes that loads and stores don't alias. This is the; default behavior. .. option:: -lqueue=<load queue size>. Specify the size of the load queue in the load/store unit emulated by the tool.; By default, the tool assumes an unbound number of entries in the load queue.; A value of zero for this flag is ignored, and the default load queue size is; used instead. .. option:: -squeue=<store queue size>. Specify the size of the store queue in the load/store unit emulated by the; tool. By default, the tool assumes an unbound number of entries in the store; queue. A value of zero for this flag is ignored, and the default store queue; size is used instead. .. option:: -timeline. Enable the timeline view. .. option:: -timeline-max-iterations=<iterations>. Limit the number of iterations to print in the timeline view. By default, the; timeline view prints information for up to 10 iterations. .. option:: -timeline-max-cycles=<cycles>. Limit the number of cycles in the timeline view, or use 0 for no limit. By",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:4128,Performance,load,load,4128," printed out by the tool in; the analysis report. .. option:: -print-imm-hex. Prefer hex format for numeric literals in the output assembly printed as part; of the report. .. option:: -dispatch=<width>. Specify a different dispatch width for the processor. The dispatch width; defaults to field 'IssueWidth' in the processor scheduling model. If width is; zero, then the default dispatch width is used. .. option:: -register-file-size=<size>. Specify the size of the register file. When specified, this flag limits how; many physical registers are available for register renaming purposes. A value; of zero for this flag means ""unlimited number of physical registers"". .. option:: -iterations=<number of iterations>. Specify the number of iterations to run. If this flag is set to 0, then the; tool sets the number of iterations to a default value (i.e. 100). .. option:: -noalias=<bool>. If set, the tool assumes that loads and stores don't alias. This is the; default behavior. .. option:: -lqueue=<load queue size>. Specify the size of the load queue in the load/store unit emulated by the tool.; By default, the tool assumes an unbound number of entries in the load queue.; A value of zero for this flag is ignored, and the default load queue size is; used instead. .. option:: -squeue=<store queue size>. Specify the size of the store queue in the load/store unit emulated by the; tool. By default, the tool assumes an unbound number of entries in the store; queue. A value of zero for this flag is ignored, and the default store queue; size is used instead. .. option:: -timeline. Enable the timeline view. .. option:: -timeline-max-iterations=<iterations>. Limit the number of iterations to print in the timeline view. By default, the; timeline view prints information for up to 10 iterations. .. option:: -timeline-max-cycles=<cycles>. Limit the number of cycles in the timeline view, or use 0 for no limit. By; default, the number of cycles is set to 80. .. option:: -resource-pressure. Enab",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:4133,Performance,queue,queue,4133," printed out by the tool in; the analysis report. .. option:: -print-imm-hex. Prefer hex format for numeric literals in the output assembly printed as part; of the report. .. option:: -dispatch=<width>. Specify a different dispatch width for the processor. The dispatch width; defaults to field 'IssueWidth' in the processor scheduling model. If width is; zero, then the default dispatch width is used. .. option:: -register-file-size=<size>. Specify the size of the register file. When specified, this flag limits how; many physical registers are available for register renaming purposes. A value; of zero for this flag means ""unlimited number of physical registers"". .. option:: -iterations=<number of iterations>. Specify the number of iterations to run. If this flag is set to 0, then the; tool sets the number of iterations to a default value (i.e. 100). .. option:: -noalias=<bool>. If set, the tool assumes that loads and stores don't alias. This is the; default behavior. .. option:: -lqueue=<load queue size>. Specify the size of the load queue in the load/store unit emulated by the tool.; By default, the tool assumes an unbound number of entries in the load queue.; A value of zero for this flag is ignored, and the default load queue size is; used instead. .. option:: -squeue=<store queue size>. Specify the size of the store queue in the load/store unit emulated by the; tool. By default, the tool assumes an unbound number of entries in the store; queue. A value of zero for this flag is ignored, and the default store queue; size is used instead. .. option:: -timeline. Enable the timeline view. .. option:: -timeline-max-iterations=<iterations>. Limit the number of iterations to print in the timeline view. By default, the; timeline view prints information for up to 10 iterations. .. option:: -timeline-max-cycles=<cycles>. Limit the number of cycles in the timeline view, or use 0 for no limit. By; default, the number of cycles is set to 80. .. option:: -resource-pressure. Enab",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:4170,Performance,load,load,4170,"n:: -print-imm-hex. Prefer hex format for numeric literals in the output assembly printed as part; of the report. .. option:: -dispatch=<width>. Specify a different dispatch width for the processor. The dispatch width; defaults to field 'IssueWidth' in the processor scheduling model. If width is; zero, then the default dispatch width is used. .. option:: -register-file-size=<size>. Specify the size of the register file. When specified, this flag limits how; many physical registers are available for register renaming purposes. A value; of zero for this flag means ""unlimited number of physical registers"". .. option:: -iterations=<number of iterations>. Specify the number of iterations to run. If this flag is set to 0, then the; tool sets the number of iterations to a default value (i.e. 100). .. option:: -noalias=<bool>. If set, the tool assumes that loads and stores don't alias. This is the; default behavior. .. option:: -lqueue=<load queue size>. Specify the size of the load queue in the load/store unit emulated by the tool.; By default, the tool assumes an unbound number of entries in the load queue.; A value of zero for this flag is ignored, and the default load queue size is; used instead. .. option:: -squeue=<store queue size>. Specify the size of the store queue in the load/store unit emulated by the; tool. By default, the tool assumes an unbound number of entries in the store; queue. A value of zero for this flag is ignored, and the default store queue; size is used instead. .. option:: -timeline. Enable the timeline view. .. option:: -timeline-max-iterations=<iterations>. Limit the number of iterations to print in the timeline view. By default, the; timeline view prints information for up to 10 iterations. .. option:: -timeline-max-cycles=<cycles>. Limit the number of cycles in the timeline view, or use 0 for no limit. By; default, the number of cycles is set to 80. .. option:: -resource-pressure. Enable the resource pressure view. This is enabled by default.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:4175,Performance,queue,queue,4175,"n:: -print-imm-hex. Prefer hex format for numeric literals in the output assembly printed as part; of the report. .. option:: -dispatch=<width>. Specify a different dispatch width for the processor. The dispatch width; defaults to field 'IssueWidth' in the processor scheduling model. If width is; zero, then the default dispatch width is used. .. option:: -register-file-size=<size>. Specify the size of the register file. When specified, this flag limits how; many physical registers are available for register renaming purposes. A value; of zero for this flag means ""unlimited number of physical registers"". .. option:: -iterations=<number of iterations>. Specify the number of iterations to run. If this flag is set to 0, then the; tool sets the number of iterations to a default value (i.e. 100). .. option:: -noalias=<bool>. If set, the tool assumes that loads and stores don't alias. This is the; default behavior. .. option:: -lqueue=<load queue size>. Specify the size of the load queue in the load/store unit emulated by the tool.; By default, the tool assumes an unbound number of entries in the load queue.; A value of zero for this flag is ignored, and the default load queue size is; used instead. .. option:: -squeue=<store queue size>. Specify the size of the store queue in the load/store unit emulated by the; tool. By default, the tool assumes an unbound number of entries in the store; queue. A value of zero for this flag is ignored, and the default store queue; size is used instead. .. option:: -timeline. Enable the timeline view. .. option:: -timeline-max-iterations=<iterations>. Limit the number of iterations to print in the timeline view. By default, the; timeline view prints information for up to 10 iterations. .. option:: -timeline-max-cycles=<cycles>. Limit the number of cycles in the timeline view, or use 0 for no limit. By; default, the number of cycles is set to 80. .. option:: -resource-pressure. Enable the resource pressure view. This is enabled by default.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:4188,Performance,load,load,4188,"n:: -print-imm-hex. Prefer hex format for numeric literals in the output assembly printed as part; of the report. .. option:: -dispatch=<width>. Specify a different dispatch width for the processor. The dispatch width; defaults to field 'IssueWidth' in the processor scheduling model. If width is; zero, then the default dispatch width is used. .. option:: -register-file-size=<size>. Specify the size of the register file. When specified, this flag limits how; many physical registers are available for register renaming purposes. A value; of zero for this flag means ""unlimited number of physical registers"". .. option:: -iterations=<number of iterations>. Specify the number of iterations to run. If this flag is set to 0, then the; tool sets the number of iterations to a default value (i.e. 100). .. option:: -noalias=<bool>. If set, the tool assumes that loads and stores don't alias. This is the; default behavior. .. option:: -lqueue=<load queue size>. Specify the size of the load queue in the load/store unit emulated by the tool.; By default, the tool assumes an unbound number of entries in the load queue.; A value of zero for this flag is ignored, and the default load queue size is; used instead. .. option:: -squeue=<store queue size>. Specify the size of the store queue in the load/store unit emulated by the; tool. By default, the tool assumes an unbound number of entries in the store; queue. A value of zero for this flag is ignored, and the default store queue; size is used instead. .. option:: -timeline. Enable the timeline view. .. option:: -timeline-max-iterations=<iterations>. Limit the number of iterations to print in the timeline view. By default, the; timeline view prints information for up to 10 iterations. .. option:: -timeline-max-cycles=<cycles>. Limit the number of cycles in the timeline view, or use 0 for no limit. By; default, the number of cycles is set to 80. .. option:: -resource-pressure. Enable the resource pressure view. This is enabled by default.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:4292,Performance,load,load,4292,"ly printed as part; of the report. .. option:: -dispatch=<width>. Specify a different dispatch width for the processor. The dispatch width; defaults to field 'IssueWidth' in the processor scheduling model. If width is; zero, then the default dispatch width is used. .. option:: -register-file-size=<size>. Specify the size of the register file. When specified, this flag limits how; many physical registers are available for register renaming purposes. A value; of zero for this flag means ""unlimited number of physical registers"". .. option:: -iterations=<number of iterations>. Specify the number of iterations to run. If this flag is set to 0, then the; tool sets the number of iterations to a default value (i.e. 100). .. option:: -noalias=<bool>. If set, the tool assumes that loads and stores don't alias. This is the; default behavior. .. option:: -lqueue=<load queue size>. Specify the size of the load queue in the load/store unit emulated by the tool.; By default, the tool assumes an unbound number of entries in the load queue.; A value of zero for this flag is ignored, and the default load queue size is; used instead. .. option:: -squeue=<store queue size>. Specify the size of the store queue in the load/store unit emulated by the; tool. By default, the tool assumes an unbound number of entries in the store; queue. A value of zero for this flag is ignored, and the default store queue; size is used instead. .. option:: -timeline. Enable the timeline view. .. option:: -timeline-max-iterations=<iterations>. Limit the number of iterations to print in the timeline view. By default, the; timeline view prints information for up to 10 iterations. .. option:: -timeline-max-cycles=<cycles>. Limit the number of cycles in the timeline view, or use 0 for no limit. By; default, the number of cycles is set to 80. .. option:: -resource-pressure. Enable the resource pressure view. This is enabled by default. .. option:: -register-file-stats. Enable register file usage statistics. .. op",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:4297,Performance,queue,queue,4297,"ly printed as part; of the report. .. option:: -dispatch=<width>. Specify a different dispatch width for the processor. The dispatch width; defaults to field 'IssueWidth' in the processor scheduling model. If width is; zero, then the default dispatch width is used. .. option:: -register-file-size=<size>. Specify the size of the register file. When specified, this flag limits how; many physical registers are available for register renaming purposes. A value; of zero for this flag means ""unlimited number of physical registers"". .. option:: -iterations=<number of iterations>. Specify the number of iterations to run. If this flag is set to 0, then the; tool sets the number of iterations to a default value (i.e. 100). .. option:: -noalias=<bool>. If set, the tool assumes that loads and stores don't alias. This is the; default behavior. .. option:: -lqueue=<load queue size>. Specify the size of the load queue in the load/store unit emulated by the tool.; By default, the tool assumes an unbound number of entries in the load queue.; A value of zero for this flag is ignored, and the default load queue size is; used instead. .. option:: -squeue=<store queue size>. Specify the size of the store queue in the load/store unit emulated by the; tool. By default, the tool assumes an unbound number of entries in the store; queue. A value of zero for this flag is ignored, and the default store queue; size is used instead. .. option:: -timeline. Enable the timeline view. .. option:: -timeline-max-iterations=<iterations>. Limit the number of iterations to print in the timeline view. By default, the; timeline view prints information for up to 10 iterations. .. option:: -timeline-max-cycles=<cycles>. Limit the number of cycles in the timeline view, or use 0 for no limit. By; default, the number of cycles is set to 80. .. option:: -resource-pressure. Enable the resource pressure view. This is enabled by default. .. option:: -register-file-stats. Enable register file usage statistics. .. op",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:4363,Performance,load,load,4363," dispatch width for the processor. The dispatch width; defaults to field 'IssueWidth' in the processor scheduling model. If width is; zero, then the default dispatch width is used. .. option:: -register-file-size=<size>. Specify the size of the register file. When specified, this flag limits how; many physical registers are available for register renaming purposes. A value; of zero for this flag means ""unlimited number of physical registers"". .. option:: -iterations=<number of iterations>. Specify the number of iterations to run. If this flag is set to 0, then the; tool sets the number of iterations to a default value (i.e. 100). .. option:: -noalias=<bool>. If set, the tool assumes that loads and stores don't alias. This is the; default behavior. .. option:: -lqueue=<load queue size>. Specify the size of the load queue in the load/store unit emulated by the tool.; By default, the tool assumes an unbound number of entries in the load queue.; A value of zero for this flag is ignored, and the default load queue size is; used instead. .. option:: -squeue=<store queue size>. Specify the size of the store queue in the load/store unit emulated by the; tool. By default, the tool assumes an unbound number of entries in the store; queue. A value of zero for this flag is ignored, and the default store queue; size is used instead. .. option:: -timeline. Enable the timeline view. .. option:: -timeline-max-iterations=<iterations>. Limit the number of iterations to print in the timeline view. By default, the; timeline view prints information for up to 10 iterations. .. option:: -timeline-max-cycles=<cycles>. Limit the number of cycles in the timeline view, or use 0 for no limit. By; default, the number of cycles is set to 80. .. option:: -resource-pressure. Enable the resource pressure view. This is enabled by default. .. option:: -register-file-stats. Enable register file usage statistics. .. option:: -dispatch-stats. Enable extra dispatch statistics. This view collects and analy",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:4368,Performance,queue,queue,4368," dispatch width for the processor. The dispatch width; defaults to field 'IssueWidth' in the processor scheduling model. If width is; zero, then the default dispatch width is used. .. option:: -register-file-size=<size>. Specify the size of the register file. When specified, this flag limits how; many physical registers are available for register renaming purposes. A value; of zero for this flag means ""unlimited number of physical registers"". .. option:: -iterations=<number of iterations>. Specify the number of iterations to run. If this flag is set to 0, then the; tool sets the number of iterations to a default value (i.e. 100). .. option:: -noalias=<bool>. If set, the tool assumes that loads and stores don't alias. This is the; default behavior. .. option:: -lqueue=<load queue size>. Specify the size of the load queue in the load/store unit emulated by the tool.; By default, the tool assumes an unbound number of entries in the load queue.; A value of zero for this flag is ignored, and the default load queue size is; used instead. .. option:: -squeue=<store queue size>. Specify the size of the store queue in the load/store unit emulated by the; tool. By default, the tool assumes an unbound number of entries in the store; queue. A value of zero for this flag is ignored, and the default store queue; size is used instead. .. option:: -timeline. Enable the timeline view. .. option:: -timeline-max-iterations=<iterations>. Limit the number of iterations to print in the timeline view. By default, the; timeline view prints information for up to 10 iterations. .. option:: -timeline-max-cycles=<cycles>. Limit the number of cycles in the timeline view, or use 0 for no limit. By; default, the number of cycles is set to 80. .. option:: -resource-pressure. Enable the resource pressure view. This is enabled by default. .. option:: -register-file-stats. Enable register file usage statistics. .. option:: -dispatch-stats. Enable extra dispatch statistics. This view collects and analy",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:4424,Performance,queue,queue,4424,"ield 'IssueWidth' in the processor scheduling model. If width is; zero, then the default dispatch width is used. .. option:: -register-file-size=<size>. Specify the size of the register file. When specified, this flag limits how; many physical registers are available for register renaming purposes. A value; of zero for this flag means ""unlimited number of physical registers"". .. option:: -iterations=<number of iterations>. Specify the number of iterations to run. If this flag is set to 0, then the; tool sets the number of iterations to a default value (i.e. 100). .. option:: -noalias=<bool>. If set, the tool assumes that loads and stores don't alias. This is the; default behavior. .. option:: -lqueue=<load queue size>. Specify the size of the load queue in the load/store unit emulated by the tool.; By default, the tool assumes an unbound number of entries in the load queue.; A value of zero for this flag is ignored, and the default load queue size is; used instead. .. option:: -squeue=<store queue size>. Specify the size of the store queue in the load/store unit emulated by the; tool. By default, the tool assumes an unbound number of entries in the store; queue. A value of zero for this flag is ignored, and the default store queue; size is used instead. .. option:: -timeline. Enable the timeline view. .. option:: -timeline-max-iterations=<iterations>. Limit the number of iterations to print in the timeline view. By default, the; timeline view prints information for up to 10 iterations. .. option:: -timeline-max-cycles=<cycles>. Limit the number of cycles in the timeline view, or use 0 for no limit. By; default, the number of cycles is set to 80. .. option:: -resource-pressure. Enable the resource pressure view. This is enabled by default. .. option:: -register-file-stats. Enable register file usage statistics. .. option:: -dispatch-stats. Enable extra dispatch statistics. This view collects and analyzes instruction; dispatch events, as well as static/dynamic dispatch",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:4467,Performance,queue,queue,4467,"h is; zero, then the default dispatch width is used. .. option:: -register-file-size=<size>. Specify the size of the register file. When specified, this flag limits how; many physical registers are available for register renaming purposes. A value; of zero for this flag means ""unlimited number of physical registers"". .. option:: -iterations=<number of iterations>. Specify the number of iterations to run. If this flag is set to 0, then the; tool sets the number of iterations to a default value (i.e. 100). .. option:: -noalias=<bool>. If set, the tool assumes that loads and stores don't alias. This is the; default behavior. .. option:: -lqueue=<load queue size>. Specify the size of the load queue in the load/store unit emulated by the tool.; By default, the tool assumes an unbound number of entries in the load queue.; A value of zero for this flag is ignored, and the default load queue size is; used instead. .. option:: -squeue=<store queue size>. Specify the size of the store queue in the load/store unit emulated by the; tool. By default, the tool assumes an unbound number of entries in the store; queue. A value of zero for this flag is ignored, and the default store queue; size is used instead. .. option:: -timeline. Enable the timeline view. .. option:: -timeline-max-iterations=<iterations>. Limit the number of iterations to print in the timeline view. By default, the; timeline view prints information for up to 10 iterations. .. option:: -timeline-max-cycles=<cycles>. Limit the number of cycles in the timeline view, or use 0 for no limit. By; default, the number of cycles is set to 80. .. option:: -resource-pressure. Enable the resource pressure view. This is enabled by default. .. option:: -register-file-stats. Enable register file usage statistics. .. option:: -dispatch-stats. Enable extra dispatch statistics. This view collects and analyzes instruction; dispatch events, as well as static/dynamic dispatch stall events. This view; is disabled by default. .. option",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:4480,Performance,load,load,4480,"h is; zero, then the default dispatch width is used. .. option:: -register-file-size=<size>. Specify the size of the register file. When specified, this flag limits how; many physical registers are available for register renaming purposes. A value; of zero for this flag means ""unlimited number of physical registers"". .. option:: -iterations=<number of iterations>. Specify the number of iterations to run. If this flag is set to 0, then the; tool sets the number of iterations to a default value (i.e. 100). .. option:: -noalias=<bool>. If set, the tool assumes that loads and stores don't alias. This is the; default behavior. .. option:: -lqueue=<load queue size>. Specify the size of the load queue in the load/store unit emulated by the tool.; By default, the tool assumes an unbound number of entries in the load queue.; A value of zero for this flag is ignored, and the default load queue size is; used instead. .. option:: -squeue=<store queue size>. Specify the size of the store queue in the load/store unit emulated by the; tool. By default, the tool assumes an unbound number of entries in the store; queue. A value of zero for this flag is ignored, and the default store queue; size is used instead. .. option:: -timeline. Enable the timeline view. .. option:: -timeline-max-iterations=<iterations>. Limit the number of iterations to print in the timeline view. By default, the; timeline view prints information for up to 10 iterations. .. option:: -timeline-max-cycles=<cycles>. Limit the number of cycles in the timeline view, or use 0 for no limit. By; default, the number of cycles is set to 80. .. option:: -resource-pressure. Enable the resource pressure view. This is enabled by default. .. option:: -register-file-stats. Enable register file usage statistics. .. option:: -dispatch-stats. Enable extra dispatch statistics. This view collects and analyzes instruction; dispatch events, as well as static/dynamic dispatch stall events. This view; is disabled by default. .. option",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:4591,Performance,queue,queue,4591,"size=<size>. Specify the size of the register file. When specified, this flag limits how; many physical registers are available for register renaming purposes. A value; of zero for this flag means ""unlimited number of physical registers"". .. option:: -iterations=<number of iterations>. Specify the number of iterations to run. If this flag is set to 0, then the; tool sets the number of iterations to a default value (i.e. 100). .. option:: -noalias=<bool>. If set, the tool assumes that loads and stores don't alias. This is the; default behavior. .. option:: -lqueue=<load queue size>. Specify the size of the load queue in the load/store unit emulated by the tool.; By default, the tool assumes an unbound number of entries in the load queue.; A value of zero for this flag is ignored, and the default load queue size is; used instead. .. option:: -squeue=<store queue size>. Specify the size of the store queue in the load/store unit emulated by the; tool. By default, the tool assumes an unbound number of entries in the store; queue. A value of zero for this flag is ignored, and the default store queue; size is used instead. .. option:: -timeline. Enable the timeline view. .. option:: -timeline-max-iterations=<iterations>. Limit the number of iterations to print in the timeline view. By default, the; timeline view prints information for up to 10 iterations. .. option:: -timeline-max-cycles=<cycles>. Limit the number of cycles in the timeline view, or use 0 for no limit. By; default, the number of cycles is set to 80. .. option:: -resource-pressure. Enable the resource pressure view. This is enabled by default. .. option:: -register-file-stats. Enable register file usage statistics. .. option:: -dispatch-stats. Enable extra dispatch statistics. This view collects and analyzes instruction; dispatch events, as well as static/dynamic dispatch stall events. This view; is disabled by default. .. option:: -scheduler-stats. Enable extra scheduler statistics. This view collects and an",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:4662,Performance,queue,queue,4662,"ow; many physical registers are available for register renaming purposes. A value; of zero for this flag means ""unlimited number of physical registers"". .. option:: -iterations=<number of iterations>. Specify the number of iterations to run. If this flag is set to 0, then the; tool sets the number of iterations to a default value (i.e. 100). .. option:: -noalias=<bool>. If set, the tool assumes that loads and stores don't alias. This is the; default behavior. .. option:: -lqueue=<load queue size>. Specify the size of the load queue in the load/store unit emulated by the tool.; By default, the tool assumes an unbound number of entries in the load queue.; A value of zero for this flag is ignored, and the default load queue size is; used instead. .. option:: -squeue=<store queue size>. Specify the size of the store queue in the load/store unit emulated by the; tool. By default, the tool assumes an unbound number of entries in the store; queue. A value of zero for this flag is ignored, and the default store queue; size is used instead. .. option:: -timeline. Enable the timeline view. .. option:: -timeline-max-iterations=<iterations>. Limit the number of iterations to print in the timeline view. By default, the; timeline view prints information for up to 10 iterations. .. option:: -timeline-max-cycles=<cycles>. Limit the number of cycles in the timeline view, or use 0 for no limit. By; default, the number of cycles is set to 80. .. option:: -resource-pressure. Enable the resource pressure view. This is enabled by default. .. option:: -register-file-stats. Enable register file usage statistics. .. option:: -dispatch-stats. Enable extra dispatch statistics. This view collects and analyzes instruction; dispatch events, as well as static/dynamic dispatch stall events. This view; is disabled by default. .. option:: -scheduler-stats. Enable extra scheduler statistics. This view collects and analyzes instruction; issue events. This view is disabled by default. .. option:: -retir",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:6694,Performance,bottleneck,bottleneck-analysis,6694,"This view is disabled by default. .. option:: -instruction-info. Enable the instruction info view. This is enabled by default. .. option:: -show-encoding. Enable the printing of instruction encodings within the instruction info view. .. option:: -show-barriers. Enable the printing of LoadBarrier and StoreBarrier flags within the; instruction info view. .. option:: -all-stats. Print all hardware statistics. This enables extra statistics related to the; dispatch logic, the hardware schedulers, the register file(s), and the retire; control unit. This option is disabled by default. .. option:: -all-views. Enable all the view. .. option:: -instruction-tables. Prints resource pressure information based on the static information; available from the processor model. This differs from the resource pressure; view because it doesn't require that the code is simulated. It instead prints; the theoretical uniform distribution of resource pressure for every; instruction in sequence. .. option:: -bottleneck-analysis. Print information about bottlenecks that affect the throughput. This analysis; can be expensive, and it is disabled by default. Bottlenecks are highlighted; in the summary view. Bottleneck analysis is currently not supported for; processors with an in-order backend. .. option:: -json. Print the requested views in valid JSON format. The instructions and the; processor resources are printed as members of special top level JSON objects.; The individual views refer to them by index. However, not all views are; currently supported. For example, the report from the bottleneck analysis is; not printed out in JSON. All the default views are currently supported. .. option:: -disable-cb. Force usage of the generic CustomBehaviour and InstrPostProcess classes rather; than using the target specific implementation. The generic classes never; detect any custom hazards or make any post processing modifications to; instructions. .. option:: -disable-im. Force usage of the generic Instr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:6739,Performance,bottleneck,bottlenecks,6739,"nstruction-info. Enable the instruction info view. This is enabled by default. .. option:: -show-encoding. Enable the printing of instruction encodings within the instruction info view. .. option:: -show-barriers. Enable the printing of LoadBarrier and StoreBarrier flags within the; instruction info view. .. option:: -all-stats. Print all hardware statistics. This enables extra statistics related to the; dispatch logic, the hardware schedulers, the register file(s), and the retire; control unit. This option is disabled by default. .. option:: -all-views. Enable all the view. .. option:: -instruction-tables. Prints resource pressure information based on the static information; available from the processor model. This differs from the resource pressure; view because it doesn't require that the code is simulated. It instead prints; the theoretical uniform distribution of resource pressure for every; instruction in sequence. .. option:: -bottleneck-analysis. Print information about bottlenecks that affect the throughput. This analysis; can be expensive, and it is disabled by default. Bottlenecks are highlighted; in the summary view. Bottleneck analysis is currently not supported for; processors with an in-order backend. .. option:: -json. Print the requested views in valid JSON format. The instructions and the; processor resources are printed as members of special top level JSON objects.; The individual views refer to them by index. However, not all views are; currently supported. For example, the report from the bottleneck analysis is; not printed out in JSON. All the default views are currently supported. .. option:: -disable-cb. Force usage of the generic CustomBehaviour and InstrPostProcess classes rather; than using the target specific implementation. The generic classes never; detect any custom hazards or make any post processing modifications to; instructions. .. option:: -disable-im. Force usage of the generic InstrumentManager rather than using the target; spec",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:6767,Performance,throughput,throughput,6767,"nstruction-info. Enable the instruction info view. This is enabled by default. .. option:: -show-encoding. Enable the printing of instruction encodings within the instruction info view. .. option:: -show-barriers. Enable the printing of LoadBarrier and StoreBarrier flags within the; instruction info view. .. option:: -all-stats. Print all hardware statistics. This enables extra statistics related to the; dispatch logic, the hardware schedulers, the register file(s), and the retire; control unit. This option is disabled by default. .. option:: -all-views. Enable all the view. .. option:: -instruction-tables. Prints resource pressure information based on the static information; available from the processor model. This differs from the resource pressure; view because it doesn't require that the code is simulated. It instead prints; the theoretical uniform distribution of resource pressure for every; instruction in sequence. .. option:: -bottleneck-analysis. Print information about bottlenecks that affect the throughput. This analysis; can be expensive, and it is disabled by default. Bottlenecks are highlighted; in the summary view. Bottleneck analysis is currently not supported for; processors with an in-order backend. .. option:: -json. Print the requested views in valid JSON format. The instructions and the; processor resources are printed as members of special top level JSON objects.; The individual views refer to them by index. However, not all views are; currently supported. For example, the report from the bottleneck analysis is; not printed out in JSON. All the default views are currently supported. .. option:: -disable-cb. Force usage of the generic CustomBehaviour and InstrPostProcess classes rather; than using the target specific implementation. The generic classes never; detect any custom hazards or make any post processing modifications to; instructions. .. option:: -disable-im. Force usage of the generic InstrumentManager rather than using the target; spec",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:7281,Performance,bottleneck,bottleneck,7281,"tion:: -all-views. Enable all the view. .. option:: -instruction-tables. Prints resource pressure information based on the static information; available from the processor model. This differs from the resource pressure; view because it doesn't require that the code is simulated. It instead prints; the theoretical uniform distribution of resource pressure for every; instruction in sequence. .. option:: -bottleneck-analysis. Print information about bottlenecks that affect the throughput. This analysis; can be expensive, and it is disabled by default. Bottlenecks are highlighted; in the summary view. Bottleneck analysis is currently not supported for; processors with an in-order backend. .. option:: -json. Print the requested views in valid JSON format. The instructions and the; processor resources are printed as members of special top level JSON objects.; The individual views refer to them by index. However, not all views are; currently supported. For example, the report from the bottleneck analysis is; not printed out in JSON. All the default views are currently supported. .. option:: -disable-cb. Force usage of the generic CustomBehaviour and InstrPostProcess classes rather; than using the target specific implementation. The generic classes never; detect any custom hazards or make any post processing modifications to; instructions. .. option:: -disable-im. Force usage of the generic InstrumentManager rather than using the target; specific implementation. The generic class creates Instruments that provide; no extra information, and InstrumentManager never overrides the default; schedule class for a given instruction. EXIT STATUS; -----------. :program:`llvm-mca` returns 0 on success. Otherwise, an error message is printed; to standard error, and the tool returns 1. USING MARKERS TO ANALYZE SPECIFIC CODE BLOCKS; ---------------------------------------------; :program:`llvm-mca` allows for the optional usage of special code comments to; mark regions of the assembly cod",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:8755,Performance,perform,performance,8755,"generic class creates Instruments that provide; no extra information, and InstrumentManager never overrides the default; schedule class for a given instruction. EXIT STATUS; -----------. :program:`llvm-mca` returns 0 on success. Otherwise, an error message is printed; to standard error, and the tool returns 1. USING MARKERS TO ANALYZE SPECIFIC CODE BLOCKS; ---------------------------------------------; :program:`llvm-mca` allows for the optional usage of special code comments to; mark regions of the assembly code to be analyzed. A comment starting with; substring ``LLVM-MCA-BEGIN`` marks the beginning of an analysis region. A; comment starting with substring ``LLVM-MCA-END`` marks the end of a region.; For example:. .. code-block:: none. # LLVM-MCA-BEGIN; ...; # LLVM-MCA-END. If no user-defined region is specified, then :program:`llvm-mca` assumes a; default region which contains every instruction in the input file. Every region; is analyzed in isolation, and the final performance report is the union of all; the reports generated for every analysis region. Analysis regions can have names. For example:. .. code-block:: none. # LLVM-MCA-BEGIN A simple example; add %eax, %eax; # LLVM-MCA-END. The code from the example above defines a region named ""A simple example"" with a; single instruction in it. Note how the region name doesn't have to be repeated; in the ``LLVM-MCA-END`` directive. In the absence of overlapping regions,; an anonymous ``LLVM-MCA-END`` directive always ends the currently active user; defined region. Example of nesting regions:. .. code-block:: none. # LLVM-MCA-BEGIN foo; add %eax, %edx; # LLVM-MCA-BEGIN bar; sub %eax, %edx; # LLVM-MCA-END bar; # LLVM-MCA-END foo. Example of overlapping regions:. .. code-block:: none. # LLVM-MCA-BEGIN foo; add %eax, %edx; # LLVM-MCA-BEGIN bar; sub %eax, %edx; # LLVM-MCA-END foo; add %eax, %edx; # LLVM-MCA-END bar. Note that multiple anonymous regions cannot overlap. Also, overlapping regions; cannot have the same name.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:10123,Performance,optimiz,optimizations,10123,"``LLVM-MCA-END`` directive. In the absence of overlapping regions,; an anonymous ``LLVM-MCA-END`` directive always ends the currently active user; defined region. Example of nesting regions:. .. code-block:: none. # LLVM-MCA-BEGIN foo; add %eax, %edx; # LLVM-MCA-BEGIN bar; sub %eax, %edx; # LLVM-MCA-END bar; # LLVM-MCA-END foo. Example of overlapping regions:. .. code-block:: none. # LLVM-MCA-BEGIN foo; add %eax, %edx; # LLVM-MCA-BEGIN bar; sub %eax, %edx; # LLVM-MCA-END foo; add %eax, %edx; # LLVM-MCA-END bar. Note that multiple anonymous regions cannot overlap. Also, overlapping regions; cannot have the same name. There is no support for marking regions from high-level source code, like C or; C++. As a workaround, inline assembly directives may be used:. .. code-block:: c++. int foo(int a, int b) {; __asm volatile(""# LLVM-MCA-BEGIN foo"":::""memory"");; a += 42;; __asm volatile(""# LLVM-MCA-END"":::""memory"");; a *= b;; return a;; }. However, this interferes with optimizations like loop vectorization and may have; an impact on the code generated. This is because the ``__asm`` statements are; seen as real code having important side effects, which limits how the code; around them can be transformed. If users want to make use of inline assembly; to emit markers, then the recommendation is to always verify that the output; assembly is equivalent to the assembly generated in the absence of markers.; The `Clang options to emit optimization reports <https://clang.llvm.org/docs/UsersManual.html#options-to-emit-optimization-reports>`_; can also help in detecting missed optimizations. INSTRUMENT REGIONS; ------------------. An InstrumentRegion describes a region of assembly code guarded by; special LLVM-MCA comment directives. .. code-block:: none. # LLVM-MCA-<INSTRUMENT_TYPE> <data>; ... ## asm. where `INSTRUMENT_TYPE` is a type defined by the target and expects; to use `data`. A comment starting with substring `LLVM-MCA-<INSTRUMENT_TYPE>`; brings data into scope for llvm-mca to ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:10590,Performance,optimiz,optimization,10590," sub %eax, %edx; # LLVM-MCA-END foo; add %eax, %edx; # LLVM-MCA-END bar. Note that multiple anonymous regions cannot overlap. Also, overlapping regions; cannot have the same name. There is no support for marking regions from high-level source code, like C or; C++. As a workaround, inline assembly directives may be used:. .. code-block:: c++. int foo(int a, int b) {; __asm volatile(""# LLVM-MCA-BEGIN foo"":::""memory"");; a += 42;; __asm volatile(""# LLVM-MCA-END"":::""memory"");; a *= b;; return a;; }. However, this interferes with optimizations like loop vectorization and may have; an impact on the code generated. This is because the ``__asm`` statements are; seen as real code having important side effects, which limits how the code; around them can be transformed. If users want to make use of inline assembly; to emit markers, then the recommendation is to always verify that the output; assembly is equivalent to the assembly generated in the absence of markers.; The `Clang options to emit optimization reports <https://clang.llvm.org/docs/UsersManual.html#options-to-emit-optimization-reports>`_; can also help in detecting missed optimizations. INSTRUMENT REGIONS; ------------------. An InstrumentRegion describes a region of assembly code guarded by; special LLVM-MCA comment directives. .. code-block:: none. # LLVM-MCA-<INSTRUMENT_TYPE> <data>; ... ## asm. where `INSTRUMENT_TYPE` is a type defined by the target and expects; to use `data`. A comment starting with substring `LLVM-MCA-<INSTRUMENT_TYPE>`; brings data into scope for llvm-mca to use in its analysis for; all following instructions. If a comment with the same `INSTRUMENT_TYPE` is found later in the; instruction list, then the original InstrumentRegion will be; automatically ended, and a new InstrumentRegion will begin. If there are comments containing the different `INSTRUMENT_TYPE`,; then both data sets remain available. In contrast with an AnalysisRegion,; an InstrumentRegion does not need a comment to end the regi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:10673,Performance,optimiz,optimization-reports,10673,"ons cannot overlap. Also, overlapping regions; cannot have the same name. There is no support for marking regions from high-level source code, like C or; C++. As a workaround, inline assembly directives may be used:. .. code-block:: c++. int foo(int a, int b) {; __asm volatile(""# LLVM-MCA-BEGIN foo"":::""memory"");; a += 42;; __asm volatile(""# LLVM-MCA-END"":::""memory"");; a *= b;; return a;; }. However, this interferes with optimizations like loop vectorization and may have; an impact on the code generated. This is because the ``__asm`` statements are; seen as real code having important side effects, which limits how the code; around them can be transformed. If users want to make use of inline assembly; to emit markers, then the recommendation is to always verify that the output; assembly is equivalent to the assembly generated in the absence of markers.; The `Clang options to emit optimization reports <https://clang.llvm.org/docs/UsersManual.html#options-to-emit-optimization-reports>`_; can also help in detecting missed optimizations. INSTRUMENT REGIONS; ------------------. An InstrumentRegion describes a region of assembly code guarded by; special LLVM-MCA comment directives. .. code-block:: none. # LLVM-MCA-<INSTRUMENT_TYPE> <data>; ... ## asm. where `INSTRUMENT_TYPE` is a type defined by the target and expects; to use `data`. A comment starting with substring `LLVM-MCA-<INSTRUMENT_TYPE>`; brings data into scope for llvm-mca to use in its analysis for; all following instructions. If a comment with the same `INSTRUMENT_TYPE` is found later in the; instruction list, then the original InstrumentRegion will be; automatically ended, and a new InstrumentRegion will begin. If there are comments containing the different `INSTRUMENT_TYPE`,; then both data sets remain available. In contrast with an AnalysisRegion,; an InstrumentRegion does not need a comment to end the region. Comments that are prefixed with `LLVM-MCA-` but do not correspond to; a valid `INSTRUMENT_TYPE` for t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:10732,Performance,optimiz,optimizations,10732,"ons cannot overlap. Also, overlapping regions; cannot have the same name. There is no support for marking regions from high-level source code, like C or; C++. As a workaround, inline assembly directives may be used:. .. code-block:: c++. int foo(int a, int b) {; __asm volatile(""# LLVM-MCA-BEGIN foo"":::""memory"");; a += 42;; __asm volatile(""# LLVM-MCA-END"":::""memory"");; a *= b;; return a;; }. However, this interferes with optimizations like loop vectorization and may have; an impact on the code generated. This is because the ``__asm`` statements are; seen as real code having important side effects, which limits how the code; around them can be transformed. If users want to make use of inline assembly; to emit markers, then the recommendation is to always verify that the output; assembly is equivalent to the assembly generated in the absence of markers.; The `Clang options to emit optimization reports <https://clang.llvm.org/docs/UsersManual.html#options-to-emit-optimization-reports>`_; can also help in detecting missed optimizations. INSTRUMENT REGIONS; ------------------. An InstrumentRegion describes a region of assembly code guarded by; special LLVM-MCA comment directives. .. code-block:: none. # LLVM-MCA-<INSTRUMENT_TYPE> <data>; ... ## asm. where `INSTRUMENT_TYPE` is a type defined by the target and expects; to use `data`. A comment starting with substring `LLVM-MCA-<INSTRUMENT_TYPE>`; brings data into scope for llvm-mca to use in its analysis for; all following instructions. If a comment with the same `INSTRUMENT_TYPE` is found later in the; instruction list, then the original InstrumentRegion will be; automatically ended, and a new InstrumentRegion will begin. If there are comments containing the different `INSTRUMENT_TYPE`,; then both data sets remain available. In contrast with an AnalysisRegion,; an InstrumentRegion does not need a comment to end the region. Comments that are prefixed with `LLVM-MCA-` but do not correspond to; a valid `INSTRUMENT_TYPE` for t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:13562,Performance,perform,performance,13562,"anywhere in the program. Example of program with no call to `vset{i}vl{i}`:. .. code-block:: none. # LLVM-MCA-RISCV-LMUL M2; vadd.vv v2, v2, v2. Example of program with call to `vset{i}vl{i}`:. .. code-block:: none. vsetvli zero, a0, e8, m1, tu, mu; # LLVM-MCA-RISCV-LMUL M1; vadd.vv v2, v2, v2. Example of program with multiple calls to `vset{i}vl{i}`:. .. code-block:: none. vsetvli zero, a0, e8, m1, tu, mu; # LLVM-MCA-RISCV-LMUL M1; vadd.vv v2, v2, v2; vsetvli zero, a0, e8, m8, tu, mu; # LLVM-MCA-RISCV-LMUL M8; vadd.vv v2, v2, v2. Example of program with call to `vsetvl`:. .. code-block:: none. vsetvl rd, rs1, rs2; # LLVM-MCA-RISCV-LMUL M1; vadd.vv v12, v12, v12; vsetvl rd, rs1, rs2; # LLVM-MCA-RISCV-LMUL M4; vadd.vv v12, v12, v12. HOW LLVM-MCA WORKS; ------------------. :program:`llvm-mca` takes assembly code as input. The assembly code is parsed; into a sequence of MCInst with the help of the existing LLVM target assembly; parsers. The parsed sequence of MCInst is then analyzed by a ``Pipeline`` module; to generate a performance report. The Pipeline module simulates the execution of the machine code sequence in a; loop of iterations (default is 100). During this process, the pipeline collects; a number of execution related statistics. At the end of this process, the; pipeline generates and prints a report from the collected statistics. Here is an example of a performance report generated by the tool for a; dot-product of two packed float vectors of four elements. The analysis is; conducted for target x86, cpu btver2. The following result can be produced via; the following command using the example located at; ``test/tools/llvm-mca/X86/BtVer2/dot-product.s``:. .. code-block:: bash. $ llvm-mca -mtriple=x86_64-unknown-unknown -mcpu=btver2 -iterations=300 dot-product.s. .. code-block:: none. Iterations: 300; Instructions: 900; Total Cycles: 610; Total uOps: 900. Dispatch Width: 2; uOps Per Cycle: 1.48; IPC: 1.48; Block RThroughput: 2.0. Instruction Info:; [1]: #uOps; [",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:13911,Performance,perform,performance,13911,"SCV-LMUL M1; vadd.vv v2, v2, v2; vsetvli zero, a0, e8, m8, tu, mu; # LLVM-MCA-RISCV-LMUL M8; vadd.vv v2, v2, v2. Example of program with call to `vsetvl`:. .. code-block:: none. vsetvl rd, rs1, rs2; # LLVM-MCA-RISCV-LMUL M1; vadd.vv v12, v12, v12; vsetvl rd, rs1, rs2; # LLVM-MCA-RISCV-LMUL M4; vadd.vv v12, v12, v12. HOW LLVM-MCA WORKS; ------------------. :program:`llvm-mca` takes assembly code as input. The assembly code is parsed; into a sequence of MCInst with the help of the existing LLVM target assembly; parsers. The parsed sequence of MCInst is then analyzed by a ``Pipeline`` module; to generate a performance report. The Pipeline module simulates the execution of the machine code sequence in a; loop of iterations (default is 100). During this process, the pipeline collects; a number of execution related statistics. At the end of this process, the; pipeline generates and prints a report from the collected statistics. Here is an example of a performance report generated by the tool for a; dot-product of two packed float vectors of four elements. The analysis is; conducted for target x86, cpu btver2. The following result can be produced via; the following command using the example located at; ``test/tools/llvm-mca/X86/BtVer2/dot-product.s``:. .. code-block:: bash. $ llvm-mca -mtriple=x86_64-unknown-unknown -mcpu=btver2 -iterations=300 dot-product.s. .. code-block:: none. Iterations: 300; Instructions: 900; Total Cycles: 610; Total uOps: 900. Dispatch Width: 2; uOps Per Cycle: 1.48; IPC: 1.48; Block RThroughput: 2.0. Instruction Info:; [1]: #uOps; [2]: Latency; [3]: RThroughput; [4]: MayLoad; [5]: MayStore; [6]: HasSideEffects (U). [1] [2] [3] [4] [5] [6] Instructions:; 1 2 1.00 vmulps	%xmm0, %xmm1, %xmm2; 1 3 1.00 vhaddps	%xmm2, %xmm2, %xmm3; 1 3 1.00 vhaddps	%xmm3, %xmm3, %xmm4. Resources:; [0] - JALU0; [1] - JALU1; [2] - JDiv; [3] - JFPA; [4] - JFPM; [5] - JFPU0; [6] - JFPU1; [7] - JLAGU; [8] - JMul; [9] - JSAGU; [10] - JSTC; [11] - JVALU0; [12] - JVALU1; [13] ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:15665,Performance,perform,performance,15665,"dps	%xmm2, %xmm2, %xmm3; 1 3 1.00 vhaddps	%xmm3, %xmm3, %xmm4. Resources:; [0] - JALU0; [1] - JALU1; [2] - JDiv; [3] - JFPA; [4] - JFPM; [5] - JFPU0; [6] - JFPU1; [7] - JLAGU; [8] - JMul; [9] - JSAGU; [10] - JSTC; [11] - JVALU0; [12] - JVALU1; [13] - JVIMUL. Resource pressure per iteration:; [0] [1] [2] [3] [4] [5] [6] [7] [8] [9] [10] [11] [12] [13]; - - - 2.00 1.00 2.00 1.00 - - - - - - -. Resource pressure by instruction:; [0] [1] [2] [3] [4] [5] [6] [7] [8] [9] [10] [11] [12] [13] Instructions:; - - - - 1.00 - 1.00 - - - - - - - vmulps	%xmm0, %xmm1, %xmm2; - - - 1.00 - 1.00 - - - - - - - - vhaddps	%xmm2, %xmm2, %xmm3; - - - 1.00 - 1.00 - - - - - - - - vhaddps	%xmm3, %xmm3, %xmm4. According to this report, the dot-product kernel has been executed 300 times,; for a total of 900 simulated instructions. The total number of simulated micro; opcodes (uOps) is also 900. The report is structured in three main sections. The first section collects a; few performance numbers; the goal of this section is to give a very quick; overview of the performance throughput. Important performance indicators are; **IPC**, **uOps Per Cycle**, and **Block RThroughput** (Block Reciprocal; Throughput). Field *DispatchWidth* is the maximum number of micro opcodes that are dispatched; to the out-of-order backend every simulated cycle. For processors with an; in-order backend, *DispatchWidth* is the maximum number of micro opcodes issued; to the backend every simulated cycle. IPC is computed dividing the total number of simulated instructions by the total; number of cycles. Field *Block RThroughput* is the reciprocal of the block throughput. Block; throughput is a theoretical quantity computed as the maximum number of blocks; (i.e. iterations) that can be executed per simulated clock cycle in the absence; of loop carried dependencies. Block throughput is superiorly limited by the; dispatch rate, and the availability of hardware resources. In the absence of loop-carried data dependencies, the ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:15752,Performance,perform,performance,15752,"dps	%xmm2, %xmm2, %xmm3; 1 3 1.00 vhaddps	%xmm3, %xmm3, %xmm4. Resources:; [0] - JALU0; [1] - JALU1; [2] - JDiv; [3] - JFPA; [4] - JFPM; [5] - JFPU0; [6] - JFPU1; [7] - JLAGU; [8] - JMul; [9] - JSAGU; [10] - JSTC; [11] - JVALU0; [12] - JVALU1; [13] - JVIMUL. Resource pressure per iteration:; [0] [1] [2] [3] [4] [5] [6] [7] [8] [9] [10] [11] [12] [13]; - - - 2.00 1.00 2.00 1.00 - - - - - - -. Resource pressure by instruction:; [0] [1] [2] [3] [4] [5] [6] [7] [8] [9] [10] [11] [12] [13] Instructions:; - - - - 1.00 - 1.00 - - - - - - - vmulps	%xmm0, %xmm1, %xmm2; - - - 1.00 - 1.00 - - - - - - - - vhaddps	%xmm2, %xmm2, %xmm3; - - - 1.00 - 1.00 - - - - - - - - vhaddps	%xmm3, %xmm3, %xmm4. According to this report, the dot-product kernel has been executed 300 times,; for a total of 900 simulated instructions. The total number of simulated micro; opcodes (uOps) is also 900. The report is structured in three main sections. The first section collects a; few performance numbers; the goal of this section is to give a very quick; overview of the performance throughput. Important performance indicators are; **IPC**, **uOps Per Cycle**, and **Block RThroughput** (Block Reciprocal; Throughput). Field *DispatchWidth* is the maximum number of micro opcodes that are dispatched; to the out-of-order backend every simulated cycle. For processors with an; in-order backend, *DispatchWidth* is the maximum number of micro opcodes issued; to the backend every simulated cycle. IPC is computed dividing the total number of simulated instructions by the total; number of cycles. Field *Block RThroughput* is the reciprocal of the block throughput. Block; throughput is a theoretical quantity computed as the maximum number of blocks; (i.e. iterations) that can be executed per simulated clock cycle in the absence; of loop carried dependencies. Block throughput is superiorly limited by the; dispatch rate, and the availability of hardware resources. In the absence of loop-carried data dependencies, the ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:15764,Performance,throughput,throughput,15764,"dps	%xmm2, %xmm2, %xmm3; 1 3 1.00 vhaddps	%xmm3, %xmm3, %xmm4. Resources:; [0] - JALU0; [1] - JALU1; [2] - JDiv; [3] - JFPA; [4] - JFPM; [5] - JFPU0; [6] - JFPU1; [7] - JLAGU; [8] - JMul; [9] - JSAGU; [10] - JSTC; [11] - JVALU0; [12] - JVALU1; [13] - JVIMUL. Resource pressure per iteration:; [0] [1] [2] [3] [4] [5] [6] [7] [8] [9] [10] [11] [12] [13]; - - - 2.00 1.00 2.00 1.00 - - - - - - -. Resource pressure by instruction:; [0] [1] [2] [3] [4] [5] [6] [7] [8] [9] [10] [11] [12] [13] Instructions:; - - - - 1.00 - 1.00 - - - - - - - vmulps	%xmm0, %xmm1, %xmm2; - - - 1.00 - 1.00 - - - - - - - - vhaddps	%xmm2, %xmm2, %xmm3; - - - 1.00 - 1.00 - - - - - - - - vhaddps	%xmm3, %xmm3, %xmm4. According to this report, the dot-product kernel has been executed 300 times,; for a total of 900 simulated instructions. The total number of simulated micro; opcodes (uOps) is also 900. The report is structured in three main sections. The first section collects a; few performance numbers; the goal of this section is to give a very quick; overview of the performance throughput. Important performance indicators are; **IPC**, **uOps Per Cycle**, and **Block RThroughput** (Block Reciprocal; Throughput). Field *DispatchWidth* is the maximum number of micro opcodes that are dispatched; to the out-of-order backend every simulated cycle. For processors with an; in-order backend, *DispatchWidth* is the maximum number of micro opcodes issued; to the backend every simulated cycle. IPC is computed dividing the total number of simulated instructions by the total; number of cycles. Field *Block RThroughput* is the reciprocal of the block throughput. Block; throughput is a theoretical quantity computed as the maximum number of blocks; (i.e. iterations) that can be executed per simulated clock cycle in the absence; of loop carried dependencies. Block throughput is superiorly limited by the; dispatch rate, and the availability of hardware resources. In the absence of loop-carried data dependencies, the ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:15786,Performance,perform,performance,15786,"; [5] - JFPU0; [6] - JFPU1; [7] - JLAGU; [8] - JMul; [9] - JSAGU; [10] - JSTC; [11] - JVALU0; [12] - JVALU1; [13] - JVIMUL. Resource pressure per iteration:; [0] [1] [2] [3] [4] [5] [6] [7] [8] [9] [10] [11] [12] [13]; - - - 2.00 1.00 2.00 1.00 - - - - - - -. Resource pressure by instruction:; [0] [1] [2] [3] [4] [5] [6] [7] [8] [9] [10] [11] [12] [13] Instructions:; - - - - 1.00 - 1.00 - - - - - - - vmulps	%xmm0, %xmm1, %xmm2; - - - 1.00 - 1.00 - - - - - - - - vhaddps	%xmm2, %xmm2, %xmm3; - - - 1.00 - 1.00 - - - - - - - - vhaddps	%xmm3, %xmm3, %xmm4. According to this report, the dot-product kernel has been executed 300 times,; for a total of 900 simulated instructions. The total number of simulated micro; opcodes (uOps) is also 900. The report is structured in three main sections. The first section collects a; few performance numbers; the goal of this section is to give a very quick; overview of the performance throughput. Important performance indicators are; **IPC**, **uOps Per Cycle**, and **Block RThroughput** (Block Reciprocal; Throughput). Field *DispatchWidth* is the maximum number of micro opcodes that are dispatched; to the out-of-order backend every simulated cycle. For processors with an; in-order backend, *DispatchWidth* is the maximum number of micro opcodes issued; to the backend every simulated cycle. IPC is computed dividing the total number of simulated instructions by the total; number of cycles. Field *Block RThroughput* is the reciprocal of the block throughput. Block; throughput is a theoretical quantity computed as the maximum number of blocks; (i.e. iterations) that can be executed per simulated clock cycle in the absence; of loop carried dependencies. Block throughput is superiorly limited by the; dispatch rate, and the availability of hardware resources. In the absence of loop-carried data dependencies, the observed IPC tends to a; theoretical maximum which can be computed by dividing the number of instructions; of a single iteration by the",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:16334,Performance,throughput,throughput,16334,"	%xmm2, %xmm2, %xmm3; - - - 1.00 - 1.00 - - - - - - - - vhaddps	%xmm3, %xmm3, %xmm4. According to this report, the dot-product kernel has been executed 300 times,; for a total of 900 simulated instructions. The total number of simulated micro; opcodes (uOps) is also 900. The report is structured in three main sections. The first section collects a; few performance numbers; the goal of this section is to give a very quick; overview of the performance throughput. Important performance indicators are; **IPC**, **uOps Per Cycle**, and **Block RThroughput** (Block Reciprocal; Throughput). Field *DispatchWidth* is the maximum number of micro opcodes that are dispatched; to the out-of-order backend every simulated cycle. For processors with an; in-order backend, *DispatchWidth* is the maximum number of micro opcodes issued; to the backend every simulated cycle. IPC is computed dividing the total number of simulated instructions by the total; number of cycles. Field *Block RThroughput* is the reciprocal of the block throughput. Block; throughput is a theoretical quantity computed as the maximum number of blocks; (i.e. iterations) that can be executed per simulated clock cycle in the absence; of loop carried dependencies. Block throughput is superiorly limited by the; dispatch rate, and the availability of hardware resources. In the absence of loop-carried data dependencies, the observed IPC tends to a; theoretical maximum which can be computed by dividing the number of instructions; of a single iteration by the `Block RThroughput`. Field 'uOps Per Cycle' is computed dividing the total number of simulated micro; opcodes by the total number of cycles. A delta between Dispatch Width and this; field is an indicator of a performance issue. In the absence of loop-carried; data dependencies, the observed 'uOps Per Cycle' should tend to a theoretical; maximum throughput which can be computed by dividing the number of uOps of a; single iteration by the `Block RThroughput`. Field *uOp",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:16353,Performance,throughput,throughput,16353,"mm4. According to this report, the dot-product kernel has been executed 300 times,; for a total of 900 simulated instructions. The total number of simulated micro; opcodes (uOps) is also 900. The report is structured in three main sections. The first section collects a; few performance numbers; the goal of this section is to give a very quick; overview of the performance throughput. Important performance indicators are; **IPC**, **uOps Per Cycle**, and **Block RThroughput** (Block Reciprocal; Throughput). Field *DispatchWidth* is the maximum number of micro opcodes that are dispatched; to the out-of-order backend every simulated cycle. For processors with an; in-order backend, *DispatchWidth* is the maximum number of micro opcodes issued; to the backend every simulated cycle. IPC is computed dividing the total number of simulated instructions by the total; number of cycles. Field *Block RThroughput* is the reciprocal of the block throughput. Block; throughput is a theoretical quantity computed as the maximum number of blocks; (i.e. iterations) that can be executed per simulated clock cycle in the absence; of loop carried dependencies. Block throughput is superiorly limited by the; dispatch rate, and the availability of hardware resources. In the absence of loop-carried data dependencies, the observed IPC tends to a; theoretical maximum which can be computed by dividing the number of instructions; of a single iteration by the `Block RThroughput`. Field 'uOps Per Cycle' is computed dividing the total number of simulated micro; opcodes by the total number of cycles. A delta between Dispatch Width and this; field is an indicator of a performance issue. In the absence of loop-carried; data dependencies, the observed 'uOps Per Cycle' should tend to a theoretical; maximum throughput which can be computed by dividing the number of uOps of a; single iteration by the `Block RThroughput`. Field *uOps Per Cycle* is bounded from above by the dispatch width. That is; because the ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:16549,Performance,throughput,throughput,16549," structured in three main sections. The first section collects a; few performance numbers; the goal of this section is to give a very quick; overview of the performance throughput. Important performance indicators are; **IPC**, **uOps Per Cycle**, and **Block RThroughput** (Block Reciprocal; Throughput). Field *DispatchWidth* is the maximum number of micro opcodes that are dispatched; to the out-of-order backend every simulated cycle. For processors with an; in-order backend, *DispatchWidth* is the maximum number of micro opcodes issued; to the backend every simulated cycle. IPC is computed dividing the total number of simulated instructions by the total; number of cycles. Field *Block RThroughput* is the reciprocal of the block throughput. Block; throughput is a theoretical quantity computed as the maximum number of blocks; (i.e. iterations) that can be executed per simulated clock cycle in the absence; of loop carried dependencies. Block throughput is superiorly limited by the; dispatch rate, and the availability of hardware resources. In the absence of loop-carried data dependencies, the observed IPC tends to a; theoretical maximum which can be computed by dividing the number of instructions; of a single iteration by the `Block RThroughput`. Field 'uOps Per Cycle' is computed dividing the total number of simulated micro; opcodes by the total number of cycles. A delta between Dispatch Width and this; field is an indicator of a performance issue. In the absence of loop-carried; data dependencies, the observed 'uOps Per Cycle' should tend to a theoretical; maximum throughput which can be computed by dividing the number of uOps of a; single iteration by the `Block RThroughput`. Field *uOps Per Cycle* is bounded from above by the dispatch width. That is; because the dispatch width limits the maximum size of a dispatch group. Both IPC; and 'uOps Per Cycle' are limited by the amount of hardware parallelism. The; availability of hardware resources affects the resource pr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:17048,Performance,perform,performance,17048,"ated cycle. For processors with an; in-order backend, *DispatchWidth* is the maximum number of micro opcodes issued; to the backend every simulated cycle. IPC is computed dividing the total number of simulated instructions by the total; number of cycles. Field *Block RThroughput* is the reciprocal of the block throughput. Block; throughput is a theoretical quantity computed as the maximum number of blocks; (i.e. iterations) that can be executed per simulated clock cycle in the absence; of loop carried dependencies. Block throughput is superiorly limited by the; dispatch rate, and the availability of hardware resources. In the absence of loop-carried data dependencies, the observed IPC tends to a; theoretical maximum which can be computed by dividing the number of instructions; of a single iteration by the `Block RThroughput`. Field 'uOps Per Cycle' is computed dividing the total number of simulated micro; opcodes by the total number of cycles. A delta between Dispatch Width and this; field is an indicator of a performance issue. In the absence of loop-carried; data dependencies, the observed 'uOps Per Cycle' should tend to a theoretical; maximum throughput which can be computed by dividing the number of uOps of a; single iteration by the `Block RThroughput`. Field *uOps Per Cycle* is bounded from above by the dispatch width. That is; because the dispatch width limits the maximum size of a dispatch group. Both IPC; and 'uOps Per Cycle' are limited by the amount of hardware parallelism. The; availability of hardware resources affects the resource pressure distribution,; and it limits the number of instructions that can be executed in parallel every; cycle. A delta between Dispatch Width and the theoretical maximum uOps per; Cycle (computed by dividing the number of uOps of a single iteration by the; `Block RThroughput`) is an indicator of a performance bottleneck caused by the; lack of hardware resources.; In general, the lower the Block RThroughput, the better. In thi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:17186,Performance,throughput,throughput,17186," computed dividing the total number of simulated instructions by the total; number of cycles. Field *Block RThroughput* is the reciprocal of the block throughput. Block; throughput is a theoretical quantity computed as the maximum number of blocks; (i.e. iterations) that can be executed per simulated clock cycle in the absence; of loop carried dependencies. Block throughput is superiorly limited by the; dispatch rate, and the availability of hardware resources. In the absence of loop-carried data dependencies, the observed IPC tends to a; theoretical maximum which can be computed by dividing the number of instructions; of a single iteration by the `Block RThroughput`. Field 'uOps Per Cycle' is computed dividing the total number of simulated micro; opcodes by the total number of cycles. A delta between Dispatch Width and this; field is an indicator of a performance issue. In the absence of loop-carried; data dependencies, the observed 'uOps Per Cycle' should tend to a theoretical; maximum throughput which can be computed by dividing the number of uOps of a; single iteration by the `Block RThroughput`. Field *uOps Per Cycle* is bounded from above by the dispatch width. That is; because the dispatch width limits the maximum size of a dispatch group. Both IPC; and 'uOps Per Cycle' are limited by the amount of hardware parallelism. The; availability of hardware resources affects the resource pressure distribution,; and it limits the number of instructions that can be executed in parallel every; cycle. A delta between Dispatch Width and the theoretical maximum uOps per; Cycle (computed by dividing the number of uOps of a single iteration by the; `Block RThroughput`) is an indicator of a performance bottleneck caused by the; lack of hardware resources.; In general, the lower the Block RThroughput, the better. In this example, ``uOps per iteration/Block RThroughput`` is 1.50. Since there; are no loop-carried dependencies, the observed `uOps Per Cycle` is expected to; approa",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:17893,Performance,perform,performance,17893," by the `Block RThroughput`. Field 'uOps Per Cycle' is computed dividing the total number of simulated micro; opcodes by the total number of cycles. A delta between Dispatch Width and this; field is an indicator of a performance issue. In the absence of loop-carried; data dependencies, the observed 'uOps Per Cycle' should tend to a theoretical; maximum throughput which can be computed by dividing the number of uOps of a; single iteration by the `Block RThroughput`. Field *uOps Per Cycle* is bounded from above by the dispatch width. That is; because the dispatch width limits the maximum size of a dispatch group. Both IPC; and 'uOps Per Cycle' are limited by the amount of hardware parallelism. The; availability of hardware resources affects the resource pressure distribution,; and it limits the number of instructions that can be executed in parallel every; cycle. A delta between Dispatch Width and the theoretical maximum uOps per; Cycle (computed by dividing the number of uOps of a single iteration by the; `Block RThroughput`) is an indicator of a performance bottleneck caused by the; lack of hardware resources.; In general, the lower the Block RThroughput, the better. In this example, ``uOps per iteration/Block RThroughput`` is 1.50. Since there; are no loop-carried dependencies, the observed `uOps Per Cycle` is expected to; approach 1.50 when the number of iterations tends to infinity. The delta between; the Dispatch Width (2.00), and the theoretical maximum uOp throughput (1.50) is; an indicator of a performance bottleneck caused by the lack of hardware; resources, and the *Resource pressure view* can help to identify the problematic; resource usage. The second section of the report is the `instruction info view`. It shows the; latency and reciprocal throughput of every instruction in the sequence. It also; reports extra information related to the number of micro opcodes, and opcode; properties (i.e., 'MayLoad', 'MayStore', and 'HasSideEffects'). Field *RThroughput",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:17905,Performance,bottleneck,bottleneck,17905," by the `Block RThroughput`. Field 'uOps Per Cycle' is computed dividing the total number of simulated micro; opcodes by the total number of cycles. A delta between Dispatch Width and this; field is an indicator of a performance issue. In the absence of loop-carried; data dependencies, the observed 'uOps Per Cycle' should tend to a theoretical; maximum throughput which can be computed by dividing the number of uOps of a; single iteration by the `Block RThroughput`. Field *uOps Per Cycle* is bounded from above by the dispatch width. That is; because the dispatch width limits the maximum size of a dispatch group. Both IPC; and 'uOps Per Cycle' are limited by the amount of hardware parallelism. The; availability of hardware resources affects the resource pressure distribution,; and it limits the number of instructions that can be executed in parallel every; cycle. A delta between Dispatch Width and the theoretical maximum uOps per; Cycle (computed by dividing the number of uOps of a single iteration by the; `Block RThroughput`) is an indicator of a performance bottleneck caused by the; lack of hardware resources.; In general, the lower the Block RThroughput, the better. In this example, ``uOps per iteration/Block RThroughput`` is 1.50. Since there; are no loop-carried dependencies, the observed `uOps Per Cycle` is expected to; approach 1.50 when the number of iterations tends to infinity. The delta between; the Dispatch Width (2.00), and the theoretical maximum uOp throughput (1.50) is; an indicator of a performance bottleneck caused by the lack of hardware; resources, and the *Resource pressure view* can help to identify the problematic; resource usage. The second section of the report is the `instruction info view`. It shows the; latency and reciprocal throughput of every instruction in the sequence. It also; reports extra information related to the number of micro opcodes, and opcode; properties (i.e., 'MayLoad', 'MayStore', and 'HasSideEffects'). Field *RThroughput",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:18318,Performance,throughput,throughput,18318," *uOps Per Cycle* is bounded from above by the dispatch width. That is; because the dispatch width limits the maximum size of a dispatch group. Both IPC; and 'uOps Per Cycle' are limited by the amount of hardware parallelism. The; availability of hardware resources affects the resource pressure distribution,; and it limits the number of instructions that can be executed in parallel every; cycle. A delta between Dispatch Width and the theoretical maximum uOps per; Cycle (computed by dividing the number of uOps of a single iteration by the; `Block RThroughput`) is an indicator of a performance bottleneck caused by the; lack of hardware resources.; In general, the lower the Block RThroughput, the better. In this example, ``uOps per iteration/Block RThroughput`` is 1.50. Since there; are no loop-carried dependencies, the observed `uOps Per Cycle` is expected to; approach 1.50 when the number of iterations tends to infinity. The delta between; the Dispatch Width (2.00), and the theoretical maximum uOp throughput (1.50) is; an indicator of a performance bottleneck caused by the lack of hardware; resources, and the *Resource pressure view* can help to identify the problematic; resource usage. The second section of the report is the `instruction info view`. It shows the; latency and reciprocal throughput of every instruction in the sequence. It also; reports extra information related to the number of micro opcodes, and opcode; properties (i.e., 'MayLoad', 'MayStore', and 'HasSideEffects'). Field *RThroughput* is the reciprocal of the instruction throughput. Throughput; is computed as the maximum number of instructions of a same type that can be; executed per clock cycle in the absence of operand dependencies. In this; example, the reciprocal throughput of a vector float multiply is 1; cycles/instruction. That is because the FP multiplier JFPM is only available; from pipeline JFPU1. Instruction encodings are displayed within the instruction info view when flag; `-show-encodin",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:18358,Performance,perform,performance,18358,"um size of a dispatch group. Both IPC; and 'uOps Per Cycle' are limited by the amount of hardware parallelism. The; availability of hardware resources affects the resource pressure distribution,; and it limits the number of instructions that can be executed in parallel every; cycle. A delta between Dispatch Width and the theoretical maximum uOps per; Cycle (computed by dividing the number of uOps of a single iteration by the; `Block RThroughput`) is an indicator of a performance bottleneck caused by the; lack of hardware resources.; In general, the lower the Block RThroughput, the better. In this example, ``uOps per iteration/Block RThroughput`` is 1.50. Since there; are no loop-carried dependencies, the observed `uOps Per Cycle` is expected to; approach 1.50 when the number of iterations tends to infinity. The delta between; the Dispatch Width (2.00), and the theoretical maximum uOp throughput (1.50) is; an indicator of a performance bottleneck caused by the lack of hardware; resources, and the *Resource pressure view* can help to identify the problematic; resource usage. The second section of the report is the `instruction info view`. It shows the; latency and reciprocal throughput of every instruction in the sequence. It also; reports extra information related to the number of micro opcodes, and opcode; properties (i.e., 'MayLoad', 'MayStore', and 'HasSideEffects'). Field *RThroughput* is the reciprocal of the instruction throughput. Throughput; is computed as the maximum number of instructions of a same type that can be; executed per clock cycle in the absence of operand dependencies. In this; example, the reciprocal throughput of a vector float multiply is 1; cycles/instruction. That is because the FP multiplier JFPM is only available; from pipeline JFPU1. Instruction encodings are displayed within the instruction info view when flag; `-show-encoding` is specified. Below is an example of `-show-encoding` output for the dot-product kernel:. .. code-block:: none.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:18370,Performance,bottleneck,bottleneck,18370,"um size of a dispatch group. Both IPC; and 'uOps Per Cycle' are limited by the amount of hardware parallelism. The; availability of hardware resources affects the resource pressure distribution,; and it limits the number of instructions that can be executed in parallel every; cycle. A delta between Dispatch Width and the theoretical maximum uOps per; Cycle (computed by dividing the number of uOps of a single iteration by the; `Block RThroughput`) is an indicator of a performance bottleneck caused by the; lack of hardware resources.; In general, the lower the Block RThroughput, the better. In this example, ``uOps per iteration/Block RThroughput`` is 1.50. Since there; are no loop-carried dependencies, the observed `uOps Per Cycle` is expected to; approach 1.50 when the number of iterations tends to infinity. The delta between; the Dispatch Width (2.00), and the theoretical maximum uOp throughput (1.50) is; an indicator of a performance bottleneck caused by the lack of hardware; resources, and the *Resource pressure view* can help to identify the problematic; resource usage. The second section of the report is the `instruction info view`. It shows the; latency and reciprocal throughput of every instruction in the sequence. It also; reports extra information related to the number of micro opcodes, and opcode; properties (i.e., 'MayLoad', 'MayStore', and 'HasSideEffects'). Field *RThroughput* is the reciprocal of the instruction throughput. Throughput; is computed as the maximum number of instructions of a same type that can be; executed per clock cycle in the absence of operand dependencies. In this; example, the reciprocal throughput of a vector float multiply is 1; cycles/instruction. That is because the FP multiplier JFPM is only available; from pipeline JFPU1. Instruction encodings are displayed within the instruction info view when flag; `-show-encoding` is specified. Below is an example of `-show-encoding` output for the dot-product kernel:. .. code-block:: none.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:18590,Performance,latency,latency,18590,"nd it limits the number of instructions that can be executed in parallel every; cycle. A delta between Dispatch Width and the theoretical maximum uOps per; Cycle (computed by dividing the number of uOps of a single iteration by the; `Block RThroughput`) is an indicator of a performance bottleneck caused by the; lack of hardware resources.; In general, the lower the Block RThroughput, the better. In this example, ``uOps per iteration/Block RThroughput`` is 1.50. Since there; are no loop-carried dependencies, the observed `uOps Per Cycle` is expected to; approach 1.50 when the number of iterations tends to infinity. The delta between; the Dispatch Width (2.00), and the theoretical maximum uOp throughput (1.50) is; an indicator of a performance bottleneck caused by the lack of hardware; resources, and the *Resource pressure view* can help to identify the problematic; resource usage. The second section of the report is the `instruction info view`. It shows the; latency and reciprocal throughput of every instruction in the sequence. It also; reports extra information related to the number of micro opcodes, and opcode; properties (i.e., 'MayLoad', 'MayStore', and 'HasSideEffects'). Field *RThroughput* is the reciprocal of the instruction throughput. Throughput; is computed as the maximum number of instructions of a same type that can be; executed per clock cycle in the absence of operand dependencies. In this; example, the reciprocal throughput of a vector float multiply is 1; cycles/instruction. That is because the FP multiplier JFPM is only available; from pipeline JFPU1. Instruction encodings are displayed within the instruction info view when flag; `-show-encoding` is specified. Below is an example of `-show-encoding` output for the dot-product kernel:. .. code-block:: none. Instruction Info:; [1]: #uOps; [2]: Latency; [3]: RThroughput; [4]: MayLoad; [5]: MayStore; [6]: HasSideEffects (U); [7]: Encoding Size. [1] [2] [3] [4] [5] [6] [7] Encodings: Instructions:; 1 2 1",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:18613,Performance,throughput,throughput,18613,"nd it limits the number of instructions that can be executed in parallel every; cycle. A delta between Dispatch Width and the theoretical maximum uOps per; Cycle (computed by dividing the number of uOps of a single iteration by the; `Block RThroughput`) is an indicator of a performance bottleneck caused by the; lack of hardware resources.; In general, the lower the Block RThroughput, the better. In this example, ``uOps per iteration/Block RThroughput`` is 1.50. Since there; are no loop-carried dependencies, the observed `uOps Per Cycle` is expected to; approach 1.50 when the number of iterations tends to infinity. The delta between; the Dispatch Width (2.00), and the theoretical maximum uOp throughput (1.50) is; an indicator of a performance bottleneck caused by the lack of hardware; resources, and the *Resource pressure view* can help to identify the problematic; resource usage. The second section of the report is the `instruction info view`. It shows the; latency and reciprocal throughput of every instruction in the sequence. It also; reports extra information related to the number of micro opcodes, and opcode; properties (i.e., 'MayLoad', 'MayStore', and 'HasSideEffects'). Field *RThroughput* is the reciprocal of the instruction throughput. Throughput; is computed as the maximum number of instructions of a same type that can be; executed per clock cycle in the absence of operand dependencies. In this; example, the reciprocal throughput of a vector float multiply is 1; cycles/instruction. That is because the FP multiplier JFPM is only available; from pipeline JFPU1. Instruction encodings are displayed within the instruction info view when flag; `-show-encoding` is specified. Below is an example of `-show-encoding` output for the dot-product kernel:. .. code-block:: none. Instruction Info:; [1]: #uOps; [2]: Latency; [3]: RThroughput; [4]: MayLoad; [5]: MayStore; [6]: HasSideEffects (U); [7]: Encoding Size. [1] [2] [3] [4] [5] [6] [7] Encodings: Instructions:; 1 2 1",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:18870,Performance,throughput,throughput,18870,"the; `Block RThroughput`) is an indicator of a performance bottleneck caused by the; lack of hardware resources.; In general, the lower the Block RThroughput, the better. In this example, ``uOps per iteration/Block RThroughput`` is 1.50. Since there; are no loop-carried dependencies, the observed `uOps Per Cycle` is expected to; approach 1.50 when the number of iterations tends to infinity. The delta between; the Dispatch Width (2.00), and the theoretical maximum uOp throughput (1.50) is; an indicator of a performance bottleneck caused by the lack of hardware; resources, and the *Resource pressure view* can help to identify the problematic; resource usage. The second section of the report is the `instruction info view`. It shows the; latency and reciprocal throughput of every instruction in the sequence. It also; reports extra information related to the number of micro opcodes, and opcode; properties (i.e., 'MayLoad', 'MayStore', and 'HasSideEffects'). Field *RThroughput* is the reciprocal of the instruction throughput. Throughput; is computed as the maximum number of instructions of a same type that can be; executed per clock cycle in the absence of operand dependencies. In this; example, the reciprocal throughput of a vector float multiply is 1; cycles/instruction. That is because the FP multiplier JFPM is only available; from pipeline JFPU1. Instruction encodings are displayed within the instruction info view when flag; `-show-encoding` is specified. Below is an example of `-show-encoding` output for the dot-product kernel:. .. code-block:: none. Instruction Info:; [1]: #uOps; [2]: Latency; [3]: RThroughput; [4]: MayLoad; [5]: MayStore; [6]: HasSideEffects (U); [7]: Encoding Size. [1] [2] [3] [4] [5] [6] [7] Encodings: Instructions:; 1 2 1.00 4 c5 f0 59 d0 vmulps	%xmm0, %xmm1, %xmm2; 1 4 1.00 4 c5 eb 7c da vhaddps	%xmm2, %xmm2, %xmm3; 1 4 1.00 4 c5 e3 7c e3 vhaddps	%xmm3, %xmm3, %xmm4. The `Encoding Size` column shows the size in bytes of instructions. The; `Encod",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:19070,Performance,throughput,throughput,19070,"Since there; are no loop-carried dependencies, the observed `uOps Per Cycle` is expected to; approach 1.50 when the number of iterations tends to infinity. The delta between; the Dispatch Width (2.00), and the theoretical maximum uOp throughput (1.50) is; an indicator of a performance bottleneck caused by the lack of hardware; resources, and the *Resource pressure view* can help to identify the problematic; resource usage. The second section of the report is the `instruction info view`. It shows the; latency and reciprocal throughput of every instruction in the sequence. It also; reports extra information related to the number of micro opcodes, and opcode; properties (i.e., 'MayLoad', 'MayStore', and 'HasSideEffects'). Field *RThroughput* is the reciprocal of the instruction throughput. Throughput; is computed as the maximum number of instructions of a same type that can be; executed per clock cycle in the absence of operand dependencies. In this; example, the reciprocal throughput of a vector float multiply is 1; cycles/instruction. That is because the FP multiplier JFPM is only available; from pipeline JFPU1. Instruction encodings are displayed within the instruction info view when flag; `-show-encoding` is specified. Below is an example of `-show-encoding` output for the dot-product kernel:. .. code-block:: none. Instruction Info:; [1]: #uOps; [2]: Latency; [3]: RThroughput; [4]: MayLoad; [5]: MayStore; [6]: HasSideEffects (U); [7]: Encoding Size. [1] [2] [3] [4] [5] [6] [7] Encodings: Instructions:; 1 2 1.00 4 c5 f0 59 d0 vmulps	%xmm0, %xmm1, %xmm2; 1 4 1.00 4 c5 eb 7c da vhaddps	%xmm2, %xmm2, %xmm3; 1 4 1.00 4 c5 e3 7c e3 vhaddps	%xmm3, %xmm3, %xmm4. The `Encoding Size` column shows the size in bytes of instructions. The; `Encodings` column shows the actual instruction encodings (byte sequences in; hex). The third section is the *Resource pressure view*. This view reports; the average number of resource cycles consumed every iteration by instructions; for every ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:20773,Performance,bottleneck,bottlenecks,20773,"g Size` column shows the size in bytes of instructions. The; `Encodings` column shows the actual instruction encodings (byte sequences in; hex). The third section is the *Resource pressure view*. This view reports; the average number of resource cycles consumed every iteration by instructions; for every processor resource unit available on the target. Information is; structured in two tables. The first table reports the number of resource cycles; spent on average every iteration. The second table correlates the resource; cycles to the machine instruction in the sequence. For example, every iteration; of the instruction vmulps always executes on resource unit [6]; (JFPU1 - floating point pipeline #1), consuming an average of 1 resource cycle; per iteration. Note that on AMD Jaguar, vector floating-point multiply can; only be issued to pipeline JFPU1, while horizontal floating-point additions can; only be issued to pipeline JFPU0. The resource pressure view helps with identifying bottlenecks caused by high; usage of specific hardware resources. Situations with resource pressure mainly; concentrated on a few resources should, in general, be avoided. Ideally,; pressure should be uniformly distributed between multiple resources. Timeline View; ^^^^^^^^^^^^^; The timeline view produces a detailed report of each instruction's state; transitions through an instruction pipeline. This view is enabled by the; command line option ``-timeline``. As instructions transition through the; various stages of the pipeline, their states are depicted in the view report.; These states are represented by the following characters:. * D : Instruction dispatched.; * e : Instruction executing.; * E : Instruction executed.; * R : Instruction retired.; * = : Instruction already dispatched, waiting to be executed.; * \- : Instruction executed, waiting to be retired. Below is the timeline view for a subset of the dot-product example located in; ``test/tools/llvm-mca/X86/BtVer2/dot-product.s`` and ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:22580,Performance,queue,queue,22580,"executed.; * \- : Instruction executed, waiting to be retired. Below is the timeline view for a subset of the dot-product example located in; ``test/tools/llvm-mca/X86/BtVer2/dot-product.s`` and processed by; :program:`llvm-mca` using the following command:. .. code-block:: bash. $ llvm-mca -mtriple=x86_64-unknown-unknown -mcpu=btver2 -iterations=3 -timeline dot-product.s. .. code-block:: none. Timeline view:; 012345; Index 0123456789. [0,0] DeeER. . . vmulps	%xmm0, %xmm1, %xmm2; [0,1] D==eeeER . . vhaddps	%xmm2, %xmm2, %xmm3; [0,2] .D====eeeER . vhaddps	%xmm3, %xmm3, %xmm4; [1,0] .DeeE-----R . vmulps	%xmm0, %xmm1, %xmm2; [1,1] . D=eeeE---R . vhaddps	%xmm2, %xmm2, %xmm3; [1,2] . D====eeeER . vhaddps	%xmm3, %xmm3, %xmm4; [2,0] . DeeE-----R . vmulps	%xmm0, %xmm1, %xmm2; [2,1] . D====eeeER . vhaddps	%xmm2, %xmm2, %xmm3; [2,2] . D======eeeER vhaddps	%xmm3, %xmm3, %xmm4. Average Wait times (based on the timeline view):; [0]: Executions; [1]: Average time spent waiting in a scheduler's queue; [2]: Average time spent waiting in a scheduler's queue while ready; [3]: Average time elapsed from WB until retire stage. [0] [1] [2] [3]; 0. 3 1.0 1.0 3.3 vmulps	%xmm0, %xmm1, %xmm2; 1. 3 3.3 0.7 1.0 vhaddps	%xmm2, %xmm2, %xmm3; 2. 3 5.7 0.0 0.0 vhaddps	%xmm3, %xmm3, %xmm4; 3 3.3 0.5 1.4 <total>. The timeline view is interesting because it shows instruction state changes; during execution. It also gives an idea of how the tool processes instructions; executed on the target, and how their timing information might be calculated. The timeline view is structured in two tables. The first table shows; instructions changing state over time (measured in cycles); the second table; (named *Average Wait times*) reports useful timing statistics, which should; help diagnose performance bottlenecks caused by long data dependencies and; sub-optimal usage of hardware resources. An instruction in the timeline view is identified by a pair of indices, where; the first index identifies an iteration, and",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:22636,Performance,queue,queue,22636,"executed.; * \- : Instruction executed, waiting to be retired. Below is the timeline view for a subset of the dot-product example located in; ``test/tools/llvm-mca/X86/BtVer2/dot-product.s`` and processed by; :program:`llvm-mca` using the following command:. .. code-block:: bash. $ llvm-mca -mtriple=x86_64-unknown-unknown -mcpu=btver2 -iterations=3 -timeline dot-product.s. .. code-block:: none. Timeline view:; 012345; Index 0123456789. [0,0] DeeER. . . vmulps	%xmm0, %xmm1, %xmm2; [0,1] D==eeeER . . vhaddps	%xmm2, %xmm2, %xmm3; [0,2] .D====eeeER . vhaddps	%xmm3, %xmm3, %xmm4; [1,0] .DeeE-----R . vmulps	%xmm0, %xmm1, %xmm2; [1,1] . D=eeeE---R . vhaddps	%xmm2, %xmm2, %xmm3; [1,2] . D====eeeER . vhaddps	%xmm3, %xmm3, %xmm4; [2,0] . DeeE-----R . vmulps	%xmm0, %xmm1, %xmm2; [2,1] . D====eeeER . vhaddps	%xmm2, %xmm2, %xmm3; [2,2] . D======eeeER vhaddps	%xmm3, %xmm3, %xmm4. Average Wait times (based on the timeline view):; [0]: Executions; [1]: Average time spent waiting in a scheduler's queue; [2]: Average time spent waiting in a scheduler's queue while ready; [3]: Average time elapsed from WB until retire stage. [0] [1] [2] [3]; 0. 3 1.0 1.0 3.3 vmulps	%xmm0, %xmm1, %xmm2; 1. 3 3.3 0.7 1.0 vhaddps	%xmm2, %xmm2, %xmm3; 2. 3 5.7 0.0 0.0 vhaddps	%xmm3, %xmm3, %xmm4; 3 3.3 0.5 1.4 <total>. The timeline view is interesting because it shows instruction state changes; during execution. It also gives an idea of how the tool processes instructions; executed on the target, and how their timing information might be calculated. The timeline view is structured in two tables. The first table shows; instructions changing state over time (measured in cycles); the second table; (named *Average Wait times*) reports useful timing statistics, which should; help diagnose performance bottlenecks caused by long data dependencies and; sub-optimal usage of hardware resources. An instruction in the timeline view is identified by a pair of indices, where; the first index identifies an iteration, and",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:23360,Performance,perform,performance,23360," [2,0] . DeeE-----R . vmulps	%xmm0, %xmm1, %xmm2; [2,1] . D====eeeER . vhaddps	%xmm2, %xmm2, %xmm3; [2,2] . D======eeeER vhaddps	%xmm3, %xmm3, %xmm4. Average Wait times (based on the timeline view):; [0]: Executions; [1]: Average time spent waiting in a scheduler's queue; [2]: Average time spent waiting in a scheduler's queue while ready; [3]: Average time elapsed from WB until retire stage. [0] [1] [2] [3]; 0. 3 1.0 1.0 3.3 vmulps	%xmm0, %xmm1, %xmm2; 1. 3 3.3 0.7 1.0 vhaddps	%xmm2, %xmm2, %xmm3; 2. 3 5.7 0.0 0.0 vhaddps	%xmm3, %xmm3, %xmm4; 3 3.3 0.5 1.4 <total>. The timeline view is interesting because it shows instruction state changes; during execution. It also gives an idea of how the tool processes instructions; executed on the target, and how their timing information might be calculated. The timeline view is structured in two tables. The first table shows; instructions changing state over time (measured in cycles); the second table; (named *Average Wait times*) reports useful timing statistics, which should; help diagnose performance bottlenecks caused by long data dependencies and; sub-optimal usage of hardware resources. An instruction in the timeline view is identified by a pair of indices, where; the first index identifies an iteration, and the second index is the; instruction index (i.e., where it appears in the code sequence). Since this; example was generated using 3 iterations: ``-iterations=3``, the iteration; indices range from 0-2 inclusively. Excluding the first and last column, the remaining columns are in cycles.; Cycles are numbered sequentially starting from 0. From the example output above, we know the following:. * Instruction [1,0] was dispatched at cycle 1.; * Instruction [1,0] started executing at cycle 2.; * Instruction [1,0] reached the write back stage at cycle 4.; * Instruction [1,0] was retired at cycle 10. Instruction [1,0] (i.e., vmulps from iteration #1) does not have to wait in the; scheduler's queue for the operands to become av",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:23372,Performance,bottleneck,bottlenecks,23372," [2,0] . DeeE-----R . vmulps	%xmm0, %xmm1, %xmm2; [2,1] . D====eeeER . vhaddps	%xmm2, %xmm2, %xmm3; [2,2] . D======eeeER vhaddps	%xmm3, %xmm3, %xmm4. Average Wait times (based on the timeline view):; [0]: Executions; [1]: Average time spent waiting in a scheduler's queue; [2]: Average time spent waiting in a scheduler's queue while ready; [3]: Average time elapsed from WB until retire stage. [0] [1] [2] [3]; 0. 3 1.0 1.0 3.3 vmulps	%xmm0, %xmm1, %xmm2; 1. 3 3.3 0.7 1.0 vhaddps	%xmm2, %xmm2, %xmm3; 2. 3 5.7 0.0 0.0 vhaddps	%xmm3, %xmm3, %xmm4; 3 3.3 0.5 1.4 <total>. The timeline view is interesting because it shows instruction state changes; during execution. It also gives an idea of how the tool processes instructions; executed on the target, and how their timing information might be calculated. The timeline view is structured in two tables. The first table shows; instructions changing state over time (measured in cycles); the second table; (named *Average Wait times*) reports useful timing statistics, which should; help diagnose performance bottlenecks caused by long data dependencies and; sub-optimal usage of hardware resources. An instruction in the timeline view is identified by a pair of indices, where; the first index identifies an iteration, and the second index is the; instruction index (i.e., where it appears in the code sequence). Since this; example was generated using 3 iterations: ``-iterations=3``, the iteration; indices range from 0-2 inclusively. Excluding the first and last column, the remaining columns are in cycles.; Cycles are numbered sequentially starting from 0. From the example output above, we know the following:. * Instruction [1,0] was dispatched at cycle 1.; * Instruction [1,0] started executing at cycle 2.; * Instruction [1,0] reached the write back stage at cycle 4.; * Instruction [1,0] was retired at cycle 10. Instruction [1,0] (i.e., vmulps from iteration #1) does not have to wait in the; scheduler's queue for the operands to become av",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:24280,Performance,queue,queue,24280,"e; (named *Average Wait times*) reports useful timing statistics, which should; help diagnose performance bottlenecks caused by long data dependencies and; sub-optimal usage of hardware resources. An instruction in the timeline view is identified by a pair of indices, where; the first index identifies an iteration, and the second index is the; instruction index (i.e., where it appears in the code sequence). Since this; example was generated using 3 iterations: ``-iterations=3``, the iteration; indices range from 0-2 inclusively. Excluding the first and last column, the remaining columns are in cycles.; Cycles are numbered sequentially starting from 0. From the example output above, we know the following:. * Instruction [1,0] was dispatched at cycle 1.; * Instruction [1,0] started executing at cycle 2.; * Instruction [1,0] reached the write back stage at cycle 4.; * Instruction [1,0] was retired at cycle 10. Instruction [1,0] (i.e., vmulps from iteration #1) does not have to wait in the; scheduler's queue for the operands to become available. By the time vmulps is; dispatched, operands are already available, and pipeline JFPU1 is ready to; serve another instruction. So the instruction can be immediately issued on the; JFPU1 pipeline. That is demonstrated by the fact that the instruction only; spent 1cy in the scheduler's queue. There is a gap of 5 cycles between the write-back stage and the retire event.; That is because instructions must retire in program order, so [1,0] has to wait; for [0,2] to be retired first (i.e., it has to wait until cycle 10). In the example, all instructions are in a RAW (Read After Write) dependency; chain. Register %xmm2 written by vmulps is immediately used by the first; vhaddps, and register %xmm3 written by the first vhaddps is used by the second; vhaddps. Long data dependencies negatively impact the ILP (Instruction Level; Parallelism). In the dot-product example, there are anti-dependencies introduced by; instructions from different i",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:24608,Performance,queue,queue,24608,"es an iteration, and the second index is the; instruction index (i.e., where it appears in the code sequence). Since this; example was generated using 3 iterations: ``-iterations=3``, the iteration; indices range from 0-2 inclusively. Excluding the first and last column, the remaining columns are in cycles.; Cycles are numbered sequentially starting from 0. From the example output above, we know the following:. * Instruction [1,0] was dispatched at cycle 1.; * Instruction [1,0] started executing at cycle 2.; * Instruction [1,0] reached the write back stage at cycle 4.; * Instruction [1,0] was retired at cycle 10. Instruction [1,0] (i.e., vmulps from iteration #1) does not have to wait in the; scheduler's queue for the operands to become available. By the time vmulps is; dispatched, operands are already available, and pipeline JFPU1 is ready to; serve another instruction. So the instruction can be immediately issued on the; JFPU1 pipeline. That is demonstrated by the fact that the instruction only; spent 1cy in the scheduler's queue. There is a gap of 5 cycles between the write-back stage and the retire event.; That is because instructions must retire in program order, so [1,0] has to wait; for [0,2] to be retired first (i.e., it has to wait until cycle 10). In the example, all instructions are in a RAW (Read After Write) dependency; chain. Register %xmm2 written by vmulps is immediately used by the first; vhaddps, and register %xmm3 written by the first vhaddps is used by the second; vhaddps. Long data dependencies negatively impact the ILP (Instruction Level; Parallelism). In the dot-product example, there are anti-dependencies introduced by; instructions from different iterations. However, those dependencies can be; removed at register renaming stage (at the cost of allocating register aliases,; and therefore consuming physical registers). Table *Average Wait times* helps diagnose performance issues that are caused by; the presence of long latency instructions and",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:25482,Performance,perform,performance,25482,"trated by the fact that the instruction only; spent 1cy in the scheduler's queue. There is a gap of 5 cycles between the write-back stage and the retire event.; That is because instructions must retire in program order, so [1,0] has to wait; for [0,2] to be retired first (i.e., it has to wait until cycle 10). In the example, all instructions are in a RAW (Read After Write) dependency; chain. Register %xmm2 written by vmulps is immediately used by the first; vhaddps, and register %xmm3 written by the first vhaddps is used by the second; vhaddps. Long data dependencies negatively impact the ILP (Instruction Level; Parallelism). In the dot-product example, there are anti-dependencies introduced by; instructions from different iterations. However, those dependencies can be; removed at register renaming stage (at the cost of allocating register aliases,; and therefore consuming physical registers). Table *Average Wait times* helps diagnose performance issues that are caused by; the presence of long latency instructions and potentially long data dependencies; which may limit the ILP. Last row, ``<total>``, shows a global average over all; instructions measured. Note that :program:`llvm-mca`, by default, assumes at; least 1cy between the dispatch event and the issue event. When the performance is limited by data dependencies and/or long latency; instructions, the number of cycles spent while in the *ready* state is expected; to be very small when compared with the total number of cycles spent in the; scheduler's queue. The difference between the two counters is a good indicator; of how large of an impact data dependencies had on the execution of the; instructions. When performance is mostly limited by the lack of hardware; resources, the delta between the two counters is small. However, the number of; cycles spent in the queue tends to be larger (i.e., more than 1-3cy),; especially when compared to other low latency instructions. Bottleneck Analysis; ^^^^^^^^^^^^^^^^^^^; T",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:25542,Performance,latency,latency,25542,"trated by the fact that the instruction only; spent 1cy in the scheduler's queue. There is a gap of 5 cycles between the write-back stage and the retire event.; That is because instructions must retire in program order, so [1,0] has to wait; for [0,2] to be retired first (i.e., it has to wait until cycle 10). In the example, all instructions are in a RAW (Read After Write) dependency; chain. Register %xmm2 written by vmulps is immediately used by the first; vhaddps, and register %xmm3 written by the first vhaddps is used by the second; vhaddps. Long data dependencies negatively impact the ILP (Instruction Level; Parallelism). In the dot-product example, there are anti-dependencies introduced by; instructions from different iterations. However, those dependencies can be; removed at register renaming stage (at the cost of allocating register aliases,; and therefore consuming physical registers). Table *Average Wait times* helps diagnose performance issues that are caused by; the presence of long latency instructions and potentially long data dependencies; which may limit the ILP. Last row, ``<total>``, shows a global average over all; instructions measured. Note that :program:`llvm-mca`, by default, assumes at; least 1cy between the dispatch event and the issue event. When the performance is limited by data dependencies and/or long latency; instructions, the number of cycles spent while in the *ready* state is expected; to be very small when compared with the total number of cycles spent in the; scheduler's queue. The difference between the two counters is a good indicator; of how large of an impact data dependencies had on the execution of the; instructions. When performance is mostly limited by the lack of hardware; resources, the delta between the two counters is small. However, the number of; cycles spent in the queue tends to be larger (i.e., more than 1-3cy),; especially when compared to other low latency instructions. Bottleneck Analysis; ^^^^^^^^^^^^^^^^^^^; T",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:25829,Performance,perform,performance,25829,"ritten by vmulps is immediately used by the first; vhaddps, and register %xmm3 written by the first vhaddps is used by the second; vhaddps. Long data dependencies negatively impact the ILP (Instruction Level; Parallelism). In the dot-product example, there are anti-dependencies introduced by; instructions from different iterations. However, those dependencies can be; removed at register renaming stage (at the cost of allocating register aliases,; and therefore consuming physical registers). Table *Average Wait times* helps diagnose performance issues that are caused by; the presence of long latency instructions and potentially long data dependencies; which may limit the ILP. Last row, ``<total>``, shows a global average over all; instructions measured. Note that :program:`llvm-mca`, by default, assumes at; least 1cy between the dispatch event and the issue event. When the performance is limited by data dependencies and/or long latency; instructions, the number of cycles spent while in the *ready* state is expected; to be very small when compared with the total number of cycles spent in the; scheduler's queue. The difference between the two counters is a good indicator; of how large of an impact data dependencies had on the execution of the; instructions. When performance is mostly limited by the lack of hardware; resources, the delta between the two counters is small. However, the number of; cycles spent in the queue tends to be larger (i.e., more than 1-3cy),; especially when compared to other low latency instructions. Bottleneck Analysis; ^^^^^^^^^^^^^^^^^^^; The ``-bottleneck-analysis`` command line option enables the analysis of; performance bottlenecks. This analysis is potentially expensive. It attempts to correlate increases in; backend pressure (caused by pipeline resource pressure and data dependencies) to; dynamic dispatch stalls. Below is an example of ``-bottleneck-analysis`` output generated by; :program:`llvm-mca` for 500 iterations of the dot-product e",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:25885,Performance,latency,latency,25885,"ritten by vmulps is immediately used by the first; vhaddps, and register %xmm3 written by the first vhaddps is used by the second; vhaddps. Long data dependencies negatively impact the ILP (Instruction Level; Parallelism). In the dot-product example, there are anti-dependencies introduced by; instructions from different iterations. However, those dependencies can be; removed at register renaming stage (at the cost of allocating register aliases,; and therefore consuming physical registers). Table *Average Wait times* helps diagnose performance issues that are caused by; the presence of long latency instructions and potentially long data dependencies; which may limit the ILP. Last row, ``<total>``, shows a global average over all; instructions measured. Note that :program:`llvm-mca`, by default, assumes at; least 1cy between the dispatch event and the issue event. When the performance is limited by data dependencies and/or long latency; instructions, the number of cycles spent while in the *ready* state is expected; to be very small when compared with the total number of cycles spent in the; scheduler's queue. The difference between the two counters is a good indicator; of how large of an impact data dependencies had on the execution of the; instructions. When performance is mostly limited by the lack of hardware; resources, the delta between the two counters is small. However, the number of; cycles spent in the queue tends to be larger (i.e., more than 1-3cy),; especially when compared to other low latency instructions. Bottleneck Analysis; ^^^^^^^^^^^^^^^^^^^; The ``-bottleneck-analysis`` command line option enables the analysis of; performance bottlenecks. This analysis is potentially expensive. It attempts to correlate increases in; backend pressure (caused by pipeline resource pressure and data dependencies) to; dynamic dispatch stalls. Below is an example of ``-bottleneck-analysis`` output generated by; :program:`llvm-mca` for 500 iterations of the dot-product e",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:26064,Performance,queue,queue,26064,"ritten by vmulps is immediately used by the first; vhaddps, and register %xmm3 written by the first vhaddps is used by the second; vhaddps. Long data dependencies negatively impact the ILP (Instruction Level; Parallelism). In the dot-product example, there are anti-dependencies introduced by; instructions from different iterations. However, those dependencies can be; removed at register renaming stage (at the cost of allocating register aliases,; and therefore consuming physical registers). Table *Average Wait times* helps diagnose performance issues that are caused by; the presence of long latency instructions and potentially long data dependencies; which may limit the ILP. Last row, ``<total>``, shows a global average over all; instructions measured. Note that :program:`llvm-mca`, by default, assumes at; least 1cy between the dispatch event and the issue event. When the performance is limited by data dependencies and/or long latency; instructions, the number of cycles spent while in the *ready* state is expected; to be very small when compared with the total number of cycles spent in the; scheduler's queue. The difference between the two counters is a good indicator; of how large of an impact data dependencies had on the execution of the; instructions. When performance is mostly limited by the lack of hardware; resources, the delta between the two counters is small. However, the number of; cycles spent in the queue tends to be larger (i.e., more than 1-3cy),; especially when compared to other low latency instructions. Bottleneck Analysis; ^^^^^^^^^^^^^^^^^^^; The ``-bottleneck-analysis`` command line option enables the analysis of; performance bottlenecks. This analysis is potentially expensive. It attempts to correlate increases in; backend pressure (caused by pipeline resource pressure and data dependencies) to; dynamic dispatch stalls. Below is an example of ``-bottleneck-analysis`` output generated by; :program:`llvm-mca` for 500 iterations of the dot-product e",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:26224,Performance,perform,performance,26224,". However, those dependencies can be; removed at register renaming stage (at the cost of allocating register aliases,; and therefore consuming physical registers). Table *Average Wait times* helps diagnose performance issues that are caused by; the presence of long latency instructions and potentially long data dependencies; which may limit the ILP. Last row, ``<total>``, shows a global average over all; instructions measured. Note that :program:`llvm-mca`, by default, assumes at; least 1cy between the dispatch event and the issue event. When the performance is limited by data dependencies and/or long latency; instructions, the number of cycles spent while in the *ready* state is expected; to be very small when compared with the total number of cycles spent in the; scheduler's queue. The difference between the two counters is a good indicator; of how large of an impact data dependencies had on the execution of the; instructions. When performance is mostly limited by the lack of hardware; resources, the delta between the two counters is small. However, the number of; cycles spent in the queue tends to be larger (i.e., more than 1-3cy),; especially when compared to other low latency instructions. Bottleneck Analysis; ^^^^^^^^^^^^^^^^^^^; The ``-bottleneck-analysis`` command line option enables the analysis of; performance bottlenecks. This analysis is potentially expensive. It attempts to correlate increases in; backend pressure (caused by pipeline resource pressure and data dependencies) to; dynamic dispatch stalls. Below is an example of ``-bottleneck-analysis`` output generated by; :program:`llvm-mca` for 500 iterations of the dot-product example on btver2. .. code-block:: none. Cycles with backend pressure increase [ 48.07% ]; Throughput Bottlenecks:; Resource Pressure [ 47.77% ]; - JFPA [ 47.77% ]; - JFPU0 [ 47.77% ]; Data Dependencies: [ 0.30% ]; - Register Dependencies [ 0.30% ]; - Memory Dependencies [ 0.00% ]. Critical sequence based on the simulation:. Instr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:26379,Performance,queue,queue,26379,"ating register aliases,; and therefore consuming physical registers). Table *Average Wait times* helps diagnose performance issues that are caused by; the presence of long latency instructions and potentially long data dependencies; which may limit the ILP. Last row, ``<total>``, shows a global average over all; instructions measured. Note that :program:`llvm-mca`, by default, assumes at; least 1cy between the dispatch event and the issue event. When the performance is limited by data dependencies and/or long latency; instructions, the number of cycles spent while in the *ready* state is expected; to be very small when compared with the total number of cycles spent in the; scheduler's queue. The difference between the two counters is a good indicator; of how large of an impact data dependencies had on the execution of the; instructions. When performance is mostly limited by the lack of hardware; resources, the delta between the two counters is small. However, the number of; cycles spent in the queue tends to be larger (i.e., more than 1-3cy),; especially when compared to other low latency instructions. Bottleneck Analysis; ^^^^^^^^^^^^^^^^^^^; The ``-bottleneck-analysis`` command line option enables the analysis of; performance bottlenecks. This analysis is potentially expensive. It attempts to correlate increases in; backend pressure (caused by pipeline resource pressure and data dependencies) to; dynamic dispatch stalls. Below is an example of ``-bottleneck-analysis`` output generated by; :program:`llvm-mca` for 500 iterations of the dot-product example on btver2. .. code-block:: none. Cycles with backend pressure increase [ 48.07% ]; Throughput Bottlenecks:; Resource Pressure [ 47.77% ]; - JFPA [ 47.77% ]; - JFPU0 [ 47.77% ]; Data Dependencies: [ 0.30% ]; - Register Dependencies [ 0.30% ]; - Memory Dependencies [ 0.00% ]. Critical sequence based on the simulation:. Instruction Dependency Information; +----< 2. vhaddps %xmm3, %xmm3, %xmm4; |; | < loop carried >; |;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:26468,Performance,latency,latency,26468,"erage Wait times* helps diagnose performance issues that are caused by; the presence of long latency instructions and potentially long data dependencies; which may limit the ILP. Last row, ``<total>``, shows a global average over all; instructions measured. Note that :program:`llvm-mca`, by default, assumes at; least 1cy between the dispatch event and the issue event. When the performance is limited by data dependencies and/or long latency; instructions, the number of cycles spent while in the *ready* state is expected; to be very small when compared with the total number of cycles spent in the; scheduler's queue. The difference between the two counters is a good indicator; of how large of an impact data dependencies had on the execution of the; instructions. When performance is mostly limited by the lack of hardware; resources, the delta between the two counters is small. However, the number of; cycles spent in the queue tends to be larger (i.e., more than 1-3cy),; especially when compared to other low latency instructions. Bottleneck Analysis; ^^^^^^^^^^^^^^^^^^^; The ``-bottleneck-analysis`` command line option enables the analysis of; performance bottlenecks. This analysis is potentially expensive. It attempts to correlate increases in; backend pressure (caused by pipeline resource pressure and data dependencies) to; dynamic dispatch stalls. Below is an example of ``-bottleneck-analysis`` output generated by; :program:`llvm-mca` for 500 iterations of the dot-product example on btver2. .. code-block:: none. Cycles with backend pressure increase [ 48.07% ]; Throughput Bottlenecks:; Resource Pressure [ 47.77% ]; - JFPA [ 47.77% ]; - JFPU0 [ 47.77% ]; Data Dependencies: [ 0.30% ]; - Register Dependencies [ 0.30% ]; - Memory Dependencies [ 0.00% ]. Critical sequence based on the simulation:. Instruction Dependency Information; +----< 2. vhaddps %xmm3, %xmm3, %xmm4; |; | < loop carried >; |; | 0. vmulps %xmm0, %xmm1, %xmm2; +----> 1. vhaddps %xmm2, %xmm2, %xmm3 ## RES",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:26539,Performance,bottleneck,bottleneck-analysis,26539,"ons and potentially long data dependencies; which may limit the ILP. Last row, ``<total>``, shows a global average over all; instructions measured. Note that :program:`llvm-mca`, by default, assumes at; least 1cy between the dispatch event and the issue event. When the performance is limited by data dependencies and/or long latency; instructions, the number of cycles spent while in the *ready* state is expected; to be very small when compared with the total number of cycles spent in the; scheduler's queue. The difference between the two counters is a good indicator; of how large of an impact data dependencies had on the execution of the; instructions. When performance is mostly limited by the lack of hardware; resources, the delta between the two counters is small. However, the number of; cycles spent in the queue tends to be larger (i.e., more than 1-3cy),; especially when compared to other low latency instructions. Bottleneck Analysis; ^^^^^^^^^^^^^^^^^^^; The ``-bottleneck-analysis`` command line option enables the analysis of; performance bottlenecks. This analysis is potentially expensive. It attempts to correlate increases in; backend pressure (caused by pipeline resource pressure and data dependencies) to; dynamic dispatch stalls. Below is an example of ``-bottleneck-analysis`` output generated by; :program:`llvm-mca` for 500 iterations of the dot-product example on btver2. .. code-block:: none. Cycles with backend pressure increase [ 48.07% ]; Throughput Bottlenecks:; Resource Pressure [ 47.77% ]; - JFPA [ 47.77% ]; - JFPU0 [ 47.77% ]; Data Dependencies: [ 0.30% ]; - Register Dependencies [ 0.30% ]; - Memory Dependencies [ 0.00% ]. Critical sequence based on the simulation:. Instruction Dependency Information; +----< 2. vhaddps %xmm3, %xmm3, %xmm4; |; | < loop carried >; |; | 0. vmulps %xmm0, %xmm1, %xmm2; +----> 1. vhaddps %xmm2, %xmm2, %xmm3 ## RESOURCE interference: JFPA [ probability: 74% ]; +----> 2. vhaddps %xmm3, %xmm3, %xmm4 ## REGISTER dependency: %x",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:26606,Performance,perform,performance,26606,"ons and potentially long data dependencies; which may limit the ILP. Last row, ``<total>``, shows a global average over all; instructions measured. Note that :program:`llvm-mca`, by default, assumes at; least 1cy between the dispatch event and the issue event. When the performance is limited by data dependencies and/or long latency; instructions, the number of cycles spent while in the *ready* state is expected; to be very small when compared with the total number of cycles spent in the; scheduler's queue. The difference between the two counters is a good indicator; of how large of an impact data dependencies had on the execution of the; instructions. When performance is mostly limited by the lack of hardware; resources, the delta between the two counters is small. However, the number of; cycles spent in the queue tends to be larger (i.e., more than 1-3cy),; especially when compared to other low latency instructions. Bottleneck Analysis; ^^^^^^^^^^^^^^^^^^^; The ``-bottleneck-analysis`` command line option enables the analysis of; performance bottlenecks. This analysis is potentially expensive. It attempts to correlate increases in; backend pressure (caused by pipeline resource pressure and data dependencies) to; dynamic dispatch stalls. Below is an example of ``-bottleneck-analysis`` output generated by; :program:`llvm-mca` for 500 iterations of the dot-product example on btver2. .. code-block:: none. Cycles with backend pressure increase [ 48.07% ]; Throughput Bottlenecks:; Resource Pressure [ 47.77% ]; - JFPA [ 47.77% ]; - JFPU0 [ 47.77% ]; Data Dependencies: [ 0.30% ]; - Register Dependencies [ 0.30% ]; - Memory Dependencies [ 0.00% ]. Critical sequence based on the simulation:. Instruction Dependency Information; +----< 2. vhaddps %xmm3, %xmm3, %xmm4; |; | < loop carried >; |; | 0. vmulps %xmm0, %xmm1, %xmm2; +----> 1. vhaddps %xmm2, %xmm2, %xmm3 ## RESOURCE interference: JFPA [ probability: 74% ]; +----> 2. vhaddps %xmm3, %xmm3, %xmm4 ## REGISTER dependency: %x",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:26618,Performance,bottleneck,bottlenecks,26618,"ons and potentially long data dependencies; which may limit the ILP. Last row, ``<total>``, shows a global average over all; instructions measured. Note that :program:`llvm-mca`, by default, assumes at; least 1cy between the dispatch event and the issue event. When the performance is limited by data dependencies and/or long latency; instructions, the number of cycles spent while in the *ready* state is expected; to be very small when compared with the total number of cycles spent in the; scheduler's queue. The difference between the two counters is a good indicator; of how large of an impact data dependencies had on the execution of the; instructions. When performance is mostly limited by the lack of hardware; resources, the delta between the two counters is small. However, the number of; cycles spent in the queue tends to be larger (i.e., more than 1-3cy),; especially when compared to other low latency instructions. Bottleneck Analysis; ^^^^^^^^^^^^^^^^^^^; The ``-bottleneck-analysis`` command line option enables the analysis of; performance bottlenecks. This analysis is potentially expensive. It attempts to correlate increases in; backend pressure (caused by pipeline resource pressure and data dependencies) to; dynamic dispatch stalls. Below is an example of ``-bottleneck-analysis`` output generated by; :program:`llvm-mca` for 500 iterations of the dot-product example on btver2. .. code-block:: none. Cycles with backend pressure increase [ 48.07% ]; Throughput Bottlenecks:; Resource Pressure [ 47.77% ]; - JFPA [ 47.77% ]; - JFPU0 [ 47.77% ]; Data Dependencies: [ 0.30% ]; - Register Dependencies [ 0.30% ]; - Memory Dependencies [ 0.00% ]. Critical sequence based on the simulation:. Instruction Dependency Information; +----< 2. vhaddps %xmm3, %xmm3, %xmm4; |; | < loop carried >; |; | 0. vmulps %xmm0, %xmm1, %xmm2; +----> 1. vhaddps %xmm2, %xmm2, %xmm3 ## RESOURCE interference: JFPA [ probability: 74% ]; +----> 2. vhaddps %xmm3, %xmm3, %xmm4 ## REGISTER dependency: %x",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:26843,Performance,bottleneck,bottleneck-analysis,26843,"ncy; instructions, the number of cycles spent while in the *ready* state is expected; to be very small when compared with the total number of cycles spent in the; scheduler's queue. The difference between the two counters is a good indicator; of how large of an impact data dependencies had on the execution of the; instructions. When performance is mostly limited by the lack of hardware; resources, the delta between the two counters is small. However, the number of; cycles spent in the queue tends to be larger (i.e., more than 1-3cy),; especially when compared to other low latency instructions. Bottleneck Analysis; ^^^^^^^^^^^^^^^^^^^; The ``-bottleneck-analysis`` command line option enables the analysis of; performance bottlenecks. This analysis is potentially expensive. It attempts to correlate increases in; backend pressure (caused by pipeline resource pressure and data dependencies) to; dynamic dispatch stalls. Below is an example of ``-bottleneck-analysis`` output generated by; :program:`llvm-mca` for 500 iterations of the dot-product example on btver2. .. code-block:: none. Cycles with backend pressure increase [ 48.07% ]; Throughput Bottlenecks:; Resource Pressure [ 47.77% ]; - JFPA [ 47.77% ]; - JFPU0 [ 47.77% ]; Data Dependencies: [ 0.30% ]; - Register Dependencies [ 0.30% ]; - Memory Dependencies [ 0.00% ]. Critical sequence based on the simulation:. Instruction Dependency Information; +----< 2. vhaddps %xmm3, %xmm3, %xmm4; |; | < loop carried >; |; | 0. vmulps %xmm0, %xmm1, %xmm2; +----> 1. vhaddps %xmm2, %xmm2, %xmm3 ## RESOURCE interference: JFPA [ probability: 74% ]; +----> 2. vhaddps %xmm3, %xmm3, %xmm4 ## REGISTER dependency: %xmm3; |; | < loop carried >; |; +----> 1. vhaddps %xmm2, %xmm2, %xmm3 ## RESOURCE interference: JFPA [ probability: 74% ]. According to the analysis, throughput is limited by resource pressure and not by; data dependencies. The analysis observed increases in backend pressure during; 48.07% of the simulated run. Almost all those ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:27709,Performance,throughput,throughput,27709,"sed by pipeline resource pressure and data dependencies) to; dynamic dispatch stalls. Below is an example of ``-bottleneck-analysis`` output generated by; :program:`llvm-mca` for 500 iterations of the dot-product example on btver2. .. code-block:: none. Cycles with backend pressure increase [ 48.07% ]; Throughput Bottlenecks:; Resource Pressure [ 47.77% ]; - JFPA [ 47.77% ]; - JFPU0 [ 47.77% ]; Data Dependencies: [ 0.30% ]; - Register Dependencies [ 0.30% ]; - Memory Dependencies [ 0.00% ]. Critical sequence based on the simulation:. Instruction Dependency Information; +----< 2. vhaddps %xmm3, %xmm3, %xmm4; |; | < loop carried >; |; | 0. vmulps %xmm0, %xmm1, %xmm2; +----> 1. vhaddps %xmm2, %xmm2, %xmm3 ## RESOURCE interference: JFPA [ probability: 74% ]; +----> 2. vhaddps %xmm3, %xmm3, %xmm4 ## REGISTER dependency: %xmm3; |; | < loop carried >; |; +----> 1. vhaddps %xmm2, %xmm2, %xmm3 ## RESOURCE interference: JFPA [ probability: 74% ]. According to the analysis, throughput is limited by resource pressure and not by; data dependencies. The analysis observed increases in backend pressure during; 48.07% of the simulated run. Almost all those pressure increase events were; caused by contention on processor resources JFPA/JFPU0. The `critical sequence` is the most expensive sequence of instructions according; to the simulation. It is annotated to provide extra information about critical; register dependencies and resource interferences between instructions. Instructions from the critical sequence are expected to significantly impact; performance. By construction, the accuracy of this analysis is strongly; dependent on the simulation and (as always) by the quality of the processor; model in llvm. Bottleneck analysis is currently not supported for processors with an in-order; backend. Extra Statistics to Further Diagnose Performance Issues; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; The ``-all-stats`` command line option enables extra statistics and performan",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:28287,Performance,perform,performance,28287," the simulation:. Instruction Dependency Information; +----< 2. vhaddps %xmm3, %xmm3, %xmm4; |; | < loop carried >; |; | 0. vmulps %xmm0, %xmm1, %xmm2; +----> 1. vhaddps %xmm2, %xmm2, %xmm3 ## RESOURCE interference: JFPA [ probability: 74% ]; +----> 2. vhaddps %xmm3, %xmm3, %xmm4 ## REGISTER dependency: %xmm3; |; | < loop carried >; |; +----> 1. vhaddps %xmm2, %xmm2, %xmm3 ## RESOURCE interference: JFPA [ probability: 74% ]. According to the analysis, throughput is limited by resource pressure and not by; data dependencies. The analysis observed increases in backend pressure during; 48.07% of the simulated run. Almost all those pressure increase events were; caused by contention on processor resources JFPA/JFPU0. The `critical sequence` is the most expensive sequence of instructions according; to the simulation. It is annotated to provide extra information about critical; register dependencies and resource interferences between instructions. Instructions from the critical sequence are expected to significantly impact; performance. By construction, the accuracy of this analysis is strongly; dependent on the simulation and (as always) by the quality of the processor; model in llvm. Bottleneck analysis is currently not supported for processors with an in-order; backend. Extra Statistics to Further Diagnose Performance Issues; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; The ``-all-stats`` command line option enables extra statistics and performance; counters for the dispatch logic, the reorder buffer, the retire control unit,; and the register file. Below is an example of ``-all-stats`` output generated by :program:`llvm-mca`; for 300 iterations of the dot-product example discussed in the previous; sections. .. code-block:: none. Dynamic Dispatch Stall Cycles:; RAT - Register unavailable: 0; RCU - Retire tokens unavailable: 0; SCHEDQ - Scheduler full: 272 (44.6%); LQ - Load queue full: 0; SQ - Store queue full: 0; GROUP - Static restrictions on the dispatch ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:28723,Performance,perform,performance,28723,"ing to the analysis, throughput is limited by resource pressure and not by; data dependencies. The analysis observed increases in backend pressure during; 48.07% of the simulated run. Almost all those pressure increase events were; caused by contention on processor resources JFPA/JFPU0. The `critical sequence` is the most expensive sequence of instructions according; to the simulation. It is annotated to provide extra information about critical; register dependencies and resource interferences between instructions. Instructions from the critical sequence are expected to significantly impact; performance. By construction, the accuracy of this analysis is strongly; dependent on the simulation and (as always) by the quality of the processor; model in llvm. Bottleneck analysis is currently not supported for processors with an in-order; backend. Extra Statistics to Further Diagnose Performance Issues; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; The ``-all-stats`` command line option enables extra statistics and performance; counters for the dispatch logic, the reorder buffer, the retire control unit,; and the register file. Below is an example of ``-all-stats`` output generated by :program:`llvm-mca`; for 300 iterations of the dot-product example discussed in the previous; sections. .. code-block:: none. Dynamic Dispatch Stall Cycles:; RAT - Register unavailable: 0; RCU - Retire tokens unavailable: 0; SCHEDQ - Scheduler full: 272 (44.6%); LQ - Load queue full: 0; SQ - Store queue full: 0; GROUP - Static restrictions on the dispatch group: 0. Dispatch Logic - number of cycles where we saw N micro opcodes dispatched:; [# dispatched], [# cycles]; 0, 24 (3.9%); 1, 272 (44.6%); 2, 314 (51.5%). Schedulers - number of cycles where we saw N micro opcodes issued:; [# issued], [# cycles]; 0, 7 (1.1%); 1, 306 (50.2%); 2, 297 (48.7%). Scheduler's queue usage:; [1] Resource name.; [2] Average number of used buffer entries.; [3] Maximum number of used buffer entries.; [4] ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:29169,Performance,queue,queue,29169," Instructions from the critical sequence are expected to significantly impact; performance. By construction, the accuracy of this analysis is strongly; dependent on the simulation and (as always) by the quality of the processor; model in llvm. Bottleneck analysis is currently not supported for processors with an in-order; backend. Extra Statistics to Further Diagnose Performance Issues; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; The ``-all-stats`` command line option enables extra statistics and performance; counters for the dispatch logic, the reorder buffer, the retire control unit,; and the register file. Below is an example of ``-all-stats`` output generated by :program:`llvm-mca`; for 300 iterations of the dot-product example discussed in the previous; sections. .. code-block:: none. Dynamic Dispatch Stall Cycles:; RAT - Register unavailable: 0; RCU - Retire tokens unavailable: 0; SCHEDQ - Scheduler full: 272 (44.6%); LQ - Load queue full: 0; SQ - Store queue full: 0; GROUP - Static restrictions on the dispatch group: 0. Dispatch Logic - number of cycles where we saw N micro opcodes dispatched:; [# dispatched], [# cycles]; 0, 24 (3.9%); 1, 272 (44.6%); 2, 314 (51.5%). Schedulers - number of cycles where we saw N micro opcodes issued:; [# issued], [# cycles]; 0, 7 (1.1%); 1, 306 (50.2%); 2, 297 (48.7%). Scheduler's queue usage:; [1] Resource name.; [2] Average number of used buffer entries.; [3] Maximum number of used buffer entries.; [4] Total number of buffer entries. [1] [2] [3] [4]; JALU01 0 0 20; JFPU01 17 18 18; JLSAGU 0 0 12. Retire Control Unit - number of cycles where we saw N instructions retired:; [# retired], [# cycles]; 0, 109 (17.9%); 1, 102 (16.7%); 2, 399 (65.4%). Total ROB Entries: 64; Max Used ROB Entries: 35 ( 54.7% ); Average Used ROB Entries per cy: 32 ( 50.0% ). Register File statistics:; Total number of mappings created: 900; Max number of mappings used: 35. * Register File #1 -- JFpuPRF:; Number of physical registers: 72; Tot",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:29195,Performance,queue,queue,29195," Instructions from the critical sequence are expected to significantly impact; performance. By construction, the accuracy of this analysis is strongly; dependent on the simulation and (as always) by the quality of the processor; model in llvm. Bottleneck analysis is currently not supported for processors with an in-order; backend. Extra Statistics to Further Diagnose Performance Issues; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; The ``-all-stats`` command line option enables extra statistics and performance; counters for the dispatch logic, the reorder buffer, the retire control unit,; and the register file. Below is an example of ``-all-stats`` output generated by :program:`llvm-mca`; for 300 iterations of the dot-product example discussed in the previous; sections. .. code-block:: none. Dynamic Dispatch Stall Cycles:; RAT - Register unavailable: 0; RCU - Retire tokens unavailable: 0; SCHEDQ - Scheduler full: 272 (44.6%); LQ - Load queue full: 0; SQ - Store queue full: 0; GROUP - Static restrictions on the dispatch group: 0. Dispatch Logic - number of cycles where we saw N micro opcodes dispatched:; [# dispatched], [# cycles]; 0, 24 (3.9%); 1, 272 (44.6%); 2, 314 (51.5%). Schedulers - number of cycles where we saw N micro opcodes issued:; [# issued], [# cycles]; 0, 7 (1.1%); 1, 306 (50.2%); 2, 297 (48.7%). Scheduler's queue usage:; [1] Resource name.; [2] Average number of used buffer entries.; [3] Maximum number of used buffer entries.; [4] Total number of buffer entries. [1] [2] [3] [4]; JALU01 0 0 20; JFPU01 17 18 18; JLSAGU 0 0 12. Retire Control Unit - number of cycles where we saw N instructions retired:; [# retired], [# cycles]; 0, 109 (17.9%); 1, 102 (16.7%); 2, 399 (65.4%). Total ROB Entries: 64; Max Used ROB Entries: 35 ( 54.7% ); Average Used ROB Entries per cy: 32 ( 50.0% ). Register File statistics:; Total number of mappings created: 900; Max number of mappings used: 35. * Register File #1 -- JFpuPRF:; Number of physical registers: 72; Tot",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:29563,Performance,queue,queue,29563,"gnose Performance Issues; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; The ``-all-stats`` command line option enables extra statistics and performance; counters for the dispatch logic, the reorder buffer, the retire control unit,; and the register file. Below is an example of ``-all-stats`` output generated by :program:`llvm-mca`; for 300 iterations of the dot-product example discussed in the previous; sections. .. code-block:: none. Dynamic Dispatch Stall Cycles:; RAT - Register unavailable: 0; RCU - Retire tokens unavailable: 0; SCHEDQ - Scheduler full: 272 (44.6%); LQ - Load queue full: 0; SQ - Store queue full: 0; GROUP - Static restrictions on the dispatch group: 0. Dispatch Logic - number of cycles where we saw N micro opcodes dispatched:; [# dispatched], [# cycles]; 0, 24 (3.9%); 1, 272 (44.6%); 2, 314 (51.5%). Schedulers - number of cycles where we saw N micro opcodes issued:; [# issued], [# cycles]; 0, 7 (1.1%); 1, 306 (50.2%); 2, 297 (48.7%). Scheduler's queue usage:; [1] Resource name.; [2] Average number of used buffer entries.; [3] Maximum number of used buffer entries.; [4] Total number of buffer entries. [1] [2] [3] [4]; JALU01 0 0 20; JFPU01 17 18 18; JLSAGU 0 0 12. Retire Control Unit - number of cycles where we saw N instructions retired:; [# retired], [# cycles]; 0, 109 (17.9%); 1, 102 (16.7%); 2, 399 (65.4%). Total ROB Entries: 64; Max Used ROB Entries: 35 ( 54.7% ); Average Used ROB Entries per cy: 32 ( 50.0% ). Register File statistics:; Total number of mappings created: 900; Max number of mappings used: 35. * Register File #1 -- JFpuPRF:; Number of physical registers: 72; Total number of mappings created: 900; Max number of mappings used: 35. * Register File #2 -- JIntegerPRF:; Number of physical registers: 64; Total number of mappings created: 0; Max number of mappings used: 0. If we look at the *Dynamic Dispatch Stall Cycles* table, we see the counter for; SCHEDQ reports 272 cycles. This counter is incremented every time the dispa",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:30643,Performance,queue,queue,30643,"name.; [2] Average number of used buffer entries.; [3] Maximum number of used buffer entries.; [4] Total number of buffer entries. [1] [2] [3] [4]; JALU01 0 0 20; JFPU01 17 18 18; JLSAGU 0 0 12. Retire Control Unit - number of cycles where we saw N instructions retired:; [# retired], [# cycles]; 0, 109 (17.9%); 1, 102 (16.7%); 2, 399 (65.4%). Total ROB Entries: 64; Max Used ROB Entries: 35 ( 54.7% ); Average Used ROB Entries per cy: 32 ( 50.0% ). Register File statistics:; Total number of mappings created: 900; Max number of mappings used: 35. * Register File #1 -- JFpuPRF:; Number of physical registers: 72; Total number of mappings created: 900; Max number of mappings used: 35. * Register File #2 -- JIntegerPRF:; Number of physical registers: 64; Total number of mappings created: 0; Max number of mappings used: 0. If we look at the *Dynamic Dispatch Stall Cycles* table, we see the counter for; SCHEDQ reports 272 cycles. This counter is incremented every time the dispatch; logic is unable to dispatch a full group because the scheduler's queue is full. Looking at the *Dispatch Logic* table, we see that the pipeline was only able to; dispatch two micro opcodes 51.5% of the time. The dispatch group was limited to; one micro opcode 44.6% of the cycles, which corresponds to 272 cycles. The; dispatch statistics are displayed by either using the command option; ``-all-stats`` or ``-dispatch-stats``. The next table, *Schedulers*, presents a histogram displaying a count,; representing the number of micro opcodes issued on some number of cycles. In; this case, of the 610 simulated cycles, single opcodes were issued 306 times; (50.2%) and there were 7 cycles where no opcodes were issued. The *Scheduler's queue usage* table shows that the average and maximum number of; buffer entries (i.e., scheduler queue entries) used at runtime. Resource JFPU01; reached its maximum (18 of 18 queue entries). Note that AMD Jaguar implements; three schedulers:. * JALU01 - A scheduler for ALU ins",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:31313,Performance,queue,queue,31313,"4; Total number of mappings created: 0; Max number of mappings used: 0. If we look at the *Dynamic Dispatch Stall Cycles* table, we see the counter for; SCHEDQ reports 272 cycles. This counter is incremented every time the dispatch; logic is unable to dispatch a full group because the scheduler's queue is full. Looking at the *Dispatch Logic* table, we see that the pipeline was only able to; dispatch two micro opcodes 51.5% of the time. The dispatch group was limited to; one micro opcode 44.6% of the cycles, which corresponds to 272 cycles. The; dispatch statistics are displayed by either using the command option; ``-all-stats`` or ``-dispatch-stats``. The next table, *Schedulers*, presents a histogram displaying a count,; representing the number of micro opcodes issued on some number of cycles. In; this case, of the 610 simulated cycles, single opcodes were issued 306 times; (50.2%) and there were 7 cycles where no opcodes were issued. The *Scheduler's queue usage* table shows that the average and maximum number of; buffer entries (i.e., scheduler queue entries) used at runtime. Resource JFPU01; reached its maximum (18 of 18 queue entries). Note that AMD Jaguar implements; three schedulers:. * JALU01 - A scheduler for ALU instructions.; * JFPU01 - A scheduler floating point operations.; * JLSAGU - A scheduler for address generation. The dot-product is a kernel of three floating point instructions (a vector; multiply followed by two horizontal adds). That explains why only the floating; point scheduler appears to be used. A full scheduler queue is either caused by data dependency chains or by a; sub-optimal usage of hardware resources. Sometimes, resource pressure can be; mitigated by rewriting the kernel using different instructions that consume; different scheduler resources. Schedulers with a small queue are less resilient; to bottlenecks caused by the presence of long data dependencies. The scheduler; statistics are displayed by using the command option ``-all-st",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:31410,Performance,queue,queue,31410," we look at the *Dynamic Dispatch Stall Cycles* table, we see the counter for; SCHEDQ reports 272 cycles. This counter is incremented every time the dispatch; logic is unable to dispatch a full group because the scheduler's queue is full. Looking at the *Dispatch Logic* table, we see that the pipeline was only able to; dispatch two micro opcodes 51.5% of the time. The dispatch group was limited to; one micro opcode 44.6% of the cycles, which corresponds to 272 cycles. The; dispatch statistics are displayed by either using the command option; ``-all-stats`` or ``-dispatch-stats``. The next table, *Schedulers*, presents a histogram displaying a count,; representing the number of micro opcodes issued on some number of cycles. In; this case, of the 610 simulated cycles, single opcodes were issued 306 times; (50.2%) and there were 7 cycles where no opcodes were issued. The *Scheduler's queue usage* table shows that the average and maximum number of; buffer entries (i.e., scheduler queue entries) used at runtime. Resource JFPU01; reached its maximum (18 of 18 queue entries). Note that AMD Jaguar implements; three schedulers:. * JALU01 - A scheduler for ALU instructions.; * JFPU01 - A scheduler floating point operations.; * JLSAGU - A scheduler for address generation. The dot-product is a kernel of three floating point instructions (a vector; multiply followed by two horizontal adds). That explains why only the floating; point scheduler appears to be used. A full scheduler queue is either caused by data dependency chains or by a; sub-optimal usage of hardware resources. Sometimes, resource pressure can be; mitigated by rewriting the kernel using different instructions that consume; different scheduler resources. Schedulers with a small queue are less resilient; to bottlenecks caused by the presence of long data dependencies. The scheduler; statistics are displayed by using the command option ``-all-stats`` or; ``-scheduler-stats``. The next table, *Retire Control Unit*, pre",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:31489,Performance,queue,queue,31489,", we see the counter for; SCHEDQ reports 272 cycles. This counter is incremented every time the dispatch; logic is unable to dispatch a full group because the scheduler's queue is full. Looking at the *Dispatch Logic* table, we see that the pipeline was only able to; dispatch two micro opcodes 51.5% of the time. The dispatch group was limited to; one micro opcode 44.6% of the cycles, which corresponds to 272 cycles. The; dispatch statistics are displayed by either using the command option; ``-all-stats`` or ``-dispatch-stats``. The next table, *Schedulers*, presents a histogram displaying a count,; representing the number of micro opcodes issued on some number of cycles. In; this case, of the 610 simulated cycles, single opcodes were issued 306 times; (50.2%) and there were 7 cycles where no opcodes were issued. The *Scheduler's queue usage* table shows that the average and maximum number of; buffer entries (i.e., scheduler queue entries) used at runtime. Resource JFPU01; reached its maximum (18 of 18 queue entries). Note that AMD Jaguar implements; three schedulers:. * JALU01 - A scheduler for ALU instructions.; * JFPU01 - A scheduler floating point operations.; * JLSAGU - A scheduler for address generation. The dot-product is a kernel of three floating point instructions (a vector; multiply followed by two horizontal adds). That explains why only the floating; point scheduler appears to be used. A full scheduler queue is either caused by data dependency chains or by a; sub-optimal usage of hardware resources. Sometimes, resource pressure can be; mitigated by rewriting the kernel using different instructions that consume; different scheduler resources. Schedulers with a small queue are less resilient; to bottlenecks caused by the presence of long data dependencies. The scheduler; statistics are displayed by using the command option ``-all-stats`` or; ``-scheduler-stats``. The next table, *Retire Control Unit*, presents a histogram displaying a count,; representing t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:31910,Performance,queue,queue,31910," command option; ``-all-stats`` or ``-dispatch-stats``. The next table, *Schedulers*, presents a histogram displaying a count,; representing the number of micro opcodes issued on some number of cycles. In; this case, of the 610 simulated cycles, single opcodes were issued 306 times; (50.2%) and there were 7 cycles where no opcodes were issued. The *Scheduler's queue usage* table shows that the average and maximum number of; buffer entries (i.e., scheduler queue entries) used at runtime. Resource JFPU01; reached its maximum (18 of 18 queue entries). Note that AMD Jaguar implements; three schedulers:. * JALU01 - A scheduler for ALU instructions.; * JFPU01 - A scheduler floating point operations.; * JLSAGU - A scheduler for address generation. The dot-product is a kernel of three floating point instructions (a vector; multiply followed by two horizontal adds). That explains why only the floating; point scheduler appears to be used. A full scheduler queue is either caused by data dependency chains or by a; sub-optimal usage of hardware resources. Sometimes, resource pressure can be; mitigated by rewriting the kernel using different instructions that consume; different scheduler resources. Schedulers with a small queue are less resilient; to bottlenecks caused by the presence of long data dependencies. The scheduler; statistics are displayed by using the command option ``-all-stats`` or; ``-scheduler-stats``. The next table, *Retire Control Unit*, presents a histogram displaying a count,; representing the number of instructions retired on some number of cycles. In; this case, of the 610 simulated cycles, two instructions were retired during the; same cycle 399 times (65.4%) and there were 109 cycles where no instructions; were retired. The retire statistics are displayed by using the command option; ``-all-stats`` or ``-retire-stats``. The last table presented is *Register File statistics*. Each physical register; file (PRF) used by the pipeline is presented in this tabl",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:32178,Performance,queue,queue,32178," were issued 306 times; (50.2%) and there were 7 cycles where no opcodes were issued. The *Scheduler's queue usage* table shows that the average and maximum number of; buffer entries (i.e., scheduler queue entries) used at runtime. Resource JFPU01; reached its maximum (18 of 18 queue entries). Note that AMD Jaguar implements; three schedulers:. * JALU01 - A scheduler for ALU instructions.; * JFPU01 - A scheduler floating point operations.; * JLSAGU - A scheduler for address generation. The dot-product is a kernel of three floating point instructions (a vector; multiply followed by two horizontal adds). That explains why only the floating; point scheduler appears to be used. A full scheduler queue is either caused by data dependency chains or by a; sub-optimal usage of hardware resources. Sometimes, resource pressure can be; mitigated by rewriting the kernel using different instructions that consume; different scheduler resources. Schedulers with a small queue are less resilient; to bottlenecks caused by the presence of long data dependencies. The scheduler; statistics are displayed by using the command option ``-all-stats`` or; ``-scheduler-stats``. The next table, *Retire Control Unit*, presents a histogram displaying a count,; representing the number of instructions retired on some number of cycles. In; this case, of the 610 simulated cycles, two instructions were retired during the; same cycle 399 times (65.4%) and there were 109 cycles where no instructions; were retired. The retire statistics are displayed by using the command option; ``-all-stats`` or ``-retire-stats``. The last table presented is *Register File statistics*. Each physical register; file (PRF) used by the pipeline is presented in this table. In the case of AMD; Jaguar, there are two register files, one for floating-point registers (JFpuPRF); and one for integer registers (JIntegerPRF). The table shows that of the 900; instructions processed, there were 900 mappings created. Since this dot-produc",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:32207,Performance,bottleneck,bottlenecks,32207," were issued 306 times; (50.2%) and there were 7 cycles where no opcodes were issued. The *Scheduler's queue usage* table shows that the average and maximum number of; buffer entries (i.e., scheduler queue entries) used at runtime. Resource JFPU01; reached its maximum (18 of 18 queue entries). Note that AMD Jaguar implements; three schedulers:. * JALU01 - A scheduler for ALU instructions.; * JFPU01 - A scheduler floating point operations.; * JLSAGU - A scheduler for address generation. The dot-product is a kernel of three floating point instructions (a vector; multiply followed by two horizontal adds). That explains why only the floating; point scheduler appears to be used. A full scheduler queue is either caused by data dependency chains or by a; sub-optimal usage of hardware resources. Sometimes, resource pressure can be; mitigated by rewriting the kernel using different instructions that consume; different scheduler resources. Schedulers with a small queue are less resilient; to bottlenecks caused by the presence of long data dependencies. The scheduler; statistics are displayed by using the command option ``-all-stats`` or; ``-scheduler-stats``. The next table, *Retire Control Unit*, presents a histogram displaying a count,; representing the number of instructions retired on some number of cycles. In; this case, of the 610 simulated cycles, two instructions were retired during the; same cycle 399 times (65.4%) and there were 109 cycles where no instructions; were retired. The retire statistics are displayed by using the command option; ``-all-stats`` or ``-retire-stats``. The last table presented is *Register File statistics*. Each physical register; file (PRF) used by the pipeline is presented in this table. In the case of AMD; Jaguar, there are two register files, one for floating-point registers (JFpuPRF); and one for integer registers (JIntegerPRF). The table shows that of the 900; instructions processed, there were 900 mappings created. Since this dot-produc",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:34653,Performance,queue,queue,34653,"he command option ``-all-stats`` or; ``-register-file-stats``. In this example, we can conclude that the IPC is mostly limited by data; dependencies, and not by resource pressure. Instruction Flow; ^^^^^^^^^^^^^^^^; This section describes the instruction flow through the default pipeline of; :program:`llvm-mca`, as well as the functional units involved in the process. The default pipeline implements the following sequence of stages used to; process instructions. * Dispatch (Instruction is dispatched to the schedulers).; * Issue (Instruction is issued to the processor pipelines).; * Write Back (Instruction is executed, and results are written back).; * Retire (Instruction is retired; writes are architecturally committed). The in-order pipeline implements the following sequence of stages:; * InOrderIssue (Instruction is issued to the processor pipelines).; * Retire (Instruction is retired; writes are architecturally committed). :program:`llvm-mca` assumes that instructions have all been decoded and placed; into a queue before the simulation start. Therefore, the instruction fetch and; decode stages are not modeled. Performance bottlenecks in the frontend are not; diagnosed. Also, :program:`llvm-mca` does not model branch prediction. Instruction Dispatch; """"""""""""""""""""""""""""""""""""""""; During the dispatch stage, instructions are picked in program order from a; queue of already decoded instructions, and dispatched in groups to the; simulated hardware schedulers. The size of a dispatch group depends on the availability of the simulated; hardware resources. The processor dispatch width defaults to the value; of the ``IssueWidth`` in LLVM's scheduling model. An instruction can be dispatched if:. * The size of the dispatch group is smaller than processor's dispatch width.; * There are enough entries in the reorder buffer.; * There are enough physical registers to do register renaming.; * The schedulers are not full. Scheduling models can optionally specify which register files are a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:34769,Performance,bottleneck,bottlenecks,34769," resource pressure. Instruction Flow; ^^^^^^^^^^^^^^^^; This section describes the instruction flow through the default pipeline of; :program:`llvm-mca`, as well as the functional units involved in the process. The default pipeline implements the following sequence of stages used to; process instructions. * Dispatch (Instruction is dispatched to the schedulers).; * Issue (Instruction is issued to the processor pipelines).; * Write Back (Instruction is executed, and results are written back).; * Retire (Instruction is retired; writes are architecturally committed). The in-order pipeline implements the following sequence of stages:; * InOrderIssue (Instruction is issued to the processor pipelines).; * Retire (Instruction is retired; writes are architecturally committed). :program:`llvm-mca` assumes that instructions have all been decoded and placed; into a queue before the simulation start. Therefore, the instruction fetch and; decode stages are not modeled. Performance bottlenecks in the frontend are not; diagnosed. Also, :program:`llvm-mca` does not model branch prediction. Instruction Dispatch; """"""""""""""""""""""""""""""""""""""""; During the dispatch stage, instructions are picked in program order from a; queue of already decoded instructions, and dispatched in groups to the; simulated hardware schedulers. The size of a dispatch group depends on the availability of the simulated; hardware resources. The processor dispatch width defaults to the value; of the ``IssueWidth`` in LLVM's scheduling model. An instruction can be dispatched if:. * The size of the dispatch group is smaller than processor's dispatch width.; * There are enough entries in the reorder buffer.; * There are enough physical registers to do register renaming.; * The schedulers are not full. Scheduling models can optionally specify which register files are available on; the processor. :program:`llvm-mca` uses that information to initialize register; file descriptors. Users can limit the number of physical registers",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:34997,Performance,queue,queue,34997," process. The default pipeline implements the following sequence of stages used to; process instructions. * Dispatch (Instruction is dispatched to the schedulers).; * Issue (Instruction is issued to the processor pipelines).; * Write Back (Instruction is executed, and results are written back).; * Retire (Instruction is retired; writes are architecturally committed). The in-order pipeline implements the following sequence of stages:; * InOrderIssue (Instruction is issued to the processor pipelines).; * Retire (Instruction is retired; writes are architecturally committed). :program:`llvm-mca` assumes that instructions have all been decoded and placed; into a queue before the simulation start. Therefore, the instruction fetch and; decode stages are not modeled. Performance bottlenecks in the frontend are not; diagnosed. Also, :program:`llvm-mca` does not model branch prediction. Instruction Dispatch; """"""""""""""""""""""""""""""""""""""""; During the dispatch stage, instructions are picked in program order from a; queue of already decoded instructions, and dispatched in groups to the; simulated hardware schedulers. The size of a dispatch group depends on the availability of the simulated; hardware resources. The processor dispatch width defaults to the value; of the ``IssueWidth`` in LLVM's scheduling model. An instruction can be dispatched if:. * The size of the dispatch group is smaller than processor's dispatch width.; * There are enough entries in the reorder buffer.; * There are enough physical registers to do register renaming.; * The schedulers are not full. Scheduling models can optionally specify which register files are available on; the processor. :program:`llvm-mca` uses that information to initialize register; file descriptors. Users can limit the number of physical registers that are; globally available for register renaming by using the command option; ``-register-file-size``. A value of zero for this option means *unbounded*. By; knowing how many registers are available ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:38824,Performance,queue,queue,38824,"ager uses a; round-robin selector to guarantee that resource usage is uniformly distributed; between all units of a group. :program:`llvm-mca`'s scheduler internally groups instructions into three sets:. * WaitSet: a set of instructions whose operands are not ready.; * ReadySet: a set of instructions ready to execute.; * IssuedSet: a set of instructions executing. Depending on the operands availability, instructions that are dispatched to the; scheduler are either placed into the WaitSet or into the ReadySet. Every cycle, the scheduler checks if instructions can be moved from the WaitSet; to the ReadySet, and if instructions from the ReadySet can be issued to the; underlying pipelines. The algorithm prioritizes older instructions over younger; instructions. Write-Back and Retire Stage; """"""""""""""""""""""""""""""""""""""""""""""""""""""; Issued instructions are moved from the ReadySet to the IssuedSet. There,; instructions wait until they reach the write-back stage. At that point, they; get removed from the queue and the retire control unit is notified. When instructions are executed, the retire control unit flags the instruction as; ""ready to retire."". Instructions are retired in program order. The register file is notified of the; retirement so that it can free the physical registers that were allocated for; the instruction during the register renaming stage. Load/Store Unit and Memory Consistency Model; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; To simulate an out-of-order execution of memory operations, :program:`llvm-mca`; utilizes a simulated load/store unit (LSUnit) to simulate the speculative; execution of loads and stores. Each load (or store) consumes an entry in the load (or store) queue. Users can; specify flags ``-lqueue`` and ``-squeue`` to limit the number of entries in the; load and store queues respectively. The queues are unbounded by default. The LSUnit implements a relaxed consistency model for memory loads and stores.; The rules are:. 1. A younger load is allowed to ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:39379,Performance,load,load,39379,"to the ReadySet. Every cycle, the scheduler checks if instructions can be moved from the WaitSet; to the ReadySet, and if instructions from the ReadySet can be issued to the; underlying pipelines. The algorithm prioritizes older instructions over younger; instructions. Write-Back and Retire Stage; """"""""""""""""""""""""""""""""""""""""""""""""""""""; Issued instructions are moved from the ReadySet to the IssuedSet. There,; instructions wait until they reach the write-back stage. At that point, they; get removed from the queue and the retire control unit is notified. When instructions are executed, the retire control unit flags the instruction as; ""ready to retire."". Instructions are retired in program order. The register file is notified of the; retirement so that it can free the physical registers that were allocated for; the instruction during the register renaming stage. Load/Store Unit and Memory Consistency Model; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; To simulate an out-of-order execution of memory operations, :program:`llvm-mca`; utilizes a simulated load/store unit (LSUnit) to simulate the speculative; execution of loads and stores. Each load (or store) consumes an entry in the load (or store) queue. Users can; specify flags ``-lqueue`` and ``-squeue`` to limit the number of entries in the; load and store queues respectively. The queues are unbounded by default. The LSUnit implements a relaxed consistency model for memory loads and stores.; The rules are:. 1. A younger load is allowed to pass an older load only if there are no; intervening stores or barriers between the two loads.; 2. A younger load is allowed to pass an older store provided that the load does; not alias with the store.; 3. A younger store is not allowed to pass an older store.; 4. A younger store is not allowed to pass an older load. By default, the LSUnit optimistically assumes that loads do not alias; (`-noalias=true`) store operations. Under this assumption, younger loads are; always allowed to pass older ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:39446,Performance,load,loads,39446,"to the ReadySet. Every cycle, the scheduler checks if instructions can be moved from the WaitSet; to the ReadySet, and if instructions from the ReadySet can be issued to the; underlying pipelines. The algorithm prioritizes older instructions over younger; instructions. Write-Back and Retire Stage; """"""""""""""""""""""""""""""""""""""""""""""""""""""; Issued instructions are moved from the ReadySet to the IssuedSet. There,; instructions wait until they reach the write-back stage. At that point, they; get removed from the queue and the retire control unit is notified. When instructions are executed, the retire control unit flags the instruction as; ""ready to retire."". Instructions are retired in program order. The register file is notified of the; retirement so that it can free the physical registers that were allocated for; the instruction during the register renaming stage. Load/Store Unit and Memory Consistency Model; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; To simulate an out-of-order execution of memory operations, :program:`llvm-mca`; utilizes a simulated load/store unit (LSUnit) to simulate the speculative; execution of loads and stores. Each load (or store) consumes an entry in the load (or store) queue. Users can; specify flags ``-lqueue`` and ``-squeue`` to limit the number of entries in the; load and store queues respectively. The queues are unbounded by default. The LSUnit implements a relaxed consistency model for memory loads and stores.; The rules are:. 1. A younger load is allowed to pass an older load only if there are no; intervening stores or barriers between the two loads.; 2. A younger load is allowed to pass an older store provided that the load does; not alias with the store.; 3. A younger store is not allowed to pass an older store.; 4. A younger store is not allowed to pass an older load. By default, the LSUnit optimistically assumes that loads do not alias; (`-noalias=true`) store operations. Under this assumption, younger loads are; always allowed to pass older ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:39469,Performance,load,load,39469," underlying pipelines. The algorithm prioritizes older instructions over younger; instructions. Write-Back and Retire Stage; """"""""""""""""""""""""""""""""""""""""""""""""""""""; Issued instructions are moved from the ReadySet to the IssuedSet. There,; instructions wait until they reach the write-back stage. At that point, they; get removed from the queue and the retire control unit is notified. When instructions are executed, the retire control unit flags the instruction as; ""ready to retire."". Instructions are retired in program order. The register file is notified of the; retirement so that it can free the physical registers that were allocated for; the instruction during the register renaming stage. Load/Store Unit and Memory Consistency Model; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; To simulate an out-of-order execution of memory operations, :program:`llvm-mca`; utilizes a simulated load/store unit (LSUnit) to simulate the speculative; execution of loads and stores. Each load (or store) consumes an entry in the load (or store) queue. Users can; specify flags ``-lqueue`` and ``-squeue`` to limit the number of entries in the; load and store queues respectively. The queues are unbounded by default. The LSUnit implements a relaxed consistency model for memory loads and stores.; The rules are:. 1. A younger load is allowed to pass an older load only if there are no; intervening stores or barriers between the two loads.; 2. A younger load is allowed to pass an older store provided that the load does; not alias with the store.; 3. A younger store is not allowed to pass an older store.; 4. A younger store is not allowed to pass an older load. By default, the LSUnit optimistically assumes that loads do not alias; (`-noalias=true`) store operations. Under this assumption, younger loads are; always allowed to pass older stores. Essentially, the LSUnit does not attempt; to run any alias analysis to predict when loads and stores do not alias with; each other. Note that, in the case of write-co",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:39510,Performance,load,load,39510," underlying pipelines. The algorithm prioritizes older instructions over younger; instructions. Write-Back and Retire Stage; """"""""""""""""""""""""""""""""""""""""""""""""""""""; Issued instructions are moved from the ReadySet to the IssuedSet. There,; instructions wait until they reach the write-back stage. At that point, they; get removed from the queue and the retire control unit is notified. When instructions are executed, the retire control unit flags the instruction as; ""ready to retire."". Instructions are retired in program order. The register file is notified of the; retirement so that it can free the physical registers that were allocated for; the instruction during the register renaming stage. Load/Store Unit and Memory Consistency Model; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; To simulate an out-of-order execution of memory operations, :program:`llvm-mca`; utilizes a simulated load/store unit (LSUnit) to simulate the speculative; execution of loads and stores. Each load (or store) consumes an entry in the load (or store) queue. Users can; specify flags ``-lqueue`` and ``-squeue`` to limit the number of entries in the; load and store queues respectively. The queues are unbounded by default. The LSUnit implements a relaxed consistency model for memory loads and stores.; The rules are:. 1. A younger load is allowed to pass an older load only if there are no; intervening stores or barriers between the two loads.; 2. A younger load is allowed to pass an older store provided that the load does; not alias with the store.; 3. A younger store is not allowed to pass an older store.; 4. A younger store is not allowed to pass an older load. By default, the LSUnit optimistically assumes that loads do not alias; (`-noalias=true`) store operations. Under this assumption, younger loads are; always allowed to pass older stores. Essentially, the LSUnit does not attempt; to run any alias analysis to predict when loads and stores do not alias with; each other. Note that, in the case of write-co",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:39526,Performance,queue,queue,39526," underlying pipelines. The algorithm prioritizes older instructions over younger; instructions. Write-Back and Retire Stage; """"""""""""""""""""""""""""""""""""""""""""""""""""""; Issued instructions are moved from the ReadySet to the IssuedSet. There,; instructions wait until they reach the write-back stage. At that point, they; get removed from the queue and the retire control unit is notified. When instructions are executed, the retire control unit flags the instruction as; ""ready to retire."". Instructions are retired in program order. The register file is notified of the; retirement so that it can free the physical registers that were allocated for; the instruction during the register renaming stage. Load/Store Unit and Memory Consistency Model; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; To simulate an out-of-order execution of memory operations, :program:`llvm-mca`; utilizes a simulated load/store unit (LSUnit) to simulate the speculative; execution of loads and stores. Each load (or store) consumes an entry in the load (or store) queue. Users can; specify flags ``-lqueue`` and ``-squeue`` to limit the number of entries in the; load and store queues respectively. The queues are unbounded by default. The LSUnit implements a relaxed consistency model for memory loads and stores.; The rules are:. 1. A younger load is allowed to pass an older load only if there are no; intervening stores or barriers between the two loads.; 2. A younger load is allowed to pass an older store provided that the load does; not alias with the store.; 3. A younger store is not allowed to pass an older store.; 4. A younger store is not allowed to pass an older load. By default, the LSUnit optimistically assumes that loads do not alias; (`-noalias=true`) store operations. Under this assumption, younger loads are; always allowed to pass older stores. Essentially, the LSUnit does not attempt; to run any alias analysis to predict when loads and stores do not alias with; each other. Note that, in the case of write-co",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:39625,Performance,load,load,39625,"te-Back and Retire Stage; """"""""""""""""""""""""""""""""""""""""""""""""""""""; Issued instructions are moved from the ReadySet to the IssuedSet. There,; instructions wait until they reach the write-back stage. At that point, they; get removed from the queue and the retire control unit is notified. When instructions are executed, the retire control unit flags the instruction as; ""ready to retire."". Instructions are retired in program order. The register file is notified of the; retirement so that it can free the physical registers that were allocated for; the instruction during the register renaming stage. Load/Store Unit and Memory Consistency Model; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; To simulate an out-of-order execution of memory operations, :program:`llvm-mca`; utilizes a simulated load/store unit (LSUnit) to simulate the speculative; execution of loads and stores. Each load (or store) consumes an entry in the load (or store) queue. Users can; specify flags ``-lqueue`` and ``-squeue`` to limit the number of entries in the; load and store queues respectively. The queues are unbounded by default. The LSUnit implements a relaxed consistency model for memory loads and stores.; The rules are:. 1. A younger load is allowed to pass an older load only if there are no; intervening stores or barriers between the two loads.; 2. A younger load is allowed to pass an older store provided that the load does; not alias with the store.; 3. A younger store is not allowed to pass an older store.; 4. A younger store is not allowed to pass an older load. By default, the LSUnit optimistically assumes that loads do not alias; (`-noalias=true`) store operations. Under this assumption, younger loads are; always allowed to pass older stores. Essentially, the LSUnit does not attempt; to run any alias analysis to predict when loads and stores do not alias with; each other. Note that, in the case of write-combining memory, rule 3 could be relaxed to; allow reordering of non-aliasing store operations. Tha",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:39640,Performance,queue,queues,39640,"te-Back and Retire Stage; """"""""""""""""""""""""""""""""""""""""""""""""""""""; Issued instructions are moved from the ReadySet to the IssuedSet. There,; instructions wait until they reach the write-back stage. At that point, they; get removed from the queue and the retire control unit is notified. When instructions are executed, the retire control unit flags the instruction as; ""ready to retire."". Instructions are retired in program order. The register file is notified of the; retirement so that it can free the physical registers that were allocated for; the instruction during the register renaming stage. Load/Store Unit and Memory Consistency Model; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; To simulate an out-of-order execution of memory operations, :program:`llvm-mca`; utilizes a simulated load/store unit (LSUnit) to simulate the speculative; execution of loads and stores. Each load (or store) consumes an entry in the load (or store) queue. Users can; specify flags ``-lqueue`` and ``-squeue`` to limit the number of entries in the; load and store queues respectively. The queues are unbounded by default. The LSUnit implements a relaxed consistency model for memory loads and stores.; The rules are:. 1. A younger load is allowed to pass an older load only if there are no; intervening stores or barriers between the two loads.; 2. A younger load is allowed to pass an older store provided that the load does; not alias with the store.; 3. A younger store is not allowed to pass an older store.; 4. A younger store is not allowed to pass an older load. By default, the LSUnit optimistically assumes that loads do not alias; (`-noalias=true`) store operations. Under this assumption, younger loads are; always allowed to pass older stores. Essentially, the LSUnit does not attempt; to run any alias analysis to predict when loads and stores do not alias with; each other. Note that, in the case of write-combining memory, rule 3 could be relaxed to; allow reordering of non-aliasing store operations. Tha",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:39665,Performance,queue,queues,39665,"ed from the ReadySet to the IssuedSet. There,; instructions wait until they reach the write-back stage. At that point, they; get removed from the queue and the retire control unit is notified. When instructions are executed, the retire control unit flags the instruction as; ""ready to retire."". Instructions are retired in program order. The register file is notified of the; retirement so that it can free the physical registers that were allocated for; the instruction during the register renaming stage. Load/Store Unit and Memory Consistency Model; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; To simulate an out-of-order execution of memory operations, :program:`llvm-mca`; utilizes a simulated load/store unit (LSUnit) to simulate the speculative; execution of loads and stores. Each load (or store) consumes an entry in the load (or store) queue. Users can; specify flags ``-lqueue`` and ``-squeue`` to limit the number of entries in the; load and store queues respectively. The queues are unbounded by default. The LSUnit implements a relaxed consistency model for memory loads and stores.; The rules are:. 1. A younger load is allowed to pass an older load only if there are no; intervening stores or barriers between the two loads.; 2. A younger load is allowed to pass an older store provided that the load does; not alias with the store.; 3. A younger store is not allowed to pass an older store.; 4. A younger store is not allowed to pass an older load. By default, the LSUnit optimistically assumes that loads do not alias; (`-noalias=true`) store operations. Under this assumption, younger loads are; always allowed to pass older stores. Essentially, the LSUnit does not attempt; to run any alias analysis to predict when loads and stores do not alias with; each other. Note that, in the case of write-combining memory, rule 3 could be relaxed to; allow reordering of non-aliasing store operations. That being said, at the; moment, there is no way to further relax the memory model (``",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:39759,Performance,load,loads,39759,"s wait until they reach the write-back stage. At that point, they; get removed from the queue and the retire control unit is notified. When instructions are executed, the retire control unit flags the instruction as; ""ready to retire."". Instructions are retired in program order. The register file is notified of the; retirement so that it can free the physical registers that were allocated for; the instruction during the register renaming stage. Load/Store Unit and Memory Consistency Model; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; To simulate an out-of-order execution of memory operations, :program:`llvm-mca`; utilizes a simulated load/store unit (LSUnit) to simulate the speculative; execution of loads and stores. Each load (or store) consumes an entry in the load (or store) queue. Users can; specify flags ``-lqueue`` and ``-squeue`` to limit the number of entries in the; load and store queues respectively. The queues are unbounded by default. The LSUnit implements a relaxed consistency model for memory loads and stores.; The rules are:. 1. A younger load is allowed to pass an older load only if there are no; intervening stores or barriers between the two loads.; 2. A younger load is allowed to pass an older store provided that the load does; not alias with the store.; 3. A younger store is not allowed to pass an older store.; 4. A younger store is not allowed to pass an older load. By default, the LSUnit optimistically assumes that loads do not alias; (`-noalias=true`) store operations. Under this assumption, younger loads are; always allowed to pass older stores. Essentially, the LSUnit does not attempt; to run any alias analysis to predict when loads and stores do not alias with; each other. Note that, in the case of write-combining memory, rule 3 could be relaxed to; allow reordering of non-aliasing store operations. That being said, at the; moment, there is no way to further relax the memory model (``-noalias`` is the; only option). Essentially, there is no ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:39807,Performance,load,load,39807,"is notified. When instructions are executed, the retire control unit flags the instruction as; ""ready to retire."". Instructions are retired in program order. The register file is notified of the; retirement so that it can free the physical registers that were allocated for; the instruction during the register renaming stage. Load/Store Unit and Memory Consistency Model; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; To simulate an out-of-order execution of memory operations, :program:`llvm-mca`; utilizes a simulated load/store unit (LSUnit) to simulate the speculative; execution of loads and stores. Each load (or store) consumes an entry in the load (or store) queue. Users can; specify flags ``-lqueue`` and ``-squeue`` to limit the number of entries in the; load and store queues respectively. The queues are unbounded by default. The LSUnit implements a relaxed consistency model for memory loads and stores.; The rules are:. 1. A younger load is allowed to pass an older load only if there are no; intervening stores or barriers between the two loads.; 2. A younger load is allowed to pass an older store provided that the load does; not alias with the store.; 3. A younger store is not allowed to pass an older store.; 4. A younger store is not allowed to pass an older load. By default, the LSUnit optimistically assumes that loads do not alias; (`-noalias=true`) store operations. Under this assumption, younger loads are; always allowed to pass older stores. Essentially, the LSUnit does not attempt; to run any alias analysis to predict when loads and stores do not alias with; each other. Note that, in the case of write-combining memory, rule 3 could be relaxed to; allow reordering of non-aliasing store operations. That being said, at the; moment, there is no way to further relax the memory model (``-noalias`` is the; only option). Essentially, there is no option to specify a different memory; type (e.g., write-back, write-combining, write-through; etc.) and consequently; to ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:39840,Performance,load,load,39840,"is notified. When instructions are executed, the retire control unit flags the instruction as; ""ready to retire."". Instructions are retired in program order. The register file is notified of the; retirement so that it can free the physical registers that were allocated for; the instruction during the register renaming stage. Load/Store Unit and Memory Consistency Model; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; To simulate an out-of-order execution of memory operations, :program:`llvm-mca`; utilizes a simulated load/store unit (LSUnit) to simulate the speculative; execution of loads and stores. Each load (or store) consumes an entry in the load (or store) queue. Users can; specify flags ``-lqueue`` and ``-squeue`` to limit the number of entries in the; load and store queues respectively. The queues are unbounded by default. The LSUnit implements a relaxed consistency model for memory loads and stores.; The rules are:. 1. A younger load is allowed to pass an older load only if there are no; intervening stores or barriers between the two loads.; 2. A younger load is allowed to pass an older store provided that the load does; not alias with the store.; 3. A younger store is not allowed to pass an older store.; 4. A younger store is not allowed to pass an older load. By default, the LSUnit optimistically assumes that loads do not alias; (`-noalias=true`) store operations. Under this assumption, younger loads are; always allowed to pass older stores. Essentially, the LSUnit does not attempt; to run any alias analysis to predict when loads and stores do not alias with; each other. Note that, in the case of write-combining memory, rule 3 could be relaxed to; allow reordering of non-aliasing store operations. That being said, at the; moment, there is no way to further relax the memory model (``-noalias`` is the; only option). Essentially, there is no option to specify a different memory; type (e.g., write-back, write-combining, write-through; etc.) and consequently; to ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:39914,Performance,load,loads,39914,"is notified. When instructions are executed, the retire control unit flags the instruction as; ""ready to retire."". Instructions are retired in program order. The register file is notified of the; retirement so that it can free the physical registers that were allocated for; the instruction during the register renaming stage. Load/Store Unit and Memory Consistency Model; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; To simulate an out-of-order execution of memory operations, :program:`llvm-mca`; utilizes a simulated load/store unit (LSUnit) to simulate the speculative; execution of loads and stores. Each load (or store) consumes an entry in the load (or store) queue. Users can; specify flags ``-lqueue`` and ``-squeue`` to limit the number of entries in the; load and store queues respectively. The queues are unbounded by default. The LSUnit implements a relaxed consistency model for memory loads and stores.; The rules are:. 1. A younger load is allowed to pass an older load only if there are no; intervening stores or barriers between the two loads.; 2. A younger load is allowed to pass an older store provided that the load does; not alias with the store.; 3. A younger store is not allowed to pass an older store.; 4. A younger store is not allowed to pass an older load. By default, the LSUnit optimistically assumes that loads do not alias; (`-noalias=true`) store operations. Under this assumption, younger loads are; always allowed to pass older stores. Essentially, the LSUnit does not attempt; to run any alias analysis to predict when loads and stores do not alias with; each other. Note that, in the case of write-combining memory, rule 3 could be relaxed to; allow reordering of non-aliasing store operations. That being said, at the; moment, there is no way to further relax the memory model (``-noalias`` is the; only option). Essentially, there is no option to specify a different memory; type (e.g., write-back, write-combining, write-through; etc.) and consequently; to ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:39935,Performance,load,load,39935,"tructions are retired in program order. The register file is notified of the; retirement so that it can free the physical registers that were allocated for; the instruction during the register renaming stage. Load/Store Unit and Memory Consistency Model; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; To simulate an out-of-order execution of memory operations, :program:`llvm-mca`; utilizes a simulated load/store unit (LSUnit) to simulate the speculative; execution of loads and stores. Each load (or store) consumes an entry in the load (or store) queue. Users can; specify flags ``-lqueue`` and ``-squeue`` to limit the number of entries in the; load and store queues respectively. The queues are unbounded by default. The LSUnit implements a relaxed consistency model for memory loads and stores.; The rules are:. 1. A younger load is allowed to pass an older load only if there are no; intervening stores or barriers between the two loads.; 2. A younger load is allowed to pass an older store provided that the load does; not alias with the store.; 3. A younger store is not allowed to pass an older store.; 4. A younger store is not allowed to pass an older load. By default, the LSUnit optimistically assumes that loads do not alias; (`-noalias=true`) store operations. Under this assumption, younger loads are; always allowed to pass older stores. Essentially, the LSUnit does not attempt; to run any alias analysis to predict when loads and stores do not alias with; each other. Note that, in the case of write-combining memory, rule 3 could be relaxed to; allow reordering of non-aliasing store operations. That being said, at the; moment, there is no way to further relax the memory model (``-noalias`` is the; only option). Essentially, there is no option to specify a different memory; type (e.g., write-back, write-combining, write-through; etc.) and consequently; to weaken, or strengthen, the memory model. Other limitations are:. * The LSUnit does not know when store-to-load forward",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:39992,Performance,load,load,39992,"tructions are retired in program order. The register file is notified of the; retirement so that it can free the physical registers that were allocated for; the instruction during the register renaming stage. Load/Store Unit and Memory Consistency Model; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; To simulate an out-of-order execution of memory operations, :program:`llvm-mca`; utilizes a simulated load/store unit (LSUnit) to simulate the speculative; execution of loads and stores. Each load (or store) consumes an entry in the load (or store) queue. Users can; specify flags ``-lqueue`` and ``-squeue`` to limit the number of entries in the; load and store queues respectively. The queues are unbounded by default. The LSUnit implements a relaxed consistency model for memory loads and stores.; The rules are:. 1. A younger load is allowed to pass an older load only if there are no; intervening stores or barriers between the two loads.; 2. A younger load is allowed to pass an older store provided that the load does; not alias with the store.; 3. A younger store is not allowed to pass an older store.; 4. A younger store is not allowed to pass an older load. By default, the LSUnit optimistically assumes that loads do not alias; (`-noalias=true`) store operations. Under this assumption, younger loads are; always allowed to pass older stores. Essentially, the LSUnit does not attempt; to run any alias analysis to predict when loads and stores do not alias with; each other. Note that, in the case of write-combining memory, rule 3 could be relaxed to; allow reordering of non-aliasing store operations. That being said, at the; moment, there is no way to further relax the memory model (``-noalias`` is the; only option). Essentially, there is no option to specify a different memory; type (e.g., write-back, write-combining, write-through; etc.) and consequently; to weaken, or strengthen, the memory model. Other limitations are:. * The LSUnit does not know when store-to-load forward",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:40140,Performance,load,load,40140,"allocated for; the instruction during the register renaming stage. Load/Store Unit and Memory Consistency Model; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; To simulate an out-of-order execution of memory operations, :program:`llvm-mca`; utilizes a simulated load/store unit (LSUnit) to simulate the speculative; execution of loads and stores. Each load (or store) consumes an entry in the load (or store) queue. Users can; specify flags ``-lqueue`` and ``-squeue`` to limit the number of entries in the; load and store queues respectively. The queues are unbounded by default. The LSUnit implements a relaxed consistency model for memory loads and stores.; The rules are:. 1. A younger load is allowed to pass an older load only if there are no; intervening stores or barriers between the two loads.; 2. A younger load is allowed to pass an older store provided that the load does; not alias with the store.; 3. A younger store is not allowed to pass an older store.; 4. A younger store is not allowed to pass an older load. By default, the LSUnit optimistically assumes that loads do not alias; (`-noalias=true`) store operations. Under this assumption, younger loads are; always allowed to pass older stores. Essentially, the LSUnit does not attempt; to run any alias analysis to predict when loads and stores do not alias with; each other. Note that, in the case of write-combining memory, rule 3 could be relaxed to; allow reordering of non-aliasing store operations. That being said, at the; moment, there is no way to further relax the memory model (``-noalias`` is the; only option). Essentially, there is no option to specify a different memory; type (e.g., write-back, write-combining, write-through; etc.) and consequently; to weaken, or strengthen, the memory model. Other limitations are:. * The LSUnit does not know when store-to-load forwarding may occur.; * The LSUnit does not know anything about cache hierarchy and memory types.; * The LSUnit does not know how to identify serial",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:40197,Performance,load,loads,40197,"it and Memory Consistency Model; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; To simulate an out-of-order execution of memory operations, :program:`llvm-mca`; utilizes a simulated load/store unit (LSUnit) to simulate the speculative; execution of loads and stores. Each load (or store) consumes an entry in the load (or store) queue. Users can; specify flags ``-lqueue`` and ``-squeue`` to limit the number of entries in the; load and store queues respectively. The queues are unbounded by default. The LSUnit implements a relaxed consistency model for memory loads and stores.; The rules are:. 1. A younger load is allowed to pass an older load only if there are no; intervening stores or barriers between the two loads.; 2. A younger load is allowed to pass an older store provided that the load does; not alias with the store.; 3. A younger store is not allowed to pass an older store.; 4. A younger store is not allowed to pass an older load. By default, the LSUnit optimistically assumes that loads do not alias; (`-noalias=true`) store operations. Under this assumption, younger loads are; always allowed to pass older stores. Essentially, the LSUnit does not attempt; to run any alias analysis to predict when loads and stores do not alias with; each other. Note that, in the case of write-combining memory, rule 3 could be relaxed to; allow reordering of non-aliasing store operations. That being said, at the; moment, there is no way to further relax the memory model (``-noalias`` is the; only option). Essentially, there is no option to specify a different memory; type (e.g., write-back, write-combining, write-through; etc.) and consequently; to weaken, or strengthen, the memory model. Other limitations are:. * The LSUnit does not know when store-to-load forwarding may occur.; * The LSUnit does not know anything about cache hierarchy and memory types.; * The LSUnit does not know how to identify serializing operations and memory; fences. The LSUnit does not attempt to predict if a ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:40284,Performance,load,loads,40284," out-of-order execution of memory operations, :program:`llvm-mca`; utilizes a simulated load/store unit (LSUnit) to simulate the speculative; execution of loads and stores. Each load (or store) consumes an entry in the load (or store) queue. Users can; specify flags ``-lqueue`` and ``-squeue`` to limit the number of entries in the; load and store queues respectively. The queues are unbounded by default. The LSUnit implements a relaxed consistency model for memory loads and stores.; The rules are:. 1. A younger load is allowed to pass an older load only if there are no; intervening stores or barriers between the two loads.; 2. A younger load is allowed to pass an older store provided that the load does; not alias with the store.; 3. A younger store is not allowed to pass an older store.; 4. A younger store is not allowed to pass an older load. By default, the LSUnit optimistically assumes that loads do not alias; (`-noalias=true`) store operations. Under this assumption, younger loads are; always allowed to pass older stores. Essentially, the LSUnit does not attempt; to run any alias analysis to predict when loads and stores do not alias with; each other. Note that, in the case of write-combining memory, rule 3 could be relaxed to; allow reordering of non-aliasing store operations. That being said, at the; moment, there is no way to further relax the memory model (``-noalias`` is the; only option). Essentially, there is no option to specify a different memory; type (e.g., write-back, write-combining, write-through; etc.) and consequently; to weaken, or strengthen, the memory model. Other limitations are:. * The LSUnit does not know when store-to-load forwarding may occur.; * The LSUnit does not know anything about cache hierarchy and memory types.; * The LSUnit does not know how to identify serializing operations and memory; fences. The LSUnit does not attempt to predict if a load or store hits or misses the L1; cache. It only knows if an instruction ""MayLoad"" and/or ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:40416,Performance,load,loads,40416,"SUnit) to simulate the speculative; execution of loads and stores. Each load (or store) consumes an entry in the load (or store) queue. Users can; specify flags ``-lqueue`` and ``-squeue`` to limit the number of entries in the; load and store queues respectively. The queues are unbounded by default. The LSUnit implements a relaxed consistency model for memory loads and stores.; The rules are:. 1. A younger load is allowed to pass an older load only if there are no; intervening stores or barriers between the two loads.; 2. A younger load is allowed to pass an older store provided that the load does; not alias with the store.; 3. A younger store is not allowed to pass an older store.; 4. A younger store is not allowed to pass an older load. By default, the LSUnit optimistically assumes that loads do not alias; (`-noalias=true`) store operations. Under this assumption, younger loads are; always allowed to pass older stores. Essentially, the LSUnit does not attempt; to run any alias analysis to predict when loads and stores do not alias with; each other. Note that, in the case of write-combining memory, rule 3 could be relaxed to; allow reordering of non-aliasing store operations. That being said, at the; moment, there is no way to further relax the memory model (``-noalias`` is the; only option). Essentially, there is no option to specify a different memory; type (e.g., write-back, write-combining, write-through; etc.) and consequently; to weaken, or strengthen, the memory model. Other limitations are:. * The LSUnit does not know when store-to-load forwarding may occur.; * The LSUnit does not know anything about cache hierarchy and memory types.; * The LSUnit does not know how to identify serializing operations and memory; fences. The LSUnit does not attempt to predict if a load or store hits or misses the L1; cache. It only knows if an instruction ""MayLoad"" and/or ""MayStore."" For; loads, the scheduling model provides an ""optimistic"" load-to-use latency (which; usually",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:40964,Performance,load,load,40964,"ss an older store provided that the load does; not alias with the store.; 3. A younger store is not allowed to pass an older store.; 4. A younger store is not allowed to pass an older load. By default, the LSUnit optimistically assumes that loads do not alias; (`-noalias=true`) store operations. Under this assumption, younger loads are; always allowed to pass older stores. Essentially, the LSUnit does not attempt; to run any alias analysis to predict when loads and stores do not alias with; each other. Note that, in the case of write-combining memory, rule 3 could be relaxed to; allow reordering of non-aliasing store operations. That being said, at the; moment, there is no way to further relax the memory model (``-noalias`` is the; only option). Essentially, there is no option to specify a different memory; type (e.g., write-back, write-combining, write-through; etc.) and consequently; to weaken, or strengthen, the memory model. Other limitations are:. * The LSUnit does not know when store-to-load forwarding may occur.; * The LSUnit does not know anything about cache hierarchy and memory types.; * The LSUnit does not know how to identify serializing operations and memory; fences. The LSUnit does not attempt to predict if a load or store hits or misses the L1; cache. It only knows if an instruction ""MayLoad"" and/or ""MayStore."" For; loads, the scheduling model provides an ""optimistic"" load-to-use latency (which; usually matches the load-to-use latency for when there is a hit in the L1D). :program:`llvm-mca` does not (on its own) know about serializing operations or; memory-barrier like instructions. The LSUnit used to conservatively use an; instruction's ""MayLoad"", ""MayStore"", and unmodeled side effects flags to; determine whether an instruction should be treated as a memory-barrier. This was; inaccurate in general and was changed so that now each instruction has an; IsAStoreBarrier and IsALoadBarrier flag. These flags are mca specific and; default to false for every ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:41034,Performance,cache,cache,41034,"; 3. A younger store is not allowed to pass an older store.; 4. A younger store is not allowed to pass an older load. By default, the LSUnit optimistically assumes that loads do not alias; (`-noalias=true`) store operations. Under this assumption, younger loads are; always allowed to pass older stores. Essentially, the LSUnit does not attempt; to run any alias analysis to predict when loads and stores do not alias with; each other. Note that, in the case of write-combining memory, rule 3 could be relaxed to; allow reordering of non-aliasing store operations. That being said, at the; moment, there is no way to further relax the memory model (``-noalias`` is the; only option). Essentially, there is no option to specify a different memory; type (e.g., write-back, write-combining, write-through; etc.) and consequently; to weaken, or strengthen, the memory model. Other limitations are:. * The LSUnit does not know when store-to-load forwarding may occur.; * The LSUnit does not know anything about cache hierarchy and memory types.; * The LSUnit does not know how to identify serializing operations and memory; fences. The LSUnit does not attempt to predict if a load or store hits or misses the L1; cache. It only knows if an instruction ""MayLoad"" and/or ""MayStore."" For; loads, the scheduling model provides an ""optimistic"" load-to-use latency (which; usually matches the load-to-use latency for when there is a hit in the L1D). :program:`llvm-mca` does not (on its own) know about serializing operations or; memory-barrier like instructions. The LSUnit used to conservatively use an; instruction's ""MayLoad"", ""MayStore"", and unmodeled side effects flags to; determine whether an instruction should be treated as a memory-barrier. This was; inaccurate in general and was changed so that now each instruction has an; IsAStoreBarrier and IsALoadBarrier flag. These flags are mca specific and; default to false for every instruction. If any instruction should have either of; these flags set, i",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:41199,Performance,load,load,41199,"oads do not alias; (`-noalias=true`) store operations. Under this assumption, younger loads are; always allowed to pass older stores. Essentially, the LSUnit does not attempt; to run any alias analysis to predict when loads and stores do not alias with; each other. Note that, in the case of write-combining memory, rule 3 could be relaxed to; allow reordering of non-aliasing store operations. That being said, at the; moment, there is no way to further relax the memory model (``-noalias`` is the; only option). Essentially, there is no option to specify a different memory; type (e.g., write-back, write-combining, write-through; etc.) and consequently; to weaken, or strengthen, the memory model. Other limitations are:. * The LSUnit does not know when store-to-load forwarding may occur.; * The LSUnit does not know anything about cache hierarchy and memory types.; * The LSUnit does not know how to identify serializing operations and memory; fences. The LSUnit does not attempt to predict if a load or store hits or misses the L1; cache. It only knows if an instruction ""MayLoad"" and/or ""MayStore."" For; loads, the scheduling model provides an ""optimistic"" load-to-use latency (which; usually matches the load-to-use latency for when there is a hit in the L1D). :program:`llvm-mca` does not (on its own) know about serializing operations or; memory-barrier like instructions. The LSUnit used to conservatively use an; instruction's ""MayLoad"", ""MayStore"", and unmodeled side effects flags to; determine whether an instruction should be treated as a memory-barrier. This was; inaccurate in general and was changed so that now each instruction has an; IsAStoreBarrier and IsALoadBarrier flag. These flags are mca specific and; default to false for every instruction. If any instruction should have either of; these flags set, it should be done within the target's InstrPostProcess class.; For an example, look at the `X86InstrPostProcess::postProcessInstruction` method; within `llvm/lib/Target/X",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:41236,Performance,cache,cache,41236,"oads do not alias; (`-noalias=true`) store operations. Under this assumption, younger loads are; always allowed to pass older stores. Essentially, the LSUnit does not attempt; to run any alias analysis to predict when loads and stores do not alias with; each other. Note that, in the case of write-combining memory, rule 3 could be relaxed to; allow reordering of non-aliasing store operations. That being said, at the; moment, there is no way to further relax the memory model (``-noalias`` is the; only option). Essentially, there is no option to specify a different memory; type (e.g., write-back, write-combining, write-through; etc.) and consequently; to weaken, or strengthen, the memory model. Other limitations are:. * The LSUnit does not know when store-to-load forwarding may occur.; * The LSUnit does not know anything about cache hierarchy and memory types.; * The LSUnit does not know how to identify serializing operations and memory; fences. The LSUnit does not attempt to predict if a load or store hits or misses the L1; cache. It only knows if an instruction ""MayLoad"" and/or ""MayStore."" For; loads, the scheduling model provides an ""optimistic"" load-to-use latency (which; usually matches the load-to-use latency for when there is a hit in the L1D). :program:`llvm-mca` does not (on its own) know about serializing operations or; memory-barrier like instructions. The LSUnit used to conservatively use an; instruction's ""MayLoad"", ""MayStore"", and unmodeled side effects flags to; determine whether an instruction should be treated as a memory-barrier. This was; inaccurate in general and was changed so that now each instruction has an; IsAStoreBarrier and IsALoadBarrier flag. These flags are mca specific and; default to false for every instruction. If any instruction should have either of; these flags set, it should be done within the target's InstrPostProcess class.; For an example, look at the `X86InstrPostProcess::postProcessInstruction` method; within `llvm/lib/Target/X",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:41309,Performance,load,loads,41309," alias analysis to predict when loads and stores do not alias with; each other. Note that, in the case of write-combining memory, rule 3 could be relaxed to; allow reordering of non-aliasing store operations. That being said, at the; moment, there is no way to further relax the memory model (``-noalias`` is the; only option). Essentially, there is no option to specify a different memory; type (e.g., write-back, write-combining, write-through; etc.) and consequently; to weaken, or strengthen, the memory model. Other limitations are:. * The LSUnit does not know when store-to-load forwarding may occur.; * The LSUnit does not know anything about cache hierarchy and memory types.; * The LSUnit does not know how to identify serializing operations and memory; fences. The LSUnit does not attempt to predict if a load or store hits or misses the L1; cache. It only knows if an instruction ""MayLoad"" and/or ""MayStore."" For; loads, the scheduling model provides an ""optimistic"" load-to-use latency (which; usually matches the load-to-use latency for when there is a hit in the L1D). :program:`llvm-mca` does not (on its own) know about serializing operations or; memory-barrier like instructions. The LSUnit used to conservatively use an; instruction's ""MayLoad"", ""MayStore"", and unmodeled side effects flags to; determine whether an instruction should be treated as a memory-barrier. This was; inaccurate in general and was changed so that now each instruction has an; IsAStoreBarrier and IsALoadBarrier flag. These flags are mca specific and; default to false for every instruction. If any instruction should have either of; these flags set, it should be done within the target's InstrPostProcess class.; For an example, look at the `X86InstrPostProcess::postProcessInstruction` method; within `llvm/lib/Target/X86/MCA/X86CustomBehaviour.cpp`. A load/store barrier consumes one entry of the load/store queue. A load/store; barrier enforces ordering of loads/stores. A younger load cannot pass a loa",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:41362,Performance,load,load-to-use,41362," alias analysis to predict when loads and stores do not alias with; each other. Note that, in the case of write-combining memory, rule 3 could be relaxed to; allow reordering of non-aliasing store operations. That being said, at the; moment, there is no way to further relax the memory model (``-noalias`` is the; only option). Essentially, there is no option to specify a different memory; type (e.g., write-back, write-combining, write-through; etc.) and consequently; to weaken, or strengthen, the memory model. Other limitations are:. * The LSUnit does not know when store-to-load forwarding may occur.; * The LSUnit does not know anything about cache hierarchy and memory types.; * The LSUnit does not know how to identify serializing operations and memory; fences. The LSUnit does not attempt to predict if a load or store hits or misses the L1; cache. It only knows if an instruction ""MayLoad"" and/or ""MayStore."" For; loads, the scheduling model provides an ""optimistic"" load-to-use latency (which; usually matches the load-to-use latency for when there is a hit in the L1D). :program:`llvm-mca` does not (on its own) know about serializing operations or; memory-barrier like instructions. The LSUnit used to conservatively use an; instruction's ""MayLoad"", ""MayStore"", and unmodeled side effects flags to; determine whether an instruction should be treated as a memory-barrier. This was; inaccurate in general and was changed so that now each instruction has an; IsAStoreBarrier and IsALoadBarrier flag. These flags are mca specific and; default to false for every instruction. If any instruction should have either of; these flags set, it should be done within the target's InstrPostProcess class.; For an example, look at the `X86InstrPostProcess::postProcessInstruction` method; within `llvm/lib/Target/X86/MCA/X86CustomBehaviour.cpp`. A load/store barrier consumes one entry of the load/store queue. A load/store; barrier enforces ordering of loads/stores. A younger load cannot pass a loa",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:41374,Performance,latency,latency,41374," alias analysis to predict when loads and stores do not alias with; each other. Note that, in the case of write-combining memory, rule 3 could be relaxed to; allow reordering of non-aliasing store operations. That being said, at the; moment, there is no way to further relax the memory model (``-noalias`` is the; only option). Essentially, there is no option to specify a different memory; type (e.g., write-back, write-combining, write-through; etc.) and consequently; to weaken, or strengthen, the memory model. Other limitations are:. * The LSUnit does not know when store-to-load forwarding may occur.; * The LSUnit does not know anything about cache hierarchy and memory types.; * The LSUnit does not know how to identify serializing operations and memory; fences. The LSUnit does not attempt to predict if a load or store hits or misses the L1; cache. It only knows if an instruction ""MayLoad"" and/or ""MayStore."" For; loads, the scheduling model provides an ""optimistic"" load-to-use latency (which; usually matches the load-to-use latency for when there is a hit in the L1D). :program:`llvm-mca` does not (on its own) know about serializing operations or; memory-barrier like instructions. The LSUnit used to conservatively use an; instruction's ""MayLoad"", ""MayStore"", and unmodeled side effects flags to; determine whether an instruction should be treated as a memory-barrier. This was; inaccurate in general and was changed so that now each instruction has an; IsAStoreBarrier and IsALoadBarrier flag. These flags are mca specific and; default to false for every instruction. If any instruction should have either of; these flags set, it should be done within the target's InstrPostProcess class.; For an example, look at the `X86InstrPostProcess::postProcessInstruction` method; within `llvm/lib/Target/X86/MCA/X86CustomBehaviour.cpp`. A load/store barrier consumes one entry of the load/store queue. A load/store; barrier enforces ordering of loads/stores. A younger load cannot pass a loa",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:41410,Performance,load,load-to-use,41410," alias analysis to predict when loads and stores do not alias with; each other. Note that, in the case of write-combining memory, rule 3 could be relaxed to; allow reordering of non-aliasing store operations. That being said, at the; moment, there is no way to further relax the memory model (``-noalias`` is the; only option). Essentially, there is no option to specify a different memory; type (e.g., write-back, write-combining, write-through; etc.) and consequently; to weaken, or strengthen, the memory model. Other limitations are:. * The LSUnit does not know when store-to-load forwarding may occur.; * The LSUnit does not know anything about cache hierarchy and memory types.; * The LSUnit does not know how to identify serializing operations and memory; fences. The LSUnit does not attempt to predict if a load or store hits or misses the L1; cache. It only knows if an instruction ""MayLoad"" and/or ""MayStore."" For; loads, the scheduling model provides an ""optimistic"" load-to-use latency (which; usually matches the load-to-use latency for when there is a hit in the L1D). :program:`llvm-mca` does not (on its own) know about serializing operations or; memory-barrier like instructions. The LSUnit used to conservatively use an; instruction's ""MayLoad"", ""MayStore"", and unmodeled side effects flags to; determine whether an instruction should be treated as a memory-barrier. This was; inaccurate in general and was changed so that now each instruction has an; IsAStoreBarrier and IsALoadBarrier flag. These flags are mca specific and; default to false for every instruction. If any instruction should have either of; these flags set, it should be done within the target's InstrPostProcess class.; For an example, look at the `X86InstrPostProcess::postProcessInstruction` method; within `llvm/lib/Target/X86/MCA/X86CustomBehaviour.cpp`. A load/store barrier consumes one entry of the load/store queue. A load/store; barrier enforces ordering of loads/stores. A younger load cannot pass a loa",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:41422,Performance,latency,latency,41422," alias analysis to predict when loads and stores do not alias with; each other. Note that, in the case of write-combining memory, rule 3 could be relaxed to; allow reordering of non-aliasing store operations. That being said, at the; moment, there is no way to further relax the memory model (``-noalias`` is the; only option). Essentially, there is no option to specify a different memory; type (e.g., write-back, write-combining, write-through; etc.) and consequently; to weaken, or strengthen, the memory model. Other limitations are:. * The LSUnit does not know when store-to-load forwarding may occur.; * The LSUnit does not know anything about cache hierarchy and memory types.; * The LSUnit does not know how to identify serializing operations and memory; fences. The LSUnit does not attempt to predict if a load or store hits or misses the L1; cache. It only knows if an instruction ""MayLoad"" and/or ""MayStore."" For; loads, the scheduling model provides an ""optimistic"" load-to-use latency (which; usually matches the load-to-use latency for when there is a hit in the L1D). :program:`llvm-mca` does not (on its own) know about serializing operations or; memory-barrier like instructions. The LSUnit used to conservatively use an; instruction's ""MayLoad"", ""MayStore"", and unmodeled side effects flags to; determine whether an instruction should be treated as a memory-barrier. This was; inaccurate in general and was changed so that now each instruction has an; IsAStoreBarrier and IsALoadBarrier flag. These flags are mca specific and; default to false for every instruction. If any instruction should have either of; these flags set, it should be done within the target's InstrPostProcess class.; For an example, look at the `X86InstrPostProcess::postProcessInstruction` method; within `llvm/lib/Target/X86/MCA/X86CustomBehaviour.cpp`. A load/store barrier consumes one entry of the load/store queue. A load/store; barrier enforces ordering of loads/stores. A younger load cannot pass a loa",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:42232,Performance,load,load,42232,"n instruction ""MayLoad"" and/or ""MayStore."" For; loads, the scheduling model provides an ""optimistic"" load-to-use latency (which; usually matches the load-to-use latency for when there is a hit in the L1D). :program:`llvm-mca` does not (on its own) know about serializing operations or; memory-barrier like instructions. The LSUnit used to conservatively use an; instruction's ""MayLoad"", ""MayStore"", and unmodeled side effects flags to; determine whether an instruction should be treated as a memory-barrier. This was; inaccurate in general and was changed so that now each instruction has an; IsAStoreBarrier and IsALoadBarrier flag. These flags are mca specific and; default to false for every instruction. If any instruction should have either of; these flags set, it should be done within the target's InstrPostProcess class.; For an example, look at the `X86InstrPostProcess::postProcessInstruction` method; within `llvm/lib/Target/X86/MCA/X86CustomBehaviour.cpp`. A load/store barrier consumes one entry of the load/store queue. A load/store; barrier enforces ordering of loads/stores. A younger load cannot pass a load; barrier. Also, a younger store cannot pass a store barrier. A younger load; has to wait for the memory/load barrier to execute. A load/store barrier is; ""executed"" when it becomes the oldest entry in the load/store queue(s). That; also means, by construction, all of the older loads/stores have been executed. In conclusion, the full set of load/store consistency rules are:. #. A store may not pass a previous store.; #. A store may not pass a previous load (regardless of ``-noalias``).; #. A store has to wait until an older store barrier is fully executed.; #. A load may pass a previous load.; #. A load may not pass a previous store unless ``-noalias`` is set.; #. A load has to wait until an older load barrier is fully executed. In-order Issue and Execute; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; In-order processors are modelled as a single ``InOrderIssueStage`` stage",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:42277,Performance,load,load,42277,"n instruction ""MayLoad"" and/or ""MayStore."" For; loads, the scheduling model provides an ""optimistic"" load-to-use latency (which; usually matches the load-to-use latency for when there is a hit in the L1D). :program:`llvm-mca` does not (on its own) know about serializing operations or; memory-barrier like instructions. The LSUnit used to conservatively use an; instruction's ""MayLoad"", ""MayStore"", and unmodeled side effects flags to; determine whether an instruction should be treated as a memory-barrier. This was; inaccurate in general and was changed so that now each instruction has an; IsAStoreBarrier and IsALoadBarrier flag. These flags are mca specific and; default to false for every instruction. If any instruction should have either of; these flags set, it should be done within the target's InstrPostProcess class.; For an example, look at the `X86InstrPostProcess::postProcessInstruction` method; within `llvm/lib/Target/X86/MCA/X86CustomBehaviour.cpp`. A load/store barrier consumes one entry of the load/store queue. A load/store; barrier enforces ordering of loads/stores. A younger load cannot pass a load; barrier. Also, a younger store cannot pass a store barrier. A younger load; has to wait for the memory/load barrier to execute. A load/store barrier is; ""executed"" when it becomes the oldest entry in the load/store queue(s). That; also means, by construction, all of the older loads/stores have been executed. In conclusion, the full set of load/store consistency rules are:. #. A store may not pass a previous store.; #. A store may not pass a previous load (regardless of ``-noalias``).; #. A store has to wait until an older store barrier is fully executed.; #. A load may pass a previous load.; #. A load may not pass a previous store unless ``-noalias`` is set.; #. A load has to wait until an older load barrier is fully executed. In-order Issue and Execute; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; In-order processors are modelled as a single ``InOrderIssueStage`` stage",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:42288,Performance,queue,queue,42288,"n instruction ""MayLoad"" and/or ""MayStore."" For; loads, the scheduling model provides an ""optimistic"" load-to-use latency (which; usually matches the load-to-use latency for when there is a hit in the L1D). :program:`llvm-mca` does not (on its own) know about serializing operations or; memory-barrier like instructions. The LSUnit used to conservatively use an; instruction's ""MayLoad"", ""MayStore"", and unmodeled side effects flags to; determine whether an instruction should be treated as a memory-barrier. This was; inaccurate in general and was changed so that now each instruction has an; IsAStoreBarrier and IsALoadBarrier flag. These flags are mca specific and; default to false for every instruction. If any instruction should have either of; these flags set, it should be done within the target's InstrPostProcess class.; For an example, look at the `X86InstrPostProcess::postProcessInstruction` method; within `llvm/lib/Target/X86/MCA/X86CustomBehaviour.cpp`. A load/store barrier consumes one entry of the load/store queue. A load/store; barrier enforces ordering of loads/stores. A younger load cannot pass a load; barrier. Also, a younger store cannot pass a store barrier. A younger load; has to wait for the memory/load barrier to execute. A load/store barrier is; ""executed"" when it becomes the oldest entry in the load/store queue(s). That; also means, by construction, all of the older loads/stores have been executed. In conclusion, the full set of load/store consistency rules are:. #. A store may not pass a previous store.; #. A store may not pass a previous load (regardless of ``-noalias``).; #. A store has to wait until an older store barrier is fully executed.; #. A load may pass a previous load.; #. A load may not pass a previous store unless ``-noalias`` is set.; #. A load has to wait until an older load barrier is fully executed. In-order Issue and Execute; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; In-order processors are modelled as a single ``InOrderIssueStage`` stage",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:42297,Performance,load,load,42297,"heduling model provides an ""optimistic"" load-to-use latency (which; usually matches the load-to-use latency for when there is a hit in the L1D). :program:`llvm-mca` does not (on its own) know about serializing operations or; memory-barrier like instructions. The LSUnit used to conservatively use an; instruction's ""MayLoad"", ""MayStore"", and unmodeled side effects flags to; determine whether an instruction should be treated as a memory-barrier. This was; inaccurate in general and was changed so that now each instruction has an; IsAStoreBarrier and IsALoadBarrier flag. These flags are mca specific and; default to false for every instruction. If any instruction should have either of; these flags set, it should be done within the target's InstrPostProcess class.; For an example, look at the `X86InstrPostProcess::postProcessInstruction` method; within `llvm/lib/Target/X86/MCA/X86CustomBehaviour.cpp`. A load/store barrier consumes one entry of the load/store queue. A load/store; barrier enforces ordering of loads/stores. A younger load cannot pass a load; barrier. Also, a younger store cannot pass a store barrier. A younger load; has to wait for the memory/load barrier to execute. A load/store barrier is; ""executed"" when it becomes the oldest entry in the load/store queue(s). That; also means, by construction, all of the older loads/stores have been executed. In conclusion, the full set of load/store consistency rules are:. #. A store may not pass a previous store.; #. A store may not pass a previous load (regardless of ``-noalias``).; #. A store has to wait until an older store barrier is fully executed.; #. A load may pass a previous load.; #. A load may not pass a previous store unless ``-noalias`` is set.; #. A load has to wait until an older load barrier is fully executed. In-order Issue and Execute; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; In-order processors are modelled as a single ``InOrderIssueStage`` stage. It; bypasses Dispatch, Scheduler and Load/Store unit. Instr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:42338,Performance,load,loads,42338,"heduling model provides an ""optimistic"" load-to-use latency (which; usually matches the load-to-use latency for when there is a hit in the L1D). :program:`llvm-mca` does not (on its own) know about serializing operations or; memory-barrier like instructions. The LSUnit used to conservatively use an; instruction's ""MayLoad"", ""MayStore"", and unmodeled side effects flags to; determine whether an instruction should be treated as a memory-barrier. This was; inaccurate in general and was changed so that now each instruction has an; IsAStoreBarrier and IsALoadBarrier flag. These flags are mca specific and; default to false for every instruction. If any instruction should have either of; these flags set, it should be done within the target's InstrPostProcess class.; For an example, look at the `X86InstrPostProcess::postProcessInstruction` method; within `llvm/lib/Target/X86/MCA/X86CustomBehaviour.cpp`. A load/store barrier consumes one entry of the load/store queue. A load/store; barrier enforces ordering of loads/stores. A younger load cannot pass a load; barrier. Also, a younger store cannot pass a store barrier. A younger load; has to wait for the memory/load barrier to execute. A load/store barrier is; ""executed"" when it becomes the oldest entry in the load/store queue(s). That; also means, by construction, all of the older loads/stores have been executed. In conclusion, the full set of load/store consistency rules are:. #. A store may not pass a previous store.; #. A store may not pass a previous load (regardless of ``-noalias``).; #. A store has to wait until an older store barrier is fully executed.; #. A load may pass a previous load.; #. A load may not pass a previous store unless ``-noalias`` is set.; #. A load has to wait until an older load barrier is fully executed. In-order Issue and Execute; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; In-order processors are modelled as a single ``InOrderIssueStage`` stage. It; bypasses Dispatch, Scheduler and Load/Store unit. Instr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:42362,Performance,load,load,42362," latency (which; usually matches the load-to-use latency for when there is a hit in the L1D). :program:`llvm-mca` does not (on its own) know about serializing operations or; memory-barrier like instructions. The LSUnit used to conservatively use an; instruction's ""MayLoad"", ""MayStore"", and unmodeled side effects flags to; determine whether an instruction should be treated as a memory-barrier. This was; inaccurate in general and was changed so that now each instruction has an; IsAStoreBarrier and IsALoadBarrier flag. These flags are mca specific and; default to false for every instruction. If any instruction should have either of; these flags set, it should be done within the target's InstrPostProcess class.; For an example, look at the `X86InstrPostProcess::postProcessInstruction` method; within `llvm/lib/Target/X86/MCA/X86CustomBehaviour.cpp`. A load/store barrier consumes one entry of the load/store queue. A load/store; barrier enforces ordering of loads/stores. A younger load cannot pass a load; barrier. Also, a younger store cannot pass a store barrier. A younger load; has to wait for the memory/load barrier to execute. A load/store barrier is; ""executed"" when it becomes the oldest entry in the load/store queue(s). That; also means, by construction, all of the older loads/stores have been executed. In conclusion, the full set of load/store consistency rules are:. #. A store may not pass a previous store.; #. A store may not pass a previous load (regardless of ``-noalias``).; #. A store has to wait until an older store barrier is fully executed.; #. A load may pass a previous load.; #. A load may not pass a previous store unless ``-noalias`` is set.; #. A load has to wait until an older load barrier is fully executed. In-order Issue and Execute; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; In-order processors are modelled as a single ``InOrderIssueStage`` stage. It; bypasses Dispatch, Scheduler and Load/Store unit. Instructions are issued as; soon as their operand regis",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:42381,Performance,load,load,42381," latency (which; usually matches the load-to-use latency for when there is a hit in the L1D). :program:`llvm-mca` does not (on its own) know about serializing operations or; memory-barrier like instructions. The LSUnit used to conservatively use an; instruction's ""MayLoad"", ""MayStore"", and unmodeled side effects flags to; determine whether an instruction should be treated as a memory-barrier. This was; inaccurate in general and was changed so that now each instruction has an; IsAStoreBarrier and IsALoadBarrier flag. These flags are mca specific and; default to false for every instruction. If any instruction should have either of; these flags set, it should be done within the target's InstrPostProcess class.; For an example, look at the `X86InstrPostProcess::postProcessInstruction` method; within `llvm/lib/Target/X86/MCA/X86CustomBehaviour.cpp`. A load/store barrier consumes one entry of the load/store queue. A load/store; barrier enforces ordering of loads/stores. A younger load cannot pass a load; barrier. Also, a younger store cannot pass a store barrier. A younger load; has to wait for the memory/load barrier to execute. A load/store barrier is; ""executed"" when it becomes the oldest entry in the load/store queue(s). That; also means, by construction, all of the older loads/stores have been executed. In conclusion, the full set of load/store consistency rules are:. #. A store may not pass a previous store.; #. A store may not pass a previous load (regardless of ``-noalias``).; #. A store has to wait until an older store barrier is fully executed.; #. A load may pass a previous load.; #. A load may not pass a previous store unless ``-noalias`` is set.; #. A load has to wait until an older load barrier is fully executed. In-order Issue and Execute; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; In-order processors are modelled as a single ``InOrderIssueStage`` stage. It; bypasses Dispatch, Scheduler and Load/Store unit. Instructions are issued as; soon as their operand regis",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:42457,Performance,load,load,42457,"m-mca` does not (on its own) know about serializing operations or; memory-barrier like instructions. The LSUnit used to conservatively use an; instruction's ""MayLoad"", ""MayStore"", and unmodeled side effects flags to; determine whether an instruction should be treated as a memory-barrier. This was; inaccurate in general and was changed so that now each instruction has an; IsAStoreBarrier and IsALoadBarrier flag. These flags are mca specific and; default to false for every instruction. If any instruction should have either of; these flags set, it should be done within the target's InstrPostProcess class.; For an example, look at the `X86InstrPostProcess::postProcessInstruction` method; within `llvm/lib/Target/X86/MCA/X86CustomBehaviour.cpp`. A load/store barrier consumes one entry of the load/store queue. A load/store; barrier enforces ordering of loads/stores. A younger load cannot pass a load; barrier. Also, a younger store cannot pass a store barrier. A younger load; has to wait for the memory/load barrier to execute. A load/store barrier is; ""executed"" when it becomes the oldest entry in the load/store queue(s). That; also means, by construction, all of the older loads/stores have been executed. In conclusion, the full set of load/store consistency rules are:. #. A store may not pass a previous store.; #. A store may not pass a previous load (regardless of ``-noalias``).; #. A store has to wait until an older store barrier is fully executed.; #. A load may pass a previous load.; #. A load may not pass a previous store unless ``-noalias`` is set.; #. A load has to wait until an older load barrier is fully executed. In-order Issue and Execute; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; In-order processors are modelled as a single ``InOrderIssueStage`` stage. It; bypasses Dispatch, Scheduler and Load/Store unit. Instructions are issued as; soon as their operand registers are available and resource requirements are; met. Multiple instructions can be issued in one cycle acc",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:42490,Performance,load,load,42490,"m-mca` does not (on its own) know about serializing operations or; memory-barrier like instructions. The LSUnit used to conservatively use an; instruction's ""MayLoad"", ""MayStore"", and unmodeled side effects flags to; determine whether an instruction should be treated as a memory-barrier. This was; inaccurate in general and was changed so that now each instruction has an; IsAStoreBarrier and IsALoadBarrier flag. These flags are mca specific and; default to false for every instruction. If any instruction should have either of; these flags set, it should be done within the target's InstrPostProcess class.; For an example, look at the `X86InstrPostProcess::postProcessInstruction` method; within `llvm/lib/Target/X86/MCA/X86CustomBehaviour.cpp`. A load/store barrier consumes one entry of the load/store queue. A load/store; barrier enforces ordering of loads/stores. A younger load cannot pass a load; barrier. Also, a younger store cannot pass a store barrier. A younger load; has to wait for the memory/load barrier to execute. A load/store barrier is; ""executed"" when it becomes the oldest entry in the load/store queue(s). That; also means, by construction, all of the older loads/stores have been executed. In conclusion, the full set of load/store consistency rules are:. #. A store may not pass a previous store.; #. A store may not pass a previous load (regardless of ``-noalias``).; #. A store has to wait until an older store barrier is fully executed.; #. A load may pass a previous load.; #. A load may not pass a previous store unless ``-noalias`` is set.; #. A load has to wait until an older load barrier is fully executed. In-order Issue and Execute; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; In-order processors are modelled as a single ``InOrderIssueStage`` stage. It; bypasses Dispatch, Scheduler and Load/Store unit. Instructions are issued as; soon as their operand registers are available and resource requirements are; met. Multiple instructions can be issued in one cycle acc",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:42517,Performance,load,load,42517,"like instructions. The LSUnit used to conservatively use an; instruction's ""MayLoad"", ""MayStore"", and unmodeled side effects flags to; determine whether an instruction should be treated as a memory-barrier. This was; inaccurate in general and was changed so that now each instruction has an; IsAStoreBarrier and IsALoadBarrier flag. These flags are mca specific and; default to false for every instruction. If any instruction should have either of; these flags set, it should be done within the target's InstrPostProcess class.; For an example, look at the `X86InstrPostProcess::postProcessInstruction` method; within `llvm/lib/Target/X86/MCA/X86CustomBehaviour.cpp`. A load/store barrier consumes one entry of the load/store queue. A load/store; barrier enforces ordering of loads/stores. A younger load cannot pass a load; barrier. Also, a younger store cannot pass a store barrier. A younger load; has to wait for the memory/load barrier to execute. A load/store barrier is; ""executed"" when it becomes the oldest entry in the load/store queue(s). That; also means, by construction, all of the older loads/stores have been executed. In conclusion, the full set of load/store consistency rules are:. #. A store may not pass a previous store.; #. A store may not pass a previous load (regardless of ``-noalias``).; #. A store has to wait until an older store barrier is fully executed.; #. A load may pass a previous load.; #. A load may not pass a previous store unless ``-noalias`` is set.; #. A load has to wait until an older load barrier is fully executed. In-order Issue and Execute; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; In-order processors are modelled as a single ``InOrderIssueStage`` stage. It; bypasses Dispatch, Scheduler and Load/Store unit. Instructions are issued as; soon as their operand registers are available and resource requirements are; met. Multiple instructions can be issued in one cycle according to the value of; the ``IssueWidth`` parameter in LLVM's scheduling model. On",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:42591,Performance,load,load,42591,"like instructions. The LSUnit used to conservatively use an; instruction's ""MayLoad"", ""MayStore"", and unmodeled side effects flags to; determine whether an instruction should be treated as a memory-barrier. This was; inaccurate in general and was changed so that now each instruction has an; IsAStoreBarrier and IsALoadBarrier flag. These flags are mca specific and; default to false for every instruction. If any instruction should have either of; these flags set, it should be done within the target's InstrPostProcess class.; For an example, look at the `X86InstrPostProcess::postProcessInstruction` method; within `llvm/lib/Target/X86/MCA/X86CustomBehaviour.cpp`. A load/store barrier consumes one entry of the load/store queue. A load/store; barrier enforces ordering of loads/stores. A younger load cannot pass a load; barrier. Also, a younger store cannot pass a store barrier. A younger load; has to wait for the memory/load barrier to execute. A load/store barrier is; ""executed"" when it becomes the oldest entry in the load/store queue(s). That; also means, by construction, all of the older loads/stores have been executed. In conclusion, the full set of load/store consistency rules are:. #. A store may not pass a previous store.; #. A store may not pass a previous load (regardless of ``-noalias``).; #. A store has to wait until an older store barrier is fully executed.; #. A load may pass a previous load.; #. A load may not pass a previous store unless ``-noalias`` is set.; #. A load has to wait until an older load barrier is fully executed. In-order Issue and Execute; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; In-order processors are modelled as a single ``InOrderIssueStage`` stage. It; bypasses Dispatch, Scheduler and Load/Store unit. Instructions are issued as; soon as their operand registers are available and resource requirements are; met. Multiple instructions can be issued in one cycle according to the value of; the ``IssueWidth`` parameter in LLVM's scheduling model. On",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:42602,Performance,queue,queue,42602,"like instructions. The LSUnit used to conservatively use an; instruction's ""MayLoad"", ""MayStore"", and unmodeled side effects flags to; determine whether an instruction should be treated as a memory-barrier. This was; inaccurate in general and was changed so that now each instruction has an; IsAStoreBarrier and IsALoadBarrier flag. These flags are mca specific and; default to false for every instruction. If any instruction should have either of; these flags set, it should be done within the target's InstrPostProcess class.; For an example, look at the `X86InstrPostProcess::postProcessInstruction` method; within `llvm/lib/Target/X86/MCA/X86CustomBehaviour.cpp`. A load/store barrier consumes one entry of the load/store queue. A load/store; barrier enforces ordering of loads/stores. A younger load cannot pass a load; barrier. Also, a younger store cannot pass a store barrier. A younger load; has to wait for the memory/load barrier to execute. A load/store barrier is; ""executed"" when it becomes the oldest entry in the load/store queue(s). That; also means, by construction, all of the older loads/stores have been executed. In conclusion, the full set of load/store consistency rules are:. #. A store may not pass a previous store.; #. A store may not pass a previous load (regardless of ``-noalias``).; #. A store has to wait until an older store barrier is fully executed.; #. A load may pass a previous load.; #. A load may not pass a previous store unless ``-noalias`` is set.; #. A load has to wait until an older load barrier is fully executed. In-order Issue and Execute; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; In-order processors are modelled as a single ``InOrderIssueStage`` stage. It; bypasses Dispatch, Scheduler and Load/Store unit. Instructions are issued as; soon as their operand registers are available and resource requirements are; met. Multiple instructions can be issued in one cycle according to the value of; the ``IssueWidth`` parameter in LLVM's scheduling model. On",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:42664,Performance,load,loads,42664,"tore"", and unmodeled side effects flags to; determine whether an instruction should be treated as a memory-barrier. This was; inaccurate in general and was changed so that now each instruction has an; IsAStoreBarrier and IsALoadBarrier flag. These flags are mca specific and; default to false for every instruction. If any instruction should have either of; these flags set, it should be done within the target's InstrPostProcess class.; For an example, look at the `X86InstrPostProcess::postProcessInstruction` method; within `llvm/lib/Target/X86/MCA/X86CustomBehaviour.cpp`. A load/store barrier consumes one entry of the load/store queue. A load/store; barrier enforces ordering of loads/stores. A younger load cannot pass a load; barrier. Also, a younger store cannot pass a store barrier. A younger load; has to wait for the memory/load barrier to execute. A load/store barrier is; ""executed"" when it becomes the oldest entry in the load/store queue(s). That; also means, by construction, all of the older loads/stores have been executed. In conclusion, the full set of load/store consistency rules are:. #. A store may not pass a previous store.; #. A store may not pass a previous load (regardless of ``-noalias``).; #. A store has to wait until an older store barrier is fully executed.; #. A load may pass a previous load.; #. A load may not pass a previous store unless ``-noalias`` is set.; #. A load has to wait until an older load barrier is fully executed. In-order Issue and Execute; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; In-order processors are modelled as a single ``InOrderIssueStage`` stage. It; bypasses Dispatch, Scheduler and Load/Store unit. Instructions are issued as; soon as their operand registers are available and resource requirements are; met. Multiple instructions can be issued in one cycle according to the value of; the ``IssueWidth`` parameter in LLVM's scheduling model. Once issued, an instruction is moved to ``IssuedInst`` set until it is ready to; retire. :pro",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:42728,Performance,load,load,42728," should be treated as a memory-barrier. This was; inaccurate in general and was changed so that now each instruction has an; IsAStoreBarrier and IsALoadBarrier flag. These flags are mca specific and; default to false for every instruction. If any instruction should have either of; these flags set, it should be done within the target's InstrPostProcess class.; For an example, look at the `X86InstrPostProcess::postProcessInstruction` method; within `llvm/lib/Target/X86/MCA/X86CustomBehaviour.cpp`. A load/store barrier consumes one entry of the load/store queue. A load/store; barrier enforces ordering of loads/stores. A younger load cannot pass a load; barrier. Also, a younger store cannot pass a store barrier. A younger load; has to wait for the memory/load barrier to execute. A load/store barrier is; ""executed"" when it becomes the oldest entry in the load/store queue(s). That; also means, by construction, all of the older loads/stores have been executed. In conclusion, the full set of load/store consistency rules are:. #. A store may not pass a previous store.; #. A store may not pass a previous load (regardless of ``-noalias``).; #. A store has to wait until an older store barrier is fully executed.; #. A load may pass a previous load.; #. A load may not pass a previous store unless ``-noalias`` is set.; #. A load has to wait until an older load barrier is fully executed. In-order Issue and Execute; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; In-order processors are modelled as a single ``InOrderIssueStage`` stage. It; bypasses Dispatch, Scheduler and Load/Store unit. Instructions are issued as; soon as their operand registers are available and resource requirements are; met. Multiple instructions can be issued in one cycle according to the value of; the ``IssueWidth`` parameter in LLVM's scheduling model. Once issued, an instruction is moved to ``IssuedInst`` set until it is ready to; retire. :program:`llvm-mca` ensures that writes are committed in-order. However,; an in",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:42841,Performance,load,load,42841,"tion has an; IsAStoreBarrier and IsALoadBarrier flag. These flags are mca specific and; default to false for every instruction. If any instruction should have either of; these flags set, it should be done within the target's InstrPostProcess class.; For an example, look at the `X86InstrPostProcess::postProcessInstruction` method; within `llvm/lib/Target/X86/MCA/X86CustomBehaviour.cpp`. A load/store barrier consumes one entry of the load/store queue. A load/store; barrier enforces ordering of loads/stores. A younger load cannot pass a load; barrier. Also, a younger store cannot pass a store barrier. A younger load; has to wait for the memory/load barrier to execute. A load/store barrier is; ""executed"" when it becomes the oldest entry in the load/store queue(s). That; also means, by construction, all of the older loads/stores have been executed. In conclusion, the full set of load/store consistency rules are:. #. A store may not pass a previous store.; #. A store may not pass a previous load (regardless of ``-noalias``).; #. A store has to wait until an older store barrier is fully executed.; #. A load may pass a previous load.; #. A load may not pass a previous store unless ``-noalias`` is set.; #. A load has to wait until an older load barrier is fully executed. In-order Issue and Execute; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; In-order processors are modelled as a single ``InOrderIssueStage`` stage. It; bypasses Dispatch, Scheduler and Load/Store unit. Instructions are issued as; soon as their operand registers are available and resource requirements are; met. Multiple instructions can be issued in one cycle according to the value of; the ``IssueWidth`` parameter in LLVM's scheduling model. Once issued, an instruction is moved to ``IssuedInst`` set until it is ready to; retire. :program:`llvm-mca` ensures that writes are committed in-order. However,; an instruction is allowed to commit writes and retire out-of-order if; ``RetireOOO`` property is true for at least one",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:42954,Performance,load,load,42954,". If any instruction should have either of; these flags set, it should be done within the target's InstrPostProcess class.; For an example, look at the `X86InstrPostProcess::postProcessInstruction` method; within `llvm/lib/Target/X86/MCA/X86CustomBehaviour.cpp`. A load/store barrier consumes one entry of the load/store queue. A load/store; barrier enforces ordering of loads/stores. A younger load cannot pass a load; barrier. Also, a younger store cannot pass a store barrier. A younger load; has to wait for the memory/load barrier to execute. A load/store barrier is; ""executed"" when it becomes the oldest entry in the load/store queue(s). That; also means, by construction, all of the older loads/stores have been executed. In conclusion, the full set of load/store consistency rules are:. #. A store may not pass a previous store.; #. A store may not pass a previous load (regardless of ``-noalias``).; #. A store has to wait until an older store barrier is fully executed.; #. A load may pass a previous load.; #. A load may not pass a previous store unless ``-noalias`` is set.; #. A load has to wait until an older load barrier is fully executed. In-order Issue and Execute; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; In-order processors are modelled as a single ``InOrderIssueStage`` stage. It; bypasses Dispatch, Scheduler and Load/Store unit. Instructions are issued as; soon as their operand registers are available and resource requirements are; met. Multiple instructions can be issued in one cycle according to the value of; the ``IssueWidth`` parameter in LLVM's scheduling model. Once issued, an instruction is moved to ``IssuedInst`` set until it is ready to; retire. :program:`llvm-mca` ensures that writes are committed in-order. However,; an instruction is allowed to commit writes and retire out-of-order if; ``RetireOOO`` property is true for at least one of its writes. Custom Behaviour; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; Due to certain instructions not being expressed perfec",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:42979,Performance,load,load,42979,". If any instruction should have either of; these flags set, it should be done within the target's InstrPostProcess class.; For an example, look at the `X86InstrPostProcess::postProcessInstruction` method; within `llvm/lib/Target/X86/MCA/X86CustomBehaviour.cpp`. A load/store barrier consumes one entry of the load/store queue. A load/store; barrier enforces ordering of loads/stores. A younger load cannot pass a load; barrier. Also, a younger store cannot pass a store barrier. A younger load; has to wait for the memory/load barrier to execute. A load/store barrier is; ""executed"" when it becomes the oldest entry in the load/store queue(s). That; also means, by construction, all of the older loads/stores have been executed. In conclusion, the full set of load/store consistency rules are:. #. A store may not pass a previous store.; #. A store may not pass a previous load (regardless of ``-noalias``).; #. A store has to wait until an older store barrier is fully executed.; #. A load may pass a previous load.; #. A load may not pass a previous store unless ``-noalias`` is set.; #. A load has to wait until an older load barrier is fully executed. In-order Issue and Execute; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; In-order processors are modelled as a single ``InOrderIssueStage`` stage. It; bypasses Dispatch, Scheduler and Load/Store unit. Instructions are issued as; soon as their operand registers are available and resource requirements are; met. Multiple instructions can be issued in one cycle according to the value of; the ``IssueWidth`` parameter in LLVM's scheduling model. Once issued, an instruction is moved to ``IssuedInst`` set until it is ready to; retire. :program:`llvm-mca` ensures that writes are committed in-order. However,; an instruction is allowed to commit writes and retire out-of-order if; ``RetireOOO`` property is true for at least one of its writes. Custom Behaviour; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; Due to certain instructions not being expressed perfec",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:42991,Performance,load,load,42991,"gs set, it should be done within the target's InstrPostProcess class.; For an example, look at the `X86InstrPostProcess::postProcessInstruction` method; within `llvm/lib/Target/X86/MCA/X86CustomBehaviour.cpp`. A load/store barrier consumes one entry of the load/store queue. A load/store; barrier enforces ordering of loads/stores. A younger load cannot pass a load; barrier. Also, a younger store cannot pass a store barrier. A younger load; has to wait for the memory/load barrier to execute. A load/store barrier is; ""executed"" when it becomes the oldest entry in the load/store queue(s). That; also means, by construction, all of the older loads/stores have been executed. In conclusion, the full set of load/store consistency rules are:. #. A store may not pass a previous store.; #. A store may not pass a previous load (regardless of ``-noalias``).; #. A store has to wait until an older store barrier is fully executed.; #. A load may pass a previous load.; #. A load may not pass a previous store unless ``-noalias`` is set.; #. A load has to wait until an older load barrier is fully executed. In-order Issue and Execute; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; In-order processors are modelled as a single ``InOrderIssueStage`` stage. It; bypasses Dispatch, Scheduler and Load/Store unit. Instructions are issued as; soon as their operand registers are available and resource requirements are; met. Multiple instructions can be issued in one cycle according to the value of; the ``IssueWidth`` parameter in LLVM's scheduling model. Once issued, an instruction is moved to ``IssuedInst`` set until it is ready to; retire. :program:`llvm-mca` ensures that writes are committed in-order. However,; an instruction is allowed to commit writes and retire out-of-order if; ``RetireOOO`` property is true for at least one of its writes. Custom Behaviour; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; Due to certain instructions not being expressed perfectly within their; scheduling model, :program:`llvm-mc",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:43060,Performance,load,load,43060," For an example, look at the `X86InstrPostProcess::postProcessInstruction` method; within `llvm/lib/Target/X86/MCA/X86CustomBehaviour.cpp`. A load/store barrier consumes one entry of the load/store queue. A load/store; barrier enforces ordering of loads/stores. A younger load cannot pass a load; barrier. Also, a younger store cannot pass a store barrier. A younger load; has to wait for the memory/load barrier to execute. A load/store barrier is; ""executed"" when it becomes the oldest entry in the load/store queue(s). That; also means, by construction, all of the older loads/stores have been executed. In conclusion, the full set of load/store consistency rules are:. #. A store may not pass a previous store.; #. A store may not pass a previous load (regardless of ``-noalias``).; #. A store has to wait until an older store barrier is fully executed.; #. A load may pass a previous load.; #. A load may not pass a previous store unless ``-noalias`` is set.; #. A load has to wait until an older load barrier is fully executed. In-order Issue and Execute; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; In-order processors are modelled as a single ``InOrderIssueStage`` stage. It; bypasses Dispatch, Scheduler and Load/Store unit. Instructions are issued as; soon as their operand registers are available and resource requirements are; met. Multiple instructions can be issued in one cycle according to the value of; the ``IssueWidth`` parameter in LLVM's scheduling model. Once issued, an instruction is moved to ``IssuedInst`` set until it is ready to; retire. :program:`llvm-mca` ensures that writes are committed in-order. However,; an instruction is allowed to commit writes and retire out-of-order if; ``RetireOOO`` property is true for at least one of its writes. Custom Behaviour; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; Due to certain instructions not being expressed perfectly within their; scheduling model, :program:`llvm-mca` isn't always able to simulate them; perfectly. Modifying the sched",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:43092,Performance,load,load,43092," For an example, look at the `X86InstrPostProcess::postProcessInstruction` method; within `llvm/lib/Target/X86/MCA/X86CustomBehaviour.cpp`. A load/store barrier consumes one entry of the load/store queue. A load/store; barrier enforces ordering of loads/stores. A younger load cannot pass a load; barrier. Also, a younger store cannot pass a store barrier. A younger load; has to wait for the memory/load barrier to execute. A load/store barrier is; ""executed"" when it becomes the oldest entry in the load/store queue(s). That; also means, by construction, all of the older loads/stores have been executed. In conclusion, the full set of load/store consistency rules are:. #. A store may not pass a previous store.; #. A store may not pass a previous load (regardless of ``-noalias``).; #. A store has to wait until an older store barrier is fully executed.; #. A load may pass a previous load.; #. A load may not pass a previous store unless ``-noalias`` is set.; #. A load has to wait until an older load barrier is fully executed. In-order Issue and Execute; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; In-order processors are modelled as a single ``InOrderIssueStage`` stage. It; bypasses Dispatch, Scheduler and Load/Store unit. Instructions are issued as; soon as their operand registers are available and resource requirements are; met. Multiple instructions can be issued in one cycle according to the value of; the ``IssueWidth`` parameter in LLVM's scheduling model. Once issued, an instruction is moved to ``IssuedInst`` set until it is ready to; retire. :program:`llvm-mca` ensures that writes are committed in-order. However,; an instruction is allowed to commit writes and retire out-of-order if; ``RetireOOO`` property is true for at least one of its writes. Custom Behaviour; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; Due to certain instructions not being expressed perfectly within their; scheduling model, :program:`llvm-mca` isn't always able to simulate them; perfectly. Modifying the sched",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:625,Safety,predict,predict,625,"llvm-mca - LLVM Machine Code Analyzer; =====================================. .. program:: llvm-mca. SYNOPSIS; --------. :program:`llvm-mca` [*options*] [input]. DESCRIPTION; -----------. :program:`llvm-mca` is a performance analysis tool that uses information; available in LLVM (e.g. scheduling models) to statically measure the performance; of machine code in a specific CPU. Performance is measured in terms of throughput as well as processor resource; consumption. The tool currently works for processors with a backend for which; there is a scheduling model available in LLVM. The main goal of this tool is not just to predict the performance of the code; when run on the target, but also help with diagnosing potential performance; issues. Given an assembly code sequence, :program:`llvm-mca` estimates the Instructions; Per Cycle (IPC), as well as hardware resource pressure. The analysis and; reporting style were inspired by the IACA tool from Intel. For example, you can compile code with clang, output assembly, and pipe it; directly into :program:`llvm-mca` for analysis:. .. code-block:: bash. $ clang foo.c -O2 --target=x86_64 -S -o - | llvm-mca -mcpu=btver2. Or for Intel syntax:. .. code-block:: bash. $ clang foo.c -O2 --target=x86_64 -masm=intel -S -o - | llvm-mca -mcpu=btver2. (:program:`llvm-mca` detects Intel syntax by the presence of an `.intel_syntax`; directive at the beginning of the input. By default its output syntax matches; that of its input.). Scheduling models are not just used to compute instruction latencies and; throughput, but also to understand what processor resources are available; and how to simulate them. By design, the quality of the analysis conducted by :program:`llvm-mca` is; inevitably affected by the quality of the scheduling models in LLVM. If you see that the performance report is not accurate for a processor,; please `file a bug <https://github.com/llvm/llvm-project/issues>`_; against the appropriate backend. OPTIONS; -------. If ``input",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:1319,Safety,detect,detects,1319," performance; of machine code in a specific CPU. Performance is measured in terms of throughput as well as processor resource; consumption. The tool currently works for processors with a backend for which; there is a scheduling model available in LLVM. The main goal of this tool is not just to predict the performance of the code; when run on the target, but also help with diagnosing potential performance; issues. Given an assembly code sequence, :program:`llvm-mca` estimates the Instructions; Per Cycle (IPC), as well as hardware resource pressure. The analysis and; reporting style were inspired by the IACA tool from Intel. For example, you can compile code with clang, output assembly, and pipe it; directly into :program:`llvm-mca` for analysis:. .. code-block:: bash. $ clang foo.c -O2 --target=x86_64 -S -o - | llvm-mca -mcpu=btver2. Or for Intel syntax:. .. code-block:: bash. $ clang foo.c -O2 --target=x86_64 -masm=intel -S -o - | llvm-mca -mcpu=btver2. (:program:`llvm-mca` detects Intel syntax by the presence of an `.intel_syntax`; directive at the beginning of the input. By default its output syntax matches; that of its input.). Scheduling models are not just used to compute instruction latencies and; throughput, but also to understand what processor resources are available; and how to simulate them. By design, the quality of the analysis conducted by :program:`llvm-mca` is; inevitably affected by the quality of the scheduling models in LLVM. If you see that the performance report is not accurate for a processor,; please `file a bug <https://github.com/llvm/llvm-project/issues>`_; against the appropriate backend. OPTIONS; -------. If ``input`` is ""``-``"" or omitted, :program:`llvm-mca` reads from standard; input. Otherwise, it will read from the specified filename. If the :option:`-o` option is omitted, then :program:`llvm-mca` will send its output; to standard output if the input is from standard input. If the :option:`-o`; option specifies ""``-``"", then the outpu",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:7556,Safety,detect,detect,7556,"s; the theoretical uniform distribution of resource pressure for every; instruction in sequence. .. option:: -bottleneck-analysis. Print information about bottlenecks that affect the throughput. This analysis; can be expensive, and it is disabled by default. Bottlenecks are highlighted; in the summary view. Bottleneck analysis is currently not supported for; processors with an in-order backend. .. option:: -json. Print the requested views in valid JSON format. The instructions and the; processor resources are printed as members of special top level JSON objects.; The individual views refer to them by index. However, not all views are; currently supported. For example, the report from the bottleneck analysis is; not printed out in JSON. All the default views are currently supported. .. option:: -disable-cb. Force usage of the generic CustomBehaviour and InstrPostProcess classes rather; than using the target specific implementation. The generic classes never; detect any custom hazards or make any post processing modifications to; instructions. .. option:: -disable-im. Force usage of the generic InstrumentManager rather than using the target; specific implementation. The generic class creates Instruments that provide; no extra information, and InstrumentManager never overrides the default; schedule class for a given instruction. EXIT STATUS; -----------. :program:`llvm-mca` returns 0 on success. Otherwise, an error message is printed; to standard error, and the tool returns 1. USING MARKERS TO ANALYZE SPECIFIC CODE BLOCKS; ---------------------------------------------; :program:`llvm-mca` allows for the optional usage of special code comments to; mark regions of the assembly code to be analyzed. A comment starting with; substring ``LLVM-MCA-BEGIN`` marks the beginning of an analysis region. A; comment starting with substring ``LLVM-MCA-END`` marks the end of a region.; For example:. .. code-block:: none. # LLVM-MCA-BEGIN; ...; # LLVM-MCA-END. If no user-defined region i",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:7574,Safety,hazard,hazards,7574,"s; the theoretical uniform distribution of resource pressure for every; instruction in sequence. .. option:: -bottleneck-analysis. Print information about bottlenecks that affect the throughput. This analysis; can be expensive, and it is disabled by default. Bottlenecks are highlighted; in the summary view. Bottleneck analysis is currently not supported for; processors with an in-order backend. .. option:: -json. Print the requested views in valid JSON format. The instructions and the; processor resources are printed as members of special top level JSON objects.; The individual views refer to them by index. However, not all views are; currently supported. For example, the report from the bottleneck analysis is; not printed out in JSON. All the default views are currently supported. .. option:: -disable-cb. Force usage of the generic CustomBehaviour and InstrPostProcess classes rather; than using the target specific implementation. The generic classes never; detect any custom hazards or make any post processing modifications to; instructions. .. option:: -disable-im. Force usage of the generic InstrumentManager rather than using the target; specific implementation. The generic class creates Instruments that provide; no extra information, and InstrumentManager never overrides the default; schedule class for a given instruction. EXIT STATUS; -----------. :program:`llvm-mca` returns 0 on success. Otherwise, an error message is printed; to standard error, and the tool returns 1. USING MARKERS TO ANALYZE SPECIFIC CODE BLOCKS; ---------------------------------------------; :program:`llvm-mca` allows for the optional usage of special code comments to; mark regions of the assembly code to be analyzed. A comment starting with; substring ``LLVM-MCA-BEGIN`` marks the beginning of an analysis region. A; comment starting with substring ``LLVM-MCA-END`` marks the end of a region.; For example:. .. code-block:: none. # LLVM-MCA-BEGIN; ...; # LLVM-MCA-END. If no user-defined region i",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:10715,Safety,detect,detecting,10715,"ons cannot overlap. Also, overlapping regions; cannot have the same name. There is no support for marking regions from high-level source code, like C or; C++. As a workaround, inline assembly directives may be used:. .. code-block:: c++. int foo(int a, int b) {; __asm volatile(""# LLVM-MCA-BEGIN foo"":::""memory"");; a += 42;; __asm volatile(""# LLVM-MCA-END"":::""memory"");; a *= b;; return a;; }. However, this interferes with optimizations like loop vectorization and may have; an impact on the code generated. This is because the ``__asm`` statements are; seen as real code having important side effects, which limits how the code; around them can be transformed. If users want to make use of inline assembly; to emit markers, then the recommendation is to always verify that the output; assembly is equivalent to the assembly generated in the absence of markers.; The `Clang options to emit optimization reports <https://clang.llvm.org/docs/UsersManual.html#options-to-emit-optimization-reports>`_; can also help in detecting missed optimizations. INSTRUMENT REGIONS; ------------------. An InstrumentRegion describes a region of assembly code guarded by; special LLVM-MCA comment directives. .. code-block:: none. # LLVM-MCA-<INSTRUMENT_TYPE> <data>; ... ## asm. where `INSTRUMENT_TYPE` is a type defined by the target and expects; to use `data`. A comment starting with substring `LLVM-MCA-<INSTRUMENT_TYPE>`; brings data into scope for llvm-mca to use in its analysis for; all following instructions. If a comment with the same `INSTRUMENT_TYPE` is found later in the; instruction list, then the original InstrumentRegion will be; automatically ended, and a new InstrumentRegion will begin. If there are comments containing the different `INSTRUMENT_TYPE`,; then both data sets remain available. In contrast with an AnalysisRegion,; an InstrumentRegion does not need a comment to end the region. Comments that are prefixed with `LLVM-MCA-` but do not correspond to; a valid `INSTRUMENT_TYPE` for t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:20936,Safety,avoid,avoided,20936,"codings (byte sequences in; hex). The third section is the *Resource pressure view*. This view reports; the average number of resource cycles consumed every iteration by instructions; for every processor resource unit available on the target. Information is; structured in two tables. The first table reports the number of resource cycles; spent on average every iteration. The second table correlates the resource; cycles to the machine instruction in the sequence. For example, every iteration; of the instruction vmulps always executes on resource unit [6]; (JFPU1 - floating point pipeline #1), consuming an average of 1 resource cycle; per iteration. Note that on AMD Jaguar, vector floating-point multiply can; only be issued to pipeline JFPU1, while horizontal floating-point additions can; only be issued to pipeline JFPU0. The resource pressure view helps with identifying bottlenecks caused by high; usage of specific hardware resources. Situations with resource pressure mainly; concentrated on a few resources should, in general, be avoided. Ideally,; pressure should be uniformly distributed between multiple resources. Timeline View; ^^^^^^^^^^^^^; The timeline view produces a detailed report of each instruction's state; transitions through an instruction pipeline. This view is enabled by the; command line option ``-timeline``. As instructions transition through the; various stages of the pipeline, their states are depicted in the view report.; These states are represented by the following characters:. * D : Instruction dispatched.; * e : Instruction executing.; * E : Instruction executed.; * R : Instruction retired.; * = : Instruction already dispatched, waiting to be executed.; * \- : Instruction executed, waiting to be retired. Below is the timeline view for a subset of the dot-product example located in; ``test/tools/llvm-mca/X86/BtVer2/dot-product.s`` and processed by; :program:`llvm-mca` using the following command:. .. code-block:: bash. $ llvm-mca -mtriple=x86_6",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:34865,Safety,predict,prediction,34865," section describes the instruction flow through the default pipeline of; :program:`llvm-mca`, as well as the functional units involved in the process. The default pipeline implements the following sequence of stages used to; process instructions. * Dispatch (Instruction is dispatched to the schedulers).; * Issue (Instruction is issued to the processor pipelines).; * Write Back (Instruction is executed, and results are written back).; * Retire (Instruction is retired; writes are architecturally committed). The in-order pipeline implements the following sequence of stages:; * InOrderIssue (Instruction is issued to the processor pipelines).; * Retire (Instruction is retired; writes are architecturally committed). :program:`llvm-mca` assumes that instructions have all been decoded and placed; into a queue before the simulation start. Therefore, the instruction fetch and; decode stages are not modeled. Performance bottlenecks in the frontend are not; diagnosed. Also, :program:`llvm-mca` does not model branch prediction. Instruction Dispatch; """"""""""""""""""""""""""""""""""""""""; During the dispatch stage, instructions are picked in program order from a; queue of already decoded instructions, and dispatched in groups to the; simulated hardware schedulers. The size of a dispatch group depends on the availability of the simulated; hardware resources. The processor dispatch width defaults to the value; of the ``IssueWidth`` in LLVM's scheduling model. An instruction can be dispatched if:. * The size of the dispatch group is smaller than processor's dispatch width.; * There are enough entries in the reorder buffer.; * There are enough physical registers to do register renaming.; * The schedulers are not full. Scheduling models can optionally specify which register files are available on; the processor. :program:`llvm-mca` uses that information to initialize register; file descriptors. Users can limit the number of physical registers that are; globally available for register renaming by using",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:36015,Safety,predict,predict,36015,"dy decoded instructions, and dispatched in groups to the; simulated hardware schedulers. The size of a dispatch group depends on the availability of the simulated; hardware resources. The processor dispatch width defaults to the value; of the ``IssueWidth`` in LLVM's scheduling model. An instruction can be dispatched if:. * The size of the dispatch group is smaller than processor's dispatch width.; * There are enough entries in the reorder buffer.; * There are enough physical registers to do register renaming.; * The schedulers are not full. Scheduling models can optionally specify which register files are available on; the processor. :program:`llvm-mca` uses that information to initialize register; file descriptors. Users can limit the number of physical registers that are; globally available for register renaming by using the command option; ``-register-file-size``. A value of zero for this option means *unbounded*. By; knowing how many registers are available for renaming, the tool can predict; dispatch stalls caused by the lack of physical registers. The number of reorder buffer entries consumed by an instruction depends on the; number of micro-opcodes specified for that instruction by the target scheduling; model. The reorder buffer is responsible for tracking the progress of; instructions that are ""in-flight"", and retiring them in program order. The; number of entries in the reorder buffer defaults to the value specified by field; `MicroOpBufferSize` in the target scheduling model. Instructions that are dispatched to the schedulers consume scheduler buffer; entries. :program:`llvm-mca` queries the scheduling model to determine the set; of buffered resources consumed by an instruction. Buffered resources are; treated like scheduler resources. Instruction Issue; """"""""""""""""""""""""""""""""""; Each processor scheduler implements a buffer of instructions. An instruction; has to wait in the scheduler's buffer until input register operands become; available. Only at that point, ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:40403,Safety,predict,predict,40403,"SUnit) to simulate the speculative; execution of loads and stores. Each load (or store) consumes an entry in the load (or store) queue. Users can; specify flags ``-lqueue`` and ``-squeue`` to limit the number of entries in the; load and store queues respectively. The queues are unbounded by default. The LSUnit implements a relaxed consistency model for memory loads and stores.; The rules are:. 1. A younger load is allowed to pass an older load only if there are no; intervening stores or barriers between the two loads.; 2. A younger load is allowed to pass an older store provided that the load does; not alias with the store.; 3. A younger store is not allowed to pass an older store.; 4. A younger store is not allowed to pass an older load. By default, the LSUnit optimistically assumes that loads do not alias; (`-noalias=true`) store operations. Under this assumption, younger loads are; always allowed to pass older stores. Essentially, the LSUnit does not attempt; to run any alias analysis to predict when loads and stores do not alias with; each other. Note that, in the case of write-combining memory, rule 3 could be relaxed to; allow reordering of non-aliasing store operations. That being said, at the; moment, there is no way to further relax the memory model (``-noalias`` is the; only option). Essentially, there is no option to specify a different memory; type (e.g., write-back, write-combining, write-through; etc.) and consequently; to weaken, or strengthen, the memory model. Other limitations are:. * The LSUnit does not know when store-to-load forwarding may occur.; * The LSUnit does not know anything about cache hierarchy and memory types.; * The LSUnit does not know how to identify serializing operations and memory; fences. The LSUnit does not attempt to predict if a load or store hits or misses the L1; cache. It only knows if an instruction ""MayLoad"" and/or ""MayStore."" For; loads, the scheduling model provides an ""optimistic"" load-to-use latency (which; usually",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:41186,Safety,predict,predict,41186,"oads do not alias; (`-noalias=true`) store operations. Under this assumption, younger loads are; always allowed to pass older stores. Essentially, the LSUnit does not attempt; to run any alias analysis to predict when loads and stores do not alias with; each other. Note that, in the case of write-combining memory, rule 3 could be relaxed to; allow reordering of non-aliasing store operations. That being said, at the; moment, there is no way to further relax the memory model (``-noalias`` is the; only option). Essentially, there is no option to specify a different memory; type (e.g., write-back, write-combining, write-through; etc.) and consequently; to weaken, or strengthen, the memory model. Other limitations are:. * The LSUnit does not know when store-to-load forwarding may occur.; * The LSUnit does not know anything about cache hierarchy and memory types.; * The LSUnit does not know how to identify serializing operations and memory; fences. The LSUnit does not attempt to predict if a load or store hits or misses the L1; cache. It only knows if an instruction ""MayLoad"" and/or ""MayStore."" For; loads, the scheduling model provides an ""optimistic"" load-to-use latency (which; usually matches the load-to-use latency for when there is a hit in the L1D). :program:`llvm-mca` does not (on its own) know about serializing operations or; memory-barrier like instructions. The LSUnit used to conservatively use an; instruction's ""MayLoad"", ""MayStore"", and unmodeled side effects flags to; determine whether an instruction should be treated as a memory-barrier. This was; inaccurate in general and was changed so that now each instruction has an; IsAStoreBarrier and IsALoadBarrier flag. These flags are mca specific and; default to false for every instruction. If any instruction should have either of; these flags set, it should be done within the target's InstrPostProcess class.; For an example, look at the `X86InstrPostProcess::postProcessInstruction` method; within `llvm/lib/Target/X",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:44393,Safety,detect,detecting,44393,"operand registers are available and resource requirements are; met. Multiple instructions can be issued in one cycle according to the value of; the ``IssueWidth`` parameter in LLVM's scheduling model. Once issued, an instruction is moved to ``IssuedInst`` set until it is ready to; retire. :program:`llvm-mca` ensures that writes are committed in-order. However,; an instruction is allowed to commit writes and retire out-of-order if; ``RetireOOO`` property is true for at least one of its writes. Custom Behaviour; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; Due to certain instructions not being expressed perfectly within their; scheduling model, :program:`llvm-mca` isn't always able to simulate them; perfectly. Modifying the scheduling model isn't always a viable; option though (maybe because the instruction is modeled incorrectly on; purpose or the instruction's behaviour is quite complex). The; CustomBehaviour class can be used in these cases to enforce proper; instruction modeling (often by customizing data dependencies and detecting; hazards that :program:`llvm-mca` has no way of knowing about). :program:`llvm-mca` comes with one generic and multiple target specific; CustomBehaviour classes. The generic class will be used if the ``-disable-cb``; flag is used or if a target specific CustomBehaviour class doesn't exist for; that target. (The generic class does nothing.) Currently, the CustomBehaviour; class is only a part of the in-order pipeline, but there are plans to add it; to the out-of-order pipeline in the future. CustomBehaviour's main method is `checkCustomHazard()` which uses the; current instruction and a list of all instructions still executing within; the pipeline to determine if the current instruction should be dispatched.; As output, the method returns an integer representing the number of cycles; that the current instruction must stall for (this can be an underestimate; if you don't know the exact number and a value of 0 represents no stall). If you'd like ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:44404,Safety,hazard,hazards,44404,"operand registers are available and resource requirements are; met. Multiple instructions can be issued in one cycle according to the value of; the ``IssueWidth`` parameter in LLVM's scheduling model. Once issued, an instruction is moved to ``IssuedInst`` set until it is ready to; retire. :program:`llvm-mca` ensures that writes are committed in-order. However,; an instruction is allowed to commit writes and retire out-of-order if; ``RetireOOO`` property is true for at least one of its writes. Custom Behaviour; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; Due to certain instructions not being expressed perfectly within their; scheduling model, :program:`llvm-mca` isn't always able to simulate them; perfectly. Modifying the scheduling model isn't always a viable; option though (maybe because the instruction is modeled incorrectly on; purpose or the instruction's behaviour is quite complex). The; CustomBehaviour class can be used in these cases to enforce proper; instruction modeling (often by customizing data dependencies and detecting; hazards that :program:`llvm-mca` has no way of knowing about). :program:`llvm-mca` comes with one generic and multiple target specific; CustomBehaviour classes. The generic class will be used if the ``-disable-cb``; flag is used or if a target specific CustomBehaviour class doesn't exist for; that target. (The generic class does nothing.) Currently, the CustomBehaviour; class is only a part of the in-order pipeline, but there are plans to add it; to the out-of-order pipeline in the future. CustomBehaviour's main method is `checkCustomHazard()` which uses the; current instruction and a list of all instructions still executing within; the pipeline to determine if the current instruction should be dispatched.; As output, the method returns an integer representing the number of cycles; that the current instruction must stall for (this can be an underestimate; if you don't know the exact number and a value of 0 represents no stall). If you'd like ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:45624,Security,access,access,45624,"eric class will be used if the ``-disable-cb``; flag is used or if a target specific CustomBehaviour class doesn't exist for; that target. (The generic class does nothing.) Currently, the CustomBehaviour; class is only a part of the in-order pipeline, but there are plans to add it; to the out-of-order pipeline in the future. CustomBehaviour's main method is `checkCustomHazard()` which uses the; current instruction and a list of all instructions still executing within; the pipeline to determine if the current instruction should be dispatched.; As output, the method returns an integer representing the number of cycles; that the current instruction must stall for (this can be an underestimate; if you don't know the exact number and a value of 0 represents no stall). If you'd like to add a CustomBehaviour class for a target that doesn't; already have one, refer to an existing implementation to see how to set it; up. The classes are implemented within the target specific backend (for; example `/llvm/lib/Target/AMDGPU/MCA/`) so that they can access backend symbols. Instrument Manager; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; On certain architectures, scheduling information for certain instructions; do not contain all of the information required to identify the most precise; schedule class. For example, data that can have an impact on scheduling can; be stored in CSR registers. One example of this is on RISCV, where values in registers such as `vtype`; and `vl` change the scheduling behaviour of vector instructions. Since MCA; does not keep track of the values in registers, instrument comments can; be used to specify these values. InstrumentManager's main function is `getSchedClassID()` which has access; to the MCInst and all of the instruments that are active for that MCInst.; This function can use the instruments to override the schedule class of; the MCInst. On RISCV, instrument comments containing LMUL information are used; by `getSchedClassID()` to map a vector instructi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:46288,Security,access,access,46288,"exact number and a value of 0 represents no stall). If you'd like to add a CustomBehaviour class for a target that doesn't; already have one, refer to an existing implementation to see how to set it; up. The classes are implemented within the target specific backend (for; example `/llvm/lib/Target/AMDGPU/MCA/`) so that they can access backend symbols. Instrument Manager; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; On certain architectures, scheduling information for certain instructions; do not contain all of the information required to identify the most precise; schedule class. For example, data that can have an impact on scheduling can; be stored in CSR registers. One example of this is on RISCV, where values in registers such as `vtype`; and `vl` change the scheduling behaviour of vector instructions. Since MCA; does not keep track of the values in registers, instrument comments can; be used to specify these values. InstrumentManager's main function is `getSchedClassID()` which has access; to the MCInst and all of the instruments that are active for that MCInst.; This function can use the instruments to override the schedule class of; the MCInst. On RISCV, instrument comments containing LMUL information are used; by `getSchedClassID()` to map a vector instruction and the active; LMUL to the scheduling class of the pseudo-instruction that describes; that base instruction and the active LMUL. Custom Views; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; :program:`llvm-mca` comes with several Views such as the Timeline View and; Summary View. These Views are generic and can work with most (if not all); targets. If you wish to add a new View to :program:`llvm-mca` and it does not; require any backend functionality that is not already exposed through MC layer; classes (MCSubtargetInfo, MCInstrInfo, etc.), please add it to the; `/tools/llvm-mca/View/` directory. However, if your new View is target specific; AND requires unexposed backend symbols or functionality, you can define it in; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:47041,Security,expose,exposed,47041,"egisters such as `vtype`; and `vl` change the scheduling behaviour of vector instructions. Since MCA; does not keep track of the values in registers, instrument comments can; be used to specify these values. InstrumentManager's main function is `getSchedClassID()` which has access; to the MCInst and all of the instruments that are active for that MCInst.; This function can use the instruments to override the schedule class of; the MCInst. On RISCV, instrument comments containing LMUL information are used; by `getSchedClassID()` to map a vector instruction and the active; LMUL to the scheduling class of the pseudo-instruction that describes; that base instruction and the active LMUL. Custom Views; """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; :program:`llvm-mca` comes with several Views such as the Timeline View and; Summary View. These Views are generic and can work with most (if not all); targets. If you wish to add a new View to :program:`llvm-mca` and it does not; require any backend functionality that is not already exposed through MC layer; classes (MCSubtargetInfo, MCInstrInfo, etc.), please add it to the; `/tools/llvm-mca/View/` directory. However, if your new View is target specific; AND requires unexposed backend symbols or functionality, you can define it in; the `/lib/Target/<TargetName>/MCA/` directory. To enable this target specific View, you will have to use this target's; CustomBehaviour class to override the `CustomBehaviour::getViews()` methods.; There are 3 variations of these methods based on where you want your View to; appear in the output: `getStartViews()`, `getPostInstrInfoViews()`, and; `getEndViews()`. These methods returns a vector of Views so you will want to; return a vector containing all of the target specific Views for the target in; question. Because these target specific (and backend dependent) Views require the; `CustomBehaviour::getViews()` variants, these Views will not be enabled if; the `-disable-cb` flag is used. Enabling these custom",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:6163,Testability,log,logic,6163," default. .. option:: -register-file-stats. Enable register file usage statistics. .. option:: -dispatch-stats. Enable extra dispatch statistics. This view collects and analyzes instruction; dispatch events, as well as static/dynamic dispatch stall events. This view; is disabled by default. .. option:: -scheduler-stats. Enable extra scheduler statistics. This view collects and analyzes instruction; issue events. This view is disabled by default. .. option:: -retire-stats. Enable extra retire control unit statistics. This view is disabled by default. .. option:: -instruction-info. Enable the instruction info view. This is enabled by default. .. option:: -show-encoding. Enable the printing of instruction encodings within the instruction info view. .. option:: -show-barriers. Enable the printing of LoadBarrier and StoreBarrier flags within the; instruction info view. .. option:: -all-stats. Print all hardware statistics. This enables extra statistics related to the; dispatch logic, the hardware schedulers, the register file(s), and the retire; control unit. This option is disabled by default. .. option:: -all-views. Enable all the view. .. option:: -instruction-tables. Prints resource pressure information based on the static information; available from the processor model. This differs from the resource pressure; view because it doesn't require that the code is simulated. It instead prints; the theoretical uniform distribution of resource pressure for every; instruction in sequence. .. option:: -bottleneck-analysis. Print information about bottlenecks that affect the throughput. This analysis; can be expensive, and it is disabled by default. Bottlenecks are highlighted; in the summary view. Bottleneck analysis is currently not supported for; processors with an in-order backend. .. option:: -json. Print the requested views in valid JSON format. The instructions and the; processor resources are printed as members of special top level JSON objects.; The individual views re",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:14168,Testability,test,test,14168,"s1, rs2; # LLVM-MCA-RISCV-LMUL M1; vadd.vv v12, v12, v12; vsetvl rd, rs1, rs2; # LLVM-MCA-RISCV-LMUL M4; vadd.vv v12, v12, v12. HOW LLVM-MCA WORKS; ------------------. :program:`llvm-mca` takes assembly code as input. The assembly code is parsed; into a sequence of MCInst with the help of the existing LLVM target assembly; parsers. The parsed sequence of MCInst is then analyzed by a ``Pipeline`` module; to generate a performance report. The Pipeline module simulates the execution of the machine code sequence in a; loop of iterations (default is 100). During this process, the pipeline collects; a number of execution related statistics. At the end of this process, the; pipeline generates and prints a report from the collected statistics. Here is an example of a performance report generated by the tool for a; dot-product of two packed float vectors of four elements. The analysis is; conducted for target x86, cpu btver2. The following result can be produced via; the following command using the example located at; ``test/tools/llvm-mca/X86/BtVer2/dot-product.s``:. .. code-block:: bash. $ llvm-mca -mtriple=x86_64-unknown-unknown -mcpu=btver2 -iterations=300 dot-product.s. .. code-block:: none. Iterations: 300; Instructions: 900; Total Cycles: 610; Total uOps: 900. Dispatch Width: 2; uOps Per Cycle: 1.48; IPC: 1.48; Block RThroughput: 2.0. Instruction Info:; [1]: #uOps; [2]: Latency; [3]: RThroughput; [4]: MayLoad; [5]: MayStore; [6]: HasSideEffects (U). [1] [2] [3] [4] [5] [6] Instructions:; 1 2 1.00 vmulps	%xmm0, %xmm1, %xmm2; 1 3 1.00 vhaddps	%xmm2, %xmm2, %xmm3; 1 3 1.00 vhaddps	%xmm3, %xmm3, %xmm4. Resources:; [0] - JALU0; [1] - JALU1; [2] - JDiv; [3] - JFPA; [4] - JFPM; [5] - JFPU0; [6] - JFPU1; [7] - JLAGU; [8] - JMul; [9] - JSAGU; [10] - JSTC; [11] - JVALU0; [12] - JVALU1; [13] - JVIMUL. Resource pressure per iteration:; [0] [1] [2] [3] [4] [5] [6] [7] [8] [9] [10] [11] [12] [13]; - - - 2.00 1.00 2.00 1.00 - - - - - - -. Resource pressure by instruction:; [0] [1] [",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:21729,Testability,test,test,21729,"peline JFPU0. The resource pressure view helps with identifying bottlenecks caused by high; usage of specific hardware resources. Situations with resource pressure mainly; concentrated on a few resources should, in general, be avoided. Ideally,; pressure should be uniformly distributed between multiple resources. Timeline View; ^^^^^^^^^^^^^; The timeline view produces a detailed report of each instruction's state; transitions through an instruction pipeline. This view is enabled by the; command line option ``-timeline``. As instructions transition through the; various stages of the pipeline, their states are depicted in the view report.; These states are represented by the following characters:. * D : Instruction dispatched.; * e : Instruction executing.; * E : Instruction executed.; * R : Instruction retired.; * = : Instruction already dispatched, waiting to be executed.; * \- : Instruction executed, waiting to be retired. Below is the timeline view for a subset of the dot-product example located in; ``test/tools/llvm-mca/X86/BtVer2/dot-product.s`` and processed by; :program:`llvm-mca` using the following command:. .. code-block:: bash. $ llvm-mca -mtriple=x86_64-unknown-unknown -mcpu=btver2 -iterations=3 -timeline dot-product.s. .. code-block:: none. Timeline view:; 012345; Index 0123456789. [0,0] DeeER. . . vmulps	%xmm0, %xmm1, %xmm2; [0,1] D==eeeER . . vhaddps	%xmm2, %xmm2, %xmm3; [0,2] .D====eeeER . vhaddps	%xmm3, %xmm3, %xmm4; [1,0] .DeeE-----R . vmulps	%xmm0, %xmm1, %xmm2; [1,1] . D=eeeE---R . vhaddps	%xmm2, %xmm2, %xmm3; [1,2] . D====eeeER . vhaddps	%xmm3, %xmm3, %xmm4; [2,0] . DeeE-----R . vmulps	%xmm0, %xmm1, %xmm2; [2,1] . D====eeeER . vhaddps	%xmm2, %xmm2, %xmm3; [2,2] . D======eeeER vhaddps	%xmm3, %xmm3, %xmm4. Average Wait times (based on the timeline view):; [0]: Executions; [1]: Average time spent waiting in a scheduler's queue; [2]: Average time spent waiting in a scheduler's queue while ready; [3]: Average time elapsed from WB until retire stage. [",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:28762,Testability,log,logic,28762,"ing to the analysis, throughput is limited by resource pressure and not by; data dependencies. The analysis observed increases in backend pressure during; 48.07% of the simulated run. Almost all those pressure increase events were; caused by contention on processor resources JFPA/JFPU0. The `critical sequence` is the most expensive sequence of instructions according; to the simulation. It is annotated to provide extra information about critical; register dependencies and resource interferences between instructions. Instructions from the critical sequence are expected to significantly impact; performance. By construction, the accuracy of this analysis is strongly; dependent on the simulation and (as always) by the quality of the processor; model in llvm. Bottleneck analysis is currently not supported for processors with an in-order; backend. Extra Statistics to Further Diagnose Performance Issues; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; The ``-all-stats`` command line option enables extra statistics and performance; counters for the dispatch logic, the reorder buffer, the retire control unit,; and the register file. Below is an example of ``-all-stats`` output generated by :program:`llvm-mca`; for 300 iterations of the dot-product example discussed in the previous; sections. .. code-block:: none. Dynamic Dispatch Stall Cycles:; RAT - Register unavailable: 0; RCU - Retire tokens unavailable: 0; SCHEDQ - Scheduler full: 272 (44.6%); LQ - Load queue full: 0; SQ - Store queue full: 0; GROUP - Static restrictions on the dispatch group: 0. Dispatch Logic - number of cycles where we saw N micro opcodes dispatched:; [# dispatched], [# cycles]; 0, 24 (3.9%); 1, 272 (44.6%); 2, 314 (51.5%). Schedulers - number of cycles where we saw N micro opcodes issued:; [# issued], [# cycles]; 0, 7 (1.1%); 1, 306 (50.2%); 2, 297 (48.7%). Scheduler's queue usage:; [1] Resource name.; [2] Average number of used buffer entries.; [3] Maximum number of used buffer entries.; [4] ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:30578,Testability,log,logic,30578,"name.; [2] Average number of used buffer entries.; [3] Maximum number of used buffer entries.; [4] Total number of buffer entries. [1] [2] [3] [4]; JALU01 0 0 20; JFPU01 17 18 18; JLSAGU 0 0 12. Retire Control Unit - number of cycles where we saw N instructions retired:; [# retired], [# cycles]; 0, 109 (17.9%); 1, 102 (16.7%); 2, 399 (65.4%). Total ROB Entries: 64; Max Used ROB Entries: 35 ( 54.7% ); Average Used ROB Entries per cy: 32 ( 50.0% ). Register File statistics:; Total number of mappings created: 900; Max number of mappings used: 35. * Register File #1 -- JFpuPRF:; Number of physical registers: 72; Total number of mappings created: 900; Max number of mappings used: 35. * Register File #2 -- JIntegerPRF:; Number of physical registers: 64; Total number of mappings created: 0; Max number of mappings used: 0. If we look at the *Dynamic Dispatch Stall Cycles* table, we see the counter for; SCHEDQ reports 272 cycles. This counter is incremented every time the dispatch; logic is unable to dispatch a full group because the scheduler's queue is full. Looking at the *Dispatch Logic* table, we see that the pipeline was only able to; dispatch two micro opcodes 51.5% of the time. The dispatch group was limited to; one micro opcode 44.6% of the cycles, which corresponds to 272 cycles. The; dispatch statistics are displayed by either using the command option; ``-all-stats`` or ``-dispatch-stats``. The next table, *Schedulers*, presents a histogram displaying a count,; representing the number of micro opcodes issued on some number of cycles. In; this case, of the 610 simulated cycles, single opcodes were issued 306 times; (50.2%) and there were 7 cycles where no opcodes were issued. The *Scheduler's queue usage* table shows that the average and maximum number of; buffer entries (i.e., scheduler queue entries) used at runtime. Resource JFPU01; reached its maximum (18 of 18 queue entries). Note that AMD Jaguar implements; three schedulers:. * JALU01 - A scheduler for ALU ins",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:8932,Usability,simpl,simple,8932,"-----------. :program:`llvm-mca` returns 0 on success. Otherwise, an error message is printed; to standard error, and the tool returns 1. USING MARKERS TO ANALYZE SPECIFIC CODE BLOCKS; ---------------------------------------------; :program:`llvm-mca` allows for the optional usage of special code comments to; mark regions of the assembly code to be analyzed. A comment starting with; substring ``LLVM-MCA-BEGIN`` marks the beginning of an analysis region. A; comment starting with substring ``LLVM-MCA-END`` marks the end of a region.; For example:. .. code-block:: none. # LLVM-MCA-BEGIN; ...; # LLVM-MCA-END. If no user-defined region is specified, then :program:`llvm-mca` assumes a; default region which contains every instruction in the input file. Every region; is analyzed in isolation, and the final performance report is the union of all; the reports generated for every analysis region. Analysis regions can have names. For example:. .. code-block:: none. # LLVM-MCA-BEGIN A simple example; add %eax, %eax; # LLVM-MCA-END. The code from the example above defines a region named ""A simple example"" with a; single instruction in it. Note how the region name doesn't have to be repeated; in the ``LLVM-MCA-END`` directive. In the absence of overlapping regions,; an anonymous ``LLVM-MCA-END`` directive always ends the currently active user; defined region. Example of nesting regions:. .. code-block:: none. # LLVM-MCA-BEGIN foo; add %eax, %edx; # LLVM-MCA-BEGIN bar; sub %eax, %edx; # LLVM-MCA-END bar; # LLVM-MCA-END foo. Example of overlapping regions:. .. code-block:: none. # LLVM-MCA-BEGIN foo; add %eax, %edx; # LLVM-MCA-BEGIN bar; sub %eax, %edx; # LLVM-MCA-END foo; add %eax, %edx; # LLVM-MCA-END bar. Note that multiple anonymous regions cannot overlap. Also, overlapping regions; cannot have the same name. There is no support for marking regions from high-level source code, like C or; C++. As a workaround, inline assembly directives may be used:. .. code-block:: c++. int foo(i",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst:9038,Usability,simpl,simple,9038,"inted; to standard error, and the tool returns 1. USING MARKERS TO ANALYZE SPECIFIC CODE BLOCKS; ---------------------------------------------; :program:`llvm-mca` allows for the optional usage of special code comments to; mark regions of the assembly code to be analyzed. A comment starting with; substring ``LLVM-MCA-BEGIN`` marks the beginning of an analysis region. A; comment starting with substring ``LLVM-MCA-END`` marks the end of a region.; For example:. .. code-block:: none. # LLVM-MCA-BEGIN; ...; # LLVM-MCA-END. If no user-defined region is specified, then :program:`llvm-mca` assumes a; default region which contains every instruction in the input file. Every region; is analyzed in isolation, and the final performance report is the union of all; the reports generated for every analysis region. Analysis regions can have names. For example:. .. code-block:: none. # LLVM-MCA-BEGIN A simple example; add %eax, %eax; # LLVM-MCA-END. The code from the example above defines a region named ""A simple example"" with a; single instruction in it. Note how the region name doesn't have to be repeated; in the ``LLVM-MCA-END`` directive. In the absence of overlapping regions,; an anonymous ``LLVM-MCA-END`` directive always ends the currently active user; defined region. Example of nesting regions:. .. code-block:: none. # LLVM-MCA-BEGIN foo; add %eax, %edx; # LLVM-MCA-BEGIN bar; sub %eax, %edx; # LLVM-MCA-END bar; # LLVM-MCA-END foo. Example of overlapping regions:. .. code-block:: none. # LLVM-MCA-BEGIN foo; add %eax, %edx; # LLVM-MCA-BEGIN bar; sub %eax, %edx; # LLVM-MCA-END foo; add %eax, %edx; # LLVM-MCA-END bar. Note that multiple anonymous regions cannot overlap. Also, overlapping regions; cannot have the same name. There is no support for marking regions from high-level source code, like C or; C++. As a workaround, inline assembly directives may be used:. .. code-block:: c++. int foo(int a, int b) {; __asm volatile(""# LLVM-MCA-BEGIN foo"":::""memory"");; a += 42;; __asm vol",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-mca.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-nm.rst:1917,Availability,failure,failure,1917,"ed, it is replaced by 8 spaces. The supported type code characters are as follows. Where both lower and; upper-case characters are listed for the same meaning, a lower-case character; represents a local symbol, whilst an upper-case character represents a global; (external) symbol:. a, A. Absolute symbol. b, B. Uninitialized data (bss) object. C. Common symbol. Multiple definitions link together into one definition. d, D. Writable data object. i, I. COFF: .idata symbol or symbol in a section with IMAGE_SCN_LNK_INFO set. n. ELF: local symbol from non-alloc section. COFF: debug symbol. N. ELF: debug section symbol, or global symbol from non-alloc section. s, S. COFF: section symbol. Mach-O: absolute symbol or symbol from a section other than __TEXT_EXEC __text,; __TEXT __text, __DATA __data, or __DATA __bss. r, R. Read-only data object. t, T. Code (text) object. u. ELF: GNU unique symbol. U. Named object is undefined in this file. v. ELF: Undefined weak object. It is not a link failure if the object is not; defined. V. ELF: Defined weak object symbol. This definition will only be used if no; regular definitions exist in a link. If multiple weak definitions and no; regular definitions exist, one of the weak definitions will be used. w. Undefined weak symbol other than an ELF object symbol. It is not a link failure; if the symbol is not defined. W. Defined weak symbol other than an ELF object symbol. This definition will only; be used if no regular definitions exist in a link. If multiple weak definitions; and no regular definitions exist, one of the weak definitions will be used. \-. Mach-O: N_STAB symbol. ?. Something unrecognizable. Because LLVM bitcode files typically contain objects that are not considered to; have addresses until they are linked into an executable image or dynamically; compiled ""just-in-time"", :program:`llvm-nm` does not print an address for any; symbol in an LLVM bitcode file, even symbols which are defined in the bitcode; file. OPTIONS; -------. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-nm.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-nm.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-nm.rst:2251,Availability,failure,failure,2251,"s) object. C. Common symbol. Multiple definitions link together into one definition. d, D. Writable data object. i, I. COFF: .idata symbol or symbol in a section with IMAGE_SCN_LNK_INFO set. n. ELF: local symbol from non-alloc section. COFF: debug symbol. N. ELF: debug section symbol, or global symbol from non-alloc section. s, S. COFF: section symbol. Mach-O: absolute symbol or symbol from a section other than __TEXT_EXEC __text,; __TEXT __text, __DATA __data, or __DATA __bss. r, R. Read-only data object. t, T. Code (text) object. u. ELF: GNU unique symbol. U. Named object is undefined in this file. v. ELF: Undefined weak object. It is not a link failure if the object is not; defined. V. ELF: Defined weak object symbol. This definition will only be used if no; regular definitions exist in a link. If multiple weak definitions and no; regular definitions exist, one of the weak definitions will be used. w. Undefined weak symbol other than an ELF object symbol. It is not a link failure; if the symbol is not defined. W. Defined weak symbol other than an ELF object symbol. This definition will only; be used if no regular definitions exist in a link. If multiple weak definitions; and no regular definitions exist, one of the weak definitions will be used. \-. Mach-O: N_STAB symbol. ?. Something unrecognizable. Because LLVM bitcode files typically contain objects that are not considered to; have addresses until they are linked into an executable image or dynamically; compiled ""just-in-time"", :program:`llvm-nm` does not print an address for any; symbol in an LLVM bitcode file, even symbols which are defined in the bitcode; file. OPTIONS; -------. .. program:: llvm-nm. .. option:: -B. Use BSD output format. Alias for ``--format=bsd``. .. option:: -X. Specify the type of XCOFF object file, ELF object file, or IR object file input; from command line or from archive files that llvm-nm should examine. The; mode must be one of the following:; ; 32; Process only 32-bit object files",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-nm.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-nm.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-nm.rst:3553,Modifiability,variab,variable,3553,"d. \-. Mach-O: N_STAB symbol. ?. Something unrecognizable. Because LLVM bitcode files typically contain objects that are not considered to; have addresses until they are linked into an executable image or dynamically; compiled ""just-in-time"", :program:`llvm-nm` does not print an address for any; symbol in an LLVM bitcode file, even symbols which are defined in the bitcode; file. OPTIONS; -------. .. program:: llvm-nm. .. option:: -B. Use BSD output format. Alias for ``--format=bsd``. .. option:: -X. Specify the type of XCOFF object file, ELF object file, or IR object file input; from command line or from archive files that llvm-nm should examine. The; mode must be one of the following:; ; 32; Process only 32-bit object files.; 64; Process only 64-bit object files.; 32_64; Process both 32-bit and 64-bit object files.; any; Process all the supported object files. On AIX OS, the default is to process 32-bit object files only and to ignore; 64-bit objects. The can be changed by setting the OBJECT_MODE environment; variable. For example, OBJECT_MODE=64 causes :program:`llvm-nm` to process; 64-bit objects and ignore 32-bit objects. The -X flag overrides the OBJECT_MODE; variable. On other operating systems, the default is to process all object files: the; OBJECT_MODE environment variable is not supported. .. option:: --debug-syms, -a. Show all symbols, even those usually suppressed. .. option:: --defined-only, -U. Print only symbols defined in this file. .. option:: --demangle, -C. Demangle symbol names. .. option:: --dynamic, -D. Display dynamic symbols instead of normal symbols. .. option:: --export-symbols. Print sorted symbols with their visibility (if applicable), with duplicates; removed. .. option:: --extern-only, -g. Print only symbols whose definitions are external; that is, accessible from; other files. .. option:: --format=<format>, -f. Select an output format; *format* may be *sysv*, *posix*, *darwin*, *bsd* or; *just-symbols*.; The default is *bsd*. .. option:",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-nm.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-nm.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-nm.rst:3710,Modifiability,variab,variable,3710,"re linked into an executable image or dynamically; compiled ""just-in-time"", :program:`llvm-nm` does not print an address for any; symbol in an LLVM bitcode file, even symbols which are defined in the bitcode; file. OPTIONS; -------. .. program:: llvm-nm. .. option:: -B. Use BSD output format. Alias for ``--format=bsd``. .. option:: -X. Specify the type of XCOFF object file, ELF object file, or IR object file input; from command line or from archive files that llvm-nm should examine. The; mode must be one of the following:; ; 32; Process only 32-bit object files.; 64; Process only 64-bit object files.; 32_64; Process both 32-bit and 64-bit object files.; any; Process all the supported object files. On AIX OS, the default is to process 32-bit object files only and to ignore; 64-bit objects. The can be changed by setting the OBJECT_MODE environment; variable. For example, OBJECT_MODE=64 causes :program:`llvm-nm` to process; 64-bit objects and ignore 32-bit objects. The -X flag overrides the OBJECT_MODE; variable. On other operating systems, the default is to process all object files: the; OBJECT_MODE environment variable is not supported. .. option:: --debug-syms, -a. Show all symbols, even those usually suppressed. .. option:: --defined-only, -U. Print only symbols defined in this file. .. option:: --demangle, -C. Demangle symbol names. .. option:: --dynamic, -D. Display dynamic symbols instead of normal symbols. .. option:: --export-symbols. Print sorted symbols with their visibility (if applicable), with duplicates; removed. .. option:: --extern-only, -g. Print only symbols whose definitions are external; that is, accessible from; other files. .. option:: --format=<format>, -f. Select an output format; *format* may be *sysv*, *posix*, *darwin*, *bsd* or; *just-symbols*.; The default is *bsd*. .. option:: --help, -h. Print a summary of command-line options and their meanings. .. option:: -j. Print just the symbol names. Alias for `--format=just-symbols``. .. option:: ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-nm.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-nm.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-nm.rst:3821,Modifiability,variab,variable,3821,"m-nm` does not print an address for any; symbol in an LLVM bitcode file, even symbols which are defined in the bitcode; file. OPTIONS; -------. .. program:: llvm-nm. .. option:: -B. Use BSD output format. Alias for ``--format=bsd``. .. option:: -X. Specify the type of XCOFF object file, ELF object file, or IR object file input; from command line or from archive files that llvm-nm should examine. The; mode must be one of the following:; ; 32; Process only 32-bit object files.; 64; Process only 64-bit object files.; 32_64; Process both 32-bit and 64-bit object files.; any; Process all the supported object files. On AIX OS, the default is to process 32-bit object files only and to ignore; 64-bit objects. The can be changed by setting the OBJECT_MODE environment; variable. For example, OBJECT_MODE=64 causes :program:`llvm-nm` to process; 64-bit objects and ignore 32-bit objects. The -X flag overrides the OBJECT_MODE; variable. On other operating systems, the default is to process all object files: the; OBJECT_MODE environment variable is not supported. .. option:: --debug-syms, -a. Show all symbols, even those usually suppressed. .. option:: --defined-only, -U. Print only symbols defined in this file. .. option:: --demangle, -C. Demangle symbol names. .. option:: --dynamic, -D. Display dynamic symbols instead of normal symbols. .. option:: --export-symbols. Print sorted symbols with their visibility (if applicable), with duplicates; removed. .. option:: --extern-only, -g. Print only symbols whose definitions are external; that is, accessible from; other files. .. option:: --format=<format>, -f. Select an output format; *format* may be *sysv*, *posix*, *darwin*, *bsd* or; *just-symbols*.; The default is *bsd*. .. option:: --help, -h. Print a summary of command-line options and their meanings. .. option:: -j. Print just the symbol names. Alias for `--format=just-symbols``. .. option:: --line-numbers, -l. Use debugging information to print the filenames and line numbers wh",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-nm.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-nm.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-nm.rst:5285,Modifiability,portab,portability,5285,"symbols whose definitions are external; that is, accessible from; other files. .. option:: --format=<format>, -f. Select an output format; *format* may be *sysv*, *posix*, *darwin*, *bsd* or; *just-symbols*.; The default is *bsd*. .. option:: --help, -h. Print a summary of command-line options and their meanings. .. option:: -j. Print just the symbol names. Alias for `--format=just-symbols``. .. option:: --line-numbers, -l. Use debugging information to print the filenames and line numbers where; symbols are defined. Undefined symbols have the location of their first; relocation printed instead. .. option:: -m. Use Darwin format. Alias for ``--format=darwin``. .. option:: --no-demangle. Don't demangle symbol names. This is the default. .. option:: --no-llvm-bc. Disable the LLVM bitcode reader. .. option:: --no-sort, -p. Show symbols in the order encountered. .. option:: --no-weak, -W. Don't print weak symbols. .. option:: --numeric-sort, -n, -v. Sort symbols by address. .. option:: --portability, -P. Use POSIX.2 output format. Alias for ``--format=posix``. .. option:: --print-armap. Print the archive symbol table, in addition to the symbols. .. option:: --print-file-name, -A, -o. Precede each symbol with the file it came from. .. option:: --print-size, -S. Show symbol size as well as address (not applicable for Mach-O). .. option:: --quiet. Suppress 'no symbols' diagnostic. .. option:: --radix=<RADIX>, -t. Specify the radix of the symbol address(es). Values accepted are *d* (decimal),; *x* (hexadecimal) and *o* (octal). .. option:: --reverse-sort, -r. Sort symbols in reverse order. .. option:: --size-sort. Sort symbols by size. .. option:: --special-syms. Do not filter special symbols from the output. .. option:: --undefined-only, -u. Print only undefined symbols. .. option:: --version, -V. Display the version of the :program:`llvm-nm` executable, then exit. Does not; stack with other commands. .. option:: @<FILE>. Read command-line options from response file `<FILE>",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-nm.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-nm.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-nm.rst:4336,Security,access,accessible,4336,"th 32-bit and 64-bit object files.; any; Process all the supported object files. On AIX OS, the default is to process 32-bit object files only and to ignore; 64-bit objects. The can be changed by setting the OBJECT_MODE environment; variable. For example, OBJECT_MODE=64 causes :program:`llvm-nm` to process; 64-bit objects and ignore 32-bit objects. The -X flag overrides the OBJECT_MODE; variable. On other operating systems, the default is to process all object files: the; OBJECT_MODE environment variable is not supported. .. option:: --debug-syms, -a. Show all symbols, even those usually suppressed. .. option:: --defined-only, -U. Print only symbols defined in this file. .. option:: --demangle, -C. Demangle symbol names. .. option:: --dynamic, -D. Display dynamic symbols instead of normal symbols. .. option:: --export-symbols. Print sorted symbols with their visibility (if applicable), with duplicates; removed. .. option:: --extern-only, -g. Print only symbols whose definitions are external; that is, accessible from; other files. .. option:: --format=<format>, -f. Select an output format; *format* may be *sysv*, *posix*, *darwin*, *bsd* or; *just-symbols*.; The default is *bsd*. .. option:: --help, -h. Print a summary of command-line options and their meanings. .. option:: -j. Print just the symbol names. Alias for `--format=just-symbols``. .. option:: --line-numbers, -l. Use debugging information to print the filenames and line numbers where; symbols are defined. Undefined symbols have the location of their first; relocation printed instead. .. option:: -m. Use Darwin format. Alias for ``--format=darwin``. .. option:: --no-demangle. Don't demangle symbol names. This is the default. .. option:: --no-llvm-bc. Disable the LLVM bitcode reader. .. option:: --no-sort, -p. Show symbols in the order encountered. .. option:: --no-weak, -W. Don't print weak symbols. .. option:: --numeric-sort, -n, -v. Sort symbols by address. .. option:: --portability, -P. Use POSIX.2 output",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-nm.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-nm.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-nm.rst:387,Usability,simpl,simple,387,"llvm-nm - list LLVM bitcode and object file's symbol table; ==========================================================. .. program:: llvm-nm. SYNOPSIS; --------. :program:`llvm-nm` [*options*] [*filenames...*]. DESCRIPTION; -----------. The :program:`llvm-nm` utility lists the names of symbols from LLVM bitcode; files, object files, and archives. Each symbol is listed along with some simple; information about its provenance. If no filename is specified, *a.out* is used; as the input. If *-* is used as a filename, :program:`llvm-nm` will read a file; from its standard input stream. :program:`llvm-nm`'s default output format is the traditional BSD :program:`nm`; output format. Each such output record consists of an (optional) 8-digit; hexadecimal address, followed by a type code character, followed by a name, for; each symbol. One record is printed per line; fields are separated by spaces.; When the address is omitted, it is replaced by 8 spaces. The supported type code characters are as follows. Where both lower and; upper-case characters are listed for the same meaning, a lower-case character; represents a local symbol, whilst an upper-case character represents a global; (external) symbol:. a, A. Absolute symbol. b, B. Uninitialized data (bss) object. C. Common symbol. Multiple definitions link together into one definition. d, D. Writable data object. i, I. COFF: .idata symbol or symbol in a section with IMAGE_SCN_LNK_INFO set. n. ELF: local symbol from non-alloc section. COFF: debug symbol. N. ELF: debug section symbol, or global symbol from non-alloc section. s, S. COFF: section symbol. Mach-O: absolute symbol or symbol from a section other than __TEXT_EXEC __text,; __TEXT __text, __DATA __data, or __DATA __bss. r, R. Read-only data object. t, T. Code (text) object. u. ELF: GNU unique symbol. U. Named object is undefined in this file. v. ELF: Undefined weak object. It is not a link failure if the object is not; defined. V. ELF: Defined weak object symbol. This defi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-nm.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-nm.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst:9796,Availability,error,error,9796,"lowing special symbols:. ====================== ========================= ==================; Character Meaning Equivalent; ====================== ========================= ==================; ``*`` Any number of characters ``.*``; ``?`` Any single character ``.``; ``\`` Escape the next character ``\``; ``[a-z]`` Character class ``[a-z]``; ``[!a-z]``, ``[^a-z]`` Negated character class ``[^a-z]``; ====================== ========================= ==================. Additionally, starting a wildcard with '!' will prevent a match, even if; another flag matches. For example ``-w -N '*' -N '!x'`` will strip all symbols; except for ``x``. The order of wildcards does not matter. For example, ``-w -N '*' -N '!x'`` is; the same as ``-w -N '!x' -N '*'``. .. option:: @<FILE>. Read command-line options and commands from response file `<FILE>`. ELF-SPECIFIC OPTIONS; --------------------. The following options are implemented only for ELF objects. If used with other; objects, :program:`llvm-objcopy` will either emit an error or silently ignore; them. .. option:: --add-symbol <name>=[<section>:]<value>[,<flags>]. Add a new symbol called ``<name>`` to the output symbol table, in the section; named ``<section>``, with value ``<value>``. If ``<section>`` is not specified,; the symbol is added as an absolute symbol. The ``<flags>`` affect the symbol; properties. Accepted values are:. - `global` = the symbol will have global binding.; - `local` = the symbol will have local binding.; - `weak` = the symbol will have weak binding.; - `default` = the symbol will have default visibility.; - `hidden` = the symbol will have hidden visibility.; - `protected` = the symbol will have protected visibility.; - `file` = the symbol will be an `STT_FILE` symbol.; - `section` = the symbol will be an `STT_SECTION` symbol.; - `object` = the symbol will be an `STT_OBJECT` symbol.; - `function` = the symbol will be an `STT_FUNC` symbol.; - `indirect-function` = the symbol will be an `STT_GNU_IFUNC` symbol.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst:20229,Availability,error,error,20229,"e values are all bfdnames. - `binary`; - `ihex`; - `elf32-i386`; - `elf32-x86-64`; - `elf64-x86-64`; - `elf32-iamcu`; - `elf32-littlearm`; - `elf64-aarch64`; - `elf64-littleaarch64`; - `elf32-littleriscv`; - `elf64-littleriscv`; - `elf32-powerpc`; - `elf32-powerpcle`; - `elf64-powerpc`; - `elf64-powerpcle`; - `elf32-bigmips`; - `elf32-ntradbigmips`; - `elf32-ntradlittlemips`; - `elf32-tradbigmips`; - `elf32-tradlittlemips`; - `elf64-tradbigmips`; - `elf64-tradlittlemips`; - `elf32-sparc`; - `elf32-sparcel`; - `elf32-hexagon`; - `elf32-loongarch`; - `elf64-loongarch`; - `elf64-s390`. Additionally, all targets except `binary` and `ihex` can have `-freebsd` as a; suffix. BINARY INPUT AND OUTPUT; -----------------------. If `binary` is used as the value for :option:`--input-target`, the input file; will be embedded as a data section in an ELF relocatable object, with symbols; ``_binary_<file_name>_start``, ``_binary_<file_name>_end``, and; ``_binary_<file_name>_size`` representing the start, end and size of the data,; where ``<file_name>`` is the path of the input file as specified on the command; line with non-alphanumeric characters converted to ``_``. If `binary` is used as the value for :option:`--output-target`, the output file; will be a raw binary file, containing the memory image of the input file.; Symbols and relocation information will be discarded. The image will start at; the address of the first loadable section in the output. EXIT STATUS; -----------. :program:`llvm-objcopy` exits with a non-zero exit code if there is an error.; Otherwise, it exits with code 0. BUGS; ----. To report bugs, please visit <https://github.com/llvm/llvm-project/labels/tools:llvm-objcopy/strip/>. There is a known issue with :option:`--input-target` and :option:`--target`; causing only ``binary`` and ``ihex`` formats to have any effect. Other values; will be ignored and :program:`llvm-objcopy` will attempt to guess the input; format. SEE ALSO; --------. :manpage:`llvm-strip(1)`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst:4581,Deployability,update,update,4581," in the output. Can be specified; multiple times to rename multiple symbols. .. option:: --redefine-syms <filename>. Rename symbols in the output as described in the file ``<filename>``. In the; file, each line represents a single symbol to rename, with the old name and new; name separated by whitespace. Leading and trailing whitespace is ignored, as is; anything following a '#'. Can be specified multiple times to read names from; multiple files. .. option:: --regex. If specified, symbol and section names specified by other switches are treated; as extended POSIX regular expression patterns. .. option:: --remove-section <section>, -R. Remove the specified section from the output. Can be specified multiple times; to remove multiple sections simultaneously. For MachO objects, ``<section>`` must be formatted as; ``<segment name>,<section name>``. .. option:: --set-section-alignment <section>=<align>. Set the alignment of section ``<section>`` to ``<align>``. Can be specified; multiple times to update multiple sections. .. option:: --set-section-flags <section>=<flag>[,<flag>,...]. Set section properties in the output of section ``<section>`` based on the; specified ``<flag>`` values. Can be specified multiple times to update multiple; sections. Supported flag names are `alloc`, `load`, `noload`, `readonly`, `exclude`,; `debug`, `code`, `data`, `rom`, `share`, `contents`, `merge`, `strings`, and; `large`. Not all flags are meaningful for all object file formats or target; architectures. For ELF objects, the flags have the following effects:. - `alloc` = add the `SHF_ALLOC` flag.; - `load` = if the section has `SHT_NOBITS` type, mark it as a `SHT_PROGBITS`; section.; - `readonly` = if this flag is not specified, add the `SHF_WRITE` flag.; - `exclude` = add the `SHF_EXCLUDE` flag.; - `code` = add the `SHF_EXECINSTR` flag.; - `merge` = add the `SHF_MERGE` flag.; - `strings` = add the `SHF_STRINGS` flag.; - `contents` = if the section has `SHT_NOBITS` type, mark it as a `SH",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst:4810,Deployability,update,update,4810," symbol to rename, with the old name and new; name separated by whitespace. Leading and trailing whitespace is ignored, as is; anything following a '#'. Can be specified multiple times to read names from; multiple files. .. option:: --regex. If specified, symbol and section names specified by other switches are treated; as extended POSIX regular expression patterns. .. option:: --remove-section <section>, -R. Remove the specified section from the output. Can be specified multiple times; to remove multiple sections simultaneously. For MachO objects, ``<section>`` must be formatted as; ``<segment name>,<section name>``. .. option:: --set-section-alignment <section>=<align>. Set the alignment of section ``<section>`` to ``<align>``. Can be specified; multiple times to update multiple sections. .. option:: --set-section-flags <section>=<flag>[,<flag>,...]. Set section properties in the output of section ``<section>`` based on the; specified ``<flag>`` values. Can be specified multiple times to update multiple; sections. Supported flag names are `alloc`, `load`, `noload`, `readonly`, `exclude`,; `debug`, `code`, `data`, `rom`, `share`, `contents`, `merge`, `strings`, and; `large`. Not all flags are meaningful for all object file formats or target; architectures. For ELF objects, the flags have the following effects:. - `alloc` = add the `SHF_ALLOC` flag.; - `load` = if the section has `SHT_NOBITS` type, mark it as a `SHT_PROGBITS`; section.; - `readonly` = if this flag is not specified, add the `SHF_WRITE` flag.; - `exclude` = add the `SHF_EXCLUDE` flag.; - `code` = add the `SHF_EXECINSTR` flag.; - `merge` = add the `SHF_MERGE` flag.; - `strings` = add the `SHF_STRINGS` flag.; - `contents` = if the section has `SHT_NOBITS` type, mark it as a `SHT_PROGBITS`; section.; - `large` = add the `SHF_X86_64_LARGE` on x86_64; rejected if the target; architecture is not x86_64. For COFF objects, the flags have the following effects:. - `alloc` = add the `IMAGE_SCN_CNT_UNINITIALIZED",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst:8281,Deployability,update,update-section,8281,"the file ``<filename>``, from the; output. In the file, each line represents a single symbol name, with leading; and trailing whitespace ignored, as is anything following a '#'. Can be; specified multiple times to read names from multiple files. .. option:: --strip-unneeded-symbol <symbol>. Remove from the output all symbols named ``<symbol>`` that are local or; undefined and are not required by any relocation. .. option:: --strip-unneeded-symbols <filename>. Remove all symbols whose names appear in the file ``<filename>``, from the; output, if they are local or undefined and are not required by any relocation.; In the file, each line represents a single symbol name, with leading and; trailing whitespace ignored, as is anything following a '#'. Can be specified; multiple times to read names from multiple files. .. option:: --strip-unneeded. Remove from the output all local or undefined symbols that are not required by; relocations. Also remove all debug sections. .. option:: --update-section <name>=<file>. Replace the contents of the section ``<name>`` with contents from the file; ``<file>``. If the section ``<name>`` is part of a segment, the new contents; cannot be larger than the existing section. .. option:: --version, -V. Display the version of the :program:`llvm-objcopy` executable. .. option:: --wildcard, -w. Allow wildcard syntax for symbol-related flags. On by default for; section-related flags. Incompatible with --regex. Wildcard syntax allows the following special symbols:. ====================== ========================= ==================; Character Meaning Equivalent; ====================== ========================= ==================; ``*`` Any number of characters ``.*``; ``?`` Any single character ``.``; ``\`` Escape the next character ``\``; ``[a-z]`` Character class ``[a-z]``; ``[!a-z]``, ``[^a-z]`` Negated character class ``[^a-z]``; ====================== ========================= ==================. Additionally, starting a wildcard with '!' wil",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst:16494,Deployability,update,update,16494,"` or the input; file's format if that option is also unspecified. .. option:: --pad-to <address>. For binary outputs, pad the output to the load address ``<address>`` using a value; of zero or the value specified by :option:`--gap-fill`. .. option:: --prefix-alloc-sections <prefix>. Add ``<prefix>`` to the front of the names of all allocatable sections in the; output. .. option:: --prefix-symbols <prefix>. Add ``<prefix>`` to the front of every symbol name in the output. .. option:: --preserve-dates, -p. Preserve access and modification timestamps in the output. .. option:: --rename-section <old>=<new>[,<flag>,...]. Rename sections called ``<old>`` to ``<new>`` in the output, and apply any; specified ``<flag>`` values. See :option:`--set-section-flags` for a list of; supported flags. Can be specified multiple times to rename multiple sections. .. option:: --set-section-type <section>=<type>. Set the type of section ``<section>`` to the integer ``<type>``. Can be; specified multiple times to update multiple sections. .. option:: --set-start-addr <addr>. Set the start address of the output to ``<addr>``. Overrides any previously; specified :option:`--change-start` or :option:`--adjust-start` options. .. option:: --split-dwo <dwo-file>. Equivalent to running :program:`llvm-objcopy` with :option:`--extract-dwo` and; ``<dwo-file>`` as the output file and no other options, and then with; :option:`--strip-dwo` on the input file. .. option:: --strip-dwo. Remove all DWARF .dwo sections from the output. .. option:: --strip-non-alloc. Remove from the output all non-allocatable sections that are not within; segments. .. option:: --strip-sections. Remove from the output all section headers and all section data not within; segments. Note that many tools will not be able to use an object without; section headers. .. option:: --target <format>, -F. Equivalent to :option:`--input-target` and :option:`--output-target` for the; specified format. See `SUPPORTED FORMATS`_ for a list of ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst:18909,Energy Efficiency,power,powerpc,18909," a '#'. Can be specified multiple times to read names from multiple files. .. option:: --weaken. Mark all defined global symbols as weak in the output. MACH-O-SPECIFIC OPTIONS; -----------------------. .. option:: --keep-undefined. Keep undefined symbols, even if they would otherwise be stripped. COFF-SPECIFIC OPTIONS; ---------------------. .. option:: --subsystem <name>[:<version>]. Set the PE subsystem, and optionally subsystem version. SUPPORTED FORMATS; -----------------. The following values are currently supported by :program:`llvm-objcopy` for the; :option:`--input-target`, :option:`--output-target`, and :option:`--target`; options. For GNU :program:`objcopy` compatibility, the values are all bfdnames. - `binary`; - `ihex`; - `elf32-i386`; - `elf32-x86-64`; - `elf64-x86-64`; - `elf32-iamcu`; - `elf32-littlearm`; - `elf64-aarch64`; - `elf64-littleaarch64`; - `elf32-littleriscv`; - `elf64-littleriscv`; - `elf32-powerpc`; - `elf32-powerpcle`; - `elf64-powerpc`; - `elf64-powerpcle`; - `elf32-bigmips`; - `elf32-ntradbigmips`; - `elf32-ntradlittlemips`; - `elf32-tradbigmips`; - `elf32-tradlittlemips`; - `elf64-tradbigmips`; - `elf64-tradlittlemips`; - `elf32-sparc`; - `elf32-sparcel`; - `elf32-hexagon`; - `elf32-loongarch`; - `elf64-loongarch`; - `elf64-s390`. Additionally, all targets except `binary` and `ihex` can have `-freebsd` as a; suffix. BINARY INPUT AND OUTPUT; -----------------------. If `binary` is used as the value for :option:`--input-target`, the input file; will be embedded as a data section in an ELF relocatable object, with symbols; ``_binary_<file_name>_start``, ``_binary_<file_name>_end``, and; ``_binary_<file_name>_size`` representing the start, end and size of the data,; where ``<file_name>`` is the path of the input file as specified on the command; line with non-alphanumeric characters converted to ``_``. If `binary` is used as the value for :option:`--output-target`, the output file; will be a raw binary file, containing the memory image of ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst:18928,Energy Efficiency,power,powerpcle,18928," a '#'. Can be specified multiple times to read names from multiple files. .. option:: --weaken. Mark all defined global symbols as weak in the output. MACH-O-SPECIFIC OPTIONS; -----------------------. .. option:: --keep-undefined. Keep undefined symbols, even if they would otherwise be stripped. COFF-SPECIFIC OPTIONS; ---------------------. .. option:: --subsystem <name>[:<version>]. Set the PE subsystem, and optionally subsystem version. SUPPORTED FORMATS; -----------------. The following values are currently supported by :program:`llvm-objcopy` for the; :option:`--input-target`, :option:`--output-target`, and :option:`--target`; options. For GNU :program:`objcopy` compatibility, the values are all bfdnames. - `binary`; - `ihex`; - `elf32-i386`; - `elf32-x86-64`; - `elf64-x86-64`; - `elf32-iamcu`; - `elf32-littlearm`; - `elf64-aarch64`; - `elf64-littleaarch64`; - `elf32-littleriscv`; - `elf64-littleriscv`; - `elf32-powerpc`; - `elf32-powerpcle`; - `elf64-powerpc`; - `elf64-powerpcle`; - `elf32-bigmips`; - `elf32-ntradbigmips`; - `elf32-ntradlittlemips`; - `elf32-tradbigmips`; - `elf32-tradlittlemips`; - `elf64-tradbigmips`; - `elf64-tradlittlemips`; - `elf32-sparc`; - `elf32-sparcel`; - `elf32-hexagon`; - `elf32-loongarch`; - `elf64-loongarch`; - `elf64-s390`. Additionally, all targets except `binary` and `ihex` can have `-freebsd` as a; suffix. BINARY INPUT AND OUTPUT; -----------------------. If `binary` is used as the value for :option:`--input-target`, the input file; will be embedded as a data section in an ELF relocatable object, with symbols; ``_binary_<file_name>_start``, ``_binary_<file_name>_end``, and; ``_binary_<file_name>_size`` representing the start, end and size of the data,; where ``<file_name>`` is the path of the input file as specified on the command; line with non-alphanumeric characters converted to ``_``. If `binary` is used as the value for :option:`--output-target`, the output file; will be a raw binary file, containing the memory image of ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst:18949,Energy Efficiency,power,powerpc,18949," a '#'. Can be specified multiple times to read names from multiple files. .. option:: --weaken. Mark all defined global symbols as weak in the output. MACH-O-SPECIFIC OPTIONS; -----------------------. .. option:: --keep-undefined. Keep undefined symbols, even if they would otherwise be stripped. COFF-SPECIFIC OPTIONS; ---------------------. .. option:: --subsystem <name>[:<version>]. Set the PE subsystem, and optionally subsystem version. SUPPORTED FORMATS; -----------------. The following values are currently supported by :program:`llvm-objcopy` for the; :option:`--input-target`, :option:`--output-target`, and :option:`--target`; options. For GNU :program:`objcopy` compatibility, the values are all bfdnames. - `binary`; - `ihex`; - `elf32-i386`; - `elf32-x86-64`; - `elf64-x86-64`; - `elf32-iamcu`; - `elf32-littlearm`; - `elf64-aarch64`; - `elf64-littleaarch64`; - `elf32-littleriscv`; - `elf64-littleriscv`; - `elf32-powerpc`; - `elf32-powerpcle`; - `elf64-powerpc`; - `elf64-powerpcle`; - `elf32-bigmips`; - `elf32-ntradbigmips`; - `elf32-ntradlittlemips`; - `elf32-tradbigmips`; - `elf32-tradlittlemips`; - `elf64-tradbigmips`; - `elf64-tradlittlemips`; - `elf32-sparc`; - `elf32-sparcel`; - `elf32-hexagon`; - `elf32-loongarch`; - `elf64-loongarch`; - `elf64-s390`. Additionally, all targets except `binary` and `ihex` can have `-freebsd` as a; suffix. BINARY INPUT AND OUTPUT; -----------------------. If `binary` is used as the value for :option:`--input-target`, the input file; will be embedded as a data section in an ELF relocatable object, with symbols; ``_binary_<file_name>_start``, ``_binary_<file_name>_end``, and; ``_binary_<file_name>_size`` representing the start, end and size of the data,; where ``<file_name>`` is the path of the input file as specified on the command; line with non-alphanumeric characters converted to ``_``. If `binary` is used as the value for :option:`--output-target`, the output file; will be a raw binary file, containing the memory image of ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst:18968,Energy Efficiency,power,powerpcle,18968," a '#'. Can be specified multiple times to read names from multiple files. .. option:: --weaken. Mark all defined global symbols as weak in the output. MACH-O-SPECIFIC OPTIONS; -----------------------. .. option:: --keep-undefined. Keep undefined symbols, even if they would otherwise be stripped. COFF-SPECIFIC OPTIONS; ---------------------. .. option:: --subsystem <name>[:<version>]. Set the PE subsystem, and optionally subsystem version. SUPPORTED FORMATS; -----------------. The following values are currently supported by :program:`llvm-objcopy` for the; :option:`--input-target`, :option:`--output-target`, and :option:`--target`; options. For GNU :program:`objcopy` compatibility, the values are all bfdnames. - `binary`; - `ihex`; - `elf32-i386`; - `elf32-x86-64`; - `elf64-x86-64`; - `elf32-iamcu`; - `elf32-littlearm`; - `elf64-aarch64`; - `elf64-littleaarch64`; - `elf32-littleriscv`; - `elf64-littleriscv`; - `elf32-powerpc`; - `elf32-powerpcle`; - `elf64-powerpc`; - `elf64-powerpcle`; - `elf32-bigmips`; - `elf32-ntradbigmips`; - `elf32-ntradlittlemips`; - `elf32-tradbigmips`; - `elf32-tradlittlemips`; - `elf64-tradbigmips`; - `elf64-tradlittlemips`; - `elf32-sparc`; - `elf32-sparcel`; - `elf32-hexagon`; - `elf32-loongarch`; - `elf64-loongarch`; - `elf64-s390`. Additionally, all targets except `binary` and `ihex` can have `-freebsd` as a; suffix. BINARY INPUT AND OUTPUT; -----------------------. If `binary` is used as the value for :option:`--input-target`, the input file; will be embedded as a data section in an ELF relocatable object, with symbols; ``_binary_<file_name>_start``, ``_binary_<file_name>_end``, and; ``_binary_<file_name>_size`` representing the start, end and size of the data,; where ``<file_name>`` is the path of the input file as specified on the command; line with non-alphanumeric characters converted to ``_``. If `binary` is used as the value for :option:`--output-target`, the output file; will be a raw binary file, containing the memory image of ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst:4130,Modifiability,extend,extended,4130,"ections that are not; `SHT_NOTE` by making them `SHT_NOBITS` and shrinking the program headers where; possible. .. option:: --only-section <section>, -j. Remove all sections from the output, except for sections named ``<section>``.; Can be specified multiple times to keep multiple sections. For MachO objects, ``<section>`` must be formatted as; ``<segment name>,<section name>``. .. option:: --redefine-sym <old>=<new>. Rename symbols called ``<old>`` to ``<new>`` in the output. Can be specified; multiple times to rename multiple symbols. .. option:: --redefine-syms <filename>. Rename symbols in the output as described in the file ``<filename>``. In the; file, each line represents a single symbol to rename, with the old name and new; name separated by whitespace. Leading and trailing whitespace is ignored, as is; anything following a '#'. Can be specified multiple times to read names from; multiple files. .. option:: --regex. If specified, symbol and section names specified by other switches are treated; as extended POSIX regular expression patterns. .. option:: --remove-section <section>, -R. Remove the specified section from the output. Can be specified multiple times; to remove multiple sections simultaneously. For MachO objects, ``<section>`` must be formatted as; ``<segment name>,<section name>``. .. option:: --set-section-alignment <section>=<align>. Set the alignment of section ``<section>`` to ``<align>``. Can be specified; multiple times to update multiple sections. .. option:: --set-section-flags <section>=<flag>[,<flag>,...]. Set section properties in the output of section ``<section>`` based on the; specified ``<flag>`` values. Can be specified multiple times to update multiple; sections. Supported flag names are `alloc`, `load`, `noload`, `readonly`, `exclude`,; `debug`, `code`, `data`, `rom`, `share`, `contents`, `merge`, `strings`, and; `large`. Not all flags are meaningful for all object file formats or target; architectures. For ELF objects, the flags ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst:2493,Performance,perform,performed,2493," of type `SHT_NOTE`, if the name; starts with "".note"". Otherwise, it will have type `SHT_PROGBITS`. Can be; specified multiple times to add multiple sections. For MachO objects, ``<section>`` must be formatted as; ``<segment name>,<section name>``. .. option:: --binary-architecture <arch>, -B. Ignored for compatibility. .. option:: --disable-deterministic-archives, -U. Use real values for UIDs, GIDs and timestamps when updating archive member; headers. .. option:: --discard-all, -x. Remove most local symbols from the output. Different file formats may limit; this to a subset of the local symbols. For example, file and section symbols in; ELF objects will not be discarded. Additionally, remove all debug sections. .. option:: --dump-section <section>=<file>. Dump the contents of section ``<section>`` into the file ``<file>``. Can be; specified multiple times to dump multiple sections to different files.; ``<file>`` is unrelated to the input and output files provided to; :program:`llvm-objcopy` and as such the normal copying and editing; operations will still be performed. No operations are performed on the sections; prior to dumping them. For MachO objects, ``<section>`` must be formatted as; ``<segment name>,<section name>``. .. option:: --enable-deterministic-archives, -D. Enable deterministic mode when copying archives, i.e. use 0 for archive member; header UIDs, GIDs and timestamp fields. On by default. .. option:: --help, -h. Print a summary of command line options. .. option:: --only-keep-debug. Produce a debug file as the output that only preserves contents of sections; useful for debugging purposes. For ELF objects, this removes the contents of `SHF_ALLOC` sections that are not; `SHT_NOTE` by making them `SHT_NOBITS` and shrinking the program headers where; possible. .. option:: --only-section <section>, -j. Remove all sections from the output, except for sections named ``<section>``.; Can be specified multiple times to keep multiple sections. For MachO object",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst:2522,Performance,perform,performed,2522,"ltiple times to add multiple sections. For MachO objects, ``<section>`` must be formatted as; ``<segment name>,<section name>``. .. option:: --binary-architecture <arch>, -B. Ignored for compatibility. .. option:: --disable-deterministic-archives, -U. Use real values for UIDs, GIDs and timestamps when updating archive member; headers. .. option:: --discard-all, -x. Remove most local symbols from the output. Different file formats may limit; this to a subset of the local symbols. For example, file and section symbols in; ELF objects will not be discarded. Additionally, remove all debug sections. .. option:: --dump-section <section>=<file>. Dump the contents of section ``<section>`` into the file ``<file>``. Can be; specified multiple times to dump multiple sections to different files.; ``<file>`` is unrelated to the input and output files provided to; :program:`llvm-objcopy` and as such the normal copying and editing; operations will still be performed. No operations are performed on the sections; prior to dumping them. For MachO objects, ``<section>`` must be formatted as; ``<segment name>,<section name>``. .. option:: --enable-deterministic-archives, -D. Enable deterministic mode when copying archives, i.e. use 0 for archive member; header UIDs, GIDs and timestamp fields. On by default. .. option:: --help, -h. Print a summary of command line options. .. option:: --only-keep-debug. Produce a debug file as the output that only preserves contents of sections; useful for debugging purposes. For ELF objects, this removes the contents of `SHF_ALLOC` sections that are not; `SHT_NOTE` by making them `SHT_NOBITS` and shrinking the program headers where; possible. .. option:: --only-section <section>, -j. Remove all sections from the output, except for sections named ``<section>``.; Can be specified multiple times to keep multiple sections. For MachO objects, ``<section>`` must be formatted as; ``<segment name>,<section name>``. .. option:: --redefine-sym <old>=<new>. Rename",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst:4872,Performance,load,load,4872,"gnored, as is; anything following a '#'. Can be specified multiple times to read names from; multiple files. .. option:: --regex. If specified, symbol and section names specified by other switches are treated; as extended POSIX regular expression patterns. .. option:: --remove-section <section>, -R. Remove the specified section from the output. Can be specified multiple times; to remove multiple sections simultaneously. For MachO objects, ``<section>`` must be formatted as; ``<segment name>,<section name>``. .. option:: --set-section-alignment <section>=<align>. Set the alignment of section ``<section>`` to ``<align>``. Can be specified; multiple times to update multiple sections. .. option:: --set-section-flags <section>=<flag>[,<flag>,...]. Set section properties in the output of section ``<section>`` based on the; specified ``<flag>`` values. Can be specified multiple times to update multiple; sections. Supported flag names are `alloc`, `load`, `noload`, `readonly`, `exclude`,; `debug`, `code`, `data`, `rom`, `share`, `contents`, `merge`, `strings`, and; `large`. Not all flags are meaningful for all object file formats or target; architectures. For ELF objects, the flags have the following effects:. - `alloc` = add the `SHF_ALLOC` flag.; - `load` = if the section has `SHT_NOBITS` type, mark it as a `SHT_PROGBITS`; section.; - `readonly` = if this flag is not specified, add the `SHF_WRITE` flag.; - `exclude` = add the `SHF_EXCLUDE` flag.; - `code` = add the `SHF_EXECINSTR` flag.; - `merge` = add the `SHF_MERGE` flag.; - `strings` = add the `SHF_STRINGS` flag.; - `contents` = if the section has `SHT_NOBITS` type, mark it as a `SHT_PROGBITS`; section.; - `large` = add the `SHF_X86_64_LARGE` on x86_64; rejected if the target; architecture is not x86_64. For COFF objects, the flags have the following effects:. - `alloc` = add the `IMAGE_SCN_CNT_UNINITIALIZED_DATA` and `IMAGE_SCN_MEM_READ`; flags, unless the `load` flag is specified.; - `noload` = add the `IMAGE_SCN_LNK",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst:5181,Performance,load,load,5181,"move the specified section from the output. Can be specified multiple times; to remove multiple sections simultaneously. For MachO objects, ``<section>`` must be formatted as; ``<segment name>,<section name>``. .. option:: --set-section-alignment <section>=<align>. Set the alignment of section ``<section>`` to ``<align>``. Can be specified; multiple times to update multiple sections. .. option:: --set-section-flags <section>=<flag>[,<flag>,...]. Set section properties in the output of section ``<section>`` based on the; specified ``<flag>`` values. Can be specified multiple times to update multiple; sections. Supported flag names are `alloc`, `load`, `noload`, `readonly`, `exclude`,; `debug`, `code`, `data`, `rom`, `share`, `contents`, `merge`, `strings`, and; `large`. Not all flags are meaningful for all object file formats or target; architectures. For ELF objects, the flags have the following effects:. - `alloc` = add the `SHF_ALLOC` flag.; - `load` = if the section has `SHT_NOBITS` type, mark it as a `SHT_PROGBITS`; section.; - `readonly` = if this flag is not specified, add the `SHF_WRITE` flag.; - `exclude` = add the `SHF_EXCLUDE` flag.; - `code` = add the `SHF_EXECINSTR` flag.; - `merge` = add the `SHF_MERGE` flag.; - `strings` = add the `SHF_STRINGS` flag.; - `contents` = if the section has `SHT_NOBITS` type, mark it as a `SHT_PROGBITS`; section.; - `large` = add the `SHF_X86_64_LARGE` on x86_64; rejected if the target; architecture is not x86_64. For COFF objects, the flags have the following effects:. - `alloc` = add the `IMAGE_SCN_CNT_UNINITIALIZED_DATA` and `IMAGE_SCN_MEM_READ`; flags, unless the `load` flag is specified.; - `noload` = add the `IMAGE_SCN_LNK_REMOVE` and `IMAGE_SCN_MEM_READ` flags.; - `readonly` = if this flag is not specified, add the `IMAGE_SCN_MEM_WRITE`; flag.; - `exclude` = add the `IMAGE_SCN_LNK_REMOVE` and `IMAGE_SCN_MEM_READ` flags.; - `debug` = add the `IMAGE_SCN_CNT_INITIALIZED_DATA`,; `IMAGE_SCN_MEM_DISCARDABLE` and `IMAGE_SCN_",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst:5857,Performance,load,load,5857,"ultiple; sections. Supported flag names are `alloc`, `load`, `noload`, `readonly`, `exclude`,; `debug`, `code`, `data`, `rom`, `share`, `contents`, `merge`, `strings`, and; `large`. Not all flags are meaningful for all object file formats or target; architectures. For ELF objects, the flags have the following effects:. - `alloc` = add the `SHF_ALLOC` flag.; - `load` = if the section has `SHT_NOBITS` type, mark it as a `SHT_PROGBITS`; section.; - `readonly` = if this flag is not specified, add the `SHF_WRITE` flag.; - `exclude` = add the `SHF_EXCLUDE` flag.; - `code` = add the `SHF_EXECINSTR` flag.; - `merge` = add the `SHF_MERGE` flag.; - `strings` = add the `SHF_STRINGS` flag.; - `contents` = if the section has `SHT_NOBITS` type, mark it as a `SHT_PROGBITS`; section.; - `large` = add the `SHF_X86_64_LARGE` on x86_64; rejected if the target; architecture is not x86_64. For COFF objects, the flags have the following effects:. - `alloc` = add the `IMAGE_SCN_CNT_UNINITIALIZED_DATA` and `IMAGE_SCN_MEM_READ`; flags, unless the `load` flag is specified.; - `noload` = add the `IMAGE_SCN_LNK_REMOVE` and `IMAGE_SCN_MEM_READ` flags.; - `readonly` = if this flag is not specified, add the `IMAGE_SCN_MEM_WRITE`; flag.; - `exclude` = add the `IMAGE_SCN_LNK_REMOVE` and `IMAGE_SCN_MEM_READ` flags.; - `debug` = add the `IMAGE_SCN_CNT_INITIALIZED_DATA`,; `IMAGE_SCN_MEM_DISCARDABLE` and `IMAGE_SCN_MEM_READ` flags.; - `code` = add the `IMAGE_SCN_CNT_CODE`, `IMAGE_SCN_MEM_EXECUTE` and; `IMAGE_SCN_MEM_READ` flags.; - `data` = add the `IMAGE_SCN_CNT_INITIALIZED_DATA` and `IMAGE_SCN_MEM_READ`; flags.; - `share` = add the `IMAGE_SCN_MEM_SHARED` and `IMAGE_SCN_MEM_READ` flags. .. option:: --strip-all-gnu. Remove all symbols, debug sections and relocations from the output. This option; is equivalent to GNU :program:`objcopy`'s ``--strip-all`` switch. .. option:: --strip-all, -S. For ELF objects, remove from the output all symbols and non-alloc sections not; within segments, except for .gnu.war",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst:15628,Performance,load,load,15628,"es from the file ``<filename>`` and mark defined non-common; symbols with those names as local in the output. In the file, each line; represents a single symbol, with leading and trailing whitespace ignored, as is; anything following a '#'. Can be specified multiple times to read names from; multiple files. .. option:: --new-symbol-visibility <visibility>. Specify the visibility of the symbols automatically created when using binary; input or :option:`--add-symbol`. Valid options are:. - `default`; - `hidden`; - `internal`; - `protected`. The default is `default`. .. option:: --output-target <format>, -O. Write the output as the specified format. See `SUPPORTED FORMATS`_ for a list; of valid ``<format>`` values. If unspecified, the output format is assumed to; be the same as the value specified for :option:`--input-target` or the input; file's format if that option is also unspecified. .. option:: --pad-to <address>. For binary outputs, pad the output to the load address ``<address>`` using a value; of zero or the value specified by :option:`--gap-fill`. .. option:: --prefix-alloc-sections <prefix>. Add ``<prefix>`` to the front of the names of all allocatable sections in the; output. .. option:: --prefix-symbols <prefix>. Add ``<prefix>`` to the front of every symbol name in the output. .. option:: --preserve-dates, -p. Preserve access and modification timestamps in the output. .. option:: --rename-section <old>=<new>[,<flag>,...]. Rename sections called ``<old>`` to ``<new>`` in the output, and apply any; specified ``<flag>`` values. See :option:`--set-section-flags` for a list of; supported flags. Can be specified multiple times to rename multiple sections. .. option:: --set-section-type <section>=<type>. Set the type of section ``<section>`` to the integer ``<type>``. Can be; specified multiple times to update multiple sections. .. option:: --set-start-addr <addr>. Set the start address of the output to ``<addr>``. Overrides any previously; specified :option:`--",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst:20100,Performance,load,loadable,20100,"e values are all bfdnames. - `binary`; - `ihex`; - `elf32-i386`; - `elf32-x86-64`; - `elf64-x86-64`; - `elf32-iamcu`; - `elf32-littlearm`; - `elf64-aarch64`; - `elf64-littleaarch64`; - `elf32-littleriscv`; - `elf64-littleriscv`; - `elf32-powerpc`; - `elf32-powerpcle`; - `elf64-powerpc`; - `elf64-powerpcle`; - `elf32-bigmips`; - `elf32-ntradbigmips`; - `elf32-ntradlittlemips`; - `elf32-tradbigmips`; - `elf32-tradlittlemips`; - `elf64-tradbigmips`; - `elf64-tradlittlemips`; - `elf32-sparc`; - `elf32-sparcel`; - `elf32-hexagon`; - `elf32-loongarch`; - `elf64-loongarch`; - `elf64-s390`. Additionally, all targets except `binary` and `ihex` can have `-freebsd` as a; suffix. BINARY INPUT AND OUTPUT; -----------------------. If `binary` is used as the value for :option:`--input-target`, the input file; will be embedded as a data section in an ELF relocatable object, with symbols; ``_binary_<file_name>_start``, ``_binary_<file_name>_end``, and; ``_binary_<file_name>_size`` representing the start, end and size of the data,; where ``<file_name>`` is the path of the input file as specified on the command; line with non-alphanumeric characters converted to ``_``. If `binary` is used as the value for :option:`--output-target`, the output file; will be a raw binary file, containing the memory image of the input file.; Symbols and relocation information will be discarded. The image will start at; the address of the first loadable section in the output. EXIT STATUS; -----------. :program:`llvm-objcopy` exits with a non-zero exit code if there is an error.; Otherwise, it exits with code 0. BUGS; ----. To report bugs, please visit <https://github.com/llvm/llvm-project/labels/tools:llvm-objcopy/strip/>. There is a known issue with :option:`--input-target` and :option:`--target`; causing only ``binary`` and ``ihex`` formats to have any effect. Other values; will be ignored and :program:`llvm-objcopy` will attempt to guess the input; format. SEE ALSO; --------. :manpage:`llvm-strip(1)`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst:16007,Security,access,access,16007,"visibility of the symbols automatically created when using binary; input or :option:`--add-symbol`. Valid options are:. - `default`; - `hidden`; - `internal`; - `protected`. The default is `default`. .. option:: --output-target <format>, -O. Write the output as the specified format. See `SUPPORTED FORMATS`_ for a list; of valid ``<format>`` values. If unspecified, the output format is assumed to; be the same as the value specified for :option:`--input-target` or the input; file's format if that option is also unspecified. .. option:: --pad-to <address>. For binary outputs, pad the output to the load address ``<address>`` using a value; of zero or the value specified by :option:`--gap-fill`. .. option:: --prefix-alloc-sections <prefix>. Add ``<prefix>`` to the front of the names of all allocatable sections in the; output. .. option:: --prefix-symbols <prefix>. Add ``<prefix>`` to the front of every symbol name in the output. .. option:: --preserve-dates, -p. Preserve access and modification timestamps in the output. .. option:: --rename-section <old>=<new>[,<flag>,...]. Rename sections called ``<old>`` to ``<new>`` in the output, and apply any; specified ``<flag>`` values. See :option:`--set-section-flags` for a list of; supported flags. Can be specified multiple times to rename multiple sections. .. option:: --set-section-type <section>=<type>. Set the type of section ``<section>`` to the integer ``<type>``. Can be; specified multiple times to update multiple sections. .. option:: --set-start-addr <addr>. Set the start address of the output to ``<addr>``. Overrides any previously; specified :option:`--change-start` or :option:`--adjust-start` options. .. option:: --split-dwo <dwo-file>. Equivalent to running :program:`llvm-objcopy` with :option:`--extract-dwo` and; ``<dwo-file>`` as the output file and no other options, and then with; :option:`--strip-dwo` on the input file. .. option:: --strip-dwo. Remove all DWARF .dwo sections from the output. .. option:: --strip-",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objcopy.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objdump.rst:1663,Availability,fault,fault-map-section,1663,"mmands:. .. option:: -a, --archive-headers. Display the information contained within an archive's headers. .. option:: -d, --disassemble. Disassemble all executable sections found in the input files. On some; architectures (AArch64, PowerPC, x86), all known instructions are disassembled by; default. On the others, :option:`--mcpu` or :option:`--mattr` is needed to; enable some instruction sets. Disabled instructions are displayed as; ``<unknown>``. .. option:: -D, --disassemble-all. Disassemble all sections found in the input files. .. option:: --disassemble-symbols=<symbol1[,symbol2,...]>. Disassemble only the specified symbols. Takes demangled symbol names when; :option:`--demangle` is specified, otherwise takes mangled symbol names.; Implies :option:`--disassemble`. .. option:: --dwarf=<value>. Dump the specified DWARF debug sections. The supported values are:. `frames` - .debug_frame. .. option:: -f, --file-headers. Display the contents of the overall file header. .. option:: --fault-map-section. Display the content of the fault map section. .. option:: -h, --headers, --section-headers. Display summaries of the headers for each section. .. option:: --help. Display usage information and exit. Does not stack with other commands. .. option:: -p, --private-headers. Display format-specific file headers. .. option:: -r, --reloc. Display the relocation entries in the file. .. option:: -R, --dynamic-reloc. Display the dynamic relocation entries in the file. .. option:: --raw-clang-ast. Dump the raw binary contents of the clang AST section. .. option:: -s, --full-contents. Display the contents of each section. .. option:: -t, --syms. Display the symbol table. .. option:: -T, --dynamic-syms. Display the contents of the dynamic symbol table. .. option:: -u, --unwind-info. Display the unwind info of the input(s). This operation is only currently supported for COFF and Mach-O object files. .. option:: -v, --version. Display the version of the :program:`llvm-objdump` executab",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objdump.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objdump.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objdump.rst:1709,Availability,fault,fault,1709,"ders. Display the information contained within an archive's headers. .. option:: -d, --disassemble. Disassemble all executable sections found in the input files. On some; architectures (AArch64, PowerPC, x86), all known instructions are disassembled by; default. On the others, :option:`--mcpu` or :option:`--mattr` is needed to; enable some instruction sets. Disabled instructions are displayed as; ``<unknown>``. .. option:: -D, --disassemble-all. Disassemble all sections found in the input files. .. option:: --disassemble-symbols=<symbol1[,symbol2,...]>. Disassemble only the specified symbols. Takes demangled symbol names when; :option:`--demangle` is specified, otherwise takes mangled symbol names.; Implies :option:`--disassemble`. .. option:: --dwarf=<value>. Dump the specified DWARF debug sections. The supported values are:. `frames` - .debug_frame. .. option:: -f, --file-headers. Display the contents of the overall file header. .. option:: --fault-map-section. Display the content of the fault map section. .. option:: -h, --headers, --section-headers. Display summaries of the headers for each section. .. option:: --help. Display usage information and exit. Does not stack with other commands. .. option:: -p, --private-headers. Display format-specific file headers. .. option:: -r, --reloc. Display the relocation entries in the file. .. option:: -R, --dynamic-reloc. Display the dynamic relocation entries in the file. .. option:: --raw-clang-ast. Dump the raw binary contents of the clang AST section. .. option:: -s, --full-contents. Display the contents of each section. .. option:: -t, --syms. Display the symbol table. .. option:: -T, --dynamic-syms. Display the contents of the dynamic symbol table. .. option:: -u, --unwind-info. Display the unwind info of the input(s). This operation is only currently supported for COFF and Mach-O object files. .. option:: -v, --version. Display the version of the :program:`llvm-objdump` executable. Does not stack; with other command",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objdump.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objdump.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objdump.rst:2750,Availability,avail,available,2750,"ection-headers. Display summaries of the headers for each section. .. option:: --help. Display usage information and exit. Does not stack with other commands. .. option:: -p, --private-headers. Display format-specific file headers. .. option:: -r, --reloc. Display the relocation entries in the file. .. option:: -R, --dynamic-reloc. Display the dynamic relocation entries in the file. .. option:: --raw-clang-ast. Dump the raw binary contents of the clang AST section. .. option:: -s, --full-contents. Display the contents of each section. .. option:: -t, --syms. Display the symbol table. .. option:: -T, --dynamic-syms. Display the contents of the dynamic symbol table. .. option:: -u, --unwind-info. Display the unwind info of the input(s). This operation is only currently supported for COFF and Mach-O object files. .. option:: -v, --version. Display the version of the :program:`llvm-objdump` executable. Does not stack; with other commands. .. option:: -x, --all-headers. Display all available header information. Equivalent to specifying; :option:`--archive-headers`, :option:`--file-headers`,; :option:`--private-headers`, :option:`--reloc`, :option:`--section-headers`,; and :option:`--syms`. OPTIONS; -------; :program:`llvm-objdump` supports the following options:. .. option:: --adjust-vma=<offset>. Increase the displayed address in disassembly or section header printing by; the specified offset. .. option:: --arch-name=<string>. Specify the target architecture when disassembling. Use :option:`--version`; for a list of available targets. .. option:: --build-id=<string>. Look up the object using the given build ID, specified as a hexadecimal; string. The found object is handled as if it were an input filename. .. option:: -C, --demangle. Demangle symbol names in the output. .. option:: --debug-file-directory <path>. Provide a path to a directory with a `.build-id` subdirectory to search for; debug information for stripped binaries. Multiple instances of this argument; are s",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objdump.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objdump.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objdump.rst:3296,Availability,avail,available,3296,"each section. .. option:: -t, --syms. Display the symbol table. .. option:: -T, --dynamic-syms. Display the contents of the dynamic symbol table. .. option:: -u, --unwind-info. Display the unwind info of the input(s). This operation is only currently supported for COFF and Mach-O object files. .. option:: -v, --version. Display the version of the :program:`llvm-objdump` executable. Does not stack; with other commands. .. option:: -x, --all-headers. Display all available header information. Equivalent to specifying; :option:`--archive-headers`, :option:`--file-headers`,; :option:`--private-headers`, :option:`--reloc`, :option:`--section-headers`,; and :option:`--syms`. OPTIONS; -------; :program:`llvm-objdump` supports the following options:. .. option:: --adjust-vma=<offset>. Increase the displayed address in disassembly or section header printing by; the specified offset. .. option:: --arch-name=<string>. Specify the target architecture when disassembling. Use :option:`--version`; for a list of available targets. .. option:: --build-id=<string>. Look up the object using the given build ID, specified as a hexadecimal; string. The found object is handled as if it were an input filename. .. option:: -C, --demangle. Demangle symbol names in the output. .. option:: --debug-file-directory <path>. Provide a path to a directory with a `.build-id` subdirectory to search for; debug information for stripped binaries. Multiple instances of this argument; are searched in the order given. .. option:: --debuginfod, --no-debuginfod. Whether or not to try debuginfod lookups for debug binaries. Unless specified,; debuginfod is only enabled if libcurl was compiled in (``LLVM_ENABLE_CURL``); and at least one server URL was provided by the environment variable; ``DEBUGINFOD_URLS``. .. option:: --debug-vars=<format>. Print the locations (in registers or memory) of source-level variables; alongside disassembly. ``format`` may be ``unicode`` or ``ascii``, defaulting; to ``unicode`` if omi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objdump.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objdump.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objdump.rst:5765,Availability,avail,available,5765,"disassembler-options=<opt1[,opt2,...]>. Pass target-specific disassembler options. Available options:. * ``reg-names-std``: ARM only (default). Print in ARM 's instruction set documentation, with r13/r14/r15 replaced by sp/lr/pc.; * ``reg-names-raw``: ARM only. Use r followed by the register number.; * ``no-aliases``: AArch64 and RISC-V only. Print raw instruction mnemonic instead of pseudo instruction mnemonic.; * ``numeric``: RISC-V only. Print raw register names instead of ABI mnemonic. (e.g. print x1 instead of ra); * ``att``: x86 only (default). Print in the AT&T syntax.; * ``intel``: x86 only. Print in the intel syntax. .. option:: --disassembler-color=<mode>. Enable or disable disassembler color output. * ``off``: Disable disassembler color output.; * ``on``: Enable disassembler color output.; * ``terminal``: Enable disassembler color output if the terminal supports it (default). .. option:: --mcpu=<cpu-name>. Target a specific CPU type for disassembly. Specify ``--mcpu=help`` to display; available CPUs. .. option:: --mattr=<a1,+a2,-a3,...>. Enable/disable target-specific attributes. Specify ``--mattr=help`` to display; the available attributes. .. option:: -mllvm <arg>. Specify an argument to forward to LLVM's CommandLine library. .. option:: --no-leading-addr, --no-addresses. When disassembling, do not print leading addresses for instructions or inline; relocations. .. option:: --no-print-imm-hex. Do not use hex format for immediate values in disassembly output. .. option:: --no-show-raw-insn. When disassembling, do not print the raw bytes of each instruction. .. option:: --offloading. Display the content of the LLVM offloading section. .. option:: --prefix=<prefix>. When disassembling with the :option:`--source` option, prepend ``prefix`` to; absolute paths. .. option:: --prefix-strip=<level>. When disassembling with the :option:`--source` option, strip out ``level``; initial directories from absolute paths. This option has no effect without; :option:`--pr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objdump.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objdump.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objdump.rst:5903,Availability,avail,available,5903,"ult). Print in ARM 's instruction set documentation, with r13/r14/r15 replaced by sp/lr/pc.; * ``reg-names-raw``: ARM only. Use r followed by the register number.; * ``no-aliases``: AArch64 and RISC-V only. Print raw instruction mnemonic instead of pseudo instruction mnemonic.; * ``numeric``: RISC-V only. Print raw register names instead of ABI mnemonic. (e.g. print x1 instead of ra); * ``att``: x86 only (default). Print in the AT&T syntax.; * ``intel``: x86 only. Print in the intel syntax. .. option:: --disassembler-color=<mode>. Enable or disable disassembler color output. * ``off``: Disable disassembler color output.; * ``on``: Enable disassembler color output.; * ``terminal``: Enable disassembler color output if the terminal supports it (default). .. option:: --mcpu=<cpu-name>. Target a specific CPU type for disassembly. Specify ``--mcpu=help`` to display; available CPUs. .. option:: --mattr=<a1,+a2,-a3,...>. Enable/disable target-specific attributes. Specify ``--mattr=help`` to display; the available attributes. .. option:: -mllvm <arg>. Specify an argument to forward to LLVM's CommandLine library. .. option:: --no-leading-addr, --no-addresses. When disassembling, do not print leading addresses for instructions or inline; relocations. .. option:: --no-print-imm-hex. Do not use hex format for immediate values in disassembly output. .. option:: --no-show-raw-insn. When disassembling, do not print the raw bytes of each instruction. .. option:: --offloading. Display the content of the LLVM offloading section. .. option:: --prefix=<prefix>. When disassembling with the :option:`--source` option, prepend ``prefix`` to; absolute paths. .. option:: --prefix-strip=<level>. When disassembling with the :option:`--source` option, strip out ``level``; initial directories from absolute paths. This option has no effect without; :option:`--prefix`. .. option:: --print-imm-hex. Use hex format when printing immediate values in disassembly output (default). .. option:: -S, --source",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objdump.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objdump.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objdump.rst:8638,Availability,avail,available,8638,"isassemble up to, but not including the specified address. When printing relocations, only print the relocations patching offsets up to ``address``. When printing symbols, only print symbols with a value up to ``address``. .. option:: --symbolize-operands. When disassembling, symbolize a branch target operand to print a label instead of a real address. When printing a PC-relative global symbol reference, print it as an offset from the leading symbol. When a bb-address-map section is present (i.e., the object file is built with ``-fbasic-block-sections=labels``), labels are retrieved from that section instead. Only works with PowerPC objects or X86 linked images. Example:; A non-symbolized branch instruction with a local target and pc-relative memory access like. .. code-block:: none. cmp eax, dword ptr [rip + 4112]; jge 0x20117e <_start+0x25>. might become. .. code-block:: none. <L0>:; cmp eax, dword ptr <g>; jge	<L0>. .. option:: --triple=<string>. Target triple to disassemble for, see ``--version`` for available targets. .. option:: -w, --wide. Ignored for compatibility with GNU objdump. .. option:: --x86-asm-syntax=<style>. Deprecated.; When used with :option:`--disassemble`, choose style of code to emit from; X86 backend. Supported values are:. .. option:: att. AT&T-style assembly. .. option:: intel. Intel-style assembly. The default disassembly style is **att**. .. option:: -z, --disassemble-zeroes. Do not skip blocks of zeroes when disassembling. .. option:: @<FILE>. Read command-line options and commands from response file `<FILE>`. MACH-O ONLY OPTIONS AND COMMANDS; --------------------------------. .. option:: --arch=<architecture>. Specify the architecture to disassemble. see ``--version`` for available; architectures. .. option:: --archive-member-offsets. Print the offset to each archive member for Mach-O archives (requires; :option:`--archive-headers`). .. option:: --bind. Display binding info. .. option:: --data-in-code. Display the data in code table. ..",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objdump.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objdump.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objdump.rst:9350,Availability,avail,available,9350,"get and pc-relative memory access like. .. code-block:: none. cmp eax, dword ptr [rip + 4112]; jge 0x20117e <_start+0x25>. might become. .. code-block:: none. <L0>:; cmp eax, dword ptr <g>; jge	<L0>. .. option:: --triple=<string>. Target triple to disassemble for, see ``--version`` for available targets. .. option:: -w, --wide. Ignored for compatibility with GNU objdump. .. option:: --x86-asm-syntax=<style>. Deprecated.; When used with :option:`--disassemble`, choose style of code to emit from; X86 backend. Supported values are:. .. option:: att. AT&T-style assembly. .. option:: intel. Intel-style assembly. The default disassembly style is **att**. .. option:: -z, --disassemble-zeroes. Do not skip blocks of zeroes when disassembling. .. option:: @<FILE>. Read command-line options and commands from response file `<FILE>`. MACH-O ONLY OPTIONS AND COMMANDS; --------------------------------. .. option:: --arch=<architecture>. Specify the architecture to disassemble. see ``--version`` for available; architectures. .. option:: --archive-member-offsets. Print the offset to each archive member for Mach-O archives (requires; :option:`--archive-headers`). .. option:: --bind. Display binding info. .. option:: --data-in-code. Display the data in code table. .. option:: --dis-symname=<name>. Disassemble just the specified symbol's instructions. .. option:: --chained-fixups. Print chained fixup information. .. option:: --dyld-info. Print bind and rebase information used by dyld to resolve external; references in a final linked binary. .. option:: --dylibs-used. Display the shared libraries used for linked files. .. option:: --dsym=<string>. Use .dSYM file for debug info. .. option:: --dylib-id. Display the shared library's ID for dylib files. .. option:: --exports-trie. Display exported symbols. .. option:: --function-starts [=<addrs|names|both>]. Print the function starts table for Mach-O objects. Either ``addrs``; (default) to print only the addresses of functions, ``names`` to",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objdump.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objdump.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objdump.rst:10397,Availability,avail,available,10397,"itectures. .. option:: --archive-member-offsets. Print the offset to each archive member for Mach-O archives (requires; :option:`--archive-headers`). .. option:: --bind. Display binding info. .. option:: --data-in-code. Display the data in code table. .. option:: --dis-symname=<name>. Disassemble just the specified symbol's instructions. .. option:: --chained-fixups. Print chained fixup information. .. option:: --dyld-info. Print bind and rebase information used by dyld to resolve external; references in a final linked binary. .. option:: --dylibs-used. Display the shared libraries used for linked files. .. option:: --dsym=<string>. Use .dSYM file for debug info. .. option:: --dylib-id. Display the shared library's ID for dylib files. .. option:: --exports-trie. Display exported symbols. .. option:: --function-starts [=<addrs|names|both>]. Print the function starts table for Mach-O objects. Either ``addrs``; (default) to print only the addresses of functions, ``names`` to print only; the names of the functions (when available), or ``both`` to print the; names beside the addresses. .. option:: -g. Print line information from debug info if available. .. option:: --full-leading-addr. Print the full leading address when disassembling. .. option:: --indirect-symbols. Display the indirect symbol table. .. option:: --info-plist. Display the info plist section as strings. .. option:: --lazy-bind. Display lazy binding info. .. option:: --link-opt-hints. Display the linker optimization hints. .. option:: -m, --macho. Use Mach-O specific object file parser. Commands and other options may behave; differently when used with ``--macho``. .. option:: --no-leading-headers. Do not print any leading headers. .. option:: --no-symbolic-operands. Do not print symbolic operands when disassembling. .. option:: --non-verbose. Display the information for Mach-O objects in non-verbose or numeric form. .. option:: --objc-meta-data. Display the Objective-C runtime meta data. .. option:: --priv",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objdump.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objdump.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objdump.rst:10521,Availability,avail,available,10521,"headers`). .. option:: --bind. Display binding info. .. option:: --data-in-code. Display the data in code table. .. option:: --dis-symname=<name>. Disassemble just the specified symbol's instructions. .. option:: --chained-fixups. Print chained fixup information. .. option:: --dyld-info. Print bind and rebase information used by dyld to resolve external; references in a final linked binary. .. option:: --dylibs-used. Display the shared libraries used for linked files. .. option:: --dsym=<string>. Use .dSYM file for debug info. .. option:: --dylib-id. Display the shared library's ID for dylib files. .. option:: --exports-trie. Display exported symbols. .. option:: --function-starts [=<addrs|names|both>]. Print the function starts table for Mach-O objects. Either ``addrs``; (default) to print only the addresses of functions, ``names`` to print only; the names of the functions (when available), or ``both`` to print the; names beside the addresses. .. option:: -g. Print line information from debug info if available. .. option:: --full-leading-addr. Print the full leading address when disassembling. .. option:: --indirect-symbols. Display the indirect symbol table. .. option:: --info-plist. Display the info plist section as strings. .. option:: --lazy-bind. Display lazy binding info. .. option:: --link-opt-hints. Display the linker optimization hints. .. option:: -m, --macho. Use Mach-O specific object file parser. Commands and other options may behave; differently when used with ``--macho``. .. option:: --no-leading-headers. Do not print any leading headers. .. option:: --no-symbolic-operands. Do not print symbolic operands when disassembling. .. option:: --non-verbose. Display the information for Mach-O objects in non-verbose or numeric form. .. option:: --objc-meta-data. Display the Objective-C runtime meta data. .. option:: --private-header. Display only the first format specific file header. .. option:: --rebase. Display rebasing information. .. option:: --rpaths. Di",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objdump.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objdump.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objdump.rst:7430,Deployability,patch,patching,7430,"on. .. option:: --prefix=<prefix>. When disassembling with the :option:`--source` option, prepend ``prefix`` to; absolute paths. .. option:: --prefix-strip=<level>. When disassembling with the :option:`--source` option, strip out ``level``; initial directories from absolute paths. This option has no effect without; :option:`--prefix`. .. option:: --print-imm-hex. Use hex format when printing immediate values in disassembly output (default). .. option:: -S, --source. When disassembling, display source interleaved with the disassembly. Implies; :option:`--disassemble`. .. option:: --show-all-symbols. Show all symbols during disassembly, even if multiple symbols are defined at; the same location. .. option:: --show-lma. Display the LMA column when dumping ELF section headers. Defaults to off; unless any section has different VMA and LMAs. .. option:: --start-address=<address>. When disassembling, only disassemble from the specified address. When printing relocations, only print the relocations patching offsets from at least ``address``. When printing symbols, only print symbols with a value of at least ``address``. .. option:: --stop-address=<address>. When disassembling, only disassemble up to, but not including the specified address. When printing relocations, only print the relocations patching offsets up to ``address``. When printing symbols, only print symbols with a value up to ``address``. .. option:: --symbolize-operands. When disassembling, symbolize a branch target operand to print a label instead of a real address. When printing a PC-relative global symbol reference, print it as an offset from the leading symbol. When a bb-address-map section is present (i.e., the object file is built with ``-fbasic-block-sections=labels``), labels are retrieved from that section instead. Only works with PowerPC objects or X86 linked images. Example:; A non-symbolized branch instruction with a local target and pc-relative memory access like. .. code-block:: none. cmp eax, dw",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objdump.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objdump.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objdump.rst:7731,Deployability,patch,patching,7731," no effect without; :option:`--prefix`. .. option:: --print-imm-hex. Use hex format when printing immediate values in disassembly output (default). .. option:: -S, --source. When disassembling, display source interleaved with the disassembly. Implies; :option:`--disassemble`. .. option:: --show-all-symbols. Show all symbols during disassembly, even if multiple symbols are defined at; the same location. .. option:: --show-lma. Display the LMA column when dumping ELF section headers. Defaults to off; unless any section has different VMA and LMAs. .. option:: --start-address=<address>. When disassembling, only disassemble from the specified address. When printing relocations, only print the relocations patching offsets from at least ``address``. When printing symbols, only print symbols with a value of at least ``address``. .. option:: --stop-address=<address>. When disassembling, only disassemble up to, but not including the specified address. When printing relocations, only print the relocations patching offsets up to ``address``. When printing symbols, only print symbols with a value up to ``address``. .. option:: --symbolize-operands. When disassembling, symbolize a branch target operand to print a label instead of a real address. When printing a PC-relative global symbol reference, print it as an offset from the leading symbol. When a bb-address-map section is present (i.e., the object file is built with ``-fbasic-block-sections=labels``), labels are retrieved from that section instead. Only works with PowerPC objects or X86 linked images. Example:; A non-symbolized branch instruction with a local target and pc-relative memory access like. .. code-block:: none. cmp eax, dword ptr [rip + 4112]; jge 0x20117e <_start+0x25>. might become. .. code-block:: none. <L0>:; cmp eax, dword ptr <g>; jge	<L0>. .. option:: --triple=<string>. Target triple to disassemble for, see ``--version`` for available targets. .. option:: -w, --wide. Ignored for compatibility with GNU objdu",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objdump.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objdump.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objdump.rst:4047,Modifiability,variab,variable,4047,"ogram:`llvm-objdump` supports the following options:. .. option:: --adjust-vma=<offset>. Increase the displayed address in disassembly or section header printing by; the specified offset. .. option:: --arch-name=<string>. Specify the target architecture when disassembling. Use :option:`--version`; for a list of available targets. .. option:: --build-id=<string>. Look up the object using the given build ID, specified as a hexadecimal; string. The found object is handled as if it were an input filename. .. option:: -C, --demangle. Demangle symbol names in the output. .. option:: --debug-file-directory <path>. Provide a path to a directory with a `.build-id` subdirectory to search for; debug information for stripped binaries. Multiple instances of this argument; are searched in the order given. .. option:: --debuginfod, --no-debuginfod. Whether or not to try debuginfod lookups for debug binaries. Unless specified,; debuginfod is only enabled if libcurl was compiled in (``LLVM_ENABLE_CURL``); and at least one server URL was provided by the environment variable; ``DEBUGINFOD_URLS``. .. option:: --debug-vars=<format>. Print the locations (in registers or memory) of source-level variables; alongside disassembly. ``format`` may be ``unicode`` or ``ascii``, defaulting; to ``unicode`` if omitted. .. option:: --debug-vars-indent=<width>. Distance to indent the source-level variable display, relative to the start; of the disassembly. Defaults to 52 characters. .. option:: -j, --section=<section1[,section2,...]>. Perform commands on the specified sections only. For Mach-O use; `segment,section` to specify the section name. .. option:: -l, --line-numbers. When disassembling, display source line numbers. Implies; :option:`--disassemble`. .. option:: -M, --disassembler-options=<opt1[,opt2,...]>. Pass target-specific disassembler options. Available options:. * ``reg-names-std``: ARM only (default). Print in ARM 's instruction set documentation, with r13/r14/r15 replaced by sp/lr/pc.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objdump.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objdump.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objdump.rst:4174,Modifiability,variab,variables,4174,"ied offset. .. option:: --arch-name=<string>. Specify the target architecture when disassembling. Use :option:`--version`; for a list of available targets. .. option:: --build-id=<string>. Look up the object using the given build ID, specified as a hexadecimal; string. The found object is handled as if it were an input filename. .. option:: -C, --demangle. Demangle symbol names in the output. .. option:: --debug-file-directory <path>. Provide a path to a directory with a `.build-id` subdirectory to search for; debug information for stripped binaries. Multiple instances of this argument; are searched in the order given. .. option:: --debuginfod, --no-debuginfod. Whether or not to try debuginfod lookups for debug binaries. Unless specified,; debuginfod is only enabled if libcurl was compiled in (``LLVM_ENABLE_CURL``); and at least one server URL was provided by the environment variable; ``DEBUGINFOD_URLS``. .. option:: --debug-vars=<format>. Print the locations (in registers or memory) of source-level variables; alongside disassembly. ``format`` may be ``unicode`` or ``ascii``, defaulting; to ``unicode`` if omitted. .. option:: --debug-vars-indent=<width>. Distance to indent the source-level variable display, relative to the start; of the disassembly. Defaults to 52 characters. .. option:: -j, --section=<section1[,section2,...]>. Perform commands on the specified sections only. For Mach-O use; `segment,section` to specify the section name. .. option:: -l, --line-numbers. When disassembling, display source line numbers. Implies; :option:`--disassemble`. .. option:: -M, --disassembler-options=<opt1[,opt2,...]>. Pass target-specific disassembler options. Available options:. * ``reg-names-std``: ARM only (default). Print in ARM 's instruction set documentation, with r13/r14/r15 replaced by sp/lr/pc.; * ``reg-names-raw``: ARM only. Use r followed by the register number.; * ``no-aliases``: AArch64 and RISC-V only. Print raw instruction mnemonic instead of pseudo instruction ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objdump.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objdump.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objdump.rst:4368,Modifiability,variab,variable,4368,"ven build ID, specified as a hexadecimal; string. The found object is handled as if it were an input filename. .. option:: -C, --demangle. Demangle symbol names in the output. .. option:: --debug-file-directory <path>. Provide a path to a directory with a `.build-id` subdirectory to search for; debug information for stripped binaries. Multiple instances of this argument; are searched in the order given. .. option:: --debuginfod, --no-debuginfod. Whether or not to try debuginfod lookups for debug binaries. Unless specified,; debuginfod is only enabled if libcurl was compiled in (``LLVM_ENABLE_CURL``); and at least one server URL was provided by the environment variable; ``DEBUGINFOD_URLS``. .. option:: --debug-vars=<format>. Print the locations (in registers or memory) of source-level variables; alongside disassembly. ``format`` may be ``unicode`` or ``ascii``, defaulting; to ``unicode`` if omitted. .. option:: --debug-vars-indent=<width>. Distance to indent the source-level variable display, relative to the start; of the disassembly. Defaults to 52 characters. .. option:: -j, --section=<section1[,section2,...]>. Perform commands on the specified sections only. For Mach-O use; `segment,section` to specify the section name. .. option:: -l, --line-numbers. When disassembling, display source line numbers. Implies; :option:`--disassemble`. .. option:: -M, --disassembler-options=<opt1[,opt2,...]>. Pass target-specific disassembler options. Available options:. * ``reg-names-std``: ARM only (default). Print in ARM 's instruction set documentation, with r13/r14/r15 replaced by sp/lr/pc.; * ``reg-names-raw``: ARM only. Use r followed by the register number.; * ``no-aliases``: AArch64 and RISC-V only. Print raw instruction mnemonic instead of pseudo instruction mnemonic.; * ``numeric``: RISC-V only. Print raw register names instead of ABI mnemonic. (e.g. print x1 instead of ra); * ``att``: x86 only (default). Print in the AT&T syntax.; * ``intel``: x86 only. Print in the intel ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objdump.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objdump.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objdump.rst:10853,Performance,optimiz,optimization,10853,"xternal; references in a final linked binary. .. option:: --dylibs-used. Display the shared libraries used for linked files. .. option:: --dsym=<string>. Use .dSYM file for debug info. .. option:: --dylib-id. Display the shared library's ID for dylib files. .. option:: --exports-trie. Display exported symbols. .. option:: --function-starts [=<addrs|names|both>]. Print the function starts table for Mach-O objects. Either ``addrs``; (default) to print only the addresses of functions, ``names`` to print only; the names of the functions (when available), or ``both`` to print the; names beside the addresses. .. option:: -g. Print line information from debug info if available. .. option:: --full-leading-addr. Print the full leading address when disassembling. .. option:: --indirect-symbols. Display the indirect symbol table. .. option:: --info-plist. Display the info plist section as strings. .. option:: --lazy-bind. Display lazy binding info. .. option:: --link-opt-hints. Display the linker optimization hints. .. option:: -m, --macho. Use Mach-O specific object file parser. Commands and other options may behave; differently when used with ``--macho``. .. option:: --no-leading-headers. Do not print any leading headers. .. option:: --no-symbolic-operands. Do not print symbolic operands when disassembling. .. option:: --non-verbose. Display the information for Mach-O objects in non-verbose or numeric form. .. option:: --objc-meta-data. Display the Objective-C runtime meta data. .. option:: --private-header. Display only the first format specific file header. .. option:: --rebase. Display rebasing information. .. option:: --rpaths. Display runtime search paths for the binary. .. option:: --universal-headers. Display universal headers. .. option:: --weak-bind. Display weak binding information. XCOFF ONLY OPTIONS AND COMMANDS; ---------------------------------. .. option:: --symbol-description. Add symbol description to disassembly output. .. option:: --traceback-table. Decode ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objdump.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objdump.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objdump.rst:8378,Security,access,access,8378,"assemble from the specified address. When printing relocations, only print the relocations patching offsets from at least ``address``. When printing symbols, only print symbols with a value of at least ``address``. .. option:: --stop-address=<address>. When disassembling, only disassemble up to, but not including the specified address. When printing relocations, only print the relocations patching offsets up to ``address``. When printing symbols, only print symbols with a value up to ``address``. .. option:: --symbolize-operands. When disassembling, symbolize a branch target operand to print a label instead of a real address. When printing a PC-relative global symbol reference, print it as an offset from the leading symbol. When a bb-address-map section is present (i.e., the object file is built with ``-fbasic-block-sections=labels``), labels are retrieved from that section instead. Only works with PowerPC objects or X86 linked images. Example:; A non-symbolized branch instruction with a local target and pc-relative memory access like. .. code-block:: none. cmp eax, dword ptr [rip + 4112]; jge 0x20117e <_start+0x25>. might become. .. code-block:: none. <L0>:; cmp eax, dword ptr <g>; jge	<L0>. .. option:: --triple=<string>. Target triple to disassemble for, see ``--version`` for available targets. .. option:: -w, --wide. Ignored for compatibility with GNU objdump. .. option:: --x86-asm-syntax=<style>. Deprecated.; When used with :option:`--disassemble`, choose style of code to emit from; X86 backend. Supported values are:. .. option:: att. AT&T-style assembly. .. option:: intel. Intel-style assembly. The default disassembly style is **att**. .. option:: -z, --disassemble-zeroes. Do not skip blocks of zeroes when disassembling. .. option:: @<FILE>. Read command-line options and commands from response file `<FILE>`. MACH-O ONLY OPTIONS AND COMMANDS; --------------------------------. .. option:: --arch=<architecture>. Specify the architecture to disassemble. see ``--ver",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objdump.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-objdump.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-opt-report.rst:2355,Availability,avail,available,2355,"ar(); }; 3 |; 4 | void Test(int *res, int *c, int *d, int *p, int n) {; 5 | int i;; 6 |; 7 | #pragma clang loop vectorize(assume_safety); 8 V4,1 | for (i = 0; i < 1600; i++) {; 9 | res[i] = (p[i] == 0) ? res[i] : res[i] + d[i];; 10 | }; 11 |; 12 U16 | for (i = 0; i < 16; i++) {; 13 | res[i] = (p[i] == 0) ? res[i] : res[i] + d[i];; 14 | }; 15 |; 16 I | foo();; 17 |; 18 | foo(); bar(); foo();; I | ^; I | ^; 19 | }; 20 |. Symbols printed on the left side of the program indicate what kind of optimization was performed.; The meanings of the symbols are as follows:. - I: The function is inlined.; - U: The loop is unrolled. The following number indicates the unroll factor.; - V: The loop is vectorized. The following numbers indicate the vector length and the interleave factor. .. note:: . If a specific line of code is output twice, it means that the same optimization pass was applied to that ; line of code twice, and the pass was able to further optimize the code on the second iteration. OPTIONS; -------. If ``input`` is ""``-``"" or omitted, :program:`llvm-opt-report` reads from standard; input. Otherwise, it will read from the specified filename. If the :option:`-o` option is omitted, then :program:`llvm-opt-report` will send its output; to standard output. If the :option:`-o` option specifies ""``-``"", then the output will also; be sent to standard output. .. option:: --help. Display available options. .. option:: --version. Display the version of this program. .. option:: --format=<string>. The format of the optimization record file.; The Argument is one of the following:. - yaml; - yaml-strtab; - bitstream. .. option:: --no-demangle. Do not demangle function names. .. option:: -o=<string>. Output file. .. option:: -r=<string>. Root for relative input paths. .. option:: -s. Do not include vectorization factors, etc. EXIT STATUS; -----------. :program:`llvm-opt-report` returns 0 on success. Otherwise, an error message is printed; to standard error, and the tool returns 1. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-opt-report.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-opt-report.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-opt-report.rst:2886,Availability,error,error,2886,"ar(); }; 3 |; 4 | void Test(int *res, int *c, int *d, int *p, int n) {; 5 | int i;; 6 |; 7 | #pragma clang loop vectorize(assume_safety); 8 V4,1 | for (i = 0; i < 1600; i++) {; 9 | res[i] = (p[i] == 0) ? res[i] : res[i] + d[i];; 10 | }; 11 |; 12 U16 | for (i = 0; i < 16; i++) {; 13 | res[i] = (p[i] == 0) ? res[i] : res[i] + d[i];; 14 | }; 15 |; 16 I | foo();; 17 |; 18 | foo(); bar(); foo();; I | ^; I | ^; 19 | }; 20 |. Symbols printed on the left side of the program indicate what kind of optimization was performed.; The meanings of the symbols are as follows:. - I: The function is inlined.; - U: The loop is unrolled. The following number indicates the unroll factor.; - V: The loop is vectorized. The following numbers indicate the vector length and the interleave factor. .. note:: . If a specific line of code is output twice, it means that the same optimization pass was applied to that ; line of code twice, and the pass was able to further optimize the code on the second iteration. OPTIONS; -------. If ``input`` is ""``-``"" or omitted, :program:`llvm-opt-report` reads from standard; input. Otherwise, it will read from the specified filename. If the :option:`-o` option is omitted, then :program:`llvm-opt-report` will send its output; to standard output. If the :option:`-o` option specifies ""``-``"", then the output will also; be sent to standard output. .. option:: --help. Display available options. .. option:: --version. Display the version of this program. .. option:: --format=<string>. The format of the optimization record file.; The Argument is one of the following:. - yaml; - yaml-strtab; - bitstream. .. option:: --no-demangle. Do not demangle function names. .. option:: -o=<string>. Output file. .. option:: -r=<string>. Root for relative input paths. .. option:: -s. Do not include vectorization factors, etc. EXIT STATUS; -----------. :program:`llvm-opt-report` returns 0 on success. Otherwise, an error message is printed; to standard error, and the tool returns 1. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-opt-report.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-opt-report.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-opt-report.rst:2924,Availability,error,error,2924,"ar(); }; 3 |; 4 | void Test(int *res, int *c, int *d, int *p, int n) {; 5 | int i;; 6 |; 7 | #pragma clang loop vectorize(assume_safety); 8 V4,1 | for (i = 0; i < 1600; i++) {; 9 | res[i] = (p[i] == 0) ? res[i] : res[i] + d[i];; 10 | }; 11 |; 12 U16 | for (i = 0; i < 16; i++) {; 13 | res[i] = (p[i] == 0) ? res[i] : res[i] + d[i];; 14 | }; 15 |; 16 I | foo();; 17 |; 18 | foo(); bar(); foo();; I | ^; I | ^; 19 | }; 20 |. Symbols printed on the left side of the program indicate what kind of optimization was performed.; The meanings of the symbols are as follows:. - I: The function is inlined.; - U: The loop is unrolled. The following number indicates the unroll factor.; - V: The loop is vectorized. The following numbers indicate the vector length and the interleave factor. .. note:: . If a specific line of code is output twice, it means that the same optimization pass was applied to that ; line of code twice, and the pass was able to further optimize the code on the second iteration. OPTIONS; -------. If ``input`` is ""``-``"" or omitted, :program:`llvm-opt-report` reads from standard; input. Otherwise, it will read from the specified filename. If the :option:`-o` option is omitted, then :program:`llvm-opt-report` will send its output; to standard output. If the :option:`-o` option specifies ""``-``"", then the output will also; be sent to standard output. .. option:: --help. Display available options. .. option:: --version. Display the version of this program. .. option:: --format=<string>. The format of the optimization record file.; The Argument is one of the following:. - yaml; - yaml-strtab; - bitstream. .. option:: --no-demangle. Do not demangle function names. .. option:: -o=<string>. Output file. .. option:: -r=<string>. Root for relative input paths. .. option:: -s. Do not include vectorization factors, etc. EXIT STATUS; -----------. :program:`llvm-opt-report` returns 0 on success. Otherwise, an error message is printed; to standard error, and the tool returns 1. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-opt-report.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-opt-report.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-opt-report.rst:2892,Integrability,message,message,2892,"ar(); }; 3 |; 4 | void Test(int *res, int *c, int *d, int *p, int n) {; 5 | int i;; 6 |; 7 | #pragma clang loop vectorize(assume_safety); 8 V4,1 | for (i = 0; i < 1600; i++) {; 9 | res[i] = (p[i] == 0) ? res[i] : res[i] + d[i];; 10 | }; 11 |; 12 U16 | for (i = 0; i < 16; i++) {; 13 | res[i] = (p[i] == 0) ? res[i] : res[i] + d[i];; 14 | }; 15 |; 16 I | foo();; 17 |; 18 | foo(); bar(); foo();; I | ^; I | ^; 19 | }; 20 |. Symbols printed on the left side of the program indicate what kind of optimization was performed.; The meanings of the symbols are as follows:. - I: The function is inlined.; - U: The loop is unrolled. The following number indicates the unroll factor.; - V: The loop is vectorized. The following numbers indicate the vector length and the interleave factor. .. note:: . If a specific line of code is output twice, it means that the same optimization pass was applied to that ; line of code twice, and the pass was able to further optimize the code on the second iteration. OPTIONS; -------. If ``input`` is ""``-``"" or omitted, :program:`llvm-opt-report` reads from standard; input. Otherwise, it will read from the specified filename. If the :option:`-o` option is omitted, then :program:`llvm-opt-report` will send its output; to standard output. If the :option:`-o` option specifies ""``-``"", then the output will also; be sent to standard output. .. option:: --help. Display available options. .. option:: --version. Display the version of this program. .. option:: --format=<string>. The format of the optimization record file.; The Argument is one of the following:. - yaml; - yaml-strtab; - bitstream. .. option:: --no-demangle. Do not demangle function names. .. option:: -o=<string>. Output file. .. option:: -r=<string>. Root for relative input paths. .. option:: -s. Do not include vectorization factors, etc. EXIT STATUS; -----------. :program:`llvm-opt-report` returns 0 on success. Otherwise, an error message is printed; to standard error, and the tool returns 1. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-opt-report.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-opt-report.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-opt-report.rst:27,Performance,optimiz,optimization,27,"llvm-opt-report - generate optimization report from YAML; ========================================================. .. program:: llvm-opt-report. SYNOPSIS; --------. :program:`llvm-opt-report` [*options*] [input]. DESCRIPTION; -----------. :program:`llvm-opt-report` is a tool to generate an optimization report from YAML optimization record files. You need to create an input YAML optimization record file before running :program:`llvm-opt-report`. It provides information on the execution time, memory usage, and other details of each optimization pass. .. code-block:: console. $ clang -c foo.c -o foo.o -O3 -fsave-optimization-record. Then, you create a report using the :program:`llvm-opt-report` command with the YAML optimization record file :file:`foo.opt.yaml` as input. .. code-block:: console. $ llvm-opt-report foo.opt.yaml -o foo.lst. foo.lst is the generated optimization report. .. code-block::. < foo.c; 1 | void bar();; 2 | void foo() { bar(); }; 3 |; 4 | void Test(int *res, int *c, int *d, int *p, int n) {; 5 | int i;; 6 |; 7 | #pragma clang loop vectorize(assume_safety); 8 V4,1 | for (i = 0; i < 1600; i++) {; 9 | res[i] = (p[i] == 0) ? res[i] : res[i] + d[i];; 10 | }; 11 |; 12 U16 | for (i = 0; i < 16; i++) {; 13 | res[i] = (p[i] == 0) ? res[i] : res[i] + d[i];; 14 | }; 15 |; 16 I | foo();; 17 |; 18 | foo(); bar(); foo();; I | ^; I | ^; 19 | }; 20 |. Symbols printed on the left side of the program indicate what kind of optimization was performed.; The meanings of the symbols are as follows:. - I: The function is inlined.; - U: The loop is unrolled. The following number indicates the unroll factor.; - V: The loop is vectorized. The following numbers indicate the vector length and the interleave factor. .. note:: . If a specific line of code is output twice, it means that the same optimization pass was applied to that ; line of code twice, and the pass was able to further optimize the code on the second iteration. OPTIONS; -------. If ``input`` is ""``-``"" or omitt",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-opt-report.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-opt-report.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-opt-report.rst:292,Performance,optimiz,optimization,292,"llvm-opt-report - generate optimization report from YAML; ========================================================. .. program:: llvm-opt-report. SYNOPSIS; --------. :program:`llvm-opt-report` [*options*] [input]. DESCRIPTION; -----------. :program:`llvm-opt-report` is a tool to generate an optimization report from YAML optimization record files. You need to create an input YAML optimization record file before running :program:`llvm-opt-report`. It provides information on the execution time, memory usage, and other details of each optimization pass. .. code-block:: console. $ clang -c foo.c -o foo.o -O3 -fsave-optimization-record. Then, you create a report using the :program:`llvm-opt-report` command with the YAML optimization record file :file:`foo.opt.yaml` as input. .. code-block:: console. $ llvm-opt-report foo.opt.yaml -o foo.lst. foo.lst is the generated optimization report. .. code-block::. < foo.c; 1 | void bar();; 2 | void foo() { bar(); }; 3 |; 4 | void Test(int *res, int *c, int *d, int *p, int n) {; 5 | int i;; 6 |; 7 | #pragma clang loop vectorize(assume_safety); 8 V4,1 | for (i = 0; i < 1600; i++) {; 9 | res[i] = (p[i] == 0) ? res[i] : res[i] + d[i];; 10 | }; 11 |; 12 U16 | for (i = 0; i < 16; i++) {; 13 | res[i] = (p[i] == 0) ? res[i] : res[i] + d[i];; 14 | }; 15 |; 16 I | foo();; 17 |; 18 | foo(); bar(); foo();; I | ^; I | ^; 19 | }; 20 |. Symbols printed on the left side of the program indicate what kind of optimization was performed.; The meanings of the symbols are as follows:. - I: The function is inlined.; - U: The loop is unrolled. The following number indicates the unroll factor.; - V: The loop is vectorized. The following numbers indicate the vector length and the interleave factor. .. note:: . If a specific line of code is output twice, it means that the same optimization pass was applied to that ; line of code twice, and the pass was able to further optimize the code on the second iteration. OPTIONS; -------. If ``input`` is ""``-``"" or omitt",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-opt-report.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-opt-report.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-opt-report.rst:322,Performance,optimiz,optimization,322,"llvm-opt-report - generate optimization report from YAML; ========================================================. .. program:: llvm-opt-report. SYNOPSIS; --------. :program:`llvm-opt-report` [*options*] [input]. DESCRIPTION; -----------. :program:`llvm-opt-report` is a tool to generate an optimization report from YAML optimization record files. You need to create an input YAML optimization record file before running :program:`llvm-opt-report`. It provides information on the execution time, memory usage, and other details of each optimization pass. .. code-block:: console. $ clang -c foo.c -o foo.o -O3 -fsave-optimization-record. Then, you create a report using the :program:`llvm-opt-report` command with the YAML optimization record file :file:`foo.opt.yaml` as input. .. code-block:: console. $ llvm-opt-report foo.opt.yaml -o foo.lst. foo.lst is the generated optimization report. .. code-block::. < foo.c; 1 | void bar();; 2 | void foo() { bar(); }; 3 |; 4 | void Test(int *res, int *c, int *d, int *p, int n) {; 5 | int i;; 6 |; 7 | #pragma clang loop vectorize(assume_safety); 8 V4,1 | for (i = 0; i < 1600; i++) {; 9 | res[i] = (p[i] == 0) ? res[i] : res[i] + d[i];; 10 | }; 11 |; 12 U16 | for (i = 0; i < 16; i++) {; 13 | res[i] = (p[i] == 0) ? res[i] : res[i] + d[i];; 14 | }; 15 |; 16 I | foo();; 17 |; 18 | foo(); bar(); foo();; I | ^; I | ^; 19 | }; 20 |. Symbols printed on the left side of the program indicate what kind of optimization was performed.; The meanings of the symbols are as follows:. - I: The function is inlined.; - U: The loop is unrolled. The following number indicates the unroll factor.; - V: The loop is vectorized. The following numbers indicate the vector length and the interleave factor. .. note:: . If a specific line of code is output twice, it means that the same optimization pass was applied to that ; line of code twice, and the pass was able to further optimize the code on the second iteration. OPTIONS; -------. If ``input`` is ""``-``"" or omitt",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-opt-report.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-opt-report.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-opt-report.rst:382,Performance,optimiz,optimization,382,"llvm-opt-report - generate optimization report from YAML; ========================================================. .. program:: llvm-opt-report. SYNOPSIS; --------. :program:`llvm-opt-report` [*options*] [input]. DESCRIPTION; -----------. :program:`llvm-opt-report` is a tool to generate an optimization report from YAML optimization record files. You need to create an input YAML optimization record file before running :program:`llvm-opt-report`. It provides information on the execution time, memory usage, and other details of each optimization pass. .. code-block:: console. $ clang -c foo.c -o foo.o -O3 -fsave-optimization-record. Then, you create a report using the :program:`llvm-opt-report` command with the YAML optimization record file :file:`foo.opt.yaml` as input. .. code-block:: console. $ llvm-opt-report foo.opt.yaml -o foo.lst. foo.lst is the generated optimization report. .. code-block::. < foo.c; 1 | void bar();; 2 | void foo() { bar(); }; 3 |; 4 | void Test(int *res, int *c, int *d, int *p, int n) {; 5 | int i;; 6 |; 7 | #pragma clang loop vectorize(assume_safety); 8 V4,1 | for (i = 0; i < 1600; i++) {; 9 | res[i] = (p[i] == 0) ? res[i] : res[i] + d[i];; 10 | }; 11 |; 12 U16 | for (i = 0; i < 16; i++) {; 13 | res[i] = (p[i] == 0) ? res[i] : res[i] + d[i];; 14 | }; 15 |; 16 I | foo();; 17 |; 18 | foo(); bar(); foo();; I | ^; I | ^; 19 | }; 20 |. Symbols printed on the left side of the program indicate what kind of optimization was performed.; The meanings of the symbols are as follows:. - I: The function is inlined.; - U: The loop is unrolled. The following number indicates the unroll factor.; - V: The loop is vectorized. The following numbers indicate the vector length and the interleave factor. .. note:: . If a specific line of code is output twice, it means that the same optimization pass was applied to that ; line of code twice, and the pass was able to further optimize the code on the second iteration. OPTIONS; -------. If ``input`` is ""``-``"" or omitt",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-opt-report.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-opt-report.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-opt-report.rst:537,Performance,optimiz,optimization,537,"llvm-opt-report - generate optimization report from YAML; ========================================================. .. program:: llvm-opt-report. SYNOPSIS; --------. :program:`llvm-opt-report` [*options*] [input]. DESCRIPTION; -----------. :program:`llvm-opt-report` is a tool to generate an optimization report from YAML optimization record files. You need to create an input YAML optimization record file before running :program:`llvm-opt-report`. It provides information on the execution time, memory usage, and other details of each optimization pass. .. code-block:: console. $ clang -c foo.c -o foo.o -O3 -fsave-optimization-record. Then, you create a report using the :program:`llvm-opt-report` command with the YAML optimization record file :file:`foo.opt.yaml` as input. .. code-block:: console. $ llvm-opt-report foo.opt.yaml -o foo.lst. foo.lst is the generated optimization report. .. code-block::. < foo.c; 1 | void bar();; 2 | void foo() { bar(); }; 3 |; 4 | void Test(int *res, int *c, int *d, int *p, int n) {; 5 | int i;; 6 |; 7 | #pragma clang loop vectorize(assume_safety); 8 V4,1 | for (i = 0; i < 1600; i++) {; 9 | res[i] = (p[i] == 0) ? res[i] : res[i] + d[i];; 10 | }; 11 |; 12 U16 | for (i = 0; i < 16; i++) {; 13 | res[i] = (p[i] == 0) ? res[i] : res[i] + d[i];; 14 | }; 15 |; 16 I | foo();; 17 |; 18 | foo(); bar(); foo();; I | ^; I | ^; 19 | }; 20 |. Symbols printed on the left side of the program indicate what kind of optimization was performed.; The meanings of the symbols are as follows:. - I: The function is inlined.; - U: The loop is unrolled. The following number indicates the unroll factor.; - V: The loop is vectorized. The following numbers indicate the vector length and the interleave factor. .. note:: . If a specific line of code is output twice, it means that the same optimization pass was applied to that ; line of code twice, and the pass was able to further optimize the code on the second iteration. OPTIONS; -------. If ``input`` is ""``-``"" or omitt",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-opt-report.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-opt-report.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-opt-report.rst:618,Performance,optimiz,optimization-record,618,"llvm-opt-report - generate optimization report from YAML; ========================================================. .. program:: llvm-opt-report. SYNOPSIS; --------. :program:`llvm-opt-report` [*options*] [input]. DESCRIPTION; -----------. :program:`llvm-opt-report` is a tool to generate an optimization report from YAML optimization record files. You need to create an input YAML optimization record file before running :program:`llvm-opt-report`. It provides information on the execution time, memory usage, and other details of each optimization pass. .. code-block:: console. $ clang -c foo.c -o foo.o -O3 -fsave-optimization-record. Then, you create a report using the :program:`llvm-opt-report` command with the YAML optimization record file :file:`foo.opt.yaml` as input. .. code-block:: console. $ llvm-opt-report foo.opt.yaml -o foo.lst. foo.lst is the generated optimization report. .. code-block::. < foo.c; 1 | void bar();; 2 | void foo() { bar(); }; 3 |; 4 | void Test(int *res, int *c, int *d, int *p, int n) {; 5 | int i;; 6 |; 7 | #pragma clang loop vectorize(assume_safety); 8 V4,1 | for (i = 0; i < 1600; i++) {; 9 | res[i] = (p[i] == 0) ? res[i] : res[i] + d[i];; 10 | }; 11 |; 12 U16 | for (i = 0; i < 16; i++) {; 13 | res[i] = (p[i] == 0) ? res[i] : res[i] + d[i];; 14 | }; 15 |; 16 I | foo();; 17 |; 18 | foo(); bar(); foo();; I | ^; I | ^; 19 | }; 20 |. Symbols printed on the left side of the program indicate what kind of optimization was performed.; The meanings of the symbols are as follows:. - I: The function is inlined.; - U: The loop is unrolled. The following number indicates the unroll factor.; - V: The loop is vectorized. The following numbers indicate the vector length and the interleave factor. .. note:: . If a specific line of code is output twice, it means that the same optimization pass was applied to that ; line of code twice, and the pass was able to further optimize the code on the second iteration. OPTIONS; -------. If ``input`` is ""``-``"" or omitt",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-opt-report.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-opt-report.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-opt-report.rst:724,Performance,optimiz,optimization,724,"llvm-opt-report - generate optimization report from YAML; ========================================================. .. program:: llvm-opt-report. SYNOPSIS; --------. :program:`llvm-opt-report` [*options*] [input]. DESCRIPTION; -----------. :program:`llvm-opt-report` is a tool to generate an optimization report from YAML optimization record files. You need to create an input YAML optimization record file before running :program:`llvm-opt-report`. It provides information on the execution time, memory usage, and other details of each optimization pass. .. code-block:: console. $ clang -c foo.c -o foo.o -O3 -fsave-optimization-record. Then, you create a report using the :program:`llvm-opt-report` command with the YAML optimization record file :file:`foo.opt.yaml` as input. .. code-block:: console. $ llvm-opt-report foo.opt.yaml -o foo.lst. foo.lst is the generated optimization report. .. code-block::. < foo.c; 1 | void bar();; 2 | void foo() { bar(); }; 3 |; 4 | void Test(int *res, int *c, int *d, int *p, int n) {; 5 | int i;; 6 |; 7 | #pragma clang loop vectorize(assume_safety); 8 V4,1 | for (i = 0; i < 1600; i++) {; 9 | res[i] = (p[i] == 0) ? res[i] : res[i] + d[i];; 10 | }; 11 |; 12 U16 | for (i = 0; i < 16; i++) {; 13 | res[i] = (p[i] == 0) ? res[i] : res[i] + d[i];; 14 | }; 15 |; 16 I | foo();; 17 |; 18 | foo(); bar(); foo();; I | ^; I | ^; 19 | }; 20 |. Symbols printed on the left side of the program indicate what kind of optimization was performed.; The meanings of the symbols are as follows:. - I: The function is inlined.; - U: The loop is unrolled. The following number indicates the unroll factor.; - V: The loop is vectorized. The following numbers indicate the vector length and the interleave factor. .. note:: . If a specific line of code is output twice, it means that the same optimization pass was applied to that ; line of code twice, and the pass was able to further optimize the code on the second iteration. OPTIONS; -------. If ``input`` is ""``-``"" or omitt",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-opt-report.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-opt-report.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-opt-report.rst:873,Performance,optimiz,optimization,873,"llvm-opt-report - generate optimization report from YAML; ========================================================. .. program:: llvm-opt-report. SYNOPSIS; --------. :program:`llvm-opt-report` [*options*] [input]. DESCRIPTION; -----------. :program:`llvm-opt-report` is a tool to generate an optimization report from YAML optimization record files. You need to create an input YAML optimization record file before running :program:`llvm-opt-report`. It provides information on the execution time, memory usage, and other details of each optimization pass. .. code-block:: console. $ clang -c foo.c -o foo.o -O3 -fsave-optimization-record. Then, you create a report using the :program:`llvm-opt-report` command with the YAML optimization record file :file:`foo.opt.yaml` as input. .. code-block:: console. $ llvm-opt-report foo.opt.yaml -o foo.lst. foo.lst is the generated optimization report. .. code-block::. < foo.c; 1 | void bar();; 2 | void foo() { bar(); }; 3 |; 4 | void Test(int *res, int *c, int *d, int *p, int n) {; 5 | int i;; 6 |; 7 | #pragma clang loop vectorize(assume_safety); 8 V4,1 | for (i = 0; i < 1600; i++) {; 9 | res[i] = (p[i] == 0) ? res[i] : res[i] + d[i];; 10 | }; 11 |; 12 U16 | for (i = 0; i < 16; i++) {; 13 | res[i] = (p[i] == 0) ? res[i] : res[i] + d[i];; 14 | }; 15 |; 16 I | foo();; 17 |; 18 | foo(); bar(); foo();; I | ^; I | ^; 19 | }; 20 |. Symbols printed on the left side of the program indicate what kind of optimization was performed.; The meanings of the symbols are as follows:. - I: The function is inlined.; - U: The loop is unrolled. The following number indicates the unroll factor.; - V: The loop is vectorized. The following numbers indicate the vector length and the interleave factor. .. note:: . If a specific line of code is output twice, it means that the same optimization pass was applied to that ; line of code twice, and the pass was able to further optimize the code on the second iteration. OPTIONS; -------. If ``input`` is ""``-``"" or omitt",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-opt-report.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-opt-report.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-opt-report.rst:1448,Performance,optimiz,optimization,1448,"gram:`llvm-opt-report`. It provides information on the execution time, memory usage, and other details of each optimization pass. .. code-block:: console. $ clang -c foo.c -o foo.o -O3 -fsave-optimization-record. Then, you create a report using the :program:`llvm-opt-report` command with the YAML optimization record file :file:`foo.opt.yaml` as input. .. code-block:: console. $ llvm-opt-report foo.opt.yaml -o foo.lst. foo.lst is the generated optimization report. .. code-block::. < foo.c; 1 | void bar();; 2 | void foo() { bar(); }; 3 |; 4 | void Test(int *res, int *c, int *d, int *p, int n) {; 5 | int i;; 6 |; 7 | #pragma clang loop vectorize(assume_safety); 8 V4,1 | for (i = 0; i < 1600; i++) {; 9 | res[i] = (p[i] == 0) ? res[i] : res[i] + d[i];; 10 | }; 11 |; 12 U16 | for (i = 0; i < 16; i++) {; 13 | res[i] = (p[i] == 0) ? res[i] : res[i] + d[i];; 14 | }; 15 |; 16 I | foo();; 17 |; 18 | foo(); bar(); foo();; I | ^; I | ^; 19 | }; 20 |. Symbols printed on the left side of the program indicate what kind of optimization was performed.; The meanings of the symbols are as follows:. - I: The function is inlined.; - U: The loop is unrolled. The following number indicates the unroll factor.; - V: The loop is vectorized. The following numbers indicate the vector length and the interleave factor. .. note:: . If a specific line of code is output twice, it means that the same optimization pass was applied to that ; line of code twice, and the pass was able to further optimize the code on the second iteration. OPTIONS; -------. If ``input`` is ""``-``"" or omitted, :program:`llvm-opt-report` reads from standard; input. Otherwise, it will read from the specified filename. If the :option:`-o` option is omitted, then :program:`llvm-opt-report` will send its output; to standard output. If the :option:`-o` option specifies ""``-``"", then the output will also; be sent to standard output. .. option:: --help. Display available options. .. option:: --version. Display the version of this p",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-opt-report.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-opt-report.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-opt-report.rst:1465,Performance,perform,performed,1465,"gram:`llvm-opt-report`. It provides information on the execution time, memory usage, and other details of each optimization pass. .. code-block:: console. $ clang -c foo.c -o foo.o -O3 -fsave-optimization-record. Then, you create a report using the :program:`llvm-opt-report` command with the YAML optimization record file :file:`foo.opt.yaml` as input. .. code-block:: console. $ llvm-opt-report foo.opt.yaml -o foo.lst. foo.lst is the generated optimization report. .. code-block::. < foo.c; 1 | void bar();; 2 | void foo() { bar(); }; 3 |; 4 | void Test(int *res, int *c, int *d, int *p, int n) {; 5 | int i;; 6 |; 7 | #pragma clang loop vectorize(assume_safety); 8 V4,1 | for (i = 0; i < 1600; i++) {; 9 | res[i] = (p[i] == 0) ? res[i] : res[i] + d[i];; 10 | }; 11 |; 12 U16 | for (i = 0; i < 16; i++) {; 13 | res[i] = (p[i] == 0) ? res[i] : res[i] + d[i];; 14 | }; 15 |; 16 I | foo();; 17 |; 18 | foo(); bar(); foo();; I | ^; I | ^; 19 | }; 20 |. Symbols printed on the left side of the program indicate what kind of optimization was performed.; The meanings of the symbols are as follows:. - I: The function is inlined.; - U: The loop is unrolled. The following number indicates the unroll factor.; - V: The loop is vectorized. The following numbers indicate the vector length and the interleave factor. .. note:: . If a specific line of code is output twice, it means that the same optimization pass was applied to that ; line of code twice, and the pass was able to further optimize the code on the second iteration. OPTIONS; -------. If ``input`` is ""``-``"" or omitted, :program:`llvm-opt-report` reads from standard; input. Otherwise, it will read from the specified filename. If the :option:`-o` option is omitted, then :program:`llvm-opt-report` will send its output; to standard output. If the :option:`-o` option specifies ""``-``"", then the output will also; be sent to standard output. .. option:: --help. Display available options. .. option:: --version. Display the version of this p",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-opt-report.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-opt-report.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-opt-report.rst:1815,Performance,optimiz,optimization,1815,"foo.lst is the generated optimization report. .. code-block::. < foo.c; 1 | void bar();; 2 | void foo() { bar(); }; 3 |; 4 | void Test(int *res, int *c, int *d, int *p, int n) {; 5 | int i;; 6 |; 7 | #pragma clang loop vectorize(assume_safety); 8 V4,1 | for (i = 0; i < 1600; i++) {; 9 | res[i] = (p[i] == 0) ? res[i] : res[i] + d[i];; 10 | }; 11 |; 12 U16 | for (i = 0; i < 16; i++) {; 13 | res[i] = (p[i] == 0) ? res[i] : res[i] + d[i];; 14 | }; 15 |; 16 I | foo();; 17 |; 18 | foo(); bar(); foo();; I | ^; I | ^; 19 | }; 20 |. Symbols printed on the left side of the program indicate what kind of optimization was performed.; The meanings of the symbols are as follows:. - I: The function is inlined.; - U: The loop is unrolled. The following number indicates the unroll factor.; - V: The loop is vectorized. The following numbers indicate the vector length and the interleave factor. .. note:: . If a specific line of code is output twice, it means that the same optimization pass was applied to that ; line of code twice, and the pass was able to further optimize the code on the second iteration. OPTIONS; -------. If ``input`` is ""``-``"" or omitted, :program:`llvm-opt-report` reads from standard; input. Otherwise, it will read from the specified filename. If the :option:`-o` option is omitted, then :program:`llvm-opt-report` will send its output; to standard output. If the :option:`-o` option specifies ""``-``"", then the output will also; be sent to standard output. .. option:: --help. Display available options. .. option:: --version. Display the version of this program. .. option:: --format=<string>. The format of the optimization record file.; The Argument is one of the following:. - yaml; - yaml-strtab; - bitstream. .. option:: --no-demangle. Do not demangle function names. .. option:: -o=<string>. Output file. .. option:: -r=<string>. Root for relative input paths. .. option:: -s. Do not include vectorization factors, etc. EXIT STATUS; -----------. :program:`llvm-opt-report`",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-opt-report.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-opt-report.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-opt-report.rst:1908,Performance,optimiz,optimize,1908,"foo.lst is the generated optimization report. .. code-block::. < foo.c; 1 | void bar();; 2 | void foo() { bar(); }; 3 |; 4 | void Test(int *res, int *c, int *d, int *p, int n) {; 5 | int i;; 6 |; 7 | #pragma clang loop vectorize(assume_safety); 8 V4,1 | for (i = 0; i < 1600; i++) {; 9 | res[i] = (p[i] == 0) ? res[i] : res[i] + d[i];; 10 | }; 11 |; 12 U16 | for (i = 0; i < 16; i++) {; 13 | res[i] = (p[i] == 0) ? res[i] : res[i] + d[i];; 14 | }; 15 |; 16 I | foo();; 17 |; 18 | foo(); bar(); foo();; I | ^; I | ^; 19 | }; 20 |. Symbols printed on the left side of the program indicate what kind of optimization was performed.; The meanings of the symbols are as follows:. - I: The function is inlined.; - U: The loop is unrolled. The following number indicates the unroll factor.; - V: The loop is vectorized. The following numbers indicate the vector length and the interleave factor. .. note:: . If a specific line of code is output twice, it means that the same optimization pass was applied to that ; line of code twice, and the pass was able to further optimize the code on the second iteration. OPTIONS; -------. If ``input`` is ""``-``"" or omitted, :program:`llvm-opt-report` reads from standard; input. Otherwise, it will read from the specified filename. If the :option:`-o` option is omitted, then :program:`llvm-opt-report` will send its output; to standard output. If the :option:`-o` option specifies ""``-``"", then the output will also; be sent to standard output. .. option:: --help. Display available options. .. option:: --version. Display the version of this program. .. option:: --format=<string>. The format of the optimization record file.; The Argument is one of the following:. - yaml; - yaml-strtab; - bitstream. .. option:: --no-demangle. Do not demangle function names. .. option:: -o=<string>. Output file. .. option:: -r=<string>. Root for relative input paths. .. option:: -s. Do not include vectorization factors, etc. EXIT STATUS; -----------. :program:`llvm-opt-report`",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-opt-report.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-opt-report.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-opt-report.rst:2483,Performance,optimiz,optimization,2483,"ar(); }; 3 |; 4 | void Test(int *res, int *c, int *d, int *p, int n) {; 5 | int i;; 6 |; 7 | #pragma clang loop vectorize(assume_safety); 8 V4,1 | for (i = 0; i < 1600; i++) {; 9 | res[i] = (p[i] == 0) ? res[i] : res[i] + d[i];; 10 | }; 11 |; 12 U16 | for (i = 0; i < 16; i++) {; 13 | res[i] = (p[i] == 0) ? res[i] : res[i] + d[i];; 14 | }; 15 |; 16 I | foo();; 17 |; 18 | foo(); bar(); foo();; I | ^; I | ^; 19 | }; 20 |. Symbols printed on the left side of the program indicate what kind of optimization was performed.; The meanings of the symbols are as follows:. - I: The function is inlined.; - U: The loop is unrolled. The following number indicates the unroll factor.; - V: The loop is vectorized. The following numbers indicate the vector length and the interleave factor. .. note:: . If a specific line of code is output twice, it means that the same optimization pass was applied to that ; line of code twice, and the pass was able to further optimize the code on the second iteration. OPTIONS; -------. If ``input`` is ""``-``"" or omitted, :program:`llvm-opt-report` reads from standard; input. Otherwise, it will read from the specified filename. If the :option:`-o` option is omitted, then :program:`llvm-opt-report` will send its output; to standard output. If the :option:`-o` option specifies ""``-``"", then the output will also; be sent to standard output. .. option:: --help. Display available options. .. option:: --version. Display the version of this program. .. option:: --format=<string>. The format of the optimization record file.; The Argument is one of the following:. - yaml; - yaml-strtab; - bitstream. .. option:: --no-demangle. Do not demangle function names. .. option:: -o=<string>. Output file. .. option:: -r=<string>. Root for relative input paths. .. option:: -s. Do not include vectorization factors, etc. EXIT STATUS; -----------. :program:`llvm-opt-report` returns 0 on success. Otherwise, an error message is printed; to standard error, and the tool returns 1. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-opt-report.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-opt-report.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-otool.rst:1874,Availability,error,error,1874,"YNOPSIS; --------. :program:`llvm-otool` [*option...*] *[file...]*. DESCRIPTION; -----------. :program:`llvm-otool` is a tool for dumping Mach-O files. It attempts to be command-line-compatible and output-compatible with macOS's; :program:`otool`. OPTIONS; -------. .. option:: -arch <value>. Select slice of universal Mach-O file. .. option:: -chained_fixups. Print chained fixup information. .. option:: -C. Print linker optimization hints. .. option:: -dyld_info. Print bind and rebase information. .. option:: -D. Print shared library id. .. option:: -d. Print data section. .. option:: -f. Print universal headers. .. option:: -G. Print data-in-code table. .. option:: --help-hidden. Print help for hidden flags. .. option:: --help. Print help. .. option:: -h. Print mach header. .. option:: -I. Print indirect symbol table. .. option:: -j. Print opcode bytes. .. option:: -L. Print used shared libraries. .. option:: -l. Print load commands. .. option:: -mcpu=<value>. Select cpu for disassembly. .. option:: -o. Print Objective-C segment. .. option:: -P. Print __TEXT,__info_plist section as strings. .. option:: -p <function name>. Start disassembly at <function name>. .. option:: -r. Print relocation entries. .. option:: -s <segname> <sectname>. Print contents of section. .. option:: -t. Print text section. .. option:: --version. Print version. .. option:: -V. Symbolize disassembled operands (implies :option:`-v`). .. option:: -v. Verbose output / disassemble when printing text sections. .. option:: -X. Omit leading addresses or headers. .. option:: -x. Print all text sections. .. option:: @<FILE>. Read command-line options and commands from response file `<FILE>`. EXIT STATUS; -----------. :program:`llvm-otool` exits with a non-zero exit code if there is an error.; Otherwise, it exits with code 0. BUGS; ----. To report bugs, please visit <https://github.com/llvm/llvm-project/labels/tools:llvm-objdump/>. SEE ALSO; --------. :manpage:`llvm-nm(1)`, :manpage:`llvm-objdump(1)`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-otool.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-otool.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-otool.rst:517,Performance,optimiz,optimization,517,"llvm-otool - Mach-O dumping tool; ================================. .. program:: llvm-otool. SYNOPSIS; --------. :program:`llvm-otool` [*option...*] *[file...]*. DESCRIPTION; -----------. :program:`llvm-otool` is a tool for dumping Mach-O files. It attempts to be command-line-compatible and output-compatible with macOS's; :program:`otool`. OPTIONS; -------. .. option:: -arch <value>. Select slice of universal Mach-O file. .. option:: -chained_fixups. Print chained fixup information. .. option:: -C. Print linker optimization hints. .. option:: -dyld_info. Print bind and rebase information. .. option:: -D. Print shared library id. .. option:: -d. Print data section. .. option:: -f. Print universal headers. .. option:: -G. Print data-in-code table. .. option:: --help-hidden. Print help for hidden flags. .. option:: --help. Print help. .. option:: -h. Print mach header. .. option:: -I. Print indirect symbol table. .. option:: -j. Print opcode bytes. .. option:: -L. Print used shared libraries. .. option:: -l. Print load commands. .. option:: -mcpu=<value>. Select cpu for disassembly. .. option:: -o. Print Objective-C segment. .. option:: -P. Print __TEXT,__info_plist section as strings. .. option:: -p <function name>. Start disassembly at <function name>. .. option:: -r. Print relocation entries. .. option:: -s <segname> <sectname>. Print contents of section. .. option:: -t. Print text section. .. option:: --version. Print version. .. option:: -V. Symbolize disassembled operands (implies :option:`-v`). .. option:: -v. Verbose output / disassemble when printing text sections. .. option:: -X. Omit leading addresses or headers. .. option:: -x. Print all text sections. .. option:: @<FILE>. Read command-line options and commands from response file `<FILE>`. EXIT STATUS; -----------. :program:`llvm-otool` exits with a non-zero exit code if there is an error.; Otherwise, it exits with code 0. BUGS; ----. To report bugs, please visit <https://github.com/llvm/llvm-project/labels/",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-otool.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-otool.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-otool.rst:1027,Performance,load,load,1027,"ol; ================================. .. program:: llvm-otool. SYNOPSIS; --------. :program:`llvm-otool` [*option...*] *[file...]*. DESCRIPTION; -----------. :program:`llvm-otool` is a tool for dumping Mach-O files. It attempts to be command-line-compatible and output-compatible with macOS's; :program:`otool`. OPTIONS; -------. .. option:: -arch <value>. Select slice of universal Mach-O file. .. option:: -chained_fixups. Print chained fixup information. .. option:: -C. Print linker optimization hints. .. option:: -dyld_info. Print bind and rebase information. .. option:: -D. Print shared library id. .. option:: -d. Print data section. .. option:: -f. Print universal headers. .. option:: -G. Print data-in-code table. .. option:: --help-hidden. Print help for hidden flags. .. option:: --help. Print help. .. option:: -h. Print mach header. .. option:: -I. Print indirect symbol table. .. option:: -j. Print opcode bytes. .. option:: -L. Print used shared libraries. .. option:: -l. Print load commands. .. option:: -mcpu=<value>. Select cpu for disassembly. .. option:: -o. Print Objective-C segment. .. option:: -P. Print __TEXT,__info_plist section as strings. .. option:: -p <function name>. Start disassembly at <function name>. .. option:: -r. Print relocation entries. .. option:: -s <segname> <sectname>. Print contents of section. .. option:: -t. Print text section. .. option:: --version. Print version. .. option:: -V. Symbolize disassembled operands (implies :option:`-v`). .. option:: -v. Verbose output / disassemble when printing text sections. .. option:: -X. Omit leading addresses or headers. .. option:: -x. Print all text sections. .. option:: @<FILE>. Read command-line options and commands from response file `<FILE>`. EXIT STATUS; -----------. :program:`llvm-otool` exits with a non-zero exit code if there is an error.; Otherwise, it exits with code 0. BUGS; ----. To report bugs, please visit <https://github.com/llvm/llvm-project/labels/tools:llvm-objdump/>. SEE ALSO",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-otool.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-otool.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-pdbutil.rst:9972,Integrability,depend,dependents,9972,") for each module dumped. .. option:: -sym-data. For each symbol record dumped as a result of the :option:`-symbols` option,; display the full bytes of the record in binary as well. Type Record Options; +++++++++++++++++++. .. option:: -types. Dump CodeView type records from TPI stream. .. option:: -type-extras. Dump additional information from the TPI stream, such as hashes and the type; index offsets array. .. option:: -type-data. For each type record dumped, display the full bytes of the record in binary as; well. .. option:: -type-index=<uint>. Only dump types with the specified type index. .. option:: -ids. Dump CodeView type records from IPI stream. .. option:: -id-extras. Dump additional information from the IPI stream, such as hashes and the type; index offsets array. .. option:: -id-data. For each ID record dumped, display the full bytes of the record in binary as; well. .. option:: -id-index=<uint>. only dump ID records with the specified hexadecimal type index. .. option:: -dependents. When used in conjunction with :option:`-type-index` or :option:`-id-index`,; dumps the entire dependency graph for the specified index instead of just the; single record with the specified index. For example, if type index 0x4000 is; a function whose return type has index 0x3000, and you specify; `-dependents=0x4000`, then this would dump both records (as well as any other; dependents in the tree). Miscellaneous Options; +++++++++++++++++++++. .. option:: -all. Implies most other options. .. option:: -section-contribs. Dump section contributions. .. option:: -section-headers. Dump image section headers. .. option:: -section-map. Dump section map. .. option:: -string-table. Dump PDB string table. .. _bytes_subcommand:. bytes; ~~~~~. USAGE: :program:`llvm-pdbutil` bytes [*options*] <input PDB file>. .. program:: llvm-pdbutil bytes. Summary; ^^^^^^^. Like the **dump** subcommand, the **bytes** subcommand displays low level; information about the structure of a PDB file, but it",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-pdbutil.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-pdbutil.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-pdbutil.rst:10078,Integrability,depend,dependency,10078,"ymbols` option,; display the full bytes of the record in binary as well. Type Record Options; +++++++++++++++++++. .. option:: -types. Dump CodeView type records from TPI stream. .. option:: -type-extras. Dump additional information from the TPI stream, such as hashes and the type; index offsets array. .. option:: -type-data. For each type record dumped, display the full bytes of the record in binary as; well. .. option:: -type-index=<uint>. Only dump types with the specified type index. .. option:: -ids. Dump CodeView type records from IPI stream. .. option:: -id-extras. Dump additional information from the IPI stream, such as hashes and the type; index offsets array. .. option:: -id-data. For each ID record dumped, display the full bytes of the record in binary as; well. .. option:: -id-index=<uint>. only dump ID records with the specified hexadecimal type index. .. option:: -dependents. When used in conjunction with :option:`-type-index` or :option:`-id-index`,; dumps the entire dependency graph for the specified index instead of just the; single record with the specified index. For example, if type index 0x4000 is; a function whose return type has index 0x3000, and you specify; `-dependents=0x4000`, then this would dump both records (as well as any other; dependents in the tree). Miscellaneous Options; +++++++++++++++++++++. .. option:: -all. Implies most other options. .. option:: -section-contribs. Dump section contributions. .. option:: -section-headers. Dump image section headers. .. option:: -section-map. Dump section map. .. option:: -string-table. Dump PDB string table. .. _bytes_subcommand:. bytes; ~~~~~. USAGE: :program:`llvm-pdbutil` bytes [*options*] <input PDB file>. .. program:: llvm-pdbutil bytes. Summary; ^^^^^^^. Like the **dump** subcommand, the **bytes** subcommand displays low level; information about the structure of a PDB file, but it is used for even deeper; forensics. The **bytes** subcommand finds various structures in a PDB file; based o",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-pdbutil.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-pdbutil.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-pdbutil.rst:10284,Integrability,depend,dependents,10284,"as. Dump additional information from the TPI stream, such as hashes and the type; index offsets array. .. option:: -type-data. For each type record dumped, display the full bytes of the record in binary as; well. .. option:: -type-index=<uint>. Only dump types with the specified type index. .. option:: -ids. Dump CodeView type records from IPI stream. .. option:: -id-extras. Dump additional information from the IPI stream, such as hashes and the type; index offsets array. .. option:: -id-data. For each ID record dumped, display the full bytes of the record in binary as; well. .. option:: -id-index=<uint>. only dump ID records with the specified hexadecimal type index. .. option:: -dependents. When used in conjunction with :option:`-type-index` or :option:`-id-index`,; dumps the entire dependency graph for the specified index instead of just the; single record with the specified index. For example, if type index 0x4000 is; a function whose return type has index 0x3000, and you specify; `-dependents=0x4000`, then this would dump both records (as well as any other; dependents in the tree). Miscellaneous Options; +++++++++++++++++++++. .. option:: -all. Implies most other options. .. option:: -section-contribs. Dump section contributions. .. option:: -section-headers. Dump image section headers. .. option:: -section-map. Dump section map. .. option:: -string-table. Dump PDB string table. .. _bytes_subcommand:. bytes; ~~~~~. USAGE: :program:`llvm-pdbutil` bytes [*options*] <input PDB file>. .. program:: llvm-pdbutil bytes. Summary; ^^^^^^^. Like the **dump** subcommand, the **bytes** subcommand displays low level; information about the structure of a PDB file, but it is used for even deeper; forensics. The **bytes** subcommand finds various structures in a PDB file; based on the command line options specified, and dumps them in hex. Someone; working on support for emitting PDBs would use this heavily, for example, to; compare one PDB against another PDB to ensure byte-fo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-pdbutil.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-pdbutil.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-pdbutil.rst:10361,Integrability,depend,dependents,10361,"as. Dump additional information from the TPI stream, such as hashes and the type; index offsets array. .. option:: -type-data. For each type record dumped, display the full bytes of the record in binary as; well. .. option:: -type-index=<uint>. Only dump types with the specified type index. .. option:: -ids. Dump CodeView type records from IPI stream. .. option:: -id-extras. Dump additional information from the IPI stream, such as hashes and the type; index offsets array. .. option:: -id-data. For each ID record dumped, display the full bytes of the record in binary as; well. .. option:: -id-index=<uint>. only dump ID records with the specified hexadecimal type index. .. option:: -dependents. When used in conjunction with :option:`-type-index` or :option:`-id-index`,; dumps the entire dependency graph for the specified index instead of just the; single record with the specified index. For example, if type index 0x4000 is; a function whose return type has index 0x3000, and you specify; `-dependents=0x4000`, then this would dump both records (as well as any other; dependents in the tree). Miscellaneous Options; +++++++++++++++++++++. .. option:: -all. Implies most other options. .. option:: -section-contribs. Dump section contributions. .. option:: -section-headers. Dump image section headers. .. option:: -section-map. Dump section map. .. option:: -string-table. Dump PDB string table. .. _bytes_subcommand:. bytes; ~~~~~. USAGE: :program:`llvm-pdbutil` bytes [*options*] <input PDB file>. .. program:: llvm-pdbutil bytes. Summary; ^^^^^^^. Like the **dump** subcommand, the **bytes** subcommand displays low level; information about the structure of a PDB file, but it is used for even deeper; forensics. The **bytes** subcommand finds various structures in a PDB file; based on the command line options specified, and dumps them in hex. Someone; working on support for emitting PDBs would use this heavily, for example, to; compare one PDB against another PDB to ensure byte-fo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-pdbutil.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-pdbutil.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-pdbutil.rst:5922,Modifiability,variab,variables,5922,"class-order. Displays classes in the specified order. .. code-block:: text. =none - Undefined / no particular sort order (default); =name - Sort classes by name; =size - Sort classes by size; =padding - Sort classes by amount of padding; =padding-pct - Sort classes by percentage of space consumed by padding; =padding-imm - Sort classes by amount of immediate padding; =padding-pct-imm - Sort classes by percentage of space consumed by immediate padding. .. option:: -class-recurse-depth=<uint>. When dumping class definitions, stop after recursing the specified number of times. The; default is 0, which is no limit. .. option:: -classes. Display classes. .. option:: -compilands. Display compilands (e.g. object files). .. option:: -enums. Display enums. .. option:: -externals. Dump external (e.g. exported) symbols. .. option:: -globals. Dump global symbols. .. option:: -lines. Dump the mappings between source lines and code addresses. .. option:: -module-syms. Display symbols (variables, functions, etc) for each compiland. .. option:: -sym-types=<types>. Type of symbols to dump when -globals, -externals, or -module-syms is; specified. (default all). .. code-block:: text. =thunks - Display thunk symbols; =data - Display data symbols; =funcs - Display function symbols; =all - Display all symbols (default). .. option:: -symbol-order=<order>. For symbols dumped via the -module-syms, -globals, or -externals options, sort; the results in specified order. .. code-block:: text. =none - Undefined / no particular sort order; =name - Sort symbols by name; =size - Sort symbols by size. .. option:: -typedefs. Display typedef types. .. option:: -types. Display all types (implies -classes, -enums, -typedefs). Other Options; +++++++++++++. .. option:: -color-output. Force color output on or off. By default, color if used if outputting to a; terminal. .. option:: -load-address=<uint>. When displaying relative virtual addresses, assume the process is loaded at the; given address and displa",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-pdbutil.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-pdbutil.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-pdbutil.rst:8958,Modifiability,variab,variables,8958,">. For all options that dump information from each module/compiland, limit to; the specified module. .. option:: -files. Dump the source files that contribute to each displayed module. .. option:: -il. Dump inlinee line information (DEBUG_S_INLINEELINES CodeView subsection). .. option:: -l. Dump line information (DEBUG_S_LINES CodeView subsection). .. option:: -modules. Dump compiland information. .. option:: -xme. Dump cross module exports (DEBUG_S_CROSSSCOPEEXPORTS CodeView subsection). .. option:: -xmi. Dump cross module imports (DEBUG_S_CROSSSCOPEIMPORTS CodeView subsection). Symbol Options; ++++++++++++++. .. option:: -globals. dump global symbol records. .. option:: -global-extras. dump additional information about the globals, such as hash buckets and hash; values. .. option:: -publics. dump public symbol records. .. option:: -public-extras. dump additional information about the publics, such as hash buckets and hash; values. .. option:: -symbols. dump symbols (functions, variables, etc) for each module dumped. .. option:: -sym-data. For each symbol record dumped as a result of the :option:`-symbols` option,; display the full bytes of the record in binary as well. Type Record Options; +++++++++++++++++++. .. option:: -types. Dump CodeView type records from TPI stream. .. option:: -type-extras. Dump additional information from the TPI stream, such as hashes and the type; index offsets array. .. option:: -type-data. For each type record dumped, display the full bytes of the record in binary as; well. .. option:: -type-index=<uint>. Only dump types with the specified type index. .. option:: -ids. Dump CodeView type records from IPI stream. .. option:: -id-extras. Dump additional information from the IPI stream, such as hashes and the type; index offsets array. .. option:: -id-data. For each ID record dumped, display the full bytes of the record in binary as; well. .. option:: -id-index=<uint>. only dump ID records with the specified hexadecimal type index. .. opt",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-pdbutil.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-pdbutil.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-pdbutil.rst:6810,Performance,load,load-address,6810,"ines. Dump the mappings between source lines and code addresses. .. option:: -module-syms. Display symbols (variables, functions, etc) for each compiland. .. option:: -sym-types=<types>. Type of symbols to dump when -globals, -externals, or -module-syms is; specified. (default all). .. code-block:: text. =thunks - Display thunk symbols; =data - Display data symbols; =funcs - Display function symbols; =all - Display all symbols (default). .. option:: -symbol-order=<order>. For symbols dumped via the -module-syms, -globals, or -externals options, sort; the results in specified order. .. code-block:: text. =none - Undefined / no particular sort order; =name - Sort symbols by name; =size - Sort symbols by size. .. option:: -typedefs. Display typedef types. .. option:: -types. Display all types (implies -classes, -enums, -typedefs). Other Options; +++++++++++++. .. option:: -color-output. Force color output on or off. By default, color if used if outputting to a; terminal. .. option:: -load-address=<uint>. When displaying relative virtual addresses, assume the process is loaded at the; given address and display what would be the absolute address. .. _dump_subcommand:. dump; ~~~~. USAGE: :program:`llvm-pdbutil` dump [*options*] <input PDB file>. .. program:: llvm-pdbutil dump. Summary; ^^^^^^^^^^^. The **dump** subcommand displays low level information about the structure of a; PDB file. It is used heavily by LLVM's testing infrastructure, but can also be; used for PDB forensics. It serves a role similar to that of Microsoft's; `cvdump` tool. .. note::; The **dump** subcommand exposes internal details of the file format. As; such, the reader should be familiar with :doc:`/PDB/index` before using this; command. Options; ^^^^^^^. MSF Container Options; +++++++++++++++++++++. .. option:: -streams. dump a summary of all of the streams in the PDB file. .. option:: -stream-blocks. In conjunction with :option:`-streams`, add information to the output about; what blocks the specif",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-pdbutil.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-pdbutil.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-pdbutil.rst:6897,Performance,load,loaded,6897,"ms. Display symbols (variables, functions, etc) for each compiland. .. option:: -sym-types=<types>. Type of symbols to dump when -globals, -externals, or -module-syms is; specified. (default all). .. code-block:: text. =thunks - Display thunk symbols; =data - Display data symbols; =funcs - Display function symbols; =all - Display all symbols (default). .. option:: -symbol-order=<order>. For symbols dumped via the -module-syms, -globals, or -externals options, sort; the results in specified order. .. code-block:: text. =none - Undefined / no particular sort order; =name - Sort symbols by name; =size - Sort symbols by size. .. option:: -typedefs. Display typedef types. .. option:: -types. Display all types (implies -classes, -enums, -typedefs). Other Options; +++++++++++++. .. option:: -color-output. Force color output on or off. By default, color if used if outputting to a; terminal. .. option:: -load-address=<uint>. When displaying relative virtual addresses, assume the process is loaded at the; given address and display what would be the absolute address. .. _dump_subcommand:. dump; ~~~~. USAGE: :program:`llvm-pdbutil` dump [*options*] <input PDB file>. .. program:: llvm-pdbutil dump. Summary; ^^^^^^^^^^^. The **dump** subcommand displays low level information about the structure of a; PDB file. It is used heavily by LLVM's testing infrastructure, but can also be; used for PDB forensics. It serves a role similar to that of Microsoft's; `cvdump` tool. .. note::; The **dump** subcommand exposes internal details of the file format. As; such, the reader should be familiar with :doc:`/PDB/index` before using this; command. Options; ^^^^^^^. MSF Container Options; +++++++++++++++++++++. .. option:: -streams. dump a summary of all of the streams in the PDB file. .. option:: -stream-blocks. In conjunction with :option:`-streams`, add information to the output about; what blocks the specified stream occupies. .. option:: -summary. Dump MSF and PDB header information. Module ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-pdbutil.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-pdbutil.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-pdbutil.rst:1075,Security,hash,hash,1075," and diagnostics; =================================================. .. program:: llvm-pdbutil. .. contents::; :local:. Synopsis; --------. :program:`llvm-pdbutil` [*subcommand*] [*options*]. Description; -----------. Display types, symbols, CodeView records, and other information from a; PDB file, as well as manipulate and create PDB files. :program:`llvm-pdbutil`; is normally used by FileCheck-based tests to test LLVM's PDB reading and; writing functionality, but can also be used for general PDB file investigation; and forensics, or as a replacement for cvdump. Subcommands; -----------. :program:`llvm-pdbutil` is separated into several subcommands each tailored to; a different purpose. A brief summary of each command follows, with more detail; in the sections that follow. * :ref:`pretty_subcommand` - Dump symbol and type information in a format that; tries to look as much like the original source code as possible.; * :ref:`dump_subcommand` - Dump low level types and structures from the PDB; file, including CodeView records, hash tables, PDB streams, etc.; * :ref:`bytes_subcommand` - Dump data from the PDB file's streams, records,; types, symbols, etc as raw bytes.; * :ref:`yaml2pdb_subcommand` - Given a yaml description of a PDB file, produce; a valid PDB file that matches that description.; * :ref:`pdb2yaml_subcommand` - For a given PDB file, produce a YAML; description of some or all of the file in a way that the PDB can be; reconstructed.; * :ref:`merge_subcommand` - Given two PDBs, produce a third PDB that is the; result of merging the two input PDBs. .. _pretty_subcommand:. pretty; ~~~~~~. .. program:: llvm-pdbutil pretty. .. important::; The **pretty** subcommand is built on the Windows DIA SDK, and as such is not; supported on non-Windows platforms. USAGE: :program:`llvm-pdbutil` pretty [*options*] <input PDB file>. Summary; ^^^^^^^^^^^. The *pretty* subcommand displays a very high level representation of your; program's debug info. Since it is built on the ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-pdbutil.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-pdbutil.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-pdbutil.rst:7412,Security,expose,exposes,7412,": text. =none - Undefined / no particular sort order; =name - Sort symbols by name; =size - Sort symbols by size. .. option:: -typedefs. Display typedef types. .. option:: -types. Display all types (implies -classes, -enums, -typedefs). Other Options; +++++++++++++. .. option:: -color-output. Force color output on or off. By default, color if used if outputting to a; terminal. .. option:: -load-address=<uint>. When displaying relative virtual addresses, assume the process is loaded at the; given address and display what would be the absolute address. .. _dump_subcommand:. dump; ~~~~. USAGE: :program:`llvm-pdbutil` dump [*options*] <input PDB file>. .. program:: llvm-pdbutil dump. Summary; ^^^^^^^^^^^. The **dump** subcommand displays low level information about the structure of a; PDB file. It is used heavily by LLVM's testing infrastructure, but can also be; used for PDB forensics. It serves a role similar to that of Microsoft's; `cvdump` tool. .. note::; The **dump** subcommand exposes internal details of the file format. As; such, the reader should be familiar with :doc:`/PDB/index` before using this; command. Options; ^^^^^^^. MSF Container Options; +++++++++++++++++++++. .. option:: -streams. dump a summary of all of the streams in the PDB file. .. option:: -stream-blocks. In conjunction with :option:`-streams`, add information to the output about; what blocks the specified stream occupies. .. option:: -summary. Dump MSF and PDB header information. Module & File Options; +++++++++++++++++++++. .. option:: -modi=<uint>. For all options that dump information from each module/compiland, limit to; the specified module. .. option:: -files. Dump the source files that contribute to each displayed module. .. option:: -il. Dump inlinee line information (DEBUG_S_INLINEELINES CodeView subsection). .. option:: -l. Dump line information (DEBUG_S_LINES CodeView subsection). .. option:: -modules. Dump compiland information. .. option:: -xme. Dump cross module exports (DEBUG_S_",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-pdbutil.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-pdbutil.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-pdbutil.rst:8716,Security,hash,hash,8716,"ream-blocks. In conjunction with :option:`-streams`, add information to the output about; what blocks the specified stream occupies. .. option:: -summary. Dump MSF and PDB header information. Module & File Options; +++++++++++++++++++++. .. option:: -modi=<uint>. For all options that dump information from each module/compiland, limit to; the specified module. .. option:: -files. Dump the source files that contribute to each displayed module. .. option:: -il. Dump inlinee line information (DEBUG_S_INLINEELINES CodeView subsection). .. option:: -l. Dump line information (DEBUG_S_LINES CodeView subsection). .. option:: -modules. Dump compiland information. .. option:: -xme. Dump cross module exports (DEBUG_S_CROSSSCOPEEXPORTS CodeView subsection). .. option:: -xmi. Dump cross module imports (DEBUG_S_CROSSSCOPEIMPORTS CodeView subsection). Symbol Options; ++++++++++++++. .. option:: -globals. dump global symbol records. .. option:: -global-extras. dump additional information about the globals, such as hash buckets and hash; values. .. option:: -publics. dump public symbol records. .. option:: -public-extras. dump additional information about the publics, such as hash buckets and hash; values. .. option:: -symbols. dump symbols (functions, variables, etc) for each module dumped. .. option:: -sym-data. For each symbol record dumped as a result of the :option:`-symbols` option,; display the full bytes of the record in binary as well. Type Record Options; +++++++++++++++++++. .. option:: -types. Dump CodeView type records from TPI stream. .. option:: -type-extras. Dump additional information from the TPI stream, such as hashes and the type; index offsets array. .. option:: -type-data. For each type record dumped, display the full bytes of the record in binary as; well. .. option:: -type-index=<uint>. Only dump types with the specified type index. .. option:: -ids. Dump CodeView type records from IPI stream. .. option:: -id-extras. Dump additional information from the IPI st",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-pdbutil.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-pdbutil.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-pdbutil.rst:8733,Security,hash,hash,8733,"ream-blocks. In conjunction with :option:`-streams`, add information to the output about; what blocks the specified stream occupies. .. option:: -summary. Dump MSF and PDB header information. Module & File Options; +++++++++++++++++++++. .. option:: -modi=<uint>. For all options that dump information from each module/compiland, limit to; the specified module. .. option:: -files. Dump the source files that contribute to each displayed module. .. option:: -il. Dump inlinee line information (DEBUG_S_INLINEELINES CodeView subsection). .. option:: -l. Dump line information (DEBUG_S_LINES CodeView subsection). .. option:: -modules. Dump compiland information. .. option:: -xme. Dump cross module exports (DEBUG_S_CROSSSCOPEEXPORTS CodeView subsection). .. option:: -xmi. Dump cross module imports (DEBUG_S_CROSSSCOPEIMPORTS CodeView subsection). Symbol Options; ++++++++++++++. .. option:: -globals. dump global symbol records. .. option:: -global-extras. dump additional information about the globals, such as hash buckets and hash; values. .. option:: -publics. dump public symbol records. .. option:: -public-extras. dump additional information about the publics, such as hash buckets and hash; values. .. option:: -symbols. dump symbols (functions, variables, etc) for each module dumped. .. option:: -sym-data. For each symbol record dumped as a result of the :option:`-symbols` option,; display the full bytes of the record in binary as well. Type Record Options; +++++++++++++++++++. .. option:: -types. Dump CodeView type records from TPI stream. .. option:: -type-extras. Dump additional information from the TPI stream, such as hashes and the type; index offsets array. .. option:: -type-data. For each type record dumped, display the full bytes of the record in binary as; well. .. option:: -type-index=<uint>. Only dump types with the specified type index. .. option:: -ids. Dump CodeView type records from IPI stream. .. option:: -id-extras. Dump additional information from the IPI st",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-pdbutil.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-pdbutil.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-pdbutil.rst:8880,Security,hash,hash,8880,"and PDB header information. Module & File Options; +++++++++++++++++++++. .. option:: -modi=<uint>. For all options that dump information from each module/compiland, limit to; the specified module. .. option:: -files. Dump the source files that contribute to each displayed module. .. option:: -il. Dump inlinee line information (DEBUG_S_INLINEELINES CodeView subsection). .. option:: -l. Dump line information (DEBUG_S_LINES CodeView subsection). .. option:: -modules. Dump compiland information. .. option:: -xme. Dump cross module exports (DEBUG_S_CROSSSCOPEEXPORTS CodeView subsection). .. option:: -xmi. Dump cross module imports (DEBUG_S_CROSSSCOPEIMPORTS CodeView subsection). Symbol Options; ++++++++++++++. .. option:: -globals. dump global symbol records. .. option:: -global-extras. dump additional information about the globals, such as hash buckets and hash; values. .. option:: -publics. dump public symbol records. .. option:: -public-extras. dump additional information about the publics, such as hash buckets and hash; values. .. option:: -symbols. dump symbols (functions, variables, etc) for each module dumped. .. option:: -sym-data. For each symbol record dumped as a result of the :option:`-symbols` option,; display the full bytes of the record in binary as well. Type Record Options; +++++++++++++++++++. .. option:: -types. Dump CodeView type records from TPI stream. .. option:: -type-extras. Dump additional information from the TPI stream, such as hashes and the type; index offsets array. .. option:: -type-data. For each type record dumped, display the full bytes of the record in binary as; well. .. option:: -type-index=<uint>. Only dump types with the specified type index. .. option:: -ids. Dump CodeView type records from IPI stream. .. option:: -id-extras. Dump additional information from the IPI stream, such as hashes and the type; index offsets array. .. option:: -id-data. For each ID record dumped, display the full bytes of the record in binary as; well. ..",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-pdbutil.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-pdbutil.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-pdbutil.rst:8897,Security,hash,hash,8897,"and PDB header information. Module & File Options; +++++++++++++++++++++. .. option:: -modi=<uint>. For all options that dump information from each module/compiland, limit to; the specified module. .. option:: -files. Dump the source files that contribute to each displayed module. .. option:: -il. Dump inlinee line information (DEBUG_S_INLINEELINES CodeView subsection). .. option:: -l. Dump line information (DEBUG_S_LINES CodeView subsection). .. option:: -modules. Dump compiland information. .. option:: -xme. Dump cross module exports (DEBUG_S_CROSSSCOPEEXPORTS CodeView subsection). .. option:: -xmi. Dump cross module imports (DEBUG_S_CROSSSCOPEIMPORTS CodeView subsection). Symbol Options; ++++++++++++++. .. option:: -globals. dump global symbol records. .. option:: -global-extras. dump additional information about the globals, such as hash buckets and hash; values. .. option:: -publics. dump public symbol records. .. option:: -public-extras. dump additional information about the publics, such as hash buckets and hash; values. .. option:: -symbols. dump symbols (functions, variables, etc) for each module dumped. .. option:: -sym-data. For each symbol record dumped as a result of the :option:`-symbols` option,; display the full bytes of the record in binary as well. Type Record Options; +++++++++++++++++++. .. option:: -types. Dump CodeView type records from TPI stream. .. option:: -type-extras. Dump additional information from the TPI stream, such as hashes and the type; index offsets array. .. option:: -type-data. For each type record dumped, display the full bytes of the record in binary as; well. .. option:: -type-index=<uint>. Only dump types with the specified type index. .. option:: -ids. Dump CodeView type records from IPI stream. .. option:: -id-extras. Dump additional information from the IPI stream, such as hashes and the type; index offsets array. .. option:: -id-data. For each ID record dumped, display the full bytes of the record in binary as; well. ..",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-pdbutil.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-pdbutil.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-pdbutil.rst:9343,Security,hash,hashes,9343,"s. Dump compiland information. .. option:: -xme. Dump cross module exports (DEBUG_S_CROSSSCOPEEXPORTS CodeView subsection). .. option:: -xmi. Dump cross module imports (DEBUG_S_CROSSSCOPEIMPORTS CodeView subsection). Symbol Options; ++++++++++++++. .. option:: -globals. dump global symbol records. .. option:: -global-extras. dump additional information about the globals, such as hash buckets and hash; values. .. option:: -publics. dump public symbol records. .. option:: -public-extras. dump additional information about the publics, such as hash buckets and hash; values. .. option:: -symbols. dump symbols (functions, variables, etc) for each module dumped. .. option:: -sym-data. For each symbol record dumped as a result of the :option:`-symbols` option,; display the full bytes of the record in binary as well. Type Record Options; +++++++++++++++++++. .. option:: -types. Dump CodeView type records from TPI stream. .. option:: -type-extras. Dump additional information from the TPI stream, such as hashes and the type; index offsets array. .. option:: -type-data. For each type record dumped, display the full bytes of the record in binary as; well. .. option:: -type-index=<uint>. Only dump types with the specified type index. .. option:: -ids. Dump CodeView type records from IPI stream. .. option:: -id-extras. Dump additional information from the IPI stream, such as hashes and the type; index offsets array. .. option:: -id-data. For each ID record dumped, display the full bytes of the record in binary as; well. .. option:: -id-index=<uint>. only dump ID records with the specified hexadecimal type index. .. option:: -dependents. When used in conjunction with :option:`-type-index` or :option:`-id-index`,; dumps the entire dependency graph for the specified index instead of just the; single record with the specified index. For example, if type index 0x4000 is; a function whose return type has index 0x3000, and you specify; `-dependents=0x4000`, then this would dump both recor",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-pdbutil.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-pdbutil.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-pdbutil.rst:9717,Security,hash,hashes,9717,"such as hash buckets and hash; values. .. option:: -publics. dump public symbol records. .. option:: -public-extras. dump additional information about the publics, such as hash buckets and hash; values. .. option:: -symbols. dump symbols (functions, variables, etc) for each module dumped. .. option:: -sym-data. For each symbol record dumped as a result of the :option:`-symbols` option,; display the full bytes of the record in binary as well. Type Record Options; +++++++++++++++++++. .. option:: -types. Dump CodeView type records from TPI stream. .. option:: -type-extras. Dump additional information from the TPI stream, such as hashes and the type; index offsets array. .. option:: -type-data. For each type record dumped, display the full bytes of the record in binary as; well. .. option:: -type-index=<uint>. Only dump types with the specified type index. .. option:: -ids. Dump CodeView type records from IPI stream. .. option:: -id-extras. Dump additional information from the IPI stream, such as hashes and the type; index offsets array. .. option:: -id-data. For each ID record dumped, display the full bytes of the record in binary as; well. .. option:: -id-index=<uint>. only dump ID records with the specified hexadecimal type index. .. option:: -dependents. When used in conjunction with :option:`-type-index` or :option:`-id-index`,; dumps the entire dependency graph for the specified index instead of just the; single record with the specified index. For example, if type index 0x4000 is; a function whose return type has index 0x3000, and you specify; `-dependents=0x4000`, then this would dump both records (as well as any other; dependents in the tree). Miscellaneous Options; +++++++++++++++++++++. .. option:: -all. Implies most other options. .. option:: -section-contribs. Dump section contributions. .. option:: -section-headers. Dump image section headers. .. option:: -section-map. Dump section map. .. option:: -string-table. Dump PDB string table. .. _bytes_subcommand",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-pdbutil.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-pdbutil.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-pdbutil.rst:438,Testability,test,tests,438,"llvm-pdbutil - PDB File forensics and diagnostics; =================================================. .. program:: llvm-pdbutil. .. contents::; :local:. Synopsis; --------. :program:`llvm-pdbutil` [*subcommand*] [*options*]. Description; -----------. Display types, symbols, CodeView records, and other information from a; PDB file, as well as manipulate and create PDB files. :program:`llvm-pdbutil`; is normally used by FileCheck-based tests to test LLVM's PDB reading and; writing functionality, but can also be used for general PDB file investigation; and forensics, or as a replacement for cvdump. Subcommands; -----------. :program:`llvm-pdbutil` is separated into several subcommands each tailored to; a different purpose. A brief summary of each command follows, with more detail; in the sections that follow. * :ref:`pretty_subcommand` - Dump symbol and type information in a format that; tries to look as much like the original source code as possible.; * :ref:`dump_subcommand` - Dump low level types and structures from the PDB; file, including CodeView records, hash tables, PDB streams, etc.; * :ref:`bytes_subcommand` - Dump data from the PDB file's streams, records,; types, symbols, etc as raw bytes.; * :ref:`yaml2pdb_subcommand` - Given a yaml description of a PDB file, produce; a valid PDB file that matches that description.; * :ref:`pdb2yaml_subcommand` - For a given PDB file, produce a YAML; description of some or all of the file in a way that the PDB can be; reconstructed.; * :ref:`merge_subcommand` - Given two PDBs, produce a third PDB that is the; result of merging the two input PDBs. .. _pretty_subcommand:. pretty; ~~~~~~. .. program:: llvm-pdbutil pretty. .. important::; The **pretty** subcommand is built on the Windows DIA SDK, and as such is not; supported on non-Windows platforms. USAGE: :program:`llvm-pdbutil` pretty [*options*] <input PDB file>. Summary; ^^^^^^^^^^^. The *pretty* subcommand displays a very high level representation of your; program's debu",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-pdbutil.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-pdbutil.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-pdbutil.rst:447,Testability,test,test,447,"llvm-pdbutil - PDB File forensics and diagnostics; =================================================. .. program:: llvm-pdbutil. .. contents::; :local:. Synopsis; --------. :program:`llvm-pdbutil` [*subcommand*] [*options*]. Description; -----------. Display types, symbols, CodeView records, and other information from a; PDB file, as well as manipulate and create PDB files. :program:`llvm-pdbutil`; is normally used by FileCheck-based tests to test LLVM's PDB reading and; writing functionality, but can also be used for general PDB file investigation; and forensics, or as a replacement for cvdump. Subcommands; -----------. :program:`llvm-pdbutil` is separated into several subcommands each tailored to; a different purpose. A brief summary of each command follows, with more detail; in the sections that follow. * :ref:`pretty_subcommand` - Dump symbol and type information in a format that; tries to look as much like the original source code as possible.; * :ref:`dump_subcommand` - Dump low level types and structures from the PDB; file, including CodeView records, hash tables, PDB streams, etc.; * :ref:`bytes_subcommand` - Dump data from the PDB file's streams, records,; types, symbols, etc as raw bytes.; * :ref:`yaml2pdb_subcommand` - Given a yaml description of a PDB file, produce; a valid PDB file that matches that description.; * :ref:`pdb2yaml_subcommand` - For a given PDB file, produce a YAML; description of some or all of the file in a way that the PDB can be; reconstructed.; * :ref:`merge_subcommand` - Given two PDBs, produce a third PDB that is the; result of merging the two input PDBs. .. _pretty_subcommand:. pretty; ~~~~~~. .. program:: llvm-pdbutil pretty. .. important::; The **pretty** subcommand is built on the Windows DIA SDK, and as such is not; supported on non-Windows platforms. USAGE: :program:`llvm-pdbutil` pretty [*options*] <input PDB file>. Summary; ^^^^^^^^^^^. The *pretty* subcommand displays a very high level representation of your; program's debu",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-pdbutil.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-pdbutil.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-pdbutil.rst:7248,Testability,test,testing,7248,":: -symbol-order=<order>. For symbols dumped via the -module-syms, -globals, or -externals options, sort; the results in specified order. .. code-block:: text. =none - Undefined / no particular sort order; =name - Sort symbols by name; =size - Sort symbols by size. .. option:: -typedefs. Display typedef types. .. option:: -types. Display all types (implies -classes, -enums, -typedefs). Other Options; +++++++++++++. .. option:: -color-output. Force color output on or off. By default, color if used if outputting to a; terminal. .. option:: -load-address=<uint>. When displaying relative virtual addresses, assume the process is loaded at the; given address and display what would be the absolute address. .. _dump_subcommand:. dump; ~~~~. USAGE: :program:`llvm-pdbutil` dump [*options*] <input PDB file>. .. program:: llvm-pdbutil dump. Summary; ^^^^^^^^^^^. The **dump** subcommand displays low level information about the structure of a; PDB file. It is used heavily by LLVM's testing infrastructure, but can also be; used for PDB forensics. It serves a role similar to that of Microsoft's; `cvdump` tool. .. note::; The **dump** subcommand exposes internal details of the file format. As; such, the reader should be familiar with :doc:`/PDB/index` before using this; command. Options; ^^^^^^^. MSF Container Options; +++++++++++++++++++++. .. option:: -streams. dump a summary of all of the streams in the PDB file. .. option:: -stream-blocks. In conjunction with :option:`-streams`, add information to the output about; what blocks the specified stream occupies. .. option:: -summary. Dump MSF and PDB header information. Module & File Options; +++++++++++++++++++++. .. option:: -modi=<uint>. For all options that dump information from each module/compiland, limit to; the specified module. .. option:: -files. Dump the source files that contribute to each displayed module. .. option:: -il. Dump inlinee line information (DEBUG_S_INLINEELINES CodeView subsection). .. option:: -l. Dump line",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-pdbutil.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-pdbutil.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-pdbutil.rst:11325,Usability,simpl,simply,11325,"+++++++. .. option:: -all. Implies most other options. .. option:: -section-contribs. Dump section contributions. .. option:: -section-headers. Dump image section headers. .. option:: -section-map. Dump section map. .. option:: -string-table. Dump PDB string table. .. _bytes_subcommand:. bytes; ~~~~~. USAGE: :program:`llvm-pdbutil` bytes [*options*] <input PDB file>. .. program:: llvm-pdbutil bytes. Summary; ^^^^^^^. Like the **dump** subcommand, the **bytes** subcommand displays low level; information about the structure of a PDB file, but it is used for even deeper; forensics. The **bytes** subcommand finds various structures in a PDB file; based on the command line options specified, and dumps them in hex. Someone; working on support for emitting PDBs would use this heavily, for example, to; compare one PDB against another PDB to ensure byte-for-byte compatibility. It; is not enough to simply compare the bytes of an entire file, or an entire stream; because it's perfectly fine for the same structure to exist at different; locations in two different PDBs, and ""finding"" the structure is half the battle. Options; ^^^^^^^. MSF File Options; ++++++++++++++++. .. option:: -block-range=<start[-end]>. Dump binary data from specified range of MSF file blocks. .. option:: -byte-range=<start[-end]>. Dump binary data from specified range of bytes in the file. .. option:: -fpm. Dump the MSF free page map. .. option:: -stream-data=<string>. Dump binary data from the specified streams. Format is SN[:Start][@Size].; For example, `-stream-data=7:3@12` dumps 12 bytes from stream 7, starting; at offset 3 in the stream. PDB Stream Options; ++++++++++++++++++. .. option:: -name-map. Dump bytes of PDB Name Map. DBI Stream Options; ++++++++++++++++++. .. option:: -ec. Dump the edit and continue map substream of the DBI stream. .. option:: -files. Dump the file info substream of the DBI stream. .. option:: -modi. Dump the modi substream of the DBI stream. .. option:: -sc. Dump section co",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-pdbutil.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-pdbutil.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profdata.rst:4046,Availability,failure,failure-mode,4046," --extbinary. Emit the profile using an extensible binary encoding. This option can only; be used with sample-based profile. The extensible binary encoding can be; more compact with compression enabled and can be loaded faster than the; default binary encoding. .. option:: --text. Emit the profile in text mode. This option can also be used with both; sample-based and instrumentation-based profile. When this option is used; the profile will be dumped in the text format that is parsable by the profile; reader. .. option:: --gcc. Emit the profile using GCC's gcov format (Not yet supported). .. option:: --sparse[=true|false]. Do not emit function records with 0 execution count. Can only be used in; conjunction with -instr. Defaults to false, since it can inhibit compiler; optimization during PGO. .. option:: --num-threads=<N>, -j. Use N threads to perform profile merging. When N=0, llvm-profdata auto-detects; an appropriate number of threads to use. This is the default. .. option:: --failure-mode=[any|all]. Set the failure mode. There are two options: 'any' causes the merge command to; fail if any profiles are invalid, and 'all' causes the merge command to fail; only if all profiles are invalid. If 'all' is set, information from any; invalid profiles is excluded from the final merged product. The default; failure mode is 'any'. .. option:: --prof-sym-list=<path>. Specify a file which contains a list of symbols to generate profile symbol; list in the profile. This option can only be used with sample-based profile; in extbinary format. The entries in this file are newline-separated. .. option:: --compress-all-sections=[true|false]. Compress all sections when writing the profile. This option can only be used; with sample-based profile in extbinary format. .. option:: --use-md5=[true|false]. Use MD5 to represent string in name table when writing the profile.; This option can only be used with sample-based profile in extbinary format. .. option:: --gen-partial-profile=[true|f",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profdata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profdata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profdata.rst:4078,Availability,failure,failure,4078,"e using an extensible binary encoding. This option can only; be used with sample-based profile. The extensible binary encoding can be; more compact with compression enabled and can be loaded faster than the; default binary encoding. .. option:: --text. Emit the profile in text mode. This option can also be used with both; sample-based and instrumentation-based profile. When this option is used; the profile will be dumped in the text format that is parsable by the profile; reader. .. option:: --gcc. Emit the profile using GCC's gcov format (Not yet supported). .. option:: --sparse[=true|false]. Do not emit function records with 0 execution count. Can only be used in; conjunction with -instr. Defaults to false, since it can inhibit compiler; optimization during PGO. .. option:: --num-threads=<N>, -j. Use N threads to perform profile merging. When N=0, llvm-profdata auto-detects; an appropriate number of threads to use. This is the default. .. option:: --failure-mode=[any|all]. Set the failure mode. There are two options: 'any' causes the merge command to; fail if any profiles are invalid, and 'all' causes the merge command to fail; only if all profiles are invalid. If 'all' is set, information from any; invalid profiles is excluded from the final merged product. The default; failure mode is 'any'. .. option:: --prof-sym-list=<path>. Specify a file which contains a list of symbols to generate profile symbol; list in the profile. This option can only be used with sample-based profile; in extbinary format. The entries in this file are newline-separated. .. option:: --compress-all-sections=[true|false]. Compress all sections when writing the profile. This option can only be used; with sample-based profile in extbinary format. .. option:: --use-md5=[true|false]. Use MD5 to represent string in name table when writing the profile.; This option can only be used with sample-based profile in extbinary format. .. option:: --gen-partial-profile=[true|false]. Mark the profile to b",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profdata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profdata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profdata.rst:4374,Availability,failure,failure,4374,"n also be used with both; sample-based and instrumentation-based profile. When this option is used; the profile will be dumped in the text format that is parsable by the profile; reader. .. option:: --gcc. Emit the profile using GCC's gcov format (Not yet supported). .. option:: --sparse[=true|false]. Do not emit function records with 0 execution count. Can only be used in; conjunction with -instr. Defaults to false, since it can inhibit compiler; optimization during PGO. .. option:: --num-threads=<N>, -j. Use N threads to perform profile merging. When N=0, llvm-profdata auto-detects; an appropriate number of threads to use. This is the default. .. option:: --failure-mode=[any|all]. Set the failure mode. There are two options: 'any' causes the merge command to; fail if any profiles are invalid, and 'all' causes the merge command to fail; only if all profiles are invalid. If 'all' is set, information from any; invalid profiles is excluded from the final merged product. The default; failure mode is 'any'. .. option:: --prof-sym-list=<path>. Specify a file which contains a list of symbols to generate profile symbol; list in the profile. This option can only be used with sample-based profile; in extbinary format. The entries in this file are newline-separated. .. option:: --compress-all-sections=[true|false]. Compress all sections when writing the profile. This option can only be used; with sample-based profile in extbinary format. .. option:: --use-md5=[true|false]. Use MD5 to represent string in name table when writing the profile.; This option can only be used with sample-based profile in extbinary format. .. option:: --gen-partial-profile=[true|false]. Mark the profile to be a partial profile which only provides partial profile; coverage for the optimized target. This option can only be used with; sample-based profile in extbinary format. .. option:: --convert-sample-profile-layout=[nest|flat]. Convert the merged profile into a profile with a new layout. Supported; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profdata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profdata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profdata.rst:13890,Availability,fault,faults,13890,"(c1_n/sum_1, c2_n/sum_2). The result overlap distribution is a percentage number, ranging from 0.0% to; 100.0%, where 0.0% means there is no overlap and 100.0% means a perfect; overlap. Here is an example, if *base profile file* has counts of {400, 600}, and; *test profile file* has matched counts of {60000, 40000}. The *overlap* is 80%. OPTIONS; ^^^^^^^. .. option:: --function=<string>. Print details for a function if the function's name contains the given string. .. option:: --help. Print a summary of command line options. .. option:: --output=<output>, -o. Specify the output file name. If *output* is ``-`` or it isn't specified,; then the output is sent to standard output. .. option:: --value-cutoff=<n>. Show only those functions whose max count values are greater or equal to ``n``.; By default, the value-cutoff is set to max of unsigned long long. .. option:: --cs. Only show overlap for the context sensitive profile counts. The default is to show; non-context sensitive profile counts. .. program:: llvm-profdata order. .. _profdata-order:. ORDER; -------. SYNOPSIS; ^^^^^^^^. :program:`llvm-profdata order` [*options*] [*filename*]. DESCRIPTION; ^^^^^^^^^^^. :program:`llvm-profdata order` uses temporal profiling traces from a profile and; finds a function order that reduces the number of page faults for those traces.; This output can be directly passed to ``lld`` via ``--symbol-ordering-file=``; for ELF or ``-order-file`` for Mach-O. If the traces found in the profile are; representative of the real world, then this order should improve startup; performance. OPTIONS; ^^^^^^^. .. option:: --help. Print a summary of command line options. .. option:: --output=<output>, -o. Specify the output file name. If *output* is ``-`` or it isn't specified,; then the output is sent to standard output. EXIT STATUS; -----------. :program:`llvm-profdata` returns 1 if the command is omitted or is invalid,; if it cannot read input files, or if there is a mismatch between their data.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profdata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profdata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profdata.rst:13863,Energy Efficiency,reduce,reduces,13863,"(c1_n/sum_1, c2_n/sum_2). The result overlap distribution is a percentage number, ranging from 0.0% to; 100.0%, where 0.0% means there is no overlap and 100.0% means a perfect; overlap. Here is an example, if *base profile file* has counts of {400, 600}, and; *test profile file* has matched counts of {60000, 40000}. The *overlap* is 80%. OPTIONS; ^^^^^^^. .. option:: --function=<string>. Print details for a function if the function's name contains the given string. .. option:: --help. Print a summary of command line options. .. option:: --output=<output>, -o. Specify the output file name. If *output* is ``-`` or it isn't specified,; then the output is sent to standard output. .. option:: --value-cutoff=<n>. Show only those functions whose max count values are greater or equal to ``n``.; By default, the value-cutoff is set to max of unsigned long long. .. option:: --cs. Only show overlap for the context sensitive profile counts. The default is to show; non-context sensitive profile counts. .. program:: llvm-profdata order. .. _profdata-order:. ORDER; -------. SYNOPSIS; ^^^^^^^^. :program:`llvm-profdata order` [*options*] [*filename*]. DESCRIPTION; ^^^^^^^^^^^. :program:`llvm-profdata order` uses temporal profiling traces from a profile and; finds a function order that reduces the number of page faults for those traces.; This output can be directly passed to ``lld`` via ``--symbol-ordering-file=``; for ELF or ``-order-file`` for Mach-O. If the traces found in the profile are; representative of the real world, then this order should improve startup; performance. OPTIONS; ^^^^^^^. .. option:: --help. Print a summary of command line options. .. option:: --output=<output>, -o. Specify the output file name. If *output* is ``-`` or it isn't specified,; then the output is sent to standard output. EXIT STATUS; -----------. :program:`llvm-profdata` returns 1 if the command is omitted or is invalid,; if it cannot read input files, or if there is a mismatch between their data.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profdata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profdata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profdata.rst:3264,Performance,load,loaded,3264,"path>, -r. Specify a file which contains a remapping from symbol names in the input; profile to the symbol names that should be used in the output profile. The; file should consist of lines of the form ``<input-symbol> <output-symbol>``.; Blank lines and lines starting with ``#`` are skipped. The :doc:`llvm-cxxmap <llvm-cxxmap>` tool can be used to generate the symbol; remapping file. .. option:: --instr (default). Specify that the input profile is an instrumentation-based profile. .. option:: --sample. Specify that the input profile is a sample-based profile. The format of the generated file can be generated in one of three ways:. .. option:: --binary (default). Emit the profile using a binary encoding. For instrumentation-based profile; the output format is the indexed binary format. .. option:: --extbinary. Emit the profile using an extensible binary encoding. This option can only; be used with sample-based profile. The extensible binary encoding can be; more compact with compression enabled and can be loaded faster than the; default binary encoding. .. option:: --text. Emit the profile in text mode. This option can also be used with both; sample-based and instrumentation-based profile. When this option is used; the profile will be dumped in the text format that is parsable by the profile; reader. .. option:: --gcc. Emit the profile using GCC's gcov format (Not yet supported). .. option:: --sparse[=true|false]. Do not emit function records with 0 execution count. Can only be used in; conjunction with -instr. Defaults to false, since it can inhibit compiler; optimization during PGO. .. option:: --num-threads=<N>, -j. Use N threads to perform profile merging. When N=0, llvm-profdata auto-detects; an appropriate number of threads to use. This is the default. .. option:: --failure-mode=[any|all]. Set the failure mode. There are two options: 'any' causes the merge command to; fail if any profiles are invalid, and 'all' causes the merge command to fail; only if all prof",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profdata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profdata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profdata.rst:3830,Performance,optimiz,optimization,3830,"rmat of the generated file can be generated in one of three ways:. .. option:: --binary (default). Emit the profile using a binary encoding. For instrumentation-based profile; the output format is the indexed binary format. .. option:: --extbinary. Emit the profile using an extensible binary encoding. This option can only; be used with sample-based profile. The extensible binary encoding can be; more compact with compression enabled and can be loaded faster than the; default binary encoding. .. option:: --text. Emit the profile in text mode. This option can also be used with both; sample-based and instrumentation-based profile. When this option is used; the profile will be dumped in the text format that is parsable by the profile; reader. .. option:: --gcc. Emit the profile using GCC's gcov format (Not yet supported). .. option:: --sparse[=true|false]. Do not emit function records with 0 execution count. Can only be used in; conjunction with -instr. Defaults to false, since it can inhibit compiler; optimization during PGO. .. option:: --num-threads=<N>, -j. Use N threads to perform profile merging. When N=0, llvm-profdata auto-detects; an appropriate number of threads to use. This is the default. .. option:: --failure-mode=[any|all]. Set the failure mode. There are two options: 'any' causes the merge command to; fail if any profiles are invalid, and 'all' causes the merge command to fail; only if all profiles are invalid. If 'all' is set, information from any; invalid profiles is excluded from the final merged product. The default; failure mode is 'any'. .. option:: --prof-sym-list=<path>. Specify a file which contains a list of symbols to generate profile symbol; list in the profile. This option can only be used with sample-based profile; in extbinary format. The entries in this file are newline-separated. .. option:: --compress-all-sections=[true|false]. Compress all sections when writing the profile. This option can only be used; with sample-based profile in extbi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profdata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profdata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profdata.rst:3907,Performance,perform,perform,3907,"lt). Emit the profile using a binary encoding. For instrumentation-based profile; the output format is the indexed binary format. .. option:: --extbinary. Emit the profile using an extensible binary encoding. This option can only; be used with sample-based profile. The extensible binary encoding can be; more compact with compression enabled and can be loaded faster than the; default binary encoding. .. option:: --text. Emit the profile in text mode. This option can also be used with both; sample-based and instrumentation-based profile. When this option is used; the profile will be dumped in the text format that is parsable by the profile; reader. .. option:: --gcc. Emit the profile using GCC's gcov format (Not yet supported). .. option:: --sparse[=true|false]. Do not emit function records with 0 execution count. Can only be used in; conjunction with -instr. Defaults to false, since it can inhibit compiler; optimization during PGO. .. option:: --num-threads=<N>, -j. Use N threads to perform profile merging. When N=0, llvm-profdata auto-detects; an appropriate number of threads to use. This is the default. .. option:: --failure-mode=[any|all]. Set the failure mode. There are two options: 'any' causes the merge command to; fail if any profiles are invalid, and 'all' causes the merge command to fail; only if all profiles are invalid. If 'all' is set, information from any; invalid profiles is excluded from the final merged product. The default; failure mode is 'any'. .. option:: --prof-sym-list=<path>. Specify a file which contains a list of symbols to generate profile symbol; list in the profile. This option can only be used with sample-based profile; in extbinary format. The entries in this file are newline-separated. .. option:: --compress-all-sections=[true|false]. Compress all sections when writing the profile. This option can only be used; with sample-based profile in extbinary format. .. option:: --use-md5=[true|false]. Use MD5 to represent string in name table wh",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profdata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profdata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profdata.rst:5154,Performance,optimiz,optimized,5154," 'any' causes the merge command to; fail if any profiles are invalid, and 'all' causes the merge command to fail; only if all profiles are invalid. If 'all' is set, information from any; invalid profiles is excluded from the final merged product. The default; failure mode is 'any'. .. option:: --prof-sym-list=<path>. Specify a file which contains a list of symbols to generate profile symbol; list in the profile. This option can only be used with sample-based profile; in extbinary format. The entries in this file are newline-separated. .. option:: --compress-all-sections=[true|false]. Compress all sections when writing the profile. This option can only be used; with sample-based profile in extbinary format. .. option:: --use-md5=[true|false]. Use MD5 to represent string in name table when writing the profile.; This option can only be used with sample-based profile in extbinary format. .. option:: --gen-partial-profile=[true|false]. Mark the profile to be a partial profile which only provides partial profile; coverage for the optimized target. This option can only be used with; sample-based profile in extbinary format. .. option:: --convert-sample-profile-layout=[nest|flat]. Convert the merged profile into a profile with a new layout. Supported; layout are ``nest`` (Nested profile, the input should be CS flat profile) and; ``flat`` (Profile with nested inlinees flattened out). .. option:: --supplement-instr-with-sample=<file>. Supplement an instrumentation profile with sample profile. The sample profile; is the input of the flag. Output will be in instrumentation format (only works; with -instr). .. option:: --zero-counter-threshold=<float>. For the function which is cold in instr profile but hot in sample profile, if; the ratio of the number of zero counters divided by the total number of; counters is above the threshold, the profile of the function will be regarded; as being harmful for performance and will be dropped. .. option:: --instr-prof-cold-threshold=<int>. U",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profdata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profdata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profdata.rst:6034,Performance,perform,performance,6034,"e profile.; This option can only be used with sample-based profile in extbinary format. .. option:: --gen-partial-profile=[true|false]. Mark the profile to be a partial profile which only provides partial profile; coverage for the optimized target. This option can only be used with; sample-based profile in extbinary format. .. option:: --convert-sample-profile-layout=[nest|flat]. Convert the merged profile into a profile with a new layout. Supported; layout are ``nest`` (Nested profile, the input should be CS flat profile) and; ``flat`` (Profile with nested inlinees flattened out). .. option:: --supplement-instr-with-sample=<file>. Supplement an instrumentation profile with sample profile. The sample profile; is the input of the flag. Output will be in instrumentation format (only works; with -instr). .. option:: --zero-counter-threshold=<float>. For the function which is cold in instr profile but hot in sample profile, if; the ratio of the number of zero counters divided by the total number of; counters is above the threshold, the profile of the function will be regarded; as being harmful for performance and will be dropped. .. option:: --instr-prof-cold-threshold=<int>. User specified cold threshold for instr profile which will override the cold; threshold got from profile summary. .. option:: --suppl-min-size-threshold=<int>. If the size of a function is smaller than the threshold, assume it can be; inlined by PGO early inliner and it will not be adjusted based on sample; profile. .. option:: --debug-info=<path>. Specify the executable or ``.dSYM`` that contains debug info for the raw profile.; When ``--debug-info-correlate`` or ``--profile-correlate=debug-info`` was used ; for instrumentation, use this option to correlate the raw profile. .. option:: --binary-file=<path>. Specify the executable that contains profile data and profile name sections for; the raw profile. When ``-profile-correlate=binary`` was used for; instrumentation, use this option to correlate t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profdata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profdata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profdata.rst:14148,Performance,perform,performance,14148,"(c1_n/sum_1, c2_n/sum_2). The result overlap distribution is a percentage number, ranging from 0.0% to; 100.0%, where 0.0% means there is no overlap and 100.0% means a perfect; overlap. Here is an example, if *base profile file* has counts of {400, 600}, and; *test profile file* has matched counts of {60000, 40000}. The *overlap* is 80%. OPTIONS; ^^^^^^^. .. option:: --function=<string>. Print details for a function if the function's name contains the given string. .. option:: --help. Print a summary of command line options. .. option:: --output=<output>, -o. Specify the output file name. If *output* is ``-`` or it isn't specified,; then the output is sent to standard output. .. option:: --value-cutoff=<n>. Show only those functions whose max count values are greater or equal to ``n``.; By default, the value-cutoff is set to max of unsigned long long. .. option:: --cs. Only show overlap for the context sensitive profile counts. The default is to show; non-context sensitive profile counts. .. program:: llvm-profdata order. .. _profdata-order:. ORDER; -------. SYNOPSIS; ^^^^^^^^. :program:`llvm-profdata order` [*options*] [*filename*]. DESCRIPTION; ^^^^^^^^^^^. :program:`llvm-profdata order` uses temporal profiling traces from a profile and; finds a function order that reduces the number of page faults for those traces.; This output can be directly passed to ``lld`` via ``--symbol-ordering-file=``; for ELF or ``-order-file`` for Mach-O. If the traces found in the profile are; representative of the real world, then this order should improve startup; performance. OPTIONS; ^^^^^^^. .. option:: --help. Print a summary of command line options. .. option:: --output=<output>, -o. Specify the output file name. If *output* is ``-`` or it isn't specified,; then the output is sent to standard output. EXIT STATUS; -----------. :program:`llvm-profdata` returns 1 if the command is omitted or is invalid,; if it cannot read input files, or if there is a mismatch between their data.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profdata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profdata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profdata.rst:3961,Safety,detect,detects,3961,"tation-based profile; the output format is the indexed binary format. .. option:: --extbinary. Emit the profile using an extensible binary encoding. This option can only; be used with sample-based profile. The extensible binary encoding can be; more compact with compression enabled and can be loaded faster than the; default binary encoding. .. option:: --text. Emit the profile in text mode. This option can also be used with both; sample-based and instrumentation-based profile. When this option is used; the profile will be dumped in the text format that is parsable by the profile; reader. .. option:: --gcc. Emit the profile using GCC's gcov format (Not yet supported). .. option:: --sparse[=true|false]. Do not emit function records with 0 execution count. Can only be used in; conjunction with -instr. Defaults to false, since it can inhibit compiler; optimization during PGO. .. option:: --num-threads=<N>, -j. Use N threads to perform profile merging. When N=0, llvm-profdata auto-detects; an appropriate number of threads to use. This is the default. .. option:: --failure-mode=[any|all]. Set the failure mode. There are two options: 'any' causes the merge command to; fail if any profiles are invalid, and 'all' causes the merge command to fail; only if all profiles are invalid. If 'all' is set, information from any; invalid profiles is excluded from the final merged product. The default; failure mode is 'any'. .. option:: --prof-sym-list=<path>. Specify a file which contains a list of symbols to generate profile symbol; list in the profile. This option can only be used with sample-based profile; in extbinary format. The entries in this file are newline-separated. .. option:: --compress-all-sections=[true|false]. Compress all sections when writing the profile. This option can only be used; with sample-based profile in extbinary format. .. option:: --use-md5=[true|false]. Use MD5 to represent string in name table when writing the profile.; This option can only be used with sa",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profdata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profdata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profdata.rst:11662,Testability,test,test,11662,"ontext sensitive profile counts. The default is to filter all; context sensitive profile counts. .. option:: --show-prof-sym-list=[true|false]. Show profile symbol list if it exists in the profile. This option is only; meaningful for sample-based profile in extbinary format. .. option:: --show-sec-info-only=[true|false]. Show basic information about each section in the profile. This option is; only meaningful for sample-based profile in extbinary format. .. option:: --debug-info=<path>. Specify the executable or ``.dSYM`` that contains debug info for the raw profile.; When ``--debug-info-correlate`` or ``--profile-correlate=debug-info`` was used; for instrumentation, use this option to show the correlated functions from the; raw profile. .. option:: --covered. Show only the functions that have been executed, i.e., functions with non-zero; counts. .. program:: llvm-profdata overlap. .. _profdata-overlap:. OVERLAP; -------. SYNOPSIS; ^^^^^^^^. :program:`llvm-profdata overlap` [*options*] [*base profile file*] [*test profile file*]. DESCRIPTION; ^^^^^^^^^^^. :program:`llvm-profdata overlap` takes two profile data files and displays the; *overlap* of counter distribution between the whole files and between any of the; specified functions. In this command, *overlap* is defined as follows:; Suppose *base profile file* has the following counts:; {c1_1, c1_2, ..., c1_n, c1_u_1, c2_u_2, ..., c2_u_s},; and *test profile file* has; {c2_1, c2_2, ..., c2_n, c2_v_1, c2_v_2, ..., c2_v_t}.; Here c{1|2}_i (i = 1 .. n) are matched counters and c1_u_i (i = 1 .. s) and; c2_v_i (i = 1 .. v) are unmatched counters (or counters only existing in); *base profile file* and *test profile file*, respectively.; Let sum_1 = c1_1 + c1_2 + ... + c1_n + c1_u_1 + c2_u_2 + ... + c2_u_s, and; sum_2 = c2_1 + c2_2 + ... + c2_n + c2_v_1 + c2_v_2 + ... + c2_v_t.; *overlap* = min(c1_1/sum_1, c2_1/sum_2) + min(c1_2/sum_1, c2_2/sum_2) + ...; + min(c1_n/sum_1, c2_n/sum_2). The result overlap distribution is a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profdata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profdata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profdata.rst:12058,Testability,test,test,12058,"rofile in extbinary format. .. option:: --debug-info=<path>. Specify the executable or ``.dSYM`` that contains debug info for the raw profile.; When ``--debug-info-correlate`` or ``--profile-correlate=debug-info`` was used; for instrumentation, use this option to show the correlated functions from the; raw profile. .. option:: --covered. Show only the functions that have been executed, i.e., functions with non-zero; counts. .. program:: llvm-profdata overlap. .. _profdata-overlap:. OVERLAP; -------. SYNOPSIS; ^^^^^^^^. :program:`llvm-profdata overlap` [*options*] [*base profile file*] [*test profile file*]. DESCRIPTION; ^^^^^^^^^^^. :program:`llvm-profdata overlap` takes two profile data files and displays the; *overlap* of counter distribution between the whole files and between any of the; specified functions. In this command, *overlap* is defined as follows:; Suppose *base profile file* has the following counts:; {c1_1, c1_2, ..., c1_n, c1_u_1, c2_u_2, ..., c2_u_s},; and *test profile file* has; {c2_1, c2_2, ..., c2_n, c2_v_1, c2_v_2, ..., c2_v_t}.; Here c{1|2}_i (i = 1 .. n) are matched counters and c1_u_i (i = 1 .. s) and; c2_v_i (i = 1 .. v) are unmatched counters (or counters only existing in); *base profile file* and *test profile file*, respectively.; Let sum_1 = c1_1 + c1_2 + ... + c1_n + c1_u_1 + c2_u_2 + ... + c2_u_s, and; sum_2 = c2_1 + c2_2 + ... + c2_n + c2_v_1 + c2_v_2 + ... + c2_v_t.; *overlap* = min(c1_1/sum_1, c2_1/sum_2) + min(c1_2/sum_1, c2_2/sum_2) + ...; + min(c1_n/sum_1, c2_n/sum_2). The result overlap distribution is a percentage number, ranging from 0.0% to; 100.0%, where 0.0% means there is no overlap and 100.0% means a perfect; overlap. Here is an example, if *base profile file* has counts of {400, 600}, and; *test profile file* has matched counts of {60000, 40000}. The *overlap* is 80%. OPTIONS; ^^^^^^^. .. option:: --function=<string>. Print details for a function if the function's name contains the given string. .. option:: --help. Prin",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profdata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profdata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profdata.rst:12314,Testability,test,test,12314,"ed; for instrumentation, use this option to show the correlated functions from the; raw profile. .. option:: --covered. Show only the functions that have been executed, i.e., functions with non-zero; counts. .. program:: llvm-profdata overlap. .. _profdata-overlap:. OVERLAP; -------. SYNOPSIS; ^^^^^^^^. :program:`llvm-profdata overlap` [*options*] [*base profile file*] [*test profile file*]. DESCRIPTION; ^^^^^^^^^^^. :program:`llvm-profdata overlap` takes two profile data files and displays the; *overlap* of counter distribution between the whole files and between any of the; specified functions. In this command, *overlap* is defined as follows:; Suppose *base profile file* has the following counts:; {c1_1, c1_2, ..., c1_n, c1_u_1, c2_u_2, ..., c2_u_s},; and *test profile file* has; {c2_1, c2_2, ..., c2_n, c2_v_1, c2_v_2, ..., c2_v_t}.; Here c{1|2}_i (i = 1 .. n) are matched counters and c1_u_i (i = 1 .. s) and; c2_v_i (i = 1 .. v) are unmatched counters (or counters only existing in); *base profile file* and *test profile file*, respectively.; Let sum_1 = c1_1 + c1_2 + ... + c1_n + c1_u_1 + c2_u_2 + ... + c2_u_s, and; sum_2 = c2_1 + c2_2 + ... + c2_n + c2_v_1 + c2_v_2 + ... + c2_v_t.; *overlap* = min(c1_1/sum_1, c2_1/sum_2) + min(c1_2/sum_1, c2_2/sum_2) + ...; + min(c1_n/sum_1, c2_n/sum_2). The result overlap distribution is a percentage number, ranging from 0.0% to; 100.0%, where 0.0% means there is no overlap and 100.0% means a perfect; overlap. Here is an example, if *base profile file* has counts of {400, 600}, and; *test profile file* has matched counts of {60000, 40000}. The *overlap* is 80%. OPTIONS; ^^^^^^^. .. option:: --function=<string>. Print details for a function if the function's name contains the given string. .. option:: --help. Print a summary of command line options. .. option:: --output=<output>, -o. Specify the output file name. If *output* is ``-`` or it isn't specified,; then the output is sent to standard output. .. option:: --value-cutoff=<n",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profdata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profdata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profdata.rst:12836,Testability,test,test,12836,"ween the whole files and between any of the; specified functions. In this command, *overlap* is defined as follows:; Suppose *base profile file* has the following counts:; {c1_1, c1_2, ..., c1_n, c1_u_1, c2_u_2, ..., c2_u_s},; and *test profile file* has; {c2_1, c2_2, ..., c2_n, c2_v_1, c2_v_2, ..., c2_v_t}.; Here c{1|2}_i (i = 1 .. n) are matched counters and c1_u_i (i = 1 .. s) and; c2_v_i (i = 1 .. v) are unmatched counters (or counters only existing in); *base profile file* and *test profile file*, respectively.; Let sum_1 = c1_1 + c1_2 + ... + c1_n + c1_u_1 + c2_u_2 + ... + c2_u_s, and; sum_2 = c2_1 + c2_2 + ... + c2_n + c2_v_1 + c2_v_2 + ... + c2_v_t.; *overlap* = min(c1_1/sum_1, c2_1/sum_2) + min(c1_2/sum_1, c2_2/sum_2) + ...; + min(c1_n/sum_1, c2_n/sum_2). The result overlap distribution is a percentage number, ranging from 0.0% to; 100.0%, where 0.0% means there is no overlap and 100.0% means a perfect; overlap. Here is an example, if *base profile file* has counts of {400, 600}, and; *test profile file* has matched counts of {60000, 40000}. The *overlap* is 80%. OPTIONS; ^^^^^^^. .. option:: --function=<string>. Print details for a function if the function's name contains the given string. .. option:: --help. Print a summary of command line options. .. option:: --output=<output>, -o. Specify the output file name. If *output* is ``-`` or it isn't specified,; then the output is sent to standard output. .. option:: --value-cutoff=<n>. Show only those functions whose max count values are greater or equal to ``n``.; By default, the value-cutoff is set to max of unsigned long long. .. option:: --cs. Only show overlap for the context sensitive profile counts. The default is to show; non-context sensitive profile counts. .. program:: llvm-profdata order. .. _profdata-order:. ORDER; -------. SYNOPSIS; ^^^^^^^^. :program:`llvm-profdata order` [*options*] [*filename*]. DESCRIPTION; ^^^^^^^^^^^. :program:`llvm-profdata order` uses temporal profiling traces from a prof",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profdata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profdata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profgen.rst:357,Performance,optimiz,optimization,357,"llvm-profgen - LLVM SPGO profile generation tool; ================================================. .. program:: llvm-profgen. SYNOPSIS; --------. :program:`llvm-profgen` [*commands*] [*options*]. DESCRIPTION; -----------. The :program:`llvm-profgen` utility generates a profile data file; from given perf script data files for sample-based profile guided; optimization(SPGO). COMMANDS; --------; At least one of the following commands are required:. .. option:: --perfscript=<string[,string,...]>. Path of perf-script trace created by Linux perf tool with `script`; command(the raw perf.data should be profiled with -b). .. option:: --binary=<string[,string,...]>. Path of the input profiled binary files. .. option:: --output=<string>. Path of the output profile file. OPTIONS; -------; :program:`llvm-profgen` supports the following options:. .. option:: --format=[text|binary|extbinary|compbinary|gcc]. Specify the format of the generated profile. Supported <format> are `text`,; `binary`, `extbinary`, `compbinary`, `gcc`, see `llvm-profdata` for more; descriptions of the format. .. option:: --show-mmap-events. Print mmap events. .. option:: --show-disassembly. Print disassembled code. .. option:: --x86-asm-syntax=[att|intel]. Specify whether to print assembly code in AT&T syntax (the default) or Intel; syntax.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profgen.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profgen.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profgen.rst:349,Usability,guid,guided,349,"llvm-profgen - LLVM SPGO profile generation tool; ================================================. .. program:: llvm-profgen. SYNOPSIS; --------. :program:`llvm-profgen` [*commands*] [*options*]. DESCRIPTION; -----------. The :program:`llvm-profgen` utility generates a profile data file; from given perf script data files for sample-based profile guided; optimization(SPGO). COMMANDS; --------; At least one of the following commands are required:. .. option:: --perfscript=<string[,string,...]>. Path of perf-script trace created by Linux perf tool with `script`; command(the raw perf.data should be profiled with -b). .. option:: --binary=<string[,string,...]>. Path of the input profiled binary files. .. option:: --output=<string>. Path of the output profile file. OPTIONS; -------; :program:`llvm-profgen` supports the following options:. .. option:: --format=[text|binary|extbinary|compbinary|gcc]. Specify the format of the generated profile. Supported <format> are `text`,; `binary`, `extbinary`, `compbinary`, `gcc`, see `llvm-profdata` for more; descriptions of the format. .. option:: --show-mmap-events. Print mmap events. .. option:: --show-disassembly. Print disassembled code. .. option:: --x86-asm-syntax=[att|intel]. Specify whether to print assembly code in AT&T syntax (the default) or Intel; syntax.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profgen.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-profgen.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readelf.rst:5610,Availability,error,errors,5610,"ons, --relocs, -r. Display the relocation entries in the file. .. option:: --sections, --section-headers, -S. Display all sections. .. option:: --section-data. When used with :option:`--sections`, display section data for each section; shown. This option has no effect for GNU style output. .. option:: --section-details, -t. Display all section details. Used as an alternative to :option:`--sections`. .. option:: --section-mapping. Display the section to segment mapping. .. option:: --section-relocations. When used with :option:`--sections`, display relocations for each section; shown. This option has no effect for GNU style output. .. option:: --section-symbols. When used with :option:`--sections`, display symbols for each section shown.; This option has no effect for GNU style output. .. option:: --stackmap. Display contents of the stackmap section. .. option:: --stack-sizes. Display the contents of the stack sizes section(s), i.e. pairs of function; names and the size of their stack frames. Currently only implemented for GNU; style output. .. option:: --string-dump=<section[,section,...]>, -p. Display the specified section(s) as a list of strings. ``section`` may be a; section index or section name. .. option:: --symbols, --syms, -s. Display the symbol table. Also display the dynamic symbol table when using GNU output style for ELF. .. option:: --unwind, -u. Display unwind information. .. option:: --version. Display the version of the :program:`llvm-readelf` executable. .. option:: --version-info, -V. Display version sections. .. option:: --wide, -W. Ignored for GNU readelf compatibility. The output is already similar to when using -W with GNU readelf. .. option:: @<FILE>. Read command-line options from response file `<FILE>`. EXIT STATUS; -----------. :program:`llvm-readelf` returns 0 under normal operation. It returns a non-zero; exit code if there were any errors. SEE ALSO; --------. :manpage:`llvm-nm(1)`, :manpage:`llvm-objdump(1)`, :manpage:`llvm-readobj(1)`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readelf.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readelf.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readelf.rst:2040,Energy Efficiency,consumption,consumption,2040,"hen used with ``-x`` or ``-p``.; If the section(s) are not compressed, they are displayed as is. .. option:: --demangle, -C. Display demangled symbol names in the output. .. option:: --dependent-libraries. Display the dependent libraries section. .. option:: --dyn-relocations. Display the dynamic relocation entries. .. option:: --dyn-symbols, --dyn-syms. Display the dynamic symbol table. .. option:: --dynamic-table, --dynamic, -d. Display the dynamic table. .. option:: --cg-profile. Display the callgraph profile section. .. option:: --histogram, -I. Display a bucket list histogram for dynamic symbol hash tables. .. option:: --elf-linker-options. Display the linker options section. .. option:: --elf-output-style=<value>. Format ELF information in the specified style. Valid options are ``LLVM``,; ``GNU``, and ``JSON``. ``LLVM`` output is an expanded and structured format.; ``GNU`` (the default) output mimics the equivalent GNU :program:`readelf`; output. ``JSON`` is JSON formatted output intended for machine consumption. .. option:: --extra-sym-info. Display extra information (section name) when showing symbols. .. option:: --section-groups, -g. Display section groups. .. option:: --expand-relocs. When used with :option:`--relocations`, display each relocation in an expanded; multi-line format. .. option:: --file-header, -h. Display file headers. .. option:: --gnu-hash-table. Display the GNU hash table for dynamic symbols. .. option:: --hash-symbols. Display the expanded hash table with dynamic symbol data. .. option:: --hash-table. Display the hash table for dynamic symbols. .. option:: --headers, -e. Equivalent to setting: :option:`--file-header`, :option:`--program-headers`,; and :option:`--sections`. .. option:: --help. Display a summary of command line options. .. option:: --hex-dump=<section[,section,...]>, -x. Display the specified section(s) as hexadecimal bytes. ``section`` may be a; section index or section name. .. option:: --memtag. Display information abo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readelf.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readelf.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readelf.rst:1203,Integrability,depend,dependent-libraries,1203,"----. The :program:`llvm-readelf` tool displays low-level format-specific information; about one or more object files. If ``input`` is ""``-``"", :program:`llvm-readelf` reads from standard; input. Otherwise, it will read from the specified ``filenames``. OPTIONS; -------. .. option:: --all, -a. Equivalent to specifying all the main display options relevant to the file; format. .. option:: --addrsig. Display the address-significance table. .. option:: --arch-specific, -A. Display architecture-specific information, e.g. the ARM attributes section on ARM. .. option:: --bb-addr-map. Display the contents of the basic block address map section(s), which contain the; address of each function, along with the relative offset of each basic block. .. option:: --decompress, -z. Dump decompressed section content when used with ``-x`` or ``-p``.; If the section(s) are not compressed, they are displayed as is. .. option:: --demangle, -C. Display demangled symbol names in the output. .. option:: --dependent-libraries. Display the dependent libraries section. .. option:: --dyn-relocations. Display the dynamic relocation entries. .. option:: --dyn-symbols, --dyn-syms. Display the dynamic symbol table. .. option:: --dynamic-table, --dynamic, -d. Display the dynamic table. .. option:: --cg-profile. Display the callgraph profile section. .. option:: --histogram, -I. Display a bucket list histogram for dynamic symbol hash tables. .. option:: --elf-linker-options. Display the linker options section. .. option:: --elf-output-style=<value>. Format ELF information in the specified style. Valid options are ``LLVM``,; ``GNU``, and ``JSON``. ``LLVM`` output is an expanded and structured format.; ``GNU`` (the default) output mimics the equivalent GNU :program:`readelf`; output. ``JSON`` is JSON formatted output intended for machine consumption. .. option:: --extra-sym-info. Display extra information (section name) when showing symbols. .. option:: --section-groups, -g. Display section groups. .. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readelf.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readelf.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readelf.rst:1236,Integrability,depend,dependent,1236,"ol displays low-level format-specific information; about one or more object files. If ``input`` is ""``-``"", :program:`llvm-readelf` reads from standard; input. Otherwise, it will read from the specified ``filenames``. OPTIONS; -------. .. option:: --all, -a. Equivalent to specifying all the main display options relevant to the file; format. .. option:: --addrsig. Display the address-significance table. .. option:: --arch-specific, -A. Display architecture-specific information, e.g. the ARM attributes section on ARM. .. option:: --bb-addr-map. Display the contents of the basic block address map section(s), which contain the; address of each function, along with the relative offset of each basic block. .. option:: --decompress, -z. Dump decompressed section content when used with ``-x`` or ``-p``.; If the section(s) are not compressed, they are displayed as is. .. option:: --demangle, -C. Display demangled symbol names in the output. .. option:: --dependent-libraries. Display the dependent libraries section. .. option:: --dyn-relocations. Display the dynamic relocation entries. .. option:: --dyn-symbols, --dyn-syms. Display the dynamic symbol table. .. option:: --dynamic-table, --dynamic, -d. Display the dynamic table. .. option:: --cg-profile. Display the callgraph profile section. .. option:: --histogram, -I. Display a bucket list histogram for dynamic symbol hash tables. .. option:: --elf-linker-options. Display the linker options section. .. option:: --elf-output-style=<value>. Format ELF information in the specified style. Valid options are ``LLVM``,; ``GNU``, and ``JSON``. ``LLVM`` output is an expanded and structured format.; ``GNU`` (the default) output mimics the equivalent GNU :program:`readelf`; output. ``JSON`` is JSON formatted output intended for machine consumption. .. option:: --extra-sym-info. Display extra information (section name) when showing symbols. .. option:: --section-groups, -g. Display section groups. .. option:: --expand-relocs. When used w",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readelf.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readelf.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readelf.rst:1625,Security,hash,hash,1625,"ig. Display the address-significance table. .. option:: --arch-specific, -A. Display architecture-specific information, e.g. the ARM attributes section on ARM. .. option:: --bb-addr-map. Display the contents of the basic block address map section(s), which contain the; address of each function, along with the relative offset of each basic block. .. option:: --decompress, -z. Dump decompressed section content when used with ``-x`` or ``-p``.; If the section(s) are not compressed, they are displayed as is. .. option:: --demangle, -C. Display demangled symbol names in the output. .. option:: --dependent-libraries. Display the dependent libraries section. .. option:: --dyn-relocations. Display the dynamic relocation entries. .. option:: --dyn-symbols, --dyn-syms. Display the dynamic symbol table. .. option:: --dynamic-table, --dynamic, -d. Display the dynamic table. .. option:: --cg-profile. Display the callgraph profile section. .. option:: --histogram, -I. Display a bucket list histogram for dynamic symbol hash tables. .. option:: --elf-linker-options. Display the linker options section. .. option:: --elf-output-style=<value>. Format ELF information in the specified style. Valid options are ``LLVM``,; ``GNU``, and ``JSON``. ``LLVM`` output is an expanded and structured format.; ``GNU`` (the default) output mimics the equivalent GNU :program:`readelf`; output. ``JSON`` is JSON formatted output intended for machine consumption. .. option:: --extra-sym-info. Display extra information (section name) when showing symbols. .. option:: --section-groups, -g. Display section groups. .. option:: --expand-relocs. When used with :option:`--relocations`, display each relocation in an expanded; multi-line format. .. option:: --file-header, -h. Display file headers. .. option:: --gnu-hash-table. Display the GNU hash table for dynamic symbols. .. option:: --hash-symbols. Display the expanded hash table with dynamic symbol data. .. option:: --hash-table. Display the hash table for dyn",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readelf.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readelf.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readelf.rst:2403,Security,hash,hash-table,2403,"l table. .. option:: --dynamic-table, --dynamic, -d. Display the dynamic table. .. option:: --cg-profile. Display the callgraph profile section. .. option:: --histogram, -I. Display a bucket list histogram for dynamic symbol hash tables. .. option:: --elf-linker-options. Display the linker options section. .. option:: --elf-output-style=<value>. Format ELF information in the specified style. Valid options are ``LLVM``,; ``GNU``, and ``JSON``. ``LLVM`` output is an expanded and structured format.; ``GNU`` (the default) output mimics the equivalent GNU :program:`readelf`; output. ``JSON`` is JSON formatted output intended for machine consumption. .. option:: --extra-sym-info. Display extra information (section name) when showing symbols. .. option:: --section-groups, -g. Display section groups. .. option:: --expand-relocs. When used with :option:`--relocations`, display each relocation in an expanded; multi-line format. .. option:: --file-header, -h. Display file headers. .. option:: --gnu-hash-table. Display the GNU hash table for dynamic symbols. .. option:: --hash-symbols. Display the expanded hash table with dynamic symbol data. .. option:: --hash-table. Display the hash table for dynamic symbols. .. option:: --headers, -e. Equivalent to setting: :option:`--file-header`, :option:`--program-headers`,; and :option:`--sections`. .. option:: --help. Display a summary of command line options. .. option:: --hex-dump=<section[,section,...]>, -x. Display the specified section(s) as hexadecimal bytes. ``section`` may be a; section index or section name. .. option:: --memtag. Display information about memory tagging present in the binary. This includes; various memtag-specific dynamic entries, decoded global descriptor sections,; and decoded Android-specific ELF notes. .. option:: --needed-libs. Display the needed libraries. .. option:: --no-demangle. Do not display demangled symbol names in the output. On by default. .. option:: --notes, -n. Display all notes. .. option:: -",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readelf.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readelf.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readelf.rst:2431,Security,hash,hash,2431,"--dynamic, -d. Display the dynamic table. .. option:: --cg-profile. Display the callgraph profile section. .. option:: --histogram, -I. Display a bucket list histogram for dynamic symbol hash tables. .. option:: --elf-linker-options. Display the linker options section. .. option:: --elf-output-style=<value>. Format ELF information in the specified style. Valid options are ``LLVM``,; ``GNU``, and ``JSON``. ``LLVM`` output is an expanded and structured format.; ``GNU`` (the default) output mimics the equivalent GNU :program:`readelf`; output. ``JSON`` is JSON formatted output intended for machine consumption. .. option:: --extra-sym-info. Display extra information (section name) when showing symbols. .. option:: --section-groups, -g. Display section groups. .. option:: --expand-relocs. When used with :option:`--relocations`, display each relocation in an expanded; multi-line format. .. option:: --file-header, -h. Display file headers. .. option:: --gnu-hash-table. Display the GNU hash table for dynamic symbols. .. option:: --hash-symbols. Display the expanded hash table with dynamic symbol data. .. option:: --hash-table. Display the hash table for dynamic symbols. .. option:: --headers, -e. Equivalent to setting: :option:`--file-header`, :option:`--program-headers`,; and :option:`--sections`. .. option:: --help. Display a summary of command line options. .. option:: --hex-dump=<section[,section,...]>, -x. Display the specified section(s) as hexadecimal bytes. ``section`` may be a; section index or section name. .. option:: --memtag. Display information about memory tagging present in the binary. This includes; various memtag-specific dynamic entries, decoded global descriptor sections,; and decoded Android-specific ELF notes. .. option:: --needed-libs. Display the needed libraries. .. option:: --no-demangle. Do not display demangled symbol names in the output. On by default. .. option:: --notes, -n. Display all notes. .. option:: --pretty-print. When used with :option",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readelf.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readelf.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readelf.rst:2477,Security,hash,hash-symbols,2477,"e. .. option:: --cg-profile. Display the callgraph profile section. .. option:: --histogram, -I. Display a bucket list histogram for dynamic symbol hash tables. .. option:: --elf-linker-options. Display the linker options section. .. option:: --elf-output-style=<value>. Format ELF information in the specified style. Valid options are ``LLVM``,; ``GNU``, and ``JSON``. ``LLVM`` output is an expanded and structured format.; ``GNU`` (the default) output mimics the equivalent GNU :program:`readelf`; output. ``JSON`` is JSON formatted output intended for machine consumption. .. option:: --extra-sym-info. Display extra information (section name) when showing symbols. .. option:: --section-groups, -g. Display section groups. .. option:: --expand-relocs. When used with :option:`--relocations`, display each relocation in an expanded; multi-line format. .. option:: --file-header, -h. Display file headers. .. option:: --gnu-hash-table. Display the GNU hash table for dynamic symbols. .. option:: --hash-symbols. Display the expanded hash table with dynamic symbol data. .. option:: --hash-table. Display the hash table for dynamic symbols. .. option:: --headers, -e. Equivalent to setting: :option:`--file-header`, :option:`--program-headers`,; and :option:`--sections`. .. option:: --help. Display a summary of command line options. .. option:: --hex-dump=<section[,section,...]>, -x. Display the specified section(s) as hexadecimal bytes. ``section`` may be a; section index or section name. .. option:: --memtag. Display information about memory tagging present in the binary. This includes; various memtag-specific dynamic entries, decoded global descriptor sections,; and decoded Android-specific ELF notes. .. option:: --needed-libs. Display the needed libraries. .. option:: --no-demangle. Do not display demangled symbol names in the output. On by default. .. option:: --notes, -n. Display all notes. .. option:: --pretty-print. When used with :option:`--elf-output-style`, JSON output will ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readelf.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readelf.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readelf.rst:2512,Security,hash,hash,2512,"allgraph profile section. .. option:: --histogram, -I. Display a bucket list histogram for dynamic symbol hash tables. .. option:: --elf-linker-options. Display the linker options section. .. option:: --elf-output-style=<value>. Format ELF information in the specified style. Valid options are ``LLVM``,; ``GNU``, and ``JSON``. ``LLVM`` output is an expanded and structured format.; ``GNU`` (the default) output mimics the equivalent GNU :program:`readelf`; output. ``JSON`` is JSON formatted output intended for machine consumption. .. option:: --extra-sym-info. Display extra information (section name) when showing symbols. .. option:: --section-groups, -g. Display section groups. .. option:: --expand-relocs. When used with :option:`--relocations`, display each relocation in an expanded; multi-line format. .. option:: --file-header, -h. Display file headers. .. option:: --gnu-hash-table. Display the GNU hash table for dynamic symbols. .. option:: --hash-symbols. Display the expanded hash table with dynamic symbol data. .. option:: --hash-table. Display the hash table for dynamic symbols. .. option:: --headers, -e. Equivalent to setting: :option:`--file-header`, :option:`--program-headers`,; and :option:`--sections`. .. option:: --help. Display a summary of command line options. .. option:: --hex-dump=<section[,section,...]>, -x. Display the specified section(s) as hexadecimal bytes. ``section`` may be a; section index or section name. .. option:: --memtag. Display information about memory tagging present in the binary. This includes; various memtag-specific dynamic entries, decoded global descriptor sections,; and decoded Android-specific ELF notes. .. option:: --needed-libs. Display the needed libraries. .. option:: --no-demangle. Do not display demangled symbol names in the output. On by default. .. option:: --notes, -n. Display all notes. .. option:: --pretty-print. When used with :option:`--elf-output-style`, JSON output will be formatted in; a more readable format. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readelf.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readelf.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readelf.rst:2563,Security,hash,hash-table,2563,"togram, -I. Display a bucket list histogram for dynamic symbol hash tables. .. option:: --elf-linker-options. Display the linker options section. .. option:: --elf-output-style=<value>. Format ELF information in the specified style. Valid options are ``LLVM``,; ``GNU``, and ``JSON``. ``LLVM`` output is an expanded and structured format.; ``GNU`` (the default) output mimics the equivalent GNU :program:`readelf`; output. ``JSON`` is JSON formatted output intended for machine consumption. .. option:: --extra-sym-info. Display extra information (section name) when showing symbols. .. option:: --section-groups, -g. Display section groups. .. option:: --expand-relocs. When used with :option:`--relocations`, display each relocation in an expanded; multi-line format. .. option:: --file-header, -h. Display file headers. .. option:: --gnu-hash-table. Display the GNU hash table for dynamic symbols. .. option:: --hash-symbols. Display the expanded hash table with dynamic symbol data. .. option:: --hash-table. Display the hash table for dynamic symbols. .. option:: --headers, -e. Equivalent to setting: :option:`--file-header`, :option:`--program-headers`,; and :option:`--sections`. .. option:: --help. Display a summary of command line options. .. option:: --hex-dump=<section[,section,...]>, -x. Display the specified section(s) as hexadecimal bytes. ``section`` may be a; section index or section name. .. option:: --memtag. Display information about memory tagging present in the binary. This includes; various memtag-specific dynamic entries, decoded global descriptor sections,; and decoded Android-specific ELF notes. .. option:: --needed-libs. Display the needed libraries. .. option:: --no-demangle. Do not display demangled symbol names in the output. On by default. .. option:: --notes, -n. Display all notes. .. option:: --pretty-print. When used with :option:`--elf-output-style`, JSON output will be formatted in; a more readable format. .. option:: --program-headers, --segments, -",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readelf.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readelf.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readelf.rst:2587,Security,hash,hash,2587,"histogram for dynamic symbol hash tables. .. option:: --elf-linker-options. Display the linker options section. .. option:: --elf-output-style=<value>. Format ELF information in the specified style. Valid options are ``LLVM``,; ``GNU``, and ``JSON``. ``LLVM`` output is an expanded and structured format.; ``GNU`` (the default) output mimics the equivalent GNU :program:`readelf`; output. ``JSON`` is JSON formatted output intended for machine consumption. .. option:: --extra-sym-info. Display extra information (section name) when showing symbols. .. option:: --section-groups, -g. Display section groups. .. option:: --expand-relocs. When used with :option:`--relocations`, display each relocation in an expanded; multi-line format. .. option:: --file-header, -h. Display file headers. .. option:: --gnu-hash-table. Display the GNU hash table for dynamic symbols. .. option:: --hash-symbols. Display the expanded hash table with dynamic symbol data. .. option:: --hash-table. Display the hash table for dynamic symbols. .. option:: --headers, -e. Equivalent to setting: :option:`--file-header`, :option:`--program-headers`,; and :option:`--sections`. .. option:: --help. Display a summary of command line options. .. option:: --hex-dump=<section[,section,...]>, -x. Display the specified section(s) as hexadecimal bytes. ``section`` may be a; section index or section name. .. option:: --memtag. Display information about memory tagging present in the binary. This includes; various memtag-specific dynamic entries, decoded global descriptor sections,; and decoded Android-specific ELF notes. .. option:: --needed-libs. Display the needed libraries. .. option:: --no-demangle. Do not display demangled symbol names in the output. On by default. .. option:: --notes, -n. Display all notes. .. option:: --pretty-print. When used with :option:`--elf-output-style`, JSON output will be formatted in; a more readable format. .. option:: --program-headers, --segments, -l. Display the program headers. .",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readelf.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readelf.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst:9000,Availability,error,errors,9000," Code command. .. option:: --macho-dsymtab. Display the Dsymtab command. .. option:: --macho-indirect-symbols. Display indirect symbols. .. option:: --macho-linker-options. Display the Mach-O-specific linker options. .. option:: --macho-segment. Display the Segment command. .. option:: --macho-version-min. Display the version min command. PE/COFF SPECIFIC OPTIONS; ------------------------. The following options are implemented only for the PE/COFF file format. .. option:: --codeview. Display CodeView debug information. .. option:: --codeview-ghash. Enable global hashing for CodeView type stream de-duplication. .. option:: --codeview-merged-types. Display the merged CodeView type stream. .. option:: --codeview-subsection-bytes. Dump raw contents of CodeView debug sections and records. .. option:: --coff-basereloc. Display the .reloc section. .. option:: --coff-debug-directory. Display the debug directory. .. option:: --coff-tls-directory. Display the TLS directory. .. option:: --coff-directives. Display the .drectve section. .. option:: --coff-exports. Display the export table. .. option:: --coff-imports. Display the import table. .. option:: --coff-load-config. Display the load config. .. option:: --coff-resources. Display the .rsrc section. XCOFF SPECIFIC OPTIONS; ----------------------. The following options are implemented only for the XCOFF file format. .. option:: --auxiliary-header. Display XCOFF Auxiliary header. .. option:: --exception-section. Display XCOFF exception section entries. .. option:: --loader-section-header. Display XCOFF loader section header. .. option:: --loader-section-symbols. Display symbol table of loader section. .. option:: --loader-section-relocations. Display relocation entries of loader section. EXIT STATUS; -----------. :program:`llvm-readobj` returns 0 under normal operation. It returns a non-zero; exit code if there were any errors. SEE ALSO; --------. :manpage:`llvm-nm(1)`, :manpage:`llvm-objdump(1)`, :manpage:`llvm-readelf(1)`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst:5750,Energy Efficiency,consumption,consumption,5750,"contain the; address of each function, along with the relative offset of each basic block. .. option:: --demangle, -C. Display demangled symbol names in the output. .. option:: --dependent-libraries. Display the dependent libraries section. .. option:: --dyn-relocations. Display the dynamic relocation entries. .. option:: --dyn-symbols, --dyn-syms, --dt. Display the dynamic symbol table. .. option:: --dynamic-table, --dynamic, -d. Display the dynamic table. .. option:: --cg-profile. Display the callgraph profile section. .. option:: --histogram, -I. Display a bucket list histogram for dynamic symbol hash tables. .. option:: --elf-linker-options. Display the linker options section. .. option:: --elf-output-style=<value>. Format ELF information in the specified style. Valid options are ``LLVM``,; ``GNU``, and ``JSON``. ``LLVM`` output (the default) is an expanded and; structured format. ``GNU`` output mimics the equivalent GNU :program:`readelf`; output. ``JSON`` is JSON formatted output intended for machine consumption. .. option:: --section-groups, -g. Display section groups. .. option:: --gnu-hash-table. Display the GNU hash table for dynamic symbols. .. option:: --hash-symbols. Display the expanded hash table with dynamic symbol data. .. option:: --hash-table. Display the hash table for dynamic symbols. .. option:: --memtag. Display information about memory tagging present in the binary. This includes; various dynamic entries, decoded global descriptor sections, and decoded; Android-specific ELF notes. .. option:: --notes, -n. Display all notes. .. option:: --pretty-print. When used with :option:`--elf-output-style`, JSON output will be formatted in; a more readable format. .. option:: --program-headers, --segments, -l. Display the program headers. .. option:: --raw-relr. Do not decode relocations in RELR relocation sections when displaying them. .. option:: --section-mapping. Display the section to segment mapping. .. option:: --stack-sizes. Display the contents ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst:612,Integrability,interface,interface,612,"llvm-readobj - LLVM Object Reader; =================================. .. program:: llvm-readobj. SYNOPSIS; --------. :program:`llvm-readobj` [*options*] [*input...*]. DESCRIPTION; -----------. The :program:`llvm-readobj` tool displays low-level format-specific information; about one or more object files. If ``input`` is ""``-``"", :program:`llvm-readobj` reads from standard; input. Otherwise, it will read from the specified ``filenames``. DIFFERENCES TO LLVM-READELF; ---------------------------. :program:`llvm-readelf` is an alias for the :manpage:`llvm-readobj` tool with a; slightly different command-line interface and output that is GNU compatible.; Following is a list of differences between :program:`llvm-readelf` and; :program:`llvm-readobj`:. - :program:`llvm-readelf` uses `GNU` for the :option:`--elf-output-style` option; by default. :program:`llvm-readobj` uses `LLVM`.; - :program:`llvm-readelf` allows single-letter grouped flags (e.g.; ``llvm-readelf -SW`` is the same as ``llvm-readelf -S -W``).; :program:`llvm-readobj` does not allow grouping.; - :program:`llvm-readelf` provides :option:`-s` as an alias for; :option:`--symbols`, for GNU :program:`readelf` compatibility, whereas it is; an alias for :option:`--section-headers` in :program:`llvm-readobj`.; - :program:`llvm-readobj` provides ``-t`` as an alias for :option:`--symbols`.; :program:`llvm-readelf` does not.; - :program:`llvm-readobj` provides ``--sr``, ``--sd``, ``--st`` and ``--dt`` as; aliases for :option:`--section-relocations`, :option:`--section-data`,; :option:`--section-symbols` and :option:`--dyn-symbols` respectively.; :program:`llvm-readelf` does not provide these aliases, to avoid conflicting; with grouped flags. GENERAL AND MULTI-FORMAT OPTIONS; --------------------------------. These options are applicable to more than one file format, or are unrelated to; file formats. .. option:: --all. Equivalent to specifying all the main display options relevant to the file; format. .. option:: --addr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst:4907,Integrability,depend,dependent-libraries,4907,"string-dump=<section[,section,...]>, -p. Display the specified section(s) as a list of strings. ``section`` may be a; section index or section name. .. option:: --string-table. Display contents of the string table. .. option:: --symbols, --syms, -s. Display the symbol table. .. option:: --unwind, -u. Display unwind information. .. option:: --version. Display the version of the :program:`llvm-readobj` executable. .. option:: @<FILE>. Read command-line options from response file `<FILE>`. ELF SPECIFIC OPTIONS; --------------------. The following options are implemented only for the ELF file format. .. option:: --arch-specific, -A. Display architecture-specific information, e.g. the ARM attributes section on ARM. .. option:: --bb-addr-map. Display the contents of the basic block address map section(s), which contain the; address of each function, along with the relative offset of each basic block. .. option:: --demangle, -C. Display demangled symbol names in the output. .. option:: --dependent-libraries. Display the dependent libraries section. .. option:: --dyn-relocations. Display the dynamic relocation entries. .. option:: --dyn-symbols, --dyn-syms, --dt. Display the dynamic symbol table. .. option:: --dynamic-table, --dynamic, -d. Display the dynamic table. .. option:: --cg-profile. Display the callgraph profile section. .. option:: --histogram, -I. Display a bucket list histogram for dynamic symbol hash tables. .. option:: --elf-linker-options. Display the linker options section. .. option:: --elf-output-style=<value>. Format ELF information in the specified style. Valid options are ``LLVM``,; ``GNU``, and ``JSON``. ``LLVM`` output (the default) is an expanded and; structured format. ``GNU`` output mimics the equivalent GNU :program:`readelf`; output. ``JSON`` is JSON formatted output intended for machine consumption. .. option:: --section-groups, -g. Display section groups. .. option:: --gnu-hash-table. Display the GNU hash table for dynamic symbols. .. option:: ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst:4940,Integrability,depend,dependent,4940," -p. Display the specified section(s) as a list of strings. ``section`` may be a; section index or section name. .. option:: --string-table. Display contents of the string table. .. option:: --symbols, --syms, -s. Display the symbol table. .. option:: --unwind, -u. Display unwind information. .. option:: --version. Display the version of the :program:`llvm-readobj` executable. .. option:: @<FILE>. Read command-line options from response file `<FILE>`. ELF SPECIFIC OPTIONS; --------------------. The following options are implemented only for the ELF file format. .. option:: --arch-specific, -A. Display architecture-specific information, e.g. the ARM attributes section on ARM. .. option:: --bb-addr-map. Display the contents of the basic block address map section(s), which contain the; address of each function, along with the relative offset of each basic block. .. option:: --demangle, -C. Display demangled symbol names in the output. .. option:: --dependent-libraries. Display the dependent libraries section. .. option:: --dyn-relocations. Display the dynamic relocation entries. .. option:: --dyn-symbols, --dyn-syms, --dt. Display the dynamic symbol table. .. option:: --dynamic-table, --dynamic, -d. Display the dynamic table. .. option:: --cg-profile. Display the callgraph profile section. .. option:: --histogram, -I. Display a bucket list histogram for dynamic symbol hash tables. .. option:: --elf-linker-options. Display the linker options section. .. option:: --elf-output-style=<value>. Format ELF information in the specified style. Valid options are ``LLVM``,; ``GNU``, and ``JSON``. ``LLVM`` output (the default) is an expanded and; structured format. ``GNU`` output mimics the equivalent GNU :program:`readelf`; output. ``JSON`` is JSON formatted output intended for machine consumption. .. option:: --section-groups, -g. Display section groups. .. option:: --gnu-hash-table. Display the GNU hash table for dynamic symbols. .. option:: --hash-symbols. Display the expanded ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst:8279,Modifiability,config,config,8279," Code command. .. option:: --macho-dsymtab. Display the Dsymtab command. .. option:: --macho-indirect-symbols. Display indirect symbols. .. option:: --macho-linker-options. Display the Mach-O-specific linker options. .. option:: --macho-segment. Display the Segment command. .. option:: --macho-version-min. Display the version min command. PE/COFF SPECIFIC OPTIONS; ------------------------. The following options are implemented only for the PE/COFF file format. .. option:: --codeview. Display CodeView debug information. .. option:: --codeview-ghash. Enable global hashing for CodeView type stream de-duplication. .. option:: --codeview-merged-types. Display the merged CodeView type stream. .. option:: --codeview-subsection-bytes. Dump raw contents of CodeView debug sections and records. .. option:: --coff-basereloc. Display the .reloc section. .. option:: --coff-debug-directory. Display the debug directory. .. option:: --coff-tls-directory. Display the TLS directory. .. option:: --coff-directives. Display the .drectve section. .. option:: --coff-exports. Display the export table. .. option:: --coff-imports. Display the import table. .. option:: --coff-load-config. Display the load config. .. option:: --coff-resources. Display the .rsrc section. XCOFF SPECIFIC OPTIONS; ----------------------. The following options are implemented only for the XCOFF file format. .. option:: --auxiliary-header. Display XCOFF Auxiliary header. .. option:: --exception-section. Display XCOFF exception section entries. .. option:: --loader-section-header. Display XCOFF loader section header. .. option:: --loader-section-symbols. Display symbol table of loader section. .. option:: --loader-section-relocations. Display relocation entries of loader section. EXIT STATUS; -----------. :program:`llvm-readobj` returns 0 under normal operation. It returns a non-zero; exit code if there were any errors. SEE ALSO; --------. :manpage:`llvm-nm(1)`, :manpage:`llvm-objdump(1)`, :manpage:`llvm-readelf(1)`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst:8304,Modifiability,config,config,8304," Code command. .. option:: --macho-dsymtab. Display the Dsymtab command. .. option:: --macho-indirect-symbols. Display indirect symbols. .. option:: --macho-linker-options. Display the Mach-O-specific linker options. .. option:: --macho-segment. Display the Segment command. .. option:: --macho-version-min. Display the version min command. PE/COFF SPECIFIC OPTIONS; ------------------------. The following options are implemented only for the PE/COFF file format. .. option:: --codeview. Display CodeView debug information. .. option:: --codeview-ghash. Enable global hashing for CodeView type stream de-duplication. .. option:: --codeview-merged-types. Display the merged CodeView type stream. .. option:: --codeview-subsection-bytes. Dump raw contents of CodeView debug sections and records. .. option:: --coff-basereloc. Display the .reloc section. .. option:: --coff-debug-directory. Display the debug directory. .. option:: --coff-tls-directory. Display the TLS directory. .. option:: --coff-directives. Display the .drectve section. .. option:: --coff-exports. Display the export table. .. option:: --coff-imports. Display the import table. .. option:: --coff-load-config. Display the load config. .. option:: --coff-resources. Display the .rsrc section. XCOFF SPECIFIC OPTIONS; ----------------------. The following options are implemented only for the XCOFF file format. .. option:: --auxiliary-header. Display XCOFF Auxiliary header. .. option:: --exception-section. Display XCOFF exception section entries. .. option:: --loader-section-header. Display XCOFF loader section header. .. option:: --loader-section-symbols. Display symbol table of loader section. .. option:: --loader-section-relocations. Display relocation entries of loader section. EXIT STATUS; -----------. :program:`llvm-readobj` returns 0 under normal operation. It returns a non-zero; exit code if there were any errors. SEE ALSO; --------. :manpage:`llvm-nm(1)`, :manpage:`llvm-objdump(1)`, :manpage:`llvm-readelf(1)`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst:8274,Performance,load,load-config,8274," Code command. .. option:: --macho-dsymtab. Display the Dsymtab command. .. option:: --macho-indirect-symbols. Display indirect symbols. .. option:: --macho-linker-options. Display the Mach-O-specific linker options. .. option:: --macho-segment. Display the Segment command. .. option:: --macho-version-min. Display the version min command. PE/COFF SPECIFIC OPTIONS; ------------------------. The following options are implemented only for the PE/COFF file format. .. option:: --codeview. Display CodeView debug information. .. option:: --codeview-ghash. Enable global hashing for CodeView type stream de-duplication. .. option:: --codeview-merged-types. Display the merged CodeView type stream. .. option:: --codeview-subsection-bytes. Dump raw contents of CodeView debug sections and records. .. option:: --coff-basereloc. Display the .reloc section. .. option:: --coff-debug-directory. Display the debug directory. .. option:: --coff-tls-directory. Display the TLS directory. .. option:: --coff-directives. Display the .drectve section. .. option:: --coff-exports. Display the export table. .. option:: --coff-imports. Display the import table. .. option:: --coff-load-config. Display the load config. .. option:: --coff-resources. Display the .rsrc section. XCOFF SPECIFIC OPTIONS; ----------------------. The following options are implemented only for the XCOFF file format. .. option:: --auxiliary-header. Display XCOFF Auxiliary header. .. option:: --exception-section. Display XCOFF exception section entries. .. option:: --loader-section-header. Display XCOFF loader section header. .. option:: --loader-section-symbols. Display symbol table of loader section. .. option:: --loader-section-relocations. Display relocation entries of loader section. EXIT STATUS; -----------. :program:`llvm-readobj` returns 0 under normal operation. It returns a non-zero; exit code if there were any errors. SEE ALSO; --------. :manpage:`llvm-nm(1)`, :manpage:`llvm-objdump(1)`, :manpage:`llvm-readelf(1)`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst:8299,Performance,load,load,8299," Code command. .. option:: --macho-dsymtab. Display the Dsymtab command. .. option:: --macho-indirect-symbols. Display indirect symbols. .. option:: --macho-linker-options. Display the Mach-O-specific linker options. .. option:: --macho-segment. Display the Segment command. .. option:: --macho-version-min. Display the version min command. PE/COFF SPECIFIC OPTIONS; ------------------------. The following options are implemented only for the PE/COFF file format. .. option:: --codeview. Display CodeView debug information. .. option:: --codeview-ghash. Enable global hashing for CodeView type stream de-duplication. .. option:: --codeview-merged-types. Display the merged CodeView type stream. .. option:: --codeview-subsection-bytes. Dump raw contents of CodeView debug sections and records. .. option:: --coff-basereloc. Display the .reloc section. .. option:: --coff-debug-directory. Display the debug directory. .. option:: --coff-tls-directory. Display the TLS directory. .. option:: --coff-directives. Display the .drectve section. .. option:: --coff-exports. Display the export table. .. option:: --coff-imports. Display the import table. .. option:: --coff-load-config. Display the load config. .. option:: --coff-resources. Display the .rsrc section. XCOFF SPECIFIC OPTIONS; ----------------------. The following options are implemented only for the XCOFF file format. .. option:: --auxiliary-header. Display XCOFF Auxiliary header. .. option:: --exception-section. Display XCOFF exception section entries. .. option:: --loader-section-header. Display XCOFF loader section header. .. option:: --loader-section-symbols. Display symbol table of loader section. .. option:: --loader-section-relocations. Display relocation entries of loader section. EXIT STATUS; -----------. :program:`llvm-readobj` returns 0 under normal operation. It returns a non-zero; exit code if there were any errors. SEE ALSO; --------. :manpage:`llvm-nm(1)`, :manpage:`llvm-objdump(1)`, :manpage:`llvm-readelf(1)`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst:8639,Performance,load,loader-section-header,8639," Code command. .. option:: --macho-dsymtab. Display the Dsymtab command. .. option:: --macho-indirect-symbols. Display indirect symbols. .. option:: --macho-linker-options. Display the Mach-O-specific linker options. .. option:: --macho-segment. Display the Segment command. .. option:: --macho-version-min. Display the version min command. PE/COFF SPECIFIC OPTIONS; ------------------------. The following options are implemented only for the PE/COFF file format. .. option:: --codeview. Display CodeView debug information. .. option:: --codeview-ghash. Enable global hashing for CodeView type stream de-duplication. .. option:: --codeview-merged-types. Display the merged CodeView type stream. .. option:: --codeview-subsection-bytes. Dump raw contents of CodeView debug sections and records. .. option:: --coff-basereloc. Display the .reloc section. .. option:: --coff-debug-directory. Display the debug directory. .. option:: --coff-tls-directory. Display the TLS directory. .. option:: --coff-directives. Display the .drectve section. .. option:: --coff-exports. Display the export table. .. option:: --coff-imports. Display the import table. .. option:: --coff-load-config. Display the load config. .. option:: --coff-resources. Display the .rsrc section. XCOFF SPECIFIC OPTIONS; ----------------------. The following options are implemented only for the XCOFF file format. .. option:: --auxiliary-header. Display XCOFF Auxiliary header. .. option:: --exception-section. Display XCOFF exception section entries. .. option:: --loader-section-header. Display XCOFF loader section header. .. option:: --loader-section-symbols. Display symbol table of loader section. .. option:: --loader-section-relocations. Display relocation entries of loader section. EXIT STATUS; -----------. :program:`llvm-readobj` returns 0 under normal operation. It returns a non-zero; exit code if there were any errors. SEE ALSO; --------. :manpage:`llvm-nm(1)`, :manpage:`llvm-objdump(1)`, :manpage:`llvm-readelf(1)`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst:8676,Performance,load,loader,8676," Code command. .. option:: --macho-dsymtab. Display the Dsymtab command. .. option:: --macho-indirect-symbols. Display indirect symbols. .. option:: --macho-linker-options. Display the Mach-O-specific linker options. .. option:: --macho-segment. Display the Segment command. .. option:: --macho-version-min. Display the version min command. PE/COFF SPECIFIC OPTIONS; ------------------------. The following options are implemented only for the PE/COFF file format. .. option:: --codeview. Display CodeView debug information. .. option:: --codeview-ghash. Enable global hashing for CodeView type stream de-duplication. .. option:: --codeview-merged-types. Display the merged CodeView type stream. .. option:: --codeview-subsection-bytes. Dump raw contents of CodeView debug sections and records. .. option:: --coff-basereloc. Display the .reloc section. .. option:: --coff-debug-directory. Display the debug directory. .. option:: --coff-tls-directory. Display the TLS directory. .. option:: --coff-directives. Display the .drectve section. .. option:: --coff-exports. Display the export table. .. option:: --coff-imports. Display the import table. .. option:: --coff-load-config. Display the load config. .. option:: --coff-resources. Display the .rsrc section. XCOFF SPECIFIC OPTIONS; ----------------------. The following options are implemented only for the XCOFF file format. .. option:: --auxiliary-header. Display XCOFF Auxiliary header. .. option:: --exception-section. Display XCOFF exception section entries. .. option:: --loader-section-header. Display XCOFF loader section header. .. option:: --loader-section-symbols. Display symbol table of loader section. .. option:: --loader-section-relocations. Display relocation entries of loader section. EXIT STATUS; -----------. :program:`llvm-readobj` returns 0 under normal operation. It returns a non-zero; exit code if there were any errors. SEE ALSO; --------. :manpage:`llvm-nm(1)`, :manpage:`llvm-objdump(1)`, :manpage:`llvm-readelf(1)`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst:8713,Performance,load,loader-section-symbols,8713," Code command. .. option:: --macho-dsymtab. Display the Dsymtab command. .. option:: --macho-indirect-symbols. Display indirect symbols. .. option:: --macho-linker-options. Display the Mach-O-specific linker options. .. option:: --macho-segment. Display the Segment command. .. option:: --macho-version-min. Display the version min command. PE/COFF SPECIFIC OPTIONS; ------------------------. The following options are implemented only for the PE/COFF file format. .. option:: --codeview. Display CodeView debug information. .. option:: --codeview-ghash. Enable global hashing for CodeView type stream de-duplication. .. option:: --codeview-merged-types. Display the merged CodeView type stream. .. option:: --codeview-subsection-bytes. Dump raw contents of CodeView debug sections and records. .. option:: --coff-basereloc. Display the .reloc section. .. option:: --coff-debug-directory. Display the debug directory. .. option:: --coff-tls-directory. Display the TLS directory. .. option:: --coff-directives. Display the .drectve section. .. option:: --coff-exports. Display the export table. .. option:: --coff-imports. Display the import table. .. option:: --coff-load-config. Display the load config. .. option:: --coff-resources. Display the .rsrc section. XCOFF SPECIFIC OPTIONS; ----------------------. The following options are implemented only for the XCOFF file format. .. option:: --auxiliary-header. Display XCOFF Auxiliary header. .. option:: --exception-section. Display XCOFF exception section entries. .. option:: --loader-section-header. Display XCOFF loader section header. .. option:: --loader-section-symbols. Display symbol table of loader section. .. option:: --loader-section-relocations. Display relocation entries of loader section. EXIT STATUS; -----------. :program:`llvm-readobj` returns 0 under normal operation. It returns a non-zero; exit code if there were any errors. SEE ALSO; --------. :manpage:`llvm-nm(1)`, :manpage:`llvm-objdump(1)`, :manpage:`llvm-readelf(1)`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst:8761,Performance,load,loader,8761," Code command. .. option:: --macho-dsymtab. Display the Dsymtab command. .. option:: --macho-indirect-symbols. Display indirect symbols. .. option:: --macho-linker-options. Display the Mach-O-specific linker options. .. option:: --macho-segment. Display the Segment command. .. option:: --macho-version-min. Display the version min command. PE/COFF SPECIFIC OPTIONS; ------------------------. The following options are implemented only for the PE/COFF file format. .. option:: --codeview. Display CodeView debug information. .. option:: --codeview-ghash. Enable global hashing for CodeView type stream de-duplication. .. option:: --codeview-merged-types. Display the merged CodeView type stream. .. option:: --codeview-subsection-bytes. Dump raw contents of CodeView debug sections and records. .. option:: --coff-basereloc. Display the .reloc section. .. option:: --coff-debug-directory. Display the debug directory. .. option:: --coff-tls-directory. Display the TLS directory. .. option:: --coff-directives. Display the .drectve section. .. option:: --coff-exports. Display the export table. .. option:: --coff-imports. Display the import table. .. option:: --coff-load-config. Display the load config. .. option:: --coff-resources. Display the .rsrc section. XCOFF SPECIFIC OPTIONS; ----------------------. The following options are implemented only for the XCOFF file format. .. option:: --auxiliary-header. Display XCOFF Auxiliary header. .. option:: --exception-section. Display XCOFF exception section entries. .. option:: --loader-section-header. Display XCOFF loader section header. .. option:: --loader-section-symbols. Display symbol table of loader section. .. option:: --loader-section-relocations. Display relocation entries of loader section. EXIT STATUS; -----------. :program:`llvm-readobj` returns 0 under normal operation. It returns a non-zero; exit code if there were any errors. SEE ALSO; --------. :manpage:`llvm-nm(1)`, :manpage:`llvm-objdump(1)`, :manpage:`llvm-readelf(1)`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst:8791,Performance,load,loader-section-relocations,8791," Code command. .. option:: --macho-dsymtab. Display the Dsymtab command. .. option:: --macho-indirect-symbols. Display indirect symbols. .. option:: --macho-linker-options. Display the Mach-O-specific linker options. .. option:: --macho-segment. Display the Segment command. .. option:: --macho-version-min. Display the version min command. PE/COFF SPECIFIC OPTIONS; ------------------------. The following options are implemented only for the PE/COFF file format. .. option:: --codeview. Display CodeView debug information. .. option:: --codeview-ghash. Enable global hashing for CodeView type stream de-duplication. .. option:: --codeview-merged-types. Display the merged CodeView type stream. .. option:: --codeview-subsection-bytes. Dump raw contents of CodeView debug sections and records. .. option:: --coff-basereloc. Display the .reloc section. .. option:: --coff-debug-directory. Display the debug directory. .. option:: --coff-tls-directory. Display the TLS directory. .. option:: --coff-directives. Display the .drectve section. .. option:: --coff-exports. Display the export table. .. option:: --coff-imports. Display the import table. .. option:: --coff-load-config. Display the load config. .. option:: --coff-resources. Display the .rsrc section. XCOFF SPECIFIC OPTIONS; ----------------------. The following options are implemented only for the XCOFF file format. .. option:: --auxiliary-header. Display XCOFF Auxiliary header. .. option:: --exception-section. Display XCOFF exception section entries. .. option:: --loader-section-header. Display XCOFF loader section header. .. option:: --loader-section-symbols. Display symbol table of loader section. .. option:: --loader-section-relocations. Display relocation entries of loader section. EXIT STATUS; -----------. :program:`llvm-readobj` returns 0 under normal operation. It returns a non-zero; exit code if there were any errors. SEE ALSO; --------. :manpage:`llvm-nm(1)`, :manpage:`llvm-objdump(1)`, :manpage:`llvm-readelf(1)`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst:8849,Performance,load,loader,8849," Code command. .. option:: --macho-dsymtab. Display the Dsymtab command. .. option:: --macho-indirect-symbols. Display indirect symbols. .. option:: --macho-linker-options. Display the Mach-O-specific linker options. .. option:: --macho-segment. Display the Segment command. .. option:: --macho-version-min. Display the version min command. PE/COFF SPECIFIC OPTIONS; ------------------------. The following options are implemented only for the PE/COFF file format. .. option:: --codeview. Display CodeView debug information. .. option:: --codeview-ghash. Enable global hashing for CodeView type stream de-duplication. .. option:: --codeview-merged-types. Display the merged CodeView type stream. .. option:: --codeview-subsection-bytes. Dump raw contents of CodeView debug sections and records. .. option:: --coff-basereloc. Display the .reloc section. .. option:: --coff-debug-directory. Display the debug directory. .. option:: --coff-tls-directory. Display the TLS directory. .. option:: --coff-directives. Display the .drectve section. .. option:: --coff-exports. Display the export table. .. option:: --coff-imports. Display the import table. .. option:: --coff-load-config. Display the load config. .. option:: --coff-resources. Display the .rsrc section. XCOFF SPECIFIC OPTIONS; ----------------------. The following options are implemented only for the XCOFF file format. .. option:: --auxiliary-header. Display XCOFF Auxiliary header. .. option:: --exception-section. Display XCOFF exception section entries. .. option:: --loader-section-header. Display XCOFF loader section header. .. option:: --loader-section-symbols. Display symbol table of loader section. .. option:: --loader-section-relocations. Display relocation entries of loader section. EXIT STATUS; -----------. :program:`llvm-readobj` returns 0 under normal operation. It returns a non-zero; exit code if there were any errors. SEE ALSO; --------. :manpage:`llvm-nm(1)`, :manpage:`llvm-objdump(1)`, :manpage:`llvm-readelf(1)`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst:1679,Safety,avoid,avoid,1679," is a list of differences between :program:`llvm-readelf` and; :program:`llvm-readobj`:. - :program:`llvm-readelf` uses `GNU` for the :option:`--elf-output-style` option; by default. :program:`llvm-readobj` uses `LLVM`.; - :program:`llvm-readelf` allows single-letter grouped flags (e.g.; ``llvm-readelf -SW`` is the same as ``llvm-readelf -S -W``).; :program:`llvm-readobj` does not allow grouping.; - :program:`llvm-readelf` provides :option:`-s` as an alias for; :option:`--symbols`, for GNU :program:`readelf` compatibility, whereas it is; an alias for :option:`--section-headers` in :program:`llvm-readobj`.; - :program:`llvm-readobj` provides ``-t`` as an alias for :option:`--symbols`.; :program:`llvm-readelf` does not.; - :program:`llvm-readobj` provides ``--sr``, ``--sd``, ``--st`` and ``--dt`` as; aliases for :option:`--section-relocations`, :option:`--section-data`,; :option:`--section-symbols` and :option:`--dyn-symbols` respectively.; :program:`llvm-readelf` does not provide these aliases, to avoid conflicting; with grouped flags. GENERAL AND MULTI-FORMAT OPTIONS; --------------------------------. These options are applicable to more than one file format, or are unrelated to; file formats. .. option:: --all. Equivalent to specifying all the main display options relevant to the file; format. .. option:: --addrsig. Display the address-significance table. .. option:: --decompress, -z. Dump decompressed section content when used with ``-x`` or ``-p``.; If the section(s) are not compressed, they are displayed as is. .. option:: --expand-relocs. When used with :option:`--relocs`, display each relocation in an expanded; multi-line format. .. option:: --file-header, -h. Display file headers. .. option:: --headers, -e. Equivalent to setting: :option:`--file-header`, :option:`--program-headers`,; and :option:`--sections`. .. option:: --help. Display a summary of command line options. .. option:: --hex-dump=<section[,section,...]>, -x. Display the specified section(s) as he",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst:5335,Security,hash,hash,5335,"executable. .. option:: @<FILE>. Read command-line options from response file `<FILE>`. ELF SPECIFIC OPTIONS; --------------------. The following options are implemented only for the ELF file format. .. option:: --arch-specific, -A. Display architecture-specific information, e.g. the ARM attributes section on ARM. .. option:: --bb-addr-map. Display the contents of the basic block address map section(s), which contain the; address of each function, along with the relative offset of each basic block. .. option:: --demangle, -C. Display demangled symbol names in the output. .. option:: --dependent-libraries. Display the dependent libraries section. .. option:: --dyn-relocations. Display the dynamic relocation entries. .. option:: --dyn-symbols, --dyn-syms, --dt. Display the dynamic symbol table. .. option:: --dynamic-table, --dynamic, -d. Display the dynamic table. .. option:: --cg-profile. Display the callgraph profile section. .. option:: --histogram, -I. Display a bucket list histogram for dynamic symbol hash tables. .. option:: --elf-linker-options. Display the linker options section. .. option:: --elf-output-style=<value>. Format ELF information in the specified style. Valid options are ``LLVM``,; ``GNU``, and ``JSON``. ``LLVM`` output (the default) is an expanded and; structured format. ``GNU`` output mimics the equivalent GNU :program:`readelf`; output. ``JSON`` is JSON formatted output intended for machine consumption. .. option:: --section-groups, -g. Display section groups. .. option:: --gnu-hash-table. Display the GNU hash table for dynamic symbols. .. option:: --hash-symbols. Display the expanded hash table with dynamic symbol data. .. option:: --hash-table. Display the hash table for dynamic symbols. .. option:: --memtag. Display information about memory tagging present in the binary. This includes; various dynamic entries, decoded global descriptor sections, and decoded; Android-specific ELF notes. .. option:: --notes, -n. Display all notes. .. option:: -",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst:5839,Security,hash,hash-table,5839,"angle, -C. Display demangled symbol names in the output. .. option:: --dependent-libraries. Display the dependent libraries section. .. option:: --dyn-relocations. Display the dynamic relocation entries. .. option:: --dyn-symbols, --dyn-syms, --dt. Display the dynamic symbol table. .. option:: --dynamic-table, --dynamic, -d. Display the dynamic table. .. option:: --cg-profile. Display the callgraph profile section. .. option:: --histogram, -I. Display a bucket list histogram for dynamic symbol hash tables. .. option:: --elf-linker-options. Display the linker options section. .. option:: --elf-output-style=<value>. Format ELF information in the specified style. Valid options are ``LLVM``,; ``GNU``, and ``JSON``. ``LLVM`` output (the default) is an expanded and; structured format. ``GNU`` output mimics the equivalent GNU :program:`readelf`; output. ``JSON`` is JSON formatted output intended for machine consumption. .. option:: --section-groups, -g. Display section groups. .. option:: --gnu-hash-table. Display the GNU hash table for dynamic symbols. .. option:: --hash-symbols. Display the expanded hash table with dynamic symbol data. .. option:: --hash-table. Display the hash table for dynamic symbols. .. option:: --memtag. Display information about memory tagging present in the binary. This includes; various dynamic entries, decoded global descriptor sections, and decoded; Android-specific ELF notes. .. option:: --notes, -n. Display all notes. .. option:: --pretty-print. When used with :option:`--elf-output-style`, JSON output will be formatted in; a more readable format. .. option:: --program-headers, --segments, -l. Display the program headers. .. option:: --raw-relr. Do not decode relocations in RELR relocation sections when displaying them. .. option:: --section-mapping. Display the section to segment mapping. .. option:: --stack-sizes. Display the contents of the stack sizes section(s), i.e. pairs of function; names and the size of their stack frames. Currently on",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst:5867,Security,hash,hash,5867,"mes in the output. .. option:: --dependent-libraries. Display the dependent libraries section. .. option:: --dyn-relocations. Display the dynamic relocation entries. .. option:: --dyn-symbols, --dyn-syms, --dt. Display the dynamic symbol table. .. option:: --dynamic-table, --dynamic, -d. Display the dynamic table. .. option:: --cg-profile. Display the callgraph profile section. .. option:: --histogram, -I. Display a bucket list histogram for dynamic symbol hash tables. .. option:: --elf-linker-options. Display the linker options section. .. option:: --elf-output-style=<value>. Format ELF information in the specified style. Valid options are ``LLVM``,; ``GNU``, and ``JSON``. ``LLVM`` output (the default) is an expanded and; structured format. ``GNU`` output mimics the equivalent GNU :program:`readelf`; output. ``JSON`` is JSON formatted output intended for machine consumption. .. option:: --section-groups, -g. Display section groups. .. option:: --gnu-hash-table. Display the GNU hash table for dynamic symbols. .. option:: --hash-symbols. Display the expanded hash table with dynamic symbol data. .. option:: --hash-table. Display the hash table for dynamic symbols. .. option:: --memtag. Display information about memory tagging present in the binary. This includes; various dynamic entries, decoded global descriptor sections, and decoded; Android-specific ELF notes. .. option:: --notes, -n. Display all notes. .. option:: --pretty-print. When used with :option:`--elf-output-style`, JSON output will be formatted in; a more readable format. .. option:: --program-headers, --segments, -l. Display the program headers. .. option:: --raw-relr. Do not decode relocations in RELR relocation sections when displaying them. .. option:: --section-mapping. Display the section to segment mapping. .. option:: --stack-sizes. Display the contents of the stack sizes section(s), i.e. pairs of function; names and the size of their stack frames. Currently only implemented for GNU; style output.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst:5913,Security,hash,hash-symbols,5913,"ent-libraries. Display the dependent libraries section. .. option:: --dyn-relocations. Display the dynamic relocation entries. .. option:: --dyn-symbols, --dyn-syms, --dt. Display the dynamic symbol table. .. option:: --dynamic-table, --dynamic, -d. Display the dynamic table. .. option:: --cg-profile. Display the callgraph profile section. .. option:: --histogram, -I. Display a bucket list histogram for dynamic symbol hash tables. .. option:: --elf-linker-options. Display the linker options section. .. option:: --elf-output-style=<value>. Format ELF information in the specified style. Valid options are ``LLVM``,; ``GNU``, and ``JSON``. ``LLVM`` output (the default) is an expanded and; structured format. ``GNU`` output mimics the equivalent GNU :program:`readelf`; output. ``JSON`` is JSON formatted output intended for machine consumption. .. option:: --section-groups, -g. Display section groups. .. option:: --gnu-hash-table. Display the GNU hash table for dynamic symbols. .. option:: --hash-symbols. Display the expanded hash table with dynamic symbol data. .. option:: --hash-table. Display the hash table for dynamic symbols. .. option:: --memtag. Display information about memory tagging present in the binary. This includes; various dynamic entries, decoded global descriptor sections, and decoded; Android-specific ELF notes. .. option:: --notes, -n. Display all notes. .. option:: --pretty-print. When used with :option:`--elf-output-style`, JSON output will be formatted in; a more readable format. .. option:: --program-headers, --segments, -l. Display the program headers. .. option:: --raw-relr. Do not decode relocations in RELR relocation sections when displaying them. .. option:: --section-mapping. Display the section to segment mapping. .. option:: --stack-sizes. Display the contents of the stack sizes section(s), i.e. pairs of function; names and the size of their stack frames. Currently only implemented for GNU; style output. .. option:: --version-info, -V. Display",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst:5948,Security,hash,hash,5948,"ries section. .. option:: --dyn-relocations. Display the dynamic relocation entries. .. option:: --dyn-symbols, --dyn-syms, --dt. Display the dynamic symbol table. .. option:: --dynamic-table, --dynamic, -d. Display the dynamic table. .. option:: --cg-profile. Display the callgraph profile section. .. option:: --histogram, -I. Display a bucket list histogram for dynamic symbol hash tables. .. option:: --elf-linker-options. Display the linker options section. .. option:: --elf-output-style=<value>. Format ELF information in the specified style. Valid options are ``LLVM``,; ``GNU``, and ``JSON``. ``LLVM`` output (the default) is an expanded and; structured format. ``GNU`` output mimics the equivalent GNU :program:`readelf`; output. ``JSON`` is JSON formatted output intended for machine consumption. .. option:: --section-groups, -g. Display section groups. .. option:: --gnu-hash-table. Display the GNU hash table for dynamic symbols. .. option:: --hash-symbols. Display the expanded hash table with dynamic symbol data. .. option:: --hash-table. Display the hash table for dynamic symbols. .. option:: --memtag. Display information about memory tagging present in the binary. This includes; various dynamic entries, decoded global descriptor sections, and decoded; Android-specific ELF notes. .. option:: --notes, -n. Display all notes. .. option:: --pretty-print. When used with :option:`--elf-output-style`, JSON output will be formatted in; a more readable format. .. option:: --program-headers, --segments, -l. Display the program headers. .. option:: --raw-relr. Do not decode relocations in RELR relocation sections when displaying them. .. option:: --section-mapping. Display the section to segment mapping. .. option:: --stack-sizes. Display the contents of the stack sizes section(s), i.e. pairs of function; names and the size of their stack frames. Currently only implemented for GNU; style output. .. option:: --version-info, -V. Display version sections. MACH-O SPECIFIC OPTION",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst:5999,Security,hash,hash-table,5999,". Display the dynamic relocation entries. .. option:: --dyn-symbols, --dyn-syms, --dt. Display the dynamic symbol table. .. option:: --dynamic-table, --dynamic, -d. Display the dynamic table. .. option:: --cg-profile. Display the callgraph profile section. .. option:: --histogram, -I. Display a bucket list histogram for dynamic symbol hash tables. .. option:: --elf-linker-options. Display the linker options section. .. option:: --elf-output-style=<value>. Format ELF information in the specified style. Valid options are ``LLVM``,; ``GNU``, and ``JSON``. ``LLVM`` output (the default) is an expanded and; structured format. ``GNU`` output mimics the equivalent GNU :program:`readelf`; output. ``JSON`` is JSON formatted output intended for machine consumption. .. option:: --section-groups, -g. Display section groups. .. option:: --gnu-hash-table. Display the GNU hash table for dynamic symbols. .. option:: --hash-symbols. Display the expanded hash table with dynamic symbol data. .. option:: --hash-table. Display the hash table for dynamic symbols. .. option:: --memtag. Display information about memory tagging present in the binary. This includes; various dynamic entries, decoded global descriptor sections, and decoded; Android-specific ELF notes. .. option:: --notes, -n. Display all notes. .. option:: --pretty-print. When used with :option:`--elf-output-style`, JSON output will be formatted in; a more readable format. .. option:: --program-headers, --segments, -l. Display the program headers. .. option:: --raw-relr. Do not decode relocations in RELR relocation sections when displaying them. .. option:: --section-mapping. Display the section to segment mapping. .. option:: --stack-sizes. Display the contents of the stack sizes section(s), i.e. pairs of function; names and the size of their stack frames. Currently only implemented for GNU; style output. .. option:: --version-info, -V. Display version sections. MACH-O SPECIFIC OPTIONS; -----------------------. The following op",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst:6023,Security,hash,hash,6023,"ntries. .. option:: --dyn-symbols, --dyn-syms, --dt. Display the dynamic symbol table. .. option:: --dynamic-table, --dynamic, -d. Display the dynamic table. .. option:: --cg-profile. Display the callgraph profile section. .. option:: --histogram, -I. Display a bucket list histogram for dynamic symbol hash tables. .. option:: --elf-linker-options. Display the linker options section. .. option:: --elf-output-style=<value>. Format ELF information in the specified style. Valid options are ``LLVM``,; ``GNU``, and ``JSON``. ``LLVM`` output (the default) is an expanded and; structured format. ``GNU`` output mimics the equivalent GNU :program:`readelf`; output. ``JSON`` is JSON formatted output intended for machine consumption. .. option:: --section-groups, -g. Display section groups. .. option:: --gnu-hash-table. Display the GNU hash table for dynamic symbols. .. option:: --hash-symbols. Display the expanded hash table with dynamic symbol data. .. option:: --hash-table. Display the hash table for dynamic symbols. .. option:: --memtag. Display information about memory tagging present in the binary. This includes; various dynamic entries, decoded global descriptor sections, and decoded; Android-specific ELF notes. .. option:: --notes, -n. Display all notes. .. option:: --pretty-print. When used with :option:`--elf-output-style`, JSON output will be formatted in; a more readable format. .. option:: --program-headers, --segments, -l. Display the program headers. .. option:: --raw-relr. Do not decode relocations in RELR relocation sections when displaying them. .. option:: --section-mapping. Display the section to segment mapping. .. option:: --stack-sizes. Display the contents of the stack sizes section(s), i.e. pairs of function; names and the size of their stack frames. Currently only implemented for GNU; style output. .. option:: --version-info, -V. Display version sections. MACH-O SPECIFIC OPTIONS; -----------------------. The following options are implemented only for th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst:7676,Security,hash,hashing,7676,"--stack-sizes. Display the contents of the stack sizes section(s), i.e. pairs of function; names and the size of their stack frames. Currently only implemented for GNU; style output. .. option:: --version-info, -V. Display version sections. MACH-O SPECIFIC OPTIONS; -----------------------. The following options are implemented only for the Mach-O file format. .. option:: --macho-data-in-code. Display the Data in Code command. .. option:: --macho-dsymtab. Display the Dsymtab command. .. option:: --macho-indirect-symbols. Display indirect symbols. .. option:: --macho-linker-options. Display the Mach-O-specific linker options. .. option:: --macho-segment. Display the Segment command. .. option:: --macho-version-min. Display the version min command. PE/COFF SPECIFIC OPTIONS; ------------------------. The following options are implemented only for the PE/COFF file format. .. option:: --codeview. Display CodeView debug information. .. option:: --codeview-ghash. Enable global hashing for CodeView type stream de-duplication. .. option:: --codeview-merged-types. Display the merged CodeView type stream. .. option:: --codeview-subsection-bytes. Dump raw contents of CodeView debug sections and records. .. option:: --coff-basereloc. Display the .reloc section. .. option:: --coff-debug-directory. Display the debug directory. .. option:: --coff-tls-directory. Display the TLS directory. .. option:: --coff-directives. Display the .drectve section. .. option:: --coff-exports. Display the export table. .. option:: --coff-imports. Display the import table. .. option:: --coff-load-config. Display the load config. .. option:: --coff-resources. Display the .rsrc section. XCOFF SPECIFIC OPTIONS; ----------------------. The following options are implemented only for the XCOFF file format. .. option:: --auxiliary-header. Display XCOFF Auxiliary header. .. option:: --exception-section. Display XCOFF exception section entries. .. option:: --loader-section-header. Display XCOFF loader section he",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-readobj.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst:338,Availability,redundant,redundant,338,"llvm-reduce - LLVM automatic testcase reducer.; ==============================================. .. program:: llvm-reduce. SYNOPSIS; --------. :program:`llvm-reduce` [*options*] [*input...*]. DESCRIPTION; -----------. The :program:`llvm-reduce` tool project that can be used for reducing the size of LLVM test cases.; It works by removing redundant or unnecessary code from LLVM test cases while still preserving ; their ability to detect bugs. If ``input`` is ""``-``"", :program:`llvm-reduce` reads from standard; input. Otherwise, it will read from the specified ``filenames``. LLVM-Reduce is a useful tool for reducing the size and ; complexity of LLVM test cases, making it easier to identify and debug issues in ; the LLVM compiler infrastructure. GENERIC OPTIONS; ---------------. .. option:: --help. Display available options (--help-hidden for more). .. option:: --abort-on-invalid-reduction. Abort if any reduction results in invalid IR. .. option::--delta-passes=<string> . Delta passes to run, separated by commas. By default, run all delta passes. .. option:: --in-place . WARNING: This option will replace your input file with the reduced version!. .. option:: --ir-passes=<string> . A textual description of the pass pipeline, same as what's passed to `opt -passes`. .. option:: -j <uint> . Maximum number of threads to use to process chunks. Set to 1 to disable parallelism. .. option:: --max-pass-iterations=<int>. Maximum number of times to run the full set of delta passes (default=5). .. option:: --mtriple=<string> . Set the target triple. .. option:: --preserve-debug-environment. Don't disable features used for crash debugging (crash reports, llvm-symbolizer and core dumps). .. option:: --print-delta-passes . Print list of delta passes, passable to --delta-passes as a comma separated liste. .. option:: --skip-delta-passes=<string> . Delta passes to not run, separated by commas. By default, run all delta passes. .. option:: --starting-granularity-level=<uint>. Number of time",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst:813,Availability,avail,available,813,"llvm-reduce - LLVM automatic testcase reducer.; ==============================================. .. program:: llvm-reduce. SYNOPSIS; --------. :program:`llvm-reduce` [*options*] [*input...*]. DESCRIPTION; -----------. The :program:`llvm-reduce` tool project that can be used for reducing the size of LLVM test cases.; It works by removing redundant or unnecessary code from LLVM test cases while still preserving ; their ability to detect bugs. If ``input`` is ""``-``"", :program:`llvm-reduce` reads from standard; input. Otherwise, it will read from the specified ``filenames``. LLVM-Reduce is a useful tool for reducing the size and ; complexity of LLVM test cases, making it easier to identify and debug issues in ; the LLVM compiler infrastructure. GENERIC OPTIONS; ---------------. .. option:: --help. Display available options (--help-hidden for more). .. option:: --abort-on-invalid-reduction. Abort if any reduction results in invalid IR. .. option::--delta-passes=<string> . Delta passes to run, separated by commas. By default, run all delta passes. .. option:: --in-place . WARNING: This option will replace your input file with the reduced version!. .. option:: --ir-passes=<string> . A textual description of the pass pipeline, same as what's passed to `opt -passes`. .. option:: -j <uint> . Maximum number of threads to use to process chunks. Set to 1 to disable parallelism. .. option:: --max-pass-iterations=<int>. Maximum number of times to run the full set of delta passes (default=5). .. option:: --mtriple=<string> . Set the target triple. .. option:: --preserve-debug-environment. Don't disable features used for crash debugging (crash reports, llvm-symbolizer and core dumps). .. option:: --print-delta-passes . Print list of delta passes, passable to --delta-passes as a comma separated liste. .. option:: --skip-delta-passes=<string> . Delta passes to not run, separated by commas. By default, run all delta passes. .. option:: --starting-granularity-level=<uint>. Number of time",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst:2822,Availability,error,errors,2822," dumps). .. option:: --print-delta-passes . Print list of delta passes, passable to --delta-passes as a comma separated liste. .. option:: --skip-delta-passes=<string> . Delta passes to not run, separated by commas. By default, run all delta passes. .. option:: --starting-granularity-level=<uint>. Number of times to divide chunks prior to first test. Note : Granularity refers to the level of detail at which the reduction process operates.; A lower granularity means that the reduction process operates at a more coarse-grained level,; while a higher granularity means that it operates at a more fine-grained level. .. option:: --test=<string> . Name of the interesting-ness test to be run. .. option:: --test-arg=<string> . Arguments passed onto the interesting-ness test. .. option:: --verbose . Print extra debugging information.; ; .. option:: --write-tmp-files-as-bitcode . Always write temporary files as bitcode instead of textual IR. .. option:: -x={ir|mir}. Input language as ir or mir. EXIT STATUS; ------------. :program:`llvm-reduce` returns 0 under normal operation. It returns a non-zero; exit code if there were any errors. EXAMPLE; -------. :program:`llvm-reduce` can be used to simplify a test that causes a; compiler crash. For example, let's assume that `opt` is crashing on the IR file; `test.ll` with error message `Assertion failed at line 1234 of; WhateverFile.cpp`, when running at `-O2`. The test case of `test.ll` can be reduced by invoking the following; command:. .. code-block:: bash. $(LLVM_BUILD_FOLDER)/bin/llvm-reduce --test=script.sh <path to>/test.ll. The shell script passed to the option `test` consists of the; following:. .. code-block:: bash. $(LLVM_BUILD_FOLDER)/bin/opt -O2 -disable-output $1 \; |& grep ""Assertion failed at line 1234 of WhateverFile.cpp"". (In this script, `grep` exits with 0 if it finds the string and that; becomes the whole script's status.). This example can be generalized to other tools that process IR files,; for example `llc`.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst:3013,Availability,error,error,3013," dumps). .. option:: --print-delta-passes . Print list of delta passes, passable to --delta-passes as a comma separated liste. .. option:: --skip-delta-passes=<string> . Delta passes to not run, separated by commas. By default, run all delta passes. .. option:: --starting-granularity-level=<uint>. Number of times to divide chunks prior to first test. Note : Granularity refers to the level of detail at which the reduction process operates.; A lower granularity means that the reduction process operates at a more coarse-grained level,; while a higher granularity means that it operates at a more fine-grained level. .. option:: --test=<string> . Name of the interesting-ness test to be run. .. option:: --test-arg=<string> . Arguments passed onto the interesting-ness test. .. option:: --verbose . Print extra debugging information.; ; .. option:: --write-tmp-files-as-bitcode . Always write temporary files as bitcode instead of textual IR. .. option:: -x={ir|mir}. Input language as ir or mir. EXIT STATUS; ------------. :program:`llvm-reduce` returns 0 under normal operation. It returns a non-zero; exit code if there were any errors. EXAMPLE; -------. :program:`llvm-reduce` can be used to simplify a test that causes a; compiler crash. For example, let's assume that `opt` is crashing on the IR file; `test.ll` with error message `Assertion failed at line 1234 of; WhateverFile.cpp`, when running at `-O2`. The test case of `test.ll` can be reduced by invoking the following; command:. .. code-block:: bash. $(LLVM_BUILD_FOLDER)/bin/llvm-reduce --test=script.sh <path to>/test.ll. The shell script passed to the option `test` consists of the; following:. .. code-block:: bash. $(LLVM_BUILD_FOLDER)/bin/opt -O2 -disable-output $1 \; |& grep ""Assertion failed at line 1234 of WhateverFile.cpp"". (In this script, `grep` exits with 0 if it finds the string and that; becomes the whole script's status.). This example can be generalized to other tools that process IR files,; for example `llc`.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst:1229,Deployability,pipeline,pipeline,1229,"reduce` tool project that can be used for reducing the size of LLVM test cases.; It works by removing redundant or unnecessary code from LLVM test cases while still preserving ; their ability to detect bugs. If ``input`` is ""``-``"", :program:`llvm-reduce` reads from standard; input. Otherwise, it will read from the specified ``filenames``. LLVM-Reduce is a useful tool for reducing the size and ; complexity of LLVM test cases, making it easier to identify and debug issues in ; the LLVM compiler infrastructure. GENERIC OPTIONS; ---------------. .. option:: --help. Display available options (--help-hidden for more). .. option:: --abort-on-invalid-reduction. Abort if any reduction results in invalid IR. .. option::--delta-passes=<string> . Delta passes to run, separated by commas. By default, run all delta passes. .. option:: --in-place . WARNING: This option will replace your input file with the reduced version!. .. option:: --ir-passes=<string> . A textual description of the pass pipeline, same as what's passed to `opt -passes`. .. option:: -j <uint> . Maximum number of threads to use to process chunks. Set to 1 to disable parallelism. .. option:: --max-pass-iterations=<int>. Maximum number of times to run the full set of delta passes (default=5). .. option:: --mtriple=<string> . Set the target triple. .. option:: --preserve-debug-environment. Don't disable features used for crash debugging (crash reports, llvm-symbolizer and core dumps). .. option:: --print-delta-passes . Print list of delta passes, passable to --delta-passes as a comma separated liste. .. option:: --skip-delta-passes=<string> . Delta passes to not run, separated by commas. By default, run all delta passes. .. option:: --starting-granularity-level=<uint>. Number of times to divide chunks prior to first test. Note : Granularity refers to the level of detail at which the reduction process operates.; A lower granularity means that the reduction process operates at a more coarse-grained level,; while a h",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst:5,Energy Efficiency,reduce,reduce,5,"llvm-reduce - LLVM automatic testcase reducer.; ==============================================. .. program:: llvm-reduce. SYNOPSIS; --------. :program:`llvm-reduce` [*options*] [*input...*]. DESCRIPTION; -----------. The :program:`llvm-reduce` tool project that can be used for reducing the size of LLVM test cases.; It works by removing redundant or unnecessary code from LLVM test cases while still preserving ; their ability to detect bugs. If ``input`` is ""``-``"", :program:`llvm-reduce` reads from standard; input. Otherwise, it will read from the specified ``filenames``. LLVM-Reduce is a useful tool for reducing the size and ; complexity of LLVM test cases, making it easier to identify and debug issues in ; the LLVM compiler infrastructure. GENERIC OPTIONS; ---------------. .. option:: --help. Display available options (--help-hidden for more). .. option:: --abort-on-invalid-reduction. Abort if any reduction results in invalid IR. .. option::--delta-passes=<string> . Delta passes to run, separated by commas. By default, run all delta passes. .. option:: --in-place . WARNING: This option will replace your input file with the reduced version!. .. option:: --ir-passes=<string> . A textual description of the pass pipeline, same as what's passed to `opt -passes`. .. option:: -j <uint> . Maximum number of threads to use to process chunks. Set to 1 to disable parallelism. .. option:: --max-pass-iterations=<int>. Maximum number of times to run the full set of delta passes (default=5). .. option:: --mtriple=<string> . Set the target triple. .. option:: --preserve-debug-environment. Don't disable features used for crash debugging (crash reports, llvm-symbolizer and core dumps). .. option:: --print-delta-passes . Print list of delta passes, passable to --delta-passes as a comma separated liste. .. option:: --skip-delta-passes=<string> . Delta passes to not run, separated by commas. By default, run all delta passes. .. option:: --starting-granularity-level=<uint>. Number of time",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst:38,Energy Efficiency,reduce,reducer,38,"llvm-reduce - LLVM automatic testcase reducer.; ==============================================. .. program:: llvm-reduce. SYNOPSIS; --------. :program:`llvm-reduce` [*options*] [*input...*]. DESCRIPTION; -----------. The :program:`llvm-reduce` tool project that can be used for reducing the size of LLVM test cases.; It works by removing redundant or unnecessary code from LLVM test cases while still preserving ; their ability to detect bugs. If ``input`` is ""``-``"", :program:`llvm-reduce` reads from standard; input. Otherwise, it will read from the specified ``filenames``. LLVM-Reduce is a useful tool for reducing the size and ; complexity of LLVM test cases, making it easier to identify and debug issues in ; the LLVM compiler infrastructure. GENERIC OPTIONS; ---------------. .. option:: --help. Display available options (--help-hidden for more). .. option:: --abort-on-invalid-reduction. Abort if any reduction results in invalid IR. .. option::--delta-passes=<string> . Delta passes to run, separated by commas. By default, run all delta passes. .. option:: --in-place . WARNING: This option will replace your input file with the reduced version!. .. option:: --ir-passes=<string> . A textual description of the pass pipeline, same as what's passed to `opt -passes`. .. option:: -j <uint> . Maximum number of threads to use to process chunks. Set to 1 to disable parallelism. .. option:: --max-pass-iterations=<int>. Maximum number of times to run the full set of delta passes (default=5). .. option:: --mtriple=<string> . Set the target triple. .. option:: --preserve-debug-environment. Don't disable features used for crash debugging (crash reports, llvm-symbolizer and core dumps). .. option:: --print-delta-passes . Print list of delta passes, passable to --delta-passes as a comma separated liste. .. option:: --skip-delta-passes=<string> . Delta passes to not run, separated by commas. By default, run all delta passes. .. option:: --starting-granularity-level=<uint>. Number of time",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst:114,Energy Efficiency,reduce,reduce,114,"llvm-reduce - LLVM automatic testcase reducer.; ==============================================. .. program:: llvm-reduce. SYNOPSIS; --------. :program:`llvm-reduce` [*options*] [*input...*]. DESCRIPTION; -----------. The :program:`llvm-reduce` tool project that can be used for reducing the size of LLVM test cases.; It works by removing redundant or unnecessary code from LLVM test cases while still preserving ; their ability to detect bugs. If ``input`` is ""``-``"", :program:`llvm-reduce` reads from standard; input. Otherwise, it will read from the specified ``filenames``. LLVM-Reduce is a useful tool for reducing the size and ; complexity of LLVM test cases, making it easier to identify and debug issues in ; the LLVM compiler infrastructure. GENERIC OPTIONS; ---------------. .. option:: --help. Display available options (--help-hidden for more). .. option:: --abort-on-invalid-reduction. Abort if any reduction results in invalid IR. .. option::--delta-passes=<string> . Delta passes to run, separated by commas. By default, run all delta passes. .. option:: --in-place . WARNING: This option will replace your input file with the reduced version!. .. option:: --ir-passes=<string> . A textual description of the pass pipeline, same as what's passed to `opt -passes`. .. option:: -j <uint> . Maximum number of threads to use to process chunks. Set to 1 to disable parallelism. .. option:: --max-pass-iterations=<int>. Maximum number of times to run the full set of delta passes (default=5). .. option:: --mtriple=<string> . Set the target triple. .. option:: --preserve-debug-environment. Don't disable features used for crash debugging (crash reports, llvm-symbolizer and core dumps). .. option:: --print-delta-passes . Print list of delta passes, passable to --delta-passes as a comma separated liste. .. option:: --skip-delta-passes=<string> . Delta passes to not run, separated by commas. By default, run all delta passes. .. option:: --starting-granularity-level=<uint>. Number of time",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst:157,Energy Efficiency,reduce,reduce,157,"llvm-reduce - LLVM automatic testcase reducer.; ==============================================. .. program:: llvm-reduce. SYNOPSIS; --------. :program:`llvm-reduce` [*options*] [*input...*]. DESCRIPTION; -----------. The :program:`llvm-reduce` tool project that can be used for reducing the size of LLVM test cases.; It works by removing redundant or unnecessary code from LLVM test cases while still preserving ; their ability to detect bugs. If ``input`` is ""``-``"", :program:`llvm-reduce` reads from standard; input. Otherwise, it will read from the specified ``filenames``. LLVM-Reduce is a useful tool for reducing the size and ; complexity of LLVM test cases, making it easier to identify and debug issues in ; the LLVM compiler infrastructure. GENERIC OPTIONS; ---------------. .. option:: --help. Display available options (--help-hidden for more). .. option:: --abort-on-invalid-reduction. Abort if any reduction results in invalid IR. .. option::--delta-passes=<string> . Delta passes to run, separated by commas. By default, run all delta passes. .. option:: --in-place . WARNING: This option will replace your input file with the reduced version!. .. option:: --ir-passes=<string> . A textual description of the pass pipeline, same as what's passed to `opt -passes`. .. option:: -j <uint> . Maximum number of threads to use to process chunks. Set to 1 to disable parallelism. .. option:: --max-pass-iterations=<int>. Maximum number of times to run the full set of delta passes (default=5). .. option:: --mtriple=<string> . Set the target triple. .. option:: --preserve-debug-environment. Don't disable features used for crash debugging (crash reports, llvm-symbolizer and core dumps). .. option:: --print-delta-passes . Print list of delta passes, passable to --delta-passes as a comma separated liste. .. option:: --skip-delta-passes=<string> . Delta passes to not run, separated by commas. By default, run all delta passes. .. option:: --starting-granularity-level=<uint>. Number of time",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst:236,Energy Efficiency,reduce,reduce,236,"llvm-reduce - LLVM automatic testcase reducer.; ==============================================. .. program:: llvm-reduce. SYNOPSIS; --------. :program:`llvm-reduce` [*options*] [*input...*]. DESCRIPTION; -----------. The :program:`llvm-reduce` tool project that can be used for reducing the size of LLVM test cases.; It works by removing redundant or unnecessary code from LLVM test cases while still preserving ; their ability to detect bugs. If ``input`` is ""``-``"", :program:`llvm-reduce` reads from standard; input. Otherwise, it will read from the specified ``filenames``. LLVM-Reduce is a useful tool for reducing the size and ; complexity of LLVM test cases, making it easier to identify and debug issues in ; the LLVM compiler infrastructure. GENERIC OPTIONS; ---------------. .. option:: --help. Display available options (--help-hidden for more). .. option:: --abort-on-invalid-reduction. Abort if any reduction results in invalid IR. .. option::--delta-passes=<string> . Delta passes to run, separated by commas. By default, run all delta passes. .. option:: --in-place . WARNING: This option will replace your input file with the reduced version!. .. option:: --ir-passes=<string> . A textual description of the pass pipeline, same as what's passed to `opt -passes`. .. option:: -j <uint> . Maximum number of threads to use to process chunks. Set to 1 to disable parallelism. .. option:: --max-pass-iterations=<int>. Maximum number of times to run the full set of delta passes (default=5). .. option:: --mtriple=<string> . Set the target triple. .. option:: --preserve-debug-environment. Don't disable features used for crash debugging (crash reports, llvm-symbolizer and core dumps). .. option:: --print-delta-passes . Print list of delta passes, passable to --delta-passes as a comma separated liste. .. option:: --skip-delta-passes=<string> . Delta passes to not run, separated by commas. By default, run all delta passes. .. option:: --starting-granularity-level=<uint>. Number of time",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst:484,Energy Efficiency,reduce,reduce,484,"llvm-reduce - LLVM automatic testcase reducer.; ==============================================. .. program:: llvm-reduce. SYNOPSIS; --------. :program:`llvm-reduce` [*options*] [*input...*]. DESCRIPTION; -----------. The :program:`llvm-reduce` tool project that can be used for reducing the size of LLVM test cases.; It works by removing redundant or unnecessary code from LLVM test cases while still preserving ; their ability to detect bugs. If ``input`` is ""``-``"", :program:`llvm-reduce` reads from standard; input. Otherwise, it will read from the specified ``filenames``. LLVM-Reduce is a useful tool for reducing the size and ; complexity of LLVM test cases, making it easier to identify and debug issues in ; the LLVM compiler infrastructure. GENERIC OPTIONS; ---------------. .. option:: --help. Display available options (--help-hidden for more). .. option:: --abort-on-invalid-reduction. Abort if any reduction results in invalid IR. .. option::--delta-passes=<string> . Delta passes to run, separated by commas. By default, run all delta passes. .. option:: --in-place . WARNING: This option will replace your input file with the reduced version!. .. option:: --ir-passes=<string> . A textual description of the pass pipeline, same as what's passed to `opt -passes`. .. option:: -j <uint> . Maximum number of threads to use to process chunks. Set to 1 to disable parallelism. .. option:: --max-pass-iterations=<int>. Maximum number of times to run the full set of delta passes (default=5). .. option:: --mtriple=<string> . Set the target triple. .. option:: --preserve-debug-environment. Don't disable features used for crash debugging (crash reports, llvm-symbolizer and core dumps). .. option:: --print-delta-passes . Print list of delta passes, passable to --delta-passes as a comma separated liste. .. option:: --skip-delta-passes=<string> . Delta passes to not run, separated by commas. By default, run all delta passes. .. option:: --starting-granularity-level=<uint>. Number of time",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst:1142,Energy Efficiency,reduce,reduced,1142,". SYNOPSIS; --------. :program:`llvm-reduce` [*options*] [*input...*]. DESCRIPTION; -----------. The :program:`llvm-reduce` tool project that can be used for reducing the size of LLVM test cases.; It works by removing redundant or unnecessary code from LLVM test cases while still preserving ; their ability to detect bugs. If ``input`` is ""``-``"", :program:`llvm-reduce` reads from standard; input. Otherwise, it will read from the specified ``filenames``. LLVM-Reduce is a useful tool for reducing the size and ; complexity of LLVM test cases, making it easier to identify and debug issues in ; the LLVM compiler infrastructure. GENERIC OPTIONS; ---------------. .. option:: --help. Display available options (--help-hidden for more). .. option:: --abort-on-invalid-reduction. Abort if any reduction results in invalid IR. .. option::--delta-passes=<string> . Delta passes to run, separated by commas. By default, run all delta passes. .. option:: --in-place . WARNING: This option will replace your input file with the reduced version!. .. option:: --ir-passes=<string> . A textual description of the pass pipeline, same as what's passed to `opt -passes`. .. option:: -j <uint> . Maximum number of threads to use to process chunks. Set to 1 to disable parallelism. .. option:: --max-pass-iterations=<int>. Maximum number of times to run the full set of delta passes (default=5). .. option:: --mtriple=<string> . Set the target triple. .. option:: --preserve-debug-environment. Don't disable features used for crash debugging (crash reports, llvm-symbolizer and core dumps). .. option:: --print-delta-passes . Print list of delta passes, passable to --delta-passes as a comma separated liste. .. option:: --skip-delta-passes=<string> . Delta passes to not run, separated by commas. By default, run all delta passes. .. option:: --starting-granularity-level=<uint>. Number of times to divide chunks prior to first test. Note : Granularity refers to the level of detail at which the reduction process ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst:2729,Energy Efficiency,reduce,reduce,2729," dumps). .. option:: --print-delta-passes . Print list of delta passes, passable to --delta-passes as a comma separated liste. .. option:: --skip-delta-passes=<string> . Delta passes to not run, separated by commas. By default, run all delta passes. .. option:: --starting-granularity-level=<uint>. Number of times to divide chunks prior to first test. Note : Granularity refers to the level of detail at which the reduction process operates.; A lower granularity means that the reduction process operates at a more coarse-grained level,; while a higher granularity means that it operates at a more fine-grained level. .. option:: --test=<string> . Name of the interesting-ness test to be run. .. option:: --test-arg=<string> . Arguments passed onto the interesting-ness test. .. option:: --verbose . Print extra debugging information.; ; .. option:: --write-tmp-files-as-bitcode . Always write temporary files as bitcode instead of textual IR. .. option:: -x={ir|mir}. Input language as ir or mir. EXIT STATUS; ------------. :program:`llvm-reduce` returns 0 under normal operation. It returns a non-zero; exit code if there were any errors. EXAMPLE; -------. :program:`llvm-reduce` can be used to simplify a test that causes a; compiler crash. For example, let's assume that `opt` is crashing on the IR file; `test.ll` with error message `Assertion failed at line 1234 of; WhateverFile.cpp`, when running at `-O2`. The test case of `test.ll` can be reduced by invoking the following; command:. .. code-block:: bash. $(LLVM_BUILD_FOLDER)/bin/llvm-reduce --test=script.sh <path to>/test.ll. The shell script passed to the option `test` consists of the; following:. .. code-block:: bash. $(LLVM_BUILD_FOLDER)/bin/opt -O2 -disable-output $1 \; |& grep ""Assertion failed at line 1234 of WhateverFile.cpp"". (In this script, `grep` exits with 0 if it finds the string and that; becomes the whole script's status.). This example can be generalized to other tools that process IR files,; for example `llc`.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst:2863,Energy Efficiency,reduce,reduce,2863," dumps). .. option:: --print-delta-passes . Print list of delta passes, passable to --delta-passes as a comma separated liste. .. option:: --skip-delta-passes=<string> . Delta passes to not run, separated by commas. By default, run all delta passes. .. option:: --starting-granularity-level=<uint>. Number of times to divide chunks prior to first test. Note : Granularity refers to the level of detail at which the reduction process operates.; A lower granularity means that the reduction process operates at a more coarse-grained level,; while a higher granularity means that it operates at a more fine-grained level. .. option:: --test=<string> . Name of the interesting-ness test to be run. .. option:: --test-arg=<string> . Arguments passed onto the interesting-ness test. .. option:: --verbose . Print extra debugging information.; ; .. option:: --write-tmp-files-as-bitcode . Always write temporary files as bitcode instead of textual IR. .. option:: -x={ir|mir}. Input language as ir or mir. EXIT STATUS; ------------. :program:`llvm-reduce` returns 0 under normal operation. It returns a non-zero; exit code if there were any errors. EXAMPLE; -------. :program:`llvm-reduce` can be used to simplify a test that causes a; compiler crash. For example, let's assume that `opt` is crashing on the IR file; `test.ll` with error message `Assertion failed at line 1234 of; WhateverFile.cpp`, when running at `-O2`. The test case of `test.ll` can be reduced by invoking the following; command:. .. code-block:: bash. $(LLVM_BUILD_FOLDER)/bin/llvm-reduce --test=script.sh <path to>/test.ll. The shell script passed to the option `test` consists of the; following:. .. code-block:: bash. $(LLVM_BUILD_FOLDER)/bin/opt -O2 -disable-output $1 \; |& grep ""Assertion failed at line 1234 of WhateverFile.cpp"". (In this script, `grep` exits with 0 if it finds the string and that; becomes the whole script's status.). This example can be generalized to other tools that process IR files,; for example `llc`.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst:3138,Energy Efficiency,reduce,reduced,3138," dumps). .. option:: --print-delta-passes . Print list of delta passes, passable to --delta-passes as a comma separated liste. .. option:: --skip-delta-passes=<string> . Delta passes to not run, separated by commas. By default, run all delta passes. .. option:: --starting-granularity-level=<uint>. Number of times to divide chunks prior to first test. Note : Granularity refers to the level of detail at which the reduction process operates.; A lower granularity means that the reduction process operates at a more coarse-grained level,; while a higher granularity means that it operates at a more fine-grained level. .. option:: --test=<string> . Name of the interesting-ness test to be run. .. option:: --test-arg=<string> . Arguments passed onto the interesting-ness test. .. option:: --verbose . Print extra debugging information.; ; .. option:: --write-tmp-files-as-bitcode . Always write temporary files as bitcode instead of textual IR. .. option:: -x={ir|mir}. Input language as ir or mir. EXIT STATUS; ------------. :program:`llvm-reduce` returns 0 under normal operation. It returns a non-zero; exit code if there were any errors. EXAMPLE; -------. :program:`llvm-reduce` can be used to simplify a test that causes a; compiler crash. For example, let's assume that `opt` is crashing on the IR file; `test.ll` with error message `Assertion failed at line 1234 of; WhateverFile.cpp`, when running at `-O2`. The test case of `test.ll` can be reduced by invoking the following; command:. .. code-block:: bash. $(LLVM_BUILD_FOLDER)/bin/llvm-reduce --test=script.sh <path to>/test.ll. The shell script passed to the option `test` consists of the; following:. .. code-block:: bash. $(LLVM_BUILD_FOLDER)/bin/opt -O2 -disable-output $1 \; |& grep ""Assertion failed at line 1234 of WhateverFile.cpp"". (In this script, `grep` exits with 0 if it finds the string and that; becomes the whole script's status.). This example can be generalized to other tools that process IR files,; for example `llc`.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst:3235,Energy Efficiency,reduce,reduce,3235," dumps). .. option:: --print-delta-passes . Print list of delta passes, passable to --delta-passes as a comma separated liste. .. option:: --skip-delta-passes=<string> . Delta passes to not run, separated by commas. By default, run all delta passes. .. option:: --starting-granularity-level=<uint>. Number of times to divide chunks prior to first test. Note : Granularity refers to the level of detail at which the reduction process operates.; A lower granularity means that the reduction process operates at a more coarse-grained level,; while a higher granularity means that it operates at a more fine-grained level. .. option:: --test=<string> . Name of the interesting-ness test to be run. .. option:: --test-arg=<string> . Arguments passed onto the interesting-ness test. .. option:: --verbose . Print extra debugging information.; ; .. option:: --write-tmp-files-as-bitcode . Always write temporary files as bitcode instead of textual IR. .. option:: -x={ir|mir}. Input language as ir or mir. EXIT STATUS; ------------. :program:`llvm-reduce` returns 0 under normal operation. It returns a non-zero; exit code if there were any errors. EXAMPLE; -------. :program:`llvm-reduce` can be used to simplify a test that causes a; compiler crash. For example, let's assume that `opt` is crashing on the IR file; `test.ll` with error message `Assertion failed at line 1234 of; WhateverFile.cpp`, when running at `-O2`. The test case of `test.ll` can be reduced by invoking the following; command:. .. code-block:: bash. $(LLVM_BUILD_FOLDER)/bin/llvm-reduce --test=script.sh <path to>/test.ll. The shell script passed to the option `test` consists of the; following:. .. code-block:: bash. $(LLVM_BUILD_FOLDER)/bin/opt -O2 -disable-output $1 \; |& grep ""Assertion failed at line 1234 of WhateverFile.cpp"". (In this script, `grep` exits with 0 if it finds the string and that; becomes the whole script's status.). This example can be generalized to other tools that process IR files,; for example `llc`.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst:3019,Integrability,message,message,3019," dumps). .. option:: --print-delta-passes . Print list of delta passes, passable to --delta-passes as a comma separated liste. .. option:: --skip-delta-passes=<string> . Delta passes to not run, separated by commas. By default, run all delta passes. .. option:: --starting-granularity-level=<uint>. Number of times to divide chunks prior to first test. Note : Granularity refers to the level of detail at which the reduction process operates.; A lower granularity means that the reduction process operates at a more coarse-grained level,; while a higher granularity means that it operates at a more fine-grained level. .. option:: --test=<string> . Name of the interesting-ness test to be run. .. option:: --test-arg=<string> . Arguments passed onto the interesting-ness test. .. option:: --verbose . Print extra debugging information.; ; .. option:: --write-tmp-files-as-bitcode . Always write temporary files as bitcode instead of textual IR. .. option:: -x={ir|mir}. Input language as ir or mir. EXIT STATUS; ------------. :program:`llvm-reduce` returns 0 under normal operation. It returns a non-zero; exit code if there were any errors. EXAMPLE; -------. :program:`llvm-reduce` can be used to simplify a test that causes a; compiler crash. For example, let's assume that `opt` is crashing on the IR file; `test.ll` with error message `Assertion failed at line 1234 of; WhateverFile.cpp`, when running at `-O2`. The test case of `test.ll` can be reduced by invoking the following; command:. .. code-block:: bash. $(LLVM_BUILD_FOLDER)/bin/llvm-reduce --test=script.sh <path to>/test.ll. The shell script passed to the option `test` consists of the; following:. .. code-block:: bash. $(LLVM_BUILD_FOLDER)/bin/opt -O2 -disable-output $1 \; |& grep ""Assertion failed at line 1234 of WhateverFile.cpp"". (In this script, `grep` exits with 0 if it finds the string and that; becomes the whole script's status.). This example can be generalized to other tools that process IR files,; for example `llc`.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst:338,Safety,redund,redundant,338,"llvm-reduce - LLVM automatic testcase reducer.; ==============================================. .. program:: llvm-reduce. SYNOPSIS; --------. :program:`llvm-reduce` [*options*] [*input...*]. DESCRIPTION; -----------. The :program:`llvm-reduce` tool project that can be used for reducing the size of LLVM test cases.; It works by removing redundant or unnecessary code from LLVM test cases while still preserving ; their ability to detect bugs. If ``input`` is ""``-``"", :program:`llvm-reduce` reads from standard; input. Otherwise, it will read from the specified ``filenames``. LLVM-Reduce is a useful tool for reducing the size and ; complexity of LLVM test cases, making it easier to identify and debug issues in ; the LLVM compiler infrastructure. GENERIC OPTIONS; ---------------. .. option:: --help. Display available options (--help-hidden for more). .. option:: --abort-on-invalid-reduction. Abort if any reduction results in invalid IR. .. option::--delta-passes=<string> . Delta passes to run, separated by commas. By default, run all delta passes. .. option:: --in-place . WARNING: This option will replace your input file with the reduced version!. .. option:: --ir-passes=<string> . A textual description of the pass pipeline, same as what's passed to `opt -passes`. .. option:: -j <uint> . Maximum number of threads to use to process chunks. Set to 1 to disable parallelism. .. option:: --max-pass-iterations=<int>. Maximum number of times to run the full set of delta passes (default=5). .. option:: --mtriple=<string> . Set the target triple. .. option:: --preserve-debug-environment. Don't disable features used for crash debugging (crash reports, llvm-symbolizer and core dumps). .. option:: --print-delta-passes . Print list of delta passes, passable to --delta-passes as a comma separated liste. .. option:: --skip-delta-passes=<string> . Delta passes to not run, separated by commas. By default, run all delta passes. .. option:: --starting-granularity-level=<uint>. Number of time",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst:431,Safety,detect,detect,431,"llvm-reduce - LLVM automatic testcase reducer.; ==============================================. .. program:: llvm-reduce. SYNOPSIS; --------. :program:`llvm-reduce` [*options*] [*input...*]. DESCRIPTION; -----------. The :program:`llvm-reduce` tool project that can be used for reducing the size of LLVM test cases.; It works by removing redundant or unnecessary code from LLVM test cases while still preserving ; their ability to detect bugs. If ``input`` is ""``-``"", :program:`llvm-reduce` reads from standard; input. Otherwise, it will read from the specified ``filenames``. LLVM-Reduce is a useful tool for reducing the size and ; complexity of LLVM test cases, making it easier to identify and debug issues in ; the LLVM compiler infrastructure. GENERIC OPTIONS; ---------------. .. option:: --help. Display available options (--help-hidden for more). .. option:: --abort-on-invalid-reduction. Abort if any reduction results in invalid IR. .. option::--delta-passes=<string> . Delta passes to run, separated by commas. By default, run all delta passes. .. option:: --in-place . WARNING: This option will replace your input file with the reduced version!. .. option:: --ir-passes=<string> . A textual description of the pass pipeline, same as what's passed to `opt -passes`. .. option:: -j <uint> . Maximum number of threads to use to process chunks. Set to 1 to disable parallelism. .. option:: --max-pass-iterations=<int>. Maximum number of times to run the full set of delta passes (default=5). .. option:: --mtriple=<string> . Set the target triple. .. option:: --preserve-debug-environment. Don't disable features used for crash debugging (crash reports, llvm-symbolizer and core dumps). .. option:: --print-delta-passes . Print list of delta passes, passable to --delta-passes as a comma separated liste. .. option:: --skip-delta-passes=<string> . Delta passes to not run, separated by commas. By default, run all delta passes. .. option:: --starting-granularity-level=<uint>. Number of time",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst:871,Safety,abort,abort-on-invalid-reduction,871,"llvm-reduce - LLVM automatic testcase reducer.; ==============================================. .. program:: llvm-reduce. SYNOPSIS; --------. :program:`llvm-reduce` [*options*] [*input...*]. DESCRIPTION; -----------. The :program:`llvm-reduce` tool project that can be used for reducing the size of LLVM test cases.; It works by removing redundant or unnecessary code from LLVM test cases while still preserving ; their ability to detect bugs. If ``input`` is ""``-``"", :program:`llvm-reduce` reads from standard; input. Otherwise, it will read from the specified ``filenames``. LLVM-Reduce is a useful tool for reducing the size and ; complexity of LLVM test cases, making it easier to identify and debug issues in ; the LLVM compiler infrastructure. GENERIC OPTIONS; ---------------. .. option:: --help. Display available options (--help-hidden for more). .. option:: --abort-on-invalid-reduction. Abort if any reduction results in invalid IR. .. option::--delta-passes=<string> . Delta passes to run, separated by commas. By default, run all delta passes. .. option:: --in-place . WARNING: This option will replace your input file with the reduced version!. .. option:: --ir-passes=<string> . A textual description of the pass pipeline, same as what's passed to `opt -passes`. .. option:: -j <uint> . Maximum number of threads to use to process chunks. Set to 1 to disable parallelism. .. option:: --max-pass-iterations=<int>. Maximum number of times to run the full set of delta passes (default=5). .. option:: --mtriple=<string> . Set the target triple. .. option:: --preserve-debug-environment. Don't disable features used for crash debugging (crash reports, llvm-symbolizer and core dumps). .. option:: --print-delta-passes . Print list of delta passes, passable to --delta-passes as a comma separated liste. .. option:: --skip-delta-passes=<string> . Delta passes to not run, separated by commas. By default, run all delta passes. .. option:: --starting-granularity-level=<uint>. Number of time",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst:29,Testability,test,testcase,29,"llvm-reduce - LLVM automatic testcase reducer.; ==============================================. .. program:: llvm-reduce. SYNOPSIS; --------. :program:`llvm-reduce` [*options*] [*input...*]. DESCRIPTION; -----------. The :program:`llvm-reduce` tool project that can be used for reducing the size of LLVM test cases.; It works by removing redundant or unnecessary code from LLVM test cases while still preserving ; their ability to detect bugs. If ``input`` is ""``-``"", :program:`llvm-reduce` reads from standard; input. Otherwise, it will read from the specified ``filenames``. LLVM-Reduce is a useful tool for reducing the size and ; complexity of LLVM test cases, making it easier to identify and debug issues in ; the LLVM compiler infrastructure. GENERIC OPTIONS; ---------------. .. option:: --help. Display available options (--help-hidden for more). .. option:: --abort-on-invalid-reduction. Abort if any reduction results in invalid IR. .. option::--delta-passes=<string> . Delta passes to run, separated by commas. By default, run all delta passes. .. option:: --in-place . WARNING: This option will replace your input file with the reduced version!. .. option:: --ir-passes=<string> . A textual description of the pass pipeline, same as what's passed to `opt -passes`. .. option:: -j <uint> . Maximum number of threads to use to process chunks. Set to 1 to disable parallelism. .. option:: --max-pass-iterations=<int>. Maximum number of times to run the full set of delta passes (default=5). .. option:: --mtriple=<string> . Set the target triple. .. option:: --preserve-debug-environment. Don't disable features used for crash debugging (crash reports, llvm-symbolizer and core dumps). .. option:: --print-delta-passes . Print list of delta passes, passable to --delta-passes as a comma separated liste. .. option:: --skip-delta-passes=<string> . Delta passes to not run, separated by commas. By default, run all delta passes. .. option:: --starting-granularity-level=<uint>. Number of time",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst:304,Testability,test,test,304,"llvm-reduce - LLVM automatic testcase reducer.; ==============================================. .. program:: llvm-reduce. SYNOPSIS; --------. :program:`llvm-reduce` [*options*] [*input...*]. DESCRIPTION; -----------. The :program:`llvm-reduce` tool project that can be used for reducing the size of LLVM test cases.; It works by removing redundant or unnecessary code from LLVM test cases while still preserving ; their ability to detect bugs. If ``input`` is ""``-``"", :program:`llvm-reduce` reads from standard; input. Otherwise, it will read from the specified ``filenames``. LLVM-Reduce is a useful tool for reducing the size and ; complexity of LLVM test cases, making it easier to identify and debug issues in ; the LLVM compiler infrastructure. GENERIC OPTIONS; ---------------. .. option:: --help. Display available options (--help-hidden for more). .. option:: --abort-on-invalid-reduction. Abort if any reduction results in invalid IR. .. option::--delta-passes=<string> . Delta passes to run, separated by commas. By default, run all delta passes. .. option:: --in-place . WARNING: This option will replace your input file with the reduced version!. .. option:: --ir-passes=<string> . A textual description of the pass pipeline, same as what's passed to `opt -passes`. .. option:: -j <uint> . Maximum number of threads to use to process chunks. Set to 1 to disable parallelism. .. option:: --max-pass-iterations=<int>. Maximum number of times to run the full set of delta passes (default=5). .. option:: --mtriple=<string> . Set the target triple. .. option:: --preserve-debug-environment. Don't disable features used for crash debugging (crash reports, llvm-symbolizer and core dumps). .. option:: --print-delta-passes . Print list of delta passes, passable to --delta-passes as a comma separated liste. .. option:: --skip-delta-passes=<string> . Delta passes to not run, separated by commas. By default, run all delta passes. .. option:: --starting-granularity-level=<uint>. Number of time",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst:378,Testability,test,test,378,"llvm-reduce - LLVM automatic testcase reducer.; ==============================================. .. program:: llvm-reduce. SYNOPSIS; --------. :program:`llvm-reduce` [*options*] [*input...*]. DESCRIPTION; -----------. The :program:`llvm-reduce` tool project that can be used for reducing the size of LLVM test cases.; It works by removing redundant or unnecessary code from LLVM test cases while still preserving ; their ability to detect bugs. If ``input`` is ""``-``"", :program:`llvm-reduce` reads from standard; input. Otherwise, it will read from the specified ``filenames``. LLVM-Reduce is a useful tool for reducing the size and ; complexity of LLVM test cases, making it easier to identify and debug issues in ; the LLVM compiler infrastructure. GENERIC OPTIONS; ---------------. .. option:: --help. Display available options (--help-hidden for more). .. option:: --abort-on-invalid-reduction. Abort if any reduction results in invalid IR. .. option::--delta-passes=<string> . Delta passes to run, separated by commas. By default, run all delta passes. .. option:: --in-place . WARNING: This option will replace your input file with the reduced version!. .. option:: --ir-passes=<string> . A textual description of the pass pipeline, same as what's passed to `opt -passes`. .. option:: -j <uint> . Maximum number of threads to use to process chunks. Set to 1 to disable parallelism. .. option:: --max-pass-iterations=<int>. Maximum number of times to run the full set of delta passes (default=5). .. option:: --mtriple=<string> . Set the target triple. .. option:: --preserve-debug-environment. Don't disable features used for crash debugging (crash reports, llvm-symbolizer and core dumps). .. option:: --print-delta-passes . Print list of delta passes, passable to --delta-passes as a comma separated liste. .. option:: --skip-delta-passes=<string> . Delta passes to not run, separated by commas. By default, run all delta passes. .. option:: --starting-granularity-level=<uint>. Number of time",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst:654,Testability,test,test,654,"llvm-reduce - LLVM automatic testcase reducer.; ==============================================. .. program:: llvm-reduce. SYNOPSIS; --------. :program:`llvm-reduce` [*options*] [*input...*]. DESCRIPTION; -----------. The :program:`llvm-reduce` tool project that can be used for reducing the size of LLVM test cases.; It works by removing redundant or unnecessary code from LLVM test cases while still preserving ; their ability to detect bugs. If ``input`` is ""``-``"", :program:`llvm-reduce` reads from standard; input. Otherwise, it will read from the specified ``filenames``. LLVM-Reduce is a useful tool for reducing the size and ; complexity of LLVM test cases, making it easier to identify and debug issues in ; the LLVM compiler infrastructure. GENERIC OPTIONS; ---------------. .. option:: --help. Display available options (--help-hidden for more). .. option:: --abort-on-invalid-reduction. Abort if any reduction results in invalid IR. .. option::--delta-passes=<string> . Delta passes to run, separated by commas. By default, run all delta passes. .. option:: --in-place . WARNING: This option will replace your input file with the reduced version!. .. option:: --ir-passes=<string> . A textual description of the pass pipeline, same as what's passed to `opt -passes`. .. option:: -j <uint> . Maximum number of threads to use to process chunks. Set to 1 to disable parallelism. .. option:: --max-pass-iterations=<int>. Maximum number of times to run the full set of delta passes (default=5). .. option:: --mtriple=<string> . Set the target triple. .. option:: --preserve-debug-environment. Don't disable features used for crash debugging (crash reports, llvm-symbolizer and core dumps). .. option:: --print-delta-passes . Print list of delta passes, passable to --delta-passes as a comma separated liste. .. option:: --skip-delta-passes=<string> . Delta passes to not run, separated by commas. By default, run all delta passes. .. option:: --starting-granularity-level=<uint>. Number of time",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst:2035,Testability,test,test,2035,"by commas. By default, run all delta passes. .. option:: --in-place . WARNING: This option will replace your input file with the reduced version!. .. option:: --ir-passes=<string> . A textual description of the pass pipeline, same as what's passed to `opt -passes`. .. option:: -j <uint> . Maximum number of threads to use to process chunks. Set to 1 to disable parallelism. .. option:: --max-pass-iterations=<int>. Maximum number of times to run the full set of delta passes (default=5). .. option:: --mtriple=<string> . Set the target triple. .. option:: --preserve-debug-environment. Don't disable features used for crash debugging (crash reports, llvm-symbolizer and core dumps). .. option:: --print-delta-passes . Print list of delta passes, passable to --delta-passes as a comma separated liste. .. option:: --skip-delta-passes=<string> . Delta passes to not run, separated by commas. By default, run all delta passes. .. option:: --starting-granularity-level=<uint>. Number of times to divide chunks prior to first test. Note : Granularity refers to the level of detail at which the reduction process operates.; A lower granularity means that the reduction process operates at a more coarse-grained level,; while a higher granularity means that it operates at a more fine-grained level. .. option:: --test=<string> . Name of the interesting-ness test to be run. .. option:: --test-arg=<string> . Arguments passed onto the interesting-ness test. .. option:: --verbose . Print extra debugging information.; ; .. option:: --write-tmp-files-as-bitcode . Always write temporary files as bitcode instead of textual IR. .. option:: -x={ir|mir}. Input language as ir or mir. EXIT STATUS; ------------. :program:`llvm-reduce` returns 0 under normal operation. It returns a non-zero; exit code if there were any errors. EXAMPLE; -------. :program:`llvm-reduce` can be used to simplify a test that causes a; compiler crash. For example, let's assume that `opt` is crashing on the IR file; `test.ll` with ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst:2321,Testability,test,test,2321,"hreads to use to process chunks. Set to 1 to disable parallelism. .. option:: --max-pass-iterations=<int>. Maximum number of times to run the full set of delta passes (default=5). .. option:: --mtriple=<string> . Set the target triple. .. option:: --preserve-debug-environment. Don't disable features used for crash debugging (crash reports, llvm-symbolizer and core dumps). .. option:: --print-delta-passes . Print list of delta passes, passable to --delta-passes as a comma separated liste. .. option:: --skip-delta-passes=<string> . Delta passes to not run, separated by commas. By default, run all delta passes. .. option:: --starting-granularity-level=<uint>. Number of times to divide chunks prior to first test. Note : Granularity refers to the level of detail at which the reduction process operates.; A lower granularity means that the reduction process operates at a more coarse-grained level,; while a higher granularity means that it operates at a more fine-grained level. .. option:: --test=<string> . Name of the interesting-ness test to be run. .. option:: --test-arg=<string> . Arguments passed onto the interesting-ness test. .. option:: --verbose . Print extra debugging information.; ; .. option:: --write-tmp-files-as-bitcode . Always write temporary files as bitcode instead of textual IR. .. option:: -x={ir|mir}. Input language as ir or mir. EXIT STATUS; ------------. :program:`llvm-reduce` returns 0 under normal operation. It returns a non-zero; exit code if there were any errors. EXAMPLE; -------. :program:`llvm-reduce` can be used to simplify a test that causes a; compiler crash. For example, let's assume that `opt` is crashing on the IR file; `test.ll` with error message `Assertion failed at line 1234 of; WhateverFile.cpp`, when running at `-O2`. The test case of `test.ll` can be reduced by invoking the following; command:. .. code-block:: bash. $(LLVM_BUILD_FOLDER)/bin/llvm-reduce --test=script.sh <path to>/test.ll. The shell script passed to the option `test` ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst:2366,Testability,test,test,2366," to 1 to disable parallelism. .. option:: --max-pass-iterations=<int>. Maximum number of times to run the full set of delta passes (default=5). .. option:: --mtriple=<string> . Set the target triple. .. option:: --preserve-debug-environment. Don't disable features used for crash debugging (crash reports, llvm-symbolizer and core dumps). .. option:: --print-delta-passes . Print list of delta passes, passable to --delta-passes as a comma separated liste. .. option:: --skip-delta-passes=<string> . Delta passes to not run, separated by commas. By default, run all delta passes. .. option:: --starting-granularity-level=<uint>. Number of times to divide chunks prior to first test. Note : Granularity refers to the level of detail at which the reduction process operates.; A lower granularity means that the reduction process operates at a more coarse-grained level,; while a higher granularity means that it operates at a more fine-grained level. .. option:: --test=<string> . Name of the interesting-ness test to be run. .. option:: --test-arg=<string> . Arguments passed onto the interesting-ness test. .. option:: --verbose . Print extra debugging information.; ; .. option:: --write-tmp-files-as-bitcode . Always write temporary files as bitcode instead of textual IR. .. option:: -x={ir|mir}. Input language as ir or mir. EXIT STATUS; ------------. :program:`llvm-reduce` returns 0 under normal operation. It returns a non-zero; exit code if there were any errors. EXAMPLE; -------. :program:`llvm-reduce` can be used to simplify a test that causes a; compiler crash. For example, let's assume that `opt` is crashing on the IR file; `test.ll` with error message `Assertion failed at line 1234 of; WhateverFile.cpp`, when running at `-O2`. The test case of `test.ll` can be reduced by invoking the following; command:. .. code-block:: bash. $(LLVM_BUILD_FOLDER)/bin/llvm-reduce --test=script.sh <path to>/test.ll. The shell script passed to the option `test` consists of the; following:. .. code",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst:2396,Testability,test,test-arg,2396," --max-pass-iterations=<int>. Maximum number of times to run the full set of delta passes (default=5). .. option:: --mtriple=<string> . Set the target triple. .. option:: --preserve-debug-environment. Don't disable features used for crash debugging (crash reports, llvm-symbolizer and core dumps). .. option:: --print-delta-passes . Print list of delta passes, passable to --delta-passes as a comma separated liste. .. option:: --skip-delta-passes=<string> . Delta passes to not run, separated by commas. By default, run all delta passes. .. option:: --starting-granularity-level=<uint>. Number of times to divide chunks prior to first test. Note : Granularity refers to the level of detail at which the reduction process operates.; A lower granularity means that the reduction process operates at a more coarse-grained level,; while a higher granularity means that it operates at a more fine-grained level. .. option:: --test=<string> . Name of the interesting-ness test to be run. .. option:: --test-arg=<string> . Arguments passed onto the interesting-ness test. .. option:: --verbose . Print extra debugging information.; ; .. option:: --write-tmp-files-as-bitcode . Always write temporary files as bitcode instead of textual IR. .. option:: -x={ir|mir}. Input language as ir or mir. EXIT STATUS; ------------. :program:`llvm-reduce` returns 0 under normal operation. It returns a non-zero; exit code if there were any errors. EXAMPLE; -------. :program:`llvm-reduce` can be used to simplify a test that causes a; compiler crash. For example, let's assume that `opt` is crashing on the IR file; `test.ll` with error message `Assertion failed at line 1234 of; WhateverFile.cpp`, when running at `-O2`. The test case of `test.ll` can be reduced by invoking the following; command:. .. code-block:: bash. $(LLVM_BUILD_FOLDER)/bin/llvm-reduce --test=script.sh <path to>/test.ll. The shell script passed to the option `test` consists of the; following:. .. code-block:: bash. $(LLVM_BUILD_FOLDER)/bin/o",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst:2459,Testability,test,test,2459,"mber of times to run the full set of delta passes (default=5). .. option:: --mtriple=<string> . Set the target triple. .. option:: --preserve-debug-environment. Don't disable features used for crash debugging (crash reports, llvm-symbolizer and core dumps). .. option:: --print-delta-passes . Print list of delta passes, passable to --delta-passes as a comma separated liste. .. option:: --skip-delta-passes=<string> . Delta passes to not run, separated by commas. By default, run all delta passes. .. option:: --starting-granularity-level=<uint>. Number of times to divide chunks prior to first test. Note : Granularity refers to the level of detail at which the reduction process operates.; A lower granularity means that the reduction process operates at a more coarse-grained level,; while a higher granularity means that it operates at a more fine-grained level. .. option:: --test=<string> . Name of the interesting-ness test to be run. .. option:: --test-arg=<string> . Arguments passed onto the interesting-ness test. .. option:: --verbose . Print extra debugging information.; ; .. option:: --write-tmp-files-as-bitcode . Always write temporary files as bitcode instead of textual IR. .. option:: -x={ir|mir}. Input language as ir or mir. EXIT STATUS; ------------. :program:`llvm-reduce` returns 0 under normal operation. It returns a non-zero; exit code if there were any errors. EXAMPLE; -------. :program:`llvm-reduce` can be used to simplify a test that causes a; compiler crash. For example, let's assume that `opt` is crashing on the IR file; `test.ll` with error message `Assertion failed at line 1234 of; WhateverFile.cpp`, when running at `-O2`. The test case of `test.ll` can be reduced by invoking the following; command:. .. code-block:: bash. $(LLVM_BUILD_FOLDER)/bin/llvm-reduce --test=script.sh <path to>/test.ll. The shell script passed to the option `test` consists of the; following:. .. code-block:: bash. $(LLVM_BUILD_FOLDER)/bin/opt -O2 -disable-output $1 \; |& grep ""As",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst:2897,Testability,test,test,2897," dumps). .. option:: --print-delta-passes . Print list of delta passes, passable to --delta-passes as a comma separated liste. .. option:: --skip-delta-passes=<string> . Delta passes to not run, separated by commas. By default, run all delta passes. .. option:: --starting-granularity-level=<uint>. Number of times to divide chunks prior to first test. Note : Granularity refers to the level of detail at which the reduction process operates.; A lower granularity means that the reduction process operates at a more coarse-grained level,; while a higher granularity means that it operates at a more fine-grained level. .. option:: --test=<string> . Name of the interesting-ness test to be run. .. option:: --test-arg=<string> . Arguments passed onto the interesting-ness test. .. option:: --verbose . Print extra debugging information.; ; .. option:: --write-tmp-files-as-bitcode . Always write temporary files as bitcode instead of textual IR. .. option:: -x={ir|mir}. Input language as ir or mir. EXIT STATUS; ------------. :program:`llvm-reduce` returns 0 under normal operation. It returns a non-zero; exit code if there were any errors. EXAMPLE; -------. :program:`llvm-reduce` can be used to simplify a test that causes a; compiler crash. For example, let's assume that `opt` is crashing on the IR file; `test.ll` with error message `Assertion failed at line 1234 of; WhateverFile.cpp`, when running at `-O2`. The test case of `test.ll` can be reduced by invoking the following; command:. .. code-block:: bash. $(LLVM_BUILD_FOLDER)/bin/llvm-reduce --test=script.sh <path to>/test.ll. The shell script passed to the option `test` consists of the; following:. .. code-block:: bash. $(LLVM_BUILD_FOLDER)/bin/opt -O2 -disable-output $1 \; |& grep ""Assertion failed at line 1234 of WhateverFile.cpp"". (In this script, `grep` exits with 0 if it finds the string and that; becomes the whole script's status.). This example can be generalized to other tools that process IR files,; for example `llc`.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst:2999,Testability,test,test,2999," dumps). .. option:: --print-delta-passes . Print list of delta passes, passable to --delta-passes as a comma separated liste. .. option:: --skip-delta-passes=<string> . Delta passes to not run, separated by commas. By default, run all delta passes. .. option:: --starting-granularity-level=<uint>. Number of times to divide chunks prior to first test. Note : Granularity refers to the level of detail at which the reduction process operates.; A lower granularity means that the reduction process operates at a more coarse-grained level,; while a higher granularity means that it operates at a more fine-grained level. .. option:: --test=<string> . Name of the interesting-ness test to be run. .. option:: --test-arg=<string> . Arguments passed onto the interesting-ness test. .. option:: --verbose . Print extra debugging information.; ; .. option:: --write-tmp-files-as-bitcode . Always write temporary files as bitcode instead of textual IR. .. option:: -x={ir|mir}. Input language as ir or mir. EXIT STATUS; ------------. :program:`llvm-reduce` returns 0 under normal operation. It returns a non-zero; exit code if there were any errors. EXAMPLE; -------. :program:`llvm-reduce` can be used to simplify a test that causes a; compiler crash. For example, let's assume that `opt` is crashing on the IR file; `test.ll` with error message `Assertion failed at line 1234 of; WhateverFile.cpp`, when running at `-O2`. The test case of `test.ll` can be reduced by invoking the following; command:. .. code-block:: bash. $(LLVM_BUILD_FOLDER)/bin/llvm-reduce --test=script.sh <path to>/test.ll. The shell script passed to the option `test` consists of the; following:. .. code-block:: bash. $(LLVM_BUILD_FOLDER)/bin/opt -O2 -disable-output $1 \; |& grep ""Assertion failed at line 1234 of WhateverFile.cpp"". (In this script, `grep` exits with 0 if it finds the string and that; becomes the whole script's status.). This example can be generalized to other tools that process IR files,; for example `llc`.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst:3108,Testability,test,test,3108," dumps). .. option:: --print-delta-passes . Print list of delta passes, passable to --delta-passes as a comma separated liste. .. option:: --skip-delta-passes=<string> . Delta passes to not run, separated by commas. By default, run all delta passes. .. option:: --starting-granularity-level=<uint>. Number of times to divide chunks prior to first test. Note : Granularity refers to the level of detail at which the reduction process operates.; A lower granularity means that the reduction process operates at a more coarse-grained level,; while a higher granularity means that it operates at a more fine-grained level. .. option:: --test=<string> . Name of the interesting-ness test to be run. .. option:: --test-arg=<string> . Arguments passed onto the interesting-ness test. .. option:: --verbose . Print extra debugging information.; ; .. option:: --write-tmp-files-as-bitcode . Always write temporary files as bitcode instead of textual IR. .. option:: -x={ir|mir}. Input language as ir or mir. EXIT STATUS; ------------. :program:`llvm-reduce` returns 0 under normal operation. It returns a non-zero; exit code if there were any errors. EXAMPLE; -------. :program:`llvm-reduce` can be used to simplify a test that causes a; compiler crash. For example, let's assume that `opt` is crashing on the IR file; `test.ll` with error message `Assertion failed at line 1234 of; WhateverFile.cpp`, when running at `-O2`. The test case of `test.ll` can be reduced by invoking the following; command:. .. code-block:: bash. $(LLVM_BUILD_FOLDER)/bin/llvm-reduce --test=script.sh <path to>/test.ll. The shell script passed to the option `test` consists of the; following:. .. code-block:: bash. $(LLVM_BUILD_FOLDER)/bin/opt -O2 -disable-output $1 \; |& grep ""Assertion failed at line 1234 of WhateverFile.cpp"". (In this script, `grep` exits with 0 if it finds the string and that; becomes the whole script's status.). This example can be generalized to other tools that process IR files,; for example `llc`.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst:3122,Testability,test,test,3122," dumps). .. option:: --print-delta-passes . Print list of delta passes, passable to --delta-passes as a comma separated liste. .. option:: --skip-delta-passes=<string> . Delta passes to not run, separated by commas. By default, run all delta passes. .. option:: --starting-granularity-level=<uint>. Number of times to divide chunks prior to first test. Note : Granularity refers to the level of detail at which the reduction process operates.; A lower granularity means that the reduction process operates at a more coarse-grained level,; while a higher granularity means that it operates at a more fine-grained level. .. option:: --test=<string> . Name of the interesting-ness test to be run. .. option:: --test-arg=<string> . Arguments passed onto the interesting-ness test. .. option:: --verbose . Print extra debugging information.; ; .. option:: --write-tmp-files-as-bitcode . Always write temporary files as bitcode instead of textual IR. .. option:: -x={ir|mir}. Input language as ir or mir. EXIT STATUS; ------------. :program:`llvm-reduce` returns 0 under normal operation. It returns a non-zero; exit code if there were any errors. EXAMPLE; -------. :program:`llvm-reduce` can be used to simplify a test that causes a; compiler crash. For example, let's assume that `opt` is crashing on the IR file; `test.ll` with error message `Assertion failed at line 1234 of; WhateverFile.cpp`, when running at `-O2`. The test case of `test.ll` can be reduced by invoking the following; command:. .. code-block:: bash. $(LLVM_BUILD_FOLDER)/bin/llvm-reduce --test=script.sh <path to>/test.ll. The shell script passed to the option `test` consists of the; following:. .. code-block:: bash. $(LLVM_BUILD_FOLDER)/bin/opt -O2 -disable-output $1 \; |& grep ""Assertion failed at line 1234 of WhateverFile.cpp"". (In this script, `grep` exits with 0 if it finds the string and that; becomes the whole script's status.). This example can be generalized to other tools that process IR files,; for example `llc`.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst:3244,Testability,test,test,3244," dumps). .. option:: --print-delta-passes . Print list of delta passes, passable to --delta-passes as a comma separated liste. .. option:: --skip-delta-passes=<string> . Delta passes to not run, separated by commas. By default, run all delta passes. .. option:: --starting-granularity-level=<uint>. Number of times to divide chunks prior to first test. Note : Granularity refers to the level of detail at which the reduction process operates.; A lower granularity means that the reduction process operates at a more coarse-grained level,; while a higher granularity means that it operates at a more fine-grained level. .. option:: --test=<string> . Name of the interesting-ness test to be run. .. option:: --test-arg=<string> . Arguments passed onto the interesting-ness test. .. option:: --verbose . Print extra debugging information.; ; .. option:: --write-tmp-files-as-bitcode . Always write temporary files as bitcode instead of textual IR. .. option:: -x={ir|mir}. Input language as ir or mir. EXIT STATUS; ------------. :program:`llvm-reduce` returns 0 under normal operation. It returns a non-zero; exit code if there were any errors. EXAMPLE; -------. :program:`llvm-reduce` can be used to simplify a test that causes a; compiler crash. For example, let's assume that `opt` is crashing on the IR file; `test.ll` with error message `Assertion failed at line 1234 of; WhateverFile.cpp`, when running at `-O2`. The test case of `test.ll` can be reduced by invoking the following; command:. .. code-block:: bash. $(LLVM_BUILD_FOLDER)/bin/llvm-reduce --test=script.sh <path to>/test.ll. The shell script passed to the option `test` consists of the; following:. .. code-block:: bash. $(LLVM_BUILD_FOLDER)/bin/opt -O2 -disable-output $1 \; |& grep ""Assertion failed at line 1234 of WhateverFile.cpp"". (In this script, `grep` exits with 0 if it finds the string and that; becomes the whole script's status.). This example can be generalized to other tools that process IR files,; for example `llc`.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst:3269,Testability,test,test,3269," dumps). .. option:: --print-delta-passes . Print list of delta passes, passable to --delta-passes as a comma separated liste. .. option:: --skip-delta-passes=<string> . Delta passes to not run, separated by commas. By default, run all delta passes. .. option:: --starting-granularity-level=<uint>. Number of times to divide chunks prior to first test. Note : Granularity refers to the level of detail at which the reduction process operates.; A lower granularity means that the reduction process operates at a more coarse-grained level,; while a higher granularity means that it operates at a more fine-grained level. .. option:: --test=<string> . Name of the interesting-ness test to be run. .. option:: --test-arg=<string> . Arguments passed onto the interesting-ness test. .. option:: --verbose . Print extra debugging information.; ; .. option:: --write-tmp-files-as-bitcode . Always write temporary files as bitcode instead of textual IR. .. option:: -x={ir|mir}. Input language as ir or mir. EXIT STATUS; ------------. :program:`llvm-reduce` returns 0 under normal operation. It returns a non-zero; exit code if there were any errors. EXAMPLE; -------. :program:`llvm-reduce` can be used to simplify a test that causes a; compiler crash. For example, let's assume that `opt` is crashing on the IR file; `test.ll` with error message `Assertion failed at line 1234 of; WhateverFile.cpp`, when running at `-O2`. The test case of `test.ll` can be reduced by invoking the following; command:. .. code-block:: bash. $(LLVM_BUILD_FOLDER)/bin/llvm-reduce --test=script.sh <path to>/test.ll. The shell script passed to the option `test` consists of the; following:. .. code-block:: bash. $(LLVM_BUILD_FOLDER)/bin/opt -O2 -disable-output $1 \; |& grep ""Assertion failed at line 1234 of WhateverFile.cpp"". (In this script, `grep` exits with 0 if it finds the string and that; becomes the whole script's status.). This example can be generalized to other tools that process IR files,; for example `llc`.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst:3317,Testability,test,test,3317," dumps). .. option:: --print-delta-passes . Print list of delta passes, passable to --delta-passes as a comma separated liste. .. option:: --skip-delta-passes=<string> . Delta passes to not run, separated by commas. By default, run all delta passes. .. option:: --starting-granularity-level=<uint>. Number of times to divide chunks prior to first test. Note : Granularity refers to the level of detail at which the reduction process operates.; A lower granularity means that the reduction process operates at a more coarse-grained level,; while a higher granularity means that it operates at a more fine-grained level. .. option:: --test=<string> . Name of the interesting-ness test to be run. .. option:: --test-arg=<string> . Arguments passed onto the interesting-ness test. .. option:: --verbose . Print extra debugging information.; ; .. option:: --write-tmp-files-as-bitcode . Always write temporary files as bitcode instead of textual IR. .. option:: -x={ir|mir}. Input language as ir or mir. EXIT STATUS; ------------. :program:`llvm-reduce` returns 0 under normal operation. It returns a non-zero; exit code if there were any errors. EXAMPLE; -------. :program:`llvm-reduce` can be used to simplify a test that causes a; compiler crash. For example, let's assume that `opt` is crashing on the IR file; `test.ll` with error message `Assertion failed at line 1234 of; WhateverFile.cpp`, when running at `-O2`. The test case of `test.ll` can be reduced by invoking the following; command:. .. code-block:: bash. $(LLVM_BUILD_FOLDER)/bin/llvm-reduce --test=script.sh <path to>/test.ll. The shell script passed to the option `test` consists of the; following:. .. code-block:: bash. $(LLVM_BUILD_FOLDER)/bin/opt -O2 -disable-output $1 \; |& grep ""Assertion failed at line 1234 of WhateverFile.cpp"". (In this script, `grep` exits with 0 if it finds the string and that; becomes the whole script's status.). This example can be generalized to other tools that process IR files,; for example `llc`.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst:2886,Usability,simpl,simplify,2886," dumps). .. option:: --print-delta-passes . Print list of delta passes, passable to --delta-passes as a comma separated liste. .. option:: --skip-delta-passes=<string> . Delta passes to not run, separated by commas. By default, run all delta passes. .. option:: --starting-granularity-level=<uint>. Number of times to divide chunks prior to first test. Note : Granularity refers to the level of detail at which the reduction process operates.; A lower granularity means that the reduction process operates at a more coarse-grained level,; while a higher granularity means that it operates at a more fine-grained level. .. option:: --test=<string> . Name of the interesting-ness test to be run. .. option:: --test-arg=<string> . Arguments passed onto the interesting-ness test. .. option:: --verbose . Print extra debugging information.; ; .. option:: --write-tmp-files-as-bitcode . Always write temporary files as bitcode instead of textual IR. .. option:: -x={ir|mir}. Input language as ir or mir. EXIT STATUS; ------------. :program:`llvm-reduce` returns 0 under normal operation. It returns a non-zero; exit code if there were any errors. EXAMPLE; -------. :program:`llvm-reduce` can be used to simplify a test that causes a; compiler crash. For example, let's assume that `opt` is crashing on the IR file; `test.ll` with error message `Assertion failed at line 1234 of; WhateverFile.cpp`, when running at `-O2`. The test case of `test.ll` can be reduced by invoking the following; command:. .. code-block:: bash. $(LLVM_BUILD_FOLDER)/bin/llvm-reduce --test=script.sh <path to>/test.ll. The shell script passed to the option `test` consists of the; following:. .. code-block:: bash. $(LLVM_BUILD_FOLDER)/bin/opt -O2 -disable-output $1 \; |& grep ""Assertion failed at line 1234 of WhateverFile.cpp"". (In this script, `grep` exits with 0 if it finds the string and that; becomes the whole script's status.). This example can be generalized to other tools that process IR files,; for example `llc`.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-reduce.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-remarkutil.rst:5424,Availability,failure,failure,5424,pecified remark arguments represented as a comma separated string.; The arguments must have a numeral value to be able to count remarks by. .. option:: --rargs[=arguments]; If `count-by` is set to `arg` this flag can be used to collect from specified remark arguments using regular expression.; The arguments must have a numeral value to be able to count remarks by. .. option:: --pass-name[=<string>]; Filter count by pass name. .. option:: --rpass-name[=<string>]; Filter count by pass name using regular expressions. .. option:: --remark-name[=<string>]; Filter count by remark name. .. option:: --rremark-name[=<string>]; Filter count by remark name using regular expressions. .. option:: --filter-arg-by[=<string>]; Filter count by argument value. .. option:: --rfilter-arg-by[=<string>]; Filter count by argument value using regular expressions. .. option:: --remark-type=<value>; Filter remarks by type with the following options.; * ``unknown``; * ``passed``; * ``missed``; * ``analysis``; * ``analysis-fp-commute``; * ``analysis-aliasing``; * ``failure``. .. _size-diff_subcommand:. size-diff; ~~~~~~~~~; .. program:: llvm-remarkutil size-diff. USAGE: :program:`llvm-remarkutil` size-diff [*options*] *file_a* *file_b* **--parser** *parser*. Summary; ^^^^^^^. :program:`llvm-remarkutil size-diff` diffs size `remarks <https://llvm.org/docs/Remarks.html>`_ in two remark files: ``file_a``; and ``file_b``. :program:`llvm-remarkutil size-diff` can be used to gain insight into which; functions were impacted the most by code generation changes. In most common use-cases ``file_a`` and ``file_b`` will be remarks output by; compiling a **fixed source** with **differing compilers** or; **differing optimization settings**. :program:`llvm-remarkutil size-diff` handles both; `YAML <https://llvm.org/docs/Remarks.html#yaml-remarks>`_ and; `bitstream <https://llvm.org/docs/Remarks.html#llvm-bitstream-remarks>`_; remarks. OPTIONS; -------. .. option:: --parser=<yaml|bitstream>. Select the type of,MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-remarkutil.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-remarkutil.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-remarkutil.rst:6074,Performance,optimiz,optimization,6074,"by remark name using regular expressions. .. option:: --filter-arg-by[=<string>]; Filter count by argument value. .. option:: --rfilter-arg-by[=<string>]; Filter count by argument value using regular expressions. .. option:: --remark-type=<value>; Filter remarks by type with the following options.; * ``unknown``; * ``passed``; * ``missed``; * ``analysis``; * ``analysis-fp-commute``; * ``analysis-aliasing``; * ``failure``. .. _size-diff_subcommand:. size-diff; ~~~~~~~~~; .. program:: llvm-remarkutil size-diff. USAGE: :program:`llvm-remarkutil` size-diff [*options*] *file_a* *file_b* **--parser** *parser*. Summary; ^^^^^^^. :program:`llvm-remarkutil size-diff` diffs size `remarks <https://llvm.org/docs/Remarks.html>`_ in two remark files: ``file_a``; and ``file_b``. :program:`llvm-remarkutil size-diff` can be used to gain insight into which; functions were impacted the most by code generation changes. In most common use-cases ``file_a`` and ``file_b`` will be remarks output by; compiling a **fixed source** with **differing compilers** or; **differing optimization settings**. :program:`llvm-remarkutil size-diff` handles both; `YAML <https://llvm.org/docs/Remarks.html#yaml-remarks>`_ and; `bitstream <https://llvm.org/docs/Remarks.html#llvm-bitstream-remarks>`_; remarks. OPTIONS; -------. .. option:: --parser=<yaml|bitstream>. Select the type of input remark parser. Required.; * ``yaml``: The tool will parse YAML remarks.; * ``bitstream``: The tool will parse bitstream remarks. .. option:: --report-style=<human|json>. Output style.; * ``human``: Human-readable textual report. Default option.; * ``json``: JSON report. .. option:: --pretty. Pretty-print JSON output. Optional. If output is not set to JSON, this does nothing. .. option:: -o=<file>. Output file for the report. Outputs to stdout by default. HUMAN-READABLE OUTPUT; ---------------------. The human-readable format for :program:`llvm-remarkutil size-diff` is composed of; two sections:. * Per-function changes.; * A ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-remarkutil.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-remarkutil.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-size.rst:4388,Availability,error,error,4388," different; file format is specified, :program:`llvm-size` falls back to ``berkeley``; format. When producing ``darwin`` format, the tool displays information about; segments and sections:. .. code-block:: console. $ llvm-size --format=darwin macho.obj macho2.obj; macho.obj:; Segment : 12; Section (__TEXT, __text): 4; Section (__DATA, __data): 8; total 12; total 12; macho2.obj:; Segment : 48; Section (__TEXT, __text): 16; Section (__DATA, __data): 32; total 48; total 48. .. option:: --help, -h. Display a summary of command line options. .. option:: -m. Equivalent to :option:`--format` with a value of ``darwin``. .. option:: -o. Equivalent to :option:`--radix` with a value of ``8``. .. option:: --radix=<value>. Display size information in the specified radix. Permitted values are ``8``,; ``10`` (the default) and ``16`` for octal, decimal and hexadecimal output; respectively. Example:. .. code-block:: console. $ llvm-size --radix=8 test.o; text data bss oct hex filename; 0152 04 04 162 72 test.o. $ llvm-size --radix=10 test.o; text data bss dec hex filename; 106 4 4 114 72 test.o. $ llvm-size --radix=16 test.o; text data bss dec hex filename; 0x6a 0x4 0x4 114 72 test.o. .. option:: --totals, -t. Applies only to ``berkeley`` output format. Display the totals for all listed; fields, in addition to the individual file listings. Example:. .. code-block:: console. $ llvm-size --totals test.elf test2.o; text data bss dec hex filename; 182 16 5 203 cb test.elf; 82 8 1 91 5b test2.o; 264 24 6 294 126 (TOTALS). .. option:: --version. Display the version of the :program:`llvm-size` executable. .. option:: -x. Equivalent to :option:`--radix` with a value of ``16``. .. option:: @<FILE>. Read command-line options from response file ``<FILE>``. EXIT STATUS; -----------. :program:`llvm-size` exits with a non-zero exit code if there is an error.; Otherwise, it exits with code 0. BUGS; ----. To report bugs, please visit <https://github.com/llvm/llvm-project/labels/tools:llvm-size/>.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-size.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-size.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-size.rst:1688,Testability,test,test,1688,"TIONS; -------. .. option:: -A. Equivalent to :option:`--format` with a value of ``sysv``. .. option:: --arch=<arch>. Architecture(s) from Mach-O universal binaries to display information for. .. option:: -B. Equivalent to :option:`--format` with a value of ``berkeley``. .. option:: --common. Include ELF common symbol sizes in bss size for ``berkeley`` output format, or; as a separate section entry for ``sysv`` output. If not specified, these; symbols are ignored. .. option:: -d. Equivalent to :option:`--radix` with a value of ``10``. .. option:: -l. Display verbose address and offset information for segments and sections in; Mach-O files in ``darwin`` format. .. option:: --format=<format>. Set the output format to the ``<format>`` specified. Available ``<format>``; options are ``berkeley`` (the default), ``sysv`` and ``darwin``. Berkeley output summarises text, data and bss sizes in each file, as shown; below for a typical pair of ELF files:. .. code-block:: console. $ llvm-size --format=berkeley test.o test2.o; text data bss dec hex filename; 182 16 5 203 cb test.elf; 82 8 1 91 5b test2.o. For Mach-O files, the output format is slightly different:. .. code-block:: console. $ llvm-size --format=berkeley macho.obj macho2.obj; __TEXT __DATA __OBJC others dec hex; 4 8 0 0 12 c macho.obj; 16 32 0 0 48 30 macho2.obj. Sysv output displays size and address information for most sections, with each; file being listed separately:. .. code-block:: console. $ llvm-size --format=sysv test.elf test2.o; test.elf :; section size addr; .eh_frame 92 2097496; .text 90 2101248; .data 16 2105344; .bss 5 2105360; .comment 209 0; Total 412. test2.o :; section size addr; .text 26 0; .data 8 0; .bss 1 0; .comment 106 0; .note.GNU-stack 0 0; .eh_frame 56 0; .llvm_addrsig 2 0; Total 199. ``darwin`` format only affects Mach-O input files. If an input of a different; file format is specified, :program:`llvm-size` falls back to ``berkeley``; format. When producing ``darwin`` format, the tool di",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-size.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-size.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-size.rst:1752,Testability,test,test,1752,"`--format` with a value of ``sysv``. .. option:: --arch=<arch>. Architecture(s) from Mach-O universal binaries to display information for. .. option:: -B. Equivalent to :option:`--format` with a value of ``berkeley``. .. option:: --common. Include ELF common symbol sizes in bss size for ``berkeley`` output format, or; as a separate section entry for ``sysv`` output. If not specified, these; symbols are ignored. .. option:: -d. Equivalent to :option:`--radix` with a value of ``10``. .. option:: -l. Display verbose address and offset information for segments and sections in; Mach-O files in ``darwin`` format. .. option:: --format=<format>. Set the output format to the ``<format>`` specified. Available ``<format>``; options are ``berkeley`` (the default), ``sysv`` and ``darwin``. Berkeley output summarises text, data and bss sizes in each file, as shown; below for a typical pair of ELF files:. .. code-block:: console. $ llvm-size --format=berkeley test.o test2.o; text data bss dec hex filename; 182 16 5 203 cb test.elf; 82 8 1 91 5b test2.o. For Mach-O files, the output format is slightly different:. .. code-block:: console. $ llvm-size --format=berkeley macho.obj macho2.obj; __TEXT __DATA __OBJC others dec hex; 4 8 0 0 12 c macho.obj; 16 32 0 0 48 30 macho2.obj. Sysv output displays size and address information for most sections, with each; file being listed separately:. .. code-block:: console. $ llvm-size --format=sysv test.elf test2.o; test.elf :; section size addr; .eh_frame 92 2097496; .text 90 2101248; .data 16 2105344; .bss 5 2105360; .comment 209 0; Total 412. test2.o :; section size addr; .text 26 0; .data 8 0; .bss 1 0; .comment 106 0; .note.GNU-stack 0 0; .eh_frame 56 0; .llvm_addrsig 2 0; Total 199. ``darwin`` format only affects Mach-O input files. If an input of a different; file format is specified, :program:`llvm-size` falls back to ``berkeley``; format. When producing ``darwin`` format, the tool displays information about; segments and sections:. .. c",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-size.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-size.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-size.rst:2172,Testability,test,test,2172,"quivalent to :option:`--radix` with a value of ``10``. .. option:: -l. Display verbose address and offset information for segments and sections in; Mach-O files in ``darwin`` format. .. option:: --format=<format>. Set the output format to the ``<format>`` specified. Available ``<format>``; options are ``berkeley`` (the default), ``sysv`` and ``darwin``. Berkeley output summarises text, data and bss sizes in each file, as shown; below for a typical pair of ELF files:. .. code-block:: console. $ llvm-size --format=berkeley test.o test2.o; text data bss dec hex filename; 182 16 5 203 cb test.elf; 82 8 1 91 5b test2.o. For Mach-O files, the output format is slightly different:. .. code-block:: console. $ llvm-size --format=berkeley macho.obj macho2.obj; __TEXT __DATA __OBJC others dec hex; 4 8 0 0 12 c macho.obj; 16 32 0 0 48 30 macho2.obj. Sysv output displays size and address information for most sections, with each; file being listed separately:. .. code-block:: console. $ llvm-size --format=sysv test.elf test2.o; test.elf :; section size addr; .eh_frame 92 2097496; .text 90 2101248; .data 16 2105344; .bss 5 2105360; .comment 209 0; Total 412. test2.o :; section size addr; .text 26 0; .data 8 0; .bss 1 0; .comment 106 0; .note.GNU-stack 0 0; .eh_frame 56 0; .llvm_addrsig 2 0; Total 199. ``darwin`` format only affects Mach-O input files. If an input of a different; file format is specified, :program:`llvm-size` falls back to ``berkeley``; format. When producing ``darwin`` format, the tool displays information about; segments and sections:. .. code-block:: console. $ llvm-size --format=darwin macho.obj macho2.obj; macho.obj:; Segment : 12; Section (__TEXT, __text): 4; Section (__DATA, __data): 8; total 12; total 12; macho2.obj:; Segment : 48; Section (__TEXT, __text): 16; Section (__DATA, __data): 32; total 48; total 48. .. option:: --help, -h. Display a summary of command line options. .. option:: -m. Equivalent to :option:`--format` with a value of ``darwin``. .. opt",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-size.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-size.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-size.rst:2190,Testability,test,test,2190," with a value of ``10``. .. option:: -l. Display verbose address and offset information for segments and sections in; Mach-O files in ``darwin`` format. .. option:: --format=<format>. Set the output format to the ``<format>`` specified. Available ``<format>``; options are ``berkeley`` (the default), ``sysv`` and ``darwin``. Berkeley output summarises text, data and bss sizes in each file, as shown; below for a typical pair of ELF files:. .. code-block:: console. $ llvm-size --format=berkeley test.o test2.o; text data bss dec hex filename; 182 16 5 203 cb test.elf; 82 8 1 91 5b test2.o. For Mach-O files, the output format is slightly different:. .. code-block:: console. $ llvm-size --format=berkeley macho.obj macho2.obj; __TEXT __DATA __OBJC others dec hex; 4 8 0 0 12 c macho.obj; 16 32 0 0 48 30 macho2.obj. Sysv output displays size and address information for most sections, with each; file being listed separately:. .. code-block:: console. $ llvm-size --format=sysv test.elf test2.o; test.elf :; section size addr; .eh_frame 92 2097496; .text 90 2101248; .data 16 2105344; .bss 5 2105360; .comment 209 0; Total 412. test2.o :; section size addr; .text 26 0; .data 8 0; .bss 1 0; .comment 106 0; .note.GNU-stack 0 0; .eh_frame 56 0; .llvm_addrsig 2 0; Total 199. ``darwin`` format only affects Mach-O input files. If an input of a different; file format is specified, :program:`llvm-size` falls back to ``berkeley``; format. When producing ``darwin`` format, the tool displays information about; segments and sections:. .. code-block:: console. $ llvm-size --format=darwin macho.obj macho2.obj; macho.obj:; Segment : 12; Section (__TEXT, __text): 4; Section (__DATA, __data): 8; total 12; total 12; macho2.obj:; Segment : 48; Section (__TEXT, __text): 16; Section (__DATA, __data): 32; total 48; total 48. .. option:: --help, -h. Display a summary of command line options. .. option:: -m. Equivalent to :option:`--format` with a value of ``darwin``. .. option:: -o. Equivalent to :optio",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-size.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-size.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-size.rst:3479,Testability,test,test,3479,"darwin`` format only affects Mach-O input files. If an input of a different; file format is specified, :program:`llvm-size` falls back to ``berkeley``; format. When producing ``darwin`` format, the tool displays information about; segments and sections:. .. code-block:: console. $ llvm-size --format=darwin macho.obj macho2.obj; macho.obj:; Segment : 12; Section (__TEXT, __text): 4; Section (__DATA, __data): 8; total 12; total 12; macho2.obj:; Segment : 48; Section (__TEXT, __text): 16; Section (__DATA, __data): 32; total 48; total 48. .. option:: --help, -h. Display a summary of command line options. .. option:: -m. Equivalent to :option:`--format` with a value of ``darwin``. .. option:: -o. Equivalent to :option:`--radix` with a value of ``8``. .. option:: --radix=<value>. Display size information in the specified radix. Permitted values are ``8``,; ``10`` (the default) and ``16`` for octal, decimal and hexadecimal output; respectively. Example:. .. code-block:: console. $ llvm-size --radix=8 test.o; text data bss oct hex filename; 0152 04 04 162 72 test.o. $ llvm-size --radix=10 test.o; text data bss dec hex filename; 106 4 4 114 72 test.o. $ llvm-size --radix=16 test.o; text data bss dec hex filename; 0x6a 0x4 0x4 114 72 test.o. .. option:: --totals, -t. Applies only to ``berkeley`` output format. Display the totals for all listed; fields, in addition to the individual file listings. Example:. .. code-block:: console. $ llvm-size --totals test.elf test2.o; text data bss dec hex filename; 182 16 5 203 cb test.elf; 82 8 1 91 5b test2.o; 264 24 6 294 126 (TOTALS). .. option:: --version. Display the version of the :program:`llvm-size` executable. .. option:: -x. Equivalent to :option:`--radix` with a value of ``16``. .. option:: @<FILE>. Read command-line options from response file ``<FILE>``. EXIT STATUS; -----------. :program:`llvm-size` exits with a non-zero exit code if there is an error.; Otherwise, it exits with code 0. BUGS; ----. To report bugs, please visit ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-size.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-size.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-size.rst:3537,Testability,test,test,3537,"iles. If an input of a different; file format is specified, :program:`llvm-size` falls back to ``berkeley``; format. When producing ``darwin`` format, the tool displays information about; segments and sections:. .. code-block:: console. $ llvm-size --format=darwin macho.obj macho2.obj; macho.obj:; Segment : 12; Section (__TEXT, __text): 4; Section (__DATA, __data): 8; total 12; total 12; macho2.obj:; Segment : 48; Section (__TEXT, __text): 16; Section (__DATA, __data): 32; total 48; total 48. .. option:: --help, -h. Display a summary of command line options. .. option:: -m. Equivalent to :option:`--format` with a value of ``darwin``. .. option:: -o. Equivalent to :option:`--radix` with a value of ``8``. .. option:: --radix=<value>. Display size information in the specified radix. Permitted values are ``8``,; ``10`` (the default) and ``16`` for octal, decimal and hexadecimal output; respectively. Example:. .. code-block:: console. $ llvm-size --radix=8 test.o; text data bss oct hex filename; 0152 04 04 162 72 test.o. $ llvm-size --radix=10 test.o; text data bss dec hex filename; 106 4 4 114 72 test.o. $ llvm-size --radix=16 test.o; text data bss dec hex filename; 0x6a 0x4 0x4 114 72 test.o. .. option:: --totals, -t. Applies only to ``berkeley`` output format. Display the totals for all listed; fields, in addition to the individual file listings. Example:. .. code-block:: console. $ llvm-size --totals test.elf test2.o; text data bss dec hex filename; 182 16 5 203 cb test.elf; 82 8 1 91 5b test2.o; 264 24 6 294 126 (TOTALS). .. option:: --version. Display the version of the :program:`llvm-size` executable. .. option:: -x. Equivalent to :option:`--radix` with a value of ``16``. .. option:: @<FILE>. Read command-line options from response file ``<FILE>``. EXIT STATUS; -----------. :program:`llvm-size` exits with a non-zero exit code if there is an error.; Otherwise, it exits with code 0. BUGS; ----. To report bugs, please visit <https://github.com/llvm/llvm-project/label",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-size.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-size.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-size.rst:3568,Testability,test,test,3568," different; file format is specified, :program:`llvm-size` falls back to ``berkeley``; format. When producing ``darwin`` format, the tool displays information about; segments and sections:. .. code-block:: console. $ llvm-size --format=darwin macho.obj macho2.obj; macho.obj:; Segment : 12; Section (__TEXT, __text): 4; Section (__DATA, __data): 8; total 12; total 12; macho2.obj:; Segment : 48; Section (__TEXT, __text): 16; Section (__DATA, __data): 32; total 48; total 48. .. option:: --help, -h. Display a summary of command line options. .. option:: -m. Equivalent to :option:`--format` with a value of ``darwin``. .. option:: -o. Equivalent to :option:`--radix` with a value of ``8``. .. option:: --radix=<value>. Display size information in the specified radix. Permitted values are ``8``,; ``10`` (the default) and ``16`` for octal, decimal and hexadecimal output; respectively. Example:. .. code-block:: console. $ llvm-size --radix=8 test.o; text data bss oct hex filename; 0152 04 04 162 72 test.o. $ llvm-size --radix=10 test.o; text data bss dec hex filename; 106 4 4 114 72 test.o. $ llvm-size --radix=16 test.o; text data bss dec hex filename; 0x6a 0x4 0x4 114 72 test.o. .. option:: --totals, -t. Applies only to ``berkeley`` output format. Display the totals for all listed; fields, in addition to the individual file listings. Example:. .. code-block:: console. $ llvm-size --totals test.elf test2.o; text data bss dec hex filename; 182 16 5 203 cb test.elf; 82 8 1 91 5b test2.o; 264 24 6 294 126 (TOTALS). .. option:: --version. Display the version of the :program:`llvm-size` executable. .. option:: -x. Equivalent to :option:`--radix` with a value of ``16``. .. option:: @<FILE>. Read command-line options from response file ``<FILE>``. EXIT STATUS; -----------. :program:`llvm-size` exits with a non-zero exit code if there is an error.; Otherwise, it exits with code 0. BUGS; ----. To report bugs, please visit <https://github.com/llvm/llvm-project/labels/tools:llvm-size/>.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-size.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-size.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-size.rst:3623,Testability,test,test,3623," different; file format is specified, :program:`llvm-size` falls back to ``berkeley``; format. When producing ``darwin`` format, the tool displays information about; segments and sections:. .. code-block:: console. $ llvm-size --format=darwin macho.obj macho2.obj; macho.obj:; Segment : 12; Section (__TEXT, __text): 4; Section (__DATA, __data): 8; total 12; total 12; macho2.obj:; Segment : 48; Section (__TEXT, __text): 16; Section (__DATA, __data): 32; total 48; total 48. .. option:: --help, -h. Display a summary of command line options. .. option:: -m. Equivalent to :option:`--format` with a value of ``darwin``. .. option:: -o. Equivalent to :option:`--radix` with a value of ``8``. .. option:: --radix=<value>. Display size information in the specified radix. Permitted values are ``8``,; ``10`` (the default) and ``16`` for octal, decimal and hexadecimal output; respectively. Example:. .. code-block:: console. $ llvm-size --radix=8 test.o; text data bss oct hex filename; 0152 04 04 162 72 test.o. $ llvm-size --radix=10 test.o; text data bss dec hex filename; 106 4 4 114 72 test.o. $ llvm-size --radix=16 test.o; text data bss dec hex filename; 0x6a 0x4 0x4 114 72 test.o. .. option:: --totals, -t. Applies only to ``berkeley`` output format. Display the totals for all listed; fields, in addition to the individual file listings. Example:. .. code-block:: console. $ llvm-size --totals test.elf test2.o; text data bss dec hex filename; 182 16 5 203 cb test.elf; 82 8 1 91 5b test2.o; 264 24 6 294 126 (TOTALS). .. option:: --version. Display the version of the :program:`llvm-size` executable. .. option:: -x. Equivalent to :option:`--radix` with a value of ``16``. .. option:: @<FILE>. Read command-line options from response file ``<FILE>``. EXIT STATUS; -----------. :program:`llvm-size` exits with a non-zero exit code if there is an error.; Otherwise, it exits with code 0. BUGS; ----. To report bugs, please visit <https://github.com/llvm/llvm-project/labels/tools:llvm-size/>.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-size.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-size.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-size.rst:3654,Testability,test,test,3654," different; file format is specified, :program:`llvm-size` falls back to ``berkeley``; format. When producing ``darwin`` format, the tool displays information about; segments and sections:. .. code-block:: console. $ llvm-size --format=darwin macho.obj macho2.obj; macho.obj:; Segment : 12; Section (__TEXT, __text): 4; Section (__DATA, __data): 8; total 12; total 12; macho2.obj:; Segment : 48; Section (__TEXT, __text): 16; Section (__DATA, __data): 32; total 48; total 48. .. option:: --help, -h. Display a summary of command line options. .. option:: -m. Equivalent to :option:`--format` with a value of ``darwin``. .. option:: -o. Equivalent to :option:`--radix` with a value of ``8``. .. option:: --radix=<value>. Display size information in the specified radix. Permitted values are ``8``,; ``10`` (the default) and ``16`` for octal, decimal and hexadecimal output; respectively. Example:. .. code-block:: console. $ llvm-size --radix=8 test.o; text data bss oct hex filename; 0152 04 04 162 72 test.o. $ llvm-size --radix=10 test.o; text data bss dec hex filename; 106 4 4 114 72 test.o. $ llvm-size --radix=16 test.o; text data bss dec hex filename; 0x6a 0x4 0x4 114 72 test.o. .. option:: --totals, -t. Applies only to ``berkeley`` output format. Display the totals for all listed; fields, in addition to the individual file listings. Example:. .. code-block:: console. $ llvm-size --totals test.elf test2.o; text data bss dec hex filename; 182 16 5 203 cb test.elf; 82 8 1 91 5b test2.o; 264 24 6 294 126 (TOTALS). .. option:: --version. Display the version of the :program:`llvm-size` executable. .. option:: -x. Equivalent to :option:`--radix` with a value of ``16``. .. option:: @<FILE>. Read command-line options from response file ``<FILE>``. EXIT STATUS; -----------. :program:`llvm-size` exits with a non-zero exit code if there is an error.; Otherwise, it exits with code 0. BUGS; ----. To report bugs, please visit <https://github.com/llvm/llvm-project/labels/tools:llvm-size/>.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-size.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-size.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-size.rst:3714,Testability,test,test,3714," different; file format is specified, :program:`llvm-size` falls back to ``berkeley``; format. When producing ``darwin`` format, the tool displays information about; segments and sections:. .. code-block:: console. $ llvm-size --format=darwin macho.obj macho2.obj; macho.obj:; Segment : 12; Section (__TEXT, __text): 4; Section (__DATA, __data): 8; total 12; total 12; macho2.obj:; Segment : 48; Section (__TEXT, __text): 16; Section (__DATA, __data): 32; total 48; total 48. .. option:: --help, -h. Display a summary of command line options. .. option:: -m. Equivalent to :option:`--format` with a value of ``darwin``. .. option:: -o. Equivalent to :option:`--radix` with a value of ``8``. .. option:: --radix=<value>. Display size information in the specified radix. Permitted values are ``8``,; ``10`` (the default) and ``16`` for octal, decimal and hexadecimal output; respectively. Example:. .. code-block:: console. $ llvm-size --radix=8 test.o; text data bss oct hex filename; 0152 04 04 162 72 test.o. $ llvm-size --radix=10 test.o; text data bss dec hex filename; 106 4 4 114 72 test.o. $ llvm-size --radix=16 test.o; text data bss dec hex filename; 0x6a 0x4 0x4 114 72 test.o. .. option:: --totals, -t. Applies only to ``berkeley`` output format. Display the totals for all listed; fields, in addition to the individual file listings. Example:. .. code-block:: console. $ llvm-size --totals test.elf test2.o; text data bss dec hex filename; 182 16 5 203 cb test.elf; 82 8 1 91 5b test2.o; 264 24 6 294 126 (TOTALS). .. option:: --version. Display the version of the :program:`llvm-size` executable. .. option:: -x. Equivalent to :option:`--radix` with a value of ``16``. .. option:: @<FILE>. Read command-line options from response file ``<FILE>``. EXIT STATUS; -----------. :program:`llvm-size` exits with a non-zero exit code if there is an error.; Otherwise, it exits with code 0. BUGS; ----. To report bugs, please visit <https://github.com/llvm/llvm-project/labels/tools:llvm-size/>.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-size.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-size.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-size.rst:3936,Testability,test,test,3936," different; file format is specified, :program:`llvm-size` falls back to ``berkeley``; format. When producing ``darwin`` format, the tool displays information about; segments and sections:. .. code-block:: console. $ llvm-size --format=darwin macho.obj macho2.obj; macho.obj:; Segment : 12; Section (__TEXT, __text): 4; Section (__DATA, __data): 8; total 12; total 12; macho2.obj:; Segment : 48; Section (__TEXT, __text): 16; Section (__DATA, __data): 32; total 48; total 48. .. option:: --help, -h. Display a summary of command line options. .. option:: -m. Equivalent to :option:`--format` with a value of ``darwin``. .. option:: -o. Equivalent to :option:`--radix` with a value of ``8``. .. option:: --radix=<value>. Display size information in the specified radix. Permitted values are ``8``,; ``10`` (the default) and ``16`` for octal, decimal and hexadecimal output; respectively. Example:. .. code-block:: console. $ llvm-size --radix=8 test.o; text data bss oct hex filename; 0152 04 04 162 72 test.o. $ llvm-size --radix=10 test.o; text data bss dec hex filename; 106 4 4 114 72 test.o. $ llvm-size --radix=16 test.o; text data bss dec hex filename; 0x6a 0x4 0x4 114 72 test.o. .. option:: --totals, -t. Applies only to ``berkeley`` output format. Display the totals for all listed; fields, in addition to the individual file listings. Example:. .. code-block:: console. $ llvm-size --totals test.elf test2.o; text data bss dec hex filename; 182 16 5 203 cb test.elf; 82 8 1 91 5b test2.o; 264 24 6 294 126 (TOTALS). .. option:: --version. Display the version of the :program:`llvm-size` executable. .. option:: -x. Equivalent to :option:`--radix` with a value of ``16``. .. option:: @<FILE>. Read command-line options from response file ``<FILE>``. EXIT STATUS; -----------. :program:`llvm-size` exits with a non-zero exit code if there is an error.; Otherwise, it exits with code 0. BUGS; ----. To report bugs, please visit <https://github.com/llvm/llvm-project/labels/tools:llvm-size/>.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-size.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-size.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-size.rst:4002,Testability,test,test,4002," different; file format is specified, :program:`llvm-size` falls back to ``berkeley``; format. When producing ``darwin`` format, the tool displays information about; segments and sections:. .. code-block:: console. $ llvm-size --format=darwin macho.obj macho2.obj; macho.obj:; Segment : 12; Section (__TEXT, __text): 4; Section (__DATA, __data): 8; total 12; total 12; macho2.obj:; Segment : 48; Section (__TEXT, __text): 16; Section (__DATA, __data): 32; total 48; total 48. .. option:: --help, -h. Display a summary of command line options. .. option:: -m. Equivalent to :option:`--format` with a value of ``darwin``. .. option:: -o. Equivalent to :option:`--radix` with a value of ``8``. .. option:: --radix=<value>. Display size information in the specified radix. Permitted values are ``8``,; ``10`` (the default) and ``16`` for octal, decimal and hexadecimal output; respectively. Example:. .. code-block:: console. $ llvm-size --radix=8 test.o; text data bss oct hex filename; 0152 04 04 162 72 test.o. $ llvm-size --radix=10 test.o; text data bss dec hex filename; 106 4 4 114 72 test.o. $ llvm-size --radix=16 test.o; text data bss dec hex filename; 0x6a 0x4 0x4 114 72 test.o. .. option:: --totals, -t. Applies only to ``berkeley`` output format. Display the totals for all listed; fields, in addition to the individual file listings. Example:. .. code-block:: console. $ llvm-size --totals test.elf test2.o; text data bss dec hex filename; 182 16 5 203 cb test.elf; 82 8 1 91 5b test2.o; 264 24 6 294 126 (TOTALS). .. option:: --version. Display the version of the :program:`llvm-size` executable. .. option:: -x. Equivalent to :option:`--radix` with a value of ``16``. .. option:: @<FILE>. Read command-line options from response file ``<FILE>``. EXIT STATUS; -----------. :program:`llvm-size` exits with a non-zero exit code if there is an error.; Otherwise, it exits with code 0. BUGS; ----. To report bugs, please visit <https://github.com/llvm/llvm-project/labels/tools:llvm-size/>.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-size.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-size.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-stress.rst:322,Testability,test,test,322,llvm-stress - generate random .ll files; =======================================. .. program:: llvm-stress. SYNOPSIS; --------. :program:`llvm-stress` [-size=filesize] [-seed=initialseed] [-o=outfile]. DESCRIPTION; -----------. The :program:`llvm-stress` tool is used to generate random ``.ll`` files that; can be used to test different components of LLVM. OPTIONS; -------. .. option:: -o filename. Specify the output filename. .. option:: -size size. Specify the size of the generated ``.ll`` file. .. option:: -seed seed. Specify the seed to be used for the randomly generated instructions. EXIT STATUS; -----------. :program:`llvm-stress` returns 0.; ,MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-stress.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-stress.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strings.rst:2641,Availability,error,error,2641,"`"" is specified as an ``input``, or no ``input`` is specified,; the program reads from the standard input stream. EXAMPLE; -------. .. code-block:: console. $ cat input.txt; bars; foo; wibble blob; $ llvm-strings input.txt; bars; wibble blob. OPTIONS; -------. .. option:: --all, -a. Silently ignored. Present for GNU :program:`strings` compatibility. .. option:: --bytes=<length>, -n. Set the minimum number of printable ASCII characters required for a sequence of; bytes to be considered a string. The default value is 4. .. option:: --help, -h. Display a summary of command line options. .. option:: --print-file-name, -f. Display the name of the containing file before each string. Example:. .. code-block:: console. $ llvm-strings --print-file-name test.o test.elf; test.o: _Z5hellov; test.o: some_bss; test.o: test.cpp; test.o: main; test.elf: test.cpp; test.elf: test2.cpp; test.elf: _Z5hellov; test.elf: main; test.elf: some_bss. .. option:: --radix=<radix>, -t. Display the offset within the file of each string, before the string and using; the specified radix. Valid ``<radix>`` values are ``o``, ``d`` and ``x`` for; octal, decimal and hexadecimal respectively. Example:. .. code-block:: console. $ llvm-strings --radix=o test.o; 1054 _Z5hellov; 1066 .rela.text; 1101 .comment; 1112 some_bss; 1123 .bss; 1130 test.cpp; 1141 main; $ llvm-strings --radix=d test.o; 556 _Z5hellov; 566 .rela.text; 577 .comment; 586 some_bss; 595 .bss; 600 test.cpp; 609 main; $ llvm-strings -t x test.o; 22c _Z5hellov; 236 .rela.text; 241 .comment; 24a some_bss; 253 .bss; 258 test.cpp; 261 main. .. option:: --version. Display the version of the :program:`llvm-strings` executable. .. option:: @<FILE>. Read command-line options from response file ``<FILE>``. EXIT STATUS; -----------. :program:`llvm-strings` exits with a non-zero exit code if there is an error.; Otherwise, it exits with code 0. BUGS; ----. To report bugs, please visit <https://github.com/llvm/llvm-project/labels/tools:llvm-strings/>.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strings.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strings.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strings.rst:1545,Testability,test,test,1545,"sequence. :program:`llvm-strings` looks for strings in each ``input`` file specified.; Unlike GNU :program:`strings` it looks in the entire input file, regardless of; file format, rather than restricting the search to certain sections of object; files. If ""``-``"" is specified as an ``input``, or no ``input`` is specified,; the program reads from the standard input stream. EXAMPLE; -------. .. code-block:: console. $ cat input.txt; bars; foo; wibble blob; $ llvm-strings input.txt; bars; wibble blob. OPTIONS; -------. .. option:: --all, -a. Silently ignored. Present for GNU :program:`strings` compatibility. .. option:: --bytes=<length>, -n. Set the minimum number of printable ASCII characters required for a sequence of; bytes to be considered a string. The default value is 4. .. option:: --help, -h. Display a summary of command line options. .. option:: --print-file-name, -f. Display the name of the containing file before each string. Example:. .. code-block:: console. $ llvm-strings --print-file-name test.o test.elf; test.o: _Z5hellov; test.o: some_bss; test.o: test.cpp; test.o: main; test.elf: test.cpp; test.elf: test2.cpp; test.elf: _Z5hellov; test.elf: main; test.elf: some_bss. .. option:: --radix=<radix>, -t. Display the offset within the file of each string, before the string and using; the specified radix. Valid ``<radix>`` values are ``o``, ``d`` and ``x`` for; octal, decimal and hexadecimal respectively. Example:. .. code-block:: console. $ llvm-strings --radix=o test.o; 1054 _Z5hellov; 1066 .rela.text; 1101 .comment; 1112 some_bss; 1123 .bss; 1130 test.cpp; 1141 main; $ llvm-strings --radix=d test.o; 556 _Z5hellov; 566 .rela.text; 577 .comment; 586 some_bss; 595 .bss; 600 test.cpp; 609 main; $ llvm-strings -t x test.o; 22c _Z5hellov; 236 .rela.text; 241 .comment; 24a some_bss; 253 .bss; 258 test.cpp; 261 main. .. option:: --version. Display the version of the :program:`llvm-strings` executable. .. option:: @<FILE>. Read command-line options from response file",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strings.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strings.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strings.rst:1552,Testability,test,test,1552,"m-strings` looks for strings in each ``input`` file specified.; Unlike GNU :program:`strings` it looks in the entire input file, regardless of; file format, rather than restricting the search to certain sections of object; files. If ""``-``"" is specified as an ``input``, or no ``input`` is specified,; the program reads from the standard input stream. EXAMPLE; -------. .. code-block:: console. $ cat input.txt; bars; foo; wibble blob; $ llvm-strings input.txt; bars; wibble blob. OPTIONS; -------. .. option:: --all, -a. Silently ignored. Present for GNU :program:`strings` compatibility. .. option:: --bytes=<length>, -n. Set the minimum number of printable ASCII characters required for a sequence of; bytes to be considered a string. The default value is 4. .. option:: --help, -h. Display a summary of command line options. .. option:: --print-file-name, -f. Display the name of the containing file before each string. Example:. .. code-block:: console. $ llvm-strings --print-file-name test.o test.elf; test.o: _Z5hellov; test.o: some_bss; test.o: test.cpp; test.o: main; test.elf: test.cpp; test.elf: test2.cpp; test.elf: _Z5hellov; test.elf: main; test.elf: some_bss. .. option:: --radix=<radix>, -t. Display the offset within the file of each string, before the string and using; the specified radix. Valid ``<radix>`` values are ``o``, ``d`` and ``x`` for; octal, decimal and hexadecimal respectively. Example:. .. code-block:: console. $ llvm-strings --radix=o test.o; 1054 _Z5hellov; 1066 .rela.text; 1101 .comment; 1112 some_bss; 1123 .bss; 1130 test.cpp; 1141 main; $ llvm-strings --radix=d test.o; 556 _Z5hellov; 566 .rela.text; 577 .comment; 586 some_bss; 595 .bss; 600 test.cpp; 609 main; $ llvm-strings -t x test.o; 22c _Z5hellov; 236 .rela.text; 241 .comment; 24a some_bss; 253 .bss; 258 test.cpp; 261 main. .. option:: --version. Display the version of the :program:`llvm-strings` executable. .. option:: @<FILE>. Read command-line options from response file ``<FILE>``. EXIT STATU",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strings.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strings.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strings.rst:1562,Testability,test,test,1562,"` looks for strings in each ``input`` file specified.; Unlike GNU :program:`strings` it looks in the entire input file, regardless of; file format, rather than restricting the search to certain sections of object; files. If ""``-``"" is specified as an ``input``, or no ``input`` is specified,; the program reads from the standard input stream. EXAMPLE; -------. .. code-block:: console. $ cat input.txt; bars; foo; wibble blob; $ llvm-strings input.txt; bars; wibble blob. OPTIONS; -------. .. option:: --all, -a. Silently ignored. Present for GNU :program:`strings` compatibility. .. option:: --bytes=<length>, -n. Set the minimum number of printable ASCII characters required for a sequence of; bytes to be considered a string. The default value is 4. .. option:: --help, -h. Display a summary of command line options. .. option:: --print-file-name, -f. Display the name of the containing file before each string. Example:. .. code-block:: console. $ llvm-strings --print-file-name test.o test.elf; test.o: _Z5hellov; test.o: some_bss; test.o: test.cpp; test.o: main; test.elf: test.cpp; test.elf: test2.cpp; test.elf: _Z5hellov; test.elf: main; test.elf: some_bss. .. option:: --radix=<radix>, -t. Display the offset within the file of each string, before the string and using; the specified radix. Valid ``<radix>`` values are ``o``, ``d`` and ``x`` for; octal, decimal and hexadecimal respectively. Example:. .. code-block:: console. $ llvm-strings --radix=o test.o; 1054 _Z5hellov; 1066 .rela.text; 1101 .comment; 1112 some_bss; 1123 .bss; 1130 test.cpp; 1141 main; $ llvm-strings --radix=d test.o; 556 _Z5hellov; 566 .rela.text; 577 .comment; 586 some_bss; 595 .bss; 600 test.cpp; 609 main; $ llvm-strings -t x test.o; 22c _Z5hellov; 236 .rela.text; 241 .comment; 24a some_bss; 253 .bss; 258 test.cpp; 261 main. .. option:: --version. Display the version of the :program:`llvm-strings` executable. .. option:: @<FILE>. Read command-line options from response file ``<FILE>``. EXIT STATUS; -----",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strings.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strings.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strings.rst:1581,Testability,test,test,1581,"rings in each ``input`` file specified.; Unlike GNU :program:`strings` it looks in the entire input file, regardless of; file format, rather than restricting the search to certain sections of object; files. If ""``-``"" is specified as an ``input``, or no ``input`` is specified,; the program reads from the standard input stream. EXAMPLE; -------. .. code-block:: console. $ cat input.txt; bars; foo; wibble blob; $ llvm-strings input.txt; bars; wibble blob. OPTIONS; -------. .. option:: --all, -a. Silently ignored. Present for GNU :program:`strings` compatibility. .. option:: --bytes=<length>, -n. Set the minimum number of printable ASCII characters required for a sequence of; bytes to be considered a string. The default value is 4. .. option:: --help, -h. Display a summary of command line options. .. option:: --print-file-name, -f. Display the name of the containing file before each string. Example:. .. code-block:: console. $ llvm-strings --print-file-name test.o test.elf; test.o: _Z5hellov; test.o: some_bss; test.o: test.cpp; test.o: main; test.elf: test.cpp; test.elf: test2.cpp; test.elf: _Z5hellov; test.elf: main; test.elf: some_bss. .. option:: --radix=<radix>, -t. Display the offset within the file of each string, before the string and using; the specified radix. Valid ``<radix>`` values are ``o``, ``d`` and ``x`` for; octal, decimal and hexadecimal respectively. Example:. .. code-block:: console. $ llvm-strings --radix=o test.o; 1054 _Z5hellov; 1066 .rela.text; 1101 .comment; 1112 some_bss; 1123 .bss; 1130 test.cpp; 1141 main; $ llvm-strings --radix=d test.o; 556 _Z5hellov; 566 .rela.text; 577 .comment; 586 some_bss; 595 .bss; 600 test.cpp; 609 main; $ llvm-strings -t x test.o; 22c _Z5hellov; 236 .rela.text; 241 .comment; 24a some_bss; 253 .bss; 258 test.cpp; 261 main. .. option:: --version. Display the version of the :program:`llvm-strings` executable. .. option:: @<FILE>. Read command-line options from response file ``<FILE>``. EXIT STATUS; -----------. :progra",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strings.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strings.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strings.rst:1599,Testability,test,test,1599,"ut`` file specified.; Unlike GNU :program:`strings` it looks in the entire input file, regardless of; file format, rather than restricting the search to certain sections of object; files. If ""``-``"" is specified as an ``input``, or no ``input`` is specified,; the program reads from the standard input stream. EXAMPLE; -------. .. code-block:: console. $ cat input.txt; bars; foo; wibble blob; $ llvm-strings input.txt; bars; wibble blob. OPTIONS; -------. .. option:: --all, -a. Silently ignored. Present for GNU :program:`strings` compatibility. .. option:: --bytes=<length>, -n. Set the minimum number of printable ASCII characters required for a sequence of; bytes to be considered a string. The default value is 4. .. option:: --help, -h. Display a summary of command line options. .. option:: --print-file-name, -f. Display the name of the containing file before each string. Example:. .. code-block:: console. $ llvm-strings --print-file-name test.o test.elf; test.o: _Z5hellov; test.o: some_bss; test.o: test.cpp; test.o: main; test.elf: test.cpp; test.elf: test2.cpp; test.elf: _Z5hellov; test.elf: main; test.elf: some_bss. .. option:: --radix=<radix>, -t. Display the offset within the file of each string, before the string and using; the specified radix. Valid ``<radix>`` values are ``o``, ``d`` and ``x`` for; octal, decimal and hexadecimal respectively. Example:. .. code-block:: console. $ llvm-strings --radix=o test.o; 1054 _Z5hellov; 1066 .rela.text; 1101 .comment; 1112 some_bss; 1123 .bss; 1130 test.cpp; 1141 main; $ llvm-strings --radix=d test.o; 556 _Z5hellov; 566 .rela.text; 577 .comment; 586 some_bss; 595 .bss; 600 test.cpp; 609 main; $ llvm-strings -t x test.o; 22c _Z5hellov; 236 .rela.text; 241 .comment; 24a some_bss; 253 .bss; 258 test.cpp; 261 main. .. option:: --version. Display the version of the :program:`llvm-strings` executable. .. option:: @<FILE>. Read command-line options from response file ``<FILE>``. EXIT STATUS; -----------. :program:`llvm-strings` e",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strings.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strings.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strings.rst:1607,Testability,test,test,1607,"cified.; Unlike GNU :program:`strings` it looks in the entire input file, regardless of; file format, rather than restricting the search to certain sections of object; files. If ""``-``"" is specified as an ``input``, or no ``input`` is specified,; the program reads from the standard input stream. EXAMPLE; -------. .. code-block:: console. $ cat input.txt; bars; foo; wibble blob; $ llvm-strings input.txt; bars; wibble blob. OPTIONS; -------. .. option:: --all, -a. Silently ignored. Present for GNU :program:`strings` compatibility. .. option:: --bytes=<length>, -n. Set the minimum number of printable ASCII characters required for a sequence of; bytes to be considered a string. The default value is 4. .. option:: --help, -h. Display a summary of command line options. .. option:: --print-file-name, -f. Display the name of the containing file before each string. Example:. .. code-block:: console. $ llvm-strings --print-file-name test.o test.elf; test.o: _Z5hellov; test.o: some_bss; test.o: test.cpp; test.o: main; test.elf: test.cpp; test.elf: test2.cpp; test.elf: _Z5hellov; test.elf: main; test.elf: some_bss. .. option:: --radix=<radix>, -t. Display the offset within the file of each string, before the string and using; the specified radix. Valid ``<radix>`` values are ``o``, ``d`` and ``x`` for; octal, decimal and hexadecimal respectively. Example:. .. code-block:: console. $ llvm-strings --radix=o test.o; 1054 _Z5hellov; 1066 .rela.text; 1101 .comment; 1112 some_bss; 1123 .bss; 1130 test.cpp; 1141 main; $ llvm-strings --radix=d test.o; 556 _Z5hellov; 566 .rela.text; 577 .comment; 586 some_bss; 595 .bss; 600 test.cpp; 609 main; $ llvm-strings -t x test.o; 22c _Z5hellov; 236 .rela.text; 241 .comment; 24a some_bss; 253 .bss; 258 test.cpp; 261 main. .. option:: --version. Display the version of the :program:`llvm-strings` executable. .. option:: @<FILE>. Read command-line options from response file ``<FILE>``. EXIT STATUS; -----------. :program:`llvm-strings` exits with a n",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strings.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strings.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strings.rst:1617,Testability,test,test,1617,"Unlike GNU :program:`strings` it looks in the entire input file, regardless of; file format, rather than restricting the search to certain sections of object; files. If ""``-``"" is specified as an ``input``, or no ``input`` is specified,; the program reads from the standard input stream. EXAMPLE; -------. .. code-block:: console. $ cat input.txt; bars; foo; wibble blob; $ llvm-strings input.txt; bars; wibble blob. OPTIONS; -------. .. option:: --all, -a. Silently ignored. Present for GNU :program:`strings` compatibility. .. option:: --bytes=<length>, -n. Set the minimum number of printable ASCII characters required for a sequence of; bytes to be considered a string. The default value is 4. .. option:: --help, -h. Display a summary of command line options. .. option:: --print-file-name, -f. Display the name of the containing file before each string. Example:. .. code-block:: console. $ llvm-strings --print-file-name test.o test.elf; test.o: _Z5hellov; test.o: some_bss; test.o: test.cpp; test.o: main; test.elf: test.cpp; test.elf: test2.cpp; test.elf: _Z5hellov; test.elf: main; test.elf: some_bss. .. option:: --radix=<radix>, -t. Display the offset within the file of each string, before the string and using; the specified radix. Valid ``<radix>`` values are ``o``, ``d`` and ``x`` for; octal, decimal and hexadecimal respectively. Example:. .. code-block:: console. $ llvm-strings --radix=o test.o; 1054 _Z5hellov; 1066 .rela.text; 1101 .comment; 1112 some_bss; 1123 .bss; 1130 test.cpp; 1141 main; $ llvm-strings --radix=d test.o; 556 _Z5hellov; 566 .rela.text; 577 .comment; 586 some_bss; 595 .bss; 600 test.cpp; 609 main; $ llvm-strings -t x test.o; 22c _Z5hellov; 236 .rela.text; 241 .comment; 24a some_bss; 253 .bss; 258 test.cpp; 261 main. .. option:: --version. Display the version of the :program:`llvm-strings` executable. .. option:: @<FILE>. Read command-line options from response file ``<FILE>``. EXIT STATUS; -----------. :program:`llvm-strings` exits with a non-zero e",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strings.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strings.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strings.rst:1631,Testability,test,test,1631,"program:`strings` it looks in the entire input file, regardless of; file format, rather than restricting the search to certain sections of object; files. If ""``-``"" is specified as an ``input``, or no ``input`` is specified,; the program reads from the standard input stream. EXAMPLE; -------. .. code-block:: console. $ cat input.txt; bars; foo; wibble blob; $ llvm-strings input.txt; bars; wibble blob. OPTIONS; -------. .. option:: --all, -a. Silently ignored. Present for GNU :program:`strings` compatibility. .. option:: --bytes=<length>, -n. Set the minimum number of printable ASCII characters required for a sequence of; bytes to be considered a string. The default value is 4. .. option:: --help, -h. Display a summary of command line options. .. option:: --print-file-name, -f. Display the name of the containing file before each string. Example:. .. code-block:: console. $ llvm-strings --print-file-name test.o test.elf; test.o: _Z5hellov; test.o: some_bss; test.o: test.cpp; test.o: main; test.elf: test.cpp; test.elf: test2.cpp; test.elf: _Z5hellov; test.elf: main; test.elf: some_bss. .. option:: --radix=<radix>, -t. Display the offset within the file of each string, before the string and using; the specified radix. Valid ``<radix>`` values are ``o``, ``d`` and ``x`` for; octal, decimal and hexadecimal respectively. Example:. .. code-block:: console. $ llvm-strings --radix=o test.o; 1054 _Z5hellov; 1066 .rela.text; 1101 .comment; 1112 some_bss; 1123 .bss; 1130 test.cpp; 1141 main; $ llvm-strings --radix=d test.o; 556 _Z5hellov; 566 .rela.text; 577 .comment; 586 some_bss; 595 .bss; 600 test.cpp; 609 main; $ llvm-strings -t x test.o; 22c _Z5hellov; 236 .rela.text; 241 .comment; 24a some_bss; 253 .bss; 258 test.cpp; 261 main. .. option:: --version. Display the version of the :program:`llvm-strings` executable. .. option:: @<FILE>. Read command-line options from response file ``<FILE>``. EXIT STATUS; -----------. :program:`llvm-strings` exits with a non-zero exit code if ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strings.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strings.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strings.rst:1641,Testability,test,test,1641,"ings` it looks in the entire input file, regardless of; file format, rather than restricting the search to certain sections of object; files. If ""``-``"" is specified as an ``input``, or no ``input`` is specified,; the program reads from the standard input stream. EXAMPLE; -------. .. code-block:: console. $ cat input.txt; bars; foo; wibble blob; $ llvm-strings input.txt; bars; wibble blob. OPTIONS; -------. .. option:: --all, -a. Silently ignored. Present for GNU :program:`strings` compatibility. .. option:: --bytes=<length>, -n. Set the minimum number of printable ASCII characters required for a sequence of; bytes to be considered a string. The default value is 4. .. option:: --help, -h. Display a summary of command line options. .. option:: --print-file-name, -f. Display the name of the containing file before each string. Example:. .. code-block:: console. $ llvm-strings --print-file-name test.o test.elf; test.o: _Z5hellov; test.o: some_bss; test.o: test.cpp; test.o: main; test.elf: test.cpp; test.elf: test2.cpp; test.elf: _Z5hellov; test.elf: main; test.elf: some_bss. .. option:: --radix=<radix>, -t. Display the offset within the file of each string, before the string and using; the specified radix. Valid ``<radix>`` values are ``o``, ``d`` and ``x`` for; octal, decimal and hexadecimal respectively. Example:. .. code-block:: console. $ llvm-strings --radix=o test.o; 1054 _Z5hellov; 1066 .rela.text; 1101 .comment; 1112 some_bss; 1123 .bss; 1130 test.cpp; 1141 main; $ llvm-strings --radix=d test.o; 556 _Z5hellov; 566 .rela.text; 577 .comment; 586 some_bss; 595 .bss; 600 test.cpp; 609 main; $ llvm-strings -t x test.o; 22c _Z5hellov; 236 .rela.text; 241 .comment; 24a some_bss; 253 .bss; 258 test.cpp; 261 main. .. option:: --version. Display the version of the :program:`llvm-strings` executable. .. option:: @<FILE>. Read command-line options from response file ``<FILE>``. EXIT STATUS; -----------. :program:`llvm-strings` exits with a non-zero exit code if there is an ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strings.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strings.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strings.rst:1651,Testability,test,test,1651,"ooks in the entire input file, regardless of; file format, rather than restricting the search to certain sections of object; files. If ""``-``"" is specified as an ``input``, or no ``input`` is specified,; the program reads from the standard input stream. EXAMPLE; -------. .. code-block:: console. $ cat input.txt; bars; foo; wibble blob; $ llvm-strings input.txt; bars; wibble blob. OPTIONS; -------. .. option:: --all, -a. Silently ignored. Present for GNU :program:`strings` compatibility. .. option:: --bytes=<length>, -n. Set the minimum number of printable ASCII characters required for a sequence of; bytes to be considered a string. The default value is 4. .. option:: --help, -h. Display a summary of command line options. .. option:: --print-file-name, -f. Display the name of the containing file before each string. Example:. .. code-block:: console. $ llvm-strings --print-file-name test.o test.elf; test.o: _Z5hellov; test.o: some_bss; test.o: test.cpp; test.o: main; test.elf: test.cpp; test.elf: test2.cpp; test.elf: _Z5hellov; test.elf: main; test.elf: some_bss. .. option:: --radix=<radix>, -t. Display the offset within the file of each string, before the string and using; the specified radix. Valid ``<radix>`` values are ``o``, ``d`` and ``x`` for; octal, decimal and hexadecimal respectively. Example:. .. code-block:: console. $ llvm-strings --radix=o test.o; 1054 _Z5hellov; 1066 .rela.text; 1101 .comment; 1112 some_bss; 1123 .bss; 1130 test.cpp; 1141 main; $ llvm-strings --radix=d test.o; 556 _Z5hellov; 566 .rela.text; 577 .comment; 586 some_bss; 595 .bss; 600 test.cpp; 609 main; $ llvm-strings -t x test.o; 22c _Z5hellov; 236 .rela.text; 241 .comment; 24a some_bss; 253 .bss; 258 test.cpp; 261 main. .. option:: --version. Display the version of the :program:`llvm-strings` executable. .. option:: @<FILE>. Read command-line options from response file ``<FILE>``. EXIT STATUS; -----------. :program:`llvm-strings` exits with a non-zero exit code if there is an error.; Ot",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strings.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strings.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strings.rst:1672,Testability,test,test,1672,"put file, regardless of; file format, rather than restricting the search to certain sections of object; files. If ""``-``"" is specified as an ``input``, or no ``input`` is specified,; the program reads from the standard input stream. EXAMPLE; -------. .. code-block:: console. $ cat input.txt; bars; foo; wibble blob; $ llvm-strings input.txt; bars; wibble blob. OPTIONS; -------. .. option:: --all, -a. Silently ignored. Present for GNU :program:`strings` compatibility. .. option:: --bytes=<length>, -n. Set the minimum number of printable ASCII characters required for a sequence of; bytes to be considered a string. The default value is 4. .. option:: --help, -h. Display a summary of command line options. .. option:: --print-file-name, -f. Display the name of the containing file before each string. Example:. .. code-block:: console. $ llvm-strings --print-file-name test.o test.elf; test.o: _Z5hellov; test.o: some_bss; test.o: test.cpp; test.o: main; test.elf: test.cpp; test.elf: test2.cpp; test.elf: _Z5hellov; test.elf: main; test.elf: some_bss. .. option:: --radix=<radix>, -t. Display the offset within the file of each string, before the string and using; the specified radix. Valid ``<radix>`` values are ``o``, ``d`` and ``x`` for; octal, decimal and hexadecimal respectively. Example:. .. code-block:: console. $ llvm-strings --radix=o test.o; 1054 _Z5hellov; 1066 .rela.text; 1101 .comment; 1112 some_bss; 1123 .bss; 1130 test.cpp; 1141 main; $ llvm-strings --radix=d test.o; 556 _Z5hellov; 566 .rela.text; 577 .comment; 586 some_bss; 595 .bss; 600 test.cpp; 609 main; $ llvm-strings -t x test.o; 22c _Z5hellov; 236 .rela.text; 241 .comment; 24a some_bss; 253 .bss; 258 test.cpp; 261 main. .. option:: --version. Display the version of the :program:`llvm-strings` executable. .. option:: @<FILE>. Read command-line options from response file ``<FILE>``. EXIT STATUS; -----------. :program:`llvm-strings` exits with a non-zero exit code if there is an error.; Otherwise, it exits wit",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strings.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strings.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strings.rst:1693,Testability,test,test,1693,"dless of; file format, rather than restricting the search to certain sections of object; files. If ""``-``"" is specified as an ``input``, or no ``input`` is specified,; the program reads from the standard input stream. EXAMPLE; -------. .. code-block:: console. $ cat input.txt; bars; foo; wibble blob; $ llvm-strings input.txt; bars; wibble blob. OPTIONS; -------. .. option:: --all, -a. Silently ignored. Present for GNU :program:`strings` compatibility. .. option:: --bytes=<length>, -n. Set the minimum number of printable ASCII characters required for a sequence of; bytes to be considered a string. The default value is 4. .. option:: --help, -h. Display a summary of command line options. .. option:: --print-file-name, -f. Display the name of the containing file before each string. Example:. .. code-block:: console. $ llvm-strings --print-file-name test.o test.elf; test.o: _Z5hellov; test.o: some_bss; test.o: test.cpp; test.o: main; test.elf: test.cpp; test.elf: test2.cpp; test.elf: _Z5hellov; test.elf: main; test.elf: some_bss. .. option:: --radix=<radix>, -t. Display the offset within the file of each string, before the string and using; the specified radix. Valid ``<radix>`` values are ``o``, ``d`` and ``x`` for; octal, decimal and hexadecimal respectively. Example:. .. code-block:: console. $ llvm-strings --radix=o test.o; 1054 _Z5hellov; 1066 .rela.text; 1101 .comment; 1112 some_bss; 1123 .bss; 1130 test.cpp; 1141 main; $ llvm-strings --radix=d test.o; 556 _Z5hellov; 566 .rela.text; 577 .comment; 586 some_bss; 595 .bss; 600 test.cpp; 609 main; $ llvm-strings -t x test.o; 22c _Z5hellov; 236 .rela.text; 241 .comment; 24a some_bss; 253 .bss; 258 test.cpp; 261 main. .. option:: --version. Display the version of the :program:`llvm-strings` executable. .. option:: @<FILE>. Read command-line options from response file ``<FILE>``. EXIT STATUS; -----------. :program:`llvm-strings` exits with a non-zero exit code if there is an error.; Otherwise, it exits with code 0. BUGS; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strings.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strings.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strings.rst:1709,Testability,test,test,1709,"at, rather than restricting the search to certain sections of object; files. If ""``-``"" is specified as an ``input``, or no ``input`` is specified,; the program reads from the standard input stream. EXAMPLE; -------. .. code-block:: console. $ cat input.txt; bars; foo; wibble blob; $ llvm-strings input.txt; bars; wibble blob. OPTIONS; -------. .. option:: --all, -a. Silently ignored. Present for GNU :program:`strings` compatibility. .. option:: --bytes=<length>, -n. Set the minimum number of printable ASCII characters required for a sequence of; bytes to be considered a string. The default value is 4. .. option:: --help, -h. Display a summary of command line options. .. option:: --print-file-name, -f. Display the name of the containing file before each string. Example:. .. code-block:: console. $ llvm-strings --print-file-name test.o test.elf; test.o: _Z5hellov; test.o: some_bss; test.o: test.cpp; test.o: main; test.elf: test.cpp; test.elf: test2.cpp; test.elf: _Z5hellov; test.elf: main; test.elf: some_bss. .. option:: --radix=<radix>, -t. Display the offset within the file of each string, before the string and using; the specified radix. Valid ``<radix>`` values are ``o``, ``d`` and ``x`` for; octal, decimal and hexadecimal respectively. Example:. .. code-block:: console. $ llvm-strings --radix=o test.o; 1054 _Z5hellov; 1066 .rela.text; 1101 .comment; 1112 some_bss; 1123 .bss; 1130 test.cpp; 1141 main; $ llvm-strings --radix=d test.o; 556 _Z5hellov; 566 .rela.text; 577 .comment; 586 some_bss; 595 .bss; 600 test.cpp; 609 main; $ llvm-strings -t x test.o; 22c _Z5hellov; 236 .rela.text; 241 .comment; 24a some_bss; 253 .bss; 258 test.cpp; 261 main. .. option:: --version. Display the version of the :program:`llvm-strings` executable. .. option:: @<FILE>. Read command-line options from response file ``<FILE>``. EXIT STATUS; -----------. :program:`llvm-strings` exits with a non-zero exit code if there is an error.; Otherwise, it exits with code 0. BUGS; ----. To report bu",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strings.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strings.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strings.rst:2025,Testability,test,test,2025,"`"" is specified as an ``input``, or no ``input`` is specified,; the program reads from the standard input stream. EXAMPLE; -------. .. code-block:: console. $ cat input.txt; bars; foo; wibble blob; $ llvm-strings input.txt; bars; wibble blob. OPTIONS; -------. .. option:: --all, -a. Silently ignored. Present for GNU :program:`strings` compatibility. .. option:: --bytes=<length>, -n. Set the minimum number of printable ASCII characters required for a sequence of; bytes to be considered a string. The default value is 4. .. option:: --help, -h. Display a summary of command line options. .. option:: --print-file-name, -f. Display the name of the containing file before each string. Example:. .. code-block:: console. $ llvm-strings --print-file-name test.o test.elf; test.o: _Z5hellov; test.o: some_bss; test.o: test.cpp; test.o: main; test.elf: test.cpp; test.elf: test2.cpp; test.elf: _Z5hellov; test.elf: main; test.elf: some_bss. .. option:: --radix=<radix>, -t. Display the offset within the file of each string, before the string and using; the specified radix. Valid ``<radix>`` values are ``o``, ``d`` and ``x`` for; octal, decimal and hexadecimal respectively. Example:. .. code-block:: console. $ llvm-strings --radix=o test.o; 1054 _Z5hellov; 1066 .rela.text; 1101 .comment; 1112 some_bss; 1123 .bss; 1130 test.cpp; 1141 main; $ llvm-strings --radix=d test.o; 556 _Z5hellov; 566 .rela.text; 577 .comment; 586 some_bss; 595 .bss; 600 test.cpp; 609 main; $ llvm-strings -t x test.o; 22c _Z5hellov; 236 .rela.text; 241 .comment; 24a some_bss; 253 .bss; 258 test.cpp; 261 main. .. option:: --version. Display the version of the :program:`llvm-strings` executable. .. option:: @<FILE>. Read command-line options from response file ``<FILE>``. EXIT STATUS; -----------. :program:`llvm-strings` exits with a non-zero exit code if there is an error.; Otherwise, it exits with code 0. BUGS; ----. To report bugs, please visit <https://github.com/llvm/llvm-project/labels/tools:llvm-strings/>.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strings.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strings.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strings.rst:2112,Testability,test,test,2112,"`"" is specified as an ``input``, or no ``input`` is specified,; the program reads from the standard input stream. EXAMPLE; -------. .. code-block:: console. $ cat input.txt; bars; foo; wibble blob; $ llvm-strings input.txt; bars; wibble blob. OPTIONS; -------. .. option:: --all, -a. Silently ignored. Present for GNU :program:`strings` compatibility. .. option:: --bytes=<length>, -n. Set the minimum number of printable ASCII characters required for a sequence of; bytes to be considered a string. The default value is 4. .. option:: --help, -h. Display a summary of command line options. .. option:: --print-file-name, -f. Display the name of the containing file before each string. Example:. .. code-block:: console. $ llvm-strings --print-file-name test.o test.elf; test.o: _Z5hellov; test.o: some_bss; test.o: test.cpp; test.o: main; test.elf: test.cpp; test.elf: test2.cpp; test.elf: _Z5hellov; test.elf: main; test.elf: some_bss. .. option:: --radix=<radix>, -t. Display the offset within the file of each string, before the string and using; the specified radix. Valid ``<radix>`` values are ``o``, ``d`` and ``x`` for; octal, decimal and hexadecimal respectively. Example:. .. code-block:: console. $ llvm-strings --radix=o test.o; 1054 _Z5hellov; 1066 .rela.text; 1101 .comment; 1112 some_bss; 1123 .bss; 1130 test.cpp; 1141 main; $ llvm-strings --radix=d test.o; 556 _Z5hellov; 566 .rela.text; 577 .comment; 586 some_bss; 595 .bss; 600 test.cpp; 609 main; $ llvm-strings -t x test.o; 22c _Z5hellov; 236 .rela.text; 241 .comment; 24a some_bss; 253 .bss; 258 test.cpp; 261 main. .. option:: --version. Display the version of the :program:`llvm-strings` executable. .. option:: @<FILE>. Read command-line options from response file ``<FILE>``. EXIT STATUS; -----------. :program:`llvm-strings` exits with a non-zero exit code if there is an error.; Otherwise, it exits with code 0. BUGS; ----. To report bugs, please visit <https://github.com/llvm/llvm-project/labels/tools:llvm-strings/>.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strings.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strings.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strings.rst:2158,Testability,test,test,2158,"`"" is specified as an ``input``, or no ``input`` is specified,; the program reads from the standard input stream. EXAMPLE; -------. .. code-block:: console. $ cat input.txt; bars; foo; wibble blob; $ llvm-strings input.txt; bars; wibble blob. OPTIONS; -------. .. option:: --all, -a. Silently ignored. Present for GNU :program:`strings` compatibility. .. option:: --bytes=<length>, -n. Set the minimum number of printable ASCII characters required for a sequence of; bytes to be considered a string. The default value is 4. .. option:: --help, -h. Display a summary of command line options. .. option:: --print-file-name, -f. Display the name of the containing file before each string. Example:. .. code-block:: console. $ llvm-strings --print-file-name test.o test.elf; test.o: _Z5hellov; test.o: some_bss; test.o: test.cpp; test.o: main; test.elf: test.cpp; test.elf: test2.cpp; test.elf: _Z5hellov; test.elf: main; test.elf: some_bss. .. option:: --radix=<radix>, -t. Display the offset within the file of each string, before the string and using; the specified radix. Valid ``<radix>`` values are ``o``, ``d`` and ``x`` for; octal, decimal and hexadecimal respectively. Example:. .. code-block:: console. $ llvm-strings --radix=o test.o; 1054 _Z5hellov; 1066 .rela.text; 1101 .comment; 1112 some_bss; 1123 .bss; 1130 test.cpp; 1141 main; $ llvm-strings --radix=d test.o; 556 _Z5hellov; 566 .rela.text; 577 .comment; 586 some_bss; 595 .bss; 600 test.cpp; 609 main; $ llvm-strings -t x test.o; 22c _Z5hellov; 236 .rela.text; 241 .comment; 24a some_bss; 253 .bss; 258 test.cpp; 261 main. .. option:: --version. Display the version of the :program:`llvm-strings` executable. .. option:: @<FILE>. Read command-line options from response file ``<FILE>``. EXIT STATUS; -----------. :program:`llvm-strings` exits with a non-zero exit code if there is an error.; Otherwise, it exits with code 0. BUGS; ----. To report bugs, please visit <https://github.com/llvm/llvm-project/labels/tools:llvm-strings/>.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strings.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strings.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strings.rst:2239,Testability,test,test,2239,"`"" is specified as an ``input``, or no ``input`` is specified,; the program reads from the standard input stream. EXAMPLE; -------. .. code-block:: console. $ cat input.txt; bars; foo; wibble blob; $ llvm-strings input.txt; bars; wibble blob. OPTIONS; -------. .. option:: --all, -a. Silently ignored. Present for GNU :program:`strings` compatibility. .. option:: --bytes=<length>, -n. Set the minimum number of printable ASCII characters required for a sequence of; bytes to be considered a string. The default value is 4. .. option:: --help, -h. Display a summary of command line options. .. option:: --print-file-name, -f. Display the name of the containing file before each string. Example:. .. code-block:: console. $ llvm-strings --print-file-name test.o test.elf; test.o: _Z5hellov; test.o: some_bss; test.o: test.cpp; test.o: main; test.elf: test.cpp; test.elf: test2.cpp; test.elf: _Z5hellov; test.elf: main; test.elf: some_bss. .. option:: --radix=<radix>, -t. Display the offset within the file of each string, before the string and using; the specified radix. Valid ``<radix>`` values are ``o``, ``d`` and ``x`` for; octal, decimal and hexadecimal respectively. Example:. .. code-block:: console. $ llvm-strings --radix=o test.o; 1054 _Z5hellov; 1066 .rela.text; 1101 .comment; 1112 some_bss; 1123 .bss; 1130 test.cpp; 1141 main; $ llvm-strings --radix=d test.o; 556 _Z5hellov; 566 .rela.text; 577 .comment; 586 some_bss; 595 .bss; 600 test.cpp; 609 main; $ llvm-strings -t x test.o; 22c _Z5hellov; 236 .rela.text; 241 .comment; 24a some_bss; 253 .bss; 258 test.cpp; 261 main. .. option:: --version. Display the version of the :program:`llvm-strings` executable. .. option:: @<FILE>. Read command-line options from response file ``<FILE>``. EXIT STATUS; -----------. :program:`llvm-strings` exits with a non-zero exit code if there is an error.; Otherwise, it exits with code 0. BUGS; ----. To report bugs, please visit <https://github.com/llvm/llvm-project/labels/tools:llvm-strings/>.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strings.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strings.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strings.rst:2279,Testability,test,test,2279,"`"" is specified as an ``input``, or no ``input`` is specified,; the program reads from the standard input stream. EXAMPLE; -------. .. code-block:: console. $ cat input.txt; bars; foo; wibble blob; $ llvm-strings input.txt; bars; wibble blob. OPTIONS; -------. .. option:: --all, -a. Silently ignored. Present for GNU :program:`strings` compatibility. .. option:: --bytes=<length>, -n. Set the minimum number of printable ASCII characters required for a sequence of; bytes to be considered a string. The default value is 4. .. option:: --help, -h. Display a summary of command line options. .. option:: --print-file-name, -f. Display the name of the containing file before each string. Example:. .. code-block:: console. $ llvm-strings --print-file-name test.o test.elf; test.o: _Z5hellov; test.o: some_bss; test.o: test.cpp; test.o: main; test.elf: test.cpp; test.elf: test2.cpp; test.elf: _Z5hellov; test.elf: main; test.elf: some_bss. .. option:: --radix=<radix>, -t. Display the offset within the file of each string, before the string and using; the specified radix. Valid ``<radix>`` values are ``o``, ``d`` and ``x`` for; octal, decimal and hexadecimal respectively. Example:. .. code-block:: console. $ llvm-strings --radix=o test.o; 1054 _Z5hellov; 1066 .rela.text; 1101 .comment; 1112 some_bss; 1123 .bss; 1130 test.cpp; 1141 main; $ llvm-strings --radix=d test.o; 556 _Z5hellov; 566 .rela.text; 577 .comment; 586 some_bss; 595 .bss; 600 test.cpp; 609 main; $ llvm-strings -t x test.o; 22c _Z5hellov; 236 .rela.text; 241 .comment; 24a some_bss; 253 .bss; 258 test.cpp; 261 main. .. option:: --version. Display the version of the :program:`llvm-strings` executable. .. option:: @<FILE>. Read command-line options from response file ``<FILE>``. EXIT STATUS; -----------. :program:`llvm-strings` exits with a non-zero exit code if there is an error.; Otherwise, it exits with code 0. BUGS; ----. To report bugs, please visit <https://github.com/llvm/llvm-project/labels/tools:llvm-strings/>.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strings.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strings.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strings.rst:2360,Testability,test,test,2360,"`"" is specified as an ``input``, or no ``input`` is specified,; the program reads from the standard input stream. EXAMPLE; -------. .. code-block:: console. $ cat input.txt; bars; foo; wibble blob; $ llvm-strings input.txt; bars; wibble blob. OPTIONS; -------. .. option:: --all, -a. Silently ignored. Present for GNU :program:`strings` compatibility. .. option:: --bytes=<length>, -n. Set the minimum number of printable ASCII characters required for a sequence of; bytes to be considered a string. The default value is 4. .. option:: --help, -h. Display a summary of command line options. .. option:: --print-file-name, -f. Display the name of the containing file before each string. Example:. .. code-block:: console. $ llvm-strings --print-file-name test.o test.elf; test.o: _Z5hellov; test.o: some_bss; test.o: test.cpp; test.o: main; test.elf: test.cpp; test.elf: test2.cpp; test.elf: _Z5hellov; test.elf: main; test.elf: some_bss. .. option:: --radix=<radix>, -t. Display the offset within the file of each string, before the string and using; the specified radix. Valid ``<radix>`` values are ``o``, ``d`` and ``x`` for; octal, decimal and hexadecimal respectively. Example:. .. code-block:: console. $ llvm-strings --radix=o test.o; 1054 _Z5hellov; 1066 .rela.text; 1101 .comment; 1112 some_bss; 1123 .bss; 1130 test.cpp; 1141 main; $ llvm-strings --radix=d test.o; 556 _Z5hellov; 566 .rela.text; 577 .comment; 586 some_bss; 595 .bss; 600 test.cpp; 609 main; $ llvm-strings -t x test.o; 22c _Z5hellov; 236 .rela.text; 241 .comment; 24a some_bss; 253 .bss; 258 test.cpp; 261 main. .. option:: --version. Display the version of the :program:`llvm-strings` executable. .. option:: @<FILE>. Read command-line options from response file ``<FILE>``. EXIT STATUS; -----------. :program:`llvm-strings` exits with a non-zero exit code if there is an error.; Otherwise, it exits with code 0. BUGS; ----. To report bugs, please visit <https://github.com/llvm/llvm-project/labels/tools:llvm-strings/>.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strings.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strings.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strip.rst:4508,Availability,error,error,4508,"llowing special symbols:. ====================== ========================= ==================; Character Meaning Equivalent; ====================== ========================= ==================; ``*`` Any number of characters ``.*``; ``?`` Any single character ``.``; ``\`` Escape the next character ``\``; ``[a-z]`` Character class ``[a-z]``; ``[!a-z]``, ``[^a-z]`` Negated character class ``[^a-z]``; ====================== ========================= ==================. Additionally, starting a wildcard with '!' will prevent a match, even if; another flag matches. For example ``-w -N '*' -N '!x'`` will strip all symbols; except for ``x``. The order of wildcards does not matter. For example, ``-w -N '*' -N '!x'`` is; the same as ``-w -N '!x' -N '*'``. .. option:: @<FILE>. Read command-line options and commands from response file `<FILE>`. ELF-SPECIFIC OPTIONS; --------------------. The following options are implemented only for ELF objects. If used with other; objects, :program:`llvm-strip` will either emit an error or silently ignore; them. .. option:: --allow-broken-links. Allow :program:`llvm-strip` to remove sections even if it would leave invalid; section references. Any invalid sh_link fields will be set to zero. .. option:: --discard-locals, -X. Remove local symbols starting with "".L"" from the output. .. option:: --keep-file-symbols. Keep symbols of type `STT_FILE`, even if they would otherwise be stripped. .. option:: --keep-section <section>. When removing sections from the output, do not remove sections named; ``<section>``. Can be specified multiple times to keep multiple sections. .. option:: --keep-symbol <symbol>, -K. When removing symbols from the output, do not remove symbols named; ``<symbol>``. Can be specified multiple times to keep multiple symbols. .. option:: --preserve-dates, -p. Preserve access and modification timestamps in the output. .. option:: --strip-sections. Remove from the output all section headers and all section data not within; segment",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strip.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strip.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strip.rst:5705,Availability,error,error,5705,"== ========================= ==================. Additionally, starting a wildcard with '!' will prevent a match, even if; another flag matches. For example ``-w -N '*' -N '!x'`` will strip all symbols; except for ``x``. The order of wildcards does not matter. For example, ``-w -N '*' -N '!x'`` is; the same as ``-w -N '!x' -N '*'``. .. option:: @<FILE>. Read command-line options and commands from response file `<FILE>`. ELF-SPECIFIC OPTIONS; --------------------. The following options are implemented only for ELF objects. If used with other; objects, :program:`llvm-strip` will either emit an error or silently ignore; them. .. option:: --allow-broken-links. Allow :program:`llvm-strip` to remove sections even if it would leave invalid; section references. Any invalid sh_link fields will be set to zero. .. option:: --discard-locals, -X. Remove local symbols starting with "".L"" from the output. .. option:: --keep-file-symbols. Keep symbols of type `STT_FILE`, even if they would otherwise be stripped. .. option:: --keep-section <section>. When removing sections from the output, do not remove sections named; ``<section>``. Can be specified multiple times to keep multiple sections. .. option:: --keep-symbol <symbol>, -K. When removing symbols from the output, do not remove symbols named; ``<symbol>``. Can be specified multiple times to keep multiple symbols. .. option:: --preserve-dates, -p. Preserve access and modification timestamps in the output. .. option:: --strip-sections. Remove from the output all section headers and all section data not within; segments. Note that many tools will not be able to use an object without; section headers. .. option:: -T. Remove Swift symbols. EXIT STATUS; -----------. :program:`llvm-strip` exits with a non-zero exit code if there is an error.; Otherwise, it exits with code 0. BUGS; ----. To report bugs, please visit <https://github.com/llvm/llvm-project/labels/tools:llvm-objcopy%2Fstrip>. SEE ALSO; --------. :manpage:`llvm-objcopy(1)`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strip.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strip.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strip.rst:2154,Modifiability,extend,extended,2154,"fferent file formats may limit; this to a subset of the local symbols. For example, file and section symbols in; ELF objects will not be discarded. Additionally, remove all debug sections. .. option:: --enable-deterministic-archives, -D. Enable deterministic mode when stripping archives, i.e. use 0 for archive member; header UIDs, GIDs and timestamp fields. On by default. .. option:: --help, -h. Print a summary of command line options. .. option:: --no-strip-all. Disable :option:`--strip-all`. .. option:: -o <file>. Write output to <file>. Multiple input files cannot be used in combination; with -o. .. option:: --only-keep-debug. Produce a debug file as the output that only preserves contents of sections; useful for debugging purposes. For ELF objects, this removes the contents of `SHF_ALLOC` sections that are not; `SHT_NOTE` by making them `SHT_NOBITS` and shrinking the program headers where; possible. .. option:: --regex. If specified, symbol and section names specified by other switches are treated; as extended POSIX regular expression patterns. .. option:: --remove-section <section>, -R. Remove the specified section from the output. Can be specified multiple times; to remove multiple sections simultaneously. .. option:: --strip-all-gnu. Remove all symbols, debug sections and relocations from the output. This option; is equivalent to GNU :program:`strip`'s ``--strip-all`` switch. .. option:: --strip-all, -s. For ELF objects, remove from the output all symbols and non-alloc sections not; within segments, except for .gnu.warning, .ARM.attribute sections and the; section name table. For COFF objects, remove all symbols, debug sections, and relocations from the; output. .. option:: --strip-debug, -d, -g, -S. Remove all debug sections from the output. .. option:: --strip-symbol <symbol>, -N. Remove all symbols named ``<symbol>`` from the output. Can be specified; multiple times to remove multiple symbols. .. option:: --strip-unneeded. Remove from the output all local o",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strip.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strip.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strip.rst:5325,Security,access,access,5325,"== ========================= ==================. Additionally, starting a wildcard with '!' will prevent a match, even if; another flag matches. For example ``-w -N '*' -N '!x'`` will strip all symbols; except for ``x``. The order of wildcards does not matter. For example, ``-w -N '*' -N '!x'`` is; the same as ``-w -N '!x' -N '*'``. .. option:: @<FILE>. Read command-line options and commands from response file `<FILE>`. ELF-SPECIFIC OPTIONS; --------------------. The following options are implemented only for ELF objects. If used with other; objects, :program:`llvm-strip` will either emit an error or silently ignore; them. .. option:: --allow-broken-links. Allow :program:`llvm-strip` to remove sections even if it would leave invalid; section references. Any invalid sh_link fields will be set to zero. .. option:: --discard-locals, -X. Remove local symbols starting with "".L"" from the output. .. option:: --keep-file-symbols. Keep symbols of type `STT_FILE`, even if they would otherwise be stripped. .. option:: --keep-section <section>. When removing sections from the output, do not remove sections named; ``<section>``. Can be specified multiple times to keep multiple sections. .. option:: --keep-symbol <symbol>, -K. When removing symbols from the output, do not remove symbols named; ``<symbol>``. Can be specified multiple times to keep multiple symbols. .. option:: --preserve-dates, -p. Preserve access and modification timestamps in the output. .. option:: --strip-sections. Remove from the output all section headers and all section data not within; segments. Note that many tools will not be able to use an object without; section headers. .. option:: -T. Remove Swift symbols. EXIT STATUS; -----------. :program:`llvm-strip` exits with a non-zero exit code if there is an error.; Otherwise, it exits with code 0. BUGS; ----. To report bugs, please visit <https://github.com/llvm/llvm-project/labels/tools:llvm-objcopy%2Fstrip>. SEE ALSO; --------. :manpage:`llvm-objcopy(1)`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strip.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-strip.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:13882,Availability,error,error,13882,"lute path. If the command-line to the compiler included; the full path, this will be the same as the default. .. option:: --verbose. Print verbose address, line and column information. .. code-block:: console. $ llvm-symbolizer --obj=inlined.elf --verbose 0x4004be; baz(); Filename: /tmp/test.cpp; Function start filename: /tmp/test.cpp; Function start line: 9; Function start address: 0x4004b6; Line: 11; Column: 18; main; Filename: /tmp/test.cpp; Function start filename: /tmp/test.cpp; Function start line: 14; Function start address: 0x4004b0; Line: 15; Column: 18. .. option:: --version, -v. Print version information for the tool. .. option:: @<FILE>. Read command-line options from response file `<FILE>`. WINDOWS/PDB SPECIFIC OPTIONS; -----------------------------. .. option:: --dia. Use the Windows DIA SDK for symbolization. If the DIA SDK is not found,; llvm-symbolizer will fall back to the native implementation. MACH-O SPECIFIC OPTIONS; -----------------------. .. option:: --default-arch <arch>. If a binary contains object files for multiple architectures (e.g. it is a; Mach-O universal binary), symbolize the object file for a given architecture.; You can also specify the architecture by writing ``binary_name:arch_name`` in; the input (see example below). If the architecture is not specified in either; way, the address will not be symbolized. Defaults to empty string. .. code-block:: console. $ cat addr.txt; /tmp/mach_universal_binary:i386 0x1f84; /tmp/mach_universal_binary:x86_64 0x100000f24. $ llvm-symbolizer < addr.txt; _main; /tmp/source_i386.cc:8. _main; /tmp/source_x86_64.cc:8. .. option:: --dsym-hint <path/to/file.dSYM>. If the debug info for a binary isn't present in the default location, look for; the debug info at the .dSYM path provided via this option. This flag can be; used multiple times. EXIT STATUS; -----------. :program:`llvm-symbolizer` returns 0. Other exit codes imply an internal program; error. SEE ALSO; --------. :manpage:`llvm-addr2line(1)`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:1702,Modifiability,variab,variable,1702," on the command-line, but addresses; are, the first address value is treated as an input name. If an input value is not; recognized, it reports that source information is not found. Input names can be specified together with the addresses either on standard; input or as positional arguments on the command-line. By default, input names; are interpreted as object file paths. However, prefixing a name with; ``BUILDID:`` states that it is a hex build ID rather than a path. This will look; up the corresponding debug binary. For consistency, prefixing a name with; ``FILE:`` explicitly states that it is an object file path (the default). A positional argument or standard input value can be preceded by ""DATA"" or; ""CODE"" to indicate that the address should be symbolized as data or executable; code respectively. If neither is specified, ""CODE"" is assumed. DATA is; symbolized as address and symbol size rather than line number. :program:`llvm-symbolizer` parses options from the environment variable; ``LLVM_SYMBOLIZER_OPTS`` after parsing options from the command line.; ``LLVM_SYMBOLIZER_OPTS`` is primarily useful for supplementing the command-line; options when :program:`llvm-symbolizer` is invoked by another program or; runtime. EXAMPLES; --------. All of the following examples use the following two source files as input. They; use a mixture of C-style and C++-style linkage to illustrate how these names are; printed differently (see :option:`--demangle`). .. code-block:: c. // test.h; extern ""C"" inline int foz() {; return 1234;; }. .. code-block:: c. // test.cpp; #include ""test.h""; int bar=42;. int foo() {; return bar;; }. int baz() {; volatile int k = 42;; return foz() + k;; }. int main() {; return foo() + baz();; }. These files are built as follows:. .. code-block:: console. $ clang -g test.cpp -o test.elf; $ clang -g -O2 test.cpp -o inlined.elf. Example 1 - addresses and object on command-line:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf 0x4004d0 0x400490; foz",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:5981,Modifiability,variab,variable,5981,"rform lookups as if the object were relocated by the; offset. .. option:: --basenames, -s. Print just the file's name without any directories, instead of the; absolute path. .. option:: --build-id. Look up the object using the given build ID, specified as a hexadecimal; string. Mutually exclusive with :option:`--obj`. .. option:: --color [=<always|auto|never>]. Specify whether to use color in :option:`--filter-markup` mode. Defaults to; ``auto``, which detects whether standard output supports color. Specifying; ``--color`` alone is equivalent to ``--color=always``. .. option:: --debug-file-directory <path>. Provide a path to a directory with a `.build-id` subdirectory to search for; debug information for stripped binaries. Multiple instances of this argument; are searched in the order given. .. option:: --debuginfod, --no-debuginfod. Whether or not to try debuginfod lookups for debug binaries. Unless specified,; debuginfod is only enabled if libcurl was compiled in (``LLVM_ENABLE_CURL``); and at least one server URL was provided by the environment variable; ``DEBUGINFOD_URLS``. .. _llvm-symbolizer-opt-C:. .. option:: --demangle, -C. Print demangled function names, if the names are mangled (e.g. the mangled; name `_Z3bazv` becomes `baz()`, whilst the non-mangled name `foz` is printed; as is). Defaults to true. .. option:: --dwp <path>. Use the specified DWP file at ``<path>`` for any CUs that have split DWARF; debug data. .. option:: --fallback-debug-path <path>. When a separate file contains debug data, and is referenced by a GNU debug; link section, use the specified path as a basis for locating the debug data if; it cannot be found relative to the object. .. option:: --filter-markup. Reads from standard input, converts contained; :doc:`Symbolizer Markup </SymbolizerMarkupFormat>` into human-readable form,; and prints the results to standard output. The following markup elements are; not yet supported:. * ``{{{hexdict}}}``; * ``{{{dumpfile}}}``. The ``{{{bt}}}`` ba",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:4874,Performance,perform,performing,4874,"4.txt; CODE test.elf 0x4004a0; DATA inlined.elf 0x601028. $ llvm-symbolizer < addr4.txt; main; /tmp/test.cpp:15:0. bar; 6295592 4. Example 6 - path-style options:. This example uses the same source file as above, but the source file's; full path is /tmp/foo/test.cpp and is compiled as follows. The first case; shows the default absolute path, the second --basenames, and the third; shows --relativenames. .. code-block:: console. $ pwd; /tmp; $ clang -g foo/test.cpp -o test.elf; $ llvm-symbolizer --obj=test.elf 0x4004a0; main; /tmp/foo/test.cpp:15:0; $ llvm-symbolizer --obj=test.elf 0x4004a0 --basenames; main; test.cpp:15:0; $ llvm-symbolizer --obj=test.elf 0x4004a0 --relativenames; main; foo/test.cpp:15:0. Example 7 - Addresses as symbol names:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf main; main; /tmp/test.cpp:14:0; $ llvm-symbolizer --obj=test.elf ""CODE foz""; foz; /tmp/test.h:1:0. OPTIONS; -------. .. option:: --adjust-vma <offset>. Add the specified offset to object file addresses when performing lookups.; This can be used to perform lookups as if the object were relocated by the; offset. .. option:: --basenames, -s. Print just the file's name without any directories, instead of the; absolute path. .. option:: --build-id. Look up the object using the given build ID, specified as a hexadecimal; string. Mutually exclusive with :option:`--obj`. .. option:: --color [=<always|auto|never>]. Specify whether to use color in :option:`--filter-markup` mode. Defaults to; ``auto``, which detects whether standard output supports color. Specifying; ``--color`` alone is equivalent to ``--color=always``. .. option:: --debug-file-directory <path>. Provide a path to a directory with a `.build-id` subdirectory to search for; debug information for stripped binaries. Multiple instances of this argument; are searched in the order given. .. option:: --debuginfod, --no-debuginfod. Whether or not to try debuginfod lookups for debug binaries. Unless specified,; debuginfod is",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:4915,Performance,perform,perform,4915,"dr4.txt; main; /tmp/test.cpp:15:0. bar; 6295592 4. Example 6 - path-style options:. This example uses the same source file as above, but the source file's; full path is /tmp/foo/test.cpp and is compiled as follows. The first case; shows the default absolute path, the second --basenames, and the third; shows --relativenames. .. code-block:: console. $ pwd; /tmp; $ clang -g foo/test.cpp -o test.elf; $ llvm-symbolizer --obj=test.elf 0x4004a0; main; /tmp/foo/test.cpp:15:0; $ llvm-symbolizer --obj=test.elf 0x4004a0 --basenames; main; test.cpp:15:0; $ llvm-symbolizer --obj=test.elf 0x4004a0 --relativenames; main; foo/test.cpp:15:0. Example 7 - Addresses as symbol names:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf main; main; /tmp/test.cpp:14:0; $ llvm-symbolizer --obj=test.elf ""CODE foz""; foz; /tmp/test.h:1:0. OPTIONS; -------. .. option:: --adjust-vma <offset>. Add the specified offset to object file addresses when performing lookups.; This can be used to perform lookups as if the object were relocated by the; offset. .. option:: --basenames, -s. Print just the file's name without any directories, instead of the; absolute path. .. option:: --build-id. Look up the object using the given build ID, specified as a hexadecimal; string. Mutually exclusive with :option:`--obj`. .. option:: --color [=<always|auto|never>]. Specify whether to use color in :option:`--filter-markup` mode. Defaults to; ``auto``, which detects whether standard output supports color. Specifying; ``--color`` alone is equivalent to ``--color=always``. .. option:: --debug-file-directory <path>. Provide a path to a directory with a `.build-id` subdirectory to search for; debug information for stripped binaries. Multiple instances of this argument; are searched in the order given. .. option:: --debuginfod, --no-debuginfod. Whether or not to try debuginfod lookups for debug binaries. Unless specified,; debuginfod is only enabled if libcurl was compiled in (``LLVM_ENABLE_CURL``); and at least on",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:7456,Performance,load,loaded,7456,"ntains debug data, and is referenced by a GNU debug; link section, use the specified path as a basis for locating the debug data if; it cannot be found relative to the object. .. option:: --filter-markup. Reads from standard input, converts contained; :doc:`Symbolizer Markup </SymbolizerMarkupFormat>` into human-readable form,; and prints the results to standard output. The following markup elements are; not yet supported:. * ``{{{hexdict}}}``; * ``{{{dumpfile}}}``. The ``{{{bt}}}`` backtrace element reports frames using the following syntax:. ``#<number>[.<inline>] <address> <function> <file>:<line>:<col> (<module>+<relative address>)``. ``<inline>`` provides frame numbers for calls inlined into the caller; corresponding to ``<number>``. The inlined call numbers start at 1 and increase; from callee to caller. ``<address>`` is an address inside the call instruction to the function. The; address may not be the start of the instruction. ``<relative address>`` is; the corresponding virtual offset in the ``<module>`` loaded at that address. .. _llvm-symbolizer-opt-f:. .. option:: --functions [=<none|short|linkage>], -f. Specify the way function names are printed (omit function name, print short; function name, or print full linkage name, respectively). Defaults to; ``linkage``. .. option:: --help, -h. Show help and usage for this command. .. _llvm-symbolizer-opt-i:. .. option:: --inlining, --inlines, -i. If a source code location is in an inlined function, prints all the inlined; frames. This is the default. .. option:: --no-inlines. Don't print inlined frames. .. option:: --no-demangle. Don't print demangled function names. .. option:: --obj <path>, --exe, -e. Path to object file to be symbolized. If ``-`` is specified, read the object; directly from the standard input stream. Mutually exclusive with; :option:`--build-id`. .. _llvm-symbolizer-opt-output-style:. .. option:: --output-style <LLVM|GNU|JSON>. Specify the preferred output style. Defaults to ``LLVM``. When th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:5374,Safety,detect,detects,5374,"n; /tmp/foo/test.cpp:15:0; $ llvm-symbolizer --obj=test.elf 0x4004a0 --basenames; main; test.cpp:15:0; $ llvm-symbolizer --obj=test.elf 0x4004a0 --relativenames; main; foo/test.cpp:15:0. Example 7 - Addresses as symbol names:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf main; main; /tmp/test.cpp:14:0; $ llvm-symbolizer --obj=test.elf ""CODE foz""; foz; /tmp/test.h:1:0. OPTIONS; -------. .. option:: --adjust-vma <offset>. Add the specified offset to object file addresses when performing lookups.; This can be used to perform lookups as if the object were relocated by the; offset. .. option:: --basenames, -s. Print just the file's name without any directories, instead of the; absolute path. .. option:: --build-id. Look up the object using the given build ID, specified as a hexadecimal; string. Mutually exclusive with :option:`--obj`. .. option:: --color [=<always|auto|never>]. Specify whether to use color in :option:`--filter-markup` mode. Defaults to; ``auto``, which detects whether standard output supports color. Specifying; ``--color`` alone is equivalent to ``--color=always``. .. option:: --debug-file-directory <path>. Provide a path to a directory with a `.build-id` subdirectory to search for; debug information for stripped binaries. Multiple instances of this argument; are searched in the order given. .. option:: --debuginfod, --no-debuginfod. Whether or not to try debuginfod lookups for debug binaries. Unless specified,; debuginfod is only enabled if libcurl was compiled in (``LLVM_ENABLE_CURL``); and at least one server URL was provided by the environment variable; ``DEBUGINFOD_URLS``. .. _llvm-symbolizer-opt-C:. .. option:: --demangle, -C. Print demangled function names, if the names are mangled (e.g. the mangled; name `_Z3bazv` becomes `baz()`, whilst the non-mangled name `foz` is printed; as is). Defaults to true. .. option:: --dwp <path>. Use the specified DWP file at ``<path>`` for any CUs that have split DWARF; debug data. .. option:: --fallbac",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:433,Testability,log,logs,433,"llvm-symbolizer - convert addresses into source code locations; ==============================================================. .. program:: llvm-symbolizer. SYNOPSIS; --------. :program:`llvm-symbolizer` [*options*] [*addresses...*]. DESCRIPTION; -----------. :program:`llvm-symbolizer` reads input names and addresses from the command-line; and prints corresponding source code locations to standard output. It can also; symbolize logs containing :doc:`Symbolizer Markup </SymbolizerMarkupFormat>` via; :option:`--filter-markup`. Addresses may be specified as numbers or symbol names. If no address is specified on the command-line, it reads the addresses from; standard input. If no input name is specified on the command-line, but addresses; are, the first address value is treated as an input name. If an input value is not; recognized, it reports that source information is not found. Input names can be specified together with the addresses either on standard; input or as positional arguments on the command-line. By default, input names; are interpreted as object file paths. However, prefixing a name with; ``BUILDID:`` states that it is a hex build ID rather than a path. This will look; up the corresponding debug binary. For consistency, prefixing a name with; ``FILE:`` explicitly states that it is an object file path (the default). A positional argument or standard input value can be preceded by ""DATA"" or; ""CODE"" to indicate that the address should be symbolized as data or executable; code respectively. If neither is specified, ""CODE"" is assumed. DATA is; symbolized as address and symbol size rather than line number. :program:`llvm-symbolizer` parses options from the environment variable; ``LLVM_SYMBOLIZER_OPTS`` after parsing options from the command line.; ``LLVM_SYMBOLIZER_OPTS`` is primarily useful for supplementing the command-line; options when :program:`llvm-symbolizer` is invoked by another program or; runtime. EXAMPLES; --------. All of the following examples use ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:2200,Testability,test,test,2200,"p the corresponding debug binary. For consistency, prefixing a name with; ``FILE:`` explicitly states that it is an object file path (the default). A positional argument or standard input value can be preceded by ""DATA"" or; ""CODE"" to indicate that the address should be symbolized as data or executable; code respectively. If neither is specified, ""CODE"" is assumed. DATA is; symbolized as address and symbol size rather than line number. :program:`llvm-symbolizer` parses options from the environment variable; ``LLVM_SYMBOLIZER_OPTS`` after parsing options from the command line.; ``LLVM_SYMBOLIZER_OPTS`` is primarily useful for supplementing the command-line; options when :program:`llvm-symbolizer` is invoked by another program or; runtime. EXAMPLES; --------. All of the following examples use the following two source files as input. They; use a mixture of C-style and C++-style linkage to illustrate how these names are; printed differently (see :option:`--demangle`). .. code-block:: c. // test.h; extern ""C"" inline int foz() {; return 1234;; }. .. code-block:: c. // test.cpp; #include ""test.h""; int bar=42;. int foo() {; return bar;; }. int baz() {; volatile int k = 42;; return foz() + k;; }. int main() {; return foo() + baz();; }. These files are built as follows:. .. code-block:: console. $ clang -g test.cpp -o test.elf; $ clang -g -O2 test.cpp -o inlined.elf. Example 1 - addresses and object on command-line:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf 0x4004d0 0x400490; foz; /tmp/test.h:1:0. baz(); /tmp/test.cpp:11:0. Example 2 - addresses on standard input:. .. code-block:: console. $ cat addr.txt; 0x4004a0; 0x400490; 0x4004d0; $ llvm-symbolizer --obj=test.elf < addr.txt; main; /tmp/test.cpp:15:0. baz(); /tmp/test.cpp:11:0. foz; /tmp/./test.h:1:0. Example 3 - object specified with address:. .. code-block:: console. $ llvm-symbolizer ""test.elf 0x400490"" ""FILE:inlined.elf 0x400480""; baz(); /tmp/test.cpp:11:0. foo(); /tmp/test.cpp:8:10. $ cat addr2.txt; FIL",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:2278,Testability,test,test,2278,"LE:`` explicitly states that it is an object file path (the default). A positional argument or standard input value can be preceded by ""DATA"" or; ""CODE"" to indicate that the address should be symbolized as data or executable; code respectively. If neither is specified, ""CODE"" is assumed. DATA is; symbolized as address and symbol size rather than line number. :program:`llvm-symbolizer` parses options from the environment variable; ``LLVM_SYMBOLIZER_OPTS`` after parsing options from the command line.; ``LLVM_SYMBOLIZER_OPTS`` is primarily useful for supplementing the command-line; options when :program:`llvm-symbolizer` is invoked by another program or; runtime. EXAMPLES; --------. All of the following examples use the following two source files as input. They; use a mixture of C-style and C++-style linkage to illustrate how these names are; printed differently (see :option:`--demangle`). .. code-block:: c. // test.h; extern ""C"" inline int foz() {; return 1234;; }. .. code-block:: c. // test.cpp; #include ""test.h""; int bar=42;. int foo() {; return bar;; }. int baz() {; volatile int k = 42;; return foz() + k;; }. int main() {; return foo() + baz();; }. These files are built as follows:. .. code-block:: console. $ clang -g test.cpp -o test.elf; $ clang -g -O2 test.cpp -o inlined.elf. Example 1 - addresses and object on command-line:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf 0x4004d0 0x400490; foz; /tmp/test.h:1:0. baz(); /tmp/test.cpp:11:0. Example 2 - addresses on standard input:. .. code-block:: console. $ cat addr.txt; 0x4004a0; 0x400490; 0x4004d0; $ llvm-symbolizer --obj=test.elf < addr.txt; main; /tmp/test.cpp:15:0. baz(); /tmp/test.cpp:11:0. foz; /tmp/./test.h:1:0. Example 3 - object specified with address:. .. code-block:: console. $ llvm-symbolizer ""test.elf 0x400490"" ""FILE:inlined.elf 0x400480""; baz(); /tmp/test.cpp:11:0. foo(); /tmp/test.cpp:8:10. $ cat addr2.txt; FILE:test.elf 0x4004a0; inlined.elf 0x400480. $ llvm-symbolizer < addr2.txt; main",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:2298,Testability,test,test,2298,"y states that it is an object file path (the default). A positional argument or standard input value can be preceded by ""DATA"" or; ""CODE"" to indicate that the address should be symbolized as data or executable; code respectively. If neither is specified, ""CODE"" is assumed. DATA is; symbolized as address and symbol size rather than line number. :program:`llvm-symbolizer` parses options from the environment variable; ``LLVM_SYMBOLIZER_OPTS`` after parsing options from the command line.; ``LLVM_SYMBOLIZER_OPTS`` is primarily useful for supplementing the command-line; options when :program:`llvm-symbolizer` is invoked by another program or; runtime. EXAMPLES; --------. All of the following examples use the following two source files as input. They; use a mixture of C-style and C++-style linkage to illustrate how these names are; printed differently (see :option:`--demangle`). .. code-block:: c. // test.h; extern ""C"" inline int foz() {; return 1234;; }. .. code-block:: c. // test.cpp; #include ""test.h""; int bar=42;. int foo() {; return bar;; }. int baz() {; volatile int k = 42;; return foz() + k;; }. int main() {; return foo() + baz();; }. These files are built as follows:. .. code-block:: console. $ clang -g test.cpp -o test.elf; $ clang -g -O2 test.cpp -o inlined.elf. Example 1 - addresses and object on command-line:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf 0x4004d0 0x400490; foz; /tmp/test.h:1:0. baz(); /tmp/test.cpp:11:0. Example 2 - addresses on standard input:. .. code-block:: console. $ cat addr.txt; 0x4004a0; 0x400490; 0x4004d0; $ llvm-symbolizer --obj=test.elf < addr.txt; main; /tmp/test.cpp:15:0. baz(); /tmp/test.cpp:11:0. foz; /tmp/./test.h:1:0. Example 3 - object specified with address:. .. code-block:: console. $ llvm-symbolizer ""test.elf 0x400490"" ""FILE:inlined.elf 0x400480""; baz(); /tmp/test.cpp:11:0. foo(); /tmp/test.cpp:8:10. $ cat addr2.txt; FILE:test.elf 0x4004a0; inlined.elf 0x400480. $ llvm-symbolizer < addr2.txt; main; /tmp/test.cp",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:2517,Testability,test,test,2517,"ectively. If neither is specified, ""CODE"" is assumed. DATA is; symbolized as address and symbol size rather than line number. :program:`llvm-symbolizer` parses options from the environment variable; ``LLVM_SYMBOLIZER_OPTS`` after parsing options from the command line.; ``LLVM_SYMBOLIZER_OPTS`` is primarily useful for supplementing the command-line; options when :program:`llvm-symbolizer` is invoked by another program or; runtime. EXAMPLES; --------. All of the following examples use the following two source files as input. They; use a mixture of C-style and C++-style linkage to illustrate how these names are; printed differently (see :option:`--demangle`). .. code-block:: c. // test.h; extern ""C"" inline int foz() {; return 1234;; }. .. code-block:: c. // test.cpp; #include ""test.h""; int bar=42;. int foo() {; return bar;; }. int baz() {; volatile int k = 42;; return foz() + k;; }. int main() {; return foo() + baz();; }. These files are built as follows:. .. code-block:: console. $ clang -g test.cpp -o test.elf; $ clang -g -O2 test.cpp -o inlined.elf. Example 1 - addresses and object on command-line:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf 0x4004d0 0x400490; foz; /tmp/test.h:1:0. baz(); /tmp/test.cpp:11:0. Example 2 - addresses on standard input:. .. code-block:: console. $ cat addr.txt; 0x4004a0; 0x400490; 0x4004d0; $ llvm-symbolizer --obj=test.elf < addr.txt; main; /tmp/test.cpp:15:0. baz(); /tmp/test.cpp:11:0. foz; /tmp/./test.h:1:0. Example 3 - object specified with address:. .. code-block:: console. $ llvm-symbolizer ""test.elf 0x400490"" ""FILE:inlined.elf 0x400480""; baz(); /tmp/test.cpp:11:0. foo(); /tmp/test.cpp:8:10. $ cat addr2.txt; FILE:test.elf 0x4004a0; inlined.elf 0x400480. $ llvm-symbolizer < addr2.txt; main; /tmp/test.cpp:15:0. foo(); /tmp/test.cpp:8:10. Example 4 - BUILDID and FILE prefixes:. .. code-block:: console. $ llvm-symbolizer ""FILE:test.elf 0x400490"" ""DATA BUILDID:123456789abcdef 0x601028""; baz(); /tmp/test.cpp:11:0. bar; 62955",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:2529,Testability,test,test,2529,"ither is specified, ""CODE"" is assumed. DATA is; symbolized as address and symbol size rather than line number. :program:`llvm-symbolizer` parses options from the environment variable; ``LLVM_SYMBOLIZER_OPTS`` after parsing options from the command line.; ``LLVM_SYMBOLIZER_OPTS`` is primarily useful for supplementing the command-line; options when :program:`llvm-symbolizer` is invoked by another program or; runtime. EXAMPLES; --------. All of the following examples use the following two source files as input. They; use a mixture of C-style and C++-style linkage to illustrate how these names are; printed differently (see :option:`--demangle`). .. code-block:: c. // test.h; extern ""C"" inline int foz() {; return 1234;; }. .. code-block:: c. // test.cpp; #include ""test.h""; int bar=42;. int foo() {; return bar;; }. int baz() {; volatile int k = 42;; return foz() + k;; }. int main() {; return foo() + baz();; }. These files are built as follows:. .. code-block:: console. $ clang -g test.cpp -o test.elf; $ clang -g -O2 test.cpp -o inlined.elf. Example 1 - addresses and object on command-line:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf 0x4004d0 0x400490; foz; /tmp/test.h:1:0. baz(); /tmp/test.cpp:11:0. Example 2 - addresses on standard input:. .. code-block:: console. $ cat addr.txt; 0x4004a0; 0x400490; 0x4004d0; $ llvm-symbolizer --obj=test.elf < addr.txt; main; /tmp/test.cpp:15:0. baz(); /tmp/test.cpp:11:0. foz; /tmp/./test.h:1:0. Example 3 - object specified with address:. .. code-block:: console. $ llvm-symbolizer ""test.elf 0x400490"" ""FILE:inlined.elf 0x400480""; baz(); /tmp/test.cpp:11:0. foo(); /tmp/test.cpp:8:10. $ cat addr2.txt; FILE:test.elf 0x4004a0; inlined.elf 0x400480. $ llvm-symbolizer < addr2.txt; main; /tmp/test.cpp:15:0. foo(); /tmp/test.cpp:8:10. Example 4 - BUILDID and FILE prefixes:. .. code-block:: console. $ llvm-symbolizer ""FILE:test.elf 0x400490"" ""DATA BUILDID:123456789abcdef 0x601028""; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. $ cat ad",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:2554,Testability,test,test,2554,", ""CODE"" is assumed. DATA is; symbolized as address and symbol size rather than line number. :program:`llvm-symbolizer` parses options from the environment variable; ``LLVM_SYMBOLIZER_OPTS`` after parsing options from the command line.; ``LLVM_SYMBOLIZER_OPTS`` is primarily useful for supplementing the command-line; options when :program:`llvm-symbolizer` is invoked by another program or; runtime. EXAMPLES; --------. All of the following examples use the following two source files as input. They; use a mixture of C-style and C++-style linkage to illustrate how these names are; printed differently (see :option:`--demangle`). .. code-block:: c. // test.h; extern ""C"" inline int foz() {; return 1234;; }. .. code-block:: c. // test.cpp; #include ""test.h""; int bar=42;. int foo() {; return bar;; }. int baz() {; volatile int k = 42;; return foz() + k;; }. int main() {; return foo() + baz();; }. These files are built as follows:. .. code-block:: console. $ clang -g test.cpp -o test.elf; $ clang -g -O2 test.cpp -o inlined.elf. Example 1 - addresses and object on command-line:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf 0x4004d0 0x400490; foz; /tmp/test.h:1:0. baz(); /tmp/test.cpp:11:0. Example 2 - addresses on standard input:. .. code-block:: console. $ cat addr.txt; 0x4004a0; 0x400490; 0x4004d0; $ llvm-symbolizer --obj=test.elf < addr.txt; main; /tmp/test.cpp:15:0. baz(); /tmp/test.cpp:11:0. foz; /tmp/./test.h:1:0. Example 3 - object specified with address:. .. code-block:: console. $ llvm-symbolizer ""test.elf 0x400490"" ""FILE:inlined.elf 0x400480""; baz(); /tmp/test.cpp:11:0. foo(); /tmp/test.cpp:8:10. $ cat addr2.txt; FILE:test.elf 0x4004a0; inlined.elf 0x400480. $ llvm-symbolizer < addr2.txt; main; /tmp/test.cpp:15:0. foo(); /tmp/test.cpp:8:10. Example 4 - BUILDID and FILE prefixes:. .. code-block:: console. $ llvm-symbolizer ""FILE:test.elf 0x400490"" ""DATA BUILDID:123456789abcdef 0x601028""; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. $ cat addr3.txt; FILE:test.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:2679,Testability,test,test,2679,"ses options from the environment variable; ``LLVM_SYMBOLIZER_OPTS`` after parsing options from the command line.; ``LLVM_SYMBOLIZER_OPTS`` is primarily useful for supplementing the command-line; options when :program:`llvm-symbolizer` is invoked by another program or; runtime. EXAMPLES; --------. All of the following examples use the following two source files as input. They; use a mixture of C-style and C++-style linkage to illustrate how these names are; printed differently (see :option:`--demangle`). .. code-block:: c. // test.h; extern ""C"" inline int foz() {; return 1234;; }. .. code-block:: c. // test.cpp; #include ""test.h""; int bar=42;. int foo() {; return bar;; }. int baz() {; volatile int k = 42;; return foz() + k;; }. int main() {; return foo() + baz();; }. These files are built as follows:. .. code-block:: console. $ clang -g test.cpp -o test.elf; $ clang -g -O2 test.cpp -o inlined.elf. Example 1 - addresses and object on command-line:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf 0x4004d0 0x400490; foz; /tmp/test.h:1:0. baz(); /tmp/test.cpp:11:0. Example 2 - addresses on standard input:. .. code-block:: console. $ cat addr.txt; 0x4004a0; 0x400490; 0x4004d0; $ llvm-symbolizer --obj=test.elf < addr.txt; main; /tmp/test.cpp:15:0. baz(); /tmp/test.cpp:11:0. foz; /tmp/./test.h:1:0. Example 3 - object specified with address:. .. code-block:: console. $ llvm-symbolizer ""test.elf 0x400490"" ""FILE:inlined.elf 0x400480""; baz(); /tmp/test.cpp:11:0. foo(); /tmp/test.cpp:8:10. $ cat addr2.txt; FILE:test.elf 0x4004a0; inlined.elf 0x400480. $ llvm-symbolizer < addr2.txt; main; /tmp/test.cpp:15:0. foo(); /tmp/test.cpp:8:10. Example 4 - BUILDID and FILE prefixes:. .. code-block:: console. $ llvm-symbolizer ""FILE:test.elf 0x400490"" ""DATA BUILDID:123456789abcdef 0x601028""; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. $ cat addr3.txt; FILE:test.elf 0x400490; DATA BUILDID:123456789abcdef 0x601028. $ llvm-symbolizer < addr3.txt; baz(); /tmp/test.cpp:11:0. bar; 629559",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:2717,Testability,test,test,2717,"ariable; ``LLVM_SYMBOLIZER_OPTS`` after parsing options from the command line.; ``LLVM_SYMBOLIZER_OPTS`` is primarily useful for supplementing the command-line; options when :program:`llvm-symbolizer` is invoked by another program or; runtime. EXAMPLES; --------. All of the following examples use the following two source files as input. They; use a mixture of C-style and C++-style linkage to illustrate how these names are; printed differently (see :option:`--demangle`). .. code-block:: c. // test.h; extern ""C"" inline int foz() {; return 1234;; }. .. code-block:: c. // test.cpp; #include ""test.h""; int bar=42;. int foo() {; return bar;; }. int baz() {; volatile int k = 42;; return foz() + k;; }. int main() {; return foo() + baz();; }. These files are built as follows:. .. code-block:: console. $ clang -g test.cpp -o test.elf; $ clang -g -O2 test.cpp -o inlined.elf. Example 1 - addresses and object on command-line:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf 0x4004d0 0x400490; foz; /tmp/test.h:1:0. baz(); /tmp/test.cpp:11:0. Example 2 - addresses on standard input:. .. code-block:: console. $ cat addr.txt; 0x4004a0; 0x400490; 0x4004d0; $ llvm-symbolizer --obj=test.elf < addr.txt; main; /tmp/test.cpp:15:0. baz(); /tmp/test.cpp:11:0. foz; /tmp/./test.h:1:0. Example 3 - object specified with address:. .. code-block:: console. $ llvm-symbolizer ""test.elf 0x400490"" ""FILE:inlined.elf 0x400480""; baz(); /tmp/test.cpp:11:0. foo(); /tmp/test.cpp:8:10. $ cat addr2.txt; FILE:test.elf 0x4004a0; inlined.elf 0x400480. $ llvm-symbolizer < addr2.txt; main; /tmp/test.cpp:15:0. foo(); /tmp/test.cpp:8:10. Example 4 - BUILDID and FILE prefixes:. .. code-block:: console. $ llvm-symbolizer ""FILE:test.elf 0x400490"" ""DATA BUILDID:123456789abcdef 0x601028""; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. $ cat addr3.txt; FILE:test.elf 0x400490; DATA BUILDID:123456789abcdef 0x601028. $ llvm-symbolizer < addr3.txt; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. Example 5 - CODE and DATA pre",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:2741,Testability,test,test,2741,"after parsing options from the command line.; ``LLVM_SYMBOLIZER_OPTS`` is primarily useful for supplementing the command-line; options when :program:`llvm-symbolizer` is invoked by another program or; runtime. EXAMPLES; --------. All of the following examples use the following two source files as input. They; use a mixture of C-style and C++-style linkage to illustrate how these names are; printed differently (see :option:`--demangle`). .. code-block:: c. // test.h; extern ""C"" inline int foz() {; return 1234;; }. .. code-block:: c. // test.cpp; #include ""test.h""; int bar=42;. int foo() {; return bar;; }. int baz() {; volatile int k = 42;; return foz() + k;; }. int main() {; return foo() + baz();; }. These files are built as follows:. .. code-block:: console. $ clang -g test.cpp -o test.elf; $ clang -g -O2 test.cpp -o inlined.elf. Example 1 - addresses and object on command-line:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf 0x4004d0 0x400490; foz; /tmp/test.h:1:0. baz(); /tmp/test.cpp:11:0. Example 2 - addresses on standard input:. .. code-block:: console. $ cat addr.txt; 0x4004a0; 0x400490; 0x4004d0; $ llvm-symbolizer --obj=test.elf < addr.txt; main; /tmp/test.cpp:15:0. baz(); /tmp/test.cpp:11:0. foz; /tmp/./test.h:1:0. Example 3 - object specified with address:. .. code-block:: console. $ llvm-symbolizer ""test.elf 0x400490"" ""FILE:inlined.elf 0x400480""; baz(); /tmp/test.cpp:11:0. foo(); /tmp/test.cpp:8:10. $ cat addr2.txt; FILE:test.elf 0x4004a0; inlined.elf 0x400480. $ llvm-symbolizer < addr2.txt; main; /tmp/test.cpp:15:0. foo(); /tmp/test.cpp:8:10. Example 4 - BUILDID and FILE prefixes:. .. code-block:: console. $ llvm-symbolizer ""FILE:test.elf 0x400490"" ""DATA BUILDID:123456789abcdef 0x601028""; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. $ cat addr3.txt; FILE:test.elf 0x400490; DATA BUILDID:123456789abcdef 0x601028. $ llvm-symbolizer < addr3.txt; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. Example 5 - CODE and DATA prefixes:. .. code-block:: console. $",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:2893,Testability,test,test,2893,"tions when :program:`llvm-symbolizer` is invoked by another program or; runtime. EXAMPLES; --------. All of the following examples use the following two source files as input. They; use a mixture of C-style and C++-style linkage to illustrate how these names are; printed differently (see :option:`--demangle`). .. code-block:: c. // test.h; extern ""C"" inline int foz() {; return 1234;; }. .. code-block:: c. // test.cpp; #include ""test.h""; int bar=42;. int foo() {; return bar;; }. int baz() {; volatile int k = 42;; return foz() + k;; }. int main() {; return foo() + baz();; }. These files are built as follows:. .. code-block:: console. $ clang -g test.cpp -o test.elf; $ clang -g -O2 test.cpp -o inlined.elf. Example 1 - addresses and object on command-line:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf 0x4004d0 0x400490; foz; /tmp/test.h:1:0. baz(); /tmp/test.cpp:11:0. Example 2 - addresses on standard input:. .. code-block:: console. $ cat addr.txt; 0x4004a0; 0x400490; 0x4004d0; $ llvm-symbolizer --obj=test.elf < addr.txt; main; /tmp/test.cpp:15:0. baz(); /tmp/test.cpp:11:0. foz; /tmp/./test.h:1:0. Example 3 - object specified with address:. .. code-block:: console. $ llvm-symbolizer ""test.elf 0x400490"" ""FILE:inlined.elf 0x400480""; baz(); /tmp/test.cpp:11:0. foo(); /tmp/test.cpp:8:10. $ cat addr2.txt; FILE:test.elf 0x4004a0; inlined.elf 0x400480. $ llvm-symbolizer < addr2.txt; main; /tmp/test.cpp:15:0. foo(); /tmp/test.cpp:8:10. Example 4 - BUILDID and FILE prefixes:. .. code-block:: console. $ llvm-symbolizer ""FILE:test.elf 0x400490"" ""DATA BUILDID:123456789abcdef 0x601028""; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. $ cat addr3.txt; FILE:test.elf 0x400490; DATA BUILDID:123456789abcdef 0x601028. $ llvm-symbolizer < addr3.txt; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. Example 5 - CODE and DATA prefixes:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf ""CODE 0x400490"" ""DATA 0x601028""; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. $ cat addr4.txt; CODE",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:2925,Testability,test,test,2925,"nother program or; runtime. EXAMPLES; --------. All of the following examples use the following two source files as input. They; use a mixture of C-style and C++-style linkage to illustrate how these names are; printed differently (see :option:`--demangle`). .. code-block:: c. // test.h; extern ""C"" inline int foz() {; return 1234;; }. .. code-block:: c. // test.cpp; #include ""test.h""; int bar=42;. int foo() {; return bar;; }. int baz() {; volatile int k = 42;; return foz() + k;; }. int main() {; return foo() + baz();; }. These files are built as follows:. .. code-block:: console. $ clang -g test.cpp -o test.elf; $ clang -g -O2 test.cpp -o inlined.elf. Example 1 - addresses and object on command-line:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf 0x4004d0 0x400490; foz; /tmp/test.h:1:0. baz(); /tmp/test.cpp:11:0. Example 2 - addresses on standard input:. .. code-block:: console. $ cat addr.txt; 0x4004a0; 0x400490; 0x4004d0; $ llvm-symbolizer --obj=test.elf < addr.txt; main; /tmp/test.cpp:15:0. baz(); /tmp/test.cpp:11:0. foz; /tmp/./test.h:1:0. Example 3 - object specified with address:. .. code-block:: console. $ llvm-symbolizer ""test.elf 0x400490"" ""FILE:inlined.elf 0x400480""; baz(); /tmp/test.cpp:11:0. foo(); /tmp/test.cpp:8:10. $ cat addr2.txt; FILE:test.elf 0x4004a0; inlined.elf 0x400480. $ llvm-symbolizer < addr2.txt; main; /tmp/test.cpp:15:0. foo(); /tmp/test.cpp:8:10. Example 4 - BUILDID and FILE prefixes:. .. code-block:: console. $ llvm-symbolizer ""FILE:test.elf 0x400490"" ""DATA BUILDID:123456789abcdef 0x601028""; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. $ cat addr3.txt; FILE:test.elf 0x400490; DATA BUILDID:123456789abcdef 0x601028. $ llvm-symbolizer < addr3.txt; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. Example 5 - CODE and DATA prefixes:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf ""CODE 0x400490"" ""DATA 0x601028""; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. $ cat addr4.txt; CODE test.elf 0x4004a0; DATA inlined.elf 0x601028. $ llvm-",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:2952,Testability,test,test,2952,"XAMPLES; --------. All of the following examples use the following two source files as input. They; use a mixture of C-style and C++-style linkage to illustrate how these names are; printed differently (see :option:`--demangle`). .. code-block:: c. // test.h; extern ""C"" inline int foz() {; return 1234;; }. .. code-block:: c. // test.cpp; #include ""test.h""; int bar=42;. int foo() {; return bar;; }. int baz() {; volatile int k = 42;; return foz() + k;; }. int main() {; return foo() + baz();; }. These files are built as follows:. .. code-block:: console. $ clang -g test.cpp -o test.elf; $ clang -g -O2 test.cpp -o inlined.elf. Example 1 - addresses and object on command-line:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf 0x4004d0 0x400490; foz; /tmp/test.h:1:0. baz(); /tmp/test.cpp:11:0. Example 2 - addresses on standard input:. .. code-block:: console. $ cat addr.txt; 0x4004a0; 0x400490; 0x4004d0; $ llvm-symbolizer --obj=test.elf < addr.txt; main; /tmp/test.cpp:15:0. baz(); /tmp/test.cpp:11:0. foz; /tmp/./test.h:1:0. Example 3 - object specified with address:. .. code-block:: console. $ llvm-symbolizer ""test.elf 0x400490"" ""FILE:inlined.elf 0x400480""; baz(); /tmp/test.cpp:11:0. foo(); /tmp/test.cpp:8:10. $ cat addr2.txt; FILE:test.elf 0x4004a0; inlined.elf 0x400480. $ llvm-symbolizer < addr2.txt; main; /tmp/test.cpp:15:0. foo(); /tmp/test.cpp:8:10. Example 4 - BUILDID and FILE prefixes:. .. code-block:: console. $ llvm-symbolizer ""FILE:test.elf 0x400490"" ""DATA BUILDID:123456789abcdef 0x601028""; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. $ cat addr3.txt; FILE:test.elf 0x400490; DATA BUILDID:123456789abcdef 0x601028. $ llvm-symbolizer < addr3.txt; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. Example 5 - CODE and DATA prefixes:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf ""CODE 0x400490"" ""DATA 0x601028""; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. $ cat addr4.txt; CODE test.elf 0x4004a0; DATA inlined.elf 0x601028. $ llvm-symbolizer < addr4.txt; main",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:2979,Testability,test,test,2979,"lowing examples use the following two source files as input. They; use a mixture of C-style and C++-style linkage to illustrate how these names are; printed differently (see :option:`--demangle`). .. code-block:: c. // test.h; extern ""C"" inline int foz() {; return 1234;; }. .. code-block:: c. // test.cpp; #include ""test.h""; int bar=42;. int foo() {; return bar;; }. int baz() {; volatile int k = 42;; return foz() + k;; }. int main() {; return foo() + baz();; }. These files are built as follows:. .. code-block:: console. $ clang -g test.cpp -o test.elf; $ clang -g -O2 test.cpp -o inlined.elf. Example 1 - addresses and object on command-line:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf 0x4004d0 0x400490; foz; /tmp/test.h:1:0. baz(); /tmp/test.cpp:11:0. Example 2 - addresses on standard input:. .. code-block:: console. $ cat addr.txt; 0x4004a0; 0x400490; 0x4004d0; $ llvm-symbolizer --obj=test.elf < addr.txt; main; /tmp/test.cpp:15:0. baz(); /tmp/test.cpp:11:0. foz; /tmp/./test.h:1:0. Example 3 - object specified with address:. .. code-block:: console. $ llvm-symbolizer ""test.elf 0x400490"" ""FILE:inlined.elf 0x400480""; baz(); /tmp/test.cpp:11:0. foo(); /tmp/test.cpp:8:10. $ cat addr2.txt; FILE:test.elf 0x4004a0; inlined.elf 0x400480. $ llvm-symbolizer < addr2.txt; main; /tmp/test.cpp:15:0. foo(); /tmp/test.cpp:8:10. Example 4 - BUILDID and FILE prefixes:. .. code-block:: console. $ llvm-symbolizer ""FILE:test.elf 0x400490"" ""DATA BUILDID:123456789abcdef 0x601028""; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. $ cat addr3.txt; FILE:test.elf 0x400490; DATA BUILDID:123456789abcdef 0x601028. $ llvm-symbolizer < addr3.txt; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. Example 5 - CODE and DATA prefixes:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf ""CODE 0x400490"" ""DATA 0x601028""; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. $ cat addr4.txt; CODE test.elf 0x4004a0; DATA inlined.elf 0x601028. $ llvm-symbolizer < addr4.txt; main; /tmp/test.cpp:15:0. bar; 629559",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:3079,Testability,test,test,3079,"e and C++-style linkage to illustrate how these names are; printed differently (see :option:`--demangle`). .. code-block:: c. // test.h; extern ""C"" inline int foz() {; return 1234;; }. .. code-block:: c. // test.cpp; #include ""test.h""; int bar=42;. int foo() {; return bar;; }. int baz() {; volatile int k = 42;; return foz() + k;; }. int main() {; return foo() + baz();; }. These files are built as follows:. .. code-block:: console. $ clang -g test.cpp -o test.elf; $ clang -g -O2 test.cpp -o inlined.elf. Example 1 - addresses and object on command-line:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf 0x4004d0 0x400490; foz; /tmp/test.h:1:0. baz(); /tmp/test.cpp:11:0. Example 2 - addresses on standard input:. .. code-block:: console. $ cat addr.txt; 0x4004a0; 0x400490; 0x4004d0; $ llvm-symbolizer --obj=test.elf < addr.txt; main; /tmp/test.cpp:15:0. baz(); /tmp/test.cpp:11:0. foz; /tmp/./test.h:1:0. Example 3 - object specified with address:. .. code-block:: console. $ llvm-symbolizer ""test.elf 0x400490"" ""FILE:inlined.elf 0x400480""; baz(); /tmp/test.cpp:11:0. foo(); /tmp/test.cpp:8:10. $ cat addr2.txt; FILE:test.elf 0x4004a0; inlined.elf 0x400480. $ llvm-symbolizer < addr2.txt; main; /tmp/test.cpp:15:0. foo(); /tmp/test.cpp:8:10. Example 4 - BUILDID and FILE prefixes:. .. code-block:: console. $ llvm-symbolizer ""FILE:test.elf 0x400490"" ""DATA BUILDID:123456789abcdef 0x601028""; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. $ cat addr3.txt; FILE:test.elf 0x400490; DATA BUILDID:123456789abcdef 0x601028. $ llvm-symbolizer < addr3.txt; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. Example 5 - CODE and DATA prefixes:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf ""CODE 0x400490"" ""DATA 0x601028""; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. $ cat addr4.txt; CODE test.elf 0x4004a0; DATA inlined.elf 0x601028. $ llvm-symbolizer < addr4.txt; main; /tmp/test.cpp:15:0. bar; 6295592 4. Example 6 - path-style options:. This example uses the same source file as above, but ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:3139,Testability,test,test,3139,"; printed differently (see :option:`--demangle`). .. code-block:: c. // test.h; extern ""C"" inline int foz() {; return 1234;; }. .. code-block:: c. // test.cpp; #include ""test.h""; int bar=42;. int foo() {; return bar;; }. int baz() {; volatile int k = 42;; return foz() + k;; }. int main() {; return foo() + baz();; }. These files are built as follows:. .. code-block:: console. $ clang -g test.cpp -o test.elf; $ clang -g -O2 test.cpp -o inlined.elf. Example 1 - addresses and object on command-line:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf 0x4004d0 0x400490; foz; /tmp/test.h:1:0. baz(); /tmp/test.cpp:11:0. Example 2 - addresses on standard input:. .. code-block:: console. $ cat addr.txt; 0x4004a0; 0x400490; 0x4004d0; $ llvm-symbolizer --obj=test.elf < addr.txt; main; /tmp/test.cpp:15:0. baz(); /tmp/test.cpp:11:0. foz; /tmp/./test.h:1:0. Example 3 - object specified with address:. .. code-block:: console. $ llvm-symbolizer ""test.elf 0x400490"" ""FILE:inlined.elf 0x400480""; baz(); /tmp/test.cpp:11:0. foo(); /tmp/test.cpp:8:10. $ cat addr2.txt; FILE:test.elf 0x4004a0; inlined.elf 0x400480. $ llvm-symbolizer < addr2.txt; main; /tmp/test.cpp:15:0. foo(); /tmp/test.cpp:8:10. Example 4 - BUILDID and FILE prefixes:. .. code-block:: console. $ llvm-symbolizer ""FILE:test.elf 0x400490"" ""DATA BUILDID:123456789abcdef 0x601028""; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. $ cat addr3.txt; FILE:test.elf 0x400490; DATA BUILDID:123456789abcdef 0x601028. $ llvm-symbolizer < addr3.txt; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. Example 5 - CODE and DATA prefixes:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf ""CODE 0x400490"" ""DATA 0x601028""; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. $ cat addr4.txt; CODE test.elf 0x4004a0; DATA inlined.elf 0x601028. $ llvm-symbolizer < addr4.txt; main; /tmp/test.cpp:15:0. bar; 6295592 4. Example 6 - path-style options:. This example uses the same source file as above, but the source file's; full path is /tmp/foo/test.cpp and is",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:3166,Testability,test,test,3166,":`--demangle`). .. code-block:: c. // test.h; extern ""C"" inline int foz() {; return 1234;; }. .. code-block:: c. // test.cpp; #include ""test.h""; int bar=42;. int foo() {; return bar;; }. int baz() {; volatile int k = 42;; return foz() + k;; }. int main() {; return foo() + baz();; }. These files are built as follows:. .. code-block:: console. $ clang -g test.cpp -o test.elf; $ clang -g -O2 test.cpp -o inlined.elf. Example 1 - addresses and object on command-line:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf 0x4004d0 0x400490; foz; /tmp/test.h:1:0. baz(); /tmp/test.cpp:11:0. Example 2 - addresses on standard input:. .. code-block:: console. $ cat addr.txt; 0x4004a0; 0x400490; 0x4004d0; $ llvm-symbolizer --obj=test.elf < addr.txt; main; /tmp/test.cpp:15:0. baz(); /tmp/test.cpp:11:0. foz; /tmp/./test.h:1:0. Example 3 - object specified with address:. .. code-block:: console. $ llvm-symbolizer ""test.elf 0x400490"" ""FILE:inlined.elf 0x400480""; baz(); /tmp/test.cpp:11:0. foo(); /tmp/test.cpp:8:10. $ cat addr2.txt; FILE:test.elf 0x4004a0; inlined.elf 0x400480. $ llvm-symbolizer < addr2.txt; main; /tmp/test.cpp:15:0. foo(); /tmp/test.cpp:8:10. Example 4 - BUILDID and FILE prefixes:. .. code-block:: console. $ llvm-symbolizer ""FILE:test.elf 0x400490"" ""DATA BUILDID:123456789abcdef 0x601028""; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. $ cat addr3.txt; FILE:test.elf 0x400490; DATA BUILDID:123456789abcdef 0x601028. $ llvm-symbolizer < addr3.txt; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. Example 5 - CODE and DATA prefixes:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf ""CODE 0x400490"" ""DATA 0x601028""; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. $ cat addr4.txt; CODE test.elf 0x4004a0; DATA inlined.elf 0x601028. $ llvm-symbolizer < addr4.txt; main; /tmp/test.cpp:15:0. bar; 6295592 4. Example 6 - path-style options:. This example uses the same source file as above, but the source file's; full path is /tmp/foo/test.cpp and is compiled as follows. The first ca",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:3203,Testability,test,test,3203,"test.h; extern ""C"" inline int foz() {; return 1234;; }. .. code-block:: c. // test.cpp; #include ""test.h""; int bar=42;. int foo() {; return bar;; }. int baz() {; volatile int k = 42;; return foz() + k;; }. int main() {; return foo() + baz();; }. These files are built as follows:. .. code-block:: console. $ clang -g test.cpp -o test.elf; $ clang -g -O2 test.cpp -o inlined.elf. Example 1 - addresses and object on command-line:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf 0x4004d0 0x400490; foz; /tmp/test.h:1:0. baz(); /tmp/test.cpp:11:0. Example 2 - addresses on standard input:. .. code-block:: console. $ cat addr.txt; 0x4004a0; 0x400490; 0x4004d0; $ llvm-symbolizer --obj=test.elf < addr.txt; main; /tmp/test.cpp:15:0. baz(); /tmp/test.cpp:11:0. foz; /tmp/./test.h:1:0. Example 3 - object specified with address:. .. code-block:: console. $ llvm-symbolizer ""test.elf 0x400490"" ""FILE:inlined.elf 0x400480""; baz(); /tmp/test.cpp:11:0. foo(); /tmp/test.cpp:8:10. $ cat addr2.txt; FILE:test.elf 0x4004a0; inlined.elf 0x400480. $ llvm-symbolizer < addr2.txt; main; /tmp/test.cpp:15:0. foo(); /tmp/test.cpp:8:10. Example 4 - BUILDID and FILE prefixes:. .. code-block:: console. $ llvm-symbolizer ""FILE:test.elf 0x400490"" ""DATA BUILDID:123456789abcdef 0x601028""; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. $ cat addr3.txt; FILE:test.elf 0x400490; DATA BUILDID:123456789abcdef 0x601028. $ llvm-symbolizer < addr3.txt; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. Example 5 - CODE and DATA prefixes:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf ""CODE 0x400490"" ""DATA 0x601028""; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. $ cat addr4.txt; CODE test.elf 0x4004a0; DATA inlined.elf 0x601028. $ llvm-symbolizer < addr4.txt; main; /tmp/test.cpp:15:0. bar; 6295592 4. Example 6 - path-style options:. This example uses the same source file as above, but the source file's; full path is /tmp/foo/test.cpp and is compiled as follows. The first case; shows the default absolute path, th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:3286,Testability,test,test,3286,"st.cpp; #include ""test.h""; int bar=42;. int foo() {; return bar;; }. int baz() {; volatile int k = 42;; return foz() + k;; }. int main() {; return foo() + baz();; }. These files are built as follows:. .. code-block:: console. $ clang -g test.cpp -o test.elf; $ clang -g -O2 test.cpp -o inlined.elf. Example 1 - addresses and object on command-line:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf 0x4004d0 0x400490; foz; /tmp/test.h:1:0. baz(); /tmp/test.cpp:11:0. Example 2 - addresses on standard input:. .. code-block:: console. $ cat addr.txt; 0x4004a0; 0x400490; 0x4004d0; $ llvm-symbolizer --obj=test.elf < addr.txt; main; /tmp/test.cpp:15:0. baz(); /tmp/test.cpp:11:0. foz; /tmp/./test.h:1:0. Example 3 - object specified with address:. .. code-block:: console. $ llvm-symbolizer ""test.elf 0x400490"" ""FILE:inlined.elf 0x400480""; baz(); /tmp/test.cpp:11:0. foo(); /tmp/test.cpp:8:10. $ cat addr2.txt; FILE:test.elf 0x4004a0; inlined.elf 0x400480. $ llvm-symbolizer < addr2.txt; main; /tmp/test.cpp:15:0. foo(); /tmp/test.cpp:8:10. Example 4 - BUILDID and FILE prefixes:. .. code-block:: console. $ llvm-symbolizer ""FILE:test.elf 0x400490"" ""DATA BUILDID:123456789abcdef 0x601028""; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. $ cat addr3.txt; FILE:test.elf 0x400490; DATA BUILDID:123456789abcdef 0x601028. $ llvm-symbolizer < addr3.txt; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. Example 5 - CODE and DATA prefixes:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf ""CODE 0x400490"" ""DATA 0x601028""; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. $ cat addr4.txt; CODE test.elf 0x4004a0; DATA inlined.elf 0x601028. $ llvm-symbolizer < addr4.txt; main; /tmp/test.cpp:15:0. bar; 6295592 4. Example 6 - path-style options:. This example uses the same source file as above, but the source file's; full path is /tmp/foo/test.cpp and is compiled as follows. The first case; shows the default absolute path, the second --basenames, and the third; shows --relativenames. .. code-block:: cons",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:3313,Testability,test,test,3313,"t bar=42;. int foo() {; return bar;; }. int baz() {; volatile int k = 42;; return foz() + k;; }. int main() {; return foo() + baz();; }. These files are built as follows:. .. code-block:: console. $ clang -g test.cpp -o test.elf; $ clang -g -O2 test.cpp -o inlined.elf. Example 1 - addresses and object on command-line:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf 0x4004d0 0x400490; foz; /tmp/test.h:1:0. baz(); /tmp/test.cpp:11:0. Example 2 - addresses on standard input:. .. code-block:: console. $ cat addr.txt; 0x4004a0; 0x400490; 0x4004d0; $ llvm-symbolizer --obj=test.elf < addr.txt; main; /tmp/test.cpp:15:0. baz(); /tmp/test.cpp:11:0. foz; /tmp/./test.h:1:0. Example 3 - object specified with address:. .. code-block:: console. $ llvm-symbolizer ""test.elf 0x400490"" ""FILE:inlined.elf 0x400480""; baz(); /tmp/test.cpp:11:0. foo(); /tmp/test.cpp:8:10. $ cat addr2.txt; FILE:test.elf 0x4004a0; inlined.elf 0x400480. $ llvm-symbolizer < addr2.txt; main; /tmp/test.cpp:15:0. foo(); /tmp/test.cpp:8:10. Example 4 - BUILDID and FILE prefixes:. .. code-block:: console. $ llvm-symbolizer ""FILE:test.elf 0x400490"" ""DATA BUILDID:123456789abcdef 0x601028""; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. $ cat addr3.txt; FILE:test.elf 0x400490; DATA BUILDID:123456789abcdef 0x601028. $ llvm-symbolizer < addr3.txt; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. Example 5 - CODE and DATA prefixes:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf ""CODE 0x400490"" ""DATA 0x601028""; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. $ cat addr4.txt; CODE test.elf 0x4004a0; DATA inlined.elf 0x601028. $ llvm-symbolizer < addr4.txt; main; /tmp/test.cpp:15:0. bar; 6295592 4. Example 6 - path-style options:. This example uses the same source file as above, but the source file's; full path is /tmp/foo/test.cpp and is compiled as follows. The first case; shows the default absolute path, the second --basenames, and the third; shows --relativenames. .. code-block:: console. $ pwd; /tmp; $ clang -g",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:3417,Testability,test,test,3417,"nt main() {; return foo() + baz();; }. These files are built as follows:. .. code-block:: console. $ clang -g test.cpp -o test.elf; $ clang -g -O2 test.cpp -o inlined.elf. Example 1 - addresses and object on command-line:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf 0x4004d0 0x400490; foz; /tmp/test.h:1:0. baz(); /tmp/test.cpp:11:0. Example 2 - addresses on standard input:. .. code-block:: console. $ cat addr.txt; 0x4004a0; 0x400490; 0x4004d0; $ llvm-symbolizer --obj=test.elf < addr.txt; main; /tmp/test.cpp:15:0. baz(); /tmp/test.cpp:11:0. foz; /tmp/./test.h:1:0. Example 3 - object specified with address:. .. code-block:: console. $ llvm-symbolizer ""test.elf 0x400490"" ""FILE:inlined.elf 0x400480""; baz(); /tmp/test.cpp:11:0. foo(); /tmp/test.cpp:8:10. $ cat addr2.txt; FILE:test.elf 0x4004a0; inlined.elf 0x400480. $ llvm-symbolizer < addr2.txt; main; /tmp/test.cpp:15:0. foo(); /tmp/test.cpp:8:10. Example 4 - BUILDID and FILE prefixes:. .. code-block:: console. $ llvm-symbolizer ""FILE:test.elf 0x400490"" ""DATA BUILDID:123456789abcdef 0x601028""; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. $ cat addr3.txt; FILE:test.elf 0x400490; DATA BUILDID:123456789abcdef 0x601028. $ llvm-symbolizer < addr3.txt; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. Example 5 - CODE and DATA prefixes:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf ""CODE 0x400490"" ""DATA 0x601028""; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. $ cat addr4.txt; CODE test.elf 0x4004a0; DATA inlined.elf 0x601028. $ llvm-symbolizer < addr4.txt; main; /tmp/test.cpp:15:0. bar; 6295592 4. Example 6 - path-style options:. This example uses the same source file as above, but the source file's; full path is /tmp/foo/test.cpp and is compiled as follows. The first case; shows the default absolute path, the second --basenames, and the third; shows --relativenames. .. code-block:: console. $ pwd; /tmp; $ clang -g foo/test.cpp -o test.elf; $ llvm-symbolizer --obj=test.elf 0x4004a0; main; /tmp/foo/test.cpp:15:0",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:3489,Testability,test,test,3489,"are built as follows:. .. code-block:: console. $ clang -g test.cpp -o test.elf; $ clang -g -O2 test.cpp -o inlined.elf. Example 1 - addresses and object on command-line:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf 0x4004d0 0x400490; foz; /tmp/test.h:1:0. baz(); /tmp/test.cpp:11:0. Example 2 - addresses on standard input:. .. code-block:: console. $ cat addr.txt; 0x4004a0; 0x400490; 0x4004d0; $ llvm-symbolizer --obj=test.elf < addr.txt; main; /tmp/test.cpp:15:0. baz(); /tmp/test.cpp:11:0. foz; /tmp/./test.h:1:0. Example 3 - object specified with address:. .. code-block:: console. $ llvm-symbolizer ""test.elf 0x400490"" ""FILE:inlined.elf 0x400480""; baz(); /tmp/test.cpp:11:0. foo(); /tmp/test.cpp:8:10. $ cat addr2.txt; FILE:test.elf 0x4004a0; inlined.elf 0x400480. $ llvm-symbolizer < addr2.txt; main; /tmp/test.cpp:15:0. foo(); /tmp/test.cpp:8:10. Example 4 - BUILDID and FILE prefixes:. .. code-block:: console. $ llvm-symbolizer ""FILE:test.elf 0x400490"" ""DATA BUILDID:123456789abcdef 0x601028""; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. $ cat addr3.txt; FILE:test.elf 0x400490; DATA BUILDID:123456789abcdef 0x601028. $ llvm-symbolizer < addr3.txt; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. Example 5 - CODE and DATA prefixes:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf ""CODE 0x400490"" ""DATA 0x601028""; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. $ cat addr4.txt; CODE test.elf 0x4004a0; DATA inlined.elf 0x601028. $ llvm-symbolizer < addr4.txt; main; /tmp/test.cpp:15:0. bar; 6295592 4. Example 6 - path-style options:. This example uses the same source file as above, but the source file's; full path is /tmp/foo/test.cpp and is compiled as follows. The first case; shows the default absolute path, the second --basenames, and the third; shows --relativenames. .. code-block:: console. $ pwd; /tmp; $ clang -g foo/test.cpp -o test.elf; $ llvm-symbolizer --obj=test.elf 0x4004a0; main; /tmp/foo/test.cpp:15:0; $ llvm-symbolizer --obj=test.elf 0x4004a0 --basen",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:3542,Testability,test,test,3542,"$ clang -g -O2 test.cpp -o inlined.elf. Example 1 - addresses and object on command-line:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf 0x4004d0 0x400490; foz; /tmp/test.h:1:0. baz(); /tmp/test.cpp:11:0. Example 2 - addresses on standard input:. .. code-block:: console. $ cat addr.txt; 0x4004a0; 0x400490; 0x4004d0; $ llvm-symbolizer --obj=test.elf < addr.txt; main; /tmp/test.cpp:15:0. baz(); /tmp/test.cpp:11:0. foz; /tmp/./test.h:1:0. Example 3 - object specified with address:. .. code-block:: console. $ llvm-symbolizer ""test.elf 0x400490"" ""FILE:inlined.elf 0x400480""; baz(); /tmp/test.cpp:11:0. foo(); /tmp/test.cpp:8:10. $ cat addr2.txt; FILE:test.elf 0x4004a0; inlined.elf 0x400480. $ llvm-symbolizer < addr2.txt; main; /tmp/test.cpp:15:0. foo(); /tmp/test.cpp:8:10. Example 4 - BUILDID and FILE prefixes:. .. code-block:: console. $ llvm-symbolizer ""FILE:test.elf 0x400490"" ""DATA BUILDID:123456789abcdef 0x601028""; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. $ cat addr3.txt; FILE:test.elf 0x400490; DATA BUILDID:123456789abcdef 0x601028. $ llvm-symbolizer < addr3.txt; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. Example 5 - CODE and DATA prefixes:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf ""CODE 0x400490"" ""DATA 0x601028""; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. $ cat addr4.txt; CODE test.elf 0x4004a0; DATA inlined.elf 0x601028. $ llvm-symbolizer < addr4.txt; main; /tmp/test.cpp:15:0. bar; 6295592 4. Example 6 - path-style options:. This example uses the same source file as above, but the source file's; full path is /tmp/foo/test.cpp and is compiled as follows. The first case; shows the default absolute path, the second --basenames, and the third; shows --relativenames. .. code-block:: console. $ pwd; /tmp; $ clang -g foo/test.cpp -o test.elf; $ llvm-symbolizer --obj=test.elf 0x4004a0; main; /tmp/foo/test.cpp:15:0; $ llvm-symbolizer --obj=test.elf 0x4004a0 --basenames; main; test.cpp:15:0; $ llvm-symbolizer --obj=test.elf 0x4004a0 --relativenam",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:3643,Testability,test,test,3643,"-block:: console. $ llvm-symbolizer --obj=test.elf 0x4004d0 0x400490; foz; /tmp/test.h:1:0. baz(); /tmp/test.cpp:11:0. Example 2 - addresses on standard input:. .. code-block:: console. $ cat addr.txt; 0x4004a0; 0x400490; 0x4004d0; $ llvm-symbolizer --obj=test.elf < addr.txt; main; /tmp/test.cpp:15:0. baz(); /tmp/test.cpp:11:0. foz; /tmp/./test.h:1:0. Example 3 - object specified with address:. .. code-block:: console. $ llvm-symbolizer ""test.elf 0x400490"" ""FILE:inlined.elf 0x400480""; baz(); /tmp/test.cpp:11:0. foo(); /tmp/test.cpp:8:10. $ cat addr2.txt; FILE:test.elf 0x4004a0; inlined.elf 0x400480. $ llvm-symbolizer < addr2.txt; main; /tmp/test.cpp:15:0. foo(); /tmp/test.cpp:8:10. Example 4 - BUILDID and FILE prefixes:. .. code-block:: console. $ llvm-symbolizer ""FILE:test.elf 0x400490"" ""DATA BUILDID:123456789abcdef 0x601028""; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. $ cat addr3.txt; FILE:test.elf 0x400490; DATA BUILDID:123456789abcdef 0x601028. $ llvm-symbolizer < addr3.txt; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. Example 5 - CODE and DATA prefixes:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf ""CODE 0x400490"" ""DATA 0x601028""; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. $ cat addr4.txt; CODE test.elf 0x4004a0; DATA inlined.elf 0x601028. $ llvm-symbolizer < addr4.txt; main; /tmp/test.cpp:15:0. bar; 6295592 4. Example 6 - path-style options:. This example uses the same source file as above, but the source file's; full path is /tmp/foo/test.cpp and is compiled as follows. The first case; shows the default absolute path, the second --basenames, and the third; shows --relativenames. .. code-block:: console. $ pwd; /tmp; $ clang -g foo/test.cpp -o test.elf; $ llvm-symbolizer --obj=test.elf 0x4004a0; main; /tmp/foo/test.cpp:15:0; $ llvm-symbolizer --obj=test.elf 0x4004a0 --basenames; main; test.cpp:15:0; $ llvm-symbolizer --obj=test.elf 0x4004a0 --relativenames; main; foo/test.cpp:15:0. Example 7 - Addresses as symbol names:. .. code-block:: console. $ l",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:3760,Testability,test,test,3760,"11:0. Example 2 - addresses on standard input:. .. code-block:: console. $ cat addr.txt; 0x4004a0; 0x400490; 0x4004d0; $ llvm-symbolizer --obj=test.elf < addr.txt; main; /tmp/test.cpp:15:0. baz(); /tmp/test.cpp:11:0. foz; /tmp/./test.h:1:0. Example 3 - object specified with address:. .. code-block:: console. $ llvm-symbolizer ""test.elf 0x400490"" ""FILE:inlined.elf 0x400480""; baz(); /tmp/test.cpp:11:0. foo(); /tmp/test.cpp:8:10. $ cat addr2.txt; FILE:test.elf 0x4004a0; inlined.elf 0x400480. $ llvm-symbolizer < addr2.txt; main; /tmp/test.cpp:15:0. foo(); /tmp/test.cpp:8:10. Example 4 - BUILDID and FILE prefixes:. .. code-block:: console. $ llvm-symbolizer ""FILE:test.elf 0x400490"" ""DATA BUILDID:123456789abcdef 0x601028""; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. $ cat addr3.txt; FILE:test.elf 0x400490; DATA BUILDID:123456789abcdef 0x601028. $ llvm-symbolizer < addr3.txt; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. Example 5 - CODE and DATA prefixes:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf ""CODE 0x400490"" ""DATA 0x601028""; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. $ cat addr4.txt; CODE test.elf 0x4004a0; DATA inlined.elf 0x601028. $ llvm-symbolizer < addr4.txt; main; /tmp/test.cpp:15:0. bar; 6295592 4. Example 6 - path-style options:. This example uses the same source file as above, but the source file's; full path is /tmp/foo/test.cpp and is compiled as follows. The first case; shows the default absolute path, the second --basenames, and the third; shows --relativenames. .. code-block:: console. $ pwd; /tmp; $ clang -g foo/test.cpp -o test.elf; $ llvm-symbolizer --obj=test.elf 0x4004a0; main; /tmp/foo/test.cpp:15:0; $ llvm-symbolizer --obj=test.elf 0x4004a0 --basenames; main; test.cpp:15:0; $ llvm-symbolizer --obj=test.elf 0x4004a0 --relativenames; main; foo/test.cpp:15:0. Example 7 - Addresses as symbol names:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf main; main; /tmp/test.cpp:14:0; $ llvm-symbolizer --obj=test.elf ""CODE foz""; foz; /",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:3814,Testability,test,test,3814,"put:. .. code-block:: console. $ cat addr.txt; 0x4004a0; 0x400490; 0x4004d0; $ llvm-symbolizer --obj=test.elf < addr.txt; main; /tmp/test.cpp:15:0. baz(); /tmp/test.cpp:11:0. foz; /tmp/./test.h:1:0. Example 3 - object specified with address:. .. code-block:: console. $ llvm-symbolizer ""test.elf 0x400490"" ""FILE:inlined.elf 0x400480""; baz(); /tmp/test.cpp:11:0. foo(); /tmp/test.cpp:8:10. $ cat addr2.txt; FILE:test.elf 0x4004a0; inlined.elf 0x400480. $ llvm-symbolizer < addr2.txt; main; /tmp/test.cpp:15:0. foo(); /tmp/test.cpp:8:10. Example 4 - BUILDID and FILE prefixes:. .. code-block:: console. $ llvm-symbolizer ""FILE:test.elf 0x400490"" ""DATA BUILDID:123456789abcdef 0x601028""; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. $ cat addr3.txt; FILE:test.elf 0x400490; DATA BUILDID:123456789abcdef 0x601028. $ llvm-symbolizer < addr3.txt; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. Example 5 - CODE and DATA prefixes:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf ""CODE 0x400490"" ""DATA 0x601028""; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. $ cat addr4.txt; CODE test.elf 0x4004a0; DATA inlined.elf 0x601028. $ llvm-symbolizer < addr4.txt; main; /tmp/test.cpp:15:0. bar; 6295592 4. Example 6 - path-style options:. This example uses the same source file as above, but the source file's; full path is /tmp/foo/test.cpp and is compiled as follows. The first case; shows the default absolute path, the second --basenames, and the third; shows --relativenames. .. code-block:: console. $ pwd; /tmp; $ clang -g foo/test.cpp -o test.elf; $ llvm-symbolizer --obj=test.elf 0x4004a0; main; /tmp/foo/test.cpp:15:0; $ llvm-symbolizer --obj=test.elf 0x4004a0 --basenames; main; test.cpp:15:0; $ llvm-symbolizer --obj=test.elf 0x4004a0 --relativenames; main; foo/test.cpp:15:0. Example 7 - Addresses as symbol names:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf main; main; /tmp/test.cpp:14:0; $ llvm-symbolizer --obj=test.elf ""CODE foz""; foz; /tmp/test.h:1:0. OPTIONS; -------. .. optio",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:3867,Testability,test,test,3867,"4d0; $ llvm-symbolizer --obj=test.elf < addr.txt; main; /tmp/test.cpp:15:0. baz(); /tmp/test.cpp:11:0. foz; /tmp/./test.h:1:0. Example 3 - object specified with address:. .. code-block:: console. $ llvm-symbolizer ""test.elf 0x400490"" ""FILE:inlined.elf 0x400480""; baz(); /tmp/test.cpp:11:0. foo(); /tmp/test.cpp:8:10. $ cat addr2.txt; FILE:test.elf 0x4004a0; inlined.elf 0x400480. $ llvm-symbolizer < addr2.txt; main; /tmp/test.cpp:15:0. foo(); /tmp/test.cpp:8:10. Example 4 - BUILDID and FILE prefixes:. .. code-block:: console. $ llvm-symbolizer ""FILE:test.elf 0x400490"" ""DATA BUILDID:123456789abcdef 0x601028""; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. $ cat addr3.txt; FILE:test.elf 0x400490; DATA BUILDID:123456789abcdef 0x601028. $ llvm-symbolizer < addr3.txt; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. Example 5 - CODE and DATA prefixes:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf ""CODE 0x400490"" ""DATA 0x601028""; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. $ cat addr4.txt; CODE test.elf 0x4004a0; DATA inlined.elf 0x601028. $ llvm-symbolizer < addr4.txt; main; /tmp/test.cpp:15:0. bar; 6295592 4. Example 6 - path-style options:. This example uses the same source file as above, but the source file's; full path is /tmp/foo/test.cpp and is compiled as follows. The first case; shows the default absolute path, the second --basenames, and the third; shows --relativenames. .. code-block:: console. $ pwd; /tmp; $ clang -g foo/test.cpp -o test.elf; $ llvm-symbolizer --obj=test.elf 0x4004a0; main; /tmp/foo/test.cpp:15:0; $ llvm-symbolizer --obj=test.elf 0x4004a0 --basenames; main; test.cpp:15:0; $ llvm-symbolizer --obj=test.elf 0x4004a0 --relativenames; main; foo/test.cpp:15:0. Example 7 - Addresses as symbol names:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf main; main; /tmp/test.cpp:14:0; $ llvm-symbolizer --obj=test.elf ""CODE foz""; foz; /tmp/test.h:1:0. OPTIONS; -------. .. option:: --adjust-vma <offset>. Add the specified offset to object file addres",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:3955,Testability,test,test,3955,"mp/test.cpp:11:0. foz; /tmp/./test.h:1:0. Example 3 - object specified with address:. .. code-block:: console. $ llvm-symbolizer ""test.elf 0x400490"" ""FILE:inlined.elf 0x400480""; baz(); /tmp/test.cpp:11:0. foo(); /tmp/test.cpp:8:10. $ cat addr2.txt; FILE:test.elf 0x4004a0; inlined.elf 0x400480. $ llvm-symbolizer < addr2.txt; main; /tmp/test.cpp:15:0. foo(); /tmp/test.cpp:8:10. Example 4 - BUILDID and FILE prefixes:. .. code-block:: console. $ llvm-symbolizer ""FILE:test.elf 0x400490"" ""DATA BUILDID:123456789abcdef 0x601028""; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. $ cat addr3.txt; FILE:test.elf 0x400490; DATA BUILDID:123456789abcdef 0x601028. $ llvm-symbolizer < addr3.txt; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. Example 5 - CODE and DATA prefixes:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf ""CODE 0x400490"" ""DATA 0x601028""; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. $ cat addr4.txt; CODE test.elf 0x4004a0; DATA inlined.elf 0x601028. $ llvm-symbolizer < addr4.txt; main; /tmp/test.cpp:15:0. bar; 6295592 4. Example 6 - path-style options:. This example uses the same source file as above, but the source file's; full path is /tmp/foo/test.cpp and is compiled as follows. The first case; shows the default absolute path, the second --basenames, and the third; shows --relativenames. .. code-block:: console. $ pwd; /tmp; $ clang -g foo/test.cpp -o test.elf; $ llvm-symbolizer --obj=test.elf 0x4004a0; main; /tmp/foo/test.cpp:15:0; $ llvm-symbolizer --obj=test.elf 0x4004a0 --basenames; main; test.cpp:15:0; $ llvm-symbolizer --obj=test.elf 0x4004a0 --relativenames; main; foo/test.cpp:15:0. Example 7 - Addresses as symbol names:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf main; main; /tmp/test.cpp:14:0; $ llvm-symbolizer --obj=test.elf ""CODE foz""; foz; /tmp/test.h:1:0. OPTIONS; -------. .. option:: --adjust-vma <offset>. Add the specified offset to object file addresses when performing lookups.; This can be used to perform lookups as if the object we",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:4113,Testability,test,test,4113,"ymbolizer ""test.elf 0x400490"" ""FILE:inlined.elf 0x400480""; baz(); /tmp/test.cpp:11:0. foo(); /tmp/test.cpp:8:10. $ cat addr2.txt; FILE:test.elf 0x4004a0; inlined.elf 0x400480. $ llvm-symbolizer < addr2.txt; main; /tmp/test.cpp:15:0. foo(); /tmp/test.cpp:8:10. Example 4 - BUILDID and FILE prefixes:. .. code-block:: console. $ llvm-symbolizer ""FILE:test.elf 0x400490"" ""DATA BUILDID:123456789abcdef 0x601028""; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. $ cat addr3.txt; FILE:test.elf 0x400490; DATA BUILDID:123456789abcdef 0x601028. $ llvm-symbolizer < addr3.txt; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. Example 5 - CODE and DATA prefixes:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf ""CODE 0x400490"" ""DATA 0x601028""; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. $ cat addr4.txt; CODE test.elf 0x4004a0; DATA inlined.elf 0x601028. $ llvm-symbolizer < addr4.txt; main; /tmp/test.cpp:15:0. bar; 6295592 4. Example 6 - path-style options:. This example uses the same source file as above, but the source file's; full path is /tmp/foo/test.cpp and is compiled as follows. The first case; shows the default absolute path, the second --basenames, and the third; shows --relativenames. .. code-block:: console. $ pwd; /tmp; $ clang -g foo/test.cpp -o test.elf; $ llvm-symbolizer --obj=test.elf 0x4004a0; main; /tmp/foo/test.cpp:15:0; $ llvm-symbolizer --obj=test.elf 0x4004a0 --basenames; main; test.cpp:15:0; $ llvm-symbolizer --obj=test.elf 0x4004a0 --relativenames; main; foo/test.cpp:15:0. Example 7 - Addresses as symbol names:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf main; main; /tmp/test.cpp:14:0; $ llvm-symbolizer --obj=test.elf ""CODE foz""; foz; /tmp/test.h:1:0. OPTIONS; -------. .. option:: --adjust-vma <offset>. Add the specified offset to object file addresses when performing lookups.; This can be used to perform lookups as if the object were relocated by the; offset. .. option:: --basenames, -s. Print just the file's name without any directories, instead ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:4314,Testability,test,test,4314,"oo(); /tmp/test.cpp:8:10. Example 4 - BUILDID and FILE prefixes:. .. code-block:: console. $ llvm-symbolizer ""FILE:test.elf 0x400490"" ""DATA BUILDID:123456789abcdef 0x601028""; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. $ cat addr3.txt; FILE:test.elf 0x400490; DATA BUILDID:123456789abcdef 0x601028. $ llvm-symbolizer < addr3.txt; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. Example 5 - CODE and DATA prefixes:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf ""CODE 0x400490"" ""DATA 0x601028""; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. $ cat addr4.txt; CODE test.elf 0x4004a0; DATA inlined.elf 0x601028. $ llvm-symbolizer < addr4.txt; main; /tmp/test.cpp:15:0. bar; 6295592 4. Example 6 - path-style options:. This example uses the same source file as above, but the source file's; full path is /tmp/foo/test.cpp and is compiled as follows. The first case; shows the default absolute path, the second --basenames, and the third; shows --relativenames. .. code-block:: console. $ pwd; /tmp; $ clang -g foo/test.cpp -o test.elf; $ llvm-symbolizer --obj=test.elf 0x4004a0; main; /tmp/foo/test.cpp:15:0; $ llvm-symbolizer --obj=test.elf 0x4004a0 --basenames; main; test.cpp:15:0; $ llvm-symbolizer --obj=test.elf 0x4004a0 --relativenames; main; foo/test.cpp:15:0. Example 7 - Addresses as symbol names:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf main; main; /tmp/test.cpp:14:0; $ llvm-symbolizer --obj=test.elf ""CODE foz""; foz; /tmp/test.h:1:0. OPTIONS; -------. .. option:: --adjust-vma <offset>. Add the specified offset to object file addresses when performing lookups.; This can be used to perform lookups as if the object were relocated by the; offset. .. option:: --basenames, -s. Print just the file's name without any directories, instead of the; absolute path. .. option:: --build-id. Look up the object using the given build ID, specified as a hexadecimal; string. Mutually exclusive with :option:`--obj`. .. option:: --color [=<always|auto|never>]. Specify whether to us",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:4326,Testability,test,test,4326,"0. Example 4 - BUILDID and FILE prefixes:. .. code-block:: console. $ llvm-symbolizer ""FILE:test.elf 0x400490"" ""DATA BUILDID:123456789abcdef 0x601028""; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. $ cat addr3.txt; FILE:test.elf 0x400490; DATA BUILDID:123456789abcdef 0x601028. $ llvm-symbolizer < addr3.txt; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. Example 5 - CODE and DATA prefixes:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf ""CODE 0x400490"" ""DATA 0x601028""; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. $ cat addr4.txt; CODE test.elf 0x4004a0; DATA inlined.elf 0x601028. $ llvm-symbolizer < addr4.txt; main; /tmp/test.cpp:15:0. bar; 6295592 4. Example 6 - path-style options:. This example uses the same source file as above, but the source file's; full path is /tmp/foo/test.cpp and is compiled as follows. The first case; shows the default absolute path, the second --basenames, and the third; shows --relativenames. .. code-block:: console. $ pwd; /tmp; $ clang -g foo/test.cpp -o test.elf; $ llvm-symbolizer --obj=test.elf 0x4004a0; main; /tmp/foo/test.cpp:15:0; $ llvm-symbolizer --obj=test.elf 0x4004a0 --basenames; main; test.cpp:15:0; $ llvm-symbolizer --obj=test.elf 0x4004a0 --relativenames; main; foo/test.cpp:15:0. Example 7 - Addresses as symbol names:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf main; main; /tmp/test.cpp:14:0; $ llvm-symbolizer --obj=test.elf ""CODE foz""; foz; /tmp/test.h:1:0. OPTIONS; -------. .. option:: --adjust-vma <offset>. Add the specified offset to object file addresses when performing lookups.; This can be used to perform lookups as if the object were relocated by the; offset. .. option:: --basenames, -s. Print just the file's name without any directories, instead of the; absolute path. .. option:: --build-id. Look up the object using the given build ID, specified as a hexadecimal; string. Mutually exclusive with :option:`--obj`. .. option:: --color [=<always|auto|never>]. Specify whether to use color in :option:`--f",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:4360,Testability,test,test,4360,"and FILE prefixes:. .. code-block:: console. $ llvm-symbolizer ""FILE:test.elf 0x400490"" ""DATA BUILDID:123456789abcdef 0x601028""; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. $ cat addr3.txt; FILE:test.elf 0x400490; DATA BUILDID:123456789abcdef 0x601028. $ llvm-symbolizer < addr3.txt; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. Example 5 - CODE and DATA prefixes:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf ""CODE 0x400490"" ""DATA 0x601028""; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. $ cat addr4.txt; CODE test.elf 0x4004a0; DATA inlined.elf 0x601028. $ llvm-symbolizer < addr4.txt; main; /tmp/test.cpp:15:0. bar; 6295592 4. Example 6 - path-style options:. This example uses the same source file as above, but the source file's; full path is /tmp/foo/test.cpp and is compiled as follows. The first case; shows the default absolute path, the second --basenames, and the third; shows --relativenames. .. code-block:: console. $ pwd; /tmp; $ clang -g foo/test.cpp -o test.elf; $ llvm-symbolizer --obj=test.elf 0x4004a0; main; /tmp/foo/test.cpp:15:0; $ llvm-symbolizer --obj=test.elf 0x4004a0 --basenames; main; test.cpp:15:0; $ llvm-symbolizer --obj=test.elf 0x4004a0 --relativenames; main; foo/test.cpp:15:0. Example 7 - Addresses as symbol names:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf main; main; /tmp/test.cpp:14:0; $ llvm-symbolizer --obj=test.elf ""CODE foz""; foz; /tmp/test.h:1:0. OPTIONS; -------. .. option:: --adjust-vma <offset>. Add the specified offset to object file addresses when performing lookups.; This can be used to perform lookups as if the object were relocated by the; offset. .. option:: --basenames, -s. Print just the file's name without any directories, instead of the; absolute path. .. option:: --build-id. Look up the object using the given build ID, specified as a hexadecimal; string. Mutually exclusive with :option:`--obj`. .. option:: --color [=<always|auto|never>]. Specify whether to use color in :option:`--filter-markup` mode. Def",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:4394,Testability,test,test,4394,": console. $ llvm-symbolizer ""FILE:test.elf 0x400490"" ""DATA BUILDID:123456789abcdef 0x601028""; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. $ cat addr3.txt; FILE:test.elf 0x400490; DATA BUILDID:123456789abcdef 0x601028. $ llvm-symbolizer < addr3.txt; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. Example 5 - CODE and DATA prefixes:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf ""CODE 0x400490"" ""DATA 0x601028""; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. $ cat addr4.txt; CODE test.elf 0x4004a0; DATA inlined.elf 0x601028. $ llvm-symbolizer < addr4.txt; main; /tmp/test.cpp:15:0. bar; 6295592 4. Example 6 - path-style options:. This example uses the same source file as above, but the source file's; full path is /tmp/foo/test.cpp and is compiled as follows. The first case; shows the default absolute path, the second --basenames, and the third; shows --relativenames. .. code-block:: console. $ pwd; /tmp; $ clang -g foo/test.cpp -o test.elf; $ llvm-symbolizer --obj=test.elf 0x4004a0; main; /tmp/foo/test.cpp:15:0; $ llvm-symbolizer --obj=test.elf 0x4004a0 --basenames; main; test.cpp:15:0; $ llvm-symbolizer --obj=test.elf 0x4004a0 --relativenames; main; foo/test.cpp:15:0. Example 7 - Addresses as symbol names:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf main; main; /tmp/test.cpp:14:0; $ llvm-symbolizer --obj=test.elf ""CODE foz""; foz; /tmp/test.h:1:0. OPTIONS; -------. .. option:: --adjust-vma <offset>. Add the specified offset to object file addresses when performing lookups.; This can be used to perform lookups as if the object were relocated by the; offset. .. option:: --basenames, -s. Print just the file's name without any directories, instead of the; absolute path. .. option:: --build-id. Look up the object using the given build ID, specified as a hexadecimal; string. Mutually exclusive with :option:`--obj`. .. option:: --color [=<always|auto|never>]. Specify whether to use color in :option:`--filter-markup` mode. Defaults to; ``auto``, which detects ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:4433,Testability,test,test,4433,"est.elf 0x400490"" ""DATA BUILDID:123456789abcdef 0x601028""; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. $ cat addr3.txt; FILE:test.elf 0x400490; DATA BUILDID:123456789abcdef 0x601028. $ llvm-symbolizer < addr3.txt; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. Example 5 - CODE and DATA prefixes:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf ""CODE 0x400490"" ""DATA 0x601028""; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. $ cat addr4.txt; CODE test.elf 0x4004a0; DATA inlined.elf 0x601028. $ llvm-symbolizer < addr4.txt; main; /tmp/test.cpp:15:0. bar; 6295592 4. Example 6 - path-style options:. This example uses the same source file as above, but the source file's; full path is /tmp/foo/test.cpp and is compiled as follows. The first case; shows the default absolute path, the second --basenames, and the third; shows --relativenames. .. code-block:: console. $ pwd; /tmp; $ clang -g foo/test.cpp -o test.elf; $ llvm-symbolizer --obj=test.elf 0x4004a0; main; /tmp/foo/test.cpp:15:0; $ llvm-symbolizer --obj=test.elf 0x4004a0 --basenames; main; test.cpp:15:0; $ llvm-symbolizer --obj=test.elf 0x4004a0 --relativenames; main; foo/test.cpp:15:0. Example 7 - Addresses as symbol names:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf main; main; /tmp/test.cpp:14:0; $ llvm-symbolizer --obj=test.elf ""CODE foz""; foz; /tmp/test.h:1:0. OPTIONS; -------. .. option:: --adjust-vma <offset>. Add the specified offset to object file addresses when performing lookups.; This can be used to perform lookups as if the object were relocated by the; offset. .. option:: --basenames, -s. Print just the file's name without any directories, instead of the; absolute path. .. option:: --build-id. Look up the object using the given build ID, specified as a hexadecimal; string. Mutually exclusive with :option:`--obj`. .. option:: --color [=<always|auto|never>]. Specify whether to use color in :option:`--filter-markup` mode. Defaults to; ``auto``, which detects whether standard output supports colo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:4470,Testability,test,test,4470,"789abcdef 0x601028""; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. $ cat addr3.txt; FILE:test.elf 0x400490; DATA BUILDID:123456789abcdef 0x601028. $ llvm-symbolizer < addr3.txt; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. Example 5 - CODE and DATA prefixes:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf ""CODE 0x400490"" ""DATA 0x601028""; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. $ cat addr4.txt; CODE test.elf 0x4004a0; DATA inlined.elf 0x601028. $ llvm-symbolizer < addr4.txt; main; /tmp/test.cpp:15:0. bar; 6295592 4. Example 6 - path-style options:. This example uses the same source file as above, but the source file's; full path is /tmp/foo/test.cpp and is compiled as follows. The first case; shows the default absolute path, the second --basenames, and the third; shows --relativenames. .. code-block:: console. $ pwd; /tmp; $ clang -g foo/test.cpp -o test.elf; $ llvm-symbolizer --obj=test.elf 0x4004a0; main; /tmp/foo/test.cpp:15:0; $ llvm-symbolizer --obj=test.elf 0x4004a0 --basenames; main; test.cpp:15:0; $ llvm-symbolizer --obj=test.elf 0x4004a0 --relativenames; main; foo/test.cpp:15:0. Example 7 - Addresses as symbol names:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf main; main; /tmp/test.cpp:14:0; $ llvm-symbolizer --obj=test.elf ""CODE foz""; foz; /tmp/test.h:1:0. OPTIONS; -------. .. option:: --adjust-vma <offset>. Add the specified offset to object file addresses when performing lookups.; This can be used to perform lookups as if the object were relocated by the; offset. .. option:: --basenames, -s. Print just the file's name without any directories, instead of the; absolute path. .. option:: --build-id. Look up the object using the given build ID, specified as a hexadecimal; string. Mutually exclusive with :option:`--obj`. .. option:: --color [=<always|auto|never>]. Specify whether to use color in :option:`--filter-markup` mode. Defaults to; ``auto``, which detects whether standard output supports color. Specifying; ``--color`` alone is eq",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:4509,Testability,test,test,4509,"cpp:11:0. bar; 6295592 4. $ cat addr3.txt; FILE:test.elf 0x400490; DATA BUILDID:123456789abcdef 0x601028. $ llvm-symbolizer < addr3.txt; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. Example 5 - CODE and DATA prefixes:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf ""CODE 0x400490"" ""DATA 0x601028""; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. $ cat addr4.txt; CODE test.elf 0x4004a0; DATA inlined.elf 0x601028. $ llvm-symbolizer < addr4.txt; main; /tmp/test.cpp:15:0. bar; 6295592 4. Example 6 - path-style options:. This example uses the same source file as above, but the source file's; full path is /tmp/foo/test.cpp and is compiled as follows. The first case; shows the default absolute path, the second --basenames, and the third; shows --relativenames. .. code-block:: console. $ pwd; /tmp; $ clang -g foo/test.cpp -o test.elf; $ llvm-symbolizer --obj=test.elf 0x4004a0; main; /tmp/foo/test.cpp:15:0; $ llvm-symbolizer --obj=test.elf 0x4004a0 --basenames; main; test.cpp:15:0; $ llvm-symbolizer --obj=test.elf 0x4004a0 --relativenames; main; foo/test.cpp:15:0. Example 7 - Addresses as symbol names:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf main; main; /tmp/test.cpp:14:0; $ llvm-symbolizer --obj=test.elf ""CODE foz""; foz; /tmp/test.h:1:0. OPTIONS; -------. .. option:: --adjust-vma <offset>. Add the specified offset to object file addresses when performing lookups.; This can be used to perform lookups as if the object were relocated by the; offset. .. option:: --basenames, -s. Print just the file's name without any directories, instead of the; absolute path. .. option:: --build-id. Look up the object using the given build ID, specified as a hexadecimal; string. Mutually exclusive with :option:`--obj`. .. option:: --color [=<always|auto|never>]. Specify whether to use color in :option:`--filter-markup` mode. Defaults to; ``auto``, which detects whether standard output supports color. Specifying; ``--color`` alone is equivalent to ``--color=always``. .. opt",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:4554,Testability,test,test,4554," FILE:test.elf 0x400490; DATA BUILDID:123456789abcdef 0x601028. $ llvm-symbolizer < addr3.txt; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. Example 5 - CODE and DATA prefixes:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf ""CODE 0x400490"" ""DATA 0x601028""; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. $ cat addr4.txt; CODE test.elf 0x4004a0; DATA inlined.elf 0x601028. $ llvm-symbolizer < addr4.txt; main; /tmp/test.cpp:15:0. bar; 6295592 4. Example 6 - path-style options:. This example uses the same source file as above, but the source file's; full path is /tmp/foo/test.cpp and is compiled as follows. The first case; shows the default absolute path, the second --basenames, and the third; shows --relativenames. .. code-block:: console. $ pwd; /tmp; $ clang -g foo/test.cpp -o test.elf; $ llvm-symbolizer --obj=test.elf 0x4004a0; main; /tmp/foo/test.cpp:15:0; $ llvm-symbolizer --obj=test.elf 0x4004a0 --basenames; main; test.cpp:15:0; $ llvm-symbolizer --obj=test.elf 0x4004a0 --relativenames; main; foo/test.cpp:15:0. Example 7 - Addresses as symbol names:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf main; main; /tmp/test.cpp:14:0; $ llvm-symbolizer --obj=test.elf ""CODE foz""; foz; /tmp/test.h:1:0. OPTIONS; -------. .. option:: --adjust-vma <offset>. Add the specified offset to object file addresses when performing lookups.; This can be used to perform lookups as if the object were relocated by the; offset. .. option:: --basenames, -s. Print just the file's name without any directories, instead of the; absolute path. .. option:: --build-id. Look up the object using the given build ID, specified as a hexadecimal; string. Mutually exclusive with :option:`--obj`. .. option:: --color [=<always|auto|never>]. Specify whether to use color in :option:`--filter-markup` mode. Defaults to; ``auto``, which detects whether standard output supports color. Specifying; ``--color`` alone is equivalent to ``--color=always``. .. option:: --debug-file-directory <path>. Provi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:4658,Testability,test,test,4658,"cpp:11:0. bar; 6295592 4. Example 5 - CODE and DATA prefixes:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf ""CODE 0x400490"" ""DATA 0x601028""; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. $ cat addr4.txt; CODE test.elf 0x4004a0; DATA inlined.elf 0x601028. $ llvm-symbolizer < addr4.txt; main; /tmp/test.cpp:15:0. bar; 6295592 4. Example 6 - path-style options:. This example uses the same source file as above, but the source file's; full path is /tmp/foo/test.cpp and is compiled as follows. The first case; shows the default absolute path, the second --basenames, and the third; shows --relativenames. .. code-block:: console. $ pwd; /tmp; $ clang -g foo/test.cpp -o test.elf; $ llvm-symbolizer --obj=test.elf 0x4004a0; main; /tmp/foo/test.cpp:15:0; $ llvm-symbolizer --obj=test.elf 0x4004a0 --basenames; main; test.cpp:15:0; $ llvm-symbolizer --obj=test.elf 0x4004a0 --relativenames; main; foo/test.cpp:15:0. Example 7 - Addresses as symbol names:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf main; main; /tmp/test.cpp:14:0; $ llvm-symbolizer --obj=test.elf ""CODE foz""; foz; /tmp/test.h:1:0. OPTIONS; -------. .. option:: --adjust-vma <offset>. Add the specified offset to object file addresses when performing lookups.; This can be used to perform lookups as if the object were relocated by the; offset. .. option:: --basenames, -s. Print just the file's name without any directories, instead of the; absolute path. .. option:: --build-id. Look up the object using the given build ID, specified as a hexadecimal; string. Mutually exclusive with :option:`--obj`. .. option:: --color [=<always|auto|never>]. Specify whether to use color in :option:`--filter-markup` mode. Defaults to; ``auto``, which detects whether standard output supports color. Specifying; ``--color`` alone is equivalent to ``--color=always``. .. option:: --debug-file-directory <path>. Provide a path to a directory with a `.build-id` subdirectory to search for; debug information for stripped binaries",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:4684,Testability,test,test,4684,"ample 5 - CODE and DATA prefixes:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf ""CODE 0x400490"" ""DATA 0x601028""; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. $ cat addr4.txt; CODE test.elf 0x4004a0; DATA inlined.elf 0x601028. $ llvm-symbolizer < addr4.txt; main; /tmp/test.cpp:15:0. bar; 6295592 4. Example 6 - path-style options:. This example uses the same source file as above, but the source file's; full path is /tmp/foo/test.cpp and is compiled as follows. The first case; shows the default absolute path, the second --basenames, and the third; shows --relativenames. .. code-block:: console. $ pwd; /tmp; $ clang -g foo/test.cpp -o test.elf; $ llvm-symbolizer --obj=test.elf 0x4004a0; main; /tmp/foo/test.cpp:15:0; $ llvm-symbolizer --obj=test.elf 0x4004a0 --basenames; main; test.cpp:15:0; $ llvm-symbolizer --obj=test.elf 0x4004a0 --relativenames; main; foo/test.cpp:15:0. Example 7 - Addresses as symbol names:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf main; main; /tmp/test.cpp:14:0; $ llvm-symbolizer --obj=test.elf ""CODE foz""; foz; /tmp/test.h:1:0. OPTIONS; -------. .. option:: --adjust-vma <offset>. Add the specified offset to object file addresses when performing lookups.; This can be used to perform lookups as if the object were relocated by the; offset. .. option:: --basenames, -s. Print just the file's name without any directories, instead of the; absolute path. .. option:: --build-id. Look up the object using the given build ID, specified as a hexadecimal; string. Mutually exclusive with :option:`--obj`. .. option:: --color [=<always|auto|never>]. Specify whether to use color in :option:`--filter-markup` mode. Defaults to; ``auto``, which detects whether standard output supports color. Specifying; ``--color`` alone is equivalent to ``--color=always``. .. option:: --debug-file-directory <path>. Provide a path to a directory with a `.build-id` subdirectory to search for; debug information for stripped binaries. Multiple instances of this",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:4723,Testability,test,test,4723,":. .. code-block:: console. $ llvm-symbolizer --obj=test.elf ""CODE 0x400490"" ""DATA 0x601028""; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. $ cat addr4.txt; CODE test.elf 0x4004a0; DATA inlined.elf 0x601028. $ llvm-symbolizer < addr4.txt; main; /tmp/test.cpp:15:0. bar; 6295592 4. Example 6 - path-style options:. This example uses the same source file as above, but the source file's; full path is /tmp/foo/test.cpp and is compiled as follows. The first case; shows the default absolute path, the second --basenames, and the third; shows --relativenames. .. code-block:: console. $ pwd; /tmp; $ clang -g foo/test.cpp -o test.elf; $ llvm-symbolizer --obj=test.elf 0x4004a0; main; /tmp/foo/test.cpp:15:0; $ llvm-symbolizer --obj=test.elf 0x4004a0 --basenames; main; test.cpp:15:0; $ llvm-symbolizer --obj=test.elf 0x4004a0 --relativenames; main; foo/test.cpp:15:0. Example 7 - Addresses as symbol names:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf main; main; /tmp/test.cpp:14:0; $ llvm-symbolizer --obj=test.elf ""CODE foz""; foz; /tmp/test.h:1:0. OPTIONS; -------. .. option:: --adjust-vma <offset>. Add the specified offset to object file addresses when performing lookups.; This can be used to perform lookups as if the object were relocated by the; offset. .. option:: --basenames, -s. Print just the file's name without any directories, instead of the; absolute path. .. option:: --build-id. Look up the object using the given build ID, specified as a hexadecimal; string. Mutually exclusive with :option:`--obj`. .. option:: --color [=<always|auto|never>]. Specify whether to use color in :option:`--filter-markup` mode. Defaults to; ``auto``, which detects whether standard output supports color. Specifying; ``--color`` alone is equivalent to ``--color=always``. .. option:: --debug-file-directory <path>. Provide a path to a directory with a `.build-id` subdirectory to search for; debug information for stripped binaries. Multiple instances of this argument; are searched in the or",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:4754,Testability,test,test,4754,"symbolizer --obj=test.elf ""CODE 0x400490"" ""DATA 0x601028""; baz(); /tmp/test.cpp:11:0. bar; 6295592 4. $ cat addr4.txt; CODE test.elf 0x4004a0; DATA inlined.elf 0x601028. $ llvm-symbolizer < addr4.txt; main; /tmp/test.cpp:15:0. bar; 6295592 4. Example 6 - path-style options:. This example uses the same source file as above, but the source file's; full path is /tmp/foo/test.cpp and is compiled as follows. The first case; shows the default absolute path, the second --basenames, and the third; shows --relativenames. .. code-block:: console. $ pwd; /tmp; $ clang -g foo/test.cpp -o test.elf; $ llvm-symbolizer --obj=test.elf 0x4004a0; main; /tmp/foo/test.cpp:15:0; $ llvm-symbolizer --obj=test.elf 0x4004a0 --basenames; main; test.cpp:15:0; $ llvm-symbolizer --obj=test.elf 0x4004a0 --relativenames; main; foo/test.cpp:15:0. Example 7 - Addresses as symbol names:. .. code-block:: console. $ llvm-symbolizer --obj=test.elf main; main; /tmp/test.cpp:14:0; $ llvm-symbolizer --obj=test.elf ""CODE foz""; foz; /tmp/test.h:1:0. OPTIONS; -------. .. option:: --adjust-vma <offset>. Add the specified offset to object file addresses when performing lookups.; This can be used to perform lookups as if the object were relocated by the; offset. .. option:: --basenames, -s. Print just the file's name without any directories, instead of the; absolute path. .. option:: --build-id. Look up the object using the given build ID, specified as a hexadecimal; string. Mutually exclusive with :option:`--obj`. .. option:: --color [=<always|auto|never>]. Specify whether to use color in :option:`--filter-markup` mode. Defaults to; ``auto``, which detects whether standard output supports color. Specifying; ``--color`` alone is equivalent to ``--color=always``. .. option:: --debug-file-directory <path>. Provide a path to a directory with a `.build-id` subdirectory to search for; debug information for stripped binaries. Multiple instances of this argument; are searched in the order given. .. option:: --debuginfod",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:9269,Testability,test,test,9269,"with; :option:`--build-id`. .. _llvm-symbolizer-opt-output-style:. .. option:: --output-style <LLVM|GNU|JSON>. Specify the preferred output style. Defaults to ``LLVM``. When the output; style is set to ``GNU``, the tool follows the style of GNU's **addr2line**.; The differences from the ``LLVM`` style are:. * Does not print the column of a source code location. * Does not add an empty line after the report for an address. * Does not replace the name of an inlined function with the name of the; topmost caller when inlined frames are not shown. * Prints an address's debug-data discriminator when it is non-zero. One way to; produce discriminators is to compile with clang's -fdebug-info-for-profiling. ``JSON`` style provides a machine readable output in JSON. If addresses are; supplied via stdin, the output JSON will be a series of individual objects.; Otherwise, all results will be contained in a single array. .. code-block:: console. $ llvm-symbolizer --obj=inlined.elf 0x4004be 0x400486 -p; baz() at /tmp/test.cpp:11:18; (inlined by) main at /tmp/test.cpp:15:0. foo() at /tmp/test.cpp:6:3. $ llvm-symbolizer --output-style=LLVM --obj=inlined.elf 0x4004be 0x400486 -p --no-inlines; main at /tmp/test.cpp:11:18. foo() at /tmp/test.cpp:6:3. $ llvm-symbolizer --output-style=GNU --obj=inlined.elf 0x4004be 0x400486 -p --no-inlines; baz() at /tmp/test.cpp:11; foo() at /tmp/test.cpp:6. $ clang -g -fdebug-info-for-profiling test.cpp -o profiling.elf; $ llvm-symbolizer --output-style=GNU --obj=profiling.elf 0x401167 -p --no-inlines; main at /tmp/test.cpp:15 (discriminator 2). $ llvm-symbolizer --output-style=JSON --obj=inlined.elf 0x4004be 0x400486 -p; [; {; ""Address"": ""0x4004be"",; ""ModuleName"": ""inlined.elf"",; ""Symbol"": [; {; ""Column"": 18,; ""Discriminator"": 0,; ""FileName"": ""/tmp/test.cpp"",; ""FunctionName"": ""baz()"",; ""Line"": 11,; ""StartAddress"": ""0x4004be"",; ""StartFileName"": ""/tmp/test.cpp"",; ""StartLine"": 9; },; {; ""Column"": 0,; ""Discriminator"": 0,; ""FileName"": ""/tmp/test.cpp"",; ""Fun",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:9311,Testability,test,test,9311,"zer-opt-output-style:. .. option:: --output-style <LLVM|GNU|JSON>. Specify the preferred output style. Defaults to ``LLVM``. When the output; style is set to ``GNU``, the tool follows the style of GNU's **addr2line**.; The differences from the ``LLVM`` style are:. * Does not print the column of a source code location. * Does not add an empty line after the report for an address. * Does not replace the name of an inlined function with the name of the; topmost caller when inlined frames are not shown. * Prints an address's debug-data discriminator when it is non-zero. One way to; produce discriminators is to compile with clang's -fdebug-info-for-profiling. ``JSON`` style provides a machine readable output in JSON. If addresses are; supplied via stdin, the output JSON will be a series of individual objects.; Otherwise, all results will be contained in a single array. .. code-block:: console. $ llvm-symbolizer --obj=inlined.elf 0x4004be 0x400486 -p; baz() at /tmp/test.cpp:11:18; (inlined by) main at /tmp/test.cpp:15:0. foo() at /tmp/test.cpp:6:3. $ llvm-symbolizer --output-style=LLVM --obj=inlined.elf 0x4004be 0x400486 -p --no-inlines; main at /tmp/test.cpp:11:18. foo() at /tmp/test.cpp:6:3. $ llvm-symbolizer --output-style=GNU --obj=inlined.elf 0x4004be 0x400486 -p --no-inlines; baz() at /tmp/test.cpp:11; foo() at /tmp/test.cpp:6. $ clang -g -fdebug-info-for-profiling test.cpp -o profiling.elf; $ llvm-symbolizer --output-style=GNU --obj=profiling.elf 0x401167 -p --no-inlines; main at /tmp/test.cpp:15 (discriminator 2). $ llvm-symbolizer --output-style=JSON --obj=inlined.elf 0x4004be 0x400486 -p; [; {; ""Address"": ""0x4004be"",; ""ModuleName"": ""inlined.elf"",; ""Symbol"": [; {; ""Column"": 18,; ""Discriminator"": 0,; ""FileName"": ""/tmp/test.cpp"",; ""FunctionName"": ""baz()"",; ""Line"": 11,; ""StartAddress"": ""0x4004be"",; ""StartFileName"": ""/tmp/test.cpp"",; ""StartLine"": 9; },; {; ""Column"": 0,; ""Discriminator"": 0,; ""FileName"": ""/tmp/test.cpp"",; ""FunctionName"": ""main"",; ""Line"": 15,; ""StartAdd",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:9340,Testability,test,test,9340,"put-style <LLVM|GNU|JSON>. Specify the preferred output style. Defaults to ``LLVM``. When the output; style is set to ``GNU``, the tool follows the style of GNU's **addr2line**.; The differences from the ``LLVM`` style are:. * Does not print the column of a source code location. * Does not add an empty line after the report for an address. * Does not replace the name of an inlined function with the name of the; topmost caller when inlined frames are not shown. * Prints an address's debug-data discriminator when it is non-zero. One way to; produce discriminators is to compile with clang's -fdebug-info-for-profiling. ``JSON`` style provides a machine readable output in JSON. If addresses are; supplied via stdin, the output JSON will be a series of individual objects.; Otherwise, all results will be contained in a single array. .. code-block:: console. $ llvm-symbolizer --obj=inlined.elf 0x4004be 0x400486 -p; baz() at /tmp/test.cpp:11:18; (inlined by) main at /tmp/test.cpp:15:0. foo() at /tmp/test.cpp:6:3. $ llvm-symbolizer --output-style=LLVM --obj=inlined.elf 0x4004be 0x400486 -p --no-inlines; main at /tmp/test.cpp:11:18. foo() at /tmp/test.cpp:6:3. $ llvm-symbolizer --output-style=GNU --obj=inlined.elf 0x4004be 0x400486 -p --no-inlines; baz() at /tmp/test.cpp:11; foo() at /tmp/test.cpp:6. $ clang -g -fdebug-info-for-profiling test.cpp -o profiling.elf; $ llvm-symbolizer --output-style=GNU --obj=profiling.elf 0x401167 -p --no-inlines; main at /tmp/test.cpp:15 (discriminator 2). $ llvm-symbolizer --output-style=JSON --obj=inlined.elf 0x4004be 0x400486 -p; [; {; ""Address"": ""0x4004be"",; ""ModuleName"": ""inlined.elf"",; ""Symbol"": [; {; ""Column"": 18,; ""Discriminator"": 0,; ""FileName"": ""/tmp/test.cpp"",; ""FunctionName"": ""baz()"",; ""Line"": 11,; ""StartAddress"": ""0x4004be"",; ""StartFileName"": ""/tmp/test.cpp"",; ""StartLine"": 9; },; {; ""Column"": 0,; ""Discriminator"": 0,; ""FileName"": ""/tmp/test.cpp"",; ""FunctionName"": ""main"",; ""Line"": 15,; ""StartAddress"": ""0x4004be"",; ""StartFileName"": ""/t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:9458,Testability,test,test,9458,"t; style is set to ``GNU``, the tool follows the style of GNU's **addr2line**.; The differences from the ``LLVM`` style are:. * Does not print the column of a source code location. * Does not add an empty line after the report for an address. * Does not replace the name of an inlined function with the name of the; topmost caller when inlined frames are not shown. * Prints an address's debug-data discriminator when it is non-zero. One way to; produce discriminators is to compile with clang's -fdebug-info-for-profiling. ``JSON`` style provides a machine readable output in JSON. If addresses are; supplied via stdin, the output JSON will be a series of individual objects.; Otherwise, all results will be contained in a single array. .. code-block:: console. $ llvm-symbolizer --obj=inlined.elf 0x4004be 0x400486 -p; baz() at /tmp/test.cpp:11:18; (inlined by) main at /tmp/test.cpp:15:0. foo() at /tmp/test.cpp:6:3. $ llvm-symbolizer --output-style=LLVM --obj=inlined.elf 0x4004be 0x400486 -p --no-inlines; main at /tmp/test.cpp:11:18. foo() at /tmp/test.cpp:6:3. $ llvm-symbolizer --output-style=GNU --obj=inlined.elf 0x4004be 0x400486 -p --no-inlines; baz() at /tmp/test.cpp:11; foo() at /tmp/test.cpp:6. $ clang -g -fdebug-info-for-profiling test.cpp -o profiling.elf; $ llvm-symbolizer --output-style=GNU --obj=profiling.elf 0x401167 -p --no-inlines; main at /tmp/test.cpp:15 (discriminator 2). $ llvm-symbolizer --output-style=JSON --obj=inlined.elf 0x4004be 0x400486 -p; [; {; ""Address"": ""0x4004be"",; ""ModuleName"": ""inlined.elf"",; ""Symbol"": [; {; ""Column"": 18,; ""Discriminator"": 0,; ""FileName"": ""/tmp/test.cpp"",; ""FunctionName"": ""baz()"",; ""Line"": 11,; ""StartAddress"": ""0x4004be"",; ""StartFileName"": ""/tmp/test.cpp"",; ""StartLine"": 9; },; {; ""Column"": 0,; ""Discriminator"": 0,; ""FileName"": ""/tmp/test.cpp"",; ""FunctionName"": ""main"",; ""Line"": 15,; ""StartAddress"": ""0x4004be"",; ""StartFileName"": ""/tmp/test.cpp"",; ""StartLine"": 14; }; ]; },; {; ""Address"": ""0x400486"",; ""ModuleName"": ""inlined.elf"",; """,MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:9488,Testability,test,test,9488,"style of GNU's **addr2line**.; The differences from the ``LLVM`` style are:. * Does not print the column of a source code location. * Does not add an empty line after the report for an address. * Does not replace the name of an inlined function with the name of the; topmost caller when inlined frames are not shown. * Prints an address's debug-data discriminator when it is non-zero. One way to; produce discriminators is to compile with clang's -fdebug-info-for-profiling. ``JSON`` style provides a machine readable output in JSON. If addresses are; supplied via stdin, the output JSON will be a series of individual objects.; Otherwise, all results will be contained in a single array. .. code-block:: console. $ llvm-symbolizer --obj=inlined.elf 0x4004be 0x400486 -p; baz() at /tmp/test.cpp:11:18; (inlined by) main at /tmp/test.cpp:15:0. foo() at /tmp/test.cpp:6:3. $ llvm-symbolizer --output-style=LLVM --obj=inlined.elf 0x4004be 0x400486 -p --no-inlines; main at /tmp/test.cpp:11:18. foo() at /tmp/test.cpp:6:3. $ llvm-symbolizer --output-style=GNU --obj=inlined.elf 0x4004be 0x400486 -p --no-inlines; baz() at /tmp/test.cpp:11; foo() at /tmp/test.cpp:6. $ clang -g -fdebug-info-for-profiling test.cpp -o profiling.elf; $ llvm-symbolizer --output-style=GNU --obj=profiling.elf 0x401167 -p --no-inlines; main at /tmp/test.cpp:15 (discriminator 2). $ llvm-symbolizer --output-style=JSON --obj=inlined.elf 0x4004be 0x400486 -p; [; {; ""Address"": ""0x4004be"",; ""ModuleName"": ""inlined.elf"",; ""Symbol"": [; {; ""Column"": 18,; ""Discriminator"": 0,; ""FileName"": ""/tmp/test.cpp"",; ""FunctionName"": ""baz()"",; ""Line"": 11,; ""StartAddress"": ""0x4004be"",; ""StartFileName"": ""/tmp/test.cpp"",; ""StartLine"": 9; },; {; ""Column"": 0,; ""Discriminator"": 0,; ""FileName"": ""/tmp/test.cpp"",; ""FunctionName"": ""main"",; ""Line"": 15,; ""StartAddress"": ""0x4004be"",; ""StartFileName"": ""/tmp/test.cpp"",; ""StartLine"": 14; }; ]; },; {; ""Address"": ""0x400486"",; ""ModuleName"": ""inlined.elf"",; ""Symbol"": [; {; ""Column"": 3,; ""Discriminator"": 0,",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:9606,Testability,test,test,9606,"olumn of a source code location. * Does not add an empty line after the report for an address. * Does not replace the name of an inlined function with the name of the; topmost caller when inlined frames are not shown. * Prints an address's debug-data discriminator when it is non-zero. One way to; produce discriminators is to compile with clang's -fdebug-info-for-profiling. ``JSON`` style provides a machine readable output in JSON. If addresses are; supplied via stdin, the output JSON will be a series of individual objects.; Otherwise, all results will be contained in a single array. .. code-block:: console. $ llvm-symbolizer --obj=inlined.elf 0x4004be 0x400486 -p; baz() at /tmp/test.cpp:11:18; (inlined by) main at /tmp/test.cpp:15:0. foo() at /tmp/test.cpp:6:3. $ llvm-symbolizer --output-style=LLVM --obj=inlined.elf 0x4004be 0x400486 -p --no-inlines; main at /tmp/test.cpp:11:18. foo() at /tmp/test.cpp:6:3. $ llvm-symbolizer --output-style=GNU --obj=inlined.elf 0x4004be 0x400486 -p --no-inlines; baz() at /tmp/test.cpp:11; foo() at /tmp/test.cpp:6. $ clang -g -fdebug-info-for-profiling test.cpp -o profiling.elf; $ llvm-symbolizer --output-style=GNU --obj=profiling.elf 0x401167 -p --no-inlines; main at /tmp/test.cpp:15 (discriminator 2). $ llvm-symbolizer --output-style=JSON --obj=inlined.elf 0x4004be 0x400486 -p; [; {; ""Address"": ""0x4004be"",; ""ModuleName"": ""inlined.elf"",; ""Symbol"": [; {; ""Column"": 18,; ""Discriminator"": 0,; ""FileName"": ""/tmp/test.cpp"",; ""FunctionName"": ""baz()"",; ""Line"": 11,; ""StartAddress"": ""0x4004be"",; ""StartFileName"": ""/tmp/test.cpp"",; ""StartLine"": 9; },; {; ""Column"": 0,; ""Discriminator"": 0,; ""FileName"": ""/tmp/test.cpp"",; ""FunctionName"": ""main"",; ""Line"": 15,; ""StartAddress"": ""0x4004be"",; ""StartFileName"": ""/tmp/test.cpp"",; ""StartLine"": 14; }; ]; },; {; ""Address"": ""0x400486"",; ""ModuleName"": ""inlined.elf"",; ""Symbol"": [; {; ""Column"": 3,; ""Discriminator"": 0,; ""FileName"": ""/tmp/test.cpp"",; ""FunctionName"": ""foo()"",; ""Line"": 6,; ""StartAddress"": ""0x400486"",; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:9633,Testability,test,test,9633,"t add an empty line after the report for an address. * Does not replace the name of an inlined function with the name of the; topmost caller when inlined frames are not shown. * Prints an address's debug-data discriminator when it is non-zero. One way to; produce discriminators is to compile with clang's -fdebug-info-for-profiling. ``JSON`` style provides a machine readable output in JSON. If addresses are; supplied via stdin, the output JSON will be a series of individual objects.; Otherwise, all results will be contained in a single array. .. code-block:: console. $ llvm-symbolizer --obj=inlined.elf 0x4004be 0x400486 -p; baz() at /tmp/test.cpp:11:18; (inlined by) main at /tmp/test.cpp:15:0. foo() at /tmp/test.cpp:6:3. $ llvm-symbolizer --output-style=LLVM --obj=inlined.elf 0x4004be 0x400486 -p --no-inlines; main at /tmp/test.cpp:11:18. foo() at /tmp/test.cpp:6:3. $ llvm-symbolizer --output-style=GNU --obj=inlined.elf 0x4004be 0x400486 -p --no-inlines; baz() at /tmp/test.cpp:11; foo() at /tmp/test.cpp:6. $ clang -g -fdebug-info-for-profiling test.cpp -o profiling.elf; $ llvm-symbolizer --output-style=GNU --obj=profiling.elf 0x401167 -p --no-inlines; main at /tmp/test.cpp:15 (discriminator 2). $ llvm-symbolizer --output-style=JSON --obj=inlined.elf 0x4004be 0x400486 -p; [; {; ""Address"": ""0x4004be"",; ""ModuleName"": ""inlined.elf"",; ""Symbol"": [; {; ""Column"": 18,; ""Discriminator"": 0,; ""FileName"": ""/tmp/test.cpp"",; ""FunctionName"": ""baz()"",; ""Line"": 11,; ""StartAddress"": ""0x4004be"",; ""StartFileName"": ""/tmp/test.cpp"",; ""StartLine"": 9; },; {; ""Column"": 0,; ""Discriminator"": 0,; ""FileName"": ""/tmp/test.cpp"",; ""FunctionName"": ""main"",; ""Line"": 15,; ""StartAddress"": ""0x4004be"",; ""StartFileName"": ""/tmp/test.cpp"",; ""StartLine"": 14; }; ]; },; {; ""Address"": ""0x400486"",; ""ModuleName"": ""inlined.elf"",; ""Symbol"": [; {; ""Column"": 3,; ""Discriminator"": 0,; ""FileName"": ""/tmp/test.cpp"",; ""FunctionName"": ""foo()"",; ""Line"": 6,; ""StartAddress"": ""0x400486"",; ""StartFileName"": ""/tmp/test.cpp"",; ""StartLi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:9683,Testability,test,test,9683,"n address. * Does not replace the name of an inlined function with the name of the; topmost caller when inlined frames are not shown. * Prints an address's debug-data discriminator when it is non-zero. One way to; produce discriminators is to compile with clang's -fdebug-info-for-profiling. ``JSON`` style provides a machine readable output in JSON. If addresses are; supplied via stdin, the output JSON will be a series of individual objects.; Otherwise, all results will be contained in a single array. .. code-block:: console. $ llvm-symbolizer --obj=inlined.elf 0x4004be 0x400486 -p; baz() at /tmp/test.cpp:11:18; (inlined by) main at /tmp/test.cpp:15:0. foo() at /tmp/test.cpp:6:3. $ llvm-symbolizer --output-style=LLVM --obj=inlined.elf 0x4004be 0x400486 -p --no-inlines; main at /tmp/test.cpp:11:18. foo() at /tmp/test.cpp:6:3. $ llvm-symbolizer --output-style=GNU --obj=inlined.elf 0x4004be 0x400486 -p --no-inlines; baz() at /tmp/test.cpp:11; foo() at /tmp/test.cpp:6. $ clang -g -fdebug-info-for-profiling test.cpp -o profiling.elf; $ llvm-symbolizer --output-style=GNU --obj=profiling.elf 0x401167 -p --no-inlines; main at /tmp/test.cpp:15 (discriminator 2). $ llvm-symbolizer --output-style=JSON --obj=inlined.elf 0x4004be 0x400486 -p; [; {; ""Address"": ""0x4004be"",; ""ModuleName"": ""inlined.elf"",; ""Symbol"": [; {; ""Column"": 18,; ""Discriminator"": 0,; ""FileName"": ""/tmp/test.cpp"",; ""FunctionName"": ""baz()"",; ""Line"": 11,; ""StartAddress"": ""0x4004be"",; ""StartFileName"": ""/tmp/test.cpp"",; ""StartLine"": 9; },; {; ""Column"": 0,; ""Discriminator"": 0,; ""FileName"": ""/tmp/test.cpp"",; ""FunctionName"": ""main"",; ""Line"": 15,; ""StartAddress"": ""0x4004be"",; ""StartFileName"": ""/tmp/test.cpp"",; ""StartLine"": 14; }; ]; },; {; ""Address"": ""0x400486"",; ""ModuleName"": ""inlined.elf"",; ""Symbol"": [; {; ""Column"": 3,; ""Discriminator"": 0,; ""FileName"": ""/tmp/test.cpp"",; ""FunctionName"": ""foo()"",; ""Line"": 6,; ""StartAddress"": ""0x400486"",; ""StartFileName"": ""/tmp/test.cpp"",; ""StartLine"": 5; }; ]; }; ]. .. option:: --pretty-",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:9806,Testability,test,test,9806,"e not shown. * Prints an address's debug-data discriminator when it is non-zero. One way to; produce discriminators is to compile with clang's -fdebug-info-for-profiling. ``JSON`` style provides a machine readable output in JSON. If addresses are; supplied via stdin, the output JSON will be a series of individual objects.; Otherwise, all results will be contained in a single array. .. code-block:: console. $ llvm-symbolizer --obj=inlined.elf 0x4004be 0x400486 -p; baz() at /tmp/test.cpp:11:18; (inlined by) main at /tmp/test.cpp:15:0. foo() at /tmp/test.cpp:6:3. $ llvm-symbolizer --output-style=LLVM --obj=inlined.elf 0x4004be 0x400486 -p --no-inlines; main at /tmp/test.cpp:11:18. foo() at /tmp/test.cpp:6:3. $ llvm-symbolizer --output-style=GNU --obj=inlined.elf 0x4004be 0x400486 -p --no-inlines; baz() at /tmp/test.cpp:11; foo() at /tmp/test.cpp:6. $ clang -g -fdebug-info-for-profiling test.cpp -o profiling.elf; $ llvm-symbolizer --output-style=GNU --obj=profiling.elf 0x401167 -p --no-inlines; main at /tmp/test.cpp:15 (discriminator 2). $ llvm-symbolizer --output-style=JSON --obj=inlined.elf 0x4004be 0x400486 -p; [; {; ""Address"": ""0x4004be"",; ""ModuleName"": ""inlined.elf"",; ""Symbol"": [; {; ""Column"": 18,; ""Discriminator"": 0,; ""FileName"": ""/tmp/test.cpp"",; ""FunctionName"": ""baz()"",; ""Line"": 11,; ""StartAddress"": ""0x4004be"",; ""StartFileName"": ""/tmp/test.cpp"",; ""StartLine"": 9; },; {; ""Column"": 0,; ""Discriminator"": 0,; ""FileName"": ""/tmp/test.cpp"",; ""FunctionName"": ""main"",; ""Line"": 15,; ""StartAddress"": ""0x4004be"",; ""StartFileName"": ""/tmp/test.cpp"",; ""StartLine"": 14; }; ]; },; {; ""Address"": ""0x400486"",; ""ModuleName"": ""inlined.elf"",; ""Symbol"": [; {; ""Column"": 3,; ""Discriminator"": 0,; ""FileName"": ""/tmp/test.cpp"",; ""FunctionName"": ""foo()"",; ""Line"": 6,; ""StartAddress"": ""0x400486"",; ""StartFileName"": ""/tmp/test.cpp"",; ""StartLine"": 5; }; ]; }; ]. .. option:: --pretty-print, -p. Print human readable output. If :option:`--inlining` is specified, the; enclosing scope is prefixed by (inline",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:10045,Testability,test,test,10045,"n JSON. If addresses are; supplied via stdin, the output JSON will be a series of individual objects.; Otherwise, all results will be contained in a single array. .. code-block:: console. $ llvm-symbolizer --obj=inlined.elf 0x4004be 0x400486 -p; baz() at /tmp/test.cpp:11:18; (inlined by) main at /tmp/test.cpp:15:0. foo() at /tmp/test.cpp:6:3. $ llvm-symbolizer --output-style=LLVM --obj=inlined.elf 0x4004be 0x400486 -p --no-inlines; main at /tmp/test.cpp:11:18. foo() at /tmp/test.cpp:6:3. $ llvm-symbolizer --output-style=GNU --obj=inlined.elf 0x4004be 0x400486 -p --no-inlines; baz() at /tmp/test.cpp:11; foo() at /tmp/test.cpp:6. $ clang -g -fdebug-info-for-profiling test.cpp -o profiling.elf; $ llvm-symbolizer --output-style=GNU --obj=profiling.elf 0x401167 -p --no-inlines; main at /tmp/test.cpp:15 (discriminator 2). $ llvm-symbolizer --output-style=JSON --obj=inlined.elf 0x4004be 0x400486 -p; [; {; ""Address"": ""0x4004be"",; ""ModuleName"": ""inlined.elf"",; ""Symbol"": [; {; ""Column"": 18,; ""Discriminator"": 0,; ""FileName"": ""/tmp/test.cpp"",; ""FunctionName"": ""baz()"",; ""Line"": 11,; ""StartAddress"": ""0x4004be"",; ""StartFileName"": ""/tmp/test.cpp"",; ""StartLine"": 9; },; {; ""Column"": 0,; ""Discriminator"": 0,; ""FileName"": ""/tmp/test.cpp"",; ""FunctionName"": ""main"",; ""Line"": 15,; ""StartAddress"": ""0x4004be"",; ""StartFileName"": ""/tmp/test.cpp"",; ""StartLine"": 14; }; ]; },; {; ""Address"": ""0x400486"",; ""ModuleName"": ""inlined.elf"",; ""Symbol"": [; {; ""Column"": 3,; ""Discriminator"": 0,; ""FileName"": ""/tmp/test.cpp"",; ""FunctionName"": ""foo()"",; ""Line"": 6,; ""StartAddress"": ""0x400486"",; ""StartFileName"": ""/tmp/test.cpp"",; ""StartLine"": 5; }; ]; }; ]. .. option:: --pretty-print, -p. Print human readable output. If :option:`--inlining` is specified, the; enclosing scope is prefixed by (inlined by).; For JSON output, the option will cause JSON to be indented and split over; new lines. Otherwise, the JSON output will be printed in a compact form. .. code-block:: console. $ llvm-symbolizer --obj=inlined.elf 0x400",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:10148,Testability,test,test,10148," objects.; Otherwise, all results will be contained in a single array. .. code-block:: console. $ llvm-symbolizer --obj=inlined.elf 0x4004be 0x400486 -p; baz() at /tmp/test.cpp:11:18; (inlined by) main at /tmp/test.cpp:15:0. foo() at /tmp/test.cpp:6:3. $ llvm-symbolizer --output-style=LLVM --obj=inlined.elf 0x4004be 0x400486 -p --no-inlines; main at /tmp/test.cpp:11:18. foo() at /tmp/test.cpp:6:3. $ llvm-symbolizer --output-style=GNU --obj=inlined.elf 0x4004be 0x400486 -p --no-inlines; baz() at /tmp/test.cpp:11; foo() at /tmp/test.cpp:6. $ clang -g -fdebug-info-for-profiling test.cpp -o profiling.elf; $ llvm-symbolizer --output-style=GNU --obj=profiling.elf 0x401167 -p --no-inlines; main at /tmp/test.cpp:15 (discriminator 2). $ llvm-symbolizer --output-style=JSON --obj=inlined.elf 0x4004be 0x400486 -p; [; {; ""Address"": ""0x4004be"",; ""ModuleName"": ""inlined.elf"",; ""Symbol"": [; {; ""Column"": 18,; ""Discriminator"": 0,; ""FileName"": ""/tmp/test.cpp"",; ""FunctionName"": ""baz()"",; ""Line"": 11,; ""StartAddress"": ""0x4004be"",; ""StartFileName"": ""/tmp/test.cpp"",; ""StartLine"": 9; },; {; ""Column"": 0,; ""Discriminator"": 0,; ""FileName"": ""/tmp/test.cpp"",; ""FunctionName"": ""main"",; ""Line"": 15,; ""StartAddress"": ""0x4004be"",; ""StartFileName"": ""/tmp/test.cpp"",; ""StartLine"": 14; }; ]; },; {; ""Address"": ""0x400486"",; ""ModuleName"": ""inlined.elf"",; ""Symbol"": [; {; ""Column"": 3,; ""Discriminator"": 0,; ""FileName"": ""/tmp/test.cpp"",; ""FunctionName"": ""foo()"",; ""Line"": 6,; ""StartAddress"": ""0x400486"",; ""StartFileName"": ""/tmp/test.cpp"",; ""StartLine"": 5; }; ]; }; ]. .. option:: --pretty-print, -p. Print human readable output. If :option:`--inlining` is specified, the; enclosing scope is prefixed by (inlined by).; For JSON output, the option will cause JSON to be indented and split over; new lines. Otherwise, the JSON output will be printed in a compact form. .. code-block:: console. $ llvm-symbolizer --obj=inlined.elf 0x4004be --inlining --pretty-print; baz() at /tmp/test.cpp:11:18; (inlined by) main at /tmp/test.c",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:10236,Testability,test,test,10236,"$ llvm-symbolizer --obj=inlined.elf 0x4004be 0x400486 -p; baz() at /tmp/test.cpp:11:18; (inlined by) main at /tmp/test.cpp:15:0. foo() at /tmp/test.cpp:6:3. $ llvm-symbolizer --output-style=LLVM --obj=inlined.elf 0x4004be 0x400486 -p --no-inlines; main at /tmp/test.cpp:11:18. foo() at /tmp/test.cpp:6:3. $ llvm-symbolizer --output-style=GNU --obj=inlined.elf 0x4004be 0x400486 -p --no-inlines; baz() at /tmp/test.cpp:11; foo() at /tmp/test.cpp:6. $ clang -g -fdebug-info-for-profiling test.cpp -o profiling.elf; $ llvm-symbolizer --output-style=GNU --obj=profiling.elf 0x401167 -p --no-inlines; main at /tmp/test.cpp:15 (discriminator 2). $ llvm-symbolizer --output-style=JSON --obj=inlined.elf 0x4004be 0x400486 -p; [; {; ""Address"": ""0x4004be"",; ""ModuleName"": ""inlined.elf"",; ""Symbol"": [; {; ""Column"": 18,; ""Discriminator"": 0,; ""FileName"": ""/tmp/test.cpp"",; ""FunctionName"": ""baz()"",; ""Line"": 11,; ""StartAddress"": ""0x4004be"",; ""StartFileName"": ""/tmp/test.cpp"",; ""StartLine"": 9; },; {; ""Column"": 0,; ""Discriminator"": 0,; ""FileName"": ""/tmp/test.cpp"",; ""FunctionName"": ""main"",; ""Line"": 15,; ""StartAddress"": ""0x4004be"",; ""StartFileName"": ""/tmp/test.cpp"",; ""StartLine"": 14; }; ]; },; {; ""Address"": ""0x400486"",; ""ModuleName"": ""inlined.elf"",; ""Symbol"": [; {; ""Column"": 3,; ""Discriminator"": 0,; ""FileName"": ""/tmp/test.cpp"",; ""FunctionName"": ""foo()"",; ""Line"": 6,; ""StartAddress"": ""0x400486"",; ""StartFileName"": ""/tmp/test.cpp"",; ""StartLine"": 5; }; ]; }; ]. .. option:: --pretty-print, -p. Print human readable output. If :option:`--inlining` is specified, the; enclosing scope is prefixed by (inlined by).; For JSON output, the option will cause JSON to be indented and split over; new lines. Otherwise, the JSON output will be printed in a compact form. .. code-block:: console. $ llvm-symbolizer --obj=inlined.elf 0x4004be --inlining --pretty-print; baz() at /tmp/test.cpp:11:18; (inlined by) main at /tmp/test.cpp:15:0. .. option:: --print-address, --addresses, -a. Print address before the source code loc",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:10338,Testability,test,test,10338,"d by) main at /tmp/test.cpp:15:0. foo() at /tmp/test.cpp:6:3. $ llvm-symbolizer --output-style=LLVM --obj=inlined.elf 0x4004be 0x400486 -p --no-inlines; main at /tmp/test.cpp:11:18. foo() at /tmp/test.cpp:6:3. $ llvm-symbolizer --output-style=GNU --obj=inlined.elf 0x4004be 0x400486 -p --no-inlines; baz() at /tmp/test.cpp:11; foo() at /tmp/test.cpp:6. $ clang -g -fdebug-info-for-profiling test.cpp -o profiling.elf; $ llvm-symbolizer --output-style=GNU --obj=profiling.elf 0x401167 -p --no-inlines; main at /tmp/test.cpp:15 (discriminator 2). $ llvm-symbolizer --output-style=JSON --obj=inlined.elf 0x4004be 0x400486 -p; [; {; ""Address"": ""0x4004be"",; ""ModuleName"": ""inlined.elf"",; ""Symbol"": [; {; ""Column"": 18,; ""Discriminator"": 0,; ""FileName"": ""/tmp/test.cpp"",; ""FunctionName"": ""baz()"",; ""Line"": 11,; ""StartAddress"": ""0x4004be"",; ""StartFileName"": ""/tmp/test.cpp"",; ""StartLine"": 9; },; {; ""Column"": 0,; ""Discriminator"": 0,; ""FileName"": ""/tmp/test.cpp"",; ""FunctionName"": ""main"",; ""Line"": 15,; ""StartAddress"": ""0x4004be"",; ""StartFileName"": ""/tmp/test.cpp"",; ""StartLine"": 14; }; ]; },; {; ""Address"": ""0x400486"",; ""ModuleName"": ""inlined.elf"",; ""Symbol"": [; {; ""Column"": 3,; ""Discriminator"": 0,; ""FileName"": ""/tmp/test.cpp"",; ""FunctionName"": ""foo()"",; ""Line"": 6,; ""StartAddress"": ""0x400486"",; ""StartFileName"": ""/tmp/test.cpp"",; ""StartLine"": 5; }; ]; }; ]. .. option:: --pretty-print, -p. Print human readable output. If :option:`--inlining` is specified, the; enclosing scope is prefixed by (inlined by).; For JSON output, the option will cause JSON to be indented and split over; new lines. Otherwise, the JSON output will be printed in a compact form. .. code-block:: console. $ llvm-symbolizer --obj=inlined.elf 0x4004be --inlining --pretty-print; baz() at /tmp/test.cpp:11:18; (inlined by) main at /tmp/test.cpp:15:0. .. option:: --print-address, --addresses, -a. Print address before the source code location. Defaults to false. .. code-block:: console. $ llvm-symbolizer --obj=inlined.elf --print-",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:10503,Testability,test,test,10503,"11:18. foo() at /tmp/test.cpp:6:3. $ llvm-symbolizer --output-style=GNU --obj=inlined.elf 0x4004be 0x400486 -p --no-inlines; baz() at /tmp/test.cpp:11; foo() at /tmp/test.cpp:6. $ clang -g -fdebug-info-for-profiling test.cpp -o profiling.elf; $ llvm-symbolizer --output-style=GNU --obj=profiling.elf 0x401167 -p --no-inlines; main at /tmp/test.cpp:15 (discriminator 2). $ llvm-symbolizer --output-style=JSON --obj=inlined.elf 0x4004be 0x400486 -p; [; {; ""Address"": ""0x4004be"",; ""ModuleName"": ""inlined.elf"",; ""Symbol"": [; {; ""Column"": 18,; ""Discriminator"": 0,; ""FileName"": ""/tmp/test.cpp"",; ""FunctionName"": ""baz()"",; ""Line"": 11,; ""StartAddress"": ""0x4004be"",; ""StartFileName"": ""/tmp/test.cpp"",; ""StartLine"": 9; },; {; ""Column"": 0,; ""Discriminator"": 0,; ""FileName"": ""/tmp/test.cpp"",; ""FunctionName"": ""main"",; ""Line"": 15,; ""StartAddress"": ""0x4004be"",; ""StartFileName"": ""/tmp/test.cpp"",; ""StartLine"": 14; }; ]; },; {; ""Address"": ""0x400486"",; ""ModuleName"": ""inlined.elf"",; ""Symbol"": [; {; ""Column"": 3,; ""Discriminator"": 0,; ""FileName"": ""/tmp/test.cpp"",; ""FunctionName"": ""foo()"",; ""Line"": 6,; ""StartAddress"": ""0x400486"",; ""StartFileName"": ""/tmp/test.cpp"",; ""StartLine"": 5; }; ]; }; ]. .. option:: --pretty-print, -p. Print human readable output. If :option:`--inlining` is specified, the; enclosing scope is prefixed by (inlined by).; For JSON output, the option will cause JSON to be indented and split over; new lines. Otherwise, the JSON output will be printed in a compact form. .. code-block:: console. $ llvm-symbolizer --obj=inlined.elf 0x4004be --inlining --pretty-print; baz() at /tmp/test.cpp:11:18; (inlined by) main at /tmp/test.cpp:15:0. .. option:: --print-address, --addresses, -a. Print address before the source code location. Defaults to false. .. code-block:: console. $ llvm-symbolizer --obj=inlined.elf --print-address 0x4004be; 0x4004be; baz(); /tmp/test.cpp:11:18; main; /tmp/test.cpp:15:0. $ llvm-symbolizer --obj=inlined.elf 0x4004be --pretty-print --print-address; 0x4004be: baz() a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:10605,Testability,test,test,10605,"4004be 0x400486 -p --no-inlines; baz() at /tmp/test.cpp:11; foo() at /tmp/test.cpp:6. $ clang -g -fdebug-info-for-profiling test.cpp -o profiling.elf; $ llvm-symbolizer --output-style=GNU --obj=profiling.elf 0x401167 -p --no-inlines; main at /tmp/test.cpp:15 (discriminator 2). $ llvm-symbolizer --output-style=JSON --obj=inlined.elf 0x4004be 0x400486 -p; [; {; ""Address"": ""0x4004be"",; ""ModuleName"": ""inlined.elf"",; ""Symbol"": [; {; ""Column"": 18,; ""Discriminator"": 0,; ""FileName"": ""/tmp/test.cpp"",; ""FunctionName"": ""baz()"",; ""Line"": 11,; ""StartAddress"": ""0x4004be"",; ""StartFileName"": ""/tmp/test.cpp"",; ""StartLine"": 9; },; {; ""Column"": 0,; ""Discriminator"": 0,; ""FileName"": ""/tmp/test.cpp"",; ""FunctionName"": ""main"",; ""Line"": 15,; ""StartAddress"": ""0x4004be"",; ""StartFileName"": ""/tmp/test.cpp"",; ""StartLine"": 14; }; ]; },; {; ""Address"": ""0x400486"",; ""ModuleName"": ""inlined.elf"",; ""Symbol"": [; {; ""Column"": 3,; ""Discriminator"": 0,; ""FileName"": ""/tmp/test.cpp"",; ""FunctionName"": ""foo()"",; ""Line"": 6,; ""StartAddress"": ""0x400486"",; ""StartFileName"": ""/tmp/test.cpp"",; ""StartLine"": 5; }; ]; }; ]. .. option:: --pretty-print, -p. Print human readable output. If :option:`--inlining` is specified, the; enclosing scope is prefixed by (inlined by).; For JSON output, the option will cause JSON to be indented and split over; new lines. Otherwise, the JSON output will be printed in a compact form. .. code-block:: console. $ llvm-symbolizer --obj=inlined.elf 0x4004be --inlining --pretty-print; baz() at /tmp/test.cpp:11:18; (inlined by) main at /tmp/test.cpp:15:0. .. option:: --print-address, --addresses, -a. Print address before the source code location. Defaults to false. .. code-block:: console. $ llvm-symbolizer --obj=inlined.elf --print-address 0x4004be; 0x4004be; baz(); /tmp/test.cpp:11:18; main; /tmp/test.cpp:15:0. $ llvm-symbolizer --obj=inlined.elf 0x4004be --pretty-print --print-address; 0x4004be: baz() at /tmp/test.cpp:11:18; (inlined by) main at /tmp/test.cpp:15:0. .. option:: --print-source-",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:11054,Testability,test,test,11054,"ileName"": ""/tmp/test.cpp"",; ""FunctionName"": ""baz()"",; ""Line"": 11,; ""StartAddress"": ""0x4004be"",; ""StartFileName"": ""/tmp/test.cpp"",; ""StartLine"": 9; },; {; ""Column"": 0,; ""Discriminator"": 0,; ""FileName"": ""/tmp/test.cpp"",; ""FunctionName"": ""main"",; ""Line"": 15,; ""StartAddress"": ""0x4004be"",; ""StartFileName"": ""/tmp/test.cpp"",; ""StartLine"": 14; }; ]; },; {; ""Address"": ""0x400486"",; ""ModuleName"": ""inlined.elf"",; ""Symbol"": [; {; ""Column"": 3,; ""Discriminator"": 0,; ""FileName"": ""/tmp/test.cpp"",; ""FunctionName"": ""foo()"",; ""Line"": 6,; ""StartAddress"": ""0x400486"",; ""StartFileName"": ""/tmp/test.cpp"",; ""StartLine"": 5; }; ]; }; ]. .. option:: --pretty-print, -p. Print human readable output. If :option:`--inlining` is specified, the; enclosing scope is prefixed by (inlined by).; For JSON output, the option will cause JSON to be indented and split over; new lines. Otherwise, the JSON output will be printed in a compact form. .. code-block:: console. $ llvm-symbolizer --obj=inlined.elf 0x4004be --inlining --pretty-print; baz() at /tmp/test.cpp:11:18; (inlined by) main at /tmp/test.cpp:15:0. .. option:: --print-address, --addresses, -a. Print address before the source code location. Defaults to false. .. code-block:: console. $ llvm-symbolizer --obj=inlined.elf --print-address 0x4004be; 0x4004be; baz(); /tmp/test.cpp:11:18; main; /tmp/test.cpp:15:0. $ llvm-symbolizer --obj=inlined.elf 0x4004be --pretty-print --print-address; 0x4004be: baz() at /tmp/test.cpp:11:18; (inlined by) main at /tmp/test.cpp:15:0. .. option:: --print-source-context-lines <N>. Print ``N`` lines of source context for each symbolized address. .. code-block:: console. $ llvm-symbolizer --obj=test.elf 0x400490 --print-source-context-lines=3; baz(); /tmp/test.cpp:11:0; 10 : volatile int k = 42;; 11 >: return foz() + k;; 12 : }. .. option:: --relativenames. Print the file's path relative to the compilation directory, instead; of the absolute path. If the command-line to the compiler included; the full path, this will be the sa",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:11096,Testability,test,test,11096,",; ""Line"": 11,; ""StartAddress"": ""0x4004be"",; ""StartFileName"": ""/tmp/test.cpp"",; ""StartLine"": 9; },; {; ""Column"": 0,; ""Discriminator"": 0,; ""FileName"": ""/tmp/test.cpp"",; ""FunctionName"": ""main"",; ""Line"": 15,; ""StartAddress"": ""0x4004be"",; ""StartFileName"": ""/tmp/test.cpp"",; ""StartLine"": 14; }; ]; },; {; ""Address"": ""0x400486"",; ""ModuleName"": ""inlined.elf"",; ""Symbol"": [; {; ""Column"": 3,; ""Discriminator"": 0,; ""FileName"": ""/tmp/test.cpp"",; ""FunctionName"": ""foo()"",; ""Line"": 6,; ""StartAddress"": ""0x400486"",; ""StartFileName"": ""/tmp/test.cpp"",; ""StartLine"": 5; }; ]; }; ]. .. option:: --pretty-print, -p. Print human readable output. If :option:`--inlining` is specified, the; enclosing scope is prefixed by (inlined by).; For JSON output, the option will cause JSON to be indented and split over; new lines. Otherwise, the JSON output will be printed in a compact form. .. code-block:: console. $ llvm-symbolizer --obj=inlined.elf 0x4004be --inlining --pretty-print; baz() at /tmp/test.cpp:11:18; (inlined by) main at /tmp/test.cpp:15:0. .. option:: --print-address, --addresses, -a. Print address before the source code location. Defaults to false. .. code-block:: console. $ llvm-symbolizer --obj=inlined.elf --print-address 0x4004be; 0x4004be; baz(); /tmp/test.cpp:11:18; main; /tmp/test.cpp:15:0. $ llvm-symbolizer --obj=inlined.elf 0x4004be --pretty-print --print-address; 0x4004be: baz() at /tmp/test.cpp:11:18; (inlined by) main at /tmp/test.cpp:15:0. .. option:: --print-source-context-lines <N>. Print ``N`` lines of source context for each symbolized address. .. code-block:: console. $ llvm-symbolizer --obj=test.elf 0x400490 --print-source-context-lines=3; baz(); /tmp/test.cpp:11:0; 10 : volatile int k = 42;; 11 >: return foz() + k;; 12 : }. .. option:: --relativenames. Print the file's path relative to the compilation directory, instead; of the absolute path. If the command-line to the compiler included; the full path, this will be the same as the default. .. option:: --verbose. Print ve",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:11332,Testability,test,test,11332,"4be"",; ""StartFileName"": ""/tmp/test.cpp"",; ""StartLine"": 14; }; ]; },; {; ""Address"": ""0x400486"",; ""ModuleName"": ""inlined.elf"",; ""Symbol"": [; {; ""Column"": 3,; ""Discriminator"": 0,; ""FileName"": ""/tmp/test.cpp"",; ""FunctionName"": ""foo()"",; ""Line"": 6,; ""StartAddress"": ""0x400486"",; ""StartFileName"": ""/tmp/test.cpp"",; ""StartLine"": 5; }; ]; }; ]. .. option:: --pretty-print, -p. Print human readable output. If :option:`--inlining` is specified, the; enclosing scope is prefixed by (inlined by).; For JSON output, the option will cause JSON to be indented and split over; new lines. Otherwise, the JSON output will be printed in a compact form. .. code-block:: console. $ llvm-symbolizer --obj=inlined.elf 0x4004be --inlining --pretty-print; baz() at /tmp/test.cpp:11:18; (inlined by) main at /tmp/test.cpp:15:0. .. option:: --print-address, --addresses, -a. Print address before the source code location. Defaults to false. .. code-block:: console. $ llvm-symbolizer --obj=inlined.elf --print-address 0x4004be; 0x4004be; baz(); /tmp/test.cpp:11:18; main; /tmp/test.cpp:15:0. $ llvm-symbolizer --obj=inlined.elf 0x4004be --pretty-print --print-address; 0x4004be: baz() at /tmp/test.cpp:11:18; (inlined by) main at /tmp/test.cpp:15:0. .. option:: --print-source-context-lines <N>. Print ``N`` lines of source context for each symbolized address. .. code-block:: console. $ llvm-symbolizer --obj=test.elf 0x400490 --print-source-context-lines=3; baz(); /tmp/test.cpp:11:0; 10 : volatile int k = 42;; 11 >: return foz() + k;; 12 : }. .. option:: --relativenames. Print the file's path relative to the compilation directory, instead; of the absolute path. If the command-line to the compiler included; the full path, this will be the same as the default. .. option:: --verbose. Print verbose address, line and column information. .. code-block:: console. $ llvm-symbolizer --obj=inlined.elf --verbose 0x4004be; baz(); Filename: /tmp/test.cpp; Function start filename: /tmp/test.cpp; Function start line: 9; Function",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:11359,Testability,test,test,11359,"""StartLine"": 14; }; ]; },; {; ""Address"": ""0x400486"",; ""ModuleName"": ""inlined.elf"",; ""Symbol"": [; {; ""Column"": 3,; ""Discriminator"": 0,; ""FileName"": ""/tmp/test.cpp"",; ""FunctionName"": ""foo()"",; ""Line"": 6,; ""StartAddress"": ""0x400486"",; ""StartFileName"": ""/tmp/test.cpp"",; ""StartLine"": 5; }; ]; }; ]. .. option:: --pretty-print, -p. Print human readable output. If :option:`--inlining` is specified, the; enclosing scope is prefixed by (inlined by).; For JSON output, the option will cause JSON to be indented and split over; new lines. Otherwise, the JSON output will be printed in a compact form. .. code-block:: console. $ llvm-symbolizer --obj=inlined.elf 0x4004be --inlining --pretty-print; baz() at /tmp/test.cpp:11:18; (inlined by) main at /tmp/test.cpp:15:0. .. option:: --print-address, --addresses, -a. Print address before the source code location. Defaults to false. .. code-block:: console. $ llvm-symbolizer --obj=inlined.elf --print-address 0x4004be; 0x4004be; baz(); /tmp/test.cpp:11:18; main; /tmp/test.cpp:15:0. $ llvm-symbolizer --obj=inlined.elf 0x4004be --pretty-print --print-address; 0x4004be: baz() at /tmp/test.cpp:11:18; (inlined by) main at /tmp/test.cpp:15:0. .. option:: --print-source-context-lines <N>. Print ``N`` lines of source context for each symbolized address. .. code-block:: console. $ llvm-symbolizer --obj=test.elf 0x400490 --print-source-context-lines=3; baz(); /tmp/test.cpp:11:0; 10 : volatile int k = 42;; 11 >: return foz() + k;; 12 : }. .. option:: --relativenames. Print the file's path relative to the compilation directory, instead; of the absolute path. If the command-line to the compiler included; the full path, this will be the same as the default. .. option:: --verbose. Print verbose address, line and column information. .. code-block:: console. $ llvm-symbolizer --obj=inlined.elf --verbose 0x4004be; baz(); Filename: /tmp/test.cpp; Function start filename: /tmp/test.cpp; Function start line: 9; Function start address: 0x4004b6; Line: 11; Column",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:11475,Testability,test,test,11475," [; {; ""Column"": 3,; ""Discriminator"": 0,; ""FileName"": ""/tmp/test.cpp"",; ""FunctionName"": ""foo()"",; ""Line"": 6,; ""StartAddress"": ""0x400486"",; ""StartFileName"": ""/tmp/test.cpp"",; ""StartLine"": 5; }; ]; }; ]. .. option:: --pretty-print, -p. Print human readable output. If :option:`--inlining` is specified, the; enclosing scope is prefixed by (inlined by).; For JSON output, the option will cause JSON to be indented and split over; new lines. Otherwise, the JSON output will be printed in a compact form. .. code-block:: console. $ llvm-symbolizer --obj=inlined.elf 0x4004be --inlining --pretty-print; baz() at /tmp/test.cpp:11:18; (inlined by) main at /tmp/test.cpp:15:0. .. option:: --print-address, --addresses, -a. Print address before the source code location. Defaults to false. .. code-block:: console. $ llvm-symbolizer --obj=inlined.elf --print-address 0x4004be; 0x4004be; baz(); /tmp/test.cpp:11:18; main; /tmp/test.cpp:15:0. $ llvm-symbolizer --obj=inlined.elf 0x4004be --pretty-print --print-address; 0x4004be: baz() at /tmp/test.cpp:11:18; (inlined by) main at /tmp/test.cpp:15:0. .. option:: --print-source-context-lines <N>. Print ``N`` lines of source context for each symbolized address. .. code-block:: console. $ llvm-symbolizer --obj=test.elf 0x400490 --print-source-context-lines=3; baz(); /tmp/test.cpp:11:0; 10 : volatile int k = 42;; 11 >: return foz() + k;; 12 : }. .. option:: --relativenames. Print the file's path relative to the compilation directory, instead; of the absolute path. If the command-line to the compiler included; the full path, this will be the same as the default. .. option:: --verbose. Print verbose address, line and column information. .. code-block:: console. $ llvm-symbolizer --obj=inlined.elf --verbose 0x4004be; baz(); Filename: /tmp/test.cpp; Function start filename: /tmp/test.cpp; Function start line: 9; Function start address: 0x4004b6; Line: 11; Column: 18; main; Filename: /tmp/test.cpp; Function start filename: /tmp/test.cpp; Function start ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:11517,Testability,test,test,11517,"p/test.cpp"",; ""FunctionName"": ""foo()"",; ""Line"": 6,; ""StartAddress"": ""0x400486"",; ""StartFileName"": ""/tmp/test.cpp"",; ""StartLine"": 5; }; ]; }; ]. .. option:: --pretty-print, -p. Print human readable output. If :option:`--inlining` is specified, the; enclosing scope is prefixed by (inlined by).; For JSON output, the option will cause JSON to be indented and split over; new lines. Otherwise, the JSON output will be printed in a compact form. .. code-block:: console. $ llvm-symbolizer --obj=inlined.elf 0x4004be --inlining --pretty-print; baz() at /tmp/test.cpp:11:18; (inlined by) main at /tmp/test.cpp:15:0. .. option:: --print-address, --addresses, -a. Print address before the source code location. Defaults to false. .. code-block:: console. $ llvm-symbolizer --obj=inlined.elf --print-address 0x4004be; 0x4004be; baz(); /tmp/test.cpp:11:18; main; /tmp/test.cpp:15:0. $ llvm-symbolizer --obj=inlined.elf 0x4004be --pretty-print --print-address; 0x4004be: baz() at /tmp/test.cpp:11:18; (inlined by) main at /tmp/test.cpp:15:0. .. option:: --print-source-context-lines <N>. Print ``N`` lines of source context for each symbolized address. .. code-block:: console. $ llvm-symbolizer --obj=test.elf 0x400490 --print-source-context-lines=3; baz(); /tmp/test.cpp:11:0; 10 : volatile int k = 42;; 11 >: return foz() + k;; 12 : }. .. option:: --relativenames. Print the file's path relative to the compilation directory, instead; of the absolute path. If the command-line to the compiler included; the full path, this will be the same as the default. .. option:: --verbose. Print verbose address, line and column information. .. code-block:: console. $ llvm-symbolizer --obj=inlined.elf --verbose 0x4004be; baz(); Filename: /tmp/test.cpp; Function start filename: /tmp/test.cpp; Function start line: 9; Function start address: 0x4004b6; Line: 11; Column: 18; main; Filename: /tmp/test.cpp; Function start filename: /tmp/test.cpp; Function start line: 14; Function start address: 0x4004b0; Line: 15; Colu",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:11692,Testability,test,test,11692," human readable output. If :option:`--inlining` is specified, the; enclosing scope is prefixed by (inlined by).; For JSON output, the option will cause JSON to be indented and split over; new lines. Otherwise, the JSON output will be printed in a compact form. .. code-block:: console. $ llvm-symbolizer --obj=inlined.elf 0x4004be --inlining --pretty-print; baz() at /tmp/test.cpp:11:18; (inlined by) main at /tmp/test.cpp:15:0. .. option:: --print-address, --addresses, -a. Print address before the source code location. Defaults to false. .. code-block:: console. $ llvm-symbolizer --obj=inlined.elf --print-address 0x4004be; 0x4004be; baz(); /tmp/test.cpp:11:18; main; /tmp/test.cpp:15:0. $ llvm-symbolizer --obj=inlined.elf 0x4004be --pretty-print --print-address; 0x4004be: baz() at /tmp/test.cpp:11:18; (inlined by) main at /tmp/test.cpp:15:0. .. option:: --print-source-context-lines <N>. Print ``N`` lines of source context for each symbolized address. .. code-block:: console. $ llvm-symbolizer --obj=test.elf 0x400490 --print-source-context-lines=3; baz(); /tmp/test.cpp:11:0; 10 : volatile int k = 42;; 11 >: return foz() + k;; 12 : }. .. option:: --relativenames. Print the file's path relative to the compilation directory, instead; of the absolute path. If the command-line to the compiler included; the full path, this will be the same as the default. .. option:: --verbose. Print verbose address, line and column information. .. code-block:: console. $ llvm-symbolizer --obj=inlined.elf --verbose 0x4004be; baz(); Filename: /tmp/test.cpp; Function start filename: /tmp/test.cpp; Function start line: 9; Function start address: 0x4004b6; Line: 11; Column: 18; main; Filename: /tmp/test.cpp; Function start filename: /tmp/test.cpp; Function start line: 14; Function start address: 0x4004b0; Line: 15; Column: 18. .. option:: --version, -v. Print version information for the tool. .. option:: @<FILE>. Read command-line options from response file `<FILE>`. WINDOWS/PDB SPECIFIC OPTIONS; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:11754,Testability,test,test,11754,"` is specified, the; enclosing scope is prefixed by (inlined by).; For JSON output, the option will cause JSON to be indented and split over; new lines. Otherwise, the JSON output will be printed in a compact form. .. code-block:: console. $ llvm-symbolizer --obj=inlined.elf 0x4004be --inlining --pretty-print; baz() at /tmp/test.cpp:11:18; (inlined by) main at /tmp/test.cpp:15:0. .. option:: --print-address, --addresses, -a. Print address before the source code location. Defaults to false. .. code-block:: console. $ llvm-symbolizer --obj=inlined.elf --print-address 0x4004be; 0x4004be; baz(); /tmp/test.cpp:11:18; main; /tmp/test.cpp:15:0. $ llvm-symbolizer --obj=inlined.elf 0x4004be --pretty-print --print-address; 0x4004be: baz() at /tmp/test.cpp:11:18; (inlined by) main at /tmp/test.cpp:15:0. .. option:: --print-source-context-lines <N>. Print ``N`` lines of source context for each symbolized address. .. code-block:: console. $ llvm-symbolizer --obj=test.elf 0x400490 --print-source-context-lines=3; baz(); /tmp/test.cpp:11:0; 10 : volatile int k = 42;; 11 >: return foz() + k;; 12 : }. .. option:: --relativenames. Print the file's path relative to the compilation directory, instead; of the absolute path. If the command-line to the compiler included; the full path, this will be the same as the default. .. option:: --verbose. Print verbose address, line and column information. .. code-block:: console. $ llvm-symbolizer --obj=inlined.elf --verbose 0x4004be; baz(); Filename: /tmp/test.cpp; Function start filename: /tmp/test.cpp; Function start line: 9; Function start address: 0x4004b6; Line: 11; Column: 18; main; Filename: /tmp/test.cpp; Function start filename: /tmp/test.cpp; Function start line: 14; Function start address: 0x4004b0; Line: 15; Column: 18. .. option:: --version, -v. Print version information for the tool. .. option:: @<FILE>. Read command-line options from response file `<FILE>`. WINDOWS/PDB SPECIFIC OPTIONS; -----------------------------. .. option:: --d",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:12227,Testability,test,test,12227,"faults to false. .. code-block:: console. $ llvm-symbolizer --obj=inlined.elf --print-address 0x4004be; 0x4004be; baz(); /tmp/test.cpp:11:18; main; /tmp/test.cpp:15:0. $ llvm-symbolizer --obj=inlined.elf 0x4004be --pretty-print --print-address; 0x4004be: baz() at /tmp/test.cpp:11:18; (inlined by) main at /tmp/test.cpp:15:0. .. option:: --print-source-context-lines <N>. Print ``N`` lines of source context for each symbolized address. .. code-block:: console. $ llvm-symbolizer --obj=test.elf 0x400490 --print-source-context-lines=3; baz(); /tmp/test.cpp:11:0; 10 : volatile int k = 42;; 11 >: return foz() + k;; 12 : }. .. option:: --relativenames. Print the file's path relative to the compilation directory, instead; of the absolute path. If the command-line to the compiler included; the full path, this will be the same as the default. .. option:: --verbose. Print verbose address, line and column information. .. code-block:: console. $ llvm-symbolizer --obj=inlined.elf --verbose 0x4004be; baz(); Filename: /tmp/test.cpp; Function start filename: /tmp/test.cpp; Function start line: 9; Function start address: 0x4004b6; Line: 11; Column: 18; main; Filename: /tmp/test.cpp; Function start filename: /tmp/test.cpp; Function start line: 14; Function start address: 0x4004b0; Line: 15; Column: 18. .. option:: --version, -v. Print version information for the tool. .. option:: @<FILE>. Read command-line options from response file `<FILE>`. WINDOWS/PDB SPECIFIC OPTIONS; -----------------------------. .. option:: --dia. Use the Windows DIA SDK for symbolization. If the DIA SDK is not found,; llvm-symbolizer will fall back to the native implementation. MACH-O SPECIFIC OPTIONS; -----------------------. .. option:: --default-arch <arch>. If a binary contains object files for multiple architectures (e.g. it is a; Mach-O universal binary), symbolize the object file for a given architecture.; You can also specify the architecture by writing ``binary_name:arch_name`` in; the input (see example",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:12267,Testability,test,test,12267,"vm-symbolizer --obj=inlined.elf --print-address 0x4004be; 0x4004be; baz(); /tmp/test.cpp:11:18; main; /tmp/test.cpp:15:0. $ llvm-symbolizer --obj=inlined.elf 0x4004be --pretty-print --print-address; 0x4004be: baz() at /tmp/test.cpp:11:18; (inlined by) main at /tmp/test.cpp:15:0. .. option:: --print-source-context-lines <N>. Print ``N`` lines of source context for each symbolized address. .. code-block:: console. $ llvm-symbolizer --obj=test.elf 0x400490 --print-source-context-lines=3; baz(); /tmp/test.cpp:11:0; 10 : volatile int k = 42;; 11 >: return foz() + k;; 12 : }. .. option:: --relativenames. Print the file's path relative to the compilation directory, instead; of the absolute path. If the command-line to the compiler included; the full path, this will be the same as the default. .. option:: --verbose. Print verbose address, line and column information. .. code-block:: console. $ llvm-symbolizer --obj=inlined.elf --verbose 0x4004be; baz(); Filename: /tmp/test.cpp; Function start filename: /tmp/test.cpp; Function start line: 9; Function start address: 0x4004b6; Line: 11; Column: 18; main; Filename: /tmp/test.cpp; Function start filename: /tmp/test.cpp; Function start line: 14; Function start address: 0x4004b0; Line: 15; Column: 18. .. option:: --version, -v. Print version information for the tool. .. option:: @<FILE>. Read command-line options from response file `<FILE>`. WINDOWS/PDB SPECIFIC OPTIONS; -----------------------------. .. option:: --dia. Use the Windows DIA SDK for symbolization. If the DIA SDK is not found,; llvm-symbolizer will fall back to the native implementation. MACH-O SPECIFIC OPTIONS; -----------------------. .. option:: --default-arch <arch>. If a binary contains object files for multiple architectures (e.g. it is a; Mach-O universal binary), symbolize the object file for a given architecture.; You can also specify the architecture by writing ``binary_name:arch_name`` in; the input (see example below). If the architecture is not specified",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:12378,Testability,test,test,12378,"/tmp/test.cpp:11:18; main; /tmp/test.cpp:15:0. $ llvm-symbolizer --obj=inlined.elf 0x4004be --pretty-print --print-address; 0x4004be: baz() at /tmp/test.cpp:11:18; (inlined by) main at /tmp/test.cpp:15:0. .. option:: --print-source-context-lines <N>. Print ``N`` lines of source context for each symbolized address. .. code-block:: console. $ llvm-symbolizer --obj=test.elf 0x400490 --print-source-context-lines=3; baz(); /tmp/test.cpp:11:0; 10 : volatile int k = 42;; 11 >: return foz() + k;; 12 : }. .. option:: --relativenames. Print the file's path relative to the compilation directory, instead; of the absolute path. If the command-line to the compiler included; the full path, this will be the same as the default. .. option:: --verbose. Print verbose address, line and column information. .. code-block:: console. $ llvm-symbolizer --obj=inlined.elf --verbose 0x4004be; baz(); Filename: /tmp/test.cpp; Function start filename: /tmp/test.cpp; Function start line: 9; Function start address: 0x4004b6; Line: 11; Column: 18; main; Filename: /tmp/test.cpp; Function start filename: /tmp/test.cpp; Function start line: 14; Function start address: 0x4004b0; Line: 15; Column: 18. .. option:: --version, -v. Print version information for the tool. .. option:: @<FILE>. Read command-line options from response file `<FILE>`. WINDOWS/PDB SPECIFIC OPTIONS; -----------------------------. .. option:: --dia. Use the Windows DIA SDK for symbolization. If the DIA SDK is not found,; llvm-symbolizer will fall back to the native implementation. MACH-O SPECIFIC OPTIONS; -----------------------. .. option:: --default-arch <arch>. If a binary contains object files for multiple architectures (e.g. it is a; Mach-O universal binary), symbolize the object file for a given architecture.; You can also specify the architecture by writing ``binary_name:arch_name`` in; the input (see example below). If the architecture is not specified in either; way, the address will not be symbolized. Defaults to empty strin",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst:12418,Testability,test,test,12418,"ed.elf 0x4004be --pretty-print --print-address; 0x4004be: baz() at /tmp/test.cpp:11:18; (inlined by) main at /tmp/test.cpp:15:0. .. option:: --print-source-context-lines <N>. Print ``N`` lines of source context for each symbolized address. .. code-block:: console. $ llvm-symbolizer --obj=test.elf 0x400490 --print-source-context-lines=3; baz(); /tmp/test.cpp:11:0; 10 : volatile int k = 42;; 11 >: return foz() + k;; 12 : }. .. option:: --relativenames. Print the file's path relative to the compilation directory, instead; of the absolute path. If the command-line to the compiler included; the full path, this will be the same as the default. .. option:: --verbose. Print verbose address, line and column information. .. code-block:: console. $ llvm-symbolizer --obj=inlined.elf --verbose 0x4004be; baz(); Filename: /tmp/test.cpp; Function start filename: /tmp/test.cpp; Function start line: 9; Function start address: 0x4004b6; Line: 11; Column: 18; main; Filename: /tmp/test.cpp; Function start filename: /tmp/test.cpp; Function start line: 14; Function start address: 0x4004b0; Line: 15; Column: 18. .. option:: --version, -v. Print version information for the tool. .. option:: @<FILE>. Read command-line options from response file `<FILE>`. WINDOWS/PDB SPECIFIC OPTIONS; -----------------------------. .. option:: --dia. Use the Windows DIA SDK for symbolization. If the DIA SDK is not found,; llvm-symbolizer will fall back to the native implementation. MACH-O SPECIFIC OPTIONS; -----------------------. .. option:: --default-arch <arch>. If a binary contains object files for multiple architectures (e.g. it is a; Mach-O universal binary), symbolize the object file for a given architecture.; You can also specify the architecture by writing ``binary_name:arch_name`` in; the input (see example below). If the architecture is not specified in either; way, the address will not be symbolized. Defaults to empty string. .. code-block:: console. $ cat addr.txt; /tmp/mach_universal_binary:i386",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-symbolizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-tli-checker.rst:325,Availability,avail,availability,325,"llvm-tli-checker - TargetLibraryInfo vs library checker; =======================================================. .. program:: llvm-tli-checker. SYNOPSIS; --------. :program:`llvm-tli-checker` [*options*] [*library-file...*]. DESCRIPTION; -----------. :program:`llvm-tli-checker` compares TargetLibraryInfo's opinion of the; availability of library functions against the set of functions exported; by the specified library files, reporting any disagreements between TLI's; opinion and whether the function is actually present. This is primarily; useful for vendors to ensure the TLI for their target is correct, and; the compiler will not ""optimize"" some code sequence into a library call; that is not actually available. EXAMPLE; -------. .. code-block:: console. $ llvm-tli-checker --triple x86_64-scei-ps4 example.so; TLI knows 466 symbols, 235 available for 'x86_64-scei-ps4'. Looking for symbols in 'example.so'; Found 235 global function symbols in 'example.so'; Found a grand total of 235 library symbols; << TLI yes SDK no: '_ZdaPv' aka operator delete[](void*); >> TLI no SDK yes: '_ZdaPvj' aka operator delete[](void*, unsigned int); << Total TLI yes SDK no: 1; >> Total TLI no SDK yes: 1; == Total TLI yes SDK yes: 234; FAIL: LLVM TLI doesn't match SDK libraries. OPTIONS; -------. .. option:: --dump-tli. Print ""available""/""not available"" for each library function, according to; TargetLibraryInfo's information for the specified triple, and exit. This; option does not read any input files. .. option:: --help, -h. Print a summary of command line options and exit. .. option:: --libdir=<directory>. A base directory to prepend to each library file path. This is handy; when there are a number of library files all in the same directory, or; a list of input filenames are kept in a response file. .. option:: --report=<level>. The amount of information to report. <level> can be summary, discrepancy,; or full. A summary report gives only the count of matching and mis-matching; symbols; d",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-tli-checker.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-tli-checker.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-tli-checker.rst:711,Availability,avail,available,711,"llvm-tli-checker - TargetLibraryInfo vs library checker; =======================================================. .. program:: llvm-tli-checker. SYNOPSIS; --------. :program:`llvm-tli-checker` [*options*] [*library-file...*]. DESCRIPTION; -----------. :program:`llvm-tli-checker` compares TargetLibraryInfo's opinion of the; availability of library functions against the set of functions exported; by the specified library files, reporting any disagreements between TLI's; opinion and whether the function is actually present. This is primarily; useful for vendors to ensure the TLI for their target is correct, and; the compiler will not ""optimize"" some code sequence into a library call; that is not actually available. EXAMPLE; -------. .. code-block:: console. $ llvm-tli-checker --triple x86_64-scei-ps4 example.so; TLI knows 466 symbols, 235 available for 'x86_64-scei-ps4'. Looking for symbols in 'example.so'; Found 235 global function symbols in 'example.so'; Found a grand total of 235 library symbols; << TLI yes SDK no: '_ZdaPv' aka operator delete[](void*); >> TLI no SDK yes: '_ZdaPvj' aka operator delete[](void*, unsigned int); << Total TLI yes SDK no: 1; >> Total TLI no SDK yes: 1; == Total TLI yes SDK yes: 234; FAIL: LLVM TLI doesn't match SDK libraries. OPTIONS; -------. .. option:: --dump-tli. Print ""available""/""not available"" for each library function, according to; TargetLibraryInfo's information for the specified triple, and exit. This; option does not read any input files. .. option:: --help, -h. Print a summary of command line options and exit. .. option:: --libdir=<directory>. A base directory to prepend to each library file path. This is handy; when there are a number of library files all in the same directory, or; a list of input filenames are kept in a response file. .. option:: --report=<level>. The amount of information to report. <level> can be summary, discrepancy,; or full. A summary report gives only the count of matching and mis-matching; symbols; d",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-tli-checker.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-tli-checker.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-tli-checker.rst:848,Availability,avail,available,848,"llvm-tli-checker - TargetLibraryInfo vs library checker; =======================================================. .. program:: llvm-tli-checker. SYNOPSIS; --------. :program:`llvm-tli-checker` [*options*] [*library-file...*]. DESCRIPTION; -----------. :program:`llvm-tli-checker` compares TargetLibraryInfo's opinion of the; availability of library functions against the set of functions exported; by the specified library files, reporting any disagreements between TLI's; opinion and whether the function is actually present. This is primarily; useful for vendors to ensure the TLI for their target is correct, and; the compiler will not ""optimize"" some code sequence into a library call; that is not actually available. EXAMPLE; -------. .. code-block:: console. $ llvm-tli-checker --triple x86_64-scei-ps4 example.so; TLI knows 466 symbols, 235 available for 'x86_64-scei-ps4'. Looking for symbols in 'example.so'; Found 235 global function symbols in 'example.so'; Found a grand total of 235 library symbols; << TLI yes SDK no: '_ZdaPv' aka operator delete[](void*); >> TLI no SDK yes: '_ZdaPvj' aka operator delete[](void*, unsigned int); << Total TLI yes SDK no: 1; >> Total TLI no SDK yes: 1; == Total TLI yes SDK yes: 234; FAIL: LLVM TLI doesn't match SDK libraries. OPTIONS; -------. .. option:: --dump-tli. Print ""available""/""not available"" for each library function, according to; TargetLibraryInfo's information for the specified triple, and exit. This; option does not read any input files. .. option:: --help, -h. Print a summary of command line options and exit. .. option:: --libdir=<directory>. A base directory to prepend to each library file path. This is handy; when there are a number of library files all in the same directory, or; a list of input filenames are kept in a response file. .. option:: --report=<level>. The amount of information to report. <level> can be summary, discrepancy,; or full. A summary report gives only the count of matching and mis-matching; symbols; d",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-tli-checker.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-tli-checker.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-tli-checker.rst:1324,Availability,avail,available,1324," exported; by the specified library files, reporting any disagreements between TLI's; opinion and whether the function is actually present. This is primarily; useful for vendors to ensure the TLI for their target is correct, and; the compiler will not ""optimize"" some code sequence into a library call; that is not actually available. EXAMPLE; -------. .. code-block:: console. $ llvm-tli-checker --triple x86_64-scei-ps4 example.so; TLI knows 466 symbols, 235 available for 'x86_64-scei-ps4'. Looking for symbols in 'example.so'; Found 235 global function symbols in 'example.so'; Found a grand total of 235 library symbols; << TLI yes SDK no: '_ZdaPv' aka operator delete[](void*); >> TLI no SDK yes: '_ZdaPvj' aka operator delete[](void*, unsigned int); << Total TLI yes SDK no: 1; >> Total TLI no SDK yes: 1; == Total TLI yes SDK yes: 234; FAIL: LLVM TLI doesn't match SDK libraries. OPTIONS; -------. .. option:: --dump-tli. Print ""available""/""not available"" for each library function, according to; TargetLibraryInfo's information for the specified triple, and exit. This; option does not read any input files. .. option:: --help, -h. Print a summary of command line options and exit. .. option:: --libdir=<directory>. A base directory to prepend to each library file path. This is handy; when there are a number of library files all in the same directory, or; a list of input filenames are kept in a response file. .. option:: --report=<level>. The amount of information to report. <level> can be summary, discrepancy,; or full. A summary report gives only the count of matching and mis-matching; symbols; discrepancy lists the mis-matching symbols; and full lists all; symbols known to TLI, matching or mis-matching. The default is discrepancy. .. option:: --separate. Read and report a summary for each library file separately. This can be; useful to identify library files that don't contribute anything that TLI; knows about. Implies --report=summary (can be overridden). .. option:: --trip",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-tli-checker.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-tli-checker.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-tli-checker.rst:1340,Availability,avail,available,1340," exported; by the specified library files, reporting any disagreements between TLI's; opinion and whether the function is actually present. This is primarily; useful for vendors to ensure the TLI for their target is correct, and; the compiler will not ""optimize"" some code sequence into a library call; that is not actually available. EXAMPLE; -------. .. code-block:: console. $ llvm-tli-checker --triple x86_64-scei-ps4 example.so; TLI knows 466 symbols, 235 available for 'x86_64-scei-ps4'. Looking for symbols in 'example.so'; Found 235 global function symbols in 'example.so'; Found a grand total of 235 library symbols; << TLI yes SDK no: '_ZdaPv' aka operator delete[](void*); >> TLI no SDK yes: '_ZdaPvj' aka operator delete[](void*, unsigned int); << Total TLI yes SDK no: 1; >> Total TLI no SDK yes: 1; == Total TLI yes SDK yes: 234; FAIL: LLVM TLI doesn't match SDK libraries. OPTIONS; -------. .. option:: --dump-tli. Print ""available""/""not available"" for each library function, according to; TargetLibraryInfo's information for the specified triple, and exit. This; option does not read any input files. .. option:: --help, -h. Print a summary of command line options and exit. .. option:: --libdir=<directory>. A base directory to prepend to each library file path. This is handy; when there are a number of library files all in the same directory, or; a list of input filenames are kept in a response file. .. option:: --report=<level>. The amount of information to report. <level> can be summary, discrepancy,; or full. A summary report gives only the count of matching and mis-matching; symbols; discrepancy lists the mis-matching symbols; and full lists all; symbols known to TLI, matching or mis-matching. The default is discrepancy. .. option:: --separate. Read and report a summary for each library file separately. This can be; useful to identify library files that don't contribute anything that TLI; knows about. Implies --report=summary (can be overridden). .. option:: --trip",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-tli-checker.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-tli-checker.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-tli-checker.rst:640,Performance,optimiz,optimize,640,"llvm-tli-checker - TargetLibraryInfo vs library checker; =======================================================. .. program:: llvm-tli-checker. SYNOPSIS; --------. :program:`llvm-tli-checker` [*options*] [*library-file...*]. DESCRIPTION; -----------. :program:`llvm-tli-checker` compares TargetLibraryInfo's opinion of the; availability of library functions against the set of functions exported; by the specified library files, reporting any disagreements between TLI's; opinion and whether the function is actually present. This is primarily; useful for vendors to ensure the TLI for their target is correct, and; the compiler will not ""optimize"" some code sequence into a library call; that is not actually available. EXAMPLE; -------. .. code-block:: console. $ llvm-tli-checker --triple x86_64-scei-ps4 example.so; TLI knows 466 symbols, 235 available for 'x86_64-scei-ps4'. Looking for symbols in 'example.so'; Found 235 global function symbols in 'example.so'; Found a grand total of 235 library symbols; << TLI yes SDK no: '_ZdaPv' aka operator delete[](void*); >> TLI no SDK yes: '_ZdaPvj' aka operator delete[](void*, unsigned int); << Total TLI yes SDK no: 1; >> Total TLI no SDK yes: 1; == Total TLI yes SDK yes: 234; FAIL: LLVM TLI doesn't match SDK libraries. OPTIONS; -------. .. option:: --dump-tli. Print ""available""/""not available"" for each library function, according to; TargetLibraryInfo's information for the specified triple, and exit. This; option does not read any input files. .. option:: --help, -h. Print a summary of command line options and exit. .. option:: --libdir=<directory>. A base directory to prepend to each library file path. This is handy; when there are a number of library files all in the same directory, or; a list of input filenames are kept in a response file. .. option:: --report=<level>. The amount of information to report. <level> can be summary, discrepancy,; or full. A summary report gives only the count of matching and mis-matching; symbols; d",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/llvm-tli-checker.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/llvm-tli-checker.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst:366,Availability,avail,available,366,"opt - LLVM optimizer; ====================. .. program:: opt. SYNOPSIS; --------. :program:`opt` [*options*] [*filename*]. DESCRIPTION; -----------. The :program:`opt` command is the modular LLVM optimizer and analyzer. It takes; LLVM source files as input, runs the specified optimizations or analyses on it,; and then outputs the optimized file. The optimizations available via; :program:`opt` depend upon what libraries were linked into it as well as any; additional libraries that have been loaded with the :option:`-load` option. Use; the :option:`-help` option to determine what optimizations you can use. If ``filename`` is omitted from the command line or is ""``-``"", :program:`opt`; reads its input from standard input. Inputs can be in either the LLVM assembly; language format (``.ll``) or the LLVM bitcode format (``.bc``). If an output filename is not specified with the :option:`-o` option,; :program:`opt` writes its output to the standard output. OPTIONS; -------. .. option:: -f. Enable binary output on terminals. Normally, :program:`opt` will refuse to; write raw bitcode output if the output stream is a terminal. With this option,; :program:`opt` will write raw bitcode regardless of the output device. .. option:: -help. Print a summary of command line options. .. option:: -o <filename>. Specify the output filename. .. option:: -S. Write output in LLVM intermediate language (instead of bitcode). .. option:: -{passname}. :program:`opt` provides the ability to run any of LLVM's optimization or; analysis passes in any order. The :option:`-help` option lists all the passes; available. The order in which the options occur on the command line are the; order in which they are executed (within pass constraints). .. option:: -strip-debug. This option causes opt to strip debug information from the module before; applying other optimizations. It is essentially the same as `-strip`; but it ensures that stripping of debug information is done first. .. option:: -verify-each. Thi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst:1599,Availability,avail,available,1599," what optimizations you can use. If ``filename`` is omitted from the command line or is ""``-``"", :program:`opt`; reads its input from standard input. Inputs can be in either the LLVM assembly; language format (``.ll``) or the LLVM bitcode format (``.bc``). If an output filename is not specified with the :option:`-o` option,; :program:`opt` writes its output to the standard output. OPTIONS; -------. .. option:: -f. Enable binary output on terminals. Normally, :program:`opt` will refuse to; write raw bitcode output if the output stream is a terminal. With this option,; :program:`opt` will write raw bitcode regardless of the output device. .. option:: -help. Print a summary of command line options. .. option:: -o <filename>. Specify the output filename. .. option:: -S. Write output in LLVM intermediate language (instead of bitcode). .. option:: -{passname}. :program:`opt` provides the ability to run any of LLVM's optimization or; analysis passes in any order. The :option:`-help` option lists all the passes; available. The order in which the options occur on the command line are the; order in which they are executed (within pass constraints). .. option:: -strip-debug. This option causes opt to strip debug information from the module before; applying other optimizations. It is essentially the same as `-strip`; but it ensures that stripping of debug information is done first. .. option:: -verify-each. This option causes opt to add a verify pass after every pass otherwise; specified on the command line (including `-verify`). This is useful; for cases where it is suspected that a pass is creating an invalid module but; it is not clear which pass is doing it. .. option:: -stats. Print statistics. .. option:: -time-passes. Record the amount of time needed for each pass and print it to standard; error. .. option:: -debug. If this is a debug build, this option will enable debug printouts from passes; which use the ``LLVM_DEBUG()`` macro. See the `LLVM Programmer's Manual; <../P",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst:2395,Availability,error,error,2395,"f command line options. .. option:: -o <filename>. Specify the output filename. .. option:: -S. Write output in LLVM intermediate language (instead of bitcode). .. option:: -{passname}. :program:`opt` provides the ability to run any of LLVM's optimization or; analysis passes in any order. The :option:`-help` option lists all the passes; available. The order in which the options occur on the command line are the; order in which they are executed (within pass constraints). .. option:: -strip-debug. This option causes opt to strip debug information from the module before; applying other optimizations. It is essentially the same as `-strip`; but it ensures that stripping of debug information is done first. .. option:: -verify-each. This option causes opt to add a verify pass after every pass otherwise; specified on the command line (including `-verify`). This is useful; for cases where it is suspected that a pass is creating an invalid module but; it is not clear which pass is doing it. .. option:: -stats. Print statistics. .. option:: -time-passes. Record the amount of time needed for each pass and print it to standard; error. .. option:: -debug. If this is a debug build, this option will enable debug printouts from passes; which use the ``LLVM_DEBUG()`` macro. See the `LLVM Programmer's Manual; <../ProgrammersManual.html>`_, section ``#DEBUG`` for more information. .. option:: -load=<plugin>. Load the dynamic object ``plugin``. This object should register new; optimization or analysis passes. Once loaded, the object will add new command; line options to enable various optimizations or analyses. To see the new; complete list of optimizations, use the :option:`-help` and :option:`-load`; options together. For example:. .. code-block:: sh. opt -load=plugin.so -help. .. option:: -print-passes. Print all available passes and exit. EXIT STATUS; -----------. If :program:`opt` succeeds, it will exit with 0. Otherwise, if an error; occurs, it will exit with a non-zero value.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst:3089,Availability,avail,available,3089,"f command line options. .. option:: -o <filename>. Specify the output filename. .. option:: -S. Write output in LLVM intermediate language (instead of bitcode). .. option:: -{passname}. :program:`opt` provides the ability to run any of LLVM's optimization or; analysis passes in any order. The :option:`-help` option lists all the passes; available. The order in which the options occur on the command line are the; order in which they are executed (within pass constraints). .. option:: -strip-debug. This option causes opt to strip debug information from the module before; applying other optimizations. It is essentially the same as `-strip`; but it ensures that stripping of debug information is done first. .. option:: -verify-each. This option causes opt to add a verify pass after every pass otherwise; specified on the command line (including `-verify`). This is useful; for cases where it is suspected that a pass is creating an invalid module but; it is not clear which pass is doing it. .. option:: -stats. Print statistics. .. option:: -time-passes. Record the amount of time needed for each pass and print it to standard; error. .. option:: -debug. If this is a debug build, this option will enable debug printouts from passes; which use the ``LLVM_DEBUG()`` macro. See the `LLVM Programmer's Manual; <../ProgrammersManual.html>`_, section ``#DEBUG`` for more information. .. option:: -load=<plugin>. Load the dynamic object ``plugin``. This object should register new; optimization or analysis passes. Once loaded, the object will add new command; line options to enable various optimizations or analyses. To see the new; complete list of optimizations, use the :option:`-help` and :option:`-load`; options together. For example:. .. code-block:: sh. opt -load=plugin.so -help. .. option:: -print-passes. Print all available passes and exit. EXIT STATUS; -----------. If :program:`opt` succeeds, it will exit with 0. Otherwise, if an error; occurs, it will exit with a non-zero value.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst:3208,Availability,error,error,3208,"f command line options. .. option:: -o <filename>. Specify the output filename. .. option:: -S. Write output in LLVM intermediate language (instead of bitcode). .. option:: -{passname}. :program:`opt` provides the ability to run any of LLVM's optimization or; analysis passes in any order. The :option:`-help` option lists all the passes; available. The order in which the options occur on the command line are the; order in which they are executed (within pass constraints). .. option:: -strip-debug. This option causes opt to strip debug information from the module before; applying other optimizations. It is essentially the same as `-strip`; but it ensures that stripping of debug information is done first. .. option:: -verify-each. This option causes opt to add a verify pass after every pass otherwise; specified on the command line (including `-verify`). This is useful; for cases where it is suspected that a pass is creating an invalid module but; it is not clear which pass is doing it. .. option:: -stats. Print statistics. .. option:: -time-passes. Record the amount of time needed for each pass and print it to standard; error. .. option:: -debug. If this is a debug build, this option will enable debug printouts from passes; which use the ``LLVM_DEBUG()`` macro. See the `LLVM Programmer's Manual; <../ProgrammersManual.html>`_, section ``#DEBUG`` for more information. .. option:: -load=<plugin>. Load the dynamic object ``plugin``. This object should register new; optimization or analysis passes. Once loaded, the object will add new command; line options to enable various optimizations or analyses. To see the new; complete list of optimizations, use the :option:`-help` and :option:`-load`; options together. For example:. .. code-block:: sh. opt -load=plugin.so -help. .. option:: -print-passes. Print all available passes and exit. EXIT STATUS; -----------. If :program:`opt` succeeds, it will exit with 0. Otherwise, if an error; occurs, it will exit with a non-zero value.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst:396,Integrability,depend,depend,396,"opt - LLVM optimizer; ====================. .. program:: opt. SYNOPSIS; --------. :program:`opt` [*options*] [*filename*]. DESCRIPTION; -----------. The :program:`opt` command is the modular LLVM optimizer and analyzer. It takes; LLVM source files as input, runs the specified optimizations or analyses on it,; and then outputs the optimized file. The optimizations available via; :program:`opt` depend upon what libraries were linked into it as well as any; additional libraries that have been loaded with the :option:`-load` option. Use; the :option:`-help` option to determine what optimizations you can use. If ``filename`` is omitted from the command line or is ""``-``"", :program:`opt`; reads its input from standard input. Inputs can be in either the LLVM assembly; language format (``.ll``) or the LLVM bitcode format (``.bc``). If an output filename is not specified with the :option:`-o` option,; :program:`opt` writes its output to the standard output. OPTIONS; -------. .. option:: -f. Enable binary output on terminals. Normally, :program:`opt` will refuse to; write raw bitcode output if the output stream is a terminal. With this option,; :program:`opt` will write raw bitcode regardless of the output device. .. option:: -help. Print a summary of command line options. .. option:: -o <filename>. Specify the output filename. .. option:: -S. Write output in LLVM intermediate language (instead of bitcode). .. option:: -{passname}. :program:`opt` provides the ability to run any of LLVM's optimization or; analysis passes in any order. The :option:`-help` option lists all the passes; available. The order in which the options occur on the command line are the; order in which they are executed (within pass constraints). .. option:: -strip-debug. This option causes opt to strip debug information from the module before; applying other optimizations. It is essentially the same as `-strip`; but it ensures that stripping of debug information is done first. .. option:: -verify-each. Thi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst:2665,Modifiability,plugin,plugin,2665,"f command line options. .. option:: -o <filename>. Specify the output filename. .. option:: -S. Write output in LLVM intermediate language (instead of bitcode). .. option:: -{passname}. :program:`opt` provides the ability to run any of LLVM's optimization or; analysis passes in any order. The :option:`-help` option lists all the passes; available. The order in which the options occur on the command line are the; order in which they are executed (within pass constraints). .. option:: -strip-debug. This option causes opt to strip debug information from the module before; applying other optimizations. It is essentially the same as `-strip`; but it ensures that stripping of debug information is done first. .. option:: -verify-each. This option causes opt to add a verify pass after every pass otherwise; specified on the command line (including `-verify`). This is useful; for cases where it is suspected that a pass is creating an invalid module but; it is not clear which pass is doing it. .. option:: -stats. Print statistics. .. option:: -time-passes. Record the amount of time needed for each pass and print it to standard; error. .. option:: -debug. If this is a debug build, this option will enable debug printouts from passes; which use the ``LLVM_DEBUG()`` macro. See the `LLVM Programmer's Manual; <../ProgrammersManual.html>`_, section ``#DEBUG`` for more information. .. option:: -load=<plugin>. Load the dynamic object ``plugin``. This object should register new; optimization or analysis passes. Once loaded, the object will add new command; line options to enable various optimizations or analyses. To see the new; complete list of optimizations, use the :option:`-help` and :option:`-load`; options together. For example:. .. code-block:: sh. opt -load=plugin.so -help. .. option:: -print-passes. Print all available passes and exit. EXIT STATUS; -----------. If :program:`opt` succeeds, it will exit with 0. Otherwise, if an error; occurs, it will exit with a non-zero value.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst:2700,Modifiability,plugin,plugin,2700,"f command line options. .. option:: -o <filename>. Specify the output filename. .. option:: -S. Write output in LLVM intermediate language (instead of bitcode). .. option:: -{passname}. :program:`opt` provides the ability to run any of LLVM's optimization or; analysis passes in any order. The :option:`-help` option lists all the passes; available. The order in which the options occur on the command line are the; order in which they are executed (within pass constraints). .. option:: -strip-debug. This option causes opt to strip debug information from the module before; applying other optimizations. It is essentially the same as `-strip`; but it ensures that stripping of debug information is done first. .. option:: -verify-each. This option causes opt to add a verify pass after every pass otherwise; specified on the command line (including `-verify`). This is useful; for cases where it is suspected that a pass is creating an invalid module but; it is not clear which pass is doing it. .. option:: -stats. Print statistics. .. option:: -time-passes. Record the amount of time needed for each pass and print it to standard; error. .. option:: -debug. If this is a debug build, this option will enable debug printouts from passes; which use the ``LLVM_DEBUG()`` macro. See the `LLVM Programmer's Manual; <../ProgrammersManual.html>`_, section ``#DEBUG`` for more information. .. option:: -load=<plugin>. Load the dynamic object ``plugin``. This object should register new; optimization or analysis passes. Once loaded, the object will add new command; line options to enable various optimizations or analyses. To see the new; complete list of optimizations, use the :option:`-help` and :option:`-load`; options together. For example:. .. code-block:: sh. opt -load=plugin.so -help. .. option:: -print-passes. Print all available passes and exit. EXIT STATUS; -----------. If :program:`opt` succeeds, it will exit with 0. Otherwise, if an error; occurs, it will exit with a non-zero value.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst:3035,Modifiability,plugin,plugin,3035,"f command line options. .. option:: -o <filename>. Specify the output filename. .. option:: -S. Write output in LLVM intermediate language (instead of bitcode). .. option:: -{passname}. :program:`opt` provides the ability to run any of LLVM's optimization or; analysis passes in any order. The :option:`-help` option lists all the passes; available. The order in which the options occur on the command line are the; order in which they are executed (within pass constraints). .. option:: -strip-debug. This option causes opt to strip debug information from the module before; applying other optimizations. It is essentially the same as `-strip`; but it ensures that stripping of debug information is done first. .. option:: -verify-each. This option causes opt to add a verify pass after every pass otherwise; specified on the command line (including `-verify`). This is useful; for cases where it is suspected that a pass is creating an invalid module but; it is not clear which pass is doing it. .. option:: -stats. Print statistics. .. option:: -time-passes. Record the amount of time needed for each pass and print it to standard; error. .. option:: -debug. If this is a debug build, this option will enable debug printouts from passes; which use the ``LLVM_DEBUG()`` macro. See the `LLVM Programmer's Manual; <../ProgrammersManual.html>`_, section ``#DEBUG`` for more information. .. option:: -load=<plugin>. Load the dynamic object ``plugin``. This object should register new; optimization or analysis passes. Once loaded, the object will add new command; line options to enable various optimizations or analyses. To see the new; complete list of optimizations, use the :option:`-help` and :option:`-load`; options together. For example:. .. code-block:: sh. opt -load=plugin.so -help. .. option:: -print-passes. Print all available passes and exit. EXIT STATUS; -----------. If :program:`opt` succeeds, it will exit with 0. Otherwise, if an error; occurs, it will exit with a non-zero value.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst:11,Performance,optimiz,optimizer,11,"opt - LLVM optimizer; ====================. .. program:: opt. SYNOPSIS; --------. :program:`opt` [*options*] [*filename*]. DESCRIPTION; -----------. The :program:`opt` command is the modular LLVM optimizer and analyzer. It takes; LLVM source files as input, runs the specified optimizations or analyses on it,; and then outputs the optimized file. The optimizations available via; :program:`opt` depend upon what libraries were linked into it as well as any; additional libraries that have been loaded with the :option:`-load` option. Use; the :option:`-help` option to determine what optimizations you can use. If ``filename`` is omitted from the command line or is ""``-``"", :program:`opt`; reads its input from standard input. Inputs can be in either the LLVM assembly; language format (``.ll``) or the LLVM bitcode format (``.bc``). If an output filename is not specified with the :option:`-o` option,; :program:`opt` writes its output to the standard output. OPTIONS; -------. .. option:: -f. Enable binary output on terminals. Normally, :program:`opt` will refuse to; write raw bitcode output if the output stream is a terminal. With this option,; :program:`opt` will write raw bitcode regardless of the output device. .. option:: -help. Print a summary of command line options. .. option:: -o <filename>. Specify the output filename. .. option:: -S. Write output in LLVM intermediate language (instead of bitcode). .. option:: -{passname}. :program:`opt` provides the ability to run any of LLVM's optimization or; analysis passes in any order. The :option:`-help` option lists all the passes; available. The order in which the options occur on the command line are the; order in which they are executed (within pass constraints). .. option:: -strip-debug. This option causes opt to strip debug information from the module before; applying other optimizations. It is essentially the same as `-strip`; but it ensures that stripping of debug information is done first. .. option:: -verify-each. Thi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst:196,Performance,optimiz,optimizer,196,"opt - LLVM optimizer; ====================. .. program:: opt. SYNOPSIS; --------. :program:`opt` [*options*] [*filename*]. DESCRIPTION; -----------. The :program:`opt` command is the modular LLVM optimizer and analyzer. It takes; LLVM source files as input, runs the specified optimizations or analyses on it,; and then outputs the optimized file. The optimizations available via; :program:`opt` depend upon what libraries were linked into it as well as any; additional libraries that have been loaded with the :option:`-load` option. Use; the :option:`-help` option to determine what optimizations you can use. If ``filename`` is omitted from the command line or is ""``-``"", :program:`opt`; reads its input from standard input. Inputs can be in either the LLVM assembly; language format (``.ll``) or the LLVM bitcode format (``.bc``). If an output filename is not specified with the :option:`-o` option,; :program:`opt` writes its output to the standard output. OPTIONS; -------. .. option:: -f. Enable binary output on terminals. Normally, :program:`opt` will refuse to; write raw bitcode output if the output stream is a terminal. With this option,; :program:`opt` will write raw bitcode regardless of the output device. .. option:: -help. Print a summary of command line options. .. option:: -o <filename>. Specify the output filename. .. option:: -S. Write output in LLVM intermediate language (instead of bitcode). .. option:: -{passname}. :program:`opt` provides the ability to run any of LLVM's optimization or; analysis passes in any order. The :option:`-help` option lists all the passes; available. The order in which the options occur on the command line are the; order in which they are executed (within pass constraints). .. option:: -strip-debug. This option causes opt to strip debug information from the module before; applying other optimizations. It is essentially the same as `-strip`; but it ensures that stripping of debug information is done first. .. option:: -verify-each. Thi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst:277,Performance,optimiz,optimizations,277,"opt - LLVM optimizer; ====================. .. program:: opt. SYNOPSIS; --------. :program:`opt` [*options*] [*filename*]. DESCRIPTION; -----------. The :program:`opt` command is the modular LLVM optimizer and analyzer. It takes; LLVM source files as input, runs the specified optimizations or analyses on it,; and then outputs the optimized file. The optimizations available via; :program:`opt` depend upon what libraries were linked into it as well as any; additional libraries that have been loaded with the :option:`-load` option. Use; the :option:`-help` option to determine what optimizations you can use. If ``filename`` is omitted from the command line or is ""``-``"", :program:`opt`; reads its input from standard input. Inputs can be in either the LLVM assembly; language format (``.ll``) or the LLVM bitcode format (``.bc``). If an output filename is not specified with the :option:`-o` option,; :program:`opt` writes its output to the standard output. OPTIONS; -------. .. option:: -f. Enable binary output on terminals. Normally, :program:`opt` will refuse to; write raw bitcode output if the output stream is a terminal. With this option,; :program:`opt` will write raw bitcode regardless of the output device. .. option:: -help. Print a summary of command line options. .. option:: -o <filename>. Specify the output filename. .. option:: -S. Write output in LLVM intermediate language (instead of bitcode). .. option:: -{passname}. :program:`opt` provides the ability to run any of LLVM's optimization or; analysis passes in any order. The :option:`-help` option lists all the passes; available. The order in which the options occur on the command line are the; order in which they are executed (within pass constraints). .. option:: -strip-debug. This option causes opt to strip debug information from the module before; applying other optimizations. It is essentially the same as `-strip`; but it ensures that stripping of debug information is done first. .. option:: -verify-each. Thi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst:332,Performance,optimiz,optimized,332,"opt - LLVM optimizer; ====================. .. program:: opt. SYNOPSIS; --------. :program:`opt` [*options*] [*filename*]. DESCRIPTION; -----------. The :program:`opt` command is the modular LLVM optimizer and analyzer. It takes; LLVM source files as input, runs the specified optimizations or analyses on it,; and then outputs the optimized file. The optimizations available via; :program:`opt` depend upon what libraries were linked into it as well as any; additional libraries that have been loaded with the :option:`-load` option. Use; the :option:`-help` option to determine what optimizations you can use. If ``filename`` is omitted from the command line or is ""``-``"", :program:`opt`; reads its input from standard input. Inputs can be in either the LLVM assembly; language format (``.ll``) or the LLVM bitcode format (``.bc``). If an output filename is not specified with the :option:`-o` option,; :program:`opt` writes its output to the standard output. OPTIONS; -------. .. option:: -f. Enable binary output on terminals. Normally, :program:`opt` will refuse to; write raw bitcode output if the output stream is a terminal. With this option,; :program:`opt` will write raw bitcode regardless of the output device. .. option:: -help. Print a summary of command line options. .. option:: -o <filename>. Specify the output filename. .. option:: -S. Write output in LLVM intermediate language (instead of bitcode). .. option:: -{passname}. :program:`opt` provides the ability to run any of LLVM's optimization or; analysis passes in any order. The :option:`-help` option lists all the passes; available. The order in which the options occur on the command line are the; order in which they are executed (within pass constraints). .. option:: -strip-debug. This option causes opt to strip debug information from the module before; applying other optimizations. It is essentially the same as `-strip`; but it ensures that stripping of debug information is done first. .. option:: -verify-each. Thi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst:352,Performance,optimiz,optimizations,352,"opt - LLVM optimizer; ====================. .. program:: opt. SYNOPSIS; --------. :program:`opt` [*options*] [*filename*]. DESCRIPTION; -----------. The :program:`opt` command is the modular LLVM optimizer and analyzer. It takes; LLVM source files as input, runs the specified optimizations or analyses on it,; and then outputs the optimized file. The optimizations available via; :program:`opt` depend upon what libraries were linked into it as well as any; additional libraries that have been loaded with the :option:`-load` option. Use; the :option:`-help` option to determine what optimizations you can use. If ``filename`` is omitted from the command line or is ""``-``"", :program:`opt`; reads its input from standard input. Inputs can be in either the LLVM assembly; language format (``.ll``) or the LLVM bitcode format (``.bc``). If an output filename is not specified with the :option:`-o` option,; :program:`opt` writes its output to the standard output. OPTIONS; -------. .. option:: -f. Enable binary output on terminals. Normally, :program:`opt` will refuse to; write raw bitcode output if the output stream is a terminal. With this option,; :program:`opt` will write raw bitcode regardless of the output device. .. option:: -help. Print a summary of command line options. .. option:: -o <filename>. Specify the output filename. .. option:: -S. Write output in LLVM intermediate language (instead of bitcode). .. option:: -{passname}. :program:`opt` provides the ability to run any of LLVM's optimization or; analysis passes in any order. The :option:`-help` option lists all the passes; available. The order in which the options occur on the command line are the; order in which they are executed (within pass constraints). .. option:: -strip-debug. This option causes opt to strip debug information from the module before; applying other optimizations. It is essentially the same as `-strip`; but it ensures that stripping of debug information is done first. .. option:: -verify-each. Thi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst:495,Performance,load,loaded,495,"opt - LLVM optimizer; ====================. .. program:: opt. SYNOPSIS; --------. :program:`opt` [*options*] [*filename*]. DESCRIPTION; -----------. The :program:`opt` command is the modular LLVM optimizer and analyzer. It takes; LLVM source files as input, runs the specified optimizations or analyses on it,; and then outputs the optimized file. The optimizations available via; :program:`opt` depend upon what libraries were linked into it as well as any; additional libraries that have been loaded with the :option:`-load` option. Use; the :option:`-help` option to determine what optimizations you can use. If ``filename`` is omitted from the command line or is ""``-``"", :program:`opt`; reads its input from standard input. Inputs can be in either the LLVM assembly; language format (``.ll``) or the LLVM bitcode format (``.bc``). If an output filename is not specified with the :option:`-o` option,; :program:`opt` writes its output to the standard output. OPTIONS; -------. .. option:: -f. Enable binary output on terminals. Normally, :program:`opt` will refuse to; write raw bitcode output if the output stream is a terminal. With this option,; :program:`opt` will write raw bitcode regardless of the output device. .. option:: -help. Print a summary of command line options. .. option:: -o <filename>. Specify the output filename. .. option:: -S. Write output in LLVM intermediate language (instead of bitcode). .. option:: -{passname}. :program:`opt` provides the ability to run any of LLVM's optimization or; analysis passes in any order. The :option:`-help` option lists all the passes; available. The order in which the options occur on the command line are the; order in which they are executed (within pass constraints). .. option:: -strip-debug. This option causes opt to strip debug information from the module before; applying other optimizations. It is essentially the same as `-strip`; but it ensures that stripping of debug information is done first. .. option:: -verify-each. Thi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst:521,Performance,load,load,521,"opt - LLVM optimizer; ====================. .. program:: opt. SYNOPSIS; --------. :program:`opt` [*options*] [*filename*]. DESCRIPTION; -----------. The :program:`opt` command is the modular LLVM optimizer and analyzer. It takes; LLVM source files as input, runs the specified optimizations or analyses on it,; and then outputs the optimized file. The optimizations available via; :program:`opt` depend upon what libraries were linked into it as well as any; additional libraries that have been loaded with the :option:`-load` option. Use; the :option:`-help` option to determine what optimizations you can use. If ``filename`` is omitted from the command line or is ""``-``"", :program:`opt`; reads its input from standard input. Inputs can be in either the LLVM assembly; language format (``.ll``) or the LLVM bitcode format (``.bc``). If an output filename is not specified with the :option:`-o` option,; :program:`opt` writes its output to the standard output. OPTIONS; -------. .. option:: -f. Enable binary output on terminals. Normally, :program:`opt` will refuse to; write raw bitcode output if the output stream is a terminal. With this option,; :program:`opt` will write raw bitcode regardless of the output device. .. option:: -help. Print a summary of command line options. .. option:: -o <filename>. Specify the output filename. .. option:: -S. Write output in LLVM intermediate language (instead of bitcode). .. option:: -{passname}. :program:`opt` provides the ability to run any of LLVM's optimization or; analysis passes in any order. The :option:`-help` option lists all the passes; available. The order in which the options occur on the command line are the; order in which they are executed (within pass constraints). .. option:: -strip-debug. This option causes opt to strip debug information from the module before; applying other optimizations. It is essentially the same as `-strip`; but it ensures that stripping of debug information is done first. .. option:: -verify-each. Thi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst:585,Performance,optimiz,optimizations,585,"opt - LLVM optimizer; ====================. .. program:: opt. SYNOPSIS; --------. :program:`opt` [*options*] [*filename*]. DESCRIPTION; -----------. The :program:`opt` command is the modular LLVM optimizer and analyzer. It takes; LLVM source files as input, runs the specified optimizations or analyses on it,; and then outputs the optimized file. The optimizations available via; :program:`opt` depend upon what libraries were linked into it as well as any; additional libraries that have been loaded with the :option:`-load` option. Use; the :option:`-help` option to determine what optimizations you can use. If ``filename`` is omitted from the command line or is ""``-``"", :program:`opt`; reads its input from standard input. Inputs can be in either the LLVM assembly; language format (``.ll``) or the LLVM bitcode format (``.bc``). If an output filename is not specified with the :option:`-o` option,; :program:`opt` writes its output to the standard output. OPTIONS; -------. .. option:: -f. Enable binary output on terminals. Normally, :program:`opt` will refuse to; write raw bitcode output if the output stream is a terminal. With this option,; :program:`opt` will write raw bitcode regardless of the output device. .. option:: -help. Print a summary of command line options. .. option:: -o <filename>. Specify the output filename. .. option:: -S. Write output in LLVM intermediate language (instead of bitcode). .. option:: -{passname}. :program:`opt` provides the ability to run any of LLVM's optimization or; analysis passes in any order. The :option:`-help` option lists all the passes; available. The order in which the options occur on the command line are the; order in which they are executed (within pass constraints). .. option:: -strip-debug. This option causes opt to strip debug information from the module before; applying other optimizations. It is essentially the same as `-strip`; but it ensures that stripping of debug information is done first. .. option:: -verify-each. Thi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst:1503,Performance,optimiz,optimization,1503,"aded with the :option:`-load` option. Use; the :option:`-help` option to determine what optimizations you can use. If ``filename`` is omitted from the command line or is ""``-``"", :program:`opt`; reads its input from standard input. Inputs can be in either the LLVM assembly; language format (``.ll``) or the LLVM bitcode format (``.bc``). If an output filename is not specified with the :option:`-o` option,; :program:`opt` writes its output to the standard output. OPTIONS; -------. .. option:: -f. Enable binary output on terminals. Normally, :program:`opt` will refuse to; write raw bitcode output if the output stream is a terminal. With this option,; :program:`opt` will write raw bitcode regardless of the output device. .. option:: -help. Print a summary of command line options. .. option:: -o <filename>. Specify the output filename. .. option:: -S. Write output in LLVM intermediate language (instead of bitcode). .. option:: -{passname}. :program:`opt` provides the ability to run any of LLVM's optimization or; analysis passes in any order. The :option:`-help` option lists all the passes; available. The order in which the options occur on the command line are the; order in which they are executed (within pass constraints). .. option:: -strip-debug. This option causes opt to strip debug information from the module before; applying other optimizations. It is essentially the same as `-strip`; but it ensures that stripping of debug information is done first. .. option:: -verify-each. This option causes opt to add a verify pass after every pass otherwise; specified on the command line (including `-verify`). This is useful; for cases where it is suspected that a pass is creating an invalid module but; it is not clear which pass is doing it. .. option:: -stats. Print statistics. .. option:: -time-passes. Record the amount of time needed for each pass and print it to standard; error. .. option:: -debug. If this is a debug build, this option will enable debug printouts from pass",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst:1851,Performance,optimiz,optimizations,1851,"code format (``.bc``). If an output filename is not specified with the :option:`-o` option,; :program:`opt` writes its output to the standard output. OPTIONS; -------. .. option:: -f. Enable binary output on terminals. Normally, :program:`opt` will refuse to; write raw bitcode output if the output stream is a terminal. With this option,; :program:`opt` will write raw bitcode regardless of the output device. .. option:: -help. Print a summary of command line options. .. option:: -o <filename>. Specify the output filename. .. option:: -S. Write output in LLVM intermediate language (instead of bitcode). .. option:: -{passname}. :program:`opt` provides the ability to run any of LLVM's optimization or; analysis passes in any order. The :option:`-help` option lists all the passes; available. The order in which the options occur on the command line are the; order in which they are executed (within pass constraints). .. option:: -strip-debug. This option causes opt to strip debug information from the module before; applying other optimizations. It is essentially the same as `-strip`; but it ensures that stripping of debug information is done first. .. option:: -verify-each. This option causes opt to add a verify pass after every pass otherwise; specified on the command line (including `-verify`). This is useful; for cases where it is suspected that a pass is creating an invalid module but; it is not clear which pass is doing it. .. option:: -stats. Print statistics. .. option:: -time-passes. Record the amount of time needed for each pass and print it to standard; error. .. option:: -debug. If this is a debug build, this option will enable debug printouts from passes; which use the ``LLVM_DEBUG()`` macro. See the `LLVM Programmer's Manual; <../ProgrammersManual.html>`_, section ``#DEBUG`` for more information. .. option:: -load=<plugin>. Load the dynamic object ``plugin``. This object should register new; optimization or analysis passes. Once loaded, the object will add new ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst:2659,Performance,load,load,2659,"f command line options. .. option:: -o <filename>. Specify the output filename. .. option:: -S. Write output in LLVM intermediate language (instead of bitcode). .. option:: -{passname}. :program:`opt` provides the ability to run any of LLVM's optimization or; analysis passes in any order. The :option:`-help` option lists all the passes; available. The order in which the options occur on the command line are the; order in which they are executed (within pass constraints). .. option:: -strip-debug. This option causes opt to strip debug information from the module before; applying other optimizations. It is essentially the same as `-strip`; but it ensures that stripping of debug information is done first. .. option:: -verify-each. This option causes opt to add a verify pass after every pass otherwise; specified on the command line (including `-verify`). This is useful; for cases where it is suspected that a pass is creating an invalid module but; it is not clear which pass is doing it. .. option:: -stats. Print statistics. .. option:: -time-passes. Record the amount of time needed for each pass and print it to standard; error. .. option:: -debug. If this is a debug build, this option will enable debug printouts from passes; which use the ``LLVM_DEBUG()`` macro. See the `LLVM Programmer's Manual; <../ProgrammersManual.html>`_, section ``#DEBUG`` for more information. .. option:: -load=<plugin>. Load the dynamic object ``plugin``. This object should register new; optimization or analysis passes. Once loaded, the object will add new command; line options to enable various optimizations or analyses. To see the new; complete list of optimizations, use the :option:`-help` and :option:`-load`; options together. For example:. .. code-block:: sh. opt -load=plugin.so -help. .. option:: -print-passes. Print all available passes and exit. EXIT STATUS; -----------. If :program:`opt` succeeds, it will exit with 0. Otherwise, if an error; occurs, it will exit with a non-zero value.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst:2743,Performance,optimiz,optimization,2743,"f command line options. .. option:: -o <filename>. Specify the output filename. .. option:: -S. Write output in LLVM intermediate language (instead of bitcode). .. option:: -{passname}. :program:`opt` provides the ability to run any of LLVM's optimization or; analysis passes in any order. The :option:`-help` option lists all the passes; available. The order in which the options occur on the command line are the; order in which they are executed (within pass constraints). .. option:: -strip-debug. This option causes opt to strip debug information from the module before; applying other optimizations. It is essentially the same as `-strip`; but it ensures that stripping of debug information is done first. .. option:: -verify-each. This option causes opt to add a verify pass after every pass otherwise; specified on the command line (including `-verify`). This is useful; for cases where it is suspected that a pass is creating an invalid module but; it is not clear which pass is doing it. .. option:: -stats. Print statistics. .. option:: -time-passes. Record the amount of time needed for each pass and print it to standard; error. .. option:: -debug. If this is a debug build, this option will enable debug printouts from passes; which use the ``LLVM_DEBUG()`` macro. See the `LLVM Programmer's Manual; <../ProgrammersManual.html>`_, section ``#DEBUG`` for more information. .. option:: -load=<plugin>. Load the dynamic object ``plugin``. This object should register new; optimization or analysis passes. Once loaded, the object will add new command; line options to enable various optimizations or analyses. To see the new; complete list of optimizations, use the :option:`-help` and :option:`-load`; options together. For example:. .. code-block:: sh. opt -load=plugin.so -help. .. option:: -print-passes. Print all available passes and exit. EXIT STATUS; -----------. If :program:`opt` succeeds, it will exit with 0. Otherwise, if an error; occurs, it will exit with a non-zero value.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst:2781,Performance,load,loaded,2781,"f command line options. .. option:: -o <filename>. Specify the output filename. .. option:: -S. Write output in LLVM intermediate language (instead of bitcode). .. option:: -{passname}. :program:`opt` provides the ability to run any of LLVM's optimization or; analysis passes in any order. The :option:`-help` option lists all the passes; available. The order in which the options occur on the command line are the; order in which they are executed (within pass constraints). .. option:: -strip-debug. This option causes opt to strip debug information from the module before; applying other optimizations. It is essentially the same as `-strip`; but it ensures that stripping of debug information is done first. .. option:: -verify-each. This option causes opt to add a verify pass after every pass otherwise; specified on the command line (including `-verify`). This is useful; for cases where it is suspected that a pass is creating an invalid module but; it is not clear which pass is doing it. .. option:: -stats. Print statistics. .. option:: -time-passes. Record the amount of time needed for each pass and print it to standard; error. .. option:: -debug. If this is a debug build, this option will enable debug printouts from passes; which use the ``LLVM_DEBUG()`` macro. See the `LLVM Programmer's Manual; <../ProgrammersManual.html>`_, section ``#DEBUG`` for more information. .. option:: -load=<plugin>. Load the dynamic object ``plugin``. This object should register new; optimization or analysis passes. Once loaded, the object will add new command; line options to enable various optimizations or analyses. To see the new; complete list of optimizations, use the :option:`-help` and :option:`-load`; options together. For example:. .. code-block:: sh. opt -load=plugin.so -help. .. option:: -print-passes. Print all available passes and exit. EXIT STATUS; -----------. If :program:`opt` succeeds, it will exit with 0. Otherwise, if an error; occurs, it will exit with a non-zero value.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst:2853,Performance,optimiz,optimizations,2853,"f command line options. .. option:: -o <filename>. Specify the output filename. .. option:: -S. Write output in LLVM intermediate language (instead of bitcode). .. option:: -{passname}. :program:`opt` provides the ability to run any of LLVM's optimization or; analysis passes in any order. The :option:`-help` option lists all the passes; available. The order in which the options occur on the command line are the; order in which they are executed (within pass constraints). .. option:: -strip-debug. This option causes opt to strip debug information from the module before; applying other optimizations. It is essentially the same as `-strip`; but it ensures that stripping of debug information is done first. .. option:: -verify-each. This option causes opt to add a verify pass after every pass otherwise; specified on the command line (including `-verify`). This is useful; for cases where it is suspected that a pass is creating an invalid module but; it is not clear which pass is doing it. .. option:: -stats. Print statistics. .. option:: -time-passes. Record the amount of time needed for each pass and print it to standard; error. .. option:: -debug. If this is a debug build, this option will enable debug printouts from passes; which use the ``LLVM_DEBUG()`` macro. See the `LLVM Programmer's Manual; <../ProgrammersManual.html>`_, section ``#DEBUG`` for more information. .. option:: -load=<plugin>. Load the dynamic object ``plugin``. This object should register new; optimization or analysis passes. Once loaded, the object will add new command; line options to enable various optimizations or analyses. To see the new; complete list of optimizations, use the :option:`-help` and :option:`-load`; options together. For example:. .. code-block:: sh. opt -load=plugin.so -help. .. option:: -print-passes. Print all available passes and exit. EXIT STATUS; -----------. If :program:`opt` succeeds, it will exit with 0. Otherwise, if an error; occurs, it will exit with a non-zero value.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst:2913,Performance,optimiz,optimizations,2913,"f command line options. .. option:: -o <filename>. Specify the output filename. .. option:: -S. Write output in LLVM intermediate language (instead of bitcode). .. option:: -{passname}. :program:`opt` provides the ability to run any of LLVM's optimization or; analysis passes in any order. The :option:`-help` option lists all the passes; available. The order in which the options occur on the command line are the; order in which they are executed (within pass constraints). .. option:: -strip-debug. This option causes opt to strip debug information from the module before; applying other optimizations. It is essentially the same as `-strip`; but it ensures that stripping of debug information is done first. .. option:: -verify-each. This option causes opt to add a verify pass after every pass otherwise; specified on the command line (including `-verify`). This is useful; for cases where it is suspected that a pass is creating an invalid module but; it is not clear which pass is doing it. .. option:: -stats. Print statistics. .. option:: -time-passes. Record the amount of time needed for each pass and print it to standard; error. .. option:: -debug. If this is a debug build, this option will enable debug printouts from passes; which use the ``LLVM_DEBUG()`` macro. See the `LLVM Programmer's Manual; <../ProgrammersManual.html>`_, section ``#DEBUG`` for more information. .. option:: -load=<plugin>. Load the dynamic object ``plugin``. This object should register new; optimization or analysis passes. Once loaded, the object will add new command; line options to enable various optimizations or analyses. To see the new; complete list of optimizations, use the :option:`-help` and :option:`-load`; options together. For example:. .. code-block:: sh. opt -load=plugin.so -help. .. option:: -print-passes. Print all available passes and exit. EXIT STATUS; -----------. If :program:`opt` succeeds, it will exit with 0. Otherwise, if an error; occurs, it will exit with a non-zero value.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst:2966,Performance,load,load,2966,"f command line options. .. option:: -o <filename>. Specify the output filename. .. option:: -S. Write output in LLVM intermediate language (instead of bitcode). .. option:: -{passname}. :program:`opt` provides the ability to run any of LLVM's optimization or; analysis passes in any order. The :option:`-help` option lists all the passes; available. The order in which the options occur on the command line are the; order in which they are executed (within pass constraints). .. option:: -strip-debug. This option causes opt to strip debug information from the module before; applying other optimizations. It is essentially the same as `-strip`; but it ensures that stripping of debug information is done first. .. option:: -verify-each. This option causes opt to add a verify pass after every pass otherwise; specified on the command line (including `-verify`). This is useful; for cases where it is suspected that a pass is creating an invalid module but; it is not clear which pass is doing it. .. option:: -stats. Print statistics. .. option:: -time-passes. Record the amount of time needed for each pass and print it to standard; error. .. option:: -debug. If this is a debug build, this option will enable debug printouts from passes; which use the ``LLVM_DEBUG()`` macro. See the `LLVM Programmer's Manual; <../ProgrammersManual.html>`_, section ``#DEBUG`` for more information. .. option:: -load=<plugin>. Load the dynamic object ``plugin``. This object should register new; optimization or analysis passes. Once loaded, the object will add new command; line options to enable various optimizations or analyses. To see the new; complete list of optimizations, use the :option:`-help` and :option:`-load`; options together. For example:. .. code-block:: sh. opt -load=plugin.so -help. .. option:: -print-passes. Print all available passes and exit. EXIT STATUS; -----------. If :program:`opt` succeeds, it will exit with 0. Otherwise, if an error; occurs, it will exit with a non-zero value.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst:3030,Performance,load,load,3030,"f command line options. .. option:: -o <filename>. Specify the output filename. .. option:: -S. Write output in LLVM intermediate language (instead of bitcode). .. option:: -{passname}. :program:`opt` provides the ability to run any of LLVM's optimization or; analysis passes in any order. The :option:`-help` option lists all the passes; available. The order in which the options occur on the command line are the; order in which they are executed (within pass constraints). .. option:: -strip-debug. This option causes opt to strip debug information from the module before; applying other optimizations. It is essentially the same as `-strip`; but it ensures that stripping of debug information is done first. .. option:: -verify-each. This option causes opt to add a verify pass after every pass otherwise; specified on the command line (including `-verify`). This is useful; for cases where it is suspected that a pass is creating an invalid module but; it is not clear which pass is doing it. .. option:: -stats. Print statistics. .. option:: -time-passes. Record the amount of time needed for each pass and print it to standard; error. .. option:: -debug. If this is a debug build, this option will enable debug printouts from passes; which use the ``LLVM_DEBUG()`` macro. See the `LLVM Programmer's Manual; <../ProgrammersManual.html>`_, section ``#DEBUG`` for more information. .. option:: -load=<plugin>. Load the dynamic object ``plugin``. This object should register new; optimization or analysis passes. Once loaded, the object will add new command; line options to enable various optimizations or analyses. To see the new; complete list of optimizations, use the :option:`-help` and :option:`-load`; options together. For example:. .. code-block:: sh. opt -load=plugin.so -help. .. option:: -print-passes. Print all available passes and exit. EXIT STATUS; -----------. If :program:`opt` succeeds, it will exit with 0. Otherwise, if an error; occurs, it will exit with a non-zero value.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst:2228,Usability,clear,clear,2228,"e regardless of the output device. .. option:: -help. Print a summary of command line options. .. option:: -o <filename>. Specify the output filename. .. option:: -S. Write output in LLVM intermediate language (instead of bitcode). .. option:: -{passname}. :program:`opt` provides the ability to run any of LLVM's optimization or; analysis passes in any order. The :option:`-help` option lists all the passes; available. The order in which the options occur on the command line are the; order in which they are executed (within pass constraints). .. option:: -strip-debug. This option causes opt to strip debug information from the module before; applying other optimizations. It is essentially the same as `-strip`; but it ensures that stripping of debug information is done first. .. option:: -verify-each. This option causes opt to add a verify pass after every pass otherwise; specified on the command line (including `-verify`). This is useful; for cases where it is suspected that a pass is creating an invalid module but; it is not clear which pass is doing it. .. option:: -stats. Print statistics. .. option:: -time-passes. Record the amount of time needed for each pass and print it to standard; error. .. option:: -debug. If this is a debug build, this option will enable debug printouts from passes; which use the ``LLVM_DEBUG()`` macro. See the `LLVM Programmer's Manual; <../ProgrammersManual.html>`_, section ``#DEBUG`` for more information. .. option:: -load=<plugin>. Load the dynamic object ``plugin``. This object should register new; optimization or analysis passes. Once loaded, the object will add new command; line options to enable various optimizations or analyses. To see the new; complete list of optimizations, use the :option:`-help` and :option:`-load`; options together. For example:. .. code-block:: sh. opt -load=plugin.so -help. .. option:: -print-passes. Print all available passes and exit. EXIT STATUS; -----------. If :program:`opt` succeeds, it will exit with 0.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/opt.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst:12891,Availability,avail,avail-interface-decls,12891,"gisters and register classes info. .. option:: -register-info-debug. Make -gen-register-info dump register information for debugging. .. option:: -gen-searchable-tables. Generate generic searchable tables. See :doc:`TableGen BackEnds <../TableGen/BackEnds>`; for a detailed description. .. option:: -gen-subtarget. Generate subtarget enumerations. .. option:: -gen-x86-EVEX2VEX-tables. Generate X86 EVEX to VEX compress tables. .. option:: -gen-x86-fold-tables. Generate X86 fold tables. .. option:: -long-string-literals. When emitting large string tables, prefer string literals over; comma-separated char literals. This can be a readability and; compile-time performance win, but upsets some compilers. .. option:: -print-enums. Print enumeration values for a class. .. option:: -class=classname. Make -print-enums print the enumeration list for the specified class. .. option:: -print-sets. Print expanded sets for testing DAG exprs. mlir-tblgen Options; ~~~~~~~~~~~~~~~~~~~. .. option:: -gen-avail-interface-decls. Generate availability interface declarations. .. option:: -gen-avail-interface-defs. Generate op interface definitions. .. option:: -gen-dialect-doc. Generate dialect documentation. .. option:: -dialect. The dialect to generate. .. option:: -gen-directive-decl. Generate declarations for directives (OpenMP, etc.). .. option:: -gen-enum-decls. Generate enum utility declarations. .. option:: -gen-enum-defs. Generate enum utility definitions. .. option:: -gen-enum-from-llvmir-conversions. Generate conversions of EnumAttrs from LLVM IR. .. option:: -gen-enum-to-llvmir-conversions. Generate conversions of EnumAttrs to LLVM IR. .. option:: -gen-llvmir-conversions. Generate LLVM IR conversions. .. option:: -gen-llvmir-intrinsics. Generate LLVM IR intrinsics. .. option:: -llvmir-intrinsics-filter. Only keep the intrinsics with the specified substring in their record name. .. option:: -dialect-opclass-base. The base class for the ops in the dialect we are to emit. .. option:: ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst:12923,Availability,avail,availability,12923,"on:: -register-info-debug. Make -gen-register-info dump register information for debugging. .. option:: -gen-searchable-tables. Generate generic searchable tables. See :doc:`TableGen BackEnds <../TableGen/BackEnds>`; for a detailed description. .. option:: -gen-subtarget. Generate subtarget enumerations. .. option:: -gen-x86-EVEX2VEX-tables. Generate X86 EVEX to VEX compress tables. .. option:: -gen-x86-fold-tables. Generate X86 fold tables. .. option:: -long-string-literals. When emitting large string tables, prefer string literals over; comma-separated char literals. This can be a readability and; compile-time performance win, but upsets some compilers. .. option:: -print-enums. Print enumeration values for a class. .. option:: -class=classname. Make -print-enums print the enumeration list for the specified class. .. option:: -print-sets. Print expanded sets for testing DAG exprs. mlir-tblgen Options; ~~~~~~~~~~~~~~~~~~~. .. option:: -gen-avail-interface-decls. Generate availability interface declarations. .. option:: -gen-avail-interface-defs. Generate op interface definitions. .. option:: -gen-dialect-doc. Generate dialect documentation. .. option:: -dialect. The dialect to generate. .. option:: -gen-directive-decl. Generate declarations for directives (OpenMP, etc.). .. option:: -gen-enum-decls. Generate enum utility declarations. .. option:: -gen-enum-defs. Generate enum utility definitions. .. option:: -gen-enum-from-llvmir-conversions. Generate conversions of EnumAttrs from LLVM IR. .. option:: -gen-enum-to-llvmir-conversions. Generate conversions of EnumAttrs to LLVM IR. .. option:: -gen-llvmir-conversions. Generate LLVM IR conversions. .. option:: -gen-llvmir-intrinsics. Generate LLVM IR intrinsics. .. option:: -llvmir-intrinsics-filter. Only keep the intrinsics with the specified substring in their record name. .. option:: -dialect-opclass-base. The base class for the ops in the dialect we are to emit. .. option:: -gen-op-decls. Generate operation declara",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst:12977,Availability,avail,avail-interface-defs,12977,"r-info dump register information for debugging. .. option:: -gen-searchable-tables. Generate generic searchable tables. See :doc:`TableGen BackEnds <../TableGen/BackEnds>`; for a detailed description. .. option:: -gen-subtarget. Generate subtarget enumerations. .. option:: -gen-x86-EVEX2VEX-tables. Generate X86 EVEX to VEX compress tables. .. option:: -gen-x86-fold-tables. Generate X86 fold tables. .. option:: -long-string-literals. When emitting large string tables, prefer string literals over; comma-separated char literals. This can be a readability and; compile-time performance win, but upsets some compilers. .. option:: -print-enums. Print enumeration values for a class. .. option:: -class=classname. Make -print-enums print the enumeration list for the specified class. .. option:: -print-sets. Print expanded sets for testing DAG exprs. mlir-tblgen Options; ~~~~~~~~~~~~~~~~~~~. .. option:: -gen-avail-interface-decls. Generate availability interface declarations. .. option:: -gen-avail-interface-defs. Generate op interface definitions. .. option:: -gen-dialect-doc. Generate dialect documentation. .. option:: -dialect. The dialect to generate. .. option:: -gen-directive-decl. Generate declarations for directives (OpenMP, etc.). .. option:: -gen-enum-decls. Generate enum utility declarations. .. option:: -gen-enum-defs. Generate enum utility definitions. .. option:: -gen-enum-from-llvmir-conversions. Generate conversions of EnumAttrs from LLVM IR. .. option:: -gen-enum-to-llvmir-conversions. Generate conversions of EnumAttrs to LLVM IR. .. option:: -gen-llvmir-conversions. Generate LLVM IR conversions. .. option:: -gen-llvmir-intrinsics. Generate LLVM IR intrinsics. .. option:: -llvmir-intrinsics-filter. Only keep the intrinsics with the specified substring in their record name. .. option:: -dialect-opclass-base. The base class for the ops in the dialect we are to emit. .. option:: -gen-op-decls. Generate operation declarations. .. option:: -gen-op-defs. Generate op",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst:14024,Availability,error,error-is-fatal,14024,"definitions. .. option:: -gen-dialect-doc. Generate dialect documentation. .. option:: -dialect. The dialect to generate. .. option:: -gen-directive-decl. Generate declarations for directives (OpenMP, etc.). .. option:: -gen-enum-decls. Generate enum utility declarations. .. option:: -gen-enum-defs. Generate enum utility definitions. .. option:: -gen-enum-from-llvmir-conversions. Generate conversions of EnumAttrs from LLVM IR. .. option:: -gen-enum-to-llvmir-conversions. Generate conversions of EnumAttrs to LLVM IR. .. option:: -gen-llvmir-conversions. Generate LLVM IR conversions. .. option:: -gen-llvmir-intrinsics. Generate LLVM IR intrinsics. .. option:: -llvmir-intrinsics-filter. Only keep the intrinsics with the specified substring in their record name. .. option:: -dialect-opclass-base. The base class for the ops in the dialect we are to emit. .. option:: -gen-op-decls. Generate operation declarations. .. option:: -gen-op-defs. Generate operation definitions. .. option:: -asmformat-error-is-fatal. Emit a fatal error if format parsing fails. .. option:: -op-exclude-regex. Regular expression of name of ops to exclude (no filter if empty). .. option:: -op-include-regex. Regular expression of name of ops to include (no filter if empty). .. option:: -gen-op-doc. Generate operation documentation. .. option:: -gen-pass-decls. Generate operation documentation. .. option:: -name namestring. The name of this group of passes. .. option:: -gen-pass-doc. Generate pass documentation. .. option:: -gen-rewriters. Generate pattern rewriters. .. option:: -gen-spirv-avail-impls. Generate SPIR-V operation utility definitions. .. option:: -gen-spirv-capability-implication. Generate utility function to return implied capabilities for a given capability. .. option:: -gen-spirv-enum-avail-decls. Generate SPIR-V enum availability declarations. .. option:: -gen-spirv-enum-avail-defs. Generate SPIR-V enum availability definitions. .. option:: -gen-spirv-op-utils. Generate SPIR-V operati",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst:14053,Availability,error,error,14053,"c. Generate dialect documentation. .. option:: -dialect. The dialect to generate. .. option:: -gen-directive-decl. Generate declarations for directives (OpenMP, etc.). .. option:: -gen-enum-decls. Generate enum utility declarations. .. option:: -gen-enum-defs. Generate enum utility definitions. .. option:: -gen-enum-from-llvmir-conversions. Generate conversions of EnumAttrs from LLVM IR. .. option:: -gen-enum-to-llvmir-conversions. Generate conversions of EnumAttrs to LLVM IR. .. option:: -gen-llvmir-conversions. Generate LLVM IR conversions. .. option:: -gen-llvmir-intrinsics. Generate LLVM IR intrinsics. .. option:: -llvmir-intrinsics-filter. Only keep the intrinsics with the specified substring in their record name. .. option:: -dialect-opclass-base. The base class for the ops in the dialect we are to emit. .. option:: -gen-op-decls. Generate operation declarations. .. option:: -gen-op-defs. Generate operation definitions. .. option:: -asmformat-error-is-fatal. Emit a fatal error if format parsing fails. .. option:: -op-exclude-regex. Regular expression of name of ops to exclude (no filter if empty). .. option:: -op-include-regex. Regular expression of name of ops to include (no filter if empty). .. option:: -gen-op-doc. Generate operation documentation. .. option:: -gen-pass-decls. Generate operation documentation. .. option:: -name namestring. The name of this group of passes. .. option:: -gen-pass-doc. Generate pass documentation. .. option:: -gen-rewriters. Generate pattern rewriters. .. option:: -gen-spirv-avail-impls. Generate SPIR-V operation utility definitions. .. option:: -gen-spirv-capability-implication. Generate utility function to return implied capabilities for a given capability. .. option:: -gen-spirv-enum-avail-decls. Generate SPIR-V enum availability declarations. .. option:: -gen-spirv-enum-avail-defs. Generate SPIR-V enum availability definitions. .. option:: -gen-spirv-op-utils. Generate SPIR-V operation utility definitions. .. option:: -gen",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst:14601,Availability,avail,avail-impls,14601," conversions. .. option:: -gen-llvmir-intrinsics. Generate LLVM IR intrinsics. .. option:: -llvmir-intrinsics-filter. Only keep the intrinsics with the specified substring in their record name. .. option:: -dialect-opclass-base. The base class for the ops in the dialect we are to emit. .. option:: -gen-op-decls. Generate operation declarations. .. option:: -gen-op-defs. Generate operation definitions. .. option:: -asmformat-error-is-fatal. Emit a fatal error if format parsing fails. .. option:: -op-exclude-regex. Regular expression of name of ops to exclude (no filter if empty). .. option:: -op-include-regex. Regular expression of name of ops to include (no filter if empty). .. option:: -gen-op-doc. Generate operation documentation. .. option:: -gen-pass-decls. Generate operation documentation. .. option:: -name namestring. The name of this group of passes. .. option:: -gen-pass-doc. Generate pass documentation. .. option:: -gen-rewriters. Generate pattern rewriters. .. option:: -gen-spirv-avail-impls. Generate SPIR-V operation utility definitions. .. option:: -gen-spirv-capability-implication. Generate utility function to return implied capabilities for a given capability. .. option:: -gen-spirv-enum-avail-decls. Generate SPIR-V enum availability declarations. .. option:: -gen-spirv-enum-avail-defs. Generate SPIR-V enum availability definitions. .. option:: -gen-spirv-op-utils. Generate SPIR-V operation utility definitions. .. option:: -gen-spirv-serialization. Generate SPIR-V (de)serialization utilities and functions. .. option:: -gen-struct-attr-decls. Generate struct utility declarations. .. option:: -gen-struct-attr-defs. Generate struct utility definitions. .. option:: -gen-typedef-decls. Generate TypeDef declarations. .. option:: -gen-typedef-defs. Generate TypeDef definitions. .. option:: -typedefs-dialect name. Generate types for this dialect. EXIT STATUS; -----------. If :program:`*-tblgen` succeeds, it will exit with 0. Otherwise, if an error; occurs, it w",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst:14817,Availability,avail,avail-decls,14817,"mir-intrinsics. Generate LLVM IR intrinsics. .. option:: -llvmir-intrinsics-filter. Only keep the intrinsics with the specified substring in their record name. .. option:: -dialect-opclass-base. The base class for the ops in the dialect we are to emit. .. option:: -gen-op-decls. Generate operation declarations. .. option:: -gen-op-defs. Generate operation definitions. .. option:: -asmformat-error-is-fatal. Emit a fatal error if format parsing fails. .. option:: -op-exclude-regex. Regular expression of name of ops to exclude (no filter if empty). .. option:: -op-include-regex. Regular expression of name of ops to include (no filter if empty). .. option:: -gen-op-doc. Generate operation documentation. .. option:: -gen-pass-decls. Generate operation documentation. .. option:: -name namestring. The name of this group of passes. .. option:: -gen-pass-doc. Generate pass documentation. .. option:: -gen-rewriters. Generate pattern rewriters. .. option:: -gen-spirv-avail-impls. Generate SPIR-V operation utility definitions. .. option:: -gen-spirv-capability-implication. Generate utility function to return implied capabilities for a given capability. .. option:: -gen-spirv-enum-avail-decls. Generate SPIR-V enum availability declarations. .. option:: -gen-spirv-enum-avail-defs. Generate SPIR-V enum availability definitions. .. option:: -gen-spirv-op-utils. Generate SPIR-V operation utility definitions. .. option:: -gen-spirv-serialization. Generate SPIR-V (de)serialization utilities and functions. .. option:: -gen-struct-attr-decls. Generate struct utility declarations. .. option:: -gen-struct-attr-defs. Generate struct utility definitions. .. option:: -gen-typedef-decls. Generate TypeDef declarations. .. option:: -gen-typedef-defs. Generate TypeDef definitions. .. option:: -typedefs-dialect name. Generate types for this dialect. EXIT STATUS; -----------. If :program:`*-tblgen` succeeds, it will exit with 0. Otherwise, if an error; occurs, it will exit with a non-zero value.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst:14851,Availability,avail,availability,14851,"mir-intrinsics. Generate LLVM IR intrinsics. .. option:: -llvmir-intrinsics-filter. Only keep the intrinsics with the specified substring in their record name. .. option:: -dialect-opclass-base. The base class for the ops in the dialect we are to emit. .. option:: -gen-op-decls. Generate operation declarations. .. option:: -gen-op-defs. Generate operation definitions. .. option:: -asmformat-error-is-fatal. Emit a fatal error if format parsing fails. .. option:: -op-exclude-regex. Regular expression of name of ops to exclude (no filter if empty). .. option:: -op-include-regex. Regular expression of name of ops to include (no filter if empty). .. option:: -gen-op-doc. Generate operation documentation. .. option:: -gen-pass-decls. Generate operation documentation. .. option:: -name namestring. The name of this group of passes. .. option:: -gen-pass-doc. Generate pass documentation. .. option:: -gen-rewriters. Generate pattern rewriters. .. option:: -gen-spirv-avail-impls. Generate SPIR-V operation utility definitions. .. option:: -gen-spirv-capability-implication. Generate utility function to return implied capabilities for a given capability. .. option:: -gen-spirv-enum-avail-decls. Generate SPIR-V enum availability declarations. .. option:: -gen-spirv-enum-avail-defs. Generate SPIR-V enum availability definitions. .. option:: -gen-spirv-op-utils. Generate SPIR-V operation utility definitions. .. option:: -gen-spirv-serialization. Generate SPIR-V (de)serialization utilities and functions. .. option:: -gen-struct-attr-decls. Generate struct utility declarations. .. option:: -gen-struct-attr-defs. Generate struct utility definitions. .. option:: -gen-typedef-decls. Generate TypeDef declarations. .. option:: -gen-typedef-defs. Generate TypeDef definitions. .. option:: -typedefs-dialect name. Generate types for this dialect. EXIT STATUS; -----------. If :program:`*-tblgen` succeeds, it will exit with 0. Otherwise, if an error; occurs, it will exit with a non-zero value.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst:14906,Availability,avail,avail-defs,14906,"mir-intrinsics. Generate LLVM IR intrinsics. .. option:: -llvmir-intrinsics-filter. Only keep the intrinsics with the specified substring in their record name. .. option:: -dialect-opclass-base. The base class for the ops in the dialect we are to emit. .. option:: -gen-op-decls. Generate operation declarations. .. option:: -gen-op-defs. Generate operation definitions. .. option:: -asmformat-error-is-fatal. Emit a fatal error if format parsing fails. .. option:: -op-exclude-regex. Regular expression of name of ops to exclude (no filter if empty). .. option:: -op-include-regex. Regular expression of name of ops to include (no filter if empty). .. option:: -gen-op-doc. Generate operation documentation. .. option:: -gen-pass-decls. Generate operation documentation. .. option:: -name namestring. The name of this group of passes. .. option:: -gen-pass-doc. Generate pass documentation. .. option:: -gen-rewriters. Generate pattern rewriters. .. option:: -gen-spirv-avail-impls. Generate SPIR-V operation utility definitions. .. option:: -gen-spirv-capability-implication. Generate utility function to return implied capabilities for a given capability. .. option:: -gen-spirv-enum-avail-decls. Generate SPIR-V enum availability declarations. .. option:: -gen-spirv-enum-avail-defs. Generate SPIR-V enum availability definitions. .. option:: -gen-spirv-op-utils. Generate SPIR-V operation utility definitions. .. option:: -gen-spirv-serialization. Generate SPIR-V (de)serialization utilities and functions. .. option:: -gen-struct-attr-decls. Generate struct utility declarations. .. option:: -gen-struct-attr-defs. Generate struct utility definitions. .. option:: -gen-typedef-decls. Generate TypeDef declarations. .. option:: -gen-typedef-defs. Generate TypeDef definitions. .. option:: -typedefs-dialect name. Generate types for this dialect. EXIT STATUS; -----------. If :program:`*-tblgen` succeeds, it will exit with 0. Otherwise, if an error; occurs, it will exit with a non-zero value.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst:14939,Availability,avail,availability,14939,"mir-intrinsics. Generate LLVM IR intrinsics. .. option:: -llvmir-intrinsics-filter. Only keep the intrinsics with the specified substring in their record name. .. option:: -dialect-opclass-base. The base class for the ops in the dialect we are to emit. .. option:: -gen-op-decls. Generate operation declarations. .. option:: -gen-op-defs. Generate operation definitions. .. option:: -asmformat-error-is-fatal. Emit a fatal error if format parsing fails. .. option:: -op-exclude-regex. Regular expression of name of ops to exclude (no filter if empty). .. option:: -op-include-regex. Regular expression of name of ops to include (no filter if empty). .. option:: -gen-op-doc. Generate operation documentation. .. option:: -gen-pass-decls. Generate operation documentation. .. option:: -name namestring. The name of this group of passes. .. option:: -gen-pass-doc. Generate pass documentation. .. option:: -gen-rewriters. Generate pattern rewriters. .. option:: -gen-spirv-avail-impls. Generate SPIR-V operation utility definitions. .. option:: -gen-spirv-capability-implication. Generate utility function to return implied capabilities for a given capability. .. option:: -gen-spirv-enum-avail-decls. Generate SPIR-V enum availability declarations. .. option:: -gen-spirv-enum-avail-defs. Generate SPIR-V enum availability definitions. .. option:: -gen-spirv-op-utils. Generate SPIR-V operation utility definitions. .. option:: -gen-spirv-serialization. Generate SPIR-V (de)serialization utilities and functions. .. option:: -gen-struct-attr-decls. Generate struct utility declarations. .. option:: -gen-struct-attr-defs. Generate struct utility definitions. .. option:: -gen-typedef-decls. Generate TypeDef declarations. .. option:: -gen-typedef-defs. Generate TypeDef definitions. .. option:: -typedefs-dialect name. Generate types for this dialect. EXIT STATUS; -----------. If :program:`*-tblgen` succeeds, it will exit with 0. Otherwise, if an error; occurs, it will exit with a non-zero value.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst:15578,Availability,error,error,15578,"mir-intrinsics. Generate LLVM IR intrinsics. .. option:: -llvmir-intrinsics-filter. Only keep the intrinsics with the specified substring in their record name. .. option:: -dialect-opclass-base. The base class for the ops in the dialect we are to emit. .. option:: -gen-op-decls. Generate operation declarations. .. option:: -gen-op-defs. Generate operation definitions. .. option:: -asmformat-error-is-fatal. Emit a fatal error if format parsing fails. .. option:: -op-exclude-regex. Regular expression of name of ops to exclude (no filter if empty). .. option:: -op-include-regex. Regular expression of name of ops to include (no filter if empty). .. option:: -gen-op-doc. Generate operation documentation. .. option:: -gen-pass-decls. Generate operation documentation. .. option:: -name namestring. The name of this group of passes. .. option:: -gen-pass-doc. Generate pass documentation. .. option:: -gen-rewriters. Generate pattern rewriters. .. option:: -gen-spirv-avail-impls. Generate SPIR-V operation utility definitions. .. option:: -gen-spirv-capability-implication. Generate utility function to return implied capabilities for a given capability. .. option:: -gen-spirv-enum-avail-decls. Generate SPIR-V enum availability declarations. .. option:: -gen-spirv-enum-avail-defs. Generate SPIR-V enum availability definitions. .. option:: -gen-spirv-op-utils. Generate SPIR-V operation utility definitions. .. option:: -gen-spirv-serialization. Generate SPIR-V (de)serialization utilities and functions. .. option:: -gen-struct-attr-decls. Generate struct utility declarations. .. option:: -gen-struct-attr-defs. Generate struct utility definitions. .. option:: -gen-typedef-decls. Generate TypeDef declarations. .. option:: -gen-typedef-defs. Generate TypeDef definitions. .. option:: -typedefs-dialect name. Generate types for this dialect. EXIT STATUS; -----------. If :program:`*-tblgen` succeeds, it will exit with 0. Otherwise, if an error; occurs, it will exit with a non-zero value.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst:5238,Energy Efficiency,efficient,efficient,5238,gs from specified component. .. option:: -gen-clang-diag-groups. Generate Clang diagnostic groups. .. option:: -gen-clang-diags-index-name. Generate Clang diagnostic name index. .. option:: -gen-clang-basic-reader. Generate Clang BasicReader classes. .. option:: -gen-clang-basic-writer. Generate Clang BasicWriter classes. .. option:: -gen-clang-comment-nodes. Generate Clang AST comment nodes. .. option:: -gen-clang-decl-nodes. Generate Clang AST declaration nodes. .. option:: -gen-clang-stmt-nodes. Generate Clang AST statement nodes. .. option:: -gen-clang-type-nodes. Generate Clang AST type nodes. .. option:: -gen-clang-type-reader. Generate Clang AbstractTypeReader class. .. option:: -gen-clang-type-writer. Generate Clang AbstractTypeWriter class. .. option:: -gen-clang-opcodes. Generate Clang constexpr interpreter opcodes. .. option:: -gen-clang-sa-checkers. Generate Clang static analyzer checkers. .. option:: -gen-clang-comment-html-tags. Generate efficient matchers for HTML tag names that are used in; documentation comments. .. option:: -gen-clang-comment-html-tags-properties. Generate efficient matchers for HTML tag properties. .. option:: -gen-clang-comment-html-named-character-references. Generate function to translate named character references to UTF-8 sequences. .. option:: -gen-clang-comment-command-info. Generate command properties for commands that are used in documentation comments. .. option:: -gen-clang-comment-command-list. Generate list of commands that are used in documentation comments. .. option:: -gen-clang-opencl-builtins. Generate OpenCL builtin declaration handlers. .. option:: -gen-arm-neon. Generate ``arm_neon.h`` for Clang. .. option:: -gen-arm-fp16. Generate ``arm_fp16.h`` for Clang. .. option:: -gen-arm-bf16. Generate ``arm_bf16.h`` for Clang. .. option:: -gen-arm-neon-sema. Generate ARM NEON sema support for Clang. .. option:: -gen-arm-neon-test. Generate ARM NEON tests for Clang. .. option:: -gen-arm-sve-header. Generate ``arm_sve.h``,MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst:5380,Energy Efficiency,efficient,efficient,5380,ags-index-name. Generate Clang diagnostic name index. .. option:: -gen-clang-basic-reader. Generate Clang BasicReader classes. .. option:: -gen-clang-basic-writer. Generate Clang BasicWriter classes. .. option:: -gen-clang-comment-nodes. Generate Clang AST comment nodes. .. option:: -gen-clang-decl-nodes. Generate Clang AST declaration nodes. .. option:: -gen-clang-stmt-nodes. Generate Clang AST statement nodes. .. option:: -gen-clang-type-nodes. Generate Clang AST type nodes. .. option:: -gen-clang-type-reader. Generate Clang AbstractTypeReader class. .. option:: -gen-clang-type-writer. Generate Clang AbstractTypeWriter class. .. option:: -gen-clang-opcodes. Generate Clang constexpr interpreter opcodes. .. option:: -gen-clang-sa-checkers. Generate Clang static analyzer checkers. .. option:: -gen-clang-comment-html-tags. Generate efficient matchers for HTML tag names that are used in; documentation comments. .. option:: -gen-clang-comment-html-tags-properties. Generate efficient matchers for HTML tag properties. .. option:: -gen-clang-comment-html-named-character-references. Generate function to translate named character references to UTF-8 sequences. .. option:: -gen-clang-comment-command-info. Generate command properties for commands that are used in documentation comments. .. option:: -gen-clang-comment-command-list. Generate list of commands that are used in documentation comments. .. option:: -gen-clang-opencl-builtins. Generate OpenCL builtin declaration handlers. .. option:: -gen-arm-neon. Generate ``arm_neon.h`` for Clang. .. option:: -gen-arm-fp16. Generate ``arm_fp16.h`` for Clang. .. option:: -gen-arm-bf16. Generate ``arm_bf16.h`` for Clang. .. option:: -gen-arm-neon-sema. Generate ARM NEON sema support for Clang. .. option:: -gen-arm-neon-test. Generate ARM NEON tests for Clang. .. option:: -gen-arm-sve-header. Generate ``arm_sve.h`` for Clang. .. option:: -gen-arm-sve-builtins. Generate ``arm_sve_builtins.inc`` for Clang. .. option:: -gen-arm-sve-builtin,MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst:1366,Integrability,depend,dependency,1366," of programs that translates target; description (``.td``) files into C++ code and other output formats. Most; users of LLVM will not need to use this program. It is used only for; writing parts of the compiler, debugger, and LLVM target backends. The details of the input and output of the :program:`*-tblgen` programs is; beyond the scope of this short introduction; please see the :doc:`TableGen; Overview <../TableGen/index>` for an introduction and for references to; additional TableGen documents. The *filename* argument specifies the name of the Target Description (``.td``); file that TableGen processes. OPTIONS; -------. General Options; ~~~~~~~~~~~~~~~. .. option:: -help. Print a description of the command line options. .. option:: -help-list. Print a description of the command line options in a simple list format. .. option:: -D=macroname. Specify the name of a macro to be defined. The name is defined, but it; has no particular value. .. option:: -d=filename. Specify the name of the dependency filename. .. option:: -debug. Enable debug output. .. option:: -dump-json. Print a JSON representation of all records, suitable for further; automated processing. .. option:: -I directory. Specify where to find other target description files for inclusion. The; ``directory`` value should be a full or partial path to a directory that; contains target description files. .. option:: -null-backend. Parse the source files and build the records, but do not run any; backend. This is useful for timing the frontend. .. option:: -o filename. Specify the output file name. If ``filename`` is ``-``, then; :program:`*-tblgen` sends its output to standard output. .. option:: -print-records. Print all classes and records to standard output (default backend option). .. option:: -print-detailed-records. Print a detailed report of all global variables, classes, and records; to standard output. .. option:: -stats. Print a report with any statistics collected by the backend. .. option:: -time-",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst:12897,Integrability,interface,interface-decls,12897,"gisters and register classes info. .. option:: -register-info-debug. Make -gen-register-info dump register information for debugging. .. option:: -gen-searchable-tables. Generate generic searchable tables. See :doc:`TableGen BackEnds <../TableGen/BackEnds>`; for a detailed description. .. option:: -gen-subtarget. Generate subtarget enumerations. .. option:: -gen-x86-EVEX2VEX-tables. Generate X86 EVEX to VEX compress tables. .. option:: -gen-x86-fold-tables. Generate X86 fold tables. .. option:: -long-string-literals. When emitting large string tables, prefer string literals over; comma-separated char literals. This can be a readability and; compile-time performance win, but upsets some compilers. .. option:: -print-enums. Print enumeration values for a class. .. option:: -class=classname. Make -print-enums print the enumeration list for the specified class. .. option:: -print-sets. Print expanded sets for testing DAG exprs. mlir-tblgen Options; ~~~~~~~~~~~~~~~~~~~. .. option:: -gen-avail-interface-decls. Generate availability interface declarations. .. option:: -gen-avail-interface-defs. Generate op interface definitions. .. option:: -gen-dialect-doc. Generate dialect documentation. .. option:: -dialect. The dialect to generate. .. option:: -gen-directive-decl. Generate declarations for directives (OpenMP, etc.). .. option:: -gen-enum-decls. Generate enum utility declarations. .. option:: -gen-enum-defs. Generate enum utility definitions. .. option:: -gen-enum-from-llvmir-conversions. Generate conversions of EnumAttrs from LLVM IR. .. option:: -gen-enum-to-llvmir-conversions. Generate conversions of EnumAttrs to LLVM IR. .. option:: -gen-llvmir-conversions. Generate LLVM IR conversions. .. option:: -gen-llvmir-intrinsics. Generate LLVM IR intrinsics. .. option:: -llvmir-intrinsics-filter. Only keep the intrinsics with the specified substring in their record name. .. option:: -dialect-opclass-base. The base class for the ops in the dialect we are to emit. .. option:: ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst:12936,Integrability,interface,interface,12936,"on:: -register-info-debug. Make -gen-register-info dump register information for debugging. .. option:: -gen-searchable-tables. Generate generic searchable tables. See :doc:`TableGen BackEnds <../TableGen/BackEnds>`; for a detailed description. .. option:: -gen-subtarget. Generate subtarget enumerations. .. option:: -gen-x86-EVEX2VEX-tables. Generate X86 EVEX to VEX compress tables. .. option:: -gen-x86-fold-tables. Generate X86 fold tables. .. option:: -long-string-literals. When emitting large string tables, prefer string literals over; comma-separated char literals. This can be a readability and; compile-time performance win, but upsets some compilers. .. option:: -print-enums. Print enumeration values for a class. .. option:: -class=classname. Make -print-enums print the enumeration list for the specified class. .. option:: -print-sets. Print expanded sets for testing DAG exprs. mlir-tblgen Options; ~~~~~~~~~~~~~~~~~~~. .. option:: -gen-avail-interface-decls. Generate availability interface declarations. .. option:: -gen-avail-interface-defs. Generate op interface definitions. .. option:: -gen-dialect-doc. Generate dialect documentation. .. option:: -dialect. The dialect to generate. .. option:: -gen-directive-decl. Generate declarations for directives (OpenMP, etc.). .. option:: -gen-enum-decls. Generate enum utility declarations. .. option:: -gen-enum-defs. Generate enum utility definitions. .. option:: -gen-enum-from-llvmir-conversions. Generate conversions of EnumAttrs from LLVM IR. .. option:: -gen-enum-to-llvmir-conversions. Generate conversions of EnumAttrs to LLVM IR. .. option:: -gen-llvmir-conversions. Generate LLVM IR conversions. .. option:: -gen-llvmir-intrinsics. Generate LLVM IR intrinsics. .. option:: -llvmir-intrinsics-filter. Only keep the intrinsics with the specified substring in their record name. .. option:: -dialect-opclass-base. The base class for the ops in the dialect we are to emit. .. option:: -gen-op-decls. Generate operation declara",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst:12983,Integrability,interface,interface-defs,12983,"r-info dump register information for debugging. .. option:: -gen-searchable-tables. Generate generic searchable tables. See :doc:`TableGen BackEnds <../TableGen/BackEnds>`; for a detailed description. .. option:: -gen-subtarget. Generate subtarget enumerations. .. option:: -gen-x86-EVEX2VEX-tables. Generate X86 EVEX to VEX compress tables. .. option:: -gen-x86-fold-tables. Generate X86 fold tables. .. option:: -long-string-literals. When emitting large string tables, prefer string literals over; comma-separated char literals. This can be a readability and; compile-time performance win, but upsets some compilers. .. option:: -print-enums. Print enumeration values for a class. .. option:: -class=classname. Make -print-enums print the enumeration list for the specified class. .. option:: -print-sets. Print expanded sets for testing DAG exprs. mlir-tblgen Options; ~~~~~~~~~~~~~~~~~~~. .. option:: -gen-avail-interface-decls. Generate availability interface declarations. .. option:: -gen-avail-interface-defs. Generate op interface definitions. .. option:: -gen-dialect-doc. Generate dialect documentation. .. option:: -dialect. The dialect to generate. .. option:: -gen-directive-decl. Generate declarations for directives (OpenMP, etc.). .. option:: -gen-enum-decls. Generate enum utility declarations. .. option:: -gen-enum-defs. Generate enum utility definitions. .. option:: -gen-enum-from-llvmir-conversions. Generate conversions of EnumAttrs from LLVM IR. .. option:: -gen-enum-to-llvmir-conversions. Generate conversions of EnumAttrs to LLVM IR. .. option:: -gen-llvmir-conversions. Generate LLVM IR conversions. .. option:: -gen-llvmir-intrinsics. Generate LLVM IR intrinsics. .. option:: -llvmir-intrinsics-filter. Only keep the intrinsics with the specified substring in their record name. .. option:: -dialect-opclass-base. The base class for the ops in the dialect we are to emit. .. option:: -gen-op-decls. Generate operation declarations. .. option:: -gen-op-defs. Generate op",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst:13011,Integrability,interface,interface,13011,"r debugging. .. option:: -gen-searchable-tables. Generate generic searchable tables. See :doc:`TableGen BackEnds <../TableGen/BackEnds>`; for a detailed description. .. option:: -gen-subtarget. Generate subtarget enumerations. .. option:: -gen-x86-EVEX2VEX-tables. Generate X86 EVEX to VEX compress tables. .. option:: -gen-x86-fold-tables. Generate X86 fold tables. .. option:: -long-string-literals. When emitting large string tables, prefer string literals over; comma-separated char literals. This can be a readability and; compile-time performance win, but upsets some compilers. .. option:: -print-enums. Print enumeration values for a class. .. option:: -class=classname. Make -print-enums print the enumeration list for the specified class. .. option:: -print-sets. Print expanded sets for testing DAG exprs. mlir-tblgen Options; ~~~~~~~~~~~~~~~~~~~. .. option:: -gen-avail-interface-decls. Generate availability interface declarations. .. option:: -gen-avail-interface-defs. Generate op interface definitions. .. option:: -gen-dialect-doc. Generate dialect documentation. .. option:: -dialect. The dialect to generate. .. option:: -gen-directive-decl. Generate declarations for directives (OpenMP, etc.). .. option:: -gen-enum-decls. Generate enum utility declarations. .. option:: -gen-enum-defs. Generate enum utility definitions. .. option:: -gen-enum-from-llvmir-conversions. Generate conversions of EnumAttrs from LLVM IR. .. option:: -gen-enum-to-llvmir-conversions. Generate conversions of EnumAttrs to LLVM IR. .. option:: -gen-llvmir-conversions. Generate LLVM IR conversions. .. option:: -gen-llvmir-intrinsics. Generate LLVM IR intrinsics. .. option:: -llvmir-intrinsics-filter. Only keep the intrinsics with the specified substring in their record name. .. option:: -dialect-opclass-base. The base class for the ops in the dialect we are to emit. .. option:: -gen-op-decls. Generate operation declarations. .. option:: -gen-op-defs. Generate operation definitions. .. option:: -as",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst:2212,Modifiability,variab,variables,2212,". Specify the name of a macro to be defined. The name is defined, but it; has no particular value. .. option:: -d=filename. Specify the name of the dependency filename. .. option:: -debug. Enable debug output. .. option:: -dump-json. Print a JSON representation of all records, suitable for further; automated processing. .. option:: -I directory. Specify where to find other target description files for inclusion. The; ``directory`` value should be a full or partial path to a directory that; contains target description files. .. option:: -null-backend. Parse the source files and build the records, but do not run any; backend. This is useful for timing the frontend. .. option:: -o filename. Specify the output file name. If ``filename`` is ``-``, then; :program:`*-tblgen` sends its output to standard output. .. option:: -print-records. Print all classes and records to standard output (default backend option). .. option:: -print-detailed-records. Print a detailed report of all global variables, classes, and records; to standard output. .. option:: -stats. Print a report with any statistics collected by the backend. .. option:: -time-phases. Time the parser and backend phases and print a report. .. option:: -version. Show the version number of the program. .. option:: -write-if-changed. Write the output file only if it is new or has changed. clang-tblgen Options; ~~~~~~~~~~~~~~~~~~~~. .. option:: -gen-clang-attr-classes. Generate Clang attribute classes. .. option:: -gen-clang-attr-parser-string-switches. Generate all parser-related attribute string switches. .. option:: -gen-clang-attr-subject-match-rules-parser-string-switches. Generate all parser-related attribute subject match rule string switches. .. option:: -gen-clang-attr-impl. Generate Clang attribute implementations. .. option:: -gen-clang-attr-list"". Generate a Clang attribute list. .. option:: -gen-clang-attr-subject-match-rule-list. Generate a Clang attribute subject match rule list. .. option:: -gen-clang-att",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst:14539,Modifiability,rewrite,rewriters,14539,VM IR. .. option:: -gen-llvmir-conversions. Generate LLVM IR conversions. .. option:: -gen-llvmir-intrinsics. Generate LLVM IR intrinsics. .. option:: -llvmir-intrinsics-filter. Only keep the intrinsics with the specified substring in their record name. .. option:: -dialect-opclass-base. The base class for the ops in the dialect we are to emit. .. option:: -gen-op-decls. Generate operation declarations. .. option:: -gen-op-defs. Generate operation definitions. .. option:: -asmformat-error-is-fatal. Emit a fatal error if format parsing fails. .. option:: -op-exclude-regex. Regular expression of name of ops to exclude (no filter if empty). .. option:: -op-include-regex. Regular expression of name of ops to include (no filter if empty). .. option:: -gen-op-doc. Generate operation documentation. .. option:: -gen-pass-decls. Generate operation documentation. .. option:: -name namestring. The name of this group of passes. .. option:: -gen-pass-doc. Generate pass documentation. .. option:: -gen-rewriters. Generate pattern rewriters. .. option:: -gen-spirv-avail-impls. Generate SPIR-V operation utility definitions. .. option:: -gen-spirv-capability-implication. Generate utility function to return implied capabilities for a given capability. .. option:: -gen-spirv-enum-avail-decls. Generate SPIR-V enum availability declarations. .. option:: -gen-spirv-enum-avail-defs. Generate SPIR-V enum availability definitions. .. option:: -gen-spirv-op-utils. Generate SPIR-V operation utility definitions. .. option:: -gen-spirv-serialization. Generate SPIR-V (de)serialization utilities and functions. .. option:: -gen-struct-attr-decls. Generate struct utility declarations. .. option:: -gen-struct-attr-defs. Generate struct utility definitions. .. option:: -gen-typedef-decls. Generate TypeDef declarations. .. option:: -gen-typedef-defs. Generate TypeDef definitions. .. option:: -typedefs-dialect name. Generate types for this dialect. EXIT STATUS; -----------. If :program:`*-tblgen` succeed,MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst:14567,Modifiability,rewrite,rewriters,14567,"mir-conversions. Generate LLVM IR conversions. .. option:: -gen-llvmir-intrinsics. Generate LLVM IR intrinsics. .. option:: -llvmir-intrinsics-filter. Only keep the intrinsics with the specified substring in their record name. .. option:: -dialect-opclass-base. The base class for the ops in the dialect we are to emit. .. option:: -gen-op-decls. Generate operation declarations. .. option:: -gen-op-defs. Generate operation definitions. .. option:: -asmformat-error-is-fatal. Emit a fatal error if format parsing fails. .. option:: -op-exclude-regex. Regular expression of name of ops to exclude (no filter if empty). .. option:: -op-include-regex. Regular expression of name of ops to include (no filter if empty). .. option:: -gen-op-doc. Generate operation documentation. .. option:: -gen-pass-decls. Generate operation documentation. .. option:: -name namestring. The name of this group of passes. .. option:: -gen-pass-doc. Generate pass documentation. .. option:: -gen-rewriters. Generate pattern rewriters. .. option:: -gen-spirv-avail-impls. Generate SPIR-V operation utility definitions. .. option:: -gen-spirv-capability-implication. Generate utility function to return implied capabilities for a given capability. .. option:: -gen-spirv-enum-avail-decls. Generate SPIR-V enum availability declarations. .. option:: -gen-spirv-enum-avail-defs. Generate SPIR-V enum availability definitions. .. option:: -gen-spirv-op-utils. Generate SPIR-V operation utility definitions. .. option:: -gen-spirv-serialization. Generate SPIR-V (de)serialization utilities and functions. .. option:: -gen-struct-attr-decls. Generate struct utility declarations. .. option:: -gen-struct-attr-defs. Generate struct utility definitions. .. option:: -gen-typedef-decls. Generate TypeDef declarations. .. option:: -gen-typedef-defs. Generate TypeDef definitions. .. option:: -typedefs-dialect name. Generate types for this dialect. EXIT STATUS; -----------. If :program:`*-tblgen` succeeds, it will exit with 0. Ot",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst:10627,Performance,optimiz,optimize-match-table,10627,"n-dag-isel generate tables to help identify the patterns matched. .. option:: -omit-comments. Make -gen-dag-isel omit comments. The default is false. .. option:: -gen-dfa-packetizer. Generate DFA Packetizer for VLIW targets. .. option:: -gen-directive-decl. Generate directive related declaration code (header file). .. option:: -gen-directive-gen. Generate directive related implementation code part. .. option:: -gen-directive-impl. Generate directive related implementation code. .. option:: -gen-disassembler. Generate disassembler. .. option:: -gen-emitter. Generate machine code emitter. .. option:: -gen-exegesis. Generate llvm-exegesis tables. .. option:: -gen-fast-isel. Generate a ""fast"" instruction selector. .. option:: -gen-global-isel. Generate GlobalISel selector. .. option:: -gisel-coverage-file=filename. Specify the file from which to retrieve coverage information. .. option:: -instrument-gisel-coverage. Make -gen-global-isel generate coverage instrumentation. .. option:: -optimize-match-table. Make -gen-global-isel generate an optimized version of the match table. .. option:: -warn-on-skipped-patterns. Make -gen-global-isel explain why a pattern was skipped for inclusion. .. option:: -gen-global-isel-combiner. Generate GlobalISel combiner. .. option:: -combiners=list. Make -gen-global-isel-combiner emit the specified combiners. .. option:: -gicombiner-debug-cxxpreds. Add debug comments to all C++ predicates emitted by -gen-global-isel-combiner. .. option:: -gicombiner-stop-after-parse. Make -gen-global-isel-combiner stop processing after parsing rules and dump state. .. option:: -gen-instr-info. Generate instruction descriptions. .. option:: -gen-instr-docs. Generate instruction documentation. .. option:: -gen-intrinsic-enums. Generate intrinsic enums. .. option:: -intrinsic-prefix=prefix. Make -gen-intrinsic-enums generate intrinsics with this target *prefix*. .. option:: -gen-intrinsic-impl. Generate intrinsic information. .. option:: -gen-opt-parser-defs.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst:10683,Performance,optimiz,optimized,10683,"erns matched. .. option:: -omit-comments. Make -gen-dag-isel omit comments. The default is false. .. option:: -gen-dfa-packetizer. Generate DFA Packetizer for VLIW targets. .. option:: -gen-directive-decl. Generate directive related declaration code (header file). .. option:: -gen-directive-gen. Generate directive related implementation code part. .. option:: -gen-directive-impl. Generate directive related implementation code. .. option:: -gen-disassembler. Generate disassembler. .. option:: -gen-emitter. Generate machine code emitter. .. option:: -gen-exegesis. Generate llvm-exegesis tables. .. option:: -gen-fast-isel. Generate a ""fast"" instruction selector. .. option:: -gen-global-isel. Generate GlobalISel selector. .. option:: -gisel-coverage-file=filename. Specify the file from which to retrieve coverage information. .. option:: -instrument-gisel-coverage. Make -gen-global-isel generate coverage instrumentation. .. option:: -optimize-match-table. Make -gen-global-isel generate an optimized version of the match table. .. option:: -warn-on-skipped-patterns. Make -gen-global-isel explain why a pattern was skipped for inclusion. .. option:: -gen-global-isel-combiner. Generate GlobalISel combiner. .. option:: -combiners=list. Make -gen-global-isel-combiner emit the specified combiners. .. option:: -gicombiner-debug-cxxpreds. Add debug comments to all C++ predicates emitted by -gen-global-isel-combiner. .. option:: -gicombiner-stop-after-parse. Make -gen-global-isel-combiner stop processing after parsing rules and dump state. .. option:: -gen-instr-info. Generate instruction descriptions. .. option:: -gen-instr-docs. Generate instruction documentation. .. option:: -gen-intrinsic-enums. Generate intrinsic enums. .. option:: -intrinsic-prefix=prefix. Make -gen-intrinsic-enums generate intrinsics with this target *prefix*. .. option:: -gen-intrinsic-impl. Generate intrinsic information. .. option:: -gen-opt-parser-defs. Generate options definitions. .. option:: -gen-opt-",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst:12556,Performance,perform,performance,12556,"insic-impl. Generate intrinsic information. .. option:: -gen-opt-parser-defs. Generate options definitions. .. option:: -gen-opt-rst. Generate option RST. .. option:: -gen-pseudo-lowering. Generate pseudo instruction lowering. .. option:: -gen-register-bank. Generate register bank descriptions. .. option:: -gen-register-info. Generate registers and register classes info. .. option:: -register-info-debug. Make -gen-register-info dump register information for debugging. .. option:: -gen-searchable-tables. Generate generic searchable tables. See :doc:`TableGen BackEnds <../TableGen/BackEnds>`; for a detailed description. .. option:: -gen-subtarget. Generate subtarget enumerations. .. option:: -gen-x86-EVEX2VEX-tables. Generate X86 EVEX to VEX compress tables. .. option:: -gen-x86-fold-tables. Generate X86 fold tables. .. option:: -long-string-literals. When emitting large string tables, prefer string literals over; comma-separated char literals. This can be a readability and; compile-time performance win, but upsets some compilers. .. option:: -print-enums. Print enumeration values for a class. .. option:: -class=classname. Make -print-enums print the enumeration list for the specified class. .. option:: -print-sets. Print expanded sets for testing DAG exprs. mlir-tblgen Options; ~~~~~~~~~~~~~~~~~~~. .. option:: -gen-avail-interface-decls. Generate availability interface declarations. .. option:: -gen-avail-interface-defs. Generate op interface definitions. .. option:: -gen-dialect-doc. Generate dialect documentation. .. option:: -dialect. The dialect to generate. .. option:: -gen-directive-decl. Generate declarations for directives (OpenMP, etc.). .. option:: -gen-enum-decls. Generate enum utility declarations. .. option:: -gen-enum-defs. Generate enum utility definitions. .. option:: -gen-enum-from-llvmir-conversions. Generate conversions of EnumAttrs from LLVM IR. .. option:: -gen-enum-to-llvmir-conversions. Generate conversions of EnumAttrs to LLVM IR. .. option:: ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst:6177,Testability,test,test,6177, analyzer checkers. .. option:: -gen-clang-comment-html-tags. Generate efficient matchers for HTML tag names that are used in; documentation comments. .. option:: -gen-clang-comment-html-tags-properties. Generate efficient matchers for HTML tag properties. .. option:: -gen-clang-comment-html-named-character-references. Generate function to translate named character references to UTF-8 sequences. .. option:: -gen-clang-comment-command-info. Generate command properties for commands that are used in documentation comments. .. option:: -gen-clang-comment-command-list. Generate list of commands that are used in documentation comments. .. option:: -gen-clang-opencl-builtins. Generate OpenCL builtin declaration handlers. .. option:: -gen-arm-neon. Generate ``arm_neon.h`` for Clang. .. option:: -gen-arm-fp16. Generate ``arm_fp16.h`` for Clang. .. option:: -gen-arm-bf16. Generate ``arm_bf16.h`` for Clang. .. option:: -gen-arm-neon-sema. Generate ARM NEON sema support for Clang. .. option:: -gen-arm-neon-test. Generate ARM NEON tests for Clang. .. option:: -gen-arm-sve-header. Generate ``arm_sve.h`` for Clang. .. option:: -gen-arm-sve-builtins. Generate ``arm_sve_builtins.inc`` for Clang. .. option:: -gen-arm-sve-builtin-codegen. Generate ``arm_sve_builtin_cg_map.inc`` for Clang. .. option:: -gen-arm-sve-typeflags. Generate ``arm_sve_typeflags.inc`` for Clang. .. option:: -gen-arm-sve-sema-rangechecks. Generate ``arm_sve_sema_rangechecks.inc`` for Clang. .. option:: -gen-arm-mve-header. Generate ``arm_mve.h`` for Clang. .. option:: -gen-arm-mve-builtin-def. Generate ARM MVE builtin definitions for Clang. .. option:: -gen-arm-mve-builtin-sema. Generate ARM MVE builtin sema checks for Clang. .. option:: -gen-arm-mve-builtin-codegen. Generate ARM MVE builtin code-generator for Clang. .. option:: -gen-arm-mve-builtin-aliases. Generate list of valid ARM MVE builtin aliases for Clang. .. option:: -gen-arm-cde-header. Generate ``arm_cde.h`` for Clang. .. option:: -gen-arm-cde-builtin,MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst:6201,Testability,test,tests,6201,-gen-clang-comment-html-tags. Generate efficient matchers for HTML tag names that are used in; documentation comments. .. option:: -gen-clang-comment-html-tags-properties. Generate efficient matchers for HTML tag properties. .. option:: -gen-clang-comment-html-named-character-references. Generate function to translate named character references to UTF-8 sequences. .. option:: -gen-clang-comment-command-info. Generate command properties for commands that are used in documentation comments. .. option:: -gen-clang-comment-command-list. Generate list of commands that are used in documentation comments. .. option:: -gen-clang-opencl-builtins. Generate OpenCL builtin declaration handlers. .. option:: -gen-arm-neon. Generate ``arm_neon.h`` for Clang. .. option:: -gen-arm-fp16. Generate ``arm_fp16.h`` for Clang. .. option:: -gen-arm-bf16. Generate ``arm_bf16.h`` for Clang. .. option:: -gen-arm-neon-sema. Generate ARM NEON sema support for Clang. .. option:: -gen-arm-neon-test. Generate ARM NEON tests for Clang. .. option:: -gen-arm-sve-header. Generate ``arm_sve.h`` for Clang. .. option:: -gen-arm-sve-builtins. Generate ``arm_sve_builtins.inc`` for Clang. .. option:: -gen-arm-sve-builtin-codegen. Generate ``arm_sve_builtin_cg_map.inc`` for Clang. .. option:: -gen-arm-sve-typeflags. Generate ``arm_sve_typeflags.inc`` for Clang. .. option:: -gen-arm-sve-sema-rangechecks. Generate ``arm_sve_sema_rangechecks.inc`` for Clang. .. option:: -gen-arm-mve-header. Generate ``arm_mve.h`` for Clang. .. option:: -gen-arm-mve-builtin-def. Generate ARM MVE builtin definitions for Clang. .. option:: -gen-arm-mve-builtin-sema. Generate ARM MVE builtin sema checks for Clang. .. option:: -gen-arm-mve-builtin-codegen. Generate ARM MVE builtin code-generator for Clang. .. option:: -gen-arm-mve-builtin-aliases. Generate list of valid ARM MVE builtin aliases for Clang. .. option:: -gen-arm-cde-header. Generate ``arm_cde.h`` for Clang. .. option:: -gen-arm-cde-builtin-def. Generate ARM CDE builtin d,MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst:8271,Testability,test,test-pragma-attribute-supported-attributes,8271,tin sema checks for Clang. .. option:: -gen-arm-cde-builtin-codegen. Generate ARM CDE builtin code-generator for Clang. .. option:: -gen-arm-cde-builtin-aliases. Generate list of valid ARM CDE builtin aliases for Clang. .. option:: -gen-riscv-vector-header. Generate ``riscv_vector.h`` for Clang. .. option:: -gen-riscv-vector-builtins. Generate ``riscv_vector_builtins.inc`` for Clang. .. option:: -gen-riscv-vector-builtin-codegen. Generate ``riscv_vector_builtin_cg.inc`` for Clang. .. option:: -gen-riscv-sifive-vector-builtins. Generate ``riscv_sifive_vector_builtins.inc`` for Clang. .. option:: -gen-riscv-sifive-vector-builtin-codegen. Generate ``riscv_sifive_vector_builtin_cg.inc`` for Clang. .. option:: -gen-attr-docs. Generate attribute documentation. .. option:: -gen-diag-docs. Generate diagnostic documentation. .. option:: -gen-opt-docs. Generate option documentation. .. option:: -gen-clang-data-collectors. Generate data collectors for AST nodes. .. option:: -gen-clang-test-pragma-attribute-supported-attributes. Generate a list of attributes supported by ``#pragma`` Clang attribute for; testing purposes. lldb-tblgen Options; ~~~~~~~~~~~~~~~~~~~. .. option:: gen-lldb-option-defs. Generate lldb OptionDefinition values. .. option:: gen-lldb-property-defs. Generate lldb PropertyDefinition values. .. option:: gen-lldb-property-enum-defs. Generate lldb PropertyDefinition enum values. llvm-tblgen Options; ~~~~~~~~~~~~~~~~~~~. .. option:: -gen-asm-matcher. Generate assembly instruction matcher. .. option:: -match-prefix=prefix. Make -gen-asm-matcher match only instructions with the given *prefix*. .. option:: -gen-asm-parser. Generate assembly instruction parser. .. option:: -asmparsernum=n. Make -gen-asm-parser emit assembly parser number *n*. .. option:: -gen-asm-writer. Generate assembly writer. .. option:: -asmwriternum=n. Make -gen-asm-writer emit assembly writer number *n*. .. option:: -gen-attrs. Generate attributes. .. option:: -gen-automata. Generate generic a,MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst:8391,Testability,test,testing,8391,RM CDE builtin code-generator for Clang. .. option:: -gen-arm-cde-builtin-aliases. Generate list of valid ARM CDE builtin aliases for Clang. .. option:: -gen-riscv-vector-header. Generate ``riscv_vector.h`` for Clang. .. option:: -gen-riscv-vector-builtins. Generate ``riscv_vector_builtins.inc`` for Clang. .. option:: -gen-riscv-vector-builtin-codegen. Generate ``riscv_vector_builtin_cg.inc`` for Clang. .. option:: -gen-riscv-sifive-vector-builtins. Generate ``riscv_sifive_vector_builtins.inc`` for Clang. .. option:: -gen-riscv-sifive-vector-builtin-codegen. Generate ``riscv_sifive_vector_builtin_cg.inc`` for Clang. .. option:: -gen-attr-docs. Generate attribute documentation. .. option:: -gen-diag-docs. Generate diagnostic documentation. .. option:: -gen-opt-docs. Generate option documentation. .. option:: -gen-clang-data-collectors. Generate data collectors for AST nodes. .. option:: -gen-clang-test-pragma-attribute-supported-attributes. Generate a list of attributes supported by ``#pragma`` Clang attribute for; testing purposes. lldb-tblgen Options; ~~~~~~~~~~~~~~~~~~~. .. option:: gen-lldb-option-defs. Generate lldb OptionDefinition values. .. option:: gen-lldb-property-defs. Generate lldb PropertyDefinition values. .. option:: gen-lldb-property-enum-defs. Generate lldb PropertyDefinition enum values. llvm-tblgen Options; ~~~~~~~~~~~~~~~~~~~. .. option:: -gen-asm-matcher. Generate assembly instruction matcher. .. option:: -match-prefix=prefix. Make -gen-asm-matcher match only instructions with the given *prefix*. .. option:: -gen-asm-parser. Generate assembly instruction parser. .. option:: -asmparsernum=n. Make -gen-asm-parser emit assembly parser number *n*. .. option:: -gen-asm-writer. Generate assembly writer. .. option:: -asmwriternum=n. Make -gen-asm-writer emit assembly writer number *n*. .. option:: -gen-attrs. Generate attributes. .. option:: -gen-automata. Generate generic automata. .. option:: -gen-callingconv. Generate calling convention descriptions,MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst:12813,Testability,test,testing,12813,"ank. Generate register bank descriptions. .. option:: -gen-register-info. Generate registers and register classes info. .. option:: -register-info-debug. Make -gen-register-info dump register information for debugging. .. option:: -gen-searchable-tables. Generate generic searchable tables. See :doc:`TableGen BackEnds <../TableGen/BackEnds>`; for a detailed description. .. option:: -gen-subtarget. Generate subtarget enumerations. .. option:: -gen-x86-EVEX2VEX-tables. Generate X86 EVEX to VEX compress tables. .. option:: -gen-x86-fold-tables. Generate X86 fold tables. .. option:: -long-string-literals. When emitting large string tables, prefer string literals over; comma-separated char literals. This can be a readability and; compile-time performance win, but upsets some compilers. .. option:: -print-enums. Print enumeration values for a class. .. option:: -class=classname. Make -print-enums print the enumeration list for the specified class. .. option:: -print-sets. Print expanded sets for testing DAG exprs. mlir-tblgen Options; ~~~~~~~~~~~~~~~~~~~. .. option:: -gen-avail-interface-decls. Generate availability interface declarations. .. option:: -gen-avail-interface-defs. Generate op interface definitions. .. option:: -gen-dialect-doc. Generate dialect documentation. .. option:: -dialect. The dialect to generate. .. option:: -gen-directive-decl. Generate declarations for directives (OpenMP, etc.). .. option:: -gen-enum-decls. Generate enum utility declarations. .. option:: -gen-enum-defs. Generate enum utility definitions. .. option:: -gen-enum-from-llvmir-conversions. Generate conversions of EnumAttrs from LLVM IR. .. option:: -gen-enum-to-llvmir-conversions. Generate conversions of EnumAttrs to LLVM IR. .. option:: -gen-llvmir-conversions. Generate LLVM IR conversions. .. option:: -gen-llvmir-intrinsics. Generate LLVM IR intrinsics. .. option:: -llvmir-intrinsics-filter. Only keep the intrinsics with the specified substring in their record name. .. option:: -dialect",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst:1174,Usability,simpl,simple,1174,"]. :program:`lldb-tblgen` [*options*] [*filename*]. :program:`llvm-tblgen` [*options*] [*filename*]. :program:`mlir-tblgen` [*options*] [*filename*]. DESCRIPTION; -----------. :program:`*-tblgen` is a family of programs that translates target; description (``.td``) files into C++ code and other output formats. Most; users of LLVM will not need to use this program. It is used only for; writing parts of the compiler, debugger, and LLVM target backends. The details of the input and output of the :program:`*-tblgen` programs is; beyond the scope of this short introduction; please see the :doc:`TableGen; Overview <../TableGen/index>` for an introduction and for references to; additional TableGen documents. The *filename* argument specifies the name of the Target Description (``.td``); file that TableGen processes. OPTIONS; -------. General Options; ~~~~~~~~~~~~~~~. .. option:: -help. Print a description of the command line options. .. option:: -help-list. Print a description of the command line options in a simple list format. .. option:: -D=macroname. Specify the name of a macro to be defined. The name is defined, but it; has no particular value. .. option:: -d=filename. Specify the name of the dependency filename. .. option:: -debug. Enable debug output. .. option:: -dump-json. Print a JSON representation of all records, suitable for further; automated processing. .. option:: -I directory. Specify where to find other target description files for inclusion. The; ``directory`` value should be a full or partial path to a directory that; contains target description files. .. option:: -null-backend. Parse the source files and build the records, but do not run any; backend. This is useful for timing the frontend. .. option:: -o filename. Specify the output file name. If ``filename`` is ``-``, then; :program:`*-tblgen` sends its output to standard output. .. option:: -print-records. Print all classes and records to standard output (default backend option). .. option:: -print-d",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/CommandGuide/tblgen.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst:4660,Availability,toler,tolerable,4660,"e; provided in the ``DependenceGraphBuilder`` class, while the ``DDGBuilder``; and ``PDGBuilder`` control some aspects of how the graph is constructed; by the way of overriding virtual methods defined in ``DependenceGraphBuilder``. Note also that the steps and the names used in this diagram are for; illustrative purposes and may be different from those in the actual; implementation. Design Trade-offs; -----------------. Advantages:; ^^^^^^^^^^^; - Builder allows graph construction code to be reused for DDG and PDG.; - Builder allows us to create DDG and PDG as separate graphs.; - DDG nodes and edges are completely disjoint from PDG nodes and edges allowing them to change easily and independently. Disadvantages:; ^^^^^^^^^^^^^^; - Builder may be perceived as over-engineering at first.; - There are some similarities between DDG nodes and edges compared to PDG nodes and edges, but there is little reuse of the class definitions. - This is tolerable given that the node and edge types are fairly simple and there is little code reuse opportunity anyway. .. _implementation-details:. Implementation Details; ======================. The current implementation of DDG differs slightly from the dependence; graph described in [1]_ in the following ways:. 1. The graph nodes in the paper represent three main program components, namely *assignment statements*, *for loop headers* and *while loop headers*. In this implementation, DDG nodes naturally represent LLVM IR instructions. An assignment statement in this implementation typically involves a node representing the ``store`` instruction along with a number of individual nodes computing the right-hand-side of the assignment that connect to the ``store`` node via a def-use edge. The loop header instructions are not represented as special nodes in this implementation because they have limited uses and can be easily identified, for example, through ``LoopAnalysis``.; 2. The paper describes five types of dependency edges between nodes n",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst:688,Integrability,depend,dependencies,688,"=========================; Dependence Graphs in LLVM; =========================. .. contents::; :local:. Introduction; ============; Dependence graphs are useful tools in compilers for analyzing relationships; between various program elements to help guide optimizations. The ideas; behind these graphs are described in papers [1]_ and [2]_. The implementation of these ideas in LLVM may be slightly different than; what is mentioned in the papers. These differences are documented in; the `implementation details <implementation-details_>`_. .. _DataDependenceGraph:. Data Dependence Graph; =====================; In its simplest form the Data Dependence Graph (or DDG) represents data; dependencies between individual instructions. Each node in such a graph; represents a single instruction and is referred to as an ""atomic"" node.; It is also possible to combine some atomic nodes that have a simple; def-use dependency between them into larger nodes that contain multiple-; instructions. As described in [1]_ the DDG uses graph abstraction to group nodes; that are part of a strongly connected component of the graph; into special nodes called pi-blocks. pi-blocks represent cycles of data; dependency that prevent reordering transformations. Since any strongly; connected component of the graph is a maximal subgraph of all the nodes; that form a cycle, pi-blocks are at most one level deep. In other words,; no pi-blocks are nested inside another pi-block, resulting in a; hierarchical representation that is at most one level deep. For example, consider the following:. .. code-block:: c++. for (int i = 1; i < n; i++) {; b[i] = c[i] + b[i-1];; }. This code contains a statement that has a loop carried dependence on; itself creating a cycle in the DDG. The figure below illustrates; how the cycle of dependency is carried through multiple def-use relations; and a memory access dependency. .. image:: cycle.png. The DDG corresponding to this example would have a pi-block that contains; all the",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst:911,Integrability,depend,dependency,911,"=========================; Dependence Graphs in LLVM; =========================. .. contents::; :local:. Introduction; ============; Dependence graphs are useful tools in compilers for analyzing relationships; between various program elements to help guide optimizations. The ideas; behind these graphs are described in papers [1]_ and [2]_. The implementation of these ideas in LLVM may be slightly different than; what is mentioned in the papers. These differences are documented in; the `implementation details <implementation-details_>`_. .. _DataDependenceGraph:. Data Dependence Graph; =====================; In its simplest form the Data Dependence Graph (or DDG) represents data; dependencies between individual instructions. Each node in such a graph; represents a single instruction and is referred to as an ""atomic"" node.; It is also possible to combine some atomic nodes that have a simple; def-use dependency between them into larger nodes that contain multiple-; instructions. As described in [1]_ the DDG uses graph abstraction to group nodes; that are part of a strongly connected component of the graph; into special nodes called pi-blocks. pi-blocks represent cycles of data; dependency that prevent reordering transformations. Since any strongly; connected component of the graph is a maximal subgraph of all the nodes; that form a cycle, pi-blocks are at most one level deep. In other words,; no pi-blocks are nested inside another pi-block, resulting in a; hierarchical representation that is at most one level deep. For example, consider the following:. .. code-block:: c++. for (int i = 1; i < n; i++) {; b[i] = c[i] + b[i-1];; }. This code contains a statement that has a loop carried dependence on; itself creating a cycle in the DDG. The figure below illustrates; how the cycle of dependency is carried through multiple def-use relations; and a memory access dependency. .. image:: cycle.png. The DDG corresponding to this example would have a pi-block that contains; all the",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst:1194,Integrability,depend,dependency,1194,"onships; between various program elements to help guide optimizations. The ideas; behind these graphs are described in papers [1]_ and [2]_. The implementation of these ideas in LLVM may be slightly different than; what is mentioned in the papers. These differences are documented in; the `implementation details <implementation-details_>`_. .. _DataDependenceGraph:. Data Dependence Graph; =====================; In its simplest form the Data Dependence Graph (or DDG) represents data; dependencies between individual instructions. Each node in such a graph; represents a single instruction and is referred to as an ""atomic"" node.; It is also possible to combine some atomic nodes that have a simple; def-use dependency between them into larger nodes that contain multiple-; instructions. As described in [1]_ the DDG uses graph abstraction to group nodes; that are part of a strongly connected component of the graph; into special nodes called pi-blocks. pi-blocks represent cycles of data; dependency that prevent reordering transformations. Since any strongly; connected component of the graph is a maximal subgraph of all the nodes; that form a cycle, pi-blocks are at most one level deep. In other words,; no pi-blocks are nested inside another pi-block, resulting in a; hierarchical representation that is at most one level deep. For example, consider the following:. .. code-block:: c++. for (int i = 1; i < n; i++) {; b[i] = c[i] + b[i-1];; }. This code contains a statement that has a loop carried dependence on; itself creating a cycle in the DDG. The figure below illustrates; how the cycle of dependency is carried through multiple def-use relations; and a memory access dependency. .. image:: cycle.png. The DDG corresponding to this example would have a pi-block that contains; all the nodes participating in the cycle, as shown below:. .. image:: cycle_pi.png. Program Dependence Graph; ========================. The Program Dependence Graph (or PDG) has a similar structure as the; D",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst:1709,Integrability,depend,dependence,1709,"en individual instructions. Each node in such a graph; represents a single instruction and is referred to as an ""atomic"" node.; It is also possible to combine some atomic nodes that have a simple; def-use dependency between them into larger nodes that contain multiple-; instructions. As described in [1]_ the DDG uses graph abstraction to group nodes; that are part of a strongly connected component of the graph; into special nodes called pi-blocks. pi-blocks represent cycles of data; dependency that prevent reordering transformations. Since any strongly; connected component of the graph is a maximal subgraph of all the nodes; that form a cycle, pi-blocks are at most one level deep. In other words,; no pi-blocks are nested inside another pi-block, resulting in a; hierarchical representation that is at most one level deep. For example, consider the following:. .. code-block:: c++. for (int i = 1; i < n; i++) {; b[i] = c[i] + b[i-1];; }. This code contains a statement that has a loop carried dependence on; itself creating a cycle in the DDG. The figure below illustrates; how the cycle of dependency is carried through multiple def-use relations; and a memory access dependency. .. image:: cycle.png. The DDG corresponding to this example would have a pi-block that contains; all the nodes participating in the cycle, as shown below:. .. image:: cycle_pi.png. Program Dependence Graph; ========================. The Program Dependence Graph (or PDG) has a similar structure as the; DDG, but it is capable of representing both data dependencies and; control-flow dependencies between program elements such as; instructions, groups of instructions, basic blocks or groups of; basic blocks. High-Level Design; =================. The DDG and the PDG are both directed graphs and they extend the; ``DirectedGraph`` class. Each implementation extends its corresponding; node and edge types resulting in the inheritance relationship depicted; in the UML diagram below:. .. image:: uml_nodes_and_",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst:1807,Integrability,depend,dependency,1807,"node.; It is also possible to combine some atomic nodes that have a simple; def-use dependency between them into larger nodes that contain multiple-; instructions. As described in [1]_ the DDG uses graph abstraction to group nodes; that are part of a strongly connected component of the graph; into special nodes called pi-blocks. pi-blocks represent cycles of data; dependency that prevent reordering transformations. Since any strongly; connected component of the graph is a maximal subgraph of all the nodes; that form a cycle, pi-blocks are at most one level deep. In other words,; no pi-blocks are nested inside another pi-block, resulting in a; hierarchical representation that is at most one level deep. For example, consider the following:. .. code-block:: c++. for (int i = 1; i < n; i++) {; b[i] = c[i] + b[i-1];; }. This code contains a statement that has a loop carried dependence on; itself creating a cycle in the DDG. The figure below illustrates; how the cycle of dependency is carried through multiple def-use relations; and a memory access dependency. .. image:: cycle.png. The DDG corresponding to this example would have a pi-block that contains; all the nodes participating in the cycle, as shown below:. .. image:: cycle_pi.png. Program Dependence Graph; ========================. The Program Dependence Graph (or PDG) has a similar structure as the; DDG, but it is capable of representing both data dependencies and; control-flow dependencies between program elements such as; instructions, groups of instructions, basic blocks or groups of; basic blocks. High-Level Design; =================. The DDG and the PDG are both directed graphs and they extend the; ``DirectedGraph`` class. Each implementation extends its corresponding; node and edge types resulting in the inheritance relationship depicted; in the UML diagram below:. .. image:: uml_nodes_and_edges.png. Graph Construction; ------------------. The graph build algorithm considers dependencies between elements of; a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst:1885,Integrability,depend,dependency,1885,"node.; It is also possible to combine some atomic nodes that have a simple; def-use dependency between them into larger nodes that contain multiple-; instructions. As described in [1]_ the DDG uses graph abstraction to group nodes; that are part of a strongly connected component of the graph; into special nodes called pi-blocks. pi-blocks represent cycles of data; dependency that prevent reordering transformations. Since any strongly; connected component of the graph is a maximal subgraph of all the nodes; that form a cycle, pi-blocks are at most one level deep. In other words,; no pi-blocks are nested inside another pi-block, resulting in a; hierarchical representation that is at most one level deep. For example, consider the following:. .. code-block:: c++. for (int i = 1; i < n; i++) {; b[i] = c[i] + b[i-1];; }. This code contains a statement that has a loop carried dependence on; itself creating a cycle in the DDG. The figure below illustrates; how the cycle of dependency is carried through multiple def-use relations; and a memory access dependency. .. image:: cycle.png. The DDG corresponding to this example would have a pi-block that contains; all the nodes participating in the cycle, as shown below:. .. image:: cycle_pi.png. Program Dependence Graph; ========================. The Program Dependence Graph (or PDG) has a similar structure as the; DDG, but it is capable of representing both data dependencies and; control-flow dependencies between program elements such as; instructions, groups of instructions, basic blocks or groups of; basic blocks. High-Level Design; =================. The DDG and the PDG are both directed graphs and they extend the; ``DirectedGraph`` class. Each implementation extends its corresponding; node and edge types resulting in the inheritance relationship depicted; in the UML diagram below:. .. image:: uml_nodes_and_edges.png. Graph Construction; ------------------. The graph build algorithm considers dependencies between elements of; a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst:2249,Integrability,depend,dependencies,2249,"onnected component of the graph is a maximal subgraph of all the nodes; that form a cycle, pi-blocks are at most one level deep. In other words,; no pi-blocks are nested inside another pi-block, resulting in a; hierarchical representation that is at most one level deep. For example, consider the following:. .. code-block:: c++. for (int i = 1; i < n; i++) {; b[i] = c[i] + b[i-1];; }. This code contains a statement that has a loop carried dependence on; itself creating a cycle in the DDG. The figure below illustrates; how the cycle of dependency is carried through multiple def-use relations; and a memory access dependency. .. image:: cycle.png. The DDG corresponding to this example would have a pi-block that contains; all the nodes participating in the cycle, as shown below:. .. image:: cycle_pi.png. Program Dependence Graph; ========================. The Program Dependence Graph (or PDG) has a similar structure as the; DDG, but it is capable of representing both data dependencies and; control-flow dependencies between program elements such as; instructions, groups of instructions, basic blocks or groups of; basic blocks. High-Level Design; =================. The DDG and the PDG are both directed graphs and they extend the; ``DirectedGraph`` class. Each implementation extends its corresponding; node and edge types resulting in the inheritance relationship depicted; in the UML diagram below:. .. image:: uml_nodes_and_edges.png. Graph Construction; ------------------. The graph build algorithm considers dependencies between elements of; a given set of instructions or basic blocks. Any dependencies coming; into or going out of instructions that do not belong to that range; are ignored. The steps in the build algorithm for the DDG are very; similar to the steps in the build algorithm for the PDG. As such,; one of the design goals is to reuse the build algorithm code to; allow creation of both DDG and PDG representations while allowing; the two implementations to define t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst:2280,Integrability,depend,dependencies,2280,"onnected component of the graph is a maximal subgraph of all the nodes; that form a cycle, pi-blocks are at most one level deep. In other words,; no pi-blocks are nested inside another pi-block, resulting in a; hierarchical representation that is at most one level deep. For example, consider the following:. .. code-block:: c++. for (int i = 1; i < n; i++) {; b[i] = c[i] + b[i-1];; }. This code contains a statement that has a loop carried dependence on; itself creating a cycle in the DDG. The figure below illustrates; how the cycle of dependency is carried through multiple def-use relations; and a memory access dependency. .. image:: cycle.png. The DDG corresponding to this example would have a pi-block that contains; all the nodes participating in the cycle, as shown below:. .. image:: cycle_pi.png. Program Dependence Graph; ========================. The Program Dependence Graph (or PDG) has a similar structure as the; DDG, but it is capable of representing both data dependencies and; control-flow dependencies between program elements such as; instructions, groups of instructions, basic blocks or groups of; basic blocks. High-Level Design; =================. The DDG and the PDG are both directed graphs and they extend the; ``DirectedGraph`` class. Each implementation extends its corresponding; node and edge types resulting in the inheritance relationship depicted; in the UML diagram below:. .. image:: uml_nodes_and_edges.png. Graph Construction; ------------------. The graph build algorithm considers dependencies between elements of; a given set of instructions or basic blocks. Any dependencies coming; into or going out of instructions that do not belong to that range; are ignored. The steps in the build algorithm for the DDG are very; similar to the steps in the build algorithm for the PDG. As such,; one of the design goals is to reuse the build algorithm code to; allow creation of both DDG and PDG representations while allowing; the two implementations to define t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst:2793,Integrability,depend,dependencies,2793,"ency is carried through multiple def-use relations; and a memory access dependency. .. image:: cycle.png. The DDG corresponding to this example would have a pi-block that contains; all the nodes participating in the cycle, as shown below:. .. image:: cycle_pi.png. Program Dependence Graph; ========================. The Program Dependence Graph (or PDG) has a similar structure as the; DDG, but it is capable of representing both data dependencies and; control-flow dependencies between program elements such as; instructions, groups of instructions, basic blocks or groups of; basic blocks. High-Level Design; =================. The DDG and the PDG are both directed graphs and they extend the; ``DirectedGraph`` class. Each implementation extends its corresponding; node and edge types resulting in the inheritance relationship depicted; in the UML diagram below:. .. image:: uml_nodes_and_edges.png. Graph Construction; ------------------. The graph build algorithm considers dependencies between elements of; a given set of instructions or basic blocks. Any dependencies coming; into or going out of instructions that do not belong to that range; are ignored. The steps in the build algorithm for the DDG are very; similar to the steps in the build algorithm for the PDG. As such,; one of the design goals is to reuse the build algorithm code to; allow creation of both DDG and PDG representations while allowing; the two implementations to define their own distinct and independent; node and edge types. This is achieved by using the well-known builder; design pattern to isolate the construction of the dependence graph; from its concrete representation. The following UML diagram depicts the overall structure of the design; pattern as it applies to the dependence graph implementation. .. image:: uml_builder_pattern.png. Notice that the common code for building the two types of graphs are; provided in the ``DependenceGraphBuilder`` class, while the ``DDGBuilder``; and ``PDGBuilder`` contr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst:2876,Integrability,depend,dependencies,2876,"DG corresponding to this example would have a pi-block that contains; all the nodes participating in the cycle, as shown below:. .. image:: cycle_pi.png. Program Dependence Graph; ========================. The Program Dependence Graph (or PDG) has a similar structure as the; DDG, but it is capable of representing both data dependencies and; control-flow dependencies between program elements such as; instructions, groups of instructions, basic blocks or groups of; basic blocks. High-Level Design; =================. The DDG and the PDG are both directed graphs and they extend the; ``DirectedGraph`` class. Each implementation extends its corresponding; node and edge types resulting in the inheritance relationship depicted; in the UML diagram below:. .. image:: uml_nodes_and_edges.png. Graph Construction; ------------------. The graph build algorithm considers dependencies between elements of; a given set of instructions or basic blocks. Any dependencies coming; into or going out of instructions that do not belong to that range; are ignored. The steps in the build algorithm for the DDG are very; similar to the steps in the build algorithm for the PDG. As such,; one of the design goals is to reuse the build algorithm code to; allow creation of both DDG and PDG representations while allowing; the two implementations to define their own distinct and independent; node and edge types. This is achieved by using the well-known builder; design pattern to isolate the construction of the dependence graph; from its concrete representation. The following UML diagram depicts the overall structure of the design; pattern as it applies to the dependence graph implementation. .. image:: uml_builder_pattern.png. Notice that the common code for building the two types of graphs are; provided in the ``DependenceGraphBuilder`` class, while the ``DDGBuilder``; and ``PDGBuilder`` control some aspects of how the graph is constructed; by the way of overriding virtual methods defined in ``Depende",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst:3423,Integrability,depend,dependence,3423,"blocks. High-Level Design; =================. The DDG and the PDG are both directed graphs and they extend the; ``DirectedGraph`` class. Each implementation extends its corresponding; node and edge types resulting in the inheritance relationship depicted; in the UML diagram below:. .. image:: uml_nodes_and_edges.png. Graph Construction; ------------------. The graph build algorithm considers dependencies between elements of; a given set of instructions or basic blocks. Any dependencies coming; into or going out of instructions that do not belong to that range; are ignored. The steps in the build algorithm for the DDG are very; similar to the steps in the build algorithm for the PDG. As such,; one of the design goals is to reuse the build algorithm code to; allow creation of both DDG and PDG representations while allowing; the two implementations to define their own distinct and independent; node and edge types. This is achieved by using the well-known builder; design pattern to isolate the construction of the dependence graph; from its concrete representation. The following UML diagram depicts the overall structure of the design; pattern as it applies to the dependence graph implementation. .. image:: uml_builder_pattern.png. Notice that the common code for building the two types of graphs are; provided in the ``DependenceGraphBuilder`` class, while the ``DDGBuilder``; and ``PDGBuilder`` control some aspects of how the graph is constructed; by the way of overriding virtual methods defined in ``DependenceGraphBuilder``. Note also that the steps and the names used in this diagram are for; illustrative purposes and may be different from those in the actual; implementation. Design Trade-offs; -----------------. Advantages:; ^^^^^^^^^^^; - Builder allows graph construction code to be reused for DDG and PDG.; - Builder allows us to create DDG and PDG as separate graphs.; - DDG nodes and edges are completely disjoint from PDG nodes and edges allowing them to change easily ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst:3575,Integrability,depend,dependence,3575,"implementation extends its corresponding; node and edge types resulting in the inheritance relationship depicted; in the UML diagram below:. .. image:: uml_nodes_and_edges.png. Graph Construction; ------------------. The graph build algorithm considers dependencies between elements of; a given set of instructions or basic blocks. Any dependencies coming; into or going out of instructions that do not belong to that range; are ignored. The steps in the build algorithm for the DDG are very; similar to the steps in the build algorithm for the PDG. As such,; one of the design goals is to reuse the build algorithm code to; allow creation of both DDG and PDG representations while allowing; the two implementations to define their own distinct and independent; node and edge types. This is achieved by using the well-known builder; design pattern to isolate the construction of the dependence graph; from its concrete representation. The following UML diagram depicts the overall structure of the design; pattern as it applies to the dependence graph implementation. .. image:: uml_builder_pattern.png. Notice that the common code for building the two types of graphs are; provided in the ``DependenceGraphBuilder`` class, while the ``DDGBuilder``; and ``PDGBuilder`` control some aspects of how the graph is constructed; by the way of overriding virtual methods defined in ``DependenceGraphBuilder``. Note also that the steps and the names used in this diagram are for; illustrative purposes and may be different from those in the actual; implementation. Design Trade-offs; -----------------. Advantages:; ^^^^^^^^^^^; - Builder allows graph construction code to be reused for DDG and PDG.; - Builder allows us to create DDG and PDG as separate graphs.; - DDG nodes and edges are completely disjoint from PDG nodes and edges allowing them to change easily and independently. Disadvantages:; ^^^^^^^^^^^^^^; - Builder may be perceived as over-engineering at first.; - There are some similarities betw",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst:4911,Integrability,depend,dependence,4911,"d in ``DependenceGraphBuilder``. Note also that the steps and the names used in this diagram are for; illustrative purposes and may be different from those in the actual; implementation. Design Trade-offs; -----------------. Advantages:; ^^^^^^^^^^^; - Builder allows graph construction code to be reused for DDG and PDG.; - Builder allows us to create DDG and PDG as separate graphs.; - DDG nodes and edges are completely disjoint from PDG nodes and edges allowing them to change easily and independently. Disadvantages:; ^^^^^^^^^^^^^^; - Builder may be perceived as over-engineering at first.; - There are some similarities between DDG nodes and edges compared to PDG nodes and edges, but there is little reuse of the class definitions. - This is tolerable given that the node and edge types are fairly simple and there is little code reuse opportunity anyway. .. _implementation-details:. Implementation Details; ======================. The current implementation of DDG differs slightly from the dependence; graph described in [1]_ in the following ways:. 1. The graph nodes in the paper represent three main program components, namely *assignment statements*, *for loop headers* and *while loop headers*. In this implementation, DDG nodes naturally represent LLVM IR instructions. An assignment statement in this implementation typically involves a node representing the ``store`` instruction along with a number of individual nodes computing the right-hand-side of the assignment that connect to the ``store`` node via a def-use edge. The loop header instructions are not represented as special nodes in this implementation because they have limited uses and can be easily identified, for example, through ``LoopAnalysis``.; 2. The paper describes five types of dependency edges between nodes namely *loop dependency*, *flow-*, *anti-*, *output-*, and *input-* dependencies. In this implementation *memory* edges represent the *flow-*, *anti-*, *output-*, and *input-* dependencies. However, *",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst:5679,Integrability,depend,dependency,5679,"airly simple and there is little code reuse opportunity anyway. .. _implementation-details:. Implementation Details; ======================. The current implementation of DDG differs slightly from the dependence; graph described in [1]_ in the following ways:. 1. The graph nodes in the paper represent three main program components, namely *assignment statements*, *for loop headers* and *while loop headers*. In this implementation, DDG nodes naturally represent LLVM IR instructions. An assignment statement in this implementation typically involves a node representing the ``store`` instruction along with a number of individual nodes computing the right-hand-side of the assignment that connect to the ``store`` node via a def-use edge. The loop header instructions are not represented as special nodes in this implementation because they have limited uses and can be easily identified, for example, through ``LoopAnalysis``.; 2. The paper describes five types of dependency edges between nodes namely *loop dependency*, *flow-*, *anti-*, *output-*, and *input-* dependencies. In this implementation *memory* edges represent the *flow-*, *anti-*, *output-*, and *input-* dependencies. However, *loop dependencies* are not made explicit, because they mainly represent association between a loop structure and the program elements inside the loop and this association is fairly obvious in LLVM IR itself.; 3. The paper describes two types of pi-blocks; *recurrences* whose bodies are SCCs and *IN* nodes whose bodies are not part of any SCC. In this implementation, pi-blocks are only created for *recurrences*. *IN* nodes remain as simple DDG nodes in the graph. References; ----------; .. [1] ""D. J. Kuck, R. H. Kuhn, D. A. Padua, B. Leasure, and M. Wolfe (1981). DEPENDENCE GRAPHS AND COMPILER OPTIMIZATIONS.""; .. [2] ""J. FERRANTE (IBM), K. J. OTTENSTEIN (Michigan Technological University) and JOE D. WARREN (Rice University), 1987. The Program Dependence Graph and Its Use in Optimization.""; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst:5723,Integrability,depend,dependency,5723,"airly simple and there is little code reuse opportunity anyway. .. _implementation-details:. Implementation Details; ======================. The current implementation of DDG differs slightly from the dependence; graph described in [1]_ in the following ways:. 1. The graph nodes in the paper represent three main program components, namely *assignment statements*, *for loop headers* and *while loop headers*. In this implementation, DDG nodes naturally represent LLVM IR instructions. An assignment statement in this implementation typically involves a node representing the ``store`` instruction along with a number of individual nodes computing the right-hand-side of the assignment that connect to the ``store`` node via a def-use edge. The loop header instructions are not represented as special nodes in this implementation because they have limited uses and can be easily identified, for example, through ``LoopAnalysis``.; 2. The paper describes five types of dependency edges between nodes namely *loop dependency*, *flow-*, *anti-*, *output-*, and *input-* dependencies. In this implementation *memory* edges represent the *flow-*, *anti-*, *output-*, and *input-* dependencies. However, *loop dependencies* are not made explicit, because they mainly represent association between a loop structure and the program elements inside the loop and this association is fairly obvious in LLVM IR itself.; 3. The paper describes two types of pi-blocks; *recurrences* whose bodies are SCCs and *IN* nodes whose bodies are not part of any SCC. In this implementation, pi-blocks are only created for *recurrences*. *IN* nodes remain as simple DDG nodes in the graph. References; ----------; .. [1] ""D. J. Kuck, R. H. Kuhn, D. A. Padua, B. Leasure, and M. Wolfe (1981). DEPENDENCE GRAPHS AND COMPILER OPTIMIZATIONS.""; .. [2] ""J. FERRANTE (IBM), K. J. OTTENSTEIN (Michigan Technological University) and JOE D. WARREN (Rice University), 1987. The Program Dependence Graph and Its Use in Optimization.""; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst:5778,Integrability,depend,dependencies,5778,"airly simple and there is little code reuse opportunity anyway. .. _implementation-details:. Implementation Details; ======================. The current implementation of DDG differs slightly from the dependence; graph described in [1]_ in the following ways:. 1. The graph nodes in the paper represent three main program components, namely *assignment statements*, *for loop headers* and *while loop headers*. In this implementation, DDG nodes naturally represent LLVM IR instructions. An assignment statement in this implementation typically involves a node representing the ``store`` instruction along with a number of individual nodes computing the right-hand-side of the assignment that connect to the ``store`` node via a def-use edge. The loop header instructions are not represented as special nodes in this implementation because they have limited uses and can be easily identified, for example, through ``LoopAnalysis``.; 2. The paper describes five types of dependency edges between nodes namely *loop dependency*, *flow-*, *anti-*, *output-*, and *input-* dependencies. In this implementation *memory* edges represent the *flow-*, *anti-*, *output-*, and *input-* dependencies. However, *loop dependencies* are not made explicit, because they mainly represent association between a loop structure and the program elements inside the loop and this association is fairly obvious in LLVM IR itself.; 3. The paper describes two types of pi-blocks; *recurrences* whose bodies are SCCs and *IN* nodes whose bodies are not part of any SCC. In this implementation, pi-blocks are only created for *recurrences*. *IN* nodes remain as simple DDG nodes in the graph. References; ----------; .. [1] ""D. J. Kuck, R. H. Kuhn, D. A. Padua, B. Leasure, and M. Wolfe (1981). DEPENDENCE GRAPHS AND COMPILER OPTIMIZATIONS.""; .. [2] ""J. FERRANTE (IBM), K. J. OTTENSTEIN (Michigan Technological University) and JOE D. WARREN (Rice University), 1987. The Program Dependence Graph and Its Use in Optimization.""; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst:5886,Integrability,depend,dependencies,5886,"airly simple and there is little code reuse opportunity anyway. .. _implementation-details:. Implementation Details; ======================. The current implementation of DDG differs slightly from the dependence; graph described in [1]_ in the following ways:. 1. The graph nodes in the paper represent three main program components, namely *assignment statements*, *for loop headers* and *while loop headers*. In this implementation, DDG nodes naturally represent LLVM IR instructions. An assignment statement in this implementation typically involves a node representing the ``store`` instruction along with a number of individual nodes computing the right-hand-side of the assignment that connect to the ``store`` node via a def-use edge. The loop header instructions are not represented as special nodes in this implementation because they have limited uses and can be easily identified, for example, through ``LoopAnalysis``.; 2. The paper describes five types of dependency edges between nodes namely *loop dependency*, *flow-*, *anti-*, *output-*, and *input-* dependencies. In this implementation *memory* edges represent the *flow-*, *anti-*, *output-*, and *input-* dependencies. However, *loop dependencies* are not made explicit, because they mainly represent association between a loop structure and the program elements inside the loop and this association is fairly obvious in LLVM IR itself.; 3. The paper describes two types of pi-blocks; *recurrences* whose bodies are SCCs and *IN* nodes whose bodies are not part of any SCC. In this implementation, pi-blocks are only created for *recurrences*. *IN* nodes remain as simple DDG nodes in the graph. References; ----------; .. [1] ""D. J. Kuck, R. H. Kuhn, D. A. Padua, B. Leasure, and M. Wolfe (1981). DEPENDENCE GRAPHS AND COMPILER OPTIMIZATIONS.""; .. [2] ""J. FERRANTE (IBM), K. J. OTTENSTEIN (Michigan Technological University) and JOE D. WARREN (Rice University), 1987. The Program Dependence Graph and Its Use in Optimization.""; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst:5915,Integrability,depend,dependencies,5915,"airly simple and there is little code reuse opportunity anyway. .. _implementation-details:. Implementation Details; ======================. The current implementation of DDG differs slightly from the dependence; graph described in [1]_ in the following ways:. 1. The graph nodes in the paper represent three main program components, namely *assignment statements*, *for loop headers* and *while loop headers*. In this implementation, DDG nodes naturally represent LLVM IR instructions. An assignment statement in this implementation typically involves a node representing the ``store`` instruction along with a number of individual nodes computing the right-hand-side of the assignment that connect to the ``store`` node via a def-use edge. The loop header instructions are not represented as special nodes in this implementation because they have limited uses and can be easily identified, for example, through ``LoopAnalysis``.; 2. The paper describes five types of dependency edges between nodes namely *loop dependency*, *flow-*, *anti-*, *output-*, and *input-* dependencies. In this implementation *memory* edges represent the *flow-*, *anti-*, *output-*, and *input-* dependencies. However, *loop dependencies* are not made explicit, because they mainly represent association between a loop structure and the program elements inside the loop and this association is fairly obvious in LLVM IR itself.; 3. The paper describes two types of pi-blocks; *recurrences* whose bodies are SCCs and *IN* nodes whose bodies are not part of any SCC. In this implementation, pi-blocks are only created for *recurrences*. *IN* nodes remain as simple DDG nodes in the graph. References; ----------; .. [1] ""D. J. Kuck, R. H. Kuhn, D. A. Padua, B. Leasure, and M. Wolfe (1981). DEPENDENCE GRAPHS AND COMPILER OPTIMIZATIONS.""; .. [2] ""J. FERRANTE (IBM), K. J. OTTENSTEIN (Michigan Technological University) and JOE D. WARREN (Rice University), 1987. The Program Dependence Graph and Its Use in Optimization.""; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst:2498,Modifiability,extend,extend,2498,"al representation that is at most one level deep. For example, consider the following:. .. code-block:: c++. for (int i = 1; i < n; i++) {; b[i] = c[i] + b[i-1];; }. This code contains a statement that has a loop carried dependence on; itself creating a cycle in the DDG. The figure below illustrates; how the cycle of dependency is carried through multiple def-use relations; and a memory access dependency. .. image:: cycle.png. The DDG corresponding to this example would have a pi-block that contains; all the nodes participating in the cycle, as shown below:. .. image:: cycle_pi.png. Program Dependence Graph; ========================. The Program Dependence Graph (or PDG) has a similar structure as the; DDG, but it is capable of representing both data dependencies and; control-flow dependencies between program elements such as; instructions, groups of instructions, basic blocks or groups of; basic blocks. High-Level Design; =================. The DDG and the PDG are both directed graphs and they extend the; ``DirectedGraph`` class. Each implementation extends its corresponding; node and edge types resulting in the inheritance relationship depicted; in the UML diagram below:. .. image:: uml_nodes_and_edges.png. Graph Construction; ------------------. The graph build algorithm considers dependencies between elements of; a given set of instructions or basic blocks. Any dependencies coming; into or going out of instructions that do not belong to that range; are ignored. The steps in the build algorithm for the DDG are very; similar to the steps in the build algorithm for the PDG. As such,; one of the design goals is to reuse the build algorithm code to; allow creation of both DDG and PDG representations while allowing; the two implementations to define their own distinct and independent; node and edge types. This is achieved by using the well-known builder; design pattern to isolate the construction of the dependence graph; from its concrete representation. The following ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst:2555,Modifiability,extend,extends,2555," = 1; i < n; i++) {; b[i] = c[i] + b[i-1];; }. This code contains a statement that has a loop carried dependence on; itself creating a cycle in the DDG. The figure below illustrates; how the cycle of dependency is carried through multiple def-use relations; and a memory access dependency. .. image:: cycle.png. The DDG corresponding to this example would have a pi-block that contains; all the nodes participating in the cycle, as shown below:. .. image:: cycle_pi.png. Program Dependence Graph; ========================. The Program Dependence Graph (or PDG) has a similar structure as the; DDG, but it is capable of representing both data dependencies and; control-flow dependencies between program elements such as; instructions, groups of instructions, basic blocks or groups of; basic blocks. High-Level Design; =================. The DDG and the PDG are both directed graphs and they extend the; ``DirectedGraph`` class. Each implementation extends its corresponding; node and edge types resulting in the inheritance relationship depicted; in the UML diagram below:. .. image:: uml_nodes_and_edges.png. Graph Construction; ------------------. The graph build algorithm considers dependencies between elements of; a given set of instructions or basic blocks. Any dependencies coming; into or going out of instructions that do not belong to that range; are ignored. The steps in the build algorithm for the DDG are very; similar to the steps in the build algorithm for the PDG. As such,; one of the design goals is to reuse the build algorithm code to; allow creation of both DDG and PDG representations while allowing; the two implementations to define their own distinct and independent; node and edge types. This is achieved by using the well-known builder; design pattern to isolate the construction of the dependence graph; from its concrete representation. The following UML diagram depicts the overall structure of the design; pattern as it applies to the dependence graph implementation.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst:2619,Modifiability,inherit,inheritance,2619," = 1; i < n; i++) {; b[i] = c[i] + b[i-1];; }. This code contains a statement that has a loop carried dependence on; itself creating a cycle in the DDG. The figure below illustrates; how the cycle of dependency is carried through multiple def-use relations; and a memory access dependency. .. image:: cycle.png. The DDG corresponding to this example would have a pi-block that contains; all the nodes participating in the cycle, as shown below:. .. image:: cycle_pi.png. Program Dependence Graph; ========================. The Program Dependence Graph (or PDG) has a similar structure as the; DDG, but it is capable of representing both data dependencies and; control-flow dependencies between program elements such as; instructions, groups of instructions, basic blocks or groups of; basic blocks. High-Level Design; =================. The DDG and the PDG are both directed graphs and they extend the; ``DirectedGraph`` class. Each implementation extends its corresponding; node and edge types resulting in the inheritance relationship depicted; in the UML diagram below:. .. image:: uml_nodes_and_edges.png. Graph Construction; ------------------. The graph build algorithm considers dependencies between elements of; a given set of instructions or basic blocks. Any dependencies coming; into or going out of instructions that do not belong to that range; are ignored. The steps in the build algorithm for the DDG are very; similar to the steps in the build algorithm for the PDG. As such,; one of the design goals is to reuse the build algorithm code to; allow creation of both DDG and PDG representations while allowing; the two implementations to define their own distinct and independent; node and edge types. This is achieved by using the well-known builder; design pattern to isolate the construction of the dependence graph; from its concrete representation. The following UML diagram depicts the overall structure of the design; pattern as it applies to the dependence graph implementation.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst:257,Performance,optimiz,optimizations,257,"=========================; Dependence Graphs in LLVM; =========================. .. contents::; :local:. Introduction; ============; Dependence graphs are useful tools in compilers for analyzing relationships; between various program elements to help guide optimizations. The ideas; behind these graphs are described in papers [1]_ and [2]_. The implementation of these ideas in LLVM may be slightly different than; what is mentioned in the papers. These differences are documented in; the `implementation details <implementation-details_>`_. .. _DataDependenceGraph:. Data Dependence Graph; =====================; In its simplest form the Data Dependence Graph (or DDG) represents data; dependencies between individual instructions. Each node in such a graph; represents a single instruction and is referred to as an ""atomic"" node.; It is also possible to combine some atomic nodes that have a simple; def-use dependency between them into larger nodes that contain multiple-; instructions. As described in [1]_ the DDG uses graph abstraction to group nodes; that are part of a strongly connected component of the graph; into special nodes called pi-blocks. pi-blocks represent cycles of data; dependency that prevent reordering transformations. Since any strongly; connected component of the graph is a maximal subgraph of all the nodes; that form a cycle, pi-blocks are at most one level deep. In other words,; no pi-blocks are nested inside another pi-block, resulting in a; hierarchical representation that is at most one level deep. For example, consider the following:. .. code-block:: c++. for (int i = 1; i < n; i++) {; b[i] = c[i] + b[i-1];; }. This code contains a statement that has a loop carried dependence on; itself creating a cycle in the DDG. The figure below illustrates; how the cycle of dependency is carried through multiple def-use relations; and a memory access dependency. .. image:: cycle.png. The DDG corresponding to this example would have a pi-block that contains; all the",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst:1878,Security,access,access,1878,"node.; It is also possible to combine some atomic nodes that have a simple; def-use dependency between them into larger nodes that contain multiple-; instructions. As described in [1]_ the DDG uses graph abstraction to group nodes; that are part of a strongly connected component of the graph; into special nodes called pi-blocks. pi-blocks represent cycles of data; dependency that prevent reordering transformations. Since any strongly; connected component of the graph is a maximal subgraph of all the nodes; that form a cycle, pi-blocks are at most one level deep. In other words,; no pi-blocks are nested inside another pi-block, resulting in a; hierarchical representation that is at most one level deep. For example, consider the following:. .. code-block:: c++. for (int i = 1; i < n; i++) {; b[i] = c[i] + b[i-1];; }. This code contains a statement that has a loop carried dependence on; itself creating a cycle in the DDG. The figure below illustrates; how the cycle of dependency is carried through multiple def-use relations; and a memory access dependency. .. image:: cycle.png. The DDG corresponding to this example would have a pi-block that contains; all the nodes participating in the cycle, as shown below:. .. image:: cycle_pi.png. Program Dependence Graph; ========================. The Program Dependence Graph (or PDG) has a similar structure as the; DDG, but it is capable of representing both data dependencies and; control-flow dependencies between program elements such as; instructions, groups of instructions, basic blocks or groups of; basic blocks. High-Level Design; =================. The DDG and the PDG are both directed graphs and they extend the; ``DirectedGraph`` class. Each implementation extends its corresponding; node and edge types resulting in the inheritance relationship depicted; in the UML diagram below:. .. image:: uml_nodes_and_edges.png. Graph Construction; ------------------. The graph build algorithm considers dependencies between elements of; a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst:251,Usability,guid,guide,251,"=========================; Dependence Graphs in LLVM; =========================. .. contents::; :local:. Introduction; ============; Dependence graphs are useful tools in compilers for analyzing relationships; between various program elements to help guide optimizations. The ideas; behind these graphs are described in papers [1]_ and [2]_. The implementation of these ideas in LLVM may be slightly different than; what is mentioned in the papers. These differences are documented in; the `implementation details <implementation-details_>`_. .. _DataDependenceGraph:. Data Dependence Graph; =====================; In its simplest form the Data Dependence Graph (or DDG) represents data; dependencies between individual instructions. Each node in such a graph; represents a single instruction and is referred to as an ""atomic"" node.; It is also possible to combine some atomic nodes that have a simple; def-use dependency between them into larger nodes that contain multiple-; instructions. As described in [1]_ the DDG uses graph abstraction to group nodes; that are part of a strongly connected component of the graph; into special nodes called pi-blocks. pi-blocks represent cycles of data; dependency that prevent reordering transformations. Since any strongly; connected component of the graph is a maximal subgraph of all the nodes; that form a cycle, pi-blocks are at most one level deep. In other words,; no pi-blocks are nested inside another pi-block, resulting in a; hierarchical representation that is at most one level deep. For example, consider the following:. .. code-block:: c++. for (int i = 1; i < n; i++) {; b[i] = c[i] + b[i-1];; }. This code contains a statement that has a loop carried dependence on; itself creating a cycle in the DDG. The figure below illustrates; how the cycle of dependency is carried through multiple def-use relations; and a memory access dependency. .. image:: cycle.png. The DDG corresponding to this example would have a pi-block that contains; all the",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst:622,Usability,simpl,simplest,622,"=========================; Dependence Graphs in LLVM; =========================. .. contents::; :local:. Introduction; ============; Dependence graphs are useful tools in compilers for analyzing relationships; between various program elements to help guide optimizations. The ideas; behind these graphs are described in papers [1]_ and [2]_. The implementation of these ideas in LLVM may be slightly different than; what is mentioned in the papers. These differences are documented in; the `implementation details <implementation-details_>`_. .. _DataDependenceGraph:. Data Dependence Graph; =====================; In its simplest form the Data Dependence Graph (or DDG) represents data; dependencies between individual instructions. Each node in such a graph; represents a single instruction and is referred to as an ""atomic"" node.; It is also possible to combine some atomic nodes that have a simple; def-use dependency between them into larger nodes that contain multiple-; instructions. As described in [1]_ the DDG uses graph abstraction to group nodes; that are part of a strongly connected component of the graph; into special nodes called pi-blocks. pi-blocks represent cycles of data; dependency that prevent reordering transformations. Since any strongly; connected component of the graph is a maximal subgraph of all the nodes; that form a cycle, pi-blocks are at most one level deep. In other words,; no pi-blocks are nested inside another pi-block, resulting in a; hierarchical representation that is at most one level deep. For example, consider the following:. .. code-block:: c++. for (int i = 1; i < n; i++) {; b[i] = c[i] + b[i-1];; }. This code contains a statement that has a loop carried dependence on; itself creating a cycle in the DDG. The figure below illustrates; how the cycle of dependency is carried through multiple def-use relations; and a memory access dependency. .. image:: cycle.png. The DDG corresponding to this example would have a pi-block that contains; all the",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst:895,Usability,simpl,simple,895,"=========================; Dependence Graphs in LLVM; =========================. .. contents::; :local:. Introduction; ============; Dependence graphs are useful tools in compilers for analyzing relationships; between various program elements to help guide optimizations. The ideas; behind these graphs are described in papers [1]_ and [2]_. The implementation of these ideas in LLVM may be slightly different than; what is mentioned in the papers. These differences are documented in; the `implementation details <implementation-details_>`_. .. _DataDependenceGraph:. Data Dependence Graph; =====================; In its simplest form the Data Dependence Graph (or DDG) represents data; dependencies between individual instructions. Each node in such a graph; represents a single instruction and is referred to as an ""atomic"" node.; It is also possible to combine some atomic nodes that have a simple; def-use dependency between them into larger nodes that contain multiple-; instructions. As described in [1]_ the DDG uses graph abstraction to group nodes; that are part of a strongly connected component of the graph; into special nodes called pi-blocks. pi-blocks represent cycles of data; dependency that prevent reordering transformations. Since any strongly; connected component of the graph is a maximal subgraph of all the nodes; that form a cycle, pi-blocks are at most one level deep. In other words,; no pi-blocks are nested inside another pi-block, resulting in a; hierarchical representation that is at most one level deep. For example, consider the following:. .. code-block:: c++. for (int i = 1; i < n; i++) {; b[i] = c[i] + b[i-1];; }. This code contains a statement that has a loop carried dependence on; itself creating a cycle in the DDG. The figure below illustrates; how the cycle of dependency is carried through multiple def-use relations; and a memory access dependency. .. image:: cycle.png. The DDG corresponding to this example would have a pi-block that contains; all the",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst:4716,Usability,simpl,simple,4716,"e; provided in the ``DependenceGraphBuilder`` class, while the ``DDGBuilder``; and ``PDGBuilder`` control some aspects of how the graph is constructed; by the way of overriding virtual methods defined in ``DependenceGraphBuilder``. Note also that the steps and the names used in this diagram are for; illustrative purposes and may be different from those in the actual; implementation. Design Trade-offs; -----------------. Advantages:; ^^^^^^^^^^^; - Builder allows graph construction code to be reused for DDG and PDG.; - Builder allows us to create DDG and PDG as separate graphs.; - DDG nodes and edges are completely disjoint from PDG nodes and edges allowing them to change easily and independently. Disadvantages:; ^^^^^^^^^^^^^^; - Builder may be perceived as over-engineering at first.; - There are some similarities between DDG nodes and edges compared to PDG nodes and edges, but there is little reuse of the class definitions. - This is tolerable given that the node and edge types are fairly simple and there is little code reuse opportunity anyway. .. _implementation-details:. Implementation Details; ======================. The current implementation of DDG differs slightly from the dependence; graph described in [1]_ in the following ways:. 1. The graph nodes in the paper represent three main program components, namely *assignment statements*, *for loop headers* and *while loop headers*. In this implementation, DDG nodes naturally represent LLVM IR instructions. An assignment statement in this implementation typically involves a node representing the ``store`` instruction along with a number of individual nodes computing the right-hand-side of the assignment that connect to the ``store`` node via a def-use edge. The loop header instructions are not represented as special nodes in this implementation because they have limited uses and can be easily identified, for example, through ``LoopAnalysis``.; 2. The paper describes five types of dependency edges between nodes n",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst:6346,Usability,simpl,simple,6346,"airly simple and there is little code reuse opportunity anyway. .. _implementation-details:. Implementation Details; ======================. The current implementation of DDG differs slightly from the dependence; graph described in [1]_ in the following ways:. 1. The graph nodes in the paper represent three main program components, namely *assignment statements*, *for loop headers* and *while loop headers*. In this implementation, DDG nodes naturally represent LLVM IR instructions. An assignment statement in this implementation typically involves a node representing the ``store`` instruction along with a number of individual nodes computing the right-hand-side of the assignment that connect to the ``store`` node via a def-use edge. The loop header instructions are not represented as special nodes in this implementation because they have limited uses and can be easily identified, for example, through ``LoopAnalysis``.; 2. The paper describes five types of dependency edges between nodes namely *loop dependency*, *flow-*, *anti-*, *output-*, and *input-* dependencies. In this implementation *memory* edges represent the *flow-*, *anti-*, *output-*, and *input-* dependencies. However, *loop dependencies* are not made explicit, because they mainly represent association between a loop structure and the program elements inside the loop and this association is fairly obvious in LLVM IR itself.; 3. The paper describes two types of pi-blocks; *recurrences* whose bodies are SCCs and *IN* nodes whose bodies are not part of any SCC. In this implementation, pi-blocks are only created for *recurrences*. *IN* nodes remain as simple DDG nodes in the graph. References; ----------; .. [1] ""D. J. Kuck, R. H. Kuhn, D. A. Padua, B. Leasure, and M. Wolfe (1981). DEPENDENCE GRAPHS AND COMPILER OPTIMIZATIONS.""; .. [2] ""J. FERRANTE (IBM), K. J. OTTENSTEIN (Michigan Technological University) and JOE D. WARREN (Rice University), 1987. The Program Dependence Graph and Its Use in Optimization.""; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/DependenceGraphs/index.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:4974,Availability,mask,masks,4974,"a; <range-metadata>` and LLVM can do the sext to zext conversion for you. Zext GEP indices to machine register width; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Internally, LLVM often promotes the width of GEP indices to machine register; width. When it does so, it will default to using sign extension (sext); operations for safety. If your source language provides information about; the range of the index, you may wish to manually extend indices to machine; register width using a zext instruction. When to specify alignment; ^^^^^^^^^^^^^^^^^^^^^^^^^^; LLVM will always generate correct code if you don’t specify alignment, but may; generate inefficient code. For example, if you are targeting MIPS (or older; ARM ISAs) then the hardware does not handle unaligned loads and stores, and; so you will enter a trap-and-emulate path if you do a load or store with; lower-than-natural alignment. To avoid this, LLVM will emit a slower; sequence of loads, shifts and masks (or load-right + load-left on MIPS) for; all cases where the load / store does not have a sufficiently high alignment; in the IR. The alignment is used to guarantee the alignment on allocas and globals,; though in most cases this is unnecessary (most targets have a sufficiently; high default alignment that they’ll be fine). It is also used to provide a; contract to the back end saying ‘either this load/store has this alignment, or; it is undefined behavior’. This means that the back end is free to emit; instructions that rely on that alignment (and mid-level optimizers are free to; perform transforms that require that alignment). For x86, it doesn’t make; much difference, as almost all instructions are alignment-independent. For; MIPS, it can make a big difference. Note that if your loads and stores are atomic, the backend will be unable to; lower an under aligned access into a sequence of natively aligned accesses.; As a result, alignment is mandatory for atomic loads and stores. Other Things to Consider; ^^^^",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:7123,Availability,avail,available,7123,"rfere with pointer aliasing; analysis), prefer GEPs. #. Prefer globals over inttoptr of a constant address - this gives you; dereferencability information. In MCJIT, use getSymbolAddress to provide; actual address. #. Be wary of ordered and atomic memory operations. They are hard to optimize; and may not be well optimized by the current optimizer. Depending on your; source language, you may consider using fences instead. #. If calling a function which is known to throw an exception (unwind), use; an invoke with a normal destination which contains an unreachable; instruction. This form conveys to the optimizer that the call returns; abnormally. For an invoke which neither returns normally or requires unwind; code in the current function, you can use a noreturn call instruction if; desired. This is generally not required because the optimizer will convert; an invoke with an unreachable unwind destination to a call instruction. #. Use profile metadata to indicate statically known cold paths, even if; dynamic profiling information is not available. This can make a large; difference in code placement and thus the performance of tight loops. #. When generating code for loops, try to avoid terminating the header block of; the loop earlier than necessary. If the terminator of the loop header; block is a loop exiting conditional branch, the effectiveness of LICM will; be limited for loads not in the header. (This is due to the fact that LLVM; may not know such a load is safe to speculatively execute and thus can't; lift an otherwise loop invariant load unless it can prove the exiting; condition is not taken.) It can be profitable, in some cases, to emit such; instructions into the header even if they are not used along a rarely; executed path that exits the loop. This guidance specifically does not; apply if the condition which terminates the loop header is itself invariant,; or can be easily discharged by inspecting the loop index variables. #. In hot loops, consider duplica",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:8571,Availability,redundant,redundant,8571,"t an otherwise loop invariant load unless it can prove the exiting; condition is not taken.) It can be profitable, in some cases, to emit such; instructions into the header even if they are not used along a rarely; executed path that exits the loop. This guidance specifically does not; apply if the condition which terminates the loop header is itself invariant,; or can be easily discharged by inspecting the loop index variables. #. In hot loops, consider duplicating instructions from small basic blocks; which end in highly predictable terminators into their successor blocks.; If a hot successor block contains instructions which can be vectorized; with the duplicated ones, this can provide a noticeable throughput; improvement. Note that this is not always profitable and does involve a; potentially large increase in code size. #. When checking a value against a constant, emit the check using a consistent; comparison type. The GVN pass *will* optimize redundant equalities even if; the type of comparison is inverted, but GVN only runs late in the pipeline.; As a result, you may miss the opportunity to run other important; optimizations. #. Avoid using arithmetic intrinsics unless you are *required* by your source; language specification to emit a particular code sequence. The optimizer; is quite good at reasoning about general control flow and arithmetic, it is; not anywhere near as strong at reasoning about the various intrinsics. If; profitable for code generation purposes, the optimizer will likely form the; intrinsics itself late in the optimization pipeline. It is *very* rarely; profitable to emit these directly in the language frontend. This item; explicitly includes the use of the :ref:`overflow intrinsics <int_overflow>`. #. Avoid using the :ref:`assume intrinsic <int_assume>` until you've; established that a) there's no other way to express the given fact and b); that fact is critical for optimization purposes. Assumes are a great; prototyping mechanism, but the",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:9972,Availability,avail,available,9972,"anywhere near as strong at reasoning about the various intrinsics. If; profitable for code generation purposes, the optimizer will likely form the; intrinsics itself late in the optimization pipeline. It is *very* rarely; profitable to emit these directly in the language frontend. This item; explicitly includes the use of the :ref:`overflow intrinsics <int_overflow>`. #. Avoid using the :ref:`assume intrinsic <int_assume>` until you've; established that a) there's no other way to express the given fact and b); that fact is critical for optimization purposes. Assumes are a great; prototyping mechanism, but they can have negative effects on both compile; time and optimization effectiveness. The former is fixable with enough; effort, but the later is fairly fundamental to their designed purpose. Describing Language Specific Properties; =======================================. When translating a source language to LLVM, finding ways to express concepts; and guarantees available in your source language which are not natively; provided by LLVM IR will greatly improve LLVM's ability to optimize your code.; As an example, C/C++'s ability to mark every add as ""no signed wrap (nsw)"" goes; a long way to assisting the optimizer in reasoning about loop induction; variables and thus generating more optimal code for loops. The LLVM LangRef includes a number of mechanisms for annotating the IR with; additional semantic information. It is *strongly* recommended that you become; highly familiar with this document. The list below is intended to highlight a; couple of items of particular interest, but is by no means exhaustive. Restricted Operation Semantics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; #. Add nsw/nuw flags as appropriate. Reasoning about overflow is; generally hard for an optimizer so providing these facts from the frontend; can be very impactful. #. Use fast-math flags on floating point operations if legal. If you don't; need strict IEEE floating point semantics, there are a numb",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:1170,Deployability,release,release,1170," contents::; :local:; :depth: 2. Abstract; ========. The intended audience of this document is developers of language frontends; targeting LLVM IR. This document is home to a collection of tips on how to; generate IR that optimizes well. IR Best Practices; =================. As with any optimizer, LLVM has its strengths and weaknesses. In some cases,; surprisingly small changes in the source IR can have a large effect on the; generated code. Beyond the specific items on the list below, it's worth noting that the most; mature frontend for LLVM is Clang. As a result, the further your IR gets from; what Clang might emit, the less likely it is to be effectively optimized. It; can often be useful to write a quick C program with the semantics you're trying; to model and see what decisions Clang's IRGen makes about what IR to emit.; Studying Clang's CodeGen directory can also be a good source of ideas. Note; that Clang and LLVM are explicitly version locked so you'll need to make sure; you're using a Clang built from the same git revision or release as the LLVM; library you're using. As always, it's *strongly* recommended that you track; tip of tree development, particularly during bring up of a new project. The Basics; ^^^^^^^^^^^. #. Make sure that your Modules contain both a data layout specification and; target triple. Without these pieces, non of the target specific optimization; will be enabled. This can have a major effect on the generated code quality. #. For each function or global emitted, use the most private linkage type; possible (private, internal or linkonce_odr preferably). Doing so will; make LLVM's inter-procedural optimizations much more effective. #. Avoid high in-degree basic blocks (e.g. basic blocks with dozens or hundreds; of predecessors). Among other issues, the register allocator is known to; perform badly with confronted with such structures. The only exception to; this guidance is that a unified return block with high in-degree is fine. Use of a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:8667,Deployability,pipeline,pipeline,8667,"t an otherwise loop invariant load unless it can prove the exiting; condition is not taken.) It can be profitable, in some cases, to emit such; instructions into the header even if they are not used along a rarely; executed path that exits the loop. This guidance specifically does not; apply if the condition which terminates the loop header is itself invariant,; or can be easily discharged by inspecting the loop index variables. #. In hot loops, consider duplicating instructions from small basic blocks; which end in highly predictable terminators into their successor blocks.; If a hot successor block contains instructions which can be vectorized; with the duplicated ones, this can provide a noticeable throughput; improvement. Note that this is not always profitable and does involve a; potentially large increase in code size. #. When checking a value against a constant, emit the check using a consistent; comparison type. The GVN pass *will* optimize redundant equalities even if; the type of comparison is inverted, but GVN only runs late in the pipeline.; As a result, you may miss the opportunity to run other important; optimizations. #. Avoid using arithmetic intrinsics unless you are *required* by your source; language specification to emit a particular code sequence. The optimizer; is quite good at reasoning about general control flow and arithmetic, it is; not anywhere near as strong at reasoning about the various intrinsics. If; profitable for code generation purposes, the optimizer will likely form the; intrinsics itself late in the optimization pipeline. It is *very* rarely; profitable to emit these directly in the language frontend. This item; explicitly includes the use of the :ref:`overflow intrinsics <int_overflow>`. #. Avoid using the :ref:`assume intrinsic <int_assume>` until you've; established that a) there's no other way to express the given fact and b); that fact is critical for optimization purposes. Assumes are a great; prototyping mechanism, but the",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:9184,Deployability,pipeline,pipeline,9184," in highly predictable terminators into their successor blocks.; If a hot successor block contains instructions which can be vectorized; with the duplicated ones, this can provide a noticeable throughput; improvement. Note that this is not always profitable and does involve a; potentially large increase in code size. #. When checking a value against a constant, emit the check using a consistent; comparison type. The GVN pass *will* optimize redundant equalities even if; the type of comparison is inverted, but GVN only runs late in the pipeline.; As a result, you may miss the opportunity to run other important; optimizations. #. Avoid using arithmetic intrinsics unless you are *required* by your source; language specification to emit a particular code sequence. The optimizer; is quite good at reasoning about general control flow and arithmetic, it is; not anywhere near as strong at reasoning about the various intrinsics. If; profitable for code generation purposes, the optimizer will likely form the; intrinsics itself late in the optimization pipeline. It is *very* rarely; profitable to emit these directly in the language frontend. This item; explicitly includes the use of the :ref:`overflow intrinsics <int_overflow>`. #. Avoid using the :ref:`assume intrinsic <int_assume>` until you've; established that a) there's no other way to express the given fact and b); that fact is critical for optimization purposes. Assumes are a great; prototyping mechanism, but they can have negative effects on both compile; time and optimization effectiveness. The former is fixable with enough; effort, but the later is fairly fundamental to their designed purpose. Describing Language Specific Properties; =======================================. When translating a source language to LLVM, finding ways to express concepts; and guarantees available in your source language which are not natively; provided by LLVM IR will greatly improve LLVM's ability to optimize your code.; As an example, C",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:12476,Deployability,pipeline,pipelines,12476,"n geps. This can help to disambiguate some aliasing queries. Undefined Values; ^^^^^^^^^^^^^^^^. #. Use poison values instead of undef values whenever possible. #. Tag function parameters with the noundef attribute whenever possible. Modeling Memory Effects; ^^^^^^^^^^^^^^^^^^^^^^^^. #. Mark functions as readnone/readonly/argmemonly or noreturn/nounwind when; known. The optimizer will try to infer these flags, but may not always be; able to. Manual annotations are particularly important for external; functions that the optimizer can not analyze. #. Use the lifetime.start/lifetime.end and invariant.start/invariant.end; intrinsics where possible. Common profitable uses are for stack like data; structures (thus allowing dead store elimination) and for describing; life times of allocas (thus allowing smaller stack sizes). #. Mark invariant locations using !invariant.load and TBAA's constant flags. Pass Ordering; ^^^^^^^^^^^^^. One of the most common mistakes made by new language frontend projects is to; use the existing -O2 or -O3 pass pipelines as is. These pass pipelines make a; good starting point for an optimizing compiler for any language, but they have; been carefully tuned for C and C++, not your target language. You will almost; certainly need to use a custom pass order to achieve optimal performance. A; couple specific suggestions:. #. For languages with numerous rarely executed guard conditions (e.g. null; checks, type checks, range checks) consider adding an extra execution or; two of LoopUnswitch and LICM to your pass order. The standard pass order,; which is tuned for C and C++ applications, may not be sufficient to remove; all dischargeable checks from loops. #. If your language uses range checks, consider using the IRCE pass. It is not; currently part of the standard pass order. #. A useful sanity check to run is to run your optimized IR back through the; -O2 pipeline again. If you see noticeable improvement in the resulting IR,; you likely need to adjust",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:12504,Deployability,pipeline,pipelines,12504,"r possible. #. Tag function parameters with the noundef attribute whenever possible. Modeling Memory Effects; ^^^^^^^^^^^^^^^^^^^^^^^^. #. Mark functions as readnone/readonly/argmemonly or noreturn/nounwind when; known. The optimizer will try to infer these flags, but may not always be; able to. Manual annotations are particularly important for external; functions that the optimizer can not analyze. #. Use the lifetime.start/lifetime.end and invariant.start/invariant.end; intrinsics where possible. Common profitable uses are for stack like data; structures (thus allowing dead store elimination) and for describing; life times of allocas (thus allowing smaller stack sizes). #. Mark invariant locations using !invariant.load and TBAA's constant flags. Pass Ordering; ^^^^^^^^^^^^^. One of the most common mistakes made by new language frontend projects is to; use the existing -O2 or -O3 pass pipelines as is. These pass pipelines make a; good starting point for an optimizing compiler for any language, but they have; been carefully tuned for C and C++, not your target language. You will almost; certainly need to use a custom pass order to achieve optimal performance. A; couple specific suggestions:. #. For languages with numerous rarely executed guard conditions (e.g. null; checks, type checks, range checks) consider adding an extra execution or; two of LoopUnswitch and LICM to your pass order. The standard pass order,; which is tuned for C and C++ applications, may not be sufficient to remove; all dischargeable checks from loops. #. If your language uses range checks, consider using the IRCE pass. It is not; currently part of the standard pass order. #. A useful sanity check to run is to run your optimized IR back through the; -O2 pipeline again. If you see noticeable improvement in the resulting IR,; you likely need to adjust your pass order. I Still Can't Find What I'm Looking For; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. If you didn't find what you were looking for above",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:13331,Deployability,pipeline,pipeline,13331,"iant.load and TBAA's constant flags. Pass Ordering; ^^^^^^^^^^^^^. One of the most common mistakes made by new language frontend projects is to; use the existing -O2 or -O3 pass pipelines as is. These pass pipelines make a; good starting point for an optimizing compiler for any language, but they have; been carefully tuned for C and C++, not your target language. You will almost; certainly need to use a custom pass order to achieve optimal performance. A; couple specific suggestions:. #. For languages with numerous rarely executed guard conditions (e.g. null; checks, type checks, range checks) consider adding an extra execution or; two of LoopUnswitch and LICM to your pass order. The standard pass order,; which is tuned for C and C++ applications, may not be sufficient to remove; all dischargeable checks from loops. #. If your language uses range checks, consider using the IRCE pass. It is not; currently part of the standard pass order. #. A useful sanity check to run is to run your optimized IR back through the; -O2 pipeline again. If you see noticeable improvement in the resulting IR,; you likely need to adjust your pass order. I Still Can't Find What I'm Looking For; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. If you didn't find what you were looking for above, consider proposing a piece; of metadata which provides the optimization hint you need. Such extensions are; relatively common and are generally well received by the community. You will; need to ensure that your proposal is sufficiently general so that it benefits; others if you wish to contribute it upstream. You should also consider describing the problem you're facing on `Discourse; <https://discourse.llvm.org>`_ and asking for advice.; It's entirely possible someone has encountered your problem before and can; give good advice. If there are multiple interested parties, that also; increases the chances that a metadata extension would be well received by the; community as a whole. Adding to this document; ===",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:14404,Deployability,patch,patch,14404,"a custom pass order to achieve optimal performance. A; couple specific suggestions:. #. For languages with numerous rarely executed guard conditions (e.g. null; checks, type checks, range checks) consider adding an extra execution or; two of LoopUnswitch and LICM to your pass order. The standard pass order,; which is tuned for C and C++ applications, may not be sufficient to remove; all dischargeable checks from loops. #. If your language uses range checks, consider using the IRCE pass. It is not; currently part of the standard pass order. #. A useful sanity check to run is to run your optimized IR back through the; -O2 pipeline again. If you see noticeable improvement in the resulting IR,; you likely need to adjust your pass order. I Still Can't Find What I'm Looking For; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. If you didn't find what you were looking for above, consider proposing a piece; of metadata which provides the optimization hint you need. Such extensions are; relatively common and are generally well received by the community. You will; need to ensure that your proposal is sufficiently general so that it benefits; others if you wish to contribute it upstream. You should also consider describing the problem you're facing on `Discourse; <https://discourse.llvm.org>`_ and asking for advice.; It's entirely possible someone has encountered your problem before and can; give good advice. If there are multiple interested parties, that also; increases the chances that a metadata extension would be well received by the; community as a whole. Adding to this document; =======================. If you run across a case that you feel deserves to be covered here, please send; a patch to `llvm-commits; <http://lists.llvm.org/mailman/listinfo/llvm-commits>`_ for review. If you have questions on these items, please ask them on `Discourse; <https://discourse.llvm.org>`_. The more relevant; context you are able to give to your question, the more likely it is to be; answered.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:5336,Integrability,contract,contract,5336,"s information about; the range of the index, you may wish to manually extend indices to machine; register width using a zext instruction. When to specify alignment; ^^^^^^^^^^^^^^^^^^^^^^^^^^; LLVM will always generate correct code if you don’t specify alignment, but may; generate inefficient code. For example, if you are targeting MIPS (or older; ARM ISAs) then the hardware does not handle unaligned loads and stores, and; so you will enter a trap-and-emulate path if you do a load or store with; lower-than-natural alignment. To avoid this, LLVM will emit a slower; sequence of loads, shifts and masks (or load-right + load-left on MIPS) for; all cases where the load / store does not have a sufficiently high alignment; in the IR. The alignment is used to guarantee the alignment on allocas and globals,; though in most cases this is unnecessary (most targets have a sufficiently; high default alignment that they’ll be fine). It is also used to provide a; contract to the back end saying ‘either this load/store has this alignment, or; it is undefined behavior’. This means that the back end is free to emit; instructions that rely on that alignment (and mid-level optimizers are free to; perform transforms that require that alignment). For x86, it doesn’t make; much difference, as almost all instructions are alignment-independent. For; MIPS, it can make a big difference. Note that if your loads and stores are atomic, the backend will be unable to; lower an under aligned access into a sequence of natively aligned accesses.; As a result, alignment is mandatory for atomic loads and stores. Other Things to Consider; ^^^^^^^^^^^^^^^^^^^^^^^^. #. Use ptrtoint/inttoptr sparingly (they interfere with pointer aliasing; analysis), prefer GEPs. #. Prefer globals over inttoptr of a constant address - this gives you; dereferencability information. In MCJIT, use getSymbolAddress to provide; actual address. #. Be wary of ordered and atomic memory operations. They are hard to optimize; and may",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:10173,Integrability,wrap,wrap,10173,"profitable to emit these directly in the language frontend. This item; explicitly includes the use of the :ref:`overflow intrinsics <int_overflow>`. #. Avoid using the :ref:`assume intrinsic <int_assume>` until you've; established that a) there's no other way to express the given fact and b); that fact is critical for optimization purposes. Assumes are a great; prototyping mechanism, but they can have negative effects on both compile; time and optimization effectiveness. The former is fixable with enough; effort, but the later is fairly fundamental to their designed purpose. Describing Language Specific Properties; =======================================. When translating a source language to LLVM, finding ways to express concepts; and guarantees available in your source language which are not natively; provided by LLVM IR will greatly improve LLVM's ability to optimize your code.; As an example, C/C++'s ability to mark every add as ""no signed wrap (nsw)"" goes; a long way to assisting the optimizer in reasoning about loop induction; variables and thus generating more optimal code for loops. The LLVM LangRef includes a number of mechanisms for annotating the IR with; additional semantic information. It is *strongly* recommended that you become; highly familiar with this document. The list below is intended to highlight a; couple of items of particular interest, but is by no means exhaustive. Restricted Operation Semantics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; #. Add nsw/nuw flags as appropriate. Reasoning about overflow is; generally hard for an optimizer so providing these facts from the frontend; can be very impactful. #. Use fast-math flags on floating point operations if legal. If you don't; need strict IEEE floating point semantics, there are a number of additional; optimizations that can be performed. This can be highly impactful for; floating point intensive computations. Describing Aliasing Properties; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. #. Add noalias/align/dereferen",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:2305,Modifiability,variab,variables,2305,"he Basics; ^^^^^^^^^^^. #. Make sure that your Modules contain both a data layout specification and; target triple. Without these pieces, non of the target specific optimization; will be enabled. This can have a major effect on the generated code quality. #. For each function or global emitted, use the most private linkage type; possible (private, internal or linkonce_odr preferably). Doing so will; make LLVM's inter-procedural optimizations much more effective. #. Avoid high in-degree basic blocks (e.g. basic blocks with dozens or hundreds; of predecessors). Among other issues, the register allocator is known to; perform badly with confronted with such structures. The only exception to; this guidance is that a unified return block with high in-degree is fine. Use of allocas; ^^^^^^^^^^^^^^. An alloca instruction can be used to represent a function scoped stack slot,; but can also represent dynamic frame expansion. When representing function; scoped variables or locations, placing alloca instructions at the beginning of; the entry block should be preferred. In particular, place them before any; call instructions. Call instructions might get inlined and replaced with; multiple basic blocks. The end result is that a following alloca instruction; would no longer be in the entry basic block afterward. The SROA (Scalar Replacement Of Aggregates) and Mem2Reg passes only attempt; to eliminate alloca instructions that are in the entry basic block. Given; SSA is the canonical form expected by much of the optimizer; if allocas can; not be eliminated by Mem2Reg or SROA, the optimizer is likely to be less; effective than it could be. Avoid loads and stores of large aggregate type; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. LLVM currently does not optimize well loads and stores of large :ref:`aggregate; types <t_aggregate>` (i.e. structs and arrays). As an alternative, consider; loading individual fields from memory. Aggregates that are smaller than the largest (performan",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:4443,Modifiability,extend,extend,4443,". These can; be an effective way to represent collections of small packed fields. Prefer zext over sext when legal; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. On some architectures (X86_64 is one), sign extension can involve an extra; instruction whereas zero extension can be folded into a load. LLVM will try to; replace a sext with a zext when it can be proven safe, but if you have; information in your source language about the range of an integer value, it can; be profitable to use a zext rather than a sext. Alternatively, you can :ref:`specify the range of the value using metadata; <range-metadata>` and LLVM can do the sext to zext conversion for you. Zext GEP indices to machine register width; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Internally, LLVM often promotes the width of GEP indices to machine register; width. When it does so, it will default to using sign extension (sext); operations for safety. If your source language provides information about; the range of the index, you may wish to manually extend indices to machine; register width using a zext instruction. When to specify alignment; ^^^^^^^^^^^^^^^^^^^^^^^^^^; LLVM will always generate correct code if you don’t specify alignment, but may; generate inefficient code. For example, if you are targeting MIPS (or older; ARM ISAs) then the hardware does not handle unaligned loads and stores, and; so you will enter a trap-and-emulate path if you do a load or store with; lower-than-natural alignment. To avoid this, LLVM will emit a slower; sequence of loads, shifts and masks (or load-right + load-left on MIPS) for; all cases where the load / store does not have a sufficiently high alignment; in the IR. The alignment is used to guarantee the alignment on allocas and globals,; though in most cases this is unnecessary (most targets have a sufficiently; high default alignment that they’ll be fine). It is also used to provide a; contract to the back end saying ‘either this load/store has this alignment, or; it is unde",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:8030,Modifiability,variab,variables,8030,"e with an unreachable unwind destination to a call instruction. #. Use profile metadata to indicate statically known cold paths, even if; dynamic profiling information is not available. This can make a large; difference in code placement and thus the performance of tight loops. #. When generating code for loops, try to avoid terminating the header block of; the loop earlier than necessary. If the terminator of the loop header; block is a loop exiting conditional branch, the effectiveness of LICM will; be limited for loads not in the header. (This is due to the fact that LLVM; may not know such a load is safe to speculatively execute and thus can't; lift an otherwise loop invariant load unless it can prove the exiting; condition is not taken.) It can be profitable, in some cases, to emit such; instructions into the header even if they are not used along a rarely; executed path that exits the loop. This guidance specifically does not; apply if the condition which terminates the loop header is itself invariant,; or can be easily discharged by inspecting the loop index variables. #. In hot loops, consider duplicating instructions from small basic blocks; which end in highly predictable terminators into their successor blocks.; If a hot successor block contains instructions which can be vectorized; with the duplicated ones, this can provide a noticeable throughput; improvement. Note that this is not always profitable and does involve a; potentially large increase in code size. #. When checking a value against a constant, emit the check using a consistent; comparison type. The GVN pass *will* optimize redundant equalities even if; the type of comparison is inverted, but GVN only runs late in the pipeline.; As a result, you may miss the opportunity to run other important; optimizations. #. Avoid using arithmetic intrinsics unless you are *required* by your source; language specification to emit a particular code sequence. The optimizer; is quite good at reasoning about gene",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:10264,Modifiability,variab,variables,10264,"profitable to emit these directly in the language frontend. This item; explicitly includes the use of the :ref:`overflow intrinsics <int_overflow>`. #. Avoid using the :ref:`assume intrinsic <int_assume>` until you've; established that a) there's no other way to express the given fact and b); that fact is critical for optimization purposes. Assumes are a great; prototyping mechanism, but they can have negative effects on both compile; time and optimization effectiveness. The former is fixable with enough; effort, but the later is fairly fundamental to their designed purpose. Describing Language Specific Properties; =======================================. When translating a source language to LLVM, finding ways to express concepts; and guarantees available in your source language which are not natively; provided by LLVM IR will greatly improve LLVM's ability to optimize your code.; As an example, C/C++'s ability to mark every add as ""no signed wrap (nsw)"" goes; a long way to assisting the optimizer in reasoning about loop induction; variables and thus generating more optimal code for loops. The LLVM LangRef includes a number of mechanisms for annotating the IR with; additional semantic information. It is *strongly* recommended that you become; highly familiar with this document. The list below is intended to highlight a; couple of items of particular interest, but is by no means exhaustive. Restricted Operation Semantics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; #. Add nsw/nuw flags as appropriate. Reasoning about overflow is; generally hard for an optimizer so providing these facts from the frontend; can be very impactful. #. Use fast-math flags on floating point operations if legal. If you don't; need strict IEEE floating point semantics, there are a number of additional; optimizations that can be performed. This can be highly impactful for; floating point intensive computations. Describing Aliasing Properties; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. #. Add noalias/align/dereferen",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:341,Performance,optimiz,optimizes,341,"=====================================; Performance Tips for Frontend Authors; =====================================. .. contents::; :local:; :depth: 2. Abstract; ========. The intended audience of this document is developers of language frontends; targeting LLVM IR. This document is home to a collection of tips on how to; generate IR that optimizes well. IR Best Practices; =================. As with any optimizer, LLVM has its strengths and weaknesses. In some cases,; surprisingly small changes in the source IR can have a large effect on the; generated code. Beyond the specific items on the list below, it's worth noting that the most; mature frontend for LLVM is Clang. As a result, the further your IR gets from; what Clang might emit, the less likely it is to be effectively optimized. It; can often be useful to write a quick C program with the semantics you're trying; to model and see what decisions Clang's IRGen makes about what IR to emit.; Studying Clang's CodeGen directory can also be a good source of ideas. Note; that Clang and LLVM are explicitly version locked so you'll need to make sure; you're using a Clang built from the same git revision or release as the LLVM; library you're using. As always, it's *strongly* recommended that you track; tip of tree development, particularly during bring up of a new project. The Basics; ^^^^^^^^^^^. #. Make sure that your Modules contain both a data layout specification and; target triple. Without these pieces, non of the target specific optimization; will be enabled. This can have a major effect on the generated code quality. #. For each function or global emitted, use the most private linkage type; possible (private, internal or linkonce_odr preferably). Doing so will; make LLVM's inter-procedural optimizations much more effective. #. Avoid high in-degree basic blocks (e.g. basic blocks with dozens or hundreds; of predecessors). Among other issues, the register allocator is known to; perform badly with confronted with suc",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:407,Performance,optimiz,optimizer,407,"=====================================; Performance Tips for Frontend Authors; =====================================. .. contents::; :local:; :depth: 2. Abstract; ========. The intended audience of this document is developers of language frontends; targeting LLVM IR. This document is home to a collection of tips on how to; generate IR that optimizes well. IR Best Practices; =================. As with any optimizer, LLVM has its strengths and weaknesses. In some cases,; surprisingly small changes in the source IR can have a large effect on the; generated code. Beyond the specific items on the list below, it's worth noting that the most; mature frontend for LLVM is Clang. As a result, the further your IR gets from; what Clang might emit, the less likely it is to be effectively optimized. It; can often be useful to write a quick C program with the semantics you're trying; to model and see what decisions Clang's IRGen makes about what IR to emit.; Studying Clang's CodeGen directory can also be a good source of ideas. Note; that Clang and LLVM are explicitly version locked so you'll need to make sure; you're using a Clang built from the same git revision or release as the LLVM; library you're using. As always, it's *strongly* recommended that you track; tip of tree development, particularly during bring up of a new project. The Basics; ^^^^^^^^^^^. #. Make sure that your Modules contain both a data layout specification and; target triple. Without these pieces, non of the target specific optimization; will be enabled. This can have a major effect on the generated code quality. #. For each function or global emitted, use the most private linkage type; possible (private, internal or linkonce_odr preferably). Doing so will; make LLVM's inter-procedural optimizations much more effective. #. Avoid high in-degree basic blocks (e.g. basic blocks with dozens or hundreds; of predecessors). Among other issues, the register allocator is known to; perform badly with confronted with suc",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:785,Performance,optimiz,optimized,785,"=====================================; Performance Tips for Frontend Authors; =====================================. .. contents::; :local:; :depth: 2. Abstract; ========. The intended audience of this document is developers of language frontends; targeting LLVM IR. This document is home to a collection of tips on how to; generate IR that optimizes well. IR Best Practices; =================. As with any optimizer, LLVM has its strengths and weaknesses. In some cases,; surprisingly small changes in the source IR can have a large effect on the; generated code. Beyond the specific items on the list below, it's worth noting that the most; mature frontend for LLVM is Clang. As a result, the further your IR gets from; what Clang might emit, the less likely it is to be effectively optimized. It; can often be useful to write a quick C program with the semantics you're trying; to model and see what decisions Clang's IRGen makes about what IR to emit.; Studying Clang's CodeGen directory can also be a good source of ideas. Note; that Clang and LLVM are explicitly version locked so you'll need to make sure; you're using a Clang built from the same git revision or release as the LLVM; library you're using. As always, it's *strongly* recommended that you track; tip of tree development, particularly during bring up of a new project. The Basics; ^^^^^^^^^^^. #. Make sure that your Modules contain both a data layout specification and; target triple. Without these pieces, non of the target specific optimization; will be enabled. This can have a major effect on the generated code quality. #. For each function or global emitted, use the most private linkage type; possible (private, internal or linkonce_odr preferably). Doing so will; make LLVM's inter-procedural optimizations much more effective. #. Avoid high in-degree basic blocks (e.g. basic blocks with dozens or hundreds; of predecessors). Among other issues, the register allocator is known to; perform badly with confronted with suc",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:1506,Performance,optimiz,optimization,1506,"ges in the source IR can have a large effect on the; generated code. Beyond the specific items on the list below, it's worth noting that the most; mature frontend for LLVM is Clang. As a result, the further your IR gets from; what Clang might emit, the less likely it is to be effectively optimized. It; can often be useful to write a quick C program with the semantics you're trying; to model and see what decisions Clang's IRGen makes about what IR to emit.; Studying Clang's CodeGen directory can also be a good source of ideas. Note; that Clang and LLVM are explicitly version locked so you'll need to make sure; you're using a Clang built from the same git revision or release as the LLVM; library you're using. As always, it's *strongly* recommended that you track; tip of tree development, particularly during bring up of a new project. The Basics; ^^^^^^^^^^^. #. Make sure that your Modules contain both a data layout specification and; target triple. Without these pieces, non of the target specific optimization; will be enabled. This can have a major effect on the generated code quality. #. For each function or global emitted, use the most private linkage type; possible (private, internal or linkonce_odr preferably). Doing so will; make LLVM's inter-procedural optimizations much more effective. #. Avoid high in-degree basic blocks (e.g. basic blocks with dozens or hundreds; of predecessors). Among other issues, the register allocator is known to; perform badly with confronted with such structures. The only exception to; this guidance is that a unified return block with high in-degree is fine. Use of allocas; ^^^^^^^^^^^^^^. An alloca instruction can be used to represent a function scoped stack slot,; but can also represent dynamic frame expansion. When representing function; scoped variables or locations, placing alloca instructions at the beginning of; the entry block should be preferred. In particular, place them before any; call instructions. Call instructions might ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:1773,Performance,optimiz,optimizations,1773,"to be effectively optimized. It; can often be useful to write a quick C program with the semantics you're trying; to model and see what decisions Clang's IRGen makes about what IR to emit.; Studying Clang's CodeGen directory can also be a good source of ideas. Note; that Clang and LLVM are explicitly version locked so you'll need to make sure; you're using a Clang built from the same git revision or release as the LLVM; library you're using. As always, it's *strongly* recommended that you track; tip of tree development, particularly during bring up of a new project. The Basics; ^^^^^^^^^^^. #. Make sure that your Modules contain both a data layout specification and; target triple. Without these pieces, non of the target specific optimization; will be enabled. This can have a major effect on the generated code quality. #. For each function or global emitted, use the most private linkage type; possible (private, internal or linkonce_odr preferably). Doing so will; make LLVM's inter-procedural optimizations much more effective. #. Avoid high in-degree basic blocks (e.g. basic blocks with dozens or hundreds; of predecessors). Among other issues, the register allocator is known to; perform badly with confronted with such structures. The only exception to; this guidance is that a unified return block with high in-degree is fine. Use of allocas; ^^^^^^^^^^^^^^. An alloca instruction can be used to represent a function scoped stack slot,; but can also represent dynamic frame expansion. When representing function; scoped variables or locations, placing alloca instructions at the beginning of; the entry block should be preferred. In particular, place them before any; call instructions. Call instructions might get inlined and replaced with; multiple basic blocks. The end result is that a following alloca instruction; would no longer be in the entry basic block afterward. The SROA (Scalar Replacement Of Aggregates) and Mem2Reg passes only attempt; to eliminate alloca instruction",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:1963,Performance,perform,perform,1963,"dying Clang's CodeGen directory can also be a good source of ideas. Note; that Clang and LLVM are explicitly version locked so you'll need to make sure; you're using a Clang built from the same git revision or release as the LLVM; library you're using. As always, it's *strongly* recommended that you track; tip of tree development, particularly during bring up of a new project. The Basics; ^^^^^^^^^^^. #. Make sure that your Modules contain both a data layout specification and; target triple. Without these pieces, non of the target specific optimization; will be enabled. This can have a major effect on the generated code quality. #. For each function or global emitted, use the most private linkage type; possible (private, internal or linkonce_odr preferably). Doing so will; make LLVM's inter-procedural optimizations much more effective. #. Avoid high in-degree basic blocks (e.g. basic blocks with dozens or hundreds; of predecessors). Among other issues, the register allocator is known to; perform badly with confronted with such structures. The only exception to; this guidance is that a unified return block with high in-degree is fine. Use of allocas; ^^^^^^^^^^^^^^. An alloca instruction can be used to represent a function scoped stack slot,; but can also represent dynamic frame expansion. When representing function; scoped variables or locations, placing alloca instructions at the beginning of; the entry block should be preferred. In particular, place them before any; call instructions. Call instructions might get inlined and replaced with; multiple basic blocks. The end result is that a following alloca instruction; would no longer be in the entry basic block afterward. The SROA (Scalar Replacement Of Aggregates) and Mem2Reg passes only attempt; to eliminate alloca instructions that are in the entry basic block. Given; SSA is the canonical form expected by much of the optimizer; if allocas can; not be eliminated by Mem2Reg or SROA, the optimizer is likely to be les",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:2862,Performance,optimiz,optimizer,2862,"cessors). Among other issues, the register allocator is known to; perform badly with confronted with such structures. The only exception to; this guidance is that a unified return block with high in-degree is fine. Use of allocas; ^^^^^^^^^^^^^^. An alloca instruction can be used to represent a function scoped stack slot,; but can also represent dynamic frame expansion. When representing function; scoped variables or locations, placing alloca instructions at the beginning of; the entry block should be preferred. In particular, place them before any; call instructions. Call instructions might get inlined and replaced with; multiple basic blocks. The end result is that a following alloca instruction; would no longer be in the entry basic block afterward. The SROA (Scalar Replacement Of Aggregates) and Mem2Reg passes only attempt; to eliminate alloca instructions that are in the entry basic block. Given; SSA is the canonical form expected by much of the optimizer; if allocas can; not be eliminated by Mem2Reg or SROA, the optimizer is likely to be less; effective than it could be. Avoid loads and stores of large aggregate type; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. LLVM currently does not optimize well loads and stores of large :ref:`aggregate; types <t_aggregate>` (i.e. structs and arrays). As an alternative, consider; loading individual fields from memory. Aggregates that are smaller than the largest (performant) load or store; instruction supported by the targeted hardware are well supported. These can; be an effective way to represent collections of small packed fields. Prefer zext over sext when legal; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. On some architectures (X86_64 is one), sign extension can involve an extra; instruction whereas zero extension can be folded into a load. LLVM will try to; replace a sext with a zext when it can be proven safe, but if you have; information in your source language about the range of an integer value, it can; be profitabl",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:2931,Performance,optimiz,optimizer,2931,"cessors). Among other issues, the register allocator is known to; perform badly with confronted with such structures. The only exception to; this guidance is that a unified return block with high in-degree is fine. Use of allocas; ^^^^^^^^^^^^^^. An alloca instruction can be used to represent a function scoped stack slot,; but can also represent dynamic frame expansion. When representing function; scoped variables or locations, placing alloca instructions at the beginning of; the entry block should be preferred. In particular, place them before any; call instructions. Call instructions might get inlined and replaced with; multiple basic blocks. The end result is that a following alloca instruction; would no longer be in the entry basic block afterward. The SROA (Scalar Replacement Of Aggregates) and Mem2Reg passes only attempt; to eliminate alloca instructions that are in the entry basic block. Given; SSA is the canonical form expected by much of the optimizer; if allocas can; not be eliminated by Mem2Reg or SROA, the optimizer is likely to be less; effective than it could be. Avoid loads and stores of large aggregate type; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. LLVM currently does not optimize well loads and stores of large :ref:`aggregate; types <t_aggregate>` (i.e. structs and arrays). As an alternative, consider; loading individual fields from memory. Aggregates that are smaller than the largest (performant) load or store; instruction supported by the targeted hardware are well supported. These can; be an effective way to represent collections of small packed fields. Prefer zext over sext when legal; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. On some architectures (X86_64 is one), sign extension can involve an extra; instruction whereas zero extension can be folded into a load. LLVM will try to; replace a sext with a zext when it can be proven safe, but if you have; information in your source language about the range of an integer value, it can; be profitabl",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:2997,Performance,load,loads,2997,"his guidance is that a unified return block with high in-degree is fine. Use of allocas; ^^^^^^^^^^^^^^. An alloca instruction can be used to represent a function scoped stack slot,; but can also represent dynamic frame expansion. When representing function; scoped variables or locations, placing alloca instructions at the beginning of; the entry block should be preferred. In particular, place them before any; call instructions. Call instructions might get inlined and replaced with; multiple basic blocks. The end result is that a following alloca instruction; would no longer be in the entry basic block afterward. The SROA (Scalar Replacement Of Aggregates) and Mem2Reg passes only attempt; to eliminate alloca instructions that are in the entry basic block. Given; SSA is the canonical form expected by much of the optimizer; if allocas can; not be eliminated by Mem2Reg or SROA, the optimizer is likely to be less; effective than it could be. Avoid loads and stores of large aggregate type; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. LLVM currently does not optimize well loads and stores of large :ref:`aggregate; types <t_aggregate>` (i.e. structs and arrays). As an alternative, consider; loading individual fields from memory. Aggregates that are smaller than the largest (performant) load or store; instruction supported by the targeted hardware are well supported. These can; be an effective way to represent collections of small packed fields. Prefer zext over sext when legal; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. On some architectures (X86_64 is one), sign extension can involve an extra; instruction whereas zero extension can be folded into a load. LLVM will try to; replace a sext with a zext when it can be proven safe, but if you have; information in your source language about the range of an integer value, it can; be profitable to use a zext rather than a sext. Alternatively, you can :ref:`specify the range of the value using metadata; <range-metadata>` and LLVM can ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:3114,Performance,optimiz,optimize,3114,". An alloca instruction can be used to represent a function scoped stack slot,; but can also represent dynamic frame expansion. When representing function; scoped variables or locations, placing alloca instructions at the beginning of; the entry block should be preferred. In particular, place them before any; call instructions. Call instructions might get inlined and replaced with; multiple basic blocks. The end result is that a following alloca instruction; would no longer be in the entry basic block afterward. The SROA (Scalar Replacement Of Aggregates) and Mem2Reg passes only attempt; to eliminate alloca instructions that are in the entry basic block. Given; SSA is the canonical form expected by much of the optimizer; if allocas can; not be eliminated by Mem2Reg or SROA, the optimizer is likely to be less; effective than it could be. Avoid loads and stores of large aggregate type; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. LLVM currently does not optimize well loads and stores of large :ref:`aggregate; types <t_aggregate>` (i.e. structs and arrays). As an alternative, consider; loading individual fields from memory. Aggregates that are smaller than the largest (performant) load or store; instruction supported by the targeted hardware are well supported. These can; be an effective way to represent collections of small packed fields. Prefer zext over sext when legal; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. On some architectures (X86_64 is one), sign extension can involve an extra; instruction whereas zero extension can be folded into a load. LLVM will try to; replace a sext with a zext when it can be proven safe, but if you have; information in your source language about the range of an integer value, it can; be profitable to use a zext rather than a sext. Alternatively, you can :ref:`specify the range of the value using metadata; <range-metadata>` and LLVM can do the sext to zext conversion for you. Zext GEP indices to machine register width; ^^^^^^^^^^^^^^^^^^",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:3128,Performance,load,loads,3128,". An alloca instruction can be used to represent a function scoped stack slot,; but can also represent dynamic frame expansion. When representing function; scoped variables or locations, placing alloca instructions at the beginning of; the entry block should be preferred. In particular, place them before any; call instructions. Call instructions might get inlined and replaced with; multiple basic blocks. The end result is that a following alloca instruction; would no longer be in the entry basic block afterward. The SROA (Scalar Replacement Of Aggregates) and Mem2Reg passes only attempt; to eliminate alloca instructions that are in the entry basic block. Given; SSA is the canonical form expected by much of the optimizer; if allocas can; not be eliminated by Mem2Reg or SROA, the optimizer is likely to be less; effective than it could be. Avoid loads and stores of large aggregate type; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. LLVM currently does not optimize well loads and stores of large :ref:`aggregate; types <t_aggregate>` (i.e. structs and arrays). As an alternative, consider; loading individual fields from memory. Aggregates that are smaller than the largest (performant) load or store; instruction supported by the targeted hardware are well supported. These can; be an effective way to represent collections of small packed fields. Prefer zext over sext when legal; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. On some architectures (X86_64 is one), sign extension can involve an extra; instruction whereas zero extension can be folded into a load. LLVM will try to; replace a sext with a zext when it can be proven safe, but if you have; information in your source language about the range of an integer value, it can; be profitable to use a zext rather than a sext. Alternatively, you can :ref:`specify the range of the value using metadata; <range-metadata>` and LLVM can do the sext to zext conversion for you. Zext GEP indices to machine register width; ^^^^^^^^^^^^^^^^^^",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:3248,Performance,load,loading,3248," frame expansion. When representing function; scoped variables or locations, placing alloca instructions at the beginning of; the entry block should be preferred. In particular, place them before any; call instructions. Call instructions might get inlined and replaced with; multiple basic blocks. The end result is that a following alloca instruction; would no longer be in the entry basic block afterward. The SROA (Scalar Replacement Of Aggregates) and Mem2Reg passes only attempt; to eliminate alloca instructions that are in the entry basic block. Given; SSA is the canonical form expected by much of the optimizer; if allocas can; not be eliminated by Mem2Reg or SROA, the optimizer is likely to be less; effective than it could be. Avoid loads and stores of large aggregate type; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. LLVM currently does not optimize well loads and stores of large :ref:`aggregate; types <t_aggregate>` (i.e. structs and arrays). As an alternative, consider; loading individual fields from memory. Aggregates that are smaller than the largest (performant) load or store; instruction supported by the targeted hardware are well supported. These can; be an effective way to represent collections of small packed fields. Prefer zext over sext when legal; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. On some architectures (X86_64 is one), sign extension can involve an extra; instruction whereas zero extension can be folded into a load. LLVM will try to; replace a sext with a zext when it can be proven safe, but if you have; information in your source language about the range of an integer value, it can; be profitable to use a zext rather than a sext. Alternatively, you can :ref:`specify the range of the value using metadata; <range-metadata>` and LLVM can do the sext to zext conversion for you. Zext GEP indices to machine register width; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Internally, LLVM often promotes the width of GEP indices to machine register; width",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:3333,Performance,perform,performant,3333," at the beginning of; the entry block should be preferred. In particular, place them before any; call instructions. Call instructions might get inlined and replaced with; multiple basic blocks. The end result is that a following alloca instruction; would no longer be in the entry basic block afterward. The SROA (Scalar Replacement Of Aggregates) and Mem2Reg passes only attempt; to eliminate alloca instructions that are in the entry basic block. Given; SSA is the canonical form expected by much of the optimizer; if allocas can; not be eliminated by Mem2Reg or SROA, the optimizer is likely to be less; effective than it could be. Avoid loads and stores of large aggregate type; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. LLVM currently does not optimize well loads and stores of large :ref:`aggregate; types <t_aggregate>` (i.e. structs and arrays). As an alternative, consider; loading individual fields from memory. Aggregates that are smaller than the largest (performant) load or store; instruction supported by the targeted hardware are well supported. These can; be an effective way to represent collections of small packed fields. Prefer zext over sext when legal; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. On some architectures (X86_64 is one), sign extension can involve an extra; instruction whereas zero extension can be folded into a load. LLVM will try to; replace a sext with a zext when it can be proven safe, but if you have; information in your source language about the range of an integer value, it can; be profitable to use a zext rather than a sext. Alternatively, you can :ref:`specify the range of the value using metadata; <range-metadata>` and LLVM can do the sext to zext conversion for you. Zext GEP indices to machine register width; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Internally, LLVM often promotes the width of GEP indices to machine register; width. When it does so, it will default to using sign extension (sext); operations for safety. If your source",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:3345,Performance,load,load,3345," at the beginning of; the entry block should be preferred. In particular, place them before any; call instructions. Call instructions might get inlined and replaced with; multiple basic blocks. The end result is that a following alloca instruction; would no longer be in the entry basic block afterward. The SROA (Scalar Replacement Of Aggregates) and Mem2Reg passes only attempt; to eliminate alloca instructions that are in the entry basic block. Given; SSA is the canonical form expected by much of the optimizer; if allocas can; not be eliminated by Mem2Reg or SROA, the optimizer is likely to be less; effective than it could be. Avoid loads and stores of large aggregate type; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. LLVM currently does not optimize well loads and stores of large :ref:`aggregate; types <t_aggregate>` (i.e. structs and arrays). As an alternative, consider; loading individual fields from memory. Aggregates that are smaller than the largest (performant) load or store; instruction supported by the targeted hardware are well supported. These can; be an effective way to represent collections of small packed fields. Prefer zext over sext when legal; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. On some architectures (X86_64 is one), sign extension can involve an extra; instruction whereas zero extension can be folded into a load. LLVM will try to; replace a sext with a zext when it can be proven safe, but if you have; information in your source language about the range of an integer value, it can; be profitable to use a zext rather than a sext. Alternatively, you can :ref:`specify the range of the value using metadata; <range-metadata>` and LLVM can do the sext to zext conversion for you. Zext GEP indices to machine register width; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Internally, LLVM often promotes the width of GEP indices to machine register; width. When it does so, it will default to using sign extension (sext); operations for safety. If your source",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:3708,Performance,load,load,3708,"lock afterward. The SROA (Scalar Replacement Of Aggregates) and Mem2Reg passes only attempt; to eliminate alloca instructions that are in the entry basic block. Given; SSA is the canonical form expected by much of the optimizer; if allocas can; not be eliminated by Mem2Reg or SROA, the optimizer is likely to be less; effective than it could be. Avoid loads and stores of large aggregate type; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. LLVM currently does not optimize well loads and stores of large :ref:`aggregate; types <t_aggregate>` (i.e. structs and arrays). As an alternative, consider; loading individual fields from memory. Aggregates that are smaller than the largest (performant) load or store; instruction supported by the targeted hardware are well supported. These can; be an effective way to represent collections of small packed fields. Prefer zext over sext when legal; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. On some architectures (X86_64 is one), sign extension can involve an extra; instruction whereas zero extension can be folded into a load. LLVM will try to; replace a sext with a zext when it can be proven safe, but if you have; information in your source language about the range of an integer value, it can; be profitable to use a zext rather than a sext. Alternatively, you can :ref:`specify the range of the value using metadata; <range-metadata>` and LLVM can do the sext to zext conversion for you. Zext GEP indices to machine register width; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Internally, LLVM often promotes the width of GEP indices to machine register; width. When it does so, it will default to using sign extension (sext); operations for safety. If your source language provides information about; the range of the index, you may wish to manually extend indices to machine; register width using a zext instruction. When to specify alignment; ^^^^^^^^^^^^^^^^^^^^^^^^^^; LLVM will always generate correct code if you don’t specify alignment, but may",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:4777,Performance,load,loads,4777,"but if you have; information in your source language about the range of an integer value, it can; be profitable to use a zext rather than a sext. Alternatively, you can :ref:`specify the range of the value using metadata; <range-metadata>` and LLVM can do the sext to zext conversion for you. Zext GEP indices to machine register width; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Internally, LLVM often promotes the width of GEP indices to machine register; width. When it does so, it will default to using sign extension (sext); operations for safety. If your source language provides information about; the range of the index, you may wish to manually extend indices to machine; register width using a zext instruction. When to specify alignment; ^^^^^^^^^^^^^^^^^^^^^^^^^^; LLVM will always generate correct code if you don’t specify alignment, but may; generate inefficient code. For example, if you are targeting MIPS (or older; ARM ISAs) then the hardware does not handle unaligned loads and stores, and; so you will enter a trap-and-emulate path if you do a load or store with; lower-than-natural alignment. To avoid this, LLVM will emit a slower; sequence of loads, shifts and masks (or load-right + load-left on MIPS) for; all cases where the load / store does not have a sufficiently high alignment; in the IR. The alignment is used to guarantee the alignment on allocas and globals,; though in most cases this is unnecessary (most targets have a sufficiently; high default alignment that they’ll be fine). It is also used to provide a; contract to the back end saying ‘either this load/store has this alignment, or; it is undefined behavior’. This means that the back end is free to emit; instructions that rely on that alignment (and mid-level optimizers are free to; perform transforms that require that alignment). For x86, it doesn’t make; much difference, as almost all instructions are alignment-independent. For; MIPS, it can make a big difference. Note that if your loads and stor",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:4854,Performance,load,load,4854,"but if you have; information in your source language about the range of an integer value, it can; be profitable to use a zext rather than a sext. Alternatively, you can :ref:`specify the range of the value using metadata; <range-metadata>` and LLVM can do the sext to zext conversion for you. Zext GEP indices to machine register width; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Internally, LLVM often promotes the width of GEP indices to machine register; width. When it does so, it will default to using sign extension (sext); operations for safety. If your source language provides information about; the range of the index, you may wish to manually extend indices to machine; register width using a zext instruction. When to specify alignment; ^^^^^^^^^^^^^^^^^^^^^^^^^^; LLVM will always generate correct code if you don’t specify alignment, but may; generate inefficient code. For example, if you are targeting MIPS (or older; ARM ISAs) then the hardware does not handle unaligned loads and stores, and; so you will enter a trap-and-emulate path if you do a load or store with; lower-than-natural alignment. To avoid this, LLVM will emit a slower; sequence of loads, shifts and masks (or load-right + load-left on MIPS) for; all cases where the load / store does not have a sufficiently high alignment; in the IR. The alignment is used to guarantee the alignment on allocas and globals,; though in most cases this is unnecessary (most targets have a sufficiently; high default alignment that they’ll be fine). It is also used to provide a; contract to the back end saying ‘either this load/store has this alignment, or; it is undefined behavior’. This means that the back end is free to emit; instructions that rely on that alignment (and mid-level optimizers are free to; perform transforms that require that alignment). For x86, it doesn’t make; much difference, as almost all instructions are alignment-independent. For; MIPS, it can make a big difference. Note that if your loads and stor",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:4956,Performance,load,loads,4956,"a; <range-metadata>` and LLVM can do the sext to zext conversion for you. Zext GEP indices to machine register width; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Internally, LLVM often promotes the width of GEP indices to machine register; width. When it does so, it will default to using sign extension (sext); operations for safety. If your source language provides information about; the range of the index, you may wish to manually extend indices to machine; register width using a zext instruction. When to specify alignment; ^^^^^^^^^^^^^^^^^^^^^^^^^^; LLVM will always generate correct code if you don’t specify alignment, but may; generate inefficient code. For example, if you are targeting MIPS (or older; ARM ISAs) then the hardware does not handle unaligned loads and stores, and; so you will enter a trap-and-emulate path if you do a load or store with; lower-than-natural alignment. To avoid this, LLVM will emit a slower; sequence of loads, shifts and masks (or load-right + load-left on MIPS) for; all cases where the load / store does not have a sufficiently high alignment; in the IR. The alignment is used to guarantee the alignment on allocas and globals,; though in most cases this is unnecessary (most targets have a sufficiently; high default alignment that they’ll be fine). It is also used to provide a; contract to the back end saying ‘either this load/store has this alignment, or; it is undefined behavior’. This means that the back end is free to emit; instructions that rely on that alignment (and mid-level optimizers are free to; perform transforms that require that alignment). For x86, it doesn’t make; much difference, as almost all instructions are alignment-independent. For; MIPS, it can make a big difference. Note that if your loads and stores are atomic, the backend will be unable to; lower an under aligned access into a sequence of natively aligned accesses.; As a result, alignment is mandatory for atomic loads and stores. Other Things to Consider; ^^^^",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:4984,Performance,load,load-right,4984,"a; <range-metadata>` and LLVM can do the sext to zext conversion for you. Zext GEP indices to machine register width; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Internally, LLVM often promotes the width of GEP indices to machine register; width. When it does so, it will default to using sign extension (sext); operations for safety. If your source language provides information about; the range of the index, you may wish to manually extend indices to machine; register width using a zext instruction. When to specify alignment; ^^^^^^^^^^^^^^^^^^^^^^^^^^; LLVM will always generate correct code if you don’t specify alignment, but may; generate inefficient code. For example, if you are targeting MIPS (or older; ARM ISAs) then the hardware does not handle unaligned loads and stores, and; so you will enter a trap-and-emulate path if you do a load or store with; lower-than-natural alignment. To avoid this, LLVM will emit a slower; sequence of loads, shifts and masks (or load-right + load-left on MIPS) for; all cases where the load / store does not have a sufficiently high alignment; in the IR. The alignment is used to guarantee the alignment on allocas and globals,; though in most cases this is unnecessary (most targets have a sufficiently; high default alignment that they’ll be fine). It is also used to provide a; contract to the back end saying ‘either this load/store has this alignment, or; it is undefined behavior’. This means that the back end is free to emit; instructions that rely on that alignment (and mid-level optimizers are free to; perform transforms that require that alignment). For x86, it doesn’t make; much difference, as almost all instructions are alignment-independent. For; MIPS, it can make a big difference. Note that if your loads and stores are atomic, the backend will be unable to; lower an under aligned access into a sequence of natively aligned accesses.; As a result, alignment is mandatory for atomic loads and stores. Other Things to Consider; ^^^^",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:4997,Performance,load,load-left,4997,"a; <range-metadata>` and LLVM can do the sext to zext conversion for you. Zext GEP indices to machine register width; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Internally, LLVM often promotes the width of GEP indices to machine register; width. When it does so, it will default to using sign extension (sext); operations for safety. If your source language provides information about; the range of the index, you may wish to manually extend indices to machine; register width using a zext instruction. When to specify alignment; ^^^^^^^^^^^^^^^^^^^^^^^^^^; LLVM will always generate correct code if you don’t specify alignment, but may; generate inefficient code. For example, if you are targeting MIPS (or older; ARM ISAs) then the hardware does not handle unaligned loads and stores, and; so you will enter a trap-and-emulate path if you do a load or store with; lower-than-natural alignment. To avoid this, LLVM will emit a slower; sequence of loads, shifts and masks (or load-right + load-left on MIPS) for; all cases where the load / store does not have a sufficiently high alignment; in the IR. The alignment is used to guarantee the alignment on allocas and globals,; though in most cases this is unnecessary (most targets have a sufficiently; high default alignment that they’ll be fine). It is also used to provide a; contract to the back end saying ‘either this load/store has this alignment, or; it is undefined behavior’. This means that the back end is free to emit; instructions that rely on that alignment (and mid-level optimizers are free to; perform transforms that require that alignment). For x86, it doesn’t make; much difference, as almost all instructions are alignment-independent. For; MIPS, it can make a big difference. Note that if your loads and stores are atomic, the backend will be unable to; lower an under aligned access into a sequence of natively aligned accesses.; As a result, alignment is mandatory for atomic loads and stores. Other Things to Consider; ^^^^",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:5041,Performance,load,load,5041,"a; <range-metadata>` and LLVM can do the sext to zext conversion for you. Zext GEP indices to machine register width; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Internally, LLVM often promotes the width of GEP indices to machine register; width. When it does so, it will default to using sign extension (sext); operations for safety. If your source language provides information about; the range of the index, you may wish to manually extend indices to machine; register width using a zext instruction. When to specify alignment; ^^^^^^^^^^^^^^^^^^^^^^^^^^; LLVM will always generate correct code if you don’t specify alignment, but may; generate inefficient code. For example, if you are targeting MIPS (or older; ARM ISAs) then the hardware does not handle unaligned loads and stores, and; so you will enter a trap-and-emulate path if you do a load or store with; lower-than-natural alignment. To avoid this, LLVM will emit a slower; sequence of loads, shifts and masks (or load-right + load-left on MIPS) for; all cases where the load / store does not have a sufficiently high alignment; in the IR. The alignment is used to guarantee the alignment on allocas and globals,; though in most cases this is unnecessary (most targets have a sufficiently; high default alignment that they’ll be fine). It is also used to provide a; contract to the back end saying ‘either this load/store has this alignment, or; it is undefined behavior’. This means that the back end is free to emit; instructions that rely on that alignment (and mid-level optimizers are free to; perform transforms that require that alignment). For x86, it doesn’t make; much difference, as almost all instructions are alignment-independent. For; MIPS, it can make a big difference. Note that if your loads and stores are atomic, the backend will be unable to; lower an under aligned access into a sequence of natively aligned accesses.; As a result, alignment is mandatory for atomic loads and stores. Other Things to Consider; ^^^^",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:5381,Performance,load,load,5381,"s information about; the range of the index, you may wish to manually extend indices to machine; register width using a zext instruction. When to specify alignment; ^^^^^^^^^^^^^^^^^^^^^^^^^^; LLVM will always generate correct code if you don’t specify alignment, but may; generate inefficient code. For example, if you are targeting MIPS (or older; ARM ISAs) then the hardware does not handle unaligned loads and stores, and; so you will enter a trap-and-emulate path if you do a load or store with; lower-than-natural alignment. To avoid this, LLVM will emit a slower; sequence of loads, shifts and masks (or load-right + load-left on MIPS) for; all cases where the load / store does not have a sufficiently high alignment; in the IR. The alignment is used to guarantee the alignment on allocas and globals,; though in most cases this is unnecessary (most targets have a sufficiently; high default alignment that they’ll be fine). It is also used to provide a; contract to the back end saying ‘either this load/store has this alignment, or; it is undefined behavior’. This means that the back end is free to emit; instructions that rely on that alignment (and mid-level optimizers are free to; perform transforms that require that alignment). For x86, it doesn’t make; much difference, as almost all instructions are alignment-independent. For; MIPS, it can make a big difference. Note that if your loads and stores are atomic, the backend will be unable to; lower an under aligned access into a sequence of natively aligned accesses.; As a result, alignment is mandatory for atomic loads and stores. Other Things to Consider; ^^^^^^^^^^^^^^^^^^^^^^^^. #. Use ptrtoint/inttoptr sparingly (they interfere with pointer aliasing; analysis), prefer GEPs. #. Prefer globals over inttoptr of a constant address - this gives you; dereferencability information. In MCJIT, use getSymbolAddress to provide; actual address. #. Be wary of ordered and atomic memory operations. They are hard to optimize; and may",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:5545,Performance,optimiz,optimizers,5545,"ignment; ^^^^^^^^^^^^^^^^^^^^^^^^^^; LLVM will always generate correct code if you don’t specify alignment, but may; generate inefficient code. For example, if you are targeting MIPS (or older; ARM ISAs) then the hardware does not handle unaligned loads and stores, and; so you will enter a trap-and-emulate path if you do a load or store with; lower-than-natural alignment. To avoid this, LLVM will emit a slower; sequence of loads, shifts and masks (or load-right + load-left on MIPS) for; all cases where the load / store does not have a sufficiently high alignment; in the IR. The alignment is used to guarantee the alignment on allocas and globals,; though in most cases this is unnecessary (most targets have a sufficiently; high default alignment that they’ll be fine). It is also used to provide a; contract to the back end saying ‘either this load/store has this alignment, or; it is undefined behavior’. This means that the back end is free to emit; instructions that rely on that alignment (and mid-level optimizers are free to; perform transforms that require that alignment). For x86, it doesn’t make; much difference, as almost all instructions are alignment-independent. For; MIPS, it can make a big difference. Note that if your loads and stores are atomic, the backend will be unable to; lower an under aligned access into a sequence of natively aligned accesses.; As a result, alignment is mandatory for atomic loads and stores. Other Things to Consider; ^^^^^^^^^^^^^^^^^^^^^^^^. #. Use ptrtoint/inttoptr sparingly (they interfere with pointer aliasing; analysis), prefer GEPs. #. Prefer globals over inttoptr of a constant address - this gives you; dereferencability information. In MCJIT, use getSymbolAddress to provide; actual address. #. Be wary of ordered and atomic memory operations. They are hard to optimize; and may not be well optimized by the current optimizer. Depending on your; source language, you may consider using fences instead. #. If calling a function which i",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:5569,Performance,perform,perform,5569,"ignment; ^^^^^^^^^^^^^^^^^^^^^^^^^^; LLVM will always generate correct code if you don’t specify alignment, but may; generate inefficient code. For example, if you are targeting MIPS (or older; ARM ISAs) then the hardware does not handle unaligned loads and stores, and; so you will enter a trap-and-emulate path if you do a load or store with; lower-than-natural alignment. To avoid this, LLVM will emit a slower; sequence of loads, shifts and masks (or load-right + load-left on MIPS) for; all cases where the load / store does not have a sufficiently high alignment; in the IR. The alignment is used to guarantee the alignment on allocas and globals,; though in most cases this is unnecessary (most targets have a sufficiently; high default alignment that they’ll be fine). It is also used to provide a; contract to the back end saying ‘either this load/store has this alignment, or; it is undefined behavior’. This means that the back end is free to emit; instructions that rely on that alignment (and mid-level optimizers are free to; perform transforms that require that alignment). For x86, it doesn’t make; much difference, as almost all instructions are alignment-independent. For; MIPS, it can make a big difference. Note that if your loads and stores are atomic, the backend will be unable to; lower an under aligned access into a sequence of natively aligned accesses.; As a result, alignment is mandatory for atomic loads and stores. Other Things to Consider; ^^^^^^^^^^^^^^^^^^^^^^^^. #. Use ptrtoint/inttoptr sparingly (they interfere with pointer aliasing; analysis), prefer GEPs. #. Prefer globals over inttoptr of a constant address - this gives you; dereferencability information. In MCJIT, use getSymbolAddress to provide; actual address. #. Be wary of ordered and atomic memory operations. They are hard to optimize; and may not be well optimized by the current optimizer. Depending on your; source language, you may consider using fences instead. #. If calling a function which i",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:5774,Performance,load,loads,5774,"late path if you do a load or store with; lower-than-natural alignment. To avoid this, LLVM will emit a slower; sequence of loads, shifts and masks (or load-right + load-left on MIPS) for; all cases where the load / store does not have a sufficiently high alignment; in the IR. The alignment is used to guarantee the alignment on allocas and globals,; though in most cases this is unnecessary (most targets have a sufficiently; high default alignment that they’ll be fine). It is also used to provide a; contract to the back end saying ‘either this load/store has this alignment, or; it is undefined behavior’. This means that the back end is free to emit; instructions that rely on that alignment (and mid-level optimizers are free to; perform transforms that require that alignment). For x86, it doesn’t make; much difference, as almost all instructions are alignment-independent. For; MIPS, it can make a big difference. Note that if your loads and stores are atomic, the backend will be unable to; lower an under aligned access into a sequence of natively aligned accesses.; As a result, alignment is mandatory for atomic loads and stores. Other Things to Consider; ^^^^^^^^^^^^^^^^^^^^^^^^. #. Use ptrtoint/inttoptr sparingly (they interfere with pointer aliasing; analysis), prefer GEPs. #. Prefer globals over inttoptr of a constant address - this gives you; dereferencability information. In MCJIT, use getSymbolAddress to provide; actual address. #. Be wary of ordered and atomic memory operations. They are hard to optimize; and may not be well optimized by the current optimizer. Depending on your; source language, you may consider using fences instead. #. If calling a function which is known to throw an exception (unwind), use; an invoke with a normal destination which contains an unreachable; instruction. This form conveys to the optimizer that the call returns; abnormally. For an invoke which neither returns normally or requires unwind; code in the current function, you can use ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:5958,Performance,load,loads,5958,"; sequence of loads, shifts and masks (or load-right + load-left on MIPS) for; all cases where the load / store does not have a sufficiently high alignment; in the IR. The alignment is used to guarantee the alignment on allocas and globals,; though in most cases this is unnecessary (most targets have a sufficiently; high default alignment that they’ll be fine). It is also used to provide a; contract to the back end saying ‘either this load/store has this alignment, or; it is undefined behavior’. This means that the back end is free to emit; instructions that rely on that alignment (and mid-level optimizers are free to; perform transforms that require that alignment). For x86, it doesn’t make; much difference, as almost all instructions are alignment-independent. For; MIPS, it can make a big difference. Note that if your loads and stores are atomic, the backend will be unable to; lower an under aligned access into a sequence of natively aligned accesses.; As a result, alignment is mandatory for atomic loads and stores. Other Things to Consider; ^^^^^^^^^^^^^^^^^^^^^^^^. #. Use ptrtoint/inttoptr sparingly (they interfere with pointer aliasing; analysis), prefer GEPs. #. Prefer globals over inttoptr of a constant address - this gives you; dereferencability information. In MCJIT, use getSymbolAddress to provide; actual address. #. Be wary of ordered and atomic memory operations. They are hard to optimize; and may not be well optimized by the current optimizer. Depending on your; source language, you may consider using fences instead. #. If calling a function which is known to throw an exception (unwind), use; an invoke with a normal destination which contains an unreachable; instruction. This form conveys to the optimizer that the call returns; abnormally. For an invoke which neither returns normally or requires unwind; code in the current function, you can use a noreturn call instruction if; desired. This is generally not required because the optimizer will convert; an",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:6357,Performance,optimiz,optimize,6357," load/store has this alignment, or; it is undefined behavior’. This means that the back end is free to emit; instructions that rely on that alignment (and mid-level optimizers are free to; perform transforms that require that alignment). For x86, it doesn’t make; much difference, as almost all instructions are alignment-independent. For; MIPS, it can make a big difference. Note that if your loads and stores are atomic, the backend will be unable to; lower an under aligned access into a sequence of natively aligned accesses.; As a result, alignment is mandatory for atomic loads and stores. Other Things to Consider; ^^^^^^^^^^^^^^^^^^^^^^^^. #. Use ptrtoint/inttoptr sparingly (they interfere with pointer aliasing; analysis), prefer GEPs. #. Prefer globals over inttoptr of a constant address - this gives you; dereferencability information. In MCJIT, use getSymbolAddress to provide; actual address. #. Be wary of ordered and atomic memory operations. They are hard to optimize; and may not be well optimized by the current optimizer. Depending on your; source language, you may consider using fences instead. #. If calling a function which is known to throw an exception (unwind), use; an invoke with a normal destination which contains an unreachable; instruction. This form conveys to the optimizer that the call returns; abnormally. For an invoke which neither returns normally or requires unwind; code in the current function, you can use a noreturn call instruction if; desired. This is generally not required because the optimizer will convert; an invoke with an unreachable unwind destination to a call instruction. #. Use profile metadata to indicate statically known cold paths, even if; dynamic profiling information is not available. This can make a large; difference in code placement and thus the performance of tight loops. #. When generating code for loops, try to avoid terminating the header block of; the loop earlier than necessary. If the terminator of the loop header; bl",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:6387,Performance,optimiz,optimized,6387," load/store has this alignment, or; it is undefined behavior’. This means that the back end is free to emit; instructions that rely on that alignment (and mid-level optimizers are free to; perform transforms that require that alignment). For x86, it doesn’t make; much difference, as almost all instructions are alignment-independent. For; MIPS, it can make a big difference. Note that if your loads and stores are atomic, the backend will be unable to; lower an under aligned access into a sequence of natively aligned accesses.; As a result, alignment is mandatory for atomic loads and stores. Other Things to Consider; ^^^^^^^^^^^^^^^^^^^^^^^^. #. Use ptrtoint/inttoptr sparingly (they interfere with pointer aliasing; analysis), prefer GEPs. #. Prefer globals over inttoptr of a constant address - this gives you; dereferencability information. In MCJIT, use getSymbolAddress to provide; actual address. #. Be wary of ordered and atomic memory operations. They are hard to optimize; and may not be well optimized by the current optimizer. Depending on your; source language, you may consider using fences instead. #. If calling a function which is known to throw an exception (unwind), use; an invoke with a normal destination which contains an unreachable; instruction. This form conveys to the optimizer that the call returns; abnormally. For an invoke which neither returns normally or requires unwind; code in the current function, you can use a noreturn call instruction if; desired. This is generally not required because the optimizer will convert; an invoke with an unreachable unwind destination to a call instruction. #. Use profile metadata to indicate statically known cold paths, even if; dynamic profiling information is not available. This can make a large; difference in code placement and thus the performance of tight loops. #. When generating code for loops, try to avoid terminating the header block of; the loop earlier than necessary. If the terminator of the loop header; bl",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:6412,Performance,optimiz,optimizer,6412," load/store has this alignment, or; it is undefined behavior’. This means that the back end is free to emit; instructions that rely on that alignment (and mid-level optimizers are free to; perform transforms that require that alignment). For x86, it doesn’t make; much difference, as almost all instructions are alignment-independent. For; MIPS, it can make a big difference. Note that if your loads and stores are atomic, the backend will be unable to; lower an under aligned access into a sequence of natively aligned accesses.; As a result, alignment is mandatory for atomic loads and stores. Other Things to Consider; ^^^^^^^^^^^^^^^^^^^^^^^^. #. Use ptrtoint/inttoptr sparingly (they interfere with pointer aliasing; analysis), prefer GEPs. #. Prefer globals over inttoptr of a constant address - this gives you; dereferencability information. In MCJIT, use getSymbolAddress to provide; actual address. #. Be wary of ordered and atomic memory operations. They are hard to optimize; and may not be well optimized by the current optimizer. Depending on your; source language, you may consider using fences instead. #. If calling a function which is known to throw an exception (unwind), use; an invoke with a normal destination which contains an unreachable; instruction. This form conveys to the optimizer that the call returns; abnormally. For an invoke which neither returns normally or requires unwind; code in the current function, you can use a noreturn call instruction if; desired. This is generally not required because the optimizer will convert; an invoke with an unreachable unwind destination to a call instruction. #. Use profile metadata to indicate statically known cold paths, even if; dynamic profiling information is not available. This can make a large; difference in code placement and thus the performance of tight loops. #. When generating code for loops, try to avoid terminating the header block of; the loop earlier than necessary. If the terminator of the loop header; bl",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:6680,Performance,optimiz,optimizer,6680,"re alignment-independent. For; MIPS, it can make a big difference. Note that if your loads and stores are atomic, the backend will be unable to; lower an under aligned access into a sequence of natively aligned accesses.; As a result, alignment is mandatory for atomic loads and stores. Other Things to Consider; ^^^^^^^^^^^^^^^^^^^^^^^^. #. Use ptrtoint/inttoptr sparingly (they interfere with pointer aliasing; analysis), prefer GEPs. #. Prefer globals over inttoptr of a constant address - this gives you; dereferencability information. In MCJIT, use getSymbolAddress to provide; actual address. #. Be wary of ordered and atomic memory operations. They are hard to optimize; and may not be well optimized by the current optimizer. Depending on your; source language, you may consider using fences instead. #. If calling a function which is known to throw an exception (unwind), use; an invoke with a normal destination which contains an unreachable; instruction. This form conveys to the optimizer that the call returns; abnormally. For an invoke which neither returns normally or requires unwind; code in the current function, you can use a noreturn call instruction if; desired. This is generally not required because the optimizer will convert; an invoke with an unreachable unwind destination to a call instruction. #. Use profile metadata to indicate statically known cold paths, even if; dynamic profiling information is not available. This can make a large; difference in code placement and thus the performance of tight loops. #. When generating code for loops, try to avoid terminating the header block of; the loop earlier than necessary. If the terminator of the loop header; block is a loop exiting conditional branch, the effectiveness of LICM will; be limited for loads not in the header. (This is due to the fact that LLVM; may not know such a load is safe to speculatively execute and thus can't; lift an otherwise loop invariant load unless it can prove the exiting; condition is ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:6916,Performance,optimiz,optimizer,6916,"atory for atomic loads and stores. Other Things to Consider; ^^^^^^^^^^^^^^^^^^^^^^^^. #. Use ptrtoint/inttoptr sparingly (they interfere with pointer aliasing; analysis), prefer GEPs. #. Prefer globals over inttoptr of a constant address - this gives you; dereferencability information. In MCJIT, use getSymbolAddress to provide; actual address. #. Be wary of ordered and atomic memory operations. They are hard to optimize; and may not be well optimized by the current optimizer. Depending on your; source language, you may consider using fences instead. #. If calling a function which is known to throw an exception (unwind), use; an invoke with a normal destination which contains an unreachable; instruction. This form conveys to the optimizer that the call returns; abnormally. For an invoke which neither returns normally or requires unwind; code in the current function, you can use a noreturn call instruction if; desired. This is generally not required because the optimizer will convert; an invoke with an unreachable unwind destination to a call instruction. #. Use profile metadata to indicate statically known cold paths, even if; dynamic profiling information is not available. This can make a large; difference in code placement and thus the performance of tight loops. #. When generating code for loops, try to avoid terminating the header block of; the loop earlier than necessary. If the terminator of the loop header; block is a loop exiting conditional branch, the effectiveness of LICM will; be limited for loads not in the header. (This is due to the fact that LLVM; may not know such a load is safe to speculatively execute and thus can't; lift an otherwise loop invariant load unless it can prove the exiting; condition is not taken.) It can be profitable, in some cases, to emit such; instructions into the header even if they are not used along a rarely; executed path that exits the loop. This guidance specifically does not; apply if the condition which terminates the loo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:7199,Performance,perform,performance,7199," - this gives you; dereferencability information. In MCJIT, use getSymbolAddress to provide; actual address. #. Be wary of ordered and atomic memory operations. They are hard to optimize; and may not be well optimized by the current optimizer. Depending on your; source language, you may consider using fences instead. #. If calling a function which is known to throw an exception (unwind), use; an invoke with a normal destination which contains an unreachable; instruction. This form conveys to the optimizer that the call returns; abnormally. For an invoke which neither returns normally or requires unwind; code in the current function, you can use a noreturn call instruction if; desired. This is generally not required because the optimizer will convert; an invoke with an unreachable unwind destination to a call instruction. #. Use profile metadata to indicate statically known cold paths, even if; dynamic profiling information is not available. This can make a large; difference in code placement and thus the performance of tight loops. #. When generating code for loops, try to avoid terminating the header block of; the loop earlier than necessary. If the terminator of the loop header; block is a loop exiting conditional branch, the effectiveness of LICM will; be limited for loads not in the header. (This is due to the fact that LLVM; may not know such a load is safe to speculatively execute and thus can't; lift an otherwise loop invariant load unless it can prove the exiting; condition is not taken.) It can be profitable, in some cases, to emit such; instructions into the header even if they are not used along a rarely; executed path that exits the loop. This guidance specifically does not; apply if the condition which terminates the loop header is itself invariant,; or can be easily discharged by inspecting the loop index variables. #. In hot loops, consider duplicating instructions from small basic blocks; which end in highly predictable terminators into their successo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:7470,Performance,load,loads,7470,"izer. Depending on your; source language, you may consider using fences instead. #. If calling a function which is known to throw an exception (unwind), use; an invoke with a normal destination which contains an unreachable; instruction. This form conveys to the optimizer that the call returns; abnormally. For an invoke which neither returns normally or requires unwind; code in the current function, you can use a noreturn call instruction if; desired. This is generally not required because the optimizer will convert; an invoke with an unreachable unwind destination to a call instruction. #. Use profile metadata to indicate statically known cold paths, even if; dynamic profiling information is not available. This can make a large; difference in code placement and thus the performance of tight loops. #. When generating code for loops, try to avoid terminating the header block of; the loop earlier than necessary. If the terminator of the loop header; block is a loop exiting conditional branch, the effectiveness of LICM will; be limited for loads not in the header. (This is due to the fact that LLVM; may not know such a load is safe to speculatively execute and thus can't; lift an otherwise loop invariant load unless it can prove the exiting; condition is not taken.) It can be profitable, in some cases, to emit such; instructions into the header even if they are not used along a rarely; executed path that exits the loop. This guidance specifically does not; apply if the condition which terminates the loop header is itself invariant,; or can be easily discharged by inspecting the loop index variables. #. In hot loops, consider duplicating instructions from small basic blocks; which end in highly predictable terminators into their successor blocks.; If a hot successor block contains instructions which can be vectorized; with the duplicated ones, this can provide a noticeable throughput; improvement. Note that this is not always profitable and does involve a; potentially l",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:7551,Performance,load,load,7551,"al destination which contains an unreachable; instruction. This form conveys to the optimizer that the call returns; abnormally. For an invoke which neither returns normally or requires unwind; code in the current function, you can use a noreturn call instruction if; desired. This is generally not required because the optimizer will convert; an invoke with an unreachable unwind destination to a call instruction. #. Use profile metadata to indicate statically known cold paths, even if; dynamic profiling information is not available. This can make a large; difference in code placement and thus the performance of tight loops. #. When generating code for loops, try to avoid terminating the header block of; the loop earlier than necessary. If the terminator of the loop header; block is a loop exiting conditional branch, the effectiveness of LICM will; be limited for loads not in the header. (This is due to the fact that LLVM; may not know such a load is safe to speculatively execute and thus can't; lift an otherwise loop invariant load unless it can prove the exiting; condition is not taken.) It can be profitable, in some cases, to emit such; instructions into the header even if they are not used along a rarely; executed path that exits the loop. This guidance specifically does not; apply if the condition which terminates the loop header is itself invariant,; or can be easily discharged by inspecting the loop index variables. #. In hot loops, consider duplicating instructions from small basic blocks; which end in highly predictable terminators into their successor blocks.; If a hot successor block contains instructions which can be vectorized; with the duplicated ones, this can provide a noticeable throughput; improvement. Note that this is not always profitable and does involve a; potentially large increase in code size. #. When checking a value against a constant, emit the check using a consistent; comparison type. The GVN pass *will* optimize redundant equalities even ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:7638,Performance,load,load,7638,"al destination which contains an unreachable; instruction. This form conveys to the optimizer that the call returns; abnormally. For an invoke which neither returns normally or requires unwind; code in the current function, you can use a noreturn call instruction if; desired. This is generally not required because the optimizer will convert; an invoke with an unreachable unwind destination to a call instruction. #. Use profile metadata to indicate statically known cold paths, even if; dynamic profiling information is not available. This can make a large; difference in code placement and thus the performance of tight loops. #. When generating code for loops, try to avoid terminating the header block of; the loop earlier than necessary. If the terminator of the loop header; block is a loop exiting conditional branch, the effectiveness of LICM will; be limited for loads not in the header. (This is due to the fact that LLVM; may not know such a load is safe to speculatively execute and thus can't; lift an otherwise loop invariant load unless it can prove the exiting; condition is not taken.) It can be profitable, in some cases, to emit such; instructions into the header even if they are not used along a rarely; executed path that exits the loop. This guidance specifically does not; apply if the condition which terminates the loop header is itself invariant,; or can be easily discharged by inspecting the loop index variables. #. In hot loops, consider duplicating instructions from small basic blocks; which end in highly predictable terminators into their successor blocks.; If a hot successor block contains instructions which can be vectorized; with the duplicated ones, this can provide a noticeable throughput; improvement. Note that this is not always profitable and does involve a; potentially large increase in code size. #. When checking a value against a constant, emit the check using a consistent; comparison type. The GVN pass *will* optimize redundant equalities even ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:8319,Performance,throughput,throughput,8319,"to avoid terminating the header block of; the loop earlier than necessary. If the terminator of the loop header; block is a loop exiting conditional branch, the effectiveness of LICM will; be limited for loads not in the header. (This is due to the fact that LLVM; may not know such a load is safe to speculatively execute and thus can't; lift an otherwise loop invariant load unless it can prove the exiting; condition is not taken.) It can be profitable, in some cases, to emit such; instructions into the header even if they are not used along a rarely; executed path that exits the loop. This guidance specifically does not; apply if the condition which terminates the loop header is itself invariant,; or can be easily discharged by inspecting the loop index variables. #. In hot loops, consider duplicating instructions from small basic blocks; which end in highly predictable terminators into their successor blocks.; If a hot successor block contains instructions which can be vectorized; with the duplicated ones, this can provide a noticeable throughput; improvement. Note that this is not always profitable and does involve a; potentially large increase in code size. #. When checking a value against a constant, emit the check using a consistent; comparison type. The GVN pass *will* optimize redundant equalities even if; the type of comparison is inverted, but GVN only runs late in the pipeline.; As a result, you may miss the opportunity to run other important; optimizations. #. Avoid using arithmetic intrinsics unless you are *required* by your source; language specification to emit a particular code sequence. The optimizer; is quite good at reasoning about general control flow and arithmetic, it is; not anywhere near as strong at reasoning about the various intrinsics. If; profitable for code generation purposes, the optimizer will likely form the; intrinsics itself late in the optimization pipeline. It is *very* rarely; profitable to emit these directly in the language f",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:8562,Performance,optimiz,optimize,8562,"t an otherwise loop invariant load unless it can prove the exiting; condition is not taken.) It can be profitable, in some cases, to emit such; instructions into the header even if they are not used along a rarely; executed path that exits the loop. This guidance specifically does not; apply if the condition which terminates the loop header is itself invariant,; or can be easily discharged by inspecting the loop index variables. #. In hot loops, consider duplicating instructions from small basic blocks; which end in highly predictable terminators into their successor blocks.; If a hot successor block contains instructions which can be vectorized; with the duplicated ones, this can provide a noticeable throughput; improvement. Note that this is not always profitable and does involve a; potentially large increase in code size. #. When checking a value against a constant, emit the check using a consistent; comparison type. The GVN pass *will* optimize redundant equalities even if; the type of comparison is inverted, but GVN only runs late in the pipeline.; As a result, you may miss the opportunity to run other important; optimizations. #. Avoid using arithmetic intrinsics unless you are *required* by your source; language specification to emit a particular code sequence. The optimizer; is quite good at reasoning about general control flow and arithmetic, it is; not anywhere near as strong at reasoning about the various intrinsics. If; profitable for code generation purposes, the optimizer will likely form the; intrinsics itself late in the optimization pipeline. It is *very* rarely; profitable to emit these directly in the language frontend. This item; explicitly includes the use of the :ref:`overflow intrinsics <int_overflow>`. #. Avoid using the :ref:`assume intrinsic <int_assume>` until you've; established that a) there's no other way to express the given fact and b); that fact is critical for optimization purposes. Assumes are a great; prototyping mechanism, but the",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:8744,Performance,optimiz,optimizations,8744,"able, in some cases, to emit such; instructions into the header even if they are not used along a rarely; executed path that exits the loop. This guidance specifically does not; apply if the condition which terminates the loop header is itself invariant,; or can be easily discharged by inspecting the loop index variables. #. In hot loops, consider duplicating instructions from small basic blocks; which end in highly predictable terminators into their successor blocks.; If a hot successor block contains instructions which can be vectorized; with the duplicated ones, this can provide a noticeable throughput; improvement. Note that this is not always profitable and does involve a; potentially large increase in code size. #. When checking a value against a constant, emit the check using a consistent; comparison type. The GVN pass *will* optimize redundant equalities even if; the type of comparison is inverted, but GVN only runs late in the pipeline.; As a result, you may miss the opportunity to run other important; optimizations. #. Avoid using arithmetic intrinsics unless you are *required* by your source; language specification to emit a particular code sequence. The optimizer; is quite good at reasoning about general control flow and arithmetic, it is; not anywhere near as strong at reasoning about the various intrinsics. If; profitable for code generation purposes, the optimizer will likely form the; intrinsics itself late in the optimization pipeline. It is *very* rarely; profitable to emit these directly in the language frontend. This item; explicitly includes the use of the :ref:`overflow intrinsics <int_overflow>`. #. Avoid using the :ref:`assume intrinsic <int_assume>` until you've; established that a) there's no other way to express the given fact and b); that fact is critical for optimization purposes. Assumes are a great; prototyping mechanism, but they can have negative effects on both compile; time and optimization effectiveness. The former is fixable with",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:8901,Performance,optimiz,optimizer,8901,"an be easily discharged by inspecting the loop index variables. #. In hot loops, consider duplicating instructions from small basic blocks; which end in highly predictable terminators into their successor blocks.; If a hot successor block contains instructions which can be vectorized; with the duplicated ones, this can provide a noticeable throughput; improvement. Note that this is not always profitable and does involve a; potentially large increase in code size. #. When checking a value against a constant, emit the check using a consistent; comparison type. The GVN pass *will* optimize redundant equalities even if; the type of comparison is inverted, but GVN only runs late in the pipeline.; As a result, you may miss the opportunity to run other important; optimizations. #. Avoid using arithmetic intrinsics unless you are *required* by your source; language specification to emit a particular code sequence. The optimizer; is quite good at reasoning about general control flow and arithmetic, it is; not anywhere near as strong at reasoning about the various intrinsics. If; profitable for code generation purposes, the optimizer will likely form the; intrinsics itself late in the optimization pipeline. It is *very* rarely; profitable to emit these directly in the language frontend. This item; explicitly includes the use of the :ref:`overflow intrinsics <int_overflow>`. #. Avoid using the :ref:`assume intrinsic <int_assume>` until you've; established that a) there's no other way to express the given fact and b); that fact is critical for optimization purposes. Assumes are a great; prototyping mechanism, but they can have negative effects on both compile; time and optimization effectiveness. The former is fixable with enough; effort, but the later is fairly fundamental to their designed purpose. Describing Language Specific Properties; =======================================. When translating a source language to LLVM, finding ways to express concepts; and guarantees availa",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:9109,Performance,optimiz,optimizer,9109," in highly predictable terminators into their successor blocks.; If a hot successor block contains instructions which can be vectorized; with the duplicated ones, this can provide a noticeable throughput; improvement. Note that this is not always profitable and does involve a; potentially large increase in code size. #. When checking a value against a constant, emit the check using a consistent; comparison type. The GVN pass *will* optimize redundant equalities even if; the type of comparison is inverted, but GVN only runs late in the pipeline.; As a result, you may miss the opportunity to run other important; optimizations. #. Avoid using arithmetic intrinsics unless you are *required* by your source; language specification to emit a particular code sequence. The optimizer; is quite good at reasoning about general control flow and arithmetic, it is; not anywhere near as strong at reasoning about the various intrinsics. If; profitable for code generation purposes, the optimizer will likely form the; intrinsics itself late in the optimization pipeline. It is *very* rarely; profitable to emit these directly in the language frontend. This item; explicitly includes the use of the :ref:`overflow intrinsics <int_overflow>`. #. Avoid using the :ref:`assume intrinsic <int_assume>` until you've; established that a) there's no other way to express the given fact and b); that fact is critical for optimization purposes. Assumes are a great; prototyping mechanism, but they can have negative effects on both compile; time and optimization effectiveness. The former is fixable with enough; effort, but the later is fairly fundamental to their designed purpose. Describing Language Specific Properties; =======================================. When translating a source language to LLVM, finding ways to express concepts; and guarantees available in your source language which are not natively; provided by LLVM IR will greatly improve LLVM's ability to optimize your code.; As an example, C",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:9171,Performance,optimiz,optimization,9171," in highly predictable terminators into their successor blocks.; If a hot successor block contains instructions which can be vectorized; with the duplicated ones, this can provide a noticeable throughput; improvement. Note that this is not always profitable and does involve a; potentially large increase in code size. #. When checking a value against a constant, emit the check using a consistent; comparison type. The GVN pass *will* optimize redundant equalities even if; the type of comparison is inverted, but GVN only runs late in the pipeline.; As a result, you may miss the opportunity to run other important; optimizations. #. Avoid using arithmetic intrinsics unless you are *required* by your source; language specification to emit a particular code sequence. The optimizer; is quite good at reasoning about general control flow and arithmetic, it is; not anywhere near as strong at reasoning about the various intrinsics. If; profitable for code generation purposes, the optimizer will likely form the; intrinsics itself late in the optimization pipeline. It is *very* rarely; profitable to emit these directly in the language frontend. This item; explicitly includes the use of the :ref:`overflow intrinsics <int_overflow>`. #. Avoid using the :ref:`assume intrinsic <int_assume>` until you've; established that a) there's no other way to express the given fact and b); that fact is critical for optimization purposes. Assumes are a great; prototyping mechanism, but they can have negative effects on both compile; time and optimization effectiveness. The former is fixable with enough; effort, but the later is fairly fundamental to their designed purpose. Describing Language Specific Properties; =======================================. When translating a source language to LLVM, finding ways to express concepts; and guarantees available in your source language which are not natively; provided by LLVM IR will greatly improve LLVM's ability to optimize your code.; As an example, C",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:9535,Performance,optimiz,optimization,9535," a value against a constant, emit the check using a consistent; comparison type. The GVN pass *will* optimize redundant equalities even if; the type of comparison is inverted, but GVN only runs late in the pipeline.; As a result, you may miss the opportunity to run other important; optimizations. #. Avoid using arithmetic intrinsics unless you are *required* by your source; language specification to emit a particular code sequence. The optimizer; is quite good at reasoning about general control flow and arithmetic, it is; not anywhere near as strong at reasoning about the various intrinsics. If; profitable for code generation purposes, the optimizer will likely form the; intrinsics itself late in the optimization pipeline. It is *very* rarely; profitable to emit these directly in the language frontend. This item; explicitly includes the use of the :ref:`overflow intrinsics <int_overflow>`. #. Avoid using the :ref:`assume intrinsic <int_assume>` until you've; established that a) there's no other way to express the given fact and b); that fact is critical for optimization purposes. Assumes are a great; prototyping mechanism, but they can have negative effects on both compile; time and optimization effectiveness. The former is fixable with enough; effort, but the later is fairly fundamental to their designed purpose. Describing Language Specific Properties; =======================================. When translating a source language to LLVM, finding ways to express concepts; and guarantees available in your source language which are not natively; provided by LLVM IR will greatly improve LLVM's ability to optimize your code.; As an example, C/C++'s ability to mark every add as ""no signed wrap (nsw)"" goes; a long way to assisting the optimizer in reasoning about loop induction; variables and thus generating more optimal code for loops. The LLVM LangRef includes a number of mechanisms for annotating the IR with; additional semantic information. It is *strongly* recommended ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:9663,Performance,optimiz,optimization,9663," is inverted, but GVN only runs late in the pipeline.; As a result, you may miss the opportunity to run other important; optimizations. #. Avoid using arithmetic intrinsics unless you are *required* by your source; language specification to emit a particular code sequence. The optimizer; is quite good at reasoning about general control flow and arithmetic, it is; not anywhere near as strong at reasoning about the various intrinsics. If; profitable for code generation purposes, the optimizer will likely form the; intrinsics itself late in the optimization pipeline. It is *very* rarely; profitable to emit these directly in the language frontend. This item; explicitly includes the use of the :ref:`overflow intrinsics <int_overflow>`. #. Avoid using the :ref:`assume intrinsic <int_assume>` until you've; established that a) there's no other way to express the given fact and b); that fact is critical for optimization purposes. Assumes are a great; prototyping mechanism, but they can have negative effects on both compile; time and optimization effectiveness. The former is fixable with enough; effort, but the later is fairly fundamental to their designed purpose. Describing Language Specific Properties; =======================================. When translating a source language to LLVM, finding ways to express concepts; and guarantees available in your source language which are not natively; provided by LLVM IR will greatly improve LLVM's ability to optimize your code.; As an example, C/C++'s ability to mark every add as ""no signed wrap (nsw)"" goes; a long way to assisting the optimizer in reasoning about loop induction; variables and thus generating more optimal code for loops. The LLVM LangRef includes a number of mechanisms for annotating the IR with; additional semantic information. It is *strongly* recommended that you become; highly familiar with this document. The list below is intended to highlight a; couple of items of particular interest, but is by no means exhaust",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:10089,Performance,optimiz,optimize,10089,"anywhere near as strong at reasoning about the various intrinsics. If; profitable for code generation purposes, the optimizer will likely form the; intrinsics itself late in the optimization pipeline. It is *very* rarely; profitable to emit these directly in the language frontend. This item; explicitly includes the use of the :ref:`overflow intrinsics <int_overflow>`. #. Avoid using the :ref:`assume intrinsic <int_assume>` until you've; established that a) there's no other way to express the given fact and b); that fact is critical for optimization purposes. Assumes are a great; prototyping mechanism, but they can have negative effects on both compile; time and optimization effectiveness. The former is fixable with enough; effort, but the later is fairly fundamental to their designed purpose. Describing Language Specific Properties; =======================================. When translating a source language to LLVM, finding ways to express concepts; and guarantees available in your source language which are not natively; provided by LLVM IR will greatly improve LLVM's ability to optimize your code.; As an example, C/C++'s ability to mark every add as ""no signed wrap (nsw)"" goes; a long way to assisting the optimizer in reasoning about loop induction; variables and thus generating more optimal code for loops. The LLVM LangRef includes a number of mechanisms for annotating the IR with; additional semantic information. It is *strongly* recommended that you become; highly familiar with this document. The list below is intended to highlight a; couple of items of particular interest, but is by no means exhaustive. Restricted Operation Semantics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; #. Add nsw/nuw flags as appropriate. Reasoning about overflow is; generally hard for an optimizer so providing these facts from the frontend; can be very impactful. #. Use fast-math flags on floating point operations if legal. If you don't; need strict IEEE floating point semantics, there are a numb",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:10219,Performance,optimiz,optimizer,10219,"profitable to emit these directly in the language frontend. This item; explicitly includes the use of the :ref:`overflow intrinsics <int_overflow>`. #. Avoid using the :ref:`assume intrinsic <int_assume>` until you've; established that a) there's no other way to express the given fact and b); that fact is critical for optimization purposes. Assumes are a great; prototyping mechanism, but they can have negative effects on both compile; time and optimization effectiveness. The former is fixable with enough; effort, but the later is fairly fundamental to their designed purpose. Describing Language Specific Properties; =======================================. When translating a source language to LLVM, finding ways to express concepts; and guarantees available in your source language which are not natively; provided by LLVM IR will greatly improve LLVM's ability to optimize your code.; As an example, C/C++'s ability to mark every add as ""no signed wrap (nsw)"" goes; a long way to assisting the optimizer in reasoning about loop induction; variables and thus generating more optimal code for loops. The LLVM LangRef includes a number of mechanisms for annotating the IR with; additional semantic information. It is *strongly* recommended that you become; highly familiar with this document. The list below is intended to highlight a; couple of items of particular interest, but is by no means exhaustive. Restricted Operation Semantics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; #. Add nsw/nuw flags as appropriate. Reasoning about overflow is; generally hard for an optimizer so providing these facts from the frontend; can be very impactful. #. Use fast-math flags on floating point operations if legal. If you don't; need strict IEEE floating point semantics, there are a number of additional; optimizations that can be performed. This can be highly impactful for; floating point intensive computations. Describing Aliasing Properties; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. #. Add noalias/align/dereferen",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:10781,Performance,optimiz,optimizer,10781,"se. Describing Language Specific Properties; =======================================. When translating a source language to LLVM, finding ways to express concepts; and guarantees available in your source language which are not natively; provided by LLVM IR will greatly improve LLVM's ability to optimize your code.; As an example, C/C++'s ability to mark every add as ""no signed wrap (nsw)"" goes; a long way to assisting the optimizer in reasoning about loop induction; variables and thus generating more optimal code for loops. The LLVM LangRef includes a number of mechanisms for annotating the IR with; additional semantic information. It is *strongly* recommended that you become; highly familiar with this document. The list below is intended to highlight a; couple of items of particular interest, but is by no means exhaustive. Restricted Operation Semantics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; #. Add nsw/nuw flags as appropriate. Reasoning about overflow is; generally hard for an optimizer so providing these facts from the frontend; can be very impactful. #. Use fast-math flags on floating point operations if legal. If you don't; need strict IEEE floating point semantics, there are a number of additional; optimizations that can be performed. This can be highly impactful for; floating point intensive computations. Describing Aliasing Properties; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. #. Add noalias/align/dereferenceable/nonnull to function arguments and return; values as appropriate. #. Use pointer aliasing metadata, especially tbaa metadata, to communicate; otherwise-non-deducible pointer aliasing facts. #. Use inbounds on geps. This can help to disambiguate some aliasing queries. Undefined Values; ^^^^^^^^^^^^^^^^. #. Use poison values instead of undef values whenever possible. #. Tag function parameters with the noundef attribute whenever possible. Modeling Memory Effects; ^^^^^^^^^^^^^^^^^^^^^^^^. #. Mark functions as readnone/readonly/argmemonly or noreturn/nounwind when; kno",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:11011,Performance,optimiz,optimizations,11011,"n your source language which are not natively; provided by LLVM IR will greatly improve LLVM's ability to optimize your code.; As an example, C/C++'s ability to mark every add as ""no signed wrap (nsw)"" goes; a long way to assisting the optimizer in reasoning about loop induction; variables and thus generating more optimal code for loops. The LLVM LangRef includes a number of mechanisms for annotating the IR with; additional semantic information. It is *strongly* recommended that you become; highly familiar with this document. The list below is intended to highlight a; couple of items of particular interest, but is by no means exhaustive. Restricted Operation Semantics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; #. Add nsw/nuw flags as appropriate. Reasoning about overflow is; generally hard for an optimizer so providing these facts from the frontend; can be very impactful. #. Use fast-math flags on floating point operations if legal. If you don't; need strict IEEE floating point semantics, there are a number of additional; optimizations that can be performed. This can be highly impactful for; floating point intensive computations. Describing Aliasing Properties; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. #. Add noalias/align/dereferenceable/nonnull to function arguments and return; values as appropriate. #. Use pointer aliasing metadata, especially tbaa metadata, to communicate; otherwise-non-deducible pointer aliasing facts. #. Use inbounds on geps. This can help to disambiguate some aliasing queries. Undefined Values; ^^^^^^^^^^^^^^^^. #. Use poison values instead of undef values whenever possible. #. Tag function parameters with the noundef attribute whenever possible. Modeling Memory Effects; ^^^^^^^^^^^^^^^^^^^^^^^^. #. Mark functions as readnone/readonly/argmemonly or noreturn/nounwind when; known. The optimizer will try to infer these flags, but may not always be; able to. Manual annotations are particularly important for external; functions that the optimizer can not analyze. #. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:11037,Performance,perform,performed,11037,"n your source language which are not natively; provided by LLVM IR will greatly improve LLVM's ability to optimize your code.; As an example, C/C++'s ability to mark every add as ""no signed wrap (nsw)"" goes; a long way to assisting the optimizer in reasoning about loop induction; variables and thus generating more optimal code for loops. The LLVM LangRef includes a number of mechanisms for annotating the IR with; additional semantic information. It is *strongly* recommended that you become; highly familiar with this document. The list below is intended to highlight a; couple of items of particular interest, but is by no means exhaustive. Restricted Operation Semantics; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^; #. Add nsw/nuw flags as appropriate. Reasoning about overflow is; generally hard for an optimizer so providing these facts from the frontend; can be very impactful. #. Use fast-math flags on floating point operations if legal. If you don't; need strict IEEE floating point semantics, there are a number of additional; optimizations that can be performed. This can be highly impactful for; floating point intensive computations. Describing Aliasing Properties; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. #. Add noalias/align/dereferenceable/nonnull to function arguments and return; values as appropriate. #. Use pointer aliasing metadata, especially tbaa metadata, to communicate; otherwise-non-deducible pointer aliasing facts. #. Use inbounds on geps. This can help to disambiguate some aliasing queries. Undefined Values; ^^^^^^^^^^^^^^^^. #. Use poison values instead of undef values whenever possible. #. Tag function parameters with the noundef attribute whenever possible. Modeling Memory Effects; ^^^^^^^^^^^^^^^^^^^^^^^^. #. Mark functions as readnone/readonly/argmemonly or noreturn/nounwind when; known. The optimizer will try to infer these flags, but may not always be; able to. Manual annotations are particularly important for external; functions that the optimizer can not analyze. #. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:11801,Performance,optimiz,optimizer,11801," can be very impactful. #. Use fast-math flags on floating point operations if legal. If you don't; need strict IEEE floating point semantics, there are a number of additional; optimizations that can be performed. This can be highly impactful for; floating point intensive computations. Describing Aliasing Properties; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. #. Add noalias/align/dereferenceable/nonnull to function arguments and return; values as appropriate. #. Use pointer aliasing metadata, especially tbaa metadata, to communicate; otherwise-non-deducible pointer aliasing facts. #. Use inbounds on geps. This can help to disambiguate some aliasing queries. Undefined Values; ^^^^^^^^^^^^^^^^. #. Use poison values instead of undef values whenever possible. #. Tag function parameters with the noundef attribute whenever possible. Modeling Memory Effects; ^^^^^^^^^^^^^^^^^^^^^^^^. #. Mark functions as readnone/readonly/argmemonly or noreturn/nounwind when; known. The optimizer will try to infer these flags, but may not always be; able to. Manual annotations are particularly important for external; functions that the optimizer can not analyze. #. Use the lifetime.start/lifetime.end and invariant.start/invariant.end; intrinsics where possible. Common profitable uses are for stack like data; structures (thus allowing dead store elimination) and for describing; life times of allocas (thus allowing smaller stack sizes). #. Mark invariant locations using !invariant.load and TBAA's constant flags. Pass Ordering; ^^^^^^^^^^^^^. One of the most common mistakes made by new language frontend projects is to; use the existing -O2 or -O3 pass pipelines as is. These pass pipelines make a; good starting point for an optimizing compiler for any language, but they have; been carefully tuned for C and C++, not your target language. You will almost; certainly need to use a custom pass order to achieve optimal performance. A; couple specific suggestions:. #. For languages with numerous rarely executed ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:11953,Performance,optimiz,optimizer,11953," don't; need strict IEEE floating point semantics, there are a number of additional; optimizations that can be performed. This can be highly impactful for; floating point intensive computations. Describing Aliasing Properties; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. #. Add noalias/align/dereferenceable/nonnull to function arguments and return; values as appropriate. #. Use pointer aliasing metadata, especially tbaa metadata, to communicate; otherwise-non-deducible pointer aliasing facts. #. Use inbounds on geps. This can help to disambiguate some aliasing queries. Undefined Values; ^^^^^^^^^^^^^^^^. #. Use poison values instead of undef values whenever possible. #. Tag function parameters with the noundef attribute whenever possible. Modeling Memory Effects; ^^^^^^^^^^^^^^^^^^^^^^^^. #. Mark functions as readnone/readonly/argmemonly or noreturn/nounwind when; known. The optimizer will try to infer these flags, but may not always be; able to. Manual annotations are particularly important for external; functions that the optimizer can not analyze. #. Use the lifetime.start/lifetime.end and invariant.start/invariant.end; intrinsics where possible. Common profitable uses are for stack like data; structures (thus allowing dead store elimination) and for describing; life times of allocas (thus allowing smaller stack sizes). #. Mark invariant locations using !invariant.load and TBAA's constant flags. Pass Ordering; ^^^^^^^^^^^^^. One of the most common mistakes made by new language frontend projects is to; use the existing -O2 or -O3 pass pipelines as is. These pass pipelines make a; good starting point for an optimizing compiler for any language, but they have; been carefully tuned for C and C++, not your target language. You will almost; certainly need to use a custom pass order to achieve optimal performance. A; couple specific suggestions:. #. For languages with numerous rarely executed guard conditions (e.g. null; checks, type checks, range checks) consider adding an extra ex",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:12303,Performance,load,load,12303,"a, especially tbaa metadata, to communicate; otherwise-non-deducible pointer aliasing facts. #. Use inbounds on geps. This can help to disambiguate some aliasing queries. Undefined Values; ^^^^^^^^^^^^^^^^. #. Use poison values instead of undef values whenever possible. #. Tag function parameters with the noundef attribute whenever possible. Modeling Memory Effects; ^^^^^^^^^^^^^^^^^^^^^^^^. #. Mark functions as readnone/readonly/argmemonly or noreturn/nounwind when; known. The optimizer will try to infer these flags, but may not always be; able to. Manual annotations are particularly important for external; functions that the optimizer can not analyze. #. Use the lifetime.start/lifetime.end and invariant.start/invariant.end; intrinsics where possible. Common profitable uses are for stack like data; structures (thus allowing dead store elimination) and for describing; life times of allocas (thus allowing smaller stack sizes). #. Mark invariant locations using !invariant.load and TBAA's constant flags. Pass Ordering; ^^^^^^^^^^^^^. One of the most common mistakes made by new language frontend projects is to; use the existing -O2 or -O3 pass pipelines as is. These pass pipelines make a; good starting point for an optimizing compiler for any language, but they have; been carefully tuned for C and C++, not your target language. You will almost; certainly need to use a custom pass order to achieve optimal performance. A; couple specific suggestions:. #. For languages with numerous rarely executed guard conditions (e.g. null; checks, type checks, range checks) consider adding an extra execution or; two of LoopUnswitch and LICM to your pass order. The standard pass order,; which is tuned for C and C++ applications, may not be sufficient to remove; all dischargeable checks from loops. #. If your language uses range checks, consider using the IRCE pass. It is not; currently part of the standard pass order. #. A useful sanity check to run is to run your optimized IR back throu",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:12549,Performance,optimiz,optimizing,12549,"r possible. #. Tag function parameters with the noundef attribute whenever possible. Modeling Memory Effects; ^^^^^^^^^^^^^^^^^^^^^^^^. #. Mark functions as readnone/readonly/argmemonly or noreturn/nounwind when; known. The optimizer will try to infer these flags, but may not always be; able to. Manual annotations are particularly important for external; functions that the optimizer can not analyze. #. Use the lifetime.start/lifetime.end and invariant.start/invariant.end; intrinsics where possible. Common profitable uses are for stack like data; structures (thus allowing dead store elimination) and for describing; life times of allocas (thus allowing smaller stack sizes). #. Mark invariant locations using !invariant.load and TBAA's constant flags. Pass Ordering; ^^^^^^^^^^^^^. One of the most common mistakes made by new language frontend projects is to; use the existing -O2 or -O3 pass pipelines as is. These pass pipelines make a; good starting point for an optimizing compiler for any language, but they have; been carefully tuned for C and C++, not your target language. You will almost; certainly need to use a custom pass order to achieve optimal performance. A; couple specific suggestions:. #. For languages with numerous rarely executed guard conditions (e.g. null; checks, type checks, range checks) consider adding an extra execution or; two of LoopUnswitch and LICM to your pass order. The standard pass order,; which is tuned for C and C++ applications, may not be sufficient to remove; all dischargeable checks from loops. #. If your language uses range checks, consider using the IRCE pass. It is not; currently part of the standard pass order. #. A useful sanity check to run is to run your optimized IR back through the; -O2 pipeline again. If you see noticeable improvement in the resulting IR,; you likely need to adjust your pass order. I Still Can't Find What I'm Looking For; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. If you didn't find what you were looking for above",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:12617,Performance,tune,tuned,12617,"r possible. #. Tag function parameters with the noundef attribute whenever possible. Modeling Memory Effects; ^^^^^^^^^^^^^^^^^^^^^^^^. #. Mark functions as readnone/readonly/argmemonly or noreturn/nounwind when; known. The optimizer will try to infer these flags, but may not always be; able to. Manual annotations are particularly important for external; functions that the optimizer can not analyze. #. Use the lifetime.start/lifetime.end and invariant.start/invariant.end; intrinsics where possible. Common profitable uses are for stack like data; structures (thus allowing dead store elimination) and for describing; life times of allocas (thus allowing smaller stack sizes). #. Mark invariant locations using !invariant.load and TBAA's constant flags. Pass Ordering; ^^^^^^^^^^^^^. One of the most common mistakes made by new language frontend projects is to; use the existing -O2 or -O3 pass pipelines as is. These pass pipelines make a; good starting point for an optimizing compiler for any language, but they have; been carefully tuned for C and C++, not your target language. You will almost; certainly need to use a custom pass order to achieve optimal performance. A; couple specific suggestions:. #. For languages with numerous rarely executed guard conditions (e.g. null; checks, type checks, range checks) consider adding an extra execution or; two of LoopUnswitch and LICM to your pass order. The standard pass order,; which is tuned for C and C++ applications, may not be sufficient to remove; all dischargeable checks from loops. #. If your language uses range checks, consider using the IRCE pass. It is not; currently part of the standard pass order. #. A useful sanity check to run is to run your optimized IR back through the; -O2 pipeline again. If you see noticeable improvement in the resulting IR,; you likely need to adjust your pass order. I Still Can't Find What I'm Looking For; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. If you didn't find what you were looking for above",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:12742,Performance,perform,performance,12742,"^^^. #. Mark functions as readnone/readonly/argmemonly or noreturn/nounwind when; known. The optimizer will try to infer these flags, but may not always be; able to. Manual annotations are particularly important for external; functions that the optimizer can not analyze. #. Use the lifetime.start/lifetime.end and invariant.start/invariant.end; intrinsics where possible. Common profitable uses are for stack like data; structures (thus allowing dead store elimination) and for describing; life times of allocas (thus allowing smaller stack sizes). #. Mark invariant locations using !invariant.load and TBAA's constant flags. Pass Ordering; ^^^^^^^^^^^^^. One of the most common mistakes made by new language frontend projects is to; use the existing -O2 or -O3 pass pipelines as is. These pass pipelines make a; good starting point for an optimizing compiler for any language, but they have; been carefully tuned for C and C++, not your target language. You will almost; certainly need to use a custom pass order to achieve optimal performance. A; couple specific suggestions:. #. For languages with numerous rarely executed guard conditions (e.g. null; checks, type checks, range checks) consider adding an extra execution or; two of LoopUnswitch and LICM to your pass order. The standard pass order,; which is tuned for C and C++ applications, may not be sufficient to remove; all dischargeable checks from loops. #. If your language uses range checks, consider using the IRCE pass. It is not; currently part of the standard pass order. #. A useful sanity check to run is to run your optimized IR back through the; -O2 pipeline again. If you see noticeable improvement in the resulting IR,; you likely need to adjust your pass order. I Still Can't Find What I'm Looking For; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. If you didn't find what you were looking for above, consider proposing a piece; of metadata which provides the optimization hint you need. Such extensions are; relatively common and",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:13022,Performance,tune,tuned,13022,"ntrinsics where possible. Common profitable uses are for stack like data; structures (thus allowing dead store elimination) and for describing; life times of allocas (thus allowing smaller stack sizes). #. Mark invariant locations using !invariant.load and TBAA's constant flags. Pass Ordering; ^^^^^^^^^^^^^. One of the most common mistakes made by new language frontend projects is to; use the existing -O2 or -O3 pass pipelines as is. These pass pipelines make a; good starting point for an optimizing compiler for any language, but they have; been carefully tuned for C and C++, not your target language. You will almost; certainly need to use a custom pass order to achieve optimal performance. A; couple specific suggestions:. #. For languages with numerous rarely executed guard conditions (e.g. null; checks, type checks, range checks) consider adding an extra execution or; two of LoopUnswitch and LICM to your pass order. The standard pass order,; which is tuned for C and C++ applications, may not be sufficient to remove; all dischargeable checks from loops. #. If your language uses range checks, consider using the IRCE pass. It is not; currently part of the standard pass order. #. A useful sanity check to run is to run your optimized IR back through the; -O2 pipeline again. If you see noticeable improvement in the resulting IR,; you likely need to adjust your pass order. I Still Can't Find What I'm Looking For; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. If you didn't find what you were looking for above, consider proposing a piece; of metadata which provides the optimization hint you need. Such extensions are; relatively common and are generally well received by the community. You will; need to ensure that your proposal is sufficiently general so that it benefits; others if you wish to contribute it upstream. You should also consider describing the problem you're facing on `Discourse; <https://discourse.llvm.org>`_ and asking for advice.; It's entirely possible someone ha",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:13296,Performance,optimiz,optimized,13296,"iant.load and TBAA's constant flags. Pass Ordering; ^^^^^^^^^^^^^. One of the most common mistakes made by new language frontend projects is to; use the existing -O2 or -O3 pass pipelines as is. These pass pipelines make a; good starting point for an optimizing compiler for any language, but they have; been carefully tuned for C and C++, not your target language. You will almost; certainly need to use a custom pass order to achieve optimal performance. A; couple specific suggestions:. #. For languages with numerous rarely executed guard conditions (e.g. null; checks, type checks, range checks) consider adding an extra execution or; two of LoopUnswitch and LICM to your pass order. The standard pass order,; which is tuned for C and C++ applications, may not be sufficient to remove; all dischargeable checks from loops. #. If your language uses range checks, consider using the IRCE pass. It is not; currently part of the standard pass order. #. A useful sanity check to run is to run your optimized IR back through the; -O2 pipeline again. If you see noticeable improvement in the resulting IR,; you likely need to adjust your pass order. I Still Can't Find What I'm Looking For; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. If you didn't find what you were looking for above, consider proposing a piece; of metadata which provides the optimization hint you need. Such extensions are; relatively common and are generally well received by the community. You will; need to ensure that your proposal is sufficiently general so that it benefits; others if you wish to contribute it upstream. You should also consider describing the problem you're facing on `Discourse; <https://discourse.llvm.org>`_ and asking for advice.; It's entirely possible someone has encountered your problem before and can; give good advice. If there are multiple interested parties, that also; increases the chances that a metadata extension would be well received by the; community as a whole. Adding to this document; ===",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:13639,Performance,optimiz,optimization,13639,"have; been carefully tuned for C and C++, not your target language. You will almost; certainly need to use a custom pass order to achieve optimal performance. A; couple specific suggestions:. #. For languages with numerous rarely executed guard conditions (e.g. null; checks, type checks, range checks) consider adding an extra execution or; two of LoopUnswitch and LICM to your pass order. The standard pass order,; which is tuned for C and C++ applications, may not be sufficient to remove; all dischargeable checks from loops. #. If your language uses range checks, consider using the IRCE pass. It is not; currently part of the standard pass order. #. A useful sanity check to run is to run your optimized IR back through the; -O2 pipeline again. If you see noticeable improvement in the resulting IR,; you likely need to adjust your pass order. I Still Can't Find What I'm Looking For; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. If you didn't find what you were looking for above, consider proposing a piece; of metadata which provides the optimization hint you need. Such extensions are; relatively common and are generally well received by the community. You will; need to ensure that your proposal is sufficiently general so that it benefits; others if you wish to contribute it upstream. You should also consider describing the problem you're facing on `Discourse; <https://discourse.llvm.org>`_ and asking for advice.; It's entirely possible someone has encountered your problem before and can; give good advice. If there are multiple interested parties, that also; increases the chances that a metadata extension would be well received by the; community as a whole. Adding to this document; =======================. If you run across a case that you feel deserves to be covered here, please send; a patch to `llvm-commits; <http://lists.llvm.org/mailman/listinfo/llvm-commits>`_ for review. If you have questions on these items, please ask them on `Discourse; <https://discourse.llvm.org>`_. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:3781,Safety,safe,safe,3781," canonical form expected by much of the optimizer; if allocas can; not be eliminated by Mem2Reg or SROA, the optimizer is likely to be less; effective than it could be. Avoid loads and stores of large aggregate type; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. LLVM currently does not optimize well loads and stores of large :ref:`aggregate; types <t_aggregate>` (i.e. structs and arrays). As an alternative, consider; loading individual fields from memory. Aggregates that are smaller than the largest (performant) load or store; instruction supported by the targeted hardware are well supported. These can; be an effective way to represent collections of small packed fields. Prefer zext over sext when legal; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. On some architectures (X86_64 is one), sign extension can involve an extra; instruction whereas zero extension can be folded into a load. LLVM will try to; replace a sext with a zext when it can be proven safe, but if you have; information in your source language about the range of an integer value, it can; be profitable to use a zext rather than a sext. Alternatively, you can :ref:`specify the range of the value using metadata; <range-metadata>` and LLVM can do the sext to zext conversion for you. Zext GEP indices to machine register width; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Internally, LLVM often promotes the width of GEP indices to machine register; width. When it does so, it will default to using sign extension (sext); operations for safety. If your source language provides information about; the range of the index, you may wish to manually extend indices to machine; register width using a zext instruction. When to specify alignment; ^^^^^^^^^^^^^^^^^^^^^^^^^^; LLVM will always generate correct code if you don’t specify alignment, but may; generate inefficient code. For example, if you are targeting MIPS (or older; ARM ISAs) then the hardware does not handle unaligned loads and stores, and; so you will enter a tra",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:4334,Safety,safe,safety,4334," that are smaller than the largest (performant) load or store; instruction supported by the targeted hardware are well supported. These can; be an effective way to represent collections of small packed fields. Prefer zext over sext when legal; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. On some architectures (X86_64 is one), sign extension can involve an extra; instruction whereas zero extension can be folded into a load. LLVM will try to; replace a sext with a zext when it can be proven safe, but if you have; information in your source language about the range of an integer value, it can; be profitable to use a zext rather than a sext. Alternatively, you can :ref:`specify the range of the value using metadata; <range-metadata>` and LLVM can do the sext to zext conversion for you. Zext GEP indices to machine register width; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Internally, LLVM often promotes the width of GEP indices to machine register; width. When it does so, it will default to using sign extension (sext); operations for safety. If your source language provides information about; the range of the index, you may wish to manually extend indices to machine; register width using a zext instruction. When to specify alignment; ^^^^^^^^^^^^^^^^^^^^^^^^^^; LLVM will always generate correct code if you don’t specify alignment, but may; generate inefficient code. For example, if you are targeting MIPS (or older; ARM ISAs) then the hardware does not handle unaligned loads and stores, and; so you will enter a trap-and-emulate path if you do a load or store with; lower-than-natural alignment. To avoid this, LLVM will emit a slower; sequence of loads, shifts and masks (or load-right + load-left on MIPS) for; all cases where the load / store does not have a sufficiently high alignment; in the IR. The alignment is used to guarantee the alignment on allocas and globals,; though in most cases this is unnecessary (most targets have a sufficiently; high default alignment that they’ll b",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:4907,Safety,avoid,avoid,4907,"a; <range-metadata>` and LLVM can do the sext to zext conversion for you. Zext GEP indices to machine register width; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Internally, LLVM often promotes the width of GEP indices to machine register; width. When it does so, it will default to using sign extension (sext); operations for safety. If your source language provides information about; the range of the index, you may wish to manually extend indices to machine; register width using a zext instruction. When to specify alignment; ^^^^^^^^^^^^^^^^^^^^^^^^^^; LLVM will always generate correct code if you don’t specify alignment, but may; generate inefficient code. For example, if you are targeting MIPS (or older; ARM ISAs) then the hardware does not handle unaligned loads and stores, and; so you will enter a trap-and-emulate path if you do a load or store with; lower-than-natural alignment. To avoid this, LLVM will emit a slower; sequence of loads, shifts and masks (or load-right + load-left on MIPS) for; all cases where the load / store does not have a sufficiently high alignment; in the IR. The alignment is used to guarantee the alignment on allocas and globals,; though in most cases this is unnecessary (most targets have a sufficiently; high default alignment that they’ll be fine). It is also used to provide a; contract to the back end saying ‘either this load/store has this alignment, or; it is undefined behavior’. This means that the back end is free to emit; instructions that rely on that alignment (and mid-level optimizers are free to; perform transforms that require that alignment). For x86, it doesn’t make; much difference, as almost all instructions are alignment-independent. For; MIPS, it can make a big difference. Note that if your loads and stores are atomic, the backend will be unable to; lower an under aligned access into a sequence of natively aligned accesses.; As a result, alignment is mandatory for atomic loads and stores. Other Things to Consider; ^^^^",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:7269,Safety,avoid,avoid,7269,"ss. #. Be wary of ordered and atomic memory operations. They are hard to optimize; and may not be well optimized by the current optimizer. Depending on your; source language, you may consider using fences instead. #. If calling a function which is known to throw an exception (unwind), use; an invoke with a normal destination which contains an unreachable; instruction. This form conveys to the optimizer that the call returns; abnormally. For an invoke which neither returns normally or requires unwind; code in the current function, you can use a noreturn call instruction if; desired. This is generally not required because the optimizer will convert; an invoke with an unreachable unwind destination to a call instruction. #. Use profile metadata to indicate statically known cold paths, even if; dynamic profiling information is not available. This can make a large; difference in code placement and thus the performance of tight loops. #. When generating code for loops, try to avoid terminating the header block of; the loop earlier than necessary. If the terminator of the loop header; block is a loop exiting conditional branch, the effectiveness of LICM will; be limited for loads not in the header. (This is due to the fact that LLVM; may not know such a load is safe to speculatively execute and thus can't; lift an otherwise loop invariant load unless it can prove the exiting; condition is not taken.) It can be profitable, in some cases, to emit such; instructions into the header even if they are not used along a rarely; executed path that exits the loop. This guidance specifically does not; apply if the condition which terminates the loop header is itself invariant,; or can be easily discharged by inspecting the loop index variables. #. In hot loops, consider duplicating instructions from small basic blocks; which end in highly predictable terminators into their successor blocks.; If a hot successor block contains instructions which can be vectorized; with the duplicated on",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:7559,Safety,safe,safe,7559,"al destination which contains an unreachable; instruction. This form conveys to the optimizer that the call returns; abnormally. For an invoke which neither returns normally or requires unwind; code in the current function, you can use a noreturn call instruction if; desired. This is generally not required because the optimizer will convert; an invoke with an unreachable unwind destination to a call instruction. #. Use profile metadata to indicate statically known cold paths, even if; dynamic profiling information is not available. This can make a large; difference in code placement and thus the performance of tight loops. #. When generating code for loops, try to avoid terminating the header block of; the loop earlier than necessary. If the terminator of the loop header; block is a loop exiting conditional branch, the effectiveness of LICM will; be limited for loads not in the header. (This is due to the fact that LLVM; may not know such a load is safe to speculatively execute and thus can't; lift an otherwise loop invariant load unless it can prove the exiting; condition is not taken.) It can be profitable, in some cases, to emit such; instructions into the header even if they are not used along a rarely; executed path that exits the loop. This guidance specifically does not; apply if the condition which terminates the loop header is itself invariant,; or can be easily discharged by inspecting the loop index variables. #. In hot loops, consider duplicating instructions from small basic blocks; which end in highly predictable terminators into their successor blocks.; If a hot successor block contains instructions which can be vectorized; with the duplicated ones, this can provide a noticeable throughput; improvement. Note that this is not always profitable and does involve a; potentially large increase in code size. #. When checking a value against a constant, emit the check using a consistent; comparison type. The GVN pass *will* optimize redundant equalities even ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:8137,Safety,predict,predictable,8137,"is not available. This can make a large; difference in code placement and thus the performance of tight loops. #. When generating code for loops, try to avoid terminating the header block of; the loop earlier than necessary. If the terminator of the loop header; block is a loop exiting conditional branch, the effectiveness of LICM will; be limited for loads not in the header. (This is due to the fact that LLVM; may not know such a load is safe to speculatively execute and thus can't; lift an otherwise loop invariant load unless it can prove the exiting; condition is not taken.) It can be profitable, in some cases, to emit such; instructions into the header even if they are not used along a rarely; executed path that exits the loop. This guidance specifically does not; apply if the condition which terminates the loop header is itself invariant,; or can be easily discharged by inspecting the loop index variables. #. In hot loops, consider duplicating instructions from small basic blocks; which end in highly predictable terminators into their successor blocks.; If a hot successor block contains instructions which can be vectorized; with the duplicated ones, this can provide a noticeable throughput; improvement. Note that this is not always profitable and does involve a; potentially large increase in code size. #. When checking a value against a constant, emit the check using a consistent; comparison type. The GVN pass *will* optimize redundant equalities even if; the type of comparison is inverted, but GVN only runs late in the pipeline.; As a result, you may miss the opportunity to run other important; optimizations. #. Avoid using arithmetic intrinsics unless you are *required* by your source; language specification to emit a particular code sequence. The optimizer; is quite good at reasoning about general control flow and arithmetic, it is; not anywhere near as strong at reasoning about the various intrinsics. If; profitable for code generation purposes, the optimiz",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:8571,Safety,redund,redundant,8571,"t an otherwise loop invariant load unless it can prove the exiting; condition is not taken.) It can be profitable, in some cases, to emit such; instructions into the header even if they are not used along a rarely; executed path that exits the loop. This guidance specifically does not; apply if the condition which terminates the loop header is itself invariant,; or can be easily discharged by inspecting the loop index variables. #. In hot loops, consider duplicating instructions from small basic blocks; which end in highly predictable terminators into their successor blocks.; If a hot successor block contains instructions which can be vectorized; with the duplicated ones, this can provide a noticeable throughput; improvement. Note that this is not always profitable and does involve a; potentially large increase in code size. #. When checking a value against a constant, emit the check using a consistent; comparison type. The GVN pass *will* optimize redundant equalities even if; the type of comparison is inverted, but GVN only runs late in the pipeline.; As a result, you may miss the opportunity to run other important; optimizations. #. Avoid using arithmetic intrinsics unless you are *required* by your source; language specification to emit a particular code sequence. The optimizer; is quite good at reasoning about general control flow and arithmetic, it is; not anywhere near as strong at reasoning about the various intrinsics. If; profitable for code generation purposes, the optimizer will likely form the; intrinsics itself late in the optimization pipeline. It is *very* rarely; profitable to emit these directly in the language frontend. This item; explicitly includes the use of the :ref:`overflow intrinsics <int_overflow>`. #. Avoid using the :ref:`assume intrinsic <int_assume>` until you've; established that a) there's no other way to express the given fact and b); that fact is critical for optimization purposes. Assumes are a great; prototyping mechanism, but the",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:13261,Safety,sanity check,sanity check,13261,"iant.load and TBAA's constant flags. Pass Ordering; ^^^^^^^^^^^^^. One of the most common mistakes made by new language frontend projects is to; use the existing -O2 or -O3 pass pipelines as is. These pass pipelines make a; good starting point for an optimizing compiler for any language, but they have; been carefully tuned for C and C++, not your target language. You will almost; certainly need to use a custom pass order to achieve optimal performance. A; couple specific suggestions:. #. For languages with numerous rarely executed guard conditions (e.g. null; checks, type checks, range checks) consider adding an extra execution or; two of LoopUnswitch and LICM to your pass order. The standard pass order,; which is tuned for C and C++ applications, may not be sufficient to remove; all dischargeable checks from loops. #. If your language uses range checks, consider using the IRCE pass. It is not; currently part of the standard pass order. #. A useful sanity check to run is to run your optimized IR back through the; -O2 pipeline again. If you see noticeable improvement in the resulting IR,; you likely need to adjust your pass order. I Still Can't Find What I'm Looking For; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. If you didn't find what you were looking for above, consider proposing a piece; of metadata which provides the optimization hint you need. Such extensions are; relatively common and are generally well received by the community. You will; need to ensure that your proposal is sufficiently general so that it benefits; others if you wish to contribute it upstream. You should also consider describing the problem you're facing on `Discourse; <https://discourse.llvm.org>`_ and asking for advice.; It's entirely possible someone has encountered your problem before and can; give good advice. If there are multiple interested parties, that also; increases the chances that a metadata extension would be well received by the; community as a whole. Adding to this document; ===",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:5857,Security,access,access,5857,"late path if you do a load or store with; lower-than-natural alignment. To avoid this, LLVM will emit a slower; sequence of loads, shifts and masks (or load-right + load-left on MIPS) for; all cases where the load / store does not have a sufficiently high alignment; in the IR. The alignment is used to guarantee the alignment on allocas and globals,; though in most cases this is unnecessary (most targets have a sufficiently; high default alignment that they’ll be fine). It is also used to provide a; contract to the back end saying ‘either this load/store has this alignment, or; it is undefined behavior’. This means that the back end is free to emit; instructions that rely on that alignment (and mid-level optimizers are free to; perform transforms that require that alignment). For x86, it doesn’t make; much difference, as almost all instructions are alignment-independent. For; MIPS, it can make a big difference. Note that if your loads and stores are atomic, the backend will be unable to; lower an under aligned access into a sequence of natively aligned accesses.; As a result, alignment is mandatory for atomic loads and stores. Other Things to Consider; ^^^^^^^^^^^^^^^^^^^^^^^^. #. Use ptrtoint/inttoptr sparingly (they interfere with pointer aliasing; analysis), prefer GEPs. #. Prefer globals over inttoptr of a constant address - this gives you; dereferencability information. In MCJIT, use getSymbolAddress to provide; actual address. #. Be wary of ordered and atomic memory operations. They are hard to optimize; and may not be well optimized by the current optimizer. Depending on your; source language, you may consider using fences instead. #. If calling a function which is known to throw an exception (unwind), use; an invoke with a normal destination which contains an unreachable; instruction. This form conveys to the optimizer that the call returns; abnormally. For an invoke which neither returns normally or requires unwind; code in the current function, you can use ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:5900,Security,access,accesses,5900,"late path if you do a load or store with; lower-than-natural alignment. To avoid this, LLVM will emit a slower; sequence of loads, shifts and masks (or load-right + load-left on MIPS) for; all cases where the load / store does not have a sufficiently high alignment; in the IR. The alignment is used to guarantee the alignment on allocas and globals,; though in most cases this is unnecessary (most targets have a sufficiently; high default alignment that they’ll be fine). It is also used to provide a; contract to the back end saying ‘either this load/store has this alignment, or; it is undefined behavior’. This means that the back end is free to emit; instructions that rely on that alignment (and mid-level optimizers are free to; perform transforms that require that alignment). For x86, it doesn’t make; much difference, as almost all instructions are alignment-independent. For; MIPS, it can make a big difference. Note that if your loads and stores are atomic, the backend will be unable to; lower an under aligned access into a sequence of natively aligned accesses.; As a result, alignment is mandatory for atomic loads and stores. Other Things to Consider; ^^^^^^^^^^^^^^^^^^^^^^^^. #. Use ptrtoint/inttoptr sparingly (they interfere with pointer aliasing; analysis), prefer GEPs. #. Prefer globals over inttoptr of a constant address - this gives you; dereferencability information. In MCJIT, use getSymbolAddress to provide; actual address. #. Be wary of ordered and atomic memory operations. They are hard to optimize; and may not be well optimized by the current optimizer. Depending on your; source language, you may consider using fences instead. #. If calling a function which is known to throw an exception (unwind), use; an invoke with a normal destination which contains an unreachable; instruction. This form conveys to the optimizer that the call returns; abnormally. For an invoke which neither returns normally or requires unwind; code in the current function, you can use ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:2043,Usability,guid,guidance,2043,"icitly version locked so you'll need to make sure; you're using a Clang built from the same git revision or release as the LLVM; library you're using. As always, it's *strongly* recommended that you track; tip of tree development, particularly during bring up of a new project. The Basics; ^^^^^^^^^^^. #. Make sure that your Modules contain both a data layout specification and; target triple. Without these pieces, non of the target specific optimization; will be enabled. This can have a major effect on the generated code quality. #. For each function or global emitted, use the most private linkage type; possible (private, internal or linkonce_odr preferably). Doing so will; make LLVM's inter-procedural optimizations much more effective. #. Avoid high in-degree basic blocks (e.g. basic blocks with dozens or hundreds; of predecessors). Among other issues, the register allocator is known to; perform badly with confronted with such structures. The only exception to; this guidance is that a unified return block with high in-degree is fine. Use of allocas; ^^^^^^^^^^^^^^. An alloca instruction can be used to represent a function scoped stack slot,; but can also represent dynamic frame expansion. When representing function; scoped variables or locations, placing alloca instructions at the beginning of; the entry block should be preferred. In particular, place them before any; call instructions. Call instructions might get inlined and replaced with; multiple basic blocks. The end result is that a following alloca instruction; would no longer be in the entry basic block afterward. The SROA (Scalar Replacement Of Aggregates) and Mem2Reg passes only attempt; to eliminate alloca instructions that are in the entry basic block. Given; SSA is the canonical form expected by much of the optimizer; if allocas can; not be eliminated by Mem2Reg or SROA, the optimizer is likely to be less; effective than it could be. Avoid loads and stores of large aggregate type; ^^^^^^^^^^^^^^^^^^^^^^^^",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst:7863,Usability,guid,guidance,7863,"e with an unreachable unwind destination to a call instruction. #. Use profile metadata to indicate statically known cold paths, even if; dynamic profiling information is not available. This can make a large; difference in code placement and thus the performance of tight loops. #. When generating code for loops, try to avoid terminating the header block of; the loop earlier than necessary. If the terminator of the loop header; block is a loop exiting conditional branch, the effectiveness of LICM will; be limited for loads not in the header. (This is due to the fact that LLVM; may not know such a load is safe to speculatively execute and thus can't; lift an otherwise loop invariant load unless it can prove the exiting; condition is not taken.) It can be profitable, in some cases, to emit such; instructions into the header even if they are not used along a rarely; executed path that exits the loop. This guidance specifically does not; apply if the condition which terminates the loop header is itself invariant,; or can be easily discharged by inspecting the loop index variables. #. In hot loops, consider duplicating instructions from small basic blocks; which end in highly predictable terminators into their successor blocks.; If a hot successor block contains instructions which can be vectorized; with the duplicated ones, this can provide a noticeable throughput; improvement. Note that this is not always profitable and does involve a; potentially large increase in code size. #. When checking a value against a constant, emit the check using a consistent; comparison type. The GVN pass *will* optimize redundant equalities even if; the type of comparison is inverted, but GVN only runs late in the pipeline.; As a result, you may miss the opportunity to run other important; optimizations. #. Avoid using arithmetic intrinsics unless you are *required* by your source; language specification to emit a particular code sequence. The optimizer; is quite good at reasoning about gene",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Frontend/PerformanceTips.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst:7667,Availability,mask,mask,7667,"subtraction and left shift with saturation. .. code-block:: none. %2:_(s32) = G_SADDSAT %0:_(s32), %1:_(s32). G_SHL, G_LSHR, G_ASHR; ^^^^^^^^^^^^^^^^^^^^^. Shift the bits of a scalar left or right inserting zeros (sign-bit for G_ASHR). G_ROTR, G_ROTL; ^^^^^^^^^^^^^^. Rotate the bits right (G_ROTR) or left (G_ROTL). G_ICMP; ^^^^^^. Perform integer comparison producing non-zero (true) or zero (false). It's; target specific whether a true value is 1, ~0U, or some other non-zero value. G_SELECT; ^^^^^^^^. Select between two values depending on a zero/non-zero value. .. code-block:: none. %5:_(s32) = G_SELECT %4(s1), %6, %2. G_PTR_ADD; ^^^^^^^^^. Add a scalar offset in addressible units to a pointer. Addressible units are; typically bytes but this may vary between targets. .. code-block:: none. %1:_(p0) = G_PTR_ADD %0:_(p0), %1:_(s32). .. caution::. There are currently no in-tree targets that use this with addressable units; not equal to 8 bit. G_PTRMASK; ^^^^^^^^^^. Zero out an arbitrary mask of bits of a pointer. The mask type must be; an integer, and the number of vector elements must match for all; operands. This corresponds to `i_intr_llvm_ptrmask`. .. code-block:: none. %2:_(p0) = G_PTRMASK %0, %1. G_SMIN, G_SMAX, G_UMIN, G_UMAX; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Take the minimum/maximum of two values. .. code-block:: none. %5:_(s32) = G_SMIN %6, %2. G_ABS; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Take the absolute value of a signed integer. The absolute value of the minimum; negative value (e.g. the 8-bit value `0x80`) is defined to be itself. .. code-block:: none. %1:_(s32) = G_ABS %0. G_UADDO, G_SADDO, G_USUBO, G_SSUBO, G_SMULO, G_UMULO; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Perform the requested arithmetic and produce a carry output in addition to the; normal result. .. code-block:: none. %3:_(s32), %4:_(s1) = G_UADDO %0, %1. G_UADDE, G_SADDE, G_USUBE, G_SSUBE; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Perform the requested arithmetic and consume a carry input in",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst:7698,Availability,mask,mask,7698,") = G_SADDSAT %0:_(s32), %1:_(s32). G_SHL, G_LSHR, G_ASHR; ^^^^^^^^^^^^^^^^^^^^^. Shift the bits of a scalar left or right inserting zeros (sign-bit for G_ASHR). G_ROTR, G_ROTL; ^^^^^^^^^^^^^^. Rotate the bits right (G_ROTR) or left (G_ROTL). G_ICMP; ^^^^^^. Perform integer comparison producing non-zero (true) or zero (false). It's; target specific whether a true value is 1, ~0U, or some other non-zero value. G_SELECT; ^^^^^^^^. Select between two values depending on a zero/non-zero value. .. code-block:: none. %5:_(s32) = G_SELECT %4(s1), %6, %2. G_PTR_ADD; ^^^^^^^^^. Add a scalar offset in addressible units to a pointer. Addressible units are; typically bytes but this may vary between targets. .. code-block:: none. %1:_(p0) = G_PTR_ADD %0:_(p0), %1:_(s32). .. caution::. There are currently no in-tree targets that use this with addressable units; not equal to 8 bit. G_PTRMASK; ^^^^^^^^^^. Zero out an arbitrary mask of bits of a pointer. The mask type must be; an integer, and the number of vector elements must match for all; operands. This corresponds to `i_intr_llvm_ptrmask`. .. code-block:: none. %2:_(p0) = G_PTRMASK %0, %1. G_SMIN, G_SMAX, G_UMIN, G_UMAX; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Take the minimum/maximum of two values. .. code-block:: none. %5:_(s32) = G_SMIN %6, %2. G_ABS; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Take the absolute value of a signed integer. The absolute value of the minimum; negative value (e.g. the 8-bit value `0x80`) is defined to be itself. .. code-block:: none. %1:_(s32) = G_ABS %0. G_UADDO, G_SADDO, G_USUBO, G_SSUBO, G_SMULO, G_UMULO; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Perform the requested arithmetic and produce a carry output in addition to the; normal result. .. code-block:: none. %3:_(s32), %4:_(s1) = G_UADDO %0, %1. G_UADDE, G_SADDE, G_USUBE, G_SSUBE; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Perform the requested arithmetic and consume a carry input in addition to the; normal input. Also produce a carry output in addition to",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst:14053,Availability,mask,mask,14053," ^^^^^^^^^^^^^^^^^^^. Returns the source operand rounded to the nearest integer with ties away from; zero. See the LLVM LangRef entry on '``llvm.lround.*'`` for details on behaviour. .. code-block:: none. %rounded_32:_(s32) = G_LROUND %round_me:_(s64); %rounded_64:_(s64) = G_LLROUND %round_me:_(s64). Vector Specific Operations; --------------------------. G_CONCAT_VECTORS; ^^^^^^^^^^^^^^^^. Concatenate two vectors to form a longer vector. G_BUILD_VECTOR, G_BUILD_VECTOR_TRUNC; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Create a vector from multiple scalar registers. No implicit; conversion is performed (i.e. the result element type must be the; same as all source operands). The _TRUNC version truncates the larger operand types to fit the; destination vector elt type. G_INSERT_VECTOR_ELT; ^^^^^^^^^^^^^^^^^^^. Insert an element into a vector. G_EXTRACT_VECTOR_ELT; ^^^^^^^^^^^^^^^^^^^^. Extract an element from a vector. G_SHUFFLE_VECTOR; ^^^^^^^^^^^^^^^^. Concatenate two vectors and shuffle the elements according to the mask operand.; The mask operand should be an IR Constant which exactly matches the; corresponding mask for the IR shufflevector instruction. Vector Reduction Operations; ---------------------------. These operations represent horizontal vector reduction, producing a scalar result. G_VECREDUCE_SEQ_FADD, G_VECREDUCE_SEQ_FMUL; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The SEQ variants perform reductions in sequential order. The first operand is; an initial scalar accumulator value, and the second operand is the vector to reduce. G_VECREDUCE_FADD, G_VECREDUCE_FMUL; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. These reductions are relaxed variants which may reduce the elements in any order. G_VECREDUCE_FMAX, G_VECREDUCE_FMIN, G_VECREDUCE_FMAXIMUM, G_VECREDUCE_FMINIMUM; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. FMIN/FMAX/FMINIMUM/FMAXIMUM nodes can have flags, for NaN/NoNaN variants. Integer/bitwise reductions; ^^^^^^^^^^^^^^^^^^^^^^^",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst:14072,Availability,mask,mask,14072,"ro. See the LLVM LangRef entry on '``llvm.lround.*'`` for details on behaviour. .. code-block:: none. %rounded_32:_(s32) = G_LROUND %round_me:_(s64); %rounded_64:_(s64) = G_LLROUND %round_me:_(s64). Vector Specific Operations; --------------------------. G_CONCAT_VECTORS; ^^^^^^^^^^^^^^^^. Concatenate two vectors to form a longer vector. G_BUILD_VECTOR, G_BUILD_VECTOR_TRUNC; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Create a vector from multiple scalar registers. No implicit; conversion is performed (i.e. the result element type must be the; same as all source operands). The _TRUNC version truncates the larger operand types to fit the; destination vector elt type. G_INSERT_VECTOR_ELT; ^^^^^^^^^^^^^^^^^^^. Insert an element into a vector. G_EXTRACT_VECTOR_ELT; ^^^^^^^^^^^^^^^^^^^^. Extract an element from a vector. G_SHUFFLE_VECTOR; ^^^^^^^^^^^^^^^^. Concatenate two vectors and shuffle the elements according to the mask operand.; The mask operand should be an IR Constant which exactly matches the; corresponding mask for the IR shufflevector instruction. Vector Reduction Operations; ---------------------------. These operations represent horizontal vector reduction, producing a scalar result. G_VECREDUCE_SEQ_FADD, G_VECREDUCE_SEQ_FMUL; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The SEQ variants perform reductions in sequential order. The first operand is; an initial scalar accumulator value, and the second operand is the vector to reduce. G_VECREDUCE_FADD, G_VECREDUCE_FMUL; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. These reductions are relaxed variants which may reduce the elements in any order. G_VECREDUCE_FMAX, G_VECREDUCE_FMIN, G_VECREDUCE_FMAXIMUM, G_VECREDUCE_FMINIMUM; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. FMIN/FMAX/FMINIMUM/FMAXIMUM nodes can have flags, for NaN/NoNaN variants. Integer/bitwise reductions; ^^^^^^^^^^^^^^^^^^^^^^^^^^. * G_VECREDUCE_ADD; * G_VECREDUCE_MUL; * G_VECREDUCE_AND; * G_VECREDUCE_OR; * G_VECREDUCE_XOR; * G_V",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst:14151,Availability,mask,mask,14151,"ro. See the LLVM LangRef entry on '``llvm.lround.*'`` for details on behaviour. .. code-block:: none. %rounded_32:_(s32) = G_LROUND %round_me:_(s64); %rounded_64:_(s64) = G_LLROUND %round_me:_(s64). Vector Specific Operations; --------------------------. G_CONCAT_VECTORS; ^^^^^^^^^^^^^^^^. Concatenate two vectors to form a longer vector. G_BUILD_VECTOR, G_BUILD_VECTOR_TRUNC; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Create a vector from multiple scalar registers. No implicit; conversion is performed (i.e. the result element type must be the; same as all source operands). The _TRUNC version truncates the larger operand types to fit the; destination vector elt type. G_INSERT_VECTOR_ELT; ^^^^^^^^^^^^^^^^^^^. Insert an element into a vector. G_EXTRACT_VECTOR_ELT; ^^^^^^^^^^^^^^^^^^^^. Extract an element from a vector. G_SHUFFLE_VECTOR; ^^^^^^^^^^^^^^^^. Concatenate two vectors and shuffle the elements according to the mask operand.; The mask operand should be an IR Constant which exactly matches the; corresponding mask for the IR shufflevector instruction. Vector Reduction Operations; ---------------------------. These operations represent horizontal vector reduction, producing a scalar result. G_VECREDUCE_SEQ_FADD, G_VECREDUCE_SEQ_FMUL; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The SEQ variants perform reductions in sequential order. The first operand is; an initial scalar accumulator value, and the second operand is the vector to reduce. G_VECREDUCE_FADD, G_VECREDUCE_FMUL; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. These reductions are relaxed variants which may reduce the elements in any order. G_VECREDUCE_FMAX, G_VECREDUCE_FMIN, G_VECREDUCE_FMAXIMUM, G_VECREDUCE_FMINIMUM; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. FMIN/FMAX/FMINIMUM/FMAXIMUM nodes can have flags, for NaN/NoNaN variants. Integer/bitwise reductions; ^^^^^^^^^^^^^^^^^^^^^^^^^^. * G_VECREDUCE_ADD; * G_VECREDUCE_MUL; * G_VECREDUCE_AND; * G_VECREDUCE_OR; * G_VECREDUCE_XOR; * G_V",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst:12369,Energy Efficiency,power,power,12369,"signaling NaN, returns a quiet NaN. G_FMAXNUM_IEEE; ^^^^^^^^^^^^^^. Perform floating-point maximum on two values, following the IEEE-754 2008; definition. This differs from FMAXNUM in the handling of signaling NaNs. If one; input is a signaling NaN, returns a quiet NaN. G_FMINIMUM; ^^^^^^^^^^. NaN-propagating minimum that also treat -0.0 as less than 0.0. While; FMINNUM_IEEE follow IEEE 754-2008 semantics, FMINIMUM follows IEEE 754-2018; draft semantics. G_FMAXIMUM; ^^^^^^^^^^. NaN-propagating maximum that also treat -0.0 as less than 0.0. While; FMAXNUM_IEEE follow IEEE 754-2008 semantics, FMAXIMUM follows IEEE 754-2018; draft semantics. G_FADD, G_FSUB, G_FMUL, G_FDIV, G_FREM; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Perform the specified floating point arithmetic. G_FMA; ^^^^^. Perform a fused multiply add (i.e. without the intermediate rounding step). G_FMAD; ^^^^^^. Perform a non-fused multiply add (i.e. with the intermediate rounding step). G_FPOW; ^^^^^^. Raise the first operand to the power of the second. G_FEXP, G_FEXP2; ^^^^^^^^^^^^^^^. Calculate the base-e or base-2 exponential of a value. G_FLOG, G_FLOG2, G_FLOG10; ^^^^^^^^^^^^^^^^^^^^^^^^^. Calculate the base-e, base-2, or base-10 respectively. G_FCEIL, G_FCOS, G_FSIN, G_FSQRT, G_FFLOOR, G_FRINT, G_FNEARBYINT; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. These correspond to the standard C functions of the same name. G_INTRINSIC_TRUNC; ^^^^^^^^^^^^^^^^^. Returns the operand rounded to the nearest integer not larger in magnitude than the operand. G_INTRINSIC_ROUND; ^^^^^^^^^^^^^^^^^. Returns the operand rounded to the nearest integer. G_LROUND, G_LLROUND; ^^^^^^^^^^^^^^^^^^^. Returns the source operand rounded to the nearest integer with ties away from; zero. See the LLVM LangRef entry on '``llvm.lround.*'`` for details on behaviour. .. code-block:: none. %rounded_32:_(s32) = G_LROUND %round_me:_(s64); %rounded_64:_(s64) = G_LLROUND %round_me:_(s64). Vector Specific Operations; -------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst:14579,Energy Efficiency,reduce,reduce,14579,"^^^^^^^^^^^. Create a vector from multiple scalar registers. No implicit; conversion is performed (i.e. the result element type must be the; same as all source operands). The _TRUNC version truncates the larger operand types to fit the; destination vector elt type. G_INSERT_VECTOR_ELT; ^^^^^^^^^^^^^^^^^^^. Insert an element into a vector. G_EXTRACT_VECTOR_ELT; ^^^^^^^^^^^^^^^^^^^^. Extract an element from a vector. G_SHUFFLE_VECTOR; ^^^^^^^^^^^^^^^^. Concatenate two vectors and shuffle the elements according to the mask operand.; The mask operand should be an IR Constant which exactly matches the; corresponding mask for the IR shufflevector instruction. Vector Reduction Operations; ---------------------------. These operations represent horizontal vector reduction, producing a scalar result. G_VECREDUCE_SEQ_FADD, G_VECREDUCE_SEQ_FMUL; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The SEQ variants perform reductions in sequential order. The first operand is; an initial scalar accumulator value, and the second operand is the vector to reduce. G_VECREDUCE_FADD, G_VECREDUCE_FMUL; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. These reductions are relaxed variants which may reduce the elements in any order. G_VECREDUCE_FMAX, G_VECREDUCE_FMIN, G_VECREDUCE_FMAXIMUM, G_VECREDUCE_FMINIMUM; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. FMIN/FMAX/FMINIMUM/FMAXIMUM nodes can have flags, for NaN/NoNaN variants. Integer/bitwise reductions; ^^^^^^^^^^^^^^^^^^^^^^^^^^. * G_VECREDUCE_ADD; * G_VECREDUCE_MUL; * G_VECREDUCE_AND; * G_VECREDUCE_OR; * G_VECREDUCE_XOR; * G_VECREDUCE_SMAX; * G_VECREDUCE_SMIN; * G_VECREDUCE_UMAX; * G_VECREDUCE_UMIN. Integer reductions may have a result type larger than the vector element type.; However, the reduction is performed using the vector element type and the value; in the top bits is unspecified. Memory Operations; -----------------. G_LOAD, G_SEXTLOAD, G_ZEXTLOAD; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Generic load. Expects a MachineMe",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst:14707,Energy Efficiency,reduce,reduce,14707,"s). The _TRUNC version truncates the larger operand types to fit the; destination vector elt type. G_INSERT_VECTOR_ELT; ^^^^^^^^^^^^^^^^^^^. Insert an element into a vector. G_EXTRACT_VECTOR_ELT; ^^^^^^^^^^^^^^^^^^^^. Extract an element from a vector. G_SHUFFLE_VECTOR; ^^^^^^^^^^^^^^^^. Concatenate two vectors and shuffle the elements according to the mask operand.; The mask operand should be an IR Constant which exactly matches the; corresponding mask for the IR shufflevector instruction. Vector Reduction Operations; ---------------------------. These operations represent horizontal vector reduction, producing a scalar result. G_VECREDUCE_SEQ_FADD, G_VECREDUCE_SEQ_FMUL; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The SEQ variants perform reductions in sequential order. The first operand is; an initial scalar accumulator value, and the second operand is the vector to reduce. G_VECREDUCE_FADD, G_VECREDUCE_FMUL; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. These reductions are relaxed variants which may reduce the elements in any order. G_VECREDUCE_FMAX, G_VECREDUCE_FMIN, G_VECREDUCE_FMAXIMUM, G_VECREDUCE_FMINIMUM; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. FMIN/FMAX/FMINIMUM/FMAXIMUM nodes can have flags, for NaN/NoNaN variants. Integer/bitwise reductions; ^^^^^^^^^^^^^^^^^^^^^^^^^^. * G_VECREDUCE_ADD; * G_VECREDUCE_MUL; * G_VECREDUCE_AND; * G_VECREDUCE_OR; * G_VECREDUCE_XOR; * G_VECREDUCE_SMAX; * G_VECREDUCE_SMIN; * G_VECREDUCE_UMAX; * G_VECREDUCE_UMIN. Integer reductions may have a result type larger than the vector element type.; However, the reduction is performed using the vector element type and the value; in the top bits is unspecified. Memory Operations; -----------------. G_LOAD, G_SEXTLOAD, G_ZEXTLOAD; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Generic load. Expects a MachineMemOperand in addition to explicit; operands. If the result size is larger than the memory size, the; high bits are undefined, sign-extended, or zero-extended respectiv",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst:7201,Integrability,depend,depending,7201," = G_ADD %src0:_(s32), %src1:_(s32). The above example adds %src1 to %src0 and stores the result in %dst. G_SDIVREM, G_UDIVREM; ^^^^^^^^^^^^^^^^^^^^. Perform integer division and remainder thereby producing two results. .. code-block:: none. %div:_(s32), %rem:_(s32) = G_SDIVREM %0:_(s32), %1:_(s32). G_SADDSAT, G_UADDSAT, G_SSUBSAT, G_USUBSAT, G_SSHLSAT, G_USHLSAT; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Signed and unsigned addition, subtraction and left shift with saturation. .. code-block:: none. %2:_(s32) = G_SADDSAT %0:_(s32), %1:_(s32). G_SHL, G_LSHR, G_ASHR; ^^^^^^^^^^^^^^^^^^^^^. Shift the bits of a scalar left or right inserting zeros (sign-bit for G_ASHR). G_ROTR, G_ROTL; ^^^^^^^^^^^^^^. Rotate the bits right (G_ROTR) or left (G_ROTL). G_ICMP; ^^^^^^. Perform integer comparison producing non-zero (true) or zero (false). It's; target specific whether a true value is 1, ~0U, or some other non-zero value. G_SELECT; ^^^^^^^^. Select between two values depending on a zero/non-zero value. .. code-block:: none. %5:_(s32) = G_SELECT %4(s1), %6, %2. G_PTR_ADD; ^^^^^^^^^. Add a scalar offset in addressible units to a pointer. Addressible units are; typically bytes but this may vary between targets. .. code-block:: none. %1:_(p0) = G_PTR_ADD %0:_(p0), %1:_(s32). .. caution::. There are currently no in-tree targets that use this with addressable units; not equal to 8 bit. G_PTRMASK; ^^^^^^^^^^. Zero out an arbitrary mask of bits of a pointer. The mask type must be; an integer, and the number of vector elements must match for all; operands. This corresponds to `i_intr_llvm_ptrmask`. .. code-block:: none. %2:_(p0) = G_PTRMASK %0, %1. G_SMIN, G_SMAX, G_UMIN, G_UMAX; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Take the minimum/maximum of two values. .. code-block:: none. %5:_(s32) = G_SMIN %6, %2. G_ABS; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Take the absolute value of a signed integer. The absolute value of the minimum; negative value (e.g. the 8-bit value `0x80`) i",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst:20145,Integrability,rout,routines,20145,"^^^^^. Conditional branch. .. code-block:: none. G_BRCOND %condition, %basicblock.<id>. G_BRINDIRECT; ^^^^^^^^^^^^. Indirect branch. .. code-block:: none. G_BRINDIRECT %src(p0). G_BRJT; ^^^^^^. Indirect branch to jump table entry. .. code-block:: none. G_BRJT %ptr(p0), %jti, %idx(s64). G_JUMP_TABLE; ^^^^^^^^^^^^. Generates a pointer to the address of the jump table specified by the source; operand. The source operand is a jump table index.; G_JUMP_TABLE can be used in conjunction with G_BRJT to support jump table; codegen with GlobalISel. .. code-block:: none. %dst:_(p0) = G_JUMP_TABLE %jump-table.0. The above example generates a pointer to the source jump table index. G_INVOKE_REGION_START; ^^^^^^^^^^^^^^^^^^^^^. A marker instruction that acts as a pseudo-terminator for regions of code that may; throw exceptions. Being a terminator, it prevents code from being inserted after; it during passes like legalization. This is needed because calls to exception; throw routines do not return, so no code that must be on an executable path must; be placed after throwing. G_INTRINSIC, G_INTRINSIC_CONVERGENT; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Call an intrinsic that has no side-effects. The _CONVERGENT variant corresponds to an LLVM IR intrinsic marked `convergent`. .. note::. Unlike SelectionDAG, there is no _VOID variant. Both of these are permitted; to have zero, one, or multiple results. G_INTRINSIC_W_SIDE_EFFECTS, G_INTRINSIC_CONVERGENT_W_SIDE_EFFECTS; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Call an intrinsic that is considered to have unknown side-effects and as such; cannot be reordered across other side-effecting instructions. The _CONVERGENT variant corresponds to an LLVM IR intrinsic marked `convergent`. .. note::. Unlike SelectionDAG, there is no _VOID variant. Both of these are permitted; to have zero, one, or multiple results. Variadic Arguments; ------------------. G_VASTART; ^^^^^^^^^. .. caution::. I found no documentation for this ins",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst:1360,Modifiability,extend,extend,1360,":: none. %0:_(s32) = G_CONSTANT i32 1. G_FCONSTANT; ^^^^^^^^^^^. A floating point constant. .. code-block:: none. %0:_(s32) = G_FCONSTANT float 1.0. G_FRAME_INDEX; ^^^^^^^^^^^^^. The address of an object in the stack frame. .. code-block:: none. %1:_(p0) = G_FRAME_INDEX %stack.0.ptr0. G_GLOBAL_VALUE; ^^^^^^^^^^^^^^. The address of a global value. .. code-block:: none. %0(p0) = G_GLOBAL_VALUE @var_local. G_BLOCK_ADDR; ^^^^^^^^^^^^. The address of a basic block. .. code-block:: none. %0:_(p0) = G_BLOCK_ADDR blockaddress(@test_blockaddress, %ir-block.block). G_CONSTANT_POOL; ^^^^^^^^^^^^^^^. The address of an object in the constant pool. .. code-block:: none. %0:_(p0) = G_CONSTANT_POOL %const.0. Integer Extension and Truncation; --------------------------------. G_ANYEXT; ^^^^^^^^. Extend the underlying scalar type of an operation, leaving the high bits; unspecified. .. code-block:: none. %1:_(s32) = G_ANYEXT %0:_(s16). G_SEXT; ^^^^^^. Sign extend the underlying scalar type of an operation, copying the sign bit; into the newly-created space. .. code-block:: none. %1:_(s32) = G_SEXT %0:_(s16). G_SEXT_INREG; ^^^^^^^^^^^^. Sign extend the value from an arbitrary bit position, copying the sign bit; into all bits above it. This is equivalent to a shl + ashr pair with an; appropriate shift amount. $sz is an immediate (MachineOperand::isImm(); returns true) to allow targets to have some bitwidths legal and others; lowered. This opcode is particularly useful if the target has sign-extension; instructions that are cheaper than the constituent shifts as the optimizer is; able to make decisions on whether it's better to hang on to the G_SEXT_INREG; or to lower it and optimize the individual shifts. .. code-block:: none. %1:_(s32) = G_SEXT_INREG %0:_(s32), 16. G_ZEXT; ^^^^^^. Zero extend the underlying scalar type of an operation, putting zero bits; into the newly-created space. .. code-block:: none. %1:_(s32) = G_ZEXT %0:_(s16). G_TRUNC; ^^^^^^^. Truncate the underlying scalar ty",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst:1548,Modifiability,extend,extend,1548,"ddress of an object in the stack frame. .. code-block:: none. %1:_(p0) = G_FRAME_INDEX %stack.0.ptr0. G_GLOBAL_VALUE; ^^^^^^^^^^^^^^. The address of a global value. .. code-block:: none. %0(p0) = G_GLOBAL_VALUE @var_local. G_BLOCK_ADDR; ^^^^^^^^^^^^. The address of a basic block. .. code-block:: none. %0:_(p0) = G_BLOCK_ADDR blockaddress(@test_blockaddress, %ir-block.block). G_CONSTANT_POOL; ^^^^^^^^^^^^^^^. The address of an object in the constant pool. .. code-block:: none. %0:_(p0) = G_CONSTANT_POOL %const.0. Integer Extension and Truncation; --------------------------------. G_ANYEXT; ^^^^^^^^. Extend the underlying scalar type of an operation, leaving the high bits; unspecified. .. code-block:: none. %1:_(s32) = G_ANYEXT %0:_(s16). G_SEXT; ^^^^^^. Sign extend the underlying scalar type of an operation, copying the sign bit; into the newly-created space. .. code-block:: none. %1:_(s32) = G_SEXT %0:_(s16). G_SEXT_INREG; ^^^^^^^^^^^^. Sign extend the value from an arbitrary bit position, copying the sign bit; into all bits above it. This is equivalent to a shl + ashr pair with an; appropriate shift amount. $sz is an immediate (MachineOperand::isImm(); returns true) to allow targets to have some bitwidths legal and others; lowered. This opcode is particularly useful if the target has sign-extension; instructions that are cheaper than the constituent shifts as the optimizer is; able to make decisions on whether it's better to hang on to the G_SEXT_INREG; or to lower it and optimize the individual shifts. .. code-block:: none. %1:_(s32) = G_SEXT_INREG %0:_(s32), 16. G_ZEXT; ^^^^^^. Zero extend the underlying scalar type of an operation, putting zero bits; into the newly-created space. .. code-block:: none. %1:_(s32) = G_ZEXT %0:_(s16). G_TRUNC; ^^^^^^^. Truncate the underlying scalar type of an operation. This is equivalent to; G_EXTRACT for scalar types, but acts elementwise on vectors. .. code-block:: none. %1:_(s16) = G_TRUNC %0:_(s32). Type Conversions; ---------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst:2205,Modifiability,extend,extend,2205,"aving the high bits; unspecified. .. code-block:: none. %1:_(s32) = G_ANYEXT %0:_(s16). G_SEXT; ^^^^^^. Sign extend the underlying scalar type of an operation, copying the sign bit; into the newly-created space. .. code-block:: none. %1:_(s32) = G_SEXT %0:_(s16). G_SEXT_INREG; ^^^^^^^^^^^^. Sign extend the value from an arbitrary bit position, copying the sign bit; into all bits above it. This is equivalent to a shl + ashr pair with an; appropriate shift amount. $sz is an immediate (MachineOperand::isImm(); returns true) to allow targets to have some bitwidths legal and others; lowered. This opcode is particularly useful if the target has sign-extension; instructions that are cheaper than the constituent shifts as the optimizer is; able to make decisions on whether it's better to hang on to the G_SEXT_INREG; or to lower it and optimize the individual shifts. .. code-block:: none. %1:_(s32) = G_SEXT_INREG %0:_(s32), 16. G_ZEXT; ^^^^^^. Zero extend the underlying scalar type of an operation, putting zero bits; into the newly-created space. .. code-block:: none. %1:_(s32) = G_ZEXT %0:_(s16). G_TRUNC; ^^^^^^^. Truncate the underlying scalar type of an operation. This is equivalent to; G_EXTRACT for scalar types, but acts elementwise on vectors. .. code-block:: none. %1:_(s16) = G_TRUNC %0:_(s32). Type Conversions; ----------------. G_INTTOPTR; ^^^^^^^^^^. Convert an integer to a pointer. .. code-block:: none. %1:_(p0) = G_INTTOPTR %0:_(s32). G_PTRTOINT; ^^^^^^^^^^. Convert a pointer to an integer. .. code-block:: none. %1:_(s32) = G_PTRTOINT %0:_(p0). G_BITCAST; ^^^^^^^^^. Reinterpret a value as a new type. This is usually done without; changing any bits but this is not always the case due a subtlety in the; definition of the :ref:`LLVM-IR Bitcast Instruction <i_bitcast>`. It; is allowed to bitcast between pointers with the same size, but; different address spaces. .. code-block:: none. %1:_(s64) = G_BITCAST %0:_(<2 x s32>). G_ADDRSPACE_CAST; ^^^^^^^^^^^^^^^^. Convert a ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst:5302,Modifiability,extend,extends,5302," registers of the specified size, starting from blocks given by; indexes. This will almost certainly be mapped to sub-register COPYs after; register banks have been selected.; The output operands are always ordered from lowest bits to highest:. .. code-block:: none. %bits_0_7:(s8), %bits_8_15:(s8),; %bits_16_23:(s8), %bits_24_31:(s8) = G_UNMERGE_VALUES %0:(s32). G_BSWAP; ^^^^^^^. Reverse the order of the bytes in a scalar. .. code-block:: none. %1:_(s32) = G_BSWAP %0:_(s32). G_BITREVERSE; ^^^^^^^^^^^^. Reverse the order of the bits in a scalar. .. code-block:: none. %1:_(s32) = G_BITREVERSE %0:_(s32). G_SBFX, G_UBFX; ^^^^^^^^^^^^^^. Extract a range of bits from a register. The source operands are registers as follows:. - Source; - The least-significant bit for the extraction; - The width of the extraction. The least-significant bit (lsb) and width operands are in the range:. ::. 0 <= lsb < lsb + width <= source bitwidth, where all values are unsigned. G_SBFX sign-extends the result, while G_UBFX zero-extends the result. .. code-block:: none. ; Extract 5 bits starting at bit 1 from %x and store them in %a.; ; Sign-extend the result.; ;; ; Example:; ; %x = 0...0000[10110]1 ---> %a = 1...111111[10110]; %lsb_one = G_CONSTANT i32 1; %width_five = G_CONSTANT i32 5; %a:_(s32) = G_SBFX %x, %lsb_one, %width_five. ; Extract 3 bits starting at bit 2 from %x and store them in %b. Zero-extend; ; the result.; ;; ; Example:; ; %x = 1...11111[100]11 ---> %b = 0...00000[100]; %lsb_two = G_CONSTANT i32 2; %width_three = G_CONSTANT i32 3; %b:_(s32) = G_UBFX %x, %lsb_two, %width_three. Integer Operations; -------------------. G_ADD, G_SUB, G_MUL, G_AND, G_OR, G_XOR, G_SDIV, G_UDIV, G_SREM, G_UREM; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. These each perform their respective integer arithmetic on a scalar. .. code-block:: none. %dst:_(s32) = G_ADD %src0:_(s32), %src1:_(s32). The above example adds %src1 to %src0 and stores the result in %dst. G_SDIVREM, G_",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst:5340,Modifiability,extend,extends,5340," registers of the specified size, starting from blocks given by; indexes. This will almost certainly be mapped to sub-register COPYs after; register banks have been selected.; The output operands are always ordered from lowest bits to highest:. .. code-block:: none. %bits_0_7:(s8), %bits_8_15:(s8),; %bits_16_23:(s8), %bits_24_31:(s8) = G_UNMERGE_VALUES %0:(s32). G_BSWAP; ^^^^^^^. Reverse the order of the bytes in a scalar. .. code-block:: none. %1:_(s32) = G_BSWAP %0:_(s32). G_BITREVERSE; ^^^^^^^^^^^^. Reverse the order of the bits in a scalar. .. code-block:: none. %1:_(s32) = G_BITREVERSE %0:_(s32). G_SBFX, G_UBFX; ^^^^^^^^^^^^^^. Extract a range of bits from a register. The source operands are registers as follows:. - Source; - The least-significant bit for the extraction; - The width of the extraction. The least-significant bit (lsb) and width operands are in the range:. ::. 0 <= lsb < lsb + width <= source bitwidth, where all values are unsigned. G_SBFX sign-extends the result, while G_UBFX zero-extends the result. .. code-block:: none. ; Extract 5 bits starting at bit 1 from %x and store them in %a.; ; Sign-extend the result.; ;; ; Example:; ; %x = 0...0000[10110]1 ---> %a = 1...111111[10110]; %lsb_one = G_CONSTANT i32 1; %width_five = G_CONSTANT i32 5; %a:_(s32) = G_SBFX %x, %lsb_one, %width_five. ; Extract 3 bits starting at bit 2 from %x and store them in %b. Zero-extend; ; the result.; ;; ; Example:; ; %x = 1...11111[100]11 ---> %b = 0...00000[100]; %lsb_two = G_CONSTANT i32 2; %width_three = G_CONSTANT i32 3; %b:_(s32) = G_UBFX %x, %lsb_two, %width_three. Integer Operations; -------------------. G_ADD, G_SUB, G_MUL, G_AND, G_OR, G_XOR, G_SDIV, G_UDIV, G_SREM, G_UREM; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. These each perform their respective integer arithmetic on a scalar. .. code-block:: none. %dst:_(s32) = G_ADD %src0:_(s32), %src1:_(s32). The above example adds %src1 to %src0 and stores the result in %dst. G_SDIVREM, G_",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst:5455,Modifiability,extend,extend,5455,"ter; register banks have been selected.; The output operands are always ordered from lowest bits to highest:. .. code-block:: none. %bits_0_7:(s8), %bits_8_15:(s8),; %bits_16_23:(s8), %bits_24_31:(s8) = G_UNMERGE_VALUES %0:(s32). G_BSWAP; ^^^^^^^. Reverse the order of the bytes in a scalar. .. code-block:: none. %1:_(s32) = G_BSWAP %0:_(s32). G_BITREVERSE; ^^^^^^^^^^^^. Reverse the order of the bits in a scalar. .. code-block:: none. %1:_(s32) = G_BITREVERSE %0:_(s32). G_SBFX, G_UBFX; ^^^^^^^^^^^^^^. Extract a range of bits from a register. The source operands are registers as follows:. - Source; - The least-significant bit for the extraction; - The width of the extraction. The least-significant bit (lsb) and width operands are in the range:. ::. 0 <= lsb < lsb + width <= source bitwidth, where all values are unsigned. G_SBFX sign-extends the result, while G_UBFX zero-extends the result. .. code-block:: none. ; Extract 5 bits starting at bit 1 from %x and store them in %a.; ; Sign-extend the result.; ;; ; Example:; ; %x = 0...0000[10110]1 ---> %a = 1...111111[10110]; %lsb_one = G_CONSTANT i32 1; %width_five = G_CONSTANT i32 5; %a:_(s32) = G_SBFX %x, %lsb_one, %width_five. ; Extract 3 bits starting at bit 2 from %x and store them in %b. Zero-extend; ; the result.; ;; ; Example:; ; %x = 1...11111[100]11 ---> %b = 0...00000[100]; %lsb_two = G_CONSTANT i32 2; %width_three = G_CONSTANT i32 3; %b:_(s32) = G_UBFX %x, %lsb_two, %width_three. Integer Operations; -------------------. G_ADD, G_SUB, G_MUL, G_AND, G_OR, G_XOR, G_SDIV, G_UDIV, G_SREM, G_UREM; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. These each perform their respective integer arithmetic on a scalar. .. code-block:: none. %dst:_(s32) = G_ADD %src0:_(s32), %src1:_(s32). The above example adds %src1 to %src0 and stores the result in %dst. G_SDIVREM, G_UDIVREM; ^^^^^^^^^^^^^^^^^^^^. Perform integer division and remainder thereby producing two results. .. code-block:: none. %div:_(s32), ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst:5720,Modifiability,extend,extend,5720," the bytes in a scalar. .. code-block:: none. %1:_(s32) = G_BSWAP %0:_(s32). G_BITREVERSE; ^^^^^^^^^^^^. Reverse the order of the bits in a scalar. .. code-block:: none. %1:_(s32) = G_BITREVERSE %0:_(s32). G_SBFX, G_UBFX; ^^^^^^^^^^^^^^. Extract a range of bits from a register. The source operands are registers as follows:. - Source; - The least-significant bit for the extraction; - The width of the extraction. The least-significant bit (lsb) and width operands are in the range:. ::. 0 <= lsb < lsb + width <= source bitwidth, where all values are unsigned. G_SBFX sign-extends the result, while G_UBFX zero-extends the result. .. code-block:: none. ; Extract 5 bits starting at bit 1 from %x and store them in %a.; ; Sign-extend the result.; ;; ; Example:; ; %x = 0...0000[10110]1 ---> %a = 1...111111[10110]; %lsb_one = G_CONSTANT i32 1; %width_five = G_CONSTANT i32 5; %a:_(s32) = G_SBFX %x, %lsb_one, %width_five. ; Extract 3 bits starting at bit 2 from %x and store them in %b. Zero-extend; ; the result.; ;; ; Example:; ; %x = 1...11111[100]11 ---> %b = 0...00000[100]; %lsb_two = G_CONSTANT i32 2; %width_three = G_CONSTANT i32 3; %b:_(s32) = G_UBFX %x, %lsb_two, %width_three. Integer Operations; -------------------. G_ADD, G_SUB, G_MUL, G_AND, G_OR, G_XOR, G_SDIV, G_UDIV, G_SREM, G_UREM; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. These each perform their respective integer arithmetic on a scalar. .. code-block:: none. %dst:_(s32) = G_ADD %src0:_(s32), %src1:_(s32). The above example adds %src1 to %src0 and stores the result in %dst. G_SDIVREM, G_UDIVREM; ^^^^^^^^^^^^^^^^^^^^. Perform integer division and remainder thereby producing two results. .. code-block:: none. %div:_(s32), %rem:_(s32) = G_SDIVREM %0:_(s32), %1:_(s32). G_SADDSAT, G_UADDSAT, G_SSUBSAT, G_USUBSAT, G_SSHLSAT, G_USHLSAT; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Signed and unsigned addition, subtraction and left shift with saturation. .. code-block:: ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst:15663,Modifiability,extend,extended,15663,"^^^^^^^^^^^^^^^^^^. These reductions are relaxed variants which may reduce the elements in any order. G_VECREDUCE_FMAX, G_VECREDUCE_FMIN, G_VECREDUCE_FMAXIMUM, G_VECREDUCE_FMINIMUM; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. FMIN/FMAX/FMINIMUM/FMAXIMUM nodes can have flags, for NaN/NoNaN variants. Integer/bitwise reductions; ^^^^^^^^^^^^^^^^^^^^^^^^^^. * G_VECREDUCE_ADD; * G_VECREDUCE_MUL; * G_VECREDUCE_AND; * G_VECREDUCE_OR; * G_VECREDUCE_XOR; * G_VECREDUCE_SMAX; * G_VECREDUCE_SMIN; * G_VECREDUCE_UMAX; * G_VECREDUCE_UMIN. Integer reductions may have a result type larger than the vector element type.; However, the reduction is performed using the vector element type and the value; in the top bits is unspecified. Memory Operations; -----------------. G_LOAD, G_SEXTLOAD, G_ZEXTLOAD; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Generic load. Expects a MachineMemOperand in addition to explicit; operands. If the result size is larger than the memory size, the; high bits are undefined, sign-extended, or zero-extended respectively. Only G_LOAD is valid if the result is a vector type. If the result is larger; than the memory size, the high elements are undefined (i.e. this is not a; per-element, vector anyextload). Unlike in SelectionDAG, atomic loads are expressed with the same; opcodes as regular loads. G_LOAD, G_SEXTLOAD and G_ZEXTLOAD may all; have atomic memory operands. G_INDEXED_LOAD; ^^^^^^^^^^^^^^. Generic indexed load. Combines a GEP with a load. $newaddr is set to $base + $offset.; If $am is 0 (post-indexed), then the value is loaded from $base; if $am is 1 (pre-indexed); then the value is loaded from $newaddr. G_INDEXED_SEXTLOAD; ^^^^^^^^^^^^^^^^^^. Same as G_INDEXED_LOAD except that the load performed is sign-extending, as with G_SEXTLOAD. G_INDEXED_ZEXTLOAD; ^^^^^^^^^^^^^^^^^^. Same as G_INDEXED_LOAD except that the load performed is zero-extending, as with G_ZEXTLOAD. G_STORE; ^^^^^^^. Generic store. Expects a MachineMemOperand in addit",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst:15681,Modifiability,extend,extended,15681,"^^^^^^^^^^^^^^^^^^. These reductions are relaxed variants which may reduce the elements in any order. G_VECREDUCE_FMAX, G_VECREDUCE_FMIN, G_VECREDUCE_FMAXIMUM, G_VECREDUCE_FMINIMUM; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. FMIN/FMAX/FMINIMUM/FMAXIMUM nodes can have flags, for NaN/NoNaN variants. Integer/bitwise reductions; ^^^^^^^^^^^^^^^^^^^^^^^^^^. * G_VECREDUCE_ADD; * G_VECREDUCE_MUL; * G_VECREDUCE_AND; * G_VECREDUCE_OR; * G_VECREDUCE_XOR; * G_VECREDUCE_SMAX; * G_VECREDUCE_SMIN; * G_VECREDUCE_UMAX; * G_VECREDUCE_UMIN. Integer reductions may have a result type larger than the vector element type.; However, the reduction is performed using the vector element type and the value; in the top bits is unspecified. Memory Operations; -----------------. G_LOAD, G_SEXTLOAD, G_ZEXTLOAD; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Generic load. Expects a MachineMemOperand in addition to explicit; operands. If the result size is larger than the memory size, the; high bits are undefined, sign-extended, or zero-extended respectively. Only G_LOAD is valid if the result is a vector type. If the result is larger; than the memory size, the high elements are undefined (i.e. this is not a; per-element, vector anyextload). Unlike in SelectionDAG, atomic loads are expressed with the same; opcodes as regular loads. G_LOAD, G_SEXTLOAD and G_ZEXTLOAD may all; have atomic memory operands. G_INDEXED_LOAD; ^^^^^^^^^^^^^^. Generic indexed load. Combines a GEP with a load. $newaddr is set to $base + $offset.; If $am is 0 (post-indexed), then the value is loaded from $base; if $am is 1 (pre-indexed); then the value is loaded from $newaddr. G_INDEXED_SEXTLOAD; ^^^^^^^^^^^^^^^^^^. Same as G_INDEXED_LOAD except that the load performed is sign-extending, as with G_SEXTLOAD. G_INDEXED_ZEXTLOAD; ^^^^^^^^^^^^^^^^^^. Same as G_INDEXED_LOAD except that the load performed is zero-extending, as with G_ZEXTLOAD. G_STORE; ^^^^^^^. Generic store. Expects a MachineMemOperand in addit",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst:16407,Modifiability,extend,extending,16407,"cified. Memory Operations; -----------------. G_LOAD, G_SEXTLOAD, G_ZEXTLOAD; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Generic load. Expects a MachineMemOperand in addition to explicit; operands. If the result size is larger than the memory size, the; high bits are undefined, sign-extended, or zero-extended respectively. Only G_LOAD is valid if the result is a vector type. If the result is larger; than the memory size, the high elements are undefined (i.e. this is not a; per-element, vector anyextload). Unlike in SelectionDAG, atomic loads are expressed with the same; opcodes as regular loads. G_LOAD, G_SEXTLOAD and G_ZEXTLOAD may all; have atomic memory operands. G_INDEXED_LOAD; ^^^^^^^^^^^^^^. Generic indexed load. Combines a GEP with a load. $newaddr is set to $base + $offset.; If $am is 0 (post-indexed), then the value is loaded from $base; if $am is 1 (pre-indexed); then the value is loaded from $newaddr. G_INDEXED_SEXTLOAD; ^^^^^^^^^^^^^^^^^^. Same as G_INDEXED_LOAD except that the load performed is sign-extending, as with G_SEXTLOAD. G_INDEXED_ZEXTLOAD; ^^^^^^^^^^^^^^^^^^. Same as G_INDEXED_LOAD except that the load performed is zero-extending, as with G_ZEXTLOAD. G_STORE; ^^^^^^^. Generic store. Expects a MachineMemOperand in addition to explicit; operands. If the stored value size is greater than the memory size,; the high bits are implicitly truncated. If this is a vector store, the; high elements are discarded (i.e. this does not function as a per-lane; vector, truncating store). G_INDEXED_STORE; ^^^^^^^^^^^^^^^. Combines a store with a GEP. See description of G_INDEXED_LOAD for indexing behaviour. G_ATOMIC_CMPXCHG_WITH_SUCCESS; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Generic atomic cmpxchg with internal success check. Expects a; MachineMemOperand in addition to explicit operands. G_ATOMIC_CMPXCHG; ^^^^^^^^^^^^^^^^. Generic atomic cmpxchg. Expects a MachineMemOperand in addition to explicit; operands. G_ATOMICRMW_XCHG, G_ATOMICRMW_ADD, G_ATOMICRMW_SUB, G_ATOMICRMW_AND,; G_A",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst:16540,Modifiability,extend,extending,16540," MachineMemOperand in addition to explicit; operands. If the result size is larger than the memory size, the; high bits are undefined, sign-extended, or zero-extended respectively. Only G_LOAD is valid if the result is a vector type. If the result is larger; than the memory size, the high elements are undefined (i.e. this is not a; per-element, vector anyextload). Unlike in SelectionDAG, atomic loads are expressed with the same; opcodes as regular loads. G_LOAD, G_SEXTLOAD and G_ZEXTLOAD may all; have atomic memory operands. G_INDEXED_LOAD; ^^^^^^^^^^^^^^. Generic indexed load. Combines a GEP with a load. $newaddr is set to $base + $offset.; If $am is 0 (post-indexed), then the value is loaded from $base; if $am is 1 (pre-indexed); then the value is loaded from $newaddr. G_INDEXED_SEXTLOAD; ^^^^^^^^^^^^^^^^^^. Same as G_INDEXED_LOAD except that the load performed is sign-extending, as with G_SEXTLOAD. G_INDEXED_ZEXTLOAD; ^^^^^^^^^^^^^^^^^^. Same as G_INDEXED_LOAD except that the load performed is zero-extending, as with G_ZEXTLOAD. G_STORE; ^^^^^^^. Generic store. Expects a MachineMemOperand in addition to explicit; operands. If the stored value size is greater than the memory size,; the high bits are implicitly truncated. If this is a vector store, the; high elements are discarded (i.e. this does not function as a per-lane; vector, truncating store). G_INDEXED_STORE; ^^^^^^^^^^^^^^^. Combines a store with a GEP. See description of G_INDEXED_LOAD for indexing behaviour. G_ATOMIC_CMPXCHG_WITH_SUCCESS; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Generic atomic cmpxchg with internal success check. Expects a; MachineMemOperand in addition to explicit operands. G_ATOMIC_CMPXCHG; ^^^^^^^^^^^^^^^^. Generic atomic cmpxchg. Expects a MachineMemOperand in addition to explicit; operands. G_ATOMICRMW_XCHG, G_ATOMICRMW_ADD, G_ATOMICRMW_SUB, G_ATOMICRMW_AND,; G_ATOMICRMW_NAND, G_ATOMICRMW_OR, G_ATOMICRMW_XOR, G_ATOMICRMW_MAX,; G_ATOMICRMW_MIN, G_ATOMICRMW_UMAX, G_ATOMICRMW_UMIN, G_ATOMICRMW_FA",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst:21849,Modifiability,extend,extended,21849,"ng instructions. The _CONVERGENT variant corresponds to an LLVM IR intrinsic marked `convergent`. .. note::. Unlike SelectionDAG, there is no _VOID variant. Both of these are permitted; to have zero, one, or multiple results. Variadic Arguments; ------------------. G_VASTART; ^^^^^^^^^. .. caution::. I found no documentation for this instruction at the time of writing. G_VAARG; ^^^^^^^. .. caution::. I found no documentation for this instruction at the time of writing. Other Operations; ----------------. G_DYN_STACKALLOC; ^^^^^^^^^^^^^^^^. Dynamically realigns the stack pointer to the specified size and alignment.; An alignment value of `0` or `1` means no specific alignment. .. code-block:: none. %8:_(p0) = G_DYN_STACKALLOC %7(s64), 32. Optimization Hints; ------------------. These instructions do not correspond to any target instructions. They act as; hints for various combines. G_ASSERT_SEXT, G_ASSERT_ZEXT; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. This signifies that the contents of a register were previously extended from a; smaller type. The smaller type is denoted using an immediate operand. For scalars, this is the; width of the entire smaller type. For vectors, this is the width of the smaller; element type. .. code-block:: none. %x_was_zexted:_(s32) = G_ASSERT_ZEXT %x(s32), 16; %y_was_zexted:_(<2 x s32>) = G_ASSERT_ZEXT %y(<2 x s32>), 16. %z_was_sexted:_(s32) = G_ASSERT_SEXT %z(s32), 8. G_ASSERT_SEXT and G_ASSERT_ZEXT act like copies, albeit with some restrictions. The source and destination registers must. - Be virtual; - Belong to the same register class; - Belong to the same register bank. It should always be safe to. - Look through the source register; - Replace the destination register with the source register. Miscellaneous; -------------. G_CONSTANT_FOLD_BARRIER; ^^^^^^^^^^^^^^^^^^^^^^^. This operation is used as an opaque barrier to prevent constant folding. Combines; and other transformations should not look through this. These have no other; semantics and ca",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst:1979,Performance,optimiz,optimizer,1979,"OOL; ^^^^^^^^^^^^^^^. The address of an object in the constant pool. .. code-block:: none. %0:_(p0) = G_CONSTANT_POOL %const.0. Integer Extension and Truncation; --------------------------------. G_ANYEXT; ^^^^^^^^. Extend the underlying scalar type of an operation, leaving the high bits; unspecified. .. code-block:: none. %1:_(s32) = G_ANYEXT %0:_(s16). G_SEXT; ^^^^^^. Sign extend the underlying scalar type of an operation, copying the sign bit; into the newly-created space. .. code-block:: none. %1:_(s32) = G_SEXT %0:_(s16). G_SEXT_INREG; ^^^^^^^^^^^^. Sign extend the value from an arbitrary bit position, copying the sign bit; into all bits above it. This is equivalent to a shl + ashr pair with an; appropriate shift amount. $sz is an immediate (MachineOperand::isImm(); returns true) to allow targets to have some bitwidths legal and others; lowered. This opcode is particularly useful if the target has sign-extension; instructions that are cheaper than the constituent shifts as the optimizer is; able to make decisions on whether it's better to hang on to the G_SEXT_INREG; or to lower it and optimize the individual shifts. .. code-block:: none. %1:_(s32) = G_SEXT_INREG %0:_(s32), 16. G_ZEXT; ^^^^^^. Zero extend the underlying scalar type of an operation, putting zero bits; into the newly-created space. .. code-block:: none. %1:_(s32) = G_ZEXT %0:_(s16). G_TRUNC; ^^^^^^^. Truncate the underlying scalar type of an operation. This is equivalent to; G_EXTRACT for scalar types, but acts elementwise on vectors. .. code-block:: none. %1:_(s16) = G_TRUNC %0:_(s32). Type Conversions; ----------------. G_INTTOPTR; ^^^^^^^^^^. Convert an integer to a pointer. .. code-block:: none. %1:_(p0) = G_INTTOPTR %0:_(s32). G_PTRTOINT; ^^^^^^^^^^. Convert a pointer to an integer. .. code-block:: none. %1:_(s32) = G_PTRTOINT %0:_(p0). G_BITCAST; ^^^^^^^^^. Reinterpret a value as a new type. This is usually done without; changing any bits but this is not always the case due a subtlety in the",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst:2090,Performance,optimiz,optimize,2090,"OOL; ^^^^^^^^^^^^^^^. The address of an object in the constant pool. .. code-block:: none. %0:_(p0) = G_CONSTANT_POOL %const.0. Integer Extension and Truncation; --------------------------------. G_ANYEXT; ^^^^^^^^. Extend the underlying scalar type of an operation, leaving the high bits; unspecified. .. code-block:: none. %1:_(s32) = G_ANYEXT %0:_(s16). G_SEXT; ^^^^^^. Sign extend the underlying scalar type of an operation, copying the sign bit; into the newly-created space. .. code-block:: none. %1:_(s32) = G_SEXT %0:_(s16). G_SEXT_INREG; ^^^^^^^^^^^^. Sign extend the value from an arbitrary bit position, copying the sign bit; into all bits above it. This is equivalent to a shl + ashr pair with an; appropriate shift amount. $sz is an immediate (MachineOperand::isImm(); returns true) to allow targets to have some bitwidths legal and others; lowered. This opcode is particularly useful if the target has sign-extension; instructions that are cheaper than the constituent shifts as the optimizer is; able to make decisions on whether it's better to hang on to the G_SEXT_INREG; or to lower it and optimize the individual shifts. .. code-block:: none. %1:_(s32) = G_SEXT_INREG %0:_(s32), 16. G_ZEXT; ^^^^^^. Zero extend the underlying scalar type of an operation, putting zero bits; into the newly-created space. .. code-block:: none. %1:_(s32) = G_ZEXT %0:_(s16). G_TRUNC; ^^^^^^^. Truncate the underlying scalar type of an operation. This is equivalent to; G_EXTRACT for scalar types, but acts elementwise on vectors. .. code-block:: none. %1:_(s16) = G_TRUNC %0:_(s32). Type Conversions; ----------------. G_INTTOPTR; ^^^^^^^^^^. Convert an integer to a pointer. .. code-block:: none. %1:_(p0) = G_INTTOPTR %0:_(s32). G_PTRTOINT; ^^^^^^^^^^. Convert a pointer to an integer. .. code-block:: none. %1:_(s32) = G_PTRTOINT %0:_(p0). G_BITCAST; ^^^^^^^^^. Reinterpret a value as a new type. This is usually done without; changing any bits but this is not always the case due a subtlety in the",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst:6115,Performance,perform,perform,6115,"ion. The least-significant bit (lsb) and width operands are in the range:. ::. 0 <= lsb < lsb + width <= source bitwidth, where all values are unsigned. G_SBFX sign-extends the result, while G_UBFX zero-extends the result. .. code-block:: none. ; Extract 5 bits starting at bit 1 from %x and store them in %a.; ; Sign-extend the result.; ;; ; Example:; ; %x = 0...0000[10110]1 ---> %a = 1...111111[10110]; %lsb_one = G_CONSTANT i32 1; %width_five = G_CONSTANT i32 5; %a:_(s32) = G_SBFX %x, %lsb_one, %width_five. ; Extract 3 bits starting at bit 2 from %x and store them in %b. Zero-extend; ; the result.; ;; ; Example:; ; %x = 1...11111[100]11 ---> %b = 0...00000[100]; %lsb_two = G_CONSTANT i32 2; %width_three = G_CONSTANT i32 3; %b:_(s32) = G_UBFX %x, %lsb_two, %width_three. Integer Operations; -------------------. G_ADD, G_SUB, G_MUL, G_AND, G_OR, G_XOR, G_SDIV, G_UDIV, G_SREM, G_UREM; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. These each perform their respective integer arithmetic on a scalar. .. code-block:: none. %dst:_(s32) = G_ADD %src0:_(s32), %src1:_(s32). The above example adds %src1 to %src0 and stores the result in %dst. G_SDIVREM, G_UDIVREM; ^^^^^^^^^^^^^^^^^^^^. Perform integer division and remainder thereby producing two results. .. code-block:: none. %div:_(s32), %rem:_(s32) = G_SDIVREM %0:_(s32), %1:_(s32). G_SADDSAT, G_UADDSAT, G_SSUBSAT, G_USUBSAT, G_SSHLSAT, G_USHLSAT; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Signed and unsigned addition, subtraction and left shift with saturation. .. code-block:: none. %2:_(s32) = G_SADDSAT %0:_(s32), %1:_(s32). G_SHL, G_LSHR, G_ASHR; ^^^^^^^^^^^^^^^^^^^^^. Shift the bits of a scalar left or right inserting zeros (sign-bit for G_ASHR). G_ROTR, G_ROTL; ^^^^^^^^^^^^^^. Rotate the bits right (G_ROTR) or left (G_ROTL). G_ICMP; ^^^^^^. Perform integer comparison producing non-zero (true) or zero (false). It's; target specific whether a true value is 1, ~0U, or some othe",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst:13620,Performance,perform,performed,13620," G_FSQRT, G_FFLOOR, G_FRINT, G_FNEARBYINT; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. These correspond to the standard C functions of the same name. G_INTRINSIC_TRUNC; ^^^^^^^^^^^^^^^^^. Returns the operand rounded to the nearest integer not larger in magnitude than the operand. G_INTRINSIC_ROUND; ^^^^^^^^^^^^^^^^^. Returns the operand rounded to the nearest integer. G_LROUND, G_LLROUND; ^^^^^^^^^^^^^^^^^^^. Returns the source operand rounded to the nearest integer with ties away from; zero. See the LLVM LangRef entry on '``llvm.lround.*'`` for details on behaviour. .. code-block:: none. %rounded_32:_(s32) = G_LROUND %round_me:_(s64); %rounded_64:_(s64) = G_LLROUND %round_me:_(s64). Vector Specific Operations; --------------------------. G_CONCAT_VECTORS; ^^^^^^^^^^^^^^^^. Concatenate two vectors to form a longer vector. G_BUILD_VECTOR, G_BUILD_VECTOR_TRUNC; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Create a vector from multiple scalar registers. No implicit; conversion is performed (i.e. the result element type must be the; same as all source operands). The _TRUNC version truncates the larger operand types to fit the; destination vector elt type. G_INSERT_VECTOR_ELT; ^^^^^^^^^^^^^^^^^^^. Insert an element into a vector. G_EXTRACT_VECTOR_ELT; ^^^^^^^^^^^^^^^^^^^^. Extract an element from a vector. G_SHUFFLE_VECTOR; ^^^^^^^^^^^^^^^^. Concatenate two vectors and shuffle the elements according to the mask operand.; The mask operand should be an IR Constant which exactly matches the; corresponding mask for the IR shufflevector instruction. Vector Reduction Operations; ---------------------------. These operations represent horizontal vector reduction, producing a scalar result. G_VECREDUCE_SEQ_FADD, G_VECREDUCE_SEQ_FMUL; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The SEQ variants perform reductions in sequential order. The first operand is; an initial scalar accumulator value, and the second operand is the vector to reduce. G_VECREDUCE_FADD, G_VECRED",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst:14440,Performance,perform,perform,14440,"m a longer vector. G_BUILD_VECTOR, G_BUILD_VECTOR_TRUNC; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Create a vector from multiple scalar registers. No implicit; conversion is performed (i.e. the result element type must be the; same as all source operands). The _TRUNC version truncates the larger operand types to fit the; destination vector elt type. G_INSERT_VECTOR_ELT; ^^^^^^^^^^^^^^^^^^^. Insert an element into a vector. G_EXTRACT_VECTOR_ELT; ^^^^^^^^^^^^^^^^^^^^. Extract an element from a vector. G_SHUFFLE_VECTOR; ^^^^^^^^^^^^^^^^. Concatenate two vectors and shuffle the elements according to the mask operand.; The mask operand should be an IR Constant which exactly matches the; corresponding mask for the IR shufflevector instruction. Vector Reduction Operations; ---------------------------. These operations represent horizontal vector reduction, producing a scalar result. G_VECREDUCE_SEQ_FADD, G_VECREDUCE_SEQ_FMUL; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The SEQ variants perform reductions in sequential order. The first operand is; an initial scalar accumulator value, and the second operand is the vector to reduce. G_VECREDUCE_FADD, G_VECREDUCE_FMUL; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. These reductions are relaxed variants which may reduce the elements in any order. G_VECREDUCE_FMAX, G_VECREDUCE_FMIN, G_VECREDUCE_FMAXIMUM, G_VECREDUCE_FMINIMUM; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. FMIN/FMAX/FMINIMUM/FMAXIMUM nodes can have flags, for NaN/NoNaN variants. Integer/bitwise reductions; ^^^^^^^^^^^^^^^^^^^^^^^^^^. * G_VECREDUCE_ADD; * G_VECREDUCE_MUL; * G_VECREDUCE_AND; * G_VECREDUCE_OR; * G_VECREDUCE_XOR; * G_VECREDUCE_SMAX; * G_VECREDUCE_SMIN; * G_VECREDUCE_UMAX; * G_VECREDUCE_UMIN. Integer reductions may have a result type larger than the vector element type.; However, the reduction is performed using the vector element type and the value; in the top bits is unspecified. Memory Operations; -----------------. G_LOAD, G_SEXTL",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst:15311,Performance,perform,performed,15311,"REDUCE_SEQ_FADD, G_VECREDUCE_SEQ_FMUL; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The SEQ variants perform reductions in sequential order. The first operand is; an initial scalar accumulator value, and the second operand is the vector to reduce. G_VECREDUCE_FADD, G_VECREDUCE_FMUL; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. These reductions are relaxed variants which may reduce the elements in any order. G_VECREDUCE_FMAX, G_VECREDUCE_FMIN, G_VECREDUCE_FMAXIMUM, G_VECREDUCE_FMINIMUM; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. FMIN/FMAX/FMINIMUM/FMAXIMUM nodes can have flags, for NaN/NoNaN variants. Integer/bitwise reductions; ^^^^^^^^^^^^^^^^^^^^^^^^^^. * G_VECREDUCE_ADD; * G_VECREDUCE_MUL; * G_VECREDUCE_AND; * G_VECREDUCE_OR; * G_VECREDUCE_XOR; * G_VECREDUCE_SMAX; * G_VECREDUCE_SMIN; * G_VECREDUCE_UMAX; * G_VECREDUCE_UMIN. Integer reductions may have a result type larger than the vector element type.; However, the reduction is performed using the vector element type and the value; in the top bits is unspecified. Memory Operations; -----------------. G_LOAD, G_SEXTLOAD, G_ZEXTLOAD; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Generic load. Expects a MachineMemOperand in addition to explicit; operands. If the result size is larger than the memory size, the; high bits are undefined, sign-extended, or zero-extended respectively. Only G_LOAD is valid if the result is a vector type. If the result is larger; than the memory size, the high elements are undefined (i.e. this is not a; per-element, vector anyextload). Unlike in SelectionDAG, atomic loads are expressed with the same; opcodes as regular loads. G_LOAD, G_SEXTLOAD and G_ZEXTLOAD may all; have atomic memory operands. G_INDEXED_LOAD; ^^^^^^^^^^^^^^. Generic indexed load. Combines a GEP with a load. $newaddr is set to $base + $offset.; If $am is 0 (post-indexed), then the value is loaded from $base; if $am is 1 (pre-indexed); then the value is loaded from $newaddr. G_INDEXED_SEXTLOAD; ^^^^^^^^^^^^^^^",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst:15508,Performance,load,load,15508,"nitial scalar accumulator value, and the second operand is the vector to reduce. G_VECREDUCE_FADD, G_VECREDUCE_FMUL; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. These reductions are relaxed variants which may reduce the elements in any order. G_VECREDUCE_FMAX, G_VECREDUCE_FMIN, G_VECREDUCE_FMAXIMUM, G_VECREDUCE_FMINIMUM; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. FMIN/FMAX/FMINIMUM/FMAXIMUM nodes can have flags, for NaN/NoNaN variants. Integer/bitwise reductions; ^^^^^^^^^^^^^^^^^^^^^^^^^^. * G_VECREDUCE_ADD; * G_VECREDUCE_MUL; * G_VECREDUCE_AND; * G_VECREDUCE_OR; * G_VECREDUCE_XOR; * G_VECREDUCE_SMAX; * G_VECREDUCE_SMIN; * G_VECREDUCE_UMAX; * G_VECREDUCE_UMIN. Integer reductions may have a result type larger than the vector element type.; However, the reduction is performed using the vector element type and the value; in the top bits is unspecified. Memory Operations; -----------------. G_LOAD, G_SEXTLOAD, G_ZEXTLOAD; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Generic load. Expects a MachineMemOperand in addition to explicit; operands. If the result size is larger than the memory size, the; high bits are undefined, sign-extended, or zero-extended respectively. Only G_LOAD is valid if the result is a vector type. If the result is larger; than the memory size, the high elements are undefined (i.e. this is not a; per-element, vector anyextload). Unlike in SelectionDAG, atomic loads are expressed with the same; opcodes as regular loads. G_LOAD, G_SEXTLOAD and G_ZEXTLOAD may all; have atomic memory operands. G_INDEXED_LOAD; ^^^^^^^^^^^^^^. Generic indexed load. Combines a GEP with a load. $newaddr is set to $base + $offset.; If $am is 0 (post-indexed), then the value is loaded from $base; if $am is 1 (pre-indexed); then the value is loaded from $newaddr. G_INDEXED_SEXTLOAD; ^^^^^^^^^^^^^^^^^^. Same as G_INDEXED_LOAD except that the load performed is sign-extending, as with G_SEXTLOAD. G_INDEXED_ZEXTLOAD; ^^^^^^^^^^^^^^^^^^. Same as G_INDEXED_LOAD excep",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst:15921,Performance,load,loads,15921,"can have flags, for NaN/NoNaN variants. Integer/bitwise reductions; ^^^^^^^^^^^^^^^^^^^^^^^^^^. * G_VECREDUCE_ADD; * G_VECREDUCE_MUL; * G_VECREDUCE_AND; * G_VECREDUCE_OR; * G_VECREDUCE_XOR; * G_VECREDUCE_SMAX; * G_VECREDUCE_SMIN; * G_VECREDUCE_UMAX; * G_VECREDUCE_UMIN. Integer reductions may have a result type larger than the vector element type.; However, the reduction is performed using the vector element type and the value; in the top bits is unspecified. Memory Operations; -----------------. G_LOAD, G_SEXTLOAD, G_ZEXTLOAD; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Generic load. Expects a MachineMemOperand in addition to explicit; operands. If the result size is larger than the memory size, the; high bits are undefined, sign-extended, or zero-extended respectively. Only G_LOAD is valid if the result is a vector type. If the result is larger; than the memory size, the high elements are undefined (i.e. this is not a; per-element, vector anyextload). Unlike in SelectionDAG, atomic loads are expressed with the same; opcodes as regular loads. G_LOAD, G_SEXTLOAD and G_ZEXTLOAD may all; have atomic memory operands. G_INDEXED_LOAD; ^^^^^^^^^^^^^^. Generic indexed load. Combines a GEP with a load. $newaddr is set to $base + $offset.; If $am is 0 (post-indexed), then the value is loaded from $base; if $am is 1 (pre-indexed); then the value is loaded from $newaddr. G_INDEXED_SEXTLOAD; ^^^^^^^^^^^^^^^^^^. Same as G_INDEXED_LOAD except that the load performed is sign-extending, as with G_SEXTLOAD. G_INDEXED_ZEXTLOAD; ^^^^^^^^^^^^^^^^^^. Same as G_INDEXED_LOAD except that the load performed is zero-extending, as with G_ZEXTLOAD. G_STORE; ^^^^^^^. Generic store. Expects a MachineMemOperand in addition to explicit; operands. If the stored value size is greater than the memory size,; the high bits are implicitly truncated. If this is a vector store, the; high elements are discarded (i.e. this does not function as a per-lane; vector, truncating store). G_INDEXED_STORE; ^^^^^^^^^^^^^^^. Comb",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst:15975,Performance,load,loads,15975,"can have flags, for NaN/NoNaN variants. Integer/bitwise reductions; ^^^^^^^^^^^^^^^^^^^^^^^^^^. * G_VECREDUCE_ADD; * G_VECREDUCE_MUL; * G_VECREDUCE_AND; * G_VECREDUCE_OR; * G_VECREDUCE_XOR; * G_VECREDUCE_SMAX; * G_VECREDUCE_SMIN; * G_VECREDUCE_UMAX; * G_VECREDUCE_UMIN. Integer reductions may have a result type larger than the vector element type.; However, the reduction is performed using the vector element type and the value; in the top bits is unspecified. Memory Operations; -----------------. G_LOAD, G_SEXTLOAD, G_ZEXTLOAD; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Generic load. Expects a MachineMemOperand in addition to explicit; operands. If the result size is larger than the memory size, the; high bits are undefined, sign-extended, or zero-extended respectively. Only G_LOAD is valid if the result is a vector type. If the result is larger; than the memory size, the high elements are undefined (i.e. this is not a; per-element, vector anyextload). Unlike in SelectionDAG, atomic loads are expressed with the same; opcodes as regular loads. G_LOAD, G_SEXTLOAD and G_ZEXTLOAD may all; have atomic memory operands. G_INDEXED_LOAD; ^^^^^^^^^^^^^^. Generic indexed load. Combines a GEP with a load. $newaddr is set to $base + $offset.; If $am is 0 (post-indexed), then the value is loaded from $base; if $am is 1 (pre-indexed); then the value is loaded from $newaddr. G_INDEXED_SEXTLOAD; ^^^^^^^^^^^^^^^^^^. Same as G_INDEXED_LOAD except that the load performed is sign-extending, as with G_SEXTLOAD. G_INDEXED_ZEXTLOAD; ^^^^^^^^^^^^^^^^^^. Same as G_INDEXED_LOAD except that the load performed is zero-extending, as with G_ZEXTLOAD. G_STORE; ^^^^^^^. Generic store. Expects a MachineMemOperand in addition to explicit; operands. If the stored value size is greater than the memory size,; the high bits are implicitly truncated. If this is a vector store, the; high elements are discarded (i.e. this does not function as a per-lane; vector, truncating store). G_INDEXED_STORE; ^^^^^^^^^^^^^^^. Comb",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst:16102,Performance,load,load,16102,"EDUCE_OR; * G_VECREDUCE_XOR; * G_VECREDUCE_SMAX; * G_VECREDUCE_SMIN; * G_VECREDUCE_UMAX; * G_VECREDUCE_UMIN. Integer reductions may have a result type larger than the vector element type.; However, the reduction is performed using the vector element type and the value; in the top bits is unspecified. Memory Operations; -----------------. G_LOAD, G_SEXTLOAD, G_ZEXTLOAD; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Generic load. Expects a MachineMemOperand in addition to explicit; operands. If the result size is larger than the memory size, the; high bits are undefined, sign-extended, or zero-extended respectively. Only G_LOAD is valid if the result is a vector type. If the result is larger; than the memory size, the high elements are undefined (i.e. this is not a; per-element, vector anyextload). Unlike in SelectionDAG, atomic loads are expressed with the same; opcodes as regular loads. G_LOAD, G_SEXTLOAD and G_ZEXTLOAD may all; have atomic memory operands. G_INDEXED_LOAD; ^^^^^^^^^^^^^^. Generic indexed load. Combines a GEP with a load. $newaddr is set to $base + $offset.; If $am is 0 (post-indexed), then the value is loaded from $base; if $am is 1 (pre-indexed); then the value is loaded from $newaddr. G_INDEXED_SEXTLOAD; ^^^^^^^^^^^^^^^^^^. Same as G_INDEXED_LOAD except that the load performed is sign-extending, as with G_SEXTLOAD. G_INDEXED_ZEXTLOAD; ^^^^^^^^^^^^^^^^^^. Same as G_INDEXED_LOAD except that the load performed is zero-extending, as with G_ZEXTLOAD. G_STORE; ^^^^^^^. Generic store. Expects a MachineMemOperand in addition to explicit; operands. If the stored value size is greater than the memory size,; the high bits are implicitly truncated. If this is a vector store, the; high elements are discarded (i.e. this does not function as a per-lane; vector, truncating store). G_INDEXED_STORE; ^^^^^^^^^^^^^^^. Combines a store with a GEP. See description of G_INDEXED_LOAD for indexing behaviour. G_ATOMIC_CMPXCHG_WITH_SUCCESS; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Generic atomic c",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst:16130,Performance,load,load,16130,"OR; * G_VECREDUCE_SMAX; * G_VECREDUCE_SMIN; * G_VECREDUCE_UMAX; * G_VECREDUCE_UMIN. Integer reductions may have a result type larger than the vector element type.; However, the reduction is performed using the vector element type and the value; in the top bits is unspecified. Memory Operations; -----------------. G_LOAD, G_SEXTLOAD, G_ZEXTLOAD; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Generic load. Expects a MachineMemOperand in addition to explicit; operands. If the result size is larger than the memory size, the; high bits are undefined, sign-extended, or zero-extended respectively. Only G_LOAD is valid if the result is a vector type. If the result is larger; than the memory size, the high elements are undefined (i.e. this is not a; per-element, vector anyextload). Unlike in SelectionDAG, atomic loads are expressed with the same; opcodes as regular loads. G_LOAD, G_SEXTLOAD and G_ZEXTLOAD may all; have atomic memory operands. G_INDEXED_LOAD; ^^^^^^^^^^^^^^. Generic indexed load. Combines a GEP with a load. $newaddr is set to $base + $offset.; If $am is 0 (post-indexed), then the value is loaded from $base; if $am is 1 (pre-indexed); then the value is loaded from $newaddr. G_INDEXED_SEXTLOAD; ^^^^^^^^^^^^^^^^^^. Same as G_INDEXED_LOAD except that the load performed is sign-extending, as with G_SEXTLOAD. G_INDEXED_ZEXTLOAD; ^^^^^^^^^^^^^^^^^^. Same as G_INDEXED_LOAD except that the load performed is zero-extending, as with G_ZEXTLOAD. G_STORE; ^^^^^^^. Generic store. Expects a MachineMemOperand in addition to explicit; operands. If the stored value size is greater than the memory size,; the high bits are implicitly truncated. If this is a vector store, the; high elements are discarded (i.e. this does not function as a per-lane; vector, truncating store). G_INDEXED_STORE; ^^^^^^^^^^^^^^^. Combines a store with a GEP. See description of G_INDEXED_LOAD for indexing behaviour. G_ATOMIC_CMPXCHG_WITH_SUCCESS; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Generic atomic cmpxchg with internal succ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst:16219,Performance,load,loaded,16219,"sult type larger than the vector element type.; However, the reduction is performed using the vector element type and the value; in the top bits is unspecified. Memory Operations; -----------------. G_LOAD, G_SEXTLOAD, G_ZEXTLOAD; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Generic load. Expects a MachineMemOperand in addition to explicit; operands. If the result size is larger than the memory size, the; high bits are undefined, sign-extended, or zero-extended respectively. Only G_LOAD is valid if the result is a vector type. If the result is larger; than the memory size, the high elements are undefined (i.e. this is not a; per-element, vector anyextload). Unlike in SelectionDAG, atomic loads are expressed with the same; opcodes as regular loads. G_LOAD, G_SEXTLOAD and G_ZEXTLOAD may all; have atomic memory operands. G_INDEXED_LOAD; ^^^^^^^^^^^^^^. Generic indexed load. Combines a GEP with a load. $newaddr is set to $base + $offset.; If $am is 0 (post-indexed), then the value is loaded from $base; if $am is 1 (pre-indexed); then the value is loaded from $newaddr. G_INDEXED_SEXTLOAD; ^^^^^^^^^^^^^^^^^^. Same as G_INDEXED_LOAD except that the load performed is sign-extending, as with G_SEXTLOAD. G_INDEXED_ZEXTLOAD; ^^^^^^^^^^^^^^^^^^. Same as G_INDEXED_LOAD except that the load performed is zero-extending, as with G_ZEXTLOAD. G_STORE; ^^^^^^^. Generic store. Expects a MachineMemOperand in addition to explicit; operands. If the stored value size is greater than the memory size,; the high bits are implicitly truncated. If this is a vector store, the; high elements are discarded (i.e. this does not function as a per-lane; vector, truncating store). G_INDEXED_STORE; ^^^^^^^^^^^^^^^. Combines a store with a GEP. See description of G_INDEXED_LOAD for indexing behaviour. G_ATOMIC_CMPXCHG_WITH_SUCCESS; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Generic atomic cmpxchg with internal success check. Expects a; MachineMemOperand in addition to explicit operands. G_ATOMIC_CMPXCHG; ^^^^^^^^^^^^^^^^. Generic",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst:16283,Performance,load,loaded,16283,"sult type larger than the vector element type.; However, the reduction is performed using the vector element type and the value; in the top bits is unspecified. Memory Operations; -----------------. G_LOAD, G_SEXTLOAD, G_ZEXTLOAD; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Generic load. Expects a MachineMemOperand in addition to explicit; operands. If the result size is larger than the memory size, the; high bits are undefined, sign-extended, or zero-extended respectively. Only G_LOAD is valid if the result is a vector type. If the result is larger; than the memory size, the high elements are undefined (i.e. this is not a; per-element, vector anyextload). Unlike in SelectionDAG, atomic loads are expressed with the same; opcodes as regular loads. G_LOAD, G_SEXTLOAD and G_ZEXTLOAD may all; have atomic memory operands. G_INDEXED_LOAD; ^^^^^^^^^^^^^^. Generic indexed load. Combines a GEP with a load. $newaddr is set to $base + $offset.; If $am is 0 (post-indexed), then the value is loaded from $base; if $am is 1 (pre-indexed); then the value is loaded from $newaddr. G_INDEXED_SEXTLOAD; ^^^^^^^^^^^^^^^^^^. Same as G_INDEXED_LOAD except that the load performed is sign-extending, as with G_SEXTLOAD. G_INDEXED_ZEXTLOAD; ^^^^^^^^^^^^^^^^^^. Same as G_INDEXED_LOAD except that the load performed is zero-extending, as with G_ZEXTLOAD. G_STORE; ^^^^^^^. Generic store. Expects a MachineMemOperand in addition to explicit; operands. If the stored value size is greater than the memory size,; the high bits are implicitly truncated. If this is a vector store, the; high elements are discarded (i.e. this does not function as a per-lane; vector, truncating store). G_INDEXED_STORE; ^^^^^^^^^^^^^^^. Combines a store with a GEP. See description of G_INDEXED_LOAD for indexing behaviour. G_ATOMIC_CMPXCHG_WITH_SUCCESS; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Generic atomic cmpxchg with internal success check. Expects a; MachineMemOperand in addition to explicit operands. G_ATOMIC_CMPXCHG; ^^^^^^^^^^^^^^^^. Generic",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst:16384,Performance,load,load,16384,"cified. Memory Operations; -----------------. G_LOAD, G_SEXTLOAD, G_ZEXTLOAD; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Generic load. Expects a MachineMemOperand in addition to explicit; operands. If the result size is larger than the memory size, the; high bits are undefined, sign-extended, or zero-extended respectively. Only G_LOAD is valid if the result is a vector type. If the result is larger; than the memory size, the high elements are undefined (i.e. this is not a; per-element, vector anyextload). Unlike in SelectionDAG, atomic loads are expressed with the same; opcodes as regular loads. G_LOAD, G_SEXTLOAD and G_ZEXTLOAD may all; have atomic memory operands. G_INDEXED_LOAD; ^^^^^^^^^^^^^^. Generic indexed load. Combines a GEP with a load. $newaddr is set to $base + $offset.; If $am is 0 (post-indexed), then the value is loaded from $base; if $am is 1 (pre-indexed); then the value is loaded from $newaddr. G_INDEXED_SEXTLOAD; ^^^^^^^^^^^^^^^^^^. Same as G_INDEXED_LOAD except that the load performed is sign-extending, as with G_SEXTLOAD. G_INDEXED_ZEXTLOAD; ^^^^^^^^^^^^^^^^^^. Same as G_INDEXED_LOAD except that the load performed is zero-extending, as with G_ZEXTLOAD. G_STORE; ^^^^^^^. Generic store. Expects a MachineMemOperand in addition to explicit; operands. If the stored value size is greater than the memory size,; the high bits are implicitly truncated. If this is a vector store, the; high elements are discarded (i.e. this does not function as a per-lane; vector, truncating store). G_INDEXED_STORE; ^^^^^^^^^^^^^^^. Combines a store with a GEP. See description of G_INDEXED_LOAD for indexing behaviour. G_ATOMIC_CMPXCHG_WITH_SUCCESS; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Generic atomic cmpxchg with internal success check. Expects a; MachineMemOperand in addition to explicit operands. G_ATOMIC_CMPXCHG; ^^^^^^^^^^^^^^^^. Generic atomic cmpxchg. Expects a MachineMemOperand in addition to explicit; operands. G_ATOMICRMW_XCHG, G_ATOMICRMW_ADD, G_ATOMICRMW_SUB, G_ATOMICRMW_AND,; G_A",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst:16389,Performance,perform,performed,16389,"cified. Memory Operations; -----------------. G_LOAD, G_SEXTLOAD, G_ZEXTLOAD; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Generic load. Expects a MachineMemOperand in addition to explicit; operands. If the result size is larger than the memory size, the; high bits are undefined, sign-extended, or zero-extended respectively. Only G_LOAD is valid if the result is a vector type. If the result is larger; than the memory size, the high elements are undefined (i.e. this is not a; per-element, vector anyextload). Unlike in SelectionDAG, atomic loads are expressed with the same; opcodes as regular loads. G_LOAD, G_SEXTLOAD and G_ZEXTLOAD may all; have atomic memory operands. G_INDEXED_LOAD; ^^^^^^^^^^^^^^. Generic indexed load. Combines a GEP with a load. $newaddr is set to $base + $offset.; If $am is 0 (post-indexed), then the value is loaded from $base; if $am is 1 (pre-indexed); then the value is loaded from $newaddr. G_INDEXED_SEXTLOAD; ^^^^^^^^^^^^^^^^^^. Same as G_INDEXED_LOAD except that the load performed is sign-extending, as with G_SEXTLOAD. G_INDEXED_ZEXTLOAD; ^^^^^^^^^^^^^^^^^^. Same as G_INDEXED_LOAD except that the load performed is zero-extending, as with G_ZEXTLOAD. G_STORE; ^^^^^^^. Generic store. Expects a MachineMemOperand in addition to explicit; operands. If the stored value size is greater than the memory size,; the high bits are implicitly truncated. If this is a vector store, the; high elements are discarded (i.e. this does not function as a per-lane; vector, truncating store). G_INDEXED_STORE; ^^^^^^^^^^^^^^^. Combines a store with a GEP. See description of G_INDEXED_LOAD for indexing behaviour. G_ATOMIC_CMPXCHG_WITH_SUCCESS; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Generic atomic cmpxchg with internal success check. Expects a; MachineMemOperand in addition to explicit operands. G_ATOMIC_CMPXCHG; ^^^^^^^^^^^^^^^^. Generic atomic cmpxchg. Expects a MachineMemOperand in addition to explicit; operands. G_ATOMICRMW_XCHG, G_ATOMICRMW_ADD, G_ATOMICRMW_SUB, G_ATOMICRMW_AND,; G_A",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst:16517,Performance,load,load,16517," MachineMemOperand in addition to explicit; operands. If the result size is larger than the memory size, the; high bits are undefined, sign-extended, or zero-extended respectively. Only G_LOAD is valid if the result is a vector type. If the result is larger; than the memory size, the high elements are undefined (i.e. this is not a; per-element, vector anyextload). Unlike in SelectionDAG, atomic loads are expressed with the same; opcodes as regular loads. G_LOAD, G_SEXTLOAD and G_ZEXTLOAD may all; have atomic memory operands. G_INDEXED_LOAD; ^^^^^^^^^^^^^^. Generic indexed load. Combines a GEP with a load. $newaddr is set to $base + $offset.; If $am is 0 (post-indexed), then the value is loaded from $base; if $am is 1 (pre-indexed); then the value is loaded from $newaddr. G_INDEXED_SEXTLOAD; ^^^^^^^^^^^^^^^^^^. Same as G_INDEXED_LOAD except that the load performed is sign-extending, as with G_SEXTLOAD. G_INDEXED_ZEXTLOAD; ^^^^^^^^^^^^^^^^^^. Same as G_INDEXED_LOAD except that the load performed is zero-extending, as with G_ZEXTLOAD. G_STORE; ^^^^^^^. Generic store. Expects a MachineMemOperand in addition to explicit; operands. If the stored value size is greater than the memory size,; the high bits are implicitly truncated. If this is a vector store, the; high elements are discarded (i.e. this does not function as a per-lane; vector, truncating store). G_INDEXED_STORE; ^^^^^^^^^^^^^^^. Combines a store with a GEP. See description of G_INDEXED_LOAD for indexing behaviour. G_ATOMIC_CMPXCHG_WITH_SUCCESS; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Generic atomic cmpxchg with internal success check. Expects a; MachineMemOperand in addition to explicit operands. G_ATOMIC_CMPXCHG; ^^^^^^^^^^^^^^^^. Generic atomic cmpxchg. Expects a MachineMemOperand in addition to explicit; operands. G_ATOMICRMW_XCHG, G_ATOMICRMW_ADD, G_ATOMICRMW_SUB, G_ATOMICRMW_AND,; G_ATOMICRMW_NAND, G_ATOMICRMW_OR, G_ATOMICRMW_XOR, G_ATOMICRMW_MAX,; G_ATOMICRMW_MIN, G_ATOMICRMW_UMAX, G_ATOMICRMW_UMIN, G_ATOMICRMW_FA",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst:16522,Performance,perform,performed,16522," MachineMemOperand in addition to explicit; operands. If the result size is larger than the memory size, the; high bits are undefined, sign-extended, or zero-extended respectively. Only G_LOAD is valid if the result is a vector type. If the result is larger; than the memory size, the high elements are undefined (i.e. this is not a; per-element, vector anyextload). Unlike in SelectionDAG, atomic loads are expressed with the same; opcodes as regular loads. G_LOAD, G_SEXTLOAD and G_ZEXTLOAD may all; have atomic memory operands. G_INDEXED_LOAD; ^^^^^^^^^^^^^^. Generic indexed load. Combines a GEP with a load. $newaddr is set to $base + $offset.; If $am is 0 (post-indexed), then the value is loaded from $base; if $am is 1 (pre-indexed); then the value is loaded from $newaddr. G_INDEXED_SEXTLOAD; ^^^^^^^^^^^^^^^^^^. Same as G_INDEXED_LOAD except that the load performed is sign-extending, as with G_SEXTLOAD. G_INDEXED_ZEXTLOAD; ^^^^^^^^^^^^^^^^^^. Same as G_INDEXED_LOAD except that the load performed is zero-extending, as with G_ZEXTLOAD. G_STORE; ^^^^^^^. Generic store. Expects a MachineMemOperand in addition to explicit; operands. If the stored value size is greater than the memory size,; the high bits are implicitly truncated. If this is a vector store, the; high elements are discarded (i.e. this does not function as a per-lane; vector, truncating store). G_INDEXED_STORE; ^^^^^^^^^^^^^^^. Combines a store with a GEP. See description of G_INDEXED_LOAD for indexing behaviour. G_ATOMIC_CMPXCHG_WITH_SUCCESS; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Generic atomic cmpxchg with internal success check. Expects a; MachineMemOperand in addition to explicit operands. G_ATOMIC_CMPXCHG; ^^^^^^^^^^^^^^^^. Generic atomic cmpxchg. Expects a MachineMemOperand in addition to explicit; operands. G_ATOMICRMW_XCHG, G_ATOMICRMW_ADD, G_ATOMICRMW_SUB, G_ATOMICRMW_AND,; G_ATOMICRMW_NAND, G_ATOMICRMW_OR, G_ATOMICRMW_XOR, G_ATOMICRMW_MAX,; G_ATOMICRMW_MIN, G_ATOMICRMW_UMAX, G_ATOMICRMW_UMIN, G_ATOMICRMW_FA",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst:18170,Performance,load,load,18170,"ion to explicit operands. G_ATOMIC_CMPXCHG; ^^^^^^^^^^^^^^^^. Generic atomic cmpxchg. Expects a MachineMemOperand in addition to explicit; operands. G_ATOMICRMW_XCHG, G_ATOMICRMW_ADD, G_ATOMICRMW_SUB, G_ATOMICRMW_AND,; G_ATOMICRMW_NAND, G_ATOMICRMW_OR, G_ATOMICRMW_XOR, G_ATOMICRMW_MAX,; G_ATOMICRMW_MIN, G_ATOMICRMW_UMAX, G_ATOMICRMW_UMIN, G_ATOMICRMW_FADD,; G_ATOMICRMW_FSUB, G_ATOMICRMW_FMAX, G_ATOMICRMW_FMIN; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Generic atomicrmw. Expects a MachineMemOperand in addition to explicit; operands. G_FENCE; ^^^^^^^. Generic fence. The first operand is the memory ordering. The second operand is; the syncscope. See the LLVM LangRef entry on the '``fence'`` instruction for more details. G_MEMCPY; ^^^^^^^^. Generic memcpy. Expects two MachineMemOperands covering the store and load; respectively, in addition to explicit operands. G_MEMCPY_INLINE; ^^^^^^^^^^^^^^^. Generic inlined memcpy. Like G_MEMCPY, but it is guaranteed that this version; will not be lowered as a call to an external function. Currently the size; operand is required to evaluate as a constant (not an immediate), though that is; expected to change when llvm.memcpy.inline is taught to support dynamic sizes. G_MEMMOVE; ^^^^^^^^^. Generic memmove. Similar to G_MEMCPY, but the source and destination memory; ranges are allowed to overlap. G_MEMSET; ^^^^^^^^. Generic memset. Expects a MachineMemOperand in addition to explicit operands. G_BZERO; ^^^^^^^. Generic bzero. Expects a MachineMemOperand in addition to explicit operands. Control Flow; ------------. G_PHI; ^^^^^. Implement the φ node in the SSA graph representing the function. .. code-block:: none. %dst(s8) = G_PHI %src1(s8), %bb.<id1>, %src2(s8), %bb.<id2>. G_BR; ^^^^. Unconditional branch. .. code-block:: none. G_BR %bb.<id>. G_BRCOND; ^^",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst:22470,Safety,safe,safe,22470,"esponds to an LLVM IR intrinsic marked `convergent`. .. note::. Unlike SelectionDAG, there is no _VOID variant. Both of these are permitted; to have zero, one, or multiple results. Variadic Arguments; ------------------. G_VASTART; ^^^^^^^^^. .. caution::. I found no documentation for this instruction at the time of writing. G_VAARG; ^^^^^^^. .. caution::. I found no documentation for this instruction at the time of writing. Other Operations; ----------------. G_DYN_STACKALLOC; ^^^^^^^^^^^^^^^^. Dynamically realigns the stack pointer to the specified size and alignment.; An alignment value of `0` or `1` means no specific alignment. .. code-block:: none. %8:_(p0) = G_DYN_STACKALLOC %7(s64), 32. Optimization Hints; ------------------. These instructions do not correspond to any target instructions. They act as; hints for various combines. G_ASSERT_SEXT, G_ASSERT_ZEXT; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. This signifies that the contents of a register were previously extended from a; smaller type. The smaller type is denoted using an immediate operand. For scalars, this is the; width of the entire smaller type. For vectors, this is the width of the smaller; element type. .. code-block:: none. %x_was_zexted:_(s32) = G_ASSERT_ZEXT %x(s32), 16; %y_was_zexted:_(<2 x s32>) = G_ASSERT_ZEXT %y(<2 x s32>), 16. %z_was_sexted:_(s32) = G_ASSERT_SEXT %z(s32), 8. G_ASSERT_SEXT and G_ASSERT_ZEXT act like copies, albeit with some restrictions. The source and destination registers must. - Be virtual; - Belong to the same register class; - Belong to the same register bank. It should always be safe to. - Look through the source register; - Replace the destination register with the source register. Miscellaneous; -------------. G_CONSTANT_FOLD_BARRIER; ^^^^^^^^^^^^^^^^^^^^^^^. This operation is used as an opaque barrier to prevent constant folding. Combines; and other transformations should not look through this. These have no other; semantics and can be safely eliminated if a target chooses.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst:22837,Safety,safe,safely,22837,"esponds to an LLVM IR intrinsic marked `convergent`. .. note::. Unlike SelectionDAG, there is no _VOID variant. Both of these are permitted; to have zero, one, or multiple results. Variadic Arguments; ------------------. G_VASTART; ^^^^^^^^^. .. caution::. I found no documentation for this instruction at the time of writing. G_VAARG; ^^^^^^^. .. caution::. I found no documentation for this instruction at the time of writing. Other Operations; ----------------. G_DYN_STACKALLOC; ^^^^^^^^^^^^^^^^. Dynamically realigns the stack pointer to the specified size and alignment.; An alignment value of `0` or `1` means no specific alignment. .. code-block:: none. %8:_(p0) = G_DYN_STACKALLOC %7(s64), 32. Optimization Hints; ------------------. These instructions do not correspond to any target instructions. They act as; hints for various combines. G_ASSERT_SEXT, G_ASSERT_ZEXT; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. This signifies that the contents of a register were previously extended from a; smaller type. The smaller type is denoted using an immediate operand. For scalars, this is the; width of the entire smaller type. For vectors, this is the width of the smaller; element type. .. code-block:: none. %x_was_zexted:_(s32) = G_ASSERT_ZEXT %x(s32), 16; %y_was_zexted:_(<2 x s32>) = G_ASSERT_ZEXT %y(<2 x s32>), 16. %z_was_sexted:_(s32) = G_ASSERT_SEXT %z(s32), 8. G_ASSERT_SEXT and G_ASSERT_ZEXT act like copies, albeit with some restrictions. The source and destination registers must. - Be virtual; - Belong to the same register class; - Belong to the same register bank. It should always be safe to. - Look through the source register; - Replace the destination register with the source register. Miscellaneous; -------------. G_CONSTANT_FOLD_BARRIER; ^^^^^^^^^^^^^^^^^^^^^^^. This operation is used as an opaque barrier to prevent constant folding. Combines; and other transformations should not look through this. These have no other; semantics and can be safely eliminated if a target chooses.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst:3460,Usability,simpl,simply,3460," equivalent to; G_EXTRACT for scalar types, but acts elementwise on vectors. .. code-block:: none. %1:_(s16) = G_TRUNC %0:_(s32). Type Conversions; ----------------. G_INTTOPTR; ^^^^^^^^^^. Convert an integer to a pointer. .. code-block:: none. %1:_(p0) = G_INTTOPTR %0:_(s32). G_PTRTOINT; ^^^^^^^^^^. Convert a pointer to an integer. .. code-block:: none. %1:_(s32) = G_PTRTOINT %0:_(p0). G_BITCAST; ^^^^^^^^^. Reinterpret a value as a new type. This is usually done without; changing any bits but this is not always the case due a subtlety in the; definition of the :ref:`LLVM-IR Bitcast Instruction <i_bitcast>`. It; is allowed to bitcast between pointers with the same size, but; different address spaces. .. code-block:: none. %1:_(s64) = G_BITCAST %0:_(<2 x s32>). G_ADDRSPACE_CAST; ^^^^^^^^^^^^^^^^. Convert a pointer to an address space to a pointer to another address space. .. code-block:: none. %1:_(p1) = G_ADDRSPACE_CAST %0:_(p0). .. caution::. :ref:`i_addrspacecast` doesn't mention what happens if the cast is simply; invalid (i.e. if the address spaces are disjoint). Scalar Operations; -----------------. G_EXTRACT; ^^^^^^^^^. Extract a register of the specified size, starting from the block given by; index. This will almost certainly be mapped to sub-register COPYs after; register banks have been selected. .. code-block:: none. %3:_(s32) = G_EXTRACT %2:_(s64), 32. G_INSERT; ^^^^^^^^. Insert a smaller register into a larger one at the specified bit-index. .. code-block:: none. %2:_(s64) = G_INSERT %0:(_s64), %1:_(s32), 0. G_MERGE_VALUES; ^^^^^^^^^^^^^^. Concatenate multiple registers of the same size into a wider register.; The input operands are always ordered from lowest bits to highest:. .. code-block:: none. %0:(s32) = G_MERGE_VALUES %bits_0_7:(s8), %bits_8_15:(s8),; %bits_16_23:(s8), %bits_24_31:(s8). G_UNMERGE_VALUES; ^^^^^^^^^^^^^^^^. Extract multiple registers of the specified size, starting from blocks given by; indexes. This will almost certainly be mapped t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GenericOpcode.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GMIR.rst:2965,Availability,redundant,redundant,2965,"out needing to distinguish them from non-generic virtual registers. For simplicity, most generic instructions only accept virtual registers (both; generic and non-generic). There are some exceptions to this but in general:. * instead of immediates, they use a generic virtual register defined by an; instruction that materializes the immediate value (see; :ref:`irtranslator-constants`). Typically this is a G_CONSTANT or a; G_FCONSTANT. One example of an exception to this rule is G_SEXT_INREG where; having an immediate is mandatory.; * instead of physical register, they use a generic virtual register that is; either defined by a ``COPY`` from the physical register or used by a ``COPY``; that defines the physical register. .. admonition:: Historical Note. We started with an alternative representation, where MRI tracks a size for; each generic virtual register, and instructions have lists of types.; That had two flaws: the type and size are redundant, and there was no generic; way of getting a given operand's type (as there was no 1:1 mapping between; instruction types and operands).; We considered putting the type in some variant of MCInstrDesc instead:; See `PR26576 <https://llvm.org/PR26576>`_: [GlobalISel] Generic MachineInstrs; need a type but this increases the memory footprint of the related objects. .. _gmir-regbank:. Register Bank; -------------. A Register Bank is a set of register classes defined by the target. This; definition is rather loose so let's talk about what they can achieve. Suppose we have a processor that has two register files, A and B. These are; equal in every way and support the same instructions for the same cost. They're; just physically stored apart and each instruction can only access registers from; A or B but never a mix of the two. If we want to perform an operation on data; that's in split between the two register files, we must first copy all the data; into a single register file. Given a processor like this, we would benefit from clus",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/GMIR.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GMIR.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GMIR.rst:9125,Availability,avail,available,9125,"or lanes:. * ``sN`` for scalars; * ``pN`` for pointers; * ``<N x sM>`` for vectors. ``LLT`` is intended to replace the usage of ``EVT`` in SelectionDAG. Here are some LLT examples and their ``EVT`` and ``Type`` equivalents:. ============= ========= ======================================; LLT EVT IR Type; ============= ========= ======================================; ``s1`` ``i1`` ``i1``; ``s8`` ``i8`` ``i8``; ``s32`` ``i32`` ``i32``; ``s32`` ``f32`` ``float``; ``s17`` ``i17`` ``i17``; ``s16`` N/A ``{i8, i8}`` [#abi-dependent]_; ``s32`` N/A ``[4 x i8]`` [#abi-dependent]_; ``p0`` ``iPTR`` ``i8*``, ``i32*``, ``%opaque*``; ``p2`` ``iPTR`` ``i8 addrspace(2)*``; ``<4 x s32>`` ``v4f32`` ``<4 x float>``; ``s64`` ``v1f64`` ``<1 x double>``; ``<3 x s32>`` ``v3i32`` ``<3 x i32>``; ============= ========= ======================================. Rationale: instructions already encode a specific interpretation of types; (e.g., ``add`` vs. ``fadd``, or ``sdiv`` vs. ``udiv``). Also encoding that; information in the type system requires introducing bitcast with no real; advantage for the selector. Pointer types are distinguished by address space. This matches IR, as opposed; to SelectionDAG where address space is an attribute on operations.; This representation better supports pointers having different sizes depending; on their addressspace. .. note::. .. caution::. Is this still true? I thought we'd removed the 1-element vector concept.; Hypothetically, it could be distinct from a scalar but I think we failed to; find a real occurrence. Currently, LLT requires at least 2 elements in vectors, but some targets have; the concept of a '1-element vector'. Representing them as their underlying; scalar type is a nice simplification. .. rubric:: Footnotes. .. [#abi-dependent] This mapping is ABI dependent. Here we've assumed no additional padding is required. Generic Opcode Reference; ------------------------. The Generic Opcodes that are available are described at :doc:`GenericOpcode`.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/GMIR.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GMIR.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GMIR.rst:262,Deployability,pipeline,pipeline,262,".. _gmir:. Generic Machine IR; ==================. .. contents::; :local:. Generic MIR (gMIR) is an intermediate representation that shares the same data; structures as :doc:`MachineIR (MIR) <../MIRLangRef>` but has more relaxed; constraints. As the compilation pipeline proceeds, these constraints are; gradually tightened until gMIR has become MIR. The rest of this document will assume that you are familiar with the concepts; in :doc:`MachineIR (MIR) <../MIRLangRef>` and will highlight the differences; between MIR and gMIR. .. _gmir-instructions:. Generic Machine Instructions; ----------------------------. .. note::. This section expands on :ref:`mir-instructions` from the MIR Language; Reference. Whereas MIR deals largely in Target Instructions and only has a small set of; target independent opcodes such as ``COPY``, ``PHI``, and ``REG_SEQUENCE``,; gMIR defines a rich collection of ``Generic Opcodes`` which are target; independent and describe operations which are typically supported by targets.; One example is ``G_ADD`` which is the generic opcode for an integer addition.; More information on each of the generic opcodes can be found at; :doc:`GenericOpcode`. The ``MachineIRBuilder`` class wraps the ``MachineInstrBuilder`` and provides; a convenient way to create these generic instructions. .. _gmir-gvregs:. Generic Virtual Registers; -------------------------. .. note::. This section expands on :ref:`mir-registers` from the MIR Language; Reference. Generic virtual registers are like virtual registers but they are not assigned a; Register Class constraint. Instead, generic virtual registers have less strict; constraints starting with a :ref:`gmir-llt` and then further constrained to a; :ref:`gmir-regbank`. Eventually they will be constrained to a register class; at which point they become normal virtual registers. Generic virtual registers can be used with all the virtual register API's; provided by ``MachineRegisterInfo``. In particular, the def-use chain API's can",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/GMIR.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GMIR.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GMIR.rst:1210,Integrability,wrap,wraps,1210," the compilation pipeline proceeds, these constraints are; gradually tightened until gMIR has become MIR. The rest of this document will assume that you are familiar with the concepts; in :doc:`MachineIR (MIR) <../MIRLangRef>` and will highlight the differences; between MIR and gMIR. .. _gmir-instructions:. Generic Machine Instructions; ----------------------------. .. note::. This section expands on :ref:`mir-instructions` from the MIR Language; Reference. Whereas MIR deals largely in Target Instructions and only has a small set of; target independent opcodes such as ``COPY``, ``PHI``, and ``REG_SEQUENCE``,; gMIR defines a rich collection of ``Generic Opcodes`` which are target; independent and describe operations which are typically supported by targets.; One example is ``G_ADD`` which is the generic opcode for an integer addition.; More information on each of the generic opcodes can be found at; :doc:`GenericOpcode`. The ``MachineIRBuilder`` class wraps the ``MachineInstrBuilder`` and provides; a convenient way to create these generic instructions. .. _gmir-gvregs:. Generic Virtual Registers; -------------------------. .. note::. This section expands on :ref:`mir-registers` from the MIR Language; Reference. Generic virtual registers are like virtual registers but they are not assigned a; Register Class constraint. Instead, generic virtual registers have less strict; constraints starting with a :ref:`gmir-llt` and then further constrained to a; :ref:`gmir-regbank`. Eventually they will be constrained to a register class; at which point they become normal virtual registers. Generic virtual registers can be used with all the virtual register API's; provided by ``MachineRegisterInfo``. In particular, the def-use chain API's can; be used without needing to distinguish them from non-generic virtual registers. For simplicity, most generic instructions only accept virtual registers (both; generic and non-generic). There are some exceptions to this but in general:. * inst",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/GMIR.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GMIR.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GMIR.rst:5053,Integrability,depend,depends,5053,"to one register file so that we minimize the cost of copying data; back and forth to satisfy the (possibly conflicting) requirements of all the; instructions. Register Banks are a means to constrain the register allocator to; use a particular register file for a virtual register. In practice, register files A and B are rarely equal. They can typically store; the same data but there's usually some restrictions on what operations you can; do on each register file. A fairly common pattern is for one of them to be; accessible to integer operations and the other accessible to floating point; operations. To accommodate this, let's rename A and B to GPR (general purpose; registers) and FPR (floating point registers). We now have some additional constraints that limit us. An operation like G_FMUL; has to happen in FPR and G_ADD has to happen in GPR. However, even though this; prescribes a lot of the assignments we still have some freedom. A G_LOAD can; happen in both GPR and FPR, and which we want depends on who is going to consume; the loaded data. Similarly, G_FNEG can happen in both GPR and FPR. If we assign; it to FPR, then we'll use floating point negation. However, if we assign it to; GPR then we can equivalently G_XOR the sign bit with 1 to invert it. In summary, Register Banks are a means of disambiguating between seemingly; equivalent choices based on some analysis of the differences when each choice; is applied in a given context. To give some concrete examples:. AArch64. AArch64 has three main banks. GPR for integer operations, FPR for floating; point and also for the NEON vector instruction set. The third is CCR and; describes the condition code register used for predication. MIPS. MIPS has five main banks of which many programs only really use one or two.; GPR is the general purpose bank for integer operations. FGR or CP1 is for; the floating point operations as well as the MSA vector instructions and a; few other application specific extensions. CP0 is for syst",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/GMIR.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GMIR.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GMIR.rst:7697,Integrability,depend,dependent,7697,":ref:`RegisterBankInfo <api-registerbankinfo>`. .. _gmir-llt:. Low Level Type; --------------. Additionally, every generic virtual register has a type, represented by an; instance of the ``LLT`` class. Like ``EVT``/``MVT``/``Type``, it has no distinction between unsigned and signed; integer types. Furthermore, it also has no distinction between integer and; floating-point types: it mainly conveys absolutely necessary information, such; as size and number of vector lanes:. * ``sN`` for scalars; * ``pN`` for pointers; * ``<N x sM>`` for vectors. ``LLT`` is intended to replace the usage of ``EVT`` in SelectionDAG. Here are some LLT examples and their ``EVT`` and ``Type`` equivalents:. ============= ========= ======================================; LLT EVT IR Type; ============= ========= ======================================; ``s1`` ``i1`` ``i1``; ``s8`` ``i8`` ``i8``; ``s32`` ``i32`` ``i32``; ``s32`` ``f32`` ``float``; ``s17`` ``i17`` ``i17``; ``s16`` N/A ``{i8, i8}`` [#abi-dependent]_; ``s32`` N/A ``[4 x i8]`` [#abi-dependent]_; ``p0`` ``iPTR`` ``i8*``, ``i32*``, ``%opaque*``; ``p2`` ``iPTR`` ``i8 addrspace(2)*``; ``<4 x s32>`` ``v4f32`` ``<4 x float>``; ``s64`` ``v1f64`` ``<1 x double>``; ``<3 x s32>`` ``v3i32`` ``<3 x i32>``; ============= ========= ======================================. Rationale: instructions already encode a specific interpretation of types; (e.g., ``add`` vs. ``fadd``, or ``sdiv`` vs. ``udiv``). Also encoding that; information in the type system requires introducing bitcast with no real; advantage for the selector. Pointer types are distinguished by address space. This matches IR, as opposed; to SelectionDAG where address space is an attribute on operations.; This representation better supports pointers having different sizes depending; on their addressspace. .. note::. .. caution::. Is this still true? I thought we'd removed the 1-element vector concept.; Hypothetically, it could be distinct from a scalar but I think we failed to; find a real",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/GMIR.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GMIR.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GMIR.rst:7741,Integrability,depend,dependent,7741,":ref:`RegisterBankInfo <api-registerbankinfo>`. .. _gmir-llt:. Low Level Type; --------------. Additionally, every generic virtual register has a type, represented by an; instance of the ``LLT`` class. Like ``EVT``/``MVT``/``Type``, it has no distinction between unsigned and signed; integer types. Furthermore, it also has no distinction between integer and; floating-point types: it mainly conveys absolutely necessary information, such; as size and number of vector lanes:. * ``sN`` for scalars; * ``pN`` for pointers; * ``<N x sM>`` for vectors. ``LLT`` is intended to replace the usage of ``EVT`` in SelectionDAG. Here are some LLT examples and their ``EVT`` and ``Type`` equivalents:. ============= ========= ======================================; LLT EVT IR Type; ============= ========= ======================================; ``s1`` ``i1`` ``i1``; ``s8`` ``i8`` ``i8``; ``s32`` ``i32`` ``i32``; ``s32`` ``f32`` ``float``; ``s17`` ``i17`` ``i17``; ``s16`` N/A ``{i8, i8}`` [#abi-dependent]_; ``s32`` N/A ``[4 x i8]`` [#abi-dependent]_; ``p0`` ``iPTR`` ``i8*``, ``i32*``, ``%opaque*``; ``p2`` ``iPTR`` ``i8 addrspace(2)*``; ``<4 x s32>`` ``v4f32`` ``<4 x float>``; ``s64`` ``v1f64`` ``<1 x double>``; ``<3 x s32>`` ``v3i32`` ``<3 x i32>``; ============= ========= ======================================. Rationale: instructions already encode a specific interpretation of types; (e.g., ``add`` vs. ``fadd``, or ``sdiv`` vs. ``udiv``). Also encoding that; information in the type system requires introducing bitcast with no real; advantage for the selector. Pointer types are distinguished by address space. This matches IR, as opposed; to SelectionDAG where address space is an attribute on operations.; This representation better supports pointers having different sizes depending; on their addressspace. .. note::. .. caution::. Is this still true? I thought we'd removed the 1-element vector concept.; Hypothetically, it could be distinct from a scalar but I think we failed to; find a real",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/GMIR.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GMIR.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GMIR.rst:8489,Integrability,depend,depending,8489,"or lanes:. * ``sN`` for scalars; * ``pN`` for pointers; * ``<N x sM>`` for vectors. ``LLT`` is intended to replace the usage of ``EVT`` in SelectionDAG. Here are some LLT examples and their ``EVT`` and ``Type`` equivalents:. ============= ========= ======================================; LLT EVT IR Type; ============= ========= ======================================; ``s1`` ``i1`` ``i1``; ``s8`` ``i8`` ``i8``; ``s32`` ``i32`` ``i32``; ``s32`` ``f32`` ``float``; ``s17`` ``i17`` ``i17``; ``s16`` N/A ``{i8, i8}`` [#abi-dependent]_; ``s32`` N/A ``[4 x i8]`` [#abi-dependent]_; ``p0`` ``iPTR`` ``i8*``, ``i32*``, ``%opaque*``; ``p2`` ``iPTR`` ``i8 addrspace(2)*``; ``<4 x s32>`` ``v4f32`` ``<4 x float>``; ``s64`` ``v1f64`` ``<1 x double>``; ``<3 x s32>`` ``v3i32`` ``<3 x i32>``; ============= ========= ======================================. Rationale: instructions already encode a specific interpretation of types; (e.g., ``add`` vs. ``fadd``, or ``sdiv`` vs. ``udiv``). Also encoding that; information in the type system requires introducing bitcast with no real; advantage for the selector. Pointer types are distinguished by address space. This matches IR, as opposed; to SelectionDAG where address space is an attribute on operations.; This representation better supports pointers having different sizes depending; on their addressspace. .. note::. .. caution::. Is this still true? I thought we'd removed the 1-element vector concept.; Hypothetically, it could be distinct from a scalar but I think we failed to; find a real occurrence. Currently, LLT requires at least 2 elements in vectors, but some targets have; the concept of a '1-element vector'. Representing them as their underlying; scalar type is a nice simplification. .. rubric:: Footnotes. .. [#abi-dependent] This mapping is ABI dependent. Here we've assumed no additional padding is required. Generic Opcode Reference; ------------------------. The Generic Opcodes that are available are described at :doc:`GenericOpcode`.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/GMIR.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GMIR.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GMIR.rst:8948,Integrability,depend,dependent,8948,"or lanes:. * ``sN`` for scalars; * ``pN`` for pointers; * ``<N x sM>`` for vectors. ``LLT`` is intended to replace the usage of ``EVT`` in SelectionDAG. Here are some LLT examples and their ``EVT`` and ``Type`` equivalents:. ============= ========= ======================================; LLT EVT IR Type; ============= ========= ======================================; ``s1`` ``i1`` ``i1``; ``s8`` ``i8`` ``i8``; ``s32`` ``i32`` ``i32``; ``s32`` ``f32`` ``float``; ``s17`` ``i17`` ``i17``; ``s16`` N/A ``{i8, i8}`` [#abi-dependent]_; ``s32`` N/A ``[4 x i8]`` [#abi-dependent]_; ``p0`` ``iPTR`` ``i8*``, ``i32*``, ``%opaque*``; ``p2`` ``iPTR`` ``i8 addrspace(2)*``; ``<4 x s32>`` ``v4f32`` ``<4 x float>``; ``s64`` ``v1f64`` ``<1 x double>``; ``<3 x s32>`` ``v3i32`` ``<3 x i32>``; ============= ========= ======================================. Rationale: instructions already encode a specific interpretation of types; (e.g., ``add`` vs. ``fadd``, or ``sdiv`` vs. ``udiv``). Also encoding that; information in the type system requires introducing bitcast with no real; advantage for the selector. Pointer types are distinguished by address space. This matches IR, as opposed; to SelectionDAG where address space is an attribute on operations.; This representation better supports pointers having different sizes depending; on their addressspace. .. note::. .. caution::. Is this still true? I thought we'd removed the 1-element vector concept.; Hypothetically, it could be distinct from a scalar but I think we failed to; find a real occurrence. Currently, LLT requires at least 2 elements in vectors, but some targets have; the concept of a '1-element vector'. Representing them as their underlying; scalar type is a nice simplification. .. rubric:: Footnotes. .. [#abi-dependent] This mapping is ABI dependent. Here we've assumed no additional padding is required. Generic Opcode Reference; ------------------------. The Generic Opcodes that are available are described at :doc:`GenericOpcode`.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/GMIR.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GMIR.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GMIR.rst:8979,Integrability,depend,dependent,8979,"or lanes:. * ``sN`` for scalars; * ``pN`` for pointers; * ``<N x sM>`` for vectors. ``LLT`` is intended to replace the usage of ``EVT`` in SelectionDAG. Here are some LLT examples and their ``EVT`` and ``Type`` equivalents:. ============= ========= ======================================; LLT EVT IR Type; ============= ========= ======================================; ``s1`` ``i1`` ``i1``; ``s8`` ``i8`` ``i8``; ``s32`` ``i32`` ``i32``; ``s32`` ``f32`` ``float``; ``s17`` ``i17`` ``i17``; ``s16`` N/A ``{i8, i8}`` [#abi-dependent]_; ``s32`` N/A ``[4 x i8]`` [#abi-dependent]_; ``p0`` ``iPTR`` ``i8*``, ``i32*``, ``%opaque*``; ``p2`` ``iPTR`` ``i8 addrspace(2)*``; ``<4 x s32>`` ``v4f32`` ``<4 x float>``; ``s64`` ``v1f64`` ``<1 x double>``; ``<3 x s32>`` ``v3i32`` ``<3 x i32>``; ============= ========= ======================================. Rationale: instructions already encode a specific interpretation of types; (e.g., ``add`` vs. ``fadd``, or ``sdiv`` vs. ``udiv``). Also encoding that; information in the type system requires introducing bitcast with no real; advantage for the selector. Pointer types are distinguished by address space. This matches IR, as opposed; to SelectionDAG where address space is an attribute on operations.; This representation better supports pointers having different sizes depending; on their addressspace. .. note::. .. caution::. Is this still true? I thought we'd removed the 1-element vector concept.; Hypothetically, it could be distinct from a scalar but I think we failed to; find a real occurrence. Currently, LLT requires at least 2 elements in vectors, but some targets have; the concept of a '1-element vector'. Representing them as their underlying; scalar type is a nice simplification. .. rubric:: Footnotes. .. [#abi-dependent] This mapping is ABI dependent. Here we've assumed no additional padding is required. Generic Opcode Reference; ------------------------. The Generic Opcodes that are available are described at :doc:`GenericOpcode`.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/GMIR.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GMIR.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GMIR.rst:3821,Performance,perform,perform,3821," and instructions have lists of types.; That had two flaws: the type and size are redundant, and there was no generic; way of getting a given operand's type (as there was no 1:1 mapping between; instruction types and operands).; We considered putting the type in some variant of MCInstrDesc instead:; See `PR26576 <https://llvm.org/PR26576>`_: [GlobalISel] Generic MachineInstrs; need a type but this increases the memory footprint of the related objects. .. _gmir-regbank:. Register Bank; -------------. A Register Bank is a set of register classes defined by the target. This; definition is rather loose so let's talk about what they can achieve. Suppose we have a processor that has two register files, A and B. These are; equal in every way and support the same instructions for the same cost. They're; just physically stored apart and each instruction can only access registers from; A or B but never a mix of the two. If we want to perform an operation on data; that's in split between the two register files, we must first copy all the data; into a single register file. Given a processor like this, we would benefit from clustering related data; together into one register file so that we minimize the cost of copying data; back and forth to satisfy the (possibly conflicting) requirements of all the; instructions. Register Banks are a means to constrain the register allocator to; use a particular register file for a virtual register. In practice, register files A and B are rarely equal. They can typically store; the same data but there's usually some restrictions on what operations you can; do on each register file. A fairly common pattern is for one of them to be; accessible to integer operations and the other accessible to floating point; operations. To accommodate this, let's rename A and B to GPR (general purpose; registers) and FPR (floating point registers). We now have some additional constraints that limit us. An operation like G_FMUL; has to happen in FPR and G_ADD has",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/GMIR.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GMIR.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GMIR.rst:5093,Performance,load,loaded,5093,"to one register file so that we minimize the cost of copying data; back and forth to satisfy the (possibly conflicting) requirements of all the; instructions. Register Banks are a means to constrain the register allocator to; use a particular register file for a virtual register. In practice, register files A and B are rarely equal. They can typically store; the same data but there's usually some restrictions on what operations you can; do on each register file. A fairly common pattern is for one of them to be; accessible to integer operations and the other accessible to floating point; operations. To accommodate this, let's rename A and B to GPR (general purpose; registers) and FPR (floating point registers). We now have some additional constraints that limit us. An operation like G_FMUL; has to happen in FPR and G_ADD has to happen in GPR. However, even though this; prescribes a lot of the assignments we still have some freedom. A G_LOAD can; happen in both GPR and FPR, and which we want depends on who is going to consume; the loaded data. Similarly, G_FNEG can happen in both GPR and FPR. If we assign; it to FPR, then we'll use floating point negation. However, if we assign it to; GPR then we can equivalently G_XOR the sign bit with 1 to invert it. In summary, Register Banks are a means of disambiguating between seemingly; equivalent choices based on some analysis of the differences when each choice; is applied in a given context. To give some concrete examples:. AArch64. AArch64 has three main banks. GPR for integer operations, FPR for floating; point and also for the NEON vector instruction set. The third is CCR and; describes the condition code register used for predication. MIPS. MIPS has five main banks of which many programs only really use one or two.; GPR is the general purpose bank for integer operations. FGR or CP1 is for; the floating point operations as well as the MSA vector instructions and a; few other application specific extensions. CP0 is for syst",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/GMIR.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GMIR.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GMIR.rst:2965,Safety,redund,redundant,2965,"out needing to distinguish them from non-generic virtual registers. For simplicity, most generic instructions only accept virtual registers (both; generic and non-generic). There are some exceptions to this but in general:. * instead of immediates, they use a generic virtual register defined by an; instruction that materializes the immediate value (see; :ref:`irtranslator-constants`). Typically this is a G_CONSTANT or a; G_FCONSTANT. One example of an exception to this rule is G_SEXT_INREG where; having an immediate is mandatory.; * instead of physical register, they use a generic virtual register that is; either defined by a ``COPY`` from the physical register or used by a ``COPY``; that defines the physical register. .. admonition:: Historical Note. We started with an alternative representation, where MRI tracks a size for; each generic virtual register, and instructions have lists of types.; That had two flaws: the type and size are redundant, and there was no generic; way of getting a given operand's type (as there was no 1:1 mapping between; instruction types and operands).; We considered putting the type in some variant of MCInstrDesc instead:; See `PR26576 <https://llvm.org/PR26576>`_: [GlobalISel] Generic MachineInstrs; need a type but this increases the memory footprint of the related objects. .. _gmir-regbank:. Register Bank; -------------. A Register Bank is a set of register classes defined by the target. This; definition is rather loose so let's talk about what they can achieve. Suppose we have a processor that has two register files, A and B. These are; equal in every way and support the same instructions for the same cost. They're; just physically stored apart and each instruction can only access registers from; A or B but never a mix of the two. If we want to perform an operation on data; that's in split between the two register files, we must first copy all the data; into a single register file. Given a processor like this, we would benefit from clus",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/GMIR.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GMIR.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GMIR.rst:3749,Security,access,access,3749," .. admonition:: Historical Note. We started with an alternative representation, where MRI tracks a size for; each generic virtual register, and instructions have lists of types.; That had two flaws: the type and size are redundant, and there was no generic; way of getting a given operand's type (as there was no 1:1 mapping between; instruction types and operands).; We considered putting the type in some variant of MCInstrDesc instead:; See `PR26576 <https://llvm.org/PR26576>`_: [GlobalISel] Generic MachineInstrs; need a type but this increases the memory footprint of the related objects. .. _gmir-regbank:. Register Bank; -------------. A Register Bank is a set of register classes defined by the target. This; definition is rather loose so let's talk about what they can achieve. Suppose we have a processor that has two register files, A and B. These are; equal in every way and support the same instructions for the same cost. They're; just physically stored apart and each instruction can only access registers from; A or B but never a mix of the two. If we want to perform an operation on data; that's in split between the two register files, we must first copy all the data; into a single register file. Given a processor like this, we would benefit from clustering related data; together into one register file so that we minimize the cost of copying data; back and forth to satisfy the (possibly conflicting) requirements of all the; instructions. Register Banks are a means to constrain the register allocator to; use a particular register file for a virtual register. In practice, register files A and B are rarely equal. They can typically store; the same data but there's usually some restrictions on what operations you can; do on each register file. A fairly common pattern is for one of them to be; accessible to integer operations and the other accessible to floating point; operations. To accommodate this, let's rename A and B to GPR (general purpose; registers) and FPR (fl",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/GMIR.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GMIR.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GMIR.rst:4565,Security,access,accessible,4565,"iles, A and B. These are; equal in every way and support the same instructions for the same cost. They're; just physically stored apart and each instruction can only access registers from; A or B but never a mix of the two. If we want to perform an operation on data; that's in split between the two register files, we must first copy all the data; into a single register file. Given a processor like this, we would benefit from clustering related data; together into one register file so that we minimize the cost of copying data; back and forth to satisfy the (possibly conflicting) requirements of all the; instructions. Register Banks are a means to constrain the register allocator to; use a particular register file for a virtual register. In practice, register files A and B are rarely equal. They can typically store; the same data but there's usually some restrictions on what operations you can; do on each register file. A fairly common pattern is for one of them to be; accessible to integer operations and the other accessible to floating point; operations. To accommodate this, let's rename A and B to GPR (general purpose; registers) and FPR (floating point registers). We now have some additional constraints that limit us. An operation like G_FMUL; has to happen in FPR and G_ADD has to happen in GPR. However, even though this; prescribes a lot of the assignments we still have some freedom. A G_LOAD can; happen in both GPR and FPR, and which we want depends on who is going to consume; the loaded data. Similarly, G_FNEG can happen in both GPR and FPR. If we assign; it to FPR, then we'll use floating point negation. However, if we assign it to; GPR then we can equivalently G_XOR the sign bit with 1 to invert it. In summary, Register Banks are a means of disambiguating between seemingly; equivalent choices based on some analysis of the differences when each choice; is applied in a given context. To give some concrete examples:. AArch64. AArch64 has three main banks. GPR for",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/GMIR.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GMIR.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GMIR.rst:4612,Security,access,accessible,4612,"iles, A and B. These are; equal in every way and support the same instructions for the same cost. They're; just physically stored apart and each instruction can only access registers from; A or B but never a mix of the two. If we want to perform an operation on data; that's in split between the two register files, we must first copy all the data; into a single register file. Given a processor like this, we would benefit from clustering related data; together into one register file so that we minimize the cost of copying data; back and forth to satisfy the (possibly conflicting) requirements of all the; instructions. Register Banks are a means to constrain the register allocator to; use a particular register file for a virtual register. In practice, register files A and B are rarely equal. They can typically store; the same data but there's usually some restrictions on what operations you can; do on each register file. A fairly common pattern is for one of them to be; accessible to integer operations and the other accessible to floating point; operations. To accommodate this, let's rename A and B to GPR (general purpose; registers) and FPR (floating point registers). We now have some additional constraints that limit us. An operation like G_FMUL; has to happen in FPR and G_ADD has to happen in GPR. However, even though this; prescribes a lot of the assignments we still have some freedom. A G_LOAD can; happen in both GPR and FPR, and which we want depends on who is going to consume; the loaded data. Similarly, G_FNEG can happen in both GPR and FPR. If we assign; it to FPR, then we'll use floating point negation. However, if we assign it to; GPR then we can equivalently G_XOR the sign bit with 1 to invert it. In summary, Register Banks are a means of disambiguating between seemingly; equivalent choices based on some analysis of the differences when each choice; is applied in a given context. To give some concrete examples:. AArch64. AArch64 has three main banks. GPR for",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/GMIR.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GMIR.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GMIR.rst:2087,Usability,simpl,simplicity,2087,"codes can be found at; :doc:`GenericOpcode`. The ``MachineIRBuilder`` class wraps the ``MachineInstrBuilder`` and provides; a convenient way to create these generic instructions. .. _gmir-gvregs:. Generic Virtual Registers; -------------------------. .. note::. This section expands on :ref:`mir-registers` from the MIR Language; Reference. Generic virtual registers are like virtual registers but they are not assigned a; Register Class constraint. Instead, generic virtual registers have less strict; constraints starting with a :ref:`gmir-llt` and then further constrained to a; :ref:`gmir-regbank`. Eventually they will be constrained to a register class; at which point they become normal virtual registers. Generic virtual registers can be used with all the virtual register API's; provided by ``MachineRegisterInfo``. In particular, the def-use chain API's can; be used without needing to distinguish them from non-generic virtual registers. For simplicity, most generic instructions only accept virtual registers (both; generic and non-generic). There are some exceptions to this but in general:. * instead of immediates, they use a generic virtual register defined by an; instruction that materializes the immediate value (see; :ref:`irtranslator-constants`). Typically this is a G_CONSTANT or a; G_FCONSTANT. One example of an exception to this rule is G_SEXT_INREG where; having an immediate is mandatory.; * instead of physical register, they use a generic virtual register that is; either defined by a ``COPY`` from the physical register or used by a ``COPY``; that defines the physical register. .. admonition:: Historical Note. We started with an alternative representation, where MRI tracks a size for; each generic virtual register, and instructions have lists of types.; That had two flaws: the type and size are redundant, and there was no generic; way of getting a given operand's type (as there was no 1:1 mapping between; instruction types and operands).; We considered putting t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/GMIR.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GMIR.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GMIR.rst:8900,Usability,simpl,simplification,8900,"or lanes:. * ``sN`` for scalars; * ``pN`` for pointers; * ``<N x sM>`` for vectors. ``LLT`` is intended to replace the usage of ``EVT`` in SelectionDAG. Here are some LLT examples and their ``EVT`` and ``Type`` equivalents:. ============= ========= ======================================; LLT EVT IR Type; ============= ========= ======================================; ``s1`` ``i1`` ``i1``; ``s8`` ``i8`` ``i8``; ``s32`` ``i32`` ``i32``; ``s32`` ``f32`` ``float``; ``s17`` ``i17`` ``i17``; ``s16`` N/A ``{i8, i8}`` [#abi-dependent]_; ``s32`` N/A ``[4 x i8]`` [#abi-dependent]_; ``p0`` ``iPTR`` ``i8*``, ``i32*``, ``%opaque*``; ``p2`` ``iPTR`` ``i8 addrspace(2)*``; ``<4 x s32>`` ``v4f32`` ``<4 x float>``; ``s64`` ``v1f64`` ``<1 x double>``; ``<3 x s32>`` ``v3i32`` ``<3 x i32>``; ============= ========= ======================================. Rationale: instructions already encode a specific interpretation of types; (e.g., ``add`` vs. ``fadd``, or ``sdiv`` vs. ``udiv``). Also encoding that; information in the type system requires introducing bitcast with no real; advantage for the selector. Pointer types are distinguished by address space. This matches IR, as opposed; to SelectionDAG where address space is an attribute on operations.; This representation better supports pointers having different sizes depending; on their addressspace. .. note::. .. caution::. Is this still true? I thought we'd removed the 1-element vector concept.; Hypothetically, it could be distinct from a scalar but I think we failed to; find a real occurrence. Currently, LLT requires at least 2 elements in vectors, but some targets have; the concept of a '1-element vector'. Representing them as their underlying; scalar type is a nice simplification. .. rubric:: Footnotes. .. [#abi-dependent] This mapping is ABI dependent. Here we've assumed no additional padding is required. Generic Opcode Reference; ------------------------. The Generic Opcodes that are available are described at :doc:`GenericOpcode`.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/GMIR.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/GMIR.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/index.rst:2482,Availability,failure,failures,2482," fast selectors share the :ref:`pipeline`, and targets can; configure that pipeline to better suit their needs. Design and Implementation Reference; ===================================. More information on the design and implementation of GlobalISel can be found in; the following sections. .. toctree::; :maxdepth: 1. GMIR; GenericOpcode; MIRPatterns; Pipeline; Porting; Resources. More information on specific passes can be found in the following sections:. .. toctree::; :maxdepth: 1. IRTranslator; Legalizer; RegBankSelect; InstructionSelect; KnownBits. .. _progress:. Progress and Future Work; ========================. The initial goal is to replace FastISel on AArch64. The next step will be to; replace SelectionDAG as the optimized ISel. ``NOTE``:; While we iterate on GlobalISel, we strive to avoid affecting the performance of; SelectionDAG, FastISel, or the other MIR passes. For instance, the types of; :ref:`gmir-gvregs` are stored in a separate table in ``MachineRegisterInfo``,; that is destroyed after :ref:`instructionselect`. .. _progress-fastisel:. FastISel Replacement; --------------------. For the initial FastISel replacement, we intend to fallback to SelectionDAG on; selection failures. Currently, compile-time of the fast pipeline is within 1.5x of FastISel.; We're optimistic we can get to within 1.1/1.2x, but beating FastISel will be; challenging given the multi-pass approach.; Still, supporting all IR (via a complete legalizer) and avoiding the fallback; to SelectionDAG in the worst case should enable better amortized performance; than SelectionDAG+FastISel. ``NOTE``:; We considered never having a fallback to SelectionDAG, instead deciding early; whether a given function is supported by GlobalISel or not. The decision would; be based on :ref:`milegalizer` queries.; We abandoned that for two reasons:; a) on IR inputs, we'd need to basically simulate the :ref:`irtranslator`;; b) to be robust against unforeseen failures and to enable iterative; improvements.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/index.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/index.rst:3204,Availability,robust,robust,3204," fast selectors share the :ref:`pipeline`, and targets can; configure that pipeline to better suit their needs. Design and Implementation Reference; ===================================. More information on the design and implementation of GlobalISel can be found in; the following sections. .. toctree::; :maxdepth: 1. GMIR; GenericOpcode; MIRPatterns; Pipeline; Porting; Resources. More information on specific passes can be found in the following sections:. .. toctree::; :maxdepth: 1. IRTranslator; Legalizer; RegBankSelect; InstructionSelect; KnownBits. .. _progress:. Progress and Future Work; ========================. The initial goal is to replace FastISel on AArch64. The next step will be to; replace SelectionDAG as the optimized ISel. ``NOTE``:; While we iterate on GlobalISel, we strive to avoid affecting the performance of; SelectionDAG, FastISel, or the other MIR passes. For instance, the types of; :ref:`gmir-gvregs` are stored in a separate table in ``MachineRegisterInfo``,; that is destroyed after :ref:`instructionselect`. .. _progress-fastisel:. FastISel Replacement; --------------------. For the initial FastISel replacement, we intend to fallback to SelectionDAG on; selection failures. Currently, compile-time of the fast pipeline is within 1.5x of FastISel.; We're optimistic we can get to within 1.1/1.2x, but beating FastISel will be; challenging given the multi-pass approach.; Still, supporting all IR (via a complete legalizer) and avoiding the fallback; to SelectionDAG in the worst case should enable better amortized performance; than SelectionDAG+FastISel. ``NOTE``:; We considered never having a fallback to SelectionDAG, instead deciding early; whether a given function is supported by GlobalISel or not. The decision would; be based on :ref:`milegalizer` queries.; We abandoned that for two reasons:; a) on IR inputs, we'd need to basically simulate the :ref:`irtranslator`;; b) to be robust against unforeseen failures and to enable iterative; improvements.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/index.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/index.rst:3230,Availability,failure,failures,3230," fast selectors share the :ref:`pipeline`, and targets can; configure that pipeline to better suit their needs. Design and Implementation Reference; ===================================. More information on the design and implementation of GlobalISel can be found in; the following sections. .. toctree::; :maxdepth: 1. GMIR; GenericOpcode; MIRPatterns; Pipeline; Porting; Resources. More information on specific passes can be found in the following sections:. .. toctree::; :maxdepth: 1. IRTranslator; Legalizer; RegBankSelect; InstructionSelect; KnownBits. .. _progress:. Progress and Future Work; ========================. The initial goal is to replace FastISel on AArch64. The next step will be to; replace SelectionDAG as the optimized ISel. ``NOTE``:; While we iterate on GlobalISel, we strive to avoid affecting the performance of; SelectionDAG, FastISel, or the other MIR passes. For instance, the types of; :ref:`gmir-gvregs` are stored in a separate table in ``MachineRegisterInfo``,; that is destroyed after :ref:`instructionselect`. .. _progress-fastisel:. FastISel Replacement; --------------------. For the initial FastISel replacement, we intend to fallback to SelectionDAG on; selection failures. Currently, compile-time of the fast pipeline is within 1.5x of FastISel.; We're optimistic we can get to within 1.1/1.2x, but beating FastISel will be; challenging given the multi-pass approach.; Still, supporting all IR (via a complete legalizer) and avoiding the fallback; to SelectionDAG in the worst case should enable better amortized performance; than SelectionDAG+FastISel. ``NOTE``:; We considered never having a fallback to SelectionDAG, instead deciding early; whether a given function is supported by GlobalISel or not. The decision would; be based on :ref:`milegalizer` queries.; We abandoned that for two reasons:; a) on IR inputs, we'd need to basically simulate the :ref:`irtranslator`;; b) to be robust against unforeseen failures and to enable iterative; improvements.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/index.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/index.rst:1311,Deployability,pipeline,pipeline,1311,"Sel is a framework that provides a set of reusable passes and utilities; for instruction selection --- translation from LLVM IR to target-specific; Machine IR (MIR). GlobalISel is intended to be a replacement for SelectionDAG and FastISel, to; solve three major problems:. * **Performance** --- SelectionDAG introduces a dedicated intermediate; representation, which has a compile-time cost. GlobalISel directly operates on the post-isel representation used by the; rest of the code generator, MIR.; It does require extensions to that representation to support arbitrary; incoming IR: :ref:`gmir`. * **Granularity** --- SelectionDAG and FastISel operate on individual basic; blocks, losing some global optimization opportunities. GlobalISel operates on the whole function. * **Modularity** --- SelectionDAG and FastISel are radically different and share; very little code. GlobalISel is built in a way that enables code reuse. For instance, both the; optimized and fast selectors share the :ref:`pipeline`, and targets can; configure that pipeline to better suit their needs. Design and Implementation Reference; ===================================. More information on the design and implementation of GlobalISel can be found in; the following sections. .. toctree::; :maxdepth: 1. GMIR; GenericOpcode; MIRPatterns; Pipeline; Porting; Resources. More information on specific passes can be found in the following sections:. .. toctree::; :maxdepth: 1. IRTranslator; Legalizer; RegBankSelect; InstructionSelect; KnownBits. .. _progress:. Progress and Future Work; ========================. The initial goal is to replace FastISel on AArch64. The next step will be to; replace SelectionDAG as the optimized ISel. ``NOTE``:; While we iterate on GlobalISel, we strive to avoid affecting the performance of; SelectionDAG, FastISel, or the other MIR passes. For instance, the types of; :ref:`gmir-gvregs` are stored in a separate table in ``MachineRegisterInfo``,; that is destroyed after :ref:`instructions",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/index.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/index.rst:1354,Deployability,pipeline,pipeline,1354,"Sel is a framework that provides a set of reusable passes and utilities; for instruction selection --- translation from LLVM IR to target-specific; Machine IR (MIR). GlobalISel is intended to be a replacement for SelectionDAG and FastISel, to; solve three major problems:. * **Performance** --- SelectionDAG introduces a dedicated intermediate; representation, which has a compile-time cost. GlobalISel directly operates on the post-isel representation used by the; rest of the code generator, MIR.; It does require extensions to that representation to support arbitrary; incoming IR: :ref:`gmir`. * **Granularity** --- SelectionDAG and FastISel operate on individual basic; blocks, losing some global optimization opportunities. GlobalISel operates on the whole function. * **Modularity** --- SelectionDAG and FastISel are radically different and share; very little code. GlobalISel is built in a way that enables code reuse. For instance, both the; optimized and fast selectors share the :ref:`pipeline`, and targets can; configure that pipeline to better suit their needs. Design and Implementation Reference; ===================================. More information on the design and implementation of GlobalISel can be found in; the following sections. .. toctree::; :maxdepth: 1. GMIR; GenericOpcode; MIRPatterns; Pipeline; Porting; Resources. More information on specific passes can be found in the following sections:. .. toctree::; :maxdepth: 1. IRTranslator; Legalizer; RegBankSelect; InstructionSelect; KnownBits. .. _progress:. Progress and Future Work; ========================. The initial goal is to replace FastISel on AArch64. The next step will be to; replace SelectionDAG as the optimized ISel. ``NOTE``:; While we iterate on GlobalISel, we strive to avoid affecting the performance of; SelectionDAG, FastISel, or the other MIR passes. For instance, the types of; :ref:`gmir-gvregs` are stored in a separate table in ``MachineRegisterInfo``,; that is destroyed after :ref:`instructions",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/index.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/index.rst:2528,Deployability,pipeline,pipeline,2528," fast selectors share the :ref:`pipeline`, and targets can; configure that pipeline to better suit their needs. Design and Implementation Reference; ===================================. More information on the design and implementation of GlobalISel can be found in; the following sections. .. toctree::; :maxdepth: 1. GMIR; GenericOpcode; MIRPatterns; Pipeline; Porting; Resources. More information on specific passes can be found in the following sections:. .. toctree::; :maxdepth: 1. IRTranslator; Legalizer; RegBankSelect; InstructionSelect; KnownBits. .. _progress:. Progress and Future Work; ========================. The initial goal is to replace FastISel on AArch64. The next step will be to; replace SelectionDAG as the optimized ISel. ``NOTE``:; While we iterate on GlobalISel, we strive to avoid affecting the performance of; SelectionDAG, FastISel, or the other MIR passes. For instance, the types of; :ref:`gmir-gvregs` are stored in a separate table in ``MachineRegisterInfo``,; that is destroyed after :ref:`instructionselect`. .. _progress-fastisel:. FastISel Replacement; --------------------. For the initial FastISel replacement, we intend to fallback to SelectionDAG on; selection failures. Currently, compile-time of the fast pipeline is within 1.5x of FastISel.; We're optimistic we can get to within 1.1/1.2x, but beating FastISel will be; challenging given the multi-pass approach.; Still, supporting all IR (via a complete legalizer) and avoiding the fallback; to SelectionDAG in the worst case should enable better amortized performance; than SelectionDAG+FastISel. ``NOTE``:; We considered never having a fallback to SelectionDAG, instead deciding early; whether a given function is supported by GlobalISel or not. The decision would; be based on :ref:`milegalizer` queries.; We abandoned that for two reasons:; a) on IR inputs, we'd need to basically simulate the :ref:`irtranslator`;; b) to be robust against unforeseen failures and to enable iterative; improvements.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/index.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/index.rst:1339,Modifiability,config,configure,1339,"Sel is a framework that provides a set of reusable passes and utilities; for instruction selection --- translation from LLVM IR to target-specific; Machine IR (MIR). GlobalISel is intended to be a replacement for SelectionDAG and FastISel, to; solve three major problems:. * **Performance** --- SelectionDAG introduces a dedicated intermediate; representation, which has a compile-time cost. GlobalISel directly operates on the post-isel representation used by the; rest of the code generator, MIR.; It does require extensions to that representation to support arbitrary; incoming IR: :ref:`gmir`. * **Granularity** --- SelectionDAG and FastISel operate on individual basic; blocks, losing some global optimization opportunities. GlobalISel operates on the whole function. * **Modularity** --- SelectionDAG and FastISel are radically different and share; very little code. GlobalISel is built in a way that enables code reuse. For instance, both the; optimized and fast selectors share the :ref:`pipeline`, and targets can; configure that pipeline to better suit their needs. Design and Implementation Reference; ===================================. More information on the design and implementation of GlobalISel can be found in; the following sections. .. toctree::; :maxdepth: 1. GMIR; GenericOpcode; MIRPatterns; Pipeline; Porting; Resources. More information on specific passes can be found in the following sections:. .. toctree::; :maxdepth: 1. IRTranslator; Legalizer; RegBankSelect; InstructionSelect; KnownBits. .. _progress:. Progress and Future Work; ========================. The initial goal is to replace FastISel on AArch64. The next step will be to; replace SelectionDAG as the optimized ISel. ``NOTE``:; While we iterate on GlobalISel, we strive to avoid affecting the performance of; SelectionDAG, FastISel, or the other MIR passes. For instance, the types of; :ref:`gmir-gvregs` are stored in a separate table in ``MachineRegisterInfo``,; that is destroyed after :ref:`instructions",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/index.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/index.rst:1017,Performance,optimiz,optimization,1017,"============================; Global Instruction Selection; ============================. .. warning::; This document is a work in progress. It reflects the current state of the; implementation, as well as open design and implementation issues. .. contents::; :local:; :depth: 1. Introduction; ============. GlobalISel is a framework that provides a set of reusable passes and utilities; for instruction selection --- translation from LLVM IR to target-specific; Machine IR (MIR). GlobalISel is intended to be a replacement for SelectionDAG and FastISel, to; solve three major problems:. * **Performance** --- SelectionDAG introduces a dedicated intermediate; representation, which has a compile-time cost. GlobalISel directly operates on the post-isel representation used by the; rest of the code generator, MIR.; It does require extensions to that representation to support arbitrary; incoming IR: :ref:`gmir`. * **Granularity** --- SelectionDAG and FastISel operate on individual basic; blocks, losing some global optimization opportunities. GlobalISel operates on the whole function. * **Modularity** --- SelectionDAG and FastISel are radically different and share; very little code. GlobalISel is built in a way that enables code reuse. For instance, both the; optimized and fast selectors share the :ref:`pipeline`, and targets can; configure that pipeline to better suit their needs. Design and Implementation Reference; ===================================. More information on the design and implementation of GlobalISel can be found in; the following sections. .. toctree::; :maxdepth: 1. GMIR; GenericOpcode; MIRPatterns; Pipeline; Porting; Resources. More information on specific passes can be found in the following sections:. .. toctree::; :maxdepth: 1. IRTranslator; Legalizer; RegBankSelect; InstructionSelect; KnownBits. .. _progress:. Progress and Future Work; ========================. The initial goal is to replace FastISel on AArch64. The next step will be to; replace SelectionDA",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/index.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/index.rst:1266,Performance,optimiz,optimized,1266,"Sel is a framework that provides a set of reusable passes and utilities; for instruction selection --- translation from LLVM IR to target-specific; Machine IR (MIR). GlobalISel is intended to be a replacement for SelectionDAG and FastISel, to; solve three major problems:. * **Performance** --- SelectionDAG introduces a dedicated intermediate; representation, which has a compile-time cost. GlobalISel directly operates on the post-isel representation used by the; rest of the code generator, MIR.; It does require extensions to that representation to support arbitrary; incoming IR: :ref:`gmir`. * **Granularity** --- SelectionDAG and FastISel operate on individual basic; blocks, losing some global optimization opportunities. GlobalISel operates on the whole function. * **Modularity** --- SelectionDAG and FastISel are radically different and share; very little code. GlobalISel is built in a way that enables code reuse. For instance, both the; optimized and fast selectors share the :ref:`pipeline`, and targets can; configure that pipeline to better suit their needs. Design and Implementation Reference; ===================================. More information on the design and implementation of GlobalISel can be found in; the following sections. .. toctree::; :maxdepth: 1. GMIR; GenericOpcode; MIRPatterns; Pipeline; Porting; Resources. More information on specific passes can be found in the following sections:. .. toctree::; :maxdepth: 1. IRTranslator; Legalizer; RegBankSelect; InstructionSelect; KnownBits. .. _progress:. Progress and Future Work; ========================. The initial goal is to replace FastISel on AArch64. The next step will be to; replace SelectionDAG as the optimized ISel. ``NOTE``:; While we iterate on GlobalISel, we strive to avoid affecting the performance of; SelectionDAG, FastISel, or the other MIR passes. For instance, the types of; :ref:`gmir-gvregs` are stored in a separate table in ``MachineRegisterInfo``,; that is destroyed after :ref:`instructions",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/index.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/index.rst:2010,Performance,optimiz,optimized,2010,"blocks, losing some global optimization opportunities. GlobalISel operates on the whole function. * **Modularity** --- SelectionDAG and FastISel are radically different and share; very little code. GlobalISel is built in a way that enables code reuse. For instance, both the; optimized and fast selectors share the :ref:`pipeline`, and targets can; configure that pipeline to better suit their needs. Design and Implementation Reference; ===================================. More information on the design and implementation of GlobalISel can be found in; the following sections. .. toctree::; :maxdepth: 1. GMIR; GenericOpcode; MIRPatterns; Pipeline; Porting; Resources. More information on specific passes can be found in the following sections:. .. toctree::; :maxdepth: 1. IRTranslator; Legalizer; RegBankSelect; InstructionSelect; KnownBits. .. _progress:. Progress and Future Work; ========================. The initial goal is to replace FastISel on AArch64. The next step will be to; replace SelectionDAG as the optimized ISel. ``NOTE``:; While we iterate on GlobalISel, we strive to avoid affecting the performance of; SelectionDAG, FastISel, or the other MIR passes. For instance, the types of; :ref:`gmir-gvregs` are stored in a separate table in ``MachineRegisterInfo``,; that is destroyed after :ref:`instructionselect`. .. _progress-fastisel:. FastISel Replacement; --------------------. For the initial FastISel replacement, we intend to fallback to SelectionDAG on; selection failures. Currently, compile-time of the fast pipeline is within 1.5x of FastISel.; We're optimistic we can get to within 1.1/1.2x, but beating FastISel will be; challenging given the multi-pass approach.; Still, supporting all IR (via a complete legalizer) and avoiding the fallback; to SelectionDAG in the worst case should enable better amortized performance; than SelectionDAG+FastISel. ``NOTE``:; We considered never having a fallback to SelectionDAG, instead deciding early; whether a given function is",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/index.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/index.rst:2102,Performance,perform,performance,2102,"ularity** --- SelectionDAG and FastISel are radically different and share; very little code. GlobalISel is built in a way that enables code reuse. For instance, both the; optimized and fast selectors share the :ref:`pipeline`, and targets can; configure that pipeline to better suit their needs. Design and Implementation Reference; ===================================. More information on the design and implementation of GlobalISel can be found in; the following sections. .. toctree::; :maxdepth: 1. GMIR; GenericOpcode; MIRPatterns; Pipeline; Porting; Resources. More information on specific passes can be found in the following sections:. .. toctree::; :maxdepth: 1. IRTranslator; Legalizer; RegBankSelect; InstructionSelect; KnownBits. .. _progress:. Progress and Future Work; ========================. The initial goal is to replace FastISel on AArch64. The next step will be to; replace SelectionDAG as the optimized ISel. ``NOTE``:; While we iterate on GlobalISel, we strive to avoid affecting the performance of; SelectionDAG, FastISel, or the other MIR passes. For instance, the types of; :ref:`gmir-gvregs` are stored in a separate table in ``MachineRegisterInfo``,; that is destroyed after :ref:`instructionselect`. .. _progress-fastisel:. FastISel Replacement; --------------------. For the initial FastISel replacement, we intend to fallback to SelectionDAG on; selection failures. Currently, compile-time of the fast pipeline is within 1.5x of FastISel.; We're optimistic we can get to within 1.1/1.2x, but beating FastISel will be; challenging given the multi-pass approach.; Still, supporting all IR (via a complete legalizer) and avoiding the fallback; to SelectionDAG in the worst case should enable better amortized performance; than SelectionDAG+FastISel. ``NOTE``:; We considered never having a fallback to SelectionDAG, instead deciding early; whether a given function is supported by GlobalISel or not. The decision would; be based on :ref:`milegalizer` queries.; We abandoned",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/index.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/index.rst:2832,Performance,perform,performance,2832," fast selectors share the :ref:`pipeline`, and targets can; configure that pipeline to better suit their needs. Design and Implementation Reference; ===================================. More information on the design and implementation of GlobalISel can be found in; the following sections. .. toctree::; :maxdepth: 1. GMIR; GenericOpcode; MIRPatterns; Pipeline; Porting; Resources. More information on specific passes can be found in the following sections:. .. toctree::; :maxdepth: 1. IRTranslator; Legalizer; RegBankSelect; InstructionSelect; KnownBits. .. _progress:. Progress and Future Work; ========================. The initial goal is to replace FastISel on AArch64. The next step will be to; replace SelectionDAG as the optimized ISel. ``NOTE``:; While we iterate on GlobalISel, we strive to avoid affecting the performance of; SelectionDAG, FastISel, or the other MIR passes. For instance, the types of; :ref:`gmir-gvregs` are stored in a separate table in ``MachineRegisterInfo``,; that is destroyed after :ref:`instructionselect`. .. _progress-fastisel:. FastISel Replacement; --------------------. For the initial FastISel replacement, we intend to fallback to SelectionDAG on; selection failures. Currently, compile-time of the fast pipeline is within 1.5x of FastISel.; We're optimistic we can get to within 1.1/1.2x, but beating FastISel will be; challenging given the multi-pass approach.; Still, supporting all IR (via a complete legalizer) and avoiding the fallback; to SelectionDAG in the worst case should enable better amortized performance; than SelectionDAG+FastISel. ``NOTE``:; We considered never having a fallback to SelectionDAG, instead deciding early; whether a given function is supported by GlobalISel or not. The decision would; be based on :ref:`milegalizer` queries.; We abandoned that for two reasons:; a) on IR inputs, we'd need to basically simulate the :ref:`irtranslator`;; b) to be robust against unforeseen failures and to enable iterative; improvements.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/index.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/index.rst:2082,Safety,avoid,avoid,2082,"ularity** --- SelectionDAG and FastISel are radically different and share; very little code. GlobalISel is built in a way that enables code reuse. For instance, both the; optimized and fast selectors share the :ref:`pipeline`, and targets can; configure that pipeline to better suit their needs. Design and Implementation Reference; ===================================. More information on the design and implementation of GlobalISel can be found in; the following sections. .. toctree::; :maxdepth: 1. GMIR; GenericOpcode; MIRPatterns; Pipeline; Porting; Resources. More information on specific passes can be found in the following sections:. .. toctree::; :maxdepth: 1. IRTranslator; Legalizer; RegBankSelect; InstructionSelect; KnownBits. .. _progress:. Progress and Future Work; ========================. The initial goal is to replace FastISel on AArch64. The next step will be to; replace SelectionDAG as the optimized ISel. ``NOTE``:; While we iterate on GlobalISel, we strive to avoid affecting the performance of; SelectionDAG, FastISel, or the other MIR passes. For instance, the types of; :ref:`gmir-gvregs` are stored in a separate table in ``MachineRegisterInfo``,; that is destroyed after :ref:`instructionselect`. .. _progress-fastisel:. FastISel Replacement; --------------------. For the initial FastISel replacement, we intend to fallback to SelectionDAG on; selection failures. Currently, compile-time of the fast pipeline is within 1.5x of FastISel.; We're optimistic we can get to within 1.1/1.2x, but beating FastISel will be; challenging given the multi-pass approach.; Still, supporting all IR (via a complete legalizer) and avoiding the fallback; to SelectionDAG in the worst case should enable better amortized performance; than SelectionDAG+FastISel. ``NOTE``:; We considered never having a fallback to SelectionDAG, instead deciding early; whether a given function is supported by GlobalISel or not. The decision would; be based on :ref:`milegalizer` queries.; We abandoned",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/index.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/index.rst:2744,Safety,avoid,avoiding,2744," fast selectors share the :ref:`pipeline`, and targets can; configure that pipeline to better suit their needs. Design and Implementation Reference; ===================================. More information on the design and implementation of GlobalISel can be found in; the following sections. .. toctree::; :maxdepth: 1. GMIR; GenericOpcode; MIRPatterns; Pipeline; Porting; Resources. More information on specific passes can be found in the following sections:. .. toctree::; :maxdepth: 1. IRTranslator; Legalizer; RegBankSelect; InstructionSelect; KnownBits. .. _progress:. Progress and Future Work; ========================. The initial goal is to replace FastISel on AArch64. The next step will be to; replace SelectionDAG as the optimized ISel. ``NOTE``:; While we iterate on GlobalISel, we strive to avoid affecting the performance of; SelectionDAG, FastISel, or the other MIR passes. For instance, the types of; :ref:`gmir-gvregs` are stored in a separate table in ``MachineRegisterInfo``,; that is destroyed after :ref:`instructionselect`. .. _progress-fastisel:. FastISel Replacement; --------------------. For the initial FastISel replacement, we intend to fallback to SelectionDAG on; selection failures. Currently, compile-time of the fast pipeline is within 1.5x of FastISel.; We're optimistic we can get to within 1.1/1.2x, but beating FastISel will be; challenging given the multi-pass approach.; Still, supporting all IR (via a complete legalizer) and avoiding the fallback; to SelectionDAG in the worst case should enable better amortized performance; than SelectionDAG+FastISel. ``NOTE``:; We considered never having a fallback to SelectionDAG, instead deciding early; whether a given function is supported by GlobalISel or not. The decision would; be based on :ref:`milegalizer` queries.; We abandoned that for two reasons:; a) on IR inputs, we'd need to basically simulate the :ref:`irtranslator`;; b) to be robust against unforeseen failures and to enable iterative; improvements.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/index.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/InstructionSelect.rst:695,Modifiability,parameteriz,parameterize,695,"; .. _instructionselect:. InstructionSelect; -----------------. This pass transforms generic machine instructions into equivalent; target-specific instructions. It traverses the ``MachineFunction`` bottom-up,; selecting uses before definitions, enabling trivial dead code elimination. .. _api-instructionselector:. API: InstructionSelector; ^^^^^^^^^^^^^^^^^^^^^^^^. The target implements the ``InstructionSelector`` class, containing the; target-specific selection logic proper. The instance is provided by the subtarget, so that it can specialize the; selector by subtarget feature (with, e.g., a vector selector overriding parts; of a general-purpose common selector).; We might also want to parameterize it by MachineFunction, to enable selector; variants based on function attributes like optsize. The simple API consists of:. .. code-block:: c++. virtual bool select(MachineInstr &MI). This target-provided method is responsible for mutating (or replacing) a; possibly-generic MI into a fully target-specific equivalent.; It is also responsible for doing the necessary constraining of gvregs into the; appropriate register classes as well as passing through COPY instructions to; the register allocator. The ``InstructionSelector`` can fold other instructions into the selected MI,; by walking the use-def chain of the vreg operands.; As GlobalISel is Global, this folding can occur across basic blocks. SelectionDAG Rule Imports; ^^^^^^^^^^^^^^^^^^^^^^^^^. TableGen will import SelectionDAG rules and provide the following function to; execute them:. .. code-block:: c++. bool selectImpl(MachineInstr &MI). The ``--stats`` option can be used to determine what proportion of rules were; successfully imported. The easiest way to use this is to copy the; ``-gen-globalisel`` tablegen command from ``ninja -v`` and modify it. Similarly, the ``--warn-on-skipped-patterns`` option can be used to obtain the; reasons that rules weren't imported. This can be used to focus on the most; important rejec",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/InstructionSelect.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/InstructionSelect.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/InstructionSelect.rst:3479,Safety,avoid,avoid,3479,"mine what proportion of rules were; successfully imported. The easiest way to use this is to copy the; ``-gen-globalisel`` tablegen command from ``ninja -v`` and modify it. Similarly, the ``--warn-on-skipped-patterns`` option can be used to obtain the; reasons that rules weren't imported. This can be used to focus on the most; important rejection reasons. PatLeaf Predicates; ^^^^^^^^^^^^^^^^^^. PatLeafs cannot be imported because their C++ is implemented in terms of; ``SDNode`` objects. PatLeafs that handle immediate predicates should be; replaced by ``ImmLeaf``, ``IntImmLeaf``, or ``FPImmLeaf`` as appropriate. There's no standard answer for other PatLeafs. Some standard predicates have; been baked into TableGen but this should not generally be done. Custom SDNodes; ^^^^^^^^^^^^^^. Custom SDNodes should be mapped to Target Pseudos using ``GINodeEquiv``. This; will cause the instruction selector to import them but you will also need to; ensure the target pseudo is introduced to the MIR before the instruction; selector. Any preceding pass is suitable but the legalizer will be a; particularly common choice. ComplexPatterns; ^^^^^^^^^^^^^^^. ComplexPatterns cannot be imported because their C++ is implemented in terms of; ``SDNode`` objects. GlobalISel versions should be defined with; ``GIComplexOperandMatcher`` and mapped to ComplexPattern with; ``GIComplexPatternEquiv``. The following predicates are useful for porting ComplexPattern:. * isBaseWithConstantOffset() - Check for base+offset structures; * isOperandImmEqual() - Check for a particular constant; * isObviouslySafeToFold() - Check for reasons an instruction can't be sunk and folded into another. There are some important points for the C++ implementation:. * Don't modify MIR in the predicate; * Renderer lambdas should capture by value to avoid use-after-free. They will be used after the predicate returns.; * Only create instructions in a renderer lambda. GlobalISel won't clean up things you create but don't use. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/InstructionSelect.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/InstructionSelect.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/InstructionSelect.rst:466,Testability,log,logic,466,"; .. _instructionselect:. InstructionSelect; -----------------. This pass transforms generic machine instructions into equivalent; target-specific instructions. It traverses the ``MachineFunction`` bottom-up,; selecting uses before definitions, enabling trivial dead code elimination. .. _api-instructionselector:. API: InstructionSelector; ^^^^^^^^^^^^^^^^^^^^^^^^. The target implements the ``InstructionSelector`` class, containing the; target-specific selection logic proper. The instance is provided by the subtarget, so that it can specialize the; selector by subtarget feature (with, e.g., a vector selector overriding parts; of a general-purpose common selector).; We might also want to parameterize it by MachineFunction, to enable selector; variants based on function attributes like optsize. The simple API consists of:. .. code-block:: c++. virtual bool select(MachineInstr &MI). This target-provided method is responsible for mutating (or replacing) a; possibly-generic MI into a fully target-specific equivalent.; It is also responsible for doing the necessary constraining of gvregs into the; appropriate register classes as well as passing through COPY instructions to; the register allocator. The ``InstructionSelector`` can fold other instructions into the selected MI,; by walking the use-def chain of the vreg operands.; As GlobalISel is Global, this folding can occur across basic blocks. SelectionDAG Rule Imports; ^^^^^^^^^^^^^^^^^^^^^^^^^. TableGen will import SelectionDAG rules and provide the following function to; execute them:. .. code-block:: c++. bool selectImpl(MachineInstr &MI). The ``--stats`` option can be used to determine what proportion of rules were; successfully imported. The easiest way to use this is to copy the; ``-gen-globalisel`` tablegen command from ``ninja -v`` and modify it. Similarly, the ``--warn-on-skipped-patterns`` option can be used to obtain the; reasons that rules weren't imported. This can be used to focus on the most; important rejec",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/InstructionSelect.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/InstructionSelect.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/InstructionSelect.rst:807,Usability,simpl,simple,807,"; .. _instructionselect:. InstructionSelect; -----------------. This pass transforms generic machine instructions into equivalent; target-specific instructions. It traverses the ``MachineFunction`` bottom-up,; selecting uses before definitions, enabling trivial dead code elimination. .. _api-instructionselector:. API: InstructionSelector; ^^^^^^^^^^^^^^^^^^^^^^^^. The target implements the ``InstructionSelector`` class, containing the; target-specific selection logic proper. The instance is provided by the subtarget, so that it can specialize the; selector by subtarget feature (with, e.g., a vector selector overriding parts; of a general-purpose common selector).; We might also want to parameterize it by MachineFunction, to enable selector; variants based on function attributes like optsize. The simple API consists of:. .. code-block:: c++. virtual bool select(MachineInstr &MI). This target-provided method is responsible for mutating (or replacing) a; possibly-generic MI into a fully target-specific equivalent.; It is also responsible for doing the necessary constraining of gvregs into the; appropriate register classes as well as passing through COPY instructions to; the register allocator. The ``InstructionSelector`` can fold other instructions into the selected MI,; by walking the use-def chain of the vreg operands.; As GlobalISel is Global, this folding can occur across basic blocks. SelectionDAG Rule Imports; ^^^^^^^^^^^^^^^^^^^^^^^^^. TableGen will import SelectionDAG rules and provide the following function to; execute them:. .. code-block:: c++. bool selectImpl(MachineInstr &MI). The ``--stats`` option can be used to determine what proportion of rules were; successfully imported. The easiest way to use this is to copy the; ``-gen-globalisel`` tablegen command from ``ninja -v`` and modify it. Similarly, the ``--warn-on-skipped-patterns`` option can be used to obtain the; reasons that rules weren't imported. This can be used to focus on the most; important rejec",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/InstructionSelect.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/InstructionSelect.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/IRTranslator.rst:2756,Availability,redundant,redundant,2756,". Translating Function Calls; --------------------------. The ``IRTranslator`` also implements the ABI's calling convention by lowering; calls, returns, and arguments to the appropriate physical register usage and; instruction sequences. This is achieved using the ``CallLowering``; implementation,. .. _irtranslator-aggregates:. Aggregates; ^^^^^^^^^^. .. caution::. This has changed since it was written and is no longer accurate. It has not; been refreshed in this pass of improving the documentation as I haven't; worked much in this part of the codebase and it should have attention from; someone more knowledgeable about it. Aggregates are lowered into multiple virtual registers, similar to; SelectionDAG's multiple vregs via ``GetValueVTs``. ``TODO``:; As some of the bits are undef (padding), we should consider augmenting the; representation with additional metadata (in effect, caching computeKnownBits; information on vregs).; See `PR26161 <https://llvm.org/PR26161>`_: [GlobalISel] Value to vreg during; IR to MachineInstr translation for aggregate type. .. _irtranslator-constants:. Translation of Constants; ------------------------. Constant operands are translated as a use of a virtual register that is defined; by a ``G_CONSTANT`` or ``G_FCONSTANT`` instruction. These instructions are; placed in the entry block to allow them to be subject to the continuous CSE; implementation (``CSEMIRBuilder``). Their debug location information is removed; to prevent this from confusing debuggers. This is beneficial as it allows us to fold constants into immediate operands; during :ref:`instructionselect`, while still avoiding redundant materializations; for expensive non-foldable constants. However, this can lead to unnecessary; spills and reloads in an -O0 pipeline, as these virtual registers can have long; live ranges. This can be mitigated by running a `localizer <https://github.com/llvm/llvm-project/blob/main/llvm/lib/CodeGen/GlobalISel/Localizer.cpp>`_; after the translator.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/IRTranslator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/IRTranslator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/IRTranslator.rst:2485,Deployability,continuous,continuous,2485,". Translating Function Calls; --------------------------. The ``IRTranslator`` also implements the ABI's calling convention by lowering; calls, returns, and arguments to the appropriate physical register usage and; instruction sequences. This is achieved using the ``CallLowering``; implementation,. .. _irtranslator-aggregates:. Aggregates; ^^^^^^^^^^. .. caution::. This has changed since it was written and is no longer accurate. It has not; been refreshed in this pass of improving the documentation as I haven't; worked much in this part of the codebase and it should have attention from; someone more knowledgeable about it. Aggregates are lowered into multiple virtual registers, similar to; SelectionDAG's multiple vregs via ``GetValueVTs``. ``TODO``:; As some of the bits are undef (padding), we should consider augmenting the; representation with additional metadata (in effect, caching computeKnownBits; information on vregs).; See `PR26161 <https://llvm.org/PR26161>`_: [GlobalISel] Value to vreg during; IR to MachineInstr translation for aggregate type. .. _irtranslator-constants:. Translation of Constants; ------------------------. Constant operands are translated as a use of a virtual register that is defined; by a ``G_CONSTANT`` or ``G_FCONSTANT`` instruction. These instructions are; placed in the entry block to allow them to be subject to the continuous CSE; implementation (``CSEMIRBuilder``). Their debug location information is removed; to prevent this from confusing debuggers. This is beneficial as it allows us to fold constants into immediate operands; during :ref:`instructionselect`, while still avoiding redundant materializations; for expensive non-foldable constants. However, this can lead to unnecessary; spills and reloads in an -O0 pipeline, as these virtual registers can have long; live ranges. This can be mitigated by running a `localizer <https://github.com/llvm/llvm-project/blob/main/llvm/lib/CodeGen/GlobalISel/Localizer.cpp>`_; after the translator.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/IRTranslator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/IRTranslator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/IRTranslator.rst:2890,Deployability,pipeline,pipeline,2890,". Translating Function Calls; --------------------------. The ``IRTranslator`` also implements the ABI's calling convention by lowering; calls, returns, and arguments to the appropriate physical register usage and; instruction sequences. This is achieved using the ``CallLowering``; implementation,. .. _irtranslator-aggregates:. Aggregates; ^^^^^^^^^^. .. caution::. This has changed since it was written and is no longer accurate. It has not; been refreshed in this pass of improving the documentation as I haven't; worked much in this part of the codebase and it should have attention from; someone more knowledgeable about it. Aggregates are lowered into multiple virtual registers, similar to; SelectionDAG's multiple vregs via ``GetValueVTs``. ``TODO``:; As some of the bits are undef (padding), we should consider augmenting the; representation with additional metadata (in effect, caching computeKnownBits; information on vregs).; See `PR26161 <https://llvm.org/PR26161>`_: [GlobalISel] Value to vreg during; IR to MachineInstr translation for aggregate type. .. _irtranslator-constants:. Translation of Constants; ------------------------. Constant operands are translated as a use of a virtual register that is defined; by a ``G_CONSTANT`` or ``G_FCONSTANT`` instruction. These instructions are; placed in the entry block to allow them to be subject to the continuous CSE; implementation (``CSEMIRBuilder``). Their debug location information is removed; to prevent this from confusing debuggers. This is beneficial as it allows us to fold constants into immediate operands; during :ref:`instructionselect`, while still avoiding redundant materializations; for expensive non-foldable constants. However, this can lead to unnecessary; spills and reloads in an -O0 pipeline, as these virtual registers can have long; live ranges. This can be mitigated by running a `localizer <https://github.com/llvm/llvm-project/blob/main/llvm/lib/CodeGen/GlobalISel/Localizer.cpp>`_; after the translator.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/IRTranslator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/IRTranslator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/IRTranslator.rst:2747,Safety,avoid,avoiding,2747,". Translating Function Calls; --------------------------. The ``IRTranslator`` also implements the ABI's calling convention by lowering; calls, returns, and arguments to the appropriate physical register usage and; instruction sequences. This is achieved using the ``CallLowering``; implementation,. .. _irtranslator-aggregates:. Aggregates; ^^^^^^^^^^. .. caution::. This has changed since it was written and is no longer accurate. It has not; been refreshed in this pass of improving the documentation as I haven't; worked much in this part of the codebase and it should have attention from; someone more knowledgeable about it. Aggregates are lowered into multiple virtual registers, similar to; SelectionDAG's multiple vregs via ``GetValueVTs``. ``TODO``:; As some of the bits are undef (padding), we should consider augmenting the; representation with additional metadata (in effect, caching computeKnownBits; information on vregs).; See `PR26161 <https://llvm.org/PR26161>`_: [GlobalISel] Value to vreg during; IR to MachineInstr translation for aggregate type. .. _irtranslator-constants:. Translation of Constants; ------------------------. Constant operands are translated as a use of a virtual register that is defined; by a ``G_CONSTANT`` or ``G_FCONSTANT`` instruction. These instructions are; placed in the entry block to allow them to be subject to the continuous CSE; implementation (``CSEMIRBuilder``). Their debug location information is removed; to prevent this from confusing debuggers. This is beneficial as it allows us to fold constants into immediate operands; during :ref:`instructionselect`, while still avoiding redundant materializations; for expensive non-foldable constants. However, this can lead to unnecessary; spills and reloads in an -O0 pipeline, as these virtual registers can have long; live ranges. This can be mitigated by running a `localizer <https://github.com/llvm/llvm-project/blob/main/llvm/lib/CodeGen/GlobalISel/Localizer.cpp>`_; after the translator.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/IRTranslator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/IRTranslator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/IRTranslator.rst:2756,Safety,redund,redundant,2756,". Translating Function Calls; --------------------------. The ``IRTranslator`` also implements the ABI's calling convention by lowering; calls, returns, and arguments to the appropriate physical register usage and; instruction sequences. This is achieved using the ``CallLowering``; implementation,. .. _irtranslator-aggregates:. Aggregates; ^^^^^^^^^^. .. caution::. This has changed since it was written and is no longer accurate. It has not; been refreshed in this pass of improving the documentation as I haven't; worked much in this part of the codebase and it should have attention from; someone more knowledgeable about it. Aggregates are lowered into multiple virtual registers, similar to; SelectionDAG's multiple vregs via ``GetValueVTs``. ``TODO``:; As some of the bits are undef (padding), we should consider augmenting the; representation with additional metadata (in effect, caching computeKnownBits; information on vregs).; See `PR26161 <https://llvm.org/PR26161>`_: [GlobalISel] Value to vreg during; IR to MachineInstr translation for aggregate type. .. _irtranslator-constants:. Translation of Constants; ------------------------. Constant operands are translated as a use of a virtual register that is defined; by a ``G_CONSTANT`` or ``G_FCONSTANT`` instruction. These instructions are; placed in the entry block to allow them to be subject to the continuous CSE; implementation (``CSEMIRBuilder``). Their debug location information is removed; to prevent this from confusing debuggers. This is beneficial as it allows us to fold constants into immediate operands; during :ref:`instructionselect`, while still avoiding redundant materializations; for expensive non-foldable constants. However, this can lead to unnecessary; spills and reloads in an -O0 pipeline, as these virtual registers can have long; live ranges. This can be mitigated by running a `localizer <https://github.com/llvm/llvm-project/blob/main/llvm/lib/CodeGen/GlobalISel/Localizer.cpp>`_; after the translator.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/IRTranslator.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/IRTranslator.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/KnownBits.rst:121,Availability,avail,available,121,"Known Bits Analysis; ===================. The Known Bits Analysis pass makes information about the known values of bits; available to other passes to enable transformations like those in the examples; below. The information is lazily computed so you should only pay for what you; use. Examples; --------. A simple example is that transforming::. a + 1. into::. a | 1. is only valid when the addition doesn't carry. In other words it's only valid; if ``a & 1`` is zero. Another example is:. .. code-block:: none. %1:(s32) = G_CONSTANT i32 0xFF0; %2:(s32) = G_AND %0, %1; %3:(s32) = G_CONSTANT i32 0x0FF; %4:(s32) = G_AND %2, %3. We can use the constants and the definition of ``G_AND`` to determine the known; bits:. .. code-block:: none. ; %0 = 0x????????; %1:(s32) = G_CONSTANT i32 0xFF0 ; %1 = 0x00000FF0; %2:(s32) = G_AND %0, %1 ; %2 = 0x00000??0; %3:(s32) = G_CONSTANT i32 0x0FF ; %3 = 0x000000FF; %4:(s32) = G_AND %2, %3 ; %4 = 0x000000?0. and then use this to simplify the expression:. .. code-block:: none. ; %0 = 0x????????; %5:(s32) = G_CONSTANT i32 0x0F0 ; %5 = 0x00000FF0; %4:(s32) = G_AND %0, %5 ; %4 = 0x000000?0. Note that ``%4`` still has the same known bits as before the transformation.; Many transformations share this property. The main exception being when the; transform causes undefined bits to become defined to either zero, one, or; defined but unknown. Usage; -----. To use Known Bits Analysis in a pass, first include the header and register the; dependency with ``INITIALIZE_PASS_DEPENDENCY``. .. code-block:: c++. #include ""llvm/CodeGen/GlobalISel/GISelKnownBits.h"". ... INITIALIZE_PASS_BEGIN(...); INITIALIZE_PASS_DEPENDENCY(GISelKnownBitsAnalysis); INITIALIZE_PASS_END(...). and require the pass in ``getAnalysisUsage``. .. code-block:: c++. void MyPass::getAnalysisUsage(AnalysisUsage &AU) const {; AU.addRequired<GISelKnownBitsAnalysis>();; // Optional: If your pass preserves known bits analysis (many do) then; // indicate that it's preserved for re-use by another pa",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/KnownBits.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/KnownBits.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/KnownBits.rst:1473,Integrability,depend,dependency,1473," 1`` is zero. Another example is:. .. code-block:: none. %1:(s32) = G_CONSTANT i32 0xFF0; %2:(s32) = G_AND %0, %1; %3:(s32) = G_CONSTANT i32 0x0FF; %4:(s32) = G_AND %2, %3. We can use the constants and the definition of ``G_AND`` to determine the known; bits:. .. code-block:: none. ; %0 = 0x????????; %1:(s32) = G_CONSTANT i32 0xFF0 ; %1 = 0x00000FF0; %2:(s32) = G_AND %0, %1 ; %2 = 0x00000??0; %3:(s32) = G_CONSTANT i32 0x0FF ; %3 = 0x000000FF; %4:(s32) = G_AND %2, %3 ; %4 = 0x000000?0. and then use this to simplify the expression:. .. code-block:: none. ; %0 = 0x????????; %5:(s32) = G_CONSTANT i32 0x0F0 ; %5 = 0x00000FF0; %4:(s32) = G_AND %0, %5 ; %4 = 0x000000?0. Note that ``%4`` still has the same known bits as before the transformation.; Many transformations share this property. The main exception being when the; transform causes undefined bits to become defined to either zero, one, or; defined but unknown. Usage; -----. To use Known Bits Analysis in a pass, first include the header and register the; dependency with ``INITIALIZE_PASS_DEPENDENCY``. .. code-block:: c++. #include ""llvm/CodeGen/GlobalISel/GISelKnownBits.h"". ... INITIALIZE_PASS_BEGIN(...); INITIALIZE_PASS_DEPENDENCY(GISelKnownBitsAnalysis); INITIALIZE_PASS_END(...). and require the pass in ``getAnalysisUsage``. .. code-block:: c++. void MyPass::getAnalysisUsage(AnalysisUsage &AU) const {; AU.addRequired<GISelKnownBitsAnalysis>();; // Optional: If your pass preserves known bits analysis (many do) then; // indicate that it's preserved for re-use by another pass here.; AU.addPreserved<GISelKnownBitsAnalysis>();; }. Then it's just a matter of fetching the analysis and using it:. .. code-block:: c++. bool MyPass::runOnMachineFunction(MachineFunction &MF) {; ...; GISelKnownBits &KB = getAnalysis<GISelKnownBitsAnalysis>().get(MF);; ...; MachineInstr *MI = ...;; KnownBits Known = KB->getKnownBits(MI->getOperand(0).getReg());; if (Known.Zeros & 1) {; // Bit 0 is known to be zero; }; ...; }. There are many more A",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/KnownBits.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/KnownBits.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/KnownBits.rst:307,Usability,simpl,simple,307,"Known Bits Analysis; ===================. The Known Bits Analysis pass makes information about the known values of bits; available to other passes to enable transformations like those in the examples; below. The information is lazily computed so you should only pay for what you; use. Examples; --------. A simple example is that transforming::. a + 1. into::. a | 1. is only valid when the addition doesn't carry. In other words it's only valid; if ``a & 1`` is zero. Another example is:. .. code-block:: none. %1:(s32) = G_CONSTANT i32 0xFF0; %2:(s32) = G_AND %0, %1; %3:(s32) = G_CONSTANT i32 0x0FF; %4:(s32) = G_AND %2, %3. We can use the constants and the definition of ``G_AND`` to determine the known; bits:. .. code-block:: none. ; %0 = 0x????????; %1:(s32) = G_CONSTANT i32 0xFF0 ; %1 = 0x00000FF0; %2:(s32) = G_AND %0, %1 ; %2 = 0x00000??0; %3:(s32) = G_CONSTANT i32 0x0FF ; %3 = 0x000000FF; %4:(s32) = G_AND %2, %3 ; %4 = 0x000000?0. and then use this to simplify the expression:. .. code-block:: none. ; %0 = 0x????????; %5:(s32) = G_CONSTANT i32 0x0F0 ; %5 = 0x00000FF0; %4:(s32) = G_AND %0, %5 ; %4 = 0x000000?0. Note that ``%4`` still has the same known bits as before the transformation.; Many transformations share this property. The main exception being when the; transform causes undefined bits to become defined to either zero, one, or; defined but unknown. Usage; -----. To use Known Bits Analysis in a pass, first include the header and register the; dependency with ``INITIALIZE_PASS_DEPENDENCY``. .. code-block:: c++. #include ""llvm/CodeGen/GlobalISel/GISelKnownBits.h"". ... INITIALIZE_PASS_BEGIN(...); INITIALIZE_PASS_DEPENDENCY(GISelKnownBitsAnalysis); INITIALIZE_PASS_END(...). and require the pass in ``getAnalysisUsage``. .. code-block:: c++. void MyPass::getAnalysisUsage(AnalysisUsage &AU) const {; AU.addRequired<GISelKnownBitsAnalysis>();; // Optional: If your pass preserves known bits analysis (many do) then; // indicate that it's preserved for re-use by another pa",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/KnownBits.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/KnownBits.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/KnownBits.rst:966,Usability,simpl,simplify,966,"Known Bits Analysis; ===================. The Known Bits Analysis pass makes information about the known values of bits; available to other passes to enable transformations like those in the examples; below. The information is lazily computed so you should only pay for what you; use. Examples; --------. A simple example is that transforming::. a + 1. into::. a | 1. is only valid when the addition doesn't carry. In other words it's only valid; if ``a & 1`` is zero. Another example is:. .. code-block:: none. %1:(s32) = G_CONSTANT i32 0xFF0; %2:(s32) = G_AND %0, %1; %3:(s32) = G_CONSTANT i32 0x0FF; %4:(s32) = G_AND %2, %3. We can use the constants and the definition of ``G_AND`` to determine the known; bits:. .. code-block:: none. ; %0 = 0x????????; %1:(s32) = G_CONSTANT i32 0xFF0 ; %1 = 0x00000FF0; %2:(s32) = G_AND %0, %1 ; %2 = 0x00000??0; %3:(s32) = G_CONSTANT i32 0x0FF ; %3 = 0x000000FF; %4:(s32) = G_AND %2, %3 ; %4 = 0x000000?0. and then use this to simplify the expression:. .. code-block:: none. ; %0 = 0x????????; %5:(s32) = G_CONSTANT i32 0x0F0 ; %5 = 0x00000FF0; %4:(s32) = G_AND %0, %5 ; %4 = 0x000000?0. Note that ``%4`` still has the same known bits as before the transformation.; Many transformations share this property. The main exception being when the; transform causes undefined bits to become defined to either zero, one, or; defined but unknown. Usage; -----. To use Known Bits Analysis in a pass, first include the header and register the; dependency with ``INITIALIZE_PASS_DEPENDENCY``. .. code-block:: c++. #include ""llvm/CodeGen/GlobalISel/GISelKnownBits.h"". ... INITIALIZE_PASS_BEGIN(...); INITIALIZE_PASS_DEPENDENCY(GISelKnownBitsAnalysis); INITIALIZE_PASS_END(...). and require the pass in ``getAnalysisUsage``. .. code-block:: c++. void MyPass::getAnalysisUsage(AnalysisUsage &AU) const {; AU.addRequired<GISelKnownBitsAnalysis>();; // Optional: If your pass preserves known bits analysis (many do) then; // indicate that it's preserved for re-use by another pa",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/KnownBits.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/KnownBits.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst:2919,Availability,avail,available,2919," a ``G_CONSTANT`` with; value ``1``. However, the following::. %2:_(s32) = G_FOO %0:_(s32), i32 1. can say that it's legal iff operand 2 is an immediate with value ``1`` because; that information is entirely contained within the single instruction. .. _api-legalizerinfo:. API: LegalizerInfo; ^^^^^^^^^^^^^^^^^^. The recommended [#legalizer-legacy-footnote]_ API looks like this::. getActionDefinitionsBuilder({G_ADD, G_SUB, G_MUL, G_AND, G_OR, G_XOR, G_SHL}); .legalFor({s32, s64, v2s32, v4s32, v2s64}); .clampScalar(0, s32, s64); .widenScalarToNextPow2(0); .clampNumElements(0, v2s32, v4s32); .clampNumElements(0, v2s64, v2s64); .moreElementsToNextPow2(0);. and describes a set of rules by which we can either declare an instruction legal; or decide which action to take to make it more legal. At the core of this ruleset is the ``LegalityQuery`` which describes the; instruction. We use a description rather than the instruction to both allow other; passes to determine legality without having to create an instruction and also to; limit the information available to the predicates to that which is safe to rely; on. Currently, the information available to the predicates that determine; legality contains:. * The opcode for the instruction. * The type of each type index (see ``type0``, ``type1``, etc.). * The size in bytes and atomic ordering for each MachineMemOperand. .. note::. An alternative worth investigating is to generalize the API to represent; actions using ``std::function`` that implements the action, instead of explicit; enum tokens (``Legal``, ``WidenScalar``, ...) that instruct it to call a; function. This would have some benefits, most notable being that Custom could; be removed. .. rubric:: Footnotes. .. [#legalizer-legacy-footnote] An API is broadly similar to; SelectionDAG/TargetLowering is available but is not recommended as a more; powerful API is available. Rule Processing and Declaring Rules; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""". The ``getActionDefinitionsBuilde",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst:3009,Availability,avail,available,3009,"``1`` because; that information is entirely contained within the single instruction. .. _api-legalizerinfo:. API: LegalizerInfo; ^^^^^^^^^^^^^^^^^^. The recommended [#legalizer-legacy-footnote]_ API looks like this::. getActionDefinitionsBuilder({G_ADD, G_SUB, G_MUL, G_AND, G_OR, G_XOR, G_SHL}); .legalFor({s32, s64, v2s32, v4s32, v2s64}); .clampScalar(0, s32, s64); .widenScalarToNextPow2(0); .clampNumElements(0, v2s32, v4s32); .clampNumElements(0, v2s64, v2s64); .moreElementsToNextPow2(0);. and describes a set of rules by which we can either declare an instruction legal; or decide which action to take to make it more legal. At the core of this ruleset is the ``LegalityQuery`` which describes the; instruction. We use a description rather than the instruction to both allow other; passes to determine legality without having to create an instruction and also to; limit the information available to the predicates to that which is safe to rely; on. Currently, the information available to the predicates that determine; legality contains:. * The opcode for the instruction. * The type of each type index (see ``type0``, ``type1``, etc.). * The size in bytes and atomic ordering for each MachineMemOperand. .. note::. An alternative worth investigating is to generalize the API to represent; actions using ``std::function`` that implements the action, instead of explicit; enum tokens (``Legal``, ``WidenScalar``, ...) that instruct it to call a; function. This would have some benefits, most notable being that Custom could; be removed. .. rubric:: Footnotes. .. [#legalizer-legacy-footnote] An API is broadly similar to; SelectionDAG/TargetLowering is available but is not recommended as a more; powerful API is available. Rule Processing and Declaring Rules; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""". The ``getActionDefinitionsBuilder`` function generates a ruleset for the given; opcode(s) that rules can be added to. If multiple opcodes are given, they are; all permanently bound to the same rul",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst:3686,Availability,avail,available,3686,"is ruleset is the ``LegalityQuery`` which describes the; instruction. We use a description rather than the instruction to both allow other; passes to determine legality without having to create an instruction and also to; limit the information available to the predicates to that which is safe to rely; on. Currently, the information available to the predicates that determine; legality contains:. * The opcode for the instruction. * The type of each type index (see ``type0``, ``type1``, etc.). * The size in bytes and atomic ordering for each MachineMemOperand. .. note::. An alternative worth investigating is to generalize the API to represent; actions using ``std::function`` that implements the action, instead of explicit; enum tokens (``Legal``, ``WidenScalar``, ...) that instruct it to call a; function. This would have some benefits, most notable being that Custom could; be removed. .. rubric:: Footnotes. .. [#legalizer-legacy-footnote] An API is broadly similar to; SelectionDAG/TargetLowering is available but is not recommended as a more; powerful API is available. Rule Processing and Declaring Rules; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""". The ``getActionDefinitionsBuilder`` function generates a ruleset for the given; opcode(s) that rules can be added to. If multiple opcodes are given, they are; all permanently bound to the same ruleset. The rules in a ruleset are executed; from top to bottom and will start again from the top if an instruction is; legalized as a result of the rules. If the ruleset is exhausted without; satisfying any rule, then it is considered unsupported. When it doesn't declare the instruction legal, each pass over the rules may; request that one type changes to another type. Sometimes this can cause multiple; types to change but we avoid this as much as possible as making multiple changes; can make it difficult to avoid infinite loops where, for example, narrowing one; type causes another to be too small and widening that type causes the first one;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst:3746,Availability,avail,available,3746,"is ruleset is the ``LegalityQuery`` which describes the; instruction. We use a description rather than the instruction to both allow other; passes to determine legality without having to create an instruction and also to; limit the information available to the predicates to that which is safe to rely; on. Currently, the information available to the predicates that determine; legality contains:. * The opcode for the instruction. * The type of each type index (see ``type0``, ``type1``, etc.). * The size in bytes and atomic ordering for each MachineMemOperand. .. note::. An alternative worth investigating is to generalize the API to represent; actions using ``std::function`` that implements the action, instead of explicit; enum tokens (``Legal``, ``WidenScalar``, ...) that instruct it to call a; function. This would have some benefits, most notable being that Custom could; be removed. .. rubric:: Footnotes. .. [#legalizer-legacy-footnote] An API is broadly similar to; SelectionDAG/TargetLowering is available but is not recommended as a more; powerful API is available. Rule Processing and Declaring Rules; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""". The ``getActionDefinitionsBuilder`` function generates a ruleset for the given; opcode(s) that rules can be added to. If multiple opcodes are given, they are; all permanently bound to the same ruleset. The rules in a ruleset are executed; from top to bottom and will start again from the top if an instruction is; legalized as a result of the rules. If the ruleset is exhausted without; satisfying any rule, then it is considered unsupported. When it doesn't declare the instruction legal, each pass over the rules may; request that one type changes to another type. Sometimes this can cause multiple; types to change but we avoid this as much as possible as making multiple changes; can make it difficult to avoid infinite loops where, for example, narrowing one; type causes another to be too small and widening that type causes the first one;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst:9117,Availability,avail,available,9117,"al. * ``unsupportedIf()``, ``unsupportedFor()``, etc. declare an instruction to be illegal; if the predicate is satisfied and indicates that there is no way to make it; legal and the compiler should fail. * ``fallback()`` falls back on an older API and should only be used while porting; existing code from that API. Rule Predicates; """""""""""""""""""""""""""""". The rule factories also have predicates in common:. * ``legal()``, ``lower()``, etc. are always satisfied. * ``legalIf()``, ``narrowScalarIf()``, etc. are satisfied if the user-supplied; ``LegalityPredicate`` function returns true. This predicate has access to the; information in the ``LegalityQuery`` to make its decision.; User-supplied predicates can also be combined using ``all(P0, P1, ...)``. * ``legalFor()``, ``narrowScalarFor()``, etc. are satisfied if the type matches one in; a given set of types. For example ``.legalFor({s16, s32})`` declares the; instruction legal if type 0 is either s16 or s32. Additional versions for two; and three type indices are generally available. For these, all the type; indices considered together must match all the types in one of the tuples. So; ``.legalFor({{s16, s32}, {s32, s64}})`` will only accept ``{s16, s32}``, or; ``{s32, s64}`` but will not accept ``{s16, s64}``. * ``legalForTypesWithMemSize()``, ``narrowScalarForTypesWithMemSize()``, etc. are; similar to ``legalFor()``, ``narrowScalarFor()``, etc. but additionally require a; MachineMemOperand to have a given size in each tuple. * ``legalForCartesianProduct()``, ``narrowScalarForCartesianProduct()``, etc. are; satisfied if each type index matches one element in each of the independent; sets. So ``.legalForCartesianProduct({s16, s32}, {s32, s64})`` will accept; ``{s16, s32}``, ``{s16, s64}``, ``{s32, s32}``, and ``{s32, s64}``. Composite Rules; """""""""""""""""""""""""""""". There are some composite rules for common situations built out of the above facilities:. * ``widenScalarToNextPow2()`` is like ``widenScalarIf()`` but is satisfied iff the",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst:3730,Energy Efficiency,power,powerful,3730,"is ruleset is the ``LegalityQuery`` which describes the; instruction. We use a description rather than the instruction to both allow other; passes to determine legality without having to create an instruction and also to; limit the information available to the predicates to that which is safe to rely; on. Currently, the information available to the predicates that determine; legality contains:. * The opcode for the instruction. * The type of each type index (see ``type0``, ``type1``, etc.). * The size in bytes and atomic ordering for each MachineMemOperand. .. note::. An alternative worth investigating is to generalize the API to represent; actions using ``std::function`` that implements the action, instead of explicit; enum tokens (``Legal``, ``WidenScalar``, ...) that instruct it to call a; function. This would have some benefits, most notable being that Custom could; be removed. .. rubric:: Footnotes. .. [#legalizer-legacy-footnote] An API is broadly similar to; SelectionDAG/TargetLowering is available but is not recommended as a more; powerful API is available. Rule Processing and Declaring Rules; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""". The ``getActionDefinitionsBuilder`` function generates a ruleset for the given; opcode(s) that rules can be added to. If multiple opcodes are given, they are; all permanently bound to the same ruleset. The rules in a ruleset are executed; from top to bottom and will start again from the top if an instruction is; legalized as a result of the rules. If the ruleset is exhausted without; satisfying any rule, then it is considered unsupported. When it doesn't declare the instruction legal, each pass over the rules may; request that one type changes to another type. Sometimes this can cause multiple; types to change but we avoid this as much as possible as making multiple changes; can make it difficult to avoid infinite loops where, for example, narrowing one; type causes another to be too small and widening that type causes the first one;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst:5905,Energy Efficiency,schedul,scheduled,5905,"ity happens more often than; legalization and legalization can require multiple passes over the rules. As a concrete example, consider the rule::. getActionDefinitionsBuilder({G_ADD, G_SUB, G_MUL, G_AND, G_OR, G_XOR, G_SHL}); .legalFor({s32, s64, v2s32, v4s32, v2s64}); .clampScalar(0, s32, s64); .widenScalarToNextPow2(0);. and the instruction::. %2:_(s7) = G_ADD %0:_(s7), %1:_(s7). this doesn't meet the predicate for the :ref:`.legalFor() <legalfor>` as ``s7``; is not one of the listed types so it falls through to the; :ref:`.clampScalar() <clampscalar>`. It does meet the predicate for this rule; as the type is smaller than the ``s32`` and this rule instructs the legalizer; to change type 0 to ``s32``. It then restarts from the top. This time it does; satisfy ``.legalFor()`` and the resulting output is::. %3:_(s32) = G_ANYEXT %0:_(s7); %4:_(s32) = G_ANYEXT %1:_(s7); %5:_(s32) = G_ADD %3:_(s32), %4:_(s32); %2:_(s7) = G_TRUNC %5:_(s32). where the ``G_ADD`` is legal and the other instructions are scheduled for; processing by the legalizer. Rule Actions; """""""""""""""""""""""". There are various rule factories that append rules to a ruleset but they have a; few actions in common:. .. _legalfor:. * ``legalIf()``, ``legalFor()``, etc. declare an instruction to be legal if the; predicate is satisfied. * ``narrowScalarIf()``, ``narrowScalarFor()``, etc. declare an instruction to be illegal; if the predicate is satisfied and indicates that narrowing the scalars in one; of the types to a specific type would make it more legal. This action supports; both scalars and vectors. * ``widenScalarIf()``, ``widenScalarFor()``, etc. declare an instruction to be illegal; if the predicate is satisfied and indicates that widening the scalars in one; of the types to a specific type would make it more legal. This action supports; both scalars and vectors. * ``fewerElementsIf()``, ``fewerElementsFor()``, etc. declare an instruction to be; illegal if the predicate is satisfied and indicates reducing th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst:10118,Energy Efficiency,power,power,10118,"ces are generally available. For these, all the type; indices considered together must match all the types in one of the tuples. So; ``.legalFor({{s16, s32}, {s32, s64}})`` will only accept ``{s16, s32}``, or; ``{s32, s64}`` but will not accept ``{s16, s64}``. * ``legalForTypesWithMemSize()``, ``narrowScalarForTypesWithMemSize()``, etc. are; similar to ``legalFor()``, ``narrowScalarFor()``, etc. but additionally require a; MachineMemOperand to have a given size in each tuple. * ``legalForCartesianProduct()``, ``narrowScalarForCartesianProduct()``, etc. are; satisfied if each type index matches one element in each of the independent; sets. So ``.legalForCartesianProduct({s16, s32}, {s32, s64})`` will accept; ``{s16, s32}``, ``{s16, s64}``, ``{s32, s32}``, and ``{s32, s64}``. Composite Rules; """""""""""""""""""""""""""""". There are some composite rules for common situations built out of the above facilities:. * ``widenScalarToNextPow2()`` is like ``widenScalarIf()`` but is satisfied iff the type; size in bits is not a power of 2 and selects a target type that is the next; largest power of 2. .. _clampscalar:. * ``minScalar()`` is like ``widenScalarIf()`` but is satisfied iff the type; size in bits is smaller than the given minimum and selects the minimum as the; target type. Similarly, there is also a ``maxScalar()`` for the maximum and a; ``clampScalar()`` to do both at once. * ``minScalarSameAs()`` is like ``minScalar()`` but the minimum is taken from another; type index. * ``moreElementsToNextMultiple()`` is like ``moreElementsToNextPow2()`` but is based on; multiples of X rather than powers of 2. .. _min-legalizerinfo:. Minimum Rule Set; ^^^^^^^^^^^^^^^^. GlobalISel's legalizer has a great deal of flexibility in how a given target; shapes the GMIR that the rest of the backend must handle. However, there are; a small number of requirements that all targets must meet. Before discussing the minimum requirements, we'll need some terminology:. Producer Type Set; The set of types wh",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst:10181,Energy Efficiency,power,power,10181,"ces are generally available. For these, all the type; indices considered together must match all the types in one of the tuples. So; ``.legalFor({{s16, s32}, {s32, s64}})`` will only accept ``{s16, s32}``, or; ``{s32, s64}`` but will not accept ``{s16, s64}``. * ``legalForTypesWithMemSize()``, ``narrowScalarForTypesWithMemSize()``, etc. are; similar to ``legalFor()``, ``narrowScalarFor()``, etc. but additionally require a; MachineMemOperand to have a given size in each tuple. * ``legalForCartesianProduct()``, ``narrowScalarForCartesianProduct()``, etc. are; satisfied if each type index matches one element in each of the independent; sets. So ``.legalForCartesianProduct({s16, s32}, {s32, s64})`` will accept; ``{s16, s32}``, ``{s16, s64}``, ``{s32, s32}``, and ``{s32, s64}``. Composite Rules; """""""""""""""""""""""""""""". There are some composite rules for common situations built out of the above facilities:. * ``widenScalarToNextPow2()`` is like ``widenScalarIf()`` but is satisfied iff the type; size in bits is not a power of 2 and selects a target type that is the next; largest power of 2. .. _clampscalar:. * ``minScalar()`` is like ``widenScalarIf()`` but is satisfied iff the type; size in bits is smaller than the given minimum and selects the minimum as the; target type. Similarly, there is also a ``maxScalar()`` for the maximum and a; ``clampScalar()`` to do both at once. * ``minScalarSameAs()`` is like ``minScalar()`` but the minimum is taken from another; type index. * ``moreElementsToNextMultiple()`` is like ``moreElementsToNextPow2()`` but is based on; multiples of X rather than powers of 2. .. _min-legalizerinfo:. Minimum Rule Set; ^^^^^^^^^^^^^^^^. GlobalISel's legalizer has a great deal of flexibility in how a given target; shapes the GMIR that the rest of the backend must handle. However, there are; a small number of requirements that all targets must meet. Before discussing the minimum requirements, we'll need some terminology:. Producer Type Set; The set of types wh",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst:10699,Energy Efficiency,power,powers,10699,"t()``, etc. are; satisfied if each type index matches one element in each of the independent; sets. So ``.legalForCartesianProduct({s16, s32}, {s32, s64})`` will accept; ``{s16, s32}``, ``{s16, s64}``, ``{s32, s32}``, and ``{s32, s64}``. Composite Rules; """""""""""""""""""""""""""""". There are some composite rules for common situations built out of the above facilities:. * ``widenScalarToNextPow2()`` is like ``widenScalarIf()`` but is satisfied iff the type; size in bits is not a power of 2 and selects a target type that is the next; largest power of 2. .. _clampscalar:. * ``minScalar()`` is like ``widenScalarIf()`` but is satisfied iff the type; size in bits is smaller than the given minimum and selects the minimum as the; target type. Similarly, there is also a ``maxScalar()`` for the maximum and a; ``clampScalar()`` to do both at once. * ``minScalarSameAs()`` is like ``minScalar()`` but the minimum is taken from another; type index. * ``moreElementsToNextMultiple()`` is like ``moreElementsToNextPow2()`` but is based on; multiples of X rather than powers of 2. .. _min-legalizerinfo:. Minimum Rule Set; ^^^^^^^^^^^^^^^^. GlobalISel's legalizer has a great deal of flexibility in how a given target; shapes the GMIR that the rest of the backend must handle. However, there are; a small number of requirements that all targets must meet. Before discussing the minimum requirements, we'll need some terminology:. Producer Type Set; The set of types which is the union of all possible types produced by at; least one legal instruction. Consumer Type Set; The set of types which is the union of all possible types consumed by at; least one legal instruction. Both sets are often identical but there's no guarantee of that. For example,; it's not uncommon to be unable to consume s64 but still be able to produce it; for a few specific instructions. Minimum Rules For Scalars; """""""""""""""""""""""""""""""""""""""""""""""""". * G_ANYEXT must be legal for all inputs from the producer type set and all larger; outputs from th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst:1418,Integrability,depend,depend,1418,"nd stored** -- if necessary, the; target can select a ``G_LOAD``/``G_STORE`` of each gvreg operand. As opposed to SelectionDAG, there are no legalization phases. In particular,; 'type' and 'operation' legalization are not separate. Legalization is iterative, and all state is contained in GMIR. To maintain the; validity of the intermediate code, instructions are introduced:. * ``G_MERGE_VALUES`` --- concatenate multiple registers of the same; size into a single wider register. * ``G_UNMERGE_VALUES`` --- extract multiple registers of the same size; from a single wider register. * ``G_EXTRACT`` --- extract a simple register (as contiguous sequences of bits); from a single wider register. As they are expected to be temporary byproducts of the legalization process,; they are combined at the end of the :ref:`milegalizer` pass.; If any remain, they are expected to always be selectable, using loads and stores; if necessary. The legality of an instruction may only depend on the instruction itself and; must not depend on any context in which the instruction is used. However, after; deciding that an instruction is not legal, using the context of the instruction; to decide how to legalize the instruction is permitted. As an example, if we; have a ``G_FOO`` instruction of the form::. %1:_(s32) = G_CONSTANT i32 1; %2:_(s32) = G_FOO %0:_(s32), %1:_(s32). it's impossible to say that G_FOO is legal iff %1 is a ``G_CONSTANT`` with; value ``1``. However, the following::. %2:_(s32) = G_FOO %0:_(s32), i32 1. can say that it's legal iff operand 2 is an immediate with value ``1`` because; that information is entirely contained within the single instruction. .. _api-legalizerinfo:. API: LegalizerInfo; ^^^^^^^^^^^^^^^^^^. The recommended [#legalizer-legacy-footnote]_ API looks like this::. getActionDefinitionsBuilder({G_ADD, G_SUB, G_MUL, G_AND, G_OR, G_XOR, G_SHL}); .legalFor({s32, s64, v2s32, v4s32, v2s64}); .clampScalar(0, s32, s64); .widenScalarToNextPow2(0); .clampNumElements(0, v2s32, ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst:1465,Integrability,depend,depend,1465,"nd stored** -- if necessary, the; target can select a ``G_LOAD``/``G_STORE`` of each gvreg operand. As opposed to SelectionDAG, there are no legalization phases. In particular,; 'type' and 'operation' legalization are not separate. Legalization is iterative, and all state is contained in GMIR. To maintain the; validity of the intermediate code, instructions are introduced:. * ``G_MERGE_VALUES`` --- concatenate multiple registers of the same; size into a single wider register. * ``G_UNMERGE_VALUES`` --- extract multiple registers of the same size; from a single wider register. * ``G_EXTRACT`` --- extract a simple register (as contiguous sequences of bits); from a single wider register. As they are expected to be temporary byproducts of the legalization process,; they are combined at the end of the :ref:`milegalizer` pass.; If any remain, they are expected to always be selectable, using loads and stores; if necessary. The legality of an instruction may only depend on the instruction itself and; must not depend on any context in which the instruction is used. However, after; deciding that an instruction is not legal, using the context of the instruction; to decide how to legalize the instruction is permitted. As an example, if we; have a ``G_FOO`` instruction of the form::. %1:_(s32) = G_CONSTANT i32 1; %2:_(s32) = G_FOO %0:_(s32), %1:_(s32). it's impossible to say that G_FOO is legal iff %1 is a ``G_CONSTANT`` with; value ``1``. However, the following::. %2:_(s32) = G_FOO %0:_(s32), i32 1. can say that it's legal iff operand 2 is an immediate with value ``1`` because; that information is entirely contained within the single instruction. .. _api-legalizerinfo:. API: LegalizerInfo; ^^^^^^^^^^^^^^^^^^. The recommended [#legalizer-legacy-footnote]_ API looks like this::. getActionDefinitionsBuilder({G_ADD, G_SUB, G_MUL, G_AND, G_OR, G_XOR, G_SHL}); .legalFor({s32, s64, v2s32, v4s32, v2s64}); .clampScalar(0, s32, s64); .widenScalarToNextPow2(0); .clampNumElements(0, v2s32, ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst:440,Performance,load,loaded,440,".. _milegalizer:. Legalizer; ---------. This pass transforms the generic machine instructions such that they are legal. A legal instruction is defined as:. * **selectable** --- the target will later be able to select it to a; target-specific (non-generic) instruction. This doesn't necessarily mean that; :doc:`InstructionSelect` has to handle it though. It just means that; **something** must handle it. * operating on **vregs that can be loaded and stored** -- if necessary, the; target can select a ``G_LOAD``/``G_STORE`` of each gvreg operand. As opposed to SelectionDAG, there are no legalization phases. In particular,; 'type' and 'operation' legalization are not separate. Legalization is iterative, and all state is contained in GMIR. To maintain the; validity of the intermediate code, instructions are introduced:. * ``G_MERGE_VALUES`` --- concatenate multiple registers of the same; size into a single wider register. * ``G_UNMERGE_VALUES`` --- extract multiple registers of the same size; from a single wider register. * ``G_EXTRACT`` --- extract a simple register (as contiguous sequences of bits); from a single wider register. As they are expected to be temporary byproducts of the legalization process,; they are combined at the end of the :ref:`milegalizer` pass.; If any remain, they are expected to always be selectable, using loads and stores; if necessary. The legality of an instruction may only depend on the instruction itself and; must not depend on any context in which the instruction is used. However, after; deciding that an instruction is not legal, using the context of the instruction; to decide how to legalize the instruction is permitted. As an example, if we; have a ``G_FOO`` instruction of the form::. %1:_(s32) = G_CONSTANT i32 1; %2:_(s32) = G_FOO %0:_(s32), %1:_(s32). it's impossible to say that G_FOO is legal iff %1 is a ``G_CONSTANT`` with; value ``1``. However, the following::. %2:_(s32) = G_FOO %0:_(s32), i32 1. can say that it's legal iff operand 2 is",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst:1346,Performance,load,loads,1346,"` has to handle it though. It just means that; **something** must handle it. * operating on **vregs that can be loaded and stored** -- if necessary, the; target can select a ``G_LOAD``/``G_STORE`` of each gvreg operand. As opposed to SelectionDAG, there are no legalization phases. In particular,; 'type' and 'operation' legalization are not separate. Legalization is iterative, and all state is contained in GMIR. To maintain the; validity of the intermediate code, instructions are introduced:. * ``G_MERGE_VALUES`` --- concatenate multiple registers of the same; size into a single wider register. * ``G_UNMERGE_VALUES`` --- extract multiple registers of the same size; from a single wider register. * ``G_EXTRACT`` --- extract a simple register (as contiguous sequences of bits); from a single wider register. As they are expected to be temporary byproducts of the legalization process,; they are combined at the end of the :ref:`milegalizer` pass.; If any remain, they are expected to always be selectable, using loads and stores; if necessary. The legality of an instruction may only depend on the instruction itself and; must not depend on any context in which the instruction is used. However, after; deciding that an instruction is not legal, using the context of the instruction; to decide how to legalize the instruction is permitted. As an example, if we; have a ``G_FOO`` instruction of the form::. %1:_(s32) = G_CONSTANT i32 1; %2:_(s32) = G_FOO %0:_(s32), %1:_(s32). it's impossible to say that G_FOO is legal iff %1 is a ``G_CONSTANT`` with; value ``1``. However, the following::. %2:_(s32) = G_FOO %0:_(s32), i32 1. can say that it's legal iff operand 2 is an immediate with value ``1`` because; that information is entirely contained within the single instruction. .. _api-legalizerinfo:. API: LegalizerInfo; ^^^^^^^^^^^^^^^^^^. The recommended [#legalizer-legacy-footnote]_ API looks like this::. getActionDefinitionsBuilder({G_ADD, G_SUB, G_MUL, G_AND, G_OR, G_XOR, G_SHL}); .legal",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst:4864,Performance,perform,performance,4864,"hat rules can be added to. If multiple opcodes are given, they are; all permanently bound to the same ruleset. The rules in a ruleset are executed; from top to bottom and will start again from the top if an instruction is; legalized as a result of the rules. If the ruleset is exhausted without; satisfying any rule, then it is considered unsupported. When it doesn't declare the instruction legal, each pass over the rules may; request that one type changes to another type. Sometimes this can cause multiple; types to change but we avoid this as much as possible as making multiple changes; can make it difficult to avoid infinite loops where, for example, narrowing one; type causes another to be too small and widening that type causes the first one; to be too big. In general, it's advisable to declare instructions legal as close to the top of; the rule as possible and to place any expensive rules as low as possible. This; helps with performance as testing for legality happens more often than; legalization and legalization can require multiple passes over the rules. As a concrete example, consider the rule::. getActionDefinitionsBuilder({G_ADD, G_SUB, G_MUL, G_AND, G_OR, G_XOR, G_SHL}); .legalFor({s32, s64, v2s32, v4s32, v2s64}); .clampScalar(0, s32, s64); .widenScalarToNextPow2(0);. and the instruction::. %2:_(s7) = G_ADD %0:_(s7), %1:_(s7). this doesn't meet the predicate for the :ref:`.legalFor() <legalfor>` as ``s7``; is not one of the listed types so it falls through to the; :ref:`.clampScalar() <clampscalar>`. It does meet the predicate for this rule; as the type is smaller than the ``s32`` and this rule instructs the legalizer; to change type 0 to ``s32``. It then restarts from the top. This time it does; satisfy ``.legalFor()`` and the resulting output is::. %3:_(s32) = G_ANYEXT %0:_(s7); %4:_(s32) = G_ANYEXT %1:_(s7); %5:_(s32) = G_ADD %3:_(s32), %4:_(s32); %2:_(s7) = G_TRUNC %5:_(s32). where the ``G_ADD`` is legal and the other instructions are scheduled for; pr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst:7619,Performance,perform,perform,7619,"ndicates that widening the scalars in one; of the types to a specific type would make it more legal. This action supports; both scalars and vectors. * ``fewerElementsIf()``, ``fewerElementsFor()``, etc. declare an instruction to be; illegal if the predicate is satisfied and indicates reducing the number of; vector elements in one of the types to a specific type would make it more; legal. This action supports vectors. * ``moreElementsIf()``, ``moreElementsFor()``, etc. declare an instruction to be illegal; if the predicate is satisfied and indicates increasing the number of vector; elements in one of the types to a specific type would make it more legal.; This action supports vectors. * ``lowerIf()``, ``lowerFor()``, etc. declare an instruction to be; illegal if the predicate is satisfied and indicates that replacing; it with equivalent instruction(s) would make it more legal. Support; for this action differs for each opcode. These may provide an; optional LegalizeMutation containing a type to attempt to perform; the expansion in a different type. * ``libcallIf()``, ``libcallFor()``, etc. declare an instruction to be illegal if the; predicate is satisfied and indicates that replacing it with a libcall would; make it more legal. Support for this action differs for; each opcode. * ``customIf()``, ``customFor()``, etc. declare an instruction to be illegal if the; predicate is satisfied and indicates that the backend developer will supply; a means of making it more legal. * ``unsupportedIf()``, ``unsupportedFor()``, etc. declare an instruction to be illegal; if the predicate is satisfied and indicates that there is no way to make it; legal and the compiler should fail. * ``fallback()`` falls back on an older API and should only be used while porting; existing code from that API. Rule Predicates; """""""""""""""""""""""""""""". The rule factories also have predicates in common:. * ``legal()``, ``lower()``, etc. are always satisfied. * ``legalIf()``, ``narrowScalarIf()``, etc. are satisf",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst:2964,Safety,safe,safe,2964," a ``G_CONSTANT`` with; value ``1``. However, the following::. %2:_(s32) = G_FOO %0:_(s32), i32 1. can say that it's legal iff operand 2 is an immediate with value ``1`` because; that information is entirely contained within the single instruction. .. _api-legalizerinfo:. API: LegalizerInfo; ^^^^^^^^^^^^^^^^^^. The recommended [#legalizer-legacy-footnote]_ API looks like this::. getActionDefinitionsBuilder({G_ADD, G_SUB, G_MUL, G_AND, G_OR, G_XOR, G_SHL}); .legalFor({s32, s64, v2s32, v4s32, v2s64}); .clampScalar(0, s32, s64); .widenScalarToNextPow2(0); .clampNumElements(0, v2s32, v4s32); .clampNumElements(0, v2s64, v2s64); .moreElementsToNextPow2(0);. and describes a set of rules by which we can either declare an instruction legal; or decide which action to take to make it more legal. At the core of this ruleset is the ``LegalityQuery`` which describes the; instruction. We use a description rather than the instruction to both allow other; passes to determine legality without having to create an instruction and also to; limit the information available to the predicates to that which is safe to rely; on. Currently, the information available to the predicates that determine; legality contains:. * The opcode for the instruction. * The type of each type index (see ``type0``, ``type1``, etc.). * The size in bytes and atomic ordering for each MachineMemOperand. .. note::. An alternative worth investigating is to generalize the API to represent; actions using ``std::function`` that implements the action, instead of explicit; enum tokens (``Legal``, ``WidenScalar``, ...) that instruct it to call a; function. This would have some benefits, most notable being that Custom could; be removed. .. rubric:: Footnotes. .. [#legalizer-legacy-footnote] An API is broadly similar to; SelectionDAG/TargetLowering is available but is not recommended as a more; powerful API is available. Rule Processing and Declaring Rules; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""". The ``getActionDefinitionsBuilde",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst:4456,Safety,avoid,avoid,4456,"Custom could; be removed. .. rubric:: Footnotes. .. [#legalizer-legacy-footnote] An API is broadly similar to; SelectionDAG/TargetLowering is available but is not recommended as a more; powerful API is available. Rule Processing and Declaring Rules; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""". The ``getActionDefinitionsBuilder`` function generates a ruleset for the given; opcode(s) that rules can be added to. If multiple opcodes are given, they are; all permanently bound to the same ruleset. The rules in a ruleset are executed; from top to bottom and will start again from the top if an instruction is; legalized as a result of the rules. If the ruleset is exhausted without; satisfying any rule, then it is considered unsupported. When it doesn't declare the instruction legal, each pass over the rules may; request that one type changes to another type. Sometimes this can cause multiple; types to change but we avoid this as much as possible as making multiple changes; can make it difficult to avoid infinite loops where, for example, narrowing one; type causes another to be too small and widening that type causes the first one; to be too big. In general, it's advisable to declare instructions legal as close to the top of; the rule as possible and to place any expensive rules as low as possible. This; helps with performance as testing for legality happens more often than; legalization and legalization can require multiple passes over the rules. As a concrete example, consider the rule::. getActionDefinitionsBuilder({G_ADD, G_SUB, G_MUL, G_AND, G_OR, G_XOR, G_SHL}); .legalFor({s32, s64, v2s32, v4s32, v2s64}); .clampScalar(0, s32, s64); .widenScalarToNextPow2(0);. and the instruction::. %2:_(s7) = G_ADD %0:_(s7), %1:_(s7). this doesn't meet the predicate for the :ref:`.legalFor() <legalfor>` as ``s7``; is not one of the listed types so it falls through to the; :ref:`.clampScalar() <clampscalar>`. It does meet the predicate for this rule; as the type is smaller than the ``s32`` and ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst:4540,Safety,avoid,avoid,4540,"Custom could; be removed. .. rubric:: Footnotes. .. [#legalizer-legacy-footnote] An API is broadly similar to; SelectionDAG/TargetLowering is available but is not recommended as a more; powerful API is available. Rule Processing and Declaring Rules; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""". The ``getActionDefinitionsBuilder`` function generates a ruleset for the given; opcode(s) that rules can be added to. If multiple opcodes are given, they are; all permanently bound to the same ruleset. The rules in a ruleset are executed; from top to bottom and will start again from the top if an instruction is; legalized as a result of the rules. If the ruleset is exhausted without; satisfying any rule, then it is considered unsupported. When it doesn't declare the instruction legal, each pass over the rules may; request that one type changes to another type. Sometimes this can cause multiple; types to change but we avoid this as much as possible as making multiple changes; can make it difficult to avoid infinite loops where, for example, narrowing one; type causes another to be too small and widening that type causes the first one; to be too big. In general, it's advisable to declare instructions legal as close to the top of; the rule as possible and to place any expensive rules as low as possible. This; helps with performance as testing for legality happens more often than; legalization and legalization can require multiple passes over the rules. As a concrete example, consider the rule::. getActionDefinitionsBuilder({G_ADD, G_SUB, G_MUL, G_AND, G_OR, G_XOR, G_SHL}); .legalFor({s32, s64, v2s32, v4s32, v2s64}); .clampScalar(0, s32, s64); .widenScalarToNextPow2(0);. and the instruction::. %2:_(s7) = G_ADD %0:_(s7), %1:_(s7). this doesn't meet the predicate for the :ref:`.legalFor() <legalfor>` as ``s7``; is not one of the listed types so it falls through to the; :ref:`.clampScalar() <clampscalar>`. It does meet the predicate for this rule; as the type is smaller than the ``s32`` and ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst:8690,Security,access,access,8690,"instruction to be illegal if the; predicate is satisfied and indicates that replacing it with a libcall would; make it more legal. Support for this action differs for; each opcode. * ``customIf()``, ``customFor()``, etc. declare an instruction to be illegal if the; predicate is satisfied and indicates that the backend developer will supply; a means of making it more legal. * ``unsupportedIf()``, ``unsupportedFor()``, etc. declare an instruction to be illegal; if the predicate is satisfied and indicates that there is no way to make it; legal and the compiler should fail. * ``fallback()`` falls back on an older API and should only be used while porting; existing code from that API. Rule Predicates; """""""""""""""""""""""""""""". The rule factories also have predicates in common:. * ``legal()``, ``lower()``, etc. are always satisfied. * ``legalIf()``, ``narrowScalarIf()``, etc. are satisfied if the user-supplied; ``LegalityPredicate`` function returns true. This predicate has access to the; information in the ``LegalityQuery`` to make its decision.; User-supplied predicates can also be combined using ``all(P0, P1, ...)``. * ``legalFor()``, ``narrowScalarFor()``, etc. are satisfied if the type matches one in; a given set of types. For example ``.legalFor({s16, s32})`` declares the; instruction legal if type 0 is either s16 or s32. Additional versions for two; and three type indices are generally available. For these, all the type; indices considered together must match all the types in one of the tuples. So; ``.legalFor({{s16, s32}, {s32, s64}})`` will only accept ``{s16, s32}``, or; ``{s32, s64}`` but will not accept ``{s16, s64}``. * ``legalForTypesWithMemSize()``, ``narrowScalarForTypesWithMemSize()``, etc. are; similar to ``legalFor()``, ``narrowScalarFor()``, etc. but additionally require a; MachineMemOperand to have a given size in each tuple. * ``legalForCartesianProduct()``, ``narrowScalarForCartesianProduct()``, etc. are; satisfied if each type index matches one element in ea",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst:4879,Testability,test,testing,4879,"hat rules can be added to. If multiple opcodes are given, they are; all permanently bound to the same ruleset. The rules in a ruleset are executed; from top to bottom and will start again from the top if an instruction is; legalized as a result of the rules. If the ruleset is exhausted without; satisfying any rule, then it is considered unsupported. When it doesn't declare the instruction legal, each pass over the rules may; request that one type changes to another type. Sometimes this can cause multiple; types to change but we avoid this as much as possible as making multiple changes; can make it difficult to avoid infinite loops where, for example, narrowing one; type causes another to be too small and widening that type causes the first one; to be too big. In general, it's advisable to declare instructions legal as close to the top of; the rule as possible and to place any expensive rules as low as possible. This; helps with performance as testing for legality happens more often than; legalization and legalization can require multiple passes over the rules. As a concrete example, consider the rule::. getActionDefinitionsBuilder({G_ADD, G_SUB, G_MUL, G_AND, G_OR, G_XOR, G_SHL}); .legalFor({s32, s64, v2s32, v4s32, v2s64}); .clampScalar(0, s32, s64); .widenScalarToNextPow2(0);. and the instruction::. %2:_(s7) = G_ADD %0:_(s7), %1:_(s7). this doesn't meet the predicate for the :ref:`.legalFor() <legalfor>` as ``s7``; is not one of the listed types so it falls through to the; :ref:`.clampScalar() <clampscalar>`. It does meet the predicate for this rule; as the type is smaller than the ``s32`` and this rule instructs the legalizer; to change type 0 to ``s32``. It then restarts from the top. This time it does; satisfy ``.legalFor()`` and the resulting output is::. %3:_(s32) = G_ANYEXT %0:_(s7); %4:_(s32) = G_ANYEXT %1:_(s7); %5:_(s32) = G_ADD %3:_(s32), %4:_(s32); %2:_(s7) = G_TRUNC %5:_(s32). where the ``G_ADD`` is legal and the other instructions are scheduled for; pr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst:1061,Usability,simpl,simple,1061,"ructions such that they are legal. A legal instruction is defined as:. * **selectable** --- the target will later be able to select it to a; target-specific (non-generic) instruction. This doesn't necessarily mean that; :doc:`InstructionSelect` has to handle it though. It just means that; **something** must handle it. * operating on **vregs that can be loaded and stored** -- if necessary, the; target can select a ``G_LOAD``/``G_STORE`` of each gvreg operand. As opposed to SelectionDAG, there are no legalization phases. In particular,; 'type' and 'operation' legalization are not separate. Legalization is iterative, and all state is contained in GMIR. To maintain the; validity of the intermediate code, instructions are introduced:. * ``G_MERGE_VALUES`` --- concatenate multiple registers of the same; size into a single wider register. * ``G_UNMERGE_VALUES`` --- extract multiple registers of the same size; from a single wider register. * ``G_EXTRACT`` --- extract a simple register (as contiguous sequences of bits); from a single wider register. As they are expected to be temporary byproducts of the legalization process,; they are combined at the end of the :ref:`milegalizer` pass.; If any remain, they are expected to always be selectable, using loads and stores; if necessary. The legality of an instruction may only depend on the instruction itself and; must not depend on any context in which the instruction is used. However, after; deciding that an instruction is not legal, using the context of the instruction; to decide how to legalize the instruction is permitted. As an example, if we; have a ``G_FOO`` instruction of the form::. %1:_(s32) = G_CONSTANT i32 1; %2:_(s32) = G_FOO %0:_(s32), %1:_(s32). it's impossible to say that G_FOO is legal iff %1 is a ``G_CONSTANT`` with; value ``1``. However, the following::. %2:_(s32) = G_FOO %0:_(s32), i32 1. can say that it's legal iff operand 2 is an immediate with value ``1`` because; that information is entirely contained within",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Legalizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/MIRPatterns.rst:1368,Availability,redundant,redundant,1368,"is still in active development. This document may become outdated; over time. If you see something that's incorrect, please update it. Use Cases; ---------. MIR patterns are supported in the following places:. * GlobalISel ``GICombineRule``; * GlobalISel ``GICombinePatFrag``. Syntax; ------. MIR patterns use the DAG datatype in TableGen. .. code-block:: text. (inst operand0, operand1, ...). ``inst`` must be a def which inherits from ``Instruction`` (e.g. ``G_FADD``); or ``GICombinePatFrag``. Operands essentially fall into one of two categories:. * immediates. * untyped, unnamed: ``0``; * untyped, named: ``0:$y``; * typed, unnamed: ``(i32 0)``; * typed, named: ``(i32 0):$y``. * machine operands. * untyped: ``$x``; * typed: ``i32:$x``. Semantics:. * A typed operand always adds an operand type check to the matcher.; * There is a trivial type inference system to propagate types. * e.g. You only need to use ``i32:$x`` once in any pattern of a; ``GICombinePatFrag`` alternative or ``GICombineRule``, then all; other patterns in that rule/alternative can simply use ``$x``; (``i32:$x`` is redundant). * A named operand's behavior depends on whether the name has been seen before. * For match patterns, reusing an operand name checks that the operands; are identical (see example 2 below).; * For apply patterns, reusing an operand name simply copies that operand into; the new instruction (see example 2 below). Operands are ordered just like they would be in a MachineInstr: the defs (outs); come first, then the uses (ins). Patterns are generally grouped into another DAG datatype with a dummy operator; such as ``match``, ``apply`` or ``pattern``. Finally, any DAG datatype in TableGen can be named. This also holds for; patterns. e.g. the following is valid: ``(G_FOO $root, (i32 0):$cst):$mypat``.; This may also be helpful to debug issues. Patterns are *always* named, and if; they don't have a name, an ""anonymous"" one is given to them. If you're trying; to debug an error related to a M",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/MIRPatterns.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/MIRPatterns.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/MIRPatterns.rst:2253,Availability,error,error,2253,"at rule/alternative can simply use ``$x``; (``i32:$x`` is redundant). * A named operand's behavior depends on whether the name has been seen before. * For match patterns, reusing an operand name checks that the operands; are identical (see example 2 below).; * For apply patterns, reusing an operand name simply copies that operand into; the new instruction (see example 2 below). Operands are ordered just like they would be in a MachineInstr: the defs (outs); come first, then the uses (ins). Patterns are generally grouped into another DAG datatype with a dummy operator; such as ``match``, ``apply`` or ``pattern``. Finally, any DAG datatype in TableGen can be named. This also holds for; patterns. e.g. the following is valid: ``(G_FOO $root, (i32 0):$cst):$mypat``.; This may also be helpful to debug issues. Patterns are *always* named, and if; they don't have a name, an ""anonymous"" one is given to them. If you're trying; to debug an error related to a MIR pattern, but the error mentions an anonymous; pattern, you can try naming your patterns to see exactly where the issue is. .. code-block:: text; :caption: Pattern Example 1. // Match; // %imp = G_IMPLICIT_DEF; // %root = G_MUL %x, %imp; (match (G_IMPLICIT_DEF $imp),; (G_MUL $root, $x, $imp)). .. code-block:: text; :caption: Pattern Example 2. // using $x twice here checks that the operand 1 and 2 of the G_AND are; // identical.; (match (G_AND $root, $x, $x)); // using $x again here copies operand 1 from G_AND into the new inst.; (apply (COPY $root, $x)). Types; -----. ValueType; ~~~~~~~~~. Subclasses of ``ValueType`` are valid types, e.g. ``i32``. GITypeOf; ~~~~~~~~. ``GITypeOf<""$x"">`` is a ``GISpecialType`` that allows for the creation of a; register or immediate with the same type as another (register) operand. Operand:. * An operand name as a string, prefixed by ``$``. Semantics:. * Can only appear in an 'apply' pattern.; * The operand name used must appear in the 'match' pattern of the; same ``GICombineRule``. .. c",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/MIRPatterns.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/MIRPatterns.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/MIRPatterns.rst:2293,Availability,error,error,2293,"at rule/alternative can simply use ``$x``; (``i32:$x`` is redundant). * A named operand's behavior depends on whether the name has been seen before. * For match patterns, reusing an operand name checks that the operands; are identical (see example 2 below).; * For apply patterns, reusing an operand name simply copies that operand into; the new instruction (see example 2 below). Operands are ordered just like they would be in a MachineInstr: the defs (outs); come first, then the uses (ins). Patterns are generally grouped into another DAG datatype with a dummy operator; such as ``match``, ``apply`` or ``pattern``. Finally, any DAG datatype in TableGen can be named. This also holds for; patterns. e.g. the following is valid: ``(G_FOO $root, (i32 0):$cst):$mypat``.; This may also be helpful to debug issues. Patterns are *always* named, and if; they don't have a name, an ""anonymous"" one is given to them. If you're trying; to debug an error related to a MIR pattern, but the error mentions an anonymous; pattern, you can try naming your patterns to see exactly where the issue is. .. code-block:: text; :caption: Pattern Example 1. // Match; // %imp = G_IMPLICIT_DEF; // %root = G_MUL %x, %imp; (match (G_IMPLICIT_DEF $imp),; (G_MUL $root, $x, $imp)). .. code-block:: text; :caption: Pattern Example 2. // using $x twice here checks that the operand 1 and 2 of the G_AND are; // identical.; (match (G_AND $root, $x, $x)); // using $x again here copies operand 1 from G_AND into the new inst.; (apply (COPY $root, $x)). Types; -----. ValueType; ~~~~~~~~~. Subclasses of ``ValueType`` are valid types, e.g. ``i32``. GITypeOf; ~~~~~~~~. ``GITypeOf<""$x"">`` is a ``GISpecialType`` that allows for the creation of a; register or immediate with the same type as another (register) operand. Operand:. * An operand name as a string, prefixed by ``$``. Semantics:. * Can only appear in an 'apply' pattern.; * The operand name used must appear in the 'match' pattern of the; same ``GICombineRule``. .. c",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/MIRPatterns.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/MIRPatterns.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/MIRPatterns.rst:7749,Availability,avail,available,7749,"`match`` or ``apply`` patterns of a; ``GICombineRule``. The ``root`` of the rule can either be a def of an instruction, or a; named pattern. The latter is helpful when the instruction you want; to match has no defs. The former is generally preferred because; it's less verbose. .. code-block:: text; :caption: Combine Rule root is a def. // Fold x op 1 -> x; def right_identity_one: GICombineRule<; (defs root:$dst),; (match (G_MUL $dst, $x, 1)),; // Note: Patterns always need to create something, we can't just replace $dst with $x, so we need a COPY.; (apply (COPY $dst, $x)); >;. .. code-block:: text; :caption: Combine Rule root is a named pattern. def Foo : GICombineRule<; (defs root:$root),; (match (G_ZEXT $tmp, (i32 0)),; (G_STORE $tmp, $ptr):$root),; (apply (G_STORE (i32 0), $ptr):$root)>;. Combine Rules also allow mixing C++ code with MIR patterns, so that you; may perform additional checks when matching, or run additional code after; rewriting a pattern. The following expansions are available for MIR patterns:. * operand names (``MachineOperand &``); * pattern names (``MachineInstr *`` for ``match``,; ``MachineInstrBuilder &`` for apply). .. code-block:: text; :caption: Example C++ Expansions. def Foo : GICombineRule<; (defs root:$root),; (match (G_ZEXT $root, $src):$mi),; (apply ""foobar(${root}.getReg(), ${src}.getReg(), ${mi}->hasImplicitDef())"")>;. Common Pattern #1: Replace a Register with Another; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. The 'apply' pattern must always redefine all operands defined by the match root.; Sometimes, we do not need to create instructions, simply replace a def with; another matched register. The ``GIReplaceReg`` builtin can do just that. .. code-block:: text. def Foo : GICombineRule<; (defs root:$dst),; (match (G_FNEG $tmp, $src), (G_FNEG $dst, $tmp)),; (apply (GIReplaceReg $dst, $src))>;. This also works if the replacement register is a temporary register from the; ``apply`` pattern. .. code-block:: text. def ReplaceTe",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/MIRPatterns.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/MIRPatterns.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/MIRPatterns.rst:14495,Availability,error,error,14495,"tiple Rules at Once. // Fold (freeze (freeze x)) -> (freeze x).; // Fold (fabs (fabs x)) -> (fabs x).; // Fold (fcanonicalize (fcanonicalize x)) -> (fcanonicalize x).; def idempotent_prop_frags : GICombinePatFrag<(outs root:$dst, $src), (ins),; [; (pattern (G_FREEZE $dst, $src), (G_FREEZE $src, $x)),; (pattern (G_FABS $dst, $src), (G_FABS $src, $x)),; (pattern (G_FCANONICALIZE $dst, $src), (G_FCANONICALIZE $src, $x)); ]; >;. def idempotent_prop : GICombineRule<; (defs root:$dst),; (match (idempotent_prop_frags $dst, $src)),; (apply (COPY $dst, $src))>;. .. code-block:: text; :caption: Example 3: Unbound Operand Names. // This fragment binds $x to an operand in all of its; // alternative patterns.; def always_binds : GICombinePatFrag<; (outs root:$dst), (ins $x),; [; (pattern (G_FREEZE $dst, $x)),; (pattern (G_FABS $dst, $x)),; ]; >;. // This fragment does not bind $x to an operand in any; // of its alternative patterns.; def does_not_bind : GICombinePatFrag<; (outs root:$dst), (ins $x),; [; (pattern (G_FREEZE $dst, $x)), // binds $x; (pattern (G_FOO $dst (i32 0))), // does not bind $x; (pattern ""return myCheck(${x}.getReg())""), // does not bind $x; ]; >;. // Here we pass $x, which is unbound, to always_binds.; // This works because if $x is unbound, always_binds will bind it for us.; def test0 : GICombineRule<; (defs root:$dst),; (match (always_binds $dst, $x)),; (apply (COPY $dst, $x))>;. // Here we pass $x, which is unbound, to does_not_bind.; // This cannot work because $x may not have been initialized in 'apply'.; // error: operand 'x' (for parameter 'src' of 'does_not_bind') cannot be unbound; def test1 : GICombineRule<; (defs root:$dst),; (match (does_not_bind $dst, $x)),; (apply (COPY $dst, $x))>;. // Here we pass $x, which is bound, to does_not_bind.; // This is fine because $x will always be bound when emitting does_not_bind; def test2 : GICombineRule<; (defs root:$dst),; (match (does_not_bind $tmp, $x); (G_MUL $dst, $x, $tmp)),; (apply (COPY $dst, $x))>;; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/MIRPatterns.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/MIRPatterns.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/MIRPatterns.rst:396,Deployability,update,update,396,"; .. _tblgen-mirpats:. ========================; MIR Patterns in TableGen; ========================. .. contents::; :local:. User's Guide; ============. This section is intended for developers who want to use MIR patterns in their; TableGen files. ``NOTE``:; This feature is still in active development. This document may become outdated; over time. If you see something that's incorrect, please update it. Use Cases; ---------. MIR patterns are supported in the following places:. * GlobalISel ``GICombineRule``; * GlobalISel ``GICombinePatFrag``. Syntax; ------. MIR patterns use the DAG datatype in TableGen. .. code-block:: text. (inst operand0, operand1, ...). ``inst`` must be a def which inherits from ``Instruction`` (e.g. ``G_FADD``); or ``GICombinePatFrag``. Operands essentially fall into one of two categories:. * immediates. * untyped, unnamed: ``0``; * untyped, named: ``0:$y``; * typed, unnamed: ``(i32 0)``; * typed, named: ``(i32 0):$y``. * machine operands. * untyped: ``$x``; * typed: ``i32:$x``. Semantics:. * A typed operand always adds an operand type check to the matcher.; * There is a trivial type inference system to propagate types. * e.g. You only need to use ``i32:$x`` once in any pattern of a; ``GICombinePatFrag`` alternative or ``GICombineRule``, then all; other patterns in that rule/alternative can simply use ``$x``; (``i32:$x`` is redundant). * A named operand's behavior depends on whether the name has been seen before. * For match patterns, reusing an operand name checks that the operands; are identical (see example 2 below).; * For apply patterns, reusing an operand name simply copies that operand into; the new instruction (see example 2 below). Operands are ordered just like they would be in a MachineInstr: the defs (outs); come first, then the uses (ins). Patterns are generally grouped into another DAG datatype with a dummy operator; such as ``match``, ``apply`` or ``pattern``. Finally, any DAG datatype in TableGen can be named. This also holds for",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/MIRPatterns.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/MIRPatterns.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/MIRPatterns.rst:3841,Energy Efficiency,power,powerful,3841,"~~~~~~~~. Subclasses of ``ValueType`` are valid types, e.g. ``i32``. GITypeOf; ~~~~~~~~. ``GITypeOf<""$x"">`` is a ``GISpecialType`` that allows for the creation of a; register or immediate with the same type as another (register) operand. Operand:. * An operand name as a string, prefixed by ``$``. Semantics:. * Can only appear in an 'apply' pattern.; * The operand name used must appear in the 'match' pattern of the; same ``GICombineRule``. .. code-block:: text; :caption: Example: Immediate. def mul_by_neg_one: GICombineRule <; (defs root:$root),; (match (G_MUL $dst, $x, -1)),; (apply (G_SUB $dst, (GITypeOf<""$x""> 0), $x)); >;. .. code-block:: text; :caption: Example: Temp Reg. def Test0 : GICombineRule<; (defs root:$dst),; (match (G_FMUL $dst, $src, -1)),; (apply (G_FSUB $dst, $src, $tmp),; (G_FNEG GITypeOf<""$dst"">:$tmp, $src))>;. Builtin Operations; ------------------. MIR Patterns also offer builtin operations, also called ""builtin instructions"".; They offer some powerful features that would otherwise require use of C++ code. GIReplaceReg; ~~~~~~~~~~~~. .. code-block:: text; :caption: Usage. (apply (GIReplaceReg $old, $new)). Operands:. * ``$old`` (out) register defined by a matched instruction; * ``$new`` (in) register. Semantics:. * Can only appear in an 'apply' pattern.; * If both old/new are operands of matched instructions,; ``canReplaceReg`` is checked before applying the rule. GIEraseRoot; ~~~~~~~~~~~. .. code-block:: text; :caption: Usage. (apply (GIEraseRoot)). Semantics:. * Can only appear as the only pattern of an 'apply' pattern list.; * The root cannot have any output operands.; * The root must be a CodeGenInstruction. Instruction Flags; -----------------. MIR Patterns support both matching & writing ``MIFlags``. .. code-block:: text; :caption: Example. def Test : GICombineRule<; (defs root:$dst),; (match (G_FOO $dst, $src, (MIFlags FmNoNans, FmNoInfs))),; (apply (G_BAR $dst, $src, (MIFlags FmReassoc)))>;. In ``apply`` patterns, we also support referring",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/MIRPatterns.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/MIRPatterns.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/MIRPatterns.rst:1409,Integrability,depend,depends,1409,"---------. MIR patterns are supported in the following places:. * GlobalISel ``GICombineRule``; * GlobalISel ``GICombinePatFrag``. Syntax; ------. MIR patterns use the DAG datatype in TableGen. .. code-block:: text. (inst operand0, operand1, ...). ``inst`` must be a def which inherits from ``Instruction`` (e.g. ``G_FADD``); or ``GICombinePatFrag``. Operands essentially fall into one of two categories:. * immediates. * untyped, unnamed: ``0``; * untyped, named: ``0:$y``; * typed, unnamed: ``(i32 0)``; * typed, named: ``(i32 0):$y``. * machine operands. * untyped: ``$x``; * typed: ``i32:$x``. Semantics:. * A typed operand always adds an operand type check to the matcher.; * There is a trivial type inference system to propagate types. * e.g. You only need to use ``i32:$x`` once in any pattern of a; ``GICombinePatFrag`` alternative or ``GICombineRule``, then all; other patterns in that rule/alternative can simply use ``$x``; (``i32:$x`` is redundant). * A named operand's behavior depends on whether the name has been seen before. * For match patterns, reusing an operand name checks that the operands; are identical (see example 2 below).; * For apply patterns, reusing an operand name simply copies that operand into; the new instruction (see example 2 below). Operands are ordered just like they would be in a MachineInstr: the defs (outs); come first, then the uses (ins). Patterns are generally grouped into another DAG datatype with a dummy operator; such as ``match``, ``apply`` or ``pattern``. Finally, any DAG datatype in TableGen can be named. This also holds for; patterns. e.g. the following is valid: ``(G_FOO $root, (i32 0):$cst):$mypat``.; This may also be helpful to debug issues. Patterns are *always* named, and if; they don't have a name, an ""anonymous"" one is given to them. If you're trying; to debug an error related to a MIR pattern, but the error mentions an anonymous; pattern, you can try naming your patterns to see exactly where the issue is. .. code-block:: text",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/MIRPatterns.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/MIRPatterns.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/MIRPatterns.rst:9396,Integrability,depend,depends,9396,"def with; another matched register. The ``GIReplaceReg`` builtin can do just that. .. code-block:: text. def Foo : GICombineRule<; (defs root:$dst),; (match (G_FNEG $tmp, $src), (G_FNEG $dst, $tmp)),; (apply (GIReplaceReg $dst, $src))>;. This also works if the replacement register is a temporary register from the; ``apply`` pattern. .. code-block:: text. def ReplaceTemp : GICombineRule<; (defs root:$a),; (match (G_BUILD_VECTOR $tmp, $x, $y),; (G_UNMERGE_VALUES $a, $b, $tmp)),; (apply (G_UNMERGE_VALUES $a, i32:$new, $y),; (GIReplaceReg $b, $new))>. Common Pattern #2: Erasing a Def-less Root; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. If we simply want to erase a def-less match root, we can use the; ``GIEraseRoot`` builtin. .. code-block:: text. def Foo : GICombineRule<; (defs root:$mi),; (match (G_STORE $a, $b):$mi),; (apply (GIEraseRoot))>;. Common Pattern #3: Emitting a Constant Value; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. When an immediate operand appears in an 'apply' pattern, the behavior; depends on whether it's typed or not. * If the immediate is typed, ``MachineIRBuilder::buildConstant`` is used; to create a ``G_CONSTANT``. A ``G_BUILD_VECTOR`` will be used for vectors.; * If the immediate is untyped, a simple immediate is added; (``MachineInstrBuilder::addImm``). There is of course a special case for ``G_CONSTANT``. Immediates for; ``G_CONSTANT`` must always be typed, and a CImm is added; (``MachineInstrBuilder::addCImm``). .. code-block:: text; :caption: Constant Emission Examples:. // Example output:; // %0 = G_CONSTANT i32 0; // %dst = COPY %0; def Foo : GICombineRule<; (defs root:$dst),; (match (G_FOO $dst, $src)),; (apply (COPY $dst, (i32 0)))>;. // Example output:; // %dst = COPY 0; // Note that this would be ill-formed because COPY; // expects a register operand!; def Bar : GICombineRule<; (defs root:$dst),; (match (G_FOO $dst, $src)),; (apply (COPY $dst, (i32 0)))>;. // Example output:; // %dst = G_CONSTANT i32 0; def Bux : GICombineRule<; (d",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/MIRPatterns.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/MIRPatterns.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/MIRPatterns.rst:695,Modifiability,inherit,inherits,695,"; .. _tblgen-mirpats:. ========================; MIR Patterns in TableGen; ========================. .. contents::; :local:. User's Guide; ============. This section is intended for developers who want to use MIR patterns in their; TableGen files. ``NOTE``:; This feature is still in active development. This document may become outdated; over time. If you see something that's incorrect, please update it. Use Cases; ---------. MIR patterns are supported in the following places:. * GlobalISel ``GICombineRule``; * GlobalISel ``GICombinePatFrag``. Syntax; ------. MIR patterns use the DAG datatype in TableGen. .. code-block:: text. (inst operand0, operand1, ...). ``inst`` must be a def which inherits from ``Instruction`` (e.g. ``G_FADD``); or ``GICombinePatFrag``. Operands essentially fall into one of two categories:. * immediates. * untyped, unnamed: ``0``; * untyped, named: ``0:$y``; * typed, unnamed: ``(i32 0)``; * typed, named: ``(i32 0):$y``. * machine operands. * untyped: ``$x``; * typed: ``i32:$x``. Semantics:. * A typed operand always adds an operand type check to the matcher.; * There is a trivial type inference system to propagate types. * e.g. You only need to use ``i32:$x`` once in any pattern of a; ``GICombinePatFrag`` alternative or ``GICombineRule``, then all; other patterns in that rule/alternative can simply use ``$x``; (``i32:$x`` is redundant). * A named operand's behavior depends on whether the name has been seen before. * For match patterns, reusing an operand name checks that the operands; are identical (see example 2 below).; * For apply patterns, reusing an operand name simply copies that operand into; the new instruction (see example 2 below). Operands are ordered just like they would be in a MachineInstr: the defs (outs); come first, then the uses (ins). Patterns are generally grouped into another DAG datatype with a dummy operator; such as ``match``, ``apply`` or ``pattern``. Finally, any DAG datatype in TableGen can be named. This also holds for",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/MIRPatterns.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/MIRPatterns.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/MIRPatterns.rst:6300,Modifiability,rewrite,rewrite,6300," a flag is NOT present; on a matched instruction, and to remove a flag from a generated instruction. .. code-block:: text; :caption: Example. ; We match NoInfs but we don't want NoNans/Reassoc to be set. $zext may have more flags.; ; Copy them all into the output instruction but remove NoInfs on the output inst.; def TestNot : GICombineRule<; (defs root:$dst),; (match (G_FOO $dst, $src, (MIFlags FmNoInfs, (not FmNoNans, FmReassoc))):$zext),; (apply (G_BAR $dst, $src, (MIFlags $zext, (not FmNoInfs))))>;. Limitations; -----------. This a non-exhaustive list of known issues with MIR patterns at this time. * Matching intrinsics is not yet possible.; * Using ``GICombinePatFrag`` within another ``GICombinePatFrag`` is not; supported.; * ``GICombinePatFrag`` can only have a single root.; * Instructions with multiple defs cannot be the root of a ``GICombinePatFrag``.; * Using ``GICombinePatFrag`` in the ``apply`` pattern of a ``GICombineRule``; is not supported.; * We cannot rewrite a matched instruction other than the root.; * Matching/creating a (CImm) immediate >64 bits is not supported; (see comment in ``GIM_CheckConstantInt``); * There is currently no way to constrain two register/immediate types to; match. e.g. if a pattern needs to work on both i32 and i64, you either; need to leave it untyped and check the type in C++, or duplicate the; pattern. GICombineRule; -------------. MIR patterns can appear in the ``match`` or ``apply`` patterns of a; ``GICombineRule``. The ``root`` of the rule can either be a def of an instruction, or a; named pattern. The latter is helpful when the instruction you want; to match has no defs. The former is generally preferred because; it's less verbose. .. code-block:: text; :caption: Combine Rule root is a def. // Fold x op 1 -> x; def right_identity_one: GICombineRule<; (defs root:$dst),; (match (G_MUL $dst, $x, 1)),; // Note: Patterns always need to create something, we can't just replace $dst with $x, so we need a COPY.; (apply (COPY $d",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/MIRPatterns.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/MIRPatterns.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/MIRPatterns.rst:7628,Performance,perform,perform,7628,"d check the type in C++, or duplicate the; pattern. GICombineRule; -------------. MIR patterns can appear in the ``match`` or ``apply`` patterns of a; ``GICombineRule``. The ``root`` of the rule can either be a def of an instruction, or a; named pattern. The latter is helpful when the instruction you want; to match has no defs. The former is generally preferred because; it's less verbose. .. code-block:: text; :caption: Combine Rule root is a def. // Fold x op 1 -> x; def right_identity_one: GICombineRule<; (defs root:$dst),; (match (G_MUL $dst, $x, 1)),; // Note: Patterns always need to create something, we can't just replace $dst with $x, so we need a COPY.; (apply (COPY $dst, $x)); >;. .. code-block:: text; :caption: Combine Rule root is a named pattern. def Foo : GICombineRule<; (defs root:$root),; (match (G_ZEXT $tmp, (i32 0)),; (G_STORE $tmp, $ptr):$root),; (apply (G_STORE (i32 0), $ptr):$root)>;. Combine Rules also allow mixing C++ code with MIR patterns, so that you; may perform additional checks when matching, or run additional code after; rewriting a pattern. The following expansions are available for MIR patterns:. * operand names (``MachineOperand &``); * pattern names (``MachineInstr *`` for ``match``,; ``MachineInstrBuilder &`` for apply). .. code-block:: text; :caption: Example C++ Expansions. def Foo : GICombineRule<; (defs root:$root),; (match (G_ZEXT $root, $src):$mi),; (apply ""foobar(${root}.getReg(), ${src}.getReg(), ${mi}->hasImplicitDef())"")>;. Common Pattern #1: Replace a Register with Another; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. The 'apply' pattern must always redefine all operands defined by the match root.; Sometimes, we do not need to create instructions, simply replace a def with; another matched register. The ``GIReplaceReg`` builtin can do just that. .. code-block:: text. def Foo : GICombineRule<; (defs root:$dst),; (match (G_FNEG $tmp, $src), (G_FNEG $dst, $tmp)),; (apply (GIReplaceReg $dst, $src))>;. This also works if ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/MIRPatterns.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/MIRPatterns.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/MIRPatterns.rst:1368,Safety,redund,redundant,1368,"is still in active development. This document may become outdated; over time. If you see something that's incorrect, please update it. Use Cases; ---------. MIR patterns are supported in the following places:. * GlobalISel ``GICombineRule``; * GlobalISel ``GICombinePatFrag``. Syntax; ------. MIR patterns use the DAG datatype in TableGen. .. code-block:: text. (inst operand0, operand1, ...). ``inst`` must be a def which inherits from ``Instruction`` (e.g. ``G_FADD``); or ``GICombinePatFrag``. Operands essentially fall into one of two categories:. * immediates. * untyped, unnamed: ``0``; * untyped, named: ``0:$y``; * typed, unnamed: ``(i32 0)``; * typed, named: ``(i32 0):$y``. * machine operands. * untyped: ``$x``; * typed: ``i32:$x``. Semantics:. * A typed operand always adds an operand type check to the matcher.; * There is a trivial type inference system to propagate types. * e.g. You only need to use ``i32:$x`` once in any pattern of a; ``GICombinePatFrag`` alternative or ``GICombineRule``, then all; other patterns in that rule/alternative can simply use ``$x``; (``i32:$x`` is redundant). * A named operand's behavior depends on whether the name has been seen before. * For match patterns, reusing an operand name checks that the operands; are identical (see example 2 below).; * For apply patterns, reusing an operand name simply copies that operand into; the new instruction (see example 2 below). Operands are ordered just like they would be in a MachineInstr: the defs (outs); come first, then the uses (ins). Patterns are generally grouped into another DAG datatype with a dummy operator; such as ``match``, ``apply`` or ``pattern``. Finally, any DAG datatype in TableGen can be named. This also holds for; patterns. e.g. the following is valid: ``(G_FOO $root, (i32 0):$cst):$mypat``.; This may also be helpful to debug issues. Patterns are *always* named, and if; they don't have a name, an ""anonymous"" one is given to them. If you're trying; to debug an error related to a M",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/MIRPatterns.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/MIRPatterns.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/MIRPatterns.rst:1334,Usability,simpl,simply,1334,"is still in active development. This document may become outdated; over time. If you see something that's incorrect, please update it. Use Cases; ---------. MIR patterns are supported in the following places:. * GlobalISel ``GICombineRule``; * GlobalISel ``GICombinePatFrag``. Syntax; ------. MIR patterns use the DAG datatype in TableGen. .. code-block:: text. (inst operand0, operand1, ...). ``inst`` must be a def which inherits from ``Instruction`` (e.g. ``G_FADD``); or ``GICombinePatFrag``. Operands essentially fall into one of two categories:. * immediates. * untyped, unnamed: ``0``; * untyped, named: ``0:$y``; * typed, unnamed: ``(i32 0)``; * typed, named: ``(i32 0):$y``. * machine operands. * untyped: ``$x``; * typed: ``i32:$x``. Semantics:. * A typed operand always adds an operand type check to the matcher.; * There is a trivial type inference system to propagate types. * e.g. You only need to use ``i32:$x`` once in any pattern of a; ``GICombinePatFrag`` alternative or ``GICombineRule``, then all; other patterns in that rule/alternative can simply use ``$x``; (``i32:$x`` is redundant). * A named operand's behavior depends on whether the name has been seen before. * For match patterns, reusing an operand name checks that the operands; are identical (see example 2 below).; * For apply patterns, reusing an operand name simply copies that operand into; the new instruction (see example 2 below). Operands are ordered just like they would be in a MachineInstr: the defs (outs); come first, then the uses (ins). Patterns are generally grouped into another DAG datatype with a dummy operator; such as ``match``, ``apply`` or ``pattern``. Finally, any DAG datatype in TableGen can be named. This also holds for; patterns. e.g. the following is valid: ``(G_FOO $root, (i32 0):$cst):$mypat``.; This may also be helpful to debug issues. Patterns are *always* named, and if; they don't have a name, an ""anonymous"" one is given to them. If you're trying; to debug an error related to a M",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/MIRPatterns.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/MIRPatterns.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/MIRPatterns.rst:1615,Usability,simpl,simply,1615,"text. (inst operand0, operand1, ...). ``inst`` must be a def which inherits from ``Instruction`` (e.g. ``G_FADD``); or ``GICombinePatFrag``. Operands essentially fall into one of two categories:. * immediates. * untyped, unnamed: ``0``; * untyped, named: ``0:$y``; * typed, unnamed: ``(i32 0)``; * typed, named: ``(i32 0):$y``. * machine operands. * untyped: ``$x``; * typed: ``i32:$x``. Semantics:. * A typed operand always adds an operand type check to the matcher.; * There is a trivial type inference system to propagate types. * e.g. You only need to use ``i32:$x`` once in any pattern of a; ``GICombinePatFrag`` alternative or ``GICombineRule``, then all; other patterns in that rule/alternative can simply use ``$x``; (``i32:$x`` is redundant). * A named operand's behavior depends on whether the name has been seen before. * For match patterns, reusing an operand name checks that the operands; are identical (see example 2 below).; * For apply patterns, reusing an operand name simply copies that operand into; the new instruction (see example 2 below). Operands are ordered just like they would be in a MachineInstr: the defs (outs); come first, then the uses (ins). Patterns are generally grouped into another DAG datatype with a dummy operator; such as ``match``, ``apply`` or ``pattern``. Finally, any DAG datatype in TableGen can be named. This also holds for; patterns. e.g. the following is valid: ``(G_FOO $root, (i32 0):$cst):$mypat``.; This may also be helpful to debug issues. Patterns are *always* named, and if; they don't have a name, an ""anonymous"" one is given to them. If you're trying; to debug an error related to a MIR pattern, but the error mentions an anonymous; pattern, you can try naming your patterns to see exactly where the issue is. .. code-block:: text; :caption: Pattern Example 1. // Match; // %imp = G_IMPLICIT_DEF; // %root = G_MUL %x, %imp; (match (G_IMPLICIT_DEF $imp),; (G_MUL $root, $x, $imp)). .. code-block:: text; :caption: Pattern Example 2. // using",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/MIRPatterns.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/MIRPatterns.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/MIRPatterns.rst:8361,Usability,simpl,simply,8361,"n: Combine Rule root is a named pattern. def Foo : GICombineRule<; (defs root:$root),; (match (G_ZEXT $tmp, (i32 0)),; (G_STORE $tmp, $ptr):$root),; (apply (G_STORE (i32 0), $ptr):$root)>;. Combine Rules also allow mixing C++ code with MIR patterns, so that you; may perform additional checks when matching, or run additional code after; rewriting a pattern. The following expansions are available for MIR patterns:. * operand names (``MachineOperand &``); * pattern names (``MachineInstr *`` for ``match``,; ``MachineInstrBuilder &`` for apply). .. code-block:: text; :caption: Example C++ Expansions. def Foo : GICombineRule<; (defs root:$root),; (match (G_ZEXT $root, $src):$mi),; (apply ""foobar(${root}.getReg(), ${src}.getReg(), ${mi}->hasImplicitDef())"")>;. Common Pattern #1: Replace a Register with Another; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. The 'apply' pattern must always redefine all operands defined by the match root.; Sometimes, we do not need to create instructions, simply replace a def with; another matched register. The ``GIReplaceReg`` builtin can do just that. .. code-block:: text. def Foo : GICombineRule<; (defs root:$dst),; (match (G_FNEG $tmp, $src), (G_FNEG $dst, $tmp)),; (apply (GIReplaceReg $dst, $src))>;. This also works if the replacement register is a temporary register from the; ``apply`` pattern. .. code-block:: text. def ReplaceTemp : GICombineRule<; (defs root:$a),; (match (G_BUILD_VECTOR $tmp, $x, $y),; (G_UNMERGE_VALUES $a, $b, $tmp)),; (apply (G_UNMERGE_VALUES $a, i32:$new, $y),; (GIReplaceReg $b, $new))>. Common Pattern #2: Erasing a Def-less Root; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. If we simply want to erase a def-less match root, we can use the; ``GIEraseRoot`` builtin. .. code-block:: text. def Foo : GICombineRule<; (defs root:$mi),; (match (G_STORE $a, $b):$mi),; (apply (GIEraseRoot))>;. Common Pattern #3: Emitting a Constant Value; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. When an immediate operand appears in",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/MIRPatterns.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/MIRPatterns.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/MIRPatterns.rst:9026,Usability,simpl,simply,9026,"ot}.getReg(), ${src}.getReg(), ${mi}->hasImplicitDef())"")>;. Common Pattern #1: Replace a Register with Another; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. The 'apply' pattern must always redefine all operands defined by the match root.; Sometimes, we do not need to create instructions, simply replace a def with; another matched register. The ``GIReplaceReg`` builtin can do just that. .. code-block:: text. def Foo : GICombineRule<; (defs root:$dst),; (match (G_FNEG $tmp, $src), (G_FNEG $dst, $tmp)),; (apply (GIReplaceReg $dst, $src))>;. This also works if the replacement register is a temporary register from the; ``apply`` pattern. .. code-block:: text. def ReplaceTemp : GICombineRule<; (defs root:$a),; (match (G_BUILD_VECTOR $tmp, $x, $y),; (G_UNMERGE_VALUES $a, $b, $tmp)),; (apply (G_UNMERGE_VALUES $a, i32:$new, $y),; (GIReplaceReg $b, $new))>. Common Pattern #2: Erasing a Def-less Root; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. If we simply want to erase a def-less match root, we can use the; ``GIEraseRoot`` builtin. .. code-block:: text. def Foo : GICombineRule<; (defs root:$mi),; (match (G_STORE $a, $b):$mi),; (apply (GIEraseRoot))>;. Common Pattern #3: Emitting a Constant Value; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. When an immediate operand appears in an 'apply' pattern, the behavior; depends on whether it's typed or not. * If the immediate is typed, ``MachineIRBuilder::buildConstant`` is used; to create a ``G_CONSTANT``. A ``G_BUILD_VECTOR`` will be used for vectors.; * If the immediate is untyped, a simple immediate is added; (``MachineInstrBuilder::addImm``). There is of course a special case for ``G_CONSTANT``. Immediates for; ``G_CONSTANT`` must always be typed, and a CImm is added; (``MachineInstrBuilder::addCImm``). .. code-block:: text; :caption: Constant Emission Examples:. // Example output:; // %0 = G_CONSTANT i32 0; // %dst = COPY %0; def Foo : GICombineRule<; (defs root:$dst),; (match (G_FOO $dst, $src)),; (apply (COPY $dst, (i3",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/MIRPatterns.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/MIRPatterns.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/MIRPatterns.rst:9617,Usability,simpl,simple,9617,"s if the replacement register is a temporary register from the; ``apply`` pattern. .. code-block:: text. def ReplaceTemp : GICombineRule<; (defs root:$a),; (match (G_BUILD_VECTOR $tmp, $x, $y),; (G_UNMERGE_VALUES $a, $b, $tmp)),; (apply (G_UNMERGE_VALUES $a, i32:$new, $y),; (GIReplaceReg $b, $new))>. Common Pattern #2: Erasing a Def-less Root; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. If we simply want to erase a def-less match root, we can use the; ``GIEraseRoot`` builtin. .. code-block:: text. def Foo : GICombineRule<; (defs root:$mi),; (match (G_STORE $a, $b):$mi),; (apply (GIEraseRoot))>;. Common Pattern #3: Emitting a Constant Value; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. When an immediate operand appears in an 'apply' pattern, the behavior; depends on whether it's typed or not. * If the immediate is typed, ``MachineIRBuilder::buildConstant`` is used; to create a ``G_CONSTANT``. A ``G_BUILD_VECTOR`` will be used for vectors.; * If the immediate is untyped, a simple immediate is added; (``MachineInstrBuilder::addImm``). There is of course a special case for ``G_CONSTANT``. Immediates for; ``G_CONSTANT`` must always be typed, and a CImm is added; (``MachineInstrBuilder::addCImm``). .. code-block:: text; :caption: Constant Emission Examples:. // Example output:; // %0 = G_CONSTANT i32 0; // %dst = COPY %0; def Foo : GICombineRule<; (defs root:$dst),; (match (G_FOO $dst, $src)),; (apply (COPY $dst, (i32 0)))>;. // Example output:; // %dst = COPY 0; // Note that this would be ill-formed because COPY; // expects a register operand!; def Bar : GICombineRule<; (defs root:$dst),; (match (G_FOO $dst, $src)),; (apply (COPY $dst, (i32 0)))>;. // Example output:; // %dst = G_CONSTANT i32 0; def Bux : GICombineRule<; (defs root:$dst),; (match (G_FOO $dst, $src)),; (apply (G_CONSTANT $dst, (i32 0)))>;. GICombinePatFrag; ----------------. ``GICombinePatFrag`` is an equivalent of ``PatFrags`` for MIR patterns.; They have two main usecases:. * Reduce repetition by creat",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/MIRPatterns.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/MIRPatterns.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst:4104,Availability,reliab,reliably,4104,"overview-customized.png. .. _maintainability-verifier:. MachineVerifier; ---------------. The pass approach lets us use the ``MachineVerifier`` to enforce invariants; that are required beyond certain points of the pipeline. For example, a; function with the ``legalized`` property can have the ``MachineVerifier``; enforce that no illegal instructions occur. Similarly, a; ``regBankSelected`` function may not have virtual registers without a register; bank assigned. .. note::. For layering reasons, ``MachineVerifier`` isn't able to be the sole verifier; in GlobalISel. Currently some of the passes also perform verification while; we find a way to solve this problem. The main issue is that GlobalISel is a separate library, so we can't; directly reference it from CodeGen. Testing; -------. The ability to test GlobalISel is significantly improved over SelectionDAG.; SelectionDAG is something of a black box and there's a lot going on inside it.; This makes it difficult to write a test that reliably tests a particular aspect; of its behaviour. For comparison, see the following diagram:. .. image:: testing-pass-level.png. Each of the grey boxes indicates an opportunity to serialize the current state; and test the behaviour between two points in the pipeline. The current state; can be serialized using ``-stop-before`` or ``-stop-after`` and loaded using; ``-start-before``, ``-start-after``, and ``-run-pass``. We can also go further still, as many of GlobalISel's passes are readily unit; testable:. .. image:: testing-unit-level.png. It's possible to create an imaginary target such as in `LegalizerHelperTest.cpp <https://github.com/llvm/llvm-project/blob/93b29d3882baf7df42e4e9bc26b977b00373ef56/llvm/unittests/CodeGen/GlobalISel/LegalizerHelperTest.cpp#L28-L57>`_; and perform a single step of the algorithm and check the result. The MIR and; FileCheck directives can be embedded using strings so you still have access to; the convenience available in llvm-lit. Debugging; ---------. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst:5062,Availability,avail,available,5062,"x and there's a lot going on inside it.; This makes it difficult to write a test that reliably tests a particular aspect; of its behaviour. For comparison, see the following diagram:. .. image:: testing-pass-level.png. Each of the grey boxes indicates an opportunity to serialize the current state; and test the behaviour between two points in the pipeline. The current state; can be serialized using ``-stop-before`` or ``-stop-after`` and loaded using; ``-start-before``, ``-start-after``, and ``-run-pass``. We can also go further still, as many of GlobalISel's passes are readily unit; testable:. .. image:: testing-unit-level.png. It's possible to create an imaginary target such as in `LegalizerHelperTest.cpp <https://github.com/llvm/llvm-project/blob/93b29d3882baf7df42e4e9bc26b977b00373ef56/llvm/unittests/CodeGen/GlobalISel/LegalizerHelperTest.cpp#L28-L57>`_; and perform a single step of the algorithm and check the result. The MIR and; FileCheck directives can be embedded using strings so you still have access to; the convenience available in llvm-lit. Debugging; ---------. One debugging technique that's proven particularly valuable is to use the; BlockExtractor to extract basic blocks into new functions. This can be used; to track down correctness bugs and can also be used to track down performance; regressions. It can also be coupled with function attributes to disable; GlobalISel for one or more of the extracted functions. .. image:: block-extract.png. The command to do the extraction is:. .. code-block:: shell. ./bin/llvm-extract -o - -S -b ‘foo:bb1;bb4’ <input> > extracted.ll. This particular example extracts two basic blocks from a function named ``foo``.; The new LLVM-IR can then be modified to add the ``failedISel`` attribute to the; extracted function containing bb4 to make that function use SelectionDAG. This can prevent some optimizations as GlobalISel is generally able to work on a; single function at a time. This technique can be repeated for different; c",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst:5268,Availability,down,down,5268,"ze the current state; and test the behaviour between two points in the pipeline. The current state; can be serialized using ``-stop-before`` or ``-stop-after`` and loaded using; ``-start-before``, ``-start-after``, and ``-run-pass``. We can also go further still, as many of GlobalISel's passes are readily unit; testable:. .. image:: testing-unit-level.png. It's possible to create an imaginary target such as in `LegalizerHelperTest.cpp <https://github.com/llvm/llvm-project/blob/93b29d3882baf7df42e4e9bc26b977b00373ef56/llvm/unittests/CodeGen/GlobalISel/LegalizerHelperTest.cpp#L28-L57>`_; and perform a single step of the algorithm and check the result. The MIR and; FileCheck directives can be embedded using strings so you still have access to; the convenience available in llvm-lit. Debugging; ---------. One debugging technique that's proven particularly valuable is to use the; BlockExtractor to extract basic blocks into new functions. This can be used; to track down correctness bugs and can also be used to track down performance; regressions. It can also be coupled with function attributes to disable; GlobalISel for one or more of the extracted functions. .. image:: block-extract.png. The command to do the extraction is:. .. code-block:: shell. ./bin/llvm-extract -o - -S -b ‘foo:bb1;bb4’ <input> > extracted.ll. This particular example extracts two basic blocks from a function named ``foo``.; The new LLVM-IR can then be modified to add the ``failedISel`` attribute to the; extracted function containing bb4 to make that function use SelectionDAG. This can prevent some optimizations as GlobalISel is generally able to work on a; single function at a time. This technique can be repeated for different; combinations of basic blocks until you have identified the critical blocks; involved in a bug. Once the critical blocks have been identified, you can further increase the; resolution to the critical instructions by splitting the blocks like from:. .. code-block:: none. bb1:; ..",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst:5320,Availability,down,down,5320,"ze the current state; and test the behaviour between two points in the pipeline. The current state; can be serialized using ``-stop-before`` or ``-stop-after`` and loaded using; ``-start-before``, ``-start-after``, and ``-run-pass``. We can also go further still, as many of GlobalISel's passes are readily unit; testable:. .. image:: testing-unit-level.png. It's possible to create an imaginary target such as in `LegalizerHelperTest.cpp <https://github.com/llvm/llvm-project/blob/93b29d3882baf7df42e4e9bc26b977b00373ef56/llvm/unittests/CodeGen/GlobalISel/LegalizerHelperTest.cpp#L28-L57>`_; and perform a single step of the algorithm and check the result. The MIR and; FileCheck directives can be embedded using strings so you still have access to; the convenience available in llvm-lit. Debugging; ---------. One debugging technique that's proven particularly valuable is to use the; BlockExtractor to extract basic blocks into new functions. This can be used; to track down correctness bugs and can also be used to track down performance; regressions. It can also be coupled with function attributes to disable; GlobalISel for one or more of the extracted functions. .. image:: block-extract.png. The command to do the extraction is:. .. code-block:: shell. ./bin/llvm-extract -o - -S -b ‘foo:bb1;bb4’ <input> > extracted.ll. This particular example extracts two basic blocks from a function named ``foo``.; The new LLVM-IR can then be modified to add the ``failedISel`` attribute to the; extracted function containing bb4 to make that function use SelectionDAG. This can prevent some optimizations as GlobalISel is generally able to work on a; single function at a time. This technique can be repeated for different; combinations of basic blocks until you have identified the critical blocks; involved in a bug. Once the critical blocks have been identified, you can further increase the; resolution to the critical instructions by splitting the blocks like from:. .. code-block:: none. bb1:; ..",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst:6774,Availability,down,down,6774,"rectives can be embedded using strings so you still have access to; the convenience available in llvm-lit. Debugging; ---------. One debugging technique that's proven particularly valuable is to use the; BlockExtractor to extract basic blocks into new functions. This can be used; to track down correctness bugs and can also be used to track down performance; regressions. It can also be coupled with function attributes to disable; GlobalISel for one or more of the extracted functions. .. image:: block-extract.png. The command to do the extraction is:. .. code-block:: shell. ./bin/llvm-extract -o - -S -b ‘foo:bb1;bb4’ <input> > extracted.ll. This particular example extracts two basic blocks from a function named ``foo``.; The new LLVM-IR can then be modified to add the ``failedISel`` attribute to the; extracted function containing bb4 to make that function use SelectionDAG. This can prevent some optimizations as GlobalISel is generally able to work on a; single function at a time. This technique can be repeated for different; combinations of basic blocks until you have identified the critical blocks; involved in a bug. Once the critical blocks have been identified, you can further increase the; resolution to the critical instructions by splitting the blocks like from:. .. code-block:: none. bb1:; ... instructions group 1 ...; ... instructions group 2 ... into:. .. code-block:: none. bb1:; ... instructions group 1 ...; br %bb2. bb2:; ... instructions group 2 ... and then repeating the process for the new blocks. It's also possible to use this technique in a mode where the main function; is compiled with GlobalISel and the extracted basic blocks are compiled with; SelectionDAG (or the other way around) to leverage the existing quality of; another code generator to track down bugs. This technique can also be used to; improve the similarity between fast and slow code when tracking down performance; regressions and help you zero in on a particular cause of the regression.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst:6885,Availability,down,down,6885,"rectives can be embedded using strings so you still have access to; the convenience available in llvm-lit. Debugging; ---------. One debugging technique that's proven particularly valuable is to use the; BlockExtractor to extract basic blocks into new functions. This can be used; to track down correctness bugs and can also be used to track down performance; regressions. It can also be coupled with function attributes to disable; GlobalISel for one or more of the extracted functions. .. image:: block-extract.png. The command to do the extraction is:. .. code-block:: shell. ./bin/llvm-extract -o - -S -b ‘foo:bb1;bb4’ <input> > extracted.ll. This particular example extracts two basic blocks from a function named ``foo``.; The new LLVM-IR can then be modified to add the ``failedISel`` attribute to the; extracted function containing bb4 to make that function use SelectionDAG. This can prevent some optimizations as GlobalISel is generally able to work on a; single function at a time. This technique can be repeated for different; combinations of basic blocks until you have identified the critical blocks; involved in a bug. Once the critical blocks have been identified, you can further increase the; resolution to the critical instructions by splitting the blocks like from:. .. code-block:: none. bb1:; ... instructions group 1 ...; ... instructions group 2 ... into:. .. code-block:: none. bb1:; ... instructions group 1 ...; br %bb2. bb2:; ... instructions group 2 ... and then repeating the process for the new blocks. It's also possible to use this technique in a mode where the main function; is compiled with GlobalISel and the extracted basic blocks are compiled with; SelectionDAG (or the other way around) to leverage the existing quality of; another code generator to track down bugs. This technique can also be used to; improve the similarity between fast and slow code when tracking down performance; regressions and help you zero in on a particular cause of the regression.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst:137,Deployability,pipeline,pipeline,137,".. _pipeline:. Core Pipeline; =============. .. toctree::; :hidden:. IRTranslator; Legalizer; RegBankSelect; InstructionSelect. The core pipeline of GlobalISel is:. .. image:: pipeline-overview.png. The four passes shown in the diagram consist of:. :doc:`IRTranslator`. Converts :doc:`LLVM-IR <../LangRef>` into :doc:`gMIR (Generic MIR) <GMIR>`.; This is largely a direct translation and has little target customization.; It's somewhat analogous to SelectionDAGBuilder but builds a flavour of MIR; called gMIR instead of a specialized representation. gMIR uses exactly the; same data structures as MIR but has more relaxed constraints. For example,; a virtual register may be constrained to a particular type without also; constraining it to a specific register class. :doc:`Legalizer`. Replaces unsupported operations with supported ones. In other words, it shapes; the gMIR to suit what the backend can support. There is a very small set of; operations which targets are required to support but aside from that targets; can shape the MIR as they wish. :doc:`Register Bank Selector <RegBankSelect>`. Binds virtual registers to register banks. This pass is intended to minimize; cross-register-bank copies by clustering portions of the MIR together. :doc:`Instruction Select <InstructionSelect>`. Select target instructions using the gMIR. At this point, the gMIR has been; constrained enough that it becomes MIR. Although we tend to talk about them as distinct passes, it should be noted that; there's a good deal of flexibility here and it's ok for things to happen; earlier than described below. For example, it's not unusual for the legalizer to; legalize an intrinsic directly to a target instruction. The concrete; requirement is that the following additional constraints are preserved after; each of these passes:. IRTranslator. The representation must be gMIR, MIR, or a mixture of the two after this pass.; The majority will typically be gMIR to begin with but later passes will; gradually tr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst:176,Deployability,pipeline,pipeline-overview,176,".. _pipeline:. Core Pipeline; =============. .. toctree::; :hidden:. IRTranslator; Legalizer; RegBankSelect; InstructionSelect. The core pipeline of GlobalISel is:. .. image:: pipeline-overview.png. The four passes shown in the diagram consist of:. :doc:`IRTranslator`. Converts :doc:`LLVM-IR <../LangRef>` into :doc:`gMIR (Generic MIR) <GMIR>`.; This is largely a direct translation and has little target customization.; It's somewhat analogous to SelectionDAGBuilder but builds a flavour of MIR; called gMIR instead of a specialized representation. gMIR uses exactly the; same data structures as MIR but has more relaxed constraints. For example,; a virtual register may be constrained to a particular type without also; constraining it to a specific register class. :doc:`Legalizer`. Replaces unsupported operations with supported ones. In other words, it shapes; the gMIR to suit what the backend can support. There is a very small set of; operations which targets are required to support but aside from that targets; can shape the MIR as they wish. :doc:`Register Bank Selector <RegBankSelect>`. Binds virtual registers to register banks. This pass is intended to minimize; cross-register-bank copies by clustering portions of the MIR together. :doc:`Instruction Select <InstructionSelect>`. Select target instructions using the gMIR. At this point, the gMIR has been; constrained enough that it becomes MIR. Although we tend to talk about them as distinct passes, it should be noted that; there's a good deal of flexibility here and it's ok for things to happen; earlier than described below. For example, it's not unusual for the legalizer to; legalize an intrinsic directly to a target instruction. The concrete; requirement is that the following additional constraints are preserved after; each of these passes:. IRTranslator. The representation must be gMIR, MIR, or a mixture of the two after this pass.; The majority will typically be gMIR to begin with but later passes will; gradually tr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst:2840,Deployability,pipeline,pipeline,2840,"epresentation must be gMIR, MIR, or a mixture of the two after this pass.; The majority will typically be gMIR to begin with but later passes will; gradually transition the gMIR to MIR. Legalizer. No illegal operations must remain or be introduced after this pass. Register Bank Selector. All virtual registers must have a register bank assigned after this pass. Instruction Select. No gMIR must remain or be introduced after this pass. In other words, we must; have completed the conversion from gMIR to MIR. In addition to these passes, there are also some optional passes that perform; an optimization. The current optional passes are:. Combiner. Replaces patterns of instructions with a better alternative. Typically, this; means improving run time performance by replacing instructions with faster; alternatives but Combiners can also focus on code size or other metrics. Additional passes such as these can be inserted to support higher optimization; levels or target specific needs. A likely pipeline is:. .. image:: pipeline-overview-with-combiners.png. Of course, combiners can be inserted in other places too. Also passes can be; replaced entirely so long as their task is complete as shown in this (more; customized) example pipeline. .. image:: pipeline-overview-customized.png. .. _maintainability-verifier:. MachineVerifier; ---------------. The pass approach lets us use the ``MachineVerifier`` to enforce invariants; that are required beyond certain points of the pipeline. For example, a; function with the ``legalized`` property can have the ``MachineVerifier``; enforce that no illegal instructions occur. Similarly, a; ``regBankSelected`` function may not have virtual registers without a register; bank assigned. .. note::. For layering reasons, ``MachineVerifier`` isn't able to be the sole verifier; in GlobalISel. Currently some of the passes also perform verification while; we find a way to solve this problem. The main issue is that GlobalISel is a separate library, so we c",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst:2865,Deployability,pipeline,pipeline-overview-with-combiners,2865,"a mixture of the two after this pass.; The majority will typically be gMIR to begin with but later passes will; gradually transition the gMIR to MIR. Legalizer. No illegal operations must remain or be introduced after this pass. Register Bank Selector. All virtual registers must have a register bank assigned after this pass. Instruction Select. No gMIR must remain or be introduced after this pass. In other words, we must; have completed the conversion from gMIR to MIR. In addition to these passes, there are also some optional passes that perform; an optimization. The current optional passes are:. Combiner. Replaces patterns of instructions with a better alternative. Typically, this; means improving run time performance by replacing instructions with faster; alternatives but Combiners can also focus on code size or other metrics. Additional passes such as these can be inserted to support higher optimization; levels or target specific needs. A likely pipeline is:. .. image:: pipeline-overview-with-combiners.png. Of course, combiners can be inserted in other places too. Also passes can be; replaced entirely so long as their task is complete as shown in this (more; customized) example pipeline. .. image:: pipeline-overview-customized.png. .. _maintainability-verifier:. MachineVerifier; ---------------. The pass approach lets us use the ``MachineVerifier`` to enforce invariants; that are required beyond certain points of the pipeline. For example, a; function with the ``legalized`` property can have the ``MachineVerifier``; enforce that no illegal instructions occur. Similarly, a; ``regBankSelected`` function may not have virtual registers without a register; bank assigned. .. note::. For layering reasons, ``MachineVerifier`` isn't able to be the sole verifier; in GlobalISel. Currently some of the passes also perform verification while; we find a way to solve this problem. The main issue is that GlobalISel is a separate library, so we can't; directly reference it from Co",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst:3077,Deployability,pipeline,pipeline,3077,"IR. Legalizer. No illegal operations must remain or be introduced after this pass. Register Bank Selector. All virtual registers must have a register bank assigned after this pass. Instruction Select. No gMIR must remain or be introduced after this pass. In other words, we must; have completed the conversion from gMIR to MIR. In addition to these passes, there are also some optional passes that perform; an optimization. The current optional passes are:. Combiner. Replaces patterns of instructions with a better alternative. Typically, this; means improving run time performance by replacing instructions with faster; alternatives but Combiners can also focus on code size or other metrics. Additional passes such as these can be inserted to support higher optimization; levels or target specific needs. A likely pipeline is:. .. image:: pipeline-overview-with-combiners.png. Of course, combiners can be inserted in other places too. Also passes can be; replaced entirely so long as their task is complete as shown in this (more; customized) example pipeline. .. image:: pipeline-overview-customized.png. .. _maintainability-verifier:. MachineVerifier; ---------------. The pass approach lets us use the ``MachineVerifier`` to enforce invariants; that are required beyond certain points of the pipeline. For example, a; function with the ``legalized`` property can have the ``MachineVerifier``; enforce that no illegal instructions occur. Similarly, a; ``regBankSelected`` function may not have virtual registers without a register; bank assigned. .. note::. For layering reasons, ``MachineVerifier`` isn't able to be the sole verifier; in GlobalISel. Currently some of the passes also perform verification while; we find a way to solve this problem. The main issue is that GlobalISel is a separate library, so we can't; directly reference it from CodeGen. Testing; -------. The ability to test GlobalISel is significantly improved over SelectionDAG.; SelectionDAG is something of a black box and",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst:3098,Deployability,pipeline,pipeline-overview-customized,3098,"gister Bank Selector. All virtual registers must have a register bank assigned after this pass. Instruction Select. No gMIR must remain or be introduced after this pass. In other words, we must; have completed the conversion from gMIR to MIR. In addition to these passes, there are also some optional passes that perform; an optimization. The current optional passes are:. Combiner. Replaces patterns of instructions with a better alternative. Typically, this; means improving run time performance by replacing instructions with faster; alternatives but Combiners can also focus on code size or other metrics. Additional passes such as these can be inserted to support higher optimization; levels or target specific needs. A likely pipeline is:. .. image:: pipeline-overview-with-combiners.png. Of course, combiners can be inserted in other places too. Also passes can be; replaced entirely so long as their task is complete as shown in this (more; customized) example pipeline. .. image:: pipeline-overview-customized.png. .. _maintainability-verifier:. MachineVerifier; ---------------. The pass approach lets us use the ``MachineVerifier`` to enforce invariants; that are required beyond certain points of the pipeline. For example, a; function with the ``legalized`` property can have the ``MachineVerifier``; enforce that no illegal instructions occur. Similarly, a; ``regBankSelected`` function may not have virtual registers without a register; bank assigned. .. note::. For layering reasons, ``MachineVerifier`` isn't able to be the sole verifier; in GlobalISel. Currently some of the passes also perform verification while; we find a way to solve this problem. The main issue is that GlobalISel is a separate library, so we can't; directly reference it from CodeGen. Testing; -------. The ability to test GlobalISel is significantly improved over SelectionDAG.; SelectionDAG is something of a black box and there's a lot going on inside it.; This makes it difficult to write a test that reli",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst:3321,Deployability,pipeline,pipeline,3321,"ter this pass. In other words, we must; have completed the conversion from gMIR to MIR. In addition to these passes, there are also some optional passes that perform; an optimization. The current optional passes are:. Combiner. Replaces patterns of instructions with a better alternative. Typically, this; means improving run time performance by replacing instructions with faster; alternatives but Combiners can also focus on code size or other metrics. Additional passes such as these can be inserted to support higher optimization; levels or target specific needs. A likely pipeline is:. .. image:: pipeline-overview-with-combiners.png. Of course, combiners can be inserted in other places too. Also passes can be; replaced entirely so long as their task is complete as shown in this (more; customized) example pipeline. .. image:: pipeline-overview-customized.png. .. _maintainability-verifier:. MachineVerifier; ---------------. The pass approach lets us use the ``MachineVerifier`` to enforce invariants; that are required beyond certain points of the pipeline. For example, a; function with the ``legalized`` property can have the ``MachineVerifier``; enforce that no illegal instructions occur. Similarly, a; ``regBankSelected`` function may not have virtual registers without a register; bank assigned. .. note::. For layering reasons, ``MachineVerifier`` isn't able to be the sole verifier; in GlobalISel. Currently some of the passes also perform verification while; we find a way to solve this problem. The main issue is that GlobalISel is a separate library, so we can't; directly reference it from CodeGen. Testing; -------. The ability to test GlobalISel is significantly improved over SelectionDAG.; SelectionDAG is something of a black box and there's a lot going on inside it.; This makes it difficult to write a test that reliably tests a particular aspect; of its behaviour. For comparison, see the following diagram:. .. image:: testing-pass-level.png. Each of the grey boxes ind",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst:4366,Deployability,pipeline,pipeline,4366,"n points of the pipeline. For example, a; function with the ``legalized`` property can have the ``MachineVerifier``; enforce that no illegal instructions occur. Similarly, a; ``regBankSelected`` function may not have virtual registers without a register; bank assigned. .. note::. For layering reasons, ``MachineVerifier`` isn't able to be the sole verifier; in GlobalISel. Currently some of the passes also perform verification while; we find a way to solve this problem. The main issue is that GlobalISel is a separate library, so we can't; directly reference it from CodeGen. Testing; -------. The ability to test GlobalISel is significantly improved over SelectionDAG.; SelectionDAG is something of a black box and there's a lot going on inside it.; This makes it difficult to write a test that reliably tests a particular aspect; of its behaviour. For comparison, see the following diagram:. .. image:: testing-pass-level.png. Each of the grey boxes indicates an opportunity to serialize the current state; and test the behaviour between two points in the pipeline. The current state; can be serialized using ``-stop-before`` or ``-stop-after`` and loaded using; ``-start-before``, ``-start-after``, and ``-run-pass``. We can also go further still, as many of GlobalISel's passes are readily unit; testable:. .. image:: testing-unit-level.png. It's possible to create an imaginary target such as in `LegalizerHelperTest.cpp <https://github.com/llvm/llvm-project/blob/93b29d3882baf7df42e4e9bc26b977b00373ef56/llvm/unittests/CodeGen/GlobalISel/LegalizerHelperTest.cpp#L28-L57>`_; and perform a single step of the algorithm and check the result. The MIR and; FileCheck directives can be embedded using strings so you still have access to; the convenience available in llvm-lit. Debugging; ---------. One debugging technique that's proven particularly valuable is to use the; BlockExtractor to extract basic blocks into new functions. This can be used; to track down correctness bugs and can also be ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst:2421,Performance,perform,perform,2421,"it becomes MIR. Although we tend to talk about them as distinct passes, it should be noted that; there's a good deal of flexibility here and it's ok for things to happen; earlier than described below. For example, it's not unusual for the legalizer to; legalize an intrinsic directly to a target instruction. The concrete; requirement is that the following additional constraints are preserved after; each of these passes:. IRTranslator. The representation must be gMIR, MIR, or a mixture of the two after this pass.; The majority will typically be gMIR to begin with but later passes will; gradually transition the gMIR to MIR. Legalizer. No illegal operations must remain or be introduced after this pass. Register Bank Selector. All virtual registers must have a register bank assigned after this pass. Instruction Select. No gMIR must remain or be introduced after this pass. In other words, we must; have completed the conversion from gMIR to MIR. In addition to these passes, there are also some optional passes that perform; an optimization. The current optional passes are:. Combiner. Replaces patterns of instructions with a better alternative. Typically, this; means improving run time performance by replacing instructions with faster; alternatives but Combiners can also focus on code size or other metrics. Additional passes such as these can be inserted to support higher optimization; levels or target specific needs. A likely pipeline is:. .. image:: pipeline-overview-with-combiners.png. Of course, combiners can be inserted in other places too. Also passes can be; replaced entirely so long as their task is complete as shown in this (more; customized) example pipeline. .. image:: pipeline-overview-customized.png. .. _maintainability-verifier:. MachineVerifier; ---------------. The pass approach lets us use the ``MachineVerifier`` to enforce invariants; that are required beyond certain points of the pipeline. For example, a; function with the ``legalized`` property can have t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst:2433,Performance,optimiz,optimization,2433,"it becomes MIR. Although we tend to talk about them as distinct passes, it should be noted that; there's a good deal of flexibility here and it's ok for things to happen; earlier than described below. For example, it's not unusual for the legalizer to; legalize an intrinsic directly to a target instruction. The concrete; requirement is that the following additional constraints are preserved after; each of these passes:. IRTranslator. The representation must be gMIR, MIR, or a mixture of the two after this pass.; The majority will typically be gMIR to begin with but later passes will; gradually transition the gMIR to MIR. Legalizer. No illegal operations must remain or be introduced after this pass. Register Bank Selector. All virtual registers must have a register bank assigned after this pass. Instruction Select. No gMIR must remain or be introduced after this pass. In other words, we must; have completed the conversion from gMIR to MIR. In addition to these passes, there are also some optional passes that perform; an optimization. The current optional passes are:. Combiner. Replaces patterns of instructions with a better alternative. Typically, this; means improving run time performance by replacing instructions with faster; alternatives but Combiners can also focus on code size or other metrics. Additional passes such as these can be inserted to support higher optimization; levels or target specific needs. A likely pipeline is:. .. image:: pipeline-overview-with-combiners.png. Of course, combiners can be inserted in other places too. Also passes can be; replaced entirely so long as their task is complete as shown in this (more; customized) example pipeline. .. image:: pipeline-overview-customized.png. .. _maintainability-verifier:. MachineVerifier; ---------------. The pass approach lets us use the ``MachineVerifier`` to enforce invariants; that are required beyond certain points of the pipeline. For example, a; function with the ``legalized`` property can have t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst:2594,Performance,perform,performance,2594,"he legalizer to; legalize an intrinsic directly to a target instruction. The concrete; requirement is that the following additional constraints are preserved after; each of these passes:. IRTranslator. The representation must be gMIR, MIR, or a mixture of the two after this pass.; The majority will typically be gMIR to begin with but later passes will; gradually transition the gMIR to MIR. Legalizer. No illegal operations must remain or be introduced after this pass. Register Bank Selector. All virtual registers must have a register bank assigned after this pass. Instruction Select. No gMIR must remain or be introduced after this pass. In other words, we must; have completed the conversion from gMIR to MIR. In addition to these passes, there are also some optional passes that perform; an optimization. The current optional passes are:. Combiner. Replaces patterns of instructions with a better alternative. Typically, this; means improving run time performance by replacing instructions with faster; alternatives but Combiners can also focus on code size or other metrics. Additional passes such as these can be inserted to support higher optimization; levels or target specific needs. A likely pipeline is:. .. image:: pipeline-overview-with-combiners.png. Of course, combiners can be inserted in other places too. Also passes can be; replaced entirely so long as their task is complete as shown in this (more; customized) example pipeline. .. image:: pipeline-overview-customized.png. .. _maintainability-verifier:. MachineVerifier; ---------------. The pass approach lets us use the ``MachineVerifier`` to enforce invariants; that are required beyond certain points of the pipeline. For example, a; function with the ``legalized`` property can have the ``MachineVerifier``; enforce that no illegal instructions occur. Similarly, a; ``regBankSelected`` function may not have virtual registers without a register; bank assigned. .. note::. For layering reasons, ``MachineVerifier`` isn't ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst:2784,Performance,optimiz,optimization,2784,"ints are preserved after; each of these passes:. IRTranslator. The representation must be gMIR, MIR, or a mixture of the two after this pass.; The majority will typically be gMIR to begin with but later passes will; gradually transition the gMIR to MIR. Legalizer. No illegal operations must remain or be introduced after this pass. Register Bank Selector. All virtual registers must have a register bank assigned after this pass. Instruction Select. No gMIR must remain or be introduced after this pass. In other words, we must; have completed the conversion from gMIR to MIR. In addition to these passes, there are also some optional passes that perform; an optimization. The current optional passes are:. Combiner. Replaces patterns of instructions with a better alternative. Typically, this; means improving run time performance by replacing instructions with faster; alternatives but Combiners can also focus on code size or other metrics. Additional passes such as these can be inserted to support higher optimization; levels or target specific needs. A likely pipeline is:. .. image:: pipeline-overview-with-combiners.png. Of course, combiners can be inserted in other places too. Also passes can be; replaced entirely so long as their task is complete as shown in this (more; customized) example pipeline. .. image:: pipeline-overview-customized.png. .. _maintainability-verifier:. MachineVerifier; ---------------. The pass approach lets us use the ``MachineVerifier`` to enforce invariants; that are required beyond certain points of the pipeline. For example, a; function with the ``legalized`` property can have the ``MachineVerifier``; enforce that no illegal instructions occur. Similarly, a; ``regBankSelected`` function may not have virtual registers without a register; bank assigned. .. note::. For layering reasons, ``MachineVerifier`` isn't able to be the sole verifier; in GlobalISel. Currently some of the passes also perform verification while; we find a way to solve this probl",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst:3713,Performance,perform,perform,3713,"l passes such as these can be inserted to support higher optimization; levels or target specific needs. A likely pipeline is:. .. image:: pipeline-overview-with-combiners.png. Of course, combiners can be inserted in other places too. Also passes can be; replaced entirely so long as their task is complete as shown in this (more; customized) example pipeline. .. image:: pipeline-overview-customized.png. .. _maintainability-verifier:. MachineVerifier; ---------------. The pass approach lets us use the ``MachineVerifier`` to enforce invariants; that are required beyond certain points of the pipeline. For example, a; function with the ``legalized`` property can have the ``MachineVerifier``; enforce that no illegal instructions occur. Similarly, a; ``regBankSelected`` function may not have virtual registers without a register; bank assigned. .. note::. For layering reasons, ``MachineVerifier`` isn't able to be the sole verifier; in GlobalISel. Currently some of the passes also perform verification while; we find a way to solve this problem. The main issue is that GlobalISel is a separate library, so we can't; directly reference it from CodeGen. Testing; -------. The ability to test GlobalISel is significantly improved over SelectionDAG.; SelectionDAG is something of a black box and there's a lot going on inside it.; This makes it difficult to write a test that reliably tests a particular aspect; of its behaviour. For comparison, see the following diagram:. .. image:: testing-pass-level.png. Each of the grey boxes indicates an opportunity to serialize the current state; and test the behaviour between two points in the pipeline. The current state; can be serialized using ``-stop-before`` or ``-stop-after`` and loaded using; ``-start-before``, ``-start-after``, and ``-run-pass``. We can also go further still, as many of GlobalISel's passes are readily unit; testable:. .. image:: testing-unit-level.png. It's possible to create an imaginary target such as in `LegalizerHelperTes",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst:4459,Performance,load,loaded,4459,"uctions occur. Similarly, a; ``regBankSelected`` function may not have virtual registers without a register; bank assigned. .. note::. For layering reasons, ``MachineVerifier`` isn't able to be the sole verifier; in GlobalISel. Currently some of the passes also perform verification while; we find a way to solve this problem. The main issue is that GlobalISel is a separate library, so we can't; directly reference it from CodeGen. Testing; -------. The ability to test GlobalISel is significantly improved over SelectionDAG.; SelectionDAG is something of a black box and there's a lot going on inside it.; This makes it difficult to write a test that reliably tests a particular aspect; of its behaviour. For comparison, see the following diagram:. .. image:: testing-pass-level.png. Each of the grey boxes indicates an opportunity to serialize the current state; and test the behaviour between two points in the pipeline. The current state; can be serialized using ``-stop-before`` or ``-stop-after`` and loaded using; ``-start-before``, ``-start-after``, and ``-run-pass``. We can also go further still, as many of GlobalISel's passes are readily unit; testable:. .. image:: testing-unit-level.png. It's possible to create an imaginary target such as in `LegalizerHelperTest.cpp <https://github.com/llvm/llvm-project/blob/93b29d3882baf7df42e4e9bc26b977b00373ef56/llvm/unittests/CodeGen/GlobalISel/LegalizerHelperTest.cpp#L28-L57>`_; and perform a single step of the algorithm and check the result. The MIR and; FileCheck directives can be embedded using strings so you still have access to; the convenience available in llvm-lit. Debugging; ---------. One debugging technique that's proven particularly valuable is to use the; BlockExtractor to extract basic blocks into new functions. This can be used; to track down correctness bugs and can also be used to track down performance; regressions. It can also be coupled with function attributes to disable; GlobalISel for one or more of the extract",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst:4892,Performance,perform,perform,4892,"y to test GlobalISel is significantly improved over SelectionDAG.; SelectionDAG is something of a black box and there's a lot going on inside it.; This makes it difficult to write a test that reliably tests a particular aspect; of its behaviour. For comparison, see the following diagram:. .. image:: testing-pass-level.png. Each of the grey boxes indicates an opportunity to serialize the current state; and test the behaviour between two points in the pipeline. The current state; can be serialized using ``-stop-before`` or ``-stop-after`` and loaded using; ``-start-before``, ``-start-after``, and ``-run-pass``. We can also go further still, as many of GlobalISel's passes are readily unit; testable:. .. image:: testing-unit-level.png. It's possible to create an imaginary target such as in `LegalizerHelperTest.cpp <https://github.com/llvm/llvm-project/blob/93b29d3882baf7df42e4e9bc26b977b00373ef56/llvm/unittests/CodeGen/GlobalISel/LegalizerHelperTest.cpp#L28-L57>`_; and perform a single step of the algorithm and check the result. The MIR and; FileCheck directives can be embedded using strings so you still have access to; the convenience available in llvm-lit. Debugging; ---------. One debugging technique that's proven particularly valuable is to use the; BlockExtractor to extract basic blocks into new functions. This can be used; to track down correctness bugs and can also be used to track down performance; regressions. It can also be coupled with function attributes to disable; GlobalISel for one or more of the extracted functions. .. image:: block-extract.png. The command to do the extraction is:. .. code-block:: shell. ./bin/llvm-extract -o - -S -b ‘foo:bb1;bb4’ <input> > extracted.ll. This particular example extracts two basic blocks from a function named ``foo``.; The new LLVM-IR can then be modified to add the ``failedISel`` attribute to the; extracted function containing bb4 to make that function use SelectionDAG. This can prevent some optimizations as GlobalISel ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst:5325,Performance,perform,performance,5325,"ze the current state; and test the behaviour between two points in the pipeline. The current state; can be serialized using ``-stop-before`` or ``-stop-after`` and loaded using; ``-start-before``, ``-start-after``, and ``-run-pass``. We can also go further still, as many of GlobalISel's passes are readily unit; testable:. .. image:: testing-unit-level.png. It's possible to create an imaginary target such as in `LegalizerHelperTest.cpp <https://github.com/llvm/llvm-project/blob/93b29d3882baf7df42e4e9bc26b977b00373ef56/llvm/unittests/CodeGen/GlobalISel/LegalizerHelperTest.cpp#L28-L57>`_; and perform a single step of the algorithm and check the result. The MIR and; FileCheck directives can be embedded using strings so you still have access to; the convenience available in llvm-lit. Debugging; ---------. One debugging technique that's proven particularly valuable is to use the; BlockExtractor to extract basic blocks into new functions. This can be used; to track down correctness bugs and can also be used to track down performance; regressions. It can also be coupled with function attributes to disable; GlobalISel for one or more of the extracted functions. .. image:: block-extract.png. The command to do the extraction is:. .. code-block:: shell. ./bin/llvm-extract -o - -S -b ‘foo:bb1;bb4’ <input> > extracted.ll. This particular example extracts two basic blocks from a function named ``foo``.; The new LLVM-IR can then be modified to add the ``failedISel`` attribute to the; extracted function containing bb4 to make that function use SelectionDAG. This can prevent some optimizations as GlobalISel is generally able to work on a; single function at a time. This technique can be repeated for different; combinations of basic blocks until you have identified the critical blocks; involved in a bug. Once the critical blocks have been identified, you can further increase the; resolution to the critical instructions by splitting the blocks like from:. .. code-block:: none. bb1:; ..",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst:5884,Performance,optimiz,optimizations,5884,"f the algorithm and check the result. The MIR and; FileCheck directives can be embedded using strings so you still have access to; the convenience available in llvm-lit. Debugging; ---------. One debugging technique that's proven particularly valuable is to use the; BlockExtractor to extract basic blocks into new functions. This can be used; to track down correctness bugs and can also be used to track down performance; regressions. It can also be coupled with function attributes to disable; GlobalISel for one or more of the extracted functions. .. image:: block-extract.png. The command to do the extraction is:. .. code-block:: shell. ./bin/llvm-extract -o - -S -b ‘foo:bb1;bb4’ <input> > extracted.ll. This particular example extracts two basic blocks from a function named ``foo``.; The new LLVM-IR can then be modified to add the ``failedISel`` attribute to the; extracted function containing bb4 to make that function use SelectionDAG. This can prevent some optimizations as GlobalISel is generally able to work on a; single function at a time. This technique can be repeated for different; combinations of basic blocks until you have identified the critical blocks; involved in a bug. Once the critical blocks have been identified, you can further increase the; resolution to the critical instructions by splitting the blocks like from:. .. code-block:: none. bb1:; ... instructions group 1 ...; ... instructions group 2 ... into:. .. code-block:: none. bb1:; ... instructions group 1 ...; br %bb2. bb2:; ... instructions group 2 ... and then repeating the process for the new blocks. It's also possible to use this technique in a mode where the main function; is compiled with GlobalISel and the extracted basic blocks are compiled with; SelectionDAG (or the other way around) to leverage the existing quality of; another code generator to track down bugs. This technique can also be used to; improve the similarity between fast and slow code when tracking down performance; regressions a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst:6890,Performance,perform,performance,6890,"rectives can be embedded using strings so you still have access to; the convenience available in llvm-lit. Debugging; ---------. One debugging technique that's proven particularly valuable is to use the; BlockExtractor to extract basic blocks into new functions. This can be used; to track down correctness bugs and can also be used to track down performance; regressions. It can also be coupled with function attributes to disable; GlobalISel for one or more of the extracted functions. .. image:: block-extract.png. The command to do the extraction is:. .. code-block:: shell. ./bin/llvm-extract -o - -S -b ‘foo:bb1;bb4’ <input> > extracted.ll. This particular example extracts two basic blocks from a function named ``foo``.; The new LLVM-IR can then be modified to add the ``failedISel`` attribute to the; extracted function containing bb4 to make that function use SelectionDAG. This can prevent some optimizations as GlobalISel is generally able to work on a; single function at a time. This technique can be repeated for different; combinations of basic blocks until you have identified the critical blocks; involved in a bug. Once the critical blocks have been identified, you can further increase the; resolution to the critical instructions by splitting the blocks like from:. .. code-block:: none. bb1:; ... instructions group 1 ...; ... instructions group 2 ... into:. .. code-block:: none. bb1:; ... instructions group 1 ...; br %bb2. bb2:; ... instructions group 2 ... and then repeating the process for the new blocks. It's also possible to use this technique in a mode where the main function; is compiled with GlobalISel and the extracted basic blocks are compiled with; SelectionDAG (or the other way around) to leverage the existing quality of; another code generator to track down bugs. This technique can also be used to; improve the similarity between fast and slow code when tracking down performance; regressions and help you zero in on a particular cause of the regression.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst:5035,Security,access,access,5035,"x and there's a lot going on inside it.; This makes it difficult to write a test that reliably tests a particular aspect; of its behaviour. For comparison, see the following diagram:. .. image:: testing-pass-level.png. Each of the grey boxes indicates an opportunity to serialize the current state; and test the behaviour between two points in the pipeline. The current state; can be serialized using ``-stop-before`` or ``-stop-after`` and loaded using; ``-start-before``, ``-start-after``, and ``-run-pass``. We can also go further still, as many of GlobalISel's passes are readily unit; testable:. .. image:: testing-unit-level.png. It's possible to create an imaginary target such as in `LegalizerHelperTest.cpp <https://github.com/llvm/llvm-project/blob/93b29d3882baf7df42e4e9bc26b977b00373ef56/llvm/unittests/CodeGen/GlobalISel/LegalizerHelperTest.cpp#L28-L57>`_; and perform a single step of the algorithm and check the result. The MIR and; FileCheck directives can be embedded using strings so you still have access to; the convenience available in llvm-lit. Debugging; ---------. One debugging technique that's proven particularly valuable is to use the; BlockExtractor to extract basic blocks into new functions. This can be used; to track down correctness bugs and can also be used to track down performance; regressions. It can also be coupled with function attributes to disable; GlobalISel for one or more of the extracted functions. .. image:: block-extract.png. The command to do the extraction is:. .. code-block:: shell. ./bin/llvm-extract -o - -S -b ‘foo:bb1;bb4’ <input> > extracted.ll. This particular example extracts two basic blocks from a function named ``foo``.; The new LLVM-IR can then be modified to add the ``failedISel`` attribute to the; extracted function containing bb4 to make that function use SelectionDAG. This can prevent some optimizations as GlobalISel is generally able to work on a; single function at a time. This technique can be repeated for different; c",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst:3917,Testability,test,test,3917," in other places too. Also passes can be; replaced entirely so long as their task is complete as shown in this (more; customized) example pipeline. .. image:: pipeline-overview-customized.png. .. _maintainability-verifier:. MachineVerifier; ---------------. The pass approach lets us use the ``MachineVerifier`` to enforce invariants; that are required beyond certain points of the pipeline. For example, a; function with the ``legalized`` property can have the ``MachineVerifier``; enforce that no illegal instructions occur. Similarly, a; ``regBankSelected`` function may not have virtual registers without a register; bank assigned. .. note::. For layering reasons, ``MachineVerifier`` isn't able to be the sole verifier; in GlobalISel. Currently some of the passes also perform verification while; we find a way to solve this problem. The main issue is that GlobalISel is a separate library, so we can't; directly reference it from CodeGen. Testing; -------. The ability to test GlobalISel is significantly improved over SelectionDAG.; SelectionDAG is something of a black box and there's a lot going on inside it.; This makes it difficult to write a test that reliably tests a particular aspect; of its behaviour. For comparison, see the following diagram:. .. image:: testing-pass-level.png. Each of the grey boxes indicates an opportunity to serialize the current state; and test the behaviour between two points in the pipeline. The current state; can be serialized using ``-stop-before`` or ``-stop-after`` and loaded using; ``-start-before``, ``-start-after``, and ``-run-pass``. We can also go further still, as many of GlobalISel's passes are readily unit; testable:. .. image:: testing-unit-level.png. It's possible to create an imaginary target such as in `LegalizerHelperTest.cpp <https://github.com/llvm/llvm-project/blob/93b29d3882baf7df42e4e9bc26b977b00373ef56/llvm/unittests/CodeGen/GlobalISel/LegalizerHelperTest.cpp#L28-L57>`_; and perform a single step of the algorithm and chec",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst:4094,Testability,test,test,4094,"overview-customized.png. .. _maintainability-verifier:. MachineVerifier; ---------------. The pass approach lets us use the ``MachineVerifier`` to enforce invariants; that are required beyond certain points of the pipeline. For example, a; function with the ``legalized`` property can have the ``MachineVerifier``; enforce that no illegal instructions occur. Similarly, a; ``regBankSelected`` function may not have virtual registers without a register; bank assigned. .. note::. For layering reasons, ``MachineVerifier`` isn't able to be the sole verifier; in GlobalISel. Currently some of the passes also perform verification while; we find a way to solve this problem. The main issue is that GlobalISel is a separate library, so we can't; directly reference it from CodeGen. Testing; -------. The ability to test GlobalISel is significantly improved over SelectionDAG.; SelectionDAG is something of a black box and there's a lot going on inside it.; This makes it difficult to write a test that reliably tests a particular aspect; of its behaviour. For comparison, see the following diagram:. .. image:: testing-pass-level.png. Each of the grey boxes indicates an opportunity to serialize the current state; and test the behaviour between two points in the pipeline. The current state; can be serialized using ``-stop-before`` or ``-stop-after`` and loaded using; ``-start-before``, ``-start-after``, and ``-run-pass``. We can also go further still, as many of GlobalISel's passes are readily unit; testable:. .. image:: testing-unit-level.png. It's possible to create an imaginary target such as in `LegalizerHelperTest.cpp <https://github.com/llvm/llvm-project/blob/93b29d3882baf7df42e4e9bc26b977b00373ef56/llvm/unittests/CodeGen/GlobalISel/LegalizerHelperTest.cpp#L28-L57>`_; and perform a single step of the algorithm and check the result. The MIR and; FileCheck directives can be embedded using strings so you still have access to; the convenience available in llvm-lit. Debugging; ---------. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst:4113,Testability,test,tests,4113,"overview-customized.png. .. _maintainability-verifier:. MachineVerifier; ---------------. The pass approach lets us use the ``MachineVerifier`` to enforce invariants; that are required beyond certain points of the pipeline. For example, a; function with the ``legalized`` property can have the ``MachineVerifier``; enforce that no illegal instructions occur. Similarly, a; ``regBankSelected`` function may not have virtual registers without a register; bank assigned. .. note::. For layering reasons, ``MachineVerifier`` isn't able to be the sole verifier; in GlobalISel. Currently some of the passes also perform verification while; we find a way to solve this problem. The main issue is that GlobalISel is a separate library, so we can't; directly reference it from CodeGen. Testing; -------. The ability to test GlobalISel is significantly improved over SelectionDAG.; SelectionDAG is something of a black box and there's a lot going on inside it.; This makes it difficult to write a test that reliably tests a particular aspect; of its behaviour. For comparison, see the following diagram:. .. image:: testing-pass-level.png. Each of the grey boxes indicates an opportunity to serialize the current state; and test the behaviour between two points in the pipeline. The current state; can be serialized using ``-stop-before`` or ``-stop-after`` and loaded using; ``-start-before``, ``-start-after``, and ``-run-pass``. We can also go further still, as many of GlobalISel's passes are readily unit; testable:. .. image:: testing-unit-level.png. It's possible to create an imaginary target such as in `LegalizerHelperTest.cpp <https://github.com/llvm/llvm-project/blob/93b29d3882baf7df42e4e9bc26b977b00373ef56/llvm/unittests/CodeGen/GlobalISel/LegalizerHelperTest.cpp#L28-L57>`_; and perform a single step of the algorithm and check the result. The MIR and; FileCheck directives can be embedded using strings so you still have access to; the convenience available in llvm-lit. Debugging; ---------. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst:4213,Testability,test,testing-pass-level,4213,"s us use the ``MachineVerifier`` to enforce invariants; that are required beyond certain points of the pipeline. For example, a; function with the ``legalized`` property can have the ``MachineVerifier``; enforce that no illegal instructions occur. Similarly, a; ``regBankSelected`` function may not have virtual registers without a register; bank assigned. .. note::. For layering reasons, ``MachineVerifier`` isn't able to be the sole verifier; in GlobalISel. Currently some of the passes also perform verification while; we find a way to solve this problem. The main issue is that GlobalISel is a separate library, so we can't; directly reference it from CodeGen. Testing; -------. The ability to test GlobalISel is significantly improved over SelectionDAG.; SelectionDAG is something of a black box and there's a lot going on inside it.; This makes it difficult to write a test that reliably tests a particular aspect; of its behaviour. For comparison, see the following diagram:. .. image:: testing-pass-level.png. Each of the grey boxes indicates an opportunity to serialize the current state; and test the behaviour between two points in the pipeline. The current state; can be serialized using ``-stop-before`` or ``-stop-after`` and loaded using; ``-start-before``, ``-start-after``, and ``-run-pass``. We can also go further still, as many of GlobalISel's passes are readily unit; testable:. .. image:: testing-unit-level.png. It's possible to create an imaginary target such as in `LegalizerHelperTest.cpp <https://github.com/llvm/llvm-project/blob/93b29d3882baf7df42e4e9bc26b977b00373ef56/llvm/unittests/CodeGen/GlobalISel/LegalizerHelperTest.cpp#L28-L57>`_; and perform a single step of the algorithm and check the result. The MIR and; FileCheck directives can be embedded using strings so you still have access to; the convenience available in llvm-lit. Debugging; ---------. One debugging technique that's proven particularly valuable is to use the; BlockExtractor to extract basic bloc",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst:4321,Testability,test,test,4321,"n points of the pipeline. For example, a; function with the ``legalized`` property can have the ``MachineVerifier``; enforce that no illegal instructions occur. Similarly, a; ``regBankSelected`` function may not have virtual registers without a register; bank assigned. .. note::. For layering reasons, ``MachineVerifier`` isn't able to be the sole verifier; in GlobalISel. Currently some of the passes also perform verification while; we find a way to solve this problem. The main issue is that GlobalISel is a separate library, so we can't; directly reference it from CodeGen. Testing; -------. The ability to test GlobalISel is significantly improved over SelectionDAG.; SelectionDAG is something of a black box and there's a lot going on inside it.; This makes it difficult to write a test that reliably tests a particular aspect; of its behaviour. For comparison, see the following diagram:. .. image:: testing-pass-level.png. Each of the grey boxes indicates an opportunity to serialize the current state; and test the behaviour between two points in the pipeline. The current state; can be serialized using ``-stop-before`` or ``-stop-after`` and loaded using; ``-start-before``, ``-start-after``, and ``-run-pass``. We can also go further still, as many of GlobalISel's passes are readily unit; testable:. .. image:: testing-unit-level.png. It's possible to create an imaginary target such as in `LegalizerHelperTest.cpp <https://github.com/llvm/llvm-project/blob/93b29d3882baf7df42e4e9bc26b977b00373ef56/llvm/unittests/CodeGen/GlobalISel/LegalizerHelperTest.cpp#L28-L57>`_; and perform a single step of the algorithm and check the result. The MIR and; FileCheck directives can be embedded using strings so you still have access to; the convenience available in llvm-lit. Debugging; ---------. One debugging technique that's proven particularly valuable is to use the; BlockExtractor to extract basic blocks into new functions. This can be used; to track down correctness bugs and can also be ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst:4608,Testability,test,testable,4608,". .. note::. For layering reasons, ``MachineVerifier`` isn't able to be the sole verifier; in GlobalISel. Currently some of the passes also perform verification while; we find a way to solve this problem. The main issue is that GlobalISel is a separate library, so we can't; directly reference it from CodeGen. Testing; -------. The ability to test GlobalISel is significantly improved over SelectionDAG.; SelectionDAG is something of a black box and there's a lot going on inside it.; This makes it difficult to write a test that reliably tests a particular aspect; of its behaviour. For comparison, see the following diagram:. .. image:: testing-pass-level.png. Each of the grey boxes indicates an opportunity to serialize the current state; and test the behaviour between two points in the pipeline. The current state; can be serialized using ``-stop-before`` or ``-stop-after`` and loaded using; ``-start-before``, ``-start-after``, and ``-run-pass``. We can also go further still, as many of GlobalISel's passes are readily unit; testable:. .. image:: testing-unit-level.png. It's possible to create an imaginary target such as in `LegalizerHelperTest.cpp <https://github.com/llvm/llvm-project/blob/93b29d3882baf7df42e4e9bc26b977b00373ef56/llvm/unittests/CodeGen/GlobalISel/LegalizerHelperTest.cpp#L28-L57>`_; and perform a single step of the algorithm and check the result. The MIR and; FileCheck directives can be embedded using strings so you still have access to; the convenience available in llvm-lit. Debugging; ---------. One debugging technique that's proven particularly valuable is to use the; BlockExtractor to extract basic blocks into new functions. This can be used; to track down correctness bugs and can also be used to track down performance; regressions. It can also be coupled with function attributes to disable; GlobalISel for one or more of the extracted functions. .. image:: block-extract.png. The command to do the extraction is:. .. code-block:: shell. ./bin/llvm-extra",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst:4630,Testability,test,testing-unit-level,4630,"ble to be the sole verifier; in GlobalISel. Currently some of the passes also perform verification while; we find a way to solve this problem. The main issue is that GlobalISel is a separate library, so we can't; directly reference it from CodeGen. Testing; -------. The ability to test GlobalISel is significantly improved over SelectionDAG.; SelectionDAG is something of a black box and there's a lot going on inside it.; This makes it difficult to write a test that reliably tests a particular aspect; of its behaviour. For comparison, see the following diagram:. .. image:: testing-pass-level.png. Each of the grey boxes indicates an opportunity to serialize the current state; and test the behaviour between two points in the pipeline. The current state; can be serialized using ``-stop-before`` or ``-stop-after`` and loaded using; ``-start-before``, ``-start-after``, and ``-run-pass``. We can also go further still, as many of GlobalISel's passes are readily unit; testable:. .. image:: testing-unit-level.png. It's possible to create an imaginary target such as in `LegalizerHelperTest.cpp <https://github.com/llvm/llvm-project/blob/93b29d3882baf7df42e4e9bc26b977b00373ef56/llvm/unittests/CodeGen/GlobalISel/LegalizerHelperTest.cpp#L28-L57>`_; and perform a single step of the algorithm and check the result. The MIR and; FileCheck directives can be embedded using strings so you still have access to; the convenience available in llvm-lit. Debugging; ---------. One debugging technique that's proven particularly valuable is to use the; BlockExtractor to extract basic blocks into new functions. This can be used; to track down correctness bugs and can also be used to track down performance; regressions. It can also be coupled with function attributes to disable; GlobalISel for one or more of the extracted functions. .. image:: block-extract.png. The command to do the extraction is:. .. code-block:: shell. ./bin/llvm-extract -o - -S -b ‘foo:bb1;bb4’ <input> > extracted.ll. This parti",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Pipeline.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Porting.rst:717,Deployability,pipeline,pipeline,717,".. _porting:. Porting GlobalISel to A New Target; ==================================. There are four major classes to implement by the target:. * :ref:`CallLowering <translator-call-lower>` --- lower calls, returns, and; arguments according to the ABI.; * :ref:`RegisterBankInfo <api-registerbankinfo>` --- describe; :ref:`gmir-regbank` coverage, cross-bank copy cost, and the mapping of; operands onto banks for each instruction.; * :ref:`LegalizerInfo <api-legalizerinfo>` --- describe what is legal, and how; to legalize what isn't.; * :ref:`InstructionSelector <api-instructionselector>` --- select generic MIR; to target-specific MIR. Additionally:. * ``TargetPassConfig`` --- create the passes constituting the pipeline,; including additional passes not included in the :ref:`pipeline`. Tutorials; =========. We'd recommend watching `this tutorial; <https://www.llvm.org/devmtg/2017-10/#tutorial2>`_ from the 2017 LLVM DevMeeting; which gave an overview of how to bring up a new backend in GlobalISel.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/Porting.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Porting.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Porting.rst:782,Deployability,pipeline,pipeline,782,".. _porting:. Porting GlobalISel to A New Target; ==================================. There are four major classes to implement by the target:. * :ref:`CallLowering <translator-call-lower>` --- lower calls, returns, and; arguments according to the ABI.; * :ref:`RegisterBankInfo <api-registerbankinfo>` --- describe; :ref:`gmir-regbank` coverage, cross-bank copy cost, and the mapping of; operands onto banks for each instruction.; * :ref:`LegalizerInfo <api-legalizerinfo>` --- describe what is legal, and how; to legalize what isn't.; * :ref:`InstructionSelector <api-instructionselector>` --- select generic MIR; to target-specific MIR. Additionally:. * ``TargetPassConfig`` --- create the passes constituting the pipeline,; including additional passes not included in the :ref:`pipeline`. Tutorials; =========. We'd recommend watching `this tutorial; <https://www.llvm.org/devmtg/2017-10/#tutorial2>`_ from the 2017 LLVM DevMeeting; which gave an overview of how to bring up a new backend in GlobalISel.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/Porting.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/Porting.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/RegBankSelect.rst:470,Availability,down,down,470,".. _regbankselect:. RegBankSelect; -------------. This pass constrains the :ref:`gmir-gvregs` operands of generic; instructions to some :ref:`gmir-regbank`. It iteratively maps instructions to a set of per-operand bank assignment.; The possible mappings are determined by the target-provided; :ref:`RegisterBankInfo <api-registerbankinfo>`.; The mapping is then applied, possibly introducing ``COPY`` instructions if; necessary. It traverses the ``MachineFunction`` top down so that all operands are already; mapped when analyzing an instruction. This pass could also remap target-specific instructions when beneficial.; In the future, this could replace the ExeDepsFix pass, as we can directly; select the best variant for an instruction that's available on multiple banks. .. _api-registerbankinfo:. API: RegisterBankInfo; ^^^^^^^^^^^^^^^^^^^^^. The ``RegisterBankInfo`` class describes multiple aspects of register banks. * **Banks**: ``addRegBankCoverage`` --- which register bank covers each; register class. * **Cross-Bank Copies**: ``copyCost`` --- the cost of a ``COPY`` from one bank; to another. * **Default Mapping**: ``getInstrMapping`` --- the default bank assignments for; a given instruction. * **Alternative Mapping**: ``getInstrAlternativeMapping`` --- the other; possible bank assignments for a given instruction. ``TODO``:; All this information should eventually be static and generated by TableGen,; mostly using existing information augmented by bank descriptions. ``TODO``:; ``getInstrMapping`` is currently separate from ``getInstrAlternativeMapping``; because the latter is more expensive: as we move to static mapping info,; both methods should be free, and we should merge them. .. _regbankselect-modes:. RegBankSelect Modes; ^^^^^^^^^^^^^^^^^^^. ``RegBankSelect`` currently has two modes:. * **Fast** --- For each instruction, pick a target-provided ""default"" bank; assignment. This is the default at -O0. * **Greedy** --- For each instruction, pick the cheapest of several;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/RegBankSelect.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/RegBankSelect.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/RegBankSelect.rst:746,Availability,avail,available,746,".. _regbankselect:. RegBankSelect; -------------. This pass constrains the :ref:`gmir-gvregs` operands of generic; instructions to some :ref:`gmir-regbank`. It iteratively maps instructions to a set of per-operand bank assignment.; The possible mappings are determined by the target-provided; :ref:`RegisterBankInfo <api-registerbankinfo>`.; The mapping is then applied, possibly introducing ``COPY`` instructions if; necessary. It traverses the ``MachineFunction`` top down so that all operands are already; mapped when analyzing an instruction. This pass could also remap target-specific instructions when beneficial.; In the future, this could replace the ExeDepsFix pass, as we can directly; select the best variant for an instruction that's available on multiple banks. .. _api-registerbankinfo:. API: RegisterBankInfo; ^^^^^^^^^^^^^^^^^^^^^. The ``RegisterBankInfo`` class describes multiple aspects of register banks. * **Banks**: ``addRegBankCoverage`` --- which register bank covers each; register class. * **Cross-Bank Copies**: ``copyCost`` --- the cost of a ``COPY`` from one bank; to another. * **Default Mapping**: ``getInstrMapping`` --- the default bank assignments for; a given instruction. * **Alternative Mapping**: ``getInstrAlternativeMapping`` --- the other; possible bank assignments for a given instruction. ``TODO``:; All this information should eventually be static and generated by TableGen,; mostly using existing information augmented by bank descriptions. ``TODO``:; ``getInstrMapping`` is currently separate from ``getInstrAlternativeMapping``; because the latter is more expensive: as we move to static mapping info,; both methods should be free, and we should merge them. .. _regbankselect-modes:. RegBankSelect Modes; ^^^^^^^^^^^^^^^^^^^. ``RegBankSelect`` currently has two modes:. * **Fast** --- For each instruction, pick a target-provided ""default"" bank; assignment. This is the default at -O0. * **Greedy** --- For each instruction, pick the cheapest of several;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/RegBankSelect.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/RegBankSelect.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/RegBankSelect.rst:2096,Performance,optimiz,optimizing,2096,"n instruction. This pass could also remap target-specific instructions when beneficial.; In the future, this could replace the ExeDepsFix pass, as we can directly; select the best variant for an instruction that's available on multiple banks. .. _api-registerbankinfo:. API: RegisterBankInfo; ^^^^^^^^^^^^^^^^^^^^^. The ``RegisterBankInfo`` class describes multiple aspects of register banks. * **Banks**: ``addRegBankCoverage`` --- which register bank covers each; register class. * **Cross-Bank Copies**: ``copyCost`` --- the cost of a ``COPY`` from one bank; to another. * **Default Mapping**: ``getInstrMapping`` --- the default bank assignments for; a given instruction. * **Alternative Mapping**: ``getInstrAlternativeMapping`` --- the other; possible bank assignments for a given instruction. ``TODO``:; All this information should eventually be static and generated by TableGen,; mostly using existing information augmented by bank descriptions. ``TODO``:; ``getInstrMapping`` is currently separate from ``getInstrAlternativeMapping``; because the latter is more expensive: as we move to static mapping info,; both methods should be free, and we should merge them. .. _regbankselect-modes:. RegBankSelect Modes; ^^^^^^^^^^^^^^^^^^^. ``RegBankSelect`` currently has two modes:. * **Fast** --- For each instruction, pick a target-provided ""default"" bank; assignment. This is the default at -O0. * **Greedy** --- For each instruction, pick the cheapest of several; target-provided bank assignment alternatives. We intend to eventually introduce an additional optimizing mode:. * **Global** --- Across multiple instructions, pick the cheapest combination of; bank assignments. ``NOTE``:; On AArch64, we are considering using the Greedy mode even at -O0 (or perhaps at; backend -O1): because :ref:`gmir-llt` doesn't distinguish floating point from; integer scalars, the default assignment for loads and stores is the integer; bank, introducing cross-bank copies on most floating point operations. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/RegBankSelect.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/RegBankSelect.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/RegBankSelect.rst:2428,Performance,load,loads,2428,"n instruction. This pass could also remap target-specific instructions when beneficial.; In the future, this could replace the ExeDepsFix pass, as we can directly; select the best variant for an instruction that's available on multiple banks. .. _api-registerbankinfo:. API: RegisterBankInfo; ^^^^^^^^^^^^^^^^^^^^^. The ``RegisterBankInfo`` class describes multiple aspects of register banks. * **Banks**: ``addRegBankCoverage`` --- which register bank covers each; register class. * **Cross-Bank Copies**: ``copyCost`` --- the cost of a ``COPY`` from one bank; to another. * **Default Mapping**: ``getInstrMapping`` --- the default bank assignments for; a given instruction. * **Alternative Mapping**: ``getInstrAlternativeMapping`` --- the other; possible bank assignments for a given instruction. ``TODO``:; All this information should eventually be static and generated by TableGen,; mostly using existing information augmented by bank descriptions. ``TODO``:; ``getInstrMapping`` is currently separate from ``getInstrAlternativeMapping``; because the latter is more expensive: as we move to static mapping info,; both methods should be free, and we should merge them. .. _regbankselect-modes:. RegBankSelect Modes; ^^^^^^^^^^^^^^^^^^^. ``RegBankSelect`` currently has two modes:. * **Fast** --- For each instruction, pick a target-provided ""default"" bank; assignment. This is the default at -O0. * **Greedy** --- For each instruction, pick the cheapest of several; target-provided bank assignment alternatives. We intend to eventually introduce an additional optimizing mode:. * **Global** --- Across multiple instructions, pick the cheapest combination of; bank assignments. ``NOTE``:; On AArch64, we are considering using the Greedy mode even at -O0 (or perhaps at; backend -O1): because :ref:`gmir-llt` doesn't distinguish floating point from; integer scalars, the default assignment for loads and stores is the integer; bank, introducing cross-bank copies on most floating point operations. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/GlobalISel/RegBankSelect.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/GlobalISel/RegBankSelect.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/CodeViewSymbols.rst:1890,Modifiability,variab,variables,1890,"s:. * Symbol records only appear in the :doc:`PublicStream`, :doc:`GlobalStream`, and; :doc:`Module Info Streams <ModiStream>`.; * Type records only appear in the :doc:`TPI & IPI streams <TpiStream>`.; * While types are referenced from other CodeView records via :ref:`type indices <type_indices>`,; symbol records are referenced by the byte offset of the record in the stream that it appears; in.; * Types can reference types (via type indices), and symbols can reference both types (via type; indices) and symbols (via offsets), but types can never reference symbols.; * There is no notion of :ref:`Leaf Records <leaf_types>` and :ref:`Member Records <member_types>`; as there are with types. Every symbol record describes is own length.; * Certain special symbol records begin a ""scope"". For these records, all following records; up until the next ``S_END`` record are ""children"" of this symbol record. For example,; given a symbol record which describes a certain function, all local variables of this; function would appear following the function up until the corresponding ``S_END`` record. Finally, there are three general categories of symbol record, grouped by where they are legal; to appear in a PDB file. Public Symbols (which appear only in the; :doc:`publics stream <PublicStream>`), Global Symbols (which appear only in the; :doc:`globals stream <GlobalStream>`) and module symbols (which appear in the; :doc:`module info stream <ModiStream>`). .. _public_symbols:. Public Symbols; --------------. Public symbols are the CodeView equivalent of DWARF ``.debug_pubnames``. There; is one public symbol record for every function or variable in the program that; has a mangled name. The :doc:`Publics Stream <PublicStream>`, which contains these; records, additionally contains a hash table that allows one to quickly locate a; record by mangled name. S_PUB32 (0x110e); ^^^^^^^^^^^^^^^^. There is only type of public symbol, an ``S_PUB32`` which describes a mangled; name, a flag indicating ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/CodeViewSymbols.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/CodeViewSymbols.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/CodeViewSymbols.rst:2545,Modifiability,variab,variable,2545,"Member Records <member_types>`; as there are with types. Every symbol record describes is own length.; * Certain special symbol records begin a ""scope"". For these records, all following records; up until the next ``S_END`` record are ""children"" of this symbol record. For example,; given a symbol record which describes a certain function, all local variables of this; function would appear following the function up until the corresponding ``S_END`` record. Finally, there are three general categories of symbol record, grouped by where they are legal; to appear in a PDB file. Public Symbols (which appear only in the; :doc:`publics stream <PublicStream>`), Global Symbols (which appear only in the; :doc:`globals stream <GlobalStream>`) and module symbols (which appear in the; :doc:`module info stream <ModiStream>`). .. _public_symbols:. Public Symbols; --------------. Public symbols are the CodeView equivalent of DWARF ``.debug_pubnames``. There; is one public symbol record for every function or variable in the program that; has a mangled name. The :doc:`Publics Stream <PublicStream>`, which contains these; records, additionally contains a hash table that allows one to quickly locate a; record by mangled name. S_PUB32 (0x110e); ^^^^^^^^^^^^^^^^. There is only type of public symbol, an ``S_PUB32`` which describes a mangled; name, a flag indicating what kind of symbol it is (e.g. function, variable), and; the symbol's address. The :ref:`dbi_section_map_substream` of the; :doc:`DBI Stream <DbiStream>` can be consulted to determine what module this address; corresponds to, and from there that module's :doc:`module debug stream <ModiStream>`; can be consulted to locate full information for the symbol with the given address. .. _global_symbols:. Global Symbols; --------------. While there is one :ref:`public symbol <public_symbols>` for every symbol in the; program with `external` linkage, there is one global symbol for every symbol in the; program with linkage (including intern",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/CodeViewSymbols.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/CodeViewSymbols.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/CodeViewSymbols.rst:2945,Modifiability,variab,variable,2945,"ntil the corresponding ``S_END`` record. Finally, there are three general categories of symbol record, grouped by where they are legal; to appear in a PDB file. Public Symbols (which appear only in the; :doc:`publics stream <PublicStream>`), Global Symbols (which appear only in the; :doc:`globals stream <GlobalStream>`) and module symbols (which appear in the; :doc:`module info stream <ModiStream>`). .. _public_symbols:. Public Symbols; --------------. Public symbols are the CodeView equivalent of DWARF ``.debug_pubnames``. There; is one public symbol record for every function or variable in the program that; has a mangled name. The :doc:`Publics Stream <PublicStream>`, which contains these; records, additionally contains a hash table that allows one to quickly locate a; record by mangled name. S_PUB32 (0x110e); ^^^^^^^^^^^^^^^^. There is only type of public symbol, an ``S_PUB32`` which describes a mangled; name, a flag indicating what kind of symbol it is (e.g. function, variable), and; the symbol's address. The :ref:`dbi_section_map_substream` of the; :doc:`DBI Stream <DbiStream>` can be consulted to determine what module this address; corresponds to, and from there that module's :doc:`module debug stream <ModiStream>`; can be consulted to locate full information for the symbol with the given address. .. _global_symbols:. Global Symbols; --------------. While there is one :ref:`public symbol <public_symbols>` for every symbol in the; program with `external` linkage, there is one global symbol for every symbol in the; program with linkage (including internal linkage). As a result, global symbols do; not describe a mangled name *or* an address, since symbols with internal linkage; need not have any mangling at all, and also may not have an address. Thus, all; global symbols simply refer directly to the full symbol record via a module/offset; combination. Similarly to :ref:`public symbols <public_symbols>`, all global symbols are contained; in a single :doc:`Globals ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/CodeViewSymbols.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/CodeViewSymbols.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/CodeViewSymbols.rst:2692,Security,hash,hash,2692,"gin a ""scope"". For these records, all following records; up until the next ``S_END`` record are ""children"" of this symbol record. For example,; given a symbol record which describes a certain function, all local variables of this; function would appear following the function up until the corresponding ``S_END`` record. Finally, there are three general categories of symbol record, grouped by where they are legal; to appear in a PDB file. Public Symbols (which appear only in the; :doc:`publics stream <PublicStream>`), Global Symbols (which appear only in the; :doc:`globals stream <GlobalStream>`) and module symbols (which appear in the; :doc:`module info stream <ModiStream>`). .. _public_symbols:. Public Symbols; --------------. Public symbols are the CodeView equivalent of DWARF ``.debug_pubnames``. There; is one public symbol record for every function or variable in the program that; has a mangled name. The :doc:`Publics Stream <PublicStream>`, which contains these; records, additionally contains a hash table that allows one to quickly locate a; record by mangled name. S_PUB32 (0x110e); ^^^^^^^^^^^^^^^^. There is only type of public symbol, an ``S_PUB32`` which describes a mangled; name, a flag indicating what kind of symbol it is (e.g. function, variable), and; the symbol's address. The :ref:`dbi_section_map_substream` of the; :doc:`DBI Stream <DbiStream>` can be consulted to determine what module this address; corresponds to, and from there that module's :doc:`module debug stream <ModiStream>`; can be consulted to locate full information for the symbol with the given address. .. _global_symbols:. Global Symbols; --------------. While there is one :ref:`public symbol <public_symbols>` for every symbol in the; program with `external` linkage, there is one global symbol for every symbol in the; program with linkage (including internal linkage). As a result, global symbols do; not describe a mangled name *or* an address, since symbols with internal linkage; need not ha",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/CodeViewSymbols.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/CodeViewSymbols.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/CodeViewSymbols.rst:3999,Security,hash,hash,3999,":`DBI Stream <DbiStream>` can be consulted to determine what module this address; corresponds to, and from there that module's :doc:`module debug stream <ModiStream>`; can be consulted to locate full information for the symbol with the given address. .. _global_symbols:. Global Symbols; --------------. While there is one :ref:`public symbol <public_symbols>` for every symbol in the; program with `external` linkage, there is one global symbol for every symbol in the; program with linkage (including internal linkage). As a result, global symbols do; not describe a mangled name *or* an address, since symbols with internal linkage; need not have any mangling at all, and also may not have an address. Thus, all; global symbols simply refer directly to the full symbol record via a module/offset; combination. Similarly to :ref:`public symbols <public_symbols>`, all global symbols are contained; in a single :doc:`Globals Stream <GlobalStream>`, which contains a hash table mapping; fully qualified name to the corresponding record in the globals stream (which as; mentioned, then contains information allowing one to locate the full record in the; corresponding module symbol stream). Note that a consequence and limitation of this design is that program-wide lookup; by anything other than an exact textually matching fully-qualified name of whatever; the compiler decided to emit is impractical. This differs from DWARF, where even; though we don't necessarily have O(1) lookup by basename within a given scope (including; O(1) scope, we at least have O(n) access within a given scope). .. important::; Program-wide lookup of names by anything other than an exact textually matching fully; qualified name is not possible. S_GDATA32; ^^^^^^^^^^. S_GTHREAD32 (0x1113); ^^^^^^^^^^^^^^^^^^^^. S_PROCREF (0x1125); ^^^^^^^^^^^^^^^^^^. S_LPROCREF (0x1127); ^^^^^^^^^^^^^^^^^^^. S_GMANDATA (0x111d); ^^^^^^^^^^^^^^^^^^^. .. _module_symbols:. Module Symbols; --------------. S_END (0x0006); ^^^^^^^^^^^^",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/CodeViewSymbols.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/CodeViewSymbols.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/CodeViewSymbols.rst:4596,Security,access,access,4596,"uding internal linkage). As a result, global symbols do; not describe a mangled name *or* an address, since symbols with internal linkage; need not have any mangling at all, and also may not have an address. Thus, all; global symbols simply refer directly to the full symbol record via a module/offset; combination. Similarly to :ref:`public symbols <public_symbols>`, all global symbols are contained; in a single :doc:`Globals Stream <GlobalStream>`, which contains a hash table mapping; fully qualified name to the corresponding record in the globals stream (which as; mentioned, then contains information allowing one to locate the full record in the; corresponding module symbol stream). Note that a consequence and limitation of this design is that program-wide lookup; by anything other than an exact textually matching fully-qualified name of whatever; the compiler decided to emit is impractical. This differs from DWARF, where even; though we don't necessarily have O(1) lookup by basename within a given scope (including; O(1) scope, we at least have O(n) access within a given scope). .. important::; Program-wide lookup of names by anything other than an exact textually matching fully; qualified name is not possible. S_GDATA32; ^^^^^^^^^^. S_GTHREAD32 (0x1113); ^^^^^^^^^^^^^^^^^^^^. S_PROCREF (0x1125); ^^^^^^^^^^^^^^^^^^. S_LPROCREF (0x1127); ^^^^^^^^^^^^^^^^^^^. S_GMANDATA (0x111d); ^^^^^^^^^^^^^^^^^^^. .. _module_symbols:. Module Symbols; --------------. S_END (0x0006); ^^^^^^^^^^^^^^. S_FRAMEPROC (0x1012); ^^^^^^^^^^^^^^^^^^^^. S_OBJNAME (0x1101); ^^^^^^^^^^^^^^^^^^. S_THUNK32 (0x1102); ^^^^^^^^^^^^^^^^^^. S_BLOCK32 (0x1103); ^^^^^^^^^^^^^^^^^^. S_LABEL32 (0x1105); ^^^^^^^^^^^^^^^^^^. S_REGISTER (0x1106); ^^^^^^^^^^^^^^^^^^^. S_BPREL32 (0x110b); ^^^^^^^^^^^^^^^^^^. S_LPROC32 (0x110f); ^^^^^^^^^^^^^^^^^^. S_GPROC32 (0x1110); ^^^^^^^^^^^^^^^^^^. S_REGREL32 (0x1111); ^^^^^^^^^^^^^^^^^^^. S_COMPILE2 (0x1116); ^^^^^^^^^^^^^^^^^^^. S_UNAMESPACE (0x1124); ^^^^^^^^^^^^^^^^^^^^",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/CodeViewSymbols.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/CodeViewSymbols.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/CodeViewSymbols.rst:3763,Usability,simpl,simply,3763,"^^^^^^^^. There is only type of public symbol, an ``S_PUB32`` which describes a mangled; name, a flag indicating what kind of symbol it is (e.g. function, variable), and; the symbol's address. The :ref:`dbi_section_map_substream` of the; :doc:`DBI Stream <DbiStream>` can be consulted to determine what module this address; corresponds to, and from there that module's :doc:`module debug stream <ModiStream>`; can be consulted to locate full information for the symbol with the given address. .. _global_symbols:. Global Symbols; --------------. While there is one :ref:`public symbol <public_symbols>` for every symbol in the; program with `external` linkage, there is one global symbol for every symbol in the; program with linkage (including internal linkage). As a result, global symbols do; not describe a mangled name *or* an address, since symbols with internal linkage; need not have any mangling at all, and also may not have an address. Thus, all; global symbols simply refer directly to the full symbol record via a module/offset; combination. Similarly to :ref:`public symbols <public_symbols>`, all global symbols are contained; in a single :doc:`Globals Stream <GlobalStream>`, which contains a hash table mapping; fully qualified name to the corresponding record in the globals stream (which as; mentioned, then contains information allowing one to locate the full record in the; corresponding module symbol stream). Note that a consequence and limitation of this design is that program-wide lookup; by anything other than an exact textually matching fully-qualified name of whatever; the compiler decided to emit is impractical. This differs from DWARF, where even; though we don't necessarily have O(1) lookup by basename within a given scope (including; O(1) scope, we at least have O(n) access within a given scope). .. important::; Program-wide lookup of names by anything other than an exact textually matching fully; qualified name is not possible. S_GDATA32; ^^^^^^^^^^. S_GTHR",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/CodeViewSymbols.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/CodeViewSymbols.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/CodeViewTypes.rst:4560,Integrability,depend,depending,4560,"ueReference = 0x01, // ""old"" reference; PointerToDataMember = 0x02, // pointer to data member; PointerToMemberFunction = 0x03, // pointer to member function; RValueReference = 0x04 // r-value reference; };; enum class PointerModifiers : uint8_t {; None = 0x00, // ""normal"" pointer; Flat32 = 0x01, // ""flat"" pointer; Volatile = 0x02, // pointer is marked volatile; Const = 0x04, // pointer is marked const; Unaligned = 0x08, // pointer is marked unaligned; Restrict = 0x10, // pointer is marked restrict; };; enum class PointerFlags : uint8_t {; WinRTSmartPointer = 0x01, // pointer is a WinRT smart pointer; LValueRefThisPointer = 0x02, // pointer is a 'this' pointer of a member function with ref qualifier (e.g. void X::foo() &); RValueRefThisPointer = 0x04 // pointer is a 'this' pointer of a member function with ref qualifier (e.g. void X::foo() &&); };. The ``Size`` field of the Attributes bitmask is a 1-byte value indicating the; pointer size. For example, a `void*` would have a size of either 4 or 8 depending; on the target architecture. On the other hand, if ``Mode`` indicates that this is; a pointer to member function or pointer to data member, then the size can be any; implementation defined number. The ``Member Ptr Info`` field of the ``LF_POINTER`` record is only present if the; attributes indicate that this is a pointer to member. Note that ""plain"" pointers to primitive types are not represented by ``LF_POINTER``; records, they are indicated by special reserved :ref:`TypeIndex values <type_indices>`. LF_MODIFIER (0x1001); ^^^^^^^^^^^^^^^^^^^^. LF_PROCEDURE (0x1008); ^^^^^^^^^^^^^^^^^^^^^. LF_MFUNCTION (0x1009); ^^^^^^^^^^^^^^^^^^^^^. LF_LABEL (0x000e); ^^^^^^^^^^^^^^^^^. LF_ARGLIST (0x1201); ^^^^^^^^^^^^^^^^^^^. LF_FIELDLIST (0x1203); ^^^^^^^^^^^^^^^^^^^^^. LF_ARRAY (0x1503); ^^^^^^^^^^^^^^^^^. LF_CLASS (0x1504); ^^^^^^^^^^^^^^^^^. LF_STRUCTURE (0x1505); ^^^^^^^^^^^^^^^^^^^^^. LF_INTERFACE (0x1519); ^^^^^^^^^^^^^^^^^^^^^. LF_UNION (0x1506); ^^^^^^^^^^^^^^^^^. LF_EN",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/CodeViewTypes.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/CodeViewTypes.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/CodeViewTypes.rst:1023,Modifiability,variab,variable,1023,"=================================; CodeView Type Records; =====================================. .. contents::; :local:. .. _types_intro:. Introduction; ============. This document describes the usage and serialization format of the various; CodeView type records that LLVM understands. This document does not describe; every single CodeView type record that is defined. In some cases, this is; because the records are clearly deprecated and can only appear in very old; software (e.g. the 16-bit types). On other cases, it is because the records; have never been observed in practice. This could be because they are only; generated for non-C++ code (e.g. Visual Basic, C#), or because they have been; made obsolete by newer records, or any number of other reasons. However, the; records we describe here should cover 99% of type records that one can expect; to encounter when dealing with modern C++ toolchains. Record Categories; =================. We can think of a sequence of CodeView type records as an array of variable length; `leaf records`. Each such record describes its own length as part of a fixed-size; header, as well as the kind of record it is. Leaf records are either padded to 4; bytes (if this type stream appears in a TPI/IPI stream of a PDB) or not padded at; all (if this type stream appears in the ``.debug$T`` section of an object file).; Padding is implemented by inserting a decreasing sequence of `<_padding_records>`; that terminates with ``LF_PAD0``. The final category of record is a ``member record``. One particular leaf type --; ``LF_FIELDLIST`` -- contains a series of embedded records. While the outer; ``LF_FIELDLIST`` describes its length (like any other leaf record), the embedded; records -- called ``member records`` do not. .. _leaf_types:. Leaf Records; ------------. All leaf records begin with the following 4 byte prefix:. .. code-block:: c++. struct RecordHeader {; uint16_t RecordLen; // Record length, not including this 2 byte field.; uint16_t Recor",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/CodeViewTypes.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/CodeViewTypes.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/CodeViewTypes.rst:424,Usability,clear,clearly,424,"﻿=====================================; CodeView Type Records; =====================================. .. contents::; :local:. .. _types_intro:. Introduction; ============. This document describes the usage and serialization format of the various; CodeView type records that LLVM understands. This document does not describe; every single CodeView type record that is defined. In some cases, this is; because the records are clearly deprecated and can only appear in very old; software (e.g. the 16-bit types). On other cases, it is because the records; have never been observed in practice. This could be because they are only; generated for non-C++ code (e.g. Visual Basic, C#), or because they have been; made obsolete by newer records, or any number of other reasons. However, the; records we describe here should cover 99% of type records that one can expect; to encounter when dealing with modern C++ toolchains. Record Categories; =================. We can think of a sequence of CodeView type records as an array of variable length; `leaf records`. Each such record describes its own length as part of a fixed-size; header, as well as the kind of record it is. Leaf records are either padded to 4; bytes (if this type stream appears in a TPI/IPI stream of a PDB) or not padded at; all (if this type stream appears in the ``.debug$T`` section of an object file).; Padding is implemented by inserting a decreasing sequence of `<_padding_records>`; that terminates with ``LF_PAD0``. The final category of record is a ``member record``. One particular leaf type --; ``LF_FIELDLIST`` -- contains a series of embedded records. While the outer; ``LF_FIELDLIST`` describes its length (like any other leaf record), the embedded; records -- called ``member records`` do not. .. _leaf_types:. Leaf Records; ------------. All leaf records begin with the following 4 byte prefix:. .. code-block:: c++. struct RecordHeader {; uint16_t RecordLen; // Record length, not including this 2 byte field.; uint16_t R",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/CodeViewTypes.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/CodeViewTypes.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/DbiStream.rst:16199,Availability,down,download,16199," be related to Edit &; Continue support in MSVC. LLVM does not support Edit & Continue, so this; stream will not be discussed further. .. _dbi_optional_dbg_stream:. Optional Debug Header Stream; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^; Begins at offset ``0`` immediately after the :ref:`dbi_ec_substream` ends, and; consumes ``Header->OptionalDbgHeaderSize`` bytes. This field is an array of; stream indices (e.g. ``uint16_t``'s), each of which identifies a stream; index in the larger MSF file which contains some additional debug information.; Each position of this array has a special meaning, allowing one to determine; what kind of debug information is at the referenced stream. ``11`` indices; are currently understood, although it's possible there may be more. The; layout of each stream generally corresponds exactly to a particular type; of debug data directory from the PE/COFF file. The format of these fields; can be found in the `Microsoft PE/COFF Specification <https://www.microsoft.com/en-us/download/details.aspx?id=19509>`__.; If any of these fields is -1, it means the corresponding type of debug info is; not present in the PDB. **FPO Data** - ``DbgStreamArray[0]``. The data in the referenced stream is an; array of ``FPO_DATA`` structures. This contains the relocated contents of; any ``.debug$F`` section from any of the linker inputs. **Exception Data** - ``DbgStreamArray[1]``. The data in the referenced stream; is a debug data directory of type ``IMAGE_DEBUG_TYPE_EXCEPTION``. **Fixup Data** - ``DbgStreamArray[2]``. The data in the referenced stream is a; debug data directory of type ``IMAGE_DEBUG_TYPE_FIXUP``. **Omap To Src Data** - ``DbgStreamArray[3]``. The data in the referenced stream; is a debug data directory of type ``IMAGE_DEBUG_TYPE_OMAP_TO_SRC``. This; is used for mapping addresses between instrumented and uninstrumented code. **Omap From Src Data** - ``DbgStreamArray[4]``. The data in the referenced stream; is a debug data directory of type ``IMAGE_DEBUG_TYPE_OMAP",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/DbiStream.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/DbiStream.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/DbiStream.rst:4514,Modifiability,variab,variable-length,4514,"** - Unknown. - **MFCTypeServerIndex** - The index of the MFC type server in the; :ref:`dbi_type_server_map_substream`. - **Flags** - A bitfield with the following layout, containing various; information about how the program was built:. .. code-block:: c++. uint16_t WasIncrementallyLinked : 1;; uint16_t ArePrivateSymbolsStripped : 1;; uint16_t HasConflictingTypes : 1;; uint16_t Reserved : 13;. The only one of these that is not self-explanatory is ``HasConflictingTypes``.; Although undocumented, ``link.exe`` contains a hidden flag ``/DEBUG:CTYPES``.; If it is passed to ``link.exe``, this field will be set. Otherwise it will; not be set. It is unclear what this flag does, although it seems to have; subtle implications on the algorithm used to look up type records. - **Machine** - A value from the `CV_CPU_TYPE_e <https://msdn.microsoft.com/en-us/library/b2fc64ek.aspx>`__; enumeration. Common values are ``0x8664`` (x86-64) and ``0x14C`` (x86). Immediately after the fixed-size DBI Stream header are ``7`` variable-length; `substreams`. The following ``7`` fields of the DBI Stream header specify the; number of bytes of the corresponding substream. Each substream's contents will; be described in detail :ref:`below <dbi_substreams>`. The length of the entire; DBI Stream should equal ``64`` (the length of the header above) plus the value; of each of the following ``7`` fields. - **ModInfoSize** - The length of the :ref:`dbi_mod_info_substream`. - **SectionContributionSize** - The length of the :ref:`dbi_sec_contr_substream`. - **SectionMapSize** - The length of the :ref:`dbi_section_map_substream`. - **SourceInfoSize** - The length of the :ref:`dbi_file_info_substream`. - **TypeServerMapSize** - The length of the :ref:`dbi_type_server_map_substream`. - **OptionalDbgHeaderSize** - The length of the :ref:`dbi_optional_dbg_stream`. - **ECSubstreamSize** - The length of the :ref:`dbi_ec_substream`. .. _dbi_substreams:. Substreams; ==========. .. _dbi_mod_info_substream:. Module ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/DbiStream.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/DbiStream.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/DbiStream.rst:5652,Modifiability,variab,variable-length,5652,"substream's contents will; be described in detail :ref:`below <dbi_substreams>`. The length of the entire; DBI Stream should equal ``64`` (the length of the header above) plus the value; of each of the following ``7`` fields. - **ModInfoSize** - The length of the :ref:`dbi_mod_info_substream`. - **SectionContributionSize** - The length of the :ref:`dbi_sec_contr_substream`. - **SectionMapSize** - The length of the :ref:`dbi_section_map_substream`. - **SourceInfoSize** - The length of the :ref:`dbi_file_info_substream`. - **TypeServerMapSize** - The length of the :ref:`dbi_type_server_map_substream`. - **OptionalDbgHeaderSize** - The length of the :ref:`dbi_optional_dbg_stream`. - **ECSubstreamSize** - The length of the :ref:`dbi_ec_substream`. .. _dbi_substreams:. Substreams; ==========. .. _dbi_mod_info_substream:. Module Info Substream; ^^^^^^^^^^^^^^^^^^^^^. Begins at offset ``0`` immediately after the :ref:`header <dbi_header>`. The; module info substream is an array of variable-length records, each one; describing a single module (e.g. object file) linked into the program. Each; record in the array has the format:. .. code-block:: c++. struct ModInfo {; uint32_t Unused1;; struct SectionContribEntry {; uint16_t Section;; char Padding1[2];; int32_t Offset;; int32_t Size;; uint32_t Characteristics;; uint16_t ModuleIndex;; char Padding2[2];; uint32_t DataCrc;; uint32_t RelocCrc;; } SectionContr;; uint16_t Flags;; uint16_t ModuleSymStream;; uint32_t SymByteSize;; uint32_t C11ByteSize;; uint32_t C13ByteSize;; uint16_t SourceFileCount;; char Padding[2];; uint32_t Unused2;; uint32_t SourceFileNameIndex;; uint32_t PdbFilePathNameIndex;; char ModuleName[];; char ObjFileName[];; };. - **SectionContr** - Describes the properties of the section in the final binary; which contain the code and data from this module. ``SectionContr.Characteristics`` corresponds to the ``Characteristics`` field; of the `IMAGE_SECTION_HEADER <https://msdn.microsoft.com/en-us/library/windows/desk",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/DbiStream.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/DbiStream.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/DbiStream.rst:18574,Performance,perform,performed,18574,"rray[2]``. The data in the referenced stream is a; debug data directory of type ``IMAGE_DEBUG_TYPE_FIXUP``. **Omap To Src Data** - ``DbgStreamArray[3]``. The data in the referenced stream; is a debug data directory of type ``IMAGE_DEBUG_TYPE_OMAP_TO_SRC``. This; is used for mapping addresses between instrumented and uninstrumented code. **Omap From Src Data** - ``DbgStreamArray[4]``. The data in the referenced stream; is a debug data directory of type ``IMAGE_DEBUG_TYPE_OMAP_FROM_SRC``. This; is used for mapping addresses between instrumented and uninstrumented code. **Section Header Data** - ``DbgStreamArray[5]``. A dump of all section headers from; the original executable. **Token / RID Map** - ``DbgStreamArray[6]``. The layout of this stream is not; understood, but it is assumed to be a mapping from ``CLR Token`` to; ``CLR Record ID``. Refer to `ECMA 335 <http://www.ecma-international.org/publications/standards/Ecma-335.htm>`__; for more information. **Xdata** - ``DbgStreamArray[7]``. A copy of the ``.xdata`` section from the; executable. **Pdata** - ``DbgStreamArray[8]``. This is assumed to be a copy of the ``.pdata``; section from the executable, but that would make it identical to; ``DbgStreamArray[1]``. The difference between these two indices is not well; understood. **New FPO Data** - ``DbgStreamArray[9]``. The data in the referenced stream is a; debug data directory of type ``IMAGE_DEBUG_TYPE_FPO``. Note that this is different; from ``DbgStreamArray[0]`` in that ``.debug$F`` sections are only emitted by MASM.; Thus, it is possible for both to appear in the same PDB if both MASM object files; and cl object files are linked into the same program. **Original Section Header Data** - ``DbgStreamArray[10]``. Similar to; ``DbgStreamArray[5]``, but contains the section headers before any binary translation; has been performed. This can be used in conjunction with ``DebugStreamArray[3]``; and ``DbgStreamArray[4]`` to map instrumented and uninstrumented addresses.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/DbiStream.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/DbiStream.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/DbiStream.rst:10869,Testability,log,logical,10869,"ngth structures. If the version is ``Ver60``,; it is an array of ``SectionContribEntry`` structures (this is the nested structure; from the ``ModInfo`` type. If the version is ``V2``, it is an array of; ``SectionContribEntry2`` structures, defined as follows:. .. code-block:: c++. struct SectionContribEntry2 {; SectionContribEntry SC;; uint32_t ISectCoff;; };. The purpose of the second field is not well understood. The name implies that; is the index of the COFF section, but this also describes the existing field; ``SectionContribEntry::Section``. .. _dbi_section_map_substream:. Section Map Substream; ^^^^^^^^^^^^^^^^^^^^^; Begins at offset ``0`` immediately after the :ref:`dbi_sec_contr_substream` ends,; and consumes ``Header->SectionMapSize`` bytes. This substream begins with an ``4``; byte header followed by an array of fixed-length records. The header and records; have the following layout:. .. code-block:: c++. struct SectionMapHeader {; uint16_t Count; // Number of segment descriptors; uint16_t LogCount; // Number of logical segment descriptors; };. struct SectionMapEntry {; uint16_t Flags; // See the SectionMapEntryFlags enum below.; uint16_t Ovl; // Logical overlay number; uint16_t Group; // Group index into descriptor array.; uint16_t Frame;; uint16_t SectionName; // Byte index of segment / group name in string table, or 0xFFFF.; uint16_t ClassName; // Byte index of class in string table, or 0xFFFF.; uint32_t Offset; // Byte offset of the logical segment within physical segment. If group is set in flags, this is the offset of the group.; uint32_t SectionLength; // Byte count of the segment or group.; };. enum class SectionMapEntryFlags : uint16_t {; Read = 1 << 0, // Segment is readable.; Write = 1 << 1, // Segment is writable.; Execute = 1 << 2, // Segment is executable.; AddressIs32Bit = 1 << 3, // Descriptor describes a 32-bit linear address.; IsSelector = 1 << 8, // Frame represents a selector.; IsAbsoluteAddress = 1 << 9, // Frame represents an absolut",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/DbiStream.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/DbiStream.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/DbiStream.rst:11302,Testability,log,logical,11302,"ion, but this also describes the existing field; ``SectionContribEntry::Section``. .. _dbi_section_map_substream:. Section Map Substream; ^^^^^^^^^^^^^^^^^^^^^; Begins at offset ``0`` immediately after the :ref:`dbi_sec_contr_substream` ends,; and consumes ``Header->SectionMapSize`` bytes. This substream begins with an ``4``; byte header followed by an array of fixed-length records. The header and records; have the following layout:. .. code-block:: c++. struct SectionMapHeader {; uint16_t Count; // Number of segment descriptors; uint16_t LogCount; // Number of logical segment descriptors; };. struct SectionMapEntry {; uint16_t Flags; // See the SectionMapEntryFlags enum below.; uint16_t Ovl; // Logical overlay number; uint16_t Group; // Group index into descriptor array.; uint16_t Frame;; uint16_t SectionName; // Byte index of segment / group name in string table, or 0xFFFF.; uint16_t ClassName; // Byte index of class in string table, or 0xFFFF.; uint32_t Offset; // Byte offset of the logical segment within physical segment. If group is set in flags, this is the offset of the group.; uint32_t SectionLength; // Byte count of the segment or group.; };. enum class SectionMapEntryFlags : uint16_t {; Read = 1 << 0, // Segment is readable.; Write = 1 << 1, // Segment is writable.; Execute = 1 << 2, // Segment is executable.; AddressIs32Bit = 1 << 3, // Descriptor describes a 32-bit linear address.; IsSelector = 1 << 8, // Frame represents a selector.; IsAbsoluteAddress = 1 << 9, // Frame represents an absolute address.; IsGroup = 1 << 10 // If set, descriptor represents a group.; };. Many of these fields are not well understood, so will not be discussed further. .. _dbi_file_info_substream:. File Info Substream; ^^^^^^^^^^^^^^^^^^^; Begins at offset ``0`` immediately after the :ref:`dbi_section_map_substream` ends,; and consumes ``Header->SourceInfoSize`` bytes. This substream defines the mapping; from module to the source files that contribute to that module. Since multi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/DbiStream.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/DbiStream.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/DbiStream.rst:1810,Usability,clear,clear,1810,"er:. Stream Header; =============; At offset 0 of the DBI Stream is a header with the following layout:. .. code-block:: c++. struct DbiStreamHeader {; int32_t VersionSignature;; uint32_t VersionHeader;; uint32_t Age;; uint16_t GlobalStreamIndex;; uint16_t BuildNumber;; uint16_t PublicStreamIndex;; uint16_t PdbDllVersion;; uint16_t SymRecordStream;; uint16_t PdbDllRbld;; int32_t ModInfoSize;; int32_t SectionContributionSize;; int32_t SectionMapSize;; int32_t SourceInfoSize;; int32_t TypeServerMapSize;; uint32_t MFCTypeServerIndex;; int32_t OptionalDbgHeaderSize;; int32_t ECSubstreamSize;; uint16_t Flags;; uint16_t Machine;; uint32_t Padding;; };. - **VersionSignature** - Unknown meaning. Appears to always be ``-1``. - **VersionHeader** - A value from the following enum. .. code-block:: c++. enum class DbiStreamVersion : uint32_t {; VC41 = 930803,; V50 = 19960307,; V60 = 19970606,; V70 = 19990903,; V110 = 20091201; };. Similar to the :doc:`PDB Stream <PdbStream>`, this value always appears to be; ``V70``, and it is not clear what the other values are for. - **Age** - The number of times the PDB has been written. Equal to the same; field from the :ref:`PDB Stream header <pdb_stream_header>`. - **GlobalStreamIndex** - The index of the :doc:`Global Symbol Stream <GlobalStream>`,; which contains CodeView symbol records for all global symbols. Actual records; are stored in the symbol record stream, and are referenced from this stream. - **BuildNumber** - A bitfield containing values representing the major and minor; version number of the toolchain (e.g. 12.0 for MSVC 2013) used to build the; program, with the following layout:. .. code-block:: c++. uint16_t MinorVersion : 8;; uint16_t MajorVersion : 7;; uint16_t NewVersionFormat : 1;. For the purposes of LLVM, we assume ``NewVersionFormat`` to be always ``true``.; If it is ``false``, the layout above does not apply and the reader should consult; the `Microsoft Source Code <https://github.com/Microsoft/microsoft-pdb>`__ for",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/DbiStream.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/DbiStream.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/DbiStream.rst:2787,Usability,guid,guidance,2787,"ys appears to be; ``V70``, and it is not clear what the other values are for. - **Age** - The number of times the PDB has been written. Equal to the same; field from the :ref:`PDB Stream header <pdb_stream_header>`. - **GlobalStreamIndex** - The index of the :doc:`Global Symbol Stream <GlobalStream>`,; which contains CodeView symbol records for all global symbols. Actual records; are stored in the symbol record stream, and are referenced from this stream. - **BuildNumber** - A bitfield containing values representing the major and minor; version number of the toolchain (e.g. 12.0 for MSVC 2013) used to build the; program, with the following layout:. .. code-block:: c++. uint16_t MinorVersion : 8;; uint16_t MajorVersion : 7;; uint16_t NewVersionFormat : 1;. For the purposes of LLVM, we assume ``NewVersionFormat`` to be always ``true``.; If it is ``false``, the layout above does not apply and the reader should consult; the `Microsoft Source Code <https://github.com/Microsoft/microsoft-pdb>`__ for; further guidance. - **PublicStreamIndex** - The index of the :doc:`Public Symbol Stream <PublicStream>`,; which contains CodeView symbol records for all public symbols. Actual records; are stored in the symbol record stream, and are referenced from this stream. - **PdbDllVersion** - The version number of ``mspdbXXXX.dll`` used to produce this; PDB. Note this obviously does not apply for LLVM as LLVM does not use ``mspdb.dll``. - **SymRecordStream** - The stream containing all CodeView symbol records used; by the program. This is used for deduplication, so that many different; compilands can refer to the same symbols without having to include the full record; content inside of each module stream. - **PdbDllRbld** - Unknown. - **MFCTypeServerIndex** - The index of the MFC type server in the; :ref:`dbi_type_server_map_substream`. - **Flags** - A bitfield with the following layout, containing various; information about how the program was built:. .. code-block:: c++. uint16_t Was",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/DbiStream.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/DbiStream.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/DbiStream.rst:3985,Usability,undo,undocumented,3985,"ecord stream, and are referenced from this stream. - **PdbDllVersion** - The version number of ``mspdbXXXX.dll`` used to produce this; PDB. Note this obviously does not apply for LLVM as LLVM does not use ``mspdb.dll``. - **SymRecordStream** - The stream containing all CodeView symbol records used; by the program. This is used for deduplication, so that many different; compilands can refer to the same symbols without having to include the full record; content inside of each module stream. - **PdbDllRbld** - Unknown. - **MFCTypeServerIndex** - The index of the MFC type server in the; :ref:`dbi_type_server_map_substream`. - **Flags** - A bitfield with the following layout, containing various; information about how the program was built:. .. code-block:: c++. uint16_t WasIncrementallyLinked : 1;; uint16_t ArePrivateSymbolsStripped : 1;; uint16_t HasConflictingTypes : 1;; uint16_t Reserved : 13;. The only one of these that is not self-explanatory is ``HasConflictingTypes``.; Although undocumented, ``link.exe`` contains a hidden flag ``/DEBUG:CTYPES``.; If it is passed to ``link.exe``, this field will be set. Otherwise it will; not be set. It is unclear what this flag does, although it seems to have; subtle implications on the algorithm used to look up type records. - **Machine** - A value from the `CV_CPU_TYPE_e <https://msdn.microsoft.com/en-us/library/b2fc64ek.aspx>`__; enumeration. Common values are ``0x8664`` (x86-64) and ``0x14C`` (x86). Immediately after the fixed-size DBI Stream header are ``7`` variable-length; `substreams`. The following ``7`` fields of the DBI Stream header specify the; number of bytes of the corresponding substream. Each substream's contents will; be described in detail :ref:`below <dbi_substreams>`. The length of the entire; DBI Stream should equal ``64`` (the length of the header above) plus the value; of each of the following ``7`` fields. - **ModInfoSize** - The length of the :ref:`dbi_mod_info_substream`. - **SectionContributionSize** - ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/DbiStream.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/DbiStream.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/DbiStream.rst:13457,Usability,simpl,simply,13457,"fsets into the string table rather than embedding the string's value; directly. The format of this substream is as follows:. .. code-block:: c++. struct FileInfoSubstream {; uint16_t NumModules;; uint16_t NumSourceFiles;. uint16_t ModIndices[NumModules];; uint16_t ModFileCounts[NumModules];; uint32_t FileNameOffsets[NumSourceFiles];; char NamesBuffer[][NumSourceFiles];; };. **NumModules** - The number of modules for which source file information is; contained within this substream. Should match the corresponding value from the; ref:`dbi_header`. **NumSourceFiles**: In theory this is supposed to contain the number of source; files for which this substream contains information. But that would present a; problem in that the width of this field being ``16``-bits would prevent one from; having more than 64K source files in a program. In early versions of the file; format, this seems to have been the case. In order to support more than this, this; field of the is simply ignored, and computed dynamically by summing up the values of; the ``ModFileCounts`` array (discussed below). In short, this value should be; ignored. **ModIndices** - This array is present, but does not appear to be useful. **ModFileCountArray** - An array of ``NumModules`` integers, each one containing; the number of source files which contribute to the module at the specified index.; While each individual module is limited to 64K contributing source files, the; union of all modules' source files may be greater than 64K. The real number of; source files is thus computed by summing this array. Note that summing this array; does not give the number of `unique` source files, only the total number of source; file contributions to modules. **FileNameOffsets** - An array of **NumSourceFiles** integers (where **NumSourceFiles**; here refers to the 32-bit value obtained from summing **ModFileCountArray**), where; each integer is an offset into **NamesBuffer** pointing to a null terminated string. **NamesBuffer** ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/DbiStream.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/DbiStream.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/HashTable.rst:1581,Performance,load,load,1581," The only supported key; value type is a uint32. The only requirement is that the producer and consumer; agree on the hash function. As such, the hash function can is not discussed; further in this document, it is assumed that for a particular instance of a PDB; file hash table, the appropriate hash function is being used. On-Disk Format; ==============. .. code-block:: none. .--------------------.-- +0; | Size |; .--------------------.-- +4; | Capacity |; .--------------------.-- +8; | Present Bit Vector |; .--------------------.-- +N; | Deleted Bit Vector |; .--------------------.-- +M ─╮; | Key | │; .--------------------.-- +M+4 │; | Value | │; .--------------------.-- +M+4+sizeof(Value) │; ... ├─ |Capacity| Bucket entries; .--------------------. │; | Key | │; .--------------------. │; | Value | │; .--------------------. ─╯. - **Size** - The number of values contained in the hash table. - **Capacity** - The number of buckets in the hash table. Producers should; maintain a load factor of no greater than ``2/3*Capacity+1``. - **Present Bit Vector** - A serialized bit vector which contains information; about which buckets have valid values. If the bucket has a value, the; corresponding bit will be set, and if the bucket doesn't have a value (either; because the bucket is empty or because the value is a tombstone value) the bit; will be unset. - **Deleted Bit Vector** - A serialized bit vector which contains information; about which buckets have tombstone values. If the entry in this bucket is; deleted, the bit will be set, otherwise it will be unset. - **Keys and Values** - A list of ``Capacity`` hash buckets, where the first; entry is the key (always a uint32), and the second entry is the value. The; state of each bucket (valid, empty, deleted) can be determined by examining; the present and deleted bit vectors. .. _hash_bit_vectors:. Present and Deleted Bit Vectors; ===============================. The bit vectors indicating the status of each bucket are serialize",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/HashTable.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/HashTable.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/HashTable.rst:213,Security,access,access,213,"The PDB Serialized Hash Table Format; ====================================. .. contents::; :local:. .. _hash_intro:. Introduction; ============. One of the design goals of the PDB format is to provide accelerated access to; debug information, and for this reason there are several occasions where hash; tables are serialized and embedded directly to the file, rather than requiring; a consumer to read a list of values and reconstruct the hash table on the fly. The serialization format supports hash tables of arbitrarily large size and; capacity, as well as value types and hash functions. The only supported key; value type is a uint32. The only requirement is that the producer and consumer; agree on the hash function. As such, the hash function can is not discussed; further in this document, it is assumed that for a particular instance of a PDB; file hash table, the appropriate hash function is being used. On-Disk Format; ==============. .. code-block:: none. .--------------------.-- +0; | Size |; .--------------------.-- +4; | Capacity |; .--------------------.-- +8; | Present Bit Vector |; .--------------------.-- +N; | Deleted Bit Vector |; .--------------------.-- +M ─╮; | Key | │; .--------------------.-- +M+4 │; | Value | │; .--------------------.-- +M+4+sizeof(Value) │; ... ├─ |Capacity| Bucket entries; .--------------------. │; | Key | │; .--------------------. │; | Value | │; .--------------------. ─╯. - **Size** - The number of values contained in the hash table. - **Capacity** - The number of buckets in the hash table. Producers should; maintain a load factor of no greater than ``2/3*Capacity+1``. - **Present Bit Vector** - A serialized bit vector which contains information; about which buckets have valid values. If the bucket has a value, the; corresponding bit will be set, and if the bucket doesn't have a value (either; because the bucket is empty or because the value is a tombstone value) the bit; will be unset. - **Deleted Bit Vector** - A serialized bit v",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/HashTable.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/HashTable.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/HashTable.rst:297,Security,hash,hash,297,"The PDB Serialized Hash Table Format; ====================================. .. contents::; :local:. .. _hash_intro:. Introduction; ============. One of the design goals of the PDB format is to provide accelerated access to; debug information, and for this reason there are several occasions where hash; tables are serialized and embedded directly to the file, rather than requiring; a consumer to read a list of values and reconstruct the hash table on the fly. The serialization format supports hash tables of arbitrarily large size and; capacity, as well as value types and hash functions. The only supported key; value type is a uint32. The only requirement is that the producer and consumer; agree on the hash function. As such, the hash function can is not discussed; further in this document, it is assumed that for a particular instance of a PDB; file hash table, the appropriate hash function is being used. On-Disk Format; ==============. .. code-block:: none. .--------------------.-- +0; | Size |; .--------------------.-- +4; | Capacity |; .--------------------.-- +8; | Present Bit Vector |; .--------------------.-- +N; | Deleted Bit Vector |; .--------------------.-- +M ─╮; | Key | │; .--------------------.-- +M+4 │; | Value | │; .--------------------.-- +M+4+sizeof(Value) │; ... ├─ |Capacity| Bucket entries; .--------------------. │; | Key | │; .--------------------. │; | Value | │; .--------------------. ─╯. - **Size** - The number of values contained in the hash table. - **Capacity** - The number of buckets in the hash table. Producers should; maintain a load factor of no greater than ``2/3*Capacity+1``. - **Present Bit Vector** - A serialized bit vector which contains information; about which buckets have valid values. If the bucket has a value, the; corresponding bit will be set, and if the bucket doesn't have a value (either; because the bucket is empty or because the value is a tombstone value) the bit; will be unset. - **Deleted Bit Vector** - A serialized bit v",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/HashTable.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/HashTable.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/HashTable.rst:439,Security,hash,hash,439,"The PDB Serialized Hash Table Format; ====================================. .. contents::; :local:. .. _hash_intro:. Introduction; ============. One of the design goals of the PDB format is to provide accelerated access to; debug information, and for this reason there are several occasions where hash; tables are serialized and embedded directly to the file, rather than requiring; a consumer to read a list of values and reconstruct the hash table on the fly. The serialization format supports hash tables of arbitrarily large size and; capacity, as well as value types and hash functions. The only supported key; value type is a uint32. The only requirement is that the producer and consumer; agree on the hash function. As such, the hash function can is not discussed; further in this document, it is assumed that for a particular instance of a PDB; file hash table, the appropriate hash function is being used. On-Disk Format; ==============. .. code-block:: none. .--------------------.-- +0; | Size |; .--------------------.-- +4; | Capacity |; .--------------------.-- +8; | Present Bit Vector |; .--------------------.-- +N; | Deleted Bit Vector |; .--------------------.-- +M ─╮; | Key | │; .--------------------.-- +M+4 │; | Value | │; .--------------------.-- +M+4+sizeof(Value) │; ... ├─ |Capacity| Bucket entries; .--------------------. │; | Key | │; .--------------------. │; | Value | │; .--------------------. ─╯. - **Size** - The number of values contained in the hash table. - **Capacity** - The number of buckets in the hash table. Producers should; maintain a load factor of no greater than ``2/3*Capacity+1``. - **Present Bit Vector** - A serialized bit vector which contains information; about which buckets have valid values. If the bucket has a value, the; corresponding bit will be set, and if the bucket doesn't have a value (either; because the bucket is empty or because the value is a tombstone value) the bit; will be unset. - **Deleted Bit Vector** - A serialized bit v",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/HashTable.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/HashTable.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/HashTable.rst:496,Security,hash,hash,496,"The PDB Serialized Hash Table Format; ====================================. .. contents::; :local:. .. _hash_intro:. Introduction; ============. One of the design goals of the PDB format is to provide accelerated access to; debug information, and for this reason there are several occasions where hash; tables are serialized and embedded directly to the file, rather than requiring; a consumer to read a list of values and reconstruct the hash table on the fly. The serialization format supports hash tables of arbitrarily large size and; capacity, as well as value types and hash functions. The only supported key; value type is a uint32. The only requirement is that the producer and consumer; agree on the hash function. As such, the hash function can is not discussed; further in this document, it is assumed that for a particular instance of a PDB; file hash table, the appropriate hash function is being used. On-Disk Format; ==============. .. code-block:: none. .--------------------.-- +0; | Size |; .--------------------.-- +4; | Capacity |; .--------------------.-- +8; | Present Bit Vector |; .--------------------.-- +N; | Deleted Bit Vector |; .--------------------.-- +M ─╮; | Key | │; .--------------------.-- +M+4 │; | Value | │; .--------------------.-- +M+4+sizeof(Value) │; ... ├─ |Capacity| Bucket entries; .--------------------. │; | Key | │; .--------------------. │; | Value | │; .--------------------. ─╯. - **Size** - The number of values contained in the hash table. - **Capacity** - The number of buckets in the hash table. Producers should; maintain a load factor of no greater than ``2/3*Capacity+1``. - **Present Bit Vector** - A serialized bit vector which contains information; about which buckets have valid values. If the bucket has a value, the; corresponding bit will be set, and if the bucket doesn't have a value (either; because the bucket is empty or because the value is a tombstone value) the bit; will be unset. - **Deleted Bit Vector** - A serialized bit v",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/HashTable.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/HashTable.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/HashTable.rst:576,Security,hash,hash,576,"The PDB Serialized Hash Table Format; ====================================. .. contents::; :local:. .. _hash_intro:. Introduction; ============. One of the design goals of the PDB format is to provide accelerated access to; debug information, and for this reason there are several occasions where hash; tables are serialized and embedded directly to the file, rather than requiring; a consumer to read a list of values and reconstruct the hash table on the fly. The serialization format supports hash tables of arbitrarily large size and; capacity, as well as value types and hash functions. The only supported key; value type is a uint32. The only requirement is that the producer and consumer; agree on the hash function. As such, the hash function can is not discussed; further in this document, it is assumed that for a particular instance of a PDB; file hash table, the appropriate hash function is being used. On-Disk Format; ==============. .. code-block:: none. .--------------------.-- +0; | Size |; .--------------------.-- +4; | Capacity |; .--------------------.-- +8; | Present Bit Vector |; .--------------------.-- +N; | Deleted Bit Vector |; .--------------------.-- +M ─╮; | Key | │; .--------------------.-- +M+4 │; | Value | │; .--------------------.-- +M+4+sizeof(Value) │; ... ├─ |Capacity| Bucket entries; .--------------------. │; | Key | │; .--------------------. │; | Value | │; .--------------------. ─╯. - **Size** - The number of values contained in the hash table. - **Capacity** - The number of buckets in the hash table. Producers should; maintain a load factor of no greater than ``2/3*Capacity+1``. - **Present Bit Vector** - A serialized bit vector which contains information; about which buckets have valid values. If the bucket has a value, the; corresponding bit will be set, and if the bucket doesn't have a value (either; because the bucket is empty or because the value is a tombstone value) the bit; will be unset. - **Deleted Bit Vector** - A serialized bit v",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/HashTable.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/HashTable.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/HashTable.rst:709,Security,hash,hash,709,"The PDB Serialized Hash Table Format; ====================================. .. contents::; :local:. .. _hash_intro:. Introduction; ============. One of the design goals of the PDB format is to provide accelerated access to; debug information, and for this reason there are several occasions where hash; tables are serialized and embedded directly to the file, rather than requiring; a consumer to read a list of values and reconstruct the hash table on the fly. The serialization format supports hash tables of arbitrarily large size and; capacity, as well as value types and hash functions. The only supported key; value type is a uint32. The only requirement is that the producer and consumer; agree on the hash function. As such, the hash function can is not discussed; further in this document, it is assumed that for a particular instance of a PDB; file hash table, the appropriate hash function is being used. On-Disk Format; ==============. .. code-block:: none. .--------------------.-- +0; | Size |; .--------------------.-- +4; | Capacity |; .--------------------.-- +8; | Present Bit Vector |; .--------------------.-- +N; | Deleted Bit Vector |; .--------------------.-- +M ─╮; | Key | │; .--------------------.-- +M+4 │; | Value | │; .--------------------.-- +M+4+sizeof(Value) │; ... ├─ |Capacity| Bucket entries; .--------------------. │; | Key | │; .--------------------. │; | Value | │; .--------------------. ─╯. - **Size** - The number of values contained in the hash table. - **Capacity** - The number of buckets in the hash table. Producers should; maintain a load factor of no greater than ``2/3*Capacity+1``. - **Present Bit Vector** - A serialized bit vector which contains information; about which buckets have valid values. If the bucket has a value, the; corresponding bit will be set, and if the bucket doesn't have a value (either; because the bucket is empty or because the value is a tombstone value) the bit; will be unset. - **Deleted Bit Vector** - A serialized bit v",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/HashTable.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/HashTable.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/HashTable.rst:737,Security,hash,hash,737,"The PDB Serialized Hash Table Format; ====================================. .. contents::; :local:. .. _hash_intro:. Introduction; ============. One of the design goals of the PDB format is to provide accelerated access to; debug information, and for this reason there are several occasions where hash; tables are serialized and embedded directly to the file, rather than requiring; a consumer to read a list of values and reconstruct the hash table on the fly. The serialization format supports hash tables of arbitrarily large size and; capacity, as well as value types and hash functions. The only supported key; value type is a uint32. The only requirement is that the producer and consumer; agree on the hash function. As such, the hash function can is not discussed; further in this document, it is assumed that for a particular instance of a PDB; file hash table, the appropriate hash function is being used. On-Disk Format; ==============. .. code-block:: none. .--------------------.-- +0; | Size |; .--------------------.-- +4; | Capacity |; .--------------------.-- +8; | Present Bit Vector |; .--------------------.-- +N; | Deleted Bit Vector |; .--------------------.-- +M ─╮; | Key | │; .--------------------.-- +M+4 │; | Value | │; .--------------------.-- +M+4+sizeof(Value) │; ... ├─ |Capacity| Bucket entries; .--------------------. │; | Key | │; .--------------------. │; | Value | │; .--------------------. ─╯. - **Size** - The number of values contained in the hash table. - **Capacity** - The number of buckets in the hash table. Producers should; maintain a load factor of no greater than ``2/3*Capacity+1``. - **Present Bit Vector** - A serialized bit vector which contains information; about which buckets have valid values. If the bucket has a value, the; corresponding bit will be set, and if the bucket doesn't have a value (either; because the bucket is empty or because the value is a tombstone value) the bit; will be unset. - **Deleted Bit Vector** - A serialized bit v",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/HashTable.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/HashTable.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/HashTable.rst:859,Security,hash,hash,859,"The PDB Serialized Hash Table Format; ====================================. .. contents::; :local:. .. _hash_intro:. Introduction; ============. One of the design goals of the PDB format is to provide accelerated access to; debug information, and for this reason there are several occasions where hash; tables are serialized and embedded directly to the file, rather than requiring; a consumer to read a list of values and reconstruct the hash table on the fly. The serialization format supports hash tables of arbitrarily large size and; capacity, as well as value types and hash functions. The only supported key; value type is a uint32. The only requirement is that the producer and consumer; agree on the hash function. As such, the hash function can is not discussed; further in this document, it is assumed that for a particular instance of a PDB; file hash table, the appropriate hash function is being used. On-Disk Format; ==============. .. code-block:: none. .--------------------.-- +0; | Size |; .--------------------.-- +4; | Capacity |; .--------------------.-- +8; | Present Bit Vector |; .--------------------.-- +N; | Deleted Bit Vector |; .--------------------.-- +M ─╮; | Key | │; .--------------------.-- +M+4 │; | Value | │; .--------------------.-- +M+4+sizeof(Value) │; ... ├─ |Capacity| Bucket entries; .--------------------. │; | Key | │; .--------------------. │; | Value | │; .--------------------. ─╯. - **Size** - The number of values contained in the hash table. - **Capacity** - The number of buckets in the hash table. Producers should; maintain a load factor of no greater than ``2/3*Capacity+1``. - **Present Bit Vector** - A serialized bit vector which contains information; about which buckets have valid values. If the bucket has a value, the; corresponding bit will be set, and if the bucket doesn't have a value (either; because the bucket is empty or because the value is a tombstone value) the bit; will be unset. - **Deleted Bit Vector** - A serialized bit v",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/HashTable.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/HashTable.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/HashTable.rst:887,Security,hash,hash,887,"The PDB Serialized Hash Table Format; ====================================. .. contents::; :local:. .. _hash_intro:. Introduction; ============. One of the design goals of the PDB format is to provide accelerated access to; debug information, and for this reason there are several occasions where hash; tables are serialized and embedded directly to the file, rather than requiring; a consumer to read a list of values and reconstruct the hash table on the fly. The serialization format supports hash tables of arbitrarily large size and; capacity, as well as value types and hash functions. The only supported key; value type is a uint32. The only requirement is that the producer and consumer; agree on the hash function. As such, the hash function can is not discussed; further in this document, it is assumed that for a particular instance of a PDB; file hash table, the appropriate hash function is being used. On-Disk Format; ==============. .. code-block:: none. .--------------------.-- +0; | Size |; .--------------------.-- +4; | Capacity |; .--------------------.-- +8; | Present Bit Vector |; .--------------------.-- +N; | Deleted Bit Vector |; .--------------------.-- +M ─╮; | Key | │; .--------------------.-- +M+4 │; | Value | │; .--------------------.-- +M+4+sizeof(Value) │; ... ├─ |Capacity| Bucket entries; .--------------------. │; | Key | │; .--------------------. │; | Value | │; .--------------------. ─╯. - **Size** - The number of values contained in the hash table. - **Capacity** - The number of buckets in the hash table. Producers should; maintain a load factor of no greater than ``2/3*Capacity+1``. - **Present Bit Vector** - A serialized bit vector which contains information; about which buckets have valid values. If the bucket has a value, the; corresponding bit will be set, and if the bucket doesn't have a value (either; because the bucket is empty or because the value is a tombstone value) the bit; will be unset. - **Deleted Bit Vector** - A serialized bit v",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/HashTable.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/HashTable.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/HashTable.rst:1482,Security,hash,hash,1482," The serialization format supports hash tables of arbitrarily large size and; capacity, as well as value types and hash functions. The only supported key; value type is a uint32. The only requirement is that the producer and consumer; agree on the hash function. As such, the hash function can is not discussed; further in this document, it is assumed that for a particular instance of a PDB; file hash table, the appropriate hash function is being used. On-Disk Format; ==============. .. code-block:: none. .--------------------.-- +0; | Size |; .--------------------.-- +4; | Capacity |; .--------------------.-- +8; | Present Bit Vector |; .--------------------.-- +N; | Deleted Bit Vector |; .--------------------.-- +M ─╮; | Key | │; .--------------------.-- +M+4 │; | Value | │; .--------------------.-- +M+4+sizeof(Value) │; ... ├─ |Capacity| Bucket entries; .--------------------. │; | Key | │; .--------------------. │; | Value | │; .--------------------. ─╯. - **Size** - The number of values contained in the hash table. - **Capacity** - The number of buckets in the hash table. Producers should; maintain a load factor of no greater than ``2/3*Capacity+1``. - **Present Bit Vector** - A serialized bit vector which contains information; about which buckets have valid values. If the bucket has a value, the; corresponding bit will be set, and if the bucket doesn't have a value (either; because the bucket is empty or because the value is a tombstone value) the bit; will be unset. - **Deleted Bit Vector** - A serialized bit vector which contains information; about which buckets have tombstone values. If the entry in this bucket is; deleted, the bit will be set, otherwise it will be unset. - **Keys and Values** - A list of ``Capacity`` hash buckets, where the first; entry is the key (always a uint32), and the second entry is the value. The; state of each bucket (valid, empty, deleted) can be determined by examining; the present and deleted bit vectors. .. _hash_bit_vectors:. Pre",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/HashTable.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/HashTable.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/HashTable.rst:1540,Security,hash,hash,1540," large size and; capacity, as well as value types and hash functions. The only supported key; value type is a uint32. The only requirement is that the producer and consumer; agree on the hash function. As such, the hash function can is not discussed; further in this document, it is assumed that for a particular instance of a PDB; file hash table, the appropriate hash function is being used. On-Disk Format; ==============. .. code-block:: none. .--------------------.-- +0; | Size |; .--------------------.-- +4; | Capacity |; .--------------------.-- +8; | Present Bit Vector |; .--------------------.-- +N; | Deleted Bit Vector |; .--------------------.-- +M ─╮; | Key | │; .--------------------.-- +M+4 │; | Value | │; .--------------------.-- +M+4+sizeof(Value) │; ... ├─ |Capacity| Bucket entries; .--------------------. │; | Key | │; .--------------------. │; | Value | │; .--------------------. ─╯. - **Size** - The number of values contained in the hash table. - **Capacity** - The number of buckets in the hash table. Producers should; maintain a load factor of no greater than ``2/3*Capacity+1``. - **Present Bit Vector** - A serialized bit vector which contains information; about which buckets have valid values. If the bucket has a value, the; corresponding bit will be set, and if the bucket doesn't have a value (either; because the bucket is empty or because the value is a tombstone value) the bit; will be unset. - **Deleted Bit Vector** - A serialized bit vector which contains information; about which buckets have tombstone values. If the entry in this bucket is; deleted, the bit will be set, otherwise it will be unset. - **Keys and Values** - A list of ``Capacity`` hash buckets, where the first; entry is the key (always a uint32), and the second entry is the value. The; state of each bucket (valid, empty, deleted) can be determined by examining; the present and deleted bit vectors. .. _hash_bit_vectors:. Present and Deleted Bit Vectors; ==============================",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/HashTable.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/HashTable.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/HashTable.rst:2215,Security,hash,hash,2215," | │; .--------------------.-- +M+4+sizeof(Value) │; ... ├─ |Capacity| Bucket entries; .--------------------. │; | Key | │; .--------------------. │; | Value | │; .--------------------. ─╯. - **Size** - The number of values contained in the hash table. - **Capacity** - The number of buckets in the hash table. Producers should; maintain a load factor of no greater than ``2/3*Capacity+1``. - **Present Bit Vector** - A serialized bit vector which contains information; about which buckets have valid values. If the bucket has a value, the; corresponding bit will be set, and if the bucket doesn't have a value (either; because the bucket is empty or because the value is a tombstone value) the bit; will be unset. - **Deleted Bit Vector** - A serialized bit vector which contains information; about which buckets have tombstone values. If the entry in this bucket is; deleted, the bit will be set, otherwise it will be unset. - **Keys and Values** - A list of ``Capacity`` hash buckets, where the first; entry is the key (always a uint32), and the second entry is the value. The; state of each bucket (valid, empty, deleted) can be determined by examining; the present and deleted bit vectors. .. _hash_bit_vectors:. Present and Deleted Bit Vectors; ===============================. The bit vectors indicating the status of each bucket are serialized as follows:. .. code-block:: none. .--------------------.-- +0; | Word Count |; .--------------------.-- +4; | Word_0 | ─╮; .--------------------.-- +8 │; | Word_1 | │; .--------------------.-- +12 ├─ |Word Count| values; ... │; .--------------------. │; | Word_N | │; .--------------------. ─╯. The words, when viewed as a contiguous block of bytes, represent a bit vector; with the following layout:. .. code-block:: none. .------------. .------------.------------.; | Word_N | ... | Word_1 | Word_0 |; .------------. .------------.------------.; | | | | |; +N*32 +(N-1)*32 +64 +32 +0. where the k'th bit of this bit vector represents the status o",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/HashTable.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/HashTable.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/HashTable.rst:3268,Security,hash,hash,3268,"of(Value) │; ... ├─ |Capacity| Bucket entries; .--------------------. │; | Key | │; .--------------------. │; | Value | │; .--------------------. ─╯. - **Size** - The number of values contained in the hash table. - **Capacity** - The number of buckets in the hash table. Producers should; maintain a load factor of no greater than ``2/3*Capacity+1``. - **Present Bit Vector** - A serialized bit vector which contains information; about which buckets have valid values. If the bucket has a value, the; corresponding bit will be set, and if the bucket doesn't have a value (either; because the bucket is empty or because the value is a tombstone value) the bit; will be unset. - **Deleted Bit Vector** - A serialized bit vector which contains information; about which buckets have tombstone values. If the entry in this bucket is; deleted, the bit will be set, otherwise it will be unset. - **Keys and Values** - A list of ``Capacity`` hash buckets, where the first; entry is the key (always a uint32), and the second entry is the value. The; state of each bucket (valid, empty, deleted) can be determined by examining; the present and deleted bit vectors. .. _hash_bit_vectors:. Present and Deleted Bit Vectors; ===============================. The bit vectors indicating the status of each bucket are serialized as follows:. .. code-block:: none. .--------------------.-- +0; | Word Count |; .--------------------.-- +4; | Word_0 | ─╮; .--------------------.-- +8 │; | Word_1 | │; .--------------------.-- +12 ├─ |Word Count| values; ... │; .--------------------. │; | Word_N | │; .--------------------. ─╯. The words, when viewed as a contiguous block of bytes, represent a bit vector; with the following layout:. .. code-block:: none. .------------. .------------.------------.; | Word_N | ... | Word_1 | Word_0 |; .------------. .------------.------------.; | | | | |; +N*32 +(N-1)*32 +64 +32 +0. where the k'th bit of this bit vector represents the status of the k'th bucket; in the hash table.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/HashTable.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/HashTable.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/index.rst:1194,Modifiability,extend,extend,1194," which contains; debug information that can be consumed by debuggers and other tools. Since; officially supported APIs exist on Windows for querying debug information from; PDBs even without the user understanding the internals of the file format, a; large ecosystem of tools has been built for Windows to consume this format. In; order for Clang to be able to generate programs that can interoperate with these; tools, it is necessary for us to generate PDB files ourselves. At the same time, LLVM has a long history of being able to cross-compile from; any platform to any platform, and we wish for the same to be true here. So it; is necessary for us to understand the PDB file format at the byte-level so that; we can generate PDB files entirely on our own. This manual describes what we know about the PDB file format today. The layout; of the file, the various streams contained within, the format of individual; records within, and more. We would like to extend our heartfelt gratitude to Microsoft, without whom we; would not be where we are today. Much of the knowledge contained within this; manual was learned through reading code published by Microsoft on their `GitHub; repo <https://github.com/Microsoft/microsoft-pdb>`__. .. _pdb_layout:. File Layout; ===========. .. important::; Unless otherwise specified, all numeric values are encoded in little endian.; If you see a type such as ``uint16_t`` or ``uint64_t`` going forward, always; assume it is little endian!. .. toctree::; :hidden:. MsfFile; PdbStream; TpiStream; DbiStream; ModiStream; PublicStream; GlobalStream; HashTable; CodeViewSymbols; CodeViewTypes. .. _msf:. The MSF Container; -----------------; A PDB file is an MSF (Multi-Stream Format) file. An MSF file is a ""file system; within a file"". It contains multiple streams (aka files) which can represent; arbitrary data, and these streams are divided into blocks which may not; necessarily be contiguously laid out within the MSF container file.; Additionally, the MSF ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/index.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/index.rst:2700,Security,hash,hash,2700,"ream; ModiStream; PublicStream; GlobalStream; HashTable; CodeViewSymbols; CodeViewTypes. .. _msf:. The MSF Container; -----------------; A PDB file is an MSF (Multi-Stream Format) file. An MSF file is a ""file system; within a file"". It contains multiple streams (aka files) which can represent; arbitrary data, and these streams are divided into blocks which may not; necessarily be contiguously laid out within the MSF container file.; Additionally, the MSF contains a stream directory (aka MFT) which describes how; the streams (files) are laid out within the MSF. For more information about the MSF container format, stream directory, and; block layout, see :doc:`MsfFile`. .. _streams:. Streams; -------; The PDB format contains a number of streams which describe various information; such as the types, symbols, source files, and compilands (e.g. object files); of a program, as well as some additional streams containing hash tables that are; used by debuggers and other tools to provide fast lookup of records and types; by name, and various other information about how the program was compiled such; as the specific toolchain used, and more. A summary of streams contained in a; PDB file is as follows:. +--------------------+------------------------------+-------------------------------------------+; | Name | Stream Index | Contents |; +====================+==============================+===========================================+; | Old Directory | - Fixed Stream Index 0 | - Previous MSF Stream Directory |; +--------------------+------------------------------+-------------------------------------------+; | PDB Stream | - Fixed Stream Index 1 | - Basic File Information |; | | | - Fields to match EXE to this PDB |; | | | - Map of named streams to stream indices |; +--------------------+------------------------------+-------------------------------------------+; | TPI Stream | - Fixed Stream Index 2 | - CodeView Type Records |; | | | - Index of TPI Hash Stream |; +-------------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/index.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/index.rst:7039,Security,hash,hash,7039,"eam | - Single combined symbol-table |; | | | - Index of Global Hash Stream |; +--------------------+------------------------------+-------------------------------------------+; | TPI Hash Stream | - Contained in TPI Stream | - Hash table for looking up TPI records |; | | | by name |; +--------------------+------------------------------+-------------------------------------------+; | IPI Hash Stream | - Contained in IPI Stream | - Hash table for looking up IPI records |; | | | by name |; +--------------------+------------------------------+-------------------------------------------+. More information about the structure of each of these can be found on the; following pages:. :doc:`PdbStream`; Information about the PDB Info Stream and how it is used to match PDBs to EXEs. :doc:`TpiStream`; Information about the TPI stream and the CodeView records contained within. :doc:`DbiStream`; Information about the DBI stream and relevant substreams including the; Module Substreams, source file information, and CodeView symbol records; contained within. :doc:`ModiStream`; Information about the Module Information Stream, of which there is one for; each compilation unit and the format of symbols contained within. :doc:`PublicStream`; Information about the Public Symbol Stream. :doc:`GlobalStream`; Information about the Global Symbol Stream. :doc:`HashTable`; Information about the serialized hash table format used internally to; represent things such as the Named Stream Map and the Hash Adjusters in the; :doc:`TPI/IPI Stream <TpiStream>`. CodeView; ========; CodeView is another format which comes into the picture. While MSF defines; the structure of the overall file, and PDB defines the set of streams that; appear within the MSF file and the format of those streams, CodeView defines; the format of **symbol and type records** that appear within specific streams.; Refer to the pages on :doc:`CodeViewSymbols` and :doc:`CodeViewTypes` for; more information about the CodeView format.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/index.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/index.rst:1345,Usability,learn,learned,1345,"ndows for querying debug information from; PDBs even without the user understanding the internals of the file format, a; large ecosystem of tools has been built for Windows to consume this format. In; order for Clang to be able to generate programs that can interoperate with these; tools, it is necessary for us to generate PDB files ourselves. At the same time, LLVM has a long history of being able to cross-compile from; any platform to any platform, and we wish for the same to be true here. So it; is necessary for us to understand the PDB file format at the byte-level so that; we can generate PDB files entirely on our own. This manual describes what we know about the PDB file format today. The layout; of the file, the various streams contained within, the format of individual; records within, and more. We would like to extend our heartfelt gratitude to Microsoft, without whom we; would not be where we are today. Much of the knowledge contained within this; manual was learned through reading code published by Microsoft on their `GitHub; repo <https://github.com/Microsoft/microsoft-pdb>`__. .. _pdb_layout:. File Layout; ===========. .. important::; Unless otherwise specified, all numeric values are encoded in little endian.; If you see a type such as ``uint16_t`` or ``uint64_t`` going forward, always; assume it is little endian!. .. toctree::; :hidden:. MsfFile; PdbStream; TpiStream; DbiStream; ModiStream; PublicStream; GlobalStream; HashTable; CodeViewSymbols; CodeViewTypes. .. _msf:. The MSF Container; -----------------; A PDB file is an MSF (Multi-Stream Format) file. An MSF file is a ""file system; within a file"". It contains multiple streams (aka files) which can represent; arbitrary data, and these streams are divided into blocks which may not; necessarily be contiguously laid out within the MSF container file.; Additionally, the MSF contains a stream directory (aka MFT) which describes how; the streams (files) are laid out within the MSF. For more information a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/index.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/ModiStream.rst:2763,Modifiability,variab,variable,2763,"lobalRefs[GlobalRefsSize];; };. - **Signature** - Unknown. In practice only the value of ``4`` has been; observed. It is hypothesized that this value corresponds to the set of; ``CV_SIGNATURE_xx`` defines in ``cvinfo.h``, with the value of ``4``; meaning that this module has C13 line information (as opposed to C11 line; information). A corollary of this is that we expect to only ever see; C13 line info, and that we do not understand the format of C11 line info. - **Symbols** - The :ref:`CodeView Symbol Substream <modi_symbol_substream>`.; ``SymbolSize`` is equal to the value of ``SymByteSize`` for the; corresponding module's entry in the :ref:`Module Info Substream; <dbi_mod_info_substream>` of the :doc:`DBI Stream <DbiStream>`. - **C11LineInfo** - A block containing CodeView line information in C11; format. ``C11Size`` is equal to the value of ``C11ByteSize`` from the; :ref:`Module Info Substream <dbi_mod_info_substream>` of the; :doc:`DBI Stream <DbiStream>`. If this value is ``0``, then C11 line; information is not present. As mentioned previously, the format of; C11 line info is not understood and we assume all line in modern PDBs; to be in C13 format. - **C13LineInfo** - A block containing CodeView line information in C13; format. ``C13Size`` is equal to the value of ``C13ByteSize`` from the; :ref:`Module Info Substream <dbi_mod_info_substream>` of the; :doc:`DBI Stream <DbiStream>`. If this value is ``0``, then C13 line; information is not present. - **GlobalRefs** - The meaning of this substream is not understood. .. _modi_symbol_substream:. The CodeView Symbol Substream; =============================. The CodeView Symbol Substream. This is an array of variable length; records describing the functions, variables, inlining information,; and other symbols defined in the compiland. The entire array consumes; ``SymbolSize-4`` bytes. The format of a CodeView Symbol Record (and; thusly, an array of CodeView Symbol Records) is described in; :doc:`CodeViewSymbols`.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/ModiStream.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/ModiStream.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/ModiStream.rst:2814,Modifiability,variab,variables,2814,"lobalRefs[GlobalRefsSize];; };. - **Signature** - Unknown. In practice only the value of ``4`` has been; observed. It is hypothesized that this value corresponds to the set of; ``CV_SIGNATURE_xx`` defines in ``cvinfo.h``, with the value of ``4``; meaning that this module has C13 line information (as opposed to C11 line; information). A corollary of this is that we expect to only ever see; C13 line info, and that we do not understand the format of C11 line info. - **Symbols** - The :ref:`CodeView Symbol Substream <modi_symbol_substream>`.; ``SymbolSize`` is equal to the value of ``SymByteSize`` for the; corresponding module's entry in the :ref:`Module Info Substream; <dbi_mod_info_substream>` of the :doc:`DBI Stream <DbiStream>`. - **C11LineInfo** - A block containing CodeView line information in C11; format. ``C11Size`` is equal to the value of ``C11ByteSize`` from the; :ref:`Module Info Substream <dbi_mod_info_substream>` of the; :doc:`DBI Stream <DbiStream>`. If this value is ``0``, then C11 line; information is not present. As mentioned previously, the format of; C11 line info is not understood and we assume all line in modern PDBs; to be in C13 format. - **C13LineInfo** - A block containing CodeView line information in C13; format. ``C13Size`` is equal to the value of ``C13ByteSize`` from the; :ref:`Module Info Substream <dbi_mod_info_substream>` of the; :doc:`DBI Stream <DbiStream>`. If this value is ``0``, then C13 line; information is not present. - **GlobalRefs** - The meaning of this substream is not understood. .. _modi_symbol_substream:. The CodeView Symbol Substream; =============================. The CodeView Symbol Substream. This is an array of variable length; records describing the functions, variables, inlining information,; and other symbols defined in the compiland. The entire array consumes; ``SymbolSize-4`` bytes. The format of a CodeView Symbol Record (and; thusly, an array of CodeView Symbol Records) is described in; :doc:`CodeViewSymbols`.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/ModiStream.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/ModiStream.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/MsfFile.rst:4396,Deployability,update,updates,4396,"of a block within the MSF file. At this block is; an array of ``ulittle32_t``'s listing the blocks that the stream directory; resides on. For large MSF files, the stream directory (which describes the; block layout of each stream) may not fit entirely on a single block. As a; result, this extra layer of indirection is introduced, whereby this block; contains the list of blocks that the stream directory occupies, and the stream; directory itself can be stitched together accordingly. The number of; ``ulittle32_t``'s in this array is given by ``ceil(NumDirectoryBytes /; BlockSize)``. .. _msf_freeblockmap:. The Free Block Map; ==================. The Free Block Map (sometimes referred to as the Free Page Map, or FPM) is a; series of blocks which contains a bit flag for every block in the file. The; flag will be set to 0 if the block is in use, and 1 if the block is unused. Each file contains two FPMs, one of which is active at any given time. This; feature is designed to support incremental and atomic updates of the underlying; MSF file. While writing to an MSF file, if the active FPM is FPM1, you can; write your new modified bitfield to FPM2, and vice versa. Only when you commit; the file to disk do you need to swap the value in the SuperBlock to point to; the new ``FreeBlockMapBlock``. The Free Block Maps are stored as a series of single blocks throughout the file; at intervals of BlockSize. Because each FPM block is of size ``BlockSize``; bytes, it contains 8 times as many bits as an interval has blocks. This means; that the first block of each FPM refers to the first 8 intervals of the file; (the first 32768 blocks), the second block of each FPM refers to the next 8; blocks, and so on. This results in far more FPM blocks being present than are; required, but in order to maintain backwards compatibility the format must stay; this way. The Stream Directory; ====================; The Stream Directory is the root of all access to the other streams in an MSF; file. Beginn",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/MsfFile.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/MsfFile.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/MsfFile.rst:2523,Integrability,depend,depending,2523,"----------------+------------------+------------------+----------+----+------+------+------+-------------+----+-----+. The file may end after any block, including immediately after a FPM1. .. note::; LLVM only supports 4096 byte blocks (sometimes referred to as the ""BigMsf""; variant), so the rest of this document will assume a block size of 4096. .. _msf_superblock:. The Superblock; ==============; At file offset 0 in an MSF file is the MSF *SuperBlock*, which is laid out as; follows:. .. code-block:: c++. struct SuperBlock {; char FileMagic[sizeof(Magic)];; ulittle32_t BlockSize;; ulittle32_t FreeBlockMapBlock;; ulittle32_t NumBlocks;; ulittle32_t NumDirectoryBytes;; ulittle32_t Unknown;; ulittle32_t BlockMapAddr;; };. - **FileMagic** - Must be equal to ``""Microsoft C / C++ MSF 7.00\\r\\n""``; followed by the bytes ``1A 44 53 00 00 00``.; - **BlockSize** - The block size of the internal file system. Valid values are; 512, 1024, 2048, and 4096 bytes. Certain aspects of the MSF file layout vary; depending on the block sizes. For the purposes of LLVM, we handle only block; sizes of 4KiB, and all further discussion assumes a block size of 4KiB.; - **FreeBlockMapBlock** - The index of a block within the file, at which begins; a bitfield representing the set of all blocks within the file which are ""free""; (i.e. the data within that block is not used). See :ref:`msf_freeblockmap`; for more information.; **Important**: ``FreeBlockMapBlock`` can only be ``1`` or ``2``!; - **NumBlocks** - The total number of blocks in the file. ``NumBlocks *; BlockSize`` should equal the size of the file on disk.; - **NumDirectoryBytes** - The size of the stream directory, in bytes. The; stream directory contains information about each stream's size and the set of; blocks that it occupies. It will be described in more detail later.; - **BlockMapAddr** - The index of a block within the MSF file. At this block is; an array of ``ulittle32_t``'s listing the blocks that the stream directory; reside",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/MsfFile.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/MsfFile.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/MsfFile.rst:7672,Integrability,depend,depending,7672,"ays is of variable length, and in particular; that the second array is jagged. **Example:** Suppose a hypothetical PDB file with a 4KiB block size, and 4; streams of lengths {1000 bytes, 8000 bytes, 16000 bytes, 9000 bytes}. Stream 0: ceil(1000 / 4096) = 1 block. Stream 1: ceil(8000 / 4096) = 2 blocks. Stream 2: ceil(16000 / 4096) = 4 blocks. Stream 3: ceil(9000 / 4096) = 3 blocks. In total, 10 blocks are used. Let's see what the stream directory might look; like:. .. code-block:: c++. struct StreamDirectory {; ulittle32_t NumStreams = 4;; ulittle32_t StreamSizes[] = {1000, 8000, 16000, 9000};; ulittle32_t StreamBlocks[][] = {; {4},; {5, 6},; {11, 9, 7, 8},; {10, 15, 12}; };; };. In total, this occupies ``15 * 4 = 60`` bytes, so; ``SuperBlock->NumDirectoryBytes`` would equal ``60``, and; ``SuperBlock->BlockMapAddr`` would be an array of one ``ulittle32_t``, since; ``60 <= SuperBlock->BlockSize``. Note also that the streams are discontiguous, and that part of stream 3 is in the; middle of part of stream 2. You cannot assume anything about the layout of the; blocks!. Alignment and Block Boundaries; ==============================; As may be clear by now, it is possible for a single field (whether it be a high; level record, a long string field, or even a single ``uint16``) to begin and; end in separate blocks. For example, if the block size is 4096 bytes, and a; ``uint16`` field begins at the last byte of the current block, then it would; need to end on the first byte of the next block. Since blocks are not; necessarily contiguously laid out in the file, this means that both the consumer; and the producer of an MSF file must be prepared to split data apart; accordingly. In the aforementioned example, the high byte of the ``uint16``; would be written to the last byte of block N, and the low byte would be written; to the first byte of block N+1, which could be tens of thousands of bytes later; (or even earlier!) in the file, depending on what the stream directory says.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/MsfFile.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/MsfFile.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/MsfFile.rst:5728,Modifiability,variab,variable,5728,"e blocks throughout the file; at intervals of BlockSize. Because each FPM block is of size ``BlockSize``; bytes, it contains 8 times as many bits as an interval has blocks. This means; that the first block of each FPM refers to the first 8 intervals of the file; (the first 32768 blocks), the second block of each FPM refers to the next 8; blocks, and so on. This results in far more FPM blocks being present than are; required, but in order to maintain backwards compatibility the format must stay; this way. The Stream Directory; ====================; The Stream Directory is the root of all access to the other streams in an MSF; file. Beginning at byte 0 of the stream directory is the following structure:. .. code-block:: c++. struct StreamDirectory {; ulittle32_t NumStreams;; ulittle32_t StreamSizes[NumStreams];; ulittle32_t StreamBlocks[NumStreams][];; };. And this structure occupies exactly ``SuperBlock->NumDirectoryBytes`` bytes.; Note that each of the last two arrays is of variable length, and in particular; that the second array is jagged. **Example:** Suppose a hypothetical PDB file with a 4KiB block size, and 4; streams of lengths {1000 bytes, 8000 bytes, 16000 bytes, 9000 bytes}. Stream 0: ceil(1000 / 4096) = 1 block. Stream 1: ceil(8000 / 4096) = 2 blocks. Stream 2: ceil(16000 / 4096) = 4 blocks. Stream 3: ceil(9000 / 4096) = 3 blocks. In total, 10 blocks are used. Let's see what the stream directory might look; like:. .. code-block:: c++. struct StreamDirectory {; ulittle32_t NumStreams = 4;; ulittle32_t StreamSizes[] = {1000, 8000, 16000, 9000};; ulittle32_t StreamBlocks[][] = {; {4},; {5, 6},; {11, 9, 7, 8},; {10, 15, 12}; };; };. In total, this occupies ``15 * 4 = 60`` bytes, so; ``SuperBlock->NumDirectoryBytes`` would equal ``60``, and; ``SuperBlock->BlockMapAddr`` would be an array of one ``ulittle32_t``, since; ``60 <= SuperBlock->BlockSize``. Note also that the streams are discontiguous, and that part of stream 3 is in the; middle of part of stream 2. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/MsfFile.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/MsfFile.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/MsfFile.rst:5333,Security,access,access,5333,"tive at any given time. This; feature is designed to support incremental and atomic updates of the underlying; MSF file. While writing to an MSF file, if the active FPM is FPM1, you can; write your new modified bitfield to FPM2, and vice versa. Only when you commit; the file to disk do you need to swap the value in the SuperBlock to point to; the new ``FreeBlockMapBlock``. The Free Block Maps are stored as a series of single blocks throughout the file; at intervals of BlockSize. Because each FPM block is of size ``BlockSize``; bytes, it contains 8 times as many bits as an interval has blocks. This means; that the first block of each FPM refers to the first 8 intervals of the file; (the first 32768 blocks), the second block of each FPM refers to the next 8; blocks, and so on. This results in far more FPM blocks being present than are; required, but in order to maintain backwards compatibility the format must stay; this way. The Stream Directory; ====================; The Stream Directory is the root of all access to the other streams in an MSF; file. Beginning at byte 0 of the stream directory is the following structure:. .. code-block:: c++. struct StreamDirectory {; ulittle32_t NumStreams;; ulittle32_t StreamSizes[NumStreams];; ulittle32_t StreamBlocks[NumStreams][];; };. And this structure occupies exactly ``SuperBlock->NumDirectoryBytes`` bytes.; Note that each of the last two arrays is of variable length, and in particular; that the second array is jagged. **Example:** Suppose a hypothetical PDB file with a 4KiB block size, and 4; streams of lengths {1000 bytes, 8000 bytes, 16000 bytes, 9000 bytes}. Stream 0: ceil(1000 / 4096) = 1 block. Stream 1: ceil(8000 / 4096) = 2 blocks. Stream 2: ceil(16000 / 4096) = 4 blocks. Stream 3: ceil(9000 / 4096) = 3 blocks. In total, 10 blocks are used. Let's see what the stream directory might look; like:. .. code-block:: c++. struct StreamDirectory {; ulittle32_t NumStreams = 4;; ulittle32_t StreamSizes[] = {1000, 8000, 16000, 9",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/MsfFile.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/MsfFile.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/MsfFile.rst:6874,Usability,clear,clear,6874,"ays is of variable length, and in particular; that the second array is jagged. **Example:** Suppose a hypothetical PDB file with a 4KiB block size, and 4; streams of lengths {1000 bytes, 8000 bytes, 16000 bytes, 9000 bytes}. Stream 0: ceil(1000 / 4096) = 1 block. Stream 1: ceil(8000 / 4096) = 2 blocks. Stream 2: ceil(16000 / 4096) = 4 blocks. Stream 3: ceil(9000 / 4096) = 3 blocks. In total, 10 blocks are used. Let's see what the stream directory might look; like:. .. code-block:: c++. struct StreamDirectory {; ulittle32_t NumStreams = 4;; ulittle32_t StreamSizes[] = {1000, 8000, 16000, 9000};; ulittle32_t StreamBlocks[][] = {; {4},; {5, 6},; {11, 9, 7, 8},; {10, 15, 12}; };; };. In total, this occupies ``15 * 4 = 60`` bytes, so; ``SuperBlock->NumDirectoryBytes`` would equal ``60``, and; ``SuperBlock->BlockMapAddr`` would be an array of one ``ulittle32_t``, since; ``60 <= SuperBlock->BlockSize``. Note also that the streams are discontiguous, and that part of stream 3 is in the; middle of part of stream 2. You cannot assume anything about the layout of the; blocks!. Alignment and Block Boundaries; ==============================; As may be clear by now, it is possible for a single field (whether it be a high; level record, a long string field, or even a single ``uint16``) to begin and; end in separate blocks. For example, if the block size is 4096 bytes, and a; ``uint16`` field begins at the last byte of the current block, then it would; need to end on the first byte of the next block. Since blocks are not; necessarily contiguously laid out in the file, this means that both the consumer; and the producer of an MSF file must be prepared to split data apart; accordingly. In the aforementioned example, the high byte of the ``uint16``; would be written to the last byte of block N, and the low byte would be written; to the first byte of block N+1, which could be tens of thousands of bytes later; (or even earlier!) in the file, depending on what the stream directory says.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/MsfFile.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/MsfFile.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/PdbStream.rst:2018,Security,hash,hash,2018," if the value is something other than ``VC70``. - **Signature** - A 32-bit time-stamp generated with a call to ``time()`` at; the time the PDB file is written. Note that due to the inherent uniqueness; problems of using a timestamp with 1-second granularity, this field does not; really serve its intended purpose, and as such is typically ignored in favor; of the ``Guid`` field, described below. - **Age** - The number of times the PDB file has been written. This can be used; along with ``Guid`` to match the PDB to its corresponding executable. - **Guid** - A 128-bit identifier guaranteed to be unique across space and time.; In general, this can be thought of as the result of calling the Win32 API; `UuidCreate <https://msdn.microsoft.com/en-us/library/windows/desktop/aa379205(v=vs.85).aspx>`__,; although LLVM cannot rely on that, as it must work on non-Windows platforms. .. _pdb_named_stream_map:. Named Stream Map; ================. Following the header is a serialized hash table whose key type is a string, and; whose value type is an integer. The existence of a mapping ``X -> Y`` means; that the stream with the name ``X`` has stream index ``Y`` in the underlying MSF; file. Note that not all streams are named (for example, the; :doc:`TPI Stream <TpiStream>` has a fixed index and as such there is no need to; look up its index by name). In practice, there are usually only a small number; of named streams and these are enumerated in the table of streams in :doc:`index`.; A corollary of this is if a stream does have a name (and as such is in the named; stream map) then consulting the Named Stream Map is likely to be the only way to; discover the stream's MSF stream index. Several important streams (such as the; global string table, which is called ``/names``) can only be located this way, and; so it is important to both produce and consume this correctly as tools will not; function correctly without it. .. important::; Some streams are located by fixed indices (e.g TPI Str",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/PdbStream.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/PdbStream.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/PdbStream.rst:3371,Security,hash,hash,3371,"me). In practice, there are usually only a small number; of named streams and these are enumerated in the table of streams in :doc:`index`.; A corollary of this is if a stream does have a name (and as such is in the named; stream map) then consulting the Named Stream Map is likely to be the only way to; discover the stream's MSF stream index. Several important streams (such as the; global string table, which is called ``/names``) can only be located this way, and; so it is important to both produce and consume this correctly as tools will not; function correctly without it. .. important::; Some streams are located by fixed indices (e.g TPI Stream has index 2), but; other streams are located by fixed names (e.g. the string table is called; ``/names``) and can only be located by consulting the Named Stream Map. The on-disk layout of the Named Stream Map consists of 2 components. The first is; a buffer of string data prefixed by a 32-bit length. The second is a serialized; hash table whose key and value types are both ``uint32_t``. The key is the offset; of a null-terminated string in the string data buffer specifying the name of the; stream, and the value is the MSF stream index of the stream with said name.; Note that although the key is an integer, the hash function used to find the right; bucket hashes the string at the corresponding offset in the string data buffer. The on-disk layout of the serialized hash table is described at :doc:`HashTable`. Note that the entire Named Stream Map is not length-prefixed, so the only way to; get to the data following it is to de-serialize it in its entirety. .. _pdb_stream_features:. PDB Feature Codes; =================; Following the Named Stream Map, and consuming all remaining bytes of the PDB; Stream is a list of values from the following enumeration:. .. code-block:: c++. enum class PdbRaw_FeatureSig : uint32_t {; VC110 = 20091201,; VC140 = 20140508,; NoTypeMerge = 0x4D544F4E,; MinimalDebugInfo = 0x494E494D,; };. The meanin",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/PdbStream.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/PdbStream.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/PdbStream.rst:3659,Security,hash,hash,3659,"scover the stream's MSF stream index. Several important streams (such as the; global string table, which is called ``/names``) can only be located this way, and; so it is important to both produce and consume this correctly as tools will not; function correctly without it. .. important::; Some streams are located by fixed indices (e.g TPI Stream has index 2), but; other streams are located by fixed names (e.g. the string table is called; ``/names``) and can only be located by consulting the Named Stream Map. The on-disk layout of the Named Stream Map consists of 2 components. The first is; a buffer of string data prefixed by a 32-bit length. The second is a serialized; hash table whose key and value types are both ``uint32_t``. The key is the offset; of a null-terminated string in the string data buffer specifying the name of the; stream, and the value is the MSF stream index of the stream with said name.; Note that although the key is an integer, the hash function used to find the right; bucket hashes the string at the corresponding offset in the string data buffer. The on-disk layout of the serialized hash table is described at :doc:`HashTable`. Note that the entire Named Stream Map is not length-prefixed, so the only way to; get to the data following it is to de-serialize it in its entirety. .. _pdb_stream_features:. PDB Feature Codes; =================; Following the Named Stream Map, and consuming all remaining bytes of the PDB; Stream is a list of values from the following enumeration:. .. code-block:: c++. enum class PdbRaw_FeatureSig : uint32_t {; VC110 = 20091201,; VC140 = 20140508,; NoTypeMerge = 0x4D544F4E,; MinimalDebugInfo = 0x494E494D,; };. The meaning of these values is summarized by the following table:. +------------------+-------------------------------------------------+; | Flag | Meaning |; +==================+=================================================+; | VC110 | - No other features flags are present |; | | - PDB contains an :doc:`IPI Stre",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/PdbStream.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/PdbStream.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/PdbStream.rst:3704,Security,hash,hashes,3704,"scover the stream's MSF stream index. Several important streams (such as the; global string table, which is called ``/names``) can only be located this way, and; so it is important to both produce and consume this correctly as tools will not; function correctly without it. .. important::; Some streams are located by fixed indices (e.g TPI Stream has index 2), but; other streams are located by fixed names (e.g. the string table is called; ``/names``) and can only be located by consulting the Named Stream Map. The on-disk layout of the Named Stream Map consists of 2 components. The first is; a buffer of string data prefixed by a 32-bit length. The second is a serialized; hash table whose key and value types are both ``uint32_t``. The key is the offset; of a null-terminated string in the string data buffer specifying the name of the; stream, and the value is the MSF stream index of the stream with said name.; Note that although the key is an integer, the hash function used to find the right; bucket hashes the string at the corresponding offset in the string data buffer. The on-disk layout of the serialized hash table is described at :doc:`HashTable`. Note that the entire Named Stream Map is not length-prefixed, so the only way to; get to the data following it is to de-serialize it in its entirety. .. _pdb_stream_features:. PDB Feature Codes; =================; Following the Named Stream Map, and consuming all remaining bytes of the PDB; Stream is a list of values from the following enumeration:. .. code-block:: c++. enum class PdbRaw_FeatureSig : uint32_t {; VC110 = 20091201,; VC140 = 20140508,; NoTypeMerge = 0x4D544F4E,; MinimalDebugInfo = 0x494E494D,; };. The meaning of these values is summarized by the following table:. +------------------+-------------------------------------------------+; | Flag | Meaning |; +==================+=================================================+; | VC110 | - No other features flags are present |; | | - PDB contains an :doc:`IPI Stre",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/PdbStream.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/PdbStream.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/PdbStream.rst:3814,Security,hash,hash,3814,"`) can only be located this way, and; so it is important to both produce and consume this correctly as tools will not; function correctly without it. .. important::; Some streams are located by fixed indices (e.g TPI Stream has index 2), but; other streams are located by fixed names (e.g. the string table is called; ``/names``) and can only be located by consulting the Named Stream Map. The on-disk layout of the Named Stream Map consists of 2 components. The first is; a buffer of string data prefixed by a 32-bit length. The second is a serialized; hash table whose key and value types are both ``uint32_t``. The key is the offset; of a null-terminated string in the string data buffer specifying the name of the; stream, and the value is the MSF stream index of the stream with said name.; Note that although the key is an integer, the hash function used to find the right; bucket hashes the string at the corresponding offset in the string data buffer. The on-disk layout of the serialized hash table is described at :doc:`HashTable`. Note that the entire Named Stream Map is not length-prefixed, so the only way to; get to the data following it is to de-serialize it in its entirety. .. _pdb_stream_features:. PDB Feature Codes; =================; Following the Named Stream Map, and consuming all remaining bytes of the PDB; Stream is a list of values from the following enumeration:. .. code-block:: c++. enum class PdbRaw_FeatureSig : uint32_t {; VC110 = 20091201,; VC140 = 20140508,; NoTypeMerge = 0x4D544F4E,; MinimalDebugInfo = 0x494E494D,; };. The meaning of these values is summarized by the following table:. +------------------+-------------------------------------------------+; | Flag | Meaning |; +==================+=================================================+; | VC110 | - No other features flags are present |; | | - PDB contains an :doc:`IPI Stream <TpiStream>` |; +------------------+-------------------------------------------------+; | VC140 | - Other feature flags ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/PdbStream.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/PdbStream.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/PdbStream.rst:5727,Usability,guid,guid,5727,"es flags are present |; | | - PDB contains an :doc:`IPI Stream <TpiStream>` |; +------------------+-------------------------------------------------+; | VC140 | - Other feature flags may be present |; | | - PDB contains an :doc:`IPI Stream <TpiStream>` |; +------------------+-------------------------------------------------+; | NoTypeMerge | - Presumably duplicate types can appear in the |; | | TPI Stream, although it's unclear why this |; | | might happen. |; +------------------+-------------------------------------------------+; | MinimalDebugInfo | - Program was linked with /DEBUG:FASTLINK |; | | - There is no TPI / IPI stream, all type info |; | | is contained in the original object files. |; +------------------+-------------------------------------------------+. Matching a PDB to its executable; ================================; The linker is responsible for writing both the PDB and the final executable, and; as a result is the only entity capable of writing the information necessary to; match the PDB to the executable. In order to accomplish this, the linker generates a guid for the PDB (or; re-uses the existing guid if it is linking incrementally) and increments the Age; field. The executable is a PE/COFF file, and part of a PE/COFF file is the presence of; number of ""directories"". For our purposes here, we are interested in the ""debug; directory"". The exact format of a debug directory is described by the; `IMAGE_DEBUG_DIRECTORY structure <https://msdn.microsoft.com/en-us/library/windows/desktop/ms680307(v=vs.85).aspx>`__.; For this particular case, the linker emits a debug directory of type; ``IMAGE_DEBUG_TYPE_CODEVIEW``. The format of this record is defined in; ``llvm/DebugInfo/CodeView/CVDebugRecord.h``, but it suffices to say here only; that it includes the same ``Guid`` and ``Age`` fields. At runtime, a; debugger or tool can scan the COFF executable image for the presence of; a debug directory of the correct type and verify that the Guid and Age match.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/PdbStream.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/PdbStream.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/PdbStream.rst:5770,Usability,guid,guid,5770,"es flags are present |; | | - PDB contains an :doc:`IPI Stream <TpiStream>` |; +------------------+-------------------------------------------------+; | VC140 | - Other feature flags may be present |; | | - PDB contains an :doc:`IPI Stream <TpiStream>` |; +------------------+-------------------------------------------------+; | NoTypeMerge | - Presumably duplicate types can appear in the |; | | TPI Stream, although it's unclear why this |; | | might happen. |; +------------------+-------------------------------------------------+; | MinimalDebugInfo | - Program was linked with /DEBUG:FASTLINK |; | | - There is no TPI / IPI stream, all type info |; | | is contained in the original object files. |; +------------------+-------------------------------------------------+. Matching a PDB to its executable; ================================; The linker is responsible for writing both the PDB and the final executable, and; as a result is the only entity capable of writing the information necessary to; match the PDB to the executable. In order to accomplish this, the linker generates a guid for the PDB (or; re-uses the existing guid if it is linking incrementally) and increments the Age; field. The executable is a PE/COFF file, and part of a PE/COFF file is the presence of; number of ""directories"". For our purposes here, we are interested in the ""debug; directory"". The exact format of a debug directory is described by the; `IMAGE_DEBUG_DIRECTORY structure <https://msdn.microsoft.com/en-us/library/windows/desktop/ms680307(v=vs.85).aspx>`__.; For this particular case, the linker emits a debug directory of type; ``IMAGE_DEBUG_TYPE_CODEVIEW``. The format of this record is defined in; ``llvm/DebugInfo/CodeView/CVDebugRecord.h``, but it suffices to say here only; that it includes the same ``Guid`` and ``Age`` fields. At runtime, a; debugger or tool can scan the COFF executable image for the presence of; a debug directory of the correct type and verify that the Guid and Age match.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/PdbStream.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/PdbStream.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/TpiStream.rst:11172,Deployability,update,update,11172,"erOffset / HashValueBufferLength** - The offset and size within; the TPI Hash Stream of the list of hash values. It should be assumed that; there are either 0 hash values, or a number equal to the number of type; records in the TPI stream (``TypeIndexEnd - TypeEndBegin``). Thus, if; ``HashBufferLength`` is not equal to ``(TypeIndexEnd - TypeEndBegin) *; HashKeySize`` we can consider the PDB malformed. - **IndexOffsetBufferOffset / IndexOffsetBufferLength** - The offset and size; within the TPI Hash Stream of the Type Index Offsets Buffer. This is a list; of pairs of uint32_t's where the first value is a :ref:`Type Index; <type_indices>` and the second value is the offset in the type record data of; the type with this index. This can be used to do a binary search followed by; a linear search to get O(log n) lookup by type index. - **HashAdjBufferOffset / HashAdjBufferLength** - The offset and size within; the TPI hash stream of a serialized hash table whose keys are the hash values; in the hash value buffer and whose values are type indices. This appears to; be useful in incremental linking scenarios, so that if a type is modified an; entry can be created mapping the old hash value to the new type index so that; a PDB file consumer can always have the most up to date version of the type; without forcing the incremental linker to garbage collect and update; references that point to the old version to now point to the new version.; The layout of this hash table is described in :doc:`HashTable`. .. _tpi_records:. CodeView Type Record List; =========================; Following the header, there are ``TypeRecordBytes`` bytes of data that; represent a variable length array of :doc:`CodeView type records; <CodeViewTypes>`. The number of such records (e.g. the length of the array); can be determined by computing the value ``Header.TypeIndexEnd -; Header.TypeIndexBegin``. O(log(n)) access is provided by way of the Type Index Offsets array (if; present) described previously.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/TpiStream.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/TpiStream.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/TpiStream.rst:11475,Modifiability,variab,variable,11475,"erOffset / HashValueBufferLength** - The offset and size within; the TPI Hash Stream of the list of hash values. It should be assumed that; there are either 0 hash values, or a number equal to the number of type; records in the TPI stream (``TypeIndexEnd - TypeEndBegin``). Thus, if; ``HashBufferLength`` is not equal to ``(TypeIndexEnd - TypeEndBegin) *; HashKeySize`` we can consider the PDB malformed. - **IndexOffsetBufferOffset / IndexOffsetBufferLength** - The offset and size; within the TPI Hash Stream of the Type Index Offsets Buffer. This is a list; of pairs of uint32_t's where the first value is a :ref:`Type Index; <type_indices>` and the second value is the offset in the type record data of; the type with this index. This can be used to do a binary search followed by; a linear search to get O(log n) lookup by type index. - **HashAdjBufferOffset / HashAdjBufferLength** - The offset and size within; the TPI hash stream of a serialized hash table whose keys are the hash values; in the hash value buffer and whose values are type indices. This appears to; be useful in incremental linking scenarios, so that if a type is modified an; entry can be created mapping the old hash value to the new type index so that; a PDB file consumer can always have the most up to date version of the type; without forcing the incremental linker to garbage collect and update; references that point to the old version to now point to the new version.; The layout of this hash table is described in :doc:`HashTable`. .. _tpi_records:. CodeView Type Record List; =========================; Following the header, there are ``TypeRecordBytes`` bytes of data that; represent a variable length array of :doc:`CodeView type records; <CodeViewTypes>`. The number of such records (e.g. the length of the array); can be determined by computing the value ``Header.TypeIndexEnd -; Header.TypeIndexBegin``. O(log(n)) access is provided by way of the Type Index Offsets array (if; present) described previously.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/TpiStream.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/TpiStream.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/TpiStream.rst:9116,Security,hash,hashes,9116,"2,; V50 = 19961031,; V70 = 19990903,; V80 = 20040203,; };. Similar to the :doc:`PDB Stream <PdbStream>`, this value always appears to be; ``V80``, and no other values have been observed. It is assumed that should; another value be observed, the layout described by this document may not be; accurate. - **HeaderSize** - ``sizeof(TpiStreamHeader)``. - **TypeIndexBegin** - The numeric value of the type index representing the; first type record in the TPI stream. This is usually the value 0x1000 as; type indices lower than this are reserved (see :ref:`Type Indices; <type_indices>` for; a discussion of reserved type indices). - **TypeIndexEnd** - One greater than the numeric value of the type index; representing the last type record in the TPI stream. The total number of; type records in the TPI stream can be computed as ``TypeIndexEnd -; TypeIndexBegin``. - **TypeRecordBytes** - The number of bytes of type record data following the; header. - **HashStreamIndex** - The index of a stream which contains a list of hashes; for every type record. This value may be -1, indicating that hash; information is not present. In practice a valid stream index is always; observed, so any producer implementation should be prepared to emit this; stream to ensure compatibility with tools which may expect it to be present. - **HashAuxStreamIndex** - Presumably the index of a stream which contains a; separate hash table, although this has not been observed in practice and it's; unclear what it might be used for. - **HashKeySize** - The size of a hash value (usually 4 bytes). - **NumHashBuckets** - The number of buckets used to generate the hash values; in the aforementioned hash streams. - **HashValueBufferOffset / HashValueBufferLength** - The offset and size within; the TPI Hash Stream of the list of hash values. It should be assumed that; there are either 0 hash values, or a number equal to the number of type; records in the TPI stream (``TypeIndexEnd - TypeEndBegin``). Thus, if; ``HashBuf",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/TpiStream.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/TpiStream.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/TpiStream.rst:9185,Security,hash,hash,9185,"eam <PdbStream>`, this value always appears to be; ``V80``, and no other values have been observed. It is assumed that should; another value be observed, the layout described by this document may not be; accurate. - **HeaderSize** - ``sizeof(TpiStreamHeader)``. - **TypeIndexBegin** - The numeric value of the type index representing the; first type record in the TPI stream. This is usually the value 0x1000 as; type indices lower than this are reserved (see :ref:`Type Indices; <type_indices>` for; a discussion of reserved type indices). - **TypeIndexEnd** - One greater than the numeric value of the type index; representing the last type record in the TPI stream. The total number of; type records in the TPI stream can be computed as ``TypeIndexEnd -; TypeIndexBegin``. - **TypeRecordBytes** - The number of bytes of type record data following the; header. - **HashStreamIndex** - The index of a stream which contains a list of hashes; for every type record. This value may be -1, indicating that hash; information is not present. In practice a valid stream index is always; observed, so any producer implementation should be prepared to emit this; stream to ensure compatibility with tools which may expect it to be present. - **HashAuxStreamIndex** - Presumably the index of a stream which contains a; separate hash table, although this has not been observed in practice and it's; unclear what it might be used for. - **HashKeySize** - The size of a hash value (usually 4 bytes). - **NumHashBuckets** - The number of buckets used to generate the hash values; in the aforementioned hash streams. - **HashValueBufferOffset / HashValueBufferLength** - The offset and size within; the TPI Hash Stream of the list of hash values. It should be assumed that; there are either 0 hash values, or a number equal to the number of type; records in the TPI stream (``TypeIndexEnd - TypeEndBegin``). Thus, if; ``HashBufferLength`` is not equal to ``(TypeIndexEnd - TypeEndBegin) *; HashKeySize`` we can con",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/TpiStream.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/TpiStream.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/TpiStream.rst:9501,Security,hash,hash,9501,"enting the; first type record in the TPI stream. This is usually the value 0x1000 as; type indices lower than this are reserved (see :ref:`Type Indices; <type_indices>` for; a discussion of reserved type indices). - **TypeIndexEnd** - One greater than the numeric value of the type index; representing the last type record in the TPI stream. The total number of; type records in the TPI stream can be computed as ``TypeIndexEnd -; TypeIndexBegin``. - **TypeRecordBytes** - The number of bytes of type record data following the; header. - **HashStreamIndex** - The index of a stream which contains a list of hashes; for every type record. This value may be -1, indicating that hash; information is not present. In practice a valid stream index is always; observed, so any producer implementation should be prepared to emit this; stream to ensure compatibility with tools which may expect it to be present. - **HashAuxStreamIndex** - Presumably the index of a stream which contains a; separate hash table, although this has not been observed in practice and it's; unclear what it might be used for. - **HashKeySize** - The size of a hash value (usually 4 bytes). - **NumHashBuckets** - The number of buckets used to generate the hash values; in the aforementioned hash streams. - **HashValueBufferOffset / HashValueBufferLength** - The offset and size within; the TPI Hash Stream of the list of hash values. It should be assumed that; there are either 0 hash values, or a number equal to the number of type; records in the TPI stream (``TypeIndexEnd - TypeEndBegin``). Thus, if; ``HashBufferLength`` is not equal to ``(TypeIndexEnd - TypeEndBegin) *; HashKeySize`` we can consider the PDB malformed. - **IndexOffsetBufferOffset / IndexOffsetBufferLength** - The offset and size; within the TPI Hash Stream of the Type Index Offsets Buffer. This is a list; of pairs of uint32_t's where the first value is a :ref:`Type Index; <type_indices>` and the second value is the offset in the type record data of;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/TpiStream.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/TpiStream.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/TpiStream.rst:9640,Security,hash,hash,9640,"(see :ref:`Type Indices; <type_indices>` for; a discussion of reserved type indices). - **TypeIndexEnd** - One greater than the numeric value of the type index; representing the last type record in the TPI stream. The total number of; type records in the TPI stream can be computed as ``TypeIndexEnd -; TypeIndexBegin``. - **TypeRecordBytes** - The number of bytes of type record data following the; header. - **HashStreamIndex** - The index of a stream which contains a list of hashes; for every type record. This value may be -1, indicating that hash; information is not present. In practice a valid stream index is always; observed, so any producer implementation should be prepared to emit this; stream to ensure compatibility with tools which may expect it to be present. - **HashAuxStreamIndex** - Presumably the index of a stream which contains a; separate hash table, although this has not been observed in practice and it's; unclear what it might be used for. - **HashKeySize** - The size of a hash value (usually 4 bytes). - **NumHashBuckets** - The number of buckets used to generate the hash values; in the aforementioned hash streams. - **HashValueBufferOffset / HashValueBufferLength** - The offset and size within; the TPI Hash Stream of the list of hash values. It should be assumed that; there are either 0 hash values, or a number equal to the number of type; records in the TPI stream (``TypeIndexEnd - TypeEndBegin``). Thus, if; ``HashBufferLength`` is not equal to ``(TypeIndexEnd - TypeEndBegin) *; HashKeySize`` we can consider the PDB malformed. - **IndexOffsetBufferOffset / IndexOffsetBufferLength** - The offset and size; within the TPI Hash Stream of the Type Index Offsets Buffer. This is a list; of pairs of uint32_t's where the first value is a :ref:`Type Index; <type_indices>` and the second value is the offset in the type record data of; the type with this index. This can be used to do a binary search followed by; a linear search to get O(log n) lookup by type in",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/TpiStream.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/TpiStream.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/TpiStream.rst:9736,Security,hash,hash,9736,"*TypeIndexEnd** - One greater than the numeric value of the type index; representing the last type record in the TPI stream. The total number of; type records in the TPI stream can be computed as ``TypeIndexEnd -; TypeIndexBegin``. - **TypeRecordBytes** - The number of bytes of type record data following the; header. - **HashStreamIndex** - The index of a stream which contains a list of hashes; for every type record. This value may be -1, indicating that hash; information is not present. In practice a valid stream index is always; observed, so any producer implementation should be prepared to emit this; stream to ensure compatibility with tools which may expect it to be present. - **HashAuxStreamIndex** - Presumably the index of a stream which contains a; separate hash table, although this has not been observed in practice and it's; unclear what it might be used for. - **HashKeySize** - The size of a hash value (usually 4 bytes). - **NumHashBuckets** - The number of buckets used to generate the hash values; in the aforementioned hash streams. - **HashValueBufferOffset / HashValueBufferLength** - The offset and size within; the TPI Hash Stream of the list of hash values. It should be assumed that; there are either 0 hash values, or a number equal to the number of type; records in the TPI stream (``TypeIndexEnd - TypeEndBegin``). Thus, if; ``HashBufferLength`` is not equal to ``(TypeIndexEnd - TypeEndBegin) *; HashKeySize`` we can consider the PDB malformed. - **IndexOffsetBufferOffset / IndexOffsetBufferLength** - The offset and size; within the TPI Hash Stream of the Type Index Offsets Buffer. This is a list; of pairs of uint32_t's where the first value is a :ref:`Type Index; <type_indices>` and the second value is the offset in the type record data of; the type with this index. This can be used to do a binary search followed by; a linear search to get O(log n) lookup by type index. - **HashAdjBufferOffset / HashAdjBufferLength** - The offset and size within; the TPI",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/TpiStream.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/TpiStream.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/TpiStream.rst:9771,Security,hash,hash,9771,"*TypeIndexEnd** - One greater than the numeric value of the type index; representing the last type record in the TPI stream. The total number of; type records in the TPI stream can be computed as ``TypeIndexEnd -; TypeIndexBegin``. - **TypeRecordBytes** - The number of bytes of type record data following the; header. - **HashStreamIndex** - The index of a stream which contains a list of hashes; for every type record. This value may be -1, indicating that hash; information is not present. In practice a valid stream index is always; observed, so any producer implementation should be prepared to emit this; stream to ensure compatibility with tools which may expect it to be present. - **HashAuxStreamIndex** - Presumably the index of a stream which contains a; separate hash table, although this has not been observed in practice and it's; unclear what it might be used for. - **HashKeySize** - The size of a hash value (usually 4 bytes). - **NumHashBuckets** - The number of buckets used to generate the hash values; in the aforementioned hash streams. - **HashValueBufferOffset / HashValueBufferLength** - The offset and size within; the TPI Hash Stream of the list of hash values. It should be assumed that; there are either 0 hash values, or a number equal to the number of type; records in the TPI stream (``TypeIndexEnd - TypeEndBegin``). Thus, if; ``HashBufferLength`` is not equal to ``(TypeIndexEnd - TypeEndBegin) *; HashKeySize`` we can consider the PDB malformed. - **IndexOffsetBufferOffset / IndexOffsetBufferLength** - The offset and size; within the TPI Hash Stream of the Type Index Offsets Buffer. This is a list; of pairs of uint32_t's where the first value is a :ref:`Type Index; <type_indices>` and the second value is the offset in the type record data of; the type with this index. This can be used to do a binary search followed by; a linear search to get O(log n) lookup by type index. - **HashAdjBufferOffset / HashAdjBufferLength** - The offset and size within; the TPI",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/TpiStream.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/TpiStream.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/TpiStream.rst:9902,Security,hash,hash,9902,". The total number of; type records in the TPI stream can be computed as ``TypeIndexEnd -; TypeIndexBegin``. - **TypeRecordBytes** - The number of bytes of type record data following the; header. - **HashStreamIndex** - The index of a stream which contains a list of hashes; for every type record. This value may be -1, indicating that hash; information is not present. In practice a valid stream index is always; observed, so any producer implementation should be prepared to emit this; stream to ensure compatibility with tools which may expect it to be present. - **HashAuxStreamIndex** - Presumably the index of a stream which contains a; separate hash table, although this has not been observed in practice and it's; unclear what it might be used for. - **HashKeySize** - The size of a hash value (usually 4 bytes). - **NumHashBuckets** - The number of buckets used to generate the hash values; in the aforementioned hash streams. - **HashValueBufferOffset / HashValueBufferLength** - The offset and size within; the TPI Hash Stream of the list of hash values. It should be assumed that; there are either 0 hash values, or a number equal to the number of type; records in the TPI stream (``TypeIndexEnd - TypeEndBegin``). Thus, if; ``HashBufferLength`` is not equal to ``(TypeIndexEnd - TypeEndBegin) *; HashKeySize`` we can consider the PDB malformed. - **IndexOffsetBufferOffset / IndexOffsetBufferLength** - The offset and size; within the TPI Hash Stream of the Type Index Offsets Buffer. This is a list; of pairs of uint32_t's where the first value is a :ref:`Type Index; <type_indices>` and the second value is the offset in the type record data of; the type with this index. This can be used to do a binary search followed by; a linear search to get O(log n) lookup by type index. - **HashAdjBufferOffset / HashAdjBufferLength** - The offset and size within; the TPI hash stream of a serialized hash table whose keys are the hash values; in the hash value buffer and whose values are type",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/TpiStream.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/TpiStream.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/TpiStream.rst:9961,Security,hash,hash,9961,"f bytes of type record data following the; header. - **HashStreamIndex** - The index of a stream which contains a list of hashes; for every type record. This value may be -1, indicating that hash; information is not present. In practice a valid stream index is always; observed, so any producer implementation should be prepared to emit this; stream to ensure compatibility with tools which may expect it to be present. - **HashAuxStreamIndex** - Presumably the index of a stream which contains a; separate hash table, although this has not been observed in practice and it's; unclear what it might be used for. - **HashKeySize** - The size of a hash value (usually 4 bytes). - **NumHashBuckets** - The number of buckets used to generate the hash values; in the aforementioned hash streams. - **HashValueBufferOffset / HashValueBufferLength** - The offset and size within; the TPI Hash Stream of the list of hash values. It should be assumed that; there are either 0 hash values, or a number equal to the number of type; records in the TPI stream (``TypeIndexEnd - TypeEndBegin``). Thus, if; ``HashBufferLength`` is not equal to ``(TypeIndexEnd - TypeEndBegin) *; HashKeySize`` we can consider the PDB malformed. - **IndexOffsetBufferOffset / IndexOffsetBufferLength** - The offset and size; within the TPI Hash Stream of the Type Index Offsets Buffer. This is a list; of pairs of uint32_t's where the first value is a :ref:`Type Index; <type_indices>` and the second value is the offset in the type record data of; the type with this index. This can be used to do a binary search followed by; a linear search to get O(log n) lookup by type index. - **HashAdjBufferOffset / HashAdjBufferLength** - The offset and size within; the TPI hash stream of a serialized hash table whose keys are the hash values; in the hash value buffer and whose values are type indices. This appears to; be useful in incremental linking scenarios, so that if a type is modified an; entry can be created mapping the old hash",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/TpiStream.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/TpiStream.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/TpiStream.rst:10728,Security,hash,hash,10728,"in the aforementioned hash streams. - **HashValueBufferOffset / HashValueBufferLength** - The offset and size within; the TPI Hash Stream of the list of hash values. It should be assumed that; there are either 0 hash values, or a number equal to the number of type; records in the TPI stream (``TypeIndexEnd - TypeEndBegin``). Thus, if; ``HashBufferLength`` is not equal to ``(TypeIndexEnd - TypeEndBegin) *; HashKeySize`` we can consider the PDB malformed. - **IndexOffsetBufferOffset / IndexOffsetBufferLength** - The offset and size; within the TPI Hash Stream of the Type Index Offsets Buffer. This is a list; of pairs of uint32_t's where the first value is a :ref:`Type Index; <type_indices>` and the second value is the offset in the type record data of; the type with this index. This can be used to do a binary search followed by; a linear search to get O(log n) lookup by type index. - **HashAdjBufferOffset / HashAdjBufferLength** - The offset and size within; the TPI hash stream of a serialized hash table whose keys are the hash values; in the hash value buffer and whose values are type indices. This appears to; be useful in incremental linking scenarios, so that if a type is modified an; entry can be created mapping the old hash value to the new type index so that; a PDB file consumer can always have the most up to date version of the type; without forcing the incremental linker to garbage collect and update; references that point to the old version to now point to the new version.; The layout of this hash table is described in :doc:`HashTable`. .. _tpi_records:. CodeView Type Record List; =========================; Following the header, there are ``TypeRecordBytes`` bytes of data that; represent a variable length array of :doc:`CodeView type records; <CodeViewTypes>`. The number of such records (e.g. the length of the array); can be determined by computing the value ``Header.TypeIndexEnd -; Header.TypeIndexBegin``. O(log(n)) access is provided by way of the Type Index",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/TpiStream.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/TpiStream.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/TpiStream.rst:10756,Security,hash,hash,10756,"in the aforementioned hash streams. - **HashValueBufferOffset / HashValueBufferLength** - The offset and size within; the TPI Hash Stream of the list of hash values. It should be assumed that; there are either 0 hash values, or a number equal to the number of type; records in the TPI stream (``TypeIndexEnd - TypeEndBegin``). Thus, if; ``HashBufferLength`` is not equal to ``(TypeIndexEnd - TypeEndBegin) *; HashKeySize`` we can consider the PDB malformed. - **IndexOffsetBufferOffset / IndexOffsetBufferLength** - The offset and size; within the TPI Hash Stream of the Type Index Offsets Buffer. This is a list; of pairs of uint32_t's where the first value is a :ref:`Type Index; <type_indices>` and the second value is the offset in the type record data of; the type with this index. This can be used to do a binary search followed by; a linear search to get O(log n) lookup by type index. - **HashAdjBufferOffset / HashAdjBufferLength** - The offset and size within; the TPI hash stream of a serialized hash table whose keys are the hash values; in the hash value buffer and whose values are type indices. This appears to; be useful in incremental linking scenarios, so that if a type is modified an; entry can be created mapping the old hash value to the new type index so that; a PDB file consumer can always have the most up to date version of the type; without forcing the incremental linker to garbage collect and update; references that point to the old version to now point to the new version.; The layout of this hash table is described in :doc:`HashTable`. .. _tpi_records:. CodeView Type Record List; =========================; Following the header, there are ``TypeRecordBytes`` bytes of data that; represent a variable length array of :doc:`CodeView type records; <CodeViewTypes>`. The number of such records (e.g. the length of the array); can be determined by computing the value ``Header.TypeIndexEnd -; Header.TypeIndexBegin``. O(log(n)) access is provided by way of the Type Index",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/TpiStream.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/TpiStream.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/TpiStream.rst:10786,Security,hash,hash,10786,"in the aforementioned hash streams. - **HashValueBufferOffset / HashValueBufferLength** - The offset and size within; the TPI Hash Stream of the list of hash values. It should be assumed that; there are either 0 hash values, or a number equal to the number of type; records in the TPI stream (``TypeIndexEnd - TypeEndBegin``). Thus, if; ``HashBufferLength`` is not equal to ``(TypeIndexEnd - TypeEndBegin) *; HashKeySize`` we can consider the PDB malformed. - **IndexOffsetBufferOffset / IndexOffsetBufferLength** - The offset and size; within the TPI Hash Stream of the Type Index Offsets Buffer. This is a list; of pairs of uint32_t's where the first value is a :ref:`Type Index; <type_indices>` and the second value is the offset in the type record data of; the type with this index. This can be used to do a binary search followed by; a linear search to get O(log n) lookup by type index. - **HashAdjBufferOffset / HashAdjBufferLength** - The offset and size within; the TPI hash stream of a serialized hash table whose keys are the hash values; in the hash value buffer and whose values are type indices. This appears to; be useful in incremental linking scenarios, so that if a type is modified an; entry can be created mapping the old hash value to the new type index so that; a PDB file consumer can always have the most up to date version of the type; without forcing the incremental linker to garbage collect and update; references that point to the old version to now point to the new version.; The layout of this hash table is described in :doc:`HashTable`. .. _tpi_records:. CodeView Type Record List; =========================; Following the header, there are ``TypeRecordBytes`` bytes of data that; represent a variable length array of :doc:`CodeView type records; <CodeViewTypes>`. The number of such records (e.g. the length of the array); can be determined by computing the value ``Header.TypeIndexEnd -; Header.TypeIndexBegin``. O(log(n)) access is provided by way of the Type Index",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/TpiStream.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/TpiStream.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/TpiStream.rst:10806,Security,hash,hash,10806,"in the aforementioned hash streams. - **HashValueBufferOffset / HashValueBufferLength** - The offset and size within; the TPI Hash Stream of the list of hash values. It should be assumed that; there are either 0 hash values, or a number equal to the number of type; records in the TPI stream (``TypeIndexEnd - TypeEndBegin``). Thus, if; ``HashBufferLength`` is not equal to ``(TypeIndexEnd - TypeEndBegin) *; HashKeySize`` we can consider the PDB malformed. - **IndexOffsetBufferOffset / IndexOffsetBufferLength** - The offset and size; within the TPI Hash Stream of the Type Index Offsets Buffer. This is a list; of pairs of uint32_t's where the first value is a :ref:`Type Index; <type_indices>` and the second value is the offset in the type record data of; the type with this index. This can be used to do a binary search followed by; a linear search to get O(log n) lookup by type index. - **HashAdjBufferOffset / HashAdjBufferLength** - The offset and size within; the TPI hash stream of a serialized hash table whose keys are the hash values; in the hash value buffer and whose values are type indices. This appears to; be useful in incremental linking scenarios, so that if a type is modified an; entry can be created mapping the old hash value to the new type index so that; a PDB file consumer can always have the most up to date version of the type; without forcing the incremental linker to garbage collect and update; references that point to the old version to now point to the new version.; The layout of this hash table is described in :doc:`HashTable`. .. _tpi_records:. CodeView Type Record List; =========================; Following the header, there are ``TypeRecordBytes`` bytes of data that; represent a variable length array of :doc:`CodeView type records; <CodeViewTypes>`. The number of such records (e.g. the length of the array); can be determined by computing the value ``Header.TypeIndexEnd -; Header.TypeIndexBegin``. O(log(n)) access is provided by way of the Type Index",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/TpiStream.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/TpiStream.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/TpiStream.rst:10991,Security,hash,hash,10991,"erOffset / HashValueBufferLength** - The offset and size within; the TPI Hash Stream of the list of hash values. It should be assumed that; there are either 0 hash values, or a number equal to the number of type; records in the TPI stream (``TypeIndexEnd - TypeEndBegin``). Thus, if; ``HashBufferLength`` is not equal to ``(TypeIndexEnd - TypeEndBegin) *; HashKeySize`` we can consider the PDB malformed. - **IndexOffsetBufferOffset / IndexOffsetBufferLength** - The offset and size; within the TPI Hash Stream of the Type Index Offsets Buffer. This is a list; of pairs of uint32_t's where the first value is a :ref:`Type Index; <type_indices>` and the second value is the offset in the type record data of; the type with this index. This can be used to do a binary search followed by; a linear search to get O(log n) lookup by type index. - **HashAdjBufferOffset / HashAdjBufferLength** - The offset and size within; the TPI hash stream of a serialized hash table whose keys are the hash values; in the hash value buffer and whose values are type indices. This appears to; be useful in incremental linking scenarios, so that if a type is modified an; entry can be created mapping the old hash value to the new type index so that; a PDB file consumer can always have the most up to date version of the type; without forcing the incremental linker to garbage collect and update; references that point to the old version to now point to the new version.; The layout of this hash table is described in :doc:`HashTable`. .. _tpi_records:. CodeView Type Record List; =========================; Following the header, there are ``TypeRecordBytes`` bytes of data that; represent a variable length array of :doc:`CodeView type records; <CodeViewTypes>`. The number of such records (e.g. the length of the array); can be determined by computing the value ``Header.TypeIndexEnd -; Header.TypeIndexBegin``. O(log(n)) access is provided by way of the Type Index Offsets array (if; present) described previously.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/TpiStream.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/TpiStream.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/TpiStream.rst:11274,Security,hash,hash,11274,"erOffset / HashValueBufferLength** - The offset and size within; the TPI Hash Stream of the list of hash values. It should be assumed that; there are either 0 hash values, or a number equal to the number of type; records in the TPI stream (``TypeIndexEnd - TypeEndBegin``). Thus, if; ``HashBufferLength`` is not equal to ``(TypeIndexEnd - TypeEndBegin) *; HashKeySize`` we can consider the PDB malformed. - **IndexOffsetBufferOffset / IndexOffsetBufferLength** - The offset and size; within the TPI Hash Stream of the Type Index Offsets Buffer. This is a list; of pairs of uint32_t's where the first value is a :ref:`Type Index; <type_indices>` and the second value is the offset in the type record data of; the type with this index. This can be used to do a binary search followed by; a linear search to get O(log n) lookup by type index. - **HashAdjBufferOffset / HashAdjBufferLength** - The offset and size within; the TPI hash stream of a serialized hash table whose keys are the hash values; in the hash value buffer and whose values are type indices. This appears to; be useful in incremental linking scenarios, so that if a type is modified an; entry can be created mapping the old hash value to the new type index so that; a PDB file consumer can always have the most up to date version of the type; without forcing the incremental linker to garbage collect and update; references that point to the old version to now point to the new version.; The layout of this hash table is described in :doc:`HashTable`. .. _tpi_records:. CodeView Type Record List; =========================; Following the header, there are ``TypeRecordBytes`` bytes of data that; represent a variable length array of :doc:`CodeView type records; <CodeViewTypes>`. The number of such records (e.g. the length of the array); can be determined by computing the value ``Header.TypeIndexEnd -; Header.TypeIndexBegin``. O(log(n)) access is provided by way of the Type Index Offsets array (if; present) described previously.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/TpiStream.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/TpiStream.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/TpiStream.rst:11707,Security,access,access,11707,"erOffset / HashValueBufferLength** - The offset and size within; the TPI Hash Stream of the list of hash values. It should be assumed that; there are either 0 hash values, or a number equal to the number of type; records in the TPI stream (``TypeIndexEnd - TypeEndBegin``). Thus, if; ``HashBufferLength`` is not equal to ``(TypeIndexEnd - TypeEndBegin) *; HashKeySize`` we can consider the PDB malformed. - **IndexOffsetBufferOffset / IndexOffsetBufferLength** - The offset and size; within the TPI Hash Stream of the Type Index Offsets Buffer. This is a list; of pairs of uint32_t's where the first value is a :ref:`Type Index; <type_indices>` and the second value is the offset in the type record data of; the type with this index. This can be used to do a binary search followed by; a linear search to get O(log n) lookup by type index. - **HashAdjBufferOffset / HashAdjBufferLength** - The offset and size within; the TPI hash stream of a serialized hash table whose keys are the hash values; in the hash value buffer and whose values are type indices. This appears to; be useful in incremental linking scenarios, so that if a type is modified an; entry can be created mapping the old hash value to the new type index so that; a PDB file consumer can always have the most up to date version of the type; without forcing the incremental linker to garbage collect and update; references that point to the old version to now point to the new version.; The layout of this hash table is described in :doc:`HashTable`. .. _tpi_records:. CodeView Type Record List; =========================; Following the header, there are ``TypeRecordBytes`` bytes of data that; represent a variable length array of :doc:`CodeView type records; <CodeViewTypes>`. The number of such records (e.g. the length of the array); can be determined by computing the value ``Header.TypeIndexEnd -; Header.TypeIndexBegin``. O(log(n)) access is provided by way of the Type Index Offsets array (if; present) described previously.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/TpiStream.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/TpiStream.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/TpiStream.rst:10613,Testability,log,log,10613,"ight be used for. - **HashKeySize** - The size of a hash value (usually 4 bytes). - **NumHashBuckets** - The number of buckets used to generate the hash values; in the aforementioned hash streams. - **HashValueBufferOffset / HashValueBufferLength** - The offset and size within; the TPI Hash Stream of the list of hash values. It should be assumed that; there are either 0 hash values, or a number equal to the number of type; records in the TPI stream (``TypeIndexEnd - TypeEndBegin``). Thus, if; ``HashBufferLength`` is not equal to ``(TypeIndexEnd - TypeEndBegin) *; HashKeySize`` we can consider the PDB malformed. - **IndexOffsetBufferOffset / IndexOffsetBufferLength** - The offset and size; within the TPI Hash Stream of the Type Index Offsets Buffer. This is a list; of pairs of uint32_t's where the first value is a :ref:`Type Index; <type_indices>` and the second value is the offset in the type record data of; the type with this index. This can be used to do a binary search followed by; a linear search to get O(log n) lookup by type index. - **HashAdjBufferOffset / HashAdjBufferLength** - The offset and size within; the TPI hash stream of a serialized hash table whose keys are the hash values; in the hash value buffer and whose values are type indices. This appears to; be useful in incremental linking scenarios, so that if a type is modified an; entry can be created mapping the old hash value to the new type index so that; a PDB file consumer can always have the most up to date version of the type; without forcing the incremental linker to garbage collect and update; references that point to the old version to now point to the new version.; The layout of this hash table is described in :doc:`HashTable`. .. _tpi_records:. CodeView Type Record List; =========================; Following the header, there are ``TypeRecordBytes`` bytes of data that; represent a variable length array of :doc:`CodeView type records; <CodeViewTypes>`. The number of such records (e.g. the leng",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/TpiStream.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/TpiStream.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/TpiStream.rst:11699,Testability,log,log,11699,"erOffset / HashValueBufferLength** - The offset and size within; the TPI Hash Stream of the list of hash values. It should be assumed that; there are either 0 hash values, or a number equal to the number of type; records in the TPI stream (``TypeIndexEnd - TypeEndBegin``). Thus, if; ``HashBufferLength`` is not equal to ``(TypeIndexEnd - TypeEndBegin) *; HashKeySize`` we can consider the PDB malformed. - **IndexOffsetBufferOffset / IndexOffsetBufferLength** - The offset and size; within the TPI Hash Stream of the Type Index Offsets Buffer. This is a list; of pairs of uint32_t's where the first value is a :ref:`Type Index; <type_indices>` and the second value is the offset in the type record data of; the type with this index. This can be used to do a binary search followed by; a linear search to get O(log n) lookup by type index. - **HashAdjBufferOffset / HashAdjBufferLength** - The offset and size within; the TPI hash stream of a serialized hash table whose keys are the hash values; in the hash value buffer and whose values are type indices. This appears to; be useful in incremental linking scenarios, so that if a type is modified an; entry can be created mapping the old hash value to the new type index so that; a PDB file consumer can always have the most up to date version of the type; without forcing the incremental linker to garbage collect and update; references that point to the old version to now point to the new version.; The layout of this hash table is described in :doc:`HashTable`. .. _tpi_records:. CodeView Type Record List; =========================; Following the header, there are ``TypeRecordBytes`` bytes of data that; represent a variable length array of :doc:`CodeView type records; <CodeViewTypes>`. The number of such records (e.g. the length of the array); can be determined by computing the value ``Header.TypeIndexEnd -; Header.TypeIndexBegin``. O(log(n)) access is provided by way of the Type Index Offsets array (if; present) described previously.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/TpiStream.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/TpiStream.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/TpiStream.rst:4162,Usability,clear,cleared,4162,"odeView Type Records <CodeViewTypes>`. .. _type_indices:. Type Indices; ============. A type index is a 32-bit integer that uniquely identifies a type inside of an; object file's ``.debug$T`` section or a PDB file's TPI or IPI stream. The; value of the type index for the first type record from the TPI stream is given; by the ``TypeIndexBegin`` member of the :ref:`TPI Stream Header <tpi_header>`; although in practice this value is always equal to 0x1000 (4096). Any type index with a high bit set is considered to come from the IPI stream,; although this appears to be more of a hack, and LLVM does not generate type; indices of this nature. They can, however, be observed in Microsoft PDBs; occasionally, so one should be prepared to handle them. Note that having the; high bit set is not a necessary condition to determine whether a type index; comes from the IPI stream, it is only sufficient. Once the high bit is cleared, any type index >= ``TypeIndexBegin`` is presumed; to come from the appropriate stream, and any type index less than this is a; bitmask which can be decomposed as follows:. .. code-block:: none. .---------------------------.------.----------.; | Unused | Mode | Kind |; '---------------------------'------'----------'; |+32 |+12 |+8 |+0. - **Kind** - A value from the following enum:. .. code-block:: c++. enum class SimpleTypeKind : uint32_t {; None = 0x0000, // uncharacterized type (no type); Void = 0x0003, // void; NotTranslated = 0x0007, // type not translated by cvpack; HResult = 0x0008, // OLE/COM HRESULT. SignedCharacter = 0x0010, // 8 bit signed; UnsignedCharacter = 0x0020, // 8 bit unsigned; NarrowCharacter = 0x0070, // really a char; WideCharacter = 0x0071, // wide char; Character16 = 0x007a, // char16_t; Character32 = 0x007b, // char32_t; Character8 = 0x007c, // char8_t. SByte = 0x0068, // 8 bit signed int; Byte = 0x0069, // 8 bit unsigned int; Int16Short = 0x0011, // 16 bit signed; UInt16Short = 0x0021, // 16 bit unsigned; Int16 = 0x0072, // 16 bi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/PDB/TpiStream.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/PDB/TpiStream.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:1803,Availability,down,down,1803,"sal is *Not* About; =================================. Changing the development policy. This proposal relates only to moving the hosting of our source-code repository; from SVN hosted on our own servers to Git hosted on GitHub. We are not proposing; using GitHub's issue tracker, pull-requests, or code-review. Contributors will continue to earn commit access on demand under the Developer; Policy, except that that a GitHub account will be required instead of SVN; username/password-hash. Why Git, and Why GitHub?; ========================. Why Move At All?; ----------------. This discussion began because we currently host our own Subversion server; and Git mirror on a voluntary basis. The LLVM Foundation sponsors the server and; provides limited support, but there is only so much it can do. Volunteers are not sysadmins themselves, but compiler engineers that happen; to know a thing or two about hosting servers. We also don't have 24/7 support,; and we sometimes wake up to see that continuous integration is broken because; the SVN server is either down or unresponsive. We should take advantage of one of the services out there (GitHub, GitLab,; and BitBucket, among others) that offer better service (24/7 stability, disk; space, Git server, code browsing, forking facilities, etc) for free. Why Git?; --------. Many new coders nowadays start with Git, and a lot of people have never used; SVN, CVS, or anything else. Websites like GitHub have changed the landscape; of open source contributions, reducing the cost of first contribution and; fostering collaboration. Git is also the version control many LLVM developers use. Despite the; sources being stored in a SVN server, these developers are already using Git; through the Git-SVN integration. Git allows you to:. * Commit, squash, merge, and fork locally without touching the remote server.; * Maintain local branches, enabling multiple threads of development.; * Collaborate on these branches (e.g. through your own fork of llvm on",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:7508,Availability,down,downstream,7508,"ves the; email format unchanged besides the commit URL. Straw Man Migration Plan; ========================. Step #1 : Before The Move; -------------------------. 1. Update docs to mention the move, so people are aware of what is going on.; 2. Set up a read-only version of the GitHub project, mirroring our current SVN; repository.; 3. Add the required bots to implement the commit emails, as well as the; umbrella repository update (if the multirepo is selected) or the read-only; Git views for the sub-projects (if the monorepo is selected). Step #2 : Git Move; ------------------. 4. Update the buildbots to pick up updates and commits from the GitHub; repository. Not all bots have to migrate at this point, but it'll help; provide infrastructure testing.; 5. Update Phabricator to pick up commits from the GitHub repository.; 6. LNT and llvmlab have to be updated: they rely on unique monotonically; increasing integer across branch [MatthewsRevNum]_.; 7. Instruct downstream integrators to pick up commits from the GitHub; repository.; 8. Review and prepare an update for the LLVM documentation. Until this point nothing has changed for developers, it will just; boil down to a lot of work for buildbot and other infrastructure; owners. The migration will pause here until all dependencies have cleared, and all; problems have been solved. Step #3: Write Access Move; --------------------------. 9. Collect developers' GitHub account information, and add them to the project.; 10. Switch the SVN repository to read-only and allow pushes to the GitHub repository.; 11. Update the documentation.; 12. Mirror Git to SVN. Step #4 : Post Move; -------------------. 13. Archive the SVN repository.; 14. Update links on the LLVM website pointing to viewvc/klaus/phab etc. to; point to GitHub instead. GitHub Repository Description; =============================. Monorepo; ----------------. The LLVM git repository hosted at https://github.com/llvm/llvm-project contains all; sub-projects in a single ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:7712,Availability,down,down,7712," docs to mention the move, so people are aware of what is going on.; 2. Set up a read-only version of the GitHub project, mirroring our current SVN; repository.; 3. Add the required bots to implement the commit emails, as well as the; umbrella repository update (if the multirepo is selected) or the read-only; Git views for the sub-projects (if the monorepo is selected). Step #2 : Git Move; ------------------. 4. Update the buildbots to pick up updates and commits from the GitHub; repository. Not all bots have to migrate at this point, but it'll help; provide infrastructure testing.; 5. Update Phabricator to pick up commits from the GitHub repository.; 6. LNT and llvmlab have to be updated: they rely on unique monotonically; increasing integer across branch [MatthewsRevNum]_.; 7. Instruct downstream integrators to pick up commits from the GitHub; repository.; 8. Review and prepare an update for the LLVM documentation. Until this point nothing has changed for developers, it will just; boil down to a lot of work for buildbot and other infrastructure; owners. The migration will pause here until all dependencies have cleared, and all; problems have been solved. Step #3: Write Access Move; --------------------------. 9. Collect developers' GitHub account information, and add them to the project.; 10. Switch the SVN repository to read-only and allow pushes to the GitHub repository.; 11. Update the documentation.; 12. Mirror Git to SVN. Step #4 : Post Move; -------------------. 13. Archive the SVN repository.; 14. Update links on the LLVM website pointing to viewvc/klaus/phab etc. to; point to GitHub instead. GitHub Repository Description; =============================. Monorepo; ----------------. The LLVM git repository hosted at https://github.com/llvm/llvm-project contains all; sub-projects in a single source tree. It is often referred to as a monorepo and; mimics an export of the current SVN repository, with each sub-project having its; own top-level directory. Not all s",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:11791,Availability,avail,availability,11791," read/write SVN bridge for its repositories. However,; there have been issues with this bridge working correctly in the past,; so it's not clear if this is something that will be supported going forward. Monorepo Drawbacks; ------------------. * Using the monolithic repository may add overhead for those contributing to a; standalone sub-project, particularly on runtimes like libcxx and compiler-rt; that don't rely on LLVM; currently, a fresh clone of libcxx is only 15MB (vs.; 1GB for the monorepo), and the commit rate of LLVM may cause more frequent; `git push` collisions when upstreaming. Affected contributors may be able to; use the SVN bridge or the single-subproject Git mirrors. However, it's; undecided if these projects will continue to be maintained.; * Using the monolithic repository may add overhead for those *integrating* a; standalone sub-project, even if they aren't contributing to it, due to the; same disk space concern as the point above. The availability of the; sub-project Git mirrors would addresses this.; * Preservation of the existing read/write SVN-based workflows relies on the; GitHub SVN bridge, which is an extra dependency. Maintaining this locks us; into GitHub and could restrict future workflow changes. Workflows; ^^^^^^^^^. * :ref:`Checkout/Clone a Single Project, without Commit Access <workflow-checkout-commit>`.; * :ref:`Checkout/Clone Multiple Projects, with Commit Access <workflow-monocheckout-multicommit>`.; * :ref:`Commit an API Change in LLVM and Update the Sub-projects <workflow-cross-repo-commit>`.; * :ref:`Branching/Stashing/Updating for Local Development or Experiments <workflow-mono-branching>`.; * :ref:`Bisecting <workflow-mono-bisecting>`. Workflow Before/After; =====================. This section goes through a few examples of workflows, intended to illustrate; how end-users or developers would interact with the repository for; various use-cases. .. _workflow-checkout-commit:. Checkout/Clone a Single Project, with Commit Access",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:14110,Availability,echo,echo,14110,"lvm.org/svn/llvm-project/llvm/trunk --username=<username>; git config svn-remote.svn.fetch :refs/remotes/origin/main; git svn rebase -l # -l avoids fetching ahead of the git mirror. Commits are performed using `svn commit` or with the sequence `git commit` and; `git svn dcommit`. .. _workflow-multicheckout-nocommit:. Monorepo Variant; ^^^^^^^^^^^^^^^^. With the monorepo variant, there are a few options, depending on your; constraints. First, you could just clone the full repository:. git clone https://github.com/llvm/llvm-project.git. At this point you have every sub-project (llvm, clang, lld, lldb, ...), which; :ref:`doesn't imply you have to build all of them <build_single_project>`. You; can still build only compiler-rt for instance. In this way it's not different; from someone who would check out all the projects with SVN today. If you want to avoid checking out all the sources, you can hide the other; directories using a Git sparse checkout::. git config core.sparseCheckout true; echo /compiler-rt > .git/info/sparse-checkout; git read-tree -mu HEAD. The data for all sub-projects is still in your `.git` directory, but in your; checkout, you only see `compiler-rt`.; Before you push, you'll need to fetch and rebase (`git pull --rebase`) as; usual. Note that when you fetch you'll likely pull in changes to sub-projects you don't; care about. If you are using sparse checkout, the files from other projects; won't appear on your disk. The only effect is that your commit hash changes. You can check whether the changes in the last fetch are relevant to your commit; by running::. git log origin/main@{1}..origin/main -- libcxx. This command can be hidden in a script so that `git llvmpush` would perform all; these steps, fail only if such a dependent change exists, and show immediately; the change that prevented the push. An immediate repeat of the command would; (almost) certainly result in a successful push.; Note that today with SVN or git-svn, this step is not possible ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:19930,Availability,failure,failure,19930,"to script around. Using the existing Git read-only view of the repositories, it is possible to use; the native Git bisection script over the llvm repository, and use some scripting; to synchronize the clang repository to match the llvm revision. .. _workflow-mono-bisecting:. Monorepo Variant; ^^^^^^^^^^^^^^^^. Bisecting on the monorepo is straightforward, and very similar to the above,; except that the bisection script does not need to include the; `git submodule update` step. The same example, finding which commit introduces a regression where clang-3.9; crashes but not clang-3.8 passes, will look like::. git bisect start releases/3.9.x releases/3.8.x; git bisect run ./bisect_script.sh. With the `bisect_script.sh` script being::. #!/bin/sh; cd $BUILD_DIR. ninja clang || exit 125 # an exit code of 125 asks ""git bisect""; # to ""skip"" the current commit. ./bin/clang some_crash_test.cpp. Also, since the monorepo handles commits update across multiple projects, you're; less like to encounter a build failure where a commit change an API in LLVM and; another later one ""fixes"" the build in clang. Moving Local Branches to the Monorepo; =====================================. Suppose you have been developing against the existing LLVM git; mirrors. You have one or more git branches that you want to migrate; to the ""final monorepo"". The simplest way to migrate such branches is with the; ``migrate-downstream-fork.py`` tool at; https://github.com/jyknight/llvm-git-migration. Basic migration; ---------------. Basic instructions for ``migrate-downstream-fork.py`` are in the; Python script and are expanded on below to a more general recipe::. # Make a repository which will become your final local mirror of the; # monorepo.; mkdir my-monorepo; git -C my-monorepo init. # Add a remote to the monorepo.; git -C my-monorepo remote add upstream/monorepo https://github.com/llvm/llvm-project.git. # Add remotes for each git mirror you use, from upstream as well as; # your local mirror. All proj",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:20327,Availability,down,downstream-fork,20327,"above,; except that the bisection script does not need to include the; `git submodule update` step. The same example, finding which commit introduces a regression where clang-3.9; crashes but not clang-3.8 passes, will look like::. git bisect start releases/3.9.x releases/3.8.x; git bisect run ./bisect_script.sh. With the `bisect_script.sh` script being::. #!/bin/sh; cd $BUILD_DIR. ninja clang || exit 125 # an exit code of 125 asks ""git bisect""; # to ""skip"" the current commit. ./bin/clang some_crash_test.cpp. Also, since the monorepo handles commits update across multiple projects, you're; less like to encounter a build failure where a commit change an API in LLVM and; another later one ""fixes"" the build in clang. Moving Local Branches to the Monorepo; =====================================. Suppose you have been developing against the existing LLVM git; mirrors. You have one or more git branches that you want to migrate; to the ""final monorepo"". The simplest way to migrate such branches is with the; ``migrate-downstream-fork.py`` tool at; https://github.com/jyknight/llvm-git-migration. Basic migration; ---------------. Basic instructions for ``migrate-downstream-fork.py`` are in the; Python script and are expanded on below to a more general recipe::. # Make a repository which will become your final local mirror of the; # monorepo.; mkdir my-monorepo; git -C my-monorepo init. # Add a remote to the monorepo.; git -C my-monorepo remote add upstream/monorepo https://github.com/llvm/llvm-project.git. # Add remotes for each git mirror you use, from upstream as well as; # your local mirror. All projects are listed here but you need only; # import those for which you have local branches.; my_projects=( clang; clang-tools-extra; compiler-rt; debuginfo-tests; libcxx; libcxxabi; libunwind; lld; lldb; llvm; openmp; polly ); for p in ${my_projects[@]}; do; git -C my-monorepo remote add upstream/split/${p} https://github.com/llvm-mirror/${p}.git; git -C my-monorepo remote add loc",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:20472,Availability,down,downstream-fork,20472,"n where clang-3.9; crashes but not clang-3.8 passes, will look like::. git bisect start releases/3.9.x releases/3.8.x; git bisect run ./bisect_script.sh. With the `bisect_script.sh` script being::. #!/bin/sh; cd $BUILD_DIR. ninja clang || exit 125 # an exit code of 125 asks ""git bisect""; # to ""skip"" the current commit. ./bin/clang some_crash_test.cpp. Also, since the monorepo handles commits update across multiple projects, you're; less like to encounter a build failure where a commit change an API in LLVM and; another later one ""fixes"" the build in clang. Moving Local Branches to the Monorepo; =====================================. Suppose you have been developing against the existing LLVM git; mirrors. You have one or more git branches that you want to migrate; to the ""final monorepo"". The simplest way to migrate such branches is with the; ``migrate-downstream-fork.py`` tool at; https://github.com/jyknight/llvm-git-migration. Basic migration; ---------------. Basic instructions for ``migrate-downstream-fork.py`` are in the; Python script and are expanded on below to a more general recipe::. # Make a repository which will become your final local mirror of the; # monorepo.; mkdir my-monorepo; git -C my-monorepo init. # Add a remote to the monorepo.; git -C my-monorepo remote add upstream/monorepo https://github.com/llvm/llvm-project.git. # Add remotes for each git mirror you use, from upstream as well as; # your local mirror. All projects are listed here but you need only; # import those for which you have local branches.; my_projects=( clang; clang-tools-extra; compiler-rt; debuginfo-tests; libcxx; libcxxabi; libunwind; lld; lldb; llvm; openmp; polly ); for p in ${my_projects[@]}; do; git -C my-monorepo remote add upstream/split/${p} https://github.com/llvm-mirror/${p}.git; git -C my-monorepo remote add local/split/${p} https://my.local.mirror.org/${p}.git; done. # Pull in all the commits.; git -C my-monorepo fetch --all. # Run migrate-downstream-fork to rewrite lo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:21434,Availability,down,downstream-fork,21434,"igrate-downstream-fork.py`` are in the; Python script and are expanded on below to a more general recipe::. # Make a repository which will become your final local mirror of the; # monorepo.; mkdir my-monorepo; git -C my-monorepo init. # Add a remote to the monorepo.; git -C my-monorepo remote add upstream/monorepo https://github.com/llvm/llvm-project.git. # Add remotes for each git mirror you use, from upstream as well as; # your local mirror. All projects are listed here but you need only; # import those for which you have local branches.; my_projects=( clang; clang-tools-extra; compiler-rt; debuginfo-tests; libcxx; libcxxabi; libunwind; lld; lldb; llvm; openmp; polly ); for p in ${my_projects[@]}; do; git -C my-monorepo remote add upstream/split/${p} https://github.com/llvm-mirror/${p}.git; git -C my-monorepo remote add local/split/${p} https://my.local.mirror.org/${p}.git; done. # Pull in all the commits.; git -C my-monorepo fetch --all. # Run migrate-downstream-fork to rewrite local branches on top of; # the upstream monorepo.; (; cd my-monorepo; migrate-downstream-fork.py \; refs/remotes/local \; refs/tags \; --new-repo-prefix=refs/remotes/upstream/monorepo \; --old-repo-prefix=refs/remotes/upstream/split \; --source-kind=split \; --revmap-out=monorepo-map.txt; ). # Octopus-merge the resulting local split histories to unify them. # Assumes local work on local split mirrors is on main (and; # upstream is presumably represented by some other branch like; # upstream/main).; my_local_branch=""main"". git -C my-monorepo branch --no-track local/octopus/main \; $(git -C my-monorepo merge-base refs/remotes/upstream/monorepo/main \; refs/remotes/local/split/llvm/${my_local_branch}); git -C my-monorepo checkout local/octopus/${my_local_branch}. subproject_branches=(); for p in ${my_projects[@]}; do; subproject_branch=${p}/local/monorepo/${my_local_branch}; git -C my-monorepo branch ${subproject_branch} \; refs/remotes/local/split/${p}/${my_local_branch}; if [[ ""${p}"" != ""l",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:21540,Availability,down,downstream-fork,21540,"ed on below to a more general recipe::. # Make a repository which will become your final local mirror of the; # monorepo.; mkdir my-monorepo; git -C my-monorepo init. # Add a remote to the monorepo.; git -C my-monorepo remote add upstream/monorepo https://github.com/llvm/llvm-project.git. # Add remotes for each git mirror you use, from upstream as well as; # your local mirror. All projects are listed here but you need only; # import those for which you have local branches.; my_projects=( clang; clang-tools-extra; compiler-rt; debuginfo-tests; libcxx; libcxxabi; libunwind; lld; lldb; llvm; openmp; polly ); for p in ${my_projects[@]}; do; git -C my-monorepo remote add upstream/split/${p} https://github.com/llvm-mirror/${p}.git; git -C my-monorepo remote add local/split/${p} https://my.local.mirror.org/${p}.git; done. # Pull in all the commits.; git -C my-monorepo fetch --all. # Run migrate-downstream-fork to rewrite local branches on top of; # the upstream monorepo.; (; cd my-monorepo; migrate-downstream-fork.py \; refs/remotes/local \; refs/tags \; --new-repo-prefix=refs/remotes/upstream/monorepo \; --old-repo-prefix=refs/remotes/upstream/split \; --source-kind=split \; --revmap-out=monorepo-map.txt; ). # Octopus-merge the resulting local split histories to unify them. # Assumes local work on local split mirrors is on main (and; # upstream is presumably represented by some other branch like; # upstream/main).; my_local_branch=""main"". git -C my-monorepo branch --no-track local/octopus/main \; $(git -C my-monorepo merge-base refs/remotes/upstream/monorepo/main \; refs/remotes/local/split/llvm/${my_local_branch}); git -C my-monorepo checkout local/octopus/${my_local_branch}. subproject_branches=(); for p in ${my_projects[@]}; do; subproject_branch=${p}/local/monorepo/${my_local_branch}; git -C my-monorepo branch ${subproject_branch} \; refs/remotes/local/split/${p}/${my_local_branch}; if [[ ""${p}"" != ""llvm"" ]]; then; subproject_branches+=( ${subproject_branch} ); fi; don",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:24132,Availability,down,downstream,24132,"branched component has its branch rewritten on top of the; monorepo and all components are unified by a giant octopus merge. If additional active local branches need to be preserved, the above; operations following the assignment to ``my_local_branch`` should be; done for each branch. Ref paths will need to be updated to map the; local branch to the corresponding upstream branch. If local branches; have no corresponding upstream branch, then the creation of; ``local/octopus/<local branch>`` need not use ``git-merge-base`` to; pinpoint its root commit; it may simply be branched from the; appropriate component branch (say, ``llvm/local_release_X``). Zipping local history; ---------------------. The octopus merge is suboptimal for many cases, because walking back; through the history of one component leaves the other components fixed; at a history that likely makes things unbuildable. Some downstream users track the order commits were made to subprojects; with some kind of ""umbrella"" project that imports the project git; mirrors as submodules, similar to the multirepo umbrella proposed; above. Such an umbrella repository looks something like this::. UM1 ---- UM2 -- UM3 -- UM4 ---- UM5 ---- UM6 ---- UM7 ---- UM8 <- main; | | | | | | |; Lllvm1 Llld1 Lclang1 Lclang2 Lllvm2 Llld2 Lmyproj1. The vertical bars represent submodule updates to a particular local; commit in the project mirror. ``UM3`` in this case is a commit of; some local umbrella repository state that is not a submodule update,; perhaps a ``README`` or project build script update. Commit ``UM8``; updates a submodule of local project ``myproj``. The tool ``zip-downstream-fork.py`` at; https://github.com/greened/llvm-git-migration/tree/zip can be used to; convert the umbrella history into a monorepo-based history with; commits in the order implied by submodule updates::. U1 - U2 - U3 <- upstream/main; \ \ \; \ -----\--------------- local/zip--.; \ \ \ |; - Lllvm1 - Llld1 - UM3 - Lclang1 - Lclang2 - Lllvm2 - Llld2",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:24875,Availability,down,downstream-fork,24875,"elease_X``). Zipping local history; ---------------------. The octopus merge is suboptimal for many cases, because walking back; through the history of one component leaves the other components fixed; at a history that likely makes things unbuildable. Some downstream users track the order commits were made to subprojects; with some kind of ""umbrella"" project that imports the project git; mirrors as submodules, similar to the multirepo umbrella proposed; above. Such an umbrella repository looks something like this::. UM1 ---- UM2 -- UM3 -- UM4 ---- UM5 ---- UM6 ---- UM7 ---- UM8 <- main; | | | | | | |; Lllvm1 Llld1 Lclang1 Lclang2 Lllvm2 Llld2 Lmyproj1. The vertical bars represent submodule updates to a particular local; commit in the project mirror. ``UM3`` in this case is a commit of; some local umbrella repository state that is not a submodule update,; perhaps a ``README`` or project build script update. Commit ``UM8``; updates a submodule of local project ``myproj``. The tool ``zip-downstream-fork.py`` at; https://github.com/greened/llvm-git-migration/tree/zip can be used to; convert the umbrella history into a monorepo-based history with; commits in the order implied by submodule updates::. U1 - U2 - U3 <- upstream/main; \ \ \; \ -----\--------------- local/zip--.; \ \ \ |; - Lllvm1 - Llld1 - UM3 - Lclang1 - Lclang2 - Lllvm2 - Llld2 - Lmyproj1 <-'. The ``U*`` commits represent upstream commits to the monorepo main; branch. Each submodule update in the local ``UM*`` commits brought in; a subproject tree at some local commit. The trees in the ``L*1``; commits represent merges from upstream. These result in edges from; the ``U*`` commits to their corresponding rewritten ``L*1`` commits.; The ``L*2`` commits did not do any merges from upstream. Note that the merge from ``U2`` to ``Lclang1`` appears redundant, but; if, say, ``U3`` changed some files in upstream clang, the ``Lclang1``; commit appearing after the ``Llld1`` commit would actually represent a; clang tree ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:25705,Availability,redundant,redundant,25705,"ript update. Commit ``UM8``; updates a submodule of local project ``myproj``. The tool ``zip-downstream-fork.py`` at; https://github.com/greened/llvm-git-migration/tree/zip can be used to; convert the umbrella history into a monorepo-based history with; commits in the order implied by submodule updates::. U1 - U2 - U3 <- upstream/main; \ \ \; \ -----\--------------- local/zip--.; \ \ \ |; - Lllvm1 - Llld1 - UM3 - Lclang1 - Lclang2 - Lllvm2 - Llld2 - Lmyproj1 <-'. The ``U*`` commits represent upstream commits to the monorepo main; branch. Each submodule update in the local ``UM*`` commits brought in; a subproject tree at some local commit. The trees in the ``L*1``; commits represent merges from upstream. These result in edges from; the ``U*`` commits to their corresponding rewritten ``L*1`` commits.; The ``L*2`` commits did not do any merges from upstream. Note that the merge from ``U2`` to ``Lclang1`` appears redundant, but; if, say, ``U3`` changed some files in upstream clang, the ``Lclang1``; commit appearing after the ``Llld1`` commit would actually represent a; clang tree *earlier* in the upstream clang history. We want the; ``local/zip`` branch to accurately represent the state of our umbrella; history and so the edge ``U2 -> Lclang1`` is a visual reminder of what; clang's tree actually looks like in ``Lclang1``. Even so, the edge ``U3 -> Llld1`` could be problematic for future; merges from upstream. git will think that we've already merged from; ``U3``, and we have, except for the state of the clang tree. One; possible mitigation strategy is to manually diff clang between ``U2``; and ``U3`` and apply those updates to ``local/zip``. Another,; possibly simpler strategy is to freeze local work on downstream; branches and merge all submodules from the latest upstream before; running ``zip-downstream-fork.py``. If downstream merged each project; from upstream in lockstep without any intervening local commits, then; things should be fine without any special action. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:26511,Availability,down,downstream,26511," commits to their corresponding rewritten ``L*1`` commits.; The ``L*2`` commits did not do any merges from upstream. Note that the merge from ``U2`` to ``Lclang1`` appears redundant, but; if, say, ``U3`` changed some files in upstream clang, the ``Lclang1``; commit appearing after the ``Llld1`` commit would actually represent a; clang tree *earlier* in the upstream clang history. We want the; ``local/zip`` branch to accurately represent the state of our umbrella; history and so the edge ``U2 -> Lclang1`` is a visual reminder of what; clang's tree actually looks like in ``Lclang1``. Even so, the edge ``U3 -> Llld1`` could be problematic for future; merges from upstream. git will think that we've already merged from; ``U3``, and we have, except for the state of the clang tree. One; possible mitigation strategy is to manually diff clang between ``U2``; and ``U3`` and apply those updates to ``local/zip``. Another,; possibly simpler strategy is to freeze local work on downstream; branches and merge all submodules from the latest upstream before; running ``zip-downstream-fork.py``. If downstream merged each project; from upstream in lockstep without any intervening local commits, then; things should be fine without any special action. We anticipate this; to be the common case. The tree for ``Lclang1`` outside of clang will represent the state of; things at ``U3`` since all of the upstream projects not participating; in the umbrella history should be in a state respecting the commit; ``U3``. The trees for llvm and lld should correctly represent commits; ``Lllvm1`` and ``Llld1``, respectively. Commit ``UM3`` changed files not related to submodules and we need; somewhere to put them. It is not safe in general to put them in the; monorepo root directory because they may conflict with files in the; monorepo. Let's assume we want them in a directory ``local`` in the; monorepo. **Example 1: Umbrella looks like the monorepo**. For this example, we'll assume that each subproject ap",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:26604,Availability,down,downstream-fork,26604," commits to their corresponding rewritten ``L*1`` commits.; The ``L*2`` commits did not do any merges from upstream. Note that the merge from ``U2`` to ``Lclang1`` appears redundant, but; if, say, ``U3`` changed some files in upstream clang, the ``Lclang1``; commit appearing after the ``Llld1`` commit would actually represent a; clang tree *earlier* in the upstream clang history. We want the; ``local/zip`` branch to accurately represent the state of our umbrella; history and so the edge ``U2 -> Lclang1`` is a visual reminder of what; clang's tree actually looks like in ``Lclang1``. Even so, the edge ``U3 -> Llld1`` could be problematic for future; merges from upstream. git will think that we've already merged from; ``U3``, and we have, except for the state of the clang tree. One; possible mitigation strategy is to manually diff clang between ``U2``; and ``U3`` and apply those updates to ``local/zip``. Another,; possibly simpler strategy is to freeze local work on downstream; branches and merge all submodules from the latest upstream before; running ``zip-downstream-fork.py``. If downstream merged each project; from upstream in lockstep without any intervening local commits, then; things should be fine without any special action. We anticipate this; to be the common case. The tree for ``Lclang1`` outside of clang will represent the state of; things at ``U3`` since all of the upstream projects not participating; in the umbrella history should be in a state respecting the commit; ``U3``. The trees for llvm and lld should correctly represent commits; ``Lllvm1`` and ``Llld1``, respectively. Commit ``UM3`` changed files not related to submodules and we need; somewhere to put them. It is not safe in general to put them in the; monorepo root directory because they may conflict with files in the; monorepo. Let's assume we want them in a directory ``local`` in the; monorepo. **Example 1: Umbrella looks like the monorepo**. For this example, we'll assume that each subproject ap",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:26629,Availability,down,downstream,26629,"s redundant, but; if, say, ``U3`` changed some files in upstream clang, the ``Lclang1``; commit appearing after the ``Llld1`` commit would actually represent a; clang tree *earlier* in the upstream clang history. We want the; ``local/zip`` branch to accurately represent the state of our umbrella; history and so the edge ``U2 -> Lclang1`` is a visual reminder of what; clang's tree actually looks like in ``Lclang1``. Even so, the edge ``U3 -> Llld1`` could be problematic for future; merges from upstream. git will think that we've already merged from; ``U3``, and we have, except for the state of the clang tree. One; possible mitigation strategy is to manually diff clang between ``U2``; and ``U3`` and apply those updates to ``local/zip``. Another,; possibly simpler strategy is to freeze local work on downstream; branches and merge all submodules from the latest upstream before; running ``zip-downstream-fork.py``. If downstream merged each project; from upstream in lockstep without any intervening local commits, then; things should be fine without any special action. We anticipate this; to be the common case. The tree for ``Lclang1`` outside of clang will represent the state of; things at ``U3`` since all of the upstream projects not participating; in the umbrella history should be in a state respecting the commit; ``U3``. The trees for llvm and lld should correctly represent commits; ``Lllvm1`` and ``Llld1``, respectively. Commit ``UM3`` changed files not related to submodules and we need; somewhere to put them. It is not safe in general to put them in the; monorepo root directory because they may conflict with files in the; monorepo. Let's assume we want them in a directory ``local`` in the; monorepo. **Example 1: Umbrella looks like the monorepo**. For this example, we'll assume that each subproject appears in its own; top-level directory in the umbrella, just as they do in the monorepo .; Let's also assume that we want the files in directory ``myproj`` to; appear in ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:27754,Availability,down,downstream-fork,27754," be fine without any special action. We anticipate this; to be the common case. The tree for ``Lclang1`` outside of clang will represent the state of; things at ``U3`` since all of the upstream projects not participating; in the umbrella history should be in a state respecting the commit; ``U3``. The trees for llvm and lld should correctly represent commits; ``Lllvm1`` and ``Llld1``, respectively. Commit ``UM3`` changed files not related to submodules and we need; somewhere to put them. It is not safe in general to put them in the; monorepo root directory because they may conflict with files in the; monorepo. Let's assume we want them in a directory ``local`` in the; monorepo. **Example 1: Umbrella looks like the monorepo**. For this example, we'll assume that each subproject appears in its own; top-level directory in the umbrella, just as they do in the monorepo .; Let's also assume that we want the files in directory ``myproj`` to; appear in ``local/myproj``. Given the above run of ``migrate-downstream-fork.py``, a recipe to; create the zipped history is below::. # Import any non-LLVM repositories the umbrella references.; git -C my-monorepo remote add localrepo \; https://my.local.mirror.org/localrepo.git; git fetch localrepo. subprojects=( clang clang-tools-extra compiler-rt debuginfo-tests libclc; libcxx libcxxabi libunwind lld lldb llgo llvm openmp; parallel-libs polly pstl ). # Import histories for upstream split projects (this was probably; # already done for the ``migrate-downstream-fork.py`` run).; for project in ${subprojects[@]}; do; git remote add upstream/split/${project} \; https://github.com/llvm-mirror/${subproject}.git; git fetch umbrella/split/${project}; done. # Import histories for downstream split projects (this was probably; # already done for the ``migrate-downstream-fork.py`` run).; for project in ${subprojects[@]}; do; git remote add local/split/${project} \; https://my.local.mirror.org/${subproject}.git; git fetch local/split/${project}; d",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:28251,Availability,down,downstream-fork,28251,"need; somewhere to put them. It is not safe in general to put them in the; monorepo root directory because they may conflict with files in the; monorepo. Let's assume we want them in a directory ``local`` in the; monorepo. **Example 1: Umbrella looks like the monorepo**. For this example, we'll assume that each subproject appears in its own; top-level directory in the umbrella, just as they do in the monorepo .; Let's also assume that we want the files in directory ``myproj`` to; appear in ``local/myproj``. Given the above run of ``migrate-downstream-fork.py``, a recipe to; create the zipped history is below::. # Import any non-LLVM repositories the umbrella references.; git -C my-monorepo remote add localrepo \; https://my.local.mirror.org/localrepo.git; git fetch localrepo. subprojects=( clang clang-tools-extra compiler-rt debuginfo-tests libclc; libcxx libcxxabi libunwind lld lldb llgo llvm openmp; parallel-libs polly pstl ). # Import histories for upstream split projects (this was probably; # already done for the ``migrate-downstream-fork.py`` run).; for project in ${subprojects[@]}; do; git remote add upstream/split/${project} \; https://github.com/llvm-mirror/${subproject}.git; git fetch umbrella/split/${project}; done. # Import histories for downstream split projects (this was probably; # already done for the ``migrate-downstream-fork.py`` run).; for project in ${subprojects[@]}; do; git remote add local/split/${project} \; https://my.local.mirror.org/${subproject}.git; git fetch local/split/${project}; done. # Import umbrella history.; git -C my-monorepo remote add umbrella \; https://my.local.mirror.org/umbrella.git; git fetch umbrella. # Put myproj in local/myproj; echo ""myproj local/myproj"" > my-monorepo/submodule-map.txt. # Rewrite history; (; cd my-monorepo; zip-downstream-fork.py \; refs/remotes/umbrella \; --new-repo-prefix=refs/remotes/upstream/monorepo \; --old-repo-prefix=refs/remotes/upstream/split \; --revmap-in=monorepo-map.txt \; --revmap-out=zi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:28477,Availability,down,downstream,28477,"hat each subproject appears in its own; top-level directory in the umbrella, just as they do in the monorepo .; Let's also assume that we want the files in directory ``myproj`` to; appear in ``local/myproj``. Given the above run of ``migrate-downstream-fork.py``, a recipe to; create the zipped history is below::. # Import any non-LLVM repositories the umbrella references.; git -C my-monorepo remote add localrepo \; https://my.local.mirror.org/localrepo.git; git fetch localrepo. subprojects=( clang clang-tools-extra compiler-rt debuginfo-tests libclc; libcxx libcxxabi libunwind lld lldb llgo llvm openmp; parallel-libs polly pstl ). # Import histories for upstream split projects (this was probably; # already done for the ``migrate-downstream-fork.py`` run).; for project in ${subprojects[@]}; do; git remote add upstream/split/${project} \; https://github.com/llvm-mirror/${subproject}.git; git fetch umbrella/split/${project}; done. # Import histories for downstream split projects (this was probably; # already done for the ``migrate-downstream-fork.py`` run).; for project in ${subprojects[@]}; do; git remote add local/split/${project} \; https://my.local.mirror.org/${subproject}.git; git fetch local/split/${project}; done. # Import umbrella history.; git -C my-monorepo remote add umbrella \; https://my.local.mirror.org/umbrella.git; git fetch umbrella. # Put myproj in local/myproj; echo ""myproj local/myproj"" > my-monorepo/submodule-map.txt. # Rewrite history; (; cd my-monorepo; zip-downstream-fork.py \; refs/remotes/umbrella \; --new-repo-prefix=refs/remotes/upstream/monorepo \; --old-repo-prefix=refs/remotes/upstream/split \; --revmap-in=monorepo-map.txt \; --revmap-out=zip-map.txt \; --subdir=local \; --submodule-map=submodule-map.txt \; --update-tags; ). # Create the zip branch (assuming umbrella main is wanted).; git -C my-monorepo branch --no-track local/zip/main refs/remotes/umbrella/main. Note that if the umbrella has submodules to non-LLVM repositories,; ``zip-dow",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:28556,Availability,down,downstream-fork,28556,"hat each subproject appears in its own; top-level directory in the umbrella, just as they do in the monorepo .; Let's also assume that we want the files in directory ``myproj`` to; appear in ``local/myproj``. Given the above run of ``migrate-downstream-fork.py``, a recipe to; create the zipped history is below::. # Import any non-LLVM repositories the umbrella references.; git -C my-monorepo remote add localrepo \; https://my.local.mirror.org/localrepo.git; git fetch localrepo. subprojects=( clang clang-tools-extra compiler-rt debuginfo-tests libclc; libcxx libcxxabi libunwind lld lldb llgo llvm openmp; parallel-libs polly pstl ). # Import histories for upstream split projects (this was probably; # already done for the ``migrate-downstream-fork.py`` run).; for project in ${subprojects[@]}; do; git remote add upstream/split/${project} \; https://github.com/llvm-mirror/${subproject}.git; git fetch umbrella/split/${project}; done. # Import histories for downstream split projects (this was probably; # already done for the ``migrate-downstream-fork.py`` run).; for project in ${subprojects[@]}; do; git remote add local/split/${project} \; https://my.local.mirror.org/${subproject}.git; git fetch local/split/${project}; done. # Import umbrella history.; git -C my-monorepo remote add umbrella \; https://my.local.mirror.org/umbrella.git; git fetch umbrella. # Put myproj in local/myproj; echo ""myproj local/myproj"" > my-monorepo/submodule-map.txt. # Rewrite history; (; cd my-monorepo; zip-downstream-fork.py \; refs/remotes/umbrella \; --new-repo-prefix=refs/remotes/upstream/monorepo \; --old-repo-prefix=refs/remotes/upstream/split \; --revmap-in=monorepo-map.txt \; --revmap-out=zip-map.txt \; --subdir=local \; --submodule-map=submodule-map.txt \; --update-tags; ). # Create the zip branch (assuming umbrella main is wanted).; git -C my-monorepo branch --no-track local/zip/main refs/remotes/umbrella/main. Note that if the umbrella has submodules to non-LLVM repositories,; ``zip-dow",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:28912,Availability,echo,echo,28912,"epo \; https://my.local.mirror.org/localrepo.git; git fetch localrepo. subprojects=( clang clang-tools-extra compiler-rt debuginfo-tests libclc; libcxx libcxxabi libunwind lld lldb llgo llvm openmp; parallel-libs polly pstl ). # Import histories for upstream split projects (this was probably; # already done for the ``migrate-downstream-fork.py`` run).; for project in ${subprojects[@]}; do; git remote add upstream/split/${project} \; https://github.com/llvm-mirror/${subproject}.git; git fetch umbrella/split/${project}; done. # Import histories for downstream split projects (this was probably; # already done for the ``migrate-downstream-fork.py`` run).; for project in ${subprojects[@]}; do; git remote add local/split/${project} \; https://my.local.mirror.org/${subproject}.git; git fetch local/split/${project}; done. # Import umbrella history.; git -C my-monorepo remote add umbrella \; https://my.local.mirror.org/umbrella.git; git fetch umbrella. # Put myproj in local/myproj; echo ""myproj local/myproj"" > my-monorepo/submodule-map.txt. # Rewrite history; (; cd my-monorepo; zip-downstream-fork.py \; refs/remotes/umbrella \; --new-repo-prefix=refs/remotes/upstream/monorepo \; --old-repo-prefix=refs/remotes/upstream/split \; --revmap-in=monorepo-map.txt \; --revmap-out=zip-map.txt \; --subdir=local \; --submodule-map=submodule-map.txt \; --update-tags; ). # Create the zip branch (assuming umbrella main is wanted).; git -C my-monorepo branch --no-track local/zip/main refs/remotes/umbrella/main. Note that if the umbrella has submodules to non-LLVM repositories,; ``zip-downstream-fork.py`` needs to know about them to be able to; rewrite commits. That is why the first step above is to fetch commits; from such repositories. With ``--update-tags`` the tool will migrate annotated tags pointing; to submodule commits that were inlined into the zipped history. If; the umbrella pulled in an upstream commit that happened to have a tag; pointing to it, that tag will be migrated, which ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:29014,Availability,down,downstream-fork,29014,"ojects=( clang clang-tools-extra compiler-rt debuginfo-tests libclc; libcxx libcxxabi libunwind lld lldb llgo llvm openmp; parallel-libs polly pstl ). # Import histories for upstream split projects (this was probably; # already done for the ``migrate-downstream-fork.py`` run).; for project in ${subprojects[@]}; do; git remote add upstream/split/${project} \; https://github.com/llvm-mirror/${subproject}.git; git fetch umbrella/split/${project}; done. # Import histories for downstream split projects (this was probably; # already done for the ``migrate-downstream-fork.py`` run).; for project in ${subprojects[@]}; do; git remote add local/split/${project} \; https://my.local.mirror.org/${subproject}.git; git fetch local/split/${project}; done. # Import umbrella history.; git -C my-monorepo remote add umbrella \; https://my.local.mirror.org/umbrella.git; git fetch umbrella. # Put myproj in local/myproj; echo ""myproj local/myproj"" > my-monorepo/submodule-map.txt. # Rewrite history; (; cd my-monorepo; zip-downstream-fork.py \; refs/remotes/umbrella \; --new-repo-prefix=refs/remotes/upstream/monorepo \; --old-repo-prefix=refs/remotes/upstream/split \; --revmap-in=monorepo-map.txt \; --revmap-out=zip-map.txt \; --subdir=local \; --submodule-map=submodule-map.txt \; --update-tags; ). # Create the zip branch (assuming umbrella main is wanted).; git -C my-monorepo branch --no-track local/zip/main refs/remotes/umbrella/main. Note that if the umbrella has submodules to non-LLVM repositories,; ``zip-downstream-fork.py`` needs to know about them to be able to; rewrite commits. That is why the first step above is to fetch commits; from such repositories. With ``--update-tags`` the tool will migrate annotated tags pointing; to submodule commits that were inlined into the zipped history. If; the umbrella pulled in an upstream commit that happened to have a tag; pointing to it, that tag will be migrated, which is almost certainly; not what is wanted. The tag can always be moved back to ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:29510,Availability,down,downstream-fork,29510,"nstream split projects (this was probably; # already done for the ``migrate-downstream-fork.py`` run).; for project in ${subprojects[@]}; do; git remote add local/split/${project} \; https://my.local.mirror.org/${subproject}.git; git fetch local/split/${project}; done. # Import umbrella history.; git -C my-monorepo remote add umbrella \; https://my.local.mirror.org/umbrella.git; git fetch umbrella. # Put myproj in local/myproj; echo ""myproj local/myproj"" > my-monorepo/submodule-map.txt. # Rewrite history; (; cd my-monorepo; zip-downstream-fork.py \; refs/remotes/umbrella \; --new-repo-prefix=refs/remotes/upstream/monorepo \; --old-repo-prefix=refs/remotes/upstream/split \; --revmap-in=monorepo-map.txt \; --revmap-out=zip-map.txt \; --subdir=local \; --submodule-map=submodule-map.txt \; --update-tags; ). # Create the zip branch (assuming umbrella main is wanted).; git -C my-monorepo branch --no-track local/zip/main refs/remotes/umbrella/main. Note that if the umbrella has submodules to non-LLVM repositories,; ``zip-downstream-fork.py`` needs to know about them to be able to; rewrite commits. That is why the first step above is to fetch commits; from such repositories. With ``--update-tags`` the tool will migrate annotated tags pointing; to submodule commits that were inlined into the zipped history. If; the umbrella pulled in an upstream commit that happened to have a tag; pointing to it, that tag will be migrated, which is almost certainly; not what is wanted. The tag can always be moved back to its original; commit after rewriting, or the ``--update-tags`` option may be; discarded and any local tags would then be migrated manually. **Example 2: Nested sources layout**. The tool handles nested submodules (e.g. llvm is a submodule in; umbrella and clang is a submodule in llvm). The file; ``submodule-map.txt`` is a list of pairs, one per line. The first; pair item describes the path to a submodule in the umbrella; repository. The second pair item describes the path whe",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:30771,Availability,down,downstream,30771,"e commits that were inlined into the zipped history. If; the umbrella pulled in an upstream commit that happened to have a tag; pointing to it, that tag will be migrated, which is almost certainly; not what is wanted. The tag can always be moved back to its original; commit after rewriting, or the ``--update-tags`` option may be; discarded and any local tags would then be migrated manually. **Example 2: Nested sources layout**. The tool handles nested submodules (e.g. llvm is a submodule in; umbrella and clang is a submodule in llvm). The file; ``submodule-map.txt`` is a list of pairs, one per line. The first; pair item describes the path to a submodule in the umbrella; repository. The second pair item describes the path where trees for; that submodule should be written in the zipped history. Let's say your umbrella repository is actually the llvm repository and; it has submodules in the ""nested sources"" layout (clang in; tools/clang, etc.). Let's also say ``projects/myproj`` is a submodule; pointing to some downstream repository. The submodule map file should; look like this (we still want myproj mapped the same way as; previously)::. tools/clang clang; tools/clang/tools/extra clang-tools-extra; projects/compiler-rt compiler-rt; projects/debuginfo-tests debuginfo-tests; projects/libclc libclc; projects/libcxx libcxx; projects/libcxxabi libcxxabi; projects/libunwind libunwind; tools/lld lld; tools/lldb lldb; projects/openmp openmp; tools/polly polly; projects/myproj local/myproj. If a submodule path does not appear in the map, the tools assumes it; should be placed in the same place in the monorepo. That means if you; use the ""nested sources"" layout in your umrella, you *must* provide; map entries for all of the projects in your umbrella (except llvm).; Otherwise trees from submodule updates will appear underneath llvm in; the zippped history. Because llvm is itself the umbrella, we use --subdir to write its; content into ``llvm`` in the zippped history::. # Import a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:32162,Availability,down,downstream-fork,32162,"ojects/libunwind libunwind; tools/lld lld; tools/lldb lldb; projects/openmp openmp; tools/polly polly; projects/myproj local/myproj. If a submodule path does not appear in the map, the tools assumes it; should be placed in the same place in the monorepo. That means if you; use the ""nested sources"" layout in your umrella, you *must* provide; map entries for all of the projects in your umbrella (except llvm).; Otherwise trees from submodule updates will appear underneath llvm in; the zippped history. Because llvm is itself the umbrella, we use --subdir to write its; content into ``llvm`` in the zippped history::. # Import any non-LLVM repositories the umbrella references.; git -C my-monorepo remote add localrepo \; https://my.local.mirror.org/localrepo.git; git fetch localrepo. subprojects=( clang clang-tools-extra compiler-rt debuginfo-tests libclc; libcxx libcxxabi libunwind lld lldb llgo llvm openmp; parallel-libs polly pstl ). # Import histories for upstream split projects (this was probably; # already done for the ``migrate-downstream-fork.py`` run).; for project in ${subprojects[@]}; do; git remote add upstream/split/${project} \; https://github.com/llvm-mirror/${subproject}.git; git fetch umbrella/split/${project}; done. # Import histories for downstream split projects (this was probably; # already done for the ``migrate-downstream-fork.py`` run).; for project in ${subprojects[@]}; do; git remote add local/split/${project} \; https://my.local.mirror.org/${subproject}.git; git fetch local/split/${project}; done. # Import umbrella history. We want this under a different refspec; # so zip-downstream-fork.py knows what it is.; git -C my-monorepo remote add umbrella \; https://my.local.mirror.org/llvm.git; git fetch umbrella. # Create the submodule map.; echo ""tools/clang clang"" > my-monorepo/submodule-map.txt; echo ""tools/clang/tools/extra clang-tools-extra"" >> my-monorepo/submodule-map.txt; echo ""projects/compiler-rt compiler-rt"" >> my-monorepo/submodule-map.txt; e",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:32388,Availability,down,downstream,32388,"t in your umrella, you *must* provide; map entries for all of the projects in your umbrella (except llvm).; Otherwise trees from submodule updates will appear underneath llvm in; the zippped history. Because llvm is itself the umbrella, we use --subdir to write its; content into ``llvm`` in the zippped history::. # Import any non-LLVM repositories the umbrella references.; git -C my-monorepo remote add localrepo \; https://my.local.mirror.org/localrepo.git; git fetch localrepo. subprojects=( clang clang-tools-extra compiler-rt debuginfo-tests libclc; libcxx libcxxabi libunwind lld lldb llgo llvm openmp; parallel-libs polly pstl ). # Import histories for upstream split projects (this was probably; # already done for the ``migrate-downstream-fork.py`` run).; for project in ${subprojects[@]}; do; git remote add upstream/split/${project} \; https://github.com/llvm-mirror/${subproject}.git; git fetch umbrella/split/${project}; done. # Import histories for downstream split projects (this was probably; # already done for the ``migrate-downstream-fork.py`` run).; for project in ${subprojects[@]}; do; git remote add local/split/${project} \; https://my.local.mirror.org/${subproject}.git; git fetch local/split/${project}; done. # Import umbrella history. We want this under a different refspec; # so zip-downstream-fork.py knows what it is.; git -C my-monorepo remote add umbrella \; https://my.local.mirror.org/llvm.git; git fetch umbrella. # Create the submodule map.; echo ""tools/clang clang"" > my-monorepo/submodule-map.txt; echo ""tools/clang/tools/extra clang-tools-extra"" >> my-monorepo/submodule-map.txt; echo ""projects/compiler-rt compiler-rt"" >> my-monorepo/submodule-map.txt; echo ""projects/debuginfo-tests debuginfo-tests"" >> my-monorepo/submodule-map.txt; echo ""projects/libclc libclc"" >> my-monorepo/submodule-map.txt; echo ""projects/libcxx libcxx"" >> my-monorepo/submodule-map.txt; echo ""projects/libcxxabi libcxxabi"" >> my-monorepo/submodule-map.txt; echo ""projects/libunwind ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:32467,Availability,down,downstream-fork,32467,"t in your umrella, you *must* provide; map entries for all of the projects in your umbrella (except llvm).; Otherwise trees from submodule updates will appear underneath llvm in; the zippped history. Because llvm is itself the umbrella, we use --subdir to write its; content into ``llvm`` in the zippped history::. # Import any non-LLVM repositories the umbrella references.; git -C my-monorepo remote add localrepo \; https://my.local.mirror.org/localrepo.git; git fetch localrepo. subprojects=( clang clang-tools-extra compiler-rt debuginfo-tests libclc; libcxx libcxxabi libunwind lld lldb llgo llvm openmp; parallel-libs polly pstl ). # Import histories for upstream split projects (this was probably; # already done for the ``migrate-downstream-fork.py`` run).; for project in ${subprojects[@]}; do; git remote add upstream/split/${project} \; https://github.com/llvm-mirror/${subproject}.git; git fetch umbrella/split/${project}; done. # Import histories for downstream split projects (this was probably; # already done for the ``migrate-downstream-fork.py`` run).; for project in ${subprojects[@]}; do; git remote add local/split/${project} \; https://my.local.mirror.org/${subproject}.git; git fetch local/split/${project}; done. # Import umbrella history. We want this under a different refspec; # so zip-downstream-fork.py knows what it is.; git -C my-monorepo remote add umbrella \; https://my.local.mirror.org/llvm.git; git fetch umbrella. # Create the submodule map.; echo ""tools/clang clang"" > my-monorepo/submodule-map.txt; echo ""tools/clang/tools/extra clang-tools-extra"" >> my-monorepo/submodule-map.txt; echo ""projects/compiler-rt compiler-rt"" >> my-monorepo/submodule-map.txt; echo ""projects/debuginfo-tests debuginfo-tests"" >> my-monorepo/submodule-map.txt; echo ""projects/libclc libclc"" >> my-monorepo/submodule-map.txt; echo ""projects/libcxx libcxx"" >> my-monorepo/submodule-map.txt; echo ""projects/libcxxabi libcxxabi"" >> my-monorepo/submodule-map.txt; echo ""projects/libunwind ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:32737,Availability,down,downstream-fork,32737,"ippped history::. # Import any non-LLVM repositories the umbrella references.; git -C my-monorepo remote add localrepo \; https://my.local.mirror.org/localrepo.git; git fetch localrepo. subprojects=( clang clang-tools-extra compiler-rt debuginfo-tests libclc; libcxx libcxxabi libunwind lld lldb llgo llvm openmp; parallel-libs polly pstl ). # Import histories for upstream split projects (this was probably; # already done for the ``migrate-downstream-fork.py`` run).; for project in ${subprojects[@]}; do; git remote add upstream/split/${project} \; https://github.com/llvm-mirror/${subproject}.git; git fetch umbrella/split/${project}; done. # Import histories for downstream split projects (this was probably; # already done for the ``migrate-downstream-fork.py`` run).; for project in ${subprojects[@]}; do; git remote add local/split/${project} \; https://my.local.mirror.org/${subproject}.git; git fetch local/split/${project}; done. # Import umbrella history. We want this under a different refspec; # so zip-downstream-fork.py knows what it is.; git -C my-monorepo remote add umbrella \; https://my.local.mirror.org/llvm.git; git fetch umbrella. # Create the submodule map.; echo ""tools/clang clang"" > my-monorepo/submodule-map.txt; echo ""tools/clang/tools/extra clang-tools-extra"" >> my-monorepo/submodule-map.txt; echo ""projects/compiler-rt compiler-rt"" >> my-monorepo/submodule-map.txt; echo ""projects/debuginfo-tests debuginfo-tests"" >> my-monorepo/submodule-map.txt; echo ""projects/libclc libclc"" >> my-monorepo/submodule-map.txt; echo ""projects/libcxx libcxx"" >> my-monorepo/submodule-map.txt; echo ""projects/libcxxabi libcxxabi"" >> my-monorepo/submodule-map.txt; echo ""projects/libunwind libunwind"" >> my-monorepo/submodule-map.txt; echo ""tools/lld lld"" >> my-monorepo/submodule-map.txt; echo ""tools/lldb lldb"" >> my-monorepo/submodule-map.txt; echo ""projects/openmp openmp"" >> my-monorepo/submodule-map.txt; echo ""tools/polly polly"" >> my-monorepo/submodule-map.txt; echo ""projects/m",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:32904,Availability,echo,echo,32904,"ng-tools-extra compiler-rt debuginfo-tests libclc; libcxx libcxxabi libunwind lld lldb llgo llvm openmp; parallel-libs polly pstl ). # Import histories for upstream split projects (this was probably; # already done for the ``migrate-downstream-fork.py`` run).; for project in ${subprojects[@]}; do; git remote add upstream/split/${project} \; https://github.com/llvm-mirror/${subproject}.git; git fetch umbrella/split/${project}; done. # Import histories for downstream split projects (this was probably; # already done for the ``migrate-downstream-fork.py`` run).; for project in ${subprojects[@]}; do; git remote add local/split/${project} \; https://my.local.mirror.org/${subproject}.git; git fetch local/split/${project}; done. # Import umbrella history. We want this under a different refspec; # so zip-downstream-fork.py knows what it is.; git -C my-monorepo remote add umbrella \; https://my.local.mirror.org/llvm.git; git fetch umbrella. # Create the submodule map.; echo ""tools/clang clang"" > my-monorepo/submodule-map.txt; echo ""tools/clang/tools/extra clang-tools-extra"" >> my-monorepo/submodule-map.txt; echo ""projects/compiler-rt compiler-rt"" >> my-monorepo/submodule-map.txt; echo ""projects/debuginfo-tests debuginfo-tests"" >> my-monorepo/submodule-map.txt; echo ""projects/libclc libclc"" >> my-monorepo/submodule-map.txt; echo ""projects/libcxx libcxx"" >> my-monorepo/submodule-map.txt; echo ""projects/libcxxabi libcxxabi"" >> my-monorepo/submodule-map.txt; echo ""projects/libunwind libunwind"" >> my-monorepo/submodule-map.txt; echo ""tools/lld lld"" >> my-monorepo/submodule-map.txt; echo ""tools/lldb lldb"" >> my-monorepo/submodule-map.txt; echo ""projects/openmp openmp"" >> my-monorepo/submodule-map.txt; echo ""tools/polly polly"" >> my-monorepo/submodule-map.txt; echo ""projects/myproj local/myproj"" >> my-monorepo/submodule-map.txt. # Rewrite history; (; cd my-monorepo; zip-downstream-fork.py \; refs/remotes/umbrella \; --new-repo-prefix=refs/remotes/upstream/monorepo \; --old-repo-pref",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:32962,Availability,echo,echo,32962,"ibunwind lld lldb llgo llvm openmp; parallel-libs polly pstl ). # Import histories for upstream split projects (this was probably; # already done for the ``migrate-downstream-fork.py`` run).; for project in ${subprojects[@]}; do; git remote add upstream/split/${project} \; https://github.com/llvm-mirror/${subproject}.git; git fetch umbrella/split/${project}; done. # Import histories for downstream split projects (this was probably; # already done for the ``migrate-downstream-fork.py`` run).; for project in ${subprojects[@]}; do; git remote add local/split/${project} \; https://my.local.mirror.org/${subproject}.git; git fetch local/split/${project}; done. # Import umbrella history. We want this under a different refspec; # so zip-downstream-fork.py knows what it is.; git -C my-monorepo remote add umbrella \; https://my.local.mirror.org/llvm.git; git fetch umbrella. # Create the submodule map.; echo ""tools/clang clang"" > my-monorepo/submodule-map.txt; echo ""tools/clang/tools/extra clang-tools-extra"" >> my-monorepo/submodule-map.txt; echo ""projects/compiler-rt compiler-rt"" >> my-monorepo/submodule-map.txt; echo ""projects/debuginfo-tests debuginfo-tests"" >> my-monorepo/submodule-map.txt; echo ""projects/libclc libclc"" >> my-monorepo/submodule-map.txt; echo ""projects/libcxx libcxx"" >> my-monorepo/submodule-map.txt; echo ""projects/libcxxabi libcxxabi"" >> my-monorepo/submodule-map.txt; echo ""projects/libunwind libunwind"" >> my-monorepo/submodule-map.txt; echo ""tools/lld lld"" >> my-monorepo/submodule-map.txt; echo ""tools/lldb lldb"" >> my-monorepo/submodule-map.txt; echo ""projects/openmp openmp"" >> my-monorepo/submodule-map.txt; echo ""tools/polly polly"" >> my-monorepo/submodule-map.txt; echo ""projects/myproj local/myproj"" >> my-monorepo/submodule-map.txt. # Rewrite history; (; cd my-monorepo; zip-downstream-fork.py \; refs/remotes/umbrella \; --new-repo-prefix=refs/remotes/upstream/monorepo \; --old-repo-prefix=refs/remotes/upstream/split \; --revmap-in=monorepo-map.txt \; --r",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:33045,Availability,echo,echo,33045,"ies for upstream split projects (this was probably; # already done for the ``migrate-downstream-fork.py`` run).; for project in ${subprojects[@]}; do; git remote add upstream/split/${project} \; https://github.com/llvm-mirror/${subproject}.git; git fetch umbrella/split/${project}; done. # Import histories for downstream split projects (this was probably; # already done for the ``migrate-downstream-fork.py`` run).; for project in ${subprojects[@]}; do; git remote add local/split/${project} \; https://my.local.mirror.org/${subproject}.git; git fetch local/split/${project}; done. # Import umbrella history. We want this under a different refspec; # so zip-downstream-fork.py knows what it is.; git -C my-monorepo remote add umbrella \; https://my.local.mirror.org/llvm.git; git fetch umbrella. # Create the submodule map.; echo ""tools/clang clang"" > my-monorepo/submodule-map.txt; echo ""tools/clang/tools/extra clang-tools-extra"" >> my-monorepo/submodule-map.txt; echo ""projects/compiler-rt compiler-rt"" >> my-monorepo/submodule-map.txt; echo ""projects/debuginfo-tests debuginfo-tests"" >> my-monorepo/submodule-map.txt; echo ""projects/libclc libclc"" >> my-monorepo/submodule-map.txt; echo ""projects/libcxx libcxx"" >> my-monorepo/submodule-map.txt; echo ""projects/libcxxabi libcxxabi"" >> my-monorepo/submodule-map.txt; echo ""projects/libunwind libunwind"" >> my-monorepo/submodule-map.txt; echo ""tools/lld lld"" >> my-monorepo/submodule-map.txt; echo ""tools/lldb lldb"" >> my-monorepo/submodule-map.txt; echo ""projects/openmp openmp"" >> my-monorepo/submodule-map.txt; echo ""tools/polly polly"" >> my-monorepo/submodule-map.txt; echo ""projects/myproj local/myproj"" >> my-monorepo/submodule-map.txt. # Rewrite history; (; cd my-monorepo; zip-downstream-fork.py \; refs/remotes/umbrella \; --new-repo-prefix=refs/remotes/upstream/monorepo \; --old-repo-prefix=refs/remotes/upstream/split \; --revmap-in=monorepo-map.txt \; --revmap-out=zip-map.txt \; --subdir=llvm \; --submodule-map=submodule-map.txt \;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:33119,Availability,echo,echo,33119,"igrate-downstream-fork.py`` run).; for project in ${subprojects[@]}; do; git remote add upstream/split/${project} \; https://github.com/llvm-mirror/${subproject}.git; git fetch umbrella/split/${project}; done. # Import histories for downstream split projects (this was probably; # already done for the ``migrate-downstream-fork.py`` run).; for project in ${subprojects[@]}; do; git remote add local/split/${project} \; https://my.local.mirror.org/${subproject}.git; git fetch local/split/${project}; done. # Import umbrella history. We want this under a different refspec; # so zip-downstream-fork.py knows what it is.; git -C my-monorepo remote add umbrella \; https://my.local.mirror.org/llvm.git; git fetch umbrella. # Create the submodule map.; echo ""tools/clang clang"" > my-monorepo/submodule-map.txt; echo ""tools/clang/tools/extra clang-tools-extra"" >> my-monorepo/submodule-map.txt; echo ""projects/compiler-rt compiler-rt"" >> my-monorepo/submodule-map.txt; echo ""projects/debuginfo-tests debuginfo-tests"" >> my-monorepo/submodule-map.txt; echo ""projects/libclc libclc"" >> my-monorepo/submodule-map.txt; echo ""projects/libcxx libcxx"" >> my-monorepo/submodule-map.txt; echo ""projects/libcxxabi libcxxabi"" >> my-monorepo/submodule-map.txt; echo ""projects/libunwind libunwind"" >> my-monorepo/submodule-map.txt; echo ""tools/lld lld"" >> my-monorepo/submodule-map.txt; echo ""tools/lldb lldb"" >> my-monorepo/submodule-map.txt; echo ""projects/openmp openmp"" >> my-monorepo/submodule-map.txt; echo ""tools/polly polly"" >> my-monorepo/submodule-map.txt; echo ""projects/myproj local/myproj"" >> my-monorepo/submodule-map.txt. # Rewrite history; (; cd my-monorepo; zip-downstream-fork.py \; refs/remotes/umbrella \; --new-repo-prefix=refs/remotes/upstream/monorepo \; --old-repo-prefix=refs/remotes/upstream/split \; --revmap-in=monorepo-map.txt \; --revmap-out=zip-map.txt \; --subdir=llvm \; --submodule-map=submodule-map.txt \; --update-tags; ). # Create the zip branch (assuming umbrella main is wanted).",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:33201,Availability,echo,echo,33201,"git remote add upstream/split/${project} \; https://github.com/llvm-mirror/${subproject}.git; git fetch umbrella/split/${project}; done. # Import histories for downstream split projects (this was probably; # already done for the ``migrate-downstream-fork.py`` run).; for project in ${subprojects[@]}; do; git remote add local/split/${project} \; https://my.local.mirror.org/${subproject}.git; git fetch local/split/${project}; done. # Import umbrella history. We want this under a different refspec; # so zip-downstream-fork.py knows what it is.; git -C my-monorepo remote add umbrella \; https://my.local.mirror.org/llvm.git; git fetch umbrella. # Create the submodule map.; echo ""tools/clang clang"" > my-monorepo/submodule-map.txt; echo ""tools/clang/tools/extra clang-tools-extra"" >> my-monorepo/submodule-map.txt; echo ""projects/compiler-rt compiler-rt"" >> my-monorepo/submodule-map.txt; echo ""projects/debuginfo-tests debuginfo-tests"" >> my-monorepo/submodule-map.txt; echo ""projects/libclc libclc"" >> my-monorepo/submodule-map.txt; echo ""projects/libcxx libcxx"" >> my-monorepo/submodule-map.txt; echo ""projects/libcxxabi libcxxabi"" >> my-monorepo/submodule-map.txt; echo ""projects/libunwind libunwind"" >> my-monorepo/submodule-map.txt; echo ""tools/lld lld"" >> my-monorepo/submodule-map.txt; echo ""tools/lldb lldb"" >> my-monorepo/submodule-map.txt; echo ""projects/openmp openmp"" >> my-monorepo/submodule-map.txt; echo ""tools/polly polly"" >> my-monorepo/submodule-map.txt; echo ""projects/myproj local/myproj"" >> my-monorepo/submodule-map.txt. # Rewrite history; (; cd my-monorepo; zip-downstream-fork.py \; refs/remotes/umbrella \; --new-repo-prefix=refs/remotes/upstream/monorepo \; --old-repo-prefix=refs/remotes/upstream/split \; --revmap-in=monorepo-map.txt \; --revmap-out=zip-map.txt \; --subdir=llvm \; --submodule-map=submodule-map.txt \; --update-tags; ). # Create the zip branch (assuming umbrella main is wanted).; git -C my-monorepo branch --no-track local/zip/main refs/remotes/umbrel",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:33265,Availability,echo,echo,33265,"lvm-mirror/${subproject}.git; git fetch umbrella/split/${project}; done. # Import histories for downstream split projects (this was probably; # already done for the ``migrate-downstream-fork.py`` run).; for project in ${subprojects[@]}; do; git remote add local/split/${project} \; https://my.local.mirror.org/${subproject}.git; git fetch local/split/${project}; done. # Import umbrella history. We want this under a different refspec; # so zip-downstream-fork.py knows what it is.; git -C my-monorepo remote add umbrella \; https://my.local.mirror.org/llvm.git; git fetch umbrella. # Create the submodule map.; echo ""tools/clang clang"" > my-monorepo/submodule-map.txt; echo ""tools/clang/tools/extra clang-tools-extra"" >> my-monorepo/submodule-map.txt; echo ""projects/compiler-rt compiler-rt"" >> my-monorepo/submodule-map.txt; echo ""projects/debuginfo-tests debuginfo-tests"" >> my-monorepo/submodule-map.txt; echo ""projects/libclc libclc"" >> my-monorepo/submodule-map.txt; echo ""projects/libcxx libcxx"" >> my-monorepo/submodule-map.txt; echo ""projects/libcxxabi libcxxabi"" >> my-monorepo/submodule-map.txt; echo ""projects/libunwind libunwind"" >> my-monorepo/submodule-map.txt; echo ""tools/lld lld"" >> my-monorepo/submodule-map.txt; echo ""tools/lldb lldb"" >> my-monorepo/submodule-map.txt; echo ""projects/openmp openmp"" >> my-monorepo/submodule-map.txt; echo ""tools/polly polly"" >> my-monorepo/submodule-map.txt; echo ""projects/myproj local/myproj"" >> my-monorepo/submodule-map.txt. # Rewrite history; (; cd my-monorepo; zip-downstream-fork.py \; refs/remotes/umbrella \; --new-repo-prefix=refs/remotes/upstream/monorepo \; --old-repo-prefix=refs/remotes/upstream/split \; --revmap-in=monorepo-map.txt \; --revmap-out=zip-map.txt \; --subdir=llvm \; --submodule-map=submodule-map.txt \; --update-tags; ). # Create the zip branch (assuming umbrella main is wanted).; git -C my-monorepo branch --no-track local/zip/main refs/remotes/umbrella/main. Comments at the top of ``zip-downstream-fork.py`` descr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:33329,Availability,echo,echo,33329,"done. # Import histories for downstream split projects (this was probably; # already done for the ``migrate-downstream-fork.py`` run).; for project in ${subprojects[@]}; do; git remote add local/split/${project} \; https://my.local.mirror.org/${subproject}.git; git fetch local/split/${project}; done. # Import umbrella history. We want this under a different refspec; # so zip-downstream-fork.py knows what it is.; git -C my-monorepo remote add umbrella \; https://my.local.mirror.org/llvm.git; git fetch umbrella. # Create the submodule map.; echo ""tools/clang clang"" > my-monorepo/submodule-map.txt; echo ""tools/clang/tools/extra clang-tools-extra"" >> my-monorepo/submodule-map.txt; echo ""projects/compiler-rt compiler-rt"" >> my-monorepo/submodule-map.txt; echo ""projects/debuginfo-tests debuginfo-tests"" >> my-monorepo/submodule-map.txt; echo ""projects/libclc libclc"" >> my-monorepo/submodule-map.txt; echo ""projects/libcxx libcxx"" >> my-monorepo/submodule-map.txt; echo ""projects/libcxxabi libcxxabi"" >> my-monorepo/submodule-map.txt; echo ""projects/libunwind libunwind"" >> my-monorepo/submodule-map.txt; echo ""tools/lld lld"" >> my-monorepo/submodule-map.txt; echo ""tools/lldb lldb"" >> my-monorepo/submodule-map.txt; echo ""projects/openmp openmp"" >> my-monorepo/submodule-map.txt; echo ""tools/polly polly"" >> my-monorepo/submodule-map.txt; echo ""projects/myproj local/myproj"" >> my-monorepo/submodule-map.txt. # Rewrite history; (; cd my-monorepo; zip-downstream-fork.py \; refs/remotes/umbrella \; --new-repo-prefix=refs/remotes/upstream/monorepo \; --old-repo-prefix=refs/remotes/upstream/split \; --revmap-in=monorepo-map.txt \; --revmap-out=zip-map.txt \; --subdir=llvm \; --submodule-map=submodule-map.txt \; --update-tags; ). # Create the zip branch (assuming umbrella main is wanted).; git -C my-monorepo branch --no-track local/zip/main refs/remotes/umbrella/main. Comments at the top of ``zip-downstream-fork.py`` describe in more; detail how the tool works and various implications of ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:33399,Availability,echo,echo,33399,"bly; # already done for the ``migrate-downstream-fork.py`` run).; for project in ${subprojects[@]}; do; git remote add local/split/${project} \; https://my.local.mirror.org/${subproject}.git; git fetch local/split/${project}; done. # Import umbrella history. We want this under a different refspec; # so zip-downstream-fork.py knows what it is.; git -C my-monorepo remote add umbrella \; https://my.local.mirror.org/llvm.git; git fetch umbrella. # Create the submodule map.; echo ""tools/clang clang"" > my-monorepo/submodule-map.txt; echo ""tools/clang/tools/extra clang-tools-extra"" >> my-monorepo/submodule-map.txt; echo ""projects/compiler-rt compiler-rt"" >> my-monorepo/submodule-map.txt; echo ""projects/debuginfo-tests debuginfo-tests"" >> my-monorepo/submodule-map.txt; echo ""projects/libclc libclc"" >> my-monorepo/submodule-map.txt; echo ""projects/libcxx libcxx"" >> my-monorepo/submodule-map.txt; echo ""projects/libcxxabi libcxxabi"" >> my-monorepo/submodule-map.txt; echo ""projects/libunwind libunwind"" >> my-monorepo/submodule-map.txt; echo ""tools/lld lld"" >> my-monorepo/submodule-map.txt; echo ""tools/lldb lldb"" >> my-monorepo/submodule-map.txt; echo ""projects/openmp openmp"" >> my-monorepo/submodule-map.txt; echo ""tools/polly polly"" >> my-monorepo/submodule-map.txt; echo ""projects/myproj local/myproj"" >> my-monorepo/submodule-map.txt. # Rewrite history; (; cd my-monorepo; zip-downstream-fork.py \; refs/remotes/umbrella \; --new-repo-prefix=refs/remotes/upstream/monorepo \; --old-repo-prefix=refs/remotes/upstream/split \; --revmap-in=monorepo-map.txt \; --revmap-out=zip-map.txt \; --subdir=llvm \; --submodule-map=submodule-map.txt \; --update-tags; ). # Create the zip branch (assuming umbrella main is wanted).; git -C my-monorepo branch --no-track local/zip/main refs/remotes/umbrella/main. Comments at the top of ``zip-downstream-fork.py`` describe in more; detail how the tool works and various implications of its operation. Importing local repositories; -------------------------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:33469,Availability,echo,echo,33469,").; for project in ${subprojects[@]}; do; git remote add local/split/${project} \; https://my.local.mirror.org/${subproject}.git; git fetch local/split/${project}; done. # Import umbrella history. We want this under a different refspec; # so zip-downstream-fork.py knows what it is.; git -C my-monorepo remote add umbrella \; https://my.local.mirror.org/llvm.git; git fetch umbrella. # Create the submodule map.; echo ""tools/clang clang"" > my-monorepo/submodule-map.txt; echo ""tools/clang/tools/extra clang-tools-extra"" >> my-monorepo/submodule-map.txt; echo ""projects/compiler-rt compiler-rt"" >> my-monorepo/submodule-map.txt; echo ""projects/debuginfo-tests debuginfo-tests"" >> my-monorepo/submodule-map.txt; echo ""projects/libclc libclc"" >> my-monorepo/submodule-map.txt; echo ""projects/libcxx libcxx"" >> my-monorepo/submodule-map.txt; echo ""projects/libcxxabi libcxxabi"" >> my-monorepo/submodule-map.txt; echo ""projects/libunwind libunwind"" >> my-monorepo/submodule-map.txt; echo ""tools/lld lld"" >> my-monorepo/submodule-map.txt; echo ""tools/lldb lldb"" >> my-monorepo/submodule-map.txt; echo ""projects/openmp openmp"" >> my-monorepo/submodule-map.txt; echo ""tools/polly polly"" >> my-monorepo/submodule-map.txt; echo ""projects/myproj local/myproj"" >> my-monorepo/submodule-map.txt. # Rewrite history; (; cd my-monorepo; zip-downstream-fork.py \; refs/remotes/umbrella \; --new-repo-prefix=refs/remotes/upstream/monorepo \; --old-repo-prefix=refs/remotes/upstream/split \; --revmap-in=monorepo-map.txt \; --revmap-out=zip-map.txt \; --subdir=llvm \; --submodule-map=submodule-map.txt \; --update-tags; ). # Create the zip branch (assuming umbrella main is wanted).; git -C my-monorepo branch --no-track local/zip/main refs/remotes/umbrella/main. Comments at the top of ``zip-downstream-fork.py`` describe in more; detail how the tool works and various implications of its operation. Importing local repositories; ----------------------------. You may have additional repositories that integrate with t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:33524,Availability,echo,echo,33524," local/split/${project} \; https://my.local.mirror.org/${subproject}.git; git fetch local/split/${project}; done. # Import umbrella history. We want this under a different refspec; # so zip-downstream-fork.py knows what it is.; git -C my-monorepo remote add umbrella \; https://my.local.mirror.org/llvm.git; git fetch umbrella. # Create the submodule map.; echo ""tools/clang clang"" > my-monorepo/submodule-map.txt; echo ""tools/clang/tools/extra clang-tools-extra"" >> my-monorepo/submodule-map.txt; echo ""projects/compiler-rt compiler-rt"" >> my-monorepo/submodule-map.txt; echo ""projects/debuginfo-tests debuginfo-tests"" >> my-monorepo/submodule-map.txt; echo ""projects/libclc libclc"" >> my-monorepo/submodule-map.txt; echo ""projects/libcxx libcxx"" >> my-monorepo/submodule-map.txt; echo ""projects/libcxxabi libcxxabi"" >> my-monorepo/submodule-map.txt; echo ""projects/libunwind libunwind"" >> my-monorepo/submodule-map.txt; echo ""tools/lld lld"" >> my-monorepo/submodule-map.txt; echo ""tools/lldb lldb"" >> my-monorepo/submodule-map.txt; echo ""projects/openmp openmp"" >> my-monorepo/submodule-map.txt; echo ""tools/polly polly"" >> my-monorepo/submodule-map.txt; echo ""projects/myproj local/myproj"" >> my-monorepo/submodule-map.txt. # Rewrite history; (; cd my-monorepo; zip-downstream-fork.py \; refs/remotes/umbrella \; --new-repo-prefix=refs/remotes/upstream/monorepo \; --old-repo-prefix=refs/remotes/upstream/split \; --revmap-in=monorepo-map.txt \; --revmap-out=zip-map.txt \; --subdir=llvm \; --submodule-map=submodule-map.txt \; --update-tags; ). # Create the zip branch (assuming umbrella main is wanted).; git -C my-monorepo branch --no-track local/zip/main refs/remotes/umbrella/main. Comments at the top of ``zip-downstream-fork.py`` describe in more; detail how the tool works and various implications of its operation. Importing local repositories; ----------------------------. You may have additional repositories that integrate with the LLVM; ecosystem, essentially extending it with new to",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:33581,Availability,echo,echo,33581,"roject}.git; git fetch local/split/${project}; done. # Import umbrella history. We want this under a different refspec; # so zip-downstream-fork.py knows what it is.; git -C my-monorepo remote add umbrella \; https://my.local.mirror.org/llvm.git; git fetch umbrella. # Create the submodule map.; echo ""tools/clang clang"" > my-monorepo/submodule-map.txt; echo ""tools/clang/tools/extra clang-tools-extra"" >> my-monorepo/submodule-map.txt; echo ""projects/compiler-rt compiler-rt"" >> my-monorepo/submodule-map.txt; echo ""projects/debuginfo-tests debuginfo-tests"" >> my-monorepo/submodule-map.txt; echo ""projects/libclc libclc"" >> my-monorepo/submodule-map.txt; echo ""projects/libcxx libcxx"" >> my-monorepo/submodule-map.txt; echo ""projects/libcxxabi libcxxabi"" >> my-monorepo/submodule-map.txt; echo ""projects/libunwind libunwind"" >> my-monorepo/submodule-map.txt; echo ""tools/lld lld"" >> my-monorepo/submodule-map.txt; echo ""tools/lldb lldb"" >> my-monorepo/submodule-map.txt; echo ""projects/openmp openmp"" >> my-monorepo/submodule-map.txt; echo ""tools/polly polly"" >> my-monorepo/submodule-map.txt; echo ""projects/myproj local/myproj"" >> my-monorepo/submodule-map.txt. # Rewrite history; (; cd my-monorepo; zip-downstream-fork.py \; refs/remotes/umbrella \; --new-repo-prefix=refs/remotes/upstream/monorepo \; --old-repo-prefix=refs/remotes/upstream/split \; --revmap-in=monorepo-map.txt \; --revmap-out=zip-map.txt \; --subdir=llvm \; --submodule-map=submodule-map.txt \; --update-tags; ). # Create the zip branch (assuming umbrella main is wanted).; git -C my-monorepo branch --no-track local/zip/main refs/remotes/umbrella/main. Comments at the top of ``zip-downstream-fork.py`` describe in more; detail how the tool works and various implications of its operation. Importing local repositories; ----------------------------. You may have additional repositories that integrate with the LLVM; ecosystem, essentially extending it with new tools. If such; repositories are tightly coupled with LLVM, it",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:33645,Availability,echo,echo,33645," umbrella history. We want this under a different refspec; # so zip-downstream-fork.py knows what it is.; git -C my-monorepo remote add umbrella \; https://my.local.mirror.org/llvm.git; git fetch umbrella. # Create the submodule map.; echo ""tools/clang clang"" > my-monorepo/submodule-map.txt; echo ""tools/clang/tools/extra clang-tools-extra"" >> my-monorepo/submodule-map.txt; echo ""projects/compiler-rt compiler-rt"" >> my-monorepo/submodule-map.txt; echo ""projects/debuginfo-tests debuginfo-tests"" >> my-monorepo/submodule-map.txt; echo ""projects/libclc libclc"" >> my-monorepo/submodule-map.txt; echo ""projects/libcxx libcxx"" >> my-monorepo/submodule-map.txt; echo ""projects/libcxxabi libcxxabi"" >> my-monorepo/submodule-map.txt; echo ""projects/libunwind libunwind"" >> my-monorepo/submodule-map.txt; echo ""tools/lld lld"" >> my-monorepo/submodule-map.txt; echo ""tools/lldb lldb"" >> my-monorepo/submodule-map.txt; echo ""projects/openmp openmp"" >> my-monorepo/submodule-map.txt; echo ""tools/polly polly"" >> my-monorepo/submodule-map.txt; echo ""projects/myproj local/myproj"" >> my-monorepo/submodule-map.txt. # Rewrite history; (; cd my-monorepo; zip-downstream-fork.py \; refs/remotes/umbrella \; --new-repo-prefix=refs/remotes/upstream/monorepo \; --old-repo-prefix=refs/remotes/upstream/split \; --revmap-in=monorepo-map.txt \; --revmap-out=zip-map.txt \; --subdir=llvm \; --submodule-map=submodule-map.txt \; --update-tags; ). # Create the zip branch (assuming umbrella main is wanted).; git -C my-monorepo branch --no-track local/zip/main refs/remotes/umbrella/main. Comments at the top of ``zip-downstream-fork.py`` describe in more; detail how the tool works and various implications of its operation. Importing local repositories; ----------------------------. You may have additional repositories that integrate with the LLVM; ecosystem, essentially extending it with new tools. If such; repositories are tightly coupled with LLVM, it may make sense to; import them into your local mirror of the ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:33704,Availability,echo,echo,33704,"ip-downstream-fork.py knows what it is.; git -C my-monorepo remote add umbrella \; https://my.local.mirror.org/llvm.git; git fetch umbrella. # Create the submodule map.; echo ""tools/clang clang"" > my-monorepo/submodule-map.txt; echo ""tools/clang/tools/extra clang-tools-extra"" >> my-monorepo/submodule-map.txt; echo ""projects/compiler-rt compiler-rt"" >> my-monorepo/submodule-map.txt; echo ""projects/debuginfo-tests debuginfo-tests"" >> my-monorepo/submodule-map.txt; echo ""projects/libclc libclc"" >> my-monorepo/submodule-map.txt; echo ""projects/libcxx libcxx"" >> my-monorepo/submodule-map.txt; echo ""projects/libcxxabi libcxxabi"" >> my-monorepo/submodule-map.txt; echo ""projects/libunwind libunwind"" >> my-monorepo/submodule-map.txt; echo ""tools/lld lld"" >> my-monorepo/submodule-map.txt; echo ""tools/lldb lldb"" >> my-monorepo/submodule-map.txt; echo ""projects/openmp openmp"" >> my-monorepo/submodule-map.txt; echo ""tools/polly polly"" >> my-monorepo/submodule-map.txt; echo ""projects/myproj local/myproj"" >> my-monorepo/submodule-map.txt. # Rewrite history; (; cd my-monorepo; zip-downstream-fork.py \; refs/remotes/umbrella \; --new-repo-prefix=refs/remotes/upstream/monorepo \; --old-repo-prefix=refs/remotes/upstream/split \; --revmap-in=monorepo-map.txt \; --revmap-out=zip-map.txt \; --subdir=llvm \; --submodule-map=submodule-map.txt \; --update-tags; ). # Create the zip branch (assuming umbrella main is wanted).; git -C my-monorepo branch --no-track local/zip/main refs/remotes/umbrella/main. Comments at the top of ``zip-downstream-fork.py`` describe in more; detail how the tool works and various implications of its operation. Importing local repositories; ----------------------------. You may have additional repositories that integrate with the LLVM; ecosystem, essentially extending it with new tools. If such; repositories are tightly coupled with LLVM, it may make sense to; import them into your local mirror of the monorepo. If such repositories participated in the umbrella repo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:33816,Availability,down,downstream-fork,33816,"dd umbrella \; https://my.local.mirror.org/llvm.git; git fetch umbrella. # Create the submodule map.; echo ""tools/clang clang"" > my-monorepo/submodule-map.txt; echo ""tools/clang/tools/extra clang-tools-extra"" >> my-monorepo/submodule-map.txt; echo ""projects/compiler-rt compiler-rt"" >> my-monorepo/submodule-map.txt; echo ""projects/debuginfo-tests debuginfo-tests"" >> my-monorepo/submodule-map.txt; echo ""projects/libclc libclc"" >> my-monorepo/submodule-map.txt; echo ""projects/libcxx libcxx"" >> my-monorepo/submodule-map.txt; echo ""projects/libcxxabi libcxxabi"" >> my-monorepo/submodule-map.txt; echo ""projects/libunwind libunwind"" >> my-monorepo/submodule-map.txt; echo ""tools/lld lld"" >> my-monorepo/submodule-map.txt; echo ""tools/lldb lldb"" >> my-monorepo/submodule-map.txt; echo ""projects/openmp openmp"" >> my-monorepo/submodule-map.txt; echo ""tools/polly polly"" >> my-monorepo/submodule-map.txt; echo ""projects/myproj local/myproj"" >> my-monorepo/submodule-map.txt. # Rewrite history; (; cd my-monorepo; zip-downstream-fork.py \; refs/remotes/umbrella \; --new-repo-prefix=refs/remotes/upstream/monorepo \; --old-repo-prefix=refs/remotes/upstream/split \; --revmap-in=monorepo-map.txt \; --revmap-out=zip-map.txt \; --subdir=llvm \; --submodule-map=submodule-map.txt \; --update-tags; ). # Create the zip branch (assuming umbrella main is wanted).; git -C my-monorepo branch --no-track local/zip/main refs/remotes/umbrella/main. Comments at the top of ``zip-downstream-fork.py`` describe in more; detail how the tool works and various implications of its operation. Importing local repositories; ----------------------------. You may have additional repositories that integrate with the LLVM; ecosystem, essentially extending it with new tools. If such; repositories are tightly coupled with LLVM, it may make sense to; import them into your local mirror of the monorepo. If such repositories participated in the umbrella repository used; during the zipping process above, they will automaticall",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:34266,Availability,down,downstream-fork,34266,".txt; echo ""projects/libcxx libcxx"" >> my-monorepo/submodule-map.txt; echo ""projects/libcxxabi libcxxabi"" >> my-monorepo/submodule-map.txt; echo ""projects/libunwind libunwind"" >> my-monorepo/submodule-map.txt; echo ""tools/lld lld"" >> my-monorepo/submodule-map.txt; echo ""tools/lldb lldb"" >> my-monorepo/submodule-map.txt; echo ""projects/openmp openmp"" >> my-monorepo/submodule-map.txt; echo ""tools/polly polly"" >> my-monorepo/submodule-map.txt; echo ""projects/myproj local/myproj"" >> my-monorepo/submodule-map.txt. # Rewrite history; (; cd my-monorepo; zip-downstream-fork.py \; refs/remotes/umbrella \; --new-repo-prefix=refs/remotes/upstream/monorepo \; --old-repo-prefix=refs/remotes/upstream/split \; --revmap-in=monorepo-map.txt \; --revmap-out=zip-map.txt \; --subdir=llvm \; --submodule-map=submodule-map.txt \; --update-tags; ). # Create the zip branch (assuming umbrella main is wanted).; git -C my-monorepo branch --no-track local/zip/main refs/remotes/umbrella/main. Comments at the top of ``zip-downstream-fork.py`` describe in more; detail how the tool works and various implications of its operation. Importing local repositories; ----------------------------. You may have additional repositories that integrate with the LLVM; ecosystem, essentially extending it with new tools. If such; repositories are tightly coupled with LLVM, it may make sense to; import them into your local mirror of the monorepo. If such repositories participated in the umbrella repository used; during the zipping process above, they will automatically be added to; the monorepo. For downstream repositories that don't participate in; an umbrella setup, the ``import-downstream-repo.py`` tool at; https://github.com/greened/llvm-git-migration/tree/import can help with; getting them into the monorepo. A recipe follows::. # Import downstream repo history into the monorepo.; git -C my-monorepo remote add myrepo https://my.local.mirror.org/myrepo.git; git fetch myrepo. my_local_tags=( refs/tags/release; re",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:34836,Availability,down,downstream,34836,"fs/remotes/upstream/monorepo \; --old-repo-prefix=refs/remotes/upstream/split \; --revmap-in=monorepo-map.txt \; --revmap-out=zip-map.txt \; --subdir=llvm \; --submodule-map=submodule-map.txt \; --update-tags; ). # Create the zip branch (assuming umbrella main is wanted).; git -C my-monorepo branch --no-track local/zip/main refs/remotes/umbrella/main. Comments at the top of ``zip-downstream-fork.py`` describe in more; detail how the tool works and various implications of its operation. Importing local repositories; ----------------------------. You may have additional repositories that integrate with the LLVM; ecosystem, essentially extending it with new tools. If such; repositories are tightly coupled with LLVM, it may make sense to; import them into your local mirror of the monorepo. If such repositories participated in the umbrella repository used; during the zipping process above, they will automatically be added to; the monorepo. For downstream repositories that don't participate in; an umbrella setup, the ``import-downstream-repo.py`` tool at; https://github.com/greened/llvm-git-migration/tree/import can help with; getting them into the monorepo. A recipe follows::. # Import downstream repo history into the monorepo.; git -C my-monorepo remote add myrepo https://my.local.mirror.org/myrepo.git; git fetch myrepo. my_local_tags=( refs/tags/release; refs/tags/hotfix ). (; cd my-monorepo; import-downstream-repo.py \; refs/remotes/myrepo \; ${my_local_tags[@]} \; --new-repo-prefix=refs/remotes/upstream/monorepo \; --subdir=myrepo \; --tag-prefix=""myrepo-""; ). # Preserve release branches.; for ref in $(git -C my-monorepo for-each-ref --format=""%(refname)"" \; refs/remotes/myrepo/release); do; branch=${ref#refs/remotes/myrepo/}; git -C my-monorepo branch --no-track myrepo/${branch} ${ref}; done. # Preserve main.; git -C my-monorepo branch --no-track myrepo/main refs/remotes/myrepo/main. # Merge main.; git -C my-monorepo checkout local/zip/main # Or local/octopus/main; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:34919,Availability,down,downstream-repo,34919,"fs/remotes/upstream/monorepo \; --old-repo-prefix=refs/remotes/upstream/split \; --revmap-in=monorepo-map.txt \; --revmap-out=zip-map.txt \; --subdir=llvm \; --submodule-map=submodule-map.txt \; --update-tags; ). # Create the zip branch (assuming umbrella main is wanted).; git -C my-monorepo branch --no-track local/zip/main refs/remotes/umbrella/main. Comments at the top of ``zip-downstream-fork.py`` describe in more; detail how the tool works and various implications of its operation. Importing local repositories; ----------------------------. You may have additional repositories that integrate with the LLVM; ecosystem, essentially extending it with new tools. If such; repositories are tightly coupled with LLVM, it may make sense to; import them into your local mirror of the monorepo. If such repositories participated in the umbrella repository used; during the zipping process above, they will automatically be added to; the monorepo. For downstream repositories that don't participate in; an umbrella setup, the ``import-downstream-repo.py`` tool at; https://github.com/greened/llvm-git-migration/tree/import can help with; getting them into the monorepo. A recipe follows::. # Import downstream repo history into the monorepo.; git -C my-monorepo remote add myrepo https://my.local.mirror.org/myrepo.git; git fetch myrepo. my_local_tags=( refs/tags/release; refs/tags/hotfix ). (; cd my-monorepo; import-downstream-repo.py \; refs/remotes/myrepo \; ${my_local_tags[@]} \; --new-repo-prefix=refs/remotes/upstream/monorepo \; --subdir=myrepo \; --tag-prefix=""myrepo-""; ). # Preserve release branches.; for ref in $(git -C my-monorepo for-each-ref --format=""%(refname)"" \; refs/remotes/myrepo/release); do; branch=${ref#refs/remotes/myrepo/}; git -C my-monorepo branch --no-track myrepo/${branch} ${ref}; done. # Preserve main.; git -C my-monorepo branch --no-track myrepo/main refs/remotes/myrepo/main. # Merge main.; git -C my-monorepo checkout local/zip/main # Or local/octopus/main; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:35083,Availability,down,downstream,35083,"reate the zip branch (assuming umbrella main is wanted).; git -C my-monorepo branch --no-track local/zip/main refs/remotes/umbrella/main. Comments at the top of ``zip-downstream-fork.py`` describe in more; detail how the tool works and various implications of its operation. Importing local repositories; ----------------------------. You may have additional repositories that integrate with the LLVM; ecosystem, essentially extending it with new tools. If such; repositories are tightly coupled with LLVM, it may make sense to; import them into your local mirror of the monorepo. If such repositories participated in the umbrella repository used; during the zipping process above, they will automatically be added to; the monorepo. For downstream repositories that don't participate in; an umbrella setup, the ``import-downstream-repo.py`` tool at; https://github.com/greened/llvm-git-migration/tree/import can help with; getting them into the monorepo. A recipe follows::. # Import downstream repo history into the monorepo.; git -C my-monorepo remote add myrepo https://my.local.mirror.org/myrepo.git; git fetch myrepo. my_local_tags=( refs/tags/release; refs/tags/hotfix ). (; cd my-monorepo; import-downstream-repo.py \; refs/remotes/myrepo \; ${my_local_tags[@]} \; --new-repo-prefix=refs/remotes/upstream/monorepo \; --subdir=myrepo \; --tag-prefix=""myrepo-""; ). # Preserve release branches.; for ref in $(git -C my-monorepo for-each-ref --format=""%(refname)"" \; refs/remotes/myrepo/release); do; branch=${ref#refs/remotes/myrepo/}; git -C my-monorepo branch --no-track myrepo/${branch} ${ref}; done. # Preserve main.; git -C my-monorepo branch --no-track myrepo/main refs/remotes/myrepo/main. # Merge main.; git -C my-monorepo checkout local/zip/main # Or local/octopus/main; git -C my-monorepo merge myrepo/main. You may want to merge other corresponding branches, for example; ``myrepo`` release branches if they were in lockstep with LLVM project; releases. ``--tag-prefix`` tells ``import",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:35303,Availability,down,downstream-repo,35303,"n more; detail how the tool works and various implications of its operation. Importing local repositories; ----------------------------. You may have additional repositories that integrate with the LLVM; ecosystem, essentially extending it with new tools. If such; repositories are tightly coupled with LLVM, it may make sense to; import them into your local mirror of the monorepo. If such repositories participated in the umbrella repository used; during the zipping process above, they will automatically be added to; the monorepo. For downstream repositories that don't participate in; an umbrella setup, the ``import-downstream-repo.py`` tool at; https://github.com/greened/llvm-git-migration/tree/import can help with; getting them into the monorepo. A recipe follows::. # Import downstream repo history into the monorepo.; git -C my-monorepo remote add myrepo https://my.local.mirror.org/myrepo.git; git fetch myrepo. my_local_tags=( refs/tags/release; refs/tags/hotfix ). (; cd my-monorepo; import-downstream-repo.py \; refs/remotes/myrepo \; ${my_local_tags[@]} \; --new-repo-prefix=refs/remotes/upstream/monorepo \; --subdir=myrepo \; --tag-prefix=""myrepo-""; ). # Preserve release branches.; for ref in $(git -C my-monorepo for-each-ref --format=""%(refname)"" \; refs/remotes/myrepo/release); do; branch=${ref#refs/remotes/myrepo/}; git -C my-monorepo branch --no-track myrepo/${branch} ${ref}; done. # Preserve main.; git -C my-monorepo branch --no-track myrepo/main refs/remotes/myrepo/main. # Merge main.; git -C my-monorepo checkout local/zip/main # Or local/octopus/main; git -C my-monorepo merge myrepo/main. You may want to merge other corresponding branches, for example; ``myrepo`` release branches if they were in lockstep with LLVM project; releases. ``--tag-prefix`` tells ``import-downstream-repo.py`` to rename; annotated tags with the given prefix. Due to limitations with; ``fast_filter_branch.py``, unannotated tags cannot be renamed; (``fast_filter_branch.py`` considers the",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:36100,Availability,down,downstream-repo,36100,"am repo history into the monorepo.; git -C my-monorepo remote add myrepo https://my.local.mirror.org/myrepo.git; git fetch myrepo. my_local_tags=( refs/tags/release; refs/tags/hotfix ). (; cd my-monorepo; import-downstream-repo.py \; refs/remotes/myrepo \; ${my_local_tags[@]} \; --new-repo-prefix=refs/remotes/upstream/monorepo \; --subdir=myrepo \; --tag-prefix=""myrepo-""; ). # Preserve release branches.; for ref in $(git -C my-monorepo for-each-ref --format=""%(refname)"" \; refs/remotes/myrepo/release); do; branch=${ref#refs/remotes/myrepo/}; git -C my-monorepo branch --no-track myrepo/${branch} ${ref}; done. # Preserve main.; git -C my-monorepo branch --no-track myrepo/main refs/remotes/myrepo/main. # Merge main.; git -C my-monorepo checkout local/zip/main # Or local/octopus/main; git -C my-monorepo merge myrepo/main. You may want to merge other corresponding branches, for example; ``myrepo`` release branches if they were in lockstep with LLVM project; releases. ``--tag-prefix`` tells ``import-downstream-repo.py`` to rename; annotated tags with the given prefix. Due to limitations with; ``fast_filter_branch.py``, unannotated tags cannot be renamed; (``fast_filter_branch.py`` considers them branches, not tags). Since; the upstream monorepo had its tags rewritten with an ""llvmorg-""; prefix, name conflicts should not be an issue. ``--tag-prefix`` can; be used to more clearly indicate which tags correspond to various; imported repositories. Given this repository history::. R1 - R2 - R3 <- main; ^; |; release/1. The above recipe results in a history like this::. U1 - U2 - U3 <- upstream/main; \ \ \; \ -----\--------------- local/zip--.; \ \ \ |; - Lllvm1 - Llld1 - UM3 - Lclang1 - Lclang2 - Lllvm2 - Llld2 - Lmyproj1 - M1 <-'; /; R1 - R2 - R3 <-.; ^ |; | |; myrepo-release/1 |; |; myrepo/main--'. Commits ``R1``, ``R2`` and ``R3`` have trees that *only* contain blobs; from ``myrepo``. If you require commits from ``myrepo`` to be; interleaved with commits on local project bran",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:37508,Availability,down,downstream-fork,37508,"used to more clearly indicate which tags correspond to various; imported repositories. Given this repository history::. R1 - R2 - R3 <- main; ^; |; release/1. The above recipe results in a history like this::. U1 - U2 - U3 <- upstream/main; \ \ \; \ -----\--------------- local/zip--.; \ \ \ |; - Lllvm1 - Llld1 - UM3 - Lclang1 - Lclang2 - Lllvm2 - Llld2 - Lmyproj1 - M1 <-'; /; R1 - R2 - R3 <-.; ^ |; | |; myrepo-release/1 |; |; myrepo/main--'. Commits ``R1``, ``R2`` and ``R3`` have trees that *only* contain blobs; from ``myrepo``. If you require commits from ``myrepo`` to be; interleaved with commits on local project branches (for example,; interleaved with ``llvm1``, ``llvm2``, etc. above) and myrepo doesn't; appear in an umbrella repository, a new tool will need to be; developed. Creating such a tool would involve:. 1. Modifying ``fast_filter_branch.py`` to optionally take a; revlist directly rather than generating it itself. 2. Creating a tool to generate an interleaved ordering of local; commits based on some criteria (``zip-downstream-fork.py`` uses the; umbrella history as its criterion). 3. Generating such an ordering and feeding it to; ``fast_filter_branch.py`` as a revlist. Some care will also likely need to be taken to handle merge commits,; to ensure the parents of such commits migrate correctly. Scrubbing the Local Monorepo; ----------------------------. Once all of the migrating, zipping and importing is done, it's time to; clean up. The python tools use ``git-fast-import`` which leaves a lot; of cruft around and we want to shrink our new monorepo mirror as much; as possible. Here is one way to do it::. git -C my-monorepo checkout main. # Delete branches we no longer need. Do this for any other branches; # you merged above.; git -C my-monorepo branch -D local/zip/main || true; git -C my-monorepo branch -D local/octopus/main || true. # Remove remotes.; git -C my-monorepo remote remove upstream/monorepo. for p in ${my_projects[@]}; do; git -C my-monorepo rem",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:301,Deployability,update,updates,301,"==============================; Moving LLVM Projects to GitHub; ==============================. Current Status; ==============. We are planning to complete the transition to GitHub by Oct 21, 2019. See; the GitHub migration `status page <https://llvm.org/GitHubMigrationStatus.html>`_; for the latest updates and instructions for how to migrate your workflows. .. contents:: Table of Contents; :depth: 4; :local:. Introduction; ============. This is a proposal to move our current revision control system from our own; hosted Subversion to GitHub. Below are the financial and technical arguments as; to why we are proposing such a move and how people (and validation; infrastructure) will continue to work with a Git-based LLVM. What This Proposal is *Not* About; =================================. Changing the development policy. This proposal relates only to moving the hosting of our source-code repository; from SVN hosted on our own servers to Git hosted on GitHub. We are not proposing; using GitHub's issue tracker, pull-requests, or code-review. Contributors will continue to earn commit access on demand under the Developer; Policy, except that that a GitHub account will be required instead of SVN; username/password-hash. Why Git, and Why GitHub?; ========================. Why Move At All?; ----------------. This discussion began because we currently host our own Subversion server; and Git mirror on a voluntary basis. The LLVM Foundation sponsors the server and; provides limited support, but there is only so much it can do. Volunteers are not sysadmins themselves, but compiler engineers that happen; to know a thing or two about hosting servers. We also don't have 24/7 support,; and we sometimes wake up to see that continuous integration is broken because; the SVN server is either down or unresponsive. We should take advantage of one of the services out there (GitHub, GitLab,; and BitBucket, among others) that offer better service (24/7 stability, disk; space, Git server, cod",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:1736,Deployability,continuous,continuous,1736,"sal is *Not* About; =================================. Changing the development policy. This proposal relates only to moving the hosting of our source-code repository; from SVN hosted on our own servers to Git hosted on GitHub. We are not proposing; using GitHub's issue tracker, pull-requests, or code-review. Contributors will continue to earn commit access on demand under the Developer; Policy, except that that a GitHub account will be required instead of SVN; username/password-hash. Why Git, and Why GitHub?; ========================. Why Move At All?; ----------------. This discussion began because we currently host our own Subversion server; and Git mirror on a voluntary basis. The LLVM Foundation sponsors the server and; provides limited support, but there is only so much it can do. Volunteers are not sysadmins themselves, but compiler engineers that happen; to know a thing or two about hosting servers. We also don't have 24/7 support,; and we sometimes wake up to see that continuous integration is broken because; the SVN server is either down or unresponsive. We should take advantage of one of the services out there (GitHub, GitLab,; and BitBucket, among others) that offer better service (24/7 stability, disk; space, Git server, code browsing, forking facilities, etc) for free. Why Git?; --------. Many new coders nowadays start with Git, and a lot of people have never used; SVN, CVS, or anything else. Websites like GitHub have changed the landscape; of open source contributions, reducing the cost of first contribution and; fostering collaboration. Git is also the version control many LLVM developers use. Despite the; sources being stored in a SVN server, these developers are already using Git; through the Git-SVN integration. Git allows you to:. * Commit, squash, merge, and fork locally without touching the remote server.; * Maintain local branches, enabling multiple threads of development.; * Collaborate on these branches (e.g. through your own fork of llvm on",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:1747,Deployability,integrat,integration,1747,"sal is *Not* About; =================================. Changing the development policy. This proposal relates only to moving the hosting of our source-code repository; from SVN hosted on our own servers to Git hosted on GitHub. We are not proposing; using GitHub's issue tracker, pull-requests, or code-review. Contributors will continue to earn commit access on demand under the Developer; Policy, except that that a GitHub account will be required instead of SVN; username/password-hash. Why Git, and Why GitHub?; ========================. Why Move At All?; ----------------. This discussion began because we currently host our own Subversion server; and Git mirror on a voluntary basis. The LLVM Foundation sponsors the server and; provides limited support, but there is only so much it can do. Volunteers are not sysadmins themselves, but compiler engineers that happen; to know a thing or two about hosting servers. We also don't have 24/7 support,; and we sometimes wake up to see that continuous integration is broken because; the SVN server is either down or unresponsive. We should take advantage of one of the services out there (GitHub, GitLab,; and BitBucket, among others) that offer better service (24/7 stability, disk; space, Git server, code browsing, forking facilities, etc) for free. Why Git?; --------. Many new coders nowadays start with Git, and a lot of people have never used; SVN, CVS, or anything else. Websites like GitHub have changed the landscape; of open source contributions, reducing the cost of first contribution and; fostering collaboration. Git is also the version control many LLVM developers use. Despite the; sources being stored in a SVN server, these developers are already using Git; through the Git-SVN integration. Git allows you to:. * Commit, squash, merge, and fork locally without touching the remote server.; * Maintain local branches, enabling multiple threads of development.; * Collaborate on these branches (e.g. through your own fork of llvm on",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:2492,Deployability,integrat,integration,2492," Foundation sponsors the server and; provides limited support, but there is only so much it can do. Volunteers are not sysadmins themselves, but compiler engineers that happen; to know a thing or two about hosting servers. We also don't have 24/7 support,; and we sometimes wake up to see that continuous integration is broken because; the SVN server is either down or unresponsive. We should take advantage of one of the services out there (GitHub, GitLab,; and BitBucket, among others) that offer better service (24/7 stability, disk; space, Git server, code browsing, forking facilities, etc) for free. Why Git?; --------. Many new coders nowadays start with Git, and a lot of people have never used; SVN, CVS, or anything else. Websites like GitHub have changed the landscape; of open source contributions, reducing the cost of first contribution and; fostering collaboration. Git is also the version control many LLVM developers use. Despite the; sources being stored in a SVN server, these developers are already using Git; through the Git-SVN integration. Git allows you to:. * Commit, squash, merge, and fork locally without touching the remote server.; * Maintain local branches, enabling multiple threads of development.; * Collaborate on these branches (e.g. through your own fork of llvm on GitHub).; * Inspect the repository history (blame, log, bisect) without Internet access.; * Maintain remote forks and branches on Git hosting services and; integrate back to the main repository. In addition, because Git seems to be replacing many OSS projects' version; control systems, there are many tools that are built over Git.; Future tooling may support Git first (if not only). Why GitHub?; -----------. GitHub, like GitLab and BitBucket, provides free code hosting for open source; projects. Any of these could replace the code-hosting infrastructure that we; have today. These services also have a dedicated team to monitor, migrate, improve and; distribute the contents of the repositor",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:2901,Deployability,integrat,integrate,2901,"tHub, GitLab,; and BitBucket, among others) that offer better service (24/7 stability, disk; space, Git server, code browsing, forking facilities, etc) for free. Why Git?; --------. Many new coders nowadays start with Git, and a lot of people have never used; SVN, CVS, or anything else. Websites like GitHub have changed the landscape; of open source contributions, reducing the cost of first contribution and; fostering collaboration. Git is also the version control many LLVM developers use. Despite the; sources being stored in a SVN server, these developers are already using Git; through the Git-SVN integration. Git allows you to:. * Commit, squash, merge, and fork locally without touching the remote server.; * Maintain local branches, enabling multiple threads of development.; * Collaborate on these branches (e.g. through your own fork of llvm on GitHub).; * Inspect the repository history (blame, log, bisect) without Internet access.; * Maintain remote forks and branches on Git hosting services and; integrate back to the main repository. In addition, because Git seems to be replacing many OSS projects' version; control systems, there are many tools that are built over Git.; Future tooling may support Git first (if not only). Why GitHub?; -----------. GitHub, like GitLab and BitBucket, provides free code hosting for open source; projects. Any of these could replace the code-hosting infrastructure that we; have today. These services also have a dedicated team to monitor, migrate, improve and; distribute the contents of the repositories depending on region and load. GitHub has one important advantage over GitLab and; BitBucket: it offers read-write **SVN** access to the repository; (https://github.com/blog/626-announcing-svn-support).; This would enable people to continue working post-migration as though our code; were still canonically in an SVN repository. In addition, there are already multiple LLVM mirrors on GitHub, indicating that; part of our community has alrea",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:6312,Deployability,update,update,6312,"sure that e.g. `clang -v` reports a; user-friendly revision number (e.g. `main-12345` or `4.0-5321`), addressing; the objections raised above with respect to this aspect of Git. What About Branches and Merges?; -------------------------------. In contrast to SVN, Git makes branching easy. Git's commit history is; represented as a DAG, a departure from SVN's linear history. However, we propose; to mandate making merge commits illegal in our canonical Git repository. Unfortunately, GitHub does not support server side hooks to enforce such a; policy. We must rely on the community to avoid pushing merge commits. GitHub offers a feature called `Status Checks`: a branch protected by; `status checks` requires commits to be explicitly allowed before the push can happen.; We could supply a pre-push hook on the client side that would run and check the; history, before allowing the commit being pushed [statuschecks]_.; However this solution would be somewhat fragile (how do you update a script; installed on every developer machine?) and prevents SVN access to the; repository. What About Commit Emails?; -------------------------. We will need a new bot to send emails for each commit. This proposal leaves the; email format unchanged besides the commit URL. Straw Man Migration Plan; ========================. Step #1 : Before The Move; -------------------------. 1. Update docs to mention the move, so people are aware of what is going on.; 2. Set up a read-only version of the GitHub project, mirroring our current SVN; repository.; 3. Add the required bots to implement the commit emails, as well as the; umbrella repository update (if the multirepo is selected) or the read-only; Git views for the sub-projects (if the monorepo is selected). Step #2 : Git Move; ------------------. 4. Update the buildbots to pick up updates and commits from the GitHub; repository. Not all bots have to migrate at this point, but it'll help; provide infrastructure testing.; 5. Update Phabricator to pick up",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:6329,Deployability,install,installed,6329,"sure that e.g. `clang -v` reports a; user-friendly revision number (e.g. `main-12345` or `4.0-5321`), addressing; the objections raised above with respect to this aspect of Git. What About Branches and Merges?; -------------------------------. In contrast to SVN, Git makes branching easy. Git's commit history is; represented as a DAG, a departure from SVN's linear history. However, we propose; to mandate making merge commits illegal in our canonical Git repository. Unfortunately, GitHub does not support server side hooks to enforce such a; policy. We must rely on the community to avoid pushing merge commits. GitHub offers a feature called `Status Checks`: a branch protected by; `status checks` requires commits to be explicitly allowed before the push can happen.; We could supply a pre-push hook on the client side that would run and check the; history, before allowing the commit being pushed [statuschecks]_.; However this solution would be somewhat fragile (how do you update a script; installed on every developer machine?) and prevents SVN access to the; repository. What About Commit Emails?; -------------------------. We will need a new bot to send emails for each commit. This proposal leaves the; email format unchanged besides the commit URL. Straw Man Migration Plan; ========================. Step #1 : Before The Move; -------------------------. 1. Update docs to mention the move, so people are aware of what is going on.; 2. Set up a read-only version of the GitHub project, mirroring our current SVN; repository.; 3. Add the required bots to implement the commit emails, as well as the; umbrella repository update (if the multirepo is selected) or the read-only; Git views for the sub-projects (if the monorepo is selected). Step #2 : Git Move; ------------------. 4. Update the buildbots to pick up updates and commits from the GitHub; repository. Not all bots have to migrate at this point, but it'll help; provide infrastructure testing.; 5. Update Phabricator to pick up",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:6964,Deployability,update,update,6964,"`Status Checks`: a branch protected by; `status checks` requires commits to be explicitly allowed before the push can happen.; We could supply a pre-push hook on the client side that would run and check the; history, before allowing the commit being pushed [statuschecks]_.; However this solution would be somewhat fragile (how do you update a script; installed on every developer machine?) and prevents SVN access to the; repository. What About Commit Emails?; -------------------------. We will need a new bot to send emails for each commit. This proposal leaves the; email format unchanged besides the commit URL. Straw Man Migration Plan; ========================. Step #1 : Before The Move; -------------------------. 1. Update docs to mention the move, so people are aware of what is going on.; 2. Set up a read-only version of the GitHub project, mirroring our current SVN; repository.; 3. Add the required bots to implement the commit emails, as well as the; umbrella repository update (if the multirepo is selected) or the read-only; Git views for the sub-projects (if the monorepo is selected). Step #2 : Git Move; ------------------. 4. Update the buildbots to pick up updates and commits from the GitHub; repository. Not all bots have to migrate at this point, but it'll help; provide infrastructure testing.; 5. Update Phabricator to pick up commits from the GitHub repository.; 6. LNT and llvmlab have to be updated: they rely on unique monotonically; increasing integer across branch [MatthewsRevNum]_.; 7. Instruct downstream integrators to pick up commits from the GitHub; repository.; 8. Review and prepare an update for the LLVM documentation. Until this point nothing has changed for developers, it will just; boil down to a lot of work for buildbot and other infrastructure; owners. The migration will pause here until all dependencies have cleared, and all; problems have been solved. Step #3: Write Access Move; --------------------------. 9. Collect developers' GitHub account",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:7157,Deployability,update,updates,7157,"d run and check the; history, before allowing the commit being pushed [statuschecks]_.; However this solution would be somewhat fragile (how do you update a script; installed on every developer machine?) and prevents SVN access to the; repository. What About Commit Emails?; -------------------------. We will need a new bot to send emails for each commit. This proposal leaves the; email format unchanged besides the commit URL. Straw Man Migration Plan; ========================. Step #1 : Before The Move; -------------------------. 1. Update docs to mention the move, so people are aware of what is going on.; 2. Set up a read-only version of the GitHub project, mirroring our current SVN; repository.; 3. Add the required bots to implement the commit emails, as well as the; umbrella repository update (if the multirepo is selected) or the read-only; Git views for the sub-projects (if the monorepo is selected). Step #2 : Git Move; ------------------. 4. Update the buildbots to pick up updates and commits from the GitHub; repository. Not all bots have to migrate at this point, but it'll help; provide infrastructure testing.; 5. Update Phabricator to pick up commits from the GitHub repository.; 6. LNT and llvmlab have to be updated: they rely on unique monotonically; increasing integer across branch [MatthewsRevNum]_.; 7. Instruct downstream integrators to pick up commits from the GitHub; repository.; 8. Review and prepare an update for the LLVM documentation. Until this point nothing has changed for developers, it will just; boil down to a lot of work for buildbot and other infrastructure; owners. The migration will pause here until all dependencies have cleared, and all; problems have been solved. Step #3: Write Access Move; --------------------------. 9. Collect developers' GitHub account information, and add them to the project.; 10. Switch the SVN repository to read-only and allow pushes to the GitHub repository.; 11. Update the documentation.; 12. Mirror Git to SVN. Ste",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:7399,Deployability,update,updated,7399,"ails?; -------------------------. We will need a new bot to send emails for each commit. This proposal leaves the; email format unchanged besides the commit URL. Straw Man Migration Plan; ========================. Step #1 : Before The Move; -------------------------. 1. Update docs to mention the move, so people are aware of what is going on.; 2. Set up a read-only version of the GitHub project, mirroring our current SVN; repository.; 3. Add the required bots to implement the commit emails, as well as the; umbrella repository update (if the multirepo is selected) or the read-only; Git views for the sub-projects (if the monorepo is selected). Step #2 : Git Move; ------------------. 4. Update the buildbots to pick up updates and commits from the GitHub; repository. Not all bots have to migrate at this point, but it'll help; provide infrastructure testing.; 5. Update Phabricator to pick up commits from the GitHub repository.; 6. LNT and llvmlab have to be updated: they rely on unique monotonically; increasing integer across branch [MatthewsRevNum]_.; 7. Instruct downstream integrators to pick up commits from the GitHub; repository.; 8. Review and prepare an update for the LLVM documentation. Until this point nothing has changed for developers, it will just; boil down to a lot of work for buildbot and other infrastructure; owners. The migration will pause here until all dependencies have cleared, and all; problems have been solved. Step #3: Write Access Move; --------------------------. 9. Collect developers' GitHub account information, and add them to the project.; 10. Switch the SVN repository to read-only and allow pushes to the GitHub repository.; 11. Update the documentation.; 12. Mirror Git to SVN. Step #4 : Post Move; -------------------. 13. Archive the SVN repository.; 14. Update links on the LLVM website pointing to viewvc/klaus/phab etc. to; point to GitHub instead. GitHub Repository Description; =============================. Monorepo; ----------------. The L",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:7519,Deployability,integrat,integrators,7519,"ves the; email format unchanged besides the commit URL. Straw Man Migration Plan; ========================. Step #1 : Before The Move; -------------------------. 1. Update docs to mention the move, so people are aware of what is going on.; 2. Set up a read-only version of the GitHub project, mirroring our current SVN; repository.; 3. Add the required bots to implement the commit emails, as well as the; umbrella repository update (if the multirepo is selected) or the read-only; Git views for the sub-projects (if the monorepo is selected). Step #2 : Git Move; ------------------. 4. Update the buildbots to pick up updates and commits from the GitHub; repository. Not all bots have to migrate at this point, but it'll help; provide infrastructure testing.; 5. Update Phabricator to pick up commits from the GitHub repository.; 6. LNT and llvmlab have to be updated: they rely on unique monotonically; increasing integer across branch [MatthewsRevNum]_.; 7. Instruct downstream integrators to pick up commits from the GitHub; repository.; 8. Review and prepare an update for the LLVM documentation. Until this point nothing has changed for developers, it will just; boil down to a lot of work for buildbot and other infrastructure; owners. The migration will pause here until all dependencies have cleared, and all; problems have been solved. Step #3: Write Access Move; --------------------------. 9. Collect developers' GitHub account information, and add them to the project.; 10. Switch the SVN repository to read-only and allow pushes to the GitHub repository.; 11. Update the documentation.; 12. Mirror Git to SVN. Step #4 : Post Move; -------------------. 13. Archive the SVN repository.; 14. Update links on the LLVM website pointing to viewvc/klaus/phab etc. to; point to GitHub instead. GitHub Repository Description; =============================. Monorepo; ----------------. The LLVM git repository hosted at https://github.com/llvm/llvm-project contains all; sub-projects in a single ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:7605,Deployability,update,update,7605,"ion Plan; ========================. Step #1 : Before The Move; -------------------------. 1. Update docs to mention the move, so people are aware of what is going on.; 2. Set up a read-only version of the GitHub project, mirroring our current SVN; repository.; 3. Add the required bots to implement the commit emails, as well as the; umbrella repository update (if the multirepo is selected) or the read-only; Git views for the sub-projects (if the monorepo is selected). Step #2 : Git Move; ------------------. 4. Update the buildbots to pick up updates and commits from the GitHub; repository. Not all bots have to migrate at this point, but it'll help; provide infrastructure testing.; 5. Update Phabricator to pick up commits from the GitHub repository.; 6. LNT and llvmlab have to be updated: they rely on unique monotonically; increasing integer across branch [MatthewsRevNum]_.; 7. Instruct downstream integrators to pick up commits from the GitHub; repository.; 8. Review and prepare an update for the LLVM documentation. Until this point nothing has changed for developers, it will just; boil down to a lot of work for buildbot and other infrastructure; owners. The migration will pause here until all dependencies have cleared, and all; problems have been solved. Step #3: Write Access Move; --------------------------. 9. Collect developers' GitHub account information, and add them to the project.; 10. Switch the SVN repository to read-only and allow pushes to the GitHub repository.; 11. Update the documentation.; 12. Mirror Git to SVN. Step #4 : Post Move; -------------------. 13. Archive the SVN repository.; 14. Update links on the LLVM website pointing to viewvc/klaus/phab etc. to; point to GitHub instead. GitHub Repository Description; =============================. Monorepo; ----------------. The LLVM git repository hosted at https://github.com/llvm/llvm-project contains all; sub-projects in a single source tree. It is often referred to as a monorepo and; mimics an export ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:11651,Deployability,integrat,integrating,11651,"ps://git.llvm.org/git/compiler-rt.git) will continue to; be maintained. Read/write SVN bridge; ^^^^^^^^^^^^^^^^^^^^^. GitHub supports a read/write SVN bridge for its repositories. However,; there have been issues with this bridge working correctly in the past,; so it's not clear if this is something that will be supported going forward. Monorepo Drawbacks; ------------------. * Using the monolithic repository may add overhead for those contributing to a; standalone sub-project, particularly on runtimes like libcxx and compiler-rt; that don't rely on LLVM; currently, a fresh clone of libcxx is only 15MB (vs.; 1GB for the monorepo), and the commit rate of LLVM may cause more frequent; `git push` collisions when upstreaming. Affected contributors may be able to; use the SVN bridge or the single-subproject Git mirrors. However, it's; undecided if these projects will continue to be maintained.; * Using the monolithic repository may add overhead for those *integrating* a; standalone sub-project, even if they aren't contributing to it, due to the; same disk space concern as the point above. The availability of the; sub-project Git mirrors would addresses this.; * Preservation of the existing read/write SVN-based workflows relies on the; GitHub SVN bridge, which is an extra dependency. Maintaining this locks us; into GitHub and could restrict future workflow changes. Workflows; ^^^^^^^^^. * :ref:`Checkout/Clone a Single Project, without Commit Access <workflow-checkout-commit>`.; * :ref:`Checkout/Clone Multiple Projects, with Commit Access <workflow-monocheckout-multicommit>`.; * :ref:`Commit an API Change in LLVM and Update the Sub-projects <workflow-cross-repo-commit>`.; * :ref:`Branching/Stashing/Updating for Local Development or Experiments <workflow-mono-branching>`.; * :ref:`Bisecting <workflow-mono-bisecting>`. Workflow Before/After; =====================. This section goes through a few examples of workflows, intended to illustrate; how end-users or developers would ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:17219,Deployability,update,update,17219,"/libcxx.git; cd libcxx; git svn init https://llvm.org/svn/llvm-project/libcxx/trunk --username=<username>; git config svn-remote.svn.fetch :refs/remotes/origin/main; git svn rebase -l; git checkout `git svn find-rev -B r258109`. Note that the list would be longer with more sub-projects. .. _workflow-monocheckout-multicommit:. Monorepo Variant; ^^^^^^^^^^^^^^^^. The repository contains natively the source for every sub-projects at the right; revision, which makes this straightforward::. git clone https://github.com/llvm/llvm-project.git; cd llvm-projects; git checkout $REVISION. As before, at this point clang, llvm, and libcxx are stored in directories; alongside each other. .. _workflow-cross-repo-commit:. Commit an API Change in LLVM and Update the Sub-projects; --------------------------------------------------------. Today this is possible, even though not common (at least not documented) for; subversion users and for git-svn users. For example, few Git users try to update; LLD or Clang in the same commit as they change an LLVM API. The multirepo variant does not address this: one would have to commit and push; separately in every individual repository. It would be possible to establish a; protocol whereby users add a special token to their commit messages that causes; the umbrella repo's updater bot to group all of them into a single revision. The monorepo variant handles this natively. Branching/Stashing/Updating for Local Development or Experiments; ----------------------------------------------------------------. Currently; ^^^^^^^^^. SVN does not allow this use case, but developers that are currently using; git-svn can do it. Let's look in practice what it means when dealing with; multiple sub-projects. To update the repository to tip of trunk::. git pull; cd tools/clang; git pull; cd ../../projects/libcxx; git pull. To create a new branch::. git checkout -b MyBranch; cd tools/clang; git checkout -b MyBranch; cd ../../projects/libcxx; git checkout -b MyBranc",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:17548,Deployability,update,updater,17548,"re sub-projects. .. _workflow-monocheckout-multicommit:. Monorepo Variant; ^^^^^^^^^^^^^^^^. The repository contains natively the source for every sub-projects at the right; revision, which makes this straightforward::. git clone https://github.com/llvm/llvm-project.git; cd llvm-projects; git checkout $REVISION. As before, at this point clang, llvm, and libcxx are stored in directories; alongside each other. .. _workflow-cross-repo-commit:. Commit an API Change in LLVM and Update the Sub-projects; --------------------------------------------------------. Today this is possible, even though not common (at least not documented) for; subversion users and for git-svn users. For example, few Git users try to update; LLD or Clang in the same commit as they change an LLVM API. The multirepo variant does not address this: one would have to commit and push; separately in every individual repository. It would be possible to establish a; protocol whereby users add a special token to their commit messages that causes; the umbrella repo's updater bot to group all of them into a single revision. The monorepo variant handles this natively. Branching/Stashing/Updating for Local Development or Experiments; ----------------------------------------------------------------. Currently; ^^^^^^^^^. SVN does not allow this use case, but developers that are currently using; git-svn can do it. Let's look in practice what it means when dealing with; multiple sub-projects. To update the repository to tip of trunk::. git pull; cd tools/clang; git pull; cd ../../projects/libcxx; git pull. To create a new branch::. git checkout -b MyBranch; cd tools/clang; git checkout -b MyBranch; cd ../../projects/libcxx; git checkout -b MyBranch. To switch branches::. git checkout AnotherBranch; cd tools/clang; git checkout AnotherBranch; cd ../../projects/libcxx; git checkout AnotherBranch. .. _workflow-mono-branching:. Monorepo Variant; ^^^^^^^^^^^^^^^^. Regular Git commands are sufficient, because everything",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:17979,Deployability,update,update,17979,"b-projects; --------------------------------------------------------. Today this is possible, even though not common (at least not documented) for; subversion users and for git-svn users. For example, few Git users try to update; LLD or Clang in the same commit as they change an LLVM API. The multirepo variant does not address this: one would have to commit and push; separately in every individual repository. It would be possible to establish a; protocol whereby users add a special token to their commit messages that causes; the umbrella repo's updater bot to group all of them into a single revision. The monorepo variant handles this natively. Branching/Stashing/Updating for Local Development or Experiments; ----------------------------------------------------------------. Currently; ^^^^^^^^^. SVN does not allow this use case, but developers that are currently using; git-svn can do it. Let's look in practice what it means when dealing with; multiple sub-projects. To update the repository to tip of trunk::. git pull; cd tools/clang; git pull; cd ../../projects/libcxx; git pull. To create a new branch::. git checkout -b MyBranch; cd tools/clang; git checkout -b MyBranch; cd ../../projects/libcxx; git checkout -b MyBranch. To switch branches::. git checkout AnotherBranch; cd tools/clang; git checkout AnotherBranch; cd ../../projects/libcxx; git checkout AnotherBranch. .. _workflow-mono-branching:. Monorepo Variant; ^^^^^^^^^^^^^^^^. Regular Git commands are sufficient, because everything is in a single; repository:. To update the repository to tip of trunk::. git pull. To create a new branch::. git checkout -b MyBranch. To switch branches::. git checkout AnotherBranch. Bisecting; ---------. Assuming a developer is looking for a bug in clang (or lld, or lldb, ...). Currently; ^^^^^^^^^. SVN does not have builtin bisection support, but the single revision across; sub-projects makes it possible to script around. Using the existing Git read-only view of the repositories, ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:18540,Deployability,update,update,18540,"t to group all of them into a single revision. The monorepo variant handles this natively. Branching/Stashing/Updating for Local Development or Experiments; ----------------------------------------------------------------. Currently; ^^^^^^^^^. SVN does not allow this use case, but developers that are currently using; git-svn can do it. Let's look in practice what it means when dealing with; multiple sub-projects. To update the repository to tip of trunk::. git pull; cd tools/clang; git pull; cd ../../projects/libcxx; git pull. To create a new branch::. git checkout -b MyBranch; cd tools/clang; git checkout -b MyBranch; cd ../../projects/libcxx; git checkout -b MyBranch. To switch branches::. git checkout AnotherBranch; cd tools/clang; git checkout AnotherBranch; cd ../../projects/libcxx; git checkout AnotherBranch. .. _workflow-mono-branching:. Monorepo Variant; ^^^^^^^^^^^^^^^^. Regular Git commands are sufficient, because everything is in a single; repository:. To update the repository to tip of trunk::. git pull. To create a new branch::. git checkout -b MyBranch. To switch branches::. git checkout AnotherBranch. Bisecting; ---------. Assuming a developer is looking for a bug in clang (or lld, or lldb, ...). Currently; ^^^^^^^^^. SVN does not have builtin bisection support, but the single revision across; sub-projects makes it possible to script around. Using the existing Git read-only view of the repositories, it is possible to use; the native Git bisection script over the llvm repository, and use some scripting; to synchronize the clang repository to match the llvm revision. .. _workflow-mono-bisecting:. Monorepo Variant; ^^^^^^^^^^^^^^^^. Bisecting on the monorepo is straightforward, and very similar to the above,; except that the bisection script does not need to include the; `git submodule update` step. The same example, finding which commit introduces a regression where clang-3.9; crashes but not clang-3.8 passes, will look like::. git bisect start release",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:19388,Deployability,update,update,19388," AnotherBranch; cd ../../projects/libcxx; git checkout AnotherBranch. .. _workflow-mono-branching:. Monorepo Variant; ^^^^^^^^^^^^^^^^. Regular Git commands are sufficient, because everything is in a single; repository:. To update the repository to tip of trunk::. git pull. To create a new branch::. git checkout -b MyBranch. To switch branches::. git checkout AnotherBranch. Bisecting; ---------. Assuming a developer is looking for a bug in clang (or lld, or lldb, ...). Currently; ^^^^^^^^^. SVN does not have builtin bisection support, but the single revision across; sub-projects makes it possible to script around. Using the existing Git read-only view of the repositories, it is possible to use; the native Git bisection script over the llvm repository, and use some scripting; to synchronize the clang repository to match the llvm revision. .. _workflow-mono-bisecting:. Monorepo Variant; ^^^^^^^^^^^^^^^^. Bisecting on the monorepo is straightforward, and very similar to the above,; except that the bisection script does not need to include the; `git submodule update` step. The same example, finding which commit introduces a regression where clang-3.9; crashes but not clang-3.8 passes, will look like::. git bisect start releases/3.9.x releases/3.8.x; git bisect run ./bisect_script.sh. With the `bisect_script.sh` script being::. #!/bin/sh; cd $BUILD_DIR. ninja clang || exit 125 # an exit code of 125 asks ""git bisect""; # to ""skip"" the current commit. ./bin/clang some_crash_test.cpp. Also, since the monorepo handles commits update across multiple projects, you're; less like to encounter a build failure where a commit change an API in LLVM and; another later one ""fixes"" the build in clang. Moving Local Branches to the Monorepo; =====================================. Suppose you have been developing against the existing LLVM git; mirrors. You have one or more git branches that you want to migrate; to the ""final monorepo"". The simplest way to migrate such branches is with the;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:19551,Deployability,release,releases,19551,"the repository to tip of trunk::. git pull. To create a new branch::. git checkout -b MyBranch. To switch branches::. git checkout AnotherBranch. Bisecting; ---------. Assuming a developer is looking for a bug in clang (or lld, or lldb, ...). Currently; ^^^^^^^^^. SVN does not have builtin bisection support, but the single revision across; sub-projects makes it possible to script around. Using the existing Git read-only view of the repositories, it is possible to use; the native Git bisection script over the llvm repository, and use some scripting; to synchronize the clang repository to match the llvm revision. .. _workflow-mono-bisecting:. Monorepo Variant; ^^^^^^^^^^^^^^^^. Bisecting on the monorepo is straightforward, and very similar to the above,; except that the bisection script does not need to include the; `git submodule update` step. The same example, finding which commit introduces a regression where clang-3.9; crashes but not clang-3.8 passes, will look like::. git bisect start releases/3.9.x releases/3.8.x; git bisect run ./bisect_script.sh. With the `bisect_script.sh` script being::. #!/bin/sh; cd $BUILD_DIR. ninja clang || exit 125 # an exit code of 125 asks ""git bisect""; # to ""skip"" the current commit. ./bin/clang some_crash_test.cpp. Also, since the monorepo handles commits update across multiple projects, you're; less like to encounter a build failure where a commit change an API in LLVM and; another later one ""fixes"" the build in clang. Moving Local Branches to the Monorepo; =====================================. Suppose you have been developing against the existing LLVM git; mirrors. You have one or more git branches that you want to migrate; to the ""final monorepo"". The simplest way to migrate such branches is with the; ``migrate-downstream-fork.py`` tool at; https://github.com/jyknight/llvm-git-migration. Basic migration; ---------------. Basic instructions for ``migrate-downstream-fork.py`` are in the; Python script and are expanded on below to ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:19566,Deployability,release,releases,19566,"f trunk::. git pull. To create a new branch::. git checkout -b MyBranch. To switch branches::. git checkout AnotherBranch. Bisecting; ---------. Assuming a developer is looking for a bug in clang (or lld, or lldb, ...). Currently; ^^^^^^^^^. SVN does not have builtin bisection support, but the single revision across; sub-projects makes it possible to script around. Using the existing Git read-only view of the repositories, it is possible to use; the native Git bisection script over the llvm repository, and use some scripting; to synchronize the clang repository to match the llvm revision. .. _workflow-mono-bisecting:. Monorepo Variant; ^^^^^^^^^^^^^^^^. Bisecting on the monorepo is straightforward, and very similar to the above,; except that the bisection script does not need to include the; `git submodule update` step. The same example, finding which commit introduces a regression where clang-3.9; crashes but not clang-3.8 passes, will look like::. git bisect start releases/3.9.x releases/3.8.x; git bisect run ./bisect_script.sh. With the `bisect_script.sh` script being::. #!/bin/sh; cd $BUILD_DIR. ninja clang || exit 125 # an exit code of 125 asks ""git bisect""; # to ""skip"" the current commit. ./bin/clang some_crash_test.cpp. Also, since the monorepo handles commits update across multiple projects, you're; less like to encounter a build failure where a commit change an API in LLVM and; another later one ""fixes"" the build in clang. Moving Local Branches to the Monorepo; =====================================. Suppose you have been developing against the existing LLVM git; mirrors. You have one or more git branches that you want to migrate; to the ""final monorepo"". The simplest way to migrate such branches is with the; ``migrate-downstream-fork.py`` tool at; https://github.com/jyknight/llvm-git-migration. Basic migration; ---------------. Basic instructions for ``migrate-downstream-fork.py`` are in the; Python script and are expanded on below to a more general recipe::",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:19858,Deployability,update,update,19858,"to script around. Using the existing Git read-only view of the repositories, it is possible to use; the native Git bisection script over the llvm repository, and use some scripting; to synchronize the clang repository to match the llvm revision. .. _workflow-mono-bisecting:. Monorepo Variant; ^^^^^^^^^^^^^^^^. Bisecting on the monorepo is straightforward, and very similar to the above,; except that the bisection script does not need to include the; `git submodule update` step. The same example, finding which commit introduces a regression where clang-3.9; crashes but not clang-3.8 passes, will look like::. git bisect start releases/3.9.x releases/3.8.x; git bisect run ./bisect_script.sh. With the `bisect_script.sh` script being::. #!/bin/sh; cd $BUILD_DIR. ninja clang || exit 125 # an exit code of 125 asks ""git bisect""; # to ""skip"" the current commit. ./bin/clang some_crash_test.cpp. Also, since the monorepo handles commits update across multiple projects, you're; less like to encounter a build failure where a commit change an API in LLVM and; another later one ""fixes"" the build in clang. Moving Local Branches to the Monorepo; =====================================. Suppose you have been developing against the existing LLVM git; mirrors. You have one or more git branches that you want to migrate; to the ""final monorepo"". The simplest way to migrate such branches is with the; ``migrate-downstream-fork.py`` tool at; https://github.com/jyknight/llvm-git-migration. Basic migration; ---------------. Basic instructions for ``migrate-downstream-fork.py`` are in the; Python script and are expanded on below to a more general recipe::. # Make a repository which will become your final local mirror of the; # monorepo.; mkdir my-monorepo; git -C my-monorepo init. # Add a remote to the monorepo.; git -C my-monorepo remote add upstream/monorepo https://github.com/llvm/llvm-project.git. # Add remotes for each git mirror you use, from upstream as well as; # your local mirror. All proj",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:23544,Deployability,update,updated,23544,"ubproject_branches[@]}. for p in ${my_projects[@]}; do; subproject_branch=${p}/local/monorepo/${my_local_branch}; git -C my-monorepo branch -d ${subproject_branch}; done. # Create local branches for upstream monorepo branches.; for ref in $(git -C my-monorepo for-each-ref --format=""%(refname)"" \; refs/remotes/upstream/monorepo); do; upstream_branch=${ref#refs/remotes/upstream/monorepo/}; git -C my-monorepo branch upstream/${upstream_branch} ${ref}; done. The above gets you to a state like the following::. U1 - U2 - U3 <- upstream/main; \ \ \; \ \ - Llld1 - Llld2 -; \ \ \; \ - Lclang1 - Lclang2-- Lmerge <- local/octopus/main; \ /; - Lllvm1 - Lllvm2-----. Each branched component has its branch rewritten on top of the; monorepo and all components are unified by a giant octopus merge. If additional active local branches need to be preserved, the above; operations following the assignment to ``my_local_branch`` should be; done for each branch. Ref paths will need to be updated to map the; local branch to the corresponding upstream branch. If local branches; have no corresponding upstream branch, then the creation of; ``local/octopus/<local branch>`` need not use ``git-merge-base`` to; pinpoint its root commit; it may simply be branched from the; appropriate component branch (say, ``llvm/local_release_X``). Zipping local history; ---------------------. The octopus merge is suboptimal for many cases, because walking back; through the history of one component leaves the other components fixed; at a history that likely makes things unbuildable. Some downstream users track the order commits were made to subprojects; with some kind of ""umbrella"" project that imports the project git; mirrors as submodules, similar to the multirepo umbrella proposed; above. Such an umbrella repository looks something like this::. UM1 ---- UM2 -- UM3 -- UM4 ---- UM5 ---- UM6 ---- UM7 ---- UM8 <- main; | | | | | | |; Lllvm1 Llld1 Lclang1 Lclang2 Lllvm2 Llld2 Lmyproj1. The vertical bars represent su",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:24574,Deployability,update,updates,24574,"corresponding upstream branch. If local branches; have no corresponding upstream branch, then the creation of; ``local/octopus/<local branch>`` need not use ``git-merge-base`` to; pinpoint its root commit; it may simply be branched from the; appropriate component branch (say, ``llvm/local_release_X``). Zipping local history; ---------------------. The octopus merge is suboptimal for many cases, because walking back; through the history of one component leaves the other components fixed; at a history that likely makes things unbuildable. Some downstream users track the order commits were made to subprojects; with some kind of ""umbrella"" project that imports the project git; mirrors as submodules, similar to the multirepo umbrella proposed; above. Such an umbrella repository looks something like this::. UM1 ---- UM2 -- UM3 -- UM4 ---- UM5 ---- UM6 ---- UM7 ---- UM8 <- main; | | | | | | |; Lllvm1 Llld1 Lclang1 Lclang2 Lllvm2 Llld2 Lmyproj1. The vertical bars represent submodule updates to a particular local; commit in the project mirror. ``UM3`` in this case is a commit of; some local umbrella repository state that is not a submodule update,; perhaps a ``README`` or project build script update. Commit ``UM8``; updates a submodule of local project ``myproj``. The tool ``zip-downstream-fork.py`` at; https://github.com/greened/llvm-git-migration/tree/zip can be used to; convert the umbrella history into a monorepo-based history with; commits in the order implied by submodule updates::. U1 - U2 - U3 <- upstream/main; \ \ \; \ -----\--------------- local/zip--.; \ \ \ |; - Lllvm1 - Llld1 - UM3 - Lclang1 - Lclang2 - Lllvm2 - Llld2 - Lmyproj1 <-'. The ``U*`` commits represent upstream commits to the monorepo main; branch. Each submodule update in the local ``UM*`` commits brought in; a subproject tree at some local commit. The trees in the ``L*1``; commits represent merges from upstream. These result in edges from; the ``U*`` commits to their corresponding rewritten ``L*1`` co",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:24733,Deployability,update,update,24733,"cal branch>`` need not use ``git-merge-base`` to; pinpoint its root commit; it may simply be branched from the; appropriate component branch (say, ``llvm/local_release_X``). Zipping local history; ---------------------. The octopus merge is suboptimal for many cases, because walking back; through the history of one component leaves the other components fixed; at a history that likely makes things unbuildable. Some downstream users track the order commits were made to subprojects; with some kind of ""umbrella"" project that imports the project git; mirrors as submodules, similar to the multirepo umbrella proposed; above. Such an umbrella repository looks something like this::. UM1 ---- UM2 -- UM3 -- UM4 ---- UM5 ---- UM6 ---- UM7 ---- UM8 <- main; | | | | | | |; Lllvm1 Llld1 Lclang1 Lclang2 Lllvm2 Llld2 Lmyproj1. The vertical bars represent submodule updates to a particular local; commit in the project mirror. ``UM3`` in this case is a commit of; some local umbrella repository state that is not a submodule update,; perhaps a ``README`` or project build script update. Commit ``UM8``; updates a submodule of local project ``myproj``. The tool ``zip-downstream-fork.py`` at; https://github.com/greened/llvm-git-migration/tree/zip can be used to; convert the umbrella history into a monorepo-based history with; commits in the order implied by submodule updates::. U1 - U2 - U3 <- upstream/main; \ \ \; \ -----\--------------- local/zip--.; \ \ \ |; - Lllvm1 - Llld1 - UM3 - Lclang1 - Lclang2 - Lllvm2 - Llld2 - Lmyproj1 <-'. The ``U*`` commits represent upstream commits to the monorepo main; branch. Each submodule update in the local ``UM*`` commits brought in; a subproject tree at some local commit. The trees in the ``L*1``; commits represent merges from upstream. These result in edges from; the ``U*`` commits to their corresponding rewritten ``L*1`` commits.; The ``L*2`` commits did not do any merges from upstream. Note that the merge from ``U2`` to ``Lclang1`` appears redundant",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:24787,Deployability,update,update,24787,"cal branch>`` need not use ``git-merge-base`` to; pinpoint its root commit; it may simply be branched from the; appropriate component branch (say, ``llvm/local_release_X``). Zipping local history; ---------------------. The octopus merge is suboptimal for many cases, because walking back; through the history of one component leaves the other components fixed; at a history that likely makes things unbuildable. Some downstream users track the order commits were made to subprojects; with some kind of ""umbrella"" project that imports the project git; mirrors as submodules, similar to the multirepo umbrella proposed; above. Such an umbrella repository looks something like this::. UM1 ---- UM2 -- UM3 -- UM4 ---- UM5 ---- UM6 ---- UM7 ---- UM8 <- main; | | | | | | |; Lllvm1 Llld1 Lclang1 Lclang2 Lllvm2 Llld2 Lmyproj1. The vertical bars represent submodule updates to a particular local; commit in the project mirror. ``UM3`` in this case is a commit of; some local umbrella repository state that is not a submodule update,; perhaps a ``README`` or project build script update. Commit ``UM8``; updates a submodule of local project ``myproj``. The tool ``zip-downstream-fork.py`` at; https://github.com/greened/llvm-git-migration/tree/zip can be used to; convert the umbrella history into a monorepo-based history with; commits in the order implied by submodule updates::. U1 - U2 - U3 <- upstream/main; \ \ \; \ -----\--------------- local/zip--.; \ \ \ |; - Lllvm1 - Llld1 - UM3 - Lclang1 - Lclang2 - Lllvm2 - Llld2 - Lmyproj1 <-'. The ``U*`` commits represent upstream commits to the monorepo main; branch. Each submodule update in the local ``UM*`` commits brought in; a subproject tree at some local commit. The trees in the ``L*1``; commits represent merges from upstream. These result in edges from; the ``U*`` commits to their corresponding rewritten ``L*1`` commits.; The ``L*2`` commits did not do any merges from upstream. Note that the merge from ``U2`` to ``Lclang1`` appears redundant",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:24811,Deployability,update,updates,24811,"appropriate component branch (say, ``llvm/local_release_X``). Zipping local history; ---------------------. The octopus merge is suboptimal for many cases, because walking back; through the history of one component leaves the other components fixed; at a history that likely makes things unbuildable. Some downstream users track the order commits were made to subprojects; with some kind of ""umbrella"" project that imports the project git; mirrors as submodules, similar to the multirepo umbrella proposed; above. Such an umbrella repository looks something like this::. UM1 ---- UM2 -- UM3 -- UM4 ---- UM5 ---- UM6 ---- UM7 ---- UM8 <- main; | | | | | | |; Lllvm1 Llld1 Lclang1 Lclang2 Lllvm2 Llld2 Lmyproj1. The vertical bars represent submodule updates to a particular local; commit in the project mirror. ``UM3`` in this case is a commit of; some local umbrella repository state that is not a submodule update,; perhaps a ``README`` or project build script update. Commit ``UM8``; updates a submodule of local project ``myproj``. The tool ``zip-downstream-fork.py`` at; https://github.com/greened/llvm-git-migration/tree/zip can be used to; convert the umbrella history into a monorepo-based history with; commits in the order implied by submodule updates::. U1 - U2 - U3 <- upstream/main; \ \ \; \ -----\--------------- local/zip--.; \ \ \ |; - Lllvm1 - Llld1 - UM3 - Lclang1 - Lclang2 - Lllvm2 - Llld2 - Lmyproj1 <-'. The ``U*`` commits represent upstream commits to the monorepo main; branch. Each submodule update in the local ``UM*`` commits brought in; a subproject tree at some local commit. The trees in the ``L*1``; commits represent merges from upstream. These result in edges from; the ``U*`` commits to their corresponding rewritten ``L*1`` commits.; The ``L*2`` commits did not do any merges from upstream. Note that the merge from ``U2`` to ``Lclang1`` appears redundant, but; if, say, ``U3`` changed some files in upstream clang, the ``Lclang1``; commit appearing after the ``Llld1`",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:25078,Deployability,update,updates,25078,"k; through the history of one component leaves the other components fixed; at a history that likely makes things unbuildable. Some downstream users track the order commits were made to subprojects; with some kind of ""umbrella"" project that imports the project git; mirrors as submodules, similar to the multirepo umbrella proposed; above. Such an umbrella repository looks something like this::. UM1 ---- UM2 -- UM3 -- UM4 ---- UM5 ---- UM6 ---- UM7 ---- UM8 <- main; | | | | | | |; Lllvm1 Llld1 Lclang1 Lclang2 Lllvm2 Llld2 Lmyproj1. The vertical bars represent submodule updates to a particular local; commit in the project mirror. ``UM3`` in this case is a commit of; some local umbrella repository state that is not a submodule update,; perhaps a ``README`` or project build script update. Commit ``UM8``; updates a submodule of local project ``myproj``. The tool ``zip-downstream-fork.py`` at; https://github.com/greened/llvm-git-migration/tree/zip can be used to; convert the umbrella history into a monorepo-based history with; commits in the order implied by submodule updates::. U1 - U2 - U3 <- upstream/main; \ \ \; \ -----\--------------- local/zip--.; \ \ \ |; - Lllvm1 - Llld1 - UM3 - Lclang1 - Lclang2 - Lllvm2 - Llld2 - Lmyproj1 <-'. The ``U*`` commits represent upstream commits to the monorepo main; branch. Each submodule update in the local ``UM*`` commits brought in; a subproject tree at some local commit. The trees in the ``L*1``; commits represent merges from upstream. These result in edges from; the ``U*`` commits to their corresponding rewritten ``L*1`` commits.; The ``L*2`` commits did not do any merges from upstream. Note that the merge from ``U2`` to ``Lclang1`` appears redundant, but; if, say, ``U3`` changed some files in upstream clang, the ``Lclang1``; commit appearing after the ``Llld1`` commit would actually represent a; clang tree *earlier* in the upstream clang history. We want the; ``local/zip`` branch to accurately represent the state of our umbrella; h",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:25341,Deployability,update,update,25341,"mething like this::. UM1 ---- UM2 -- UM3 -- UM4 ---- UM5 ---- UM6 ---- UM7 ---- UM8 <- main; | | | | | | |; Lllvm1 Llld1 Lclang1 Lclang2 Lllvm2 Llld2 Lmyproj1. The vertical bars represent submodule updates to a particular local; commit in the project mirror. ``UM3`` in this case is a commit of; some local umbrella repository state that is not a submodule update,; perhaps a ``README`` or project build script update. Commit ``UM8``; updates a submodule of local project ``myproj``. The tool ``zip-downstream-fork.py`` at; https://github.com/greened/llvm-git-migration/tree/zip can be used to; convert the umbrella history into a monorepo-based history with; commits in the order implied by submodule updates::. U1 - U2 - U3 <- upstream/main; \ \ \; \ -----\--------------- local/zip--.; \ \ \ |; - Lllvm1 - Llld1 - UM3 - Lclang1 - Lclang2 - Lllvm2 - Llld2 - Lmyproj1 <-'. The ``U*`` commits represent upstream commits to the monorepo main; branch. Each submodule update in the local ``UM*`` commits brought in; a subproject tree at some local commit. The trees in the ``L*1``; commits represent merges from upstream. These result in edges from; the ``U*`` commits to their corresponding rewritten ``L*1`` commits.; The ``L*2`` commits did not do any merges from upstream. Note that the merge from ``U2`` to ``Lclang1`` appears redundant, but; if, say, ``U3`` changed some files in upstream clang, the ``Lclang1``; commit appearing after the ``Llld1`` commit would actually represent a; clang tree *earlier* in the upstream clang history. We want the; ``local/zip`` branch to accurately represent the state of our umbrella; history and so the edge ``U2 -> Lclang1`` is a visual reminder of what; clang's tree actually looks like in ``Lclang1``. Even so, the edge ``U3 -> Llld1`` could be problematic for future; merges from upstream. git will think that we've already merged from; ``U3``, and we have, except for the state of the clang tree. One; possible mitigation strategy is to manually diff clan",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:26422,Deployability,update,updates,26422,"ht in; a subproject tree at some local commit. The trees in the ``L*1``; commits represent merges from upstream. These result in edges from; the ``U*`` commits to their corresponding rewritten ``L*1`` commits.; The ``L*2`` commits did not do any merges from upstream. Note that the merge from ``U2`` to ``Lclang1`` appears redundant, but; if, say, ``U3`` changed some files in upstream clang, the ``Lclang1``; commit appearing after the ``Llld1`` commit would actually represent a; clang tree *earlier* in the upstream clang history. We want the; ``local/zip`` branch to accurately represent the state of our umbrella; history and so the edge ``U2 -> Lclang1`` is a visual reminder of what; clang's tree actually looks like in ``Lclang1``. Even so, the edge ``U3 -> Llld1`` could be problematic for future; merges from upstream. git will think that we've already merged from; ``U3``, and we have, except for the state of the clang tree. One; possible mitigation strategy is to manually diff clang between ``U2``; and ``U3`` and apply those updates to ``local/zip``. Another,; possibly simpler strategy is to freeze local work on downstream; branches and merge all submodules from the latest upstream before; running ``zip-downstream-fork.py``. If downstream merged each project; from upstream in lockstep without any intervening local commits, then; things should be fine without any special action. We anticipate this; to be the common case. The tree for ``Lclang1`` outside of clang will represent the state of; things at ``U3`` since all of the upstream projects not participating; in the umbrella history should be in a state respecting the commit; ``U3``. The trees for llvm and lld should correctly represent commits; ``Lllvm1`` and ``Llld1``, respectively. Commit ``UM3`` changed files not related to submodules and we need; somewhere to put them. It is not safe in general to put them in the; monorepo root directory because they may conflict with files in the; monorepo. Let's assume we want ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:29279,Deployability,update,update-tags,29279," project in ${subprojects[@]}; do; git remote add upstream/split/${project} \; https://github.com/llvm-mirror/${subproject}.git; git fetch umbrella/split/${project}; done. # Import histories for downstream split projects (this was probably; # already done for the ``migrate-downstream-fork.py`` run).; for project in ${subprojects[@]}; do; git remote add local/split/${project} \; https://my.local.mirror.org/${subproject}.git; git fetch local/split/${project}; done. # Import umbrella history.; git -C my-monorepo remote add umbrella \; https://my.local.mirror.org/umbrella.git; git fetch umbrella. # Put myproj in local/myproj; echo ""myproj local/myproj"" > my-monorepo/submodule-map.txt. # Rewrite history; (; cd my-monorepo; zip-downstream-fork.py \; refs/remotes/umbrella \; --new-repo-prefix=refs/remotes/upstream/monorepo \; --old-repo-prefix=refs/remotes/upstream/split \; --revmap-in=monorepo-map.txt \; --revmap-out=zip-map.txt \; --subdir=local \; --submodule-map=submodule-map.txt \; --update-tags; ). # Create the zip branch (assuming umbrella main is wanted).; git -C my-monorepo branch --no-track local/zip/main refs/remotes/umbrella/main. Note that if the umbrella has submodules to non-LLVM repositories,; ``zip-downstream-fork.py`` needs to know about them to be able to; rewrite commits. That is why the first step above is to fetch commits; from such repositories. With ``--update-tags`` the tool will migrate annotated tags pointing; to submodule commits that were inlined into the zipped history. If; the umbrella pulled in an upstream commit that happened to have a tag; pointing to it, that tag will be migrated, which is almost certainly; not what is wanted. The tag can always be moved back to its original; commit after rewriting, or the ``--update-tags`` option may be; discarded and any local tags would then be migrated manually. **Example 2: Nested sources layout**. The tool handles nested submodules (e.g. llvm is a submodule in; umbrella and clang is a submodule in l",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:29675,Deployability,update,update-tags,29675,"${project}; done. # Import umbrella history.; git -C my-monorepo remote add umbrella \; https://my.local.mirror.org/umbrella.git; git fetch umbrella. # Put myproj in local/myproj; echo ""myproj local/myproj"" > my-monorepo/submodule-map.txt. # Rewrite history; (; cd my-monorepo; zip-downstream-fork.py \; refs/remotes/umbrella \; --new-repo-prefix=refs/remotes/upstream/monorepo \; --old-repo-prefix=refs/remotes/upstream/split \; --revmap-in=monorepo-map.txt \; --revmap-out=zip-map.txt \; --subdir=local \; --submodule-map=submodule-map.txt \; --update-tags; ). # Create the zip branch (assuming umbrella main is wanted).; git -C my-monorepo branch --no-track local/zip/main refs/remotes/umbrella/main. Note that if the umbrella has submodules to non-LLVM repositories,; ``zip-downstream-fork.py`` needs to know about them to be able to; rewrite commits. That is why the first step above is to fetch commits; from such repositories. With ``--update-tags`` the tool will migrate annotated tags pointing; to submodule commits that were inlined into the zipped history. If; the umbrella pulled in an upstream commit that happened to have a tag; pointing to it, that tag will be migrated, which is almost certainly; not what is wanted. The tag can always be moved back to its original; commit after rewriting, or the ``--update-tags`` option may be; discarded and any local tags would then be migrated manually. **Example 2: Nested sources layout**. The tool handles nested submodules (e.g. llvm is a submodule in; umbrella and clang is a submodule in llvm). The file; ``submodule-map.txt`` is a list of pairs, one per line. The first; pair item describes the path to a submodule in the umbrella; repository. The second pair item describes the path where trees for; that submodule should be written in the zipped history. Let's say your umbrella repository is actually the llvm repository and; it has submodules in the ""nested sources"" layout (clang in; tools/clang, etc.). Let's also say ``projects/myp",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:30050,Deployability,update,update-tags,30050,"rella \; --new-repo-prefix=refs/remotes/upstream/monorepo \; --old-repo-prefix=refs/remotes/upstream/split \; --revmap-in=monorepo-map.txt \; --revmap-out=zip-map.txt \; --subdir=local \; --submodule-map=submodule-map.txt \; --update-tags; ). # Create the zip branch (assuming umbrella main is wanted).; git -C my-monorepo branch --no-track local/zip/main refs/remotes/umbrella/main. Note that if the umbrella has submodules to non-LLVM repositories,; ``zip-downstream-fork.py`` needs to know about them to be able to; rewrite commits. That is why the first step above is to fetch commits; from such repositories. With ``--update-tags`` the tool will migrate annotated tags pointing; to submodule commits that were inlined into the zipped history. If; the umbrella pulled in an upstream commit that happened to have a tag; pointing to it, that tag will be migrated, which is almost certainly; not what is wanted. The tag can always be moved back to its original; commit after rewriting, or the ``--update-tags`` option may be; discarded and any local tags would then be migrated manually. **Example 2: Nested sources layout**. The tool handles nested submodules (e.g. llvm is a submodule in; umbrella and clang is a submodule in llvm). The file; ``submodule-map.txt`` is a list of pairs, one per line. The first; pair item describes the path to a submodule in the umbrella; repository. The second pair item describes the path where trees for; that submodule should be written in the zipped history. Let's say your umbrella repository is actually the llvm repository and; it has submodules in the ""nested sources"" layout (clang in; tools/clang, etc.). Let's also say ``projects/myproj`` is a submodule; pointing to some downstream repository. The submodule map file should; look like this (we still want myproj mapped the same way as; previously)::. tools/clang clang; tools/clang/tools/extra clang-tools-extra; projects/compiler-rt compiler-rt; projects/debuginfo-tests debuginfo-tests; projects/libc",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:31562,Deployability,update,updates,31562,"repository is actually the llvm repository and; it has submodules in the ""nested sources"" layout (clang in; tools/clang, etc.). Let's also say ``projects/myproj`` is a submodule; pointing to some downstream repository. The submodule map file should; look like this (we still want myproj mapped the same way as; previously)::. tools/clang clang; tools/clang/tools/extra clang-tools-extra; projects/compiler-rt compiler-rt; projects/debuginfo-tests debuginfo-tests; projects/libclc libclc; projects/libcxx libcxx; projects/libcxxabi libcxxabi; projects/libunwind libunwind; tools/lld lld; tools/lldb lldb; projects/openmp openmp; tools/polly polly; projects/myproj local/myproj. If a submodule path does not appear in the map, the tools assumes it; should be placed in the same place in the monorepo. That means if you; use the ""nested sources"" layout in your umrella, you *must* provide; map entries for all of the projects in your umbrella (except llvm).; Otherwise trees from submodule updates will appear underneath llvm in; the zippped history. Because llvm is itself the umbrella, we use --subdir to write its; content into ``llvm`` in the zippped history::. # Import any non-LLVM repositories the umbrella references.; git -C my-monorepo remote add localrepo \; https://my.local.mirror.org/localrepo.git; git fetch localrepo. subprojects=( clang clang-tools-extra compiler-rt debuginfo-tests libclc; libcxx libcxxabi libunwind lld lldb llgo llvm openmp; parallel-libs polly pstl ). # Import histories for upstream split projects (this was probably; # already done for the ``migrate-downstream-fork.py`` run).; for project in ${subprojects[@]}; do; git remote add upstream/split/${project} \; https://github.com/llvm-mirror/${subproject}.git; git fetch umbrella/split/${project}; done. # Import histories for downstream split projects (this was probably; # already done for the ``migrate-downstream-fork.py`` run).; for project in ${subprojects[@]}; do; git remote add local/split/${project} \; ht",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:34080,Deployability,update,update-tags,34080,""" >> my-monorepo/submodule-map.txt; echo ""projects/debuginfo-tests debuginfo-tests"" >> my-monorepo/submodule-map.txt; echo ""projects/libclc libclc"" >> my-monorepo/submodule-map.txt; echo ""projects/libcxx libcxx"" >> my-monorepo/submodule-map.txt; echo ""projects/libcxxabi libcxxabi"" >> my-monorepo/submodule-map.txt; echo ""projects/libunwind libunwind"" >> my-monorepo/submodule-map.txt; echo ""tools/lld lld"" >> my-monorepo/submodule-map.txt; echo ""tools/lldb lldb"" >> my-monorepo/submodule-map.txt; echo ""projects/openmp openmp"" >> my-monorepo/submodule-map.txt; echo ""tools/polly polly"" >> my-monorepo/submodule-map.txt; echo ""projects/myproj local/myproj"" >> my-monorepo/submodule-map.txt. # Rewrite history; (; cd my-monorepo; zip-downstream-fork.py \; refs/remotes/umbrella \; --new-repo-prefix=refs/remotes/upstream/monorepo \; --old-repo-prefix=refs/remotes/upstream/split \; --revmap-in=monorepo-map.txt \; --revmap-out=zip-map.txt \; --subdir=llvm \; --submodule-map=submodule-map.txt \; --update-tags; ). # Create the zip branch (assuming umbrella main is wanted).; git -C my-monorepo branch --no-track local/zip/main refs/remotes/umbrella/main. Comments at the top of ``zip-downstream-fork.py`` describe in more; detail how the tool works and various implications of its operation. Importing local repositories; ----------------------------. You may have additional repositories that integrate with the LLVM; ecosystem, essentially extending it with new tools. If such; repositories are tightly coupled with LLVM, it may make sense to; import them into your local mirror of the monorepo. If such repositories participated in the umbrella repository used; during the zipping process above, they will automatically be added to; the monorepo. For downstream repositories that don't participate in; an umbrella setup, the ``import-downstream-repo.py`` tool at; https://github.com/greened/llvm-git-migration/tree/import can help with; getting them into the monorepo. A recipe follows::. # Import ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:34476,Deployability,integrat,integrate,34476," my-monorepo/submodule-map.txt; echo ""tools/lldb lldb"" >> my-monorepo/submodule-map.txt; echo ""projects/openmp openmp"" >> my-monorepo/submodule-map.txt; echo ""tools/polly polly"" >> my-monorepo/submodule-map.txt; echo ""projects/myproj local/myproj"" >> my-monorepo/submodule-map.txt. # Rewrite history; (; cd my-monorepo; zip-downstream-fork.py \; refs/remotes/umbrella \; --new-repo-prefix=refs/remotes/upstream/monorepo \; --old-repo-prefix=refs/remotes/upstream/split \; --revmap-in=monorepo-map.txt \; --revmap-out=zip-map.txt \; --subdir=llvm \; --submodule-map=submodule-map.txt \; --update-tags; ). # Create the zip branch (assuming umbrella main is wanted).; git -C my-monorepo branch --no-track local/zip/main refs/remotes/umbrella/main. Comments at the top of ``zip-downstream-fork.py`` describe in more; detail how the tool works and various implications of its operation. Importing local repositories; ----------------------------. You may have additional repositories that integrate with the LLVM; ecosystem, essentially extending it with new tools. If such; repositories are tightly coupled with LLVM, it may make sense to; import them into your local mirror of the monorepo. If such repositories participated in the umbrella repository used; during the zipping process above, they will automatically be added to; the monorepo. For downstream repositories that don't participate in; an umbrella setup, the ``import-downstream-repo.py`` tool at; https://github.com/greened/llvm-git-migration/tree/import can help with; getting them into the monorepo. A recipe follows::. # Import downstream repo history into the monorepo.; git -C my-monorepo remote add myrepo https://my.local.mirror.org/myrepo.git; git fetch myrepo. my_local_tags=( refs/tags/release; refs/tags/hotfix ). (; cd my-monorepo; import-downstream-repo.py \; refs/remotes/myrepo \; ${my_local_tags[@]} \; --new-repo-prefix=refs/remotes/upstream/monorepo \; --subdir=myrepo \; --tag-prefix=""myrepo-""; ). # Preserve release branc",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:35248,Deployability,release,release,35248," the top of ``zip-downstream-fork.py`` describe in more; detail how the tool works and various implications of its operation. Importing local repositories; ----------------------------. You may have additional repositories that integrate with the LLVM; ecosystem, essentially extending it with new tools. If such; repositories are tightly coupled with LLVM, it may make sense to; import them into your local mirror of the monorepo. If such repositories participated in the umbrella repository used; during the zipping process above, they will automatically be added to; the monorepo. For downstream repositories that don't participate in; an umbrella setup, the ``import-downstream-repo.py`` tool at; https://github.com/greened/llvm-git-migration/tree/import can help with; getting them into the monorepo. A recipe follows::. # Import downstream repo history into the monorepo.; git -C my-monorepo remote add myrepo https://my.local.mirror.org/myrepo.git; git fetch myrepo. my_local_tags=( refs/tags/release; refs/tags/hotfix ). (; cd my-monorepo; import-downstream-repo.py \; refs/remotes/myrepo \; ${my_local_tags[@]} \; --new-repo-prefix=refs/remotes/upstream/monorepo \; --subdir=myrepo \; --tag-prefix=""myrepo-""; ). # Preserve release branches.; for ref in $(git -C my-monorepo for-each-ref --format=""%(refname)"" \; refs/remotes/myrepo/release); do; branch=${ref#refs/remotes/myrepo/}; git -C my-monorepo branch --no-track myrepo/${branch} ${ref}; done. # Preserve main.; git -C my-monorepo branch --no-track myrepo/main refs/remotes/myrepo/main. # Merge main.; git -C my-monorepo checkout local/zip/main # Or local/octopus/main; git -C my-monorepo merge myrepo/main. You may want to merge other corresponding branches, for example; ``myrepo`` release branches if they were in lockstep with LLVM project; releases. ``--tag-prefix`` tells ``import-downstream-repo.py`` to rename; annotated tags with the given prefix. Due to limitations with; ``fast_filter_branch.py``, unannotated tags cannot be ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:35267,Deployability,hotfix,hotfix,35267," the top of ``zip-downstream-fork.py`` describe in more; detail how the tool works and various implications of its operation. Importing local repositories; ----------------------------. You may have additional repositories that integrate with the LLVM; ecosystem, essentially extending it with new tools. If such; repositories are tightly coupled with LLVM, it may make sense to; import them into your local mirror of the monorepo. If such repositories participated in the umbrella repository used; during the zipping process above, they will automatically be added to; the monorepo. For downstream repositories that don't participate in; an umbrella setup, the ``import-downstream-repo.py`` tool at; https://github.com/greened/llvm-git-migration/tree/import can help with; getting them into the monorepo. A recipe follows::. # Import downstream repo history into the monorepo.; git -C my-monorepo remote add myrepo https://my.local.mirror.org/myrepo.git; git fetch myrepo. my_local_tags=( refs/tags/release; refs/tags/hotfix ). (; cd my-monorepo; import-downstream-repo.py \; refs/remotes/myrepo \; ${my_local_tags[@]} \; --new-repo-prefix=refs/remotes/upstream/monorepo \; --subdir=myrepo \; --tag-prefix=""myrepo-""; ). # Preserve release branches.; for ref in $(git -C my-monorepo for-each-ref --format=""%(refname)"" \; refs/remotes/myrepo/release); do; branch=${ref#refs/remotes/myrepo/}; git -C my-monorepo branch --no-track myrepo/${branch} ${ref}; done. # Preserve main.; git -C my-monorepo branch --no-track myrepo/main refs/remotes/myrepo/main. # Merge main.; git -C my-monorepo checkout local/zip/main # Or local/octopus/main; git -C my-monorepo merge myrepo/main. You may want to merge other corresponding branches, for example; ``myrepo`` release branches if they were in lockstep with LLVM project; releases. ``--tag-prefix`` tells ``import-downstream-repo.py`` to rename; annotated tags with the given prefix. Due to limitations with; ``fast_filter_branch.py``, unannotated tags cannot be ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:35480,Deployability,release,release,35480,"ate with the LLVM; ecosystem, essentially extending it with new tools. If such; repositories are tightly coupled with LLVM, it may make sense to; import them into your local mirror of the monorepo. If such repositories participated in the umbrella repository used; during the zipping process above, they will automatically be added to; the monorepo. For downstream repositories that don't participate in; an umbrella setup, the ``import-downstream-repo.py`` tool at; https://github.com/greened/llvm-git-migration/tree/import can help with; getting them into the monorepo. A recipe follows::. # Import downstream repo history into the monorepo.; git -C my-monorepo remote add myrepo https://my.local.mirror.org/myrepo.git; git fetch myrepo. my_local_tags=( refs/tags/release; refs/tags/hotfix ). (; cd my-monorepo; import-downstream-repo.py \; refs/remotes/myrepo \; ${my_local_tags[@]} \; --new-repo-prefix=refs/remotes/upstream/monorepo \; --subdir=myrepo \; --tag-prefix=""myrepo-""; ). # Preserve release branches.; for ref in $(git -C my-monorepo for-each-ref --format=""%(refname)"" \; refs/remotes/myrepo/release); do; branch=${ref#refs/remotes/myrepo/}; git -C my-monorepo branch --no-track myrepo/${branch} ${ref}; done. # Preserve main.; git -C my-monorepo branch --no-track myrepo/main refs/remotes/myrepo/main. # Merge main.; git -C my-monorepo checkout local/zip/main # Or local/octopus/main; git -C my-monorepo merge myrepo/main. You may want to merge other corresponding branches, for example; ``myrepo`` release branches if they were in lockstep with LLVM project; releases. ``--tag-prefix`` tells ``import-downstream-repo.py`` to rename; annotated tags with the given prefix. Due to limitations with; ``fast_filter_branch.py``, unannotated tags cannot be renamed; (``fast_filter_branch.py`` considers them branches, not tags). Since; the upstream monorepo had its tags rewritten with an ""llvmorg-""; prefix, name conflicts should not be an issue. ``--tag-prefix`` can; be used to more clear",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:35589,Deployability,release,release,35589,"LVM, it may make sense to; import them into your local mirror of the monorepo. If such repositories participated in the umbrella repository used; during the zipping process above, they will automatically be added to; the monorepo. For downstream repositories that don't participate in; an umbrella setup, the ``import-downstream-repo.py`` tool at; https://github.com/greened/llvm-git-migration/tree/import can help with; getting them into the monorepo. A recipe follows::. # Import downstream repo history into the monorepo.; git -C my-monorepo remote add myrepo https://my.local.mirror.org/myrepo.git; git fetch myrepo. my_local_tags=( refs/tags/release; refs/tags/hotfix ). (; cd my-monorepo; import-downstream-repo.py \; refs/remotes/myrepo \; ${my_local_tags[@]} \; --new-repo-prefix=refs/remotes/upstream/monorepo \; --subdir=myrepo \; --tag-prefix=""myrepo-""; ). # Preserve release branches.; for ref in $(git -C my-monorepo for-each-ref --format=""%(refname)"" \; refs/remotes/myrepo/release); do; branch=${ref#refs/remotes/myrepo/}; git -C my-monorepo branch --no-track myrepo/${branch} ${ref}; done. # Preserve main.; git -C my-monorepo branch --no-track myrepo/main refs/remotes/myrepo/main. # Merge main.; git -C my-monorepo checkout local/zip/main # Or local/octopus/main; git -C my-monorepo merge myrepo/main. You may want to merge other corresponding branches, for example; ``myrepo`` release branches if they were in lockstep with LLVM project; releases. ``--tag-prefix`` tells ``import-downstream-repo.py`` to rename; annotated tags with the given prefix. Due to limitations with; ``fast_filter_branch.py``, unannotated tags cannot be renamed; (``fast_filter_branch.py`` considers them branches, not tags). Since; the upstream monorepo had its tags rewritten with an ""llvmorg-""; prefix, name conflicts should not be an issue. ``--tag-prefix`` can; be used to more clearly indicate which tags correspond to various; imported repositories. Given this repository history::. R1 - R2 - R3 <- m",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:35997,Deployability,release,release,35997,"n/tree/import can help with; getting them into the monorepo. A recipe follows::. # Import downstream repo history into the monorepo.; git -C my-monorepo remote add myrepo https://my.local.mirror.org/myrepo.git; git fetch myrepo. my_local_tags=( refs/tags/release; refs/tags/hotfix ). (; cd my-monorepo; import-downstream-repo.py \; refs/remotes/myrepo \; ${my_local_tags[@]} \; --new-repo-prefix=refs/remotes/upstream/monorepo \; --subdir=myrepo \; --tag-prefix=""myrepo-""; ). # Preserve release branches.; for ref in $(git -C my-monorepo for-each-ref --format=""%(refname)"" \; refs/remotes/myrepo/release); do; branch=${ref#refs/remotes/myrepo/}; git -C my-monorepo branch --no-track myrepo/${branch} ${ref}; done. # Preserve main.; git -C my-monorepo branch --no-track myrepo/main refs/remotes/myrepo/main. # Merge main.; git -C my-monorepo checkout local/zip/main # Or local/octopus/main; git -C my-monorepo merge myrepo/main. You may want to merge other corresponding branches, for example; ``myrepo`` release branches if they were in lockstep with LLVM project; releases. ``--tag-prefix`` tells ``import-downstream-repo.py`` to rename; annotated tags with the given prefix. Due to limitations with; ``fast_filter_branch.py``, unannotated tags cannot be renamed; (``fast_filter_branch.py`` considers them branches, not tags). Since; the upstream monorepo had its tags rewritten with an ""llvmorg-""; prefix, name conflicts should not be an issue. ``--tag-prefix`` can; be used to more clearly indicate which tags correspond to various; imported repositories. Given this repository history::. R1 - R2 - R3 <- main; ^; |; release/1. The above recipe results in a history like this::. U1 - U2 - U3 <- upstream/main; \ \ \; \ -----\--------------- local/zip--.; \ \ \ |; - Lllvm1 - Llld1 - UM3 - Lclang1 - Lclang2 - Lllvm2 - Llld2 - Lmyproj1 - M1 <-'; /; R1 - R2 - R3 <-.; ^ |; | |; myrepo-release/1 |; |; myrepo/main--'. Commits ``R1``, ``R2`` and ``R3`` have trees that *only* contain blobs; from ``myre",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:36058,Deployability,release,releases,36058,"n/tree/import can help with; getting them into the monorepo. A recipe follows::. # Import downstream repo history into the monorepo.; git -C my-monorepo remote add myrepo https://my.local.mirror.org/myrepo.git; git fetch myrepo. my_local_tags=( refs/tags/release; refs/tags/hotfix ). (; cd my-monorepo; import-downstream-repo.py \; refs/remotes/myrepo \; ${my_local_tags[@]} \; --new-repo-prefix=refs/remotes/upstream/monorepo \; --subdir=myrepo \; --tag-prefix=""myrepo-""; ). # Preserve release branches.; for ref in $(git -C my-monorepo for-each-ref --format=""%(refname)"" \; refs/remotes/myrepo/release); do; branch=${ref#refs/remotes/myrepo/}; git -C my-monorepo branch --no-track myrepo/${branch} ${ref}; done. # Preserve main.; git -C my-monorepo branch --no-track myrepo/main refs/remotes/myrepo/main. # Merge main.; git -C my-monorepo checkout local/zip/main # Or local/octopus/main; git -C my-monorepo merge myrepo/main. You may want to merge other corresponding branches, for example; ``myrepo`` release branches if they were in lockstep with LLVM project; releases. ``--tag-prefix`` tells ``import-downstream-repo.py`` to rename; annotated tags with the given prefix. Due to limitations with; ``fast_filter_branch.py``, unannotated tags cannot be renamed; (``fast_filter_branch.py`` considers them branches, not tags). Since; the upstream monorepo had its tags rewritten with an ""llvmorg-""; prefix, name conflicts should not be an issue. ``--tag-prefix`` can; be used to more clearly indicate which tags correspond to various; imported repositories. Given this repository history::. R1 - R2 - R3 <- main; ^; |; release/1. The above recipe results in a history like this::. U1 - U2 - U3 <- upstream/main; \ \ \; \ -----\--------------- local/zip--.; \ \ \ |; - Lllvm1 - Llld1 - UM3 - Lclang1 - Lclang2 - Lllvm2 - Llld2 - Lmyproj1 - M1 <-'; /; R1 - R2 - R3 <-.; ^ |; | |; myrepo-release/1 |; |; myrepo/main--'. Commits ``R1``, ``R2`` and ``R3`` have trees that *only* contain blobs; from ``myre",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:36613,Deployability,release,release,36613,"branch=${ref#refs/remotes/myrepo/}; git -C my-monorepo branch --no-track myrepo/${branch} ${ref}; done. # Preserve main.; git -C my-monorepo branch --no-track myrepo/main refs/remotes/myrepo/main. # Merge main.; git -C my-monorepo checkout local/zip/main # Or local/octopus/main; git -C my-monorepo merge myrepo/main. You may want to merge other corresponding branches, for example; ``myrepo`` release branches if they were in lockstep with LLVM project; releases. ``--tag-prefix`` tells ``import-downstream-repo.py`` to rename; annotated tags with the given prefix. Due to limitations with; ``fast_filter_branch.py``, unannotated tags cannot be renamed; (``fast_filter_branch.py`` considers them branches, not tags). Since; the upstream monorepo had its tags rewritten with an ""llvmorg-""; prefix, name conflicts should not be an issue. ``--tag-prefix`` can; be used to more clearly indicate which tags correspond to various; imported repositories. Given this repository history::. R1 - R2 - R3 <- main; ^; |; release/1. The above recipe results in a history like this::. U1 - U2 - U3 <- upstream/main; \ \ \; \ -----\--------------- local/zip--.; \ \ \ |; - Lllvm1 - Llld1 - UM3 - Lclang1 - Lclang2 - Lllvm2 - Llld2 - Lmyproj1 - M1 <-'; /; R1 - R2 - R3 <-.; ^ |; | |; myrepo-release/1 |; |; myrepo/main--'. Commits ``R1``, ``R2`` and ``R3`` have trees that *only* contain blobs; from ``myrepo``. If you require commits from ``myrepo`` to be; interleaved with commits on local project branches (for example,; interleaved with ``llvm1``, ``llvm2``, etc. above) and myrepo doesn't; appear in an umbrella repository, a new tool will need to be; developed. Creating such a tool would involve:. 1. Modifying ``fast_filter_branch.py`` to optionally take a; revlist directly rather than generating it itself. 2. Creating a tool to generate an interleaved ordering of local; commits based on some criteria (``zip-downstream-fork.py`` uses the; umbrella history as its criterion). 3. Generating such an orderin",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:36879,Deployability,release,release,36879,"t -C my-monorepo merge myrepo/main. You may want to merge other corresponding branches, for example; ``myrepo`` release branches if they were in lockstep with LLVM project; releases. ``--tag-prefix`` tells ``import-downstream-repo.py`` to rename; annotated tags with the given prefix. Due to limitations with; ``fast_filter_branch.py``, unannotated tags cannot be renamed; (``fast_filter_branch.py`` considers them branches, not tags). Since; the upstream monorepo had its tags rewritten with an ""llvmorg-""; prefix, name conflicts should not be an issue. ``--tag-prefix`` can; be used to more clearly indicate which tags correspond to various; imported repositories. Given this repository history::. R1 - R2 - R3 <- main; ^; |; release/1. The above recipe results in a history like this::. U1 - U2 - U3 <- upstream/main; \ \ \; \ -----\--------------- local/zip--.; \ \ \ |; - Lllvm1 - Llld1 - UM3 - Lclang1 - Lclang2 - Lllvm2 - Llld2 - Lmyproj1 - M1 <-'; /; R1 - R2 - R3 <-.; ^ |; | |; myrepo-release/1 |; |; myrepo/main--'. Commits ``R1``, ``R2`` and ``R3`` have trees that *only* contain blobs; from ``myrepo``. If you require commits from ``myrepo`` to be; interleaved with commits on local project branches (for example,; interleaved with ``llvm1``, ``llvm2``, etc. above) and myrepo doesn't; appear in an umbrella repository, a new tool will need to be; developed. Creating such a tool would involve:. 1. Modifying ``fast_filter_branch.py`` to optionally take a; revlist directly rather than generating it itself. 2. Creating a tool to generate an interleaved ordering of local; commits based on some criteria (``zip-downstream-fork.py`` uses the; umbrella history as its criterion). 3. Generating such an ordering and feeding it to; ``fast_filter_branch.py`` as a revlist. Some care will also likely need to be taken to handle merge commits,; to ensure the parents of such commits migrate correctly. Scrubbing the Local Monorepo; ----------------------------. Once all of the migrating, zippin",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:38734,Deployability,release,release,38734,"its migrate correctly. Scrubbing the Local Monorepo; ----------------------------. Once all of the migrating, zipping and importing is done, it's time to; clean up. The python tools use ``git-fast-import`` which leaves a lot; of cruft around and we want to shrink our new monorepo mirror as much; as possible. Here is one way to do it::. git -C my-monorepo checkout main. # Delete branches we no longer need. Do this for any other branches; # you merged above.; git -C my-monorepo branch -D local/zip/main || true; git -C my-monorepo branch -D local/octopus/main || true. # Remove remotes.; git -C my-monorepo remote remove upstream/monorepo. for p in ${my_projects[@]}; do; git -C my-monorepo remote remove upstream/split/${p}; git -C my-monorepo remote remove local/split/${p}; done. git -C my-monorepo remote remove localrepo; git -C my-monorepo remote remove umbrella; git -C my-monorepo remote remove myrepo. # Add anything else here you don't need. refs/tags/release is; # listed below assuming tags have been rewritten with a local prefix.; # If not, remove it from this list.; refs_to_clean=(; refs/original; refs/remotes; refs/tags/backups; refs/tags/release; ). git -C my-monorepo for-each-ref --format=""%(refname)"" ${refs_to_clean[@]} |; xargs -n1 --no-run-if-empty git -C my-monorepo update-ref -d. git -C my-monorepo reflog expire --all --expire=now. # fast_filter_branch.py might have gc running in the background.; while ! git -C my-monorepo \; -c gc.reflogExpire=0 \; -c gc.reflogExpireUnreachable=0 \; -c gc.rerereresolved=0 \; -c gc.rerereunresolved=0 \; -c gc.pruneExpire=now \; gc --prune=now; do; continue; done. # Takes a LOOOONG time!; git -C my-monorepo repack -A -d -f --depth=250 --window=250. git -C my-monorepo prune-packed; git -C my-monorepo prune. You should now have a trim monorepo. Upload it to your git server and; happy hacking!. References; ==========. .. [LattnerRevNum] Chris Lattner, http://lists.llvm.org/pipermail/llvm-dev/2011-July/041739.html; .. [TrickRev",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:38929,Deployability,release,release,38929,"ting is done, it's time to; clean up. The python tools use ``git-fast-import`` which leaves a lot; of cruft around and we want to shrink our new monorepo mirror as much; as possible. Here is one way to do it::. git -C my-monorepo checkout main. # Delete branches we no longer need. Do this for any other branches; # you merged above.; git -C my-monorepo branch -D local/zip/main || true; git -C my-monorepo branch -D local/octopus/main || true. # Remove remotes.; git -C my-monorepo remote remove upstream/monorepo. for p in ${my_projects[@]}; do; git -C my-monorepo remote remove upstream/split/${p}; git -C my-monorepo remote remove local/split/${p}; done. git -C my-monorepo remote remove localrepo; git -C my-monorepo remote remove umbrella; git -C my-monorepo remote remove myrepo. # Add anything else here you don't need. refs/tags/release is; # listed below assuming tags have been rewritten with a local prefix.; # If not, remove it from this list.; refs_to_clean=(; refs/original; refs/remotes; refs/tags/backups; refs/tags/release; ). git -C my-monorepo for-each-ref --format=""%(refname)"" ${refs_to_clean[@]} |; xargs -n1 --no-run-if-empty git -C my-monorepo update-ref -d. git -C my-monorepo reflog expire --all --expire=now. # fast_filter_branch.py might have gc running in the background.; while ! git -C my-monorepo \; -c gc.reflogExpire=0 \; -c gc.reflogExpireUnreachable=0 \; -c gc.rerereresolved=0 \; -c gc.rerereunresolved=0 \; -c gc.pruneExpire=now \; gc --prune=now; do; continue; done. # Takes a LOOOONG time!; git -C my-monorepo repack -A -d -f --depth=250 --window=250. git -C my-monorepo prune-packed; git -C my-monorepo prune. You should now have a trim monorepo. Upload it to your git server and; happy hacking!. References; ==========. .. [LattnerRevNum] Chris Lattner, http://lists.llvm.org/pipermail/llvm-dev/2011-July/041739.html; .. [TrickRevNum] Andrew Trick, http://lists.llvm.org/pipermail/llvm-dev/2011-July/041721.html; .. [JSonnRevNum] Joerg Sonnenberger, http://",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:39065,Deployability,update,update-ref,39065,"d and we want to shrink our new monorepo mirror as much; as possible. Here is one way to do it::. git -C my-monorepo checkout main. # Delete branches we no longer need. Do this for any other branches; # you merged above.; git -C my-monorepo branch -D local/zip/main || true; git -C my-monorepo branch -D local/octopus/main || true. # Remove remotes.; git -C my-monorepo remote remove upstream/monorepo. for p in ${my_projects[@]}; do; git -C my-monorepo remote remove upstream/split/${p}; git -C my-monorepo remote remove local/split/${p}; done. git -C my-monorepo remote remove localrepo; git -C my-monorepo remote remove umbrella; git -C my-monorepo remote remove myrepo. # Add anything else here you don't need. refs/tags/release is; # listed below assuming tags have been rewritten with a local prefix.; # If not, remove it from this list.; refs_to_clean=(; refs/original; refs/remotes; refs/tags/backups; refs/tags/release; ). git -C my-monorepo for-each-ref --format=""%(refname)"" ${refs_to_clean[@]} |; xargs -n1 --no-run-if-empty git -C my-monorepo update-ref -d. git -C my-monorepo reflog expire --all --expire=now. # fast_filter_branch.py might have gc running in the background.; while ! git -C my-monorepo \; -c gc.reflogExpire=0 \; -c gc.reflogExpireUnreachable=0 \; -c gc.rerereresolved=0 \; -c gc.rerereunresolved=0 \; -c gc.pruneExpire=now \; gc --prune=now; do; continue; done. # Takes a LOOOONG time!; git -C my-monorepo repack -A -d -f --depth=250 --window=250. git -C my-monorepo prune-packed; git -C my-monorepo prune. You should now have a trim monorepo. Upload it to your git server and; happy hacking!. References; ==========. .. [LattnerRevNum] Chris Lattner, http://lists.llvm.org/pipermail/llvm-dev/2011-July/041739.html; .. [TrickRevNum] Andrew Trick, http://lists.llvm.org/pipermail/llvm-dev/2011-July/041721.html; .. [JSonnRevNum] Joerg Sonnenberger, http://lists.llvm.org/pipermail/llvm-dev/2011-July/041688.html; .. [MatthewsRevNum] Chris Matthews, http://lists.llvm.org",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:3371,Energy Efficiency,monitor,monitor,3371,"s being stored in a SVN server, these developers are already using Git; through the Git-SVN integration. Git allows you to:. * Commit, squash, merge, and fork locally without touching the remote server.; * Maintain local branches, enabling multiple threads of development.; * Collaborate on these branches (e.g. through your own fork of llvm on GitHub).; * Inspect the repository history (blame, log, bisect) without Internet access.; * Maintain remote forks and branches on Git hosting services and; integrate back to the main repository. In addition, because Git seems to be replacing many OSS projects' version; control systems, there are many tools that are built over Git.; Future tooling may support Git first (if not only). Why GitHub?; -----------. GitHub, like GitLab and BitBucket, provides free code hosting for open source; projects. Any of these could replace the code-hosting infrastructure that we; have today. These services also have a dedicated team to monitor, migrate, improve and; distribute the contents of the repositories depending on region and load. GitHub has one important advantage over GitLab and; BitBucket: it offers read-write **SVN** access to the repository; (https://github.com/blog/626-announcing-svn-support).; This would enable people to continue working post-migration as though our code; were still canonically in an SVN repository. In addition, there are already multiple LLVM mirrors on GitHub, indicating that; part of our community has already settled there. On Managing Revision Numbers with Git; -------------------------------------. The current SVN repository hosts all the LLVM sub-projects alongside each other.; A single revision number (e.g. r123456) thus identifies a consistent version of; all LLVM sub-projects. Git does not use sequential integer revision number but instead uses a hash to; identify each commit. The loss of a sequential integer revision number has been a sticking point in; past discussions about Git:. - ""The 'branch' I most",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:24919,Energy Efficiency,green,greened,24919,"k; through the history of one component leaves the other components fixed; at a history that likely makes things unbuildable. Some downstream users track the order commits were made to subprojects; with some kind of ""umbrella"" project that imports the project git; mirrors as submodules, similar to the multirepo umbrella proposed; above. Such an umbrella repository looks something like this::. UM1 ---- UM2 -- UM3 -- UM4 ---- UM5 ---- UM6 ---- UM7 ---- UM8 <- main; | | | | | | |; Lllvm1 Llld1 Lclang1 Lclang2 Lllvm2 Llld2 Lmyproj1. The vertical bars represent submodule updates to a particular local; commit in the project mirror. ``UM3`` in this case is a commit of; some local umbrella repository state that is not a submodule update,; perhaps a ``README`` or project build script update. Commit ``UM8``; updates a submodule of local project ``myproj``. The tool ``zip-downstream-fork.py`` at; https://github.com/greened/llvm-git-migration/tree/zip can be used to; convert the umbrella history into a monorepo-based history with; commits in the order implied by submodule updates::. U1 - U2 - U3 <- upstream/main; \ \ \; \ -----\--------------- local/zip--.; \ \ \ |; - Lllvm1 - Llld1 - UM3 - Lclang1 - Lclang2 - Lllvm2 - Llld2 - Lmyproj1 <-'. The ``U*`` commits represent upstream commits to the monorepo main; branch. Each submodule update in the local ``UM*`` commits brought in; a subproject tree at some local commit. The trees in the ``L*1``; commits represent merges from upstream. These result in edges from; the ``U*`` commits to their corresponding rewritten ``L*1`` commits.; The ``L*2`` commits did not do any merges from upstream. Note that the merge from ``U2`` to ``Lclang1`` appears redundant, but; if, say, ``U3`` changed some files in upstream clang, the ``Lclang1``; commit appearing after the ``Llld1`` commit would actually represent a; clang tree *earlier* in the upstream clang history. We want the; ``local/zip`` branch to accurately represent the state of our umbrella; h",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:34968,Energy Efficiency,green,greened,34968,"=zip-map.txt \; --subdir=llvm \; --submodule-map=submodule-map.txt \; --update-tags; ). # Create the zip branch (assuming umbrella main is wanted).; git -C my-monorepo branch --no-track local/zip/main refs/remotes/umbrella/main. Comments at the top of ``zip-downstream-fork.py`` describe in more; detail how the tool works and various implications of its operation. Importing local repositories; ----------------------------. You may have additional repositories that integrate with the LLVM; ecosystem, essentially extending it with new tools. If such; repositories are tightly coupled with LLVM, it may make sense to; import them into your local mirror of the monorepo. If such repositories participated in the umbrella repository used; during the zipping process above, they will automatically be added to; the monorepo. For downstream repositories that don't participate in; an umbrella setup, the ``import-downstream-repo.py`` tool at; https://github.com/greened/llvm-git-migration/tree/import can help with; getting them into the monorepo. A recipe follows::. # Import downstream repo history into the monorepo.; git -C my-monorepo remote add myrepo https://my.local.mirror.org/myrepo.git; git fetch myrepo. my_local_tags=( refs/tags/release; refs/tags/hotfix ). (; cd my-monorepo; import-downstream-repo.py \; refs/remotes/myrepo \; ${my_local_tags[@]} \; --new-repo-prefix=refs/remotes/upstream/monorepo \; --subdir=myrepo \; --tag-prefix=""myrepo-""; ). # Preserve release branches.; for ref in $(git -C my-monorepo for-each-ref --format=""%(refname)"" \; refs/remotes/myrepo/release); do; branch=${ref#refs/remotes/myrepo/}; git -C my-monorepo branch --no-track myrepo/${branch} ${ref}; done. # Preserve main.; git -C my-monorepo branch --no-track myrepo/main refs/remotes/myrepo/main. # Merge main.; git -C my-monorepo checkout local/zip/main # Or local/octopus/main; git -C my-monorepo merge myrepo/main. You may want to merge other corresponding branches, for example; ``myrepo`` release bran",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:1747,Integrability,integrat,integration,1747,"sal is *Not* About; =================================. Changing the development policy. This proposal relates only to moving the hosting of our source-code repository; from SVN hosted on our own servers to Git hosted on GitHub. We are not proposing; using GitHub's issue tracker, pull-requests, or code-review. Contributors will continue to earn commit access on demand under the Developer; Policy, except that that a GitHub account will be required instead of SVN; username/password-hash. Why Git, and Why GitHub?; ========================. Why Move At All?; ----------------. This discussion began because we currently host our own Subversion server; and Git mirror on a voluntary basis. The LLVM Foundation sponsors the server and; provides limited support, but there is only so much it can do. Volunteers are not sysadmins themselves, but compiler engineers that happen; to know a thing or two about hosting servers. We also don't have 24/7 support,; and we sometimes wake up to see that continuous integration is broken because; the SVN server is either down or unresponsive. We should take advantage of one of the services out there (GitHub, GitLab,; and BitBucket, among others) that offer better service (24/7 stability, disk; space, Git server, code browsing, forking facilities, etc) for free. Why Git?; --------. Many new coders nowadays start with Git, and a lot of people have never used; SVN, CVS, or anything else. Websites like GitHub have changed the landscape; of open source contributions, reducing the cost of first contribution and; fostering collaboration. Git is also the version control many LLVM developers use. Despite the; sources being stored in a SVN server, these developers are already using Git; through the Git-SVN integration. Git allows you to:. * Commit, squash, merge, and fork locally without touching the remote server.; * Maintain local branches, enabling multiple threads of development.; * Collaborate on these branches (e.g. through your own fork of llvm on",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:2492,Integrability,integrat,integration,2492," Foundation sponsors the server and; provides limited support, but there is only so much it can do. Volunteers are not sysadmins themselves, but compiler engineers that happen; to know a thing or two about hosting servers. We also don't have 24/7 support,; and we sometimes wake up to see that continuous integration is broken because; the SVN server is either down or unresponsive. We should take advantage of one of the services out there (GitHub, GitLab,; and BitBucket, among others) that offer better service (24/7 stability, disk; space, Git server, code browsing, forking facilities, etc) for free. Why Git?; --------. Many new coders nowadays start with Git, and a lot of people have never used; SVN, CVS, or anything else. Websites like GitHub have changed the landscape; of open source contributions, reducing the cost of first contribution and; fostering collaboration. Git is also the version control many LLVM developers use. Despite the; sources being stored in a SVN server, these developers are already using Git; through the Git-SVN integration. Git allows you to:. * Commit, squash, merge, and fork locally without touching the remote server.; * Maintain local branches, enabling multiple threads of development.; * Collaborate on these branches (e.g. through your own fork of llvm on GitHub).; * Inspect the repository history (blame, log, bisect) without Internet access.; * Maintain remote forks and branches on Git hosting services and; integrate back to the main repository. In addition, because Git seems to be replacing many OSS projects' version; control systems, there are many tools that are built over Git.; Future tooling may support Git first (if not only). Why GitHub?; -----------. GitHub, like GitLab and BitBucket, provides free code hosting for open source; projects. Any of these could replace the code-hosting infrastructure that we; have today. These services also have a dedicated team to monitor, migrate, improve and; distribute the contents of the repositor",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:2901,Integrability,integrat,integrate,2901,"tHub, GitLab,; and BitBucket, among others) that offer better service (24/7 stability, disk; space, Git server, code browsing, forking facilities, etc) for free. Why Git?; --------. Many new coders nowadays start with Git, and a lot of people have never used; SVN, CVS, or anything else. Websites like GitHub have changed the landscape; of open source contributions, reducing the cost of first contribution and; fostering collaboration. Git is also the version control many LLVM developers use. Despite the; sources being stored in a SVN server, these developers are already using Git; through the Git-SVN integration. Git allows you to:. * Commit, squash, merge, and fork locally without touching the remote server.; * Maintain local branches, enabling multiple threads of development.; * Collaborate on these branches (e.g. through your own fork of llvm on GitHub).; * Inspect the repository history (blame, log, bisect) without Internet access.; * Maintain remote forks and branches on Git hosting services and; integrate back to the main repository. In addition, because Git seems to be replacing many OSS projects' version; control systems, there are many tools that are built over Git.; Future tooling may support Git first (if not only). Why GitHub?; -----------. GitHub, like GitLab and BitBucket, provides free code hosting for open source; projects. Any of these could replace the code-hosting infrastructure that we; have today. These services also have a dedicated team to monitor, migrate, improve and; distribute the contents of the repositories depending on region and load. GitHub has one important advantage over GitLab and; BitBucket: it offers read-write **SVN** access to the repository; (https://github.com/blog/626-announcing-svn-support).; This would enable people to continue working post-migration as though our code; were still canonically in an SVN repository. In addition, there are already multiple LLVM mirrors on GitHub, indicating that; part of our community has alrea",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:3446,Integrability,depend,depending,3446,"s being stored in a SVN server, these developers are already using Git; through the Git-SVN integration. Git allows you to:. * Commit, squash, merge, and fork locally without touching the remote server.; * Maintain local branches, enabling multiple threads of development.; * Collaborate on these branches (e.g. through your own fork of llvm on GitHub).; * Inspect the repository history (blame, log, bisect) without Internet access.; * Maintain remote forks and branches on Git hosting services and; integrate back to the main repository. In addition, because Git seems to be replacing many OSS projects' version; control systems, there are many tools that are built over Git.; Future tooling may support Git first (if not only). Why GitHub?; -----------. GitHub, like GitLab and BitBucket, provides free code hosting for open source; projects. Any of these could replace the code-hosting infrastructure that we; have today. These services also have a dedicated team to monitor, migrate, improve and; distribute the contents of the repositories depending on region and load. GitHub has one important advantage over GitLab and; BitBucket: it offers read-write **SVN** access to the repository; (https://github.com/blog/626-announcing-svn-support).; This would enable people to continue working post-migration as though our code; were still canonically in an SVN repository. In addition, there are already multiple LLVM mirrors on GitHub, indicating that; part of our community has already settled there. On Managing Revision Numbers with Git; -------------------------------------. The current SVN repository hosts all the LLVM sub-projects alongside each other.; A single revision number (e.g. r123456) thus identifies a consistent version of; all LLVM sub-projects. Git does not use sequential integer revision number but instead uses a hash to; identify each commit. The loss of a sequential integer revision number has been a sticking point in; past discussions about Git:. - ""The 'branch' I most",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:7519,Integrability,integrat,integrators,7519,"ves the; email format unchanged besides the commit URL. Straw Man Migration Plan; ========================. Step #1 : Before The Move; -------------------------. 1. Update docs to mention the move, so people are aware of what is going on.; 2. Set up a read-only version of the GitHub project, mirroring our current SVN; repository.; 3. Add the required bots to implement the commit emails, as well as the; umbrella repository update (if the multirepo is selected) or the read-only; Git views for the sub-projects (if the monorepo is selected). Step #2 : Git Move; ------------------. 4. Update the buildbots to pick up updates and commits from the GitHub; repository. Not all bots have to migrate at this point, but it'll help; provide infrastructure testing.; 5. Update Phabricator to pick up commits from the GitHub repository.; 6. LNT and llvmlab have to be updated: they rely on unique monotonically; increasing integer across branch [MatthewsRevNum]_.; 7. Instruct downstream integrators to pick up commits from the GitHub; repository.; 8. Review and prepare an update for the LLVM documentation. Until this point nothing has changed for developers, it will just; boil down to a lot of work for buildbot and other infrastructure; owners. The migration will pause here until all dependencies have cleared, and all; problems have been solved. Step #3: Write Access Move; --------------------------. 9. Collect developers' GitHub account information, and add them to the project.; 10. Switch the SVN repository to read-only and allow pushes to the GitHub repository.; 11. Update the documentation.; 12. Mirror Git to SVN. Step #4 : Post Move; -------------------. 13. Archive the SVN repository.; 14. Update links on the LLVM website pointing to viewvc/klaus/phab etc. to; point to GitHub instead. GitHub Repository Description; =============================. Monorepo; ----------------. The LLVM git repository hosted at https://github.com/llvm/llvm-project contains all; sub-projects in a single ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:7821,Integrability,depend,dependencies,7821,"mirroring our current SVN; repository.; 3. Add the required bots to implement the commit emails, as well as the; umbrella repository update (if the multirepo is selected) or the read-only; Git views for the sub-projects (if the monorepo is selected). Step #2 : Git Move; ------------------. 4. Update the buildbots to pick up updates and commits from the GitHub; repository. Not all bots have to migrate at this point, but it'll help; provide infrastructure testing.; 5. Update Phabricator to pick up commits from the GitHub repository.; 6. LNT and llvmlab have to be updated: they rely on unique monotonically; increasing integer across branch [MatthewsRevNum]_.; 7. Instruct downstream integrators to pick up commits from the GitHub; repository.; 8. Review and prepare an update for the LLVM documentation. Until this point nothing has changed for developers, it will just; boil down to a lot of work for buildbot and other infrastructure; owners. The migration will pause here until all dependencies have cleared, and all; problems have been solved. Step #3: Write Access Move; --------------------------. 9. Collect developers' GitHub account information, and add them to the project.; 10. Switch the SVN repository to read-only and allow pushes to the GitHub repository.; 11. Update the documentation.; 12. Mirror Git to SVN. Step #4 : Post Move; -------------------. 13. Archive the SVN repository.; 14. Update links on the LLVM website pointing to viewvc/klaus/phab etc. to; point to GitHub instead. GitHub Repository Description; =============================. Monorepo; ----------------. The LLVM git repository hosted at https://github.com/llvm/llvm-project contains all; sub-projects in a single source tree. It is often referred to as a monorepo and; mimics an export of the current SVN repository, with each sub-project having its; own top-level directory. Not all sub-projects are used for building toolchains.; For example, www/ and test-suite/ are not part of the monorepo. Putting all",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:9078,Integrability,depend,dependency,9078,"to read-only and allow pushes to the GitHub repository.; 11. Update the documentation.; 12. Mirror Git to SVN. Step #4 : Post Move; -------------------. 13. Archive the SVN repository.; 14. Update links on the LLVM website pointing to viewvc/klaus/phab etc. to; point to GitHub instead. GitHub Repository Description; =============================. Monorepo; ----------------. The LLVM git repository hosted at https://github.com/llvm/llvm-project contains all; sub-projects in a single source tree. It is often referred to as a monorepo and; mimics an export of the current SVN repository, with each sub-project having its; own top-level directory. Not all sub-projects are used for building toolchains.; For example, www/ and test-suite/ are not part of the monorepo. Putting all sub-projects in a single checkout makes cross-project refactoring; naturally simple:. * New sub-projects can be trivially split out for better reuse and/or layering; (e.g., to allow libSupport and/or LIT to be used by runtimes without adding a; dependency on LLVM).; * Changing an API in LLVM and upgrading the sub-projects will always be done in; a single commit, designing away a common source of temporary build breakage.; * Moving code across sub-project (during refactoring for instance) in a single; commit enables accurate `git blame` when tracking code change history.; * Tooling based on `git grep` works natively across sub-projects, allowing to; easier find refactoring opportunities across projects (for example reusing a; datastructure initially in LLDB by moving it into libSupport).; * Having all the sources present encourages maintaining the other sub-projects; when changing API. Finally, the monorepo maintains the property of the existing SVN repository that; the sub-projects move synchronously, and a single revision number (or commit; hash) identifies the state of the development across all projects. .. _build_single_project:. Building a single sub-project; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Even",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:10773,Integrability,bridg,bridge,10773,"he existing SVN repository that; the sub-projects move synchronously, and a single revision number (or commit; hash) identifies the state of the development across all projects. .. _build_single_project:. Building a single sub-project; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Even though there is a single source tree, you are not required to build; all sub-projects together. It is trivial to configure builds for a single; sub-project. For example::. mkdir build && cd build; # Configure only LLVM (default); cmake path/to/monorepo; # Configure LLVM and lld; cmake path/to/monorepo -DLLVM_ENABLE_PROJECTS=lld; # Configure LLVM and clang; cmake path/to/monorepo -DLLVM_ENABLE_PROJECTS=clang. .. _git-svn-mirror:. Outstanding Questions; ---------------------. Read-only sub-project mirrors; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. With the Monorepo, it is undecided whether the existing single-subproject; mirrors (e.g. https://git.llvm.org/git/compiler-rt.git) will continue to; be maintained. Read/write SVN bridge; ^^^^^^^^^^^^^^^^^^^^^. GitHub supports a read/write SVN bridge for its repositories. However,; there have been issues with this bridge working correctly in the past,; so it's not clear if this is something that will be supported going forward. Monorepo Drawbacks; ------------------. * Using the monolithic repository may add overhead for those contributing to a; standalone sub-project, particularly on runtimes like libcxx and compiler-rt; that don't rely on LLVM; currently, a fresh clone of libcxx is only 15MB (vs.; 1GB for the monorepo), and the commit rate of LLVM may cause more frequent; `git push` collisions when upstreaming. Affected contributors may be able to; use the SVN bridge or the single-subproject Git mirrors. However, it's; undecided if these projects will continue to be maintained.; * Using the monolithic repository may add overhead for those *integrating* a; standalone sub-project, even if they aren't contributing to it, due to the; same disk space concern as the point ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:10837,Integrability,bridg,bridge,10837," synchronously, and a single revision number (or commit; hash) identifies the state of the development across all projects. .. _build_single_project:. Building a single sub-project; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Even though there is a single source tree, you are not required to build; all sub-projects together. It is trivial to configure builds for a single; sub-project. For example::. mkdir build && cd build; # Configure only LLVM (default); cmake path/to/monorepo; # Configure LLVM and lld; cmake path/to/monorepo -DLLVM_ENABLE_PROJECTS=lld; # Configure LLVM and clang; cmake path/to/monorepo -DLLVM_ENABLE_PROJECTS=clang. .. _git-svn-mirror:. Outstanding Questions; ---------------------. Read-only sub-project mirrors; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. With the Monorepo, it is undecided whether the existing single-subproject; mirrors (e.g. https://git.llvm.org/git/compiler-rt.git) will continue to; be maintained. Read/write SVN bridge; ^^^^^^^^^^^^^^^^^^^^^. GitHub supports a read/write SVN bridge for its repositories. However,; there have been issues with this bridge working correctly in the past,; so it's not clear if this is something that will be supported going forward. Monorepo Drawbacks; ------------------. * Using the monolithic repository may add overhead for those contributing to a; standalone sub-project, particularly on runtimes like libcxx and compiler-rt; that don't rely on LLVM; currently, a fresh clone of libcxx is only 15MB (vs.; 1GB for the monorepo), and the commit rate of LLVM may cause more frequent; `git push` collisions when upstreaming. Affected contributors may be able to; use the SVN bridge or the single-subproject Git mirrors. However, it's; undecided if these projects will continue to be maintained.; * Using the monolithic repository may add overhead for those *integrating* a; standalone sub-project, even if they aren't contributing to it, due to the; same disk space concern as the point above. The availability of the; sub-project Git mirror",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:10909,Integrability,bridg,bridge,10909,"all projects. .. _build_single_project:. Building a single sub-project; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Even though there is a single source tree, you are not required to build; all sub-projects together. It is trivial to configure builds for a single; sub-project. For example::. mkdir build && cd build; # Configure only LLVM (default); cmake path/to/monorepo; # Configure LLVM and lld; cmake path/to/monorepo -DLLVM_ENABLE_PROJECTS=lld; # Configure LLVM and clang; cmake path/to/monorepo -DLLVM_ENABLE_PROJECTS=clang. .. _git-svn-mirror:. Outstanding Questions; ---------------------. Read-only sub-project mirrors; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. With the Monorepo, it is undecided whether the existing single-subproject; mirrors (e.g. https://git.llvm.org/git/compiler-rt.git) will continue to; be maintained. Read/write SVN bridge; ^^^^^^^^^^^^^^^^^^^^^. GitHub supports a read/write SVN bridge for its repositories. However,; there have been issues with this bridge working correctly in the past,; so it's not clear if this is something that will be supported going forward. Monorepo Drawbacks; ------------------. * Using the monolithic repository may add overhead for those contributing to a; standalone sub-project, particularly on runtimes like libcxx and compiler-rt; that don't rely on LLVM; currently, a fresh clone of libcxx is only 15MB (vs.; 1GB for the monorepo), and the commit rate of LLVM may cause more frequent; `git push` collisions when upstreaming. Affected contributors may be able to; use the SVN bridge or the single-subproject Git mirrors. However, it's; undecided if these projects will continue to be maintained.; * Using the monolithic repository may add overhead for those *integrating* a; standalone sub-project, even if they aren't contributing to it, due to the; same disk space concern as the point above. The availability of the; sub-project Git mirrors would addresses this.; * Preservation of the existing read/write SVN-based workflows relies on the; GitHub SV",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:11468,Integrability,bridg,bridge,11468,".. _git-svn-mirror:. Outstanding Questions; ---------------------. Read-only sub-project mirrors; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. With the Monorepo, it is undecided whether the existing single-subproject; mirrors (e.g. https://git.llvm.org/git/compiler-rt.git) will continue to; be maintained. Read/write SVN bridge; ^^^^^^^^^^^^^^^^^^^^^. GitHub supports a read/write SVN bridge for its repositories. However,; there have been issues with this bridge working correctly in the past,; so it's not clear if this is something that will be supported going forward. Monorepo Drawbacks; ------------------. * Using the monolithic repository may add overhead for those contributing to a; standalone sub-project, particularly on runtimes like libcxx and compiler-rt; that don't rely on LLVM; currently, a fresh clone of libcxx is only 15MB (vs.; 1GB for the monorepo), and the commit rate of LLVM may cause more frequent; `git push` collisions when upstreaming. Affected contributors may be able to; use the SVN bridge or the single-subproject Git mirrors. However, it's; undecided if these projects will continue to be maintained.; * Using the monolithic repository may add overhead for those *integrating* a; standalone sub-project, even if they aren't contributing to it, due to the; same disk space concern as the point above. The availability of the; sub-project Git mirrors would addresses this.; * Preservation of the existing read/write SVN-based workflows relies on the; GitHub SVN bridge, which is an extra dependency. Maintaining this locks us; into GitHub and could restrict future workflow changes. Workflows; ^^^^^^^^^. * :ref:`Checkout/Clone a Single Project, without Commit Access <workflow-checkout-commit>`.; * :ref:`Checkout/Clone Multiple Projects, with Commit Access <workflow-monocheckout-multicommit>`.; * :ref:`Commit an API Change in LLVM and Update the Sub-projects <workflow-cross-repo-commit>`.; * :ref:`Branching/Stashing/Updating for Local Development or Experiments <workflow-mo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:11651,Integrability,integrat,integrating,11651,"ps://git.llvm.org/git/compiler-rt.git) will continue to; be maintained. Read/write SVN bridge; ^^^^^^^^^^^^^^^^^^^^^. GitHub supports a read/write SVN bridge for its repositories. However,; there have been issues with this bridge working correctly in the past,; so it's not clear if this is something that will be supported going forward. Monorepo Drawbacks; ------------------. * Using the monolithic repository may add overhead for those contributing to a; standalone sub-project, particularly on runtimes like libcxx and compiler-rt; that don't rely on LLVM; currently, a fresh clone of libcxx is only 15MB (vs.; 1GB for the monorepo), and the commit rate of LLVM may cause more frequent; `git push` collisions when upstreaming. Affected contributors may be able to; use the SVN bridge or the single-subproject Git mirrors. However, it's; undecided if these projects will continue to be maintained.; * Using the monolithic repository may add overhead for those *integrating* a; standalone sub-project, even if they aren't contributing to it, due to the; same disk space concern as the point above. The availability of the; sub-project Git mirrors would addresses this.; * Preservation of the existing read/write SVN-based workflows relies on the; GitHub SVN bridge, which is an extra dependency. Maintaining this locks us; into GitHub and could restrict future workflow changes. Workflows; ^^^^^^^^^. * :ref:`Checkout/Clone a Single Project, without Commit Access <workflow-checkout-commit>`.; * :ref:`Checkout/Clone Multiple Projects, with Commit Access <workflow-monocheckout-multicommit>`.; * :ref:`Commit an API Change in LLVM and Update the Sub-projects <workflow-cross-repo-commit>`.; * :ref:`Branching/Stashing/Updating for Local Development or Experiments <workflow-mono-branching>`.; * :ref:`Bisecting <workflow-mono-bisecting>`. Workflow Before/After; =====================. This section goes through a few examples of workflows, intended to illustrate; how end-users or developers would ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:11947,Integrability,bridg,bridge,11947,"ing correctly in the past,; so it's not clear if this is something that will be supported going forward. Monorepo Drawbacks; ------------------. * Using the monolithic repository may add overhead for those contributing to a; standalone sub-project, particularly on runtimes like libcxx and compiler-rt; that don't rely on LLVM; currently, a fresh clone of libcxx is only 15MB (vs.; 1GB for the monorepo), and the commit rate of LLVM may cause more frequent; `git push` collisions when upstreaming. Affected contributors may be able to; use the SVN bridge or the single-subproject Git mirrors. However, it's; undecided if these projects will continue to be maintained.; * Using the monolithic repository may add overhead for those *integrating* a; standalone sub-project, even if they aren't contributing to it, due to the; same disk space concern as the point above. The availability of the; sub-project Git mirrors would addresses this.; * Preservation of the existing read/write SVN-based workflows relies on the; GitHub SVN bridge, which is an extra dependency. Maintaining this locks us; into GitHub and could restrict future workflow changes. Workflows; ^^^^^^^^^. * :ref:`Checkout/Clone a Single Project, without Commit Access <workflow-checkout-commit>`.; * :ref:`Checkout/Clone Multiple Projects, with Commit Access <workflow-monocheckout-multicommit>`.; * :ref:`Commit an API Change in LLVM and Update the Sub-projects <workflow-cross-repo-commit>`.; * :ref:`Branching/Stashing/Updating for Local Development or Experiments <workflow-mono-branching>`.; * :ref:`Bisecting <workflow-mono-bisecting>`. Workflow Before/After; =====================. This section goes through a few examples of workflows, intended to illustrate; how end-users or developers would interact with the repository for; various use-cases. .. _workflow-checkout-commit:. Checkout/Clone a Single Project, with Commit Access; ---------------------------------------------------. Currently; ^^^^^^^^^. ::. # direct SVN check",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:11973,Integrability,depend,dependency,11973,"ing correctly in the past,; so it's not clear if this is something that will be supported going forward. Monorepo Drawbacks; ------------------. * Using the monolithic repository may add overhead for those contributing to a; standalone sub-project, particularly on runtimes like libcxx and compiler-rt; that don't rely on LLVM; currently, a fresh clone of libcxx is only 15MB (vs.; 1GB for the monorepo), and the commit rate of LLVM may cause more frequent; `git push` collisions when upstreaming. Affected contributors may be able to; use the SVN bridge or the single-subproject Git mirrors. However, it's; undecided if these projects will continue to be maintained.; * Using the monolithic repository may add overhead for those *integrating* a; standalone sub-project, even if they aren't contributing to it, due to the; same disk space concern as the point above. The availability of the; sub-project Git mirrors would addresses this.; * Preservation of the existing read/write SVN-based workflows relies on the; GitHub SVN bridge, which is an extra dependency. Maintaining this locks us; into GitHub and could restrict future workflow changes. Workflows; ^^^^^^^^^. * :ref:`Checkout/Clone a Single Project, without Commit Access <workflow-checkout-commit>`.; * :ref:`Checkout/Clone Multiple Projects, with Commit Access <workflow-monocheckout-multicommit>`.; * :ref:`Commit an API Change in LLVM and Update the Sub-projects <workflow-cross-repo-commit>`.; * :ref:`Branching/Stashing/Updating for Local Development or Experiments <workflow-mono-branching>`.; * :ref:`Bisecting <workflow-mono-bisecting>`. Workflow Before/After; =====================. This section goes through a few examples of workflows, intended to illustrate; how end-users or developers would interact with the repository for; various use-cases. .. _workflow-checkout-commit:. Checkout/Clone a Single Project, with Commit Access; ---------------------------------------------------. Currently; ^^^^^^^^^. ::. # direct SVN check",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:13517,Integrability,depend,depending,13517,"low-mono-bisecting>`. Workflow Before/After; =====================. This section goes through a few examples of workflows, intended to illustrate; how end-users or developers would interact with the repository for; various use-cases. .. _workflow-checkout-commit:. Checkout/Clone a Single Project, with Commit Access; ---------------------------------------------------. Currently; ^^^^^^^^^. ::. # direct SVN checkout; svn co https://user@llvm.org/svn/llvm-project/llvm/trunk llvm; # or using the read-only Git view, with git-svn; git clone https://llvm.org/git/llvm.git; cd llvm; git svn init https://llvm.org/svn/llvm-project/llvm/trunk --username=<username>; git config svn-remote.svn.fetch :refs/remotes/origin/main; git svn rebase -l # -l avoids fetching ahead of the git mirror. Commits are performed using `svn commit` or with the sequence `git commit` and; `git svn dcommit`. .. _workflow-multicheckout-nocommit:. Monorepo Variant; ^^^^^^^^^^^^^^^^. With the monorepo variant, there are a few options, depending on your; constraints. First, you could just clone the full repository:. git clone https://github.com/llvm/llvm-project.git. At this point you have every sub-project (llvm, clang, lld, lldb, ...), which; :ref:`doesn't imply you have to build all of them <build_single_project>`. You; can still build only compiler-rt for instance. In this way it's not different; from someone who would check out all the projects with SVN today. If you want to avoid checking out all the sources, you can hide the other; directories using a Git sparse checkout::. git config core.sparseCheckout true; echo /compiler-rt > .git/info/sparse-checkout; git read-tree -mu HEAD. The data for all sub-projects is still in your `.git` directory, but in your; checkout, you only see `compiler-rt`.; Before you push, you'll need to fetch and rebase (`git pull --rebase`) as; usual. Note that when you fetch you'll likely pull in changes to sub-projects you don't; care about. If you are using sparse checkout",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:14873,Integrability,depend,dependent,14873," In this way it's not different; from someone who would check out all the projects with SVN today. If you want to avoid checking out all the sources, you can hide the other; directories using a Git sparse checkout::. git config core.sparseCheckout true; echo /compiler-rt > .git/info/sparse-checkout; git read-tree -mu HEAD. The data for all sub-projects is still in your `.git` directory, but in your; checkout, you only see `compiler-rt`.; Before you push, you'll need to fetch and rebase (`git pull --rebase`) as; usual. Note that when you fetch you'll likely pull in changes to sub-projects you don't; care about. If you are using sparse checkout, the files from other projects; won't appear on your disk. The only effect is that your commit hash changes. You can check whether the changes in the last fetch are relevant to your commit; by running::. git log origin/main@{1}..origin/main -- libcxx. This command can be hidden in a script so that `git llvmpush` would perform all; these steps, fail only if such a dependent change exists, and show immediately; the change that prevented the push. An immediate repeat of the command would; (almost) certainly result in a successful push.; Note that today with SVN or git-svn, this step is not possible since the; ""rebase"" implicitly happens while committing (unless a conflict occurs). Checkout/Clone Multiple Projects, with Commit Access; ----------------------------------------------------. Let's look how to assemble llvm+clang+libcxx at a given revision. Currently; ^^^^^^^^^. ::. svn co https://llvm.org/svn/llvm-project/llvm/trunk llvm -r $REVISION; cd llvm/tools; svn co https://llvm.org/svn/llvm-project/clang/trunk clang -r $REVISION; cd ../projects; svn co https://llvm.org/svn/llvm-project/libcxx/trunk libcxx -r $REVISION. Or using git-svn::. git clone https://llvm.org/git/llvm.git; cd llvm/; git svn init https://llvm.org/svn/llvm-project/llvm/trunk --username=<username>; git config svn-remote.svn.fetch :refs/remotes/origin/main; gi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:17447,Integrability,protocol,protocol,17447,"re sub-projects. .. _workflow-monocheckout-multicommit:. Monorepo Variant; ^^^^^^^^^^^^^^^^. The repository contains natively the source for every sub-projects at the right; revision, which makes this straightforward::. git clone https://github.com/llvm/llvm-project.git; cd llvm-projects; git checkout $REVISION. As before, at this point clang, llvm, and libcxx are stored in directories; alongside each other. .. _workflow-cross-repo-commit:. Commit an API Change in LLVM and Update the Sub-projects; --------------------------------------------------------. Today this is possible, even though not common (at least not documented) for; subversion users and for git-svn users. For example, few Git users try to update; LLD or Clang in the same commit as they change an LLVM API. The multirepo variant does not address this: one would have to commit and push; separately in every individual repository. It would be possible to establish a; protocol whereby users add a special token to their commit messages that causes; the umbrella repo's updater bot to group all of them into a single revision. The monorepo variant handles this natively. Branching/Stashing/Updating for Local Development or Experiments; ----------------------------------------------------------------. Currently; ^^^^^^^^^. SVN does not allow this use case, but developers that are currently using; git-svn can do it. Let's look in practice what it means when dealing with; multiple sub-projects. To update the repository to tip of trunk::. git pull; cd tools/clang; git pull; cd ../../projects/libcxx; git pull. To create a new branch::. git checkout -b MyBranch; cd tools/clang; git checkout -b MyBranch; cd ../../projects/libcxx; git checkout -b MyBranch. To switch branches::. git checkout AnotherBranch; cd tools/clang; git checkout AnotherBranch; cd ../../projects/libcxx; git checkout AnotherBranch. .. _workflow-mono-branching:. Monorepo Variant; ^^^^^^^^^^^^^^^^. Regular Git commands are sufficient, because everything",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:17506,Integrability,message,messages,17506,"re sub-projects. .. _workflow-monocheckout-multicommit:. Monorepo Variant; ^^^^^^^^^^^^^^^^. The repository contains natively the source for every sub-projects at the right; revision, which makes this straightforward::. git clone https://github.com/llvm/llvm-project.git; cd llvm-projects; git checkout $REVISION. As before, at this point clang, llvm, and libcxx are stored in directories; alongside each other. .. _workflow-cross-repo-commit:. Commit an API Change in LLVM and Update the Sub-projects; --------------------------------------------------------. Today this is possible, even though not common (at least not documented) for; subversion users and for git-svn users. For example, few Git users try to update; LLD or Clang in the same commit as they change an LLVM API. The multirepo variant does not address this: one would have to commit and push; separately in every individual repository. It would be possible to establish a; protocol whereby users add a special token to their commit messages that causes; the umbrella repo's updater bot to group all of them into a single revision. The monorepo variant handles this natively. Branching/Stashing/Updating for Local Development or Experiments; ----------------------------------------------------------------. Currently; ^^^^^^^^^. SVN does not allow this use case, but developers that are currently using; git-svn can do it. Let's look in practice what it means when dealing with; multiple sub-projects. To update the repository to tip of trunk::. git pull; cd tools/clang; git pull; cd ../../projects/libcxx; git pull. To create a new branch::. git checkout -b MyBranch; cd tools/clang; git checkout -b MyBranch; cd ../../projects/libcxx; git checkout -b MyBranch. To switch branches::. git checkout AnotherBranch; cd tools/clang; git checkout AnotherBranch; cd ../../projects/libcxx; git checkout AnotherBranch. .. _workflow-mono-branching:. Monorepo Variant; ^^^^^^^^^^^^^^^^. Regular Git commands are sufficient, because everything",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:19105,Integrability,synchroniz,synchronize,19105,"ull; cd ../../projects/libcxx; git pull. To create a new branch::. git checkout -b MyBranch; cd tools/clang; git checkout -b MyBranch; cd ../../projects/libcxx; git checkout -b MyBranch. To switch branches::. git checkout AnotherBranch; cd tools/clang; git checkout AnotherBranch; cd ../../projects/libcxx; git checkout AnotherBranch. .. _workflow-mono-branching:. Monorepo Variant; ^^^^^^^^^^^^^^^^. Regular Git commands are sufficient, because everything is in a single; repository:. To update the repository to tip of trunk::. git pull. To create a new branch::. git checkout -b MyBranch. To switch branches::. git checkout AnotherBranch. Bisecting; ---------. Assuming a developer is looking for a bug in clang (or lld, or lldb, ...). Currently; ^^^^^^^^^. SVN does not have builtin bisection support, but the single revision across; sub-projects makes it possible to script around. Using the existing Git read-only view of the repositories, it is possible to use; the native Git bisection script over the llvm repository, and use some scripting; to synchronize the clang repository to match the llvm revision. .. _workflow-mono-bisecting:. Monorepo Variant; ^^^^^^^^^^^^^^^^. Bisecting on the monorepo is straightforward, and very similar to the above,; except that the bisection script does not need to include the; `git submodule update` step. The same example, finding which commit introduces a regression where clang-3.9; crashes but not clang-3.8 passes, will look like::. git bisect start releases/3.9.x releases/3.8.x; git bisect run ./bisect_script.sh. With the `bisect_script.sh` script being::. #!/bin/sh; cd $BUILD_DIR. ninja clang || exit 125 # an exit code of 125 asks ""git bisect""; # to ""skip"" the current commit. ./bin/clang some_crash_test.cpp. Also, since the monorepo handles commits update across multiple projects, you're; less like to encounter a build failure where a commit change an API in LLVM and; another later one ""fixes"" the build in clang. Moving Local Branches to ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:34476,Integrability,integrat,integrate,34476," my-monorepo/submodule-map.txt; echo ""tools/lldb lldb"" >> my-monorepo/submodule-map.txt; echo ""projects/openmp openmp"" >> my-monorepo/submodule-map.txt; echo ""tools/polly polly"" >> my-monorepo/submodule-map.txt; echo ""projects/myproj local/myproj"" >> my-monorepo/submodule-map.txt. # Rewrite history; (; cd my-monorepo; zip-downstream-fork.py \; refs/remotes/umbrella \; --new-repo-prefix=refs/remotes/upstream/monorepo \; --old-repo-prefix=refs/remotes/upstream/split \; --revmap-in=monorepo-map.txt \; --revmap-out=zip-map.txt \; --subdir=llvm \; --submodule-map=submodule-map.txt \; --update-tags; ). # Create the zip branch (assuming umbrella main is wanted).; git -C my-monorepo branch --no-track local/zip/main refs/remotes/umbrella/main. Comments at the top of ``zip-downstream-fork.py`` describe in more; detail how the tool works and various implications of its operation. Importing local repositories; ----------------------------. You may have additional repositories that integrate with the LLVM; ecosystem, essentially extending it with new tools. If such; repositories are tightly coupled with LLVM, it may make sense to; import them into your local mirror of the monorepo. If such repositories participated in the umbrella repository used; during the zipping process above, they will automatically be added to; the monorepo. For downstream repositories that don't participate in; an umbrella setup, the ``import-downstream-repo.py`` tool at; https://github.com/greened/llvm-git-migration/tree/import can help with; getting them into the monorepo. A recipe follows::. # Import downstream repo history into the monorepo.; git -C my-monorepo remote add myrepo https://my.local.mirror.org/myrepo.git; git fetch myrepo. my_local_tags=( refs/tags/release; refs/tags/hotfix ). (; cd my-monorepo; import-downstream-repo.py \; refs/remotes/myrepo \; ${my_local_tags[@]} \; --new-repo-prefix=refs/remotes/upstream/monorepo \; --subdir=myrepo \; --tag-prefix=""myrepo-""; ). # Preserve release branc",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:8887,Modifiability,refactor,refactoring,8887,"e been solved. Step #3: Write Access Move; --------------------------. 9. Collect developers' GitHub account information, and add them to the project.; 10. Switch the SVN repository to read-only and allow pushes to the GitHub repository.; 11. Update the documentation.; 12. Mirror Git to SVN. Step #4 : Post Move; -------------------. 13. Archive the SVN repository.; 14. Update links on the LLVM website pointing to viewvc/klaus/phab etc. to; point to GitHub instead. GitHub Repository Description; =============================. Monorepo; ----------------. The LLVM git repository hosted at https://github.com/llvm/llvm-project contains all; sub-projects in a single source tree. It is often referred to as a monorepo and; mimics an export of the current SVN repository, with each sub-project having its; own top-level directory. Not all sub-projects are used for building toolchains.; For example, www/ and test-suite/ are not part of the monorepo. Putting all sub-projects in a single checkout makes cross-project refactoring; naturally simple:. * New sub-projects can be trivially split out for better reuse and/or layering; (e.g., to allow libSupport and/or LIT to be used by runtimes without adding a; dependency on LLVM).; * Changing an API in LLVM and upgrading the sub-projects will always be done in; a single commit, designing away a common source of temporary build breakage.; * Moving code across sub-project (during refactoring for instance) in a single; commit enables accurate `git blame` when tracking code change history.; * Tooling based on `git grep` works natively across sub-projects, allowing to; easier find refactoring opportunities across projects (for example reusing a; datastructure initially in LLDB by moving it into libSupport).; * Having all the sources present encourages maintaining the other sub-projects; when changing API. Finally, the monorepo maintains the property of the existing SVN repository that; the sub-projects move synchronously, and a single revisi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:9300,Modifiability,refactor,refactoring,9300,"ead. GitHub Repository Description; =============================. Monorepo; ----------------. The LLVM git repository hosted at https://github.com/llvm/llvm-project contains all; sub-projects in a single source tree. It is often referred to as a monorepo and; mimics an export of the current SVN repository, with each sub-project having its; own top-level directory. Not all sub-projects are used for building toolchains.; For example, www/ and test-suite/ are not part of the monorepo. Putting all sub-projects in a single checkout makes cross-project refactoring; naturally simple:. * New sub-projects can be trivially split out for better reuse and/or layering; (e.g., to allow libSupport and/or LIT to be used by runtimes without adding a; dependency on LLVM).; * Changing an API in LLVM and upgrading the sub-projects will always be done in; a single commit, designing away a common source of temporary build breakage.; * Moving code across sub-project (during refactoring for instance) in a single; commit enables accurate `git blame` when tracking code change history.; * Tooling based on `git grep` works natively across sub-projects, allowing to; easier find refactoring opportunities across projects (for example reusing a; datastructure initially in LLDB by moving it into libSupport).; * Having all the sources present encourages maintaining the other sub-projects; when changing API. Finally, the monorepo maintains the property of the existing SVN repository that; the sub-projects move synchronously, and a single revision number (or commit; hash) identifies the state of the development across all projects. .. _build_single_project:. Building a single sub-project; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Even though there is a single source tree, you are not required to build; all sub-projects together. It is trivial to configure builds for a single; sub-project. For example::. mkdir build && cd build; # Configure only LLVM (default); cmake path/to/monorepo; # Configure LLVM and lld; c",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:9502,Modifiability,refactor,refactoring,9502,"ojects in a single source tree. It is often referred to as a monorepo and; mimics an export of the current SVN repository, with each sub-project having its; own top-level directory. Not all sub-projects are used for building toolchains.; For example, www/ and test-suite/ are not part of the monorepo. Putting all sub-projects in a single checkout makes cross-project refactoring; naturally simple:. * New sub-projects can be trivially split out for better reuse and/or layering; (e.g., to allow libSupport and/or LIT to be used by runtimes without adding a; dependency on LLVM).; * Changing an API in LLVM and upgrading the sub-projects will always be done in; a single commit, designing away a common source of temporary build breakage.; * Moving code across sub-project (during refactoring for instance) in a single; commit enables accurate `git blame` when tracking code change history.; * Tooling based on `git grep` works natively across sub-projects, allowing to; easier find refactoring opportunities across projects (for example reusing a; datastructure initially in LLDB by moving it into libSupport).; * Having all the sources present encourages maintaining the other sub-projects; when changing API. Finally, the monorepo maintains the property of the existing SVN repository that; the sub-projects move synchronously, and a single revision number (or commit; hash) identifies the state of the development across all projects. .. _build_single_project:. Building a single sub-project; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Even though there is a single source tree, you are not required to build; all sub-projects together. It is trivial to configure builds for a single; sub-project. For example::. mkdir build && cd build; # Configure only LLVM (default); cmake path/to/monorepo; # Configure LLVM and lld; cmake path/to/monorepo -DLLVM_ENABLE_PROJECTS=lld; # Configure LLVM and clang; cmake path/to/monorepo -DLLVM_ENABLE_PROJECTS=clang. .. _git-svn-mirror:. Outstanding Questions; ------------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:10165,Modifiability,config,configure,10165,"in; a single commit, designing away a common source of temporary build breakage.; * Moving code across sub-project (during refactoring for instance) in a single; commit enables accurate `git blame` when tracking code change history.; * Tooling based on `git grep` works natively across sub-projects, allowing to; easier find refactoring opportunities across projects (for example reusing a; datastructure initially in LLDB by moving it into libSupport).; * Having all the sources present encourages maintaining the other sub-projects; when changing API. Finally, the monorepo maintains the property of the existing SVN repository that; the sub-projects move synchronously, and a single revision number (or commit; hash) identifies the state of the development across all projects. .. _build_single_project:. Building a single sub-project; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Even though there is a single source tree, you are not required to build; all sub-projects together. It is trivial to configure builds for a single; sub-project. For example::. mkdir build && cd build; # Configure only LLVM (default); cmake path/to/monorepo; # Configure LLVM and lld; cmake path/to/monorepo -DLLVM_ENABLE_PROJECTS=lld; # Configure LLVM and clang; cmake path/to/monorepo -DLLVM_ENABLE_PROJECTS=clang. .. _git-svn-mirror:. Outstanding Questions; ---------------------. Read-only sub-project mirrors; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. With the Monorepo, it is undecided whether the existing single-subproject; mirrors (e.g. https://git.llvm.org/git/compiler-rt.git) will continue to; be maintained. Read/write SVN bridge; ^^^^^^^^^^^^^^^^^^^^^. GitHub supports a read/write SVN bridge for its repositories. However,; there have been issues with this bridge working correctly in the past,; so it's not clear if this is something that will be supported going forward. Monorepo Drawbacks; ------------------. * Using the monolithic repository may add overhead for those contributing to a; standalone sub-project, particula",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:13173,Modifiability,config,config,13173," <workflow-checkout-commit>`.; * :ref:`Checkout/Clone Multiple Projects, with Commit Access <workflow-monocheckout-multicommit>`.; * :ref:`Commit an API Change in LLVM and Update the Sub-projects <workflow-cross-repo-commit>`.; * :ref:`Branching/Stashing/Updating for Local Development or Experiments <workflow-mono-branching>`.; * :ref:`Bisecting <workflow-mono-bisecting>`. Workflow Before/After; =====================. This section goes through a few examples of workflows, intended to illustrate; how end-users or developers would interact with the repository for; various use-cases. .. _workflow-checkout-commit:. Checkout/Clone a Single Project, with Commit Access; ---------------------------------------------------. Currently; ^^^^^^^^^. ::. # direct SVN checkout; svn co https://user@llvm.org/svn/llvm-project/llvm/trunk llvm; # or using the read-only Git view, with git-svn; git clone https://llvm.org/git/llvm.git; cd llvm; git svn init https://llvm.org/svn/llvm-project/llvm/trunk --username=<username>; git config svn-remote.svn.fetch :refs/remotes/origin/main; git svn rebase -l # -l avoids fetching ahead of the git mirror. Commits are performed using `svn commit` or with the sequence `git commit` and; `git svn dcommit`. .. _workflow-multicheckout-nocommit:. Monorepo Variant; ^^^^^^^^^^^^^^^^. With the monorepo variant, there are a few options, depending on your; constraints. First, you could just clone the full repository:. git clone https://github.com/llvm/llvm-project.git. At this point you have every sub-project (llvm, clang, lld, lldb, ...), which; :ref:`doesn't imply you have to build all of them <build_single_project>`. You; can still build only compiler-rt for instance. In this way it's not different; from someone who would check out all the projects with SVN today. If you want to avoid checking out all the sources, you can hide the other; directories using a Git sparse checkout::. git config core.sparseCheckout true; echo /compiler-rt > .git/info/sparse-checko",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:14077,Modifiability,config,config,14077,"d llvm; git svn init https://llvm.org/svn/llvm-project/llvm/trunk --username=<username>; git config svn-remote.svn.fetch :refs/remotes/origin/main; git svn rebase -l # -l avoids fetching ahead of the git mirror. Commits are performed using `svn commit` or with the sequence `git commit` and; `git svn dcommit`. .. _workflow-multicheckout-nocommit:. Monorepo Variant; ^^^^^^^^^^^^^^^^. With the monorepo variant, there are a few options, depending on your; constraints. First, you could just clone the full repository:. git clone https://github.com/llvm/llvm-project.git. At this point you have every sub-project (llvm, clang, lld, lldb, ...), which; :ref:`doesn't imply you have to build all of them <build_single_project>`. You; can still build only compiler-rt for instance. In this way it's not different; from someone who would check out all the projects with SVN today. If you want to avoid checking out all the sources, you can hide the other; directories using a Git sparse checkout::. git config core.sparseCheckout true; echo /compiler-rt > .git/info/sparse-checkout; git read-tree -mu HEAD. The data for all sub-projects is still in your `.git` directory, but in your; checkout, you only see `compiler-rt`.; Before you push, you'll need to fetch and rebase (`git pull --rebase`) as; usual. Note that when you fetch you'll likely pull in changes to sub-projects you don't; care about. If you are using sparse checkout, the files from other projects; won't appear on your disk. The only effect is that your commit hash changes. You can check whether the changes in the last fetch are relevant to your commit; by running::. git log origin/main@{1}..origin/main -- libcxx. This command can be hidden in a script so that `git llvmpush` would perform all; these steps, fail only if such a dependent change exists, and show immediately; the change that prevented the push. An immediate repeat of the command would; (almost) certainly result in a successful push.; Note that today with SVN or git-sv",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:15800,Modifiability,config,config,15800,"hidden in a script so that `git llvmpush` would perform all; these steps, fail only if such a dependent change exists, and show immediately; the change that prevented the push. An immediate repeat of the command would; (almost) certainly result in a successful push.; Note that today with SVN or git-svn, this step is not possible since the; ""rebase"" implicitly happens while committing (unless a conflict occurs). Checkout/Clone Multiple Projects, with Commit Access; ----------------------------------------------------. Let's look how to assemble llvm+clang+libcxx at a given revision. Currently; ^^^^^^^^^. ::. svn co https://llvm.org/svn/llvm-project/llvm/trunk llvm -r $REVISION; cd llvm/tools; svn co https://llvm.org/svn/llvm-project/clang/trunk clang -r $REVISION; cd ../projects; svn co https://llvm.org/svn/llvm-project/libcxx/trunk libcxx -r $REVISION. Or using git-svn::. git clone https://llvm.org/git/llvm.git; cd llvm/; git svn init https://llvm.org/svn/llvm-project/llvm/trunk --username=<username>; git config svn-remote.svn.fetch :refs/remotes/origin/main; git svn rebase -l; git checkout `git svn find-rev -B r258109`; cd tools; git clone https://llvm.org/git/clang.git; cd clang/; git svn init https://llvm.org/svn/llvm-project/clang/trunk --username=<username>; git config svn-remote.svn.fetch :refs/remotes/origin/main; git svn rebase -l; git checkout `git svn find-rev -B r258109`; cd ../../projects/; git clone https://llvm.org/git/libcxx.git; cd libcxx; git svn init https://llvm.org/svn/llvm-project/libcxx/trunk --username=<username>; git config svn-remote.svn.fetch :refs/remotes/origin/main; git svn rebase -l; git checkout `git svn find-rev -B r258109`. Note that the list would be longer with more sub-projects. .. _workflow-monocheckout-multicommit:. Monorepo Variant; ^^^^^^^^^^^^^^^^. The repository contains natively the source for every sub-projects at the right; revision, which makes this straightforward::. git clone https://github.com/llvm/llvm-project.git; cd",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:16067,Modifiability,config,config,16067," Note that today with SVN or git-svn, this step is not possible since the; ""rebase"" implicitly happens while committing (unless a conflict occurs). Checkout/Clone Multiple Projects, with Commit Access; ----------------------------------------------------. Let's look how to assemble llvm+clang+libcxx at a given revision. Currently; ^^^^^^^^^. ::. svn co https://llvm.org/svn/llvm-project/llvm/trunk llvm -r $REVISION; cd llvm/tools; svn co https://llvm.org/svn/llvm-project/clang/trunk clang -r $REVISION; cd ../projects; svn co https://llvm.org/svn/llvm-project/libcxx/trunk libcxx -r $REVISION. Or using git-svn::. git clone https://llvm.org/git/llvm.git; cd llvm/; git svn init https://llvm.org/svn/llvm-project/llvm/trunk --username=<username>; git config svn-remote.svn.fetch :refs/remotes/origin/main; git svn rebase -l; git checkout `git svn find-rev -B r258109`; cd tools; git clone https://llvm.org/git/clang.git; cd clang/; git svn init https://llvm.org/svn/llvm-project/clang/trunk --username=<username>; git config svn-remote.svn.fetch :refs/remotes/origin/main; git svn rebase -l; git checkout `git svn find-rev -B r258109`; cd ../../projects/; git clone https://llvm.org/git/libcxx.git; cd libcxx; git svn init https://llvm.org/svn/llvm-project/libcxx/trunk --username=<username>; git config svn-remote.svn.fetch :refs/remotes/origin/main; git svn rebase -l; git checkout `git svn find-rev -B r258109`. Note that the list would be longer with more sub-projects. .. _workflow-monocheckout-multicommit:. Monorepo Variant; ^^^^^^^^^^^^^^^^. The repository contains natively the source for every sub-projects at the right; revision, which makes this straightforward::. git clone https://github.com/llvm/llvm-project.git; cd llvm-projects; git checkout $REVISION. As before, at this point clang, llvm, and libcxx are stored in directories; alongside each other. .. _workflow-cross-repo-commit:. Commit an API Change in LLVM and Update the Sub-projects; -------------------------------------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:16346,Modifiability,config,config,16346,"mble llvm+clang+libcxx at a given revision. Currently; ^^^^^^^^^. ::. svn co https://llvm.org/svn/llvm-project/llvm/trunk llvm -r $REVISION; cd llvm/tools; svn co https://llvm.org/svn/llvm-project/clang/trunk clang -r $REVISION; cd ../projects; svn co https://llvm.org/svn/llvm-project/libcxx/trunk libcxx -r $REVISION. Or using git-svn::. git clone https://llvm.org/git/llvm.git; cd llvm/; git svn init https://llvm.org/svn/llvm-project/llvm/trunk --username=<username>; git config svn-remote.svn.fetch :refs/remotes/origin/main; git svn rebase -l; git checkout `git svn find-rev -B r258109`; cd tools; git clone https://llvm.org/git/clang.git; cd clang/; git svn init https://llvm.org/svn/llvm-project/clang/trunk --username=<username>; git config svn-remote.svn.fetch :refs/remotes/origin/main; git svn rebase -l; git checkout `git svn find-rev -B r258109`; cd ../../projects/; git clone https://llvm.org/git/libcxx.git; cd libcxx; git svn init https://llvm.org/svn/llvm-project/libcxx/trunk --username=<username>; git config svn-remote.svn.fetch :refs/remotes/origin/main; git svn rebase -l; git checkout `git svn find-rev -B r258109`. Note that the list would be longer with more sub-projects. .. _workflow-monocheckout-multicommit:. Monorepo Variant; ^^^^^^^^^^^^^^^^. The repository contains natively the source for every sub-projects at the right; revision, which makes this straightforward::. git clone https://github.com/llvm/llvm-project.git; cd llvm-projects; git checkout $REVISION. As before, at this point clang, llvm, and libcxx are stored in directories; alongside each other. .. _workflow-cross-repo-commit:. Commit an API Change in LLVM and Update the Sub-projects; --------------------------------------------------------. Today this is possible, even though not common (at least not documented) for; subversion users and for git-svn users. For example, few Git users try to update; LLD or Clang in the same commit as they change an LLVM API. The multirepo variant does not address",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:21453,Modifiability,rewrite,rewrite,21453,"igrate-downstream-fork.py`` are in the; Python script and are expanded on below to a more general recipe::. # Make a repository which will become your final local mirror of the; # monorepo.; mkdir my-monorepo; git -C my-monorepo init. # Add a remote to the monorepo.; git -C my-monorepo remote add upstream/monorepo https://github.com/llvm/llvm-project.git. # Add remotes for each git mirror you use, from upstream as well as; # your local mirror. All projects are listed here but you need only; # import those for which you have local branches.; my_projects=( clang; clang-tools-extra; compiler-rt; debuginfo-tests; libcxx; libcxxabi; libunwind; lld; lldb; llvm; openmp; polly ); for p in ${my_projects[@]}; do; git -C my-monorepo remote add upstream/split/${p} https://github.com/llvm-mirror/${p}.git; git -C my-monorepo remote add local/split/${p} https://my.local.mirror.org/${p}.git; done. # Pull in all the commits.; git -C my-monorepo fetch --all. # Run migrate-downstream-fork to rewrite local branches on top of; # the upstream monorepo.; (; cd my-monorepo; migrate-downstream-fork.py \; refs/remotes/local \; refs/tags \; --new-repo-prefix=refs/remotes/upstream/monorepo \; --old-repo-prefix=refs/remotes/upstream/split \; --source-kind=split \; --revmap-out=monorepo-map.txt; ). # Octopus-merge the resulting local split histories to unify them. # Assumes local work on local split mirrors is on main (and; # upstream is presumably represented by some other branch like; # upstream/main).; my_local_branch=""main"". git -C my-monorepo branch --no-track local/octopus/main \; $(git -C my-monorepo merge-base refs/remotes/upstream/monorepo/main \; refs/remotes/local/split/llvm/${my_local_branch}); git -C my-monorepo checkout local/octopus/${my_local_branch}. subproject_branches=(); for p in ${my_projects[@]}; do; subproject_branch=${p}/local/monorepo/${my_local_branch}; git -C my-monorepo branch ${subproject_branch} \; refs/remotes/local/split/${p}/${my_local_branch}; if [[ ""${p}"" != ""l",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:29571,Modifiability,rewrite,rewrite,29571,"downstream-fork.py`` run).; for project in ${subprojects[@]}; do; git remote add local/split/${project} \; https://my.local.mirror.org/${subproject}.git; git fetch local/split/${project}; done. # Import umbrella history.; git -C my-monorepo remote add umbrella \; https://my.local.mirror.org/umbrella.git; git fetch umbrella. # Put myproj in local/myproj; echo ""myproj local/myproj"" > my-monorepo/submodule-map.txt. # Rewrite history; (; cd my-monorepo; zip-downstream-fork.py \; refs/remotes/umbrella \; --new-repo-prefix=refs/remotes/upstream/monorepo \; --old-repo-prefix=refs/remotes/upstream/split \; --revmap-in=monorepo-map.txt \; --revmap-out=zip-map.txt \; --subdir=local \; --submodule-map=submodule-map.txt \; --update-tags; ). # Create the zip branch (assuming umbrella main is wanted).; git -C my-monorepo branch --no-track local/zip/main refs/remotes/umbrella/main. Note that if the umbrella has submodules to non-LLVM repositories,; ``zip-downstream-fork.py`` needs to know about them to be able to; rewrite commits. That is why the first step above is to fetch commits; from such repositories. With ``--update-tags`` the tool will migrate annotated tags pointing; to submodule commits that were inlined into the zipped history. If; the umbrella pulled in an upstream commit that happened to have a tag; pointing to it, that tag will be migrated, which is almost certainly; not what is wanted. The tag can always be moved back to its original; commit after rewriting, or the ``--update-tags`` option may be; discarded and any local tags would then be migrated manually. **Example 2: Nested sources layout**. The tool handles nested submodules (e.g. llvm is a submodule in; umbrella and clang is a submodule in llvm). The file; ``submodule-map.txt`` is a list of pairs, one per line. The first; pair item describes the path to a submodule in the umbrella; repository. The second pair item describes the path where trees for; that submodule should be written in the zipped history. Let's ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:34524,Modifiability,extend,extending,34524," my-monorepo/submodule-map.txt; echo ""tools/lldb lldb"" >> my-monorepo/submodule-map.txt; echo ""projects/openmp openmp"" >> my-monorepo/submodule-map.txt; echo ""tools/polly polly"" >> my-monorepo/submodule-map.txt; echo ""projects/myproj local/myproj"" >> my-monorepo/submodule-map.txt. # Rewrite history; (; cd my-monorepo; zip-downstream-fork.py \; refs/remotes/umbrella \; --new-repo-prefix=refs/remotes/upstream/monorepo \; --old-repo-prefix=refs/remotes/upstream/split \; --revmap-in=monorepo-map.txt \; --revmap-out=zip-map.txt \; --subdir=llvm \; --submodule-map=submodule-map.txt \; --update-tags; ). # Create the zip branch (assuming umbrella main is wanted).; git -C my-monorepo branch --no-track local/zip/main refs/remotes/umbrella/main. Comments at the top of ``zip-downstream-fork.py`` describe in more; detail how the tool works and various implications of its operation. Importing local repositories; ----------------------------. You may have additional repositories that integrate with the LLVM; ecosystem, essentially extending it with new tools. If such; repositories are tightly coupled with LLVM, it may make sense to; import them into your local mirror of the monorepo. If such repositories participated in the umbrella repository used; during the zipping process above, they will automatically be added to; the monorepo. For downstream repositories that don't participate in; an umbrella setup, the ``import-downstream-repo.py`` tool at; https://github.com/greened/llvm-git-migration/tree/import can help with; getting them into the monorepo. A recipe follows::. # Import downstream repo history into the monorepo.; git -C my-monorepo remote add myrepo https://my.local.mirror.org/myrepo.git; git fetch myrepo. my_local_tags=( refs/tags/release; refs/tags/hotfix ). (; cd my-monorepo; import-downstream-repo.py \; refs/remotes/myrepo \; ${my_local_tags[@]} \; --new-repo-prefix=refs/remotes/upstream/monorepo \; --subdir=myrepo \; --tag-prefix=""myrepo-""; ). # Preserve release branc",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:3470,Performance,load,load,3470,"s being stored in a SVN server, these developers are already using Git; through the Git-SVN integration. Git allows you to:. * Commit, squash, merge, and fork locally without touching the remote server.; * Maintain local branches, enabling multiple threads of development.; * Collaborate on these branches (e.g. through your own fork of llvm on GitHub).; * Inspect the repository history (blame, log, bisect) without Internet access.; * Maintain remote forks and branches on Git hosting services and; integrate back to the main repository. In addition, because Git seems to be replacing many OSS projects' version; control systems, there are many tools that are built over Git.; Future tooling may support Git first (if not only). Why GitHub?; -----------. GitHub, like GitLab and BitBucket, provides free code hosting for open source; projects. Any of these could replace the code-hosting infrastructure that we; have today. These services also have a dedicated team to monitor, migrate, improve and; distribute the contents of the repositories depending on region and load. GitHub has one important advantage over GitLab and; BitBucket: it offers read-write **SVN** access to the repository; (https://github.com/blog/626-announcing-svn-support).; This would enable people to continue working post-migration as though our code; were still canonically in an SVN repository. In addition, there are already multiple LLVM mirrors on GitHub, indicating that; part of our community has already settled there. On Managing Revision Numbers with Git; -------------------------------------. The current SVN repository hosts all the LLVM sub-projects alongside each other.; A single revision number (e.g. r123456) thus identifies a consistent version of; all LLVM sub-projects. Git does not use sequential integer revision number but instead uses a hash to; identify each commit. The loss of a sequential integer revision number has been a sticking point in; past discussions about Git:. - ""The 'branch' I most",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:13304,Performance,perform,performed,13304,"rojects <workflow-cross-repo-commit>`.; * :ref:`Branching/Stashing/Updating for Local Development or Experiments <workflow-mono-branching>`.; * :ref:`Bisecting <workflow-mono-bisecting>`. Workflow Before/After; =====================. This section goes through a few examples of workflows, intended to illustrate; how end-users or developers would interact with the repository for; various use-cases. .. _workflow-checkout-commit:. Checkout/Clone a Single Project, with Commit Access; ---------------------------------------------------. Currently; ^^^^^^^^^. ::. # direct SVN checkout; svn co https://user@llvm.org/svn/llvm-project/llvm/trunk llvm; # or using the read-only Git view, with git-svn; git clone https://llvm.org/git/llvm.git; cd llvm; git svn init https://llvm.org/svn/llvm-project/llvm/trunk --username=<username>; git config svn-remote.svn.fetch :refs/remotes/origin/main; git svn rebase -l # -l avoids fetching ahead of the git mirror. Commits are performed using `svn commit` or with the sequence `git commit` and; `git svn dcommit`. .. _workflow-multicheckout-nocommit:. Monorepo Variant; ^^^^^^^^^^^^^^^^. With the monorepo variant, there are a few options, depending on your; constraints. First, you could just clone the full repository:. git clone https://github.com/llvm/llvm-project.git. At this point you have every sub-project (llvm, clang, lld, lldb, ...), which; :ref:`doesn't imply you have to build all of them <build_single_project>`. You; can still build only compiler-rt for instance. In this way it's not different; from someone who would check out all the projects with SVN today. If you want to avoid checking out all the sources, you can hide the other; directories using a Git sparse checkout::. git config core.sparseCheckout true; echo /compiler-rt > .git/info/sparse-checkout; git read-tree -mu HEAD. The data for all sub-projects is still in your `.git` directory, but in your; checkout, you only see `compiler-rt`.; Before you push, you'll need to fetch and r",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:14827,Performance,perform,perform,14827," In this way it's not different; from someone who would check out all the projects with SVN today. If you want to avoid checking out all the sources, you can hide the other; directories using a Git sparse checkout::. git config core.sparseCheckout true; echo /compiler-rt > .git/info/sparse-checkout; git read-tree -mu HEAD. The data for all sub-projects is still in your `.git` directory, but in your; checkout, you only see `compiler-rt`.; Before you push, you'll need to fetch and rebase (`git pull --rebase`) as; usual. Note that when you fetch you'll likely pull in changes to sub-projects you don't; care about. If you are using sparse checkout, the files from other projects; won't appear on your disk. The only effect is that your commit hash changes. You can check whether the changes in the last fetch are relevant to your commit; by running::. git log origin/main@{1}..origin/main -- libcxx. This command can be hidden in a script so that `git llvmpush` would perform all; these steps, fail only if such a dependent change exists, and show immediately; the change that prevented the push. An immediate repeat of the command would; (almost) certainly result in a successful push.; Note that today with SVN or git-svn, this step is not possible since the; ""rebase"" implicitly happens while committing (unless a conflict occurs). Checkout/Clone Multiple Projects, with Commit Access; ----------------------------------------------------. Let's look how to assemble llvm+clang+libcxx at a given revision. Currently; ^^^^^^^^^. ::. svn co https://llvm.org/svn/llvm-project/llvm/trunk llvm -r $REVISION; cd llvm/tools; svn co https://llvm.org/svn/llvm-project/clang/trunk clang -r $REVISION; cd ../projects; svn co https://llvm.org/svn/llvm-project/libcxx/trunk libcxx -r $REVISION. Or using git-svn::. git clone https://llvm.org/git/llvm.git; cd llvm/; git svn init https://llvm.org/svn/llvm-project/llvm/trunk --username=<username>; git config svn-remote.svn.fetch :refs/remotes/origin/main; gi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:5917,Safety,avoid,avoid,5917,"in...', that's a; non-trivial issue."" [JSonnRevNum]_; - ""Sequential IDs are important for LNT and llvmlab bisection tool."" [MatthewsRevNum]_. However, Git can emulate this increasing revision number:; ``git rev-list --count <commit-hash>``. This identifier is unique only; within a single branch, but this means the tuple `(num, branch-name)` uniquely; identifies a commit. We can thus use this revision number to ensure that e.g. `clang -v` reports a; user-friendly revision number (e.g. `main-12345` or `4.0-5321`), addressing; the objections raised above with respect to this aspect of Git. What About Branches and Merges?; -------------------------------. In contrast to SVN, Git makes branching easy. Git's commit history is; represented as a DAG, a departure from SVN's linear history. However, we propose; to mandate making merge commits illegal in our canonical Git repository. Unfortunately, GitHub does not support server side hooks to enforce such a; policy. We must rely on the community to avoid pushing merge commits. GitHub offers a feature called `Status Checks`: a branch protected by; `status checks` requires commits to be explicitly allowed before the push can happen.; We could supply a pre-push hook on the client side that would run and check the; history, before allowing the commit being pushed [statuschecks]_.; However this solution would be somewhat fragile (how do you update a script; installed on every developer machine?) and prevents SVN access to the; repository. What About Commit Emails?; -------------------------. We will need a new bot to send emails for each commit. This proposal leaves the; email format unchanged besides the commit URL. Straw Man Migration Plan; ========================. Step #1 : Before The Move; -------------------------. 1. Update docs to mention the move, so people are aware of what is going on.; 2. Set up a read-only version of the GitHub project, mirroring our current SVN; repository.; 3. Add the required bots to implement the c",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:13251,Safety,avoid,avoids,13251," <workflow-monocheckout-multicommit>`.; * :ref:`Commit an API Change in LLVM and Update the Sub-projects <workflow-cross-repo-commit>`.; * :ref:`Branching/Stashing/Updating for Local Development or Experiments <workflow-mono-branching>`.; * :ref:`Bisecting <workflow-mono-bisecting>`. Workflow Before/After; =====================. This section goes through a few examples of workflows, intended to illustrate; how end-users or developers would interact with the repository for; various use-cases. .. _workflow-checkout-commit:. Checkout/Clone a Single Project, with Commit Access; ---------------------------------------------------. Currently; ^^^^^^^^^. ::. # direct SVN checkout; svn co https://user@llvm.org/svn/llvm-project/llvm/trunk llvm; # or using the read-only Git view, with git-svn; git clone https://llvm.org/git/llvm.git; cd llvm; git svn init https://llvm.org/svn/llvm-project/llvm/trunk --username=<username>; git config svn-remote.svn.fetch :refs/remotes/origin/main; git svn rebase -l # -l avoids fetching ahead of the git mirror. Commits are performed using `svn commit` or with the sequence `git commit` and; `git svn dcommit`. .. _workflow-multicheckout-nocommit:. Monorepo Variant; ^^^^^^^^^^^^^^^^. With the monorepo variant, there are a few options, depending on your; constraints. First, you could just clone the full repository:. git clone https://github.com/llvm/llvm-project.git. At this point you have every sub-project (llvm, clang, lld, lldb, ...), which; :ref:`doesn't imply you have to build all of them <build_single_project>`. You; can still build only compiler-rt for instance. In this way it's not different; from someone who would check out all the projects with SVN today. If you want to avoid checking out all the sources, you can hide the other; directories using a Git sparse checkout::. git config core.sparseCheckout true; echo /compiler-rt > .git/info/sparse-checkout; git read-tree -mu HEAD. The data for all sub-projects is still in your `.git` director",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:13970,Safety,avoid,avoid,13970," Git view, with git-svn; git clone https://llvm.org/git/llvm.git; cd llvm; git svn init https://llvm.org/svn/llvm-project/llvm/trunk --username=<username>; git config svn-remote.svn.fetch :refs/remotes/origin/main; git svn rebase -l # -l avoids fetching ahead of the git mirror. Commits are performed using `svn commit` or with the sequence `git commit` and; `git svn dcommit`. .. _workflow-multicheckout-nocommit:. Monorepo Variant; ^^^^^^^^^^^^^^^^. With the monorepo variant, there are a few options, depending on your; constraints. First, you could just clone the full repository:. git clone https://github.com/llvm/llvm-project.git. At this point you have every sub-project (llvm, clang, lld, lldb, ...), which; :ref:`doesn't imply you have to build all of them <build_single_project>`. You; can still build only compiler-rt for instance. In this way it's not different; from someone who would check out all the projects with SVN today. If you want to avoid checking out all the sources, you can hide the other; directories using a Git sparse checkout::. git config core.sparseCheckout true; echo /compiler-rt > .git/info/sparse-checkout; git read-tree -mu HEAD. The data for all sub-projects is still in your `.git` directory, but in your; checkout, you only see `compiler-rt`.; Before you push, you'll need to fetch and rebase (`git pull --rebase`) as; usual. Note that when you fetch you'll likely pull in changes to sub-projects you don't; care about. If you are using sparse checkout, the files from other projects; won't appear on your disk. The only effect is that your commit hash changes. You can check whether the changes in the last fetch are relevant to your commit; by running::. git log origin/main@{1}..origin/main -- libcxx. This command can be hidden in a script so that `git llvmpush` would perform all; these steps, fail only if such a dependent change exists, and show immediately; the change that prevented the push. An immediate repeat of the command would; (almost) certai",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:25705,Safety,redund,redundant,25705,"ript update. Commit ``UM8``; updates a submodule of local project ``myproj``. The tool ``zip-downstream-fork.py`` at; https://github.com/greened/llvm-git-migration/tree/zip can be used to; convert the umbrella history into a monorepo-based history with; commits in the order implied by submodule updates::. U1 - U2 - U3 <- upstream/main; \ \ \; \ -----\--------------- local/zip--.; \ \ \ |; - Lllvm1 - Llld1 - UM3 - Lclang1 - Lclang2 - Lllvm2 - Llld2 - Lmyproj1 <-'. The ``U*`` commits represent upstream commits to the monorepo main; branch. Each submodule update in the local ``UM*`` commits brought in; a subproject tree at some local commit. The trees in the ``L*1``; commits represent merges from upstream. These result in edges from; the ``U*`` commits to their corresponding rewritten ``L*1`` commits.; The ``L*2`` commits did not do any merges from upstream. Note that the merge from ``U2`` to ``Lclang1`` appears redundant, but; if, say, ``U3`` changed some files in upstream clang, the ``Lclang1``; commit appearing after the ``Llld1`` commit would actually represent a; clang tree *earlier* in the upstream clang history. We want the; ``local/zip`` branch to accurately represent the state of our umbrella; history and so the edge ``U2 -> Lclang1`` is a visual reminder of what; clang's tree actually looks like in ``Lclang1``. Even so, the edge ``U3 -> Llld1`` could be problematic for future; merges from upstream. git will think that we've already merged from; ``U3``, and we have, except for the state of the clang tree. One; possible mitigation strategy is to manually diff clang between ``U2``; and ``U3`` and apply those updates to ``local/zip``. Another,; possibly simpler strategy is to freeze local work on downstream; branches and merge all submodules from the latest upstream before; running ``zip-downstream-fork.py``. If downstream merged each project; from upstream in lockstep without any intervening local commits, then; things should be fine without any special action. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:27247,Safety,safe,safe,27247,"e of the clang tree. One; possible mitigation strategy is to manually diff clang between ``U2``; and ``U3`` and apply those updates to ``local/zip``. Another,; possibly simpler strategy is to freeze local work on downstream; branches and merge all submodules from the latest upstream before; running ``zip-downstream-fork.py``. If downstream merged each project; from upstream in lockstep without any intervening local commits, then; things should be fine without any special action. We anticipate this; to be the common case. The tree for ``Lclang1`` outside of clang will represent the state of; things at ``U3`` since all of the upstream projects not participating; in the umbrella history should be in a state respecting the commit; ``U3``. The trees for llvm and lld should correctly represent commits; ``Lllvm1`` and ``Llld1``, respectively. Commit ``UM3`` changed files not related to submodules and we need; somewhere to put them. It is not safe in general to put them in the; monorepo root directory because they may conflict with files in the; monorepo. Let's assume we want them in a directory ``local`` in the; monorepo. **Example 1: Umbrella looks like the monorepo**. For this example, we'll assume that each subproject appears in its own; top-level directory in the umbrella, just as they do in the monorepo .; Let's also assume that we want the files in directory ``myproj`` to; appear in ``local/myproj``. Given the above run of ``migrate-downstream-fork.py``, a recipe to; create the zipped history is below::. # Import any non-LLVM repositories the umbrella references.; git -C my-monorepo remote add localrepo \; https://my.local.mirror.org/localrepo.git; git fetch localrepo. subprojects=( clang clang-tools-extra compiler-rt debuginfo-tests libclc; libcxx libcxxabi libunwind lld lldb llgo llvm openmp; parallel-libs polly pstl ). # Import histories for upstream split projects (this was probably; # already done for the ``migrate-downstream-fork.py`` run).; for project in ${sub",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:656,Security,validat,validation,656,"==============================; Moving LLVM Projects to GitHub; ==============================. Current Status; ==============. We are planning to complete the transition to GitHub by Oct 21, 2019. See; the GitHub migration `status page <https://llvm.org/GitHubMigrationStatus.html>`_; for the latest updates and instructions for how to migrate your workflows. .. contents:: Table of Contents; :depth: 4; :local:. Introduction; ============. This is a proposal to move our current revision control system from our own; hosted Subversion to GitHub. Below are the financial and technical arguments as; to why we are proposing such a move and how people (and validation; infrastructure) will continue to work with a Git-based LLVM. What This Proposal is *Not* About; =================================. Changing the development policy. This proposal relates only to moving the hosting of our source-code repository; from SVN hosted on our own servers to Git hosted on GitHub. We are not proposing; using GitHub's issue tracker, pull-requests, or code-review. Contributors will continue to earn commit access on demand under the Developer; Policy, except that that a GitHub account will be required instead of SVN; username/password-hash. Why Git, and Why GitHub?; ========================. Why Move At All?; ----------------. This discussion began because we currently host our own Subversion server; and Git mirror on a voluntary basis. The LLVM Foundation sponsors the server and; provides limited support, but there is only so much it can do. Volunteers are not sysadmins themselves, but compiler engineers that happen; to know a thing or two about hosting servers. We also don't have 24/7 support,; and we sometimes wake up to see that continuous integration is broken because; the SVN server is either down or unresponsive. We should take advantage of one of the services out there (GitHub, GitLab,; and BitBucket, among others) that offer better service (24/7 stability, disk; space, Git server, cod",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:1097,Security,access,access,1097," to complete the transition to GitHub by Oct 21, 2019. See; the GitHub migration `status page <https://llvm.org/GitHubMigrationStatus.html>`_; for the latest updates and instructions for how to migrate your workflows. .. contents:: Table of Contents; :depth: 4; :local:. Introduction; ============. This is a proposal to move our current revision control system from our own; hosted Subversion to GitHub. Below are the financial and technical arguments as; to why we are proposing such a move and how people (and validation; infrastructure) will continue to work with a Git-based LLVM. What This Proposal is *Not* About; =================================. Changing the development policy. This proposal relates only to moving the hosting of our source-code repository; from SVN hosted on our own servers to Git hosted on GitHub. We are not proposing; using GitHub's issue tracker, pull-requests, or code-review. Contributors will continue to earn commit access on demand under the Developer; Policy, except that that a GitHub account will be required instead of SVN; username/password-hash. Why Git, and Why GitHub?; ========================. Why Move At All?; ----------------. This discussion began because we currently host our own Subversion server; and Git mirror on a voluntary basis. The LLVM Foundation sponsors the server and; provides limited support, but there is only so much it can do. Volunteers are not sysadmins themselves, but compiler engineers that happen; to know a thing or two about hosting servers. We also don't have 24/7 support,; and we sometimes wake up to see that continuous integration is broken because; the SVN server is either down or unresponsive. We should take advantage of one of the services out there (GitHub, GitLab,; and BitBucket, among others) that offer better service (24/7 stability, disk; space, Git server, code browsing, forking facilities, etc) for free. Why Git?; --------. Many new coders nowadays start with Git, and a lot of people have never used",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:1219,Security,password,password-hash,1219," to complete the transition to GitHub by Oct 21, 2019. See; the GitHub migration `status page <https://llvm.org/GitHubMigrationStatus.html>`_; for the latest updates and instructions for how to migrate your workflows. .. contents:: Table of Contents; :depth: 4; :local:. Introduction; ============. This is a proposal to move our current revision control system from our own; hosted Subversion to GitHub. Below are the financial and technical arguments as; to why we are proposing such a move and how people (and validation; infrastructure) will continue to work with a Git-based LLVM. What This Proposal is *Not* About; =================================. Changing the development policy. This proposal relates only to moving the hosting of our source-code repository; from SVN hosted on our own servers to Git hosted on GitHub. We are not proposing; using GitHub's issue tracker, pull-requests, or code-review. Contributors will continue to earn commit access on demand under the Developer; Policy, except that that a GitHub account will be required instead of SVN; username/password-hash. Why Git, and Why GitHub?; ========================. Why Move At All?; ----------------. This discussion began because we currently host our own Subversion server; and Git mirror on a voluntary basis. The LLVM Foundation sponsors the server and; provides limited support, but there is only so much it can do. Volunteers are not sysadmins themselves, but compiler engineers that happen; to know a thing or two about hosting servers. We also don't have 24/7 support,; and we sometimes wake up to see that continuous integration is broken because; the SVN server is either down or unresponsive. We should take advantage of one of the services out there (GitHub, GitLab,; and BitBucket, among others) that offer better service (24/7 stability, disk; space, Git server, code browsing, forking facilities, etc) for free. Why Git?; --------. Many new coders nowadays start with Git, and a lot of people have never used",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:2826,Security,access,access,2826,"is either down or unresponsive. We should take advantage of one of the services out there (GitHub, GitLab,; and BitBucket, among others) that offer better service (24/7 stability, disk; space, Git server, code browsing, forking facilities, etc) for free. Why Git?; --------. Many new coders nowadays start with Git, and a lot of people have never used; SVN, CVS, or anything else. Websites like GitHub have changed the landscape; of open source contributions, reducing the cost of first contribution and; fostering collaboration. Git is also the version control many LLVM developers use. Despite the; sources being stored in a SVN server, these developers are already using Git; through the Git-SVN integration. Git allows you to:. * Commit, squash, merge, and fork locally without touching the remote server.; * Maintain local branches, enabling multiple threads of development.; * Collaborate on these branches (e.g. through your own fork of llvm on GitHub).; * Inspect the repository history (blame, log, bisect) without Internet access.; * Maintain remote forks and branches on Git hosting services and; integrate back to the main repository. In addition, because Git seems to be replacing many OSS projects' version; control systems, there are many tools that are built over Git.; Future tooling may support Git first (if not only). Why GitHub?; -----------. GitHub, like GitLab and BitBucket, provides free code hosting for open source; projects. Any of these could replace the code-hosting infrastructure that we; have today. These services also have a dedicated team to monitor, migrate, improve and; distribute the contents of the repositories depending on region and load. GitHub has one important advantage over GitLab and; BitBucket: it offers read-write **SVN** access to the repository; (https://github.com/blog/626-announcing-svn-support).; This would enable people to continue working post-migration as though our code; were still canonically in an SVN repository. In addition, there ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:3568,Security,access,access,3568," merge, and fork locally without touching the remote server.; * Maintain local branches, enabling multiple threads of development.; * Collaborate on these branches (e.g. through your own fork of llvm on GitHub).; * Inspect the repository history (blame, log, bisect) without Internet access.; * Maintain remote forks and branches on Git hosting services and; integrate back to the main repository. In addition, because Git seems to be replacing many OSS projects' version; control systems, there are many tools that are built over Git.; Future tooling may support Git first (if not only). Why GitHub?; -----------. GitHub, like GitLab and BitBucket, provides free code hosting for open source; projects. Any of these could replace the code-hosting infrastructure that we; have today. These services also have a dedicated team to monitor, migrate, improve and; distribute the contents of the repositories depending on region and load. GitHub has one important advantage over GitLab and; BitBucket: it offers read-write **SVN** access to the repository; (https://github.com/blog/626-announcing-svn-support).; This would enable people to continue working post-migration as though our code; were still canonically in an SVN repository. In addition, there are already multiple LLVM mirrors on GitHub, indicating that; part of our community has already settled there. On Managing Revision Numbers with Git; -------------------------------------. The current SVN repository hosts all the LLVM sub-projects alongside each other.; A single revision number (e.g. r123456) thus identifies a consistent version of; all LLVM sub-projects. Git does not use sequential integer revision number but instead uses a hash to; identify each commit. The loss of a sequential integer revision number has been a sticking point in; past discussions about Git:. - ""The 'branch' I most care about is mainline, and losing the ability to say; 'fixed in r1234' (with some sort of monotonically increasing number) would; be a tragic",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:4239,Security,hash,hash,4239," for open source; projects. Any of these could replace the code-hosting infrastructure that we; have today. These services also have a dedicated team to monitor, migrate, improve and; distribute the contents of the repositories depending on region and load. GitHub has one important advantage over GitLab and; BitBucket: it offers read-write **SVN** access to the repository; (https://github.com/blog/626-announcing-svn-support).; This would enable people to continue working post-migration as though our code; were still canonically in an SVN repository. In addition, there are already multiple LLVM mirrors on GitHub, indicating that; part of our community has already settled there. On Managing Revision Numbers with Git; -------------------------------------. The current SVN repository hosts all the LLVM sub-projects alongside each other.; A single revision number (e.g. r123456) thus identifies a consistent version of; all LLVM sub-projects. Git does not use sequential integer revision number but instead uses a hash to; identify each commit. The loss of a sequential integer revision number has been a sticking point in; past discussions about Git:. - ""The 'branch' I most care about is mainline, and losing the ability to say; 'fixed in r1234' (with some sort of monotonically increasing number) would; be a tragic loss."" [LattnerRevNum]_; - ""I like those results sorted by time and the chronology should be obvious, but; timestamps are incredibly cumbersome and make it difficult to verify that a; given checkout matches a given set of results."" [TrickRevNum]_; - ""There is still the major regression with unreadable version numbers.; Given the amount of Bugzilla traffic with 'Fixed in...', that's a; non-trivial issue."" [JSonnRevNum]_; - ""Sequential IDs are important for LNT and llvmlab bisection tool."" [MatthewsRevNum]_. However, Git can emulate this increasing revision number:; ``git rev-list --count <commit-hash>``. This identifier is unique only; within a single branch, but thi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:5146,Security,hash,hash,5146,"thus identifies a consistent version of; all LLVM sub-projects. Git does not use sequential integer revision number but instead uses a hash to; identify each commit. The loss of a sequential integer revision number has been a sticking point in; past discussions about Git:. - ""The 'branch' I most care about is mainline, and losing the ability to say; 'fixed in r1234' (with some sort of monotonically increasing number) would; be a tragic loss."" [LattnerRevNum]_; - ""I like those results sorted by time and the chronology should be obvious, but; timestamps are incredibly cumbersome and make it difficult to verify that a; given checkout matches a given set of results."" [TrickRevNum]_; - ""There is still the major regression with unreadable version numbers.; Given the amount of Bugzilla traffic with 'Fixed in...', that's a; non-trivial issue."" [JSonnRevNum]_; - ""Sequential IDs are important for LNT and llvmlab bisection tool."" [MatthewsRevNum]_. However, Git can emulate this increasing revision number:; ``git rev-list --count <commit-hash>``. This identifier is unique only; within a single branch, but this means the tuple `(num, branch-name)` uniquely; identifies a commit. We can thus use this revision number to ensure that e.g. `clang -v` reports a; user-friendly revision number (e.g. `main-12345` or `4.0-5321`), addressing; the objections raised above with respect to this aspect of Git. What About Branches and Merges?; -------------------------------. In contrast to SVN, Git makes branching easy. Git's commit history is; represented as a DAG, a departure from SVN's linear history. However, we propose; to mandate making merge commits illegal in our canonical Git repository. Unfortunately, GitHub does not support server side hooks to enforce such a; policy. We must rely on the community to avoid pushing merge commits. GitHub offers a feature called `Status Checks`: a branch protected by; `status checks` requires commits to be explicitly allowed before the push can happen.; W",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:6385,Security,access,access,6385,"sure that e.g. `clang -v` reports a; user-friendly revision number (e.g. `main-12345` or `4.0-5321`), addressing; the objections raised above with respect to this aspect of Git. What About Branches and Merges?; -------------------------------. In contrast to SVN, Git makes branching easy. Git's commit history is; represented as a DAG, a departure from SVN's linear history. However, we propose; to mandate making merge commits illegal in our canonical Git repository. Unfortunately, GitHub does not support server side hooks to enforce such a; policy. We must rely on the community to avoid pushing merge commits. GitHub offers a feature called `Status Checks`: a branch protected by; `status checks` requires commits to be explicitly allowed before the push can happen.; We could supply a pre-push hook on the client side that would run and check the; history, before allowing the commit being pushed [statuschecks]_.; However this solution would be somewhat fragile (how do you update a script; installed on every developer machine?) and prevents SVN access to the; repository. What About Commit Emails?; -------------------------. We will need a new bot to send emails for each commit. This proposal leaves the; email format unchanged besides the commit URL. Straw Man Migration Plan; ========================. Step #1 : Before The Move; -------------------------. 1. Update docs to mention the move, so people are aware of what is going on.; 2. Set up a read-only version of the GitHub project, mirroring our current SVN; repository.; 3. Add the required bots to implement the commit emails, as well as the; umbrella repository update (if the multirepo is selected) or the read-only; Git views for the sub-projects (if the monorepo is selected). Step #2 : Git Move; ------------------. 4. Update the buildbots to pick up updates and commits from the GitHub; repository. Not all bots have to migrate at this point, but it'll help; provide infrastructure testing.; 5. Update Phabricator to pick up",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:9891,Security,hash,hash,9891,"ts in a single checkout makes cross-project refactoring; naturally simple:. * New sub-projects can be trivially split out for better reuse and/or layering; (e.g., to allow libSupport and/or LIT to be used by runtimes without adding a; dependency on LLVM).; * Changing an API in LLVM and upgrading the sub-projects will always be done in; a single commit, designing away a common source of temporary build breakage.; * Moving code across sub-project (during refactoring for instance) in a single; commit enables accurate `git blame` when tracking code change history.; * Tooling based on `git grep` works natively across sub-projects, allowing to; easier find refactoring opportunities across projects (for example reusing a; datastructure initially in LLDB by moving it into libSupport).; * Having all the sources present encourages maintaining the other sub-projects; when changing API. Finally, the monorepo maintains the property of the existing SVN repository that; the sub-projects move synchronously, and a single revision number (or commit; hash) identifies the state of the development across all projects. .. _build_single_project:. Building a single sub-project; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Even though there is a single source tree, you are not required to build; all sub-projects together. It is trivial to configure builds for a single; sub-project. For example::. mkdir build && cd build; # Configure only LLVM (default); cmake path/to/monorepo; # Configure LLVM and lld; cmake path/to/monorepo -DLLVM_ENABLE_PROJECTS=lld; # Configure LLVM and clang; cmake path/to/monorepo -DLLVM_ENABLE_PROJECTS=clang. .. _git-svn-mirror:. Outstanding Questions; ---------------------. Read-only sub-project mirrors; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. With the Monorepo, it is undecided whether the existing single-subproject; mirrors (e.g. https://git.llvm.org/git/compiler-rt.git) will continue to; be maintained. Read/write SVN bridge; ^^^^^^^^^^^^^^^^^^^^^. GitHub supports a read/write SVN bridge ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:14602,Security,hash,hash,14602,"sitory:. git clone https://github.com/llvm/llvm-project.git. At this point you have every sub-project (llvm, clang, lld, lldb, ...), which; :ref:`doesn't imply you have to build all of them <build_single_project>`. You; can still build only compiler-rt for instance. In this way it's not different; from someone who would check out all the projects with SVN today. If you want to avoid checking out all the sources, you can hide the other; directories using a Git sparse checkout::. git config core.sparseCheckout true; echo /compiler-rt > .git/info/sparse-checkout; git read-tree -mu HEAD. The data for all sub-projects is still in your `.git` directory, but in your; checkout, you only see `compiler-rt`.; Before you push, you'll need to fetch and rebase (`git pull --rebase`) as; usual. Note that when you fetch you'll likely pull in changes to sub-projects you don't; care about. If you are using sparse checkout, the files from other projects; won't appear on your disk. The only effect is that your commit hash changes. You can check whether the changes in the last fetch are relevant to your commit; by running::. git log origin/main@{1}..origin/main -- libcxx. This command can be hidden in a script so that `git llvmpush` would perform all; these steps, fail only if such a dependent change exists, and show immediately; the change that prevented the push. An immediate repeat of the command would; (almost) certainly result in a successful push.; Note that today with SVN or git-svn, this step is not possible since the; ""rebase"" implicitly happens while committing (unless a conflict occurs). Checkout/Clone Multiple Projects, with Commit Access; ----------------------------------------------------. Let's look how to assemble llvm+clang+libcxx at a given revision. Currently; ^^^^^^^^^. ::. svn co https://llvm.org/svn/llvm-project/llvm/trunk llvm -r $REVISION; cd llvm/tools; svn co https://llvm.org/svn/llvm-project/clang/trunk clang -r $REVISION; cd ../projects; svn co https://llvm.o",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:2796,Testability,log,log,2796,"is either down or unresponsive. We should take advantage of one of the services out there (GitHub, GitLab,; and BitBucket, among others) that offer better service (24/7 stability, disk; space, Git server, code browsing, forking facilities, etc) for free. Why Git?; --------. Many new coders nowadays start with Git, and a lot of people have never used; SVN, CVS, or anything else. Websites like GitHub have changed the landscape; of open source contributions, reducing the cost of first contribution and; fostering collaboration. Git is also the version control many LLVM developers use. Despite the; sources being stored in a SVN server, these developers are already using Git; through the Git-SVN integration. Git allows you to:. * Commit, squash, merge, and fork locally without touching the remote server.; * Maintain local branches, enabling multiple threads of development.; * Collaborate on these branches (e.g. through your own fork of llvm on GitHub).; * Inspect the repository history (blame, log, bisect) without Internet access.; * Maintain remote forks and branches on Git hosting services and; integrate back to the main repository. In addition, because Git seems to be replacing many OSS projects' version; control systems, there are many tools that are built over Git.; Future tooling may support Git first (if not only). Why GitHub?; -----------. GitHub, like GitLab and BitBucket, provides free code hosting for open source; projects. Any of these could replace the code-hosting infrastructure that we; have today. These services also have a dedicated team to monitor, migrate, improve and; distribute the contents of the repositories depending on region and load. GitHub has one important advantage over GitLab and; BitBucket: it offers read-write **SVN** access to the repository; (https://github.com/blog/626-announcing-svn-support).; This would enable people to continue working post-migration as though our code; were still canonically in an SVN repository. In addition, there ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:7289,Testability,test,testing,7289," However this solution would be somewhat fragile (how do you update a script; installed on every developer machine?) and prevents SVN access to the; repository. What About Commit Emails?; -------------------------. We will need a new bot to send emails for each commit. This proposal leaves the; email format unchanged besides the commit URL. Straw Man Migration Plan; ========================. Step #1 : Before The Move; -------------------------. 1. Update docs to mention the move, so people are aware of what is going on.; 2. Set up a read-only version of the GitHub project, mirroring our current SVN; repository.; 3. Add the required bots to implement the commit emails, as well as the; umbrella repository update (if the multirepo is selected) or the read-only; Git views for the sub-projects (if the monorepo is selected). Step #2 : Git Move; ------------------. 4. Update the buildbots to pick up updates and commits from the GitHub; repository. Not all bots have to migrate at this point, but it'll help; provide infrastructure testing.; 5. Update Phabricator to pick up commits from the GitHub repository.; 6. LNT and llvmlab have to be updated: they rely on unique monotonically; increasing integer across branch [MatthewsRevNum]_.; 7. Instruct downstream integrators to pick up commits from the GitHub; repository.; 8. Review and prepare an update for the LLVM documentation. Until this point nothing has changed for developers, it will just; boil down to a lot of work for buildbot and other infrastructure; owners. The migration will pause here until all dependencies have cleared, and all; problems have been solved. Step #3: Write Access Move; --------------------------. 9. Collect developers' GitHub account information, and add them to the project.; 10. Switch the SVN repository to read-only and allow pushes to the GitHub repository.; 11. Update the documentation.; 12. Mirror Git to SVN. Step #4 : Post Move; -------------------. 13. Archive the SVN repository.; 14. Update lin",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:8779,Testability,test,test-suite,8779,"gration will pause here until all dependencies have cleared, and all; problems have been solved. Step #3: Write Access Move; --------------------------. 9. Collect developers' GitHub account information, and add them to the project.; 10. Switch the SVN repository to read-only and allow pushes to the GitHub repository.; 11. Update the documentation.; 12. Mirror Git to SVN. Step #4 : Post Move; -------------------. 13. Archive the SVN repository.; 14. Update links on the LLVM website pointing to viewvc/klaus/phab etc. to; point to GitHub instead. GitHub Repository Description; =============================. Monorepo; ----------------. The LLVM git repository hosted at https://github.com/llvm/llvm-project contains all; sub-projects in a single source tree. It is often referred to as a monorepo and; mimics an export of the current SVN repository, with each sub-project having its; own top-level directory. Not all sub-projects are used for building toolchains.; For example, www/ and test-suite/ are not part of the monorepo. Putting all sub-projects in a single checkout makes cross-project refactoring; naturally simple:. * New sub-projects can be trivially split out for better reuse and/or layering; (e.g., to allow libSupport and/or LIT to be used by runtimes without adding a; dependency on LLVM).; * Changing an API in LLVM and upgrading the sub-projects will always be done in; a single commit, designing away a common source of temporary build breakage.; * Moving code across sub-project (during refactoring for instance) in a single; commit enables accurate `git blame` when tracking code change history.; * Tooling based on `git grep` works natively across sub-projects, allowing to; easier find refactoring opportunities across projects (for example reusing a; datastructure initially in LLDB by moving it into libSupport).; * Having all the sources present encourages maintaining the other sub-projects; when changing API. Finally, the monorepo maintains the property of the exist",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:14715,Testability,log,log,14715," which; :ref:`doesn't imply you have to build all of them <build_single_project>`. You; can still build only compiler-rt for instance. In this way it's not different; from someone who would check out all the projects with SVN today. If you want to avoid checking out all the sources, you can hide the other; directories using a Git sparse checkout::. git config core.sparseCheckout true; echo /compiler-rt > .git/info/sparse-checkout; git read-tree -mu HEAD. The data for all sub-projects is still in your `.git` directory, but in your; checkout, you only see `compiler-rt`.; Before you push, you'll need to fetch and rebase (`git pull --rebase`) as; usual. Note that when you fetch you'll likely pull in changes to sub-projects you don't; care about. If you are using sparse checkout, the files from other projects; won't appear on your disk. The only effect is that your commit hash changes. You can check whether the changes in the last fetch are relevant to your commit; by running::. git log origin/main@{1}..origin/main -- libcxx. This command can be hidden in a script so that `git llvmpush` would perform all; these steps, fail only if such a dependent change exists, and show immediately; the change that prevented the push. An immediate repeat of the command would; (almost) certainly result in a successful push.; Note that today with SVN or git-svn, this step is not possible since the; ""rebase"" implicitly happens while committing (unless a conflict occurs). Checkout/Clone Multiple Projects, with Commit Access; ----------------------------------------------------. Let's look how to assemble llvm+clang+libcxx at a given revision. Currently; ^^^^^^^^^. ::. svn co https://llvm.org/svn/llvm-project/llvm/trunk llvm -r $REVISION; cd llvm/tools; svn co https://llvm.org/svn/llvm-project/clang/trunk clang -r $REVISION; cd ../projects; svn co https://llvm.org/svn/llvm-project/libcxx/trunk libcxx -r $REVISION. Or using git-svn::. git clone https://llvm.org/git/llvm.git; cd llvm/; git svn ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:21075,Testability,test,tests,21075,"developing against the existing LLVM git; mirrors. You have one or more git branches that you want to migrate; to the ""final monorepo"". The simplest way to migrate such branches is with the; ``migrate-downstream-fork.py`` tool at; https://github.com/jyknight/llvm-git-migration. Basic migration; ---------------. Basic instructions for ``migrate-downstream-fork.py`` are in the; Python script and are expanded on below to a more general recipe::. # Make a repository which will become your final local mirror of the; # monorepo.; mkdir my-monorepo; git -C my-monorepo init. # Add a remote to the monorepo.; git -C my-monorepo remote add upstream/monorepo https://github.com/llvm/llvm-project.git. # Add remotes for each git mirror you use, from upstream as well as; # your local mirror. All projects are listed here but you need only; # import those for which you have local branches.; my_projects=( clang; clang-tools-extra; compiler-rt; debuginfo-tests; libcxx; libcxxabi; libunwind; lld; lldb; llvm; openmp; polly ); for p in ${my_projects[@]}; do; git -C my-monorepo remote add upstream/split/${p} https://github.com/llvm-mirror/${p}.git; git -C my-monorepo remote add local/split/${p} https://my.local.mirror.org/${p}.git; done. # Pull in all the commits.; git -C my-monorepo fetch --all. # Run migrate-downstream-fork to rewrite local branches on top of; # the upstream monorepo.; (; cd my-monorepo; migrate-downstream-fork.py \; refs/remotes/local \; refs/tags \; --new-repo-prefix=refs/remotes/upstream/monorepo \; --old-repo-prefix=refs/remotes/upstream/split \; --source-kind=split \; --revmap-out=monorepo-map.txt; ). # Octopus-merge the resulting local split histories to unify them. # Assumes local work on local split mirrors is on main (and; # upstream is presumably represented by some other branch like; # upstream/main).; my_local_branch=""main"". git -C my-monorepo branch --no-track local/octopus/main \; $(git -C my-monorepo merge-base refs/remotes/upstream/monorepo/main \; refs/re",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:28055,Testability,test,tests,28055,"ould correctly represent commits; ``Lllvm1`` and ``Llld1``, respectively. Commit ``UM3`` changed files not related to submodules and we need; somewhere to put them. It is not safe in general to put them in the; monorepo root directory because they may conflict with files in the; monorepo. Let's assume we want them in a directory ``local`` in the; monorepo. **Example 1: Umbrella looks like the monorepo**. For this example, we'll assume that each subproject appears in its own; top-level directory in the umbrella, just as they do in the monorepo .; Let's also assume that we want the files in directory ``myproj`` to; appear in ``local/myproj``. Given the above run of ``migrate-downstream-fork.py``, a recipe to; create the zipped history is below::. # Import any non-LLVM repositories the umbrella references.; git -C my-monorepo remote add localrepo \; https://my.local.mirror.org/localrepo.git; git fetch localrepo. subprojects=( clang clang-tools-extra compiler-rt debuginfo-tests libclc; libcxx libcxxabi libunwind lld lldb llgo llvm openmp; parallel-libs polly pstl ). # Import histories for upstream split projects (this was probably; # already done for the ``migrate-downstream-fork.py`` run).; for project in ${subprojects[@]}; do; git remote add upstream/split/${project} \; https://github.com/llvm-mirror/${subproject}.git; git fetch umbrella/split/${project}; done. # Import histories for downstream split projects (this was probably; # already done for the ``migrate-downstream-fork.py`` run).; for project in ${subprojects[@]}; do; git remote add local/split/${project} \; https://my.local.mirror.org/${subproject}.git; git fetch local/split/${project}; done. # Import umbrella history.; git -C my-monorepo remote add umbrella \; https://my.local.mirror.org/umbrella.git; git fetch umbrella. # Put myproj in local/myproj; echo ""myproj local/myproj"" > my-monorepo/submodule-map.txt. # Rewrite history; (; cd my-monorepo; zip-downstream-fork.py \; refs/remotes/umbrella \; --new-repo-",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:31016,Testability,test,tests,31016,"be; discarded and any local tags would then be migrated manually. **Example 2: Nested sources layout**. The tool handles nested submodules (e.g. llvm is a submodule in; umbrella and clang is a submodule in llvm). The file; ``submodule-map.txt`` is a list of pairs, one per line. The first; pair item describes the path to a submodule in the umbrella; repository. The second pair item describes the path where trees for; that submodule should be written in the zipped history. Let's say your umbrella repository is actually the llvm repository and; it has submodules in the ""nested sources"" layout (clang in; tools/clang, etc.). Let's also say ``projects/myproj`` is a submodule; pointing to some downstream repository. The submodule map file should; look like this (we still want myproj mapped the same way as; previously)::. tools/clang clang; tools/clang/tools/extra clang-tools-extra; projects/compiler-rt compiler-rt; projects/debuginfo-tests debuginfo-tests; projects/libclc libclc; projects/libcxx libcxx; projects/libcxxabi libcxxabi; projects/libunwind libunwind; tools/lld lld; tools/lldb lldb; projects/openmp openmp; tools/polly polly; projects/myproj local/myproj. If a submodule path does not appear in the map, the tools assumes it; should be placed in the same place in the monorepo. That means if you; use the ""nested sources"" layout in your umrella, you *must* provide; map entries for all of the projects in your umbrella (except llvm).; Otherwise trees from submodule updates will appear underneath llvm in; the zippped history. Because llvm is itself the umbrella, we use --subdir to write its; content into ``llvm`` in the zippped history::. # Import any non-LLVM repositories the umbrella references.; git -C my-monorepo remote add localrepo \; https://my.local.mirror.org/localrepo.git; git fetch localrepo. subprojects=( clang clang-tools-extra compiler-rt debuginfo-tests libclc; libcxx libcxxabi libunwind lld lldb llgo llvm openmp; parallel-libs polly pstl ). # Import histo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:31032,Testability,test,tests,31032,"be; discarded and any local tags would then be migrated manually. **Example 2: Nested sources layout**. The tool handles nested submodules (e.g. llvm is a submodule in; umbrella and clang is a submodule in llvm). The file; ``submodule-map.txt`` is a list of pairs, one per line. The first; pair item describes the path to a submodule in the umbrella; repository. The second pair item describes the path where trees for; that submodule should be written in the zipped history. Let's say your umbrella repository is actually the llvm repository and; it has submodules in the ""nested sources"" layout (clang in; tools/clang, etc.). Let's also say ``projects/myproj`` is a submodule; pointing to some downstream repository. The submodule map file should; look like this (we still want myproj mapped the same way as; previously)::. tools/clang clang; tools/clang/tools/extra clang-tools-extra; projects/compiler-rt compiler-rt; projects/debuginfo-tests debuginfo-tests; projects/libclc libclc; projects/libcxx libcxx; projects/libcxxabi libcxxabi; projects/libunwind libunwind; tools/lld lld; tools/lldb lldb; projects/openmp openmp; tools/polly polly; projects/myproj local/myproj. If a submodule path does not appear in the map, the tools assumes it; should be placed in the same place in the monorepo. That means if you; use the ""nested sources"" layout in your umrella, you *must* provide; map entries for all of the projects in your umbrella (except llvm).; Otherwise trees from submodule updates will appear underneath llvm in; the zippped history. Because llvm is itself the umbrella, we use --subdir to write its; content into ``llvm`` in the zippped history::. # Import any non-LLVM repositories the umbrella references.; git -C my-monorepo remote add localrepo \; https://my.local.mirror.org/localrepo.git; git fetch localrepo. subprojects=( clang clang-tools-extra compiler-rt debuginfo-tests libclc; libcxx libcxxabi libunwind lld lldb llgo llvm openmp; parallel-libs polly pstl ). # Import histo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:31966,Testability,test,tests,31966," compiler-rt; projects/debuginfo-tests debuginfo-tests; projects/libclc libclc; projects/libcxx libcxx; projects/libcxxabi libcxxabi; projects/libunwind libunwind; tools/lld lld; tools/lldb lldb; projects/openmp openmp; tools/polly polly; projects/myproj local/myproj. If a submodule path does not appear in the map, the tools assumes it; should be placed in the same place in the monorepo. That means if you; use the ""nested sources"" layout in your umrella, you *must* provide; map entries for all of the projects in your umbrella (except llvm).; Otherwise trees from submodule updates will appear underneath llvm in; the zippped history. Because llvm is itself the umbrella, we use --subdir to write its; content into ``llvm`` in the zippped history::. # Import any non-LLVM repositories the umbrella references.; git -C my-monorepo remote add localrepo \; https://my.local.mirror.org/localrepo.git; git fetch localrepo. subprojects=( clang clang-tools-extra compiler-rt debuginfo-tests libclc; libcxx libcxxabi libunwind lld lldb llgo llvm openmp; parallel-libs polly pstl ). # Import histories for upstream split projects (this was probably; # already done for the ``migrate-downstream-fork.py`` run).; for project in ${subprojects[@]}; do; git remote add upstream/split/${project} \; https://github.com/llvm-mirror/${subproject}.git; git fetch umbrella/split/${project}; done. # Import histories for downstream split projects (this was probably; # already done for the ``migrate-downstream-fork.py`` run).; for project in ${subprojects[@]}; do; git remote add local/split/${project} \; https://my.local.mirror.org/${subproject}.git; git fetch local/split/${project}; done. # Import umbrella history. We want this under a different refspec; # so zip-downstream-fork.py knows what it is.; git -C my-monorepo remote add umbrella \; https://my.local.mirror.org/llvm.git; git fetch umbrella. # Create the submodule map.; echo ""tools/clang clang"" > my-monorepo/submodule-map.txt; echo ""tools/clang/too",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:33144,Testability,test,tests,33144,"igrate-downstream-fork.py`` run).; for project in ${subprojects[@]}; do; git remote add upstream/split/${project} \; https://github.com/llvm-mirror/${subproject}.git; git fetch umbrella/split/${project}; done. # Import histories for downstream split projects (this was probably; # already done for the ``migrate-downstream-fork.py`` run).; for project in ${subprojects[@]}; do; git remote add local/split/${project} \; https://my.local.mirror.org/${subproject}.git; git fetch local/split/${project}; done. # Import umbrella history. We want this under a different refspec; # so zip-downstream-fork.py knows what it is.; git -C my-monorepo remote add umbrella \; https://my.local.mirror.org/llvm.git; git fetch umbrella. # Create the submodule map.; echo ""tools/clang clang"" > my-monorepo/submodule-map.txt; echo ""tools/clang/tools/extra clang-tools-extra"" >> my-monorepo/submodule-map.txt; echo ""projects/compiler-rt compiler-rt"" >> my-monorepo/submodule-map.txt; echo ""projects/debuginfo-tests debuginfo-tests"" >> my-monorepo/submodule-map.txt; echo ""projects/libclc libclc"" >> my-monorepo/submodule-map.txt; echo ""projects/libcxx libcxx"" >> my-monorepo/submodule-map.txt; echo ""projects/libcxxabi libcxxabi"" >> my-monorepo/submodule-map.txt; echo ""projects/libunwind libunwind"" >> my-monorepo/submodule-map.txt; echo ""tools/lld lld"" >> my-monorepo/submodule-map.txt; echo ""tools/lldb lldb"" >> my-monorepo/submodule-map.txt; echo ""projects/openmp openmp"" >> my-monorepo/submodule-map.txt; echo ""tools/polly polly"" >> my-monorepo/submodule-map.txt; echo ""projects/myproj local/myproj"" >> my-monorepo/submodule-map.txt. # Rewrite history; (; cd my-monorepo; zip-downstream-fork.py \; refs/remotes/umbrella \; --new-repo-prefix=refs/remotes/upstream/monorepo \; --old-repo-prefix=refs/remotes/upstream/split \; --revmap-in=monorepo-map.txt \; --revmap-out=zip-map.txt \; --subdir=llvm \; --submodule-map=submodule-map.txt \; --update-tags; ). # Create the zip branch (assuming umbrella main is wanted).",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:33160,Testability,test,tests,33160,"igrate-downstream-fork.py`` run).; for project in ${subprojects[@]}; do; git remote add upstream/split/${project} \; https://github.com/llvm-mirror/${subproject}.git; git fetch umbrella/split/${project}; done. # Import histories for downstream split projects (this was probably; # already done for the ``migrate-downstream-fork.py`` run).; for project in ${subprojects[@]}; do; git remote add local/split/${project} \; https://my.local.mirror.org/${subproject}.git; git fetch local/split/${project}; done. # Import umbrella history. We want this under a different refspec; # so zip-downstream-fork.py knows what it is.; git -C my-monorepo remote add umbrella \; https://my.local.mirror.org/llvm.git; git fetch umbrella. # Create the submodule map.; echo ""tools/clang clang"" > my-monorepo/submodule-map.txt; echo ""tools/clang/tools/extra clang-tools-extra"" >> my-monorepo/submodule-map.txt; echo ""projects/compiler-rt compiler-rt"" >> my-monorepo/submodule-map.txt; echo ""projects/debuginfo-tests debuginfo-tests"" >> my-monorepo/submodule-map.txt; echo ""projects/libclc libclc"" >> my-monorepo/submodule-map.txt; echo ""projects/libcxx libcxx"" >> my-monorepo/submodule-map.txt; echo ""projects/libcxxabi libcxxabi"" >> my-monorepo/submodule-map.txt; echo ""projects/libunwind libunwind"" >> my-monorepo/submodule-map.txt; echo ""tools/lld lld"" >> my-monorepo/submodule-map.txt; echo ""tools/lldb lldb"" >> my-monorepo/submodule-map.txt; echo ""projects/openmp openmp"" >> my-monorepo/submodule-map.txt; echo ""tools/polly polly"" >> my-monorepo/submodule-map.txt; echo ""projects/myproj local/myproj"" >> my-monorepo/submodule-map.txt. # Rewrite history; (; cd my-monorepo; zip-downstream-fork.py \; refs/remotes/umbrella \; --new-repo-prefix=refs/remotes/upstream/monorepo \; --old-repo-prefix=refs/remotes/upstream/split \; --revmap-in=monorepo-map.txt \; --revmap-out=zip-map.txt \; --subdir=llvm \; --submodule-map=submodule-map.txt \; --update-tags; ). # Create the zip branch (assuming umbrella main is wanted).",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:5367,Usability,user-friendly,user-friendly,5367,"Git:. - ""The 'branch' I most care about is mainline, and losing the ability to say; 'fixed in r1234' (with some sort of monotonically increasing number) would; be a tragic loss."" [LattnerRevNum]_; - ""I like those results sorted by time and the chronology should be obvious, but; timestamps are incredibly cumbersome and make it difficult to verify that a; given checkout matches a given set of results."" [TrickRevNum]_; - ""There is still the major regression with unreadable version numbers.; Given the amount of Bugzilla traffic with 'Fixed in...', that's a; non-trivial issue."" [JSonnRevNum]_; - ""Sequential IDs are important for LNT and llvmlab bisection tool."" [MatthewsRevNum]_. However, Git can emulate this increasing revision number:; ``git rev-list --count <commit-hash>``. This identifier is unique only; within a single branch, but this means the tuple `(num, branch-name)` uniquely; identifies a commit. We can thus use this revision number to ensure that e.g. `clang -v` reports a; user-friendly revision number (e.g. `main-12345` or `4.0-5321`), addressing; the objections raised above with respect to this aspect of Git. What About Branches and Merges?; -------------------------------. In contrast to SVN, Git makes branching easy. Git's commit history is; represented as a DAG, a departure from SVN's linear history. However, we propose; to mandate making merge commits illegal in our canonical Git repository. Unfortunately, GitHub does not support server side hooks to enforce such a; policy. We must rely on the community to avoid pushing merge commits. GitHub offers a feature called `Status Checks`: a branch protected by; `status checks` requires commits to be explicitly allowed before the push can happen.; We could supply a pre-push hook on the client side that would run and check the; history, before allowing the commit being pushed [statuschecks]_.; However this solution would be somewhat fragile (how do you update a script; installed on every developer machine?) and ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:7800,Usability,pause,pause,7800,"mirroring our current SVN; repository.; 3. Add the required bots to implement the commit emails, as well as the; umbrella repository update (if the multirepo is selected) or the read-only; Git views for the sub-projects (if the monorepo is selected). Step #2 : Git Move; ------------------. 4. Update the buildbots to pick up updates and commits from the GitHub; repository. Not all bots have to migrate at this point, but it'll help; provide infrastructure testing.; 5. Update Phabricator to pick up commits from the GitHub repository.; 6. LNT and llvmlab have to be updated: they rely on unique monotonically; increasing integer across branch [MatthewsRevNum]_.; 7. Instruct downstream integrators to pick up commits from the GitHub; repository.; 8. Review and prepare an update for the LLVM documentation. Until this point nothing has changed for developers, it will just; boil down to a lot of work for buildbot and other infrastructure; owners. The migration will pause here until all dependencies have cleared, and all; problems have been solved. Step #3: Write Access Move; --------------------------. 9. Collect developers' GitHub account information, and add them to the project.; 10. Switch the SVN repository to read-only and allow pushes to the GitHub repository.; 11. Update the documentation.; 12. Mirror Git to SVN. Step #4 : Post Move; -------------------. 13. Archive the SVN repository.; 14. Update links on the LLVM website pointing to viewvc/klaus/phab etc. to; point to GitHub instead. GitHub Repository Description; =============================. Monorepo; ----------------. The LLVM git repository hosted at https://github.com/llvm/llvm-project contains all; sub-projects in a single source tree. It is often referred to as a monorepo and; mimics an export of the current SVN repository, with each sub-project having its; own top-level directory. Not all sub-projects are used for building toolchains.; For example, www/ and test-suite/ are not part of the monorepo. Putting all",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:7839,Usability,clear,cleared,7839,"mirroring our current SVN; repository.; 3. Add the required bots to implement the commit emails, as well as the; umbrella repository update (if the multirepo is selected) or the read-only; Git views for the sub-projects (if the monorepo is selected). Step #2 : Git Move; ------------------. 4. Update the buildbots to pick up updates and commits from the GitHub; repository. Not all bots have to migrate at this point, but it'll help; provide infrastructure testing.; 5. Update Phabricator to pick up commits from the GitHub repository.; 6. LNT and llvmlab have to be updated: they rely on unique monotonically; increasing integer across branch [MatthewsRevNum]_.; 7. Instruct downstream integrators to pick up commits from the GitHub; repository.; 8. Review and prepare an update for the LLVM documentation. Until this point nothing has changed for developers, it will just; boil down to a lot of work for buildbot and other infrastructure; owners. The migration will pause here until all dependencies have cleared, and all; problems have been solved. Step #3: Write Access Move; --------------------------. 9. Collect developers' GitHub account information, and add them to the project.; 10. Switch the SVN repository to read-only and allow pushes to the GitHub repository.; 11. Update the documentation.; 12. Mirror Git to SVN. Step #4 : Post Move; -------------------. 13. Archive the SVN repository.; 14. Update links on the LLVM website pointing to viewvc/klaus/phab etc. to; point to GitHub instead. GitHub Repository Description; =============================. Monorepo; ----------------. The LLVM git repository hosted at https://github.com/llvm/llvm-project contains all; sub-projects in a single source tree. It is often referred to as a monorepo and; mimics an export of the current SVN repository, with each sub-project having its; own top-level directory. Not all sub-projects are used for building toolchains.; For example, www/ and test-suite/ are not part of the monorepo. Putting all",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:8910,Usability,simpl,simple,8910,"e been solved. Step #3: Write Access Move; --------------------------. 9. Collect developers' GitHub account information, and add them to the project.; 10. Switch the SVN repository to read-only and allow pushes to the GitHub repository.; 11. Update the documentation.; 12. Mirror Git to SVN. Step #4 : Post Move; -------------------. 13. Archive the SVN repository.; 14. Update links on the LLVM website pointing to viewvc/klaus/phab etc. to; point to GitHub instead. GitHub Repository Description; =============================. Monorepo; ----------------. The LLVM git repository hosted at https://github.com/llvm/llvm-project contains all; sub-projects in a single source tree. It is often referred to as a monorepo and; mimics an export of the current SVN repository, with each sub-project having its; own top-level directory. Not all sub-projects are used for building toolchains.; For example, www/ and test-suite/ are not part of the monorepo. Putting all sub-projects in a single checkout makes cross-project refactoring; naturally simple:. * New sub-projects can be trivially split out for better reuse and/or layering; (e.g., to allow libSupport and/or LIT to be used by runtimes without adding a; dependency on LLVM).; * Changing an API in LLVM and upgrading the sub-projects will always be done in; a single commit, designing away a common source of temporary build breakage.; * Moving code across sub-project (during refactoring for instance) in a single; commit enables accurate `git blame` when tracking code change history.; * Tooling based on `git grep` works natively across sub-projects, allowing to; easier find refactoring opportunities across projects (for example reusing a; datastructure initially in LLDB by moving it into libSupport).; * Having all the sources present encourages maintaining the other sub-projects; when changing API. Finally, the monorepo maintains the property of the existing SVN repository that; the sub-projects move synchronously, and a single revisi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:10960,Usability,clear,clear,10960,"all projects. .. _build_single_project:. Building a single sub-project; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Even though there is a single source tree, you are not required to build; all sub-projects together. It is trivial to configure builds for a single; sub-project. For example::. mkdir build && cd build; # Configure only LLVM (default); cmake path/to/monorepo; # Configure LLVM and lld; cmake path/to/monorepo -DLLVM_ENABLE_PROJECTS=lld; # Configure LLVM and clang; cmake path/to/monorepo -DLLVM_ENABLE_PROJECTS=clang. .. _git-svn-mirror:. Outstanding Questions; ---------------------. Read-only sub-project mirrors; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. With the Monorepo, it is undecided whether the existing single-subproject; mirrors (e.g. https://git.llvm.org/git/compiler-rt.git) will continue to; be maintained. Read/write SVN bridge; ^^^^^^^^^^^^^^^^^^^^^. GitHub supports a read/write SVN bridge for its repositories. However,; there have been issues with this bridge working correctly in the past,; so it's not clear if this is something that will be supported going forward. Monorepo Drawbacks; ------------------. * Using the monolithic repository may add overhead for those contributing to a; standalone sub-project, particularly on runtimes like libcxx and compiler-rt; that don't rely on LLVM; currently, a fresh clone of libcxx is only 15MB (vs.; 1GB for the monorepo), and the commit rate of LLVM may cause more frequent; `git push` collisions when upstreaming. Affected contributors may be able to; use the SVN bridge or the single-subproject Git mirrors. However, it's; undecided if these projects will continue to be maintained.; * Using the monolithic repository may add overhead for those *integrating* a; standalone sub-project, even if they aren't contributing to it, due to the; same disk space concern as the point above. The availability of the; sub-project Git mirrors would addresses this.; * Preservation of the existing read/write SVN-based workflows relies on the; GitHub SV",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:20266,Usability,simpl,simplest,20266,"above,; except that the bisection script does not need to include the; `git submodule update` step. The same example, finding which commit introduces a regression where clang-3.9; crashes but not clang-3.8 passes, will look like::. git bisect start releases/3.9.x releases/3.8.x; git bisect run ./bisect_script.sh. With the `bisect_script.sh` script being::. #!/bin/sh; cd $BUILD_DIR. ninja clang || exit 125 # an exit code of 125 asks ""git bisect""; # to ""skip"" the current commit. ./bin/clang some_crash_test.cpp. Also, since the monorepo handles commits update across multiple projects, you're; less like to encounter a build failure where a commit change an API in LLVM and; another later one ""fixes"" the build in clang. Moving Local Branches to the Monorepo; =====================================. Suppose you have been developing against the existing LLVM git; mirrors. You have one or more git branches that you want to migrate; to the ""final monorepo"". The simplest way to migrate such branches is with the; ``migrate-downstream-fork.py`` tool at; https://github.com/jyknight/llvm-git-migration. Basic migration; ---------------. Basic instructions for ``migrate-downstream-fork.py`` are in the; Python script and are expanded on below to a more general recipe::. # Make a repository which will become your final local mirror of the; # monorepo.; mkdir my-monorepo; git -C my-monorepo init. # Add a remote to the monorepo.; git -C my-monorepo remote add upstream/monorepo https://github.com/llvm/llvm-project.git. # Add remotes for each git mirror you use, from upstream as well as; # your local mirror. All projects are listed here but you need only; # import those for which you have local branches.; my_projects=( clang; clang-tools-extra; compiler-rt; debuginfo-tests; libcxx; libcxxabi; libunwind; lld; lldb; llvm; openmp; polly ); for p in ${my_projects[@]}; do; git -C my-monorepo remote add upstream/split/${p} https://github.com/llvm-mirror/${p}.git; git -C my-monorepo remote add loc",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:23797,Usability,simpl,simply,23797," branches for upstream monorepo branches.; for ref in $(git -C my-monorepo for-each-ref --format=""%(refname)"" \; refs/remotes/upstream/monorepo); do; upstream_branch=${ref#refs/remotes/upstream/monorepo/}; git -C my-monorepo branch upstream/${upstream_branch} ${ref}; done. The above gets you to a state like the following::. U1 - U2 - U3 <- upstream/main; \ \ \; \ \ - Llld1 - Llld2 -; \ \ \; \ - Lclang1 - Lclang2-- Lmerge <- local/octopus/main; \ /; - Lllvm1 - Lllvm2-----. Each branched component has its branch rewritten on top of the; monorepo and all components are unified by a giant octopus merge. If additional active local branches need to be preserved, the above; operations following the assignment to ``my_local_branch`` should be; done for each branch. Ref paths will need to be updated to map the; local branch to the corresponding upstream branch. If local branches; have no corresponding upstream branch, then the creation of; ``local/octopus/<local branch>`` need not use ``git-merge-base`` to; pinpoint its root commit; it may simply be branched from the; appropriate component branch (say, ``llvm/local_release_X``). Zipping local history; ---------------------. The octopus merge is suboptimal for many cases, because walking back; through the history of one component leaves the other components fixed; at a history that likely makes things unbuildable. Some downstream users track the order commits were made to subprojects; with some kind of ""umbrella"" project that imports the project git; mirrors as submodules, similar to the multirepo umbrella proposed; above. Such an umbrella repository looks something like this::. UM1 ---- UM2 -- UM3 -- UM4 ---- UM5 ---- UM6 ---- UM7 ---- UM8 <- main; | | | | | | |; Lllvm1 Llld1 Lclang1 Lclang2 Lllvm2 Llld2 Lmyproj1. The vertical bars represent submodule updates to a particular local; commit in the project mirror. ``UM3`` in this case is a commit of; some local umbrella repository state that is not a submodule update,; perhaps a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:26467,Usability,simpl,simpler,26467," commits to their corresponding rewritten ``L*1`` commits.; The ``L*2`` commits did not do any merges from upstream. Note that the merge from ``U2`` to ``Lclang1`` appears redundant, but; if, say, ``U3`` changed some files in upstream clang, the ``Lclang1``; commit appearing after the ``Llld1`` commit would actually represent a; clang tree *earlier* in the upstream clang history. We want the; ``local/zip`` branch to accurately represent the state of our umbrella; history and so the edge ``U2 -> Lclang1`` is a visual reminder of what; clang's tree actually looks like in ``Lclang1``. Even so, the edge ``U3 -> Llld1`` could be problematic for future; merges from upstream. git will think that we've already merged from; ``U3``, and we have, except for the state of the clang tree. One; possible mitigation strategy is to manually diff clang between ``U2``; and ``U3`` and apply those updates to ``local/zip``. Another,; possibly simpler strategy is to freeze local work on downstream; branches and merge all submodules from the latest upstream before; running ``zip-downstream-fork.py``. If downstream merged each project; from upstream in lockstep without any intervening local commits, then; things should be fine without any special action. We anticipate this; to be the common case. The tree for ``Lclang1`` outside of clang will represent the state of; things at ``U3`` since all of the upstream projects not participating; in the umbrella history should be in a state respecting the commit; ``U3``. The trees for llvm and lld should correctly represent commits; ``Lllvm1`` and ``Llld1``, respectively. Commit ``UM3`` changed files not related to submodules and we need; somewhere to put them. It is not safe in general to put them in the; monorepo root directory because they may conflict with files in the; monorepo. Let's assume we want them in a directory ``local`` in the; monorepo. **Example 1: Umbrella looks like the monorepo**. For this example, we'll assume that each subproject ap",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst:36478,Usability,clear,clearly,36478,"s.; for ref in $(git -C my-monorepo for-each-ref --format=""%(refname)"" \; refs/remotes/myrepo/release); do; branch=${ref#refs/remotes/myrepo/}; git -C my-monorepo branch --no-track myrepo/${branch} ${ref}; done. # Preserve main.; git -C my-monorepo branch --no-track myrepo/main refs/remotes/myrepo/main. # Merge main.; git -C my-monorepo checkout local/zip/main # Or local/octopus/main; git -C my-monorepo merge myrepo/main. You may want to merge other corresponding branches, for example; ``myrepo`` release branches if they were in lockstep with LLVM project; releases. ``--tag-prefix`` tells ``import-downstream-repo.py`` to rename; annotated tags with the given prefix. Due to limitations with; ``fast_filter_branch.py``, unannotated tags cannot be renamed; (``fast_filter_branch.py`` considers them branches, not tags). Since; the upstream monorepo had its tags rewritten with an ""llvmorg-""; prefix, name conflicts should not be an issue. ``--tag-prefix`` can; be used to more clearly indicate which tags correspond to various; imported repositories. Given this repository history::. R1 - R2 - R3 <- main; ^; |; release/1. The above recipe results in a history like this::. U1 - U2 - U3 <- upstream/main; \ \ \; \ -----\--------------- local/zip--.; \ \ \ |; - Lllvm1 - Llld1 - UM3 - Lclang1 - Lclang2 - Lllvm2 - Llld2 - Lmyproj1 - M1 <-'; /; R1 - R2 - R3 <-.; ^ |; | |; myrepo-release/1 |; |; myrepo/main--'. Commits ``R1``, ``R2`` and ``R3`` have trees that *only* contain blobs; from ``myrepo``. If you require commits from ``myrepo`` to be; interleaved with commits on local project branches (for example,; interleaved with ``llvm1``, ``llvm2``, etc. above) and myrepo doesn't; appear in an umbrella repository, a new tool will need to be; developed. Creating such a tool would involve:. 1. Modifying ``fast_filter_branch.py`` to optionally take a; revlist directly rather than generating it itself. 2. Creating a tool to generate an interleaved ordering of local; commits based on some cri",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/GitHubMove.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst:343,Availability,error,errors,343,"=====================; Test-Suite Extensions; =====================. .. contents::; :depth: 1; :local:. Abstract; ========. These are ideas for additional programs, benchmarks, applications and; algorithms that could be added to the LLVM Test-Suite.; The test-suite could be much larger than it is now, which would help us; detecting compiler errors (crashes, miscompiles) during development. Most probably, the reason why the programs below have not been added to; the test-suite yet is that nobody has found time to do it. But there; might be other issues as well, such as. * Licensing (Support can still be added as external module,; like for the SPEC benchmarks). * Language (in particular, there is no official LLVM frontend; for FORTRAN yet). * Parallelism (currently, all programs in test-suite use; one thread only). Benchmarks; ==========. SPEC CPU 2017; -------------; https://www.spec.org/cpu2017/. The following have not been included yet because they contain Fortran; code. In case of cactuBSSN only a small portion is Fortran. The hosts's; Fortran compiler could be used for these parts. Note that CMake's Ninja generator has difficulties with Fortran. See the; `CMake documentation <https://cmake.org/cmake/help/v3.13/generator/Ninja.html#fortran-support>`_; for details. * 503.bwaves_r/603.bwaves_s; * 507.cactuBSSN_r; * 521.wrf_r/621.wrf_s; * 527.cam4_r/627.cam4_s; * 628.pop2_s; * 548.exchange2_r/648.exchange2_s; * 549.fotonik3d_r/649.fotonik3d_s; * 554.roms_r/654.roms_s. SPEC OMP2012; ------------; https://www.spec.org/omp2012/. * 350.md; * 351.bwaves; * 352.nab; * 357.bt331; * 358.botsalgn; * 359.botsspar; * 360.ilbdc; * 362.fma3d; * 363.swim; * 367.imagick; * 370.mgrid331; * 371.applu331; * 372.smithwa; * 376.kdtree. OpenCV; ------; https://opencv.org/. OpenMP 4.x SIMD Benchmarks; --------------------------; https://github.com/flwende/simd_benchmarks. PWM-benchmarking; ----------------; https://github.com/tbepler/PWM-benchmarking. SLAMBench; ---------; https://github.c",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst:3459,Availability,avail,available,3459,"ix-test-suite/>`_; and is itself a collection of benchmark suites. Parboil Benchmarks; ------------------; http://impact.crhc.illinois.edu/parboil/parboil.aspx. MachSuite; ---------; https://breagen.github.io/MachSuite/. Rodinia; -------; http://lava.cs.virginia.edu/Rodinia/download_links.htm. Rodinia has already been partially included in; MultiSource/Benchmarks/Rodinia. Benchmarks still missing are:. * streamcluster; * particlefilter; * nw; * nn; * myocyte; * mummergpu; * lud; * leukocyte; * lavaMD; * kmeans; * hotspot3D; * heartwall; * cfd; * bfs; * b+tree. vecmathlib tests harness; ------------------------; https://bitbucket.org/eschnett/vecmathlib/wiki/Home. PARSEC; ------; http://parsec.cs.princeton.edu/. Graph500 reference implementations; ----------------------------------; https://github.com/graph500/graph500/tree/v2-spec. NAS Parallel Benchmarks; -----------------------; https://www.nas.nasa.gov/publications/npb.html. The official benchmark is written in Fortran, but an unofficial; C-translation is available as well:; https://github.com/benchmark-subsetting/NPB3.0-omp-C. DARPA HPCS SSCA#2 C/OpenMP reference implementation; ---------------------------------------------------; http://www.highproductivity.org/SSCABmks.htm. This web site does not exist any more, but there seems to be a copy of; some of the benchmarks; https://github.com/gtcasl/hpc-benchmarks/tree/master/SSCA2v2.2. Kokkos; ------; https://github.com/kokkos/kokkos-kernels/tree/master/perf_test; https://github.com/kokkos/kokkos/tree/master/benchmarks. PolyMage; --------; https://github.com/bondhugula/polymage-benchmarks. PolyBench; ---------; https://sourceforge.net/projects/polybench/. A modified version of Polybench 3.2 is already presented in; SingleSource/Benchmarks/Polybench. A newer version 4.2.1 is available. High Performance Geometric Multigrid; ------------------------------------; https://crd.lbl.gov/departments/computer-science/PAR/research/hpgmg/. RAJA Performance Suite; -------------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst:4241,Availability,avail,available,4241,"com/graph500/graph500/tree/v2-spec. NAS Parallel Benchmarks; -----------------------; https://www.nas.nasa.gov/publications/npb.html. The official benchmark is written in Fortran, but an unofficial; C-translation is available as well:; https://github.com/benchmark-subsetting/NPB3.0-omp-C. DARPA HPCS SSCA#2 C/OpenMP reference implementation; ---------------------------------------------------; http://www.highproductivity.org/SSCABmks.htm. This web site does not exist any more, but there seems to be a copy of; some of the benchmarks; https://github.com/gtcasl/hpc-benchmarks/tree/master/SSCA2v2.2. Kokkos; ------; https://github.com/kokkos/kokkos-kernels/tree/master/perf_test; https://github.com/kokkos/kokkos/tree/master/benchmarks. PolyMage; --------; https://github.com/bondhugula/polymage-benchmarks. PolyBench; ---------; https://sourceforge.net/projects/polybench/. A modified version of Polybench 3.2 is already presented in; SingleSource/Benchmarks/Polybench. A newer version 4.2.1 is available. High Performance Geometric Multigrid; ------------------------------------; https://crd.lbl.gov/departments/computer-science/PAR/research/hpgmg/. RAJA Performance Suite; ----------------------; https://github.com/LLNL/RAJAPerf. CORAL-2 Benchmarks; ------------------; https://asc.llnl.gov/coral-2-benchmarks/. Many of its programs have already been integrated in; MultiSource/Benchmarks/DOE-ProxyApps-C and; MultiSource/Benchmarks/DOE-ProxyApps-C++. * Nekbone; * QMCPack; * LAMMPS; * Kripke; * Quicksilver; * PENNANT; * Big Data Analytic Suite; * Deep Learning Suite; * Stream; * Stride; * ML/DL micro-benchmark; * Pynamic; * ACME; * VPIC; * Laghos; * Parallel Integer Sort; * Havoq. NWChem; ------; http://www.nwchem-sw.org/index.php/Benchmarks. TVM; ----; https://github.com/dmlc/tvm/tree/main/apps/benchmark. HydroBench; ----------; https://github.com/HydroBench/Hydro. ParRes; ------; https://github.com/ParRes/Kernels/tree/default/Cxx11. Applications/Libraries; ======================. G",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst:4601,Deployability,integrat,integrated,4601,"------; http://www.highproductivity.org/SSCABmks.htm. This web site does not exist any more, but there seems to be a copy of; some of the benchmarks; https://github.com/gtcasl/hpc-benchmarks/tree/master/SSCA2v2.2. Kokkos; ------; https://github.com/kokkos/kokkos-kernels/tree/master/perf_test; https://github.com/kokkos/kokkos/tree/master/benchmarks. PolyMage; --------; https://github.com/bondhugula/polymage-benchmarks. PolyBench; ---------; https://sourceforge.net/projects/polybench/. A modified version of Polybench 3.2 is already presented in; SingleSource/Benchmarks/Polybench. A newer version 4.2.1 is available. High Performance Geometric Multigrid; ------------------------------------; https://crd.lbl.gov/departments/computer-science/PAR/research/hpgmg/. RAJA Performance Suite; ----------------------; https://github.com/LLNL/RAJAPerf. CORAL-2 Benchmarks; ------------------; https://asc.llnl.gov/coral-2-benchmarks/. Many of its programs have already been integrated in; MultiSource/Benchmarks/DOE-ProxyApps-C and; MultiSource/Benchmarks/DOE-ProxyApps-C++. * Nekbone; * QMCPack; * LAMMPS; * Kripke; * Quicksilver; * PENNANT; * Big Data Analytic Suite; * Deep Learning Suite; * Stream; * Stride; * ML/DL micro-benchmark; * Pynamic; * ACME; * VPIC; * Laghos; * Parallel Integer Sort; * Havoq. NWChem; ------; http://www.nwchem-sw.org/index.php/Benchmarks. TVM; ----; https://github.com/dmlc/tvm/tree/main/apps/benchmark. HydroBench; ----------; https://github.com/HydroBench/Hydro. ParRes; ------; https://github.com/ParRes/Kernels/tree/default/Cxx11. Applications/Libraries; ======================. GnuPG; -----; https://gnupg.org/. Blitz++; -------; https://sourceforge.net/projects/blitz/. FFmpeg; ------; https://ffmpeg.org/. FreePOOMA; ---------; http://www.nongnu.org/freepooma/. FTensors; --------; http://www.wlandry.net/Projects/FTensor. rawspeed; --------; https://github.com/darktable-org/rawspeed. Its test dataset is 756 MB in size, which is too large to be included; into th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst:4601,Integrability,integrat,integrated,4601,"------; http://www.highproductivity.org/SSCABmks.htm. This web site does not exist any more, but there seems to be a copy of; some of the benchmarks; https://github.com/gtcasl/hpc-benchmarks/tree/master/SSCA2v2.2. Kokkos; ------; https://github.com/kokkos/kokkos-kernels/tree/master/perf_test; https://github.com/kokkos/kokkos/tree/master/benchmarks. PolyMage; --------; https://github.com/bondhugula/polymage-benchmarks. PolyBench; ---------; https://sourceforge.net/projects/polybench/. A modified version of Polybench 3.2 is already presented in; SingleSource/Benchmarks/Polybench. A newer version 4.2.1 is available. High Performance Geometric Multigrid; ------------------------------------; https://crd.lbl.gov/departments/computer-science/PAR/research/hpgmg/. RAJA Performance Suite; ----------------------; https://github.com/LLNL/RAJAPerf. CORAL-2 Benchmarks; ------------------; https://asc.llnl.gov/coral-2-benchmarks/. Many of its programs have already been integrated in; MultiSource/Benchmarks/DOE-ProxyApps-C and; MultiSource/Benchmarks/DOE-ProxyApps-C++. * Nekbone; * QMCPack; * LAMMPS; * Kripke; * Quicksilver; * PENNANT; * Big Data Analytic Suite; * Deep Learning Suite; * Stream; * Stride; * ML/DL micro-benchmark; * Pynamic; * ACME; * VPIC; * Laghos; * Parallel Integer Sort; * Havoq. NWChem; ------; http://www.nwchem-sw.org/index.php/Benchmarks. TVM; ----; https://github.com/dmlc/tvm/tree/main/apps/benchmark. HydroBench; ----------; https://github.com/HydroBench/Hydro. ParRes; ------; https://github.com/ParRes/Kernels/tree/default/Cxx11. Applications/Libraries; ======================. GnuPG; -----; https://gnupg.org/. Blitz++; -------; https://sourceforge.net/projects/blitz/. FFmpeg; ------; https://ffmpeg.org/. FreePOOMA; ---------; http://www.nongnu.org/freepooma/. FTensors; --------; http://www.wlandry.net/Projects/FTensor. rawspeed; --------; https://github.com/darktable-org/rawspeed. Its test dataset is 756 MB in size, which is too large to be included; into th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst:324,Safety,detect,detecting,324,"=====================; Test-Suite Extensions; =====================. .. contents::; :depth: 1; :local:. Abstract; ========. These are ideas for additional programs, benchmarks, applications and; algorithms that could be added to the LLVM Test-Suite.; The test-suite could be much larger than it is now, which would help us; detecting compiler errors (crashes, miscompiles) during development. Most probably, the reason why the programs below have not been added to; the test-suite yet is that nobody has found time to do it. But there; might be other issues as well, such as. * Licensing (Support can still be added as external module,; like for the SPEC benchmarks). * Language (in particular, there is no official LLVM frontend; for FORTRAN yet). * Parallelism (currently, all programs in test-suite use; one thread only). Benchmarks; ==========. SPEC CPU 2017; -------------; https://www.spec.org/cpu2017/. The following have not been included yet because they contain Fortran; code. In case of cactuBSSN only a small portion is Fortran. The hosts's; Fortran compiler could be used for these parts. Note that CMake's Ninja generator has difficulties with Fortran. See the; `CMake documentation <https://cmake.org/cmake/help/v3.13/generator/Ninja.html#fortran-support>`_; for details. * 503.bwaves_r/603.bwaves_s; * 507.cactuBSSN_r; * 521.wrf_r/621.wrf_s; * 527.cam4_r/627.cam4_s; * 628.pop2_s; * 548.exchange2_r/648.exchange2_s; * 549.fotonik3d_r/649.fotonik3d_s; * 554.roms_r/654.roms_s. SPEC OMP2012; ------------; https://www.spec.org/omp2012/. * 350.md; * 351.bwaves; * 352.nab; * 357.bt331; * 358.botsalgn; * 359.botsspar; * 360.ilbdc; * 362.fma3d; * 363.swim; * 367.imagick; * 370.mgrid331; * 371.applu331; * 372.smithwa; * 376.kdtree. OpenCV; ------; https://opencv.org/. OpenMP 4.x SIMD Benchmarks; --------------------------; https://github.com/flwende/simd_benchmarks. PWM-benchmarking; ----------------; https://github.com/tbepler/PWM-benchmarking. SLAMBench; ---------; https://github.c",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst:6057,Safety,detect,detection,6057,"ormance Suite; ----------------------; https://github.com/LLNL/RAJAPerf. CORAL-2 Benchmarks; ------------------; https://asc.llnl.gov/coral-2-benchmarks/. Many of its programs have already been integrated in; MultiSource/Benchmarks/DOE-ProxyApps-C and; MultiSource/Benchmarks/DOE-ProxyApps-C++. * Nekbone; * QMCPack; * LAMMPS; * Kripke; * Quicksilver; * PENNANT; * Big Data Analytic Suite; * Deep Learning Suite; * Stream; * Stride; * ML/DL micro-benchmark; * Pynamic; * ACME; * VPIC; * Laghos; * Parallel Integer Sort; * Havoq. NWChem; ------; http://www.nwchem-sw.org/index.php/Benchmarks. TVM; ----; https://github.com/dmlc/tvm/tree/main/apps/benchmark. HydroBench; ----------; https://github.com/HydroBench/Hydro. ParRes; ------; https://github.com/ParRes/Kernels/tree/default/Cxx11. Applications/Libraries; ======================. GnuPG; -----; https://gnupg.org/. Blitz++; -------; https://sourceforge.net/projects/blitz/. FFmpeg; ------; https://ffmpeg.org/. FreePOOMA; ---------; http://www.nongnu.org/freepooma/. FTensors; --------; http://www.wlandry.net/Projects/FTensor. rawspeed; --------; https://github.com/darktable-org/rawspeed. Its test dataset is 756 MB in size, which is too large to be included; into the test-suite repository. C++ Performance Benchmarks; --------------------------; https://gitlab.com/chriscox/CppPerformanceBenchmarks. Generic Algorithms; ==================. Image processing; ----------------. Resampling; ``````````. * Bilinear; * Bicubic; * Lanczos. Dither; ``````. * Threshold; * Random; * Halftone; * Bayer; * Floyd-Steinberg; * Jarvis; * Stucki; * Burkes; * Sierra; * Atkinson; * Gradient-based. Feature detection; `````````````````. * Harris; * Histogram of Oriented Gradients. Color conversion; ````````````````. * RGB to grayscale; * HSL to RGB. Graph; -----. Search Algorithms; `````````````````. * Breadth-First-Search; * Depth-First-Search; * Dijkstra's algorithm; * A-Star. Spanning Tree; `````````````. * Kruskal's algorithm; * Prim's algorithm; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst:165,Testability,benchmark,benchmarks,165,"=====================; Test-Suite Extensions; =====================. .. contents::; :depth: 1; :local:. Abstract; ========. These are ideas for additional programs, benchmarks, applications and; algorithms that could be added to the LLVM Test-Suite.; The test-suite could be much larger than it is now, which would help us; detecting compiler errors (crashes, miscompiles) during development. Most probably, the reason why the programs below have not been added to; the test-suite yet is that nobody has found time to do it. But there; might be other issues as well, such as. * Licensing (Support can still be added as external module,; like for the SPEC benchmarks). * Language (in particular, there is no official LLVM frontend; for FORTRAN yet). * Parallelism (currently, all programs in test-suite use; one thread only). Benchmarks; ==========. SPEC CPU 2017; -------------; https://www.spec.org/cpu2017/. The following have not been included yet because they contain Fortran; code. In case of cactuBSSN only a small portion is Fortran. The hosts's; Fortran compiler could be used for these parts. Note that CMake's Ninja generator has difficulties with Fortran. See the; `CMake documentation <https://cmake.org/cmake/help/v3.13/generator/Ninja.html#fortran-support>`_; for details. * 503.bwaves_r/603.bwaves_s; * 507.cactuBSSN_r; * 521.wrf_r/621.wrf_s; * 527.cam4_r/627.cam4_s; * 628.pop2_s; * 548.exchange2_r/648.exchange2_s; * 549.fotonik3d_r/649.fotonik3d_s; * 554.roms_r/654.roms_s. SPEC OMP2012; ------------; https://www.spec.org/omp2012/. * 350.md; * 351.bwaves; * 352.nab; * 357.bt331; * 358.botsalgn; * 359.botsspar; * 360.ilbdc; * 362.fma3d; * 363.swim; * 367.imagick; * 370.mgrid331; * 371.applu331; * 372.smithwa; * 376.kdtree. OpenCV; ------; https://opencv.org/. OpenMP 4.x SIMD Benchmarks; --------------------------; https://github.com/flwende/simd_benchmarks. PWM-benchmarking; ----------------; https://github.com/tbepler/PWM-benchmarking. SLAMBench; ---------; https://github.c",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst:255,Testability,test,test-suite,255,"=====================; Test-Suite Extensions; =====================. .. contents::; :depth: 1; :local:. Abstract; ========. These are ideas for additional programs, benchmarks, applications and; algorithms that could be added to the LLVM Test-Suite.; The test-suite could be much larger than it is now, which would help us; detecting compiler errors (crashes, miscompiles) during development. Most probably, the reason why the programs below have not been added to; the test-suite yet is that nobody has found time to do it. But there; might be other issues as well, such as. * Licensing (Support can still be added as external module,; like for the SPEC benchmarks). * Language (in particular, there is no official LLVM frontend; for FORTRAN yet). * Parallelism (currently, all programs in test-suite use; one thread only). Benchmarks; ==========. SPEC CPU 2017; -------------; https://www.spec.org/cpu2017/. The following have not been included yet because they contain Fortran; code. In case of cactuBSSN only a small portion is Fortran. The hosts's; Fortran compiler could be used for these parts. Note that CMake's Ninja generator has difficulties with Fortran. See the; `CMake documentation <https://cmake.org/cmake/help/v3.13/generator/Ninja.html#fortran-support>`_; for details. * 503.bwaves_r/603.bwaves_s; * 507.cactuBSSN_r; * 521.wrf_r/621.wrf_s; * 527.cam4_r/627.cam4_s; * 628.pop2_s; * 548.exchange2_r/648.exchange2_s; * 549.fotonik3d_r/649.fotonik3d_s; * 554.roms_r/654.roms_s. SPEC OMP2012; ------------; https://www.spec.org/omp2012/. * 350.md; * 351.bwaves; * 352.nab; * 357.bt331; * 358.botsalgn; * 359.botsspar; * 360.ilbdc; * 362.fma3d; * 363.swim; * 367.imagick; * 370.mgrid331; * 371.applu331; * 372.smithwa; * 376.kdtree. OpenCV; ------; https://opencv.org/. OpenMP 4.x SIMD Benchmarks; --------------------------; https://github.com/flwende/simd_benchmarks. PWM-benchmarking; ----------------; https://github.com/tbepler/PWM-benchmarking. SLAMBench; ---------; https://github.c",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst:470,Testability,test,test-suite,470,"=====================; Test-Suite Extensions; =====================. .. contents::; :depth: 1; :local:. Abstract; ========. These are ideas for additional programs, benchmarks, applications and; algorithms that could be added to the LLVM Test-Suite.; The test-suite could be much larger than it is now, which would help us; detecting compiler errors (crashes, miscompiles) during development. Most probably, the reason why the programs below have not been added to; the test-suite yet is that nobody has found time to do it. But there; might be other issues as well, such as. * Licensing (Support can still be added as external module,; like for the SPEC benchmarks). * Language (in particular, there is no official LLVM frontend; for FORTRAN yet). * Parallelism (currently, all programs in test-suite use; one thread only). Benchmarks; ==========. SPEC CPU 2017; -------------; https://www.spec.org/cpu2017/. The following have not been included yet because they contain Fortran; code. In case of cactuBSSN only a small portion is Fortran. The hosts's; Fortran compiler could be used for these parts. Note that CMake's Ninja generator has difficulties with Fortran. See the; `CMake documentation <https://cmake.org/cmake/help/v3.13/generator/Ninja.html#fortran-support>`_; for details. * 503.bwaves_r/603.bwaves_s; * 507.cactuBSSN_r; * 521.wrf_r/621.wrf_s; * 527.cam4_r/627.cam4_s; * 628.pop2_s; * 548.exchange2_r/648.exchange2_s; * 549.fotonik3d_r/649.fotonik3d_s; * 554.roms_r/654.roms_s. SPEC OMP2012; ------------; https://www.spec.org/omp2012/. * 350.md; * 351.bwaves; * 352.nab; * 357.bt331; * 358.botsalgn; * 359.botsspar; * 360.ilbdc; * 362.fma3d; * 363.swim; * 367.imagick; * 370.mgrid331; * 371.applu331; * 372.smithwa; * 376.kdtree. OpenCV; ------; https://opencv.org/. OpenMP 4.x SIMD Benchmarks; --------------------------; https://github.com/flwende/simd_benchmarks. PWM-benchmarking; ----------------; https://github.com/tbepler/PWM-benchmarking. SLAMBench; ---------; https://github.c",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst:655,Testability,benchmark,benchmarks,655,"=====================; Test-Suite Extensions; =====================. .. contents::; :depth: 1; :local:. Abstract; ========. These are ideas for additional programs, benchmarks, applications and; algorithms that could be added to the LLVM Test-Suite.; The test-suite could be much larger than it is now, which would help us; detecting compiler errors (crashes, miscompiles) during development. Most probably, the reason why the programs below have not been added to; the test-suite yet is that nobody has found time to do it. But there; might be other issues as well, such as. * Licensing (Support can still be added as external module,; like for the SPEC benchmarks). * Language (in particular, there is no official LLVM frontend; for FORTRAN yet). * Parallelism (currently, all programs in test-suite use; one thread only). Benchmarks; ==========. SPEC CPU 2017; -------------; https://www.spec.org/cpu2017/. The following have not been included yet because they contain Fortran; code. In case of cactuBSSN only a small portion is Fortran. The hosts's; Fortran compiler could be used for these parts. Note that CMake's Ninja generator has difficulties with Fortran. See the; `CMake documentation <https://cmake.org/cmake/help/v3.13/generator/Ninja.html#fortran-support>`_; for details. * 503.bwaves_r/603.bwaves_s; * 507.cactuBSSN_r; * 521.wrf_r/621.wrf_s; * 527.cam4_r/627.cam4_s; * 628.pop2_s; * 548.exchange2_r/648.exchange2_s; * 549.fotonik3d_r/649.fotonik3d_s; * 554.roms_r/654.roms_s. SPEC OMP2012; ------------; https://www.spec.org/omp2012/. * 350.md; * 351.bwaves; * 352.nab; * 357.bt331; * 358.botsalgn; * 359.botsspar; * 360.ilbdc; * 362.fma3d; * 363.swim; * 367.imagick; * 370.mgrid331; * 371.applu331; * 372.smithwa; * 376.kdtree. OpenCV; ------; https://opencv.org/. OpenMP 4.x SIMD Benchmarks; --------------------------; https://github.com/flwende/simd_benchmarks. PWM-benchmarking; ----------------; https://github.com/tbepler/PWM-benchmarking. SLAMBench; ---------; https://github.c",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst:791,Testability,test,test-suite,791,"=====================; Test-Suite Extensions; =====================. .. contents::; :depth: 1; :local:. Abstract; ========. These are ideas for additional programs, benchmarks, applications and; algorithms that could be added to the LLVM Test-Suite.; The test-suite could be much larger than it is now, which would help us; detecting compiler errors (crashes, miscompiles) during development. Most probably, the reason why the programs below have not been added to; the test-suite yet is that nobody has found time to do it. But there; might be other issues as well, such as. * Licensing (Support can still be added as external module,; like for the SPEC benchmarks). * Language (in particular, there is no official LLVM frontend; for FORTRAN yet). * Parallelism (currently, all programs in test-suite use; one thread only). Benchmarks; ==========. SPEC CPU 2017; -------------; https://www.spec.org/cpu2017/. The following have not been included yet because they contain Fortran; code. In case of cactuBSSN only a small portion is Fortran. The hosts's; Fortran compiler could be used for these parts. Note that CMake's Ninja generator has difficulties with Fortran. See the; `CMake documentation <https://cmake.org/cmake/help/v3.13/generator/Ninja.html#fortran-support>`_; for details. * 503.bwaves_r/603.bwaves_s; * 507.cactuBSSN_r; * 521.wrf_r/621.wrf_s; * 527.cam4_r/627.cam4_s; * 628.pop2_s; * 548.exchange2_r/648.exchange2_s; * 549.fotonik3d_r/649.fotonik3d_s; * 554.roms_r/654.roms_s. SPEC OMP2012; ------------; https://www.spec.org/omp2012/. * 350.md; * 351.bwaves; * 352.nab; * 357.bt331; * 358.botsalgn; * 359.botsspar; * 360.ilbdc; * 362.fma3d; * 363.swim; * 367.imagick; * 370.mgrid331; * 371.applu331; * 372.smithwa; * 376.kdtree. OpenCV; ------; https://opencv.org/. OpenMP 4.x SIMD Benchmarks; --------------------------; https://github.com/flwende/simd_benchmarks. PWM-benchmarking; ----------------; https://github.com/tbepler/PWM-benchmarking. SLAMBench; ---------; https://github.c",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst:1886,Testability,benchmark,benchmarking,1886,/. The following have not been included yet because they contain Fortran; code. In case of cactuBSSN only a small portion is Fortran. The hosts's; Fortran compiler could be used for these parts. Note that CMake's Ninja generator has difficulties with Fortran. See the; `CMake documentation <https://cmake.org/cmake/help/v3.13/generator/Ninja.html#fortran-support>`_; for details. * 503.bwaves_r/603.bwaves_s; * 507.cactuBSSN_r; * 521.wrf_r/621.wrf_s; * 527.cam4_r/627.cam4_s; * 628.pop2_s; * 548.exchange2_r/648.exchange2_s; * 549.fotonik3d_r/649.fotonik3d_s; * 554.roms_r/654.roms_s. SPEC OMP2012; ------------; https://www.spec.org/omp2012/. * 350.md; * 351.bwaves; * 352.nab; * 357.bt331; * 358.botsalgn; * 359.botsspar; * 360.ilbdc; * 362.fma3d; * 363.swim; * 367.imagick; * 370.mgrid331; * 371.applu331; * 372.smithwa; * 376.kdtree. OpenCV; ------; https://opencv.org/. OpenMP 4.x SIMD Benchmarks; --------------------------; https://github.com/flwende/simd_benchmarks. PWM-benchmarking; ----------------; https://github.com/tbepler/PWM-benchmarking. SLAMBench; ---------; https://github.com/pamela-project/slambench. FireHose; --------; http://firehose.sandia.gov/. A Benchmark for the C/C++ Standard Library; ------------------------------------------; https://github.com/hiraditya/std-benchmark. OpenBenchmarking.org CPU / Processor Suite; ------------------------------------------; https://openbenchmarking.org/suite/pts/cpu. This is a subset of the; `Phoronix Test Suite <https://github.com/phoronix-test-suite/phoronix-test-suite/>`_; and is itself a collection of benchmark suites. Parboil Benchmarks; ------------------; http://impact.crhc.illinois.edu/parboil/parboil.aspx. MachSuite; ---------; https://breagen.github.io/MachSuite/. Rodinia; -------; http://lava.cs.virginia.edu/Rodinia/download_links.htm. Rodinia has already been partially included in; MultiSource/Benchmarks/Rodinia. Benchmarks still missing are:. * streamcluster; * particlefilter; * nw; * nn; * myocyte; * mummer,MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst:1949,Testability,benchmark,benchmarking,1949,yet because they contain Fortran; code. In case of cactuBSSN only a small portion is Fortran. The hosts's; Fortran compiler could be used for these parts. Note that CMake's Ninja generator has difficulties with Fortran. See the; `CMake documentation <https://cmake.org/cmake/help/v3.13/generator/Ninja.html#fortran-support>`_; for details. * 503.bwaves_r/603.bwaves_s; * 507.cactuBSSN_r; * 521.wrf_r/621.wrf_s; * 527.cam4_r/627.cam4_s; * 628.pop2_s; * 548.exchange2_r/648.exchange2_s; * 549.fotonik3d_r/649.fotonik3d_s; * 554.roms_r/654.roms_s. SPEC OMP2012; ------------; https://www.spec.org/omp2012/. * 350.md; * 351.bwaves; * 352.nab; * 357.bt331; * 358.botsalgn; * 359.botsspar; * 360.ilbdc; * 362.fma3d; * 363.swim; * 367.imagick; * 370.mgrid331; * 371.applu331; * 372.smithwa; * 376.kdtree. OpenCV; ------; https://opencv.org/. OpenMP 4.x SIMD Benchmarks; --------------------------; https://github.com/flwende/simd_benchmarks. PWM-benchmarking; ----------------; https://github.com/tbepler/PWM-benchmarking. SLAMBench; ---------; https://github.com/pamela-project/slambench. FireHose; --------; http://firehose.sandia.gov/. A Benchmark for the C/C++ Standard Library; ------------------------------------------; https://github.com/hiraditya/std-benchmark. OpenBenchmarking.org CPU / Processor Suite; ------------------------------------------; https://openbenchmarking.org/suite/pts/cpu. This is a subset of the; `Phoronix Test Suite <https://github.com/phoronix-test-suite/phoronix-test-suite/>`_; and is itself a collection of benchmark suites. Parboil Benchmarks; ------------------; http://impact.crhc.illinois.edu/parboil/parboil.aspx. MachSuite; ---------; https://breagen.github.io/MachSuite/. Rodinia; -------; http://lava.cs.virginia.edu/Rodinia/download_links.htm. Rodinia has already been partially included in; MultiSource/Benchmarks/Rodinia. Benchmarks still missing are:. * streamcluster; * particlefilter; * nw; * nn; * myocyte; * mummergpu; * lud; * leukocyte; * lavaMD; * kmea,MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst:2200,Testability,benchmark,benchmark,2200, <https://cmake.org/cmake/help/v3.13/generator/Ninja.html#fortran-support>`_; for details. * 503.bwaves_r/603.bwaves_s; * 507.cactuBSSN_r; * 521.wrf_r/621.wrf_s; * 527.cam4_r/627.cam4_s; * 628.pop2_s; * 548.exchange2_r/648.exchange2_s; * 549.fotonik3d_r/649.fotonik3d_s; * 554.roms_r/654.roms_s. SPEC OMP2012; ------------; https://www.spec.org/omp2012/. * 350.md; * 351.bwaves; * 352.nab; * 357.bt331; * 358.botsalgn; * 359.botsspar; * 360.ilbdc; * 362.fma3d; * 363.swim; * 367.imagick; * 370.mgrid331; * 371.applu331; * 372.smithwa; * 376.kdtree. OpenCV; ------; https://opencv.org/. OpenMP 4.x SIMD Benchmarks; --------------------------; https://github.com/flwende/simd_benchmarks. PWM-benchmarking; ----------------; https://github.com/tbepler/PWM-benchmarking. SLAMBench; ---------; https://github.com/pamela-project/slambench. FireHose; --------; http://firehose.sandia.gov/. A Benchmark for the C/C++ Standard Library; ------------------------------------------; https://github.com/hiraditya/std-benchmark. OpenBenchmarking.org CPU / Processor Suite; ------------------------------------------; https://openbenchmarking.org/suite/pts/cpu. This is a subset of the; `Phoronix Test Suite <https://github.com/phoronix-test-suite/phoronix-test-suite/>`_; and is itself a collection of benchmark suites. Parboil Benchmarks; ------------------; http://impact.crhc.illinois.edu/parboil/parboil.aspx. MachSuite; ---------; https://breagen.github.io/MachSuite/. Rodinia; -------; http://lava.cs.virginia.edu/Rodinia/download_links.htm. Rodinia has already been partially included in; MultiSource/Benchmarks/Rodinia. Benchmarks still missing are:. * streamcluster; * particlefilter; * nw; * nn; * myocyte; * mummergpu; * lud; * leukocyte; * lavaMD; * kmeans; * hotspot3D; * heartwall; * cfd; * bfs; * b+tree. vecmathlib tests harness; ------------------------; https://bitbucket.org/eschnett/vecmathlib/wiki/Home. PARSEC; ------; http://parsec.cs.princeton.edu/. Graph500 reference implementations; ----,MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst:2418,Testability,test,test-suite,2418,".fotonik3d_s; * 554.roms_r/654.roms_s. SPEC OMP2012; ------------; https://www.spec.org/omp2012/. * 350.md; * 351.bwaves; * 352.nab; * 357.bt331; * 358.botsalgn; * 359.botsspar; * 360.ilbdc; * 362.fma3d; * 363.swim; * 367.imagick; * 370.mgrid331; * 371.applu331; * 372.smithwa; * 376.kdtree. OpenCV; ------; https://opencv.org/. OpenMP 4.x SIMD Benchmarks; --------------------------; https://github.com/flwende/simd_benchmarks. PWM-benchmarking; ----------------; https://github.com/tbepler/PWM-benchmarking. SLAMBench; ---------; https://github.com/pamela-project/slambench. FireHose; --------; http://firehose.sandia.gov/. A Benchmark for the C/C++ Standard Library; ------------------------------------------; https://github.com/hiraditya/std-benchmark. OpenBenchmarking.org CPU / Processor Suite; ------------------------------------------; https://openbenchmarking.org/suite/pts/cpu. This is a subset of the; `Phoronix Test Suite <https://github.com/phoronix-test-suite/phoronix-test-suite/>`_; and is itself a collection of benchmark suites. Parboil Benchmarks; ------------------; http://impact.crhc.illinois.edu/parboil/parboil.aspx. MachSuite; ---------; https://breagen.github.io/MachSuite/. Rodinia; -------; http://lava.cs.virginia.edu/Rodinia/download_links.htm. Rodinia has already been partially included in; MultiSource/Benchmarks/Rodinia. Benchmarks still missing are:. * streamcluster; * particlefilter; * nw; * nn; * myocyte; * mummergpu; * lud; * leukocyte; * lavaMD; * kmeans; * hotspot3D; * heartwall; * cfd; * bfs; * b+tree. vecmathlib tests harness; ------------------------; https://bitbucket.org/eschnett/vecmathlib/wiki/Home. PARSEC; ------; http://parsec.cs.princeton.edu/. Graph500 reference implementations; ----------------------------------; https://github.com/graph500/graph500/tree/v2-spec. NAS Parallel Benchmarks; -----------------------; https://www.nas.nasa.gov/publications/npb.html. The official benchmark is written in Fortran, but an unofficial; C-translati",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst:2438,Testability,test,test-suite,2438,".fotonik3d_s; * 554.roms_r/654.roms_s. SPEC OMP2012; ------------; https://www.spec.org/omp2012/. * 350.md; * 351.bwaves; * 352.nab; * 357.bt331; * 358.botsalgn; * 359.botsspar; * 360.ilbdc; * 362.fma3d; * 363.swim; * 367.imagick; * 370.mgrid331; * 371.applu331; * 372.smithwa; * 376.kdtree. OpenCV; ------; https://opencv.org/. OpenMP 4.x SIMD Benchmarks; --------------------------; https://github.com/flwende/simd_benchmarks. PWM-benchmarking; ----------------; https://github.com/tbepler/PWM-benchmarking. SLAMBench; ---------; https://github.com/pamela-project/slambench. FireHose; --------; http://firehose.sandia.gov/. A Benchmark for the C/C++ Standard Library; ------------------------------------------; https://github.com/hiraditya/std-benchmark. OpenBenchmarking.org CPU / Processor Suite; ------------------------------------------; https://openbenchmarking.org/suite/pts/cpu. This is a subset of the; `Phoronix Test Suite <https://github.com/phoronix-test-suite/phoronix-test-suite/>`_; and is itself a collection of benchmark suites. Parboil Benchmarks; ------------------; http://impact.crhc.illinois.edu/parboil/parboil.aspx. MachSuite; ---------; https://breagen.github.io/MachSuite/. Rodinia; -------; http://lava.cs.virginia.edu/Rodinia/download_links.htm. Rodinia has already been partially included in; MultiSource/Benchmarks/Rodinia. Benchmarks still missing are:. * streamcluster; * particlefilter; * nw; * nn; * myocyte; * mummergpu; * lud; * leukocyte; * lavaMD; * kmeans; * hotspot3D; * heartwall; * cfd; * bfs; * b+tree. vecmathlib tests harness; ------------------------; https://bitbucket.org/eschnett/vecmathlib/wiki/Home. PARSEC; ------; http://parsec.cs.princeton.edu/. Graph500 reference implementations; ----------------------------------; https://github.com/graph500/graph500/tree/v2-spec. NAS Parallel Benchmarks; -----------------------; https://www.nas.nasa.gov/publications/npb.html. The official benchmark is written in Fortran, but an unofficial; C-translati",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst:2484,Testability,benchmark,benchmark,2484,".fotonik3d_s; * 554.roms_r/654.roms_s. SPEC OMP2012; ------------; https://www.spec.org/omp2012/. * 350.md; * 351.bwaves; * 352.nab; * 357.bt331; * 358.botsalgn; * 359.botsspar; * 360.ilbdc; * 362.fma3d; * 363.swim; * 367.imagick; * 370.mgrid331; * 371.applu331; * 372.smithwa; * 376.kdtree. OpenCV; ------; https://opencv.org/. OpenMP 4.x SIMD Benchmarks; --------------------------; https://github.com/flwende/simd_benchmarks. PWM-benchmarking; ----------------; https://github.com/tbepler/PWM-benchmarking. SLAMBench; ---------; https://github.com/pamela-project/slambench. FireHose; --------; http://firehose.sandia.gov/. A Benchmark for the C/C++ Standard Library; ------------------------------------------; https://github.com/hiraditya/std-benchmark. OpenBenchmarking.org CPU / Processor Suite; ------------------------------------------; https://openbenchmarking.org/suite/pts/cpu. This is a subset of the; `Phoronix Test Suite <https://github.com/phoronix-test-suite/phoronix-test-suite/>`_; and is itself a collection of benchmark suites. Parboil Benchmarks; ------------------; http://impact.crhc.illinois.edu/parboil/parboil.aspx. MachSuite; ---------; https://breagen.github.io/MachSuite/. Rodinia; -------; http://lava.cs.virginia.edu/Rodinia/download_links.htm. Rodinia has already been partially included in; MultiSource/Benchmarks/Rodinia. Benchmarks still missing are:. * streamcluster; * particlefilter; * nw; * nn; * myocyte; * mummergpu; * lud; * leukocyte; * lavaMD; * kmeans; * hotspot3D; * heartwall; * cfd; * bfs; * b+tree. vecmathlib tests harness; ------------------------; https://bitbucket.org/eschnett/vecmathlib/wiki/Home. PARSEC; ------; http://parsec.cs.princeton.edu/. Graph500 reference implementations; ----------------------------------; https://github.com/graph500/graph500/tree/v2-spec. NAS Parallel Benchmarks; -----------------------; https://www.nas.nasa.gov/publications/npb.html. The official benchmark is written in Fortran, but an unofficial; C-translati",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst:3013,Testability,test,tests,3013,"se; --------; http://firehose.sandia.gov/. A Benchmark for the C/C++ Standard Library; ------------------------------------------; https://github.com/hiraditya/std-benchmark. OpenBenchmarking.org CPU / Processor Suite; ------------------------------------------; https://openbenchmarking.org/suite/pts/cpu. This is a subset of the; `Phoronix Test Suite <https://github.com/phoronix-test-suite/phoronix-test-suite/>`_; and is itself a collection of benchmark suites. Parboil Benchmarks; ------------------; http://impact.crhc.illinois.edu/parboil/parboil.aspx. MachSuite; ---------; https://breagen.github.io/MachSuite/. Rodinia; -------; http://lava.cs.virginia.edu/Rodinia/download_links.htm. Rodinia has already been partially included in; MultiSource/Benchmarks/Rodinia. Benchmarks still missing are:. * streamcluster; * particlefilter; * nw; * nn; * myocyte; * mummergpu; * lud; * leukocyte; * lavaMD; * kmeans; * hotspot3D; * heartwall; * cfd; * bfs; * b+tree. vecmathlib tests harness; ------------------------; https://bitbucket.org/eschnett/vecmathlib/wiki/Home. PARSEC; ------; http://parsec.cs.princeton.edu/. Graph500 reference implementations; ----------------------------------; https://github.com/graph500/graph500/tree/v2-spec. NAS Parallel Benchmarks; -----------------------; https://www.nas.nasa.gov/publications/npb.html. The official benchmark is written in Fortran, but an unofficial; C-translation is available as well:; https://github.com/benchmark-subsetting/NPB3.0-omp-C. DARPA HPCS SSCA#2 C/OpenMP reference implementation; ---------------------------------------------------; http://www.highproductivity.org/SSCABmks.htm. This web site does not exist any more, but there seems to be a copy of; some of the benchmarks; https://github.com/gtcasl/hpc-benchmarks/tree/master/SSCA2v2.2. Kokkos; ------; https://github.com/kokkos/kokkos-kernels/tree/master/perf_test; https://github.com/kokkos/kokkos/tree/master/benchmarks. PolyMage; --------; https://github.com/bondhugula/polym",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst:3390,Testability,benchmark,benchmark,3390,"ix-test-suite/>`_; and is itself a collection of benchmark suites. Parboil Benchmarks; ------------------; http://impact.crhc.illinois.edu/parboil/parboil.aspx. MachSuite; ---------; https://breagen.github.io/MachSuite/. Rodinia; -------; http://lava.cs.virginia.edu/Rodinia/download_links.htm. Rodinia has already been partially included in; MultiSource/Benchmarks/Rodinia. Benchmarks still missing are:. * streamcluster; * particlefilter; * nw; * nn; * myocyte; * mummergpu; * lud; * leukocyte; * lavaMD; * kmeans; * hotspot3D; * heartwall; * cfd; * bfs; * b+tree. vecmathlib tests harness; ------------------------; https://bitbucket.org/eschnett/vecmathlib/wiki/Home. PARSEC; ------; http://parsec.cs.princeton.edu/. Graph500 reference implementations; ----------------------------------; https://github.com/graph500/graph500/tree/v2-spec. NAS Parallel Benchmarks; -----------------------; https://www.nas.nasa.gov/publications/npb.html. The official benchmark is written in Fortran, but an unofficial; C-translation is available as well:; https://github.com/benchmark-subsetting/NPB3.0-omp-C. DARPA HPCS SSCA#2 C/OpenMP reference implementation; ---------------------------------------------------; http://www.highproductivity.org/SSCABmks.htm. This web site does not exist any more, but there seems to be a copy of; some of the benchmarks; https://github.com/gtcasl/hpc-benchmarks/tree/master/SSCA2v2.2. Kokkos; ------; https://github.com/kokkos/kokkos-kernels/tree/master/perf_test; https://github.com/kokkos/kokkos/tree/master/benchmarks. PolyMage; --------; https://github.com/bondhugula/polymage-benchmarks. PolyBench; ---------; https://sourceforge.net/projects/polybench/. A modified version of Polybench 3.2 is already presented in; SingleSource/Benchmarks/Polybench. A newer version 4.2.1 is available. High Performance Geometric Multigrid; ------------------------------------; https://crd.lbl.gov/departments/computer-science/PAR/research/hpgmg/. RAJA Performance Suite; -------------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst:3498,Testability,benchmark,benchmark-subsetting,3498," Benchmarks; ------------------; http://impact.crhc.illinois.edu/parboil/parboil.aspx. MachSuite; ---------; https://breagen.github.io/MachSuite/. Rodinia; -------; http://lava.cs.virginia.edu/Rodinia/download_links.htm. Rodinia has already been partially included in; MultiSource/Benchmarks/Rodinia. Benchmarks still missing are:. * streamcluster; * particlefilter; * nw; * nn; * myocyte; * mummergpu; * lud; * leukocyte; * lavaMD; * kmeans; * hotspot3D; * heartwall; * cfd; * bfs; * b+tree. vecmathlib tests harness; ------------------------; https://bitbucket.org/eschnett/vecmathlib/wiki/Home. PARSEC; ------; http://parsec.cs.princeton.edu/. Graph500 reference implementations; ----------------------------------; https://github.com/graph500/graph500/tree/v2-spec. NAS Parallel Benchmarks; -----------------------; https://www.nas.nasa.gov/publications/npb.html. The official benchmark is written in Fortran, but an unofficial; C-translation is available as well:; https://github.com/benchmark-subsetting/NPB3.0-omp-C. DARPA HPCS SSCA#2 C/OpenMP reference implementation; ---------------------------------------------------; http://www.highproductivity.org/SSCABmks.htm. This web site does not exist any more, but there seems to be a copy of; some of the benchmarks; https://github.com/gtcasl/hpc-benchmarks/tree/master/SSCA2v2.2. Kokkos; ------; https://github.com/kokkos/kokkos-kernels/tree/master/perf_test; https://github.com/kokkos/kokkos/tree/master/benchmarks. PolyMage; --------; https://github.com/bondhugula/polymage-benchmarks. PolyBench; ---------; https://sourceforge.net/projects/polybench/. A modified version of Polybench 3.2 is already presented in; SingleSource/Benchmarks/Polybench. A newer version 4.2.1 is available. High Performance Geometric Multigrid; ------------------------------------; https://crd.lbl.gov/departments/computer-science/PAR/research/hpgmg/. RAJA Performance Suite; ----------------------; https://github.com/LLNL/RAJAPerf. CORAL-2 Benchmarks; ---------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst:3769,Testability,benchmark,benchmarks,3769,"s already been partially included in; MultiSource/Benchmarks/Rodinia. Benchmarks still missing are:. * streamcluster; * particlefilter; * nw; * nn; * myocyte; * mummergpu; * lud; * leukocyte; * lavaMD; * kmeans; * hotspot3D; * heartwall; * cfd; * bfs; * b+tree. vecmathlib tests harness; ------------------------; https://bitbucket.org/eschnett/vecmathlib/wiki/Home. PARSEC; ------; http://parsec.cs.princeton.edu/. Graph500 reference implementations; ----------------------------------; https://github.com/graph500/graph500/tree/v2-spec. NAS Parallel Benchmarks; -----------------------; https://www.nas.nasa.gov/publications/npb.html. The official benchmark is written in Fortran, but an unofficial; C-translation is available as well:; https://github.com/benchmark-subsetting/NPB3.0-omp-C. DARPA HPCS SSCA#2 C/OpenMP reference implementation; ---------------------------------------------------; http://www.highproductivity.org/SSCABmks.htm. This web site does not exist any more, but there seems to be a copy of; some of the benchmarks; https://github.com/gtcasl/hpc-benchmarks/tree/master/SSCA2v2.2. Kokkos; ------; https://github.com/kokkos/kokkos-kernels/tree/master/perf_test; https://github.com/kokkos/kokkos/tree/master/benchmarks. PolyMage; --------; https://github.com/bondhugula/polymage-benchmarks. PolyBench; ---------; https://sourceforge.net/projects/polybench/. A modified version of Polybench 3.2 is already presented in; SingleSource/Benchmarks/Polybench. A newer version 4.2.1 is available. High Performance Geometric Multigrid; ------------------------------------; https://crd.lbl.gov/departments/computer-science/PAR/research/hpgmg/. RAJA Performance Suite; ----------------------; https://github.com/LLNL/RAJAPerf. CORAL-2 Benchmarks; ------------------; https://asc.llnl.gov/coral-2-benchmarks/. Many of its programs have already been integrated in; MultiSource/Benchmarks/DOE-ProxyApps-C and; MultiSource/Benchmarks/DOE-ProxyApps-C++. * Nekbone; * QMCPack; * LAMMPS; * Krip",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst:3811,Testability,benchmark,benchmarks,3811,"s still missing are:. * streamcluster; * particlefilter; * nw; * nn; * myocyte; * mummergpu; * lud; * leukocyte; * lavaMD; * kmeans; * hotspot3D; * heartwall; * cfd; * bfs; * b+tree. vecmathlib tests harness; ------------------------; https://bitbucket.org/eschnett/vecmathlib/wiki/Home. PARSEC; ------; http://parsec.cs.princeton.edu/. Graph500 reference implementations; ----------------------------------; https://github.com/graph500/graph500/tree/v2-spec. NAS Parallel Benchmarks; -----------------------; https://www.nas.nasa.gov/publications/npb.html. The official benchmark is written in Fortran, but an unofficial; C-translation is available as well:; https://github.com/benchmark-subsetting/NPB3.0-omp-C. DARPA HPCS SSCA#2 C/OpenMP reference implementation; ---------------------------------------------------; http://www.highproductivity.org/SSCABmks.htm. This web site does not exist any more, but there seems to be a copy of; some of the benchmarks; https://github.com/gtcasl/hpc-benchmarks/tree/master/SSCA2v2.2. Kokkos; ------; https://github.com/kokkos/kokkos-kernels/tree/master/perf_test; https://github.com/kokkos/kokkos/tree/master/benchmarks. PolyMage; --------; https://github.com/bondhugula/polymage-benchmarks. PolyBench; ---------; https://sourceforge.net/projects/polybench/. A modified version of Polybench 3.2 is already presented in; SingleSource/Benchmarks/Polybench. A newer version 4.2.1 is available. High Performance Geometric Multigrid; ------------------------------------; https://crd.lbl.gov/departments/computer-science/PAR/research/hpgmg/. RAJA Performance Suite; ----------------------; https://github.com/LLNL/RAJAPerf. CORAL-2 Benchmarks; ------------------; https://asc.llnl.gov/coral-2-benchmarks/. Many of its programs have already been integrated in; MultiSource/Benchmarks/DOE-ProxyApps-C and; MultiSource/Benchmarks/DOE-ProxyApps-C++. * Nekbone; * QMCPack; * LAMMPS; * Kripke; * Quicksilver; * PENNANT; * Big Data Analytic Suite; * Deep Learning Suite;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst:3970,Testability,benchmark,benchmarks,3970,"t3D; * heartwall; * cfd; * bfs; * b+tree. vecmathlib tests harness; ------------------------; https://bitbucket.org/eschnett/vecmathlib/wiki/Home. PARSEC; ------; http://parsec.cs.princeton.edu/. Graph500 reference implementations; ----------------------------------; https://github.com/graph500/graph500/tree/v2-spec. NAS Parallel Benchmarks; -----------------------; https://www.nas.nasa.gov/publications/npb.html. The official benchmark is written in Fortran, but an unofficial; C-translation is available as well:; https://github.com/benchmark-subsetting/NPB3.0-omp-C. DARPA HPCS SSCA#2 C/OpenMP reference implementation; ---------------------------------------------------; http://www.highproductivity.org/SSCABmks.htm. This web site does not exist any more, but there seems to be a copy of; some of the benchmarks; https://github.com/gtcasl/hpc-benchmarks/tree/master/SSCA2v2.2. Kokkos; ------; https://github.com/kokkos/kokkos-kernels/tree/master/perf_test; https://github.com/kokkos/kokkos/tree/master/benchmarks. PolyMage; --------; https://github.com/bondhugula/polymage-benchmarks. PolyBench; ---------; https://sourceforge.net/projects/polybench/. A modified version of Polybench 3.2 is already presented in; SingleSource/Benchmarks/Polybench. A newer version 4.2.1 is available. High Performance Geometric Multigrid; ------------------------------------; https://crd.lbl.gov/departments/computer-science/PAR/research/hpgmg/. RAJA Performance Suite; ----------------------; https://github.com/LLNL/RAJAPerf. CORAL-2 Benchmarks; ------------------; https://asc.llnl.gov/coral-2-benchmarks/. Many of its programs have already been integrated in; MultiSource/Benchmarks/DOE-ProxyApps-C and; MultiSource/Benchmarks/DOE-ProxyApps-C++. * Nekbone; * QMCPack; * LAMMPS; * Kripke; * Quicksilver; * PENNANT; * Big Data Analytic Suite; * Deep Learning Suite; * Stream; * Stride; * ML/DL micro-benchmark; * Pynamic; * ACME; * VPIC; * Laghos; * Parallel Integer Sort; * Havoq. NWChem; ------; http://ww",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst:4041,Testability,benchmark,benchmarks,4041,"------------------; https://bitbucket.org/eschnett/vecmathlib/wiki/Home. PARSEC; ------; http://parsec.cs.princeton.edu/. Graph500 reference implementations; ----------------------------------; https://github.com/graph500/graph500/tree/v2-spec. NAS Parallel Benchmarks; -----------------------; https://www.nas.nasa.gov/publications/npb.html. The official benchmark is written in Fortran, but an unofficial; C-translation is available as well:; https://github.com/benchmark-subsetting/NPB3.0-omp-C. DARPA HPCS SSCA#2 C/OpenMP reference implementation; ---------------------------------------------------; http://www.highproductivity.org/SSCABmks.htm. This web site does not exist any more, but there seems to be a copy of; some of the benchmarks; https://github.com/gtcasl/hpc-benchmarks/tree/master/SSCA2v2.2. Kokkos; ------; https://github.com/kokkos/kokkos-kernels/tree/master/perf_test; https://github.com/kokkos/kokkos/tree/master/benchmarks. PolyMage; --------; https://github.com/bondhugula/polymage-benchmarks. PolyBench; ---------; https://sourceforge.net/projects/polybench/. A modified version of Polybench 3.2 is already presented in; SingleSource/Benchmarks/Polybench. A newer version 4.2.1 is available. High Performance Geometric Multigrid; ------------------------------------; https://crd.lbl.gov/departments/computer-science/PAR/research/hpgmg/. RAJA Performance Suite; ----------------------; https://github.com/LLNL/RAJAPerf. CORAL-2 Benchmarks; ------------------; https://asc.llnl.gov/coral-2-benchmarks/. Many of its programs have already been integrated in; MultiSource/Benchmarks/DOE-ProxyApps-C and; MultiSource/Benchmarks/DOE-ProxyApps-C++. * Nekbone; * QMCPack; * LAMMPS; * Kripke; * Quicksilver; * PENNANT; * Big Data Analytic Suite; * Deep Learning Suite; * Stream; * Stride; * ML/DL micro-benchmark; * Pynamic; * ACME; * VPIC; * Laghos; * Parallel Integer Sort; * Havoq. NWChem; ------; http://www.nwchem-sw.org/index.php/Benchmarks. TVM; ----; https://github.com/dmlc/t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst:4549,Testability,benchmark,benchmarks,4549,"2 C/OpenMP reference implementation; ---------------------------------------------------; http://www.highproductivity.org/SSCABmks.htm. This web site does not exist any more, but there seems to be a copy of; some of the benchmarks; https://github.com/gtcasl/hpc-benchmarks/tree/master/SSCA2v2.2. Kokkos; ------; https://github.com/kokkos/kokkos-kernels/tree/master/perf_test; https://github.com/kokkos/kokkos/tree/master/benchmarks. PolyMage; --------; https://github.com/bondhugula/polymage-benchmarks. PolyBench; ---------; https://sourceforge.net/projects/polybench/. A modified version of Polybench 3.2 is already presented in; SingleSource/Benchmarks/Polybench. A newer version 4.2.1 is available. High Performance Geometric Multigrid; ------------------------------------; https://crd.lbl.gov/departments/computer-science/PAR/research/hpgmg/. RAJA Performance Suite; ----------------------; https://github.com/LLNL/RAJAPerf. CORAL-2 Benchmarks; ------------------; https://asc.llnl.gov/coral-2-benchmarks/. Many of its programs have already been integrated in; MultiSource/Benchmarks/DOE-ProxyApps-C and; MultiSource/Benchmarks/DOE-ProxyApps-C++. * Nekbone; * QMCPack; * LAMMPS; * Kripke; * Quicksilver; * PENNANT; * Big Data Analytic Suite; * Deep Learning Suite; * Stream; * Stride; * ML/DL micro-benchmark; * Pynamic; * ACME; * VPIC; * Laghos; * Parallel Integer Sort; * Havoq. NWChem; ------; http://www.nwchem-sw.org/index.php/Benchmarks. TVM; ----; https://github.com/dmlc/tvm/tree/main/apps/benchmark. HydroBench; ----------; https://github.com/HydroBench/Hydro. ParRes; ------; https://github.com/ParRes/Kernels/tree/default/Cxx11. Applications/Libraries; ======================. GnuPG; -----; https://gnupg.org/. Blitz++; -------; https://sourceforge.net/projects/blitz/. FFmpeg; ------; https://ffmpeg.org/. FreePOOMA; ---------; http://www.nongnu.org/freepooma/. FTensors; --------; http://www.wlandry.net/Projects/FTensor. rawspeed; --------; https://github.com/darktable-org/rawspe",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst:4854,Testability,benchmark,benchmark,4854,"rks/tree/master/SSCA2v2.2. Kokkos; ------; https://github.com/kokkos/kokkos-kernels/tree/master/perf_test; https://github.com/kokkos/kokkos/tree/master/benchmarks. PolyMage; --------; https://github.com/bondhugula/polymage-benchmarks. PolyBench; ---------; https://sourceforge.net/projects/polybench/. A modified version of Polybench 3.2 is already presented in; SingleSource/Benchmarks/Polybench. A newer version 4.2.1 is available. High Performance Geometric Multigrid; ------------------------------------; https://crd.lbl.gov/departments/computer-science/PAR/research/hpgmg/. RAJA Performance Suite; ----------------------; https://github.com/LLNL/RAJAPerf. CORAL-2 Benchmarks; ------------------; https://asc.llnl.gov/coral-2-benchmarks/. Many of its programs have already been integrated in; MultiSource/Benchmarks/DOE-ProxyApps-C and; MultiSource/Benchmarks/DOE-ProxyApps-C++. * Nekbone; * QMCPack; * LAMMPS; * Kripke; * Quicksilver; * PENNANT; * Big Data Analytic Suite; * Deep Learning Suite; * Stream; * Stride; * ML/DL micro-benchmark; * Pynamic; * ACME; * VPIC; * Laghos; * Parallel Integer Sort; * Havoq. NWChem; ------; http://www.nwchem-sw.org/index.php/Benchmarks. TVM; ----; https://github.com/dmlc/tvm/tree/main/apps/benchmark. HydroBench; ----------; https://github.com/HydroBench/Hydro. ParRes; ------; https://github.com/ParRes/Kernels/tree/default/Cxx11. Applications/Libraries; ======================. GnuPG; -----; https://gnupg.org/. Blitz++; -------; https://sourceforge.net/projects/blitz/. FFmpeg; ------; https://ffmpeg.org/. FreePOOMA; ---------; http://www.nongnu.org/freepooma/. FTensors; --------; http://www.wlandry.net/Projects/FTensor. rawspeed; --------; https://github.com/darktable-org/rawspeed. Its test dataset is 756 MB in size, which is too large to be included; into the test-suite repository. C++ Performance Benchmarks; --------------------------; https://gitlab.com/chriscox/CppPerformanceBenchmarks. Generic Algorithms; ==================. Image proces",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst:5053,Testability,benchmark,benchmark,5053,"chmarks. PolyBench; ---------; https://sourceforge.net/projects/polybench/. A modified version of Polybench 3.2 is already presented in; SingleSource/Benchmarks/Polybench. A newer version 4.2.1 is available. High Performance Geometric Multigrid; ------------------------------------; https://crd.lbl.gov/departments/computer-science/PAR/research/hpgmg/. RAJA Performance Suite; ----------------------; https://github.com/LLNL/RAJAPerf. CORAL-2 Benchmarks; ------------------; https://asc.llnl.gov/coral-2-benchmarks/. Many of its programs have already been integrated in; MultiSource/Benchmarks/DOE-ProxyApps-C and; MultiSource/Benchmarks/DOE-ProxyApps-C++. * Nekbone; * QMCPack; * LAMMPS; * Kripke; * Quicksilver; * PENNANT; * Big Data Analytic Suite; * Deep Learning Suite; * Stream; * Stride; * ML/DL micro-benchmark; * Pynamic; * ACME; * VPIC; * Laghos; * Parallel Integer Sort; * Havoq. NWChem; ------; http://www.nwchem-sw.org/index.php/Benchmarks. TVM; ----; https://github.com/dmlc/tvm/tree/main/apps/benchmark. HydroBench; ----------; https://github.com/HydroBench/Hydro. ParRes; ------; https://github.com/ParRes/Kernels/tree/default/Cxx11. Applications/Libraries; ======================. GnuPG; -----; https://gnupg.org/. Blitz++; -------; https://sourceforge.net/projects/blitz/. FFmpeg; ------; https://ffmpeg.org/. FreePOOMA; ---------; http://www.nongnu.org/freepooma/. FTensors; --------; http://www.wlandry.net/Projects/FTensor. rawspeed; --------; https://github.com/darktable-org/rawspeed. Its test dataset is 756 MB in size, which is too large to be included; into the test-suite repository. C++ Performance Benchmarks; --------------------------; https://gitlab.com/chriscox/CppPerformanceBenchmarks. Generic Algorithms; ==================. Image processing; ----------------. Resampling; ``````````. * Bilinear; * Bicubic; * Lanczos. Dither; ``````. * Threshold; * Random; * Halftone; * Bayer; * Floyd-Steinberg; * Jarvis; * Stucki; * Burkes; * Sierra; * Atkinson; * Gradient-ba",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst:5557,Testability,test,test,5557,"ormance Suite; ----------------------; https://github.com/LLNL/RAJAPerf. CORAL-2 Benchmarks; ------------------; https://asc.llnl.gov/coral-2-benchmarks/. Many of its programs have already been integrated in; MultiSource/Benchmarks/DOE-ProxyApps-C and; MultiSource/Benchmarks/DOE-ProxyApps-C++. * Nekbone; * QMCPack; * LAMMPS; * Kripke; * Quicksilver; * PENNANT; * Big Data Analytic Suite; * Deep Learning Suite; * Stream; * Stride; * ML/DL micro-benchmark; * Pynamic; * ACME; * VPIC; * Laghos; * Parallel Integer Sort; * Havoq. NWChem; ------; http://www.nwchem-sw.org/index.php/Benchmarks. TVM; ----; https://github.com/dmlc/tvm/tree/main/apps/benchmark. HydroBench; ----------; https://github.com/HydroBench/Hydro. ParRes; ------; https://github.com/ParRes/Kernels/tree/default/Cxx11. Applications/Libraries; ======================. GnuPG; -----; https://gnupg.org/. Blitz++; -------; https://sourceforge.net/projects/blitz/. FFmpeg; ------; https://ffmpeg.org/. FreePOOMA; ---------; http://www.nongnu.org/freepooma/. FTensors; --------; http://www.wlandry.net/Projects/FTensor. rawspeed; --------; https://github.com/darktable-org/rawspeed. Its test dataset is 756 MB in size, which is too large to be included; into the test-suite repository. C++ Performance Benchmarks; --------------------------; https://gitlab.com/chriscox/CppPerformanceBenchmarks. Generic Algorithms; ==================. Image processing; ----------------. Resampling; ``````````. * Bilinear; * Bicubic; * Lanczos. Dither; ``````. * Threshold; * Random; * Halftone; * Bayer; * Floyd-Steinberg; * Jarvis; * Stucki; * Burkes; * Sierra; * Atkinson; * Gradient-based. Feature detection; `````````````````. * Harris; * Histogram of Oriented Gradients. Color conversion; ````````````````. * RGB to grayscale; * HSL to RGB. Graph; -----. Search Algorithms; `````````````````. * Breadth-First-Search; * Depth-First-Search; * Dijkstra's algorithm; * A-Star. Spanning Tree; `````````````. * Kruskal's algorithm; * Prim's algorithm; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst:5633,Testability,test,test-suite,5633,"ormance Suite; ----------------------; https://github.com/LLNL/RAJAPerf. CORAL-2 Benchmarks; ------------------; https://asc.llnl.gov/coral-2-benchmarks/. Many of its programs have already been integrated in; MultiSource/Benchmarks/DOE-ProxyApps-C and; MultiSource/Benchmarks/DOE-ProxyApps-C++. * Nekbone; * QMCPack; * LAMMPS; * Kripke; * Quicksilver; * PENNANT; * Big Data Analytic Suite; * Deep Learning Suite; * Stream; * Stride; * ML/DL micro-benchmark; * Pynamic; * ACME; * VPIC; * Laghos; * Parallel Integer Sort; * Havoq. NWChem; ------; http://www.nwchem-sw.org/index.php/Benchmarks. TVM; ----; https://github.com/dmlc/tvm/tree/main/apps/benchmark. HydroBench; ----------; https://github.com/HydroBench/Hydro. ParRes; ------; https://github.com/ParRes/Kernels/tree/default/Cxx11. Applications/Libraries; ======================. GnuPG; -----; https://gnupg.org/. Blitz++; -------; https://sourceforge.net/projects/blitz/. FFmpeg; ------; https://ffmpeg.org/. FreePOOMA; ---------; http://www.nongnu.org/freepooma/. FTensors; --------; http://www.wlandry.net/Projects/FTensor. rawspeed; --------; https://github.com/darktable-org/rawspeed. Its test dataset is 756 MB in size, which is too large to be included; into the test-suite repository. C++ Performance Benchmarks; --------------------------; https://gitlab.com/chriscox/CppPerformanceBenchmarks. Generic Algorithms; ==================. Image processing; ----------------. Resampling; ``````````. * Bilinear; * Bicubic; * Lanczos. Dither; ``````. * Threshold; * Random; * Halftone; * Bayer; * Floyd-Steinberg; * Jarvis; * Stucki; * Burkes; * Sierra; * Atkinson; * Gradient-based. Feature detection; `````````````````. * Harris; * Histogram of Oriented Gradients. Color conversion; ````````````````. * RGB to grayscale; * HSL to RGB. Graph; -----. Search Algorithms; `````````````````. * Breadth-First-Search; * Depth-First-Search; * Dijkstra's algorithm; * A-Star. Spanning Tree; `````````````. * Kruskal's algorithm; * Prim's algorithm; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/TestSuite.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/VariableNames.rst:7842,Availability,down,downstream,7842,"`remarkEmitter``; or even ``remarker``. The following is a list of longer class names and the associated shorter; variable name. ========================= =============; Class name Variable name; ========================= =============; BasicBlock block; ConstantExpr expr; ExecutionEngine engine; MachineOperand operand; OptimizationRemarkEmitter remarker; PreservedAnalyses analyses; PreservedAnalysesChecker checker; TargetLowering lowering; TargetMachine machine; ========================= =============. Transition Options; ==================. There are three main options for transitioning:. 1. Keep the current coding standard; 2. Laissez faire; 3. Big bang. Keep the current coding standard; --------------------------------. Proponents of keeping the current coding standard (i.e. not transitioning at; all) question whether the cost of transition outweighs the benefit; [EmersonConcern]_ [ReamesConcern]_ [BradburyConcern]_.; The costs are that ``git blame`` will become less usable; and that merging the; changes will be costly for downstream maintainers. See `Big bang`_ for potential; mitigations. Laissez faire; -------------. The coding standard could allow both ``CamelCase`` and ``camelBack`` styles for; variable names [LattnerTransition]_. A code review to implement this is at https://reviews.llvm.org/D57896. Advantages; **********. * Very easy to implement initially. Disadvantages; *************. * Leads to inconsistency [BradburyConcern]_ [AminiInconsistent]_.; * Inconsistency means it will be hard to know at a guess what name a variable; will have [DasInconsistent]_ [CarruthInconsistent]_.; * Some large-scale renaming may happen anyway, leading to its disadvantages; without any mitigations. Big bang; --------. With this approach, variables will be renamed by an automated script in a series; of large commits. The principle advantage of this approach is that it minimises the cost of; inconsistency [BradburyTransition]_ [RobinsonTransition]_. It goes against a policy",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/VariableNames.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/VariableNames.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/VariableNames.rst:9877,Availability,down,downstream,9877,"ted that LLD would be a good starter project for the renaming; [Ueyama]_. Keeping git blame usable; ************************. ``git blame`` (or ``git annotate``) permits quickly identifying the commit that; changed a given line in a file. After renaming variables, many lines will show; as being changed by that one commit, requiring a further invocation of ``git; blame`` to identify prior, more interesting commits [GreeneGitBlame]_; [RicciAcronyms]_. **Mitigation**: `git-hyper-blame; <https://commondatastorage.googleapis.com/chrome-infra-docs/flat/depot_tools/docs/html/git-hyper-blame.html>`_; can ignore or ""look through"" a given set of commits.; A ``.git-blame-ignore-revs`` file identifying the variable renaming commits; could be added to the LLVM git repository root directory.; It is being `investigated; <https://public-inbox.org/git/20190324235020.49706-1-michael@platin.gs/>`_; whether similar functionality could be added to ``git blame`` itself. Minimising cost of downstream merges; ************************************. There are many forks of LLVM with downstream changes. Merging a large-scale; renaming change could be difficult for the fork maintainers. **Mitigation**: A large-scale renaming would be automated. A fork maintainer can; merge from the commit immediately before the renaming, then apply the renaming; script to their own branch. They can then merge again from the renaming commit,; resolving all conflicts by choosing their own version. This could be tested on; the [SVE]_ fork. Provisional Plan; ================. This is a provisional plan for the `Big bang`_ approach. It has not been agreed. #. Investigate improving ``git blame``. The extent to which it can be made to; ""look through"" commits may impact how big a change can be made. #. Write a script to expand acronyms. #. Experiment and perform dry runs of the various refactoring options.; Results can be published in forks of the LLVM Git repository. #. Consider the evidence and agree on the new polic",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/VariableNames.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/VariableNames.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/VariableNames.rst:9968,Availability,down,downstream,9968,"eyama]_. Keeping git blame usable; ************************. ``git blame`` (or ``git annotate``) permits quickly identifying the commit that; changed a given line in a file. After renaming variables, many lines will show; as being changed by that one commit, requiring a further invocation of ``git; blame`` to identify prior, more interesting commits [GreeneGitBlame]_; [RicciAcronyms]_. **Mitigation**: `git-hyper-blame; <https://commondatastorage.googleapis.com/chrome-infra-docs/flat/depot_tools/docs/html/git-hyper-blame.html>`_; can ignore or ""look through"" a given set of commits.; A ``.git-blame-ignore-revs`` file identifying the variable renaming commits; could be added to the LLVM git repository root directory.; It is being `investigated; <https://public-inbox.org/git/20190324235020.49706-1-michael@platin.gs/>`_; whether similar functionality could be added to ``git blame`` itself. Minimising cost of downstream merges; ************************************. There are many forks of LLVM with downstream changes. Merging a large-scale; renaming change could be difficult for the fork maintainers. **Mitigation**: A large-scale renaming would be automated. A fork maintainer can; merge from the commit immediately before the renaming, then apply the renaming; script to their own branch. They can then merge again from the renaming commit,; resolving all conflicts by choosing their own version. This could be tested on; the [SVE]_ fork. Provisional Plan; ================. This is a provisional plan for the `Big bang`_ approach. It has not been agreed. #. Investigate improving ``git blame``. The extent to which it can be made to; ""look through"" commits may impact how big a change can be made. #. Write a script to expand acronyms. #. Experiment and perform dry runs of the various refactoring options.; Results can be published in forks of the LLVM Git repository. #. Consider the evidence and agree on the new policy. #. Agree & announce a date for the renaming of the starter pro",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/VariableNames.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/VariableNames.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/VariableNames.rst:11321,Availability,down,downstream,11321,"gain from the renaming commit,; resolving all conflicts by choosing their own version. This could be tested on; the [SVE]_ fork. Provisional Plan; ================. This is a provisional plan for the `Big bang`_ approach. It has not been agreed. #. Investigate improving ``git blame``. The extent to which it can be made to; ""look through"" commits may impact how big a change can be made. #. Write a script to expand acronyms. #. Experiment and perform dry runs of the various refactoring options.; Results can be published in forks of the LLVM Git repository. #. Consider the evidence and agree on the new policy. #. Agree & announce a date for the renaming of the starter project (LLD). #. Update the `policy page <../CodingStandards.html>`_. This will explain the; old and new rules and which projects each applies to. #. Refactor the starter project in two commits:. 1. Add or change the project's .clang-tidy to reflect the agreed rules.; (This is in a separate commit to enable the merging process described in; `Minimising cost of downstream merges`_).; Also update the project list on the policy page.; 2. Apply ``clang-tidy`` to the project's files, with only the; ``readability-identifier-naming`` rules enabled. ``clang-tidy`` will also; reformat the affected lines according to the rules in ``.clang-format``.; It is anticipated that this will be a good dog-fooding opportunity for; clang-tidy, and bugs should be fixed in the process, likely including:. * `readability-identifier-naming incorrectly fixes lambda capture; <https://bugs.llvm.org/show_bug.cgi?id=41119>`_.; * `readability-identifier-naming incorrectly fixes variables which; become keywords <https://bugs.llvm.org/show_bug.cgi?id=41120>`_.; * `readability-identifier-naming misses fixing member variables in; destructor <https://bugs.llvm.org/show_bug.cgi?id=41122>`_. #. Gather feedback and refine the process as appropriate. #. Apply the process to the following projects, with a suitable delay between; each (at least 4 w",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/VariableNames.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/VariableNames.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/VariableNames.rst:11349,Deployability,update,update,11349,"n. This could be tested on; the [SVE]_ fork. Provisional Plan; ================. This is a provisional plan for the `Big bang`_ approach. It has not been agreed. #. Investigate improving ``git blame``. The extent to which it can be made to; ""look through"" commits may impact how big a change can be made. #. Write a script to expand acronyms. #. Experiment and perform dry runs of the various refactoring options.; Results can be published in forks of the LLVM Git repository. #. Consider the evidence and agree on the new policy. #. Agree & announce a date for the renaming of the starter project (LLD). #. Update the `policy page <../CodingStandards.html>`_. This will explain the; old and new rules and which projects each applies to. #. Refactor the starter project in two commits:. 1. Add or change the project's .clang-tidy to reflect the agreed rules.; (This is in a separate commit to enable the merging process described in; `Minimising cost of downstream merges`_).; Also update the project list on the policy page.; 2. Apply ``clang-tidy`` to the project's files, with only the; ``readability-identifier-naming`` rules enabled. ``clang-tidy`` will also; reformat the affected lines according to the rules in ``.clang-format``.; It is anticipated that this will be a good dog-fooding opportunity for; clang-tidy, and bugs should be fixed in the process, likely including:. * `readability-identifier-naming incorrectly fixes lambda capture; <https://bugs.llvm.org/show_bug.cgi?id=41119>`_.; * `readability-identifier-naming incorrectly fixes variables which; become keywords <https://bugs.llvm.org/show_bug.cgi?id=41120>`_.; * `readability-identifier-naming misses fixing member variables in; destructor <https://bugs.llvm.org/show_bug.cgi?id=41122>`_. #. Gather feedback and refine the process as appropriate. #. Apply the process to the following projects, with a suitable delay between; each (at least 4 weeks after the first change, at least 2 weeks subsequently); to allow gathering fur",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/VariableNames.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/VariableNames.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/VariableNames.rst:747,Modifiability,variab,variable,747,"===================; Variable Names Plan; ===================. .. contents::; :local:. This plan is *provisional*. It is not agreed upon. It is written with the; intention of capturing the desires and concerns of the LLVM community, and; forming them into a plan that can be agreed upon.; The original author is somewhat naïve in the ways of LLVM so there will; inevitably be some details that are flawed. You can help - you can edit this; page (preferably with a Phabricator review for larger changes) or reply to the; `Request For Comments thread; <http://lists.llvm.org/pipermail/llvm-dev/2019-February/130083.html>`_. Too Long; Didn't Read; =====================. Improve the readability of LLVM code. Introduction; ============. The current `variable naming rule; <../CodingStandards.html#name-types-functions-variables-and-enumerators-properly>`_; states:. Variable names should be nouns (as they represent state). The name should be; camel case, and start with an upper case letter (e.g. Leader or Boats). This rule is the same as that for type names. This is a problem because the; type name cannot be reused for a variable name [*]_. LLVM developers tend to; work around this by either prepending ``The`` to the type name::. Triple TheTriple;. ... or more commonly use an acronym, despite the coding standard stating ""Avoid; abbreviations unless they are well known""::. Triple T;. The proliferation of acronyms leads to hard-to-read code such as `this; <https://github.com/llvm/llvm-project/blob/0a8bc14ad7f3209fe702d18e250194cd90188596/llvm/lib/Transforms/Vectorize/LoopVectorize.cpp#L7445>`_::. InnerLoopVectorizer LB(L, PSE, LI, DT, TLI, TTI, AC, ORE, VF.Width, IC,; &LVL, &CM);. Many other coding guidelines [LLDB]_ [Google]_ [WebKit]_ [Qt]_ [Rust]_ [Swift]_; [Python]_ require that variable names begin with a lower case letter in contrast; to class names which begin with a capital letter. This convention means that the; most readable variable name also requires the least thought::. T",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/VariableNames.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/VariableNames.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/VariableNames.rst:815,Modifiability,variab,variables-and-enumerators-properly,815,"===================; Variable Names Plan; ===================. .. contents::; :local:. This plan is *provisional*. It is not agreed upon. It is written with the; intention of capturing the desires and concerns of the LLVM community, and; forming them into a plan that can be agreed upon.; The original author is somewhat naïve in the ways of LLVM so there will; inevitably be some details that are flawed. You can help - you can edit this; page (preferably with a Phabricator review for larger changes) or reply to the; `Request For Comments thread; <http://lists.llvm.org/pipermail/llvm-dev/2019-February/130083.html>`_. Too Long; Didn't Read; =====================. Improve the readability of LLVM code. Introduction; ============. The current `variable naming rule; <../CodingStandards.html#name-types-functions-variables-and-enumerators-properly>`_; states:. Variable names should be nouns (as they represent state). The name should be; camel case, and start with an upper case letter (e.g. Leader or Boats). This rule is the same as that for type names. This is a problem because the; type name cannot be reused for a variable name [*]_. LLVM developers tend to; work around this by either prepending ``The`` to the type name::. Triple TheTriple;. ... or more commonly use an acronym, despite the coding standard stating ""Avoid; abbreviations unless they are well known""::. Triple T;. The proliferation of acronyms leads to hard-to-read code such as `this; <https://github.com/llvm/llvm-project/blob/0a8bc14ad7f3209fe702d18e250194cd90188596/llvm/lib/Transforms/Vectorize/LoopVectorize.cpp#L7445>`_::. InnerLoopVectorizer LB(L, PSE, LI, DT, TLI, TTI, AC, ORE, VF.Width, IC,; &LVL, &CM);. Many other coding guidelines [LLDB]_ [Google]_ [WebKit]_ [Qt]_ [Rust]_ [Swift]_; [Python]_ require that variable names begin with a lower case letter in contrast; to class names which begin with a capital letter. This convention means that the; most readable variable name also requires the least thought::. T",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/VariableNames.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/VariableNames.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/VariableNames.rst:1123,Modifiability,variab,variable,1123,"*provisional*. It is not agreed upon. It is written with the; intention of capturing the desires and concerns of the LLVM community, and; forming them into a plan that can be agreed upon.; The original author is somewhat naïve in the ways of LLVM so there will; inevitably be some details that are flawed. You can help - you can edit this; page (preferably with a Phabricator review for larger changes) or reply to the; `Request For Comments thread; <http://lists.llvm.org/pipermail/llvm-dev/2019-February/130083.html>`_. Too Long; Didn't Read; =====================. Improve the readability of LLVM code. Introduction; ============. The current `variable naming rule; <../CodingStandards.html#name-types-functions-variables-and-enumerators-properly>`_; states:. Variable names should be nouns (as they represent state). The name should be; camel case, and start with an upper case letter (e.g. Leader or Boats). This rule is the same as that for type names. This is a problem because the; type name cannot be reused for a variable name [*]_. LLVM developers tend to; work around this by either prepending ``The`` to the type name::. Triple TheTriple;. ... or more commonly use an acronym, despite the coding standard stating ""Avoid; abbreviations unless they are well known""::. Triple T;. The proliferation of acronyms leads to hard-to-read code such as `this; <https://github.com/llvm/llvm-project/blob/0a8bc14ad7f3209fe702d18e250194cd90188596/llvm/lib/Transforms/Vectorize/LoopVectorize.cpp#L7445>`_::. InnerLoopVectorizer LB(L, PSE, LI, DT, TLI, TTI, AC, ORE, VF.Width, IC,; &LVL, &CM);. Many other coding guidelines [LLDB]_ [Google]_ [WebKit]_ [Qt]_ [Rust]_ [Swift]_; [Python]_ require that variable names begin with a lower case letter in contrast; to class names which begin with a capital letter. This convention means that the; most readable variable name also requires the least thought::. Triple triple;. There is some agreement that the current rule is broken [LattnerAgree]_; [ArsenaultA",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Proposals/VariableNames.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Proposals/VariableNames.rst
