id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/hail-is/hail/issues/1822#issuecomment-301916658:1885,Testability,stub,stubs,1885,"uals=0 disable_indel_quals=false emit_original_quals=false preserve_qscores_less_than=6 defaultBaseQualities=-1 validation_strictness=SILENT remove_program_records=false keep_program_records=false unsafe=null num_threads=1 num_cpu_threads_per_data_thread=1 num_io_threads=0 monitorThreadEfficiency=false num_bam_file_handles=null read_group_black_list=null pedigree=[] pedigreeString=[] pedigreeValidationType=STRICT allow_intervals_with_unindexed_bam=false generateShadowBCF=false logging_level=INFO log_to_file=null help=false input=[(RodBinding name=input source=/seq/dax/all_1kg_exomes/v1/all_1kg_exomes.snps.unfiltered.vcf)] recal_file=(RodBinding name=recal_file source=/seq/dax/all_1kg_exomes/v1/all_1kg_exomes.snps.recal) tranches_file=/seq/dax/all_1kg_exomes/v1/all_1kg_exomes.snps.tranches out=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub no_cmdline_in_header=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub sites_only=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub bcf=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub ts_filter_level=98.5 ignore_filter=null mode=SNP filter_mismatching_base_and_quals=false""; ##CombineVariants=""analysis_type=CombineVariants input_file=[] read_buffer_size=null phone_home=STANDARD gatk_key=null tag=NA read_filter=[] intervals=[/seq/dax/all_1kg_exomes/v1/all_1kg_exomes.padded.interval_list] excludeIntervals=null interval_set_rule=UNION interval_merging=ALL interval_padding=0 reference_sequence=/seq/references/Homo_sapiens_assembly19/v1/Homo_sapiens_assembly19.fasta nonDeterministicRandomSeed=false disableRandomization=false maxRuntime=-1 maxRuntimeUnits=MINUTES downsampling_type=BY_SAMPLE downsample_to_fraction=null downsample_to_coverage=1000 use_legacy_downsampler=false baq=OFF baqGapOpenPenalty=40.0 fix_misencoded_quality_scores=false allow_potentially_misencoded_quality_scores=false performanceLog=null useOriginalQualities=false BQSR=null quantize_quals=0 disable_indel_qua",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/1822#issuecomment-301916658
https://github.com/hail-is/hail/issues/1822#issuecomment-301916658:1953,Testability,stub,stubs,1953,"qscores_less_than=6 defaultBaseQualities=-1 validation_strictness=SILENT remove_program_records=false keep_program_records=false unsafe=null num_threads=1 num_cpu_threads_per_data_thread=1 num_io_threads=0 monitorThreadEfficiency=false num_bam_file_handles=null read_group_black_list=null pedigree=[] pedigreeString=[] pedigreeValidationType=STRICT allow_intervals_with_unindexed_bam=false generateShadowBCF=false logging_level=INFO log_to_file=null help=false input=[(RodBinding name=input source=/seq/dax/all_1kg_exomes/v1/all_1kg_exomes.snps.unfiltered.vcf)] recal_file=(RodBinding name=recal_file source=/seq/dax/all_1kg_exomes/v1/all_1kg_exomes.snps.recal) tranches_file=/seq/dax/all_1kg_exomes/v1/all_1kg_exomes.snps.tranches out=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub no_cmdline_in_header=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub sites_only=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub bcf=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub ts_filter_level=98.5 ignore_filter=null mode=SNP filter_mismatching_base_and_quals=false""; ##CombineVariants=""analysis_type=CombineVariants input_file=[] read_buffer_size=null phone_home=STANDARD gatk_key=null tag=NA read_filter=[] intervals=[/seq/dax/all_1kg_exomes/v1/all_1kg_exomes.padded.interval_list] excludeIntervals=null interval_set_rule=UNION interval_merging=ALL interval_padding=0 reference_sequence=/seq/references/Homo_sapiens_assembly19/v1/Homo_sapiens_assembly19.fasta nonDeterministicRandomSeed=false disableRandomization=false maxRuntime=-1 maxRuntimeUnits=MINUTES downsampling_type=BY_SAMPLE downsample_to_fraction=null downsample_to_coverage=1000 use_legacy_downsampler=false baq=OFF baqGapOpenPenalty=40.0 fix_misencoded_quality_scores=false allow_potentially_misencoded_quality_scores=false performanceLog=null useOriginalQualities=false BQSR=null quantize_quals=0 disable_indel_quals=false emit_original_quals=false preserve_qscores_less_than=6 defa",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/1822#issuecomment-301916658
https://github.com/hail-is/hail/issues/1822#issuecomment-301916658:3634,Testability,stub,stubs,3634,"coverage=1000 use_legacy_downsampler=false baq=OFF baqGapOpenPenalty=40.0 fix_misencoded_quality_scores=false allow_potentially_misencoded_quality_scores=false performanceLog=null useOriginalQualities=false BQSR=null quantize_quals=0 disable_indel_quals=false emit_original_quals=false preserve_qscores_less_than=6 defaultBaseQualities=-1 validation_strictness=SILENT remove_program_records=false keep_program_records=false unsafe=null num_threads=1 num_cpu_threads_per_data_thread=1 num_io_threads=0 monitorThreadEfficiency=false num_bam_file_handles=null read_group_black_list=null pedigree=[] pedigreeString=[] pedigreeValidationType=STRICT allow_intervals_with_unindexed_bam=false generateShadowBCF=false logging_level=INFO log_to_file=null help=false variant=[(RodBinding name=variant source=/seq/dax/all_1kg_exomes/v1/all_1kg_exomes.snps.recalibrated.vcf), (RodBinding name=variant2 source=/seq/dax/all_1kg_exomes/v1/all_1kg_exomes.indels.filtered.vcf)] out=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub no_cmdline_in_header=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub sites_only=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub bcf=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub genotypemergeoption=UNSORTED filteredrecordsmergetype=KEEP_IF_ANY_UNFILTERED multipleallelesmergetype=BY_TYPE rod_priority_list=null printComplexMerges=false filteredAreUncalled=false minimalVCF=false setKey=set assumeIdenticalSamples=true minimumN=1 suppressCommandLineHeader=false mergeInfoWithMaxAC=false filter_mismatching_base_and_quals=false""; ##FILTER=<ID=Indel_FS,Description=""FS>200.0"">; ##FILTER=<ID=Indel_InbreedingCoeff,Description=""InbreedingCoeff<-0.8"">; ##FILTER=<ID=Indel_QD,Description=""QD<2.0"">; ##FILTER=<ID=Indel_ReadPosRankSum,Description=""ReadPosRankSum<-20.0"">; ##FILTER=<ID=LowQual,Description=""Low quality"">; ##FILTER=<ID=VQSRTrancheSNP98.50to98.60,Description=""Truth sensitivity tranche level for SNP model at VQS Lod:",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/1822#issuecomment-301916658
https://github.com/hail-is/hail/issues/1822#issuecomment-301916658:3719,Testability,stub,stubs,3719,"ded_quality_scores=false allow_potentially_misencoded_quality_scores=false performanceLog=null useOriginalQualities=false BQSR=null quantize_quals=0 disable_indel_quals=false emit_original_quals=false preserve_qscores_less_than=6 defaultBaseQualities=-1 validation_strictness=SILENT remove_program_records=false keep_program_records=false unsafe=null num_threads=1 num_cpu_threads_per_data_thread=1 num_io_threads=0 monitorThreadEfficiency=false num_bam_file_handles=null read_group_black_list=null pedigree=[] pedigreeString=[] pedigreeValidationType=STRICT allow_intervals_with_unindexed_bam=false generateShadowBCF=false logging_level=INFO log_to_file=null help=false variant=[(RodBinding name=variant source=/seq/dax/all_1kg_exomes/v1/all_1kg_exomes.snps.recalibrated.vcf), (RodBinding name=variant2 source=/seq/dax/all_1kg_exomes/v1/all_1kg_exomes.indels.filtered.vcf)] out=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub no_cmdline_in_header=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub sites_only=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub bcf=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub genotypemergeoption=UNSORTED filteredrecordsmergetype=KEEP_IF_ANY_UNFILTERED multipleallelesmergetype=BY_TYPE rod_priority_list=null printComplexMerges=false filteredAreUncalled=false minimalVCF=false setKey=set assumeIdenticalSamples=true minimumN=1 suppressCommandLineHeader=false mergeInfoWithMaxAC=false filter_mismatching_base_and_quals=false""; ##FILTER=<ID=Indel_FS,Description=""FS>200.0"">; ##FILTER=<ID=Indel_InbreedingCoeff,Description=""InbreedingCoeff<-0.8"">; ##FILTER=<ID=Indel_QD,Description=""QD<2.0"">; ##FILTER=<ID=Indel_ReadPosRankSum,Description=""ReadPosRankSum<-20.0"">; ##FILTER=<ID=LowQual,Description=""Low quality"">; ##FILTER=<ID=VQSRTrancheSNP98.50to98.60,Description=""Truth sensitivity tranche level for SNP model at VQS Lod: -1.4503 <= x < -1.2551"">; ##FILTER=<ID=VQSRTrancheSNP98.60to98.80,Description=""Truth",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/1822#issuecomment-301916658
https://github.com/hail-is/hail/issues/1822#issuecomment-301916658:3794,Testability,stub,stubs,3794,"performanceLog=null useOriginalQualities=false BQSR=null quantize_quals=0 disable_indel_quals=false emit_original_quals=false preserve_qscores_less_than=6 defaultBaseQualities=-1 validation_strictness=SILENT remove_program_records=false keep_program_records=false unsafe=null num_threads=1 num_cpu_threads_per_data_thread=1 num_io_threads=0 monitorThreadEfficiency=false num_bam_file_handles=null read_group_black_list=null pedigree=[] pedigreeString=[] pedigreeValidationType=STRICT allow_intervals_with_unindexed_bam=false generateShadowBCF=false logging_level=INFO log_to_file=null help=false variant=[(RodBinding name=variant source=/seq/dax/all_1kg_exomes/v1/all_1kg_exomes.snps.recalibrated.vcf), (RodBinding name=variant2 source=/seq/dax/all_1kg_exomes/v1/all_1kg_exomes.indels.filtered.vcf)] out=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub no_cmdline_in_header=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub sites_only=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub bcf=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub genotypemergeoption=UNSORTED filteredrecordsmergetype=KEEP_IF_ANY_UNFILTERED multipleallelesmergetype=BY_TYPE rod_priority_list=null printComplexMerges=false filteredAreUncalled=false minimalVCF=false setKey=set assumeIdenticalSamples=true minimumN=1 suppressCommandLineHeader=false mergeInfoWithMaxAC=false filter_mismatching_base_and_quals=false""; ##FILTER=<ID=Indel_FS,Description=""FS>200.0"">; ##FILTER=<ID=Indel_InbreedingCoeff,Description=""InbreedingCoeff<-0.8"">; ##FILTER=<ID=Indel_QD,Description=""QD<2.0"">; ##FILTER=<ID=Indel_ReadPosRankSum,Description=""ReadPosRankSum<-20.0"">; ##FILTER=<ID=LowQual,Description=""Low quality"">; ##FILTER=<ID=VQSRTrancheSNP98.50to98.60,Description=""Truth sensitivity tranche level for SNP model at VQS Lod: -1.4503 <= x < -1.2551"">; ##FILTER=<ID=VQSRTrancheSNP98.60to98.80,Description=""Truth sensitivity tranche level for SNP model at VQS Lod: -2.0727 <= x < -1.4503",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/1822#issuecomment-301916658
https://github.com/hail-is/hail/issues/1822#issuecomment-301916658:3862,Testability,stub,stubs,3862,"als=0 disable_indel_quals=false emit_original_quals=false preserve_qscores_less_than=6 defaultBaseQualities=-1 validation_strictness=SILENT remove_program_records=false keep_program_records=false unsafe=null num_threads=1 num_cpu_threads_per_data_thread=1 num_io_threads=0 monitorThreadEfficiency=false num_bam_file_handles=null read_group_black_list=null pedigree=[] pedigreeString=[] pedigreeValidationType=STRICT allow_intervals_with_unindexed_bam=false generateShadowBCF=false logging_level=INFO log_to_file=null help=false variant=[(RodBinding name=variant source=/seq/dax/all_1kg_exomes/v1/all_1kg_exomes.snps.recalibrated.vcf), (RodBinding name=variant2 source=/seq/dax/all_1kg_exomes/v1/all_1kg_exomes.indels.filtered.vcf)] out=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub no_cmdline_in_header=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub sites_only=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub bcf=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub genotypemergeoption=UNSORTED filteredrecordsmergetype=KEEP_IF_ANY_UNFILTERED multipleallelesmergetype=BY_TYPE rod_priority_list=null printComplexMerges=false filteredAreUncalled=false minimalVCF=false setKey=set assumeIdenticalSamples=true minimumN=1 suppressCommandLineHeader=false mergeInfoWithMaxAC=false filter_mismatching_base_and_quals=false""; ##FILTER=<ID=Indel_FS,Description=""FS>200.0"">; ##FILTER=<ID=Indel_InbreedingCoeff,Description=""InbreedingCoeff<-0.8"">; ##FILTER=<ID=Indel_QD,Description=""QD<2.0"">; ##FILTER=<ID=Indel_ReadPosRankSum,Description=""ReadPosRankSum<-20.0"">; ##FILTER=<ID=LowQual,Description=""Low quality"">; ##FILTER=<ID=VQSRTrancheSNP98.50to98.60,Description=""Truth sensitivity tranche level for SNP model at VQS Lod: -1.4503 <= x < -1.2551"">; ##FILTER=<ID=VQSRTrancheSNP98.60to98.80,Description=""Truth sensitivity tranche level for SNP model at VQS Lod: -2.0727 <= x < -1.4503"">; ##FILTER=<ID=VQSRTrancheSNP98.80to98.90,Description=""Truth sensi",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/1822#issuecomment-301916658
https://github.com/hail-is/hail/issues/1822#issuecomment-301916658:6707,Testability,test,test,6707,"SNP99.30to99.50,Description=""Truth sensitivity tranche level for SNP model at VQS Lod: -7.5522 <= x < -4.8125"">; ##FILTER=<ID=VQSRTrancheSNP99.50to99.90,Description=""Truth sensitivity tranche level for SNP model at VQS Lod: -109.7088 <= x < -7.5522"">; ##FILTER=<ID=VQSRTrancheSNP99.90to100.00+,Description=""Truth sensitivity tranche level for SNP model at VQS Lod < -3227.3414"">; ##FILTER=<ID=VQSRTrancheSNP99.90to100.00,Description=""Truth sensitivity tranche level for SNP model at VQS Lod: -3227.3414 <= x < -109.7088"">; ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Allelic depths for the ref and alt alleles in the order listed"">; ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Approximate read depth (reads with MQ=255 or with bad mates are filtered)"">; ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Genotype Quality"">; ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">; ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification"">; ##INFO=<ID=AC,Number=A,Type=Integer,Description=""Allele count in genotypes, for each ALT allele, in the same order as listed"">; ##INFO=<ID=AF,Number=A,Type=Float,Description=""Allele Frequency, for each ALT allele, in the same order as listed"">; ##INFO=<ID=AN,Number=1,Type=Integer,Description=""Total number of alleles in called genotypes"">; ##INFO=<ID=BaseQRankSum,Number=1,Type=Float,Description=""Z-score from Wilcoxon rank sum test of Alt Vs. Ref base qualities"">; ##INFO=<ID=DB,Number=0,Type=Flag,Description=""dbSNP Membership"">; ##INFO=<ID=DP,Number=1,Type=Integer,Description=""Approximate read depth; some reads may have been filtered"">; ##INFO=<ID=DS,Number=0,Type=Flag,Description=""Were any of the samples downsampled?"">; ##INFO=<ID=Dels,Number=1,Type=Float,Description=""Fraction of Reads Containing Spanning Deletions"">; ##INFO=<ID=END,Number=1,Type=Integer,Description=""Stop position of the interval"">; ##INFO=<ID=FS,Number=1,Type=Float,Description=""",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/1822#issuecomment-301916658
https://github.com/hail-is/hail/issues/1822#issuecomment-301916658:7279,Testability,test,test,7279,"order as listed"">; ##INFO=<ID=AN,Number=1,Type=Integer,Description=""Total number of alleles in called genotypes"">; ##INFO=<ID=BaseQRankSum,Number=1,Type=Float,Description=""Z-score from Wilcoxon rank sum test of Alt Vs. Ref base qualities"">; ##INFO=<ID=DB,Number=0,Type=Flag,Description=""dbSNP Membership"">; ##INFO=<ID=DP,Number=1,Type=Integer,Description=""Approximate read depth; some reads may have been filtered"">; ##INFO=<ID=DS,Number=0,Type=Flag,Description=""Were any of the samples downsampled?"">; ##INFO=<ID=Dels,Number=1,Type=Float,Description=""Fraction of Reads Containing Spanning Deletions"">; ##INFO=<ID=END,Number=1,Type=Integer,Description=""Stop position of the interval"">; ##INFO=<ID=FS,Number=1,Type=Float,Description=""Phred-scaled p-value using Fisher's exact test to detect strand bias"">; ##INFO=<ID=HaplotypeScore,Number=1,Type=Float,Description=""Consistency of the site with at most two segregating haplotypes"">; ##INFO=<ID=InbreedingCoeff,Number=1,Type=Float,Description=""Inbreeding coefficient as estimated from the genotype likelihoods per-sample when compared against the Hardy-Weinberg expectation"">; ##INFO=<ID=MLEAC,Number=A,Type=Integer,Description=""Maximum likelihood expectation (MLE) for the allele counts (not necessarily the same as the AC), for each ALT allele, in the same order as listed"">; ##INFO=<ID=MLEAF,Number=A,Type=Float,Description=""Maximum likelihood expectation (MLE) for the allele frequency (not necessarily the same as the AF), for each ALT allele, in the same order as listed"">; ##INFO=<ID=MQ,Number=1,Type=Float,Description=""RMS Mapping Quality"">; ##INFO=<ID=MQ0,Number=1,Type=Integer,Description=""Total Mapping Quality Zero Reads"">; ##INFO=<ID=MQRankSum,Number=1,Type=Float,Description=""Z-score From Wilcoxon rank sum test of Alt vs. Ref read mapping qualities"">; ##INFO=<ID=OriginalContig,Number=1,Type=String,Description=""The name of the source contig/chromosome prior to liftover."">; ##INFO=<ID=OriginalStart,Number=1,Type=String,Description=""The p",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/1822#issuecomment-301916658
https://github.com/hail-is/hail/issues/1822#issuecomment-301916658:8272,Testability,test,test,8272,"order as listed"">; ##INFO=<ID=AN,Number=1,Type=Integer,Description=""Total number of alleles in called genotypes"">; ##INFO=<ID=BaseQRankSum,Number=1,Type=Float,Description=""Z-score from Wilcoxon rank sum test of Alt Vs. Ref base qualities"">; ##INFO=<ID=DB,Number=0,Type=Flag,Description=""dbSNP Membership"">; ##INFO=<ID=DP,Number=1,Type=Integer,Description=""Approximate read depth; some reads may have been filtered"">; ##INFO=<ID=DS,Number=0,Type=Flag,Description=""Were any of the samples downsampled?"">; ##INFO=<ID=Dels,Number=1,Type=Float,Description=""Fraction of Reads Containing Spanning Deletions"">; ##INFO=<ID=END,Number=1,Type=Integer,Description=""Stop position of the interval"">; ##INFO=<ID=FS,Number=1,Type=Float,Description=""Phred-scaled p-value using Fisher's exact test to detect strand bias"">; ##INFO=<ID=HaplotypeScore,Number=1,Type=Float,Description=""Consistency of the site with at most two segregating haplotypes"">; ##INFO=<ID=InbreedingCoeff,Number=1,Type=Float,Description=""Inbreeding coefficient as estimated from the genotype likelihoods per-sample when compared against the Hardy-Weinberg expectation"">; ##INFO=<ID=MLEAC,Number=A,Type=Integer,Description=""Maximum likelihood expectation (MLE) for the allele counts (not necessarily the same as the AC), for each ALT allele, in the same order as listed"">; ##INFO=<ID=MLEAF,Number=A,Type=Float,Description=""Maximum likelihood expectation (MLE) for the allele frequency (not necessarily the same as the AF), for each ALT allele, in the same order as listed"">; ##INFO=<ID=MQ,Number=1,Type=Float,Description=""RMS Mapping Quality"">; ##INFO=<ID=MQ0,Number=1,Type=Integer,Description=""Total Mapping Quality Zero Reads"">; ##INFO=<ID=MQRankSum,Number=1,Type=Float,Description=""Z-score From Wilcoxon rank sum test of Alt vs. Ref read mapping qualities"">; ##INFO=<ID=OriginalContig,Number=1,Type=String,Description=""The name of the source contig/chromosome prior to liftover."">; ##INFO=<ID=OriginalStart,Number=1,Type=String,Description=""The p",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/1822#issuecomment-301916658
https://github.com/hail-is/hail/issues/1822#issuecomment-301916658:8964,Testability,test,test,8964,"##INFO=<ID=MLEAF,Number=A,Type=Float,Description=""Maximum likelihood expectation (MLE) for the allele frequency (not necessarily the same as the AF), for each ALT allele, in the same order as listed"">; ##INFO=<ID=MQ,Number=1,Type=Float,Description=""RMS Mapping Quality"">; ##INFO=<ID=MQ0,Number=1,Type=Integer,Description=""Total Mapping Quality Zero Reads"">; ##INFO=<ID=MQRankSum,Number=1,Type=Float,Description=""Z-score From Wilcoxon rank sum test of Alt vs. Ref read mapping qualities"">; ##INFO=<ID=OriginalContig,Number=1,Type=String,Description=""The name of the source contig/chromosome prior to liftover."">; ##INFO=<ID=OriginalStart,Number=1,Type=String,Description=""The position of the variant on the source contig prior to liftover."">; ##INFO=<ID=QD,Number=1,Type=Float,Description=""Variant Confidence/Quality by Depth"">; ##INFO=<ID=RPA,Number=.,Type=Integer,Description=""Number of times tandem repeat unit is repeated, for each allele (including reference)"">; ##INFO=<ID=RU,Number=1,Type=String,Description=""Tandem repeat unit (bases)"">; ##INFO=<ID=ReadPosRankSum,Number=1,Type=Float,Description=""Z-score from Wilcoxon rank sum test of Alt vs. Ref read position bias"">; ##INFO=<ID=SNPEFF_AMINO_ACID_CHANGE,Number=1,Type=String,Description=""Old/New amino acid for the highest-impact effect resulting from the current variant (in HGVS style)"">; ##INFO=<ID=SNPEFF_CODON_CHANGE,Number=1,Type=String,Description=""Old/New codon for the highest-impact effect resulting from the current variant"">; ##INFO=<ID=SNPEFF_EFFECT,Number=1,Type=String,Description=""The highest-impact effect resulting from the current variant (or one of the highest-impact effects, if there is a tie)"">; ##INFO=<ID=SNPEFF_EXON_ID,Number=1,Type=String,Description=""Exon ID for the highest-impact effect resulting from the current variant"">; ##INFO=<ID=SNPEFF_FUNCTIONAL_CLASS,Number=1,Type=String,Description=""Functional class of the highest-impact effect resulting from the current variant: [NONE, SILENT, MISSENSE, NONSENSE]"">",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/1822#issuecomment-301916658
https://github.com/hail-is/hail/issues/1822#issuecomment-301916658:10565,Testability,Log,Log,10565," amino acid for the highest-impact effect resulting from the current variant (in HGVS style)"">; ##INFO=<ID=SNPEFF_CODON_CHANGE,Number=1,Type=String,Description=""Old/New codon for the highest-impact effect resulting from the current variant"">; ##INFO=<ID=SNPEFF_EFFECT,Number=1,Type=String,Description=""The highest-impact effect resulting from the current variant (or one of the highest-impact effects, if there is a tie)"">; ##INFO=<ID=SNPEFF_EXON_ID,Number=1,Type=String,Description=""Exon ID for the highest-impact effect resulting from the current variant"">; ##INFO=<ID=SNPEFF_FUNCTIONAL_CLASS,Number=1,Type=String,Description=""Functional class of the highest-impact effect resulting from the current variant: [NONE, SILENT, MISSENSE, NONSENSE]"">; ##INFO=<ID=SNPEFF_GENE_BIOTYPE,Number=1,Type=String,Description=""Gene biotype for the highest-impact effect resulting from the current variant"">; ##INFO=<ID=SNPEFF_GENE_NAME,Number=1,Type=String,Description=""Gene name for the highest-impact effect resulting from the current variant"">; ##INFO=<ID=SNPEFF_IMPACT,Number=1,Type=String,Description=""Impact of the highest-impact effect resulting from the current variant [MODIFIER, LOW, MODERATE, HIGH]"">; ##INFO=<ID=SNPEFF_TRANSCRIPT_ID,Number=1,Type=String,Description=""Transcript ID for the highest-impact effect resulting from the current variant"">; ##INFO=<ID=STR,Number=0,Type=Flag,Description=""Variant is a short tandem repeat"">; ##INFO=<ID=VQSLOD,Number=1,Type=Float,Description=""Log odds ratio of being a true variant versus being false under the trained gaussian mixture model"">; ##INFO=<ID=culprit,Number=1,Type=String,Description=""The annotation which was the worst performing in the Gaussian mixture model, likely the reason why the variant was filtered out"">; ##INFO=<ID=set,Number=1,Type=String,Description=""Source VCF for the merged record in CombineVariants"">; ##OriginalSnpEffCmd=""SnpEff eff -v -onlyCoding true -c /seq/references/Homo_sapiens_assembly19/v1/snpEff/Homo_sapiens_assembly19.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/1822#issuecomment-301916658
https://github.com/hail-is/hail/issues/1822#issuecomment-301916658:12798,Testability,stub,stubs,12798,"downsample_to_coverage=1000 use_legacy_downsampler=false baq=OFF baqGapOpenPenalty=40.0 fix_misencoded_quality_scores=false allow_potentially_misencoded_quality_scores=false performanceLog=null useOriginalQualities=false BQSR=null quantize_quals=0 disable_indel_quals=false emit_original_quals=false preserve_qscores_less_than=6 defaultBaseQualities=-1 validation_strictness=SILENT remove_program_records=false keep_program_records=false unsafe=null num_threads=1 num_cpu_threads_per_data_thread=1 num_io_threads=0 monitorThreadEfficiency=false num_bam_file_handles=null read_group_black_list=null pedigree=[] pedigreeString=[] pedigreeValidationType=STRICT allow_intervals_with_unindexed_bam=false generateShadowBCF=false logging_level=INFO log_to_file=null help=false variant=(RodBinding name=variant source=/seq/dax/all_1kg_exomes/v1/all_1kg_exomes.unfiltered.vcf) discordance=(RodBinding name= source=UNBOUND) concordance=(RodBinding name= source=UNBOUND) out=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub no_cmdline_in_header=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub sites_only=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub bcf=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub sample_name=[] sample_expressions=null sample_file=null exclude_sample_name=[] exclude_sample_file=[] select_expressions=[] excludeNonVariants=false excludeFiltered=false regenotype=false restrictAllelesTo=ALL keepOriginalAC=false mendelianViolation=false mendelianViolationQualThreshold=0.0 select_random_fraction=0.0 remove_fraction_genotypes=0.0 selectTypeToInclude=[INDEL] keepIDs=null fullyDecode=false forceGenotypesDecode=false justRead=false maxIndelSize=2147483647 ALLOW_NONOVERLAPPING_COMMAND_LINE_SAMPLES=false filter_mismatching_base_and_quals=false""; ##UnifiedGenotyper=""analysis_type=UnifiedGenotyper input_file=[/seq/dax/all_1kg_exomes/v1/all_1kg_exomes.bam.list] read_buffer_size=null phone_home=STANDARD gatk_key=null tag=NA re",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/1822#issuecomment-301916658
https://github.com/hail-is/hail/issues/1822#issuecomment-301916658:12883,Testability,stub,stubs,12883,".0 fix_misencoded_quality_scores=false allow_potentially_misencoded_quality_scores=false performanceLog=null useOriginalQualities=false BQSR=null quantize_quals=0 disable_indel_quals=false emit_original_quals=false preserve_qscores_less_than=6 defaultBaseQualities=-1 validation_strictness=SILENT remove_program_records=false keep_program_records=false unsafe=null num_threads=1 num_cpu_threads_per_data_thread=1 num_io_threads=0 monitorThreadEfficiency=false num_bam_file_handles=null read_group_black_list=null pedigree=[] pedigreeString=[] pedigreeValidationType=STRICT allow_intervals_with_unindexed_bam=false generateShadowBCF=false logging_level=INFO log_to_file=null help=false variant=(RodBinding name=variant source=/seq/dax/all_1kg_exomes/v1/all_1kg_exomes.unfiltered.vcf) discordance=(RodBinding name= source=UNBOUND) concordance=(RodBinding name= source=UNBOUND) out=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub no_cmdline_in_header=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub sites_only=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub bcf=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub sample_name=[] sample_expressions=null sample_file=null exclude_sample_name=[] exclude_sample_file=[] select_expressions=[] excludeNonVariants=false excludeFiltered=false regenotype=false restrictAllelesTo=ALL keepOriginalAC=false mendelianViolation=false mendelianViolationQualThreshold=0.0 select_random_fraction=0.0 remove_fraction_genotypes=0.0 selectTypeToInclude=[INDEL] keepIDs=null fullyDecode=false forceGenotypesDecode=false justRead=false maxIndelSize=2147483647 ALLOW_NONOVERLAPPING_COMMAND_LINE_SAMPLES=false filter_mismatching_base_and_quals=false""; ##UnifiedGenotyper=""analysis_type=UnifiedGenotyper input_file=[/seq/dax/all_1kg_exomes/v1/all_1kg_exomes.bam.list] read_buffer_size=null phone_home=STANDARD gatk_key=null tag=NA read_filter=[] intervals=[/seq/dax/all_1kg_exomes/v1/scatter/temp_0001_of_1200/scattere",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/1822#issuecomment-301916658
https://github.com/hail-is/hail/issues/1822#issuecomment-301916658:12958,Testability,stub,stubs,12958,"_scores=false performanceLog=null useOriginalQualities=false BQSR=null quantize_quals=0 disable_indel_quals=false emit_original_quals=false preserve_qscores_less_than=6 defaultBaseQualities=-1 validation_strictness=SILENT remove_program_records=false keep_program_records=false unsafe=null num_threads=1 num_cpu_threads_per_data_thread=1 num_io_threads=0 monitorThreadEfficiency=false num_bam_file_handles=null read_group_black_list=null pedigree=[] pedigreeString=[] pedigreeValidationType=STRICT allow_intervals_with_unindexed_bam=false generateShadowBCF=false logging_level=INFO log_to_file=null help=false variant=(RodBinding name=variant source=/seq/dax/all_1kg_exomes/v1/all_1kg_exomes.unfiltered.vcf) discordance=(RodBinding name= source=UNBOUND) concordance=(RodBinding name= source=UNBOUND) out=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub no_cmdline_in_header=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub sites_only=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub bcf=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub sample_name=[] sample_expressions=null sample_file=null exclude_sample_name=[] exclude_sample_file=[] select_expressions=[] excludeNonVariants=false excludeFiltered=false regenotype=false restrictAllelesTo=ALL keepOriginalAC=false mendelianViolation=false mendelianViolationQualThreshold=0.0 select_random_fraction=0.0 remove_fraction_genotypes=0.0 selectTypeToInclude=[INDEL] keepIDs=null fullyDecode=false forceGenotypesDecode=false justRead=false maxIndelSize=2147483647 ALLOW_NONOVERLAPPING_COMMAND_LINE_SAMPLES=false filter_mismatching_base_and_quals=false""; ##UnifiedGenotyper=""analysis_type=UnifiedGenotyper input_file=[/seq/dax/all_1kg_exomes/v1/all_1kg_exomes.bam.list] read_buffer_size=null phone_home=STANDARD gatk_key=null tag=NA read_filter=[] intervals=[/seq/dax/all_1kg_exomes/v1/scatter/temp_0001_of_1200/scattered.intervals] excludeIntervals=null interval_set_rule=UNION interval_merging",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/1822#issuecomment-301916658
https://github.com/hail-is/hail/issues/1822#issuecomment-301916658:13026,Testability,stub,stubs,13026,"ll quantize_quals=0 disable_indel_quals=false emit_original_quals=false preserve_qscores_less_than=6 defaultBaseQualities=-1 validation_strictness=SILENT remove_program_records=false keep_program_records=false unsafe=null num_threads=1 num_cpu_threads_per_data_thread=1 num_io_threads=0 monitorThreadEfficiency=false num_bam_file_handles=null read_group_black_list=null pedigree=[] pedigreeString=[] pedigreeValidationType=STRICT allow_intervals_with_unindexed_bam=false generateShadowBCF=false logging_level=INFO log_to_file=null help=false variant=(RodBinding name=variant source=/seq/dax/all_1kg_exomes/v1/all_1kg_exomes.unfiltered.vcf) discordance=(RodBinding name= source=UNBOUND) concordance=(RodBinding name= source=UNBOUND) out=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub no_cmdline_in_header=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub sites_only=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub bcf=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub sample_name=[] sample_expressions=null sample_file=null exclude_sample_name=[] exclude_sample_file=[] select_expressions=[] excludeNonVariants=false excludeFiltered=false regenotype=false restrictAllelesTo=ALL keepOriginalAC=false mendelianViolation=false mendelianViolationQualThreshold=0.0 select_random_fraction=0.0 remove_fraction_genotypes=0.0 selectTypeToInclude=[INDEL] keepIDs=null fullyDecode=false forceGenotypesDecode=false justRead=false maxIndelSize=2147483647 ALLOW_NONOVERLAPPING_COMMAND_LINE_SAMPLES=false filter_mismatching_base_and_quals=false""; ##UnifiedGenotyper=""analysis_type=UnifiedGenotyper input_file=[/seq/dax/all_1kg_exomes/v1/all_1kg_exomes.bam.list] read_buffer_size=null phone_home=STANDARD gatk_key=null tag=NA read_filter=[] intervals=[/seq/dax/all_1kg_exomes/v1/scatter/temp_0001_of_1200/scattered.intervals] excludeIntervals=null interval_set_rule=UNION interval_merging=ALL interval_padding=0 reference_sequence=/seq/references/Homo_sapi",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/1822#issuecomment-301916658
https://github.com/hail-is/hail/issues/1822#issuecomment-301916658:16118,Testability,log,logRemovedReadsFromContaminationFiltering,16118,"yping=5 min_indel_fraction_per_sample=0.25 indel_heterozygosity=1.25E-4 indelGapContinuationPenalty=10 indelGapOpenPenalty=45 indelHaplotypeSize=80 indelDebug=false ignoreSNPAlleles=false allReadsSP=false ignoreLaneInfo=false reference_sample_calls=(RodBinding name= source=UNBOUND) reference_sample_name=null sample_ploidy=2 min_quality_score=1 max_quality_score=40 site_quality_prior=20 min_power_threshold_for_calling=0.95 min_reference_depth=100 exclude_filtered_reference_sites=false heterozygosity=0.0010 genotyping_mode=DISCOVERY output_mode=EMIT_VARIANTS_ONLY standard_min_confidence_threshold_for_calling=30.0 standard_min_confidence_threshold_for_emitting=30.0 alleles=(RodBinding name= source=UNBOUND) max_alternate_alleles=6 p_nonref_model=EXACT_INDEPENDENT contamination_fraction_to_filter=0.0 contamination_percentage_per_sample_file=/seq/dax/all_1kg_exomes/v1/all_1kg_exomes.v1.contamination_levels.txt logRemovedReadsFromContaminationFiltering=null exactcallslog=null dbsnp=(RodBinding name=dbsnp source=/seq/references/Homo_sapiens_assembly19/v1/Homo_sapiens_assembly19.dbsnp.vcf) comp=[] out=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub no_cmdline_in_header=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub sites_only=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub bcf=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub debug_file=null metrics_file=null annotation=[] excludeAnnotation=[] filter_mismatching_base_and_quals=false""; ##VariantAnnotator=""analysis_type=VariantAnnotator input_file=[] read_buffer_size=null phone_home=STANDARD gatk_key=null tag=NA read_filter=[] intervals=[/seq/references/HybSelOligos/whole_exome_agilent_1.1_refseq_plus_3_boosters/whole_exome_agilent_1.1_refseq_plus_3_boosters.Homo_sapiens_assembly19.targets.interval_list] excludeIntervals=null interval_set_rule=UNION interval_merging=ALL interval_padding=50 reference_sequence=/seq/references/Homo_sapiens_assembly19/v1/Homo_sapiens_as",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/1822#issuecomment-301916658
https://github.com/hail-is/hail/issues/1822#issuecomment-301916658:16343,Testability,stub,stubs,16343,"0 indelDebug=false ignoreSNPAlleles=false allReadsSP=false ignoreLaneInfo=false reference_sample_calls=(RodBinding name= source=UNBOUND) reference_sample_name=null sample_ploidy=2 min_quality_score=1 max_quality_score=40 site_quality_prior=20 min_power_threshold_for_calling=0.95 min_reference_depth=100 exclude_filtered_reference_sites=false heterozygosity=0.0010 genotyping_mode=DISCOVERY output_mode=EMIT_VARIANTS_ONLY standard_min_confidence_threshold_for_calling=30.0 standard_min_confidence_threshold_for_emitting=30.0 alleles=(RodBinding name= source=UNBOUND) max_alternate_alleles=6 p_nonref_model=EXACT_INDEPENDENT contamination_fraction_to_filter=0.0 contamination_percentage_per_sample_file=/seq/dax/all_1kg_exomes/v1/all_1kg_exomes.v1.contamination_levels.txt logRemovedReadsFromContaminationFiltering=null exactcallslog=null dbsnp=(RodBinding name=dbsnp source=/seq/references/Homo_sapiens_assembly19/v1/Homo_sapiens_assembly19.dbsnp.vcf) comp=[] out=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub no_cmdline_in_header=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub sites_only=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub bcf=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub debug_file=null metrics_file=null annotation=[] excludeAnnotation=[] filter_mismatching_base_and_quals=false""; ##VariantAnnotator=""analysis_type=VariantAnnotator input_file=[] read_buffer_size=null phone_home=STANDARD gatk_key=null tag=NA read_filter=[] intervals=[/seq/references/HybSelOligos/whole_exome_agilent_1.1_refseq_plus_3_boosters/whole_exome_agilent_1.1_refseq_plus_3_boosters.Homo_sapiens_assembly19.targets.interval_list] excludeIntervals=null interval_set_rule=UNION interval_merging=ALL interval_padding=50 reference_sequence=/seq/references/Homo_sapiens_assembly19/v1/Homo_sapiens_assembly19.fasta nonDeterministicRandomSeed=false disableRandomization=false maxRuntime=-1 maxRuntimeUnits=MINUTES downsampling_type=BY_SAMPLE down",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/1822#issuecomment-301916658
https://github.com/hail-is/hail/issues/1822#issuecomment-301916658:16428,Testability,stub,stubs,16428,"ence_sample_calls=(RodBinding name= source=UNBOUND) reference_sample_name=null sample_ploidy=2 min_quality_score=1 max_quality_score=40 site_quality_prior=20 min_power_threshold_for_calling=0.95 min_reference_depth=100 exclude_filtered_reference_sites=false heterozygosity=0.0010 genotyping_mode=DISCOVERY output_mode=EMIT_VARIANTS_ONLY standard_min_confidence_threshold_for_calling=30.0 standard_min_confidence_threshold_for_emitting=30.0 alleles=(RodBinding name= source=UNBOUND) max_alternate_alleles=6 p_nonref_model=EXACT_INDEPENDENT contamination_fraction_to_filter=0.0 contamination_percentage_per_sample_file=/seq/dax/all_1kg_exomes/v1/all_1kg_exomes.v1.contamination_levels.txt logRemovedReadsFromContaminationFiltering=null exactcallslog=null dbsnp=(RodBinding name=dbsnp source=/seq/references/Homo_sapiens_assembly19/v1/Homo_sapiens_assembly19.dbsnp.vcf) comp=[] out=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub no_cmdline_in_header=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub sites_only=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub bcf=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub debug_file=null metrics_file=null annotation=[] excludeAnnotation=[] filter_mismatching_base_and_quals=false""; ##VariantAnnotator=""analysis_type=VariantAnnotator input_file=[] read_buffer_size=null phone_home=STANDARD gatk_key=null tag=NA read_filter=[] intervals=[/seq/references/HybSelOligos/whole_exome_agilent_1.1_refseq_plus_3_boosters/whole_exome_agilent_1.1_refseq_plus_3_boosters.Homo_sapiens_assembly19.targets.interval_list] excludeIntervals=null interval_set_rule=UNION interval_merging=ALL interval_padding=50 reference_sequence=/seq/references/Homo_sapiens_assembly19/v1/Homo_sapiens_assembly19.fasta nonDeterministicRandomSeed=false disableRandomization=false maxRuntime=-1 maxRuntimeUnits=MINUTES downsampling_type=BY_SAMPLE downsample_to_fraction=null downsample_to_coverage=1000 use_legacy_downsampler=false baq=",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/1822#issuecomment-301916658
https://github.com/hail-is/hail/issues/1822#issuecomment-301916658:16503,Testability,stub,stubs,16503,"ull sample_ploidy=2 min_quality_score=1 max_quality_score=40 site_quality_prior=20 min_power_threshold_for_calling=0.95 min_reference_depth=100 exclude_filtered_reference_sites=false heterozygosity=0.0010 genotyping_mode=DISCOVERY output_mode=EMIT_VARIANTS_ONLY standard_min_confidence_threshold_for_calling=30.0 standard_min_confidence_threshold_for_emitting=30.0 alleles=(RodBinding name= source=UNBOUND) max_alternate_alleles=6 p_nonref_model=EXACT_INDEPENDENT contamination_fraction_to_filter=0.0 contamination_percentage_per_sample_file=/seq/dax/all_1kg_exomes/v1/all_1kg_exomes.v1.contamination_levels.txt logRemovedReadsFromContaminationFiltering=null exactcallslog=null dbsnp=(RodBinding name=dbsnp source=/seq/references/Homo_sapiens_assembly19/v1/Homo_sapiens_assembly19.dbsnp.vcf) comp=[] out=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub no_cmdline_in_header=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub sites_only=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub bcf=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub debug_file=null metrics_file=null annotation=[] excludeAnnotation=[] filter_mismatching_base_and_quals=false""; ##VariantAnnotator=""analysis_type=VariantAnnotator input_file=[] read_buffer_size=null phone_home=STANDARD gatk_key=null tag=NA read_filter=[] intervals=[/seq/references/HybSelOligos/whole_exome_agilent_1.1_refseq_plus_3_boosters/whole_exome_agilent_1.1_refseq_plus_3_boosters.Homo_sapiens_assembly19.targets.interval_list] excludeIntervals=null interval_set_rule=UNION interval_merging=ALL interval_padding=50 reference_sequence=/seq/references/Homo_sapiens_assembly19/v1/Homo_sapiens_assembly19.fasta nonDeterministicRandomSeed=false disableRandomization=false maxRuntime=-1 maxRuntimeUnits=MINUTES downsampling_type=BY_SAMPLE downsample_to_fraction=null downsample_to_coverage=1000 use_legacy_downsampler=false baq=OFF baqGapOpenPenalty=40.0 fix_misencoded_quality_scores=false allow_potent",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/1822#issuecomment-301916658
https://github.com/hail-is/hail/issues/1822#issuecomment-301916658:16571,Testability,stub,stubs,16571,"ality_prior=20 min_power_threshold_for_calling=0.95 min_reference_depth=100 exclude_filtered_reference_sites=false heterozygosity=0.0010 genotyping_mode=DISCOVERY output_mode=EMIT_VARIANTS_ONLY standard_min_confidence_threshold_for_calling=30.0 standard_min_confidence_threshold_for_emitting=30.0 alleles=(RodBinding name= source=UNBOUND) max_alternate_alleles=6 p_nonref_model=EXACT_INDEPENDENT contamination_fraction_to_filter=0.0 contamination_percentage_per_sample_file=/seq/dax/all_1kg_exomes/v1/all_1kg_exomes.v1.contamination_levels.txt logRemovedReadsFromContaminationFiltering=null exactcallslog=null dbsnp=(RodBinding name=dbsnp source=/seq/references/Homo_sapiens_assembly19/v1/Homo_sapiens_assembly19.dbsnp.vcf) comp=[] out=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub no_cmdline_in_header=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub sites_only=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub bcf=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub debug_file=null metrics_file=null annotation=[] excludeAnnotation=[] filter_mismatching_base_and_quals=false""; ##VariantAnnotator=""analysis_type=VariantAnnotator input_file=[] read_buffer_size=null phone_home=STANDARD gatk_key=null tag=NA read_filter=[] intervals=[/seq/references/HybSelOligos/whole_exome_agilent_1.1_refseq_plus_3_boosters/whole_exome_agilent_1.1_refseq_plus_3_boosters.Homo_sapiens_assembly19.targets.interval_list] excludeIntervals=null interval_set_rule=UNION interval_merging=ALL interval_padding=50 reference_sequence=/seq/references/Homo_sapiens_assembly19/v1/Homo_sapiens_assembly19.fasta nonDeterministicRandomSeed=false disableRandomization=false maxRuntime=-1 maxRuntimeUnits=MINUTES downsampling_type=BY_SAMPLE downsample_to_fraction=null downsample_to_coverage=1000 use_legacy_downsampler=false baq=OFF baqGapOpenPenalty=40.0 fix_misencoded_quality_scores=false allow_potentially_misencoded_quality_scores=false performanceLog=null useOrigina",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/1822#issuecomment-301916658
https://github.com/hail-is/hail/issues/1822#issuecomment-301916658:18436,Testability,stub,stubs,18436,"apOpenPenalty=40.0 fix_misencoded_quality_scores=false allow_potentially_misencoded_quality_scores=false performanceLog=null useOriginalQualities=false BQSR=null quantize_quals=0 disable_indel_quals=false emit_original_quals=false preserve_qscores_less_than=6 defaultBaseQualities=-1 validation_strictness=SILENT remove_program_records=false keep_program_records=false unsafe=null num_threads=1 num_cpu_threads_per_data_thread=1 num_io_threads=0 monitorThreadEfficiency=false num_bam_file_handles=null read_group_black_list=null pedigree=[] pedigreeString=[] pedigreeValidationType=STRICT allow_intervals_with_unindexed_bam=false generateShadowBCF=false logging_level=INFO log_to_file=null help=false variant=(RodBinding name=variant source=/seq/dax/all_1kg_exomes/v1/all_1kg_exomes.unannotated.vcf) snpEffFile=(RodBinding name=snpEffFile source=/seq/dax/all_1kg_exomes/v1/all_1kg_exomes.snpeff.vcf) dbsnp=(RodBinding name= source=UNBOUND) comp=[] resource=[] out=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub no_cmdline_in_header=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub sites_only=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub bcf=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub annotation=[SnpEff] excludeAnnotation=[] group=[] expression=[] useAllAnnotations=false list=false alwaysAppendDbsnpId=false MendelViolationGenotypeQualityThreshold=0.0 requireStrictAlleleMatch=false filter_mismatching_base_and_quals=false""; ##VariantFiltration=""analysis_type=VariantFiltration input_file=[] read_buffer_size=null phone_home=STANDARD gatk_key=null tag=NA read_filter=[] intervals=[/seq/dax/all_1kg_exomes/v1/all_1kg_exomes.padded.interval_list] excludeIntervals=null interval_set_rule=UNION interval_merging=ALL interval_padding=0 reference_sequence=/seq/references/Homo_sapiens_assembly19/v1/Homo_sapiens_assembly19.fasta nonDeterministicRandomSeed=false disableRandomization=false maxRuntime=-1 maxRuntimeUnits=MINUTES downsa",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/1822#issuecomment-301916658
https://github.com/hail-is/hail/issues/1822#issuecomment-301916658:18521,Testability,stub,stubs,18521,"uality_scores=false performanceLog=null useOriginalQualities=false BQSR=null quantize_quals=0 disable_indel_quals=false emit_original_quals=false preserve_qscores_less_than=6 defaultBaseQualities=-1 validation_strictness=SILENT remove_program_records=false keep_program_records=false unsafe=null num_threads=1 num_cpu_threads_per_data_thread=1 num_io_threads=0 monitorThreadEfficiency=false num_bam_file_handles=null read_group_black_list=null pedigree=[] pedigreeString=[] pedigreeValidationType=STRICT allow_intervals_with_unindexed_bam=false generateShadowBCF=false logging_level=INFO log_to_file=null help=false variant=(RodBinding name=variant source=/seq/dax/all_1kg_exomes/v1/all_1kg_exomes.unannotated.vcf) snpEffFile=(RodBinding name=snpEffFile source=/seq/dax/all_1kg_exomes/v1/all_1kg_exomes.snpeff.vcf) dbsnp=(RodBinding name= source=UNBOUND) comp=[] resource=[] out=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub no_cmdline_in_header=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub sites_only=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub bcf=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub annotation=[SnpEff] excludeAnnotation=[] group=[] expression=[] useAllAnnotations=false list=false alwaysAppendDbsnpId=false MendelViolationGenotypeQualityThreshold=0.0 requireStrictAlleleMatch=false filter_mismatching_base_and_quals=false""; ##VariantFiltration=""analysis_type=VariantFiltration input_file=[] read_buffer_size=null phone_home=STANDARD gatk_key=null tag=NA read_filter=[] intervals=[/seq/dax/all_1kg_exomes/v1/all_1kg_exomes.padded.interval_list] excludeIntervals=null interval_set_rule=UNION interval_merging=ALL interval_padding=0 reference_sequence=/seq/references/Homo_sapiens_assembly19/v1/Homo_sapiens_assembly19.fasta nonDeterministicRandomSeed=false disableRandomization=false maxRuntime=-1 maxRuntimeUnits=MINUTES downsampling_type=BY_SAMPLE downsample_to_fraction=null downsample_to_coverage=1000 use_leg",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/1822#issuecomment-301916658
https://github.com/hail-is/hail/issues/1822#issuecomment-301916658:18596,Testability,stub,stubs,18596,"l quantize_quals=0 disable_indel_quals=false emit_original_quals=false preserve_qscores_less_than=6 defaultBaseQualities=-1 validation_strictness=SILENT remove_program_records=false keep_program_records=false unsafe=null num_threads=1 num_cpu_threads_per_data_thread=1 num_io_threads=0 monitorThreadEfficiency=false num_bam_file_handles=null read_group_black_list=null pedigree=[] pedigreeString=[] pedigreeValidationType=STRICT allow_intervals_with_unindexed_bam=false generateShadowBCF=false logging_level=INFO log_to_file=null help=false variant=(RodBinding name=variant source=/seq/dax/all_1kg_exomes/v1/all_1kg_exomes.unannotated.vcf) snpEffFile=(RodBinding name=snpEffFile source=/seq/dax/all_1kg_exomes/v1/all_1kg_exomes.snpeff.vcf) dbsnp=(RodBinding name= source=UNBOUND) comp=[] resource=[] out=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub no_cmdline_in_header=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub sites_only=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub bcf=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub annotation=[SnpEff] excludeAnnotation=[] group=[] expression=[] useAllAnnotations=false list=false alwaysAppendDbsnpId=false MendelViolationGenotypeQualityThreshold=0.0 requireStrictAlleleMatch=false filter_mismatching_base_and_quals=false""; ##VariantFiltration=""analysis_type=VariantFiltration input_file=[] read_buffer_size=null phone_home=STANDARD gatk_key=null tag=NA read_filter=[] intervals=[/seq/dax/all_1kg_exomes/v1/all_1kg_exomes.padded.interval_list] excludeIntervals=null interval_set_rule=UNION interval_merging=ALL interval_padding=0 reference_sequence=/seq/references/Homo_sapiens_assembly19/v1/Homo_sapiens_assembly19.fasta nonDeterministicRandomSeed=false disableRandomization=false maxRuntime=-1 maxRuntimeUnits=MINUTES downsampling_type=BY_SAMPLE downsample_to_fraction=null downsample_to_coverage=1000 use_legacy_downsampler=false baq=OFF baqGapOpenPenalty=40.0 fix_misencoded_quality",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/1822#issuecomment-301916658
https://github.com/hail-is/hail/issues/1822#issuecomment-301916658:18664,Testability,stub,stubs,18664,"se preserve_qscores_less_than=6 defaultBaseQualities=-1 validation_strictness=SILENT remove_program_records=false keep_program_records=false unsafe=null num_threads=1 num_cpu_threads_per_data_thread=1 num_io_threads=0 monitorThreadEfficiency=false num_bam_file_handles=null read_group_black_list=null pedigree=[] pedigreeString=[] pedigreeValidationType=STRICT allow_intervals_with_unindexed_bam=false generateShadowBCF=false logging_level=INFO log_to_file=null help=false variant=(RodBinding name=variant source=/seq/dax/all_1kg_exomes/v1/all_1kg_exomes.unannotated.vcf) snpEffFile=(RodBinding name=snpEffFile source=/seq/dax/all_1kg_exomes/v1/all_1kg_exomes.snpeff.vcf) dbsnp=(RodBinding name= source=UNBOUND) comp=[] resource=[] out=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub no_cmdline_in_header=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub sites_only=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub bcf=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub annotation=[SnpEff] excludeAnnotation=[] group=[] expression=[] useAllAnnotations=false list=false alwaysAppendDbsnpId=false MendelViolationGenotypeQualityThreshold=0.0 requireStrictAlleleMatch=false filter_mismatching_base_and_quals=false""; ##VariantFiltration=""analysis_type=VariantFiltration input_file=[] read_buffer_size=null phone_home=STANDARD gatk_key=null tag=NA read_filter=[] intervals=[/seq/dax/all_1kg_exomes/v1/all_1kg_exomes.padded.interval_list] excludeIntervals=null interval_set_rule=UNION interval_merging=ALL interval_padding=0 reference_sequence=/seq/references/Homo_sapiens_assembly19/v1/Homo_sapiens_assembly19.fasta nonDeterministicRandomSeed=false disableRandomization=false maxRuntime=-1 maxRuntimeUnits=MINUTES downsampling_type=BY_SAMPLE downsample_to_fraction=null downsample_to_coverage=1000 use_legacy_downsampler=false baq=OFF baqGapOpenPenalty=40.0 fix_misencoded_quality_scores=false allow_potentially_misencoded_quality_scores=false perf",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/1822#issuecomment-301916658
https://github.com/hail-is/hail/issues/1822#issuecomment-301916658:20440,Testability,stub,stubs,20440,"ng_type=BY_SAMPLE downsample_to_fraction=null downsample_to_coverage=1000 use_legacy_downsampler=false baq=OFF baqGapOpenPenalty=40.0 fix_misencoded_quality_scores=false allow_potentially_misencoded_quality_scores=false performanceLog=null useOriginalQualities=false BQSR=null quantize_quals=0 disable_indel_quals=false emit_original_quals=false preserve_qscores_less_than=6 defaultBaseQualities=-1 validation_strictness=SILENT remove_program_records=false keep_program_records=false unsafe=null num_threads=1 num_cpu_threads_per_data_thread=1 num_io_threads=0 monitorThreadEfficiency=false num_bam_file_handles=null read_group_black_list=null pedigree=[] pedigreeString=[] pedigreeValidationType=STRICT allow_intervals_with_unindexed_bam=false generateShadowBCF=false logging_level=INFO log_to_file=null help=false variant=(RodBinding name=variant source=/seq/dax/all_1kg_exomes/v1/all_1kg_exomes.indels.unfiltered.vcf) mask=(RodBinding name= source=UNBOUND) out=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub no_cmdline_in_header=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub sites_only=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub bcf=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub filterExpression=[FS>200.0, QD<2.0, ReadPosRankSum<-20.0, InbreedingCoeff<-0.8] filterName=[Indel_FS, Indel_QD, Indel_ReadPosRankSum, Indel_InbreedingCoeff] genotypeFilterExpression=[] genotypeFilterName=[] clusterSize=3 clusterWindowSize=0 maskExtension=0 maskName=Mask missingValuesInExpressionsShouldEvaluateAsFailing=false invalidatePreviousFilters=false filter_mismatching_base_and_quals=false""; ##contig=<ID=1,length=248956422>; ##contig=<ID=2,length=242193529>; ##contig=<ID=3,length=198295559>; ##contig=<ID=4,length=190214555>; ##contig=<ID=5,length=181538259>; ##contig=<ID=6,length=170805979>; ##contig=<ID=7,length=159345973>; ##contig=<ID=8,length=145138636>; ##contig=<ID=9,length=138394717>; ##contig=<ID=10,length=133797422>; ##",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/1822#issuecomment-301916658
https://github.com/hail-is/hail/issues/1822#issuecomment-301916658:20525,Testability,stub,stubs,20525,"downsampler=false baq=OFF baqGapOpenPenalty=40.0 fix_misencoded_quality_scores=false allow_potentially_misencoded_quality_scores=false performanceLog=null useOriginalQualities=false BQSR=null quantize_quals=0 disable_indel_quals=false emit_original_quals=false preserve_qscores_less_than=6 defaultBaseQualities=-1 validation_strictness=SILENT remove_program_records=false keep_program_records=false unsafe=null num_threads=1 num_cpu_threads_per_data_thread=1 num_io_threads=0 monitorThreadEfficiency=false num_bam_file_handles=null read_group_black_list=null pedigree=[] pedigreeString=[] pedigreeValidationType=STRICT allow_intervals_with_unindexed_bam=false generateShadowBCF=false logging_level=INFO log_to_file=null help=false variant=(RodBinding name=variant source=/seq/dax/all_1kg_exomes/v1/all_1kg_exomes.indels.unfiltered.vcf) mask=(RodBinding name= source=UNBOUND) out=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub no_cmdline_in_header=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub sites_only=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub bcf=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub filterExpression=[FS>200.0, QD<2.0, ReadPosRankSum<-20.0, InbreedingCoeff<-0.8] filterName=[Indel_FS, Indel_QD, Indel_ReadPosRankSum, Indel_InbreedingCoeff] genotypeFilterExpression=[] genotypeFilterName=[] clusterSize=3 clusterWindowSize=0 maskExtension=0 maskName=Mask missingValuesInExpressionsShouldEvaluateAsFailing=false invalidatePreviousFilters=false filter_mismatching_base_and_quals=false""; ##contig=<ID=1,length=248956422>; ##contig=<ID=2,length=242193529>; ##contig=<ID=3,length=198295559>; ##contig=<ID=4,length=190214555>; ##contig=<ID=5,length=181538259>; ##contig=<ID=6,length=170805979>; ##contig=<ID=7,length=159345973>; ##contig=<ID=8,length=145138636>; ##contig=<ID=9,length=138394717>; ##contig=<ID=10,length=133797422>; ##contig=<ID=11,length=135086622>; ##contig=<ID=12,length=133275309>; ##contig=<ID=13,l",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/1822#issuecomment-301916658
https://github.com/hail-is/hail/issues/1822#issuecomment-301916658:20600,Testability,stub,stubs,20600,"res=false allow_potentially_misencoded_quality_scores=false performanceLog=null useOriginalQualities=false BQSR=null quantize_quals=0 disable_indel_quals=false emit_original_quals=false preserve_qscores_less_than=6 defaultBaseQualities=-1 validation_strictness=SILENT remove_program_records=false keep_program_records=false unsafe=null num_threads=1 num_cpu_threads_per_data_thread=1 num_io_threads=0 monitorThreadEfficiency=false num_bam_file_handles=null read_group_black_list=null pedigree=[] pedigreeString=[] pedigreeValidationType=STRICT allow_intervals_with_unindexed_bam=false generateShadowBCF=false logging_level=INFO log_to_file=null help=false variant=(RodBinding name=variant source=/seq/dax/all_1kg_exomes/v1/all_1kg_exomes.indels.unfiltered.vcf) mask=(RodBinding name= source=UNBOUND) out=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub no_cmdline_in_header=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub sites_only=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub bcf=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub filterExpression=[FS>200.0, QD<2.0, ReadPosRankSum<-20.0, InbreedingCoeff<-0.8] filterName=[Indel_FS, Indel_QD, Indel_ReadPosRankSum, Indel_InbreedingCoeff] genotypeFilterExpression=[] genotypeFilterName=[] clusterSize=3 clusterWindowSize=0 maskExtension=0 maskName=Mask missingValuesInExpressionsShouldEvaluateAsFailing=false invalidatePreviousFilters=false filter_mismatching_base_and_quals=false""; ##contig=<ID=1,length=248956422>; ##contig=<ID=2,length=242193529>; ##contig=<ID=3,length=198295559>; ##contig=<ID=4,length=190214555>; ##contig=<ID=5,length=181538259>; ##contig=<ID=6,length=170805979>; ##contig=<ID=7,length=159345973>; ##contig=<ID=8,length=145138636>; ##contig=<ID=9,length=138394717>; ##contig=<ID=10,length=133797422>; ##contig=<ID=11,length=135086622>; ##contig=<ID=12,length=133275309>; ##contig=<ID=13,length=114364328>; ##contig=<ID=14,length=107043718>; ##contig=<ID=15,length",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/1822#issuecomment-301916658
https://github.com/hail-is/hail/issues/1822#issuecomment-301916658:20668,Testability,stub,stubs,20668,"nceLog=null useOriginalQualities=false BQSR=null quantize_quals=0 disable_indel_quals=false emit_original_quals=false preserve_qscores_less_than=6 defaultBaseQualities=-1 validation_strictness=SILENT remove_program_records=false keep_program_records=false unsafe=null num_threads=1 num_cpu_threads_per_data_thread=1 num_io_threads=0 monitorThreadEfficiency=false num_bam_file_handles=null read_group_black_list=null pedigree=[] pedigreeString=[] pedigreeValidationType=STRICT allow_intervals_with_unindexed_bam=false generateShadowBCF=false logging_level=INFO log_to_file=null help=false variant=(RodBinding name=variant source=/seq/dax/all_1kg_exomes/v1/all_1kg_exomes.indels.unfiltered.vcf) mask=(RodBinding name= source=UNBOUND) out=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub no_cmdline_in_header=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub sites_only=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub bcf=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub filterExpression=[FS>200.0, QD<2.0, ReadPosRankSum<-20.0, InbreedingCoeff<-0.8] filterName=[Indel_FS, Indel_QD, Indel_ReadPosRankSum, Indel_InbreedingCoeff] genotypeFilterExpression=[] genotypeFilterName=[] clusterSize=3 clusterWindowSize=0 maskExtension=0 maskName=Mask missingValuesInExpressionsShouldEvaluateAsFailing=false invalidatePreviousFilters=false filter_mismatching_base_and_quals=false""; ##contig=<ID=1,length=248956422>; ##contig=<ID=2,length=242193529>; ##contig=<ID=3,length=198295559>; ##contig=<ID=4,length=190214555>; ##contig=<ID=5,length=181538259>; ##contig=<ID=6,length=170805979>; ##contig=<ID=7,length=159345973>; ##contig=<ID=8,length=145138636>; ##contig=<ID=9,length=138394717>; ##contig=<ID=10,length=133797422>; ##contig=<ID=11,length=135086622>; ##contig=<ID=12,length=133275309>; ##contig=<ID=13,length=114364328>; ##contig=<ID=14,length=107043718>; ##contig=<ID=15,length=101991189>; ##contig=<ID=16,length=90338345>; ##contig=<ID=17,lengt",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/1822#issuecomment-301916658
https://github.com/hail-is/hail/issues/1823#issuecomment-302457141:3,Deployability,update,update,3,"An update: I missed an additional `annotate_variants_table(kt_keyed_on_variant)` in my example above. Interestingly, it seems to work if I do:; ```; vds.annotate_variants_table(kt_keyed_on_variant).annotate_variants_table(kt_keyed_on_locus).write(); ```; but fails if I:; ```; vds.annotate_variants_table(kt_keyed_on_locus).annotate_variants_table(kt_keyed_on_variant).write(); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/1823#issuecomment-302457141
https://github.com/hail-is/hail/pull/1826#issuecomment-301944755:5,Security,expose,exposed,5,"This exposed a problem with typecheck - you can't check arguments that need to be the class you're defining, like `concordance` or `join`. . I marked these as `anytype` for now. I will ruminate on this.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1826#issuecomment-301944755
https://github.com/hail-is/hail/pull/1826#issuecomment-301948641:57,Modifiability,inherit,inheritance,57,"I had exactly the same idea, but it causes problems with inheritance.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1826#issuecomment-301948641
https://github.com/hail-is/hail/pull/1826#issuecomment-301973652:46,Availability,error,error,46,Let's merge this so people don't get horrible error messages for now. I'll make an issue to make typecheck more powerful.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1826#issuecomment-301973652
https://github.com/hail-is/hail/pull/1826#issuecomment-301973652:112,Energy Efficiency,power,powerful,112,Let's merge this so people don't get horrible error messages for now. I'll make an issue to make typecheck more powerful.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1826#issuecomment-301973652
https://github.com/hail-is/hail/pull/1826#issuecomment-301973652:52,Integrability,message,messages,52,Let's merge this so people don't get horrible error messages for now. I'll make an issue to make typecheck more powerful.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1826#issuecomment-301973652
https://github.com/hail-is/hail/pull/1827#issuecomment-302116530:33,Deployability,integrat,integration,33,Great! I think we should run the integration tests as part of `testAll` and kill the integration tests in the CI.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1827#issuecomment-302116530
https://github.com/hail-is/hail/pull/1827#issuecomment-302116530:85,Deployability,integrat,integration,85,Great! I think we should run the integration tests as part of `testAll` and kill the integration tests in the CI.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1827#issuecomment-302116530
https://github.com/hail-is/hail/pull/1827#issuecomment-302116530:33,Integrability,integrat,integration,33,Great! I think we should run the integration tests as part of `testAll` and kill the integration tests in the CI.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1827#issuecomment-302116530
https://github.com/hail-is/hail/pull/1827#issuecomment-302116530:85,Integrability,integrat,integration,85,Great! I think we should run the integration tests as part of `testAll` and kill the integration tests in the CI.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1827#issuecomment-302116530
https://github.com/hail-is/hail/pull/1827#issuecomment-302116530:45,Testability,test,tests,45,Great! I think we should run the integration tests as part of `testAll` and kill the integration tests in the CI.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1827#issuecomment-302116530
https://github.com/hail-is/hail/pull/1827#issuecomment-302116530:63,Testability,test,testAll,63,Great! I think we should run the integration tests as part of `testAll` and kill the integration tests in the CI.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1827#issuecomment-302116530
https://github.com/hail-is/hail/pull/1827#issuecomment-302116530:97,Testability,test,tests,97,Great! I think we should run the integration tests as part of `testAll` and kill the integration tests in the CI.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1827#issuecomment-302116530
https://github.com/hail-is/hail/pull/1827#issuecomment-302134641:68,Testability,test,tests,68,@cseed back to you. I'm open to suggestions on how to structure the tests locations / file naming.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1827#issuecomment-302134641
https://github.com/hail-is/hail/pull/1833#issuecomment-302138783:57,Deployability,update,update,57,"Actually, I realized I need this for aggregators... will update PR. Sorry.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1833#issuecomment-302138783
https://github.com/hail-is/hail/pull/1839#issuecomment-302194372:61,Integrability,interface,interface,61,"@danking this is just the first step, but it provides a good interface to the function you need for PCrelate",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1839#issuecomment-302194372
https://github.com/hail-is/hail/pull/1854#issuecomment-302792319:4,Availability,error,error,4,the error message? or what?. Can you write a docstring for that function?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1854#issuecomment-302792319
https://github.com/hail-is/hail/pull/1854#issuecomment-302792319:10,Integrability,message,message,10,the error message? or what?. Can you write a docstring for that function?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1854#issuecomment-302792319
https://github.com/hail-is/hail/pull/1859#issuecomment-302843950:31,Testability,test,testing,31,The `range` method is nice for testing + exploration. I want to use this in a tutorial to show some stuff. The `indexed` method address #1785 and is pretty useful more broadly.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1859#issuecomment-302843950
https://github.com/hail-is/hail/pull/1864#issuecomment-302978218:25,Safety,unsafe,unsafe,25,"I'm not sure how this is unsafe. Could you explain?. I think that if we have code producing an RDD with a mismatched partitioner, we should correct that code. We have to be able to assume that an RDD is accurately reflected by its partitioner",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1864#issuecomment-302978218
https://github.com/hail-is/hail/pull/1864#issuecomment-302978822:166,Availability,error,errors,166,i think the better solution is to check that the ordered key inside the partitioner is the same as the implicit ordered key supplied. this also could have caught the errors,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1864#issuecomment-302978822
https://github.com/hail-is/hail/pull/1864#issuecomment-303237349:606,Availability,error,errors,606,"> I'm not sure how this is unsafe. Could you explain?. Partitioner just says what elements are in what partitions. OrderedRDD also guarantees those elements are in a specific order. It is not safe to take an RDD partitioned with an OrderedPartitioner and just ""make"" it an OrderedRDD. Case where it fails: in read, union, which creates a partition-aware RDD that unions corresponding partition from a set of identically partitioned RDDs. > i think the better solution is to check that the ordered key inside the partitioner is the same as the implicit ordered key supplied. this also could have caught the errors. The error was making it into an OrderedRDD without sorting. It is perfectly valid to have an OrderedPartitioner-partitioned RDD that is sorted. (Above read case.)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1864#issuecomment-303237349
https://github.com/hail-is/hail/pull/1864#issuecomment-303237349:618,Availability,error,error,618,"> I'm not sure how this is unsafe. Could you explain?. Partitioner just says what elements are in what partitions. OrderedRDD also guarantees those elements are in a specific order. It is not safe to take an RDD partitioned with an OrderedPartitioner and just ""make"" it an OrderedRDD. Case where it fails: in read, union, which creates a partition-aware RDD that unions corresponding partition from a set of identically partitioned RDDs. > i think the better solution is to check that the ordered key inside the partitioner is the same as the implicit ordered key supplied. this also could have caught the errors. The error was making it into an OrderedRDD without sorting. It is perfectly valid to have an OrderedPartitioner-partitioned RDD that is sorted. (Above read case.)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1864#issuecomment-303237349
https://github.com/hail-is/hail/pull/1864#issuecomment-303237349:27,Safety,unsafe,unsafe,27,"> I'm not sure how this is unsafe. Could you explain?. Partitioner just says what elements are in what partitions. OrderedRDD also guarantees those elements are in a specific order. It is not safe to take an RDD partitioned with an OrderedPartitioner and just ""make"" it an OrderedRDD. Case where it fails: in read, union, which creates a partition-aware RDD that unions corresponding partition from a set of identically partitioned RDDs. > i think the better solution is to check that the ordered key inside the partitioner is the same as the implicit ordered key supplied. this also could have caught the errors. The error was making it into an OrderedRDD without sorting. It is perfectly valid to have an OrderedPartitioner-partitioned RDD that is sorted. (Above read case.)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1864#issuecomment-303237349
https://github.com/hail-is/hail/pull/1864#issuecomment-303237349:192,Safety,safe,safe,192,"> I'm not sure how this is unsafe. Could you explain?. Partitioner just says what elements are in what partitions. OrderedRDD also guarantees those elements are in a specific order. It is not safe to take an RDD partitioned with an OrderedPartitioner and just ""make"" it an OrderedRDD. Case where it fails: in read, union, which creates a partition-aware RDD that unions corresponding partition from a set of identically partitioned RDDs. > i think the better solution is to check that the ordered key inside the partitioner is the same as the implicit ordered key supplied. this also could have caught the errors. The error was making it into an OrderedRDD without sorting. It is perfectly valid to have an OrderedPartitioner-partitioned RDD that is sorted. (Above read case.)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1864#issuecomment-303237349
https://github.com/hail-is/hail/pull/1872#issuecomment-304126037:253,Testability,test,tests,253,"@tpoterba ready for another look. I killed isGenericGenotype. filterGenotypes just makes filtered cells null. GenotypeStream now supports null genotypes, this is a breaking change. I bumped the file version (to 0x101) and nuked the 0.1 and other legacy tests. The merge target is now the 0.2 branch. Once the CI is correctly handling 0.1 and devel/0.2, we can merge 0.2 into the master and just work out of master.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1872#issuecomment-304126037
https://github.com/hail-is/hail/pull/1872#issuecomment-305223718:199,Safety,safe,safe,199,"Allow the Genotype in VSM to be null. This means you can't call `g.gt` anymore, since `g` might be null. Moved the user-visible Genotype functions to the Genotype companion object and made them null-safe. This makes the behavior of filterGenotypes between VariantDataset and GenericDataset consistent. Fixed the tests. @tpoterba ready for another look.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1872#issuecomment-305223718
https://github.com/hail-is/hail/pull/1872#issuecomment-305223718:312,Testability,test,tests,312,"Allow the Genotype in VSM to be null. This means you can't call `g.gt` anymore, since `g` might be null. Moved the user-visible Genotype functions to the Genotype companion object and made them null-safe. This makes the behavior of filterGenotypes between VariantDataset and GenericDataset consistent. Fixed the tests. @tpoterba ready for another look.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1872#issuecomment-305223718
https://github.com/hail-is/hail/pull/1872#issuecomment-305741770:14,Testability,test,tests,14,Fixed all the tests.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1872#issuecomment-305741770
https://github.com/hail-is/hail/pull/1875#issuecomment-303504943:33,Testability,test,tests,33,"Please make the one change, pass tests, and merge.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1875#issuecomment-303504943
https://github.com/hail-is/hail/pull/1884#issuecomment-304078746:16,Performance,perform,performance,16,"And if you have performance benchmarks already, make a note of them here.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1884#issuecomment-304078746
https://github.com/hail-is/hail/pull/1884#issuecomment-304078746:28,Testability,benchmark,benchmarks,28,"And if you have performance benchmarks already, make a note of them here.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1884#issuecomment-304078746
https://github.com/hail-is/hail/pull/1884#issuecomment-304080520:2,Performance,Perform,Performance,2,"~~Performance note: Was able to do 100k variants by 500k samples with 1000 partitions on 800 cores in 5m4s. We've never successfully done such a multiply on gCloud, but even 50k by 100k examples with the old method took a little more than 20 minutes, so safe to say this is an improvement.~~. Unfortunately, there was a bug that resulted in not all the work getting done and as such the method is not actually as performant as initial tests suggested.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1884#issuecomment-304080520
https://github.com/hail-is/hail/pull/1884#issuecomment-304080520:413,Performance,perform,performant,413,"~~Performance note: Was able to do 100k variants by 500k samples with 1000 partitions on 800 cores in 5m4s. We've never successfully done such a multiply on gCloud, but even 50k by 100k examples with the old method took a little more than 20 minutes, so safe to say this is an improvement.~~. Unfortunately, there was a bug that resulted in not all the work getting done and as such the method is not actually as performant as initial tests suggested.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1884#issuecomment-304080520
https://github.com/hail-is/hail/pull/1884#issuecomment-304080520:254,Safety,safe,safe,254,"~~Performance note: Was able to do 100k variants by 500k samples with 1000 partitions on 800 cores in 5m4s. We've never successfully done such a multiply on gCloud, but even 50k by 100k examples with the old method took a little more than 20 minutes, so safe to say this is an improvement.~~. Unfortunately, there was a bug that resulted in not all the work getting done and as such the method is not actually as performant as initial tests suggested.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1884#issuecomment-304080520
https://github.com/hail-is/hail/pull/1884#issuecomment-304080520:435,Testability,test,tests,435,"~~Performance note: Was able to do 100k variants by 500k samples with 1000 partitions on 800 cores in 5m4s. We've never successfully done such a multiply on gCloud, but even 50k by 100k examples with the old method took a little more than 20 minutes, so safe to say this is an improvement.~~. Unfortunately, there was a bug that resulted in not all the work getting done and as such the method is not actually as performant as initial tests suggested.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1884#issuecomment-304080520
https://github.com/hail-is/hail/issues/1887#issuecomment-305268107:313,Deployability,release,release,313,"Maybe we should make an issue tag for things to fix before 0.2? We can't fix this without making a breaking interface change, but it's a really easy change that we shouldn't forget to include once we do 0.2. More generally, it seems like it would be good if we knew what we were planning on including before next release.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/1887#issuecomment-305268107
https://github.com/hail-is/hail/issues/1887#issuecomment-305268107:108,Integrability,interface,interface,108,"Maybe we should make an issue tag for things to fix before 0.2? We can't fix this without making a breaking interface change, but it's a really easy change that we shouldn't forget to include once we do 0.2. More generally, it seems like it would be good if we knew what we were planning on including before next release.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/1887#issuecomment-305268107
https://github.com/hail-is/hail/pull/1893#issuecomment-305345167:52,Testability,test,tests,52,Note that I am not at all convinced that the random tests are providing good coverage: https://github.com/hail-is/hail/issues/1894,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1893#issuecomment-305345167
https://github.com/hail-is/hail/pull/1895#issuecomment-306268836:59,Testability,test,testing,59,@danking I also have a PR onto your branch with randomized testing and comparison against Breeze here : https://github.com/danking/hail/pull/1,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1895#issuecomment-306268836
https://github.com/hail-is/hail/pull/1895#issuecomment-312064471:103,Testability,test,tests,103,"@cseed @johnc1231 Ok here's the final iteration. One more look over is appreciated, I added a bunch of tests. Commentary very welcome on testing strategy and code.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1895#issuecomment-312064471
https://github.com/hail-is/hail/pull/1895#issuecomment-312064471:137,Testability,test,testing,137,"@cseed @johnc1231 Ok here's the final iteration. One more look over is appreciated, I added a bunch of tests. Commentary very welcome on testing strategy and code.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1895#issuecomment-312064471
https://github.com/hail-is/hail/pull/1895#issuecomment-312331956:67,Testability,test,tests,67,"Made two small comments, but they're a typo and an organization of tests comment. I'm fine with the code here, and happy with the tests. Just leaves @cseed to sign off on this",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1895#issuecomment-312331956
https://github.com/hail-is/hail/pull/1895#issuecomment-312331956:130,Testability,test,tests,130,"Made two small comments, but they're a typo and an organization of tests comment. I'm fine with the code here, and happy with the tests. Just leaves @cseed to sign off on this",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1895#issuecomment-312331956
https://github.com/hail-is/hail/issues/1896#issuecomment-408636691:22,Availability,error,error,22,"This now gives a nice error message:. ```; >>> hl.uniroot(lambda x: x * x + 1, -1, 1).value; Error summary: HailException: sign of endpoints must have opposite signs, got: f(min) = 2.0, f(max) = 2.0; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/1896#issuecomment-408636691
https://github.com/hail-is/hail/issues/1896#issuecomment-408636691:93,Availability,Error,Error,93,"This now gives a nice error message:. ```; >>> hl.uniroot(lambda x: x * x + 1, -1, 1).value; Error summary: HailException: sign of endpoints must have opposite signs, got: f(min) = 2.0, f(max) = 2.0; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/1896#issuecomment-408636691
https://github.com/hail-is/hail/issues/1896#issuecomment-408636691:28,Integrability,message,message,28,"This now gives a nice error message:. ```; >>> hl.uniroot(lambda x: x * x + 1, -1, 1).value; Error summary: HailException: sign of endpoints must have opposite signs, got: f(min) = 2.0, f(max) = 2.0; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/1896#issuecomment-408636691
https://github.com/hail-is/hail/pull/1900#issuecomment-307388969:105,Performance,perform,performance,105,"Looks good, I say we put it in. I think in the future we should talk somewhere about things important to performance though that new users often get wrong (not caching appropriately, repartitioning, etc.)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1900#issuecomment-307388969
https://github.com/hail-is/hail/pull/1902#issuecomment-306294818:15,Availability,failure,failures,15,"A few new test failures coming from better generators, I assume. IBD one looks like a weird corner case where we differ from plink when there are only three variants. I'll look at the rest soon.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1902#issuecomment-306294818
https://github.com/hail-is/hail/pull/1902#issuecomment-306294818:10,Testability,test,test,10,"A few new test failures coming from better generators, I assume. IBD one looks like a weird corner case where we differ from plink when there are only three variants. I'll look at the rest soon.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1902#issuecomment-306294818
https://github.com/hail-is/hail/pull/1902#issuecomment-321381973:19,Testability,test,test,19,@cseed back to you test hopefully pass now,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1902#issuecomment-321381973
https://github.com/hail-is/hail/pull/1914#issuecomment-308780378:407,Availability,down,downsides,407,"1. Functionally, it's already possible -- should be able to do `vds.annotate_variants_db('va.dann')` and get the `va.dann.score` annotation in your VDS. Taking a step further, you can even do `vds.annotate_variants_db('va')` and get all of the annotations. It's just a matter of designing the query builder to encourage people using the function in whatever way we think is optimal, I suppose. What are the downsides to carrying around a lot of annotations in a VDS? I worry that if we supplied a select-all `va` option, everybody would just use that -- but if there aren't any major drawbacks, maybe that's the way to go and we don't even really need a query builder. Or maybe just allowing top-level selections like `va.dann`, `va.chromHMM`, etc. would be a good intermediate solution. 2. Yes! I'd definitely be interested in working on a Scala implementation, if one of you would be willing to work with a newbie :). Though I think if we can get this Python version working & usable first, that may be best. 3. I'll look into this. I don't have a solution yet. That's why in the method documentation, I used ; `.. code-block:: python` statements to add example code snippets. With the `>>> ...` syntax, the build was trying to run those examples and throwing weird errors like you anticipated.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1914#issuecomment-308780378
https://github.com/hail-is/hail/pull/1914#issuecomment-308780378:1268,Availability,error,errors,1268,"1. Functionally, it's already possible -- should be able to do `vds.annotate_variants_db('va.dann')` and get the `va.dann.score` annotation in your VDS. Taking a step further, you can even do `vds.annotate_variants_db('va')` and get all of the annotations. It's just a matter of designing the query builder to encourage people using the function in whatever way we think is optimal, I suppose. What are the downsides to carrying around a lot of annotations in a VDS? I worry that if we supplied a select-all `va` option, everybody would just use that -- but if there aren't any major drawbacks, maybe that's the way to go and we don't even really need a query builder. Or maybe just allowing top-level selections like `va.dann`, `va.chromHMM`, etc. would be a good intermediate solution. 2. Yes! I'd definitely be interested in working on a Scala implementation, if one of you would be willing to work with a newbie :). Though I think if we can get this Python version working & usable first, that may be best. 3. I'll look into this. I don't have a solution yet. That's why in the method documentation, I used ; `.. code-block:: python` statements to add example code snippets. With the `>>> ...` syntax, the build was trying to run those examples and throwing weird errors like you anticipated.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1914#issuecomment-308780378
https://github.com/hail-is/hail/pull/1914#issuecomment-308780378:979,Usability,usab,usable,979,"1. Functionally, it's already possible -- should be able to do `vds.annotate_variants_db('va.dann')` and get the `va.dann.score` annotation in your VDS. Taking a step further, you can even do `vds.annotate_variants_db('va')` and get all of the annotations. It's just a matter of designing the query builder to encourage people using the function in whatever way we think is optimal, I suppose. What are the downsides to carrying around a lot of annotations in a VDS? I worry that if we supplied a select-all `va` option, everybody would just use that -- but if there aren't any major drawbacks, maybe that's the way to go and we don't even really need a query builder. Or maybe just allowing top-level selections like `va.dann`, `va.chromHMM`, etc. would be a good intermediate solution. 2. Yes! I'd definitely be interested in working on a Scala implementation, if one of you would be willing to work with a newbie :). Though I think if we can get this Python version working & usable first, that may be best. 3. I'll look into this. I don't have a solution yet. That's why in the method documentation, I used ; `.. code-block:: python` statements to add example code snippets. With the `>>> ...` syntax, the build was trying to run those examples and throwing weird errors like you anticipated.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1914#issuecomment-308780378
https://github.com/hail-is/hail/pull/1929#issuecomment-311341764:91,Testability,test,tests,91,I didn't claim to have fixed this one yet. Mentioned I had not pushed because it will fail tests due to per-variant beta being wrong.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1929#issuecomment-311341764
https://github.com/hail-is/hail/pull/1929#issuecomment-313825166:19,Availability,error,error,19,then make sure the error says number of eigenvectors and not ``n_eigs``,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1929#issuecomment-313825166
https://github.com/hail-is/hail/pull/1936#issuecomment-311068359:266,Deployability,configurat,configuration,266,With this new approach I'm trying to use a PHP script to fetch the metadata from SQLite and pass it off as a JSON file to the client to build the documentation web page. It looks like the script isn't running properly on the CI server -- I guess maybe there is some configuration to be done to allow PHP scripts to run on the web server?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1936#issuecomment-311068359
https://github.com/hail-is/hail/pull/1936#issuecomment-311068359:266,Modifiability,config,configuration,266,With this new approach I'm trying to use a PHP script to fetch the metadata from SQLite and pass it off as a JSON file to the client to build the documentation web page. It looks like the script isn't running properly on the CI server -- I guess maybe there is some configuration to be done to allow PHP scripts to run on the web server?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1936#issuecomment-311068359
https://github.com/hail-is/hail/pull/1936#issuecomment-314784714:33,Deployability,update,updates,33,@tpoterba @jigold committed some updates based on your feedback.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1936#issuecomment-314784714
https://github.com/hail-is/hail/pull/1936#issuecomment-314784714:55,Usability,feedback,feedback,55,@tpoterba @jigold committed some updates based on your feedback.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1936#issuecomment-314784714
https://github.com/hail-is/hail/pull/1936#issuecomment-315459328:269,Energy Efficiency,reduce,reduce,269,"@jigold addressed those changes. . Regarding the margin of the `div.wy-nav-content` element, I'm reducing the padding on the right rather than increasing the max-width, I think that should keep the left margin aligned. Though I think that it might not be a bad idea to reduce the left margin across all of the doc pages. I changed one of the treeview parameters as well, hopefully will help with selection issue you were experiencing. Though it is still a bit finicky in certain situations, usually when selecting/unselecting some combination of parent and child nodes (such as in gnomad.exomes). Selecting child nodes on selection of the parent isn't a basic option in the treeview class unfortunately, and I haven't figured out a way to do it that is completely to my satisfaction yet. The clear selections button seems to reset everything appropriately, at least.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1936#issuecomment-315459328
https://github.com/hail-is/hail/pull/1936#issuecomment-315459328:792,Usability,clear,clear,792,"@jigold addressed those changes. . Regarding the margin of the `div.wy-nav-content` element, I'm reducing the padding on the right rather than increasing the max-width, I think that should keep the left margin aligned. Though I think that it might not be a bad idea to reduce the left margin across all of the doc pages. I changed one of the treeview parameters as well, hopefully will help with selection issue you were experiencing. Though it is still a bit finicky in certain situations, usually when selecting/unselecting some combination of parent and child nodes (such as in gnomad.exomes). Selecting child nodes on selection of the parent isn't a basic option in the treeview class unfortunately, and I haven't figured out a way to do it that is completely to my satisfaction yet. The clear selections button seems to reset everything appropriately, at least.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1936#issuecomment-315459328
https://github.com/hail-is/hail/pull/1946#issuecomment-313167921:7,Availability,ping,ping,7,@cseed ping,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1946#issuecomment-313167921
https://github.com/hail-is/hail/pull/1948#issuecomment-311690040:340,Energy Efficiency,monitor,monitor,340,"It seems odd that I have to get below the fold to see any discussion of the engineering work. I don't know how other engineers look for jobs, but I tend to look for the technical details of what the day-to-day would consist of. Maybe @cseed can weigh in? I don't want to tip the scales with a sample of size 1. This is what I can see on my monitor:; ![screen shot 2017-06-28 at 11 06 59 am](https://user-images.githubusercontent.com/106194/27644588-f27f6862-5bf1-11e7-8b2f-820a7ba31490.png). On my laptop screen it looks like this:; ![screen shot 2017-06-28 at 11 07 56 am](https://user-images.githubusercontent.com/106194/27644640-11e85c5e-5bf2-11e7-91c3-0dc9df976c58.png)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1948#issuecomment-311690040
https://github.com/hail-is/hail/pull/1948#issuecomment-311694515:78,Usability,clear,clearer,78,"@danking I changed the homepage banner to ""Hail is hiring engineers!"" so it's clearer. I'll merge now but happy to keep iterating.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1948#issuecomment-311694515
https://github.com/hail-is/hail/pull/1955#issuecomment-311982284:173,Usability,clear,clear,173,"@cseed FWIW, Java has a [`BitSet` class](https://docs.oracle.com/javase/8/docs/api/java/util/BitSet.html) that implements dynamically growing BitSets. It implements `set`, `clear` (for every bit), `clear` (your `reset`), and `get` (your `apply`).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1955#issuecomment-311982284
https://github.com/hail-is/hail/pull/1955#issuecomment-311982284:198,Usability,clear,clear,198,"@cseed FWIW, Java has a [`BitSet` class](https://docs.oracle.com/javase/8/docs/api/java/util/BitSet.html) that implements dynamically growing BitSets. It implements `set`, `clear` (for every bit), `clear` (your `reset`), and `get` (your `apply`).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1955#issuecomment-311982284
https://github.com/hail-is/hail/issues/1963#issuecomment-481354319:195,Availability,avail,available,195,"@tpoterba @danking We at Databricks are still interested in this. Although Hail's frontend is in Python, it's still useful to publish to maven central. First, it makes the dependency information available. I've seen people write pipelines that are partly in Hail and partly in PySpark and can include Java libraries for things like data sources. There's a lot of tooling for resolving dependency conflicts between different libraries, but they're not very accessible unless all your dependencies are published to maven repos and have dependency poms available. It's also easier to update pipelines to the latest Hail version if the artifacts published to a standard location.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/1963#issuecomment-481354319
https://github.com/hail-is/hail/issues/1963#issuecomment-481354319:550,Availability,avail,available,550,"@tpoterba @danking We at Databricks are still interested in this. Although Hail's frontend is in Python, it's still useful to publish to maven central. First, it makes the dependency information available. I've seen people write pipelines that are partly in Hail and partly in PySpark and can include Java libraries for things like data sources. There's a lot of tooling for resolving dependency conflicts between different libraries, but they're not very accessible unless all your dependencies are published to maven repos and have dependency poms available. It's also easier to update pipelines to the latest Hail version if the artifacts published to a standard location.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/1963#issuecomment-481354319
https://github.com/hail-is/hail/issues/1963#issuecomment-481354319:229,Deployability,pipeline,pipelines,229,"@tpoterba @danking We at Databricks are still interested in this. Although Hail's frontend is in Python, it's still useful to publish to maven central. First, it makes the dependency information available. I've seen people write pipelines that are partly in Hail and partly in PySpark and can include Java libraries for things like data sources. There's a lot of tooling for resolving dependency conflicts between different libraries, but they're not very accessible unless all your dependencies are published to maven repos and have dependency poms available. It's also easier to update pipelines to the latest Hail version if the artifacts published to a standard location.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/1963#issuecomment-481354319
https://github.com/hail-is/hail/issues/1963#issuecomment-481354319:581,Deployability,update,update,581,"@tpoterba @danking We at Databricks are still interested in this. Although Hail's frontend is in Python, it's still useful to publish to maven central. First, it makes the dependency information available. I've seen people write pipelines that are partly in Hail and partly in PySpark and can include Java libraries for things like data sources. There's a lot of tooling for resolving dependency conflicts between different libraries, but they're not very accessible unless all your dependencies are published to maven repos and have dependency poms available. It's also easier to update pipelines to the latest Hail version if the artifacts published to a standard location.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/1963#issuecomment-481354319
https://github.com/hail-is/hail/issues/1963#issuecomment-481354319:588,Deployability,pipeline,pipelines,588,"@tpoterba @danking We at Databricks are still interested in this. Although Hail's frontend is in Python, it's still useful to publish to maven central. First, it makes the dependency information available. I've seen people write pipelines that are partly in Hail and partly in PySpark and can include Java libraries for things like data sources. There's a lot of tooling for resolving dependency conflicts between different libraries, but they're not very accessible unless all your dependencies are published to maven repos and have dependency poms available. It's also easier to update pipelines to the latest Hail version if the artifacts published to a standard location.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/1963#issuecomment-481354319
https://github.com/hail-is/hail/issues/1963#issuecomment-481354319:172,Integrability,depend,dependency,172,"@tpoterba @danking We at Databricks are still interested in this. Although Hail's frontend is in Python, it's still useful to publish to maven central. First, it makes the dependency information available. I've seen people write pipelines that are partly in Hail and partly in PySpark and can include Java libraries for things like data sources. There's a lot of tooling for resolving dependency conflicts between different libraries, but they're not very accessible unless all your dependencies are published to maven repos and have dependency poms available. It's also easier to update pipelines to the latest Hail version if the artifacts published to a standard location.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/1963#issuecomment-481354319
https://github.com/hail-is/hail/issues/1963#issuecomment-481354319:385,Integrability,depend,dependency,385,"@tpoterba @danking We at Databricks are still interested in this. Although Hail's frontend is in Python, it's still useful to publish to maven central. First, it makes the dependency information available. I've seen people write pipelines that are partly in Hail and partly in PySpark and can include Java libraries for things like data sources. There's a lot of tooling for resolving dependency conflicts between different libraries, but they're not very accessible unless all your dependencies are published to maven repos and have dependency poms available. It's also easier to update pipelines to the latest Hail version if the artifacts published to a standard location.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/1963#issuecomment-481354319
https://github.com/hail-is/hail/issues/1963#issuecomment-481354319:483,Integrability,depend,dependencies,483,"@tpoterba @danking We at Databricks are still interested in this. Although Hail's frontend is in Python, it's still useful to publish to maven central. First, it makes the dependency information available. I've seen people write pipelines that are partly in Hail and partly in PySpark and can include Java libraries for things like data sources. There's a lot of tooling for resolving dependency conflicts between different libraries, but they're not very accessible unless all your dependencies are published to maven repos and have dependency poms available. It's also easier to update pipelines to the latest Hail version if the artifacts published to a standard location.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/1963#issuecomment-481354319
https://github.com/hail-is/hail/issues/1963#issuecomment-481354319:534,Integrability,depend,dependency,534,"@tpoterba @danking We at Databricks are still interested in this. Although Hail's frontend is in Python, it's still useful to publish to maven central. First, it makes the dependency information available. I've seen people write pipelines that are partly in Hail and partly in PySpark and can include Java libraries for things like data sources. There's a lot of tooling for resolving dependency conflicts between different libraries, but they're not very accessible unless all your dependencies are published to maven repos and have dependency poms available. It's also easier to update pipelines to the latest Hail version if the artifacts published to a standard location.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/1963#issuecomment-481354319
https://github.com/hail-is/hail/issues/1963#issuecomment-481354319:456,Security,access,accessible,456,"@tpoterba @danking We at Databricks are still interested in this. Although Hail's frontend is in Python, it's still useful to publish to maven central. First, it makes the dependency information available. I've seen people write pipelines that are partly in Hail and partly in PySpark and can include Java libraries for things like data sources. There's a lot of tooling for resolving dependency conflicts between different libraries, but they're not very accessible unless all your dependencies are published to maven repos and have dependency poms available. It's also easier to update pipelines to the latest Hail version if the artifacts published to a standard location.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/1963#issuecomment-481354319
https://github.com/hail-is/hail/pull/1972#issuecomment-315444947:17,Testability,test,test,17,Does this need a test?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1972#issuecomment-315444947
https://github.com/hail-is/hail/pull/1972#issuecomment-316468753:6,Testability,test,test,6,We'll test this when we add keytable random gens. For now I think this is a clear fix,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1972#issuecomment-316468753
https://github.com/hail-is/hail/pull/1972#issuecomment-316468753:76,Usability,clear,clear,76,We'll test this when we add keytable random gens. For now I think this is a clear fix,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1972#issuecomment-316468753
https://github.com/hail-is/hail/pull/1973#issuecomment-317271753:17,Testability,test,tests,17,"Also, looks like tests are unhappy.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1973#issuecomment-317271753
https://github.com/hail-is/hail/pull/1973#issuecomment-320358482:227,Availability,redundant,redundant,227,Currently the linear SKAT routine is implemented to be optimal for the case of (genetic variants) k < n (genetic samples). Implementation will process sets of variants associated to the same gene in such a way that there is no redundant computation in the algorithm. . cases handled:; hard call genetic data; dosage genetic data; k << n - (Cannot explicitly form a matrix containing all the genotype data) . ran on chromosome 22 1kgDataset with approximately 100 intervals and the program runs in about 3-4 minutes with 2 workers and 12 pre-emptibles with 8 cores each.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1973#issuecomment-320358482
https://github.com/hail-is/hail/pull/1973#issuecomment-320358482:26,Integrability,rout,routine,26,Currently the linear SKAT routine is implemented to be optimal for the case of (genetic variants) k < n (genetic samples). Implementation will process sets of variants associated to the same gene in such a way that there is no redundant computation in the algorithm. . cases handled:; hard call genetic data; dosage genetic data; k << n - (Cannot explicitly form a matrix containing all the genotype data) . ran on chromosome 22 1kgDataset with approximately 100 intervals and the program runs in about 3-4 minutes with 2 workers and 12 pre-emptibles with 8 cores each.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1973#issuecomment-320358482
https://github.com/hail-is/hail/pull/1973#issuecomment-320358482:227,Safety,redund,redundant,227,Currently the linear SKAT routine is implemented to be optimal for the case of (genetic variants) k < n (genetic samples). Implementation will process sets of variants associated to the same gene in such a way that there is no redundant computation in the algorithm. . cases handled:; hard call genetic data; dosage genetic data; k << n - (Cannot explicitly form a matrix containing all the genotype data) . ran on chromosome 22 1kgDataset with approximately 100 intervals and the program runs in about 3-4 minutes with 2 workers and 12 pre-emptibles with 8 cores each.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1973#issuecomment-320358482
https://github.com/hail-is/hail/pull/1973#issuecomment-320361030:97,Performance,optimiz,optimized,97,"How many cores were you using?. Also, am I correct that this runs even when k > n, it's just not optimized for that case?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1973#issuecomment-320361030
https://github.com/hail-is/hail/issues/1975#issuecomment-313702288:453,Energy Efficiency,reduce,reduces,453,"The #1895 Fast Multiply PR is not merged yet, but the multiplication algorithm used there should be the foundation for a tree-aggregating multiply. In particular, [`BetterBlockMatrix.BlockMatrixMultiplyRDD`](https://github.com/danking/hail/blob/b4dda2386e342afe0da1cb809ce756bddd029074/src/main/scala/org/apache/spark/mllib/linalg/distributed/BetterBlockMatrix.scala). My thinking is to produce a layer of a new rdd, `BlockMatrixTreeMultiplyRDD`, which reduces the number of partitions by an order of magnitude in the manner given above. The description above doesn't account for the situation in which the smaller dimension has more than one block. In that situation, we would not perform any condensation of partitions along the smaller dimension (we can't! if we did there would be too few blocks in the output matrix, `C`) .",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/1975#issuecomment-313702288
https://github.com/hail-is/hail/issues/1975#issuecomment-313702288:682,Performance,perform,perform,682,"The #1895 Fast Multiply PR is not merged yet, but the multiplication algorithm used there should be the foundation for a tree-aggregating multiply. In particular, [`BetterBlockMatrix.BlockMatrixMultiplyRDD`](https://github.com/danking/hail/blob/b4dda2386e342afe0da1cb809ce756bddd029074/src/main/scala/org/apache/spark/mllib/linalg/distributed/BetterBlockMatrix.scala). My thinking is to produce a layer of a new rdd, `BlockMatrixTreeMultiplyRDD`, which reduces the number of partitions by an order of magnitude in the manner given above. The description above doesn't account for the situation in which the smaller dimension has more than one block. In that situation, we would not perform any condensation of partitions along the smaller dimension (we can't! if we did there would be too few blocks in the output matrix, `C`) .",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/1975#issuecomment-313702288
https://github.com/hail-is/hail/issues/1983#issuecomment-329826002:198,Availability,failure,failures,198,"The correct fix is to change this line in `lookup` from `if (tt.xs.size == typ.xs.size)` to `if (tt.xs.size == typ.xs.size && typ.getClass == tt.getClass)`. However, this will cause many test suite failures and we would have to fix 100s of lines of expr language in both the docs and the test suites. In the meantime we could change the AST code for `Select` to `lookupMethodReturnType` on failure of `lookupFieldReturnType`. . The user will not be able to trigger this error once the expression language is implemented in Python.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/1983#issuecomment-329826002
https://github.com/hail-is/hail/issues/1983#issuecomment-329826002:390,Availability,failure,failure,390,"The correct fix is to change this line in `lookup` from `if (tt.xs.size == typ.xs.size)` to `if (tt.xs.size == typ.xs.size && typ.getClass == tt.getClass)`. However, this will cause many test suite failures and we would have to fix 100s of lines of expr language in both the docs and the test suites. In the meantime we could change the AST code for `Select` to `lookupMethodReturnType` on failure of `lookupFieldReturnType`. . The user will not be able to trigger this error once the expression language is implemented in Python.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/1983#issuecomment-329826002
https://github.com/hail-is/hail/issues/1983#issuecomment-329826002:470,Availability,error,error,470,"The correct fix is to change this line in `lookup` from `if (tt.xs.size == typ.xs.size)` to `if (tt.xs.size == typ.xs.size && typ.getClass == tt.getClass)`. However, this will cause many test suite failures and we would have to fix 100s of lines of expr language in both the docs and the test suites. In the meantime we could change the AST code for `Select` to `lookupMethodReturnType` on failure of `lookupFieldReturnType`. . The user will not be able to trigger this error once the expression language is implemented in Python.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/1983#issuecomment-329826002
https://github.com/hail-is/hail/issues/1983#issuecomment-329826002:187,Testability,test,test,187,"The correct fix is to change this line in `lookup` from `if (tt.xs.size == typ.xs.size)` to `if (tt.xs.size == typ.xs.size && typ.getClass == tt.getClass)`. However, this will cause many test suite failures and we would have to fix 100s of lines of expr language in both the docs and the test suites. In the meantime we could change the AST code for `Select` to `lookupMethodReturnType` on failure of `lookupFieldReturnType`. . The user will not be able to trigger this error once the expression language is implemented in Python.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/1983#issuecomment-329826002
https://github.com/hail-is/hail/issues/1983#issuecomment-329826002:288,Testability,test,test,288,"The correct fix is to change this line in `lookup` from `if (tt.xs.size == typ.xs.size)` to `if (tt.xs.size == typ.xs.size && typ.getClass == tt.getClass)`. However, this will cause many test suite failures and we would have to fix 100s of lines of expr language in both the docs and the test suites. In the meantime we could change the AST code for `Select` to `lookupMethodReturnType` on failure of `lookupFieldReturnType`. . The user will not be able to trigger this error once the expression language is implemented in Python.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/1983#issuecomment-329826002
https://github.com/hail-is/hail/pull/1984#issuecomment-314618826:26,Integrability,interface,interface,26,Will experiment with that interface. It's unfortunate that I can't change the order of arguments in the method now without breaking things. The order no longer makes sense as we add a bunch of things at the end.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1984#issuecomment-314618826
https://github.com/hail-is/hail/pull/1984#issuecomment-314625073:253,Testability,test,tested,253,"@jbloom22 Addressed first round of comments (though I haven't yet played with distributing the multiply in the solving for U from V case). I added a ""filterVariantsExpr"" to allow for the LOCO situation we're interested in allowing for, though I haven't tested any per-variant betas / pvals in cases where LDMatrix was used yet.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1984#issuecomment-314625073
https://github.com/hail-is/hail/pull/1984#issuecomment-315443392:64,Integrability,interface,interface,64,"@jbloom22 I cannot have two parameters without breaking current interface. In order to have two parameters, I'd have to give kinshipMatrix a default value of None, but I can't do that since it is not permissible to have default valued arguments listed before arguments that don't have defaults. Going to have to just have the name be ""kinshipMatrix"" but it can be either LD or Kinship until we change name in next version.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1984#issuecomment-315443392
https://github.com/hail-is/hail/pull/1984#issuecomment-316386605:373,Availability,avail,available,373,"Problem: Currently in the LD Matrix case I compute V, multiply it through the genotype matrix to get U, then subset columns of U. U is probably bigger than V though, so this could limit the number of eigenvectors that can be used. Probably should just subset columns of V to the desired number of eigenvectors for performance and to increase maximum number of eigenvectors available.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1984#issuecomment-316386605
https://github.com/hail-is/hail/pull/1984#issuecomment-316386605:314,Performance,perform,performance,314,"Problem: Currently in the LD Matrix case I compute V, multiply it through the genotype matrix to get U, then subset columns of U. U is probably bigger than V though, so this could limit the number of eigenvectors that can be used. Probably should just subset columns of V to the desired number of eigenvectors for performance and to increase maximum number of eigenvectors available.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1984#issuecomment-316386605
https://github.com/hail-is/hail/pull/1984#issuecomment-319971210:30,Integrability,interface,interface,30,"The creeping expansion of the interface is on me as we tried to not break 0.1. I'd appreciate discussing in person what makes the most sense for 0.1. Here are the pieces I think we should separate for devel, though we could consider providing a meta-interface as well that combines some of them for usability. I'm writing (U, S, L) for a local matrix of eigenvectors U, an array of eigenvalues S, and an array of labels L on the rows of U (as with labels for SymmetricMatrix). 1) VDS to a (labeled) symmetric matrix (we have these: GRM, RRM, LD matrix, and Dan is working on a way to read and write them). 2) Symmetric matrix to (U, S, L), which we'll want to write and read. This modularizes the single-core eigen-decomposition bottleneck. 3) Variant-labeled (V, S, L) and VDS with those variants to transport (V, S, L) to sample-labeled (U, S, L). Currently this also requires knowing the number of samples used to make the LDMatrix since that number is used in its normalization. I agree it feels unnatural to need to remember this; to avoid it we'd need an unnormalized version. 4) Sample-labeled (U, S, L) and VDS to global fit of LMM including delta. This is currently a local computation that's been pretty fast in practice but as sample sizes increase we will want to distribute evaluating many values of delta in parallel. Note this step only uses the sample annotations on the VDS, so logically it could also be on KeyTable (which would be the sample KeyTable of the VDS). 5) Sample-labeled (U, S, L), VDS, and delta to per-variant-fit of LMM. This VDS can now contain exactly the variants one wants to fit. (5) should eventually be decomposed as well. The first command should project from Matrix to Matrix (projecting both numeric cells and a list of numeric sample annotations) and some additional small data. Then (6) will do per variant tests starting from after this projection (that is, after what is the BIG computation when you have tens of millions of variants). That way users can",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1984#issuecomment-319971210
https://github.com/hail-is/hail/pull/1984#issuecomment-319971210:250,Integrability,interface,interface,250,"The creeping expansion of the interface is on me as we tried to not break 0.1. I'd appreciate discussing in person what makes the most sense for 0.1. Here are the pieces I think we should separate for devel, though we could consider providing a meta-interface as well that combines some of them for usability. I'm writing (U, S, L) for a local matrix of eigenvectors U, an array of eigenvalues S, and an array of labels L on the rows of U (as with labels for SymmetricMatrix). 1) VDS to a (labeled) symmetric matrix (we have these: GRM, RRM, LD matrix, and Dan is working on a way to read and write them). 2) Symmetric matrix to (U, S, L), which we'll want to write and read. This modularizes the single-core eigen-decomposition bottleneck. 3) Variant-labeled (V, S, L) and VDS with those variants to transport (V, S, L) to sample-labeled (U, S, L). Currently this also requires knowing the number of samples used to make the LDMatrix since that number is used in its normalization. I agree it feels unnatural to need to remember this; to avoid it we'd need an unnormalized version. 4) Sample-labeled (U, S, L) and VDS to global fit of LMM including delta. This is currently a local computation that's been pretty fast in practice but as sample sizes increase we will want to distribute evaluating many values of delta in parallel. Note this step only uses the sample annotations on the VDS, so logically it could also be on KeyTable (which would be the sample KeyTable of the VDS). 5) Sample-labeled (U, S, L), VDS, and delta to per-variant-fit of LMM. This VDS can now contain exactly the variants one wants to fit. (5) should eventually be decomposed as well. The first command should project from Matrix to Matrix (projecting both numeric cells and a list of numeric sample annotations) and some additional small data. Then (6) will do per variant tests starting from after this projection (that is, after what is the BIG computation when you have tens of millions of variants). That way users can",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1984#issuecomment-319971210
https://github.com/hail-is/hail/pull/1984#issuecomment-319971210:729,Performance,bottleneck,bottleneck,729,"The creeping expansion of the interface is on me as we tried to not break 0.1. I'd appreciate discussing in person what makes the most sense for 0.1. Here are the pieces I think we should separate for devel, though we could consider providing a meta-interface as well that combines some of them for usability. I'm writing (U, S, L) for a local matrix of eigenvectors U, an array of eigenvalues S, and an array of labels L on the rows of U (as with labels for SymmetricMatrix). 1) VDS to a (labeled) symmetric matrix (we have these: GRM, RRM, LD matrix, and Dan is working on a way to read and write them). 2) Symmetric matrix to (U, S, L), which we'll want to write and read. This modularizes the single-core eigen-decomposition bottleneck. 3) Variant-labeled (V, S, L) and VDS with those variants to transport (V, S, L) to sample-labeled (U, S, L). Currently this also requires knowing the number of samples used to make the LDMatrix since that number is used in its normalization. I agree it feels unnatural to need to remember this; to avoid it we'd need an unnormalized version. 4) Sample-labeled (U, S, L) and VDS to global fit of LMM including delta. This is currently a local computation that's been pretty fast in practice but as sample sizes increase we will want to distribute evaluating many values of delta in parallel. Note this step only uses the sample annotations on the VDS, so logically it could also be on KeyTable (which would be the sample KeyTable of the VDS). 5) Sample-labeled (U, S, L), VDS, and delta to per-variant-fit of LMM. This VDS can now contain exactly the variants one wants to fit. (5) should eventually be decomposed as well. The first command should project from Matrix to Matrix (projecting both numeric cells and a list of numeric sample annotations) and some additional small data. Then (6) will do per variant tests starting from after this projection (that is, after what is the BIG computation when you have tens of millions of variants). That way users can",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1984#issuecomment-319971210
https://github.com/hail-is/hail/pull/1984#issuecomment-319971210:1039,Safety,avoid,avoid,1039,"terface is on me as we tried to not break 0.1. I'd appreciate discussing in person what makes the most sense for 0.1. Here are the pieces I think we should separate for devel, though we could consider providing a meta-interface as well that combines some of them for usability. I'm writing (U, S, L) for a local matrix of eigenvectors U, an array of eigenvalues S, and an array of labels L on the rows of U (as with labels for SymmetricMatrix). 1) VDS to a (labeled) symmetric matrix (we have these: GRM, RRM, LD matrix, and Dan is working on a way to read and write them). 2) Symmetric matrix to (U, S, L), which we'll want to write and read. This modularizes the single-core eigen-decomposition bottleneck. 3) Variant-labeled (V, S, L) and VDS with those variants to transport (V, S, L) to sample-labeled (U, S, L). Currently this also requires knowing the number of samples used to make the LDMatrix since that number is used in its normalization. I agree it feels unnatural to need to remember this; to avoid it we'd need an unnormalized version. 4) Sample-labeled (U, S, L) and VDS to global fit of LMM including delta. This is currently a local computation that's been pretty fast in practice but as sample sizes increase we will want to distribute evaluating many values of delta in parallel. Note this step only uses the sample annotations on the VDS, so logically it could also be on KeyTable (which would be the sample KeyTable of the VDS). 5) Sample-labeled (U, S, L), VDS, and delta to per-variant-fit of LMM. This VDS can now contain exactly the variants one wants to fit. (5) should eventually be decomposed as well. The first command should project from Matrix to Matrix (projecting both numeric cells and a list of numeric sample annotations) and some additional small data. Then (6) will do per variant tests starting from after this projection (that is, after what is the BIG computation when you have tens of millions of variants). That way users can quickly iterate on exploration",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1984#issuecomment-319971210
https://github.com/hail-is/hail/pull/1984#issuecomment-319971210:1395,Testability,log,logically,1395,"ng in person what makes the most sense for 0.1. Here are the pieces I think we should separate for devel, though we could consider providing a meta-interface as well that combines some of them for usability. I'm writing (U, S, L) for a local matrix of eigenvectors U, an array of eigenvalues S, and an array of labels L on the rows of U (as with labels for SymmetricMatrix). 1) VDS to a (labeled) symmetric matrix (we have these: GRM, RRM, LD matrix, and Dan is working on a way to read and write them). 2) Symmetric matrix to (U, S, L), which we'll want to write and read. This modularizes the single-core eigen-decomposition bottleneck. 3) Variant-labeled (V, S, L) and VDS with those variants to transport (V, S, L) to sample-labeled (U, S, L). Currently this also requires knowing the number of samples used to make the LDMatrix since that number is used in its normalization. I agree it feels unnatural to need to remember this; to avoid it we'd need an unnormalized version. 4) Sample-labeled (U, S, L) and VDS to global fit of LMM including delta. This is currently a local computation that's been pretty fast in practice but as sample sizes increase we will want to distribute evaluating many values of delta in parallel. Note this step only uses the sample annotations on the VDS, so logically it could also be on KeyTable (which would be the sample KeyTable of the VDS). 5) Sample-labeled (U, S, L), VDS, and delta to per-variant-fit of LMM. This VDS can now contain exactly the variants one wants to fit. (5) should eventually be decomposed as well. The first command should project from Matrix to Matrix (projecting both numeric cells and a list of numeric sample annotations) and some additional small data. Then (6) will do per variant tests starting from after this projection (that is, after what is the BIG computation when you have tens of millions of variants). That way users can quickly iterate on exploration of covariates, fine mapping, and so on, for any fixed set of samples.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1984#issuecomment-319971210
https://github.com/hail-is/hail/pull/1984#issuecomment-319971210:1852,Testability,test,tests,1852,"ng in person what makes the most sense for 0.1. Here are the pieces I think we should separate for devel, though we could consider providing a meta-interface as well that combines some of them for usability. I'm writing (U, S, L) for a local matrix of eigenvectors U, an array of eigenvalues S, and an array of labels L on the rows of U (as with labels for SymmetricMatrix). 1) VDS to a (labeled) symmetric matrix (we have these: GRM, RRM, LD matrix, and Dan is working on a way to read and write them). 2) Symmetric matrix to (U, S, L), which we'll want to write and read. This modularizes the single-core eigen-decomposition bottleneck. 3) Variant-labeled (V, S, L) and VDS with those variants to transport (V, S, L) to sample-labeled (U, S, L). Currently this also requires knowing the number of samples used to make the LDMatrix since that number is used in its normalization. I agree it feels unnatural to need to remember this; to avoid it we'd need an unnormalized version. 4) Sample-labeled (U, S, L) and VDS to global fit of LMM including delta. This is currently a local computation that's been pretty fast in practice but as sample sizes increase we will want to distribute evaluating many values of delta in parallel. Note this step only uses the sample annotations on the VDS, so logically it could also be on KeyTable (which would be the sample KeyTable of the VDS). 5) Sample-labeled (U, S, L), VDS, and delta to per-variant-fit of LMM. This VDS can now contain exactly the variants one wants to fit. (5) should eventually be decomposed as well. The first command should project from Matrix to Matrix (projecting both numeric cells and a list of numeric sample annotations) and some additional small data. Then (6) will do per variant tests starting from after this projection (that is, after what is the BIG computation when you have tens of millions of variants). That way users can quickly iterate on exploration of covariates, fine mapping, and so on, for any fixed set of samples.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1984#issuecomment-319971210
https://github.com/hail-is/hail/pull/1984#issuecomment-319971210:299,Usability,usab,usability,299,"The creeping expansion of the interface is on me as we tried to not break 0.1. I'd appreciate discussing in person what makes the most sense for 0.1. Here are the pieces I think we should separate for devel, though we could consider providing a meta-interface as well that combines some of them for usability. I'm writing (U, S, L) for a local matrix of eigenvectors U, an array of eigenvalues S, and an array of labels L on the rows of U (as with labels for SymmetricMatrix). 1) VDS to a (labeled) symmetric matrix (we have these: GRM, RRM, LD matrix, and Dan is working on a way to read and write them). 2) Symmetric matrix to (U, S, L), which we'll want to write and read. This modularizes the single-core eigen-decomposition bottleneck. 3) Variant-labeled (V, S, L) and VDS with those variants to transport (V, S, L) to sample-labeled (U, S, L). Currently this also requires knowing the number of samples used to make the LDMatrix since that number is used in its normalization. I agree it feels unnatural to need to remember this; to avoid it we'd need an unnormalized version. 4) Sample-labeled (U, S, L) and VDS to global fit of LMM including delta. This is currently a local computation that's been pretty fast in practice but as sample sizes increase we will want to distribute evaluating many values of delta in parallel. Note this step only uses the sample annotations on the VDS, so logically it could also be on KeyTable (which would be the sample KeyTable of the VDS). 5) Sample-labeled (U, S, L), VDS, and delta to per-variant-fit of LMM. This VDS can now contain exactly the variants one wants to fit. (5) should eventually be decomposed as well. The first command should project from Matrix to Matrix (projecting both numeric cells and a list of numeric sample annotations) and some additional small data. Then (6) will do per variant tests starting from after this projection (that is, after what is the BIG computation when you have tens of millions of variants). That way users can",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1984#issuecomment-319971210
https://github.com/hail-is/hail/pull/1984#issuecomment-320541669:43,Testability,test,testing,43,Note to reviewer: Just changed per variant testing to be handled in blocks with matrix matrix multiplies. Hopefully a bit faster.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1984#issuecomment-320541669
https://github.com/hail-is/hail/pull/1984#issuecomment-320542160:29,Modifiability,refactor,refactoring,29,I'm nearly through a modular refactoring as discussed that I'll revise on this and make PR back to the branch tomorrow.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1984#issuecomment-320542160
https://github.com/hail-is/hail/pull/1984#issuecomment-321887358:52,Integrability,interface,interface,52,@jbloom22 @johnc1231 I can't approve as long as the interface is broken.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1984#issuecomment-321887358
https://github.com/hail-is/hail/pull/1984#issuecomment-323375461:37,Testability,test,tested,37,fitUsingDelta's behavior needs to be tested as it relates to global annotations. No explicit tests for this that I saw,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1984#issuecomment-323375461
https://github.com/hail-is/hail/pull/1984#issuecomment-323375461:93,Testability,test,tests,93,fitUsingDelta's behavior needs to be tested as it relates to global annotations. No explicit tests for this that I saw,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1984#issuecomment-323375461
https://github.com/hail-is/hail/pull/1987#issuecomment-317845459:86,Deployability,deploy,deployment,86,"Ben, can you reopen the PR from a branch on your fork of Hail? We're deleting all non-deployment branches from the main repository.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1987#issuecomment-317845459
https://github.com/hail-is/hail/pull/1991#issuecomment-315409653:56,Testability,test,test,56,"There is at least one somewhat unpleasant change in the test in dataset.py: ; annotated.globalSignature().typeCheck(annotated.globalAnnotation()); fails when the java type is Long, but long no longer excists in python 3 and maps to int. I'm not sure what is going wrong there, I'll have a look on monday.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1991#issuecomment-315409653
https://github.com/hail-is/hail/pull/1991#issuecomment-316414396:5,Deployability,update,updated,5,I've updated the code to address the easy comments. The annotated.globalSignature and hadoop_writer ones I don't know how and whether to fix.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/1991#issuecomment-316414396
https://github.com/hail-is/hail/issues/1998#issuecomment-316252831:80,Testability,log,log-space,80,"I think this is equivalent to the 0-1 knapsack problem. Think about doing it in log-space. Let s be the size. Let (x_i) be the scaled dirichlet that sums to log(s). Let l_i = log floor(e^x_i) and u_i = log (floor(e^x_i) + 1). Let f_i = l_i - x_i be the ""fractional"" part and F = sum f_i. You want to find a subset of d_i = u_i - l_i whose sum is maximized but <= F. A 1-pass greedy algorithm seems good enough.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/1998#issuecomment-316252831
https://github.com/hail-is/hail/issues/1998#issuecomment-316252831:157,Testability,log,log,157,"I think this is equivalent to the 0-1 knapsack problem. Think about doing it in log-space. Let s be the size. Let (x_i) be the scaled dirichlet that sums to log(s). Let l_i = log floor(e^x_i) and u_i = log (floor(e^x_i) + 1). Let f_i = l_i - x_i be the ""fractional"" part and F = sum f_i. You want to find a subset of d_i = u_i - l_i whose sum is maximized but <= F. A 1-pass greedy algorithm seems good enough.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/1998#issuecomment-316252831
https://github.com/hail-is/hail/issues/1998#issuecomment-316252831:175,Testability,log,log,175,"I think this is equivalent to the 0-1 knapsack problem. Think about doing it in log-space. Let s be the size. Let (x_i) be the scaled dirichlet that sums to log(s). Let l_i = log floor(e^x_i) and u_i = log (floor(e^x_i) + 1). Let f_i = l_i - x_i be the ""fractional"" part and F = sum f_i. You want to find a subset of d_i = u_i - l_i whose sum is maximized but <= F. A 1-pass greedy algorithm seems good enough.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/1998#issuecomment-316252831
https://github.com/hail-is/hail/issues/1998#issuecomment-316252831:202,Testability,log,log,202,"I think this is equivalent to the 0-1 knapsack problem. Think about doing it in log-space. Let s be the size. Let (x_i) be the scaled dirichlet that sums to log(s). Let l_i = log floor(e^x_i) and u_i = log (floor(e^x_i) + 1). Let f_i = l_i - x_i be the ""fractional"" part and F = sum f_i. You want to find a subset of d_i = u_i - l_i whose sum is maximized but <= F. A 1-pass greedy algorithm seems good enough.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/1998#issuecomment-316252831
https://github.com/hail-is/hail/issues/2003#issuecomment-330569535:8,Deployability,install,install,8,The pip install for pyspark installs the 2.2 version of Spark. Will that pyspark version work with Hail? The Getting Started Page only documents 2.0 and 2.1.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2003#issuecomment-330569535
https://github.com/hail-is/hail/issues/2003#issuecomment-330569535:28,Deployability,install,installs,28,The pip install for pyspark installs the 2.2 version of Spark. Will that pyspark version work with Hail? The Getting Started Page only documents 2.0 and 2.1.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2003#issuecomment-330569535
https://github.com/hail-is/hail/pull/2004#issuecomment-318079424:21,Testability,Assert,AssertionError,21,Caused by: java.lang.AssertionError: assertion failed; 	at scala.Predef$.assert(Predef.scala:156); 	at is.hail.variant.GenotypeBuilder.write(Genotype.scala:1269); 	at is.hail.variant.GenotypeStreamBuilder.$plus$eq(GenotypeStream.scala:156); 	at is.hail.variant.GenotypeStreamBuilder.$plus$eq(GenotypeStream.scala:148); 	at scala.collection.generic.Growable$$anonfun$$plus$plus$eq$1.apply(Growable.scala:59); 	at scala.collection.generic.Growable$$anonfun$$plus$plus$eq$1.apply(Growable.scala:59); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at is.hail.utils.richUtils.RichIterable$$anon$3$$anon$9.foreach(RichIterable.scala:38),MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2004#issuecomment-318079424
https://github.com/hail-is/hail/pull/2004#issuecomment-318079424:37,Testability,assert,assertion,37,Caused by: java.lang.AssertionError: assertion failed; 	at scala.Predef$.assert(Predef.scala:156); 	at is.hail.variant.GenotypeBuilder.write(Genotype.scala:1269); 	at is.hail.variant.GenotypeStreamBuilder.$plus$eq(GenotypeStream.scala:156); 	at is.hail.variant.GenotypeStreamBuilder.$plus$eq(GenotypeStream.scala:148); 	at scala.collection.generic.Growable$$anonfun$$plus$plus$eq$1.apply(Growable.scala:59); 	at scala.collection.generic.Growable$$anonfun$$plus$plus$eq$1.apply(Growable.scala:59); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at is.hail.utils.richUtils.RichIterable$$anon$3$$anon$9.foreach(RichIterable.scala:38),MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2004#issuecomment-318079424
https://github.com/hail-is/hail/pull/2004#issuecomment-318079424:73,Testability,assert,assert,73,Caused by: java.lang.AssertionError: assertion failed; 	at scala.Predef$.assert(Predef.scala:156); 	at is.hail.variant.GenotypeBuilder.write(Genotype.scala:1269); 	at is.hail.variant.GenotypeStreamBuilder.$plus$eq(GenotypeStream.scala:156); 	at is.hail.variant.GenotypeStreamBuilder.$plus$eq(GenotypeStream.scala:148); 	at scala.collection.generic.Growable$$anonfun$$plus$plus$eq$1.apply(Growable.scala:59); 	at scala.collection.generic.Growable$$anonfun$$plus$plus$eq$1.apply(Growable.scala:59); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at is.hail.utils.richUtils.RichIterable$$anon$3$$anon$9.foreach(RichIterable.scala:38),MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2004#issuecomment-318079424
https://github.com/hail-is/hail/issues/2006#issuecomment-317562287:37,Modifiability,inherit,inherits,37,I still don't see what's wrong. TSet inherits from TIterable which does override it.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2006#issuecomment-317562287
https://github.com/hail-is/hail/pull/2007#issuecomment-318852681:31,Modifiability,refactor,refactor,31,"Closing, will incorporate into refactor of linreg on dev.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2007#issuecomment-318852681
https://github.com/hail-is/hail/pull/2024#issuecomment-318098685:91,Integrability,interface,interface,91,"@cseed ripping out the references to Report (DuplicateReport) objects screws up the Python interface because it supports the method deduplicate() in VariantSampleMatrix, which initializes a Report object",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2024#issuecomment-318098685
https://github.com/hail-is/hail/pull/2036#issuecomment-318518817:62,Deployability,upgrade,upgrade,62,"Buy it, use it, break it, fix it; Trash it, change it, mail - upgrade it; Charge it, point it, zoom it, press it; Snap it, work it, quick - erase it; Write it, cut it, paste it, save it; Load it, check it, quick - rewrite it; Plug it, play it, burn it, rip it; Drag and drop it, zip - unzip it; Lock it, fill it, call it, find it; View it, code it, jam - unlock it; Surf it, scroll it, pause it, click it; Cross it, crack it, switch - update it; Name it, read it, tune it, print it; Scan it, send it, fax - rename it; Touch it, bring it, pay it, watch it; Turn it, leave it, start - format it",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2036#issuecomment-318518817
https://github.com/hail-is/hail/pull/2036#issuecomment-318518817:435,Deployability,update,update,435,"Buy it, use it, break it, fix it; Trash it, change it, mail - upgrade it; Charge it, point it, zoom it, press it; Snap it, work it, quick - erase it; Write it, cut it, paste it, save it; Load it, check it, quick - rewrite it; Plug it, play it, burn it, rip it; Drag and drop it, zip - unzip it; Lock it, fill it, call it, find it; View it, code it, jam - unlock it; Surf it, scroll it, pause it, click it; Cross it, crack it, switch - update it; Name it, read it, tune it, print it; Scan it, send it, fax - rename it; Touch it, bring it, pay it, watch it; Turn it, leave it, start - format it",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2036#issuecomment-318518817
https://github.com/hail-is/hail/pull/2036#issuecomment-318518817:74,Energy Efficiency,Charge,Charge,74,"Buy it, use it, break it, fix it; Trash it, change it, mail - upgrade it; Charge it, point it, zoom it, press it; Snap it, work it, quick - erase it; Write it, cut it, paste it, save it; Load it, check it, quick - rewrite it; Plug it, play it, burn it, rip it; Drag and drop it, zip - unzip it; Lock it, fill it, call it, find it; View it, code it, jam - unlock it; Surf it, scroll it, pause it, click it; Cross it, crack it, switch - update it; Name it, read it, tune it, print it; Scan it, send it, fax - rename it; Touch it, bring it, pay it, watch it; Turn it, leave it, start - format it",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2036#issuecomment-318518817
https://github.com/hail-is/hail/pull/2036#issuecomment-318518817:214,Modifiability,rewrite,rewrite,214,"Buy it, use it, break it, fix it; Trash it, change it, mail - upgrade it; Charge it, point it, zoom it, press it; Snap it, work it, quick - erase it; Write it, cut it, paste it, save it; Load it, check it, quick - rewrite it; Plug it, play it, burn it, rip it; Drag and drop it, zip - unzip it; Lock it, fill it, call it, find it; View it, code it, jam - unlock it; Surf it, scroll it, pause it, click it; Cross it, crack it, switch - update it; Name it, read it, tune it, print it; Scan it, send it, fax - rename it; Touch it, bring it, pay it, watch it; Turn it, leave it, start - format it",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2036#issuecomment-318518817
https://github.com/hail-is/hail/pull/2036#issuecomment-318518817:187,Performance,Load,Load,187,"Buy it, use it, break it, fix it; Trash it, change it, mail - upgrade it; Charge it, point it, zoom it, press it; Snap it, work it, quick - erase it; Write it, cut it, paste it, save it; Load it, check it, quick - rewrite it; Plug it, play it, burn it, rip it; Drag and drop it, zip - unzip it; Lock it, fill it, call it, find it; View it, code it, jam - unlock it; Surf it, scroll it, pause it, click it; Cross it, crack it, switch - update it; Name it, read it, tune it, print it; Scan it, send it, fax - rename it; Touch it, bring it, pay it, watch it; Turn it, leave it, start - format it",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2036#issuecomment-318518817
https://github.com/hail-is/hail/pull/2036#issuecomment-318518817:464,Performance,tune,tune,464,"Buy it, use it, break it, fix it; Trash it, change it, mail - upgrade it; Charge it, point it, zoom it, press it; Snap it, work it, quick - erase it; Write it, cut it, paste it, save it; Load it, check it, quick - rewrite it; Plug it, play it, burn it, rip it; Drag and drop it, zip - unzip it; Lock it, fill it, call it, find it; View it, code it, jam - unlock it; Surf it, scroll it, pause it, click it; Cross it, crack it, switch - update it; Name it, read it, tune it, print it; Scan it, send it, fax - rename it; Touch it, bring it, pay it, watch it; Turn it, leave it, start - format it",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2036#issuecomment-318518817
https://github.com/hail-is/hail/pull/2036#issuecomment-318518817:386,Usability,pause,pause,386,"Buy it, use it, break it, fix it; Trash it, change it, mail - upgrade it; Charge it, point it, zoom it, press it; Snap it, work it, quick - erase it; Write it, cut it, paste it, save it; Load it, check it, quick - rewrite it; Plug it, play it, burn it, rip it; Drag and drop it, zip - unzip it; Lock it, fill it, call it, find it; View it, code it, jam - unlock it; Surf it, scroll it, pause it, click it; Cross it, crack it, switch - update it; Name it, read it, tune it, print it; Scan it, send it, fax - rename it; Touch it, bring it, pay it, watch it; Turn it, leave it, start - format it",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2036#issuecomment-318518817
https://github.com/hail-is/hail/pull/2037#issuecomment-318852593:32,Modifiability,refactor,refactoring,32,"Closing, will make new PR after refactoring against dev.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2037#issuecomment-318852593
https://github.com/hail-is/hail/pull/2039#issuecomment-318789172:126,Safety,sanity check,sanity check,126,"@tpoterba Fixed the tests and tutorials. Ready for a look. Just a rebase of 0.2 that you already reviewed, should just need a sanity check.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2039#issuecomment-318789172
https://github.com/hail-is/hail/pull/2039#issuecomment-318789172:20,Testability,test,tests,20,"@tpoterba Fixed the tests and tutorials. Ready for a look. Just a rebase of 0.2 that you already reviewed, should just need a sanity check.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2039#issuecomment-318789172
https://github.com/hail-is/hail/pull/2040#issuecomment-319675886:74,Testability,test,test,74,"@johnc1231 I've addressed these changes in the branch I'm working with to test, so I can merge them if you agree with Dan's comments. In particular, do you have evidence the caching matters? (I've removed it)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2040#issuecomment-319675886
https://github.com/hail-is/hail/pull/2040#issuecomment-319677861:109,Testability,test,test,109,"I don't have evidence that it matters, feel like it would though. If it's out for now that's fine, I'll do a test on Friday if needed.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2040#issuecomment-319677861
https://github.com/hail-is/hail/pull/2042#issuecomment-318833001:16,Availability,failure,failure,16,Looks like test failure is due to needing to wrap phenotype in array in this line; `top_5_pvals = (vds.linreg('sa.metadata.CaffeineConsumption')`; of; https://github.com/hail-is/hail/blob/master/python/hail/docs/tutorials/expression-language-part-2.ipynb,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2042#issuecomment-318833001
https://github.com/hail-is/hail/pull/2042#issuecomment-318833001:45,Integrability,wrap,wrap,45,Looks like test failure is due to needing to wrap phenotype in array in this line; `top_5_pvals = (vds.linreg('sa.metadata.CaffeineConsumption')`; of; https://github.com/hail-is/hail/blob/master/python/hail/docs/tutorials/expression-language-part-2.ipynb,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2042#issuecomment-318833001
https://github.com/hail-is/hail/pull/2042#issuecomment-318833001:11,Testability,test,test,11,Looks like test failure is due to needing to wrap phenotype in array in this line; `top_5_pvals = (vds.linreg('sa.metadata.CaffeineConsumption')`; of; https://github.com/hail-is/hail/blob/master/python/hail/docs/tutorials/expression-language-part-2.ipynb,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2042#issuecomment-318833001
https://github.com/hail-is/hail/pull/2049#issuecomment-319098074:268,Availability,error,error,268,"@bw2 Hey looks like there's some weird version issues. Can you set up the gradle to use a Spark 2.1 compatible version of elastic search if spark version is set to a 2.1.x version and use a Spark 2.0 compatible version of elastic search?. I don't fully understand the error, but it definitely looks like there's a spark version mismatch.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2049#issuecomment-319098074
https://github.com/hail-is/hail/pull/2049#issuecomment-320089871:136,Testability,test,tests,136,"@danking I'm not sure if I understood your point, but I noticed some potential mismatches between versions that I've now corrected. The tests don't seem to be running to completion though. They've been running for ~ 24 hours. Is that expected?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2049#issuecomment-320089871
https://github.com/hail-is/hail/pull/2049#issuecomment-320090326:21,Testability,test,tests,21,"The Hail CI runs the tests against a merge of this branch with master, so they can't start until the merge conflicts are resolved. The GitHub UI uses the same icon for running and not started when a check is required. I think it does this because checks are not required to notify GitHub that they have started.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2049#issuecomment-320090326
https://github.com/hail-is/hail/pull/2049#issuecomment-320274234:604,Availability,avail,available,604,"@danking IIUC the TeamCity build is now working with spark-2.1.0 but not spark-2.0.2; (even though running `./gradlew shadowJar archiveZip` on my laptop with spark-2.0.2 works fine.). From looking at the Maven repo; https://mvnrepository.com/artifact/org.elasticsearch/elasticsearch-spark-20_2.11; and the elasticsearch-spark connector docs; https://www.elastic.co/guide/en/elasticsearch/hadoop/master/spark.html; there's no indication that some versions only support v2.1, though it does say; ```; elasticsearch-hadoop allows Elasticsearch to be used in Spark in two ways: through the dedicated support available since 2.1 or through the Map/Reduce bridge since 2.0. Spark 2.0 is supported in elasticsearch-hadoop since version 5.0; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2049#issuecomment-320274234
https://github.com/hail-is/hail/pull/2049#issuecomment-320274234:643,Energy Efficiency,Reduce,Reduce,643,"@danking IIUC the TeamCity build is now working with spark-2.1.0 but not spark-2.0.2; (even though running `./gradlew shadowJar archiveZip` on my laptop with spark-2.0.2 works fine.). From looking at the Maven repo; https://mvnrepository.com/artifact/org.elasticsearch/elasticsearch-spark-20_2.11; and the elasticsearch-spark connector docs; https://www.elastic.co/guide/en/elasticsearch/hadoop/master/spark.html; there's no indication that some versions only support v2.1, though it does say; ```; elasticsearch-hadoop allows Elasticsearch to be used in Spark in two ways: through the dedicated support available since 2.1 or through the Map/Reduce bridge since 2.0. Spark 2.0 is supported in elasticsearch-hadoop since version 5.0; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2049#issuecomment-320274234
https://github.com/hail-is/hail/pull/2049#issuecomment-320274234:650,Integrability,bridg,bridge,650,"@danking IIUC the TeamCity build is now working with spark-2.1.0 but not spark-2.0.2; (even though running `./gradlew shadowJar archiveZip` on my laptop with spark-2.0.2 works fine.). From looking at the Maven repo; https://mvnrepository.com/artifact/org.elasticsearch/elasticsearch-spark-20_2.11; and the elasticsearch-spark connector docs; https://www.elastic.co/guide/en/elasticsearch/hadoop/master/spark.html; there's no indication that some versions only support v2.1, though it does say; ```; elasticsearch-hadoop allows Elasticsearch to be used in Spark in two ways: through the dedicated support available since 2.1 or through the Map/Reduce bridge since 2.0. Spark 2.0 is supported in elasticsearch-hadoop since version 5.0; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2049#issuecomment-320274234
https://github.com/hail-is/hail/pull/2049#issuecomment-320274234:365,Usability,guid,guide,365,"@danking IIUC the TeamCity build is now working with spark-2.1.0 but not spark-2.0.2; (even though running `./gradlew shadowJar archiveZip` on my laptop with spark-2.0.2 works fine.). From looking at the Maven repo; https://mvnrepository.com/artifact/org.elasticsearch/elasticsearch-spark-20_2.11; and the elasticsearch-spark connector docs; https://www.elastic.co/guide/en/elasticsearch/hadoop/master/spark.html; there's no indication that some versions only support v2.1, though it does say; ```; elasticsearch-hadoop allows Elasticsearch to be used in Spark in two ways: through the dedicated support available since 2.1 or through the Map/Reduce bridge since 2.0. Spark 2.0 is supported in elasticsearch-hadoop since version 5.0; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2049#issuecomment-320274234
https://github.com/hail-is/hail/pull/2049#issuecomment-320333635:165,Availability,down,download,165,"It's a bit confusing, but on the CI page you can navigate to the Artifacts tab from which you can open the [build report's index.html](https://ci.hail.is/repository/download/HailSourceCode_HailCi/33165:id/build/reports/tests/index.html). The error looks to me like a Hail problem, not a you problem. I'll investigate further.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2049#issuecomment-320333635
https://github.com/hail-is/hail/pull/2049#issuecomment-320333635:242,Availability,error,error,242,"It's a bit confusing, but on the CI page you can navigate to the Artifacts tab from which you can open the [build report's index.html](https://ci.hail.is/repository/download/HailSourceCode_HailCi/33165:id/build/reports/tests/index.html). The error looks to me like a Hail problem, not a you problem. I'll investigate further.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2049#issuecomment-320333635
https://github.com/hail-is/hail/pull/2049#issuecomment-320333635:219,Testability,test,tests,219,"It's a bit confusing, but on the CI page you can navigate to the Artifacts tab from which you can open the [build report's index.html](https://ci.hail.is/repository/download/HailSourceCode_HailCi/33165:id/build/reports/tests/index.html). The error looks to me like a Hail problem, not a you problem. I'll investigate further.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2049#issuecomment-320333635
https://github.com/hail-is/hail/pull/2049#issuecomment-320335957:266,Integrability,depend,dependency,266,"@bw2 that package name is a lie, sadly. The [maven repository page](https://mvnrepository.com/artifact/org.elasticsearch/elasticsearch-spark-20_2.11/5.5.1) for `org.elasticsearch:elasticsearch-spark-20_2.11:5.5.1` lists `org.apache.spark:spark-core_2.11:2.1.0` as a dependency, which is decidedly not 2.0. We'll have to use elasticsearch-spark 5.1.2. It's a bit annoying. You'll have to extend the [spark version-specific logic](https://github.com/hail-is/hail/pull/2049/files#diff-c197962302397baf3a4cc36463dce5eaR44) in `build.gradle`. You'll want to bind a new name, something like `elasticsearchSparkVersion`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2049#issuecomment-320335957
https://github.com/hail-is/hail/pull/2049#issuecomment-320335957:387,Modifiability,extend,extend,387,"@bw2 that package name is a lie, sadly. The [maven repository page](https://mvnrepository.com/artifact/org.elasticsearch/elasticsearch-spark-20_2.11/5.5.1) for `org.elasticsearch:elasticsearch-spark-20_2.11:5.5.1` lists `org.apache.spark:spark-core_2.11:2.1.0` as a dependency, which is decidedly not 2.0. We'll have to use elasticsearch-spark 5.1.2. It's a bit annoying. You'll have to extend the [spark version-specific logic](https://github.com/hail-is/hail/pull/2049/files#diff-c197962302397baf3a4cc36463dce5eaR44) in `build.gradle`. You'll want to bind a new name, something like `elasticsearchSparkVersion`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2049#issuecomment-320335957
https://github.com/hail-is/hail/pull/2049#issuecomment-320335957:422,Testability,log,logic,422,"@bw2 that package name is a lie, sadly. The [maven repository page](https://mvnrepository.com/artifact/org.elasticsearch/elasticsearch-spark-20_2.11/5.5.1) for `org.elasticsearch:elasticsearch-spark-20_2.11:5.5.1` lists `org.apache.spark:spark-core_2.11:2.1.0` as a dependency, which is decidedly not 2.0. We'll have to use elasticsearch-spark 5.1.2. It's a bit annoying. You'll have to extend the [spark version-specific logic](https://github.com/hail-is/hail/pull/2049/files#diff-c197962302397baf3a4cc36463dce5eaR44) in `build.gradle`. You'll want to bind a new name, something like `elasticsearchSparkVersion`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2049#issuecomment-320335957
https://github.com/hail-is/hail/pull/2060#issuecomment-319533736:117,Testability,test,test,117,"Here's some examples:. Original:; ```; from hail import *; hc = HailContext(min_block_size=6); test_resources = 'src/test/resources'. cov = hc.import_table(test_resources + '/regressionLinear.cov',; types={'Cov1': TDouble(), 'Cov2': TDouble()}).key_by('Sample'). phen1 = hc.import_table(test_resources + '/regressionLinear.pheno', missing='0',; types={'Pheno': TDouble()}).key_by('Sample'); phen2 = hc.import_table(test_resources + '/regressionLogisticBoolean.pheno', missing='0',; types={'isCase': TBoolean()}).key_by('Sample'). regression = (hc.import_vcf(test_resources + '/regressionLinear.vcf'); .split_multi(); .annotate_samples_table(cov, root='sa.cov'); .annotate_samples_table(phen1, root='sa.pheno.Pheno'); .annotate_samples_table(phen2, root='sa.pheno.isCase')).with_id('regression'). vds_assoc = (regression; .annotate_samples_expr('sa.culprit = gs.filter(g => v == Variant(""1"", 1, ""C"", ""T"")).map(g => g.gt).collect()[0]'); .annotate_samples_expr('sa.pheno.PhenoLMM = (1 + 0.1 * sa.cov.Cov1 * sa.cov.Cov2) * sa.culprit').with_id('vds_assoc')). vds_kinship = vds_assoc.filter_variants_expr('v.start < 4'); km = vds_kinship.rrm(False, False).with_id('km'); vds_assoc = vds_assoc.lmmreg(km, 'sa.pheno.PhenoLMM', ['sa.cov.Cov1', 'sa.cov.Cov2']); vds_assoc.export_variants('/tmp/lmmreg3.tsv', 'Variant = v, va.lmmreg.*'); ```. History output:; ```; # 2017-08-01T20:23:38.202686; # version: devel-37d32d3. hc = (HailContext(min_block_size=6)). regression = (hc; .import_vcf('src/test/resources/regressionLinear.vcf'); .split_multi(); .annotate_samples_table(hc; .import_table('src/test/resources/regressionLinear.cov', types={'Cov1': TDouble(), 'Cov2': TDouble()}); .key_by('Sample'), root='sa.cov'); .annotate_samples_table(hc; .import_table('src/test/resources/regressionLinear.pheno', types={'Pheno': TDouble()}, missing='0'); .key_by('Sample'), root='sa.pheno.Pheno'); .annotate_samples_table(hc; .import_table('src/test/resources/regressionLogisticBoolean.pheno', types={'isCase': TBoolean(",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2060#issuecomment-319533736
https://github.com/hail-is/hail/pull/2060#issuecomment-319533736:1485,Testability,test,test,1485,"ase': TBoolean()}).key_by('Sample'). regression = (hc.import_vcf(test_resources + '/regressionLinear.vcf'); .split_multi(); .annotate_samples_table(cov, root='sa.cov'); .annotate_samples_table(phen1, root='sa.pheno.Pheno'); .annotate_samples_table(phen2, root='sa.pheno.isCase')).with_id('regression'). vds_assoc = (regression; .annotate_samples_expr('sa.culprit = gs.filter(g => v == Variant(""1"", 1, ""C"", ""T"")).map(g => g.gt).collect()[0]'); .annotate_samples_expr('sa.pheno.PhenoLMM = (1 + 0.1 * sa.cov.Cov1 * sa.cov.Cov2) * sa.culprit').with_id('vds_assoc')). vds_kinship = vds_assoc.filter_variants_expr('v.start < 4'); km = vds_kinship.rrm(False, False).with_id('km'); vds_assoc = vds_assoc.lmmreg(km, 'sa.pheno.PhenoLMM', ['sa.cov.Cov1', 'sa.cov.Cov2']); vds_assoc.export_variants('/tmp/lmmreg3.tsv', 'Variant = v, va.lmmreg.*'); ```. History output:; ```; # 2017-08-01T20:23:38.202686; # version: devel-37d32d3. hc = (HailContext(min_block_size=6)). regression = (hc; .import_vcf('src/test/resources/regressionLinear.vcf'); .split_multi(); .annotate_samples_table(hc; .import_table('src/test/resources/regressionLinear.cov', types={'Cov1': TDouble(), 'Cov2': TDouble()}); .key_by('Sample'), root='sa.cov'); .annotate_samples_table(hc; .import_table('src/test/resources/regressionLinear.pheno', types={'Pheno': TDouble()}, missing='0'); .key_by('Sample'), root='sa.pheno.Pheno'); .annotate_samples_table(hc; .import_table('src/test/resources/regressionLogisticBoolean.pheno', types={'isCase': TBoolean()}, missing='0'); .key_by('Sample'), root='sa.pheno.isCase')). vds_assoc = (regression; .annotate_samples_expr('sa.culprit = gs.filter(g => v == Variant(""1"", 1, ""C"", ""T"")).map(g => g.gt).collect()[0]'); .annotate_samples_expr('sa.pheno.PhenoLMM = (1 + 0.1 * sa.cov.Cov1 * sa.cov.Cov2) * sa.culprit')). km = (vds_assoc; .filter_variants_expr('v.start < 4'); .rrm()). (vds_assoc; .lmmreg(km, 'sa.pheno.PhenoLMM', covariates=['sa.cov.Cov1', 'sa.cov.Cov2']); .export_variants('/tmp/lmmreg3.tsv', ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2060#issuecomment-319533736
https://github.com/hail-is/hail/pull/2060#issuecomment-319533736:1587,Testability,test,test,1587,"'). regression = (hc.import_vcf(test_resources + '/regressionLinear.vcf'); .split_multi(); .annotate_samples_table(cov, root='sa.cov'); .annotate_samples_table(phen1, root='sa.pheno.Pheno'); .annotate_samples_table(phen2, root='sa.pheno.isCase')).with_id('regression'). vds_assoc = (regression; .annotate_samples_expr('sa.culprit = gs.filter(g => v == Variant(""1"", 1, ""C"", ""T"")).map(g => g.gt).collect()[0]'); .annotate_samples_expr('sa.pheno.PhenoLMM = (1 + 0.1 * sa.cov.Cov1 * sa.cov.Cov2) * sa.culprit').with_id('vds_assoc')). vds_kinship = vds_assoc.filter_variants_expr('v.start < 4'); km = vds_kinship.rrm(False, False).with_id('km'); vds_assoc = vds_assoc.lmmreg(km, 'sa.pheno.PhenoLMM', ['sa.cov.Cov1', 'sa.cov.Cov2']); vds_assoc.export_variants('/tmp/lmmreg3.tsv', 'Variant = v, va.lmmreg.*'); ```. History output:; ```; # 2017-08-01T20:23:38.202686; # version: devel-37d32d3. hc = (HailContext(min_block_size=6)). regression = (hc; .import_vcf('src/test/resources/regressionLinear.vcf'); .split_multi(); .annotate_samples_table(hc; .import_table('src/test/resources/regressionLinear.cov', types={'Cov1': TDouble(), 'Cov2': TDouble()}); .key_by('Sample'), root='sa.cov'); .annotate_samples_table(hc; .import_table('src/test/resources/regressionLinear.pheno', types={'Pheno': TDouble()}, missing='0'); .key_by('Sample'), root='sa.pheno.Pheno'); .annotate_samples_table(hc; .import_table('src/test/resources/regressionLogisticBoolean.pheno', types={'isCase': TBoolean()}, missing='0'); .key_by('Sample'), root='sa.pheno.isCase')). vds_assoc = (regression; .annotate_samples_expr('sa.culprit = gs.filter(g => v == Variant(""1"", 1, ""C"", ""T"")).map(g => g.gt).collect()[0]'); .annotate_samples_expr('sa.pheno.PhenoLMM = (1 + 0.1 * sa.cov.Cov1 * sa.cov.Cov2) * sa.culprit')). km = (vds_assoc; .filter_variants_expr('v.start < 4'); .rrm()). (vds_assoc; .lmmreg(km, 'sa.pheno.PhenoLMM', covariates=['sa.cov.Cov1', 'sa.cov.Cov2']); .export_variants('/tmp/lmmreg3.tsv', 'Variant = v, va.lmmreg.*')); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2060#issuecomment-319533736
https://github.com/hail-is/hail/pull/2060#issuecomment-319533736:1754,Testability,test,test,1754,"'). regression = (hc.import_vcf(test_resources + '/regressionLinear.vcf'); .split_multi(); .annotate_samples_table(cov, root='sa.cov'); .annotate_samples_table(phen1, root='sa.pheno.Pheno'); .annotate_samples_table(phen2, root='sa.pheno.isCase')).with_id('regression'). vds_assoc = (regression; .annotate_samples_expr('sa.culprit = gs.filter(g => v == Variant(""1"", 1, ""C"", ""T"")).map(g => g.gt).collect()[0]'); .annotate_samples_expr('sa.pheno.PhenoLMM = (1 + 0.1 * sa.cov.Cov1 * sa.cov.Cov2) * sa.culprit').with_id('vds_assoc')). vds_kinship = vds_assoc.filter_variants_expr('v.start < 4'); km = vds_kinship.rrm(False, False).with_id('km'); vds_assoc = vds_assoc.lmmreg(km, 'sa.pheno.PhenoLMM', ['sa.cov.Cov1', 'sa.cov.Cov2']); vds_assoc.export_variants('/tmp/lmmreg3.tsv', 'Variant = v, va.lmmreg.*'); ```. History output:; ```; # 2017-08-01T20:23:38.202686; # version: devel-37d32d3. hc = (HailContext(min_block_size=6)). regression = (hc; .import_vcf('src/test/resources/regressionLinear.vcf'); .split_multi(); .annotate_samples_table(hc; .import_table('src/test/resources/regressionLinear.cov', types={'Cov1': TDouble(), 'Cov2': TDouble()}); .key_by('Sample'), root='sa.cov'); .annotate_samples_table(hc; .import_table('src/test/resources/regressionLinear.pheno', types={'Pheno': TDouble()}, missing='0'); .key_by('Sample'), root='sa.pheno.Pheno'); .annotate_samples_table(hc; .import_table('src/test/resources/regressionLogisticBoolean.pheno', types={'isCase': TBoolean()}, missing='0'); .key_by('Sample'), root='sa.pheno.isCase')). vds_assoc = (regression; .annotate_samples_expr('sa.culprit = gs.filter(g => v == Variant(""1"", 1, ""C"", ""T"")).map(g => g.gt).collect()[0]'); .annotate_samples_expr('sa.pheno.PhenoLMM = (1 + 0.1 * sa.cov.Cov1 * sa.cov.Cov2) * sa.culprit')). km = (vds_assoc; .filter_variants_expr('v.start < 4'); .rrm()). (vds_assoc; .lmmreg(km, 'sa.pheno.PhenoLMM', covariates=['sa.cov.Cov1', 'sa.cov.Cov2']); .export_variants('/tmp/lmmreg3.tsv', 'Variant = v, va.lmmreg.*')); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2060#issuecomment-319533736
https://github.com/hail-is/hail/pull/2060#issuecomment-319533736:1926,Testability,test,test,1926,"'). regression = (hc.import_vcf(test_resources + '/regressionLinear.vcf'); .split_multi(); .annotate_samples_table(cov, root='sa.cov'); .annotate_samples_table(phen1, root='sa.pheno.Pheno'); .annotate_samples_table(phen2, root='sa.pheno.isCase')).with_id('regression'). vds_assoc = (regression; .annotate_samples_expr('sa.culprit = gs.filter(g => v == Variant(""1"", 1, ""C"", ""T"")).map(g => g.gt).collect()[0]'); .annotate_samples_expr('sa.pheno.PhenoLMM = (1 + 0.1 * sa.cov.Cov1 * sa.cov.Cov2) * sa.culprit').with_id('vds_assoc')). vds_kinship = vds_assoc.filter_variants_expr('v.start < 4'); km = vds_kinship.rrm(False, False).with_id('km'); vds_assoc = vds_assoc.lmmreg(km, 'sa.pheno.PhenoLMM', ['sa.cov.Cov1', 'sa.cov.Cov2']); vds_assoc.export_variants('/tmp/lmmreg3.tsv', 'Variant = v, va.lmmreg.*'); ```. History output:; ```; # 2017-08-01T20:23:38.202686; # version: devel-37d32d3. hc = (HailContext(min_block_size=6)). regression = (hc; .import_vcf('src/test/resources/regressionLinear.vcf'); .split_multi(); .annotate_samples_table(hc; .import_table('src/test/resources/regressionLinear.cov', types={'Cov1': TDouble(), 'Cov2': TDouble()}); .key_by('Sample'), root='sa.cov'); .annotate_samples_table(hc; .import_table('src/test/resources/regressionLinear.pheno', types={'Pheno': TDouble()}, missing='0'); .key_by('Sample'), root='sa.pheno.Pheno'); .annotate_samples_table(hc; .import_table('src/test/resources/regressionLogisticBoolean.pheno', types={'isCase': TBoolean()}, missing='0'); .key_by('Sample'), root='sa.pheno.isCase')). vds_assoc = (regression; .annotate_samples_expr('sa.culprit = gs.filter(g => v == Variant(""1"", 1, ""C"", ""T"")).map(g => g.gt).collect()[0]'); .annotate_samples_expr('sa.pheno.PhenoLMM = (1 + 0.1 * sa.cov.Cov1 * sa.cov.Cov2) * sa.culprit')). km = (vds_assoc; .filter_variants_expr('v.start < 4'); .rrm()). (vds_assoc; .lmmreg(km, 'sa.pheno.PhenoLMM', covariates=['sa.cov.Cov1', 'sa.cov.Cov2']); .export_variants('/tmp/lmmreg3.tsv', 'Variant = v, va.lmmreg.*')); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2060#issuecomment-319533736
https://github.com/hail-is/hail/pull/2060#issuecomment-322237507:261,Testability,log,log,261,"I'm not sure what the problem is you're referring to with TStruct is. ```; In [1]: from hail import *; In [2]: from hail.expr import *; In [3]: hc = HailContext(); Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; hail: info: SparkUI: http://172.20.20.20:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version devel-5d97891. In [4]: s = TStruct(['a', 'b'], [TGenotype(), TStruct(['c', 'd'], [TInt32(), TString()])]); In [5]: s; Out[5]: TStruct(['a', 'b'], [TGenotype(), TStruct(['c', 'd'], [TInt(), TString()])]); In [6]: struct = Struct({'a': 5, 'b': 10, 'c': 'hello'}); In [7]: print(struct._history); # 2017-08-14T12:17:18.033131; # version: devel-5d97891. (Struct(attributes={'a': 5, 'c': 'hello', 'b': 10})). In [8]: struct._history; Out[8]: Struct(attributes={'a': 5, 'c': 'hello', 'b': 10}); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2060#issuecomment-322237507
https://github.com/hail-is/hail/pull/2060#issuecomment-322237507:293,Testability,log,logging,293,"I'm not sure what the problem is you're referring to with TStruct is. ```; In [1]: from hail import *; In [2]: from hail.expr import *; In [3]: hc = HailContext(); Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; hail: info: SparkUI: http://172.20.20.20:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version devel-5d97891. In [4]: s = TStruct(['a', 'b'], [TGenotype(), TStruct(['c', 'd'], [TInt32(), TString()])]); In [5]: s; Out[5]: TStruct(['a', 'b'], [TGenotype(), TStruct(['c', 'd'], [TInt(), TString()])]); In [6]: struct = Struct({'a': 5, 'b': 10, 'c': 'hello'}); In [7]: print(struct._history); # 2017-08-14T12:17:18.033131; # version: devel-5d97891. (Struct(attributes={'a': 5, 'c': 'hello', 'b': 10})). In [8]: struct._history; Out[8]: Struct(attributes={'a': 5, 'c': 'hello', 'b': 10}); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2060#issuecomment-322237507
https://github.com/hail-is/hail/pull/2060#issuecomment-322262037:29,Testability,test,test,29,Can you give an example or a test case you think will fail?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2060#issuecomment-322262037
https://github.com/hail-is/hail/pull/2060#issuecomment-322267032:70,Testability,test,test,70,"I mostly think if we're actually using reprs meaningfully, we need to test them. At least for types, variants + loci + intervals, etc.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2060#issuecomment-322267032
https://github.com/hail-is/hail/pull/2060#issuecomment-322284636:171,Modifiability,inherit,inherited,171,I see now what you are saying about the Structs -- the issue is the attributes on each Field object. I am tempted to go back to my original implementation where the types inherited from `HistoryMixin` and the `__init__` method was recorded when the object was initialized. @cseed didn't think it was necessary to have a Type have a history and suggested using `repr` to print how the object was created.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2060#issuecomment-322284636
https://github.com/hail-is/hail/pull/2060#issuecomment-322287098:42,Testability,test,tests,42,though I would like to see some repr/eval tests!,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2060#issuecomment-322287098
https://github.com/hail-is/hail/issues/2062#issuecomment-319673723:72,Deployability,install,installed,72,"It looks like it is failing when trying to start Java. Do you have Java installed? What version? This is what I get on my mac:. ```; $ java -version; java version ""1.8.0_31""; Java(TM) SE Runtime Environment (build 1.8.0_31-b13); Java HotSpot(TM) 64-Bit Server VM (build 25.31-b07, mixed mode); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2062#issuecomment-319673723
https://github.com/hail-is/hail/issues/2062#issuecomment-319675148:256,Deployability,install,installed,256,"I get the following version: ; ``; $ java -version; java version ""1.8.0_111""; Java(TM) SE Runtime Environment (build 1.8.0_111-b14); Java HotSpot(TM) 64-Bit Server VM (build 25.111-b14, mixed mode); ``; I'm using virtualenv to run python 2.7 and I think I installed all the dependencies and python libraries that were required. Any further idea on what I can do to get this to work?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2062#issuecomment-319675148
https://github.com/hail-is/hail/issues/2062#issuecomment-319675148:274,Integrability,depend,dependencies,274,"I get the following version: ; ``; $ java -version; java version ""1.8.0_111""; Java(TM) SE Runtime Environment (build 1.8.0_111-b14); Java HotSpot(TM) 64-Bit Server VM (build 25.111-b14, mixed mode); ``; I'm using virtualenv to run python 2.7 and I think I installed all the dependencies and python libraries that were required. Any further idea on what I can do to get this to work?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2062#issuecomment-319675148
https://github.com/hail-is/hail/issues/2062#issuecomment-319677826:93,Deployability,deploy,deploy,93,"Ah. We haven't tested against Spark 2.2 yet, so that could be the issue. We currently test / deploy against 2.0.2 and 2.1.0, though I imagine we'll update these versions to 2.1.x and 2.2.x soon.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2062#issuecomment-319677826
https://github.com/hail-is/hail/issues/2062#issuecomment-319677826:148,Deployability,update,update,148,"Ah. We haven't tested against Spark 2.2 yet, so that could be the issue. We currently test / deploy against 2.0.2 and 2.1.0, though I imagine we'll update these versions to 2.1.x and 2.2.x soon.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2062#issuecomment-319677826
https://github.com/hail-is/hail/issues/2062#issuecomment-319677826:15,Testability,test,tested,15,"Ah. We haven't tested against Spark 2.2 yet, so that could be the issue. We currently test / deploy against 2.0.2 and 2.1.0, though I imagine we'll update these versions to 2.1.x and 2.2.x soon.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2062#issuecomment-319677826
https://github.com/hail-is/hail/issues/2062#issuecomment-319677826:86,Testability,test,test,86,"Ah. We haven't tested against Spark 2.2 yet, so that could be the issue. We currently test / deploy against 2.0.2 and 2.1.0, though I imagine we'll update these versions to 2.1.x and 2.2.x soon.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2062#issuecomment-319677826
https://github.com/hail-is/hail/issues/2062#issuecomment-319677878:54,Availability,error,error,54,"I'm still at a loss as to the source of this specific error, though.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2062#issuecomment-319677878
https://github.com/hail-is/hail/issues/2062#issuecomment-319701721:68,Availability,down,downloading,68,@ihelbig Did you install through brew or pip? Normally we recommend downloading the official Spark distribution. @danking Did you install through brew? Did you see anything like this?. /Users/ih/hailenv/lib/python2.7/site-packages/pyspark/java_gateway.py:77 is trying to start Spark by invoking $SPARK_HOME/bin/spark-submit. What is $SPARK_HOME?. You might modify java_gateway.py before like 77 to print out `command` to see what command in detail it is trying to invoke.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2062#issuecomment-319701721
https://github.com/hail-is/hail/issues/2062#issuecomment-319701721:17,Deployability,install,install,17,@ihelbig Did you install through brew or pip? Normally we recommend downloading the official Spark distribution. @danking Did you install through brew? Did you see anything like this?. /Users/ih/hailenv/lib/python2.7/site-packages/pyspark/java_gateway.py:77 is trying to start Spark by invoking $SPARK_HOME/bin/spark-submit. What is $SPARK_HOME?. You might modify java_gateway.py before like 77 to print out `command` to see what command in detail it is trying to invoke.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2062#issuecomment-319701721
https://github.com/hail-is/hail/issues/2062#issuecomment-319701721:130,Deployability,install,install,130,@ihelbig Did you install through brew or pip? Normally we recommend downloading the official Spark distribution. @danking Did you install through brew? Did you see anything like this?. /Users/ih/hailenv/lib/python2.7/site-packages/pyspark/java_gateway.py:77 is trying to start Spark by invoking $SPARK_HOME/bin/spark-submit. What is $SPARK_HOME?. You might modify java_gateway.py before like 77 to print out `command` to see what command in detail it is trying to invoke.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2062#issuecomment-319701721
https://github.com/hail-is/hail/issues/2062#issuecomment-319702678:85,Availability,down,downgrading,85,I used pip install - currently struggling to install the pyspark 2.0.2 version after downgrading to spark 2.0.2 . ``$SPARK_HOME is /Users/ih/languages/spark-2.0.2-bin-hadoop2.7/bin``,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2062#issuecomment-319702678
https://github.com/hail-is/hail/issues/2062#issuecomment-319702678:11,Deployability,install,install,11,I used pip install - currently struggling to install the pyspark 2.0.2 version after downgrading to spark 2.0.2 . ``$SPARK_HOME is /Users/ih/languages/spark-2.0.2-bin-hadoop2.7/bin``,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2062#issuecomment-319702678
https://github.com/hail-is/hail/issues/2062#issuecomment-319702678:45,Deployability,install,install,45,I used pip install - currently struggling to install the pyspark 2.0.2 version after downgrading to spark 2.0.2 . ``$SPARK_HOME is /Users/ih/languages/spark-2.0.2-bin-hadoop2.7/bin``,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2062#issuecomment-319702678
https://github.com/hail-is/hail/issues/2062#issuecomment-319704034:36,Availability,echo,echo,36,I use this:; ```; dking@wmb16-359 # echo $SPARK_HOME; /Users/dking/borg/spark-2.0.2-bin-hadoop2.7/; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2062#issuecomment-319704034
https://github.com/hail-is/hail/issues/2062#issuecomment-319706791:586,Deployability,install,installs,586,"I removed the extra ``bin`` - when I run hc=HailContext(), I get the following: . ``>>> hc = HailContext(); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-422>"", line 2, in __init__; File ""/Users/ih/languages/hail.is/hail/python/hail/typecheck/check.py"", line 226, in _typecheck; return f(*args, **kwargs); File ""/Users/ih/languages/hail.is/hail/python/hail/context.py"", line 83, in __init__; parquet_compression, min_block_size, branching_factor, tmp_dir); TypeError: 'JavaPackage' object is not callable``. I am realizing that pip still installs pyspark 2.2.0 - is this the issue?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2062#issuecomment-319706791
https://github.com/hail-is/hail/issues/2062#issuecomment-319707620:132,Availability,error,error,132,"Yeah, no trailing bin. I think we can sanity-check the SPARK_HOME setting in the HailContext constructor to give a more informative error message.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2062#issuecomment-319707620
https://github.com/hail-is/hail/issues/2062#issuecomment-319707620:138,Integrability,message,message,138,"Yeah, no trailing bin. I think we can sanity-check the SPARK_HOME setting in the HailContext constructor to give a more informative error message.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2062#issuecomment-319707620
https://github.com/hail-is/hail/issues/2062#issuecomment-319708208:32,Availability,error,error,32,Konrad and Beryl have seen this error before trying to use Spark 2.2:; http://discuss.hail.is/t/typeerror-javapackage-object-is-not-callable/250,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2062#issuecomment-319708208
https://github.com/hail-is/hail/issues/2062#issuecomment-319712395:5,Availability,echo,echo,5,"```; echo $SPARK_CLASSPATH; /Users/ih/languages/hail.is/hail/build/libs/hail-all-spark.jar; ```; SPARK_CLASSPATH is set correctly, however, I still get the error message; ```; >>> hc = HailContext(); Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-422>"", line 2, in __init__; File ""/Users/ih/languages/hail.is/hail/python/hail/typecheck/check.py"", line 226, in _typecheck; return f(*args, **kwargs); File ""/Users/ih/languages/hail.is/hail/python/hail/context.py"", line 83, in __init__; parquet_compression, min_block_size, branching_factor, tmp_dir); TypeError: 'JavaPackage' object is not callable; ```. What do I need to do about the driverClassPath?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2062#issuecomment-319712395
https://github.com/hail-is/hail/issues/2062#issuecomment-319712395:156,Availability,error,error,156,"```; echo $SPARK_CLASSPATH; /Users/ih/languages/hail.is/hail/build/libs/hail-all-spark.jar; ```; SPARK_CLASSPATH is set correctly, however, I still get the error message; ```; >>> hc = HailContext(); Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-422>"", line 2, in __init__; File ""/Users/ih/languages/hail.is/hail/python/hail/typecheck/check.py"", line 226, in _typecheck; return f(*args, **kwargs); File ""/Users/ih/languages/hail.is/hail/python/hail/context.py"", line 83, in __init__; parquet_compression, min_block_size, branching_factor, tmp_dir); TypeError: 'JavaPackage' object is not callable; ```. What do I need to do about the driverClassPath?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2062#issuecomment-319712395
https://github.com/hail-is/hail/issues/2062#issuecomment-319712395:162,Integrability,message,message,162,"```; echo $SPARK_CLASSPATH; /Users/ih/languages/hail.is/hail/build/libs/hail-all-spark.jar; ```; SPARK_CLASSPATH is set correctly, however, I still get the error message; ```; >>> hc = HailContext(); Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-422>"", line 2, in __init__; File ""/Users/ih/languages/hail.is/hail/python/hail/typecheck/check.py"", line 226, in _typecheck; return f(*args, **kwargs); File ""/Users/ih/languages/hail.is/hail/python/hail/context.py"", line 83, in __init__; parquet_compression, min_block_size, branching_factor, tmp_dir); TypeError: 'JavaPackage' object is not callable; ```. What do I need to do about the driverClassPath?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2062#issuecomment-319712395
https://github.com/hail-is/hail/issues/2062#issuecomment-319712395:297,Testability,log,log,297,"```; echo $SPARK_CLASSPATH; /Users/ih/languages/hail.is/hail/build/libs/hail-all-spark.jar; ```; SPARK_CLASSPATH is set correctly, however, I still get the error message; ```; >>> hc = HailContext(); Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-422>"", line 2, in __init__; File ""/Users/ih/languages/hail.is/hail/python/hail/typecheck/check.py"", line 226, in _typecheck; return f(*args, **kwargs); File ""/Users/ih/languages/hail.is/hail/python/hail/context.py"", line 83, in __init__; parquet_compression, min_block_size, branching_factor, tmp_dir); TypeError: 'JavaPackage' object is not callable; ```. What do I need to do about the driverClassPath?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2062#issuecomment-319712395
https://github.com/hail-is/hail/issues/2062#issuecomment-319712395:329,Testability,log,logging,329,"```; echo $SPARK_CLASSPATH; /Users/ih/languages/hail.is/hail/build/libs/hail-all-spark.jar; ```; SPARK_CLASSPATH is set correctly, however, I still get the error message; ```; >>> hc = HailContext(); Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-422>"", line 2, in __init__; File ""/Users/ih/languages/hail.is/hail/python/hail/typecheck/check.py"", line 226, in _typecheck; return f(*args, **kwargs); File ""/Users/ih/languages/hail.is/hail/python/hail/context.py"", line 83, in __init__; parquet_compression, min_block_size, branching_factor, tmp_dir); TypeError: 'JavaPackage' object is not callable; ```. What do I need to do about the driverClassPath?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2062#issuecomment-319712395
https://github.com/hail-is/hail/issues/2062#issuecomment-319714443:101,Integrability,wrap,wrapped,101,"Can you try running this before hail context creation:; ```python; old_popen = subprocess.Popen. def wrapped(*args, **kwargs):; print('args are: ' + str(args)); print('kwargs are: ' + str(kwargs)); return old_popen(*args, **kwargs). subprocess.Popen = wrapped; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2062#issuecomment-319714443
https://github.com/hail-is/hail/issues/2062#issuecomment-319714443:252,Integrability,wrap,wrapped,252,"Can you try running this before hail context creation:; ```python; old_popen = subprocess.Popen. def wrapped(*args, **kwargs):; print('args are: ' + str(args)); print('kwargs are: ' + str(kwargs)); return old_popen(*args, **kwargs). subprocess.Popen = wrapped; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2062#issuecomment-319714443
https://github.com/hail-is/hail/issues/2062#issuecomment-319716779:54,Deployability,patch,patches,54,"Sorry, should have clarified - the above code ""monkey-patches"" the subprocess Popen function so it prints before it runs. Just pop the code above your `hc = HailContext(...)`, everything else can remain unchanged.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2062#issuecomment-319716779
https://github.com/hail-is/hail/issues/2062#issuecomment-319717790:75,Integrability,wrap,wrapped,75,"``>>> import subprocess``; ``>>> old_popen = subprocess.Popen``; ``>>> def wrapped(*args, **kwargs):``; ``... print('args are: ' + str(args))``; ``... print('kwargs are: ' + str(kwargs))``; ``... return old_popen(*args, **kwargs)``; ``... ``; ``>>> subprocess.Popen = wrapped``; ``>>> hc = HailContext()``; ``Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties``; ``Setting default log level to ""WARN"".``; ``To adjust logging level use sc.setLogLevel(newLevel).``; ``Traceback (most recent call last):``; `` File ""<stdin>"", line 1, in <module>``; `` File ""<decorator-gen-422>"", line 2, in __init__``; `` File ""/Users/ih/languages/hail.is/hail/python/hail/typecheck/check.py"", line 226, in _typecheck; return f(*args, **kwargs)``; `` File ""/Users/ih/languages/hail.is/hail/python/hail/context.py"", line 83, in __init__; parquet_compression, min_block_size, branching_factor, tmp_dir)``; ``TypeError: 'JavaPackage' object is not callable``. Is this what you were suggesting or am I missing something?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2062#issuecomment-319717790
https://github.com/hail-is/hail/issues/2062#issuecomment-319717790:268,Integrability,wrap,wrapped,268,"``>>> import subprocess``; ``>>> old_popen = subprocess.Popen``; ``>>> def wrapped(*args, **kwargs):``; ``... print('args are: ' + str(args))``; ``... print('kwargs are: ' + str(kwargs))``; ``... return old_popen(*args, **kwargs)``; ``... ``; ``>>> subprocess.Popen = wrapped``; ``>>> hc = HailContext()``; ``Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties``; ``Setting default log level to ""WARN"".``; ``To adjust logging level use sc.setLogLevel(newLevel).``; ``Traceback (most recent call last):``; `` File ""<stdin>"", line 1, in <module>``; `` File ""<decorator-gen-422>"", line 2, in __init__``; `` File ""/Users/ih/languages/hail.is/hail/python/hail/typecheck/check.py"", line 226, in _typecheck; return f(*args, **kwargs)``; `` File ""/Users/ih/languages/hail.is/hail/python/hail/context.py"", line 83, in __init__; parquet_compression, min_block_size, branching_factor, tmp_dir)``; ``TypeError: 'JavaPackage' object is not callable``. Is this what you were suggesting or am I missing something?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2062#issuecomment-319717790
https://github.com/hail-is/hail/issues/2062#issuecomment-319717790:410,Testability,log,log,410,"``>>> import subprocess``; ``>>> old_popen = subprocess.Popen``; ``>>> def wrapped(*args, **kwargs):``; ``... print('args are: ' + str(args))``; ``... print('kwargs are: ' + str(kwargs))``; ``... return old_popen(*args, **kwargs)``; ``... ``; ``>>> subprocess.Popen = wrapped``; ``>>> hc = HailContext()``; ``Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties``; ``Setting default log level to ""WARN"".``; ``To adjust logging level use sc.setLogLevel(newLevel).``; ``Traceback (most recent call last):``; `` File ""<stdin>"", line 1, in <module>``; `` File ""<decorator-gen-422>"", line 2, in __init__``; `` File ""/Users/ih/languages/hail.is/hail/python/hail/typecheck/check.py"", line 226, in _typecheck; return f(*args, **kwargs)``; `` File ""/Users/ih/languages/hail.is/hail/python/hail/context.py"", line 83, in __init__; parquet_compression, min_block_size, branching_factor, tmp_dir)``; ``TypeError: 'JavaPackage' object is not callable``. Is this what you were suggesting or am I missing something?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2062#issuecomment-319717790
https://github.com/hail-is/hail/issues/2062#issuecomment-319717790:446,Testability,log,logging,446,"``>>> import subprocess``; ``>>> old_popen = subprocess.Popen``; ``>>> def wrapped(*args, **kwargs):``; ``... print('args are: ' + str(args))``; ``... print('kwargs are: ' + str(kwargs))``; ``... return old_popen(*args, **kwargs)``; ``... ``; ``>>> subprocess.Popen = wrapped``; ``>>> hc = HailContext()``; ``Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties``; ``Setting default log level to ""WARN"".``; ``To adjust logging level use sc.setLogLevel(newLevel).``; ``Traceback (most recent call last):``; `` File ""<stdin>"", line 1, in <module>``; `` File ""<decorator-gen-422>"", line 2, in __init__``; `` File ""/Users/ih/languages/hail.is/hail/python/hail/typecheck/check.py"", line 226, in _typecheck; return f(*args, **kwargs)``; `` File ""/Users/ih/languages/hail.is/hail/python/hail/context.py"", line 83, in __init__; parquet_compression, min_block_size, branching_factor, tmp_dir)``; ``TypeError: 'JavaPackage' object is not callable``. Is this what you were suggesting or am I missing something?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2062#issuecomment-319717790
https://github.com/hail-is/hail/issues/2062#issuecomment-319718587:23,Availability,error,error,23,"Oh, it looks like this error isn't from a subprocess call. The thing you added would help debug the first error you posted (No such file or directory) but not this one, it looks like.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2062#issuecomment-319718587
https://github.com/hail-is/hail/issues/2062#issuecomment-319718587:106,Availability,error,error,106,"Oh, it looks like this error isn't from a subprocess call. The thing you added would help debug the first error you posted (No such file or directory) but not this one, it looks like.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2062#issuecomment-319718587
https://github.com/hail-is/hail/issues/2062#issuecomment-319749996:1396,Availability,avail,available,1396,"Here is what I get when invoking pyspark. $ pyspark; Python 2.7.13 (default, Jul 18 2017, 09:16:53) ; [GCC 4.2.1 Compatible Apple LLVM 8.0.0 (clang-800.0.42.1)] on darwin; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; 17/08/02 13:56:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 17/08/02 13:56:47 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/Users/ih/languages/hail.is/build/libs/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 17/08/02 13:56:47 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/Users/ih/languages/hail.is/build/libs/hail-all-spark.jar' as a work-around.; 17/08/02 13:56:47 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/Users/ih/languages/hail.is/build/libs/hail-all-spark.jar' as a work-around.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 2.7.13 (default, Jul 18 2017 09:16:53); SparkSession available as 'spark'",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2062#issuecomment-319749996
https://github.com/hail-is/hail/issues/2062#issuecomment-319749996:469,Performance,load,load,469,"Here is what I get when invoking pyspark. $ pyspark; Python 2.7.13 (default, Jul 18 2017, 09:16:53) ; [GCC 4.2.1 Compatible Apple LLVM 8.0.0 (clang-800.0.42.1)] on darwin; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; 17/08/02 13:56:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 17/08/02 13:56:47 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/Users/ih/languages/hail.is/build/libs/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 17/08/02 13:56:47 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/Users/ih/languages/hail.is/build/libs/hail-all-spark.jar' as a work-around.; 17/08/02 13:56:47 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/Users/ih/languages/hail.is/build/libs/hail-all-spark.jar' as a work-around.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 2.7.13 (default, Jul 18 2017 09:16:53); SparkSession available as 'spark'",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2062#issuecomment-319749996
https://github.com/hail-is/hail/issues/2062#issuecomment-319749996:618,Safety,detect,detected,618,"Here is what I get when invoking pyspark. $ pyspark; Python 2.7.13 (default, Jul 18 2017, 09:16:53) ; [GCC 4.2.1 Compatible Apple LLVM 8.0.0 (clang-800.0.42.1)] on darwin; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; 17/08/02 13:56:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 17/08/02 13:56:47 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/Users/ih/languages/hail.is/build/libs/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 17/08/02 13:56:47 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/Users/ih/languages/hail.is/build/libs/hail-all-spark.jar' as a work-around.; 17/08/02 13:56:47 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/Users/ih/languages/hail.is/build/libs/hail-all-spark.jar' as a work-around.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 2.7.13 (default, Jul 18 2017 09:16:53); SparkSession available as 'spark'",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2062#issuecomment-319749996
https://github.com/hail-is/hail/issues/2062#issuecomment-319749996:341,Testability,log,log,341,"Here is what I get when invoking pyspark. $ pyspark; Python 2.7.13 (default, Jul 18 2017, 09:16:53) ; [GCC 4.2.1 Compatible Apple LLVM 8.0.0 (clang-800.0.42.1)] on darwin; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; 17/08/02 13:56:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 17/08/02 13:56:47 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/Users/ih/languages/hail.is/build/libs/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 17/08/02 13:56:47 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/Users/ih/languages/hail.is/build/libs/hail-all-spark.jar' as a work-around.; 17/08/02 13:56:47 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/Users/ih/languages/hail.is/build/libs/hail-all-spark.jar' as a work-around.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 2.7.13 (default, Jul 18 2017 09:16:53); SparkSession available as 'spark'",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2062#issuecomment-319749996
https://github.com/hail-is/hail/issues/2062#issuecomment-319749996:373,Testability,log,logging,373,"Here is what I get when invoking pyspark. $ pyspark; Python 2.7.13 (default, Jul 18 2017, 09:16:53) ; [GCC 4.2.1 Compatible Apple LLVM 8.0.0 (clang-800.0.42.1)] on darwin; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; 17/08/02 13:56:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 17/08/02 13:56:47 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/Users/ih/languages/hail.is/build/libs/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 17/08/02 13:56:47 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/Users/ih/languages/hail.is/build/libs/hail-all-spark.jar' as a work-around.; 17/08/02 13:56:47 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/Users/ih/languages/hail.is/build/libs/hail-all-spark.jar' as a work-around.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 2.7.13 (default, Jul 18 2017 09:16:53); SparkSession available as 'spark'",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2062#issuecomment-319749996
https://github.com/hail-is/hail/issues/2062#issuecomment-320149912:386,Availability,error,error,386,"I just wanted to let you know that the issue was fixed by running python through Jupyter notebook on my Mac where the HailContext could be created without problems. I never managed to run this through the command line, but as I wanted to use the notebook, anyway, this was ok for me. . However, I encountered a problem within your tutorial with the 'data/1kg.vds', which throws a fatal error ; ``HailException: Invalid VDS: old version [4]; Recreate VDS with current version of Hail.``; However, as this is a separate problem, I'll open up a separate issue for this.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2062#issuecomment-320149912
https://github.com/hail-is/hail/issues/2062#issuecomment-320242551:164,Availability,error,error,164,"Regarding the `pyspark` issue, it looks like you have to use `--properties-file` and then put that comma-sepearted list as a newline-separated list in a file. That error message is pyspark's rather terrible way of telling you that it doesn't support a `--properties` option. Regarding the old version of VDS, the `master` branch of hail is now an unstable development branch. If you want a consistent user experience with backwards compatible interfaces, please check out and exclusively use the `0.1` branch. Tim discusses the wider change [here](http://discuss.hail.is/t/deployment-changes-branching-off-for-faster-development/261/1). The VDS format will likely change on the scale of days on the `master` branch. Regarding the `hail/scripts` folder, that is a repository of scripts that our build system uses as templates to create a pre-compiled, ready-to-go distribution that only requires a Spark installation. These distributions are available from the Google Storage API at gs://hail-common/distributions. If you're building from source, I recommend following exactly the steps listed [here](https://hail.is/docs/stable/getting_started.html#building-hail-from-source) so as to avoid any future hiccups. NB: the steps for [Running Hail Locally](https://hail.is/docs/stable/getting_started.html#running-hail-locally) are for using the pre-compiled distribution, not for the result of building hail directly from source.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2062#issuecomment-320242551
https://github.com/hail-is/hail/issues/2062#issuecomment-320242551:941,Availability,avail,available,941,"Regarding the `pyspark` issue, it looks like you have to use `--properties-file` and then put that comma-sepearted list as a newline-separated list in a file. That error message is pyspark's rather terrible way of telling you that it doesn't support a `--properties` option. Regarding the old version of VDS, the `master` branch of hail is now an unstable development branch. If you want a consistent user experience with backwards compatible interfaces, please check out and exclusively use the `0.1` branch. Tim discusses the wider change [here](http://discuss.hail.is/t/deployment-changes-branching-off-for-faster-development/261/1). The VDS format will likely change on the scale of days on the `master` branch. Regarding the `hail/scripts` folder, that is a repository of scripts that our build system uses as templates to create a pre-compiled, ready-to-go distribution that only requires a Spark installation. These distributions are available from the Google Storage API at gs://hail-common/distributions. If you're building from source, I recommend following exactly the steps listed [here](https://hail.is/docs/stable/getting_started.html#building-hail-from-source) so as to avoid any future hiccups. NB: the steps for [Running Hail Locally](https://hail.is/docs/stable/getting_started.html#running-hail-locally) are for using the pre-compiled distribution, not for the result of building hail directly from source.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2062#issuecomment-320242551
https://github.com/hail-is/hail/issues/2062#issuecomment-320242551:573,Deployability,deploy,deployment-changes-branching-off-for-faster-development,573,"Regarding the `pyspark` issue, it looks like you have to use `--properties-file` and then put that comma-sepearted list as a newline-separated list in a file. That error message is pyspark's rather terrible way of telling you that it doesn't support a `--properties` option. Regarding the old version of VDS, the `master` branch of hail is now an unstable development branch. If you want a consistent user experience with backwards compatible interfaces, please check out and exclusively use the `0.1` branch. Tim discusses the wider change [here](http://discuss.hail.is/t/deployment-changes-branching-off-for-faster-development/261/1). The VDS format will likely change on the scale of days on the `master` branch. Regarding the `hail/scripts` folder, that is a repository of scripts that our build system uses as templates to create a pre-compiled, ready-to-go distribution that only requires a Spark installation. These distributions are available from the Google Storage API at gs://hail-common/distributions. If you're building from source, I recommend following exactly the steps listed [here](https://hail.is/docs/stable/getting_started.html#building-hail-from-source) so as to avoid any future hiccups. NB: the steps for [Running Hail Locally](https://hail.is/docs/stable/getting_started.html#running-hail-locally) are for using the pre-compiled distribution, not for the result of building hail directly from source.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2062#issuecomment-320242551
https://github.com/hail-is/hail/issues/2062#issuecomment-320242551:903,Deployability,install,installation,903,"Regarding the `pyspark` issue, it looks like you have to use `--properties-file` and then put that comma-sepearted list as a newline-separated list in a file. That error message is pyspark's rather terrible way of telling you that it doesn't support a `--properties` option. Regarding the old version of VDS, the `master` branch of hail is now an unstable development branch. If you want a consistent user experience with backwards compatible interfaces, please check out and exclusively use the `0.1` branch. Tim discusses the wider change [here](http://discuss.hail.is/t/deployment-changes-branching-off-for-faster-development/261/1). The VDS format will likely change on the scale of days on the `master` branch. Regarding the `hail/scripts` folder, that is a repository of scripts that our build system uses as templates to create a pre-compiled, ready-to-go distribution that only requires a Spark installation. These distributions are available from the Google Storage API at gs://hail-common/distributions. If you're building from source, I recommend following exactly the steps listed [here](https://hail.is/docs/stable/getting_started.html#building-hail-from-source) so as to avoid any future hiccups. NB: the steps for [Running Hail Locally](https://hail.is/docs/stable/getting_started.html#running-hail-locally) are for using the pre-compiled distribution, not for the result of building hail directly from source.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2062#issuecomment-320242551
https://github.com/hail-is/hail/issues/2062#issuecomment-320242551:170,Integrability,message,message,170,"Regarding the `pyspark` issue, it looks like you have to use `--properties-file` and then put that comma-sepearted list as a newline-separated list in a file. That error message is pyspark's rather terrible way of telling you that it doesn't support a `--properties` option. Regarding the old version of VDS, the `master` branch of hail is now an unstable development branch. If you want a consistent user experience with backwards compatible interfaces, please check out and exclusively use the `0.1` branch. Tim discusses the wider change [here](http://discuss.hail.is/t/deployment-changes-branching-off-for-faster-development/261/1). The VDS format will likely change on the scale of days on the `master` branch. Regarding the `hail/scripts` folder, that is a repository of scripts that our build system uses as templates to create a pre-compiled, ready-to-go distribution that only requires a Spark installation. These distributions are available from the Google Storage API at gs://hail-common/distributions. If you're building from source, I recommend following exactly the steps listed [here](https://hail.is/docs/stable/getting_started.html#building-hail-from-source) so as to avoid any future hiccups. NB: the steps for [Running Hail Locally](https://hail.is/docs/stable/getting_started.html#running-hail-locally) are for using the pre-compiled distribution, not for the result of building hail directly from source.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2062#issuecomment-320242551
https://github.com/hail-is/hail/issues/2062#issuecomment-320242551:443,Integrability,interface,interfaces,443,"Regarding the `pyspark` issue, it looks like you have to use `--properties-file` and then put that comma-sepearted list as a newline-separated list in a file. That error message is pyspark's rather terrible way of telling you that it doesn't support a `--properties` option. Regarding the old version of VDS, the `master` branch of hail is now an unstable development branch. If you want a consistent user experience with backwards compatible interfaces, please check out and exclusively use the `0.1` branch. Tim discusses the wider change [here](http://discuss.hail.is/t/deployment-changes-branching-off-for-faster-development/261/1). The VDS format will likely change on the scale of days on the `master` branch. Regarding the `hail/scripts` folder, that is a repository of scripts that our build system uses as templates to create a pre-compiled, ready-to-go distribution that only requires a Spark installation. These distributions are available from the Google Storage API at gs://hail-common/distributions. If you're building from source, I recommend following exactly the steps listed [here](https://hail.is/docs/stable/getting_started.html#building-hail-from-source) so as to avoid any future hiccups. NB: the steps for [Running Hail Locally](https://hail.is/docs/stable/getting_started.html#running-hail-locally) are for using the pre-compiled distribution, not for the result of building hail directly from source.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2062#issuecomment-320242551
https://github.com/hail-is/hail/issues/2062#issuecomment-320242551:1185,Safety,avoid,avoid,1185,"Regarding the `pyspark` issue, it looks like you have to use `--properties-file` and then put that comma-sepearted list as a newline-separated list in a file. That error message is pyspark's rather terrible way of telling you that it doesn't support a `--properties` option. Regarding the old version of VDS, the `master` branch of hail is now an unstable development branch. If you want a consistent user experience with backwards compatible interfaces, please check out and exclusively use the `0.1` branch. Tim discusses the wider change [here](http://discuss.hail.is/t/deployment-changes-branching-off-for-faster-development/261/1). The VDS format will likely change on the scale of days on the `master` branch. Regarding the `hail/scripts` folder, that is a repository of scripts that our build system uses as templates to create a pre-compiled, ready-to-go distribution that only requires a Spark installation. These distributions are available from the Google Storage API at gs://hail-common/distributions. If you're building from source, I recommend following exactly the steps listed [here](https://hail.is/docs/stable/getting_started.html#building-hail-from-source) so as to avoid any future hiccups. NB: the steps for [Running Hail Locally](https://hail.is/docs/stable/getting_started.html#running-hail-locally) are for using the pre-compiled distribution, not for the result of building hail directly from source.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2062#issuecomment-320242551
https://github.com/hail-is/hail/issues/2062#issuecomment-320242551:401,Usability,user experience,user experience,401,"Regarding the `pyspark` issue, it looks like you have to use `--properties-file` and then put that comma-sepearted list as a newline-separated list in a file. That error message is pyspark's rather terrible way of telling you that it doesn't support a `--properties` option. Regarding the old version of VDS, the `master` branch of hail is now an unstable development branch. If you want a consistent user experience with backwards compatible interfaces, please check out and exclusively use the `0.1` branch. Tim discusses the wider change [here](http://discuss.hail.is/t/deployment-changes-branching-off-for-faster-development/261/1). The VDS format will likely change on the scale of days on the `master` branch. Regarding the `hail/scripts` folder, that is a repository of scripts that our build system uses as templates to create a pre-compiled, ready-to-go distribution that only requires a Spark installation. These distributions are available from the Google Storage API at gs://hail-common/distributions. If you're building from source, I recommend following exactly the steps listed [here](https://hail.is/docs/stable/getting_started.html#building-hail-from-source) so as to avoid any future hiccups. NB: the steps for [Running Hail Locally](https://hail.is/docs/stable/getting_started.html#running-hail-locally) are for using the pre-compiled distribution, not for the result of building hail directly from source.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2062#issuecomment-320242551
https://github.com/hail-is/hail/issues/2062#issuecomment-320243052:2,Availability,down,downloadable,2,a downloadable link to the distributions can be found here: ; https://hail.is/docs/stable/getting_started.html. The current link for Spark 2.0.2 is https://storage.googleapis.com/hail-common/distributions/0.1/Hail-0.1-4238176-Spark-2.0.2.zip,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2062#issuecomment-320243052
https://github.com/hail-is/hail/pull/2063#issuecomment-319959888:7,Testability,test,tested,7,I just tested on Dataproc and it works there just fine.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2063#issuecomment-319959888
https://github.com/hail-is/hail/issues/2067#issuecomment-320243639:87,Deployability,release,release,87,"I think we should remove tutorials from devel for now, and add them back in before 0.2 release",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2067#issuecomment-320243639
https://github.com/hail-is/hail/issues/2067#issuecomment-320256546:0,Deployability,Install,Installation,0,Installation of 0.1 works; `git clone -b 0.1 https://github.com/broadinstitute/hail.git`; The only thing to add is that you have to do `chmod u+x gradlew` in order to `$ ./gradlew -Dspark.version=2.0.2 shadowJar`,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2067#issuecomment-320256546
https://github.com/hail-is/hail/pull/2071#issuecomment-322527815:40,Integrability,interface,interfaces,40,@cseed I switched to using the existing interfaces. Can this be approved now?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2071#issuecomment-322527815
https://github.com/hail-is/hail/pull/2073#issuecomment-322529797:51,Integrability,interface,interfaces,51,@cseed I also switched this PR to use the existing interfaces.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2073#issuecomment-322529797
https://github.com/hail-is/hail/pull/2074#issuecomment-320641116:52,Availability,down,down,52,"I'll digest over the next day or so, then let's sit down and go through some of the design choices + trajectory together.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2074#issuecomment-320641116
https://github.com/hail-is/hail/pull/2074#issuecomment-321090734:268,Performance,load,loads,268,"@tpoterba Back to you. Addressed comments. Nuked MemoryBlock, moved the array to MemoryBuffer. I think I made the safety tests in MemoryBuffer complete. I changed the array to Array[Byte]. It is working. There might still be an alignment issue (x86 supports unaligned loads but with possible performance penalty) but I'm OK leaving it to be addressed separately. I think ComplexType is good but I agree we can remove representation and just fundamentalType.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2074#issuecomment-321090734
https://github.com/hail-is/hail/pull/2074#issuecomment-321090734:292,Performance,perform,performance,292,"@tpoterba Back to you. Addressed comments. Nuked MemoryBlock, moved the array to MemoryBuffer. I think I made the safety tests in MemoryBuffer complete. I changed the array to Array[Byte]. It is working. There might still be an alignment issue (x86 supports unaligned loads but with possible performance penalty) but I'm OK leaving it to be addressed separately. I think ComplexType is good but I agree we can remove representation and just fundamentalType.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2074#issuecomment-321090734
https://github.com/hail-is/hail/pull/2074#issuecomment-321090734:114,Safety,safe,safety,114,"@tpoterba Back to you. Addressed comments. Nuked MemoryBlock, moved the array to MemoryBuffer. I think I made the safety tests in MemoryBuffer complete. I changed the array to Array[Byte]. It is working. There might still be an alignment issue (x86 supports unaligned loads but with possible performance penalty) but I'm OK leaving it to be addressed separately. I think ComplexType is good but I agree we can remove representation and just fundamentalType.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2074#issuecomment-321090734
https://github.com/hail-is/hail/pull/2074#issuecomment-321090734:121,Testability,test,tests,121,"@tpoterba Back to you. Addressed comments. Nuked MemoryBlock, moved the array to MemoryBuffer. I think I made the safety tests in MemoryBuffer complete. I changed the array to Array[Byte]. It is working. There might still be an alignment issue (x86 supports unaligned loads but with possible performance penalty) but I'm OK leaving it to be addressed separately. I think ComplexType is good but I agree we can remove representation and just fundamentalType.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2074#issuecomment-321090734
https://github.com/hail-is/hail/pull/2074#issuecomment-321102215:7,Safety,Unsafe,UnsafeRowBuilder,7,"Nuked `UnsafeRowBuilder` and associated tests. There was a bug in the tests that the stronger asserts in MemoryBuffer caught. Easier to nuke than fix, since we aren't planning to use it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2074#issuecomment-321102215
https://github.com/hail-is/hail/pull/2074#issuecomment-321102215:40,Testability,test,tests,40,"Nuked `UnsafeRowBuilder` and associated tests. There was a bug in the tests that the stronger asserts in MemoryBuffer caught. Easier to nuke than fix, since we aren't planning to use it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2074#issuecomment-321102215
https://github.com/hail-is/hail/pull/2074#issuecomment-321102215:70,Testability,test,tests,70,"Nuked `UnsafeRowBuilder` and associated tests. There was a bug in the tests that the stronger asserts in MemoryBuffer caught. Easier to nuke than fix, since we aren't planning to use it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2074#issuecomment-321102215
https://github.com/hail-is/hail/pull/2074#issuecomment-321102215:94,Testability,assert,asserts,94,"Nuked `UnsafeRowBuilder` and associated tests. There was a bug in the tests that the stronger asserts in MemoryBuffer caught. Easier to nuke than fix, since we aren't planning to use it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2074#issuecomment-321102215
https://github.com/hail-is/hail/issues/2076#issuecomment-320923206:108,Security,access,access,108,"How are you running Spark? Are you running in local mode, or in cluster mode? In local mode, you won't have access to the HDFS file scheme.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-320923206
https://github.com/hail-is/hail/issues/2076#issuecomment-321152609:2148,Availability,avail,available,2148,"der: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 17/08/09 12:51:55 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/opt/Software/hail/build/libs/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 17/08/09 12:51:55 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; 17/08/09 12:51:55 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; 17/08/09 12:51:56 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 3.5.2 (default, Jul 12 2017 14:00:23); SparkSession available as 'spark'. In [1]: from hail import *; ---------------------------------------------------------------------------; ImportError Traceback (most recent call last); <ipython-input-1-3181c5d8fca5> in <module>(); ----> 1 from hail import *. /opt/Software/hail/python/hail/__init__.py in <module>(); ----> 1 import hail.expr; 2 from hail.representation import *; 3 from hail.context import HailContext; 4 from hail.dataset import VariantDataset; 5 from hail.expr import *. /opt/Software/hail/python/hail/expr.py in <module>(); 1 import abc; 2 from hail.java import scala_object, Env, jset; ----> 3 from hail.representation import Variant, AltAllele, Genotype, Locus, Interval, Struct, Call; 4 ; 5 . /opt/Software/hail/python/hail/representation/__init__.py in <module>(); ----> 1 from hail.representation.variant import Variant, Locus, AltAllele; 2 from hail.representation.interval import Interval; 3 from hail.representation.genotype import Genotype, Call; 4 from hail.representa",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321152609
https://github.com/hail-is/hail/issues/2076#issuecomment-321152609:3939,Availability,error,errors,3939,"___/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 3.5.2 (default, Jul 12 2017 14:00:23); SparkSession available as 'spark'. In [1]: from hail import *; ---------------------------------------------------------------------------; ImportError Traceback (most recent call last); <ipython-input-1-3181c5d8fca5> in <module>(); ----> 1 from hail import *. /opt/Software/hail/python/hail/__init__.py in <module>(); ----> 1 import hail.expr; 2 from hail.representation import *; 3 from hail.context import HailContext; 4 from hail.dataset import VariantDataset; 5 from hail.expr import *. /opt/Software/hail/python/hail/expr.py in <module>(); 1 import abc; 2 from hail.java import scala_object, Env, jset; ----> 3 from hail.representation import Variant, AltAllele, Genotype, Locus, Interval, Struct, Call; 4 ; 5 . /opt/Software/hail/python/hail/representation/__init__.py in <module>(); ----> 1 from hail.representation.variant import Variant, Locus, AltAllele; 2 from hail.representation.interval import Interval; 3 from hail.representation.genotype import Genotype, Call; 4 from hail.representation.annotations import Struct; 5 from hail.representation.pedigree import Trio, Pedigree. /opt/Software/hail/python/hail/representation/variant.py in <module>(); 1 from hail.java import scala_object, Env, handle_py4j; ----> 2 from hail.typecheck import *; 3 ; 4 class Variant(object):; 5 """""". /opt/Software/hail/python/hail/typecheck/__init__.py in <module>(); ----> 1 from check import *; 2 ; 3 __all__ = ['typecheck',; 4 'typecheck_method',; 5 'none',. ImportError: No module named 'check'. In [2]: hc = HailContext(sc); ---------------------------------------------------------------------------; NameError Traceback (most recent call last); <ipython-input-2-2e980fcce31d> in <module>(); ----> 1 hc = HailContext(sc). NameError: name 'HailContext' is not defined. In [3]: ; ```; There are still some errors, is there something wrong with my configurations?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321152609
https://github.com/hail-is/hail/issues/2076#issuecomment-321152609:3980,Deployability,configurat,configurations,3980,"___/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 3.5.2 (default, Jul 12 2017 14:00:23); SparkSession available as 'spark'. In [1]: from hail import *; ---------------------------------------------------------------------------; ImportError Traceback (most recent call last); <ipython-input-1-3181c5d8fca5> in <module>(); ----> 1 from hail import *. /opt/Software/hail/python/hail/__init__.py in <module>(); ----> 1 import hail.expr; 2 from hail.representation import *; 3 from hail.context import HailContext; 4 from hail.dataset import VariantDataset; 5 from hail.expr import *. /opt/Software/hail/python/hail/expr.py in <module>(); 1 import abc; 2 from hail.java import scala_object, Env, jset; ----> 3 from hail.representation import Variant, AltAllele, Genotype, Locus, Interval, Struct, Call; 4 ; 5 . /opt/Software/hail/python/hail/representation/__init__.py in <module>(); ----> 1 from hail.representation.variant import Variant, Locus, AltAllele; 2 from hail.representation.interval import Interval; 3 from hail.representation.genotype import Genotype, Call; 4 from hail.representation.annotations import Struct; 5 from hail.representation.pedigree import Trio, Pedigree. /opt/Software/hail/python/hail/representation/variant.py in <module>(); 1 from hail.java import scala_object, Env, handle_py4j; ----> 2 from hail.typecheck import *; 3 ; 4 class Variant(object):; 5 """""". /opt/Software/hail/python/hail/typecheck/__init__.py in <module>(); ----> 1 from check import *; 2 ; 3 __all__ = ['typecheck',; 4 'typecheck_method',; 5 'none',. ImportError: No module named 'check'. In [2]: hc = HailContext(sc); ---------------------------------------------------------------------------; NameError Traceback (most recent call last); <ipython-input-2-2e980fcce31d> in <module>(); ----> 1 hc = HailContext(sc). NameError: name 'HailContext' is not defined. In [3]: ; ```; There are still some errors, is there something wrong with my configurations?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321152609
https://github.com/hail-is/hail/issues/2076#issuecomment-321152609:703,Modifiability,enhance,enhanced,703,"Hi, when we executed the command above, the results are as follows:; ```; [root@tele-1 ~]# PYSPARK_PYTHON=""ipython"" pyspark --conf spark.sql.files.openCostInBytes=1099511627776 --conf spark.sql.files.maxPartitionBytes=1099511627776 --conf spark.hadoop.parquet.block.size=1099511627776 --conf spark.serializer=org.apache.spark.serializer.KryoSerializer; /usr/local/lib/python3.5/site-packages/IPython/core/history.py:228: UserWarning: IPython History requires SQLite, your history will not be saved; warn(""IPython History requires SQLite, your history will not be saved""); Python 3.5.2 (default, Jul 12 2017, 14:00:23) ; Type ""copyright"", ""credits"" or ""license"" for more information. IPython 5.1.0 -- An enhanced Interactive Python.; ? -> Introduction and overview of IPython's features.; %quickref -> Quick reference.; help -> Python's own help system.; object? -> Details about 'object', use 'object??' for extra details.; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; 17/08/09 12:51:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 17/08/09 12:51:55 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/opt/Software/hail/build/libs/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 17/08/09 12:51:55 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; 17/08/09 12:51:55 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; 17/08/09 12:51:56 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.; Welcome to; ____ __; / __/__ ___ _____/ /",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321152609
https://github.com/hail-is/hail/issues/2076#issuecomment-321152609:3980,Modifiability,config,configurations,3980,"___/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 3.5.2 (default, Jul 12 2017 14:00:23); SparkSession available as 'spark'. In [1]: from hail import *; ---------------------------------------------------------------------------; ImportError Traceback (most recent call last); <ipython-input-1-3181c5d8fca5> in <module>(); ----> 1 from hail import *. /opt/Software/hail/python/hail/__init__.py in <module>(); ----> 1 import hail.expr; 2 from hail.representation import *; 3 from hail.context import HailContext; 4 from hail.dataset import VariantDataset; 5 from hail.expr import *. /opt/Software/hail/python/hail/expr.py in <module>(); 1 import abc; 2 from hail.java import scala_object, Env, jset; ----> 3 from hail.representation import Variant, AltAllele, Genotype, Locus, Interval, Struct, Call; 4 ; 5 . /opt/Software/hail/python/hail/representation/__init__.py in <module>(); ----> 1 from hail.representation.variant import Variant, Locus, AltAllele; 2 from hail.representation.interval import Interval; 3 from hail.representation.genotype import Genotype, Call; 4 from hail.representation.annotations import Struct; 5 from hail.representation.pedigree import Trio, Pedigree. /opt/Software/hail/python/hail/representation/variant.py in <module>(); 1 from hail.java import scala_object, Env, handle_py4j; ----> 2 from hail.typecheck import *; 3 ; 4 class Variant(object):; 5 """""". /opt/Software/hail/python/hail/typecheck/__init__.py in <module>(); ----> 1 from check import *; 2 ; 3 __all__ = ['typecheck',; 4 'typecheck_method',; 5 'none',. ImportError: No module named 'check'. In [2]: hc = HailContext(sc); ---------------------------------------------------------------------------; NameError Traceback (most recent call last); <ipython-input-2-2e980fcce31d> in <module>(); ----> 1 hc = HailContext(sc). NameError: name 'HailContext' is not defined. In [3]: ; ```; There are still some errors, is there something wrong with my configurations?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321152609
https://github.com/hail-is/hail/issues/2076#issuecomment-321152609:1149,Performance,load,load,1149,"s.openCostInBytes=1099511627776 --conf spark.sql.files.maxPartitionBytes=1099511627776 --conf spark.hadoop.parquet.block.size=1099511627776 --conf spark.serializer=org.apache.spark.serializer.KryoSerializer; /usr/local/lib/python3.5/site-packages/IPython/core/history.py:228: UserWarning: IPython History requires SQLite, your history will not be saved; warn(""IPython History requires SQLite, your history will not be saved""); Python 3.5.2 (default, Jul 12 2017, 14:00:23) ; Type ""copyright"", ""credits"" or ""license"" for more information. IPython 5.1.0 -- An enhanced Interactive Python.; ? -> Introduction and overview of IPython's features.; %quickref -> Quick reference.; help -> Python's own help system.; object? -> Details about 'object', use 'object??' for extra details.; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; 17/08/09 12:51:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 17/08/09 12:51:55 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/opt/Software/hail/build/libs/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 17/08/09 12:51:55 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; 17/08/09 12:51:55 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; 17/08/09 12:51:56 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 3.5.2 (default, Jul 12 2017 14:00:23); SparkSessi",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321152609
https://github.com/hail-is/hail/issues/2076#issuecomment-321152609:1298,Safety,detect,detected,1298,"627776 --conf spark.serializer=org.apache.spark.serializer.KryoSerializer; /usr/local/lib/python3.5/site-packages/IPython/core/history.py:228: UserWarning: IPython History requires SQLite, your history will not be saved; warn(""IPython History requires SQLite, your history will not be saved""); Python 3.5.2 (default, Jul 12 2017, 14:00:23) ; Type ""copyright"", ""credits"" or ""license"" for more information. IPython 5.1.0 -- An enhanced Interactive Python.; ? -> Introduction and overview of IPython's features.; %quickref -> Quick reference.; help -> Python's own help system.; object? -> Details about 'object', use 'object??' for extra details.; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; 17/08/09 12:51:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 17/08/09 12:51:55 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/opt/Software/hail/build/libs/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 17/08/09 12:51:55 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; 17/08/09 12:51:55 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; 17/08/09 12:51:56 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 3.5.2 (default, Jul 12 2017 14:00:23); SparkSession available as 'spark'. In [1]: from hail import *; ---------------------------------------------------------------------------; Impo",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321152609
https://github.com/hail-is/hail/issues/2076#issuecomment-321152609:1021,Testability,log,log,1021,"ted the command above, the results are as follows:; ```; [root@tele-1 ~]# PYSPARK_PYTHON=""ipython"" pyspark --conf spark.sql.files.openCostInBytes=1099511627776 --conf spark.sql.files.maxPartitionBytes=1099511627776 --conf spark.hadoop.parquet.block.size=1099511627776 --conf spark.serializer=org.apache.spark.serializer.KryoSerializer; /usr/local/lib/python3.5/site-packages/IPython/core/history.py:228: UserWarning: IPython History requires SQLite, your history will not be saved; warn(""IPython History requires SQLite, your history will not be saved""); Python 3.5.2 (default, Jul 12 2017, 14:00:23) ; Type ""copyright"", ""credits"" or ""license"" for more information. IPython 5.1.0 -- An enhanced Interactive Python.; ? -> Introduction and overview of IPython's features.; %quickref -> Quick reference.; help -> Python's own help system.; object? -> Details about 'object', use 'object??' for extra details.; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; 17/08/09 12:51:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 17/08/09 12:51:55 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/opt/Software/hail/build/libs/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 17/08/09 12:51:55 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; 17/08/09 12:51:55 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; 17/08/09 12:51:56 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321152609
https://github.com/hail-is/hail/issues/2076#issuecomment-321152609:1053,Testability,log,logging,1053,"s follows:; ```; [root@tele-1 ~]# PYSPARK_PYTHON=""ipython"" pyspark --conf spark.sql.files.openCostInBytes=1099511627776 --conf spark.sql.files.maxPartitionBytes=1099511627776 --conf spark.hadoop.parquet.block.size=1099511627776 --conf spark.serializer=org.apache.spark.serializer.KryoSerializer; /usr/local/lib/python3.5/site-packages/IPython/core/history.py:228: UserWarning: IPython History requires SQLite, your history will not be saved; warn(""IPython History requires SQLite, your history will not be saved""); Python 3.5.2 (default, Jul 12 2017, 14:00:23) ; Type ""copyright"", ""credits"" or ""license"" for more information. IPython 5.1.0 -- An enhanced Interactive Python.; ? -> Introduction and overview of IPython's features.; %quickref -> Quick reference.; help -> Python's own help system.; object? -> Details about 'object', use 'object??' for extra details.; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; 17/08/09 12:51:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 17/08/09 12:51:55 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/opt/Software/hail/build/libs/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 17/08/09 12:51:55 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; 17/08/09 12:51:55 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; 17/08/09 12:51:56 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ ver",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321152609
https://github.com/hail-is/hail/issues/2076#issuecomment-321211196:168,Deployability,release,release,168,"Are you using Python 3? Hail currently only supports Python 2, though we expect to be either compatible with both or _only_ compatible with Python 3 in the next stable release",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321211196
https://github.com/hail-is/hail/issues/2076#issuecomment-321215583:1608,Availability,avail,available,1608,"""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; 17/08/09 18:18:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 17/08/09 18:18:30 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/opt/Software/hail/build/libs/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 17/08/09 18:18:30 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; 17/08/09 18:18:30 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; >>> from hail import *; >>> hc = HailContext(sc); hail: info: SparkUI: http://192.168.1.4:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.1-0320a61; >>> hc.import_vcf('/hail/test/BRCA1.raw_indel.vcf').write('/hail/test/brca1.vds'); hail: warning: `/hail/test/BRCA1.raw_indel.vcf' refers to no files; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-483>"", line 2, in import_vcf; File ""/opt/Software/hail/python/hail/java.py"", line 112, in handle_py4j; 'Error summary: %s' % (deepest, full, Env.hc().version, deepest)); hail.java.FatalError: HailException: arguments refer to no files. Java stack trace:; is.hail.utils.HailException: arguments refer to no files; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:6); 	at is.hail.utils.package$.fatal(package.scala:25); 	at is.hail.io.vcf.LoadVCF$.globAllVCFs(LoadVCF.scala:105); 	at is.hail.HailContext.importVCFs",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321215583
https://github.com/hail-is/hail/issues/2076#issuecomment-321215583:2172,Availability,Error,Error,2172,"k.executor.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; 17/08/09 18:18:30 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; >>> from hail import *; >>> hc = HailContext(sc); hail: info: SparkUI: http://192.168.1.4:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.1-0320a61; >>> hc.import_vcf('/hail/test/BRCA1.raw_indel.vcf').write('/hail/test/brca1.vds'); hail: warning: `/hail/test/BRCA1.raw_indel.vcf' refers to no files; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-483>"", line 2, in import_vcf; File ""/opt/Software/hail/python/hail/java.py"", line 112, in handle_py4j; 'Error summary: %s' % (deepest, full, Env.hc().version, deepest)); hail.java.FatalError: HailException: arguments refer to no files. Java stack trace:; is.hail.utils.HailException: arguments refer to no files; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:6); 	at is.hail.utils.package$.fatal(package.scala:25); 	at is.hail.io.vcf.LoadVCF$.globAllVCFs(LoadVCF.scala:105); 	at is.hail.HailContext.importVCFs(HailContext.scala:523); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321215583
https://github.com/hail-is/hail/issues/2076#issuecomment-321215583:2399,Availability,Error,ErrorHandling,2399,"rk-around.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; >>> from hail import *; >>> hc = HailContext(sc); hail: info: SparkUI: http://192.168.1.4:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.1-0320a61; >>> hc.import_vcf('/hail/test/BRCA1.raw_indel.vcf').write('/hail/test/brca1.vds'); hail: warning: `/hail/test/BRCA1.raw_indel.vcf' refers to no files; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-483>"", line 2, in import_vcf; File ""/opt/Software/hail/python/hail/java.py"", line 112, in handle_py4j; 'Error summary: %s' % (deepest, full, Env.hc().version, deepest)); hail.java.FatalError: HailException: arguments refer to no files. Java stack trace:; is.hail.utils.HailException: arguments refer to no files; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:6); 	at is.hail.utils.package$.fatal(package.scala:25); 	at is.hail.io.vcf.LoadVCF$.globAllVCFs(LoadVCF.scala:105); 	at is.hail.HailContext.importVCFs(HailContext.scala:523); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:745). Hail version: 0.1-0320a61; Error summary: HailException: arguments refer to no",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321215583
https://github.com/hail-is/hail/issues/2076#issuecomment-321215583:2425,Availability,Error,ErrorHandling,2425," Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; >>> from hail import *; >>> hc = HailContext(sc); hail: info: SparkUI: http://192.168.1.4:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.1-0320a61; >>> hc.import_vcf('/hail/test/BRCA1.raw_indel.vcf').write('/hail/test/brca1.vds'); hail: warning: `/hail/test/BRCA1.raw_indel.vcf' refers to no files; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-483>"", line 2, in import_vcf; File ""/opt/Software/hail/python/hail/java.py"", line 112, in handle_py4j; 'Error summary: %s' % (deepest, full, Env.hc().version, deepest)); hail.java.FatalError: HailException: arguments refer to no files. Java stack trace:; is.hail.utils.HailException: arguments refer to no files; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:6); 	at is.hail.utils.package$.fatal(package.scala:25); 	at is.hail.io.vcf.LoadVCF$.globAllVCFs(LoadVCF.scala:105); 	at is.hail.HailContext.importVCFs(HailContext.scala:523); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:745). Hail version: 0.1-0320a61; Error summary: HailException: arguments refer to no files; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321215583
https://github.com/hail-is/hail/issues/2076#issuecomment-321215583:3358,Availability,Error,Error,3358," Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; >>> from hail import *; >>> hc = HailContext(sc); hail: info: SparkUI: http://192.168.1.4:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.1-0320a61; >>> hc.import_vcf('/hail/test/BRCA1.raw_indel.vcf').write('/hail/test/brca1.vds'); hail: warning: `/hail/test/BRCA1.raw_indel.vcf' refers to no files; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-483>"", line 2, in import_vcf; File ""/opt/Software/hail/python/hail/java.py"", line 112, in handle_py4j; 'Error summary: %s' % (deepest, full, Env.hc().version, deepest)); hail.java.FatalError: HailException: arguments refer to no files. Java stack trace:; is.hail.utils.HailException: arguments refer to no files; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:6); 	at is.hail.utils.package$.fatal(package.scala:25); 	at is.hail.io.vcf.LoadVCF$.globAllVCFs(LoadVCF.scala:105); 	at is.hail.HailContext.importVCFs(HailContext.scala:523); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:745). Hail version: 0.1-0320a61; Error summary: HailException: arguments refer to no files; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321215583
https://github.com/hail-is/hail/issues/2076#issuecomment-321215583:710,Performance,load,load,710,"When I use python 2.7.5, it still can't work: ; ```; [root@tele-1 ~]# pyspark --conf spark.sql.files.openCostInBytes=1099511627776 --conf spark.sql.files.maxPartitionBytes=1099511627776 --conf spark.hadoop.parquet.block.size=1099511627776 --conf spark.serializer=org.apache.spark.serializer.KryoSerializer; ****Python 2.7.5 (default, Nov 6 2016, 00:28:07)**** ; [GCC 4.8.5 20150623 (Red Hat 4.8.5-11)] on linux2; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; 17/08/09 18:18:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 17/08/09 18:18:30 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/opt/Software/hail/build/libs/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 17/08/09 18:18:30 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; 17/08/09 18:18:30 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; >>> from hail import *; >>> hc = HailContext(sc); hail: info: SparkUI: http://192.168.1.4:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.1-0320a61; >>> hc.import_vcf('/hail/test/BRCA1.raw_indel.vcf').write('/hail/test/brca1.vds'); hail: warning: `/hail/test/BRCA1.raw_indel.vcf' refers to no files; Traceback (most recent call",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321215583
https://github.com/hail-is/hail/issues/2076#issuecomment-321215583:2520,Performance,Load,LoadVCF,2520," Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; >>> from hail import *; >>> hc = HailContext(sc); hail: info: SparkUI: http://192.168.1.4:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.1-0320a61; >>> hc.import_vcf('/hail/test/BRCA1.raw_indel.vcf').write('/hail/test/brca1.vds'); hail: warning: `/hail/test/BRCA1.raw_indel.vcf' refers to no files; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-483>"", line 2, in import_vcf; File ""/opt/Software/hail/python/hail/java.py"", line 112, in handle_py4j; 'Error summary: %s' % (deepest, full, Env.hc().version, deepest)); hail.java.FatalError: HailException: arguments refer to no files. Java stack trace:; is.hail.utils.HailException: arguments refer to no files; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:6); 	at is.hail.utils.package$.fatal(package.scala:25); 	at is.hail.io.vcf.LoadVCF$.globAllVCFs(LoadVCF.scala:105); 	at is.hail.HailContext.importVCFs(HailContext.scala:523); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:745). Hail version: 0.1-0320a61; Error summary: HailException: arguments refer to no files; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321215583
https://github.com/hail-is/hail/issues/2076#issuecomment-321215583:2541,Performance,Load,LoadVCF,2541," Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; >>> from hail import *; >>> hc = HailContext(sc); hail: info: SparkUI: http://192.168.1.4:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.1-0320a61; >>> hc.import_vcf('/hail/test/BRCA1.raw_indel.vcf').write('/hail/test/brca1.vds'); hail: warning: `/hail/test/BRCA1.raw_indel.vcf' refers to no files; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-483>"", line 2, in import_vcf; File ""/opt/Software/hail/python/hail/java.py"", line 112, in handle_py4j; 'Error summary: %s' % (deepest, full, Env.hc().version, deepest)); hail.java.FatalError: HailException: arguments refer to no files. Java stack trace:; is.hail.utils.HailException: arguments refer to no files; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:6); 	at is.hail.utils.package$.fatal(package.scala:25); 	at is.hail.io.vcf.LoadVCF$.globAllVCFs(LoadVCF.scala:105); 	at is.hail.HailContext.importVCFs(HailContext.scala:523); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:745). Hail version: 0.1-0320a61; Error summary: HailException: arguments refer to no files; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321215583
https://github.com/hail-is/hail/issues/2076#issuecomment-321215583:859,Safety,detect,detected,859,"When I use python 2.7.5, it still can't work: ; ```; [root@tele-1 ~]# pyspark --conf spark.sql.files.openCostInBytes=1099511627776 --conf spark.sql.files.maxPartitionBytes=1099511627776 --conf spark.hadoop.parquet.block.size=1099511627776 --conf spark.serializer=org.apache.spark.serializer.KryoSerializer; ****Python 2.7.5 (default, Nov 6 2016, 00:28:07)**** ; [GCC 4.8.5 20150623 (Red Hat 4.8.5-11)] on linux2; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; 17/08/09 18:18:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 17/08/09 18:18:30 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/opt/Software/hail/build/libs/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 17/08/09 18:18:30 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; 17/08/09 18:18:30 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; >>> from hail import *; >>> hc = HailContext(sc); hail: info: SparkUI: http://192.168.1.4:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.1-0320a61; >>> hc.import_vcf('/hail/test/BRCA1.raw_indel.vcf').write('/hail/test/brca1.vds'); hail: warning: `/hail/test/BRCA1.raw_indel.vcf' refers to no files; Traceback (most recent call",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321215583
https://github.com/hail-is/hail/issues/2076#issuecomment-321215583:582,Testability,log,log,582,"When I use python 2.7.5, it still can't work: ; ```; [root@tele-1 ~]# pyspark --conf spark.sql.files.openCostInBytes=1099511627776 --conf spark.sql.files.maxPartitionBytes=1099511627776 --conf spark.hadoop.parquet.block.size=1099511627776 --conf spark.serializer=org.apache.spark.serializer.KryoSerializer; ****Python 2.7.5 (default, Nov 6 2016, 00:28:07)**** ; [GCC 4.8.5 20150623 (Red Hat 4.8.5-11)] on linux2; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; 17/08/09 18:18:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 17/08/09 18:18:30 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/opt/Software/hail/build/libs/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 17/08/09 18:18:30 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; 17/08/09 18:18:30 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; >>> from hail import *; >>> hc = HailContext(sc); hail: info: SparkUI: http://192.168.1.4:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.1-0320a61; >>> hc.import_vcf('/hail/test/BRCA1.raw_indel.vcf').write('/hail/test/brca1.vds'); hail: warning: `/hail/test/BRCA1.raw_indel.vcf' refers to no files; Traceback (most recent call",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321215583
https://github.com/hail-is/hail/issues/2076#issuecomment-321215583:614,Testability,log,logging,614,"When I use python 2.7.5, it still can't work: ; ```; [root@tele-1 ~]# pyspark --conf spark.sql.files.openCostInBytes=1099511627776 --conf spark.sql.files.maxPartitionBytes=1099511627776 --conf spark.hadoop.parquet.block.size=1099511627776 --conf spark.serializer=org.apache.spark.serializer.KryoSerializer; ****Python 2.7.5 (default, Nov 6 2016, 00:28:07)**** ; [GCC 4.8.5 20150623 (Red Hat 4.8.5-11)] on linux2; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; 17/08/09 18:18:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 17/08/09 18:18:30 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/opt/Software/hail/build/libs/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 17/08/09 18:18:30 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; 17/08/09 18:18:30 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; >>> from hail import *; >>> hc = HailContext(sc); hail: info: SparkUI: http://192.168.1.4:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.1-0320a61; >>> hc.import_vcf('/hail/test/BRCA1.raw_indel.vcf').write('/hail/test/brca1.vds'); hail: warning: `/hail/test/BRCA1.raw_indel.vcf' refers to no files; Traceback (most recent call",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321215583
https://github.com/hail-is/hail/issues/2076#issuecomment-321215583:1848,Testability,test,test,1848,"_CLASSPATH was detected (set to '/opt/Software/hail/build/libs/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 17/08/09 18:18:30 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; 17/08/09 18:18:30 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; >>> from hail import *; >>> hc = HailContext(sc); hail: info: SparkUI: http://192.168.1.4:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.1-0320a61; >>> hc.import_vcf('/hail/test/BRCA1.raw_indel.vcf').write('/hail/test/brca1.vds'); hail: warning: `/hail/test/BRCA1.raw_indel.vcf' refers to no files; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-483>"", line 2, in import_vcf; File ""/opt/Software/hail/python/hail/java.py"", line 112, in handle_py4j; 'Error summary: %s' % (deepest, full, Env.hc().version, deepest)); hail.java.FatalError: HailException: arguments refer to no files. Java stack trace:; is.hail.utils.HailException: arguments refer to no files; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:6); 	at is.hail.utils.package$.fatal(package.scala:25); 	at is.hail.io.vcf.LoadVCF$.globAllVCFs(LoadVCF.scala:105); 	at is.hail.HailContext.importVCFs(HailContext.scala:523); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorI",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321215583
https://github.com/hail-is/hail/issues/2076#issuecomment-321215583:1888,Testability,test,test,1888,"are/hail/build/libs/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 17/08/09 18:18:30 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; 17/08/09 18:18:30 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; >>> from hail import *; >>> hc = HailContext(sc); hail: info: SparkUI: http://192.168.1.4:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.1-0320a61; >>> hc.import_vcf('/hail/test/BRCA1.raw_indel.vcf').write('/hail/test/brca1.vds'); hail: warning: `/hail/test/BRCA1.raw_indel.vcf' refers to no files; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-483>"", line 2, in import_vcf; File ""/opt/Software/hail/python/hail/java.py"", line 112, in handle_py4j; 'Error summary: %s' % (deepest, full, Env.hc().version, deepest)); hail.java.FatalError: HailException: arguments refer to no files. Java stack trace:; is.hail.utils.HailException: arguments refer to no files; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:6); 	at is.hail.utils.package$.fatal(package.scala:25); 	at is.hail.io.vcf.LoadVCF$.globAllVCFs(LoadVCF.scala:105); 	at is.hail.HailContext.importVCFs(HailContext.scala:523); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321215583
https://github.com/hail-is/hail/issues/2076#issuecomment-321215583:1928,Testability,test,test,1928,"rk.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 17/08/09 18:18:30 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; 17/08/09 18:18:30 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; >>> from hail import *; >>> hc = HailContext(sc); hail: info: SparkUI: http://192.168.1.4:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.1-0320a61; >>> hc.import_vcf('/hail/test/BRCA1.raw_indel.vcf').write('/hail/test/brca1.vds'); hail: warning: `/hail/test/BRCA1.raw_indel.vcf' refers to no files; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-483>"", line 2, in import_vcf; File ""/opt/Software/hail/python/hail/java.py"", line 112, in handle_py4j; 'Error summary: %s' % (deepest, full, Env.hc().version, deepest)); hail.java.FatalError: HailException: arguments refer to no files. Java stack trace:; is.hail.utils.HailException: arguments refer to no files; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:6); 	at is.hail.utils.package$.fatal(package.scala:25); 	at is.hail.io.vcf.LoadVCF$.globAllVCFs(LoadVCF.scala:105); 	at is.hail.HailContext.importVCFs(HailContext.scala:523); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321215583
https://github.com/hail-is/hail/issues/2076#issuecomment-321224012:24,Availability,error,error,24,"ok, so back to the same error. I think your Spark cluster must be configured incorrectly, which is something we can't really help with. You should be able to do:; ```; pyspark; ```; and then:; ```python; sc.textFile('/hail/test/BRCA1.raw_indel.vcf'); ```; without error.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321224012
https://github.com/hail-is/hail/issues/2076#issuecomment-321224012:264,Availability,error,error,264,"ok, so back to the same error. I think your Spark cluster must be configured incorrectly, which is something we can't really help with. You should be able to do:; ```; pyspark; ```; and then:; ```python; sc.textFile('/hail/test/BRCA1.raw_indel.vcf'); ```; without error.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321224012
https://github.com/hail-is/hail/issues/2076#issuecomment-321224012:66,Modifiability,config,configured,66,"ok, so back to the same error. I think your Spark cluster must be configured incorrectly, which is something we can't really help with. You should be able to do:; ```; pyspark; ```; and then:; ```python; sc.textFile('/hail/test/BRCA1.raw_indel.vcf'); ```; without error.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321224012
https://github.com/hail-is/hail/issues/2076#issuecomment-321224012:223,Testability,test,test,223,"ok, so back to the same error. I think your Spark cluster must be configured incorrectly, which is something we can't really help with. You should be able to do:; ```; pyspark; ```; and then:; ```python; sc.textFile('/hail/test/BRCA1.raw_indel.vcf'); ```; without error.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321224012
https://github.com/hail-is/hail/issues/2076#issuecomment-321228506:1446,Availability,avail,available,1446,"""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; 17/08/09 19:16:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 17/08/09 19:16:02 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/opt/Software/hail/build/libs/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 17/08/09 19:16:02 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; 17/08/09 19:16:02 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; >>> sc.textFile('/hail/test/BRCA1.raw_indel.vcf'); /hail/test/BRCA1.raw_indel.vcf MapPartitionsRDD[1] at textFile at NativeMethodAccessorImpl.java:-2; >>> ; ```. ----------------; When I executed the command in local mode , there seems to hava some result:; ```; [root@tele-1 ~]# python; Python 2.7.5 (default, Nov 6 2016, 00:28:07) ; [GCC 4.8.5 20150623 (Red Hat 4.8.5-11)] on linux2; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; >>> from hail import *; >>> hc = HailContext();; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; hail: info: SparkUI: http://192.168.1.4:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.1-0320a61; >>> hc.import_vcf('/opt/NfsDir/UserDir/wanghn/BRCA1.raw_indel.vcf').write('/opt/NfsDir/UserDir/wanghn/BRCA1.raw_indel_1.vds'); hail: info: No",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321228506
https://github.com/hail-is/hail/issues/2076#issuecomment-321228506:2769,Deployability,configurat,configuration,2769," use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 17/08/09 19:16:02 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; 17/08/09 19:16:02 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; >>> sc.textFile('/hail/test/BRCA1.raw_indel.vcf'); /hail/test/BRCA1.raw_indel.vcf MapPartitionsRDD[1] at textFile at NativeMethodAccessorImpl.java:-2; >>> ; ```. ----------------; When I executed the command in local mode , there seems to hava some result:; ```; [root@tele-1 ~]# python; Python 2.7.5 (default, Nov 6 2016, 00:28:07) ; [GCC 4.8.5 20150623 (Red Hat 4.8.5-11)] on linux2; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; >>> from hail import *; >>> hc = HailContext();; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; hail: info: SparkUI: http://192.168.1.4:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.1-0320a61; >>> hc.import_vcf('/opt/NfsDir/UserDir/wanghn/BRCA1.raw_indel.vcf').write('/opt/NfsDir/UserDir/wanghn/BRCA1.raw_indel_1.vds'); hail: info: No multiallelics detected.; hail: info: Coerced unsorted dataset; SLF4J: Failed to load class ""org.slf4j.impl.StaticLoggerBinder"".; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.; ```; ------------------------; How can I check if my spark configuration meet the requirement of the hail?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321228506
https://github.com/hail-is/hail/issues/2076#issuecomment-321228506:2769,Modifiability,config,configuration,2769," use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 17/08/09 19:16:02 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; 17/08/09 19:16:02 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; >>> sc.textFile('/hail/test/BRCA1.raw_indel.vcf'); /hail/test/BRCA1.raw_indel.vcf MapPartitionsRDD[1] at textFile at NativeMethodAccessorImpl.java:-2; >>> ; ```. ----------------; When I executed the command in local mode , there seems to hava some result:; ```; [root@tele-1 ~]# python; Python 2.7.5 (default, Nov 6 2016, 00:28:07) ; [GCC 4.8.5 20150623 (Red Hat 4.8.5-11)] on linux2; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; >>> from hail import *; >>> hc = HailContext();; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; hail: info: SparkUI: http://192.168.1.4:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.1-0320a61; >>> hc.import_vcf('/opt/NfsDir/UserDir/wanghn/BRCA1.raw_indel.vcf').write('/opt/NfsDir/UserDir/wanghn/BRCA1.raw_indel_1.vds'); hail: info: No multiallelics detected.; hail: info: Coerced unsorted dataset; SLF4J: Failed to load class ""org.slf4j.impl.StaticLoggerBinder"".; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.; ```; ------------------------; How can I check if my spark configuration meet the requirement of the hail?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321228506
https://github.com/hail-is/hail/issues/2076#issuecomment-321228506:548,Performance,load,load,548,"Yes, when I do :; ```; pyspark; sc.textFile('/hail/test/BRCA1.raw_indel.vcf') ; ```; The following information is shown:; ```; [root@tele-1 ~]# pyspark; Python 2.7.5 (default, Nov 6 2016, 00:28:07) ; [GCC 4.8.5 20150623 (Red Hat 4.8.5-11)] on linux2; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; 17/08/09 19:16:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 17/08/09 19:16:02 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/opt/Software/hail/build/libs/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 17/08/09 19:16:02 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; 17/08/09 19:16:02 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; >>> sc.textFile('/hail/test/BRCA1.raw_indel.vcf'); /hail/test/BRCA1.raw_indel.vcf MapPartitionsRDD[1] at textFile at NativeMethodAccessorImpl.java:-2; >>> ; ```. ----------------; When I executed the command in local mode , there seems to hava some result:; ```; [root@tele-1 ~]# python; Python 2.7.5 (default, Nov 6 2016, 00:28:07) ; [GCC 4.8.5 20150623 (Red Hat 4.8.5-11)] on linux2; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; >>> from hail import *; >>> hc = HailContext();; Using Spark's default log",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321228506
https://github.com/hail-is/hail/issues/2076#issuecomment-321228506:2514,Performance,load,load,2514," use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 17/08/09 19:16:02 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; 17/08/09 19:16:02 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; >>> sc.textFile('/hail/test/BRCA1.raw_indel.vcf'); /hail/test/BRCA1.raw_indel.vcf MapPartitionsRDD[1] at textFile at NativeMethodAccessorImpl.java:-2; >>> ; ```. ----------------; When I executed the command in local mode , there seems to hava some result:; ```; [root@tele-1 ~]# python; Python 2.7.5 (default, Nov 6 2016, 00:28:07) ; [GCC 4.8.5 20150623 (Red Hat 4.8.5-11)] on linux2; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; >>> from hail import *; >>> hc = HailContext();; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; hail: info: SparkUI: http://192.168.1.4:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.1-0320a61; >>> hc.import_vcf('/opt/NfsDir/UserDir/wanghn/BRCA1.raw_indel.vcf').write('/opt/NfsDir/UserDir/wanghn/BRCA1.raw_indel_1.vds'); hail: info: No multiallelics detected.; hail: info: Coerced unsorted dataset; SLF4J: Failed to load class ""org.slf4j.impl.StaticLoggerBinder"".; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.; ```; ------------------------; How can I check if my spark configuration meet the requirement of the hail?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321228506
https://github.com/hail-is/hail/issues/2076#issuecomment-321228506:697,Safety,detect,detected,697,"Yes, when I do :; ```; pyspark; sc.textFile('/hail/test/BRCA1.raw_indel.vcf') ; ```; The following information is shown:; ```; [root@tele-1 ~]# pyspark; Python 2.7.5 (default, Nov 6 2016, 00:28:07) ; [GCC 4.8.5 20150623 (Red Hat 4.8.5-11)] on linux2; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; 17/08/09 19:16:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 17/08/09 19:16:02 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/opt/Software/hail/build/libs/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 17/08/09 19:16:02 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; 17/08/09 19:16:02 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; >>> sc.textFile('/hail/test/BRCA1.raw_indel.vcf'); /hail/test/BRCA1.raw_indel.vcf MapPartitionsRDD[1] at textFile at NativeMethodAccessorImpl.java:-2; >>> ; ```. ----------------; When I executed the command in local mode , there seems to hava some result:; ```; [root@tele-1 ~]# python; Python 2.7.5 (default, Nov 6 2016, 00:28:07) ; [GCC 4.8.5 20150623 (Red Hat 4.8.5-11)] on linux2; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; >>> from hail import *; >>> hc = HailContext();; Using Spark's default log",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321228506
https://github.com/hail-is/hail/issues/2076#issuecomment-321228506:2448,Safety,detect,detected,2448," use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 17/08/09 19:16:02 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; 17/08/09 19:16:02 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; >>> sc.textFile('/hail/test/BRCA1.raw_indel.vcf'); /hail/test/BRCA1.raw_indel.vcf MapPartitionsRDD[1] at textFile at NativeMethodAccessorImpl.java:-2; >>> ; ```. ----------------; When I executed the command in local mode , there seems to hava some result:; ```; [root@tele-1 ~]# python; Python 2.7.5 (default, Nov 6 2016, 00:28:07) ; [GCC 4.8.5 20150623 (Red Hat 4.8.5-11)] on linux2; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; >>> from hail import *; >>> hc = HailContext();; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; hail: info: SparkUI: http://192.168.1.4:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.1-0320a61; >>> hc.import_vcf('/opt/NfsDir/UserDir/wanghn/BRCA1.raw_indel.vcf').write('/opt/NfsDir/UserDir/wanghn/BRCA1.raw_indel_1.vds'); hail: info: No multiallelics detected.; hail: info: Coerced unsorted dataset; SLF4J: Failed to load class ""org.slf4j.impl.StaticLoggerBinder"".; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.; ```; ------------------------; How can I check if my spark configuration meet the requirement of the hail?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321228506
https://github.com/hail-is/hail/issues/2076#issuecomment-321228506:51,Testability,test,test,51,"Yes, when I do :; ```; pyspark; sc.textFile('/hail/test/BRCA1.raw_indel.vcf') ; ```; The following information is shown:; ```; [root@tele-1 ~]# pyspark; Python 2.7.5 (default, Nov 6 2016, 00:28:07) ; [GCC 4.8.5 20150623 (Red Hat 4.8.5-11)] on linux2; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; 17/08/09 19:16:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 17/08/09 19:16:02 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/opt/Software/hail/build/libs/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 17/08/09 19:16:02 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; 17/08/09 19:16:02 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; >>> sc.textFile('/hail/test/BRCA1.raw_indel.vcf'); /hail/test/BRCA1.raw_indel.vcf MapPartitionsRDD[1] at textFile at NativeMethodAccessorImpl.java:-2; >>> ; ```. ----------------; When I executed the command in local mode , there seems to hava some result:; ```; [root@tele-1 ~]# python; Python 2.7.5 (default, Nov 6 2016, 00:28:07) ; [GCC 4.8.5 20150623 (Red Hat 4.8.5-11)] on linux2; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; >>> from hail import *; >>> hc = HailContext();; Using Spark's default log",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321228506
https://github.com/hail-is/hail/issues/2076#issuecomment-321228506:420,Testability,log,log,420,"Yes, when I do :; ```; pyspark; sc.textFile('/hail/test/BRCA1.raw_indel.vcf') ; ```; The following information is shown:; ```; [root@tele-1 ~]# pyspark; Python 2.7.5 (default, Nov 6 2016, 00:28:07) ; [GCC 4.8.5 20150623 (Red Hat 4.8.5-11)] on linux2; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; 17/08/09 19:16:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 17/08/09 19:16:02 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/opt/Software/hail/build/libs/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 17/08/09 19:16:02 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; 17/08/09 19:16:02 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; >>> sc.textFile('/hail/test/BRCA1.raw_indel.vcf'); /hail/test/BRCA1.raw_indel.vcf MapPartitionsRDD[1] at textFile at NativeMethodAccessorImpl.java:-2; >>> ; ```. ----------------; When I executed the command in local mode , there seems to hava some result:; ```; [root@tele-1 ~]# python; Python 2.7.5 (default, Nov 6 2016, 00:28:07) ; [GCC 4.8.5 20150623 (Red Hat 4.8.5-11)] on linux2; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; >>> from hail import *; >>> hc = HailContext();; Using Spark's default log",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321228506
https://github.com/hail-is/hail/issues/2076#issuecomment-321228506:452,Testability,log,logging,452,"Yes, when I do :; ```; pyspark; sc.textFile('/hail/test/BRCA1.raw_indel.vcf') ; ```; The following information is shown:; ```; [root@tele-1 ~]# pyspark; Python 2.7.5 (default, Nov 6 2016, 00:28:07) ; [GCC 4.8.5 20150623 (Red Hat 4.8.5-11)] on linux2; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; 17/08/09 19:16:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 17/08/09 19:16:02 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/opt/Software/hail/build/libs/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 17/08/09 19:16:02 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; 17/08/09 19:16:02 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; >>> sc.textFile('/hail/test/BRCA1.raw_indel.vcf'); /hail/test/BRCA1.raw_indel.vcf MapPartitionsRDD[1] at textFile at NativeMethodAccessorImpl.java:-2; >>> ; ```. ----------------; When I executed the command in local mode , there seems to hava some result:; ```; [root@tele-1 ~]# python; Python 2.7.5 (default, Nov 6 2016, 00:28:07) ; [GCC 4.8.5 20150623 (Red Hat 4.8.5-11)] on linux2; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; >>> from hail import *; >>> hc = HailContext();; Using Spark's default log",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321228506
https://github.com/hail-is/hail/issues/2076#issuecomment-321228506:1492,Testability,test,test,1492,"evel).; 17/08/09 19:16:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 17/08/09 19:16:02 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/opt/Software/hail/build/libs/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 17/08/09 19:16:02 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; 17/08/09 19:16:02 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; >>> sc.textFile('/hail/test/BRCA1.raw_indel.vcf'); /hail/test/BRCA1.raw_indel.vcf MapPartitionsRDD[1] at textFile at NativeMethodAccessorImpl.java:-2; >>> ; ```. ----------------; When I executed the command in local mode , there seems to hava some result:; ```; [root@tele-1 ~]# python; Python 2.7.5 (default, Nov 6 2016, 00:28:07) ; [GCC 4.8.5 20150623 (Red Hat 4.8.5-11)] on linux2; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; >>> from hail import *; >>> hc = HailContext();; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; hail: info: SparkUI: http://192.168.1.4:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.1-0320a61; >>> hc.import_vcf('/opt/NfsDir/UserDir/wanghn/BRCA1.raw_indel.vcf').write('/opt/NfsDir/UserDir/wanghn/BRCA1.raw_indel_1.vds'); hail: info: No multiallelics detected.; hail: info: Coerced unsorted da",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321228506
https://github.com/hail-is/hail/issues/2076#issuecomment-321228506:1526,Testability,test,test,1526,"eCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 17/08/09 19:16:02 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/opt/Software/hail/build/libs/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 17/08/09 19:16:02 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; 17/08/09 19:16:02 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; >>> sc.textFile('/hail/test/BRCA1.raw_indel.vcf'); /hail/test/BRCA1.raw_indel.vcf MapPartitionsRDD[1] at textFile at NativeMethodAccessorImpl.java:-2; >>> ; ```. ----------------; When I executed the command in local mode , there seems to hava some result:; ```; [root@tele-1 ~]# python; Python 2.7.5 (default, Nov 6 2016, 00:28:07) ; [GCC 4.8.5 20150623 (Red Hat 4.8.5-11)] on linux2; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; >>> from hail import *; >>> hc = HailContext();; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; hail: info: SparkUI: http://192.168.1.4:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.1-0320a61; >>> hc.import_vcf('/opt/NfsDir/UserDir/wanghn/BRCA1.raw_indel.vcf').write('/opt/NfsDir/UserDir/wanghn/BRCA1.raw_indel_1.vds'); hail: info: No multiallelics detected.; hail: info: Coerced unsorted dataset; SLF4J: Failed to load class ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321228506
https://github.com/hail-is/hail/issues/2076#issuecomment-321228506:2073,Testability,log,log,2073," use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 17/08/09 19:16:02 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; 17/08/09 19:16:02 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; >>> sc.textFile('/hail/test/BRCA1.raw_indel.vcf'); /hail/test/BRCA1.raw_indel.vcf MapPartitionsRDD[1] at textFile at NativeMethodAccessorImpl.java:-2; >>> ; ```. ----------------; When I executed the command in local mode , there seems to hava some result:; ```; [root@tele-1 ~]# python; Python 2.7.5 (default, Nov 6 2016, 00:28:07) ; [GCC 4.8.5 20150623 (Red Hat 4.8.5-11)] on linux2; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; >>> from hail import *; >>> hc = HailContext();; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; hail: info: SparkUI: http://192.168.1.4:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.1-0320a61; >>> hc.import_vcf('/opt/NfsDir/UserDir/wanghn/BRCA1.raw_indel.vcf').write('/opt/NfsDir/UserDir/wanghn/BRCA1.raw_indel_1.vds'); hail: info: No multiallelics detected.; hail: info: Coerced unsorted dataset; SLF4J: Failed to load class ""org.slf4j.impl.StaticLoggerBinder"".; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.; ```; ------------------------; How can I check if my spark configuration meet the requirement of the hail?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321228506
https://github.com/hail-is/hail/issues/2076#issuecomment-321228506:2105,Testability,log,logging,2105," use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 17/08/09 19:16:02 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; 17/08/09 19:16:02 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; >>> sc.textFile('/hail/test/BRCA1.raw_indel.vcf'); /hail/test/BRCA1.raw_indel.vcf MapPartitionsRDD[1] at textFile at NativeMethodAccessorImpl.java:-2; >>> ; ```. ----------------; When I executed the command in local mode , there seems to hava some result:; ```; [root@tele-1 ~]# python; Python 2.7.5 (default, Nov 6 2016, 00:28:07) ; [GCC 4.8.5 20150623 (Red Hat 4.8.5-11)] on linux2; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; >>> from hail import *; >>> hc = HailContext();; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; hail: info: SparkUI: http://192.168.1.4:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.1-0320a61; >>> hc.import_vcf('/opt/NfsDir/UserDir/wanghn/BRCA1.raw_indel.vcf').write('/opt/NfsDir/UserDir/wanghn/BRCA1.raw_indel_1.vds'); hail: info: No multiallelics detected.; hail: info: Coerced unsorted dataset; SLF4J: Failed to load class ""org.slf4j.impl.StaticLoggerBinder"".; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.; ```; ------------------------; How can I check if my spark configuration meet the requirement of the hail?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321228506
https://github.com/hail-is/hail/issues/2076#issuecomment-321228506:2603,Testability,log,logger,2603," use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 17/08/09 19:16:02 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; 17/08/09 19:16:02 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; >>> sc.textFile('/hail/test/BRCA1.raw_indel.vcf'); /hail/test/BRCA1.raw_indel.vcf MapPartitionsRDD[1] at textFile at NativeMethodAccessorImpl.java:-2; >>> ; ```. ----------------; When I executed the command in local mode , there seems to hava some result:; ```; [root@tele-1 ~]# python; Python 2.7.5 (default, Nov 6 2016, 00:28:07) ; [GCC 4.8.5 20150623 (Red Hat 4.8.5-11)] on linux2; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; >>> from hail import *; >>> hc = HailContext();; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; hail: info: SparkUI: http://192.168.1.4:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.1-0320a61; >>> hc.import_vcf('/opt/NfsDir/UserDir/wanghn/BRCA1.raw_indel.vcf').write('/opt/NfsDir/UserDir/wanghn/BRCA1.raw_indel_1.vds'); hail: info: No multiallelics detected.; hail: info: Coerced unsorted dataset; SLF4J: Failed to load class ""org.slf4j.impl.StaticLoggerBinder"".; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.; ```; ------------------------; How can I check if my spark configuration meet the requirement of the hail?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321228506
https://github.com/hail-is/hail/issues/2076#issuecomment-321241969:277,Availability,error,errors,277,"Does the version of spark matter? such as apache spark 2.0.2 and the cloudera spark?; We use the cloudera hadoop,but for hail, the cloudera'spark can't work,so in the configuration we replaced the cloudera spark with the apache spark2.0.2,and this works in local mode,but have errors in cluster mode",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321241969
https://github.com/hail-is/hail/issues/2076#issuecomment-321241969:167,Deployability,configurat,configuration,167,"Does the version of spark matter? such as apache spark 2.0.2 and the cloudera spark?; We use the cloudera hadoop,but for hail, the cloudera'spark can't work,so in the configuration we replaced the cloudera spark with the apache spark2.0.2,and this works in local mode,but have errors in cluster mode",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321241969
https://github.com/hail-is/hail/issues/2076#issuecomment-321241969:167,Modifiability,config,configuration,167,"Does the version of spark matter? such as apache spark 2.0.2 and the cloudera spark?; We use the cloudera hadoop,but for hail, the cloudera'spark can't work,so in the configuration we replaced the cloudera spark with the apache spark2.0.2,and this works in local mode,but have errors in cluster mode",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321241969
https://github.com/hail-is/hail/issues/2076#issuecomment-321241976:277,Availability,error,errors,277,"Does the version of spark matter? such as apache spark 2.0.2 and the cloudera spark?; We use the cloudera hadoop,but for hail, the cloudera'spark can't work,so in the configuration we replaced the cloudera spark with the apache spark2.0.2,and this works in local mode,but have errors in cluster mode",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321241976
https://github.com/hail-is/hail/issues/2076#issuecomment-321241976:167,Deployability,configurat,configuration,167,"Does the version of spark matter? such as apache spark 2.0.2 and the cloudera spark?; We use the cloudera hadoop,but for hail, the cloudera'spark can't work,so in the configuration we replaced the cloudera spark with the apache spark2.0.2,and this works in local mode,but have errors in cluster mode",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321241976
https://github.com/hail-is/hail/issues/2076#issuecomment-321241976:167,Modifiability,config,configuration,167,"Does the version of spark matter? such as apache spark 2.0.2 and the cloudera spark?; We use the cloudera hadoop,but for hail, the cloudera'spark can't work,so in the configuration we replaced the cloudera spark with the apache spark2.0.2,and this works in local mode,but have errors in cluster mode",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321241976
https://github.com/hail-is/hail/issues/2076#issuecomment-321255115:69,Deployability,install,installed,69,"I don't think so - as long as the same version of Spark and Hail are installed, it should work with 2.0.2 or 2.1.0 or CDH deployments of those versions.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321255115
https://github.com/hail-is/hail/issues/2076#issuecomment-321255115:122,Deployability,deploy,deployments,122,"I don't think so - as long as the same version of Spark and Hail are installed, it should work with 2.0.2 or 2.1.0 or CDH deployments of those versions.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321255115
https://github.com/hail-is/hail/issues/2076#issuecomment-321255324:34,Availability,error,error,34,"The ""Arguments refer to no files"" error means that the hadoop file connector may not be working properly, but since you're able to read the file with `textFile` I'm baffled (we call sc.textFile internally to import a VCF!)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321255324
https://github.com/hail-is/hail/issues/2076#issuecomment-321265505:75,Availability,error,error,75,"Sorry to bring those troubles, is there anything I should do to locate the error?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321265505
https://github.com/hail-is/hail/issues/2076#issuecomment-321420160:2032,Availability,avail,available,2032,"""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; 17/08/10 08:41:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 17/08/10 08:41:32 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/opt/Software/hail/build/libs/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 17/08/10 08:41:32 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; 17/08/10 08:41:32 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 3.5.2 (default, Jul 12 2017 14:00:23); SparkSession available as 'spark'. In [1]: ; ```; -----------------------------; Step2 : read the file with sc.textFile; ```; In [1]: rdd = sc.textFile('/hail/test/BRCA1.raw_indel.vcf'); ```; -----------------------------; Step3, import hail and read the file with hail:; ```; In [2]: from hail import *; ---------------------------------------------------------------------------; ImportError Traceback (most recent call last); <ipython-input-2-3181c5d8fca5> in <module>(); ----> 1 from hail import *. /opt/Software/hail/python/hail/__init__.py in <module>(); ----> 1 import hail.expr; 2 from hail.representation import *; 3 from hail.context import HailContext; 4 from hail.dataset import VariantDataset; 5 from hail.expr import *. /opt/Software/hail/python/hail/expr.py in <module>(); 1 import abc; 2 from hail.java import scala_object, Env, jset; ----> 3 from hail.representation import Variant, AltAllele, Genotype, Locus, Interval, Struct, Call; 4 ; 5 . /opt/Software/hail/python/hail/represent",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321420160
https://github.com/hail-is/hail/issues/2076#issuecomment-321420160:687,Modifiability,enhance,enhanced,687,"OK, sure.; Step1 : when start pyspark with the cons; ```; [root@tele-1 ~]# PYSPARK_PYTHON=""ipython"" pyspark --conf spark.sql.files.openCostInBytes=1099511627776 --conf spark.sql.files.maxPartitionBytes=1099511627776 --conf spark.hadoop.parquet.block.size=1099511627776 --conf spark.serializer=org.apache.spark.serializer.KryoSerializer; /usr/local/lib/python3.5/site-packages/IPython/core/history.py:228: UserWarning: IPython History requires SQLite, your history will not be saved; warn(""IPython History requires SQLite, your history will not be saved""); Python 3.5.2 (default, Jul 12 2017, 14:00:23) ; Type ""copyright"", ""credits"" or ""license"" for more information. IPython 5.1.0 -- An enhanced Interactive Python.; ? -> Introduction and overview of IPython's features.; %quickref -> Quick reference.; help -> Python's own help system.; object? -> Details about 'object', use 'object??' for extra details.; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; 17/08/10 08:41:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 17/08/10 08:41:32 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/opt/Software/hail/build/libs/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 17/08/10 08:41:32 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; 17/08/10 08:41:32 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 3.5.2 (default, Jul 1",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321420160
https://github.com/hail-is/hail/issues/2076#issuecomment-321420160:1133,Performance,load,load,1133,"s.openCostInBytes=1099511627776 --conf spark.sql.files.maxPartitionBytes=1099511627776 --conf spark.hadoop.parquet.block.size=1099511627776 --conf spark.serializer=org.apache.spark.serializer.KryoSerializer; /usr/local/lib/python3.5/site-packages/IPython/core/history.py:228: UserWarning: IPython History requires SQLite, your history will not be saved; warn(""IPython History requires SQLite, your history will not be saved""); Python 3.5.2 (default, Jul 12 2017, 14:00:23) ; Type ""copyright"", ""credits"" or ""license"" for more information. IPython 5.1.0 -- An enhanced Interactive Python.; ? -> Introduction and overview of IPython's features.; %quickref -> Quick reference.; help -> Python's own help system.; object? -> Details about 'object', use 'object??' for extra details.; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; 17/08/10 08:41:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 17/08/10 08:41:32 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/opt/Software/hail/build/libs/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 17/08/10 08:41:32 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; 17/08/10 08:41:32 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 3.5.2 (default, Jul 12 2017 14:00:23); SparkSession available as 'spark'. In [1]: ; ```; -----------------------------; Step2 : read the file with sc",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321420160
https://github.com/hail-is/hail/issues/2076#issuecomment-321420160:1282,Safety,detect,detected,1282,"627776 --conf spark.serializer=org.apache.spark.serializer.KryoSerializer; /usr/local/lib/python3.5/site-packages/IPython/core/history.py:228: UserWarning: IPython History requires SQLite, your history will not be saved; warn(""IPython History requires SQLite, your history will not be saved""); Python 3.5.2 (default, Jul 12 2017, 14:00:23) ; Type ""copyright"", ""credits"" or ""license"" for more information. IPython 5.1.0 -- An enhanced Interactive Python.; ? -> Introduction and overview of IPython's features.; %quickref -> Quick reference.; help -> Python's own help system.; object? -> Details about 'object', use 'object??' for extra details.; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; 17/08/10 08:41:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 17/08/10 08:41:32 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/opt/Software/hail/build/libs/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 17/08/10 08:41:32 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; 17/08/10 08:41:32 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 3.5.2 (default, Jul 12 2017 14:00:23); SparkSession available as 'spark'. In [1]: ; ```; -----------------------------; Step2 : read the file with sc.textFile; ```; In [1]: rdd = sc.textFile('/hail/test/BRCA1.raw_indel.vcf'); ```; -----------------------------; Step3, import hail an",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321420160
https://github.com/hail-is/hail/issues/2076#issuecomment-321420160:1005,Testability,log,log,1005,"K, sure.; Step1 : when start pyspark with the cons; ```; [root@tele-1 ~]# PYSPARK_PYTHON=""ipython"" pyspark --conf spark.sql.files.openCostInBytes=1099511627776 --conf spark.sql.files.maxPartitionBytes=1099511627776 --conf spark.hadoop.parquet.block.size=1099511627776 --conf spark.serializer=org.apache.spark.serializer.KryoSerializer; /usr/local/lib/python3.5/site-packages/IPython/core/history.py:228: UserWarning: IPython History requires SQLite, your history will not be saved; warn(""IPython History requires SQLite, your history will not be saved""); Python 3.5.2 (default, Jul 12 2017, 14:00:23) ; Type ""copyright"", ""credits"" or ""license"" for more information. IPython 5.1.0 -- An enhanced Interactive Python.; ? -> Introduction and overview of IPython's features.; %quickref -> Quick reference.; help -> Python's own help system.; object? -> Details about 'object', use 'object??' for extra details.; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; 17/08/10 08:41:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 17/08/10 08:41:32 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/opt/Software/hail/build/libs/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 17/08/10 08:41:32 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; 17/08/10 08:41:32 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 3.5.2 (default, Jul 1",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321420160
https://github.com/hail-is/hail/issues/2076#issuecomment-321420160:1037,Testability,log,logging,1037,"h the cons; ```; [root@tele-1 ~]# PYSPARK_PYTHON=""ipython"" pyspark --conf spark.sql.files.openCostInBytes=1099511627776 --conf spark.sql.files.maxPartitionBytes=1099511627776 --conf spark.hadoop.parquet.block.size=1099511627776 --conf spark.serializer=org.apache.spark.serializer.KryoSerializer; /usr/local/lib/python3.5/site-packages/IPython/core/history.py:228: UserWarning: IPython History requires SQLite, your history will not be saved; warn(""IPython History requires SQLite, your history will not be saved""); Python 3.5.2 (default, Jul 12 2017, 14:00:23) ; Type ""copyright"", ""credits"" or ""license"" for more information. IPython 5.1.0 -- An enhanced Interactive Python.; ? -> Introduction and overview of IPython's features.; %quickref -> Quick reference.; help -> Python's own help system.; object? -> Details about 'object', use 'object??' for extra details.; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; 17/08/10 08:41:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 17/08/10 08:41:32 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/opt/Software/hail/build/libs/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 17/08/10 08:41:32 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; 17/08/10 08:41:32 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 3.5.2 (default, Jul 12 2017 14:00:23); SparkSession available ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321420160
https://github.com/hail-is/hail/issues/2076#issuecomment-321420160:2178,Testability,test,test,2178,"rm... using builtin-java classes where applicable; 17/08/10 08:41:32 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/opt/Software/hail/build/libs/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 17/08/10 08:41:32 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; 17/08/10 08:41:32 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 3.5.2 (default, Jul 12 2017 14:00:23); SparkSession available as 'spark'. In [1]: ; ```; -----------------------------; Step2 : read the file with sc.textFile; ```; In [1]: rdd = sc.textFile('/hail/test/BRCA1.raw_indel.vcf'); ```; -----------------------------; Step3, import hail and read the file with hail:; ```; In [2]: from hail import *; ---------------------------------------------------------------------------; ImportError Traceback (most recent call last); <ipython-input-2-3181c5d8fca5> in <module>(); ----> 1 from hail import *. /opt/Software/hail/python/hail/__init__.py in <module>(); ----> 1 import hail.expr; 2 from hail.representation import *; 3 from hail.context import HailContext; 4 from hail.dataset import VariantDataset; 5 from hail.expr import *. /opt/Software/hail/python/hail/expr.py in <module>(); 1 import abc; 2 from hail.java import scala_object, Env, jset; ----> 3 from hail.representation import Variant, AltAllele, Genotype, Locus, Interval, Struct, Call; 4 ; 5 . /opt/Software/hail/python/hail/representation/__init__.py in <module>(); ----> 1 from hail.representation.variant import Variant, Locus, AltAllele; 2 from hail.representation.interval import Interv",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321420160
https://github.com/hail-is/hail/issues/2076#issuecomment-321420160:4064,Testability,test,test,4064,"--------------------------; ImportError Traceback (most recent call last); <ipython-input-2-3181c5d8fca5> in <module>(); ----> 1 from hail import *. /opt/Software/hail/python/hail/__init__.py in <module>(); ----> 1 import hail.expr; 2 from hail.representation import *; 3 from hail.context import HailContext; 4 from hail.dataset import VariantDataset; 5 from hail.expr import *. /opt/Software/hail/python/hail/expr.py in <module>(); 1 import abc; 2 from hail.java import scala_object, Env, jset; ----> 3 from hail.representation import Variant, AltAllele, Genotype, Locus, Interval, Struct, Call; 4 ; 5 . /opt/Software/hail/python/hail/representation/__init__.py in <module>(); ----> 1 from hail.representation.variant import Variant, Locus, AltAllele; 2 from hail.representation.interval import Interval; 3 from hail.representation.genotype import Genotype, Call; 4 from hail.representation.annotations import Struct; 5 from hail.representation.pedigree import Trio, Pedigree. /opt/Software/hail/python/hail/representation/variant.py in <module>(); 1 from hail.java import scala_object, Env, handle_py4j; ----> 2 from hail.typecheck import *; 3 ; 4 class Variant(object):; 5 """""". /opt/Software/hail/python/hail/typecheck/__init__.py in <module>(); ----> 1 from check import *; 2 ; 3 __all__ = ['typecheck',; 4 'typecheck_method',; 5 'none',. ImportError: No module named 'check'. In [3]: hc = HailContext(sc); ---------------------------------------------------------------------------; NameError Traceback (most recent call last); <ipython-input-3-2e980fcce31d> in <module>(); ----> 1 hc = HailContext(sc). NameError: name 'HailContext' is not defined. In [4]: vds = hc.import_vcf('/hail/test/BRCA1.raw_indel.vcf'); ---------------------------------------------------------------------------; NameError Traceback (most recent call last); <ipython-input-4-7c2f3eb5060d> in <module>(); ----> 1 vds = hc.import_vcf('/hail/test/BRCA1.raw_indel.vcf'). NameError: name 'hc' is not defined. In [5]: ; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321420160
https://github.com/hail-is/hail/issues/2076#issuecomment-321420160:4295,Testability,test,test,4295,"--------------------------; ImportError Traceback (most recent call last); <ipython-input-2-3181c5d8fca5> in <module>(); ----> 1 from hail import *. /opt/Software/hail/python/hail/__init__.py in <module>(); ----> 1 import hail.expr; 2 from hail.representation import *; 3 from hail.context import HailContext; 4 from hail.dataset import VariantDataset; 5 from hail.expr import *. /opt/Software/hail/python/hail/expr.py in <module>(); 1 import abc; 2 from hail.java import scala_object, Env, jset; ----> 3 from hail.representation import Variant, AltAllele, Genotype, Locus, Interval, Struct, Call; 4 ; 5 . /opt/Software/hail/python/hail/representation/__init__.py in <module>(); ----> 1 from hail.representation.variant import Variant, Locus, AltAllele; 2 from hail.representation.interval import Interval; 3 from hail.representation.genotype import Genotype, Call; 4 from hail.representation.annotations import Struct; 5 from hail.representation.pedigree import Trio, Pedigree. /opt/Software/hail/python/hail/representation/variant.py in <module>(); 1 from hail.java import scala_object, Env, handle_py4j; ----> 2 from hail.typecheck import *; 3 ; 4 class Variant(object):; 5 """""". /opt/Software/hail/python/hail/typecheck/__init__.py in <module>(); ----> 1 from check import *; 2 ; 3 __all__ = ['typecheck',; 4 'typecheck_method',; 5 'none',. ImportError: No module named 'check'. In [3]: hc = HailContext(sc); ---------------------------------------------------------------------------; NameError Traceback (most recent call last); <ipython-input-3-2e980fcce31d> in <module>(); ----> 1 hc = HailContext(sc). NameError: name 'HailContext' is not defined. In [4]: vds = hc.import_vcf('/hail/test/BRCA1.raw_indel.vcf'); ---------------------------------------------------------------------------; NameError Traceback (most recent call last); <ipython-input-4-7c2f3eb5060d> in <module>(); ----> 1 vds = hc.import_vcf('/hail/test/BRCA1.raw_indel.vcf'). NameError: name 'hc' is not defined. In [5]: ; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321420160
https://github.com/hail-is/hail/issues/2076#issuecomment-321420671:32,Modifiability,variab,variable,32,or replace the `PYSPARK_PYTHON` variable to your python2 location,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321420671
https://github.com/hail-is/hail/issues/2076#issuecomment-321424071:1557,Availability,avail,available,1557,"""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; 17/08/10 09:10:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 17/08/10 09:10:21 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/opt/Software/hail/build/libs/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 17/08/10 09:10:21 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; 17/08/10 09:10:21 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; ```; ----------------------------; ```; >>> rdd = sc.textFile('/hail/test/BRCA1.raw_indel.vcf'); >>> from hail import *; >>> hc = HailContext(sc); hail: info: SparkUI: http://192.168.1.4:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.1-0320a61; ```; ----------------------------------; ```; >>> vds = hc.import_vcf('/hail/test/BRCA1.raw_indel.vcf'); hail: warning: `/hail/test/BRCA1.raw_indel.vcf' refers to no files; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-483>"", line 2, in import_vcf; File ""/opt/Software/hail/python/hail/java.py"", line 112, in handle_py4j; 'Error summary: %s' % (deepest, full, Env.hc().version, deepest)); hail.java.FatalError: HailException: arguments refer to no files. Java stack trace:; is.hail.utils.HailException: arguments refer to no files; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:6); 	at is.hail.utils.package$.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321424071
https://github.com/hail-is/hail/issues/2076#issuecomment-321424071:2240,Availability,Error,Error,2240,"ARN SparkConf: Setting 'spark.driver.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; ```; ----------------------------; ```; >>> rdd = sc.textFile('/hail/test/BRCA1.raw_indel.vcf'); >>> from hail import *; >>> hc = HailContext(sc); hail: info: SparkUI: http://192.168.1.4:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.1-0320a61; ```; ----------------------------------; ```; >>> vds = hc.import_vcf('/hail/test/BRCA1.raw_indel.vcf'); hail: warning: `/hail/test/BRCA1.raw_indel.vcf' refers to no files; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-483>"", line 2, in import_vcf; File ""/opt/Software/hail/python/hail/java.py"", line 112, in handle_py4j; 'Error summary: %s' % (deepest, full, Env.hc().version, deepest)); hail.java.FatalError: HailException: arguments refer to no files. Java stack trace:; is.hail.utils.HailException: arguments refer to no files; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:6); 	at is.hail.utils.package$.fatal(package.scala:25); 	at is.hail.io.vcf.LoadVCF$.globAllVCFs(LoadVCF.scala:105); 	at is.hail.HailContext.importVCFs(HailContext.scala:523); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321424071
https://github.com/hail-is/hail/issues/2076#issuecomment-321424071:2467,Availability,Error,ErrorHandling,2467,"2; /_/. Using Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; ```; ----------------------------; ```; >>> rdd = sc.textFile('/hail/test/BRCA1.raw_indel.vcf'); >>> from hail import *; >>> hc = HailContext(sc); hail: info: SparkUI: http://192.168.1.4:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.1-0320a61; ```; ----------------------------------; ```; >>> vds = hc.import_vcf('/hail/test/BRCA1.raw_indel.vcf'); hail: warning: `/hail/test/BRCA1.raw_indel.vcf' refers to no files; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-483>"", line 2, in import_vcf; File ""/opt/Software/hail/python/hail/java.py"", line 112, in handle_py4j; 'Error summary: %s' % (deepest, full, Env.hc().version, deepest)); hail.java.FatalError: HailException: arguments refer to no files. Java stack trace:; is.hail.utils.HailException: arguments refer to no files; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:6); 	at is.hail.utils.package$.fatal(package.scala:25); 	at is.hail.io.vcf.LoadVCF$.globAllVCFs(LoadVCF.scala:105); 	at is.hail.HailContext.importVCFs(HailContext.scala:523); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:745). Hail version: 0.1-0320a61; Error summary: HailException: arguments refer to no",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321424071
https://github.com/hail-is/hail/issues/2076#issuecomment-321424071:2493,Availability,Error,ErrorHandling,2493,"ng Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; ```; ----------------------------; ```; >>> rdd = sc.textFile('/hail/test/BRCA1.raw_indel.vcf'); >>> from hail import *; >>> hc = HailContext(sc); hail: info: SparkUI: http://192.168.1.4:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.1-0320a61; ```; ----------------------------------; ```; >>> vds = hc.import_vcf('/hail/test/BRCA1.raw_indel.vcf'); hail: warning: `/hail/test/BRCA1.raw_indel.vcf' refers to no files; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-483>"", line 2, in import_vcf; File ""/opt/Software/hail/python/hail/java.py"", line 112, in handle_py4j; 'Error summary: %s' % (deepest, full, Env.hc().version, deepest)); hail.java.FatalError: HailException: arguments refer to no files. Java stack trace:; is.hail.utils.HailException: arguments refer to no files; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:6); 	at is.hail.utils.package$.fatal(package.scala:25); 	at is.hail.io.vcf.LoadVCF$.globAllVCFs(LoadVCF.scala:105); 	at is.hail.HailContext.importVCFs(HailContext.scala:523); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:745). Hail version: 0.1-0320a61; Error summary: HailException: arguments refer to no files; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321424071
https://github.com/hail-is/hail/issues/2076#issuecomment-321424071:3426,Availability,Error,Error,3426,"ng Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; ```; ----------------------------; ```; >>> rdd = sc.textFile('/hail/test/BRCA1.raw_indel.vcf'); >>> from hail import *; >>> hc = HailContext(sc); hail: info: SparkUI: http://192.168.1.4:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.1-0320a61; ```; ----------------------------------; ```; >>> vds = hc.import_vcf('/hail/test/BRCA1.raw_indel.vcf'); hail: warning: `/hail/test/BRCA1.raw_indel.vcf' refers to no files; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-483>"", line 2, in import_vcf; File ""/opt/Software/hail/python/hail/java.py"", line 112, in handle_py4j; 'Error summary: %s' % (deepest, full, Env.hc().version, deepest)); hail.java.FatalError: HailException: arguments refer to no files. Java stack trace:; is.hail.utils.HailException: arguments refer to no files; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:6); 	at is.hail.utils.package$.fatal(package.scala:25); 	at is.hail.io.vcf.LoadVCF$.globAllVCFs(LoadVCF.scala:105); 	at is.hail.HailContext.importVCFs(HailContext.scala:523); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:745). Hail version: 0.1-0320a61; Error summary: HailException: arguments refer to no files; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321424071
https://github.com/hail-is/hail/issues/2076#issuecomment-321424071:659,Performance,load,load,659,"OK.; ```; [root@tele-1 ~]# pyspark --conf spark.sql.files.openCostInBytes=1099511627776 --conf spark.sql.files.maxPartitionBytes=1099511627776 --conf spark.hadoop.parquet.block.size=1099511627776 --conf spark.serializer=org.apache.spark.serializer.KryoSerializer; Python 2.7.5 (default, Nov 6 2016, 00:28:07) ; [GCC 4.8.5 20150623 (Red Hat 4.8.5-11)] on linux2; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; 17/08/10 09:10:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 17/08/10 09:10:21 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/opt/Software/hail/build/libs/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 17/08/10 09:10:21 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; 17/08/10 09:10:21 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; ```; ----------------------------; ```; >>> rdd = sc.textFile('/hail/test/BRCA1.raw_indel.vcf'); >>> from hail import *; >>> hc = HailContext(sc); hail: info: SparkUI: http://192.168.1.4:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.1-0320a61; ```; ----------------------------------; ```; >>> vds = hc.import_vcf('/hail/test/BRCA1.raw_indel.vcf'); hail: warning: `/hail/test/",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321424071
https://github.com/hail-is/hail/issues/2076#issuecomment-321424071:2588,Performance,Load,LoadVCF,2588,"ng Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; ```; ----------------------------; ```; >>> rdd = sc.textFile('/hail/test/BRCA1.raw_indel.vcf'); >>> from hail import *; >>> hc = HailContext(sc); hail: info: SparkUI: http://192.168.1.4:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.1-0320a61; ```; ----------------------------------; ```; >>> vds = hc.import_vcf('/hail/test/BRCA1.raw_indel.vcf'); hail: warning: `/hail/test/BRCA1.raw_indel.vcf' refers to no files; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-483>"", line 2, in import_vcf; File ""/opt/Software/hail/python/hail/java.py"", line 112, in handle_py4j; 'Error summary: %s' % (deepest, full, Env.hc().version, deepest)); hail.java.FatalError: HailException: arguments refer to no files. Java stack trace:; is.hail.utils.HailException: arguments refer to no files; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:6); 	at is.hail.utils.package$.fatal(package.scala:25); 	at is.hail.io.vcf.LoadVCF$.globAllVCFs(LoadVCF.scala:105); 	at is.hail.HailContext.importVCFs(HailContext.scala:523); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:745). Hail version: 0.1-0320a61; Error summary: HailException: arguments refer to no files; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321424071
https://github.com/hail-is/hail/issues/2076#issuecomment-321424071:2609,Performance,Load,LoadVCF,2609,"ng Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; ```; ----------------------------; ```; >>> rdd = sc.textFile('/hail/test/BRCA1.raw_indel.vcf'); >>> from hail import *; >>> hc = HailContext(sc); hail: info: SparkUI: http://192.168.1.4:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.1-0320a61; ```; ----------------------------------; ```; >>> vds = hc.import_vcf('/hail/test/BRCA1.raw_indel.vcf'); hail: warning: `/hail/test/BRCA1.raw_indel.vcf' refers to no files; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-483>"", line 2, in import_vcf; File ""/opt/Software/hail/python/hail/java.py"", line 112, in handle_py4j; 'Error summary: %s' % (deepest, full, Env.hc().version, deepest)); hail.java.FatalError: HailException: arguments refer to no files. Java stack trace:; is.hail.utils.HailException: arguments refer to no files; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:6); 	at is.hail.utils.package$.fatal(package.scala:25); 	at is.hail.io.vcf.LoadVCF$.globAllVCFs(LoadVCF.scala:105); 	at is.hail.HailContext.importVCFs(HailContext.scala:523); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:745). Hail version: 0.1-0320a61; Error summary: HailException: arguments refer to no files; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321424071
https://github.com/hail-is/hail/issues/2076#issuecomment-321424071:808,Safety,detect,detected,808,"OK.; ```; [root@tele-1 ~]# pyspark --conf spark.sql.files.openCostInBytes=1099511627776 --conf spark.sql.files.maxPartitionBytes=1099511627776 --conf spark.hadoop.parquet.block.size=1099511627776 --conf spark.serializer=org.apache.spark.serializer.KryoSerializer; Python 2.7.5 (default, Nov 6 2016, 00:28:07) ; [GCC 4.8.5 20150623 (Red Hat 4.8.5-11)] on linux2; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; 17/08/10 09:10:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 17/08/10 09:10:21 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/opt/Software/hail/build/libs/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 17/08/10 09:10:21 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; 17/08/10 09:10:21 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; ```; ----------------------------; ```; >>> rdd = sc.textFile('/hail/test/BRCA1.raw_indel.vcf'); >>> from hail import *; >>> hc = HailContext(sc); hail: info: SparkUI: http://192.168.1.4:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.1-0320a61; ```; ----------------------------------; ```; >>> vds = hc.import_vcf('/hail/test/BRCA1.raw_indel.vcf'); hail: warning: `/hail/test/",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321424071
https://github.com/hail-is/hail/issues/2076#issuecomment-321424071:531,Testability,log,log,531,"OK.; ```; [root@tele-1 ~]# pyspark --conf spark.sql.files.openCostInBytes=1099511627776 --conf spark.sql.files.maxPartitionBytes=1099511627776 --conf spark.hadoop.parquet.block.size=1099511627776 --conf spark.serializer=org.apache.spark.serializer.KryoSerializer; Python 2.7.5 (default, Nov 6 2016, 00:28:07) ; [GCC 4.8.5 20150623 (Red Hat 4.8.5-11)] on linux2; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; 17/08/10 09:10:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 17/08/10 09:10:21 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/opt/Software/hail/build/libs/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 17/08/10 09:10:21 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; 17/08/10 09:10:21 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; ```; ----------------------------; ```; >>> rdd = sc.textFile('/hail/test/BRCA1.raw_indel.vcf'); >>> from hail import *; >>> hc = HailContext(sc); hail: info: SparkUI: http://192.168.1.4:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.1-0320a61; ```; ----------------------------------; ```; >>> vds = hc.import_vcf('/hail/test/BRCA1.raw_indel.vcf'); hail: warning: `/hail/test/",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321424071
https://github.com/hail-is/hail/issues/2076#issuecomment-321424071:563,Testability,log,logging,563,"OK.; ```; [root@tele-1 ~]# pyspark --conf spark.sql.files.openCostInBytes=1099511627776 --conf spark.sql.files.maxPartitionBytes=1099511627776 --conf spark.hadoop.parquet.block.size=1099511627776 --conf spark.serializer=org.apache.spark.serializer.KryoSerializer; Python 2.7.5 (default, Nov 6 2016, 00:28:07) ; [GCC 4.8.5 20150623 (Red Hat 4.8.5-11)] on linux2; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; 17/08/10 09:10:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 17/08/10 09:10:21 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/opt/Software/hail/build/libs/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 17/08/10 09:10:21 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; 17/08/10 09:10:21 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; ```; ----------------------------; ```; >>> rdd = sc.textFile('/hail/test/BRCA1.raw_indel.vcf'); >>> from hail import *; >>> hc = HailContext(sc); hail: info: SparkUI: http://192.168.1.4:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.1-0320a61; ```; ----------------------------------; ```; >>> vds = hc.import_vcf('/hail/test/BRCA1.raw_indel.vcf'); hail: warning: `/hail/test/",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321424071
https://github.com/hail-is/hail/issues/2076#issuecomment-321424071:1649,Testability,test,test,1649,"r: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 17/08/10 09:10:21 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/opt/Software/hail/build/libs/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 17/08/10 09:10:21 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; 17/08/10 09:10:21 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; ```; ----------------------------; ```; >>> rdd = sc.textFile('/hail/test/BRCA1.raw_indel.vcf'); >>> from hail import *; >>> hc = HailContext(sc); hail: info: SparkUI: http://192.168.1.4:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.1-0320a61; ```; ----------------------------------; ```; >>> vds = hc.import_vcf('/hail/test/BRCA1.raw_indel.vcf'); hail: warning: `/hail/test/BRCA1.raw_indel.vcf' refers to no files; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-483>"", line 2, in import_vcf; File ""/opt/Software/hail/python/hail/java.py"", line 112, in handle_py4j; 'Error summary: %s' % (deepest, full, Env.hc().version, deepest)); hail.java.FatalError: HailException: arguments refer to no files. Java stack trace:; is.hail.utils.HailException: arguments refer to no files; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:6); 	at is.hail.utils.package$.fatal(package.scala:25); 	at is.hail.io.vcf.LoadVCF$.globAllVCFs(LoadVCF.scala:105); 	at is.hail.HailCo",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321424071
https://github.com/hail-is/hail/issues/2076#issuecomment-321424071:1946,Testability,test,test,1946,"k-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 17/08/10 09:10:21 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; 17/08/10 09:10:21 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; ```; ----------------------------; ```; >>> rdd = sc.textFile('/hail/test/BRCA1.raw_indel.vcf'); >>> from hail import *; >>> hc = HailContext(sc); hail: info: SparkUI: http://192.168.1.4:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.1-0320a61; ```; ----------------------------------; ```; >>> vds = hc.import_vcf('/hail/test/BRCA1.raw_indel.vcf'); hail: warning: `/hail/test/BRCA1.raw_indel.vcf' refers to no files; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-483>"", line 2, in import_vcf; File ""/opt/Software/hail/python/hail/java.py"", line 112, in handle_py4j; 'Error summary: %s' % (deepest, full, Env.hc().version, deepest)); hail.java.FatalError: HailException: arguments refer to no files. Java stack trace:; is.hail.utils.HailException: arguments refer to no files; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:6); 	at is.hail.utils.package$.fatal(package.scala:25); 	at is.hail.io.vcf.LoadVCF$.globAllVCFs(LoadVCF.scala:105); 	at is.hail.HailContext.importVCFs(HailContext.scala:523); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.re",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321424071
https://github.com/hail-is/hail/issues/2076#issuecomment-321424071:1996,Testability,test,test,1996,"the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 17/08/10 09:10:21 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; 17/08/10 09:10:21 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; ```; ----------------------------; ```; >>> rdd = sc.textFile('/hail/test/BRCA1.raw_indel.vcf'); >>> from hail import *; >>> hc = HailContext(sc); hail: info: SparkUI: http://192.168.1.4:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.1-0320a61; ```; ----------------------------------; ```; >>> vds = hc.import_vcf('/hail/test/BRCA1.raw_indel.vcf'); hail: warning: `/hail/test/BRCA1.raw_indel.vcf' refers to no files; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-483>"", line 2, in import_vcf; File ""/opt/Software/hail/python/hail/java.py"", line 112, in handle_py4j; 'Error summary: %s' % (deepest, full, Env.hc().version, deepest)); hail.java.FatalError: HailException: arguments refer to no files. Java stack trace:; is.hail.utils.HailException: arguments refer to no files; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:6); 	at is.hail.utils.package$.fatal(package.scala:25); 	at is.hail.io.vcf.LoadVCF$.globAllVCFs(LoadVCF.scala:105); 	at is.hail.HailContext.importVCFs(HailContext.scala:523); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321424071
https://github.com/hail-is/hail/issues/2076#issuecomment-322217747:81,Testability,test,test,81,"@Sun-shan Can you try starting `pyspark` and executing:. ```; sc.textFile(""/hail/test/BRCA1.raw_indel.vcf"").count(); ```. and share with us the results.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-322217747
https://github.com/hail-is/hail/issues/2076#issuecomment-322349367:1364,Availability,avail,available,1364,"""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; 17/08/15 08:58:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 17/08/15 08:58:31 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/opt/Software/hail/build/libs/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 17/08/15 08:58:31 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; 17/08/15 08:58:31 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; >>> sc.textFile(""/hail/test/BRCA1.raw_indel.vcf"").count(); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/opt/Software/spark/spark-2.0.2-bin-hadoop2.6/python/pyspark/rdd.py"", line 1008, in count; return self.mapPartitions(lambda i: [sum(1 for _ in i)]).sum(); File ""/opt/Software/spark/spark-2.0.2-bin-hadoop2.6/python/pyspark/rdd.py"", line 999, in sum; return self.mapPartitions(lambda x: [sum(x)]).fold(0, operator.add); File ""/opt/Software/spark/spark-2.0.2-bin-hadoop2.6/python/pyspark/rdd.py"", line 873, in fold; vals = self.mapPartitions(func).collect(); File ""/opt/Software/spark/spark-2.0.2-bin-hadoop2.6/python/pyspark/rdd.py"", line 776, in collect; port = self.ctx._jvm.PythonRDD.collectAndServe(self._jrdd.rdd()); File ""/opt/Software/spark/spark-2.0.2-bin-hadoop2.6/python/lib/py4j-0.10.3-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/opt/Software/spark/spark-2.0.2-bin-hadoop2.6/python/pyspark/sql/utils",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-322349367
https://github.com/hail-is/hail/issues/2076#issuecomment-322349367:2560,Availability,error,error,2560,".6/python/pyspark/rdd.py"", line 1008, in count; return self.mapPartitions(lambda i: [sum(1 for _ in i)]).sum(); File ""/opt/Software/spark/spark-2.0.2-bin-hadoop2.6/python/pyspark/rdd.py"", line 999, in sum; return self.mapPartitions(lambda x: [sum(x)]).fold(0, operator.add); File ""/opt/Software/spark/spark-2.0.2-bin-hadoop2.6/python/pyspark/rdd.py"", line 873, in fold; vals = self.mapPartitions(func).collect(); File ""/opt/Software/spark/spark-2.0.2-bin-hadoop2.6/python/pyspark/rdd.py"", line 776, in collect; port = self.ctx._jvm.PythonRDD.collectAndServe(self._jrdd.rdd()); File ""/opt/Software/spark/spark-2.0.2-bin-hadoop2.6/python/lib/py4j-0.10.3-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/opt/Software/spark/spark-2.0.2-bin-hadoop2.6/python/pyspark/sql/utils.py"", line 63, in deco; return f(*a, **kw); File ""/opt/Software/spark/spark-2.0.2-bin-hadoop2.6/python/lib/py4j-0.10.3-src.zip/py4j/protocol.py"", line 319, in get_return_value; py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.; : org.apache.hadoop.mapred.InvalidInputException: Input path does not exist: file:/hail/test/BRCA1.raw_indel.vcf; 	at org.apache.hadoop.mapred.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:285); 	at org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:228); 	at org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:313); 	at org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:199); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246); 	at scala.Option.getOrElse(Option.scala:121); 	at org.apache.spark.rdd.RDD.partitions(RDD.scala:246); 	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-322349367
https://github.com/hail-is/hail/issues/2076#issuecomment-322349367:2483,Integrability,protocol,protocol,2483,"ile ""<stdin>"", line 1, in <module>; File ""/opt/Software/spark/spark-2.0.2-bin-hadoop2.6/python/pyspark/rdd.py"", line 1008, in count; return self.mapPartitions(lambda i: [sum(1 for _ in i)]).sum(); File ""/opt/Software/spark/spark-2.0.2-bin-hadoop2.6/python/pyspark/rdd.py"", line 999, in sum; return self.mapPartitions(lambda x: [sum(x)]).fold(0, operator.add); File ""/opt/Software/spark/spark-2.0.2-bin-hadoop2.6/python/pyspark/rdd.py"", line 873, in fold; vals = self.mapPartitions(func).collect(); File ""/opt/Software/spark/spark-2.0.2-bin-hadoop2.6/python/pyspark/rdd.py"", line 776, in collect; port = self.ctx._jvm.PythonRDD.collectAndServe(self._jrdd.rdd()); File ""/opt/Software/spark/spark-2.0.2-bin-hadoop2.6/python/lib/py4j-0.10.3-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/opt/Software/spark/spark-2.0.2-bin-hadoop2.6/python/pyspark/sql/utils.py"", line 63, in deco; return f(*a, **kw); File ""/opt/Software/spark/spark-2.0.2-bin-hadoop2.6/python/lib/py4j-0.10.3-src.zip/py4j/protocol.py"", line 319, in get_return_value; py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.; : org.apache.hadoop.mapred.InvalidInputException: Input path does not exist: file:/hail/test/BRCA1.raw_indel.vcf; 	at org.apache.hadoop.mapred.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:285); 	at org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:228); 	at org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:313); 	at org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:199); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246); 	at scala.Option.getOrElse(Option.scala:121); 	at org.apache.spark.rdd.RDD.partitions(RDD.scala:246); 	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-322349367
https://github.com/hail-is/hail/issues/2076#issuecomment-322349367:2533,Integrability,protocol,protocol,2533,"e/spark/spark-2.0.2-bin-hadoop2.6/python/pyspark/rdd.py"", line 1008, in count; return self.mapPartitions(lambda i: [sum(1 for _ in i)]).sum(); File ""/opt/Software/spark/spark-2.0.2-bin-hadoop2.6/python/pyspark/rdd.py"", line 999, in sum; return self.mapPartitions(lambda x: [sum(x)]).fold(0, operator.add); File ""/opt/Software/spark/spark-2.0.2-bin-hadoop2.6/python/pyspark/rdd.py"", line 873, in fold; vals = self.mapPartitions(func).collect(); File ""/opt/Software/spark/spark-2.0.2-bin-hadoop2.6/python/pyspark/rdd.py"", line 776, in collect; port = self.ctx._jvm.PythonRDD.collectAndServe(self._jrdd.rdd()); File ""/opt/Software/spark/spark-2.0.2-bin-hadoop2.6/python/lib/py4j-0.10.3-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/opt/Software/spark/spark-2.0.2-bin-hadoop2.6/python/pyspark/sql/utils.py"", line 63, in deco; return f(*a, **kw); File ""/opt/Software/spark/spark-2.0.2-bin-hadoop2.6/python/lib/py4j-0.10.3-src.zip/py4j/protocol.py"", line 319, in get_return_value; py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.; : org.apache.hadoop.mapred.InvalidInputException: Input path does not exist: file:/hail/test/BRCA1.raw_indel.vcf; 	at org.apache.hadoop.mapred.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:285); 	at org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:228); 	at org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:313); 	at org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:199); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246); 	at scala.Option.getOrElse(Option.scala:121); 	at org.apache.spark.rdd.RDD.partitions(RDD.scala:246); 	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248); 	at org.apache.spark.rdd.RDD$$anonfun$p",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-322349367
https://github.com/hail-is/hail/issues/2076#issuecomment-322349367:466,Performance,load,load,466,"Hi, danking, the result is as follows:; ```; [root@tele-1 ~]# pyspark; Python 2.7.5 (default, Nov 6 2016, 00:28:07) ; [GCC 4.8.5 20150623 (Red Hat 4.8.5-11)] on linux2; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; 17/08/15 08:58:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 17/08/15 08:58:31 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/opt/Software/hail/build/libs/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 17/08/15 08:58:31 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; 17/08/15 08:58:31 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; >>> sc.textFile(""/hail/test/BRCA1.raw_indel.vcf"").count(); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/opt/Software/spark/spark-2.0.2-bin-hadoop2.6/python/pyspark/rdd.py"", line 1008, in count; return self.mapPartitions(lambda i: [sum(1 for _ in i)]).sum(); File ""/opt/Software/spark/spark-2.0.2-bin-hadoop2.6/python/pyspark/rdd.py"", line 999, in sum; return self.mapPartitions(lambda x: [sum(x)]).fold(0, operator.add); File ""/opt/Software/spark/spark-2.0.2-bin-hadoop2.6/python/pyspark/rdd.py"", line 873, in fold; vals = self.mapPartitions(func).collect(); File ""/opt/Software/",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-322349367
https://github.com/hail-is/hail/issues/2076#issuecomment-322349367:615,Safety,detect,detected,615,"Hi, danking, the result is as follows:; ```; [root@tele-1 ~]# pyspark; Python 2.7.5 (default, Nov 6 2016, 00:28:07) ; [GCC 4.8.5 20150623 (Red Hat 4.8.5-11)] on linux2; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; 17/08/15 08:58:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 17/08/15 08:58:31 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/opt/Software/hail/build/libs/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 17/08/15 08:58:31 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; 17/08/15 08:58:31 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; >>> sc.textFile(""/hail/test/BRCA1.raw_indel.vcf"").count(); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/opt/Software/spark/spark-2.0.2-bin-hadoop2.6/python/pyspark/rdd.py"", line 1008, in count; return self.mapPartitions(lambda i: [sum(1 for _ in i)]).sum(); File ""/opt/Software/spark/spark-2.0.2-bin-hadoop2.6/python/pyspark/rdd.py"", line 999, in sum; return self.mapPartitions(lambda x: [sum(x)]).fold(0, operator.add); File ""/opt/Software/spark/spark-2.0.2-bin-hadoop2.6/python/pyspark/rdd.py"", line 873, in fold; vals = self.mapPartitions(func).collect(); File ""/opt/Software/",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-322349367
https://github.com/hail-is/hail/issues/2076#issuecomment-322349367:338,Testability,log,log,338,"Hi, danking, the result is as follows:; ```; [root@tele-1 ~]# pyspark; Python 2.7.5 (default, Nov 6 2016, 00:28:07) ; [GCC 4.8.5 20150623 (Red Hat 4.8.5-11)] on linux2; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; 17/08/15 08:58:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 17/08/15 08:58:31 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/opt/Software/hail/build/libs/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 17/08/15 08:58:31 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; 17/08/15 08:58:31 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; >>> sc.textFile(""/hail/test/BRCA1.raw_indel.vcf"").count(); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/opt/Software/spark/spark-2.0.2-bin-hadoop2.6/python/pyspark/rdd.py"", line 1008, in count; return self.mapPartitions(lambda i: [sum(1 for _ in i)]).sum(); File ""/opt/Software/spark/spark-2.0.2-bin-hadoop2.6/python/pyspark/rdd.py"", line 999, in sum; return self.mapPartitions(lambda x: [sum(x)]).fold(0, operator.add); File ""/opt/Software/spark/spark-2.0.2-bin-hadoop2.6/python/pyspark/rdd.py"", line 873, in fold; vals = self.mapPartitions(func).collect(); File ""/opt/Software/",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-322349367
https://github.com/hail-is/hail/issues/2076#issuecomment-322349367:370,Testability,log,logging,370,"Hi, danking, the result is as follows:; ```; [root@tele-1 ~]# pyspark; Python 2.7.5 (default, Nov 6 2016, 00:28:07) ; [GCC 4.8.5 20150623 (Red Hat 4.8.5-11)] on linux2; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; 17/08/15 08:58:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 17/08/15 08:58:31 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/opt/Software/hail/build/libs/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 17/08/15 08:58:31 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; 17/08/15 08:58:31 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; >>> sc.textFile(""/hail/test/BRCA1.raw_indel.vcf"").count(); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/opt/Software/spark/spark-2.0.2-bin-hadoop2.6/python/pyspark/rdd.py"", line 1008, in count; return self.mapPartitions(lambda i: [sum(1 for _ in i)]).sum(); File ""/opt/Software/spark/spark-2.0.2-bin-hadoop2.6/python/pyspark/rdd.py"", line 999, in sum; return self.mapPartitions(lambda x: [sum(x)]).fold(0, operator.add); File ""/opt/Software/spark/spark-2.0.2-bin-hadoop2.6/python/pyspark/rdd.py"", line 873, in fold; vals = self.mapPartitions(func).collect(); File ""/opt/Software/",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-322349367
https://github.com/hail-is/hail/issues/2076#issuecomment-322349367:1410,Testability,test,test,1410,"evel).; 17/08/15 08:58:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 17/08/15 08:58:31 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/opt/Software/hail/build/libs/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 17/08/15 08:58:31 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; 17/08/15 08:58:31 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; >>> sc.textFile(""/hail/test/BRCA1.raw_indel.vcf"").count(); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/opt/Software/spark/spark-2.0.2-bin-hadoop2.6/python/pyspark/rdd.py"", line 1008, in count; return self.mapPartitions(lambda i: [sum(1 for _ in i)]).sum(); File ""/opt/Software/spark/spark-2.0.2-bin-hadoop2.6/python/pyspark/rdd.py"", line 999, in sum; return self.mapPartitions(lambda x: [sum(x)]).fold(0, operator.add); File ""/opt/Software/spark/spark-2.0.2-bin-hadoop2.6/python/pyspark/rdd.py"", line 873, in fold; vals = self.mapPartitions(func).collect(); File ""/opt/Software/spark/spark-2.0.2-bin-hadoop2.6/python/pyspark/rdd.py"", line 776, in collect; port = self.ctx._jvm.PythonRDD.collectAndServe(self._jrdd.rdd()); File ""/opt/Software/spark/spark-2.0.2-bin-hadoop2.6/python/lib/py4j-0.10.3-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/opt/Software/spark/spark-2.0.2-bin-hadoop2.6/python/pyspark/sql/utils.py"", line 63, in deco; return f(*a, **kw); File ""/opt/So",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-322349367
https://github.com/hail-is/hail/issues/2076#issuecomment-322349367:2735,Testability,test,test,2735,"k-2.0.2-bin-hadoop2.6/python/pyspark/rdd.py"", line 999, in sum; return self.mapPartitions(lambda x: [sum(x)]).fold(0, operator.add); File ""/opt/Software/spark/spark-2.0.2-bin-hadoop2.6/python/pyspark/rdd.py"", line 873, in fold; vals = self.mapPartitions(func).collect(); File ""/opt/Software/spark/spark-2.0.2-bin-hadoop2.6/python/pyspark/rdd.py"", line 776, in collect; port = self.ctx._jvm.PythonRDD.collectAndServe(self._jrdd.rdd()); File ""/opt/Software/spark/spark-2.0.2-bin-hadoop2.6/python/lib/py4j-0.10.3-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/opt/Software/spark/spark-2.0.2-bin-hadoop2.6/python/pyspark/sql/utils.py"", line 63, in deco; return f(*a, **kw); File ""/opt/Software/spark/spark-2.0.2-bin-hadoop2.6/python/lib/py4j-0.10.3-src.zip/py4j/protocol.py"", line 319, in get_return_value; py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.; : org.apache.hadoop.mapred.InvalidInputException: Input path does not exist: file:/hail/test/BRCA1.raw_indel.vcf; 	at org.apache.hadoop.mapred.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:285); 	at org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:228); 	at org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:313); 	at org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:199); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246); 	at scala.Option.getOrElse(Option.scala:121); 	at org.apache.spark.rdd.RDD.partitions(RDD.scala:246); 	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:248); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:246); 	at scala.Option.getOrElse(Option.scala:121); 	at org.apache.spark.rdd.RDD.partitions(RDD.scala:246); 	at org.apache.spark.api.python.Pyth",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-322349367
https://github.com/hail-is/hail/issues/2076#issuecomment-322539635:27,Availability,error,error,27,"@Sun-shan According to the error message you posted, Spark itself cannot find `/hail/test/BRCA1.raw_indel.vcf`:; ```; py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.; : org.apache.hadoop.mapred.InvalidInputException: Input path does not exist: file:/hail/test/BRCA1.raw_indel.vcf; ```. Looking at that error message, it looks like Spark is interpreting your path as a local file system path, _not_ a hadoop path. Moreover, earlier in your posted output this line:; ```; 17/08/15 08:58:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; ```; suggests that you're not actually connecting to a Spark cluster with a properly configured Hadoop installation. ---. Your Spark cluster appears improperly configured. I'm not sure if `pyspark` is even connecting to your cluster. You might try looking at [this StackOverflow post](https://stackoverflow.com/questions/34642292/cant-connect-pyspark-to-master) about connecting `pyspark` to a Spark cluster. I strongly recommend running `pyspark` again and executing:; ```; spark.sparkContext.master; ```; This should print the URL of your Spark master node. If this prints a String starting with `local`, then you're definitely not connecting to a Spark cluster.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-322539635
https://github.com/hail-is/hail/issues/2076#issuecomment-322539635:150,Availability,error,error,150,"@Sun-shan According to the error message you posted, Spark itself cannot find `/hail/test/BRCA1.raw_indel.vcf`:; ```; py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.; : org.apache.hadoop.mapred.InvalidInputException: Input path does not exist: file:/hail/test/BRCA1.raw_indel.vcf; ```. Looking at that error message, it looks like Spark is interpreting your path as a local file system path, _not_ a hadoop path. Moreover, earlier in your posted output this line:; ```; 17/08/15 08:58:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; ```; suggests that you're not actually connecting to a Spark cluster with a properly configured Hadoop installation. ---. Your Spark cluster appears improperly configured. I'm not sure if `pyspark` is even connecting to your cluster. You might try looking at [this StackOverflow post](https://stackoverflow.com/questions/34642292/cant-connect-pyspark-to-master) about connecting `pyspark` to a Spark cluster. I strongly recommend running `pyspark` again and executing:; ```; spark.sparkContext.master; ```; This should print the URL of your Spark master node. If this prints a String starting with `local`, then you're definitely not connecting to a Spark cluster.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-322539635
https://github.com/hail-is/hail/issues/2076#issuecomment-322539635:372,Availability,error,error,372,"@Sun-shan According to the error message you posted, Spark itself cannot find `/hail/test/BRCA1.raw_indel.vcf`:; ```; py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.; : org.apache.hadoop.mapred.InvalidInputException: Input path does not exist: file:/hail/test/BRCA1.raw_indel.vcf; ```. Looking at that error message, it looks like Spark is interpreting your path as a local file system path, _not_ a hadoop path. Moreover, earlier in your posted output this line:; ```; 17/08/15 08:58:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; ```; suggests that you're not actually connecting to a Spark cluster with a properly configured Hadoop installation. ---. Your Spark cluster appears improperly configured. I'm not sure if `pyspark` is even connecting to your cluster. You might try looking at [this StackOverflow post](https://stackoverflow.com/questions/34642292/cant-connect-pyspark-to-master) about connecting `pyspark` to a Spark cluster. I strongly recommend running `pyspark` again and executing:; ```; spark.sparkContext.master; ```; This should print the URL of your Spark master node. If this prints a String starting with `local`, then you're definitely not connecting to a Spark cluster.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-322539635
https://github.com/hail-is/hail/issues/2076#issuecomment-322539635:787,Deployability,install,installation,787,"@Sun-shan According to the error message you posted, Spark itself cannot find `/hail/test/BRCA1.raw_indel.vcf`:; ```; py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.; : org.apache.hadoop.mapred.InvalidInputException: Input path does not exist: file:/hail/test/BRCA1.raw_indel.vcf; ```. Looking at that error message, it looks like Spark is interpreting your path as a local file system path, _not_ a hadoop path. Moreover, earlier in your posted output this line:; ```; 17/08/15 08:58:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; ```; suggests that you're not actually connecting to a Spark cluster with a properly configured Hadoop installation. ---. Your Spark cluster appears improperly configured. I'm not sure if `pyspark` is even connecting to your cluster. You might try looking at [this StackOverflow post](https://stackoverflow.com/questions/34642292/cant-connect-pyspark-to-master) about connecting `pyspark` to a Spark cluster. I strongly recommend running `pyspark` again and executing:; ```; spark.sparkContext.master; ```; This should print the URL of your Spark master node. If this prints a String starting with `local`, then you're definitely not connecting to a Spark cluster.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-322539635
https://github.com/hail-is/hail/issues/2076#issuecomment-322539635:33,Integrability,message,message,33,"@Sun-shan According to the error message you posted, Spark itself cannot find `/hail/test/BRCA1.raw_indel.vcf`:; ```; py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.; : org.apache.hadoop.mapred.InvalidInputException: Input path does not exist: file:/hail/test/BRCA1.raw_indel.vcf; ```. Looking at that error message, it looks like Spark is interpreting your path as a local file system path, _not_ a hadoop path. Moreover, earlier in your posted output this line:; ```; 17/08/15 08:58:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; ```; suggests that you're not actually connecting to a Spark cluster with a properly configured Hadoop installation. ---. Your Spark cluster appears improperly configured. I'm not sure if `pyspark` is even connecting to your cluster. You might try looking at [this StackOverflow post](https://stackoverflow.com/questions/34642292/cant-connect-pyspark-to-master) about connecting `pyspark` to a Spark cluster. I strongly recommend running `pyspark` again and executing:; ```; spark.sparkContext.master; ```; This should print the URL of your Spark master node. If this prints a String starting with `local`, then you're definitely not connecting to a Spark cluster.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-322539635
https://github.com/hail-is/hail/issues/2076#issuecomment-322539635:123,Integrability,protocol,protocol,123,"@Sun-shan According to the error message you posted, Spark itself cannot find `/hail/test/BRCA1.raw_indel.vcf`:; ```; py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.; : org.apache.hadoop.mapred.InvalidInputException: Input path does not exist: file:/hail/test/BRCA1.raw_indel.vcf; ```. Looking at that error message, it looks like Spark is interpreting your path as a local file system path, _not_ a hadoop path. Moreover, earlier in your posted output this line:; ```; 17/08/15 08:58:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; ```; suggests that you're not actually connecting to a Spark cluster with a properly configured Hadoop installation. ---. Your Spark cluster appears improperly configured. I'm not sure if `pyspark` is even connecting to your cluster. You might try looking at [this StackOverflow post](https://stackoverflow.com/questions/34642292/cant-connect-pyspark-to-master) about connecting `pyspark` to a Spark cluster. I strongly recommend running `pyspark` again and executing:; ```; spark.sparkContext.master; ```; This should print the URL of your Spark master node. If this prints a String starting with `local`, then you're definitely not connecting to a Spark cluster.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-322539635
https://github.com/hail-is/hail/issues/2076#issuecomment-322539635:378,Integrability,message,message,378,"@Sun-shan According to the error message you posted, Spark itself cannot find `/hail/test/BRCA1.raw_indel.vcf`:; ```; py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.; : org.apache.hadoop.mapred.InvalidInputException: Input path does not exist: file:/hail/test/BRCA1.raw_indel.vcf; ```. Looking at that error message, it looks like Spark is interpreting your path as a local file system path, _not_ a hadoop path. Moreover, earlier in your posted output this line:; ```; 17/08/15 08:58:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; ```; suggests that you're not actually connecting to a Spark cluster with a properly configured Hadoop installation. ---. Your Spark cluster appears improperly configured. I'm not sure if `pyspark` is even connecting to your cluster. You might try looking at [this StackOverflow post](https://stackoverflow.com/questions/34642292/cant-connect-pyspark-to-master) about connecting `pyspark` to a Spark cluster. I strongly recommend running `pyspark` again and executing:; ```; spark.sparkContext.master; ```; This should print the URL of your Spark master node. If this prints a String starting with `local`, then you're definitely not connecting to a Spark cluster.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-322539635
https://github.com/hail-is/hail/issues/2076#issuecomment-322539635:769,Modifiability,config,configured,769,"@Sun-shan According to the error message you posted, Spark itself cannot find `/hail/test/BRCA1.raw_indel.vcf`:; ```; py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.; : org.apache.hadoop.mapred.InvalidInputException: Input path does not exist: file:/hail/test/BRCA1.raw_indel.vcf; ```. Looking at that error message, it looks like Spark is interpreting your path as a local file system path, _not_ a hadoop path. Moreover, earlier in your posted output this line:; ```; 17/08/15 08:58:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; ```; suggests that you're not actually connecting to a Spark cluster with a properly configured Hadoop installation. ---. Your Spark cluster appears improperly configured. I'm not sure if `pyspark` is even connecting to your cluster. You might try looking at [this StackOverflow post](https://stackoverflow.com/questions/34642292/cant-connect-pyspark-to-master) about connecting `pyspark` to a Spark cluster. I strongly recommend running `pyspark` again and executing:; ```; spark.sparkContext.master; ```; This should print the URL of your Spark master node. If this prints a String starting with `local`, then you're definitely not connecting to a Spark cluster.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-322539635
https://github.com/hail-is/hail/issues/2076#issuecomment-322539635:844,Modifiability,config,configured,844,"@Sun-shan According to the error message you posted, Spark itself cannot find `/hail/test/BRCA1.raw_indel.vcf`:; ```; py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.; : org.apache.hadoop.mapred.InvalidInputException: Input path does not exist: file:/hail/test/BRCA1.raw_indel.vcf; ```. Looking at that error message, it looks like Spark is interpreting your path as a local file system path, _not_ a hadoop path. Moreover, earlier in your posted output this line:; ```; 17/08/15 08:58:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; ```; suggests that you're not actually connecting to a Spark cluster with a properly configured Hadoop installation. ---. Your Spark cluster appears improperly configured. I'm not sure if `pyspark` is even connecting to your cluster. You might try looking at [this StackOverflow post](https://stackoverflow.com/questions/34642292/cant-connect-pyspark-to-master) about connecting `pyspark` to a Spark cluster. I strongly recommend running `pyspark` again and executing:; ```; spark.sparkContext.master; ```; This should print the URL of your Spark master node. If this prints a String starting with `local`, then you're definitely not connecting to a Spark cluster.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-322539635
https://github.com/hail-is/hail/issues/2076#issuecomment-322539635:591,Performance,load,load,591,"@Sun-shan According to the error message you posted, Spark itself cannot find `/hail/test/BRCA1.raw_indel.vcf`:; ```; py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.; : org.apache.hadoop.mapred.InvalidInputException: Input path does not exist: file:/hail/test/BRCA1.raw_indel.vcf; ```. Looking at that error message, it looks like Spark is interpreting your path as a local file system path, _not_ a hadoop path. Moreover, earlier in your posted output this line:; ```; 17/08/15 08:58:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; ```; suggests that you're not actually connecting to a Spark cluster with a properly configured Hadoop installation. ---. Your Spark cluster appears improperly configured. I'm not sure if `pyspark` is even connecting to your cluster. You might try looking at [this StackOverflow post](https://stackoverflow.com/questions/34642292/cant-connect-pyspark-to-master) about connecting `pyspark` to a Spark cluster. I strongly recommend running `pyspark` again and executing:; ```; spark.sparkContext.master; ```; This should print the URL of your Spark master node. If this prints a String starting with `local`, then you're definitely not connecting to a Spark cluster.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-322539635
https://github.com/hail-is/hail/issues/2076#issuecomment-322539635:85,Testability,test,test,85,"@Sun-shan According to the error message you posted, Spark itself cannot find `/hail/test/BRCA1.raw_indel.vcf`:; ```; py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.; : org.apache.hadoop.mapred.InvalidInputException: Input path does not exist: file:/hail/test/BRCA1.raw_indel.vcf; ```. Looking at that error message, it looks like Spark is interpreting your path as a local file system path, _not_ a hadoop path. Moreover, earlier in your posted output this line:; ```; 17/08/15 08:58:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; ```; suggests that you're not actually connecting to a Spark cluster with a properly configured Hadoop installation. ---. Your Spark cluster appears improperly configured. I'm not sure if `pyspark` is even connecting to your cluster. You might try looking at [this StackOverflow post](https://stackoverflow.com/questions/34642292/cant-connect-pyspark-to-master) about connecting `pyspark` to a Spark cluster. I strongly recommend running `pyspark` again and executing:; ```; spark.sparkContext.master; ```; This should print the URL of your Spark master node. If this prints a String starting with `local`, then you're definitely not connecting to a Spark cluster.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-322539635
https://github.com/hail-is/hail/issues/2076#issuecomment-322539635:325,Testability,test,test,325,"@Sun-shan According to the error message you posted, Spark itself cannot find `/hail/test/BRCA1.raw_indel.vcf`:; ```; py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.; : org.apache.hadoop.mapred.InvalidInputException: Input path does not exist: file:/hail/test/BRCA1.raw_indel.vcf; ```. Looking at that error message, it looks like Spark is interpreting your path as a local file system path, _not_ a hadoop path. Moreover, earlier in your posted output this line:; ```; 17/08/15 08:58:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; ```; suggests that you're not actually connecting to a Spark cluster with a properly configured Hadoop installation. ---. Your Spark cluster appears improperly configured. I'm not sure if `pyspark` is even connecting to your cluster. You might try looking at [this StackOverflow post](https://stackoverflow.com/questions/34642292/cant-connect-pyspark-to-master) about connecting `pyspark` to a Spark cluster. I strongly recommend running `pyspark` again and executing:; ```; spark.sparkContext.master; ```; This should print the URL of your Spark master node. If this prints a String starting with `local`, then you're definitely not connecting to a Spark cluster.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-322539635
https://github.com/hail-is/hail/issues/2076#issuecomment-336722486:960,Availability,avail,available,960,"Hi, @danking ; I reconfigurated the spark cluster, with the cloudera spark : version 2.2.0.cloudera1; But I can't import hail this time, How can I fix it?. The test:; ```; >>> spark.sparkContext.master; u'yarn'. bash-4.2$ pyspark; WARNING: User-defined SPARK_HOME (/opt/cloudera/parcels/SPARK2-2.2.0.cloudera1-1.cdh5.12.0.p0.142354/lib/spark2) overrides detected (/opt/cloudera/parcels/SPARK2/lib/spark2).; WARNING: Running pyspark from user-defined location.; Python 2.7.5 (default, Nov 6 2016, 00:28:07) ; [GCC 4.8.5 20150623 (Red Hat 4.8.5-11)] on linux2; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.2.0.cloudera1; /_/. Using Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; >>> spark.sparkContext.master; u'yarn'; >>> import hail; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/opt/Software/hail/python/hail/__init__.py"", line 1, in <module>; import hail.expr; File ""/opt/Software/hail/python/hail/expr.py"", line 3, in <module>; from hail.representation import Variant, AltAllele, Genotype, Locus, Interval, Struct, Call; File ""/opt/Software/hail/python/hail/representation/__init__.py"", line 1, in <module>; from hail.representation.variant import Variant, Locus, AltAllele; File ""/opt/Software/hail/python/hail/representation/variant.py"", line 2, in <module>; from hail.typecheck import *; File ""/opt/Software/hail/python/hail/typecheck/__init__.py"", line 1, in <module>; from check import *; File ""/opt/Software/hail/python/hail/typecheck/check.py"", line 1, in <module>; from decorator import decorator, getargspec; ImportError: cannot import name getargspec; >>> ; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-336722486
https://github.com/hail-is/hail/issues/2076#issuecomment-336722486:354,Safety,detect,detected,354,"Hi, @danking ; I reconfigurated the spark cluster, with the cloudera spark : version 2.2.0.cloudera1; But I can't import hail this time, How can I fix it?. The test:; ```; >>> spark.sparkContext.master; u'yarn'. bash-4.2$ pyspark; WARNING: User-defined SPARK_HOME (/opt/cloudera/parcels/SPARK2-2.2.0.cloudera1-1.cdh5.12.0.p0.142354/lib/spark2) overrides detected (/opt/cloudera/parcels/SPARK2/lib/spark2).; WARNING: Running pyspark from user-defined location.; Python 2.7.5 (default, Nov 6 2016, 00:28:07) ; [GCC 4.8.5 20150623 (Red Hat 4.8.5-11)] on linux2; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.2.0.cloudera1; /_/. Using Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; >>> spark.sparkContext.master; u'yarn'; >>> import hail; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/opt/Software/hail/python/hail/__init__.py"", line 1, in <module>; import hail.expr; File ""/opt/Software/hail/python/hail/expr.py"", line 3, in <module>; from hail.representation import Variant, AltAllele, Genotype, Locus, Interval, Struct, Call; File ""/opt/Software/hail/python/hail/representation/__init__.py"", line 1, in <module>; from hail.representation.variant import Variant, Locus, AltAllele; File ""/opt/Software/hail/python/hail/representation/variant.py"", line 2, in <module>; from hail.typecheck import *; File ""/opt/Software/hail/python/hail/typecheck/__init__.py"", line 1, in <module>; from check import *; File ""/opt/Software/hail/python/hail/typecheck/check.py"", line 1, in <module>; from decorator import decorator, getargspec; ImportError: cannot import name getargspec; >>> ; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-336722486
https://github.com/hail-is/hail/issues/2076#issuecomment-336722486:160,Testability,test,test,160,"Hi, @danking ; I reconfigurated the spark cluster, with the cloudera spark : version 2.2.0.cloudera1; But I can't import hail this time, How can I fix it?. The test:; ```; >>> spark.sparkContext.master; u'yarn'. bash-4.2$ pyspark; WARNING: User-defined SPARK_HOME (/opt/cloudera/parcels/SPARK2-2.2.0.cloudera1-1.cdh5.12.0.p0.142354/lib/spark2) overrides detected (/opt/cloudera/parcels/SPARK2/lib/spark2).; WARNING: Running pyspark from user-defined location.; Python 2.7.5 (default, Nov 6 2016, 00:28:07) ; [GCC 4.8.5 20150623 (Red Hat 4.8.5-11)] on linux2; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.2.0.cloudera1; /_/. Using Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; >>> spark.sparkContext.master; u'yarn'; >>> import hail; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/opt/Software/hail/python/hail/__init__.py"", line 1, in <module>; import hail.expr; File ""/opt/Software/hail/python/hail/expr.py"", line 3, in <module>; from hail.representation import Variant, AltAllele, Genotype, Locus, Interval, Struct, Call; File ""/opt/Software/hail/python/hail/representation/__init__.py"", line 1, in <module>; from hail.representation.variant import Variant, Locus, AltAllele; File ""/opt/Software/hail/python/hail/representation/variant.py"", line 2, in <module>; from hail.typecheck import *; File ""/opt/Software/hail/python/hail/typecheck/__init__.py"", line 1, in <module>; from check import *; File ""/opt/Software/hail/python/hail/typecheck/check.py"", line 1, in <module>; from decorator import decorator, getargspec; ImportError: cannot import name getargspec; >>> ; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-336722486
https://github.com/hail-is/hail/issues/2076#issuecomment-336722486:647,Testability,log,log,647,"Hi, @danking ; I reconfigurated the spark cluster, with the cloudera spark : version 2.2.0.cloudera1; But I can't import hail this time, How can I fix it?. The test:; ```; >>> spark.sparkContext.master; u'yarn'. bash-4.2$ pyspark; WARNING: User-defined SPARK_HOME (/opt/cloudera/parcels/SPARK2-2.2.0.cloudera1-1.cdh5.12.0.p0.142354/lib/spark2) overrides detected (/opt/cloudera/parcels/SPARK2/lib/spark2).; WARNING: Running pyspark from user-defined location.; Python 2.7.5 (default, Nov 6 2016, 00:28:07) ; [GCC 4.8.5 20150623 (Red Hat 4.8.5-11)] on linux2; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.2.0.cloudera1; /_/. Using Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; >>> spark.sparkContext.master; u'yarn'; >>> import hail; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/opt/Software/hail/python/hail/__init__.py"", line 1, in <module>; import hail.expr; File ""/opt/Software/hail/python/hail/expr.py"", line 3, in <module>; from hail.representation import Variant, AltAllele, Genotype, Locus, Interval, Struct, Call; File ""/opt/Software/hail/python/hail/representation/__init__.py"", line 1, in <module>; from hail.representation.variant import Variant, Locus, AltAllele; File ""/opt/Software/hail/python/hail/representation/variant.py"", line 2, in <module>; from hail.typecheck import *; File ""/opt/Software/hail/python/hail/typecheck/__init__.py"", line 1, in <module>; from check import *; File ""/opt/Software/hail/python/hail/typecheck/check.py"", line 1, in <module>; from decorator import decorator, getargspec; ImportError: cannot import name getargspec; >>> ; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-336722486
https://github.com/hail-is/hail/issues/2076#issuecomment-336722486:679,Testability,log,logging,679,"Hi, @danking ; I reconfigurated the spark cluster, with the cloudera spark : version 2.2.0.cloudera1; But I can't import hail this time, How can I fix it?. The test:; ```; >>> spark.sparkContext.master; u'yarn'. bash-4.2$ pyspark; WARNING: User-defined SPARK_HOME (/opt/cloudera/parcels/SPARK2-2.2.0.cloudera1-1.cdh5.12.0.p0.142354/lib/spark2) overrides detected (/opt/cloudera/parcels/SPARK2/lib/spark2).; WARNING: Running pyspark from user-defined location.; Python 2.7.5 (default, Nov 6 2016, 00:28:07) ; [GCC 4.8.5 20150623 (Red Hat 4.8.5-11)] on linux2; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.2.0.cloudera1; /_/. Using Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; >>> spark.sparkContext.master; u'yarn'; >>> import hail; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/opt/Software/hail/python/hail/__init__.py"", line 1, in <module>; import hail.expr; File ""/opt/Software/hail/python/hail/expr.py"", line 3, in <module>; from hail.representation import Variant, AltAllele, Genotype, Locus, Interval, Struct, Call; File ""/opt/Software/hail/python/hail/representation/__init__.py"", line 1, in <module>; from hail.representation.variant import Variant, Locus, AltAllele; File ""/opt/Software/hail/python/hail/representation/variant.py"", line 2, in <module>; from hail.typecheck import *; File ""/opt/Software/hail/python/hail/typecheck/__init__.py"", line 1, in <module>; from check import *; File ""/opt/Software/hail/python/hail/typecheck/check.py"", line 1, in <module>; from decorator import decorator, getargspec; ImportError: cannot import name getargspec; >>> ; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-336722486
https://github.com/hail-is/hail/issues/2076#issuecomment-336903534:166,Availability,error,error,166,"Hi @Sun-shan,. First, I should note that we do not currently test hail against Spark version 2.2.0, I recommend using Spark 2.1.1 or 2.0.2. Spark versions aside, the error you encountered is unrelated to Spark, as far as I know. What version of the `decorator` package is installed on your machine? `decorator` version 4.0.10 should work correctly. Unfortunately, we are still looking for a python dependency management solution. My apologies that you've run into this issue.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-336903534
https://github.com/hail-is/hail/issues/2076#issuecomment-336903534:272,Deployability,install,installed,272,"Hi @Sun-shan,. First, I should note that we do not currently test hail against Spark version 2.2.0, I recommend using Spark 2.1.1 or 2.0.2. Spark versions aside, the error you encountered is unrelated to Spark, as far as I know. What version of the `decorator` package is installed on your machine? `decorator` version 4.0.10 should work correctly. Unfortunately, we are still looking for a python dependency management solution. My apologies that you've run into this issue.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-336903534
https://github.com/hail-is/hail/issues/2076#issuecomment-336903534:398,Integrability,depend,dependency,398,"Hi @Sun-shan,. First, I should note that we do not currently test hail against Spark version 2.2.0, I recommend using Spark 2.1.1 or 2.0.2. Spark versions aside, the error you encountered is unrelated to Spark, as far as I know. What version of the `decorator` package is installed on your machine? `decorator` version 4.0.10 should work correctly. Unfortunately, we are still looking for a python dependency management solution. My apologies that you've run into this issue.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-336903534
https://github.com/hail-is/hail/issues/2076#issuecomment-336903534:61,Testability,test,test,61,"Hi @Sun-shan,. First, I should note that we do not currently test hail against Spark version 2.2.0, I recommend using Spark 2.1.1 or 2.0.2. Spark versions aside, the error you encountered is unrelated to Spark, as far as I know. What version of the `decorator` package is installed on your machine? `decorator` version 4.0.10 should work correctly. Unfortunately, we are still looking for a python dependency management solution. My apologies that you've run into this issue.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-336903534
https://github.com/hail-is/hail/issues/2076#issuecomment-337132579:92,Availability,error,error,92,"thank you very much for the reply,; when I upgrade the decorator from 3.4.0 to 4.1.2 , this error disappears. ```; Installing collected packages: decorator; Found existing installation: decorator 3.4.0; Uninstalling decorator-3.4.0:; Successfully uninstalled decorator-3.4.0; Successfully installed decorator-4.1.2. ```. But there is another error, as follows. ```; bash-4.2$ pyspark; WARNING: User-defined SPARK_HOME (/opt/cloudera/parcels/SPARK2-2.2.0.cloudera1-1.cdh5.12.0.p0.142354/lib/spark2) overrides detected (/opt/cloudera/parcels/SPARK2/lib/spark2).; WARNING: Running pyspark from user-defined location.; Python 2.7.5 (default, Nov 6 2016, 00:28:07) ; [GCC 4.8.5 20150623 (Red Hat 4.8.5-11)] on linux2; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.2.0.cloudera1; /_/. Using Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; >>> from hail import *; >>> hc = hail.Context(); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; NameError: name 'hail' is not defined; >>> hc = hail.HailContext(); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; NameError: name 'hail' is not defined; >>> hc = HailContext(); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-470>"", line 2, in __init__; File ""/opt/Software/hail/python/hail/typecheck/check.py"", line 245, in _typecheck; return f(*args, **kwargs); File ""/opt/Software/hail/python/hail/context.py"", line 88, in __init__; parquet_compression, min_block_size, branching_factor, tmp_dir); TypeError: 'JavaPackage' object is not callable; ```; My Java version; ```; [root@mg opt]# java -version; java version ""1.8.0_91""; Java(TM) SE Runtime Environment (bui",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-337132579
https://github.com/hail-is/hail/issues/2076#issuecomment-337132579:343,Availability,error,error,343,"thank you very much for the reply,; when I upgrade the decorator from 3.4.0 to 4.1.2 , this error disappears. ```; Installing collected packages: decorator; Found existing installation: decorator 3.4.0; Uninstalling decorator-3.4.0:; Successfully uninstalled decorator-3.4.0; Successfully installed decorator-4.1.2. ```. But there is another error, as follows. ```; bash-4.2$ pyspark; WARNING: User-defined SPARK_HOME (/opt/cloudera/parcels/SPARK2-2.2.0.cloudera1-1.cdh5.12.0.p0.142354/lib/spark2) overrides detected (/opt/cloudera/parcels/SPARK2/lib/spark2).; WARNING: Running pyspark from user-defined location.; Python 2.7.5 (default, Nov 6 2016, 00:28:07) ; [GCC 4.8.5 20150623 (Red Hat 4.8.5-11)] on linux2; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.2.0.cloudera1; /_/. Using Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; >>> from hail import *; >>> hc = hail.Context(); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; NameError: name 'hail' is not defined; >>> hc = hail.HailContext(); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; NameError: name 'hail' is not defined; >>> hc = HailContext(); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-470>"", line 2, in __init__; File ""/opt/Software/hail/python/hail/typecheck/check.py"", line 245, in _typecheck; return f(*args, **kwargs); File ""/opt/Software/hail/python/hail/context.py"", line 88, in __init__; parquet_compression, min_block_size, branching_factor, tmp_dir); TypeError: 'JavaPackage' object is not callable; ```; My Java version; ```; [root@mg opt]# java -version; java version ""1.8.0_91""; Java(TM) SE Runtime Environment (bui",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-337132579
https://github.com/hail-is/hail/issues/2076#issuecomment-337132579:1116,Availability,avail,available,1116,"this error disappears. ```; Installing collected packages: decorator; Found existing installation: decorator 3.4.0; Uninstalling decorator-3.4.0:; Successfully uninstalled decorator-3.4.0; Successfully installed decorator-4.1.2. ```. But there is another error, as follows. ```; bash-4.2$ pyspark; WARNING: User-defined SPARK_HOME (/opt/cloudera/parcels/SPARK2-2.2.0.cloudera1-1.cdh5.12.0.p0.142354/lib/spark2) overrides detected (/opt/cloudera/parcels/SPARK2/lib/spark2).; WARNING: Running pyspark from user-defined location.; Python 2.7.5 (default, Nov 6 2016, 00:28:07) ; [GCC 4.8.5 20150623 (Red Hat 4.8.5-11)] on linux2; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.2.0.cloudera1; /_/. Using Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; >>> from hail import *; >>> hc = hail.Context(); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; NameError: name 'hail' is not defined; >>> hc = hail.HailContext(); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; NameError: name 'hail' is not defined; >>> hc = HailContext(); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-470>"", line 2, in __init__; File ""/opt/Software/hail/python/hail/typecheck/check.py"", line 245, in _typecheck; return f(*args, **kwargs); File ""/opt/Software/hail/python/hail/context.py"", line 88, in __init__; parquet_compression, min_block_size, branching_factor, tmp_dir); TypeError: 'JavaPackage' object is not callable; ```; My Java version; ```; [root@mg opt]# java -version; java version ""1.8.0_91""; Java(TM) SE Runtime Environment (build 1.8.0_91-b14); Java HotSpot(TM) 64-Bit Server VM (build 25.91-b14, mixed mode); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-337132579
https://github.com/hail-is/hail/issues/2076#issuecomment-337132579:43,Deployability,upgrade,upgrade,43,"thank you very much for the reply,; when I upgrade the decorator from 3.4.0 to 4.1.2 , this error disappears. ```; Installing collected packages: decorator; Found existing installation: decorator 3.4.0; Uninstalling decorator-3.4.0:; Successfully uninstalled decorator-3.4.0; Successfully installed decorator-4.1.2. ```. But there is another error, as follows. ```; bash-4.2$ pyspark; WARNING: User-defined SPARK_HOME (/opt/cloudera/parcels/SPARK2-2.2.0.cloudera1-1.cdh5.12.0.p0.142354/lib/spark2) overrides detected (/opt/cloudera/parcels/SPARK2/lib/spark2).; WARNING: Running pyspark from user-defined location.; Python 2.7.5 (default, Nov 6 2016, 00:28:07) ; [GCC 4.8.5 20150623 (Red Hat 4.8.5-11)] on linux2; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.2.0.cloudera1; /_/. Using Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; >>> from hail import *; >>> hc = hail.Context(); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; NameError: name 'hail' is not defined; >>> hc = hail.HailContext(); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; NameError: name 'hail' is not defined; >>> hc = HailContext(); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-470>"", line 2, in __init__; File ""/opt/Software/hail/python/hail/typecheck/check.py"", line 245, in _typecheck; return f(*args, **kwargs); File ""/opt/Software/hail/python/hail/context.py"", line 88, in __init__; parquet_compression, min_block_size, branching_factor, tmp_dir); TypeError: 'JavaPackage' object is not callable; ```; My Java version; ```; [root@mg opt]# java -version; java version ""1.8.0_91""; Java(TM) SE Runtime Environment (bui",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-337132579
https://github.com/hail-is/hail/issues/2076#issuecomment-337132579:116,Deployability,Install,Installing,116,"thank you very much for the reply,; when I upgrade the decorator from 3.4.0 to 4.1.2 , this error disappears. ```; Installing collected packages: decorator; Found existing installation: decorator 3.4.0; Uninstalling decorator-3.4.0:; Successfully uninstalled decorator-3.4.0; Successfully installed decorator-4.1.2. ```. But there is another error, as follows. ```; bash-4.2$ pyspark; WARNING: User-defined SPARK_HOME (/opt/cloudera/parcels/SPARK2-2.2.0.cloudera1-1.cdh5.12.0.p0.142354/lib/spark2) overrides detected (/opt/cloudera/parcels/SPARK2/lib/spark2).; WARNING: Running pyspark from user-defined location.; Python 2.7.5 (default, Nov 6 2016, 00:28:07) ; [GCC 4.8.5 20150623 (Red Hat 4.8.5-11)] on linux2; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.2.0.cloudera1; /_/. Using Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; >>> from hail import *; >>> hc = hail.Context(); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; NameError: name 'hail' is not defined; >>> hc = hail.HailContext(); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; NameError: name 'hail' is not defined; >>> hc = HailContext(); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-470>"", line 2, in __init__; File ""/opt/Software/hail/python/hail/typecheck/check.py"", line 245, in _typecheck; return f(*args, **kwargs); File ""/opt/Software/hail/python/hail/context.py"", line 88, in __init__; parquet_compression, min_block_size, branching_factor, tmp_dir); TypeError: 'JavaPackage' object is not callable; ```; My Java version; ```; [root@mg opt]# java -version; java version ""1.8.0_91""; Java(TM) SE Runtime Environment (bui",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-337132579
https://github.com/hail-is/hail/issues/2076#issuecomment-337132579:173,Deployability,install,installation,173,"thank you very much for the reply,; when I upgrade the decorator from 3.4.0 to 4.1.2 , this error disappears. ```; Installing collected packages: decorator; Found existing installation: decorator 3.4.0; Uninstalling decorator-3.4.0:; Successfully uninstalled decorator-3.4.0; Successfully installed decorator-4.1.2. ```. But there is another error, as follows. ```; bash-4.2$ pyspark; WARNING: User-defined SPARK_HOME (/opt/cloudera/parcels/SPARK2-2.2.0.cloudera1-1.cdh5.12.0.p0.142354/lib/spark2) overrides detected (/opt/cloudera/parcels/SPARK2/lib/spark2).; WARNING: Running pyspark from user-defined location.; Python 2.7.5 (default, Nov 6 2016, 00:28:07) ; [GCC 4.8.5 20150623 (Red Hat 4.8.5-11)] on linux2; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.2.0.cloudera1; /_/. Using Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; >>> from hail import *; >>> hc = hail.Context(); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; NameError: name 'hail' is not defined; >>> hc = hail.HailContext(); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; NameError: name 'hail' is not defined; >>> hc = HailContext(); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-470>"", line 2, in __init__; File ""/opt/Software/hail/python/hail/typecheck/check.py"", line 245, in _typecheck; return f(*args, **kwargs); File ""/opt/Software/hail/python/hail/context.py"", line 88, in __init__; parquet_compression, min_block_size, branching_factor, tmp_dir); TypeError: 'JavaPackage' object is not callable; ```; My Java version; ```; [root@mg opt]# java -version; java version ""1.8.0_91""; Java(TM) SE Runtime Environment (bui",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-337132579
https://github.com/hail-is/hail/issues/2076#issuecomment-337132579:290,Deployability,install,installed,290,"thank you very much for the reply,; when I upgrade the decorator from 3.4.0 to 4.1.2 , this error disappears. ```; Installing collected packages: decorator; Found existing installation: decorator 3.4.0; Uninstalling decorator-3.4.0:; Successfully uninstalled decorator-3.4.0; Successfully installed decorator-4.1.2. ```. But there is another error, as follows. ```; bash-4.2$ pyspark; WARNING: User-defined SPARK_HOME (/opt/cloudera/parcels/SPARK2-2.2.0.cloudera1-1.cdh5.12.0.p0.142354/lib/spark2) overrides detected (/opt/cloudera/parcels/SPARK2/lib/spark2).; WARNING: Running pyspark from user-defined location.; Python 2.7.5 (default, Nov 6 2016, 00:28:07) ; [GCC 4.8.5 20150623 (Red Hat 4.8.5-11)] on linux2; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.2.0.cloudera1; /_/. Using Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; >>> from hail import *; >>> hc = hail.Context(); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; NameError: name 'hail' is not defined; >>> hc = hail.HailContext(); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; NameError: name 'hail' is not defined; >>> hc = HailContext(); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-470>"", line 2, in __init__; File ""/opt/Software/hail/python/hail/typecheck/check.py"", line 245, in _typecheck; return f(*args, **kwargs); File ""/opt/Software/hail/python/hail/context.py"", line 88, in __init__; parquet_compression, min_block_size, branching_factor, tmp_dir); TypeError: 'JavaPackage' object is not callable; ```; My Java version; ```; [root@mg opt]# java -version; java version ""1.8.0_91""; Java(TM) SE Runtime Environment (bui",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-337132579
https://github.com/hail-is/hail/issues/2076#issuecomment-337132579:510,Safety,detect,detected,510,"thank you very much for the reply,; when I upgrade the decorator from 3.4.0 to 4.1.2 , this error disappears. ```; Installing collected packages: decorator; Found existing installation: decorator 3.4.0; Uninstalling decorator-3.4.0:; Successfully uninstalled decorator-3.4.0; Successfully installed decorator-4.1.2. ```. But there is another error, as follows. ```; bash-4.2$ pyspark; WARNING: User-defined SPARK_HOME (/opt/cloudera/parcels/SPARK2-2.2.0.cloudera1-1.cdh5.12.0.p0.142354/lib/spark2) overrides detected (/opt/cloudera/parcels/SPARK2/lib/spark2).; WARNING: Running pyspark from user-defined location.; Python 2.7.5 (default, Nov 6 2016, 00:28:07) ; [GCC 4.8.5 20150623 (Red Hat 4.8.5-11)] on linux2; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.2.0.cloudera1; /_/. Using Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; >>> from hail import *; >>> hc = hail.Context(); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; NameError: name 'hail' is not defined; >>> hc = hail.HailContext(); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; NameError: name 'hail' is not defined; >>> hc = HailContext(); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-470>"", line 2, in __init__; File ""/opt/Software/hail/python/hail/typecheck/check.py"", line 245, in _typecheck; return f(*args, **kwargs); File ""/opt/Software/hail/python/hail/context.py"", line 88, in __init__; parquet_compression, min_block_size, branching_factor, tmp_dir); TypeError: 'JavaPackage' object is not callable; ```; My Java version; ```; [root@mg opt]# java -version; java version ""1.8.0_91""; Java(TM) SE Runtime Environment (bui",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-337132579
https://github.com/hail-is/hail/issues/2076#issuecomment-337132579:803,Testability,log,log,803,"thank you very much for the reply,; when I upgrade the decorator from 3.4.0 to 4.1.2 , this error disappears. ```; Installing collected packages: decorator; Found existing installation: decorator 3.4.0; Uninstalling decorator-3.4.0:; Successfully uninstalled decorator-3.4.0; Successfully installed decorator-4.1.2. ```. But there is another error, as follows. ```; bash-4.2$ pyspark; WARNING: User-defined SPARK_HOME (/opt/cloudera/parcels/SPARK2-2.2.0.cloudera1-1.cdh5.12.0.p0.142354/lib/spark2) overrides detected (/opt/cloudera/parcels/SPARK2/lib/spark2).; WARNING: Running pyspark from user-defined location.; Python 2.7.5 (default, Nov 6 2016, 00:28:07) ; [GCC 4.8.5 20150623 (Red Hat 4.8.5-11)] on linux2; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.2.0.cloudera1; /_/. Using Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; >>> from hail import *; >>> hc = hail.Context(); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; NameError: name 'hail' is not defined; >>> hc = hail.HailContext(); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; NameError: name 'hail' is not defined; >>> hc = HailContext(); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-470>"", line 2, in __init__; File ""/opt/Software/hail/python/hail/typecheck/check.py"", line 245, in _typecheck; return f(*args, **kwargs); File ""/opt/Software/hail/python/hail/context.py"", line 88, in __init__; parquet_compression, min_block_size, branching_factor, tmp_dir); TypeError: 'JavaPackage' object is not callable; ```; My Java version; ```; [root@mg opt]# java -version; java version ""1.8.0_91""; Java(TM) SE Runtime Environment (bui",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-337132579
https://github.com/hail-is/hail/issues/2076#issuecomment-337132579:835,Testability,log,logging,835,"thank you very much for the reply,; when I upgrade the decorator from 3.4.0 to 4.1.2 , this error disappears. ```; Installing collected packages: decorator; Found existing installation: decorator 3.4.0; Uninstalling decorator-3.4.0:; Successfully uninstalled decorator-3.4.0; Successfully installed decorator-4.1.2. ```. But there is another error, as follows. ```; bash-4.2$ pyspark; WARNING: User-defined SPARK_HOME (/opt/cloudera/parcels/SPARK2-2.2.0.cloudera1-1.cdh5.12.0.p0.142354/lib/spark2) overrides detected (/opt/cloudera/parcels/SPARK2/lib/spark2).; WARNING: Running pyspark from user-defined location.; Python 2.7.5 (default, Nov 6 2016, 00:28:07) ; [GCC 4.8.5 20150623 (Red Hat 4.8.5-11)] on linux2; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.2.0.cloudera1; /_/. Using Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; >>> from hail import *; >>> hc = hail.Context(); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; NameError: name 'hail' is not defined; >>> hc = hail.HailContext(); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; NameError: name 'hail' is not defined; >>> hc = HailContext(); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-470>"", line 2, in __init__; File ""/opt/Software/hail/python/hail/typecheck/check.py"", line 245, in _typecheck; return f(*args, **kwargs); File ""/opt/Software/hail/python/hail/context.py"", line 88, in __init__; parquet_compression, min_block_size, branching_factor, tmp_dir); TypeError: 'JavaPackage' object is not callable; ```; My Java version; ```; [root@mg opt]# java -version; java version ""1.8.0_91""; Java(TM) SE Runtime Environment (bui",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-337132579
https://github.com/hail-is/hail/issues/2076#issuecomment-337352607:41,Availability,echo,echo,41,What is the output of this script?. ```; echo $HAIL_HOME; echo $PYTHONPATH; echo $SPARK_CLASSPATH; ```. This might be caused by an incorrect compilation of hail. The output of the above script will tell us more about what to check next.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-337352607
https://github.com/hail-is/hail/issues/2076#issuecomment-337352607:58,Availability,echo,echo,58,What is the output of this script?. ```; echo $HAIL_HOME; echo $PYTHONPATH; echo $SPARK_CLASSPATH; ```. This might be caused by an incorrect compilation of hail. The output of the above script will tell us more about what to check next.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-337352607
https://github.com/hail-is/hail/issues/2076#issuecomment-337352607:76,Availability,echo,echo,76,What is the output of this script?. ```; echo $HAIL_HOME; echo $PYTHONPATH; echo $SPARK_CLASSPATH; ```. This might be caused by an incorrect compilation of hail. The output of the above script will tell us more about what to check next.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-337352607
https://github.com/hail-is/hail/issues/2076#issuecomment-337442177:31,Availability,echo,echo,31,"@danking; ```; [root@mg hail]# echo $HAIL_HOME; /opt/Software/hail; [root@mg hail]# echo $PYTHONPATH; :/opt/Software/hail/python:/opt/cloudera/parcels/SPARK2/lib/spark2/python:/opt/cloudera/parcels/SPARK2/lib/spark2/python/lib/py4j-0.10.4-src.zip; [root@mg hail]# cd /opt/Software/hail/python; [root@mg python]# ls; hail; [root@mg python]# cd /opt/cloudera/parcels/SPARK2/lib/spark2/python; [root@mg python]# ls; docs lib MANIFEST.in pylintrc pyspark README.md run-tests run-tests.py setup.cfg setup.py test_support; [root@mg python]# cd /opt/cloudera/parcels/SPARK2/lib/spark2/python/lib/; [root@mg lib]# ls; py4j-0.10.4-src.zip PY4J_LICENSE.txt pyspark.zip; [root@mg lib]# echo $SPARK_CLASSPATH; /opt/Software/hail/build/libs/hail-all-spark.jar; [root@mg lib]# cd /opt/Software/hail/build/libs/; [root@mg libs]# ls; hail-all-spark.jar; ```; the configuration file:; ```; export SPARK_HOME=/opt/cloudera/parcels/SPARK2/lib/spark2; export HAIL_HOME=/opt/Software/hail; export PYTHONPATH=""$PYTHONPATH:$HAIL_HOME/python:$SPARK_HOME/python:`echo $SPARK_HOME/python/lib/py4j*-src.zip`""; export SPARK_CLASSPATH=$HAIL_HOME/build/libs/hail-all-spark.jar; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-337442177
https://github.com/hail-is/hail/issues/2076#issuecomment-337442177:84,Availability,echo,echo,84,"@danking; ```; [root@mg hail]# echo $HAIL_HOME; /opt/Software/hail; [root@mg hail]# echo $PYTHONPATH; :/opt/Software/hail/python:/opt/cloudera/parcels/SPARK2/lib/spark2/python:/opt/cloudera/parcels/SPARK2/lib/spark2/python/lib/py4j-0.10.4-src.zip; [root@mg hail]# cd /opt/Software/hail/python; [root@mg python]# ls; hail; [root@mg python]# cd /opt/cloudera/parcels/SPARK2/lib/spark2/python; [root@mg python]# ls; docs lib MANIFEST.in pylintrc pyspark README.md run-tests run-tests.py setup.cfg setup.py test_support; [root@mg python]# cd /opt/cloudera/parcels/SPARK2/lib/spark2/python/lib/; [root@mg lib]# ls; py4j-0.10.4-src.zip PY4J_LICENSE.txt pyspark.zip; [root@mg lib]# echo $SPARK_CLASSPATH; /opt/Software/hail/build/libs/hail-all-spark.jar; [root@mg lib]# cd /opt/Software/hail/build/libs/; [root@mg libs]# ls; hail-all-spark.jar; ```; the configuration file:; ```; export SPARK_HOME=/opt/cloudera/parcels/SPARK2/lib/spark2; export HAIL_HOME=/opt/Software/hail; export PYTHONPATH=""$PYTHONPATH:$HAIL_HOME/python:$SPARK_HOME/python:`echo $SPARK_HOME/python/lib/py4j*-src.zip`""; export SPARK_CLASSPATH=$HAIL_HOME/build/libs/hail-all-spark.jar; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-337442177
https://github.com/hail-is/hail/issues/2076#issuecomment-337442177:675,Availability,echo,echo,675,"@danking; ```; [root@mg hail]# echo $HAIL_HOME; /opt/Software/hail; [root@mg hail]# echo $PYTHONPATH; :/opt/Software/hail/python:/opt/cloudera/parcels/SPARK2/lib/spark2/python:/opt/cloudera/parcels/SPARK2/lib/spark2/python/lib/py4j-0.10.4-src.zip; [root@mg hail]# cd /opt/Software/hail/python; [root@mg python]# ls; hail; [root@mg python]# cd /opt/cloudera/parcels/SPARK2/lib/spark2/python; [root@mg python]# ls; docs lib MANIFEST.in pylintrc pyspark README.md run-tests run-tests.py setup.cfg setup.py test_support; [root@mg python]# cd /opt/cloudera/parcels/SPARK2/lib/spark2/python/lib/; [root@mg lib]# ls; py4j-0.10.4-src.zip PY4J_LICENSE.txt pyspark.zip; [root@mg lib]# echo $SPARK_CLASSPATH; /opt/Software/hail/build/libs/hail-all-spark.jar; [root@mg lib]# cd /opt/Software/hail/build/libs/; [root@mg libs]# ls; hail-all-spark.jar; ```; the configuration file:; ```; export SPARK_HOME=/opt/cloudera/parcels/SPARK2/lib/spark2; export HAIL_HOME=/opt/Software/hail; export PYTHONPATH=""$PYTHONPATH:$HAIL_HOME/python:$SPARK_HOME/python:`echo $SPARK_HOME/python/lib/py4j*-src.zip`""; export SPARK_CLASSPATH=$HAIL_HOME/build/libs/hail-all-spark.jar; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-337442177
https://github.com/hail-is/hail/issues/2076#issuecomment-337442177:1038,Availability,echo,echo,1038,"@danking; ```; [root@mg hail]# echo $HAIL_HOME; /opt/Software/hail; [root@mg hail]# echo $PYTHONPATH; :/opt/Software/hail/python:/opt/cloudera/parcels/SPARK2/lib/spark2/python:/opt/cloudera/parcels/SPARK2/lib/spark2/python/lib/py4j-0.10.4-src.zip; [root@mg hail]# cd /opt/Software/hail/python; [root@mg python]# ls; hail; [root@mg python]# cd /opt/cloudera/parcels/SPARK2/lib/spark2/python; [root@mg python]# ls; docs lib MANIFEST.in pylintrc pyspark README.md run-tests run-tests.py setup.cfg setup.py test_support; [root@mg python]# cd /opt/cloudera/parcels/SPARK2/lib/spark2/python/lib/; [root@mg lib]# ls; py4j-0.10.4-src.zip PY4J_LICENSE.txt pyspark.zip; [root@mg lib]# echo $SPARK_CLASSPATH; /opt/Software/hail/build/libs/hail-all-spark.jar; [root@mg lib]# cd /opt/Software/hail/build/libs/; [root@mg libs]# ls; hail-all-spark.jar; ```; the configuration file:; ```; export SPARK_HOME=/opt/cloudera/parcels/SPARK2/lib/spark2; export HAIL_HOME=/opt/Software/hail; export PYTHONPATH=""$PYTHONPATH:$HAIL_HOME/python:$SPARK_HOME/python:`echo $SPARK_HOME/python/lib/py4j*-src.zip`""; export SPARK_CLASSPATH=$HAIL_HOME/build/libs/hail-all-spark.jar; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-337442177
https://github.com/hail-is/hail/issues/2076#issuecomment-337442177:847,Deployability,configurat,configuration,847,"@danking; ```; [root@mg hail]# echo $HAIL_HOME; /opt/Software/hail; [root@mg hail]# echo $PYTHONPATH; :/opt/Software/hail/python:/opt/cloudera/parcels/SPARK2/lib/spark2/python:/opt/cloudera/parcels/SPARK2/lib/spark2/python/lib/py4j-0.10.4-src.zip; [root@mg hail]# cd /opt/Software/hail/python; [root@mg python]# ls; hail; [root@mg python]# cd /opt/cloudera/parcels/SPARK2/lib/spark2/python; [root@mg python]# ls; docs lib MANIFEST.in pylintrc pyspark README.md run-tests run-tests.py setup.cfg setup.py test_support; [root@mg python]# cd /opt/cloudera/parcels/SPARK2/lib/spark2/python/lib/; [root@mg lib]# ls; py4j-0.10.4-src.zip PY4J_LICENSE.txt pyspark.zip; [root@mg lib]# echo $SPARK_CLASSPATH; /opt/Software/hail/build/libs/hail-all-spark.jar; [root@mg lib]# cd /opt/Software/hail/build/libs/; [root@mg libs]# ls; hail-all-spark.jar; ```; the configuration file:; ```; export SPARK_HOME=/opt/cloudera/parcels/SPARK2/lib/spark2; export HAIL_HOME=/opt/Software/hail; export PYTHONPATH=""$PYTHONPATH:$HAIL_HOME/python:$SPARK_HOME/python:`echo $SPARK_HOME/python/lib/py4j*-src.zip`""; export SPARK_CLASSPATH=$HAIL_HOME/build/libs/hail-all-spark.jar; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-337442177
https://github.com/hail-is/hail/issues/2076#issuecomment-337442177:847,Modifiability,config,configuration,847,"@danking; ```; [root@mg hail]# echo $HAIL_HOME; /opt/Software/hail; [root@mg hail]# echo $PYTHONPATH; :/opt/Software/hail/python:/opt/cloudera/parcels/SPARK2/lib/spark2/python:/opt/cloudera/parcels/SPARK2/lib/spark2/python/lib/py4j-0.10.4-src.zip; [root@mg hail]# cd /opt/Software/hail/python; [root@mg python]# ls; hail; [root@mg python]# cd /opt/cloudera/parcels/SPARK2/lib/spark2/python; [root@mg python]# ls; docs lib MANIFEST.in pylintrc pyspark README.md run-tests run-tests.py setup.cfg setup.py test_support; [root@mg python]# cd /opt/cloudera/parcels/SPARK2/lib/spark2/python/lib/; [root@mg lib]# ls; py4j-0.10.4-src.zip PY4J_LICENSE.txt pyspark.zip; [root@mg lib]# echo $SPARK_CLASSPATH; /opt/Software/hail/build/libs/hail-all-spark.jar; [root@mg lib]# cd /opt/Software/hail/build/libs/; [root@mg libs]# ls; hail-all-spark.jar; ```; the configuration file:; ```; export SPARK_HOME=/opt/cloudera/parcels/SPARK2/lib/spark2; export HAIL_HOME=/opt/Software/hail; export PYTHONPATH=""$PYTHONPATH:$HAIL_HOME/python:$SPARK_HOME/python:`echo $SPARK_HOME/python/lib/py4j*-src.zip`""; export SPARK_CLASSPATH=$HAIL_HOME/build/libs/hail-all-spark.jar; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-337442177
https://github.com/hail-is/hail/issues/2076#issuecomment-337442177:465,Testability,test,tests,465,"@danking; ```; [root@mg hail]# echo $HAIL_HOME; /opt/Software/hail; [root@mg hail]# echo $PYTHONPATH; :/opt/Software/hail/python:/opt/cloudera/parcels/SPARK2/lib/spark2/python:/opt/cloudera/parcels/SPARK2/lib/spark2/python/lib/py4j-0.10.4-src.zip; [root@mg hail]# cd /opt/Software/hail/python; [root@mg python]# ls; hail; [root@mg python]# cd /opt/cloudera/parcels/SPARK2/lib/spark2/python; [root@mg python]# ls; docs lib MANIFEST.in pylintrc pyspark README.md run-tests run-tests.py setup.cfg setup.py test_support; [root@mg python]# cd /opt/cloudera/parcels/SPARK2/lib/spark2/python/lib/; [root@mg lib]# ls; py4j-0.10.4-src.zip PY4J_LICENSE.txt pyspark.zip; [root@mg lib]# echo $SPARK_CLASSPATH; /opt/Software/hail/build/libs/hail-all-spark.jar; [root@mg lib]# cd /opt/Software/hail/build/libs/; [root@mg libs]# ls; hail-all-spark.jar; ```; the configuration file:; ```; export SPARK_HOME=/opt/cloudera/parcels/SPARK2/lib/spark2; export HAIL_HOME=/opt/Software/hail; export PYTHONPATH=""$PYTHONPATH:$HAIL_HOME/python:$SPARK_HOME/python:`echo $SPARK_HOME/python/lib/py4j*-src.zip`""; export SPARK_CLASSPATH=$HAIL_HOME/build/libs/hail-all-spark.jar; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-337442177
https://github.com/hail-is/hail/issues/2076#issuecomment-337442177:475,Testability,test,tests,475,"@danking; ```; [root@mg hail]# echo $HAIL_HOME; /opt/Software/hail; [root@mg hail]# echo $PYTHONPATH; :/opt/Software/hail/python:/opt/cloudera/parcels/SPARK2/lib/spark2/python:/opt/cloudera/parcels/SPARK2/lib/spark2/python/lib/py4j-0.10.4-src.zip; [root@mg hail]# cd /opt/Software/hail/python; [root@mg python]# ls; hail; [root@mg python]# cd /opt/cloudera/parcels/SPARK2/lib/spark2/python; [root@mg python]# ls; docs lib MANIFEST.in pylintrc pyspark README.md run-tests run-tests.py setup.cfg setup.py test_support; [root@mg python]# cd /opt/cloudera/parcels/SPARK2/lib/spark2/python/lib/; [root@mg lib]# ls; py4j-0.10.4-src.zip PY4J_LICENSE.txt pyspark.zip; [root@mg lib]# echo $SPARK_CLASSPATH; /opt/Software/hail/build/libs/hail-all-spark.jar; [root@mg lib]# cd /opt/Software/hail/build/libs/; [root@mg libs]# ls; hail-all-spark.jar; ```; the configuration file:; ```; export SPARK_HOME=/opt/cloudera/parcels/SPARK2/lib/spark2; export HAIL_HOME=/opt/Software/hail; export PYTHONPATH=""$PYTHONPATH:$HAIL_HOME/python:$SPARK_HOME/python:`echo $SPARK_HOME/python/lib/py4j*-src.zip`""; export SPARK_CLASSPATH=$HAIL_HOME/build/libs/hail-all-spark.jar; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-337442177
https://github.com/hail-is/hail/issues/2076#issuecomment-337610577:228,Deployability,configurat,configuration,228,"Your previous post includes a warning message that your `SPARK_HOME`, in that shell, is set to:; ```; /opt/cloudera/parcels/SPARK2-2.2.0.cloudera1-1.cdh5.12.0.p0.142354/lib/spark2; ```; Could you try setting `SPARK_HOME` in the configuration file to `/opt/cloudera/parcels/SPARK2-2.2.0.cloudera1-1.cdh5.12.0.p0.142354/lib/spark2` and then try again to create a `HailContext`?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-337610577
https://github.com/hail-is/hail/issues/2076#issuecomment-337610577:38,Integrability,message,message,38,"Your previous post includes a warning message that your `SPARK_HOME`, in that shell, is set to:; ```; /opt/cloudera/parcels/SPARK2-2.2.0.cloudera1-1.cdh5.12.0.p0.142354/lib/spark2; ```; Could you try setting `SPARK_HOME` in the configuration file to `/opt/cloudera/parcels/SPARK2-2.2.0.cloudera1-1.cdh5.12.0.p0.142354/lib/spark2` and then try again to create a `HailContext`?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-337610577
https://github.com/hail-is/hail/issues/2076#issuecomment-337610577:228,Modifiability,config,configuration,228,"Your previous post includes a warning message that your `SPARK_HOME`, in that shell, is set to:; ```; /opt/cloudera/parcels/SPARK2-2.2.0.cloudera1-1.cdh5.12.0.p0.142354/lib/spark2; ```; Could you try setting `SPARK_HOME` in the configuration file to `/opt/cloudera/parcels/SPARK2-2.2.0.cloudera1-1.cdh5.12.0.p0.142354/lib/spark2` and then try again to create a `HailContext`?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-337610577
https://github.com/hail-is/hail/issues/2076#issuecomment-337627831:295,Testability,test,test,295,"Hi, @danking; I follow the instruction in hail website to set the environment:; export SPARK_HOME=/opt/cloudera/parcels/SPARK2/lib/spark2;; Actually, the SPARK2 above is a soft link of the ""SPARK2-2.2.0.cloudera1-1.cdh5.12.0.p0.142354/"" in the same directory; Anyway,I will try to change it and test later",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-337627831
https://github.com/hail-is/hail/issues/2076#issuecomment-337639898:97,Availability,error,error,97,"Ah, I see. If those paths point to the same location then it shouldn't make any difference. This error almost certainly means that `pyspark` cannot find your hail jar. I suspect that Spark 2.2.x has dropped support for the `SPARK_CLASSPATH` environment variable. Can you try starting `pyspark` with these options:; ```; pyspark \; --jars $HAIL_HOME/build/libs/hail-all-spark.jar \; --conf=spark.driver.extraClassPath=$HAIL_HOME/build/libs/hail-all-spark.jar \; --conf=spark.executor.extraClassPath=./hail-all-spark.jar. ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-337639898
https://github.com/hail-is/hail/issues/2076#issuecomment-337639898:253,Modifiability,variab,variable,253,"Ah, I see. If those paths point to the same location then it shouldn't make any difference. This error almost certainly means that `pyspark` cannot find your hail jar. I suspect that Spark 2.2.x has dropped support for the `SPARK_CLASSPATH` environment variable. Can you try starting `pyspark` with these options:; ```; pyspark \; --jars $HAIL_HOME/build/libs/hail-all-spark.jar \; --conf=spark.driver.extraClassPath=$HAIL_HOME/build/libs/hail-all-spark.jar \; --conf=spark.executor.extraClassPath=./hail-all-spark.jar. ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-337639898
https://github.com/hail-is/hail/issues/2076#issuecomment-337768198:1101,Availability,avail,available,1101,"rs $HAIL_HOME/build/libs/hail-all-spark.jar --conf=spark.driver.extraClassPath=$HAIL_HOME/build/libs/hail-all-spark.jar --conf=spark.executor.extraClassPath=./hail-all-spark.jar; WARNING: User-defined SPARK_HOME (/opt/cloudera/parcels/SPARK2-2.2.0.cloudera1-1.cdh5.12.0.p0.142354/lib/spark2) overrides detected (/opt/cloudera/parcels/SPARK2/lib/spark2).; WARNING: Running pyspark from user-defined location.; Python 2.7.5 (default, Aug 4 2017, 00:39:18) ; [GCC 4.8.5 20150623 (Red Hat 4.8.5-16)] on linux2; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; 17/10/19 08:45:43 WARN util.Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.2.0.cloudera1; /_/. Using Python version 2.7.5 (default, Aug 4 2017 00:39:18); SparkSession available as 'spark'.; >>> import hail; >>> hc = hail.HailContext(); log4j:ERROR setFile(null,false) call failed.; java.io.FileNotFoundException: hail.log (Permission denied); 	at java.io.FileOutputStream.open0(Native Method); 	at java.io.FileOutputStream.open(FileOutputStream.java:270); 	at java.io.FileOutputStream.<init>(FileOutputStream.java:213); 	at java.io.FileOutputStream.<init>(FileOutputStream.java:133); 	at org.apache.log4j.FileAppender.setFile(FileAppender.java:294); 	at org.apache.log4j.FileAppender.activateOptions(FileAppender.java:165); 	at org.apache.log4j.config.PropertySetter.activate(PropertySetter.java:307); 	at org.apache.log4j.config.PropertySetter.setProperties(PropertySetter.java:172); 	at org.apache.log4j.config.PropertySetter.setProperties(PropertySetter.java:104); 	at org.apache.log4j.PropertyConfigurator.parseAppender(PropertyConfigurator.java:842); 	at org.apache.log4j.PropertyConfigurator.parseCategory(PropertyConfigurator.java:768); 	at org.ap",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-337768198
https://github.com/hail-is/hail/issues/2076#issuecomment-337768198:1176,Availability,ERROR,ERROR,1176,"libs/hail-all-spark.jar --conf=spark.executor.extraClassPath=./hail-all-spark.jar; WARNING: User-defined SPARK_HOME (/opt/cloudera/parcels/SPARK2-2.2.0.cloudera1-1.cdh5.12.0.p0.142354/lib/spark2) overrides detected (/opt/cloudera/parcels/SPARK2/lib/spark2).; WARNING: Running pyspark from user-defined location.; Python 2.7.5 (default, Aug 4 2017, 00:39:18) ; [GCC 4.8.5 20150623 (Red Hat 4.8.5-16)] on linux2; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; 17/10/19 08:45:43 WARN util.Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.2.0.cloudera1; /_/. Using Python version 2.7.5 (default, Aug 4 2017 00:39:18); SparkSession available as 'spark'.; >>> import hail; >>> hc = hail.HailContext(); log4j:ERROR setFile(null,false) call failed.; java.io.FileNotFoundException: hail.log (Permission denied); 	at java.io.FileOutputStream.open0(Native Method); 	at java.io.FileOutputStream.open(FileOutputStream.java:270); 	at java.io.FileOutputStream.<init>(FileOutputStream.java:213); 	at java.io.FileOutputStream.<init>(FileOutputStream.java:133); 	at org.apache.log4j.FileAppender.setFile(FileAppender.java:294); 	at org.apache.log4j.FileAppender.activateOptions(FileAppender.java:165); 	at org.apache.log4j.config.PropertySetter.activate(PropertySetter.java:307); 	at org.apache.log4j.config.PropertySetter.setProperties(PropertySetter.java:172); 	at org.apache.log4j.config.PropertySetter.setProperties(PropertySetter.java:104); 	at org.apache.log4j.PropertyConfigurator.parseAppender(PropertyConfigurator.java:842); 	at org.apache.log4j.PropertyConfigurator.parseCategory(PropertyConfigurator.java:768); 	at org.apache.log4j.PropertyConfigurator.configureRootCategory(PropertyConfigurator.java:648); 	at org.apa",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-337768198
https://github.com/hail-is/hail/issues/2076#issuecomment-337768198:3372,Availability,Error,Error,3372,"nder.java:165); 	at org.apache.log4j.config.PropertySetter.activate(PropertySetter.java:307); 	at org.apache.log4j.config.PropertySetter.setProperties(PropertySetter.java:172); 	at org.apache.log4j.config.PropertySetter.setProperties(PropertySetter.java:104); 	at org.apache.log4j.PropertyConfigurator.parseAppender(PropertyConfigurator.java:842); 	at org.apache.log4j.PropertyConfigurator.parseCategory(PropertyConfigurator.java:768); 	at org.apache.log4j.PropertyConfigurator.configureRootCategory(PropertyConfigurator.java:648); 	at org.apache.log4j.PropertyConfigurator.doConfigure(PropertyConfigurator.java:514); 	at org.apache.log4j.PropertyConfigurator.configure(PropertyConfigurator.java:440); 	at is.hail.HailContext$.configureLogging(HailContext.scala:132); 	at is.hail.HailContext$.apply(HailContext.scala:159); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:745); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-289>"", line 2, in __init__; File ""/opt/Software/hail/python/hail/java.py"", line 112, in handle_py4j; 'Error summary: %s' % (deepest, full, Env.hc().version, deepest)); File ""/opt/Software/hail/python/hail/java.py"", line 42, in hc; raise EnvironmentError('no Hail context initialized, create one first'); EnvironmentError: no Hail context initialized, create one first; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-337768198
https://github.com/hail-is/hail/issues/2076#issuecomment-337768198:1679,Modifiability,config,config,1679," log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; 17/10/19 08:45:43 WARN util.Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.2.0.cloudera1; /_/. Using Python version 2.7.5 (default, Aug 4 2017 00:39:18); SparkSession available as 'spark'.; >>> import hail; >>> hc = hail.HailContext(); log4j:ERROR setFile(null,false) call failed.; java.io.FileNotFoundException: hail.log (Permission denied); 	at java.io.FileOutputStream.open0(Native Method); 	at java.io.FileOutputStream.open(FileOutputStream.java:270); 	at java.io.FileOutputStream.<init>(FileOutputStream.java:213); 	at java.io.FileOutputStream.<init>(FileOutputStream.java:133); 	at org.apache.log4j.FileAppender.setFile(FileAppender.java:294); 	at org.apache.log4j.FileAppender.activateOptions(FileAppender.java:165); 	at org.apache.log4j.config.PropertySetter.activate(PropertySetter.java:307); 	at org.apache.log4j.config.PropertySetter.setProperties(PropertySetter.java:172); 	at org.apache.log4j.config.PropertySetter.setProperties(PropertySetter.java:104); 	at org.apache.log4j.PropertyConfigurator.parseAppender(PropertyConfigurator.java:842); 	at org.apache.log4j.PropertyConfigurator.parseCategory(PropertyConfigurator.java:768); 	at org.apache.log4j.PropertyConfigurator.configureRootCategory(PropertyConfigurator.java:648); 	at org.apache.log4j.PropertyConfigurator.doConfigure(PropertyConfigurator.java:514); 	at org.apache.log4j.PropertyConfigurator.configure(PropertyConfigurator.java:440); 	at is.hail.HailContext$.configureLogging(HailContext.scala:132); 	at is.hail.HailContext$.apply(HailContext.scala:159); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAc",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-337768198
https://github.com/hail-is/hail/issues/2076#issuecomment-337768198:1757,Modifiability,config,config,1757,"or SparkR, use setLogLevel(newLevel).; 17/10/19 08:45:43 WARN util.Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.2.0.cloudera1; /_/. Using Python version 2.7.5 (default, Aug 4 2017 00:39:18); SparkSession available as 'spark'.; >>> import hail; >>> hc = hail.HailContext(); log4j:ERROR setFile(null,false) call failed.; java.io.FileNotFoundException: hail.log (Permission denied); 	at java.io.FileOutputStream.open0(Native Method); 	at java.io.FileOutputStream.open(FileOutputStream.java:270); 	at java.io.FileOutputStream.<init>(FileOutputStream.java:213); 	at java.io.FileOutputStream.<init>(FileOutputStream.java:133); 	at org.apache.log4j.FileAppender.setFile(FileAppender.java:294); 	at org.apache.log4j.FileAppender.activateOptions(FileAppender.java:165); 	at org.apache.log4j.config.PropertySetter.activate(PropertySetter.java:307); 	at org.apache.log4j.config.PropertySetter.setProperties(PropertySetter.java:172); 	at org.apache.log4j.config.PropertySetter.setProperties(PropertySetter.java:104); 	at org.apache.log4j.PropertyConfigurator.parseAppender(PropertyConfigurator.java:842); 	at org.apache.log4j.PropertyConfigurator.parseCategory(PropertyConfigurator.java:768); 	at org.apache.log4j.PropertyConfigurator.configureRootCategory(PropertyConfigurator.java:648); 	at org.apache.log4j.PropertyConfigurator.doConfigure(PropertyConfigurator.java:514); 	at org.apache.log4j.PropertyConfigurator.configure(PropertyConfigurator.java:440); 	at is.hail.HailContext$.configureLogging(HailContext.scala:132); 	at is.hail.HailContext$.apply(HailContext.scala:159); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-337768198
https://github.com/hail-is/hail/issues/2076#issuecomment-337768198:1840,Modifiability,config,config,1840,"SparkUI' could not bind on port 4040. Attempting port 4041.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.2.0.cloudera1; /_/. Using Python version 2.7.5 (default, Aug 4 2017 00:39:18); SparkSession available as 'spark'.; >>> import hail; >>> hc = hail.HailContext(); log4j:ERROR setFile(null,false) call failed.; java.io.FileNotFoundException: hail.log (Permission denied); 	at java.io.FileOutputStream.open0(Native Method); 	at java.io.FileOutputStream.open(FileOutputStream.java:270); 	at java.io.FileOutputStream.<init>(FileOutputStream.java:213); 	at java.io.FileOutputStream.<init>(FileOutputStream.java:133); 	at org.apache.log4j.FileAppender.setFile(FileAppender.java:294); 	at org.apache.log4j.FileAppender.activateOptions(FileAppender.java:165); 	at org.apache.log4j.config.PropertySetter.activate(PropertySetter.java:307); 	at org.apache.log4j.config.PropertySetter.setProperties(PropertySetter.java:172); 	at org.apache.log4j.config.PropertySetter.setProperties(PropertySetter.java:104); 	at org.apache.log4j.PropertyConfigurator.parseAppender(PropertyConfigurator.java:842); 	at org.apache.log4j.PropertyConfigurator.parseCategory(PropertyConfigurator.java:768); 	at org.apache.log4j.PropertyConfigurator.configureRootCategory(PropertyConfigurator.java:648); 	at org.apache.log4j.PropertyConfigurator.doConfigure(PropertyConfigurator.java:514); 	at org.apache.log4j.PropertyConfigurator.configure(PropertyConfigurator.java:440); 	at is.hail.HailContext$.configureLogging(HailContext.scala:132); 	at is.hail.HailContext$.apply(HailContext.scala:159); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-337768198
https://github.com/hail-is/hail/issues/2076#issuecomment-337768198:2120,Modifiability,config,configureRootCategory,2120,">>> hc = hail.HailContext(); log4j:ERROR setFile(null,false) call failed.; java.io.FileNotFoundException: hail.log (Permission denied); 	at java.io.FileOutputStream.open0(Native Method); 	at java.io.FileOutputStream.open(FileOutputStream.java:270); 	at java.io.FileOutputStream.<init>(FileOutputStream.java:213); 	at java.io.FileOutputStream.<init>(FileOutputStream.java:133); 	at org.apache.log4j.FileAppender.setFile(FileAppender.java:294); 	at org.apache.log4j.FileAppender.activateOptions(FileAppender.java:165); 	at org.apache.log4j.config.PropertySetter.activate(PropertySetter.java:307); 	at org.apache.log4j.config.PropertySetter.setProperties(PropertySetter.java:172); 	at org.apache.log4j.config.PropertySetter.setProperties(PropertySetter.java:104); 	at org.apache.log4j.PropertyConfigurator.parseAppender(PropertyConfigurator.java:842); 	at org.apache.log4j.PropertyConfigurator.parseCategory(PropertyConfigurator.java:768); 	at org.apache.log4j.PropertyConfigurator.configureRootCategory(PropertyConfigurator.java:648); 	at org.apache.log4j.PropertyConfigurator.doConfigure(PropertyConfigurator.java:514); 	at org.apache.log4j.PropertyConfigurator.configure(PropertyConfigurator.java:440); 	at is.hail.HailContext$.configureLogging(HailContext.scala:132); 	at is.hail.HailContext$.apply(HailContext.scala:159); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-337768198
https://github.com/hail-is/hail/issues/2076#issuecomment-337768198:2302,Modifiability,config,configure,2302,"e Method); 	at java.io.FileOutputStream.open(FileOutputStream.java:270); 	at java.io.FileOutputStream.<init>(FileOutputStream.java:213); 	at java.io.FileOutputStream.<init>(FileOutputStream.java:133); 	at org.apache.log4j.FileAppender.setFile(FileAppender.java:294); 	at org.apache.log4j.FileAppender.activateOptions(FileAppender.java:165); 	at org.apache.log4j.config.PropertySetter.activate(PropertySetter.java:307); 	at org.apache.log4j.config.PropertySetter.setProperties(PropertySetter.java:172); 	at org.apache.log4j.config.PropertySetter.setProperties(PropertySetter.java:104); 	at org.apache.log4j.PropertyConfigurator.parseAppender(PropertyConfigurator.java:842); 	at org.apache.log4j.PropertyConfigurator.parseCategory(PropertyConfigurator.java:768); 	at org.apache.log4j.PropertyConfigurator.configureRootCategory(PropertyConfigurator.java:648); 	at org.apache.log4j.PropertyConfigurator.doConfigure(PropertyConfigurator.java:514); 	at org.apache.log4j.PropertyConfigurator.configure(PropertyConfigurator.java:440); 	at is.hail.HailContext$.configureLogging(HailContext.scala:132); 	at is.hail.HailContext$.apply(HailContext.scala:159); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:745); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-289>"", line 2, in __init__; File ""/opt/Software/",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-337768198
https://github.com/hail-is/hail/issues/2076#issuecomment-337768198:2369,Modifiability,config,configureLogging,2369,":270); 	at java.io.FileOutputStream.<init>(FileOutputStream.java:213); 	at java.io.FileOutputStream.<init>(FileOutputStream.java:133); 	at org.apache.log4j.FileAppender.setFile(FileAppender.java:294); 	at org.apache.log4j.FileAppender.activateOptions(FileAppender.java:165); 	at org.apache.log4j.config.PropertySetter.activate(PropertySetter.java:307); 	at org.apache.log4j.config.PropertySetter.setProperties(PropertySetter.java:172); 	at org.apache.log4j.config.PropertySetter.setProperties(PropertySetter.java:104); 	at org.apache.log4j.PropertyConfigurator.parseAppender(PropertyConfigurator.java:842); 	at org.apache.log4j.PropertyConfigurator.parseCategory(PropertyConfigurator.java:768); 	at org.apache.log4j.PropertyConfigurator.configureRootCategory(PropertyConfigurator.java:648); 	at org.apache.log4j.PropertyConfigurator.doConfigure(PropertyConfigurator.java:514); 	at org.apache.log4j.PropertyConfigurator.configure(PropertyConfigurator.java:440); 	at is.hail.HailContext$.configureLogging(HailContext.scala:132); 	at is.hail.HailContext$.apply(HailContext.scala:159); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:745); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-289>"", line 2, in __init__; File ""/opt/Software/hail/python/hail/java.py"", line 112, in handle_py4j; 'Error summar",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-337768198
https://github.com/hail-is/hail/issues/2076#issuecomment-337768198:390,Safety,detect,detected,390,"@danking ; The info is as follows:; ```; [root@mg hail]# su hdfs; bash-4.2$ pyspark --jars $HAIL_HOME/build/libs/hail-all-spark.jar --conf=spark.driver.extraClassPath=$HAIL_HOME/build/libs/hail-all-spark.jar --conf=spark.executor.extraClassPath=./hail-all-spark.jar; WARNING: User-defined SPARK_HOME (/opt/cloudera/parcels/SPARK2-2.2.0.cloudera1-1.cdh5.12.0.p0.142354/lib/spark2) overrides detected (/opt/cloudera/parcels/SPARK2/lib/spark2).; WARNING: Running pyspark from user-defined location.; Python 2.7.5 (default, Aug 4 2017, 00:39:18) ; [GCC 4.8.5 20150623 (Red Hat 4.8.5-16)] on linux2; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; 17/10/19 08:45:43 WARN util.Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.2.0.cloudera1; /_/. Using Python version 2.7.5 (default, Aug 4 2017 00:39:18); SparkSession available as 'spark'.; >>> import hail; >>> hc = hail.HailContext(); log4j:ERROR setFile(null,false) call failed.; java.io.FileNotFoundException: hail.log (Permission denied); 	at java.io.FileOutputStream.open0(Native Method); 	at java.io.FileOutputStream.open(FileOutputStream.java:270); 	at java.io.FileOutputStream.<init>(FileOutputStream.java:213); 	at java.io.FileOutputStream.<init>(FileOutputStream.java:133); 	at org.apache.log4j.FileAppender.setFile(FileAppender.java:294); 	at org.apache.log4j.FileAppender.activateOptions(FileAppender.java:165); 	at org.apache.log4j.config.PropertySetter.activate(PropertySetter.java:307); 	at org.apache.log4j.config.PropertySetter.setProperties(PropertySetter.java:172); 	at org.apache.log4j.config.PropertySetter.setProperties(PropertySetter.java:104); 	at org.apache.log4j.PropertyConfigurator.parseAppender(PropertyConfigurator.java:842); 	at org.apa",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-337768198
https://github.com/hail-is/hail/issues/2076#issuecomment-337768198:683,Testability,log,log,683,"@danking ; The info is as follows:; ```; [root@mg hail]# su hdfs; bash-4.2$ pyspark --jars $HAIL_HOME/build/libs/hail-all-spark.jar --conf=spark.driver.extraClassPath=$HAIL_HOME/build/libs/hail-all-spark.jar --conf=spark.executor.extraClassPath=./hail-all-spark.jar; WARNING: User-defined SPARK_HOME (/opt/cloudera/parcels/SPARK2-2.2.0.cloudera1-1.cdh5.12.0.p0.142354/lib/spark2) overrides detected (/opt/cloudera/parcels/SPARK2/lib/spark2).; WARNING: Running pyspark from user-defined location.; Python 2.7.5 (default, Aug 4 2017, 00:39:18) ; [GCC 4.8.5 20150623 (Red Hat 4.8.5-16)] on linux2; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; 17/10/19 08:45:43 WARN util.Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.2.0.cloudera1; /_/. Using Python version 2.7.5 (default, Aug 4 2017 00:39:18); SparkSession available as 'spark'.; >>> import hail; >>> hc = hail.HailContext(); log4j:ERROR setFile(null,false) call failed.; java.io.FileNotFoundException: hail.log (Permission denied); 	at java.io.FileOutputStream.open0(Native Method); 	at java.io.FileOutputStream.open(FileOutputStream.java:270); 	at java.io.FileOutputStream.<init>(FileOutputStream.java:213); 	at java.io.FileOutputStream.<init>(FileOutputStream.java:133); 	at org.apache.log4j.FileAppender.setFile(FileAppender.java:294); 	at org.apache.log4j.FileAppender.activateOptions(FileAppender.java:165); 	at org.apache.log4j.config.PropertySetter.activate(PropertySetter.java:307); 	at org.apache.log4j.config.PropertySetter.setProperties(PropertySetter.java:172); 	at org.apache.log4j.config.PropertySetter.setProperties(PropertySetter.java:104); 	at org.apache.log4j.PropertyConfigurator.parseAppender(PropertyConfigurator.java:842); 	at org.apa",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-337768198
https://github.com/hail-is/hail/issues/2076#issuecomment-337768198:715,Testability,log,logging,715,"@danking ; The info is as follows:; ```; [root@mg hail]# su hdfs; bash-4.2$ pyspark --jars $HAIL_HOME/build/libs/hail-all-spark.jar --conf=spark.driver.extraClassPath=$HAIL_HOME/build/libs/hail-all-spark.jar --conf=spark.executor.extraClassPath=./hail-all-spark.jar; WARNING: User-defined SPARK_HOME (/opt/cloudera/parcels/SPARK2-2.2.0.cloudera1-1.cdh5.12.0.p0.142354/lib/spark2) overrides detected (/opt/cloudera/parcels/SPARK2/lib/spark2).; WARNING: Running pyspark from user-defined location.; Python 2.7.5 (default, Aug 4 2017, 00:39:18) ; [GCC 4.8.5 20150623 (Red Hat 4.8.5-16)] on linux2; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; 17/10/19 08:45:43 WARN util.Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.2.0.cloudera1; /_/. Using Python version 2.7.5 (default, Aug 4 2017 00:39:18); SparkSession available as 'spark'.; >>> import hail; >>> hc = hail.HailContext(); log4j:ERROR setFile(null,false) call failed.; java.io.FileNotFoundException: hail.log (Permission denied); 	at java.io.FileOutputStream.open0(Native Method); 	at java.io.FileOutputStream.open(FileOutputStream.java:270); 	at java.io.FileOutputStream.<init>(FileOutputStream.java:213); 	at java.io.FileOutputStream.<init>(FileOutputStream.java:133); 	at org.apache.log4j.FileAppender.setFile(FileAppender.java:294); 	at org.apache.log4j.FileAppender.activateOptions(FileAppender.java:165); 	at org.apache.log4j.config.PropertySetter.activate(PropertySetter.java:307); 	at org.apache.log4j.config.PropertySetter.setProperties(PropertySetter.java:172); 	at org.apache.log4j.config.PropertySetter.setProperties(PropertySetter.java:104); 	at org.apache.log4j.PropertyConfigurator.parseAppender(PropertyConfigurator.java:842); 	at org.apa",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-337768198
https://github.com/hail-is/hail/issues/2076#issuecomment-337768198:1252,Testability,log,log,1252,"RNING: User-defined SPARK_HOME (/opt/cloudera/parcels/SPARK2-2.2.0.cloudera1-1.cdh5.12.0.p0.142354/lib/spark2) overrides detected (/opt/cloudera/parcels/SPARK2/lib/spark2).; WARNING: Running pyspark from user-defined location.; Python 2.7.5 (default, Aug 4 2017, 00:39:18) ; [GCC 4.8.5 20150623 (Red Hat 4.8.5-16)] on linux2; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; 17/10/19 08:45:43 WARN util.Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.2.0.cloudera1; /_/. Using Python version 2.7.5 (default, Aug 4 2017 00:39:18); SparkSession available as 'spark'.; >>> import hail; >>> hc = hail.HailContext(); log4j:ERROR setFile(null,false) call failed.; java.io.FileNotFoundException: hail.log (Permission denied); 	at java.io.FileOutputStream.open0(Native Method); 	at java.io.FileOutputStream.open(FileOutputStream.java:270); 	at java.io.FileOutputStream.<init>(FileOutputStream.java:213); 	at java.io.FileOutputStream.<init>(FileOutputStream.java:133); 	at org.apache.log4j.FileAppender.setFile(FileAppender.java:294); 	at org.apache.log4j.FileAppender.activateOptions(FileAppender.java:165); 	at org.apache.log4j.config.PropertySetter.activate(PropertySetter.java:307); 	at org.apache.log4j.config.PropertySetter.setProperties(PropertySetter.java:172); 	at org.apache.log4j.config.PropertySetter.setProperties(PropertySetter.java:104); 	at org.apache.log4j.PropertyConfigurator.parseAppender(PropertyConfigurator.java:842); 	at org.apache.log4j.PropertyConfigurator.parseCategory(PropertyConfigurator.java:768); 	at org.apache.log4j.PropertyConfigurator.configureRootCategory(PropertyConfigurator.java:648); 	at org.apache.log4j.PropertyConfigurator.doConfigure(PropertyConfigurator.java:514); 	at org.a",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-337768198
https://github.com/hail-is/hail/issues/2076#issuecomment-337912555:304,Security,access,access,304,Hail defaults to logging to `hail.log` in the working directory of the Spark process. Apparently the user running spark doesn't have permission to create files in its working directory. You might try ; ```python; hc = hail.HailContext(log='/tmp/hail.log'); ```. Or any other file to which you have write access.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-337912555
https://github.com/hail-is/hail/issues/2076#issuecomment-337912555:17,Testability,log,logging,17,Hail defaults to logging to `hail.log` in the working directory of the Spark process. Apparently the user running spark doesn't have permission to create files in its working directory. You might try ; ```python; hc = hail.HailContext(log='/tmp/hail.log'); ```. Or any other file to which you have write access.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-337912555
https://github.com/hail-is/hail/issues/2076#issuecomment-337912555:34,Testability,log,log,34,Hail defaults to logging to `hail.log` in the working directory of the Spark process. Apparently the user running spark doesn't have permission to create files in its working directory. You might try ; ```python; hc = hail.HailContext(log='/tmp/hail.log'); ```. Or any other file to which you have write access.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-337912555
https://github.com/hail-is/hail/issues/2076#issuecomment-337912555:235,Testability,log,log,235,Hail defaults to logging to `hail.log` in the working directory of the Spark process. Apparently the user running spark doesn't have permission to create files in its working directory. You might try ; ```python; hc = hail.HailContext(log='/tmp/hail.log'); ```. Or any other file to which you have write access.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-337912555
https://github.com/hail-is/hail/issues/2076#issuecomment-337912555:250,Testability,log,log,250,Hail defaults to logging to `hail.log` in the working directory of the Spark process. Apparently the user running spark doesn't have permission to create files in its working directory. You might try ; ```python; hc = hail.HailContext(log='/tmp/hail.log'); ```. Or any other file to which you have write access.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-337912555
https://github.com/hail-is/hail/issues/2076#issuecomment-337917356:338,Availability,Error,Error,338,"And what is this mean :; ```; EnvironmentError: no Hail context initialized, create one first; ```; how to initialize the hail context?; ```; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-289>"", line 2, in __init__; File ""/opt/Software/hail/python/hail/java.py"", line 112, in handle_py4j; 'Error summary: %s' % (deepest, full, Env.hc().version, deepest)); File ""/opt/Software/hail/python/hail/java.py"", line 42, in hc; raise EnvironmentError('no Hail context initialized, create one first'); EnvironmentError: no Hail context initialized, create one first; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-337917356
https://github.com/hail-is/hail/issues/2076#issuecomment-337918138:28,Availability,error,error,28,"That's all part of the same error. If you resolve the file permissions issue, then the HailContext can be successfully initialized. I'll report this confusing error message to the team.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-337918138
https://github.com/hail-is/hail/issues/2076#issuecomment-337918138:159,Availability,error,error,159,"That's all part of the same error. If you resolve the file permissions issue, then the HailContext can be successfully initialized. I'll report this confusing error message to the team.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-337918138
https://github.com/hail-is/hail/issues/2076#issuecomment-337918138:165,Integrability,message,message,165,"That's all part of the same error. If you resolve the file permissions issue, then the HailContext can be successfully initialized. I'll report this confusing error message to the team.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-337918138
https://github.com/hail-is/hail/issues/2076#issuecomment-338418807:691,Availability,Error,Error,691,"```; hail: info: SparkUI: http://10.131.101.159:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.1-f69b497; >>> print sc; <SparkContext master=yarn appName=PySparkShell>; >>> print hc; <hail.context.HailContext object at 0x1f15350>; >>> hc.import_vcf(); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; TypeError: import_vcf() takes at least 2 arguments (1 given); >>> hc.import_vcf('/hail/sample.vcf'); [Stage 0:> (0 + 1) / 2]Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-313>"", line 2, in import_vcf; File ""/opt/Software/hail/python/hail/java.py"", line 112, in handle_py4j; 'Error summary: %s' % (deepest, full, Env.hc().version, deepest)); hail.java.FatalError: SparkException: Failed to get broadcast_4_piece0 of broadcast_4. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 4 times, most recent failure: Lost task 0.3 in stage 0.0 (TID 6, com2, executor 1): java.io.IOException: org.apache.spark.SparkException: Failed to get broadcast_4_piece0 of broadcast_4; 	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1310); 	at org.apache.spark.broadcast.TorrentBroadcast.readBroadcastBlock(TorrentBroadcast.scala:206); 	at org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute(TorrentBroadcast.scala:66); 	at org.apache.spark.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:66); 	at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:96); 	at org.apache.spark.broadcast.Broadcast.value(Broadcast.scala:70); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:81); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-338418807
https://github.com/hail-is/hail/issues/2076#issuecomment-338418807:921,Availability,failure,failure,921,"```; hail: info: SparkUI: http://10.131.101.159:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.1-f69b497; >>> print sc; <SparkContext master=yarn appName=PySparkShell>; >>> print hc; <hail.context.HailContext object at 0x1f15350>; >>> hc.import_vcf(); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; TypeError: import_vcf() takes at least 2 arguments (1 given); >>> hc.import_vcf('/hail/sample.vcf'); [Stage 0:> (0 + 1) / 2]Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-313>"", line 2, in import_vcf; File ""/opt/Software/hail/python/hail/java.py"", line 112, in handle_py4j; 'Error summary: %s' % (deepest, full, Env.hc().version, deepest)); hail.java.FatalError: SparkException: Failed to get broadcast_4_piece0 of broadcast_4. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 4 times, most recent failure: Lost task 0.3 in stage 0.0 (TID 6, com2, executor 1): java.io.IOException: org.apache.spark.SparkException: Failed to get broadcast_4_piece0 of broadcast_4; 	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1310); 	at org.apache.spark.broadcast.TorrentBroadcast.readBroadcastBlock(TorrentBroadcast.scala:206); 	at org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute(TorrentBroadcast.scala:66); 	at org.apache.spark.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:66); 	at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:96); 	at org.apache.spark.broadcast.Broadcast.value(Broadcast.scala:70); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:81); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-338418807
https://github.com/hail-is/hail/issues/2076#issuecomment-338418807:978,Availability,failure,failure,978,"```; hail: info: SparkUI: http://10.131.101.159:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.1-f69b497; >>> print sc; <SparkContext master=yarn appName=PySparkShell>; >>> print hc; <hail.context.HailContext object at 0x1f15350>; >>> hc.import_vcf(); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; TypeError: import_vcf() takes at least 2 arguments (1 given); >>> hc.import_vcf('/hail/sample.vcf'); [Stage 0:> (0 + 1) / 2]Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-313>"", line 2, in import_vcf; File ""/opt/Software/hail/python/hail/java.py"", line 112, in handle_py4j; 'Error summary: %s' % (deepest, full, Env.hc().version, deepest)); hail.java.FatalError: SparkException: Failed to get broadcast_4_piece0 of broadcast_4. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 4 times, most recent failure: Lost task 0.3 in stage 0.0 (TID 6, com2, executor 1): java.io.IOException: org.apache.spark.SparkException: Failed to get broadcast_4_piece0 of broadcast_4; 	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1310); 	at org.apache.spark.broadcast.TorrentBroadcast.readBroadcastBlock(TorrentBroadcast.scala:206); 	at org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute(TorrentBroadcast.scala:66); 	at org.apache.spark.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:66); 	at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:96); 	at org.apache.spark.broadcast.Broadcast.value(Broadcast.scala:70); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:81); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-338418807
https://github.com/hail-is/hail/issues/2076#issuecomment-338418807:8612,Availability,Error,Error,8612,il.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748)org.apache.spark.SparkException: Failed to get broadcast_4_piece0 of broadcast_4; 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply$mcVI$sp(TorrentBroadcast.scala:178); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:150); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:150); 	at scala.collection.immutable.List.foreach(List.scala:381); 	at org.apache.spark.broadcast.TorrentBroadcast.org$apache$spark$broadcast$TorrentBroadcast$$readBlocks(TorrentBroadcast.scala:150); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1.apply(TorrentBroadcast.scala:222); 	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1303); 	at org.apache.spark.broadcast.TorrentBroadcast.readBroadcastBlock(TorrentBroadcast.scala:206); 	at org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute(TorrentBroadcast.scala:66); 	at org.apache.spark.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:66); 	at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:96); 	at org.apache.spark.broadcast.Broadcast.value(Broadcast.scala:70); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:81); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Hail version: 0.1-f69b497; Error summary: SparkException: Failed to get broadcast_4_piece0 of broadcast_4; >>> ; ```; @danking,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-338418807
https://github.com/hail-is/hail/issues/2076#issuecomment-338418807:1660,Energy Efficiency,schedul,scheduler,1660,"ine 112, in handle_py4j; 'Error summary: %s' % (deepest, full, Env.hc().version, deepest)); hail.java.FatalError: SparkException: Failed to get broadcast_4_piece0 of broadcast_4. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 4 times, most recent failure: Lost task 0.3 in stage 0.0 (TID 6, com2, executor 1): java.io.IOException: org.apache.spark.SparkException: Failed to get broadcast_4_piece0 of broadcast_4; 	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1310); 	at org.apache.spark.broadcast.TorrentBroadcast.readBroadcastBlock(TorrentBroadcast.scala:206); 	at org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute(TorrentBroadcast.scala:66); 	at org.apache.spark.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:66); 	at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:96); 	at org.apache.spark.broadcast.Broadcast.value(Broadcast.scala:70); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:81); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: org.apache.spark.SparkException: Failed to get broadcast_4_piece0 of broadcast_4; 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply$mcVI$sp(TorrentBroadcast.scala:178); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:150); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:150); 	at scala.collection.immutable.List.foreach(List.scala:381",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-338418807
https://github.com/hail-is/hail/issues/2076#issuecomment-338418807:1732,Energy Efficiency,schedul,scheduler,1732,"version, deepest)); hail.java.FatalError: SparkException: Failed to get broadcast_4_piece0 of broadcast_4. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 4 times, most recent failure: Lost task 0.3 in stage 0.0 (TID 6, com2, executor 1): java.io.IOException: org.apache.spark.SparkException: Failed to get broadcast_4_piece0 of broadcast_4; 	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1310); 	at org.apache.spark.broadcast.TorrentBroadcast.readBroadcastBlock(TorrentBroadcast.scala:206); 	at org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute(TorrentBroadcast.scala:66); 	at org.apache.spark.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:66); 	at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:96); 	at org.apache.spark.broadcast.Broadcast.value(Broadcast.scala:70); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:81); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: org.apache.spark.SparkException: Failed to get broadcast_4_piece0 of broadcast_4; 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply$mcVI$sp(TorrentBroadcast.scala:178); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:150); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:150); 	at scala.collection.immutable.List.foreach(List.scala:381); 	at org.apache.spark.broadcast.TorrentBroadcast.org$apache$spark$broa",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-338418807
https://github.com/hail-is/hail/issues/2076#issuecomment-338418807:3038,Energy Efficiency,schedul,scheduler,3038,d.java:748); Caused by: org.apache.spark.SparkException: Failed to get broadcast_4_piece0 of broadcast_4; 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply$mcVI$sp(TorrentBroadcast.scala:178); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:150); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:150); 	at scala.collection.immutable.List.foreach(List.scala:381); 	at org.apache.spark.broadcast.TorrentBroadcast.org$apache$spark$broadcast$TorrentBroadcast$$readBlocks(TorrentBroadcast.scala:150); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1.apply(TorrentBroadcast.scala:222); 	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1303); 	... 11 more. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apa,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-338418807
https://github.com/hail-is/hail/issues/2076#issuecomment-338418807:3078,Energy Efficiency,schedul,scheduler,3078,iled to get broadcast_4_piece0 of broadcast_4; 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply$mcVI$sp(TorrentBroadcast.scala:178); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:150); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:150); 	at scala.collection.immutable.List.foreach(List.scala:381); 	at org.apache.spark.broadcast.TorrentBroadcast.org$apache$spark$broadcast$TorrentBroadcast$$readBlocks(TorrentBroadcast.scala:150); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1.apply(TorrentBroadcast.scala:222); 	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1303); 	... 11 more. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-338418807
https://github.com/hail-is/hail/issues/2076#issuecomment-338418807:3177,Energy Efficiency,schedul,scheduler,3177,rrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply$mcVI$sp(TorrentBroadcast.scala:178); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:150); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:150); 	at scala.collection.immutable.List.foreach(List.scala:381); 	at org.apache.spark.broadcast.TorrentBroadcast.org$apache$spark$broadcast$TorrentBroadcast$$readBlocks(TorrentBroadcast.scala:150); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1.apply(TorrentBroadcast.scala:222); 	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1303); 	... 11 more. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProces,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-338418807
https://github.com/hail-is/hail/issues/2076#issuecomment-338418807:3275,Energy Efficiency,schedul,scheduler,3275,rrentBroadcast.scala:178); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:150); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:150); 	at scala.collection.immutable.List.foreach(List.scala:381); 	at org.apache.spark.broadcast.TorrentBroadcast.org$apache$spark$broadcast$TorrentBroadcast$$readBlocks(TorrentBroadcast.scala:150); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1.apply(TorrentBroadcast.scala:222); 	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1303); 	... 11 more. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoo,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-338418807
https://github.com/hail-is/hail/issues/2076#issuecomment-338418807:3529,Energy Efficiency,schedul,scheduler,3529,adcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:150); 	at scala.collection.immutable.List.foreach(List.scala:381); 	at org.apache.spark.broadcast.TorrentBroadcast.org$apache$spark$broadcast$TorrentBroadcast$$readBlocks(TorrentBroadcast.scala:150); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1.apply(TorrentBroadcast.scala:222); 	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1303); 	... 11 more. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2119); 	at org.apache.spark.rdd.RDD$$a,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-338418807
https://github.com/hail-is/hail/issues/2076#issuecomment-338418807:3610,Energy Efficiency,schedul,scheduler,3610,a.collection.immutable.List.foreach(List.scala:381); 	at org.apache.spark.broadcast.TorrentBroadcast.org$apache$spark$broadcast$TorrentBroadcast$$readBlocks(TorrentBroadcast.scala:150); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1.apply(TorrentBroadcast.scala:222); 	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1303); 	... 11 more. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2119); 	at org.apache.spark.rdd.RDD$$anonfun$fold$1.apply(RDD.scala:1089); 	at org.apache.spark.rdd.RDDOperationScope$.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-338418807
https://github.com/hail-is/hail/issues/2076#issuecomment-338418807:3716,Energy Efficiency,schedul,scheduler,3716,pache$spark$broadcast$TorrentBroadcast$$readBlocks(TorrentBroadcast.scala:150); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1.apply(TorrentBroadcast.scala:222); 	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1303); 	... 11 more. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2119); 	at org.apache.spark.rdd.RDD$$anonfun$fold$1.apply(RDD.scala:1089); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperation,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-338418807
https://github.com/hail-is/hail/issues/2076#issuecomment-338418807:3866,Energy Efficiency,schedul,scheduler,3866,Block$1.apply(TorrentBroadcast.scala:222); 	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1303); 	... 11 more. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2119); 	at org.apache.spark.rdd.RDD$$anonfun$fold$1.apply(RDD.scala:1089); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); 	at org.apache.spark.rdd.RDD.fold(RDD.scala:1083); 	at is.hail.utils.richUtil,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-338418807
https://github.com/hail-is/hail/issues/2076#issuecomment-338418807:3955,Energy Efficiency,schedul,scheduler,3955,ion(Utils.scala:1303); 	... 11 more. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2119); 	at org.apache.spark.rdd.RDD$$anonfun$fold$1.apply(RDD.scala:1089); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); 	at org.apache.spark.rdd.RDD.fold(RDD.scala:1083); 	at is.hail.utils.richUtils.RichRDD$.exists$extension(RichRDD.scala:26); 	at is.hail.utils.richUtils.RichRDD$.foral,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-338418807
https://github.com/hail-is/hail/issues/2076#issuecomment-338418807:4053,Energy Efficiency,schedul,scheduler,4053,er.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2119); 	at org.apache.spark.rdd.RDD$$anonfun$fold$1.apply(RDD.scala:1089); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); 	at org.apache.spark.rdd.RDD.fold(RDD.scala:1083); 	at is.hail.utils.richUtils.RichRDD$.exists$extension(RichRDD.scala:26); 	at is.hail.utils.richUtils.RichRDD$.forall$extension(RichRDD.scala:22); 	at is.hail.io.vcf.LoadVCF$.apply(LoadVCF.scala:286); 	at is.hail.H,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-338418807
https://github.com/hail-is/hail/issues/2076#issuecomment-338418807:4149,Energy Efficiency,schedul,scheduler,4149,; 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2119); 	at org.apache.spark.rdd.RDD$$anonfun$fold$1.apply(RDD.scala:1089); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); 	at org.apache.spark.rdd.RDD.fold(RDD.scala:1083); 	at is.hail.utils.richUtils.RichRDD$.exists$extension(RichRDD.scala:26); 	at is.hail.utils.richUtils.RichRDD$.forall$extension(RichRDD.scala:22); 	at is.hail.io.vcf.LoadVCF$.apply(LoadVCF.scala:286); 	at is.hail.HailContext.importVCFs(HailContext.scala:529); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(N,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-338418807
https://github.com/hail-is/hail/issues/2076#issuecomment-338418807:4314,Energy Efficiency,schedul,scheduler,4314,.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2119); 	at org.apache.spark.rdd.RDD$$anonfun$fold$1.apply(RDD.scala:1089); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); 	at org.apache.spark.rdd.RDD.fold(RDD.scala:1083); 	at is.hail.utils.richUtils.RichRDD$.exists$extension(RichRDD.scala:26); 	at is.hail.utils.richUtils.RichRDD$.forall$extension(RichRDD.scala:22); 	at is.hail.io.vcf.LoadVCF$.apply(LoadVCF.scala:286); 	at is.hail.HailContext.importVCFs(HailContext.scala:529); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMetho,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-338418807
https://github.com/hail-is/hail/issues/2076#issuecomment-338418807:6432,Energy Efficiency,schedul,scheduler,6432,(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:745)java.io.IOException: org.apache.spark.SparkException: Failed to get broadcast_4_piece0 of broadcast_4; 	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1310); 	at org.apache.spark.broadcast.TorrentBroadcast.readBroadcastBlock(TorrentBroadcast.scala:206); 	at org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute(TorrentBroadcast.scala:66); 	at org.apache.spark.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:66); 	at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:96); 	at org.apache.spark.broadcast.Broadcast.value(Broadcast.scala:70); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:81); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748)org.apache.spark.SparkException: Failed to get broadcast_4_piece0 of broadcast_4; 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply$mcVI$sp(TorrentBroadcast.scala:178); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:150); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:150); 	at scala.collection.immutable.List.foreach(List.scala:381); 	at org.ap,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-338418807
https://github.com/hail-is/hail/issues/2076#issuecomment-338418807:6504,Energy Efficiency,schedul,scheduler,6504,flectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:745)java.io.IOException: org.apache.spark.SparkException: Failed to get broadcast_4_piece0 of broadcast_4; 	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1310); 	at org.apache.spark.broadcast.TorrentBroadcast.readBroadcastBlock(TorrentBroadcast.scala:206); 	at org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute(TorrentBroadcast.scala:66); 	at org.apache.spark.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:66); 	at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:96); 	at org.apache.spark.broadcast.Broadcast.value(Broadcast.scala:70); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:81); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748)org.apache.spark.SparkException: Failed to get broadcast_4_piece0 of broadcast_4; 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply$mcVI$sp(TorrentBroadcast.scala:178); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:150); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:150); 	at scala.collection.immutable.List.foreach(List.scala:381); 	at org.apache.spark.broadcast.TorrentBroadcast.org$apache$spark$broadcast$Torrent,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-338418807
https://github.com/hail-is/hail/issues/2076#issuecomment-338418807:8189,Energy Efficiency,schedul,scheduler,8189,il.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748)org.apache.spark.SparkException: Failed to get broadcast_4_piece0 of broadcast_4; 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply$mcVI$sp(TorrentBroadcast.scala:178); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:150); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:150); 	at scala.collection.immutable.List.foreach(List.scala:381); 	at org.apache.spark.broadcast.TorrentBroadcast.org$apache$spark$broadcast$TorrentBroadcast$$readBlocks(TorrentBroadcast.scala:150); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1.apply(TorrentBroadcast.scala:222); 	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1303); 	at org.apache.spark.broadcast.TorrentBroadcast.readBroadcastBlock(TorrentBroadcast.scala:206); 	at org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute(TorrentBroadcast.scala:66); 	at org.apache.spark.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:66); 	at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:96); 	at org.apache.spark.broadcast.Broadcast.value(Broadcast.scala:70); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:81); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Hail version: 0.1-f69b497; Error summary: SparkException: Failed to get broadcast_4_piece0 of broadcast_4; >>> ; ```; @danking,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-338418807
https://github.com/hail-is/hail/issues/2076#issuecomment-338418807:8261,Energy Efficiency,schedul,scheduler,8261,il.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748)org.apache.spark.SparkException: Failed to get broadcast_4_piece0 of broadcast_4; 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply$mcVI$sp(TorrentBroadcast.scala:178); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:150); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:150); 	at scala.collection.immutable.List.foreach(List.scala:381); 	at org.apache.spark.broadcast.TorrentBroadcast.org$apache$spark$broadcast$TorrentBroadcast$$readBlocks(TorrentBroadcast.scala:150); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1.apply(TorrentBroadcast.scala:222); 	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1303); 	at org.apache.spark.broadcast.TorrentBroadcast.readBroadcastBlock(TorrentBroadcast.scala:206); 	at org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute(TorrentBroadcast.scala:66); 	at org.apache.spark.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:66); 	at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:96); 	at org.apache.spark.broadcast.Broadcast.value(Broadcast.scala:70); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:81); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Hail version: 0.1-f69b497; Error summary: SparkException: Failed to get broadcast_4_piece0 of broadcast_4; >>> ; ```; @danking,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-338418807
https://github.com/hail-is/hail/issues/2076#issuecomment-338418807:1857,Performance,concurren,concurrent,1857," org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 4 times, most recent failure: Lost task 0.3 in stage 0.0 (TID 6, com2, executor 1): java.io.IOException: org.apache.spark.SparkException: Failed to get broadcast_4_piece0 of broadcast_4; 	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1310); 	at org.apache.spark.broadcast.TorrentBroadcast.readBroadcastBlock(TorrentBroadcast.scala:206); 	at org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute(TorrentBroadcast.scala:66); 	at org.apache.spark.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:66); 	at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:96); 	at org.apache.spark.broadcast.Broadcast.value(Broadcast.scala:70); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:81); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: org.apache.spark.SparkException: Failed to get broadcast_4_piece0 of broadcast_4; 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply$mcVI$sp(TorrentBroadcast.scala:178); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:150); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:150); 	at scala.collection.immutable.List.foreach(List.scala:381); 	at org.apache.spark.broadcast.TorrentBroadcast.org$apache$spark$broadcast$TorrentBroadcast$$readBlocks(TorrentBroadcast.scala:150); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readB",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-338418807
https://github.com/hail-is/hail/issues/2076#issuecomment-338418807:1942,Performance,concurren,concurrent,1942,".0 failed 4 times, most recent failure: Lost task 0.3 in stage 0.0 (TID 6, com2, executor 1): java.io.IOException: org.apache.spark.SparkException: Failed to get broadcast_4_piece0 of broadcast_4; 	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1310); 	at org.apache.spark.broadcast.TorrentBroadcast.readBroadcastBlock(TorrentBroadcast.scala:206); 	at org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute(TorrentBroadcast.scala:66); 	at org.apache.spark.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:66); 	at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:96); 	at org.apache.spark.broadcast.Broadcast.value(Broadcast.scala:70); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:81); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: org.apache.spark.SparkException: Failed to get broadcast_4_piece0 of broadcast_4; 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply$mcVI$sp(TorrentBroadcast.scala:178); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:150); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:150); 	at scala.collection.immutable.List.foreach(List.scala:381); 	at org.apache.spark.broadcast.TorrentBroadcast.org$apache$spark$broadcast$TorrentBroadcast$$readBlocks(TorrentBroadcast.scala:150); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1.apply(TorrentBroadcast.scala:222); 	at org.apache.spark.util.Utils$.t",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-338418807
https://github.com/hail-is/hail/issues/2076#issuecomment-338418807:5010,Performance,Load,LoadVCF,5010,uler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2119); 	at org.apache.spark.rdd.RDD$$anonfun$fold$1.apply(RDD.scala:1089); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); 	at org.apache.spark.rdd.RDD.fold(RDD.scala:1083); 	at is.hail.utils.richUtils.RichRDD$.exists$extension(RichRDD.scala:26); 	at is.hail.utils.richUtils.RichRDD$.forall$extension(RichRDD.scala:22); 	at is.hail.io.vcf.LoadVCF$.apply(LoadVCF.scala:286); 	at is.hail.HailContext.importVCFs(HailContext.scala:529); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:745)java.io.IOException: org.apache.spark.SparkException: Failed to get broadcast_4_piece0 of broadcast_4; 	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1310); 	at org.apache.spark.broadcast,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-338418807
https://github.com/hail-is/hail/issues/2076#issuecomment-338418807:5025,Performance,Load,LoadVCF,5025,714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2119); 	at org.apache.spark.rdd.RDD$$anonfun$fold$1.apply(RDD.scala:1089); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); 	at org.apache.spark.rdd.RDD.fold(RDD.scala:1083); 	at is.hail.utils.richUtils.RichRDD$.exists$extension(RichRDD.scala:26); 	at is.hail.utils.richUtils.RichRDD$.forall$extension(RichRDD.scala:22); 	at is.hail.io.vcf.LoadVCF$.apply(LoadVCF.scala:286); 	at is.hail.HailContext.importVCFs(HailContext.scala:529); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:745)java.io.IOException: org.apache.spark.SparkException: Failed to get broadcast_4_piece0 of broadcast_4; 	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1310); 	at org.apache.spark.broadcast.TorrentBro,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-338418807
https://github.com/hail-is/hail/issues/2076#issuecomment-338418807:6629,Performance,concurren,concurrent,6629,ommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:745)java.io.IOException: org.apache.spark.SparkException: Failed to get broadcast_4_piece0 of broadcast_4; 	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1310); 	at org.apache.spark.broadcast.TorrentBroadcast.readBroadcastBlock(TorrentBroadcast.scala:206); 	at org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute(TorrentBroadcast.scala:66); 	at org.apache.spark.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:66); 	at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:96); 	at org.apache.spark.broadcast.Broadcast.value(Broadcast.scala:70); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:81); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748)org.apache.spark.SparkException: Failed to get broadcast_4_piece0 of broadcast_4; 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply$mcVI$sp(TorrentBroadcast.scala:178); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:150); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:150); 	at scala.collection.immutable.List.foreach(List.scala:381); 	at org.apache.spark.broadcast.TorrentBroadcast.org$apache$spark$broadcast$TorrentBroadcast$$readBlocks(TorrentBroadcast.scala:150); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-338418807
https://github.com/hail-is/hail/issues/2076#issuecomment-338418807:6714,Performance,concurren,concurrent,6714,j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:745)java.io.IOException: org.apache.spark.SparkException: Failed to get broadcast_4_piece0 of broadcast_4; 	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1310); 	at org.apache.spark.broadcast.TorrentBroadcast.readBroadcastBlock(TorrentBroadcast.scala:206); 	at org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute(TorrentBroadcast.scala:66); 	at org.apache.spark.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:66); 	at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:96); 	at org.apache.spark.broadcast.Broadcast.value(Broadcast.scala:70); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:81); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748)org.apache.spark.SparkException: Failed to get broadcast_4_piece0 of broadcast_4; 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply$mcVI$sp(TorrentBroadcast.scala:178); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:150); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:150); 	at scala.collection.immutable.List.foreach(List.scala:381); 	at org.apache.spark.broadcast.TorrentBroadcast.org$apache$spark$broadcast$TorrentBroadcast$$readBlocks(TorrentBroadcast.scala:150); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1.apply(TorrentBroadcast.scala:222); 	at org.apache.spark.util.Utils$.tryOrIOExcepti,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-338418807
https://github.com/hail-is/hail/issues/2076#issuecomment-338418807:8386,Performance,concurren,concurrent,8386,il.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748)org.apache.spark.SparkException: Failed to get broadcast_4_piece0 of broadcast_4; 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply$mcVI$sp(TorrentBroadcast.scala:178); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:150); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:150); 	at scala.collection.immutable.List.foreach(List.scala:381); 	at org.apache.spark.broadcast.TorrentBroadcast.org$apache$spark$broadcast$TorrentBroadcast$$readBlocks(TorrentBroadcast.scala:150); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1.apply(TorrentBroadcast.scala:222); 	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1303); 	at org.apache.spark.broadcast.TorrentBroadcast.readBroadcastBlock(TorrentBroadcast.scala:206); 	at org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute(TorrentBroadcast.scala:66); 	at org.apache.spark.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:66); 	at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:96); 	at org.apache.spark.broadcast.Broadcast.value(Broadcast.scala:70); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:81); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Hail version: 0.1-f69b497; Error summary: SparkException: Failed to get broadcast_4_piece0 of broadcast_4; >>> ; ```; @danking,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-338418807
https://github.com/hail-is/hail/issues/2076#issuecomment-338418807:8471,Performance,concurren,concurrent,8471,il.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748)org.apache.spark.SparkException: Failed to get broadcast_4_piece0 of broadcast_4; 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply$mcVI$sp(TorrentBroadcast.scala:178); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:150); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:150); 	at scala.collection.immutable.List.foreach(List.scala:381); 	at org.apache.spark.broadcast.TorrentBroadcast.org$apache$spark$broadcast$TorrentBroadcast$$readBlocks(TorrentBroadcast.scala:150); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1.apply(TorrentBroadcast.scala:222); 	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1303); 	at org.apache.spark.broadcast.TorrentBroadcast.readBroadcastBlock(TorrentBroadcast.scala:206); 	at org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute(TorrentBroadcast.scala:66); 	at org.apache.spark.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:66); 	at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:96); 	at org.apache.spark.broadcast.Broadcast.value(Broadcast.scala:70); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:81); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Hail version: 0.1-f69b497; Error summary: SparkException: Failed to get broadcast_4_piece0 of broadcast_4; >>> ; ```; @danking,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-338418807
https://github.com/hail-is/hail/issues/2076#issuecomment-338418807:900,Safety,abort,aborted,900,"```; hail: info: SparkUI: http://10.131.101.159:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.1-f69b497; >>> print sc; <SparkContext master=yarn appName=PySparkShell>; >>> print hc; <hail.context.HailContext object at 0x1f15350>; >>> hc.import_vcf(); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; TypeError: import_vcf() takes at least 2 arguments (1 given); >>> hc.import_vcf('/hail/sample.vcf'); [Stage 0:> (0 + 1) / 2]Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-313>"", line 2, in import_vcf; File ""/opt/Software/hail/python/hail/java.py"", line 112, in handle_py4j; 'Error summary: %s' % (deepest, full, Env.hc().version, deepest)); hail.java.FatalError: SparkException: Failed to get broadcast_4_piece0 of broadcast_4. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 4 times, most recent failure: Lost task 0.3 in stage 0.0 (TID 6, com2, executor 1): java.io.IOException: org.apache.spark.SparkException: Failed to get broadcast_4_piece0 of broadcast_4; 	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1310); 	at org.apache.spark.broadcast.TorrentBroadcast.readBroadcastBlock(TorrentBroadcast.scala:206); 	at org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute(TorrentBroadcast.scala:66); 	at org.apache.spark.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:66); 	at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:96); 	at org.apache.spark.broadcast.Broadcast.value(Broadcast.scala:70); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:81); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-338418807
https://github.com/hail-is/hail/issues/2076#issuecomment-338418807:3209,Safety,abort,abortStage,3209,n$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply$mcVI$sp(TorrentBroadcast.scala:178); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:150); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:150); 	at scala.collection.immutable.List.foreach(List.scala:381); 	at org.apache.spark.broadcast.TorrentBroadcast.org$apache$spark$broadcast$TorrentBroadcast$$readBlocks(TorrentBroadcast.scala:150); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1.apply(TorrentBroadcast.scala:222); 	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1303); 	... 11 more. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGSche,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-338418807
https://github.com/hail-is/hail/issues/2076#issuecomment-338418807:3307,Safety,abort,abortStage,3307,78); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:150); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:150); 	at scala.collection.immutable.List.foreach(List.scala:381); 	at org.apache.spark.broadcast.TorrentBroadcast.org$apache$spark$broadcast$TorrentBroadcast$$readBlocks(TorrentBroadcast.scala:150); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1.apply(TorrentBroadcast.scala:222); 	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1303); 	... 11 more. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.ap,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-338418807
https://github.com/hail-is/hail/issues/2076#issuecomment-338418807:3552,Safety,abort,abortStage,3552,locks$1.apply(TorrentBroadcast.scala:150); 	at scala.collection.immutable.List.foreach(List.scala:381); 	at org.apache.spark.broadcast.TorrentBroadcast.org$apache$spark$broadcast$TorrentBroadcast$$readBlocks(TorrentBroadcast.scala:150); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1.apply(TorrentBroadcast.scala:222); 	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1303); 	... 11 more. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2119); 	at org.apache.spark.rdd.RDD$$anonfun$fold$1.apply(RDD.scala:,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-338418807
https://github.com/hail-is/hail/issues/2076#issuecomment-338442661:614,Availability,Error,Error,614,"On Oct 21, 2017, at 1:27 PM, Sun-shan <notifications@github.com> wrote:. > hail: info: SparkUI: http://10.131.101.159:4040; > Welcome to; > __ __ <>__; > / // /__ __/ /; > / __ / _ `/ / /; > // //_,/// version 0.1-f69b497; > ; > print sc; > ; > >>> print hc >>> hc.import_vcf() Traceback (most recent call last): File """", line 1, in TypeError: import_vcf() takes at least 2 arguments (1 given) >>> hc.import_vcf('/hail/sample.vcf') [Stage 0:> (0 + 1) / 2]Traceback (most recent call last): File """", line 1, in File """", line 2, in import_vcf File ""/opt/Software/hail/python/hail/java.py"", line 112, in handle_py4j 'Error summary: %s' % (deepest, full, Env.hc().version, deepest)) hail.java.FatalError: SparkException: Failed to get broadcast_4_piece0 of broadcast_4. This type of Spark exception seems to be related to the configuration option spark.cleaner.ttl. Have you set that to a value other than the default?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-338442661
https://github.com/hail-is/hail/issues/2076#issuecomment-338442661:822,Deployability,configurat,configuration,822,"On Oct 21, 2017, at 1:27 PM, Sun-shan <notifications@github.com> wrote:. > hail: info: SparkUI: http://10.131.101.159:4040; > Welcome to; > __ __ <>__; > / // /__ __/ /; > / __ / _ `/ / /; > // //_,/// version 0.1-f69b497; > ; > print sc; > ; > >>> print hc >>> hc.import_vcf() Traceback (most recent call last): File """", line 1, in TypeError: import_vcf() takes at least 2 arguments (1 given) >>> hc.import_vcf('/hail/sample.vcf') [Stage 0:> (0 + 1) / 2]Traceback (most recent call last): File """", line 1, in File """", line 2, in import_vcf File ""/opt/Software/hail/python/hail/java.py"", line 112, in handle_py4j 'Error summary: %s' % (deepest, full, Env.hc().version, deepest)) hail.java.FatalError: SparkException: Failed to get broadcast_4_piece0 of broadcast_4. This type of Spark exception seems to be related to the configuration option spark.cleaner.ttl. Have you set that to a value other than the default?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-338442661
https://github.com/hail-is/hail/issues/2076#issuecomment-338442661:822,Modifiability,config,configuration,822,"On Oct 21, 2017, at 1:27 PM, Sun-shan <notifications@github.com> wrote:. > hail: info: SparkUI: http://10.131.101.159:4040; > Welcome to; > __ __ <>__; > / // /__ __/ /; > / __ / _ `/ / /; > // //_,/// version 0.1-f69b497; > ; > print sc; > ; > >>> print hc >>> hc.import_vcf() Traceback (most recent call last): File """", line 1, in TypeError: import_vcf() takes at least 2 arguments (1 given) >>> hc.import_vcf('/hail/sample.vcf') [Stage 0:> (0 + 1) / 2]Traceback (most recent call last): File """", line 1, in File """", line 2, in import_vcf File ""/opt/Software/hail/python/hail/java.py"", line 112, in handle_py4j 'Error summary: %s' % (deepest, full, Env.hc().version, deepest)) hail.java.FatalError: SparkException: Failed to get broadcast_4_piece0 of broadcast_4. This type of Spark exception seems to be related to the configuration option spark.cleaner.ttl. Have you set that to a value other than the default?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-338442661
https://github.com/hail-is/hail/issues/2076#issuecomment-338462427:81,Modifiability,variab,variables,81,"I didn't set that to a value,and kept it by default.; I have no idea about which variables should be set to some value, is there a guide to show all the variables I should set ? I didn't see something like this in the hail website?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-338462427
https://github.com/hail-is/hail/issues/2076#issuecomment-338462427:153,Modifiability,variab,variables,153,"I didn't set that to a value,and kept it by default.; I have no idea about which variables should be set to some value, is there a guide to show all the variables I should set ? I didn't see something like this in the hail website?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-338462427
https://github.com/hail-is/hail/issues/2076#issuecomment-338462427:131,Usability,guid,guide,131,"I didn't set that to a value,and kept it by default.; I have no idea about which variables should be set to some value, is there a guide to show all the variables I should set ? I didn't see something like this in the hail website?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-338462427
https://github.com/hail-is/hail/issues/2076#issuecomment-338716796:142,Availability,error,error,142,"If you start a HailContext with no arguments:; ```python; HailContext(); ```; then Hail does not require you to set any Spark variables. This error:; ```; hail.java.FatalError: SparkException: Failed to get broadcast_4_piece0 of broadcast_4; ```; is caused by a failure in your Spark cluster. I suggested investigating `spark.cleaner.ttl` due to [Spark bug 5594](https://issues.apache.org/jira/browse/SPARK-5594). This also seems to happen when [you're running more than one spark context at once](https://github.com/spark-jobserver/spark-jobserver/issues/147). You might also be encountering [Spark bug 116599](https://issues.apache.org/jira/browse/SPARK-16599). I think the most productive use of your time is to:; 1. restart your spark cluster; 2. ensure there are no pending jobs and no one will submit any jobs while you run the next steps; 3. start a fresh `pyspark` session; 4. execute your hail commands. If this _still_ fails, then I suspect your Spark cluster is misconfigured in some way.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-338716796
https://github.com/hail-is/hail/issues/2076#issuecomment-338716796:262,Availability,failure,failure,262,"If you start a HailContext with no arguments:; ```python; HailContext(); ```; then Hail does not require you to set any Spark variables. This error:; ```; hail.java.FatalError: SparkException: Failed to get broadcast_4_piece0 of broadcast_4; ```; is caused by a failure in your Spark cluster. I suggested investigating `spark.cleaner.ttl` due to [Spark bug 5594](https://issues.apache.org/jira/browse/SPARK-5594). This also seems to happen when [you're running more than one spark context at once](https://github.com/spark-jobserver/spark-jobserver/issues/147). You might also be encountering [Spark bug 116599](https://issues.apache.org/jira/browse/SPARK-16599). I think the most productive use of your time is to:; 1. restart your spark cluster; 2. ensure there are no pending jobs and no one will submit any jobs while you run the next steps; 3. start a fresh `pyspark` session; 4. execute your hail commands. If this _still_ fails, then I suspect your Spark cluster is misconfigured in some way.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-338716796
https://github.com/hail-is/hail/issues/2076#issuecomment-338716796:126,Modifiability,variab,variables,126,"If you start a HailContext with no arguments:; ```python; HailContext(); ```; then Hail does not require you to set any Spark variables. This error:; ```; hail.java.FatalError: SparkException: Failed to get broadcast_4_piece0 of broadcast_4; ```; is caused by a failure in your Spark cluster. I suggested investigating `spark.cleaner.ttl` due to [Spark bug 5594](https://issues.apache.org/jira/browse/SPARK-5594). This also seems to happen when [you're running more than one spark context at once](https://github.com/spark-jobserver/spark-jobserver/issues/147). You might also be encountering [Spark bug 116599](https://issues.apache.org/jira/browse/SPARK-16599). I think the most productive use of your time is to:; 1. restart your spark cluster; 2. ensure there are no pending jobs and no one will submit any jobs while you run the next steps; 3. start a fresh `pyspark` session; 4. execute your hail commands. If this _still_ fails, then I suspect your Spark cluster is misconfigured in some way.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-338716796
https://github.com/hail-is/hail/pull/2084#issuecomment-321332562:0,Integrability,Depend,Depends,0,Depends on #2063,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2084#issuecomment-321332562
https://github.com/hail-is/hail/pull/2086#issuecomment-321899435:43,Testability,test,test,43,@cseed Back to you. Is there a good way to test if it's actually working?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2086#issuecomment-321899435
https://github.com/hail-is/hail/pull/2089#issuecomment-321580378:134,Testability,benchmark,benchmarking,134,"Yeah, OK, this isn't great. Do you have exac sites file snippet you're using somewhere? I clearly need to start doing more systematic benchmarking.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2089#issuecomment-321580378
https://github.com/hail-is/hail/pull/2089#issuecomment-321580378:90,Usability,clear,clearly,90,"Yeah, OK, this isn't great. Do you have exac sites file snippet you're using somewhere? I clearly need to start doing more systematic benchmarking.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2089#issuecomment-321580378
https://github.com/hail-is/hail/pull/2089#issuecomment-321580612:40,Deployability,release,release,40,"I think this is the TSV from the public release, so I'll put it on a bucket.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2089#issuecomment-321580612
https://github.com/hail-is/hail/pull/2089#issuecomment-321885309:18,Performance,perform,performance,18,I think given the performance I'll need to take another try at this.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2089#issuecomment-321885309
https://github.com/hail-is/hail/pull/2089#issuecomment-322304632:66,Performance,perform,performance,66,Needed by https://github.com/hail-is/hail/pull/2097. Will address performance once Row is gone and we're pure unsafe.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2089#issuecomment-322304632
https://github.com/hail-is/hail/pull/2089#issuecomment-322304632:110,Safety,unsafe,unsafe,110,Needed by https://github.com/hail-is/hail/pull/2097. Will address performance once Row is gone and we're pure unsafe.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2089#issuecomment-322304632
https://github.com/hail-is/hail/pull/2093#issuecomment-321729305:41,Security,access,accessors,41,"The main point of this is to isolate the accessors in one place to make changing them easier, e.g. if we want to move the missing bits in structs to pack them more tightly, or make fields required, which is now almost trivial.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2093#issuecomment-321729305
https://github.com/hail-is/hail/pull/2097#issuecomment-322357572:68,Safety,Unsafe,UnsafeRow,68,@tpoterba Ready for another look. I now use the coders to serialize UnsafeRow and UnsafeIndexedSeq.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2097#issuecomment-322357572
https://github.com/hail-is/hail/pull/2097#issuecomment-322357572:82,Safety,Unsafe,UnsafeIndexedSeq,82,@tpoterba Ready for another look. I now use the coders to serialize UnsafeRow and UnsafeIndexedSeq.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2097#issuecomment-322357572
https://github.com/hail-is/hail/pull/2111#issuecomment-322775027:13,Modifiability,refactor,refactoring,13,Next step is refactoring KeyTable.keyedRDD to no longer separate the value columns completely - just pull out the key columns as a separate thing. Then we can fix the bug where outer joins strip the right-hand key.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2111#issuecomment-322775027
https://github.com/hail-is/hail/pull/2116#issuecomment-322951262:0,Integrability,Depend,Depends,0,Depends on #2111,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2116#issuecomment-322951262
https://github.com/hail-is/hail/pull/2120#issuecomment-327816767:6,Testability,test,tests,6,added tests + addressed comments. Back to you.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2120#issuecomment-327816767
https://github.com/hail-is/hail/pull/2127#issuecomment-325806107:24,Testability,test,testing,24,Closing while we set up testing.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2127#issuecomment-325806107
https://github.com/hail-is/hail/pull/2129#issuecomment-323611362:374,Availability,error,error,374,Now `hc.import_vcf('/Users/jbloom/data/bgz_error/sample_plain.vcf.bgz')` on mislabeled plaintext file gives:. ```; FatalError: ZipException: File does not conform to block gzip format. Java stack trace:; java.util.zip.ZipException: File does not conform to block gzip format.; 	at is.hail.io.compress.BGzipInputStream$BGzipHeader.<init>(BGzipInputStream.java:35); ```. This error message is closer to that thrown in the .gz case when reading a plain text file:. ```; FatalError: IOException: not a gzip file. Java stack trace:; java.io.IOException: not a gzip file; 	at org.apache.hadoop.io.compress.zlib.BuiltInGzipDecompressor; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2129#issuecomment-323611362
https://github.com/hail-is/hail/pull/2129#issuecomment-323611362:380,Integrability,message,message,380,Now `hc.import_vcf('/Users/jbloom/data/bgz_error/sample_plain.vcf.bgz')` on mislabeled plaintext file gives:. ```; FatalError: ZipException: File does not conform to block gzip format. Java stack trace:; java.util.zip.ZipException: File does not conform to block gzip format.; 	at is.hail.io.compress.BGzipInputStream$BGzipHeader.<init>(BGzipInputStream.java:35); ```. This error message is closer to that thrown in the .gz case when reading a plain text file:. ```; FatalError: IOException: not a gzip file. Java stack trace:; java.io.IOException: not a gzip file; 	at org.apache.hadoop.io.compress.zlib.BuiltInGzipDecompressor; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2129#issuecomment-323611362
https://github.com/hail-is/hail/pull/2132#issuecomment-325495835:199,Availability,fault,fault,199,"I need to investigate further, but now I see a segfault and I think it's coming from the LMM tests. I need to fix the `test-gcp.sh` script so that it looks for the coredump file in the case of a seg fault. ```; [Stage 2225:==========================================> (3 + 1) / 4]2017-08-28 21:47:32 Hail: INFO: No multiallelics detected.; 2017-08-28 21:47:32 Hail: INFO: Ordering unsorted dataset with network shuffle; 2017-08-28 21:47:33 Hail: WARN: called redundant split on an already split VDS; 2017-08-28 21:47:33 Hail: INFO: using 2 trios for transmission analysis; [Stage 2229:==========================================> (3 + 1) / 4]2017-08-28 21:47:35 Hail: INFO: while writing:; file:/tmp/hail.16cpq9RzwI7a/out.00000.txt; merge time: 65.459ms; 2017-08-28 21:47:35 Hail: INFO: No multiallelics detected.; 2017-08-28 21:47:35 Hail: INFO: Ordering unsorted dataset with network shuffle; [Stage 2234:============================================> (4 + 1) / 5]2017-08-28 21:47:37 Hail: WARN: Found 2 samples with missing sex information (not 1 or 2).; Missing sex identifiers: [ 0 ]; 2017-08-28 21:47:37 Hail: WARN: 2 samples discarded from .fam: sex of child is missing.; 2017-08-28 21:47:38 Hail: INFO: Found 250 samples in fam file.; 2017-08-28 21:47:38 Hail: INFO: Found 2000 variants in bim file.; 2017-08-28 21:47:38 Hail: INFO: Coerced sorted dataset; 2017-08-28 21:47:38 Hail: INFO: Modified the genotype schema with annotateGenotypesExpr.; Original: Struct{GT:Call}; New: Genotype; 2017-08-28 21:47:38 Hail: INFO: Reading table to impute column types; [Stage 2258:============================> (1 + 1) / 2]2017-08-28 21:47:40 Hail: INFO: Finished type imputation; Loading column `f0' as type String (imputed); Loading column `f1' as type String (imputed); Loading column `f2' as type Float64 (imputed); 2017-08-28 21:47:41 Hail: INFO: Reading table to impute column types; 2017-08-28 21:47:41 Hail: INFO: Finished type imputation; Loading column `f0' as type String (imputed); Loading colu",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2132#issuecomment-325495835
https://github.com/hail-is/hail/pull/2132#issuecomment-325495835:458,Availability,redundant,redundant,458,"I need to investigate further, but now I see a segfault and I think it's coming from the LMM tests. I need to fix the `test-gcp.sh` script so that it looks for the coredump file in the case of a seg fault. ```; [Stage 2225:==========================================> (3 + 1) / 4]2017-08-28 21:47:32 Hail: INFO: No multiallelics detected.; 2017-08-28 21:47:32 Hail: INFO: Ordering unsorted dataset with network shuffle; 2017-08-28 21:47:33 Hail: WARN: called redundant split on an already split VDS; 2017-08-28 21:47:33 Hail: INFO: using 2 trios for transmission analysis; [Stage 2229:==========================================> (3 + 1) / 4]2017-08-28 21:47:35 Hail: INFO: while writing:; file:/tmp/hail.16cpq9RzwI7a/out.00000.txt; merge time: 65.459ms; 2017-08-28 21:47:35 Hail: INFO: No multiallelics detected.; 2017-08-28 21:47:35 Hail: INFO: Ordering unsorted dataset with network shuffle; [Stage 2234:============================================> (4 + 1) / 5]2017-08-28 21:47:37 Hail: WARN: Found 2 samples with missing sex information (not 1 or 2).; Missing sex identifiers: [ 0 ]; 2017-08-28 21:47:37 Hail: WARN: 2 samples discarded from .fam: sex of child is missing.; 2017-08-28 21:47:38 Hail: INFO: Found 250 samples in fam file.; 2017-08-28 21:47:38 Hail: INFO: Found 2000 variants in bim file.; 2017-08-28 21:47:38 Hail: INFO: Coerced sorted dataset; 2017-08-28 21:47:38 Hail: INFO: Modified the genotype schema with annotateGenotypesExpr.; Original: Struct{GT:Call}; New: Genotype; 2017-08-28 21:47:38 Hail: INFO: Reading table to impute column types; [Stage 2258:============================> (1 + 1) / 2]2017-08-28 21:47:40 Hail: INFO: Finished type imputation; Loading column `f0' as type String (imputed); Loading column `f1' as type String (imputed); Loading column `f2' as type Float64 (imputed); 2017-08-28 21:47:41 Hail: INFO: Reading table to impute column types; 2017-08-28 21:47:41 Hail: INFO: Finished type imputation; Loading column `f0' as type String (imputed); Loading colu",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2132#issuecomment-325495835
https://github.com/hail-is/hail/pull/2132#issuecomment-325495835:5741,Availability,redundant,redundant,5741,"t: sigmaG2 = 0.13829390418697945; 2017-08-28 21:47:47 Hail: INFO: lmmreg: global model fit: sigmaE2 = 0.8304138510277874; 2017-08-28 21:47:47 Hail: INFO: lmmreg: global model fit: delta = 6.004703214575758; 2017-08-28 21:47:47 Hail: INFO: lmmreg: global model fit: h2 = 0.1427612233333665; 2017-08-28 21:47:47 Hail: INFO: lmmreg: global model fit: seH2 = 0.13770872661270844; 2017-08-28 21:47:48 Hail: INFO: Reading table with no type imputation; Loading column `Sample' as type `String' (type not specified); Loading column `Cov1' as type `Float64' (user-specified); Loading column `Cov2' as type `Float64' (user-specified). 2017-08-28 21:47:48 Hail: INFO: Reading table with no type imputation; Loading column `Sample' as type `String' (type not specified); Loading column `Pheno' as type `Float64' (user-specified). 2017-08-28 21:47:48 Hail: INFO: No multiallelics detected.; 2017-08-28 21:47:48 Hail: INFO: Coerced sorted dataset; 2017-08-28 21:47:48 Hail: WARN: called redundant `filtermulti' on an already split or multiallelic-filtered VDS; 2017-08-28 21:47:48 Hail: INFO: rrm: Computing Realized Relationship Matrix...; 2017-08-28 21:47:49 Hail: INFO: rrm: RRM computed using 3 variants.; 2017-08-28 21:47:49 Hail: WARN: 1 of 8 samples have a missing phenotype or covariate.; 2017-08-28 21:47:49 Hail: INFO: lmmreg: running lmmreg on 7 samples with 3 sample covariates including intercept...; 2017-08-28 21:47:49 Hail: INFO: lmmreg: Computing eigendecomposition of kinship matrix...; 2017-08-28 21:47:49 Hail: INFO: lmmreg: Estimating delta using REML... ; 2017-08-28 21:47:49 Hail: INFO: lmmreg: Evals 1 to 7: 3.09757, 2.66667, 2.23576, 0.00000, 0.00000, -0.00000, -0.00000; 2017-08-28 21:47:49 Hail: INFO: lmmreg: Evals 7 to 1: -0.00000, -0.00000, 0.00000, 0.00000, 2.23576, 2.66667, 3.09757; 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: beta = Map(intercept -> 0.48721539559123606, sa.cov.Cov1 -> 0.5924758486080468, sa.cov.Cov2 -> -0.23132255249379874); 2017-08-28 21:47:50 Ha",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2132#issuecomment-325495835
https://github.com/hail-is/hail/pull/2132#issuecomment-325495835:7392,Availability,fault,fault,7392,"uting eigendecomposition of kinship matrix...; 2017-08-28 21:47:49 Hail: INFO: lmmreg: Estimating delta using REML... ; 2017-08-28 21:47:49 Hail: INFO: lmmreg: Evals 1 to 7: 3.09757, 2.66667, 2.23576, 0.00000, 0.00000, -0.00000, -0.00000; 2017-08-28 21:47:49 Hail: INFO: lmmreg: Evals 7 to 1: -0.00000, -0.00000, 0.00000, 0.00000, 2.23576, 2.66667, 3.09757; 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: beta = Map(intercept -> 0.48721539559123606, sa.cov.Cov1 -> 0.5924758486080468, sa.cov.Cov2 -> -0.23132255249379874); 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: sigmaG2 = 0.25961182888248313; 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: sigmaE2 = 0.02099926061895032; 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: delta = 0.08088714874566029; 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: h2 = 0.9251659631261897; 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: seH2 = 0.11525741506951385; 2017-08-28 21:47:50 Hail: INFO: baldingnichols: generating genotypes for 10 populations, 100 samples, and 300 variants...; 2017-08-28 21:47:50 Hail: INFO: Coerced sorted dataset; bash: line 12: 5047 Segmentation fault spark-submit --class org.testng.TestNG --jars ./hail-all-spark-test.jar --conf ""spark.driver.extraClassPath=./hail-all-spark-test.jar"" --conf 'spark.executor.extraClassPath=./hail-all-spark-test.jar' ./hail-all-spark-test.jar ./testng.xml; + TEST_EXIT_CODE=139; + set -e; + gcloud --project broad-ctsa compute scp --recurse cluster-ci-d1n0nk3vmzf4-m:test-output test-output; scp: test-output: No such file or directory; ERROR: (gcloud.compute.scp) [/usr/bin/scp] exited with return code [1].; + cleanup; + gcloud --project broad-ctsa -q dataproc clusters delete --async cluster-ci-d1n0nk3vmzf4; Deleting [https://dataproc.googleapis.com/v1/projects/broad-ctsa/regions/global/clusters/cluster-ci-d1n0nk3vmzf4] with operation [projects/broad-ctsa/regions/global/operations/3a35ffb5-aac5-4329-9762-67a8f4fadf66].; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2132#issuecomment-325495835
https://github.com/hail-is/hail/pull/2132#issuecomment-325495835:7818,Availability,ERROR,ERROR,7818,"uting eigendecomposition of kinship matrix...; 2017-08-28 21:47:49 Hail: INFO: lmmreg: Estimating delta using REML... ; 2017-08-28 21:47:49 Hail: INFO: lmmreg: Evals 1 to 7: 3.09757, 2.66667, 2.23576, 0.00000, 0.00000, -0.00000, -0.00000; 2017-08-28 21:47:49 Hail: INFO: lmmreg: Evals 7 to 1: -0.00000, -0.00000, 0.00000, 0.00000, 2.23576, 2.66667, 3.09757; 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: beta = Map(intercept -> 0.48721539559123606, sa.cov.Cov1 -> 0.5924758486080468, sa.cov.Cov2 -> -0.23132255249379874); 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: sigmaG2 = 0.25961182888248313; 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: sigmaE2 = 0.02099926061895032; 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: delta = 0.08088714874566029; 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: h2 = 0.9251659631261897; 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: seH2 = 0.11525741506951385; 2017-08-28 21:47:50 Hail: INFO: baldingnichols: generating genotypes for 10 populations, 100 samples, and 300 variants...; 2017-08-28 21:47:50 Hail: INFO: Coerced sorted dataset; bash: line 12: 5047 Segmentation fault spark-submit --class org.testng.TestNG --jars ./hail-all-spark-test.jar --conf ""spark.driver.extraClassPath=./hail-all-spark-test.jar"" --conf 'spark.executor.extraClassPath=./hail-all-spark-test.jar' ./hail-all-spark-test.jar ./testng.xml; + TEST_EXIT_CODE=139; + set -e; + gcloud --project broad-ctsa compute scp --recurse cluster-ci-d1n0nk3vmzf4-m:test-output test-output; scp: test-output: No such file or directory; ERROR: (gcloud.compute.scp) [/usr/bin/scp] exited with return code [1].; + cleanup; + gcloud --project broad-ctsa -q dataproc clusters delete --async cluster-ci-d1n0nk3vmzf4; Deleting [https://dataproc.googleapis.com/v1/projects/broad-ctsa/regions/global/clusters/cluster-ci-d1n0nk3vmzf4] with operation [projects/broad-ctsa/regions/global/operations/3a35ffb5-aac5-4329-9762-67a8f4fadf66].; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2132#issuecomment-325495835
https://github.com/hail-is/hail/pull/2132#issuecomment-325495835:1676,Performance,Load,Loading,1676,"tected.; 2017-08-28 21:47:35 Hail: INFO: Ordering unsorted dataset with network shuffle; [Stage 2234:============================================> (4 + 1) / 5]2017-08-28 21:47:37 Hail: WARN: Found 2 samples with missing sex information (not 1 or 2).; Missing sex identifiers: [ 0 ]; 2017-08-28 21:47:37 Hail: WARN: 2 samples discarded from .fam: sex of child is missing.; 2017-08-28 21:47:38 Hail: INFO: Found 250 samples in fam file.; 2017-08-28 21:47:38 Hail: INFO: Found 2000 variants in bim file.; 2017-08-28 21:47:38 Hail: INFO: Coerced sorted dataset; 2017-08-28 21:47:38 Hail: INFO: Modified the genotype schema with annotateGenotypesExpr.; Original: Struct{GT:Call}; New: Genotype; 2017-08-28 21:47:38 Hail: INFO: Reading table to impute column types; [Stage 2258:============================> (1 + 1) / 2]2017-08-28 21:47:40 Hail: INFO: Finished type imputation; Loading column `f0' as type String (imputed); Loading column `f1' as type String (imputed); Loading column `f2' as type Float64 (imputed); 2017-08-28 21:47:41 Hail: INFO: Reading table to impute column types; 2017-08-28 21:47:41 Hail: INFO: Finished type imputation; Loading column `f0' as type String (imputed); Loading column `f1' as type String (imputed); Loading column `f2' as type Float64 (imputed); 2017-08-28 21:47:41 Hail: INFO: rrm: Computing Realized Relationship Matrix...; [Stage 2263:============================> (1 + 1) / 2]2017-08-28 21:47:44 Hail: INFO: rrm: RRM computed using 1000 variants.; 2017-08-28 21:47:45 Hail: INFO: lmmreg: running lmmreg on 250 samples with 2 sample covariates including intercept...; 2017-08-28 21:47:45 Hail: INFO: lmmreg: Computing eigendecomposition of kinship matrix...; 2017-08-28 21:47:45 Hail: INFO: lmmreg: Estimating delta using REML... ; 2017-08-28 21:47:45 Hail: INFO: lmmreg: Evals 1 to 20: 14.94768, 2.08278, 2.02984, 1.99490, 1.97532, 1.96462, 1.95253, 1.92972, 1.91744, 1.90489, 1.87748, 1.86775, 1.84180, 1.82938, 1.81619, 1.79946, 1.78303, 1.77441, 1.75651, 1.7511",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2132#issuecomment-325495835
https://github.com/hail-is/hail/pull/2132#issuecomment-325495835:1722,Performance,Load,Loading,1722,"tected.; 2017-08-28 21:47:35 Hail: INFO: Ordering unsorted dataset with network shuffle; [Stage 2234:============================================> (4 + 1) / 5]2017-08-28 21:47:37 Hail: WARN: Found 2 samples with missing sex information (not 1 or 2).; Missing sex identifiers: [ 0 ]; 2017-08-28 21:47:37 Hail: WARN: 2 samples discarded from .fam: sex of child is missing.; 2017-08-28 21:47:38 Hail: INFO: Found 250 samples in fam file.; 2017-08-28 21:47:38 Hail: INFO: Found 2000 variants in bim file.; 2017-08-28 21:47:38 Hail: INFO: Coerced sorted dataset; 2017-08-28 21:47:38 Hail: INFO: Modified the genotype schema with annotateGenotypesExpr.; Original: Struct{GT:Call}; New: Genotype; 2017-08-28 21:47:38 Hail: INFO: Reading table to impute column types; [Stage 2258:============================> (1 + 1) / 2]2017-08-28 21:47:40 Hail: INFO: Finished type imputation; Loading column `f0' as type String (imputed); Loading column `f1' as type String (imputed); Loading column `f2' as type Float64 (imputed); 2017-08-28 21:47:41 Hail: INFO: Reading table to impute column types; 2017-08-28 21:47:41 Hail: INFO: Finished type imputation; Loading column `f0' as type String (imputed); Loading column `f1' as type String (imputed); Loading column `f2' as type Float64 (imputed); 2017-08-28 21:47:41 Hail: INFO: rrm: Computing Realized Relationship Matrix...; [Stage 2263:============================> (1 + 1) / 2]2017-08-28 21:47:44 Hail: INFO: rrm: RRM computed using 1000 variants.; 2017-08-28 21:47:45 Hail: INFO: lmmreg: running lmmreg on 250 samples with 2 sample covariates including intercept...; 2017-08-28 21:47:45 Hail: INFO: lmmreg: Computing eigendecomposition of kinship matrix...; 2017-08-28 21:47:45 Hail: INFO: lmmreg: Estimating delta using REML... ; 2017-08-28 21:47:45 Hail: INFO: lmmreg: Evals 1 to 20: 14.94768, 2.08278, 2.02984, 1.99490, 1.97532, 1.96462, 1.95253, 1.92972, 1.91744, 1.90489, 1.87748, 1.86775, 1.84180, 1.82938, 1.81619, 1.79946, 1.78303, 1.77441, 1.75651, 1.7511",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2132#issuecomment-325495835
https://github.com/hail-is/hail/pull/2132#issuecomment-325495835:1768,Performance,Load,Loading,1768,"tected.; 2017-08-28 21:47:35 Hail: INFO: Ordering unsorted dataset with network shuffle; [Stage 2234:============================================> (4 + 1) / 5]2017-08-28 21:47:37 Hail: WARN: Found 2 samples with missing sex information (not 1 or 2).; Missing sex identifiers: [ 0 ]; 2017-08-28 21:47:37 Hail: WARN: 2 samples discarded from .fam: sex of child is missing.; 2017-08-28 21:47:38 Hail: INFO: Found 250 samples in fam file.; 2017-08-28 21:47:38 Hail: INFO: Found 2000 variants in bim file.; 2017-08-28 21:47:38 Hail: INFO: Coerced sorted dataset; 2017-08-28 21:47:38 Hail: INFO: Modified the genotype schema with annotateGenotypesExpr.; Original: Struct{GT:Call}; New: Genotype; 2017-08-28 21:47:38 Hail: INFO: Reading table to impute column types; [Stage 2258:============================> (1 + 1) / 2]2017-08-28 21:47:40 Hail: INFO: Finished type imputation; Loading column `f0' as type String (imputed); Loading column `f1' as type String (imputed); Loading column `f2' as type Float64 (imputed); 2017-08-28 21:47:41 Hail: INFO: Reading table to impute column types; 2017-08-28 21:47:41 Hail: INFO: Finished type imputation; Loading column `f0' as type String (imputed); Loading column `f1' as type String (imputed); Loading column `f2' as type Float64 (imputed); 2017-08-28 21:47:41 Hail: INFO: rrm: Computing Realized Relationship Matrix...; [Stage 2263:============================> (1 + 1) / 2]2017-08-28 21:47:44 Hail: INFO: rrm: RRM computed using 1000 variants.; 2017-08-28 21:47:45 Hail: INFO: lmmreg: running lmmreg on 250 samples with 2 sample covariates including intercept...; 2017-08-28 21:47:45 Hail: INFO: lmmreg: Computing eigendecomposition of kinship matrix...; 2017-08-28 21:47:45 Hail: INFO: lmmreg: Estimating delta using REML... ; 2017-08-28 21:47:45 Hail: INFO: lmmreg: Evals 1 to 20: 14.94768, 2.08278, 2.02984, 1.99490, 1.97532, 1.96462, 1.95253, 1.92972, 1.91744, 1.90489, 1.87748, 1.86775, 1.84180, 1.82938, 1.81619, 1.79946, 1.78303, 1.77441, 1.75651, 1.7511",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2132#issuecomment-325495835
https://github.com/hail-is/hail/pull/2132#issuecomment-325495835:1943,Performance,Load,Loading,1943,"tected.; 2017-08-28 21:47:35 Hail: INFO: Ordering unsorted dataset with network shuffle; [Stage 2234:============================================> (4 + 1) / 5]2017-08-28 21:47:37 Hail: WARN: Found 2 samples with missing sex information (not 1 or 2).; Missing sex identifiers: [ 0 ]; 2017-08-28 21:47:37 Hail: WARN: 2 samples discarded from .fam: sex of child is missing.; 2017-08-28 21:47:38 Hail: INFO: Found 250 samples in fam file.; 2017-08-28 21:47:38 Hail: INFO: Found 2000 variants in bim file.; 2017-08-28 21:47:38 Hail: INFO: Coerced sorted dataset; 2017-08-28 21:47:38 Hail: INFO: Modified the genotype schema with annotateGenotypesExpr.; Original: Struct{GT:Call}; New: Genotype; 2017-08-28 21:47:38 Hail: INFO: Reading table to impute column types; [Stage 2258:============================> (1 + 1) / 2]2017-08-28 21:47:40 Hail: INFO: Finished type imputation; Loading column `f0' as type String (imputed); Loading column `f1' as type String (imputed); Loading column `f2' as type Float64 (imputed); 2017-08-28 21:47:41 Hail: INFO: Reading table to impute column types; 2017-08-28 21:47:41 Hail: INFO: Finished type imputation; Loading column `f0' as type String (imputed); Loading column `f1' as type String (imputed); Loading column `f2' as type Float64 (imputed); 2017-08-28 21:47:41 Hail: INFO: rrm: Computing Realized Relationship Matrix...; [Stage 2263:============================> (1 + 1) / 2]2017-08-28 21:47:44 Hail: INFO: rrm: RRM computed using 1000 variants.; 2017-08-28 21:47:45 Hail: INFO: lmmreg: running lmmreg on 250 samples with 2 sample covariates including intercept...; 2017-08-28 21:47:45 Hail: INFO: lmmreg: Computing eigendecomposition of kinship matrix...; 2017-08-28 21:47:45 Hail: INFO: lmmreg: Estimating delta using REML... ; 2017-08-28 21:47:45 Hail: INFO: lmmreg: Evals 1 to 20: 14.94768, 2.08278, 2.02984, 1.99490, 1.97532, 1.96462, 1.95253, 1.92972, 1.91744, 1.90489, 1.87748, 1.86775, 1.84180, 1.82938, 1.81619, 1.79946, 1.78303, 1.77441, 1.75651, 1.7511",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2132#issuecomment-325495835
https://github.com/hail-is/hail/pull/2132#issuecomment-325495835:1989,Performance,Load,Loading,1989,"tected.; 2017-08-28 21:47:35 Hail: INFO: Ordering unsorted dataset with network shuffle; [Stage 2234:============================================> (4 + 1) / 5]2017-08-28 21:47:37 Hail: WARN: Found 2 samples with missing sex information (not 1 or 2).; Missing sex identifiers: [ 0 ]; 2017-08-28 21:47:37 Hail: WARN: 2 samples discarded from .fam: sex of child is missing.; 2017-08-28 21:47:38 Hail: INFO: Found 250 samples in fam file.; 2017-08-28 21:47:38 Hail: INFO: Found 2000 variants in bim file.; 2017-08-28 21:47:38 Hail: INFO: Coerced sorted dataset; 2017-08-28 21:47:38 Hail: INFO: Modified the genotype schema with annotateGenotypesExpr.; Original: Struct{GT:Call}; New: Genotype; 2017-08-28 21:47:38 Hail: INFO: Reading table to impute column types; [Stage 2258:============================> (1 + 1) / 2]2017-08-28 21:47:40 Hail: INFO: Finished type imputation; Loading column `f0' as type String (imputed); Loading column `f1' as type String (imputed); Loading column `f2' as type Float64 (imputed); 2017-08-28 21:47:41 Hail: INFO: Reading table to impute column types; 2017-08-28 21:47:41 Hail: INFO: Finished type imputation; Loading column `f0' as type String (imputed); Loading column `f1' as type String (imputed); Loading column `f2' as type Float64 (imputed); 2017-08-28 21:47:41 Hail: INFO: rrm: Computing Realized Relationship Matrix...; [Stage 2263:============================> (1 + 1) / 2]2017-08-28 21:47:44 Hail: INFO: rrm: RRM computed using 1000 variants.; 2017-08-28 21:47:45 Hail: INFO: lmmreg: running lmmreg on 250 samples with 2 sample covariates including intercept...; 2017-08-28 21:47:45 Hail: INFO: lmmreg: Computing eigendecomposition of kinship matrix...; 2017-08-28 21:47:45 Hail: INFO: lmmreg: Estimating delta using REML... ; 2017-08-28 21:47:45 Hail: INFO: lmmreg: Evals 1 to 20: 14.94768, 2.08278, 2.02984, 1.99490, 1.97532, 1.96462, 1.95253, 1.92972, 1.91744, 1.90489, 1.87748, 1.86775, 1.84180, 1.82938, 1.81619, 1.79946, 1.78303, 1.77441, 1.75651, 1.7511",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2132#issuecomment-325495835
https://github.com/hail-is/hail/pull/2132#issuecomment-325495835:2035,Performance,Load,Loading,2035,"tected.; 2017-08-28 21:47:35 Hail: INFO: Ordering unsorted dataset with network shuffle; [Stage 2234:============================================> (4 + 1) / 5]2017-08-28 21:47:37 Hail: WARN: Found 2 samples with missing sex information (not 1 or 2).; Missing sex identifiers: [ 0 ]; 2017-08-28 21:47:37 Hail: WARN: 2 samples discarded from .fam: sex of child is missing.; 2017-08-28 21:47:38 Hail: INFO: Found 250 samples in fam file.; 2017-08-28 21:47:38 Hail: INFO: Found 2000 variants in bim file.; 2017-08-28 21:47:38 Hail: INFO: Coerced sorted dataset; 2017-08-28 21:47:38 Hail: INFO: Modified the genotype schema with annotateGenotypesExpr.; Original: Struct{GT:Call}; New: Genotype; 2017-08-28 21:47:38 Hail: INFO: Reading table to impute column types; [Stage 2258:============================> (1 + 1) / 2]2017-08-28 21:47:40 Hail: INFO: Finished type imputation; Loading column `f0' as type String (imputed); Loading column `f1' as type String (imputed); Loading column `f2' as type Float64 (imputed); 2017-08-28 21:47:41 Hail: INFO: Reading table to impute column types; 2017-08-28 21:47:41 Hail: INFO: Finished type imputation; Loading column `f0' as type String (imputed); Loading column `f1' as type String (imputed); Loading column `f2' as type Float64 (imputed); 2017-08-28 21:47:41 Hail: INFO: rrm: Computing Realized Relationship Matrix...; [Stage 2263:============================> (1 + 1) / 2]2017-08-28 21:47:44 Hail: INFO: rrm: RRM computed using 1000 variants.; 2017-08-28 21:47:45 Hail: INFO: lmmreg: running lmmreg on 250 samples with 2 sample covariates including intercept...; 2017-08-28 21:47:45 Hail: INFO: lmmreg: Computing eigendecomposition of kinship matrix...; 2017-08-28 21:47:45 Hail: INFO: lmmreg: Estimating delta using REML... ; 2017-08-28 21:47:45 Hail: INFO: lmmreg: Evals 1 to 20: 14.94768, 2.08278, 2.02984, 1.99490, 1.97532, 1.96462, 1.95253, 1.92972, 1.91744, 1.90489, 1.87748, 1.86775, 1.84180, 1.82938, 1.81619, 1.79946, 1.78303, 1.77441, 1.75651, 1.7511",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2132#issuecomment-325495835
https://github.com/hail-is/hail/pull/2132#issuecomment-325495835:5214,Performance,Load,Loading,5214,".85950, 1.85650, 1.83358, 1.82607, 1.81018, 1.77451, 1.75714, 1.74538, 1.73411; 2017-08-28 21:47:47 Hail: INFO: lmmreg: Evals 250 to 230: 0.00000, 0.25129, 0.25898, 0.26631, 0.26798, 0.27447, 0.27757, 0.28447, 0.29418, 0.30385, 0.31053, 0.31348, 0.31638, 0.32141, 0.32747, 0.33643, 0.34130, 0.34292, 0.34890, 0.34984; 2017-08-28 21:47:47 Hail: INFO: lmmreg: global model fit: beta = Map(intercept -> 0.0370042272400176, sa.cov -> -0.012886009824596447); 2017-08-28 21:47:47 Hail: INFO: lmmreg: global model fit: sigmaG2 = 0.13829390418697945; 2017-08-28 21:47:47 Hail: INFO: lmmreg: global model fit: sigmaE2 = 0.8304138510277874; 2017-08-28 21:47:47 Hail: INFO: lmmreg: global model fit: delta = 6.004703214575758; 2017-08-28 21:47:47 Hail: INFO: lmmreg: global model fit: h2 = 0.1427612233333665; 2017-08-28 21:47:47 Hail: INFO: lmmreg: global model fit: seH2 = 0.13770872661270844; 2017-08-28 21:47:48 Hail: INFO: Reading table with no type imputation; Loading column `Sample' as type `String' (type not specified); Loading column `Cov1' as type `Float64' (user-specified); Loading column `Cov2' as type `Float64' (user-specified). 2017-08-28 21:47:48 Hail: INFO: Reading table with no type imputation; Loading column `Sample' as type `String' (type not specified); Loading column `Pheno' as type `Float64' (user-specified). 2017-08-28 21:47:48 Hail: INFO: No multiallelics detected.; 2017-08-28 21:47:48 Hail: INFO: Coerced sorted dataset; 2017-08-28 21:47:48 Hail: WARN: called redundant `filtermulti' on an already split or multiallelic-filtered VDS; 2017-08-28 21:47:48 Hail: INFO: rrm: Computing Realized Relationship Matrix...; 2017-08-28 21:47:49 Hail: INFO: rrm: RRM computed using 3 variants.; 2017-08-28 21:47:49 Hail: WARN: 1 of 8 samples have a missing phenotype or covariate.; 2017-08-28 21:47:49 Hail: INFO: lmmreg: running lmmreg on 7 samples with 3 sample covariates including intercept...; 2017-08-28 21:47:49 Hail: INFO: lmmreg: Computing eigendecomposition of kinship matrix...;",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2132#issuecomment-325495835
https://github.com/hail-is/hail/pull/2132#issuecomment-325495835:5277,Performance,Load,Loading,5277,".85950, 1.85650, 1.83358, 1.82607, 1.81018, 1.77451, 1.75714, 1.74538, 1.73411; 2017-08-28 21:47:47 Hail: INFO: lmmreg: Evals 250 to 230: 0.00000, 0.25129, 0.25898, 0.26631, 0.26798, 0.27447, 0.27757, 0.28447, 0.29418, 0.30385, 0.31053, 0.31348, 0.31638, 0.32141, 0.32747, 0.33643, 0.34130, 0.34292, 0.34890, 0.34984; 2017-08-28 21:47:47 Hail: INFO: lmmreg: global model fit: beta = Map(intercept -> 0.0370042272400176, sa.cov -> -0.012886009824596447); 2017-08-28 21:47:47 Hail: INFO: lmmreg: global model fit: sigmaG2 = 0.13829390418697945; 2017-08-28 21:47:47 Hail: INFO: lmmreg: global model fit: sigmaE2 = 0.8304138510277874; 2017-08-28 21:47:47 Hail: INFO: lmmreg: global model fit: delta = 6.004703214575758; 2017-08-28 21:47:47 Hail: INFO: lmmreg: global model fit: h2 = 0.1427612233333665; 2017-08-28 21:47:47 Hail: INFO: lmmreg: global model fit: seH2 = 0.13770872661270844; 2017-08-28 21:47:48 Hail: INFO: Reading table with no type imputation; Loading column `Sample' as type `String' (type not specified); Loading column `Cov1' as type `Float64' (user-specified); Loading column `Cov2' as type `Float64' (user-specified). 2017-08-28 21:47:48 Hail: INFO: Reading table with no type imputation; Loading column `Sample' as type `String' (type not specified); Loading column `Pheno' as type `Float64' (user-specified). 2017-08-28 21:47:48 Hail: INFO: No multiallelics detected.; 2017-08-28 21:47:48 Hail: INFO: Coerced sorted dataset; 2017-08-28 21:47:48 Hail: WARN: called redundant `filtermulti' on an already split or multiallelic-filtered VDS; 2017-08-28 21:47:48 Hail: INFO: rrm: Computing Realized Relationship Matrix...; 2017-08-28 21:47:49 Hail: INFO: rrm: RRM computed using 3 variants.; 2017-08-28 21:47:49 Hail: WARN: 1 of 8 samples have a missing phenotype or covariate.; 2017-08-28 21:47:49 Hail: INFO: lmmreg: running lmmreg on 7 samples with 3 sample covariates including intercept...; 2017-08-28 21:47:49 Hail: INFO: lmmreg: Computing eigendecomposition of kinship matrix...;",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2132#issuecomment-325495835
https://github.com/hail-is/hail/pull/2132#issuecomment-325495835:5335,Performance,Load,Loading,5335,".85950, 1.85650, 1.83358, 1.82607, 1.81018, 1.77451, 1.75714, 1.74538, 1.73411; 2017-08-28 21:47:47 Hail: INFO: lmmreg: Evals 250 to 230: 0.00000, 0.25129, 0.25898, 0.26631, 0.26798, 0.27447, 0.27757, 0.28447, 0.29418, 0.30385, 0.31053, 0.31348, 0.31638, 0.32141, 0.32747, 0.33643, 0.34130, 0.34292, 0.34890, 0.34984; 2017-08-28 21:47:47 Hail: INFO: lmmreg: global model fit: beta = Map(intercept -> 0.0370042272400176, sa.cov -> -0.012886009824596447); 2017-08-28 21:47:47 Hail: INFO: lmmreg: global model fit: sigmaG2 = 0.13829390418697945; 2017-08-28 21:47:47 Hail: INFO: lmmreg: global model fit: sigmaE2 = 0.8304138510277874; 2017-08-28 21:47:47 Hail: INFO: lmmreg: global model fit: delta = 6.004703214575758; 2017-08-28 21:47:47 Hail: INFO: lmmreg: global model fit: h2 = 0.1427612233333665; 2017-08-28 21:47:47 Hail: INFO: lmmreg: global model fit: seH2 = 0.13770872661270844; 2017-08-28 21:47:48 Hail: INFO: Reading table with no type imputation; Loading column `Sample' as type `String' (type not specified); Loading column `Cov1' as type `Float64' (user-specified); Loading column `Cov2' as type `Float64' (user-specified). 2017-08-28 21:47:48 Hail: INFO: Reading table with no type imputation; Loading column `Sample' as type `String' (type not specified); Loading column `Pheno' as type `Float64' (user-specified). 2017-08-28 21:47:48 Hail: INFO: No multiallelics detected.; 2017-08-28 21:47:48 Hail: INFO: Coerced sorted dataset; 2017-08-28 21:47:48 Hail: WARN: called redundant `filtermulti' on an already split or multiallelic-filtered VDS; 2017-08-28 21:47:48 Hail: INFO: rrm: Computing Realized Relationship Matrix...; 2017-08-28 21:47:49 Hail: INFO: rrm: RRM computed using 3 variants.; 2017-08-28 21:47:49 Hail: WARN: 1 of 8 samples have a missing phenotype or covariate.; 2017-08-28 21:47:49 Hail: INFO: lmmreg: running lmmreg on 7 samples with 3 sample covariates including intercept...; 2017-08-28 21:47:49 Hail: INFO: lmmreg: Computing eigendecomposition of kinship matrix...;",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2132#issuecomment-325495835
https://github.com/hail-is/hail/pull/2132#issuecomment-325495835:5464,Performance,Load,Loading,5464,"31053, 0.31348, 0.31638, 0.32141, 0.32747, 0.33643, 0.34130, 0.34292, 0.34890, 0.34984; 2017-08-28 21:47:47 Hail: INFO: lmmreg: global model fit: beta = Map(intercept -> 0.0370042272400176, sa.cov -> -0.012886009824596447); 2017-08-28 21:47:47 Hail: INFO: lmmreg: global model fit: sigmaG2 = 0.13829390418697945; 2017-08-28 21:47:47 Hail: INFO: lmmreg: global model fit: sigmaE2 = 0.8304138510277874; 2017-08-28 21:47:47 Hail: INFO: lmmreg: global model fit: delta = 6.004703214575758; 2017-08-28 21:47:47 Hail: INFO: lmmreg: global model fit: h2 = 0.1427612233333665; 2017-08-28 21:47:47 Hail: INFO: lmmreg: global model fit: seH2 = 0.13770872661270844; 2017-08-28 21:47:48 Hail: INFO: Reading table with no type imputation; Loading column `Sample' as type `String' (type not specified); Loading column `Cov1' as type `Float64' (user-specified); Loading column `Cov2' as type `Float64' (user-specified). 2017-08-28 21:47:48 Hail: INFO: Reading table with no type imputation; Loading column `Sample' as type `String' (type not specified); Loading column `Pheno' as type `Float64' (user-specified). 2017-08-28 21:47:48 Hail: INFO: No multiallelics detected.; 2017-08-28 21:47:48 Hail: INFO: Coerced sorted dataset; 2017-08-28 21:47:48 Hail: WARN: called redundant `filtermulti' on an already split or multiallelic-filtered VDS; 2017-08-28 21:47:48 Hail: INFO: rrm: Computing Realized Relationship Matrix...; 2017-08-28 21:47:49 Hail: INFO: rrm: RRM computed using 3 variants.; 2017-08-28 21:47:49 Hail: WARN: 1 of 8 samples have a missing phenotype or covariate.; 2017-08-28 21:47:49 Hail: INFO: lmmreg: running lmmreg on 7 samples with 3 sample covariates including intercept...; 2017-08-28 21:47:49 Hail: INFO: lmmreg: Computing eigendecomposition of kinship matrix...; 2017-08-28 21:47:49 Hail: INFO: lmmreg: Estimating delta using REML... ; 2017-08-28 21:47:49 Hail: INFO: lmmreg: Evals 1 to 7: 3.09757, 2.66667, 2.23576, 0.00000, 0.00000, -0.00000, -0.00000; 2017-08-28 21:47:49 Hail: INFO: lmmreg",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2132#issuecomment-325495835
https://github.com/hail-is/hail/pull/2132#issuecomment-325495835:5527,Performance,Load,Loading,5527,"31053, 0.31348, 0.31638, 0.32141, 0.32747, 0.33643, 0.34130, 0.34292, 0.34890, 0.34984; 2017-08-28 21:47:47 Hail: INFO: lmmreg: global model fit: beta = Map(intercept -> 0.0370042272400176, sa.cov -> -0.012886009824596447); 2017-08-28 21:47:47 Hail: INFO: lmmreg: global model fit: sigmaG2 = 0.13829390418697945; 2017-08-28 21:47:47 Hail: INFO: lmmreg: global model fit: sigmaE2 = 0.8304138510277874; 2017-08-28 21:47:47 Hail: INFO: lmmreg: global model fit: delta = 6.004703214575758; 2017-08-28 21:47:47 Hail: INFO: lmmreg: global model fit: h2 = 0.1427612233333665; 2017-08-28 21:47:47 Hail: INFO: lmmreg: global model fit: seH2 = 0.13770872661270844; 2017-08-28 21:47:48 Hail: INFO: Reading table with no type imputation; Loading column `Sample' as type `String' (type not specified); Loading column `Cov1' as type `Float64' (user-specified); Loading column `Cov2' as type `Float64' (user-specified). 2017-08-28 21:47:48 Hail: INFO: Reading table with no type imputation; Loading column `Sample' as type `String' (type not specified); Loading column `Pheno' as type `Float64' (user-specified). 2017-08-28 21:47:48 Hail: INFO: No multiallelics detected.; 2017-08-28 21:47:48 Hail: INFO: Coerced sorted dataset; 2017-08-28 21:47:48 Hail: WARN: called redundant `filtermulti' on an already split or multiallelic-filtered VDS; 2017-08-28 21:47:48 Hail: INFO: rrm: Computing Realized Relationship Matrix...; 2017-08-28 21:47:49 Hail: INFO: rrm: RRM computed using 3 variants.; 2017-08-28 21:47:49 Hail: WARN: 1 of 8 samples have a missing phenotype or covariate.; 2017-08-28 21:47:49 Hail: INFO: lmmreg: running lmmreg on 7 samples with 3 sample covariates including intercept...; 2017-08-28 21:47:49 Hail: INFO: lmmreg: Computing eigendecomposition of kinship matrix...; 2017-08-28 21:47:49 Hail: INFO: lmmreg: Estimating delta using REML... ; 2017-08-28 21:47:49 Hail: INFO: lmmreg: Evals 1 to 7: 3.09757, 2.66667, 2.23576, 0.00000, 0.00000, -0.00000, -0.00000; 2017-08-28 21:47:49 Hail: INFO: lmmreg",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2132#issuecomment-325495835
https://github.com/hail-is/hail/pull/2132#issuecomment-325495835:328,Safety,detect,detected,328,"I need to investigate further, but now I see a segfault and I think it's coming from the LMM tests. I need to fix the `test-gcp.sh` script so that it looks for the coredump file in the case of a seg fault. ```; [Stage 2225:==========================================> (3 + 1) / 4]2017-08-28 21:47:32 Hail: INFO: No multiallelics detected.; 2017-08-28 21:47:32 Hail: INFO: Ordering unsorted dataset with network shuffle; 2017-08-28 21:47:33 Hail: WARN: called redundant split on an already split VDS; 2017-08-28 21:47:33 Hail: INFO: using 2 trios for transmission analysis; [Stage 2229:==========================================> (3 + 1) / 4]2017-08-28 21:47:35 Hail: INFO: while writing:; file:/tmp/hail.16cpq9RzwI7a/out.00000.txt; merge time: 65.459ms; 2017-08-28 21:47:35 Hail: INFO: No multiallelics detected.; 2017-08-28 21:47:35 Hail: INFO: Ordering unsorted dataset with network shuffle; [Stage 2234:============================================> (4 + 1) / 5]2017-08-28 21:47:37 Hail: WARN: Found 2 samples with missing sex information (not 1 or 2).; Missing sex identifiers: [ 0 ]; 2017-08-28 21:47:37 Hail: WARN: 2 samples discarded from .fam: sex of child is missing.; 2017-08-28 21:47:38 Hail: INFO: Found 250 samples in fam file.; 2017-08-28 21:47:38 Hail: INFO: Found 2000 variants in bim file.; 2017-08-28 21:47:38 Hail: INFO: Coerced sorted dataset; 2017-08-28 21:47:38 Hail: INFO: Modified the genotype schema with annotateGenotypesExpr.; Original: Struct{GT:Call}; New: Genotype; 2017-08-28 21:47:38 Hail: INFO: Reading table to impute column types; [Stage 2258:============================> (1 + 1) / 2]2017-08-28 21:47:40 Hail: INFO: Finished type imputation; Loading column `f0' as type String (imputed); Loading column `f1' as type String (imputed); Loading column `f2' as type Float64 (imputed); 2017-08-28 21:47:41 Hail: INFO: Reading table to impute column types; 2017-08-28 21:47:41 Hail: INFO: Finished type imputation; Loading column `f0' as type String (imputed); Loading colu",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2132#issuecomment-325495835
https://github.com/hail-is/hail/pull/2132#issuecomment-325495835:458,Safety,redund,redundant,458,"I need to investigate further, but now I see a segfault and I think it's coming from the LMM tests. I need to fix the `test-gcp.sh` script so that it looks for the coredump file in the case of a seg fault. ```; [Stage 2225:==========================================> (3 + 1) / 4]2017-08-28 21:47:32 Hail: INFO: No multiallelics detected.; 2017-08-28 21:47:32 Hail: INFO: Ordering unsorted dataset with network shuffle; 2017-08-28 21:47:33 Hail: WARN: called redundant split on an already split VDS; 2017-08-28 21:47:33 Hail: INFO: using 2 trios for transmission analysis; [Stage 2229:==========================================> (3 + 1) / 4]2017-08-28 21:47:35 Hail: INFO: while writing:; file:/tmp/hail.16cpq9RzwI7a/out.00000.txt; merge time: 65.459ms; 2017-08-28 21:47:35 Hail: INFO: No multiallelics detected.; 2017-08-28 21:47:35 Hail: INFO: Ordering unsorted dataset with network shuffle; [Stage 2234:============================================> (4 + 1) / 5]2017-08-28 21:47:37 Hail: WARN: Found 2 samples with missing sex information (not 1 or 2).; Missing sex identifiers: [ 0 ]; 2017-08-28 21:47:37 Hail: WARN: 2 samples discarded from .fam: sex of child is missing.; 2017-08-28 21:47:38 Hail: INFO: Found 250 samples in fam file.; 2017-08-28 21:47:38 Hail: INFO: Found 2000 variants in bim file.; 2017-08-28 21:47:38 Hail: INFO: Coerced sorted dataset; 2017-08-28 21:47:38 Hail: INFO: Modified the genotype schema with annotateGenotypesExpr.; Original: Struct{GT:Call}; New: Genotype; 2017-08-28 21:47:38 Hail: INFO: Reading table to impute column types; [Stage 2258:============================> (1 + 1) / 2]2017-08-28 21:47:40 Hail: INFO: Finished type imputation; Loading column `f0' as type String (imputed); Loading column `f1' as type String (imputed); Loading column `f2' as type Float64 (imputed); 2017-08-28 21:47:41 Hail: INFO: Reading table to impute column types; 2017-08-28 21:47:41 Hail: INFO: Finished type imputation; Loading column `f0' as type String (imputed); Loading colu",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2132#issuecomment-325495835
https://github.com/hail-is/hail/pull/2132#issuecomment-325495835:802,Safety,detect,detected,802,"I need to investigate further, but now I see a segfault and I think it's coming from the LMM tests. I need to fix the `test-gcp.sh` script so that it looks for the coredump file in the case of a seg fault. ```; [Stage 2225:==========================================> (3 + 1) / 4]2017-08-28 21:47:32 Hail: INFO: No multiallelics detected.; 2017-08-28 21:47:32 Hail: INFO: Ordering unsorted dataset with network shuffle; 2017-08-28 21:47:33 Hail: WARN: called redundant split on an already split VDS; 2017-08-28 21:47:33 Hail: INFO: using 2 trios for transmission analysis; [Stage 2229:==========================================> (3 + 1) / 4]2017-08-28 21:47:35 Hail: INFO: while writing:; file:/tmp/hail.16cpq9RzwI7a/out.00000.txt; merge time: 65.459ms; 2017-08-28 21:47:35 Hail: INFO: No multiallelics detected.; 2017-08-28 21:47:35 Hail: INFO: Ordering unsorted dataset with network shuffle; [Stage 2234:============================================> (4 + 1) / 5]2017-08-28 21:47:37 Hail: WARN: Found 2 samples with missing sex information (not 1 or 2).; Missing sex identifiers: [ 0 ]; 2017-08-28 21:47:37 Hail: WARN: 2 samples discarded from .fam: sex of child is missing.; 2017-08-28 21:47:38 Hail: INFO: Found 250 samples in fam file.; 2017-08-28 21:47:38 Hail: INFO: Found 2000 variants in bim file.; 2017-08-28 21:47:38 Hail: INFO: Coerced sorted dataset; 2017-08-28 21:47:38 Hail: INFO: Modified the genotype schema with annotateGenotypesExpr.; Original: Struct{GT:Call}; New: Genotype; 2017-08-28 21:47:38 Hail: INFO: Reading table to impute column types; [Stage 2258:============================> (1 + 1) / 2]2017-08-28 21:47:40 Hail: INFO: Finished type imputation; Loading column `f0' as type String (imputed); Loading column `f1' as type String (imputed); Loading column `f2' as type Float64 (imputed); 2017-08-28 21:47:41 Hail: INFO: Reading table to impute column types; 2017-08-28 21:47:41 Hail: INFO: Finished type imputation; Loading column `f0' as type String (imputed); Loading colu",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2132#issuecomment-325495835
https://github.com/hail-is/hail/pull/2132#issuecomment-325495835:5635,Safety,detect,detected,5635,": global model fit: beta = Map(intercept -> 0.0370042272400176, sa.cov -> -0.012886009824596447); 2017-08-28 21:47:47 Hail: INFO: lmmreg: global model fit: sigmaG2 = 0.13829390418697945; 2017-08-28 21:47:47 Hail: INFO: lmmreg: global model fit: sigmaE2 = 0.8304138510277874; 2017-08-28 21:47:47 Hail: INFO: lmmreg: global model fit: delta = 6.004703214575758; 2017-08-28 21:47:47 Hail: INFO: lmmreg: global model fit: h2 = 0.1427612233333665; 2017-08-28 21:47:47 Hail: INFO: lmmreg: global model fit: seH2 = 0.13770872661270844; 2017-08-28 21:47:48 Hail: INFO: Reading table with no type imputation; Loading column `Sample' as type `String' (type not specified); Loading column `Cov1' as type `Float64' (user-specified); Loading column `Cov2' as type `Float64' (user-specified). 2017-08-28 21:47:48 Hail: INFO: Reading table with no type imputation; Loading column `Sample' as type `String' (type not specified); Loading column `Pheno' as type `Float64' (user-specified). 2017-08-28 21:47:48 Hail: INFO: No multiallelics detected.; 2017-08-28 21:47:48 Hail: INFO: Coerced sorted dataset; 2017-08-28 21:47:48 Hail: WARN: called redundant `filtermulti' on an already split or multiallelic-filtered VDS; 2017-08-28 21:47:48 Hail: INFO: rrm: Computing Realized Relationship Matrix...; 2017-08-28 21:47:49 Hail: INFO: rrm: RRM computed using 3 variants.; 2017-08-28 21:47:49 Hail: WARN: 1 of 8 samples have a missing phenotype or covariate.; 2017-08-28 21:47:49 Hail: INFO: lmmreg: running lmmreg on 7 samples with 3 sample covariates including intercept...; 2017-08-28 21:47:49 Hail: INFO: lmmreg: Computing eigendecomposition of kinship matrix...; 2017-08-28 21:47:49 Hail: INFO: lmmreg: Estimating delta using REML... ; 2017-08-28 21:47:49 Hail: INFO: lmmreg: Evals 1 to 7: 3.09757, 2.66667, 2.23576, 0.00000, 0.00000, -0.00000, -0.00000; 2017-08-28 21:47:49 Hail: INFO: lmmreg: Evals 7 to 1: -0.00000, -0.00000, 0.00000, 0.00000, 2.23576, 2.66667, 3.09757; 2017-08-28 21:47:50 Hail: INFO: lmmreg: globa",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2132#issuecomment-325495835
https://github.com/hail-is/hail/pull/2132#issuecomment-325495835:5741,Safety,redund,redundant,5741,"t: sigmaG2 = 0.13829390418697945; 2017-08-28 21:47:47 Hail: INFO: lmmreg: global model fit: sigmaE2 = 0.8304138510277874; 2017-08-28 21:47:47 Hail: INFO: lmmreg: global model fit: delta = 6.004703214575758; 2017-08-28 21:47:47 Hail: INFO: lmmreg: global model fit: h2 = 0.1427612233333665; 2017-08-28 21:47:47 Hail: INFO: lmmreg: global model fit: seH2 = 0.13770872661270844; 2017-08-28 21:47:48 Hail: INFO: Reading table with no type imputation; Loading column `Sample' as type `String' (type not specified); Loading column `Cov1' as type `Float64' (user-specified); Loading column `Cov2' as type `Float64' (user-specified). 2017-08-28 21:47:48 Hail: INFO: Reading table with no type imputation; Loading column `Sample' as type `String' (type not specified); Loading column `Pheno' as type `Float64' (user-specified). 2017-08-28 21:47:48 Hail: INFO: No multiallelics detected.; 2017-08-28 21:47:48 Hail: INFO: Coerced sorted dataset; 2017-08-28 21:47:48 Hail: WARN: called redundant `filtermulti' on an already split or multiallelic-filtered VDS; 2017-08-28 21:47:48 Hail: INFO: rrm: Computing Realized Relationship Matrix...; 2017-08-28 21:47:49 Hail: INFO: rrm: RRM computed using 3 variants.; 2017-08-28 21:47:49 Hail: WARN: 1 of 8 samples have a missing phenotype or covariate.; 2017-08-28 21:47:49 Hail: INFO: lmmreg: running lmmreg on 7 samples with 3 sample covariates including intercept...; 2017-08-28 21:47:49 Hail: INFO: lmmreg: Computing eigendecomposition of kinship matrix...; 2017-08-28 21:47:49 Hail: INFO: lmmreg: Estimating delta using REML... ; 2017-08-28 21:47:49 Hail: INFO: lmmreg: Evals 1 to 7: 3.09757, 2.66667, 2.23576, 0.00000, 0.00000, -0.00000, -0.00000; 2017-08-28 21:47:49 Hail: INFO: lmmreg: Evals 7 to 1: -0.00000, -0.00000, 0.00000, 0.00000, 2.23576, 2.66667, 3.09757; 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: beta = Map(intercept -> 0.48721539559123606, sa.cov.Cov1 -> 0.5924758486080468, sa.cov.Cov2 -> -0.23132255249379874); 2017-08-28 21:47:50 Ha",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2132#issuecomment-325495835
https://github.com/hail-is/hail/pull/2132#issuecomment-325495835:93,Testability,test,tests,93,"I need to investigate further, but now I see a segfault and I think it's coming from the LMM tests. I need to fix the `test-gcp.sh` script so that it looks for the coredump file in the case of a seg fault. ```; [Stage 2225:==========================================> (3 + 1) / 4]2017-08-28 21:47:32 Hail: INFO: No multiallelics detected.; 2017-08-28 21:47:32 Hail: INFO: Ordering unsorted dataset with network shuffle; 2017-08-28 21:47:33 Hail: WARN: called redundant split on an already split VDS; 2017-08-28 21:47:33 Hail: INFO: using 2 trios for transmission analysis; [Stage 2229:==========================================> (3 + 1) / 4]2017-08-28 21:47:35 Hail: INFO: while writing:; file:/tmp/hail.16cpq9RzwI7a/out.00000.txt; merge time: 65.459ms; 2017-08-28 21:47:35 Hail: INFO: No multiallelics detected.; 2017-08-28 21:47:35 Hail: INFO: Ordering unsorted dataset with network shuffle; [Stage 2234:============================================> (4 + 1) / 5]2017-08-28 21:47:37 Hail: WARN: Found 2 samples with missing sex information (not 1 or 2).; Missing sex identifiers: [ 0 ]; 2017-08-28 21:47:37 Hail: WARN: 2 samples discarded from .fam: sex of child is missing.; 2017-08-28 21:47:38 Hail: INFO: Found 250 samples in fam file.; 2017-08-28 21:47:38 Hail: INFO: Found 2000 variants in bim file.; 2017-08-28 21:47:38 Hail: INFO: Coerced sorted dataset; 2017-08-28 21:47:38 Hail: INFO: Modified the genotype schema with annotateGenotypesExpr.; Original: Struct{GT:Call}; New: Genotype; 2017-08-28 21:47:38 Hail: INFO: Reading table to impute column types; [Stage 2258:============================> (1 + 1) / 2]2017-08-28 21:47:40 Hail: INFO: Finished type imputation; Loading column `f0' as type String (imputed); Loading column `f1' as type String (imputed); Loading column `f2' as type Float64 (imputed); 2017-08-28 21:47:41 Hail: INFO: Reading table to impute column types; 2017-08-28 21:47:41 Hail: INFO: Finished type imputation; Loading column `f0' as type String (imputed); Loading colu",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2132#issuecomment-325495835
https://github.com/hail-is/hail/pull/2132#issuecomment-325495835:119,Testability,test,test-gcp,119,"I need to investigate further, but now I see a segfault and I think it's coming from the LMM tests. I need to fix the `test-gcp.sh` script so that it looks for the coredump file in the case of a seg fault. ```; [Stage 2225:==========================================> (3 + 1) / 4]2017-08-28 21:47:32 Hail: INFO: No multiallelics detected.; 2017-08-28 21:47:32 Hail: INFO: Ordering unsorted dataset with network shuffle; 2017-08-28 21:47:33 Hail: WARN: called redundant split on an already split VDS; 2017-08-28 21:47:33 Hail: INFO: using 2 trios for transmission analysis; [Stage 2229:==========================================> (3 + 1) / 4]2017-08-28 21:47:35 Hail: INFO: while writing:; file:/tmp/hail.16cpq9RzwI7a/out.00000.txt; merge time: 65.459ms; 2017-08-28 21:47:35 Hail: INFO: No multiallelics detected.; 2017-08-28 21:47:35 Hail: INFO: Ordering unsorted dataset with network shuffle; [Stage 2234:============================================> (4 + 1) / 5]2017-08-28 21:47:37 Hail: WARN: Found 2 samples with missing sex information (not 1 or 2).; Missing sex identifiers: [ 0 ]; 2017-08-28 21:47:37 Hail: WARN: 2 samples discarded from .fam: sex of child is missing.; 2017-08-28 21:47:38 Hail: INFO: Found 250 samples in fam file.; 2017-08-28 21:47:38 Hail: INFO: Found 2000 variants in bim file.; 2017-08-28 21:47:38 Hail: INFO: Coerced sorted dataset; 2017-08-28 21:47:38 Hail: INFO: Modified the genotype schema with annotateGenotypesExpr.; Original: Struct{GT:Call}; New: Genotype; 2017-08-28 21:47:38 Hail: INFO: Reading table to impute column types; [Stage 2258:============================> (1 + 1) / 2]2017-08-28 21:47:40 Hail: INFO: Finished type imputation; Loading column `f0' as type String (imputed); Loading column `f1' as type String (imputed); Loading column `f2' as type Float64 (imputed); 2017-08-28 21:47:41 Hail: INFO: Reading table to impute column types; 2017-08-28 21:47:41 Hail: INFO: Finished type imputation; Loading column `f0' as type String (imputed); Loading colu",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2132#issuecomment-325495835
https://github.com/hail-is/hail/pull/2132#issuecomment-325495835:7423,Testability,test,testng,7423,"uting eigendecomposition of kinship matrix...; 2017-08-28 21:47:49 Hail: INFO: lmmreg: Estimating delta using REML... ; 2017-08-28 21:47:49 Hail: INFO: lmmreg: Evals 1 to 7: 3.09757, 2.66667, 2.23576, 0.00000, 0.00000, -0.00000, -0.00000; 2017-08-28 21:47:49 Hail: INFO: lmmreg: Evals 7 to 1: -0.00000, -0.00000, 0.00000, 0.00000, 2.23576, 2.66667, 3.09757; 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: beta = Map(intercept -> 0.48721539559123606, sa.cov.Cov1 -> 0.5924758486080468, sa.cov.Cov2 -> -0.23132255249379874); 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: sigmaG2 = 0.25961182888248313; 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: sigmaE2 = 0.02099926061895032; 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: delta = 0.08088714874566029; 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: h2 = 0.9251659631261897; 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: seH2 = 0.11525741506951385; 2017-08-28 21:47:50 Hail: INFO: baldingnichols: generating genotypes for 10 populations, 100 samples, and 300 variants...; 2017-08-28 21:47:50 Hail: INFO: Coerced sorted dataset; bash: line 12: 5047 Segmentation fault spark-submit --class org.testng.TestNG --jars ./hail-all-spark-test.jar --conf ""spark.driver.extraClassPath=./hail-all-spark-test.jar"" --conf 'spark.executor.extraClassPath=./hail-all-spark-test.jar' ./hail-all-spark-test.jar ./testng.xml; + TEST_EXIT_CODE=139; + set -e; + gcloud --project broad-ctsa compute scp --recurse cluster-ci-d1n0nk3vmzf4-m:test-output test-output; scp: test-output: No such file or directory; ERROR: (gcloud.compute.scp) [/usr/bin/scp] exited with return code [1].; + cleanup; + gcloud --project broad-ctsa -q dataproc clusters delete --async cluster-ci-d1n0nk3vmzf4; Deleting [https://dataproc.googleapis.com/v1/projects/broad-ctsa/regions/global/clusters/cluster-ci-d1n0nk3vmzf4] with operation [projects/broad-ctsa/regions/global/operations/3a35ffb5-aac5-4329-9762-67a8f4fadf66].; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2132#issuecomment-325495835
https://github.com/hail-is/hail/pull/2132#issuecomment-325495835:7430,Testability,Test,TestNG,7430,"uting eigendecomposition of kinship matrix...; 2017-08-28 21:47:49 Hail: INFO: lmmreg: Estimating delta using REML... ; 2017-08-28 21:47:49 Hail: INFO: lmmreg: Evals 1 to 7: 3.09757, 2.66667, 2.23576, 0.00000, 0.00000, -0.00000, -0.00000; 2017-08-28 21:47:49 Hail: INFO: lmmreg: Evals 7 to 1: -0.00000, -0.00000, 0.00000, 0.00000, 2.23576, 2.66667, 3.09757; 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: beta = Map(intercept -> 0.48721539559123606, sa.cov.Cov1 -> 0.5924758486080468, sa.cov.Cov2 -> -0.23132255249379874); 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: sigmaG2 = 0.25961182888248313; 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: sigmaE2 = 0.02099926061895032; 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: delta = 0.08088714874566029; 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: h2 = 0.9251659631261897; 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: seH2 = 0.11525741506951385; 2017-08-28 21:47:50 Hail: INFO: baldingnichols: generating genotypes for 10 populations, 100 samples, and 300 variants...; 2017-08-28 21:47:50 Hail: INFO: Coerced sorted dataset; bash: line 12: 5047 Segmentation fault spark-submit --class org.testng.TestNG --jars ./hail-all-spark-test.jar --conf ""spark.driver.extraClassPath=./hail-all-spark-test.jar"" --conf 'spark.executor.extraClassPath=./hail-all-spark-test.jar' ./hail-all-spark-test.jar ./testng.xml; + TEST_EXIT_CODE=139; + set -e; + gcloud --project broad-ctsa compute scp --recurse cluster-ci-d1n0nk3vmzf4-m:test-output test-output; scp: test-output: No such file or directory; ERROR: (gcloud.compute.scp) [/usr/bin/scp] exited with return code [1].; + cleanup; + gcloud --project broad-ctsa -q dataproc clusters delete --async cluster-ci-d1n0nk3vmzf4; Deleting [https://dataproc.googleapis.com/v1/projects/broad-ctsa/regions/global/clusters/cluster-ci-d1n0nk3vmzf4] with operation [projects/broad-ctsa/regions/global/operations/3a35ffb5-aac5-4329-9762-67a8f4fadf66].; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2132#issuecomment-325495835
https://github.com/hail-is/hail/pull/2132#issuecomment-325495835:7461,Testability,test,test,7461,"uting eigendecomposition of kinship matrix...; 2017-08-28 21:47:49 Hail: INFO: lmmreg: Estimating delta using REML... ; 2017-08-28 21:47:49 Hail: INFO: lmmreg: Evals 1 to 7: 3.09757, 2.66667, 2.23576, 0.00000, 0.00000, -0.00000, -0.00000; 2017-08-28 21:47:49 Hail: INFO: lmmreg: Evals 7 to 1: -0.00000, -0.00000, 0.00000, 0.00000, 2.23576, 2.66667, 3.09757; 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: beta = Map(intercept -> 0.48721539559123606, sa.cov.Cov1 -> 0.5924758486080468, sa.cov.Cov2 -> -0.23132255249379874); 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: sigmaG2 = 0.25961182888248313; 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: sigmaE2 = 0.02099926061895032; 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: delta = 0.08088714874566029; 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: h2 = 0.9251659631261897; 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: seH2 = 0.11525741506951385; 2017-08-28 21:47:50 Hail: INFO: baldingnichols: generating genotypes for 10 populations, 100 samples, and 300 variants...; 2017-08-28 21:47:50 Hail: INFO: Coerced sorted dataset; bash: line 12: 5047 Segmentation fault spark-submit --class org.testng.TestNG --jars ./hail-all-spark-test.jar --conf ""spark.driver.extraClassPath=./hail-all-spark-test.jar"" --conf 'spark.executor.extraClassPath=./hail-all-spark-test.jar' ./hail-all-spark-test.jar ./testng.xml; + TEST_EXIT_CODE=139; + set -e; + gcloud --project broad-ctsa compute scp --recurse cluster-ci-d1n0nk3vmzf4-m:test-output test-output; scp: test-output: No such file or directory; ERROR: (gcloud.compute.scp) [/usr/bin/scp] exited with return code [1].; + cleanup; + gcloud --project broad-ctsa -q dataproc clusters delete --async cluster-ci-d1n0nk3vmzf4; Deleting [https://dataproc.googleapis.com/v1/projects/broad-ctsa/regions/global/clusters/cluster-ci-d1n0nk3vmzf4] with operation [projects/broad-ctsa/regions/global/operations/3a35ffb5-aac5-4329-9762-67a8f4fadf66].; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2132#issuecomment-325495835
https://github.com/hail-is/hail/pull/2132#issuecomment-325495835:7523,Testability,test,test,7523,"uting eigendecomposition of kinship matrix...; 2017-08-28 21:47:49 Hail: INFO: lmmreg: Estimating delta using REML... ; 2017-08-28 21:47:49 Hail: INFO: lmmreg: Evals 1 to 7: 3.09757, 2.66667, 2.23576, 0.00000, 0.00000, -0.00000, -0.00000; 2017-08-28 21:47:49 Hail: INFO: lmmreg: Evals 7 to 1: -0.00000, -0.00000, 0.00000, 0.00000, 2.23576, 2.66667, 3.09757; 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: beta = Map(intercept -> 0.48721539559123606, sa.cov.Cov1 -> 0.5924758486080468, sa.cov.Cov2 -> -0.23132255249379874); 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: sigmaG2 = 0.25961182888248313; 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: sigmaE2 = 0.02099926061895032; 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: delta = 0.08088714874566029; 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: h2 = 0.9251659631261897; 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: seH2 = 0.11525741506951385; 2017-08-28 21:47:50 Hail: INFO: baldingnichols: generating genotypes for 10 populations, 100 samples, and 300 variants...; 2017-08-28 21:47:50 Hail: INFO: Coerced sorted dataset; bash: line 12: 5047 Segmentation fault spark-submit --class org.testng.TestNG --jars ./hail-all-spark-test.jar --conf ""spark.driver.extraClassPath=./hail-all-spark-test.jar"" --conf 'spark.executor.extraClassPath=./hail-all-spark-test.jar' ./hail-all-spark-test.jar ./testng.xml; + TEST_EXIT_CODE=139; + set -e; + gcloud --project broad-ctsa compute scp --recurse cluster-ci-d1n0nk3vmzf4-m:test-output test-output; scp: test-output: No such file or directory; ERROR: (gcloud.compute.scp) [/usr/bin/scp] exited with return code [1].; + cleanup; + gcloud --project broad-ctsa -q dataproc clusters delete --async cluster-ci-d1n0nk3vmzf4; Deleting [https://dataproc.googleapis.com/v1/projects/broad-ctsa/regions/global/clusters/cluster-ci-d1n0nk3vmzf4] with operation [projects/broad-ctsa/regions/global/operations/3a35ffb5-aac5-4329-9762-67a8f4fadf66].; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2132#issuecomment-325495835
https://github.com/hail-is/hail/pull/2132#issuecomment-325495835:7588,Testability,test,test,7588,"uting eigendecomposition of kinship matrix...; 2017-08-28 21:47:49 Hail: INFO: lmmreg: Estimating delta using REML... ; 2017-08-28 21:47:49 Hail: INFO: lmmreg: Evals 1 to 7: 3.09757, 2.66667, 2.23576, 0.00000, 0.00000, -0.00000, -0.00000; 2017-08-28 21:47:49 Hail: INFO: lmmreg: Evals 7 to 1: -0.00000, -0.00000, 0.00000, 0.00000, 2.23576, 2.66667, 3.09757; 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: beta = Map(intercept -> 0.48721539559123606, sa.cov.Cov1 -> 0.5924758486080468, sa.cov.Cov2 -> -0.23132255249379874); 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: sigmaG2 = 0.25961182888248313; 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: sigmaE2 = 0.02099926061895032; 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: delta = 0.08088714874566029; 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: h2 = 0.9251659631261897; 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: seH2 = 0.11525741506951385; 2017-08-28 21:47:50 Hail: INFO: baldingnichols: generating genotypes for 10 populations, 100 samples, and 300 variants...; 2017-08-28 21:47:50 Hail: INFO: Coerced sorted dataset; bash: line 12: 5047 Segmentation fault spark-submit --class org.testng.TestNG --jars ./hail-all-spark-test.jar --conf ""spark.driver.extraClassPath=./hail-all-spark-test.jar"" --conf 'spark.executor.extraClassPath=./hail-all-spark-test.jar' ./hail-all-spark-test.jar ./testng.xml; + TEST_EXIT_CODE=139; + set -e; + gcloud --project broad-ctsa compute scp --recurse cluster-ci-d1n0nk3vmzf4-m:test-output test-output; scp: test-output: No such file or directory; ERROR: (gcloud.compute.scp) [/usr/bin/scp] exited with return code [1].; + cleanup; + gcloud --project broad-ctsa -q dataproc clusters delete --async cluster-ci-d1n0nk3vmzf4; Deleting [https://dataproc.googleapis.com/v1/projects/broad-ctsa/regions/global/clusters/cluster-ci-d1n0nk3vmzf4] with operation [projects/broad-ctsa/regions/global/operations/3a35ffb5-aac5-4329-9762-67a8f4fadf66].; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2132#issuecomment-325495835
https://github.com/hail-is/hail/pull/2132#issuecomment-325495835:7615,Testability,test,test,7615,"uting eigendecomposition of kinship matrix...; 2017-08-28 21:47:49 Hail: INFO: lmmreg: Estimating delta using REML... ; 2017-08-28 21:47:49 Hail: INFO: lmmreg: Evals 1 to 7: 3.09757, 2.66667, 2.23576, 0.00000, 0.00000, -0.00000, -0.00000; 2017-08-28 21:47:49 Hail: INFO: lmmreg: Evals 7 to 1: -0.00000, -0.00000, 0.00000, 0.00000, 2.23576, 2.66667, 3.09757; 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: beta = Map(intercept -> 0.48721539559123606, sa.cov.Cov1 -> 0.5924758486080468, sa.cov.Cov2 -> -0.23132255249379874); 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: sigmaG2 = 0.25961182888248313; 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: sigmaE2 = 0.02099926061895032; 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: delta = 0.08088714874566029; 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: h2 = 0.9251659631261897; 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: seH2 = 0.11525741506951385; 2017-08-28 21:47:50 Hail: INFO: baldingnichols: generating genotypes for 10 populations, 100 samples, and 300 variants...; 2017-08-28 21:47:50 Hail: INFO: Coerced sorted dataset; bash: line 12: 5047 Segmentation fault spark-submit --class org.testng.TestNG --jars ./hail-all-spark-test.jar --conf ""spark.driver.extraClassPath=./hail-all-spark-test.jar"" --conf 'spark.executor.extraClassPath=./hail-all-spark-test.jar' ./hail-all-spark-test.jar ./testng.xml; + TEST_EXIT_CODE=139; + set -e; + gcloud --project broad-ctsa compute scp --recurse cluster-ci-d1n0nk3vmzf4-m:test-output test-output; scp: test-output: No such file or directory; ERROR: (gcloud.compute.scp) [/usr/bin/scp] exited with return code [1].; + cleanup; + gcloud --project broad-ctsa -q dataproc clusters delete --async cluster-ci-d1n0nk3vmzf4; Deleting [https://dataproc.googleapis.com/v1/projects/broad-ctsa/regions/global/clusters/cluster-ci-d1n0nk3vmzf4] with operation [projects/broad-ctsa/regions/global/operations/3a35ffb5-aac5-4329-9762-67a8f4fadf66].; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2132#issuecomment-325495835
https://github.com/hail-is/hail/pull/2132#issuecomment-325495835:7626,Testability,test,testng,7626,"uting eigendecomposition of kinship matrix...; 2017-08-28 21:47:49 Hail: INFO: lmmreg: Estimating delta using REML... ; 2017-08-28 21:47:49 Hail: INFO: lmmreg: Evals 1 to 7: 3.09757, 2.66667, 2.23576, 0.00000, 0.00000, -0.00000, -0.00000; 2017-08-28 21:47:49 Hail: INFO: lmmreg: Evals 7 to 1: -0.00000, -0.00000, 0.00000, 0.00000, 2.23576, 2.66667, 3.09757; 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: beta = Map(intercept -> 0.48721539559123606, sa.cov.Cov1 -> 0.5924758486080468, sa.cov.Cov2 -> -0.23132255249379874); 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: sigmaG2 = 0.25961182888248313; 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: sigmaE2 = 0.02099926061895032; 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: delta = 0.08088714874566029; 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: h2 = 0.9251659631261897; 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: seH2 = 0.11525741506951385; 2017-08-28 21:47:50 Hail: INFO: baldingnichols: generating genotypes for 10 populations, 100 samples, and 300 variants...; 2017-08-28 21:47:50 Hail: INFO: Coerced sorted dataset; bash: line 12: 5047 Segmentation fault spark-submit --class org.testng.TestNG --jars ./hail-all-spark-test.jar --conf ""spark.driver.extraClassPath=./hail-all-spark-test.jar"" --conf 'spark.executor.extraClassPath=./hail-all-spark-test.jar' ./hail-all-spark-test.jar ./testng.xml; + TEST_EXIT_CODE=139; + set -e; + gcloud --project broad-ctsa compute scp --recurse cluster-ci-d1n0nk3vmzf4-m:test-output test-output; scp: test-output: No such file or directory; ERROR: (gcloud.compute.scp) [/usr/bin/scp] exited with return code [1].; + cleanup; + gcloud --project broad-ctsa -q dataproc clusters delete --async cluster-ci-d1n0nk3vmzf4; Deleting [https://dataproc.googleapis.com/v1/projects/broad-ctsa/regions/global/clusters/cluster-ci-d1n0nk3vmzf4] with operation [projects/broad-ctsa/regions/global/operations/3a35ffb5-aac5-4329-9762-67a8f4fadf66].; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2132#issuecomment-325495835
https://github.com/hail-is/hail/pull/2132#issuecomment-325495835:7748,Testability,test,test-output,7748,"uting eigendecomposition of kinship matrix...; 2017-08-28 21:47:49 Hail: INFO: lmmreg: Estimating delta using REML... ; 2017-08-28 21:47:49 Hail: INFO: lmmreg: Evals 1 to 7: 3.09757, 2.66667, 2.23576, 0.00000, 0.00000, -0.00000, -0.00000; 2017-08-28 21:47:49 Hail: INFO: lmmreg: Evals 7 to 1: -0.00000, -0.00000, 0.00000, 0.00000, 2.23576, 2.66667, 3.09757; 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: beta = Map(intercept -> 0.48721539559123606, sa.cov.Cov1 -> 0.5924758486080468, sa.cov.Cov2 -> -0.23132255249379874); 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: sigmaG2 = 0.25961182888248313; 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: sigmaE2 = 0.02099926061895032; 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: delta = 0.08088714874566029; 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: h2 = 0.9251659631261897; 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: seH2 = 0.11525741506951385; 2017-08-28 21:47:50 Hail: INFO: baldingnichols: generating genotypes for 10 populations, 100 samples, and 300 variants...; 2017-08-28 21:47:50 Hail: INFO: Coerced sorted dataset; bash: line 12: 5047 Segmentation fault spark-submit --class org.testng.TestNG --jars ./hail-all-spark-test.jar --conf ""spark.driver.extraClassPath=./hail-all-spark-test.jar"" --conf 'spark.executor.extraClassPath=./hail-all-spark-test.jar' ./hail-all-spark-test.jar ./testng.xml; + TEST_EXIT_CODE=139; + set -e; + gcloud --project broad-ctsa compute scp --recurse cluster-ci-d1n0nk3vmzf4-m:test-output test-output; scp: test-output: No such file or directory; ERROR: (gcloud.compute.scp) [/usr/bin/scp] exited with return code [1].; + cleanup; + gcloud --project broad-ctsa -q dataproc clusters delete --async cluster-ci-d1n0nk3vmzf4; Deleting [https://dataproc.googleapis.com/v1/projects/broad-ctsa/regions/global/clusters/cluster-ci-d1n0nk3vmzf4] with operation [projects/broad-ctsa/regions/global/operations/3a35ffb5-aac5-4329-9762-67a8f4fadf66].; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2132#issuecomment-325495835
https://github.com/hail-is/hail/pull/2132#issuecomment-325495835:7760,Testability,test,test-output,7760,"uting eigendecomposition of kinship matrix...; 2017-08-28 21:47:49 Hail: INFO: lmmreg: Estimating delta using REML... ; 2017-08-28 21:47:49 Hail: INFO: lmmreg: Evals 1 to 7: 3.09757, 2.66667, 2.23576, 0.00000, 0.00000, -0.00000, -0.00000; 2017-08-28 21:47:49 Hail: INFO: lmmreg: Evals 7 to 1: -0.00000, -0.00000, 0.00000, 0.00000, 2.23576, 2.66667, 3.09757; 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: beta = Map(intercept -> 0.48721539559123606, sa.cov.Cov1 -> 0.5924758486080468, sa.cov.Cov2 -> -0.23132255249379874); 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: sigmaG2 = 0.25961182888248313; 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: sigmaE2 = 0.02099926061895032; 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: delta = 0.08088714874566029; 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: h2 = 0.9251659631261897; 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: seH2 = 0.11525741506951385; 2017-08-28 21:47:50 Hail: INFO: baldingnichols: generating genotypes for 10 populations, 100 samples, and 300 variants...; 2017-08-28 21:47:50 Hail: INFO: Coerced sorted dataset; bash: line 12: 5047 Segmentation fault spark-submit --class org.testng.TestNG --jars ./hail-all-spark-test.jar --conf ""spark.driver.extraClassPath=./hail-all-spark-test.jar"" --conf 'spark.executor.extraClassPath=./hail-all-spark-test.jar' ./hail-all-spark-test.jar ./testng.xml; + TEST_EXIT_CODE=139; + set -e; + gcloud --project broad-ctsa compute scp --recurse cluster-ci-d1n0nk3vmzf4-m:test-output test-output; scp: test-output: No such file or directory; ERROR: (gcloud.compute.scp) [/usr/bin/scp] exited with return code [1].; + cleanup; + gcloud --project broad-ctsa -q dataproc clusters delete --async cluster-ci-d1n0nk3vmzf4; Deleting [https://dataproc.googleapis.com/v1/projects/broad-ctsa/regions/global/clusters/cluster-ci-d1n0nk3vmzf4] with operation [projects/broad-ctsa/regions/global/operations/3a35ffb5-aac5-4329-9762-67a8f4fadf66].; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2132#issuecomment-325495835
https://github.com/hail-is/hail/pull/2132#issuecomment-325495835:7778,Testability,test,test-output,7778,"uting eigendecomposition of kinship matrix...; 2017-08-28 21:47:49 Hail: INFO: lmmreg: Estimating delta using REML... ; 2017-08-28 21:47:49 Hail: INFO: lmmreg: Evals 1 to 7: 3.09757, 2.66667, 2.23576, 0.00000, 0.00000, -0.00000, -0.00000; 2017-08-28 21:47:49 Hail: INFO: lmmreg: Evals 7 to 1: -0.00000, -0.00000, 0.00000, 0.00000, 2.23576, 2.66667, 3.09757; 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: beta = Map(intercept -> 0.48721539559123606, sa.cov.Cov1 -> 0.5924758486080468, sa.cov.Cov2 -> -0.23132255249379874); 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: sigmaG2 = 0.25961182888248313; 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: sigmaE2 = 0.02099926061895032; 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: delta = 0.08088714874566029; 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: h2 = 0.9251659631261897; 2017-08-28 21:47:50 Hail: INFO: lmmreg: global model fit: seH2 = 0.11525741506951385; 2017-08-28 21:47:50 Hail: INFO: baldingnichols: generating genotypes for 10 populations, 100 samples, and 300 variants...; 2017-08-28 21:47:50 Hail: INFO: Coerced sorted dataset; bash: line 12: 5047 Segmentation fault spark-submit --class org.testng.TestNG --jars ./hail-all-spark-test.jar --conf ""spark.driver.extraClassPath=./hail-all-spark-test.jar"" --conf 'spark.executor.extraClassPath=./hail-all-spark-test.jar' ./hail-all-spark-test.jar ./testng.xml; + TEST_EXIT_CODE=139; + set -e; + gcloud --project broad-ctsa compute scp --recurse cluster-ci-d1n0nk3vmzf4-m:test-output test-output; scp: test-output: No such file or directory; ERROR: (gcloud.compute.scp) [/usr/bin/scp] exited with return code [1].; + cleanup; + gcloud --project broad-ctsa -q dataproc clusters delete --async cluster-ci-d1n0nk3vmzf4; Deleting [https://dataproc.googleapis.com/v1/projects/broad-ctsa/regions/global/clusters/cluster-ci-d1n0nk3vmzf4] with operation [projects/broad-ctsa/regions/global/operations/3a35ffb5-aac5-4329-9762-67a8f4fadf66].; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2132#issuecomment-325495835
https://github.com/hail-is/hail/pull/2132#issuecomment-325737476:271,Testability,log,log,271,"@jbloom22 disregard, I'm a dummy, I was compiling on the CI server and then submitting which, of course, resulted in a binary that had AVX2 instructions and the clusters we use don't have AVX2-capable processors. For the record, the useful information is stored in `/var/log/hadoop-yarn/userlogs/`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2132#issuecomment-325737476
https://github.com/hail-is/hail/pull/2132#issuecomment-326109741:89,Availability,failure,failures,89,@danking we should merge the delta change anyway as that's a bug that may result in test failures in the future (I just made PR of fix to 0.1). I think the log reg change is fine to go in as well.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2132#issuecomment-326109741
https://github.com/hail-is/hail/pull/2132#issuecomment-326109741:84,Testability,test,test,84,@danking we should merge the delta change anyway as that's a bug that may result in test failures in the future (I just made PR of fix to 0.1). I think the log reg change is fine to go in as well.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2132#issuecomment-326109741
https://github.com/hail-is/hail/pull/2132#issuecomment-326109741:156,Testability,log,log,156,@danking we should merge the delta change anyway as that's a bug that may result in test failures in the future (I just made PR of fix to 0.1). I think the log reg change is fine to go in as well.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2132#issuecomment-326109741
https://github.com/hail-is/hail/pull/2145#issuecomment-324995288:63,Availability,down,downloaded,63,"Has the math never rendered on the CI server? I see MathJax.js downloaded successfully but math isn't rendered, for example, in `lmmreg`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2145#issuecomment-324995288
https://github.com/hail-is/hail/pull/2147#issuecomment-324725390:27,Testability,test,test,27,"Also, can you add a larger test with 1024 elements? Maybe check 557th element is correct after 556 extractMax operations?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2147#issuecomment-324725390
https://github.com/hail-is/hail/pull/2148#issuecomment-326072568:933,Security,hash,hash,933,"In the worst case of a fully connected graph it's O(n) insertions, at an average cost of O(1), followed by O(n) `extractMax` which are O(log n) each. For each `extractMax` we have to decrease priority on every other node, so thats O(n^2) decreasePriority which is O(log n) each. So the dominating factor is O(n^2 log(n)). We should almost never see fully connected graphs. I suspect we'll usually have disconnected graphs of fully connected subgraphs. Then the runtime is O(m * n^2 log(n)) where `m` is the number of families and `n` is the average family size. `n` should be rather small, probably not higher than 20? probably smaller. `m` could be quite large, but we're linear in `m`. Some timings for fully connected graphs of size `n`:. | `n` | time (minutes) |; |-|-|; | 1024 | 0.0051 |; | 8192 | 0.13 |; | 32767 | 3.0 |; | 65535 | 12.5 |. According to the profiler, the vast majority of the time is spent interacting with the hash table. We could probably get the constants a lot lower by using an array instead of a hash table (since we have a perfect hash function: sample index). ---. ```; def fullyConnected(n: Int) {; val biggestFirst = new BinaryHeap[Int](). var i = 0; while (i <= n) {; biggestFirst.insert(i, n); i += 1; }. val g = (i: Int) => 0 to n. while (biggestFirst.maxPriority() > 0) {; val current = biggestFirst.extractMax(); val neighbors = g(current); neighbors.foreach { x =>; if (biggestFirst.contains(x)); biggestFirst.decreasePriority(x, _ - 1); }; }. val actual = biggestFirst.toArray; assert(actual.length === 1); }; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2148#issuecomment-326072568
https://github.com/hail-is/hail/pull/2148#issuecomment-326072568:1024,Security,hash,hash,1024,"In the worst case of a fully connected graph it's O(n) insertions, at an average cost of O(1), followed by O(n) `extractMax` which are O(log n) each. For each `extractMax` we have to decrease priority on every other node, so thats O(n^2) decreasePriority which is O(log n) each. So the dominating factor is O(n^2 log(n)). We should almost never see fully connected graphs. I suspect we'll usually have disconnected graphs of fully connected subgraphs. Then the runtime is O(m * n^2 log(n)) where `m` is the number of families and `n` is the average family size. `n` should be rather small, probably not higher than 20? probably smaller. `m` could be quite large, but we're linear in `m`. Some timings for fully connected graphs of size `n`:. | `n` | time (minutes) |; |-|-|; | 1024 | 0.0051 |; | 8192 | 0.13 |; | 32767 | 3.0 |; | 65535 | 12.5 |. According to the profiler, the vast majority of the time is spent interacting with the hash table. We could probably get the constants a lot lower by using an array instead of a hash table (since we have a perfect hash function: sample index). ---. ```; def fullyConnected(n: Int) {; val biggestFirst = new BinaryHeap[Int](). var i = 0; while (i <= n) {; biggestFirst.insert(i, n); i += 1; }. val g = (i: Int) => 0 to n. while (biggestFirst.maxPriority() > 0) {; val current = biggestFirst.extractMax(); val neighbors = g(current); neighbors.foreach { x =>; if (biggestFirst.contains(x)); biggestFirst.decreasePriority(x, _ - 1); }; }. val actual = biggestFirst.toArray; assert(actual.length === 1); }; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2148#issuecomment-326072568
https://github.com/hail-is/hail/pull/2148#issuecomment-326072568:1060,Security,hash,hash,1060,"In the worst case of a fully connected graph it's O(n) insertions, at an average cost of O(1), followed by O(n) `extractMax` which are O(log n) each. For each `extractMax` we have to decrease priority on every other node, so thats O(n^2) decreasePriority which is O(log n) each. So the dominating factor is O(n^2 log(n)). We should almost never see fully connected graphs. I suspect we'll usually have disconnected graphs of fully connected subgraphs. Then the runtime is O(m * n^2 log(n)) where `m` is the number of families and `n` is the average family size. `n` should be rather small, probably not higher than 20? probably smaller. `m` could be quite large, but we're linear in `m`. Some timings for fully connected graphs of size `n`:. | `n` | time (minutes) |; |-|-|; | 1024 | 0.0051 |; | 8192 | 0.13 |; | 32767 | 3.0 |; | 65535 | 12.5 |. According to the profiler, the vast majority of the time is spent interacting with the hash table. We could probably get the constants a lot lower by using an array instead of a hash table (since we have a perfect hash function: sample index). ---. ```; def fullyConnected(n: Int) {; val biggestFirst = new BinaryHeap[Int](). var i = 0; while (i <= n) {; biggestFirst.insert(i, n); i += 1; }. val g = (i: Int) => 0 to n. while (biggestFirst.maxPriority() > 0) {; val current = biggestFirst.extractMax(); val neighbors = g(current); neighbors.foreach { x =>; if (biggestFirst.contains(x)); biggestFirst.decreasePriority(x, _ - 1); }; }. val actual = biggestFirst.toArray; assert(actual.length === 1); }; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2148#issuecomment-326072568
https://github.com/hail-is/hail/pull/2148#issuecomment-326072568:137,Testability,log,log,137,"In the worst case of a fully connected graph it's O(n) insertions, at an average cost of O(1), followed by O(n) `extractMax` which are O(log n) each. For each `extractMax` we have to decrease priority on every other node, so thats O(n^2) decreasePriority which is O(log n) each. So the dominating factor is O(n^2 log(n)). We should almost never see fully connected graphs. I suspect we'll usually have disconnected graphs of fully connected subgraphs. Then the runtime is O(m * n^2 log(n)) where `m` is the number of families and `n` is the average family size. `n` should be rather small, probably not higher than 20? probably smaller. `m` could be quite large, but we're linear in `m`. Some timings for fully connected graphs of size `n`:. | `n` | time (minutes) |; |-|-|; | 1024 | 0.0051 |; | 8192 | 0.13 |; | 32767 | 3.0 |; | 65535 | 12.5 |. According to the profiler, the vast majority of the time is spent interacting with the hash table. We could probably get the constants a lot lower by using an array instead of a hash table (since we have a perfect hash function: sample index). ---. ```; def fullyConnected(n: Int) {; val biggestFirst = new BinaryHeap[Int](). var i = 0; while (i <= n) {; biggestFirst.insert(i, n); i += 1; }. val g = (i: Int) => 0 to n. while (biggestFirst.maxPriority() > 0) {; val current = biggestFirst.extractMax(); val neighbors = g(current); neighbors.foreach { x =>; if (biggestFirst.contains(x)); biggestFirst.decreasePriority(x, _ - 1); }; }. val actual = biggestFirst.toArray; assert(actual.length === 1); }; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2148#issuecomment-326072568
https://github.com/hail-is/hail/pull/2148#issuecomment-326072568:266,Testability,log,log,266,"In the worst case of a fully connected graph it's O(n) insertions, at an average cost of O(1), followed by O(n) `extractMax` which are O(log n) each. For each `extractMax` we have to decrease priority on every other node, so thats O(n^2) decreasePriority which is O(log n) each. So the dominating factor is O(n^2 log(n)). We should almost never see fully connected graphs. I suspect we'll usually have disconnected graphs of fully connected subgraphs. Then the runtime is O(m * n^2 log(n)) where `m` is the number of families and `n` is the average family size. `n` should be rather small, probably not higher than 20? probably smaller. `m` could be quite large, but we're linear in `m`. Some timings for fully connected graphs of size `n`:. | `n` | time (minutes) |; |-|-|; | 1024 | 0.0051 |; | 8192 | 0.13 |; | 32767 | 3.0 |; | 65535 | 12.5 |. According to the profiler, the vast majority of the time is spent interacting with the hash table. We could probably get the constants a lot lower by using an array instead of a hash table (since we have a perfect hash function: sample index). ---. ```; def fullyConnected(n: Int) {; val biggestFirst = new BinaryHeap[Int](). var i = 0; while (i <= n) {; biggestFirst.insert(i, n); i += 1; }. val g = (i: Int) => 0 to n. while (biggestFirst.maxPriority() > 0) {; val current = biggestFirst.extractMax(); val neighbors = g(current); neighbors.foreach { x =>; if (biggestFirst.contains(x)); biggestFirst.decreasePriority(x, _ - 1); }; }. val actual = biggestFirst.toArray; assert(actual.length === 1); }; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2148#issuecomment-326072568
https://github.com/hail-is/hail/pull/2148#issuecomment-326072568:313,Testability,log,log,313,"In the worst case of a fully connected graph it's O(n) insertions, at an average cost of O(1), followed by O(n) `extractMax` which are O(log n) each. For each `extractMax` we have to decrease priority on every other node, so thats O(n^2) decreasePriority which is O(log n) each. So the dominating factor is O(n^2 log(n)). We should almost never see fully connected graphs. I suspect we'll usually have disconnected graphs of fully connected subgraphs. Then the runtime is O(m * n^2 log(n)) where `m` is the number of families and `n` is the average family size. `n` should be rather small, probably not higher than 20? probably smaller. `m` could be quite large, but we're linear in `m`. Some timings for fully connected graphs of size `n`:. | `n` | time (minutes) |; |-|-|; | 1024 | 0.0051 |; | 8192 | 0.13 |; | 32767 | 3.0 |; | 65535 | 12.5 |. According to the profiler, the vast majority of the time is spent interacting with the hash table. We could probably get the constants a lot lower by using an array instead of a hash table (since we have a perfect hash function: sample index). ---. ```; def fullyConnected(n: Int) {; val biggestFirst = new BinaryHeap[Int](). var i = 0; while (i <= n) {; biggestFirst.insert(i, n); i += 1; }. val g = (i: Int) => 0 to n. while (biggestFirst.maxPriority() > 0) {; val current = biggestFirst.extractMax(); val neighbors = g(current); neighbors.foreach { x =>; if (biggestFirst.contains(x)); biggestFirst.decreasePriority(x, _ - 1); }; }. val actual = biggestFirst.toArray; assert(actual.length === 1); }; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2148#issuecomment-326072568
https://github.com/hail-is/hail/pull/2148#issuecomment-326072568:482,Testability,log,log,482,"In the worst case of a fully connected graph it's O(n) insertions, at an average cost of O(1), followed by O(n) `extractMax` which are O(log n) each. For each `extractMax` we have to decrease priority on every other node, so thats O(n^2) decreasePriority which is O(log n) each. So the dominating factor is O(n^2 log(n)). We should almost never see fully connected graphs. I suspect we'll usually have disconnected graphs of fully connected subgraphs. Then the runtime is O(m * n^2 log(n)) where `m` is the number of families and `n` is the average family size. `n` should be rather small, probably not higher than 20? probably smaller. `m` could be quite large, but we're linear in `m`. Some timings for fully connected graphs of size `n`:. | `n` | time (minutes) |; |-|-|; | 1024 | 0.0051 |; | 8192 | 0.13 |; | 32767 | 3.0 |; | 65535 | 12.5 |. According to the profiler, the vast majority of the time is spent interacting with the hash table. We could probably get the constants a lot lower by using an array instead of a hash table (since we have a perfect hash function: sample index). ---. ```; def fullyConnected(n: Int) {; val biggestFirst = new BinaryHeap[Int](). var i = 0; while (i <= n) {; biggestFirst.insert(i, n); i += 1; }. val g = (i: Int) => 0 to n. while (biggestFirst.maxPriority() > 0) {; val current = biggestFirst.extractMax(); val neighbors = g(current); neighbors.foreach { x =>; if (biggestFirst.contains(x)); biggestFirst.decreasePriority(x, _ - 1); }; }. val actual = biggestFirst.toArray; assert(actual.length === 1); }; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2148#issuecomment-326072568
https://github.com/hail-is/hail/pull/2148#issuecomment-326072568:1517,Testability,assert,assert,1517,"In the worst case of a fully connected graph it's O(n) insertions, at an average cost of O(1), followed by O(n) `extractMax` which are O(log n) each. For each `extractMax` we have to decrease priority on every other node, so thats O(n^2) decreasePriority which is O(log n) each. So the dominating factor is O(n^2 log(n)). We should almost never see fully connected graphs. I suspect we'll usually have disconnected graphs of fully connected subgraphs. Then the runtime is O(m * n^2 log(n)) where `m` is the number of families and `n` is the average family size. `n` should be rather small, probably not higher than 20? probably smaller. `m` could be quite large, but we're linear in `m`. Some timings for fully connected graphs of size `n`:. | `n` | time (minutes) |; |-|-|; | 1024 | 0.0051 |; | 8192 | 0.13 |; | 32767 | 3.0 |; | 65535 | 12.5 |. According to the profiler, the vast majority of the time is spent interacting with the hash table. We could probably get the constants a lot lower by using an array instead of a hash table (since we have a perfect hash function: sample index). ---. ```; def fullyConnected(n: Int) {; val biggestFirst = new BinaryHeap[Int](). var i = 0; while (i <= n) {; biggestFirst.insert(i, n); i += 1; }. val g = (i: Int) => 0 to n. while (biggestFirst.maxPriority() > 0) {; val current = biggestFirst.extractMax(); val neighbors = g(current); neighbors.foreach { x =>; if (biggestFirst.contains(x)); biggestFirst.decreasePriority(x, _ - 1); }; }. val actual = biggestFirst.toArray; assert(actual.length === 1); }; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2148#issuecomment-326072568
https://github.com/hail-is/hail/pull/2148#issuecomment-326106858:80,Availability,failure,failure,80,"Back to you. I made some inline comments before starting review, see both. Test failure is due to not changing high_kin to related_pairs on the right hand side, etc. in doc example.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2148#issuecomment-326106858
https://github.com/hail-is/hail/pull/2148#issuecomment-326106858:75,Testability,Test,Test,75,"Back to you. I made some inline comments before starting review, see both. Test failure is due to not changing high_kin to related_pairs on the right hand side, etc. in doc example.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2148#issuecomment-326106858
https://github.com/hail-is/hail/pull/2148#issuecomment-326124085:668,Security,hash,hash,668,"I'm not gonna do the BinaryIntHeap stuff. For graphs smaller than 2^13, the cost is dominated by non-heap-things. For fully connected graphs of 2^13 or larger, representing the full graph in memory (you'll note in my examples I cheated by never reifying the graph) is rather difficult because you've got 2^26 nodes. I can't reify a 2^13 fully connected graph on my laptop with 4GB of RAM. The edge array alone is gonna be about 2^26 / 2 * 8 positions long, which is like 130 MB already, then each pair is probably about 100 bytes, so like a gig, and all I did was create an array of edges. Then I'd have to manipulate that to get an array of all the vertex set, and a hash map from vertex to its integer. I don't see this being so great for fully connected graphs. Perhaps there's some investigation needed for less fully connected graphs. But in that case the quadratic behavior is less relevant.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2148#issuecomment-326124085
https://github.com/hail-is/hail/pull/2153#issuecomment-325388707:435,Availability,failure,failure,435,"I've merged a stack of changes to this branch including:; - Cleaned up tests, including refactoring, making Balding-Nichols covariates deterministic and removing lots of extra test code; - Reorder args in Scala to match Python, related bug fixes; - Improved large N performance by using single array D rather than A and B; - Moved dense versus sparse matching outside of loop; - Improved Python docs and Scala remarks; - Debugged test failure only occurring in Spark 2.1.0, which turned out to be related to accuracy of Davies. I've increased accuracy to 1e-8 which is enough to make current tests pass. Once this goes in, I'll make PRs to:; - Allow users to set accuracy and iterations on Davies, will use same defaults as R: 1e-6 and 10k.; - Add number of variants per key as column.; - Fix behavior to finish running even if some groups are too big upper bound, or if Cholesky fails. Document this behavior. Less urgently, but to keep in mind:; - If bottleneck, improve performance of Gramian computation in large N case using blocking; - Improve Davies C code",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2153#issuecomment-325388707
https://github.com/hail-is/hail/pull/2153#issuecomment-325388707:88,Modifiability,refactor,refactoring,88,"I've merged a stack of changes to this branch including:; - Cleaned up tests, including refactoring, making Balding-Nichols covariates deterministic and removing lots of extra test code; - Reorder args in Scala to match Python, related bug fixes; - Improved large N performance by using single array D rather than A and B; - Moved dense versus sparse matching outside of loop; - Improved Python docs and Scala remarks; - Debugged test failure only occurring in Spark 2.1.0, which turned out to be related to accuracy of Davies. I've increased accuracy to 1e-8 which is enough to make current tests pass. Once this goes in, I'll make PRs to:; - Allow users to set accuracy and iterations on Davies, will use same defaults as R: 1e-6 and 10k.; - Add number of variants per key as column.; - Fix behavior to finish running even if some groups are too big upper bound, or if Cholesky fails. Document this behavior. Less urgently, but to keep in mind:; - If bottleneck, improve performance of Gramian computation in large N case using blocking; - Improve Davies C code",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2153#issuecomment-325388707
https://github.com/hail-is/hail/pull/2153#issuecomment-325388707:266,Performance,perform,performance,266,"I've merged a stack of changes to this branch including:; - Cleaned up tests, including refactoring, making Balding-Nichols covariates deterministic and removing lots of extra test code; - Reorder args in Scala to match Python, related bug fixes; - Improved large N performance by using single array D rather than A and B; - Moved dense versus sparse matching outside of loop; - Improved Python docs and Scala remarks; - Debugged test failure only occurring in Spark 2.1.0, which turned out to be related to accuracy of Davies. I've increased accuracy to 1e-8 which is enough to make current tests pass. Once this goes in, I'll make PRs to:; - Allow users to set accuracy and iterations on Davies, will use same defaults as R: 1e-6 and 10k.; - Add number of variants per key as column.; - Fix behavior to finish running even if some groups are too big upper bound, or if Cholesky fails. Document this behavior. Less urgently, but to keep in mind:; - If bottleneck, improve performance of Gramian computation in large N case using blocking; - Improve Davies C code",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2153#issuecomment-325388707
https://github.com/hail-is/hail/pull/2153#issuecomment-325388707:953,Performance,bottleneck,bottleneck,953,"I've merged a stack of changes to this branch including:; - Cleaned up tests, including refactoring, making Balding-Nichols covariates deterministic and removing lots of extra test code; - Reorder args in Scala to match Python, related bug fixes; - Improved large N performance by using single array D rather than A and B; - Moved dense versus sparse matching outside of loop; - Improved Python docs and Scala remarks; - Debugged test failure only occurring in Spark 2.1.0, which turned out to be related to accuracy of Davies. I've increased accuracy to 1e-8 which is enough to make current tests pass. Once this goes in, I'll make PRs to:; - Allow users to set accuracy and iterations on Davies, will use same defaults as R: 1e-6 and 10k.; - Add number of variants per key as column.; - Fix behavior to finish running even if some groups are too big upper bound, or if Cholesky fails. Document this behavior. Less urgently, but to keep in mind:; - If bottleneck, improve performance of Gramian computation in large N case using blocking; - Improve Davies C code",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2153#issuecomment-325388707
https://github.com/hail-is/hail/pull/2153#issuecomment-325388707:973,Performance,perform,performance,973,"I've merged a stack of changes to this branch including:; - Cleaned up tests, including refactoring, making Balding-Nichols covariates deterministic and removing lots of extra test code; - Reorder args in Scala to match Python, related bug fixes; - Improved large N performance by using single array D rather than A and B; - Moved dense versus sparse matching outside of loop; - Improved Python docs and Scala remarks; - Debugged test failure only occurring in Spark 2.1.0, which turned out to be related to accuracy of Davies. I've increased accuracy to 1e-8 which is enough to make current tests pass. Once this goes in, I'll make PRs to:; - Allow users to set accuracy and iterations on Davies, will use same defaults as R: 1e-6 and 10k.; - Add number of variants per key as column.; - Fix behavior to finish running even if some groups are too big upper bound, or if Cholesky fails. Document this behavior. Less urgently, but to keep in mind:; - If bottleneck, improve performance of Gramian computation in large N case using blocking; - Improve Davies C code",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2153#issuecomment-325388707
https://github.com/hail-is/hail/pull/2153#issuecomment-325388707:71,Testability,test,tests,71,"I've merged a stack of changes to this branch including:; - Cleaned up tests, including refactoring, making Balding-Nichols covariates deterministic and removing lots of extra test code; - Reorder args in Scala to match Python, related bug fixes; - Improved large N performance by using single array D rather than A and B; - Moved dense versus sparse matching outside of loop; - Improved Python docs and Scala remarks; - Debugged test failure only occurring in Spark 2.1.0, which turned out to be related to accuracy of Davies. I've increased accuracy to 1e-8 which is enough to make current tests pass. Once this goes in, I'll make PRs to:; - Allow users to set accuracy and iterations on Davies, will use same defaults as R: 1e-6 and 10k.; - Add number of variants per key as column.; - Fix behavior to finish running even if some groups are too big upper bound, or if Cholesky fails. Document this behavior. Less urgently, but to keep in mind:; - If bottleneck, improve performance of Gramian computation in large N case using blocking; - Improve Davies C code",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2153#issuecomment-325388707
https://github.com/hail-is/hail/pull/2153#issuecomment-325388707:176,Testability,test,test,176,"I've merged a stack of changes to this branch including:; - Cleaned up tests, including refactoring, making Balding-Nichols covariates deterministic and removing lots of extra test code; - Reorder args in Scala to match Python, related bug fixes; - Improved large N performance by using single array D rather than A and B; - Moved dense versus sparse matching outside of loop; - Improved Python docs and Scala remarks; - Debugged test failure only occurring in Spark 2.1.0, which turned out to be related to accuracy of Davies. I've increased accuracy to 1e-8 which is enough to make current tests pass. Once this goes in, I'll make PRs to:; - Allow users to set accuracy and iterations on Davies, will use same defaults as R: 1e-6 and 10k.; - Add number of variants per key as column.; - Fix behavior to finish running even if some groups are too big upper bound, or if Cholesky fails. Document this behavior. Less urgently, but to keep in mind:; - If bottleneck, improve performance of Gramian computation in large N case using blocking; - Improve Davies C code",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2153#issuecomment-325388707
https://github.com/hail-is/hail/pull/2153#issuecomment-325388707:430,Testability,test,test,430,"I've merged a stack of changes to this branch including:; - Cleaned up tests, including refactoring, making Balding-Nichols covariates deterministic and removing lots of extra test code; - Reorder args in Scala to match Python, related bug fixes; - Improved large N performance by using single array D rather than A and B; - Moved dense versus sparse matching outside of loop; - Improved Python docs and Scala remarks; - Debugged test failure only occurring in Spark 2.1.0, which turned out to be related to accuracy of Davies. I've increased accuracy to 1e-8 which is enough to make current tests pass. Once this goes in, I'll make PRs to:; - Allow users to set accuracy and iterations on Davies, will use same defaults as R: 1e-6 and 10k.; - Add number of variants per key as column.; - Fix behavior to finish running even if some groups are too big upper bound, or if Cholesky fails. Document this behavior. Less urgently, but to keep in mind:; - If bottleneck, improve performance of Gramian computation in large N case using blocking; - Improve Davies C code",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2153#issuecomment-325388707
https://github.com/hail-is/hail/pull/2153#issuecomment-325388707:592,Testability,test,tests,592,"I've merged a stack of changes to this branch including:; - Cleaned up tests, including refactoring, making Balding-Nichols covariates deterministic and removing lots of extra test code; - Reorder args in Scala to match Python, related bug fixes; - Improved large N performance by using single array D rather than A and B; - Moved dense versus sparse matching outside of loop; - Improved Python docs and Scala remarks; - Debugged test failure only occurring in Spark 2.1.0, which turned out to be related to accuracy of Davies. I've increased accuracy to 1e-8 which is enough to make current tests pass. Once this goes in, I'll make PRs to:; - Allow users to set accuracy and iterations on Davies, will use same defaults as R: 1e-6 and 10k.; - Add number of variants per key as column.; - Fix behavior to finish running even if some groups are too big upper bound, or if Cholesky fails. Document this behavior. Less urgently, but to keep in mind:; - If bottleneck, improve performance of Gramian computation in large N case using blocking; - Improve Davies C code",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2153#issuecomment-325388707
https://github.com/hail-is/hail/pull/2160#issuecomment-325781229:9,Availability,failure,failure,9,"Re: test failure, I'll rebase once the cloud script is in 0.1.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2160#issuecomment-325781229
https://github.com/hail-is/hail/pull/2160#issuecomment-325781229:4,Testability,test,test,4,"Re: test failure, I'll rebase once the cloud script is in 0.1.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2160#issuecomment-325781229
https://github.com/hail-is/hail/pull/2160#issuecomment-326643889:975,Integrability,wrap,wrapper,975,"As I mentioned, I think this, plus KinshipMatrix and LDMatrix are getting lost in the domain-specific details. I suggest the following structure:; - an abstract Python `Matrix` class for numeric matrices. This should have (at least) three implementations: local, indexed-row and block. It should have read/write methods. It should support at least basic operations: *, +, -. They might not all be supported on all combination of implementations. There should be operations for converting between them. @danking is working on freeing us from Spark matrices and building on Breeze. You might coordinate here.; - a `Vector` class; - a `KeyedMatrix` which has row and column keys with schemas, or possibly a SymmetricKeyedMatrix to start if that is all we need (e.g. for Kinship and LD). This should again have read/write.; - then Eigen is just a KeyedMatrix with a Vector; - I'd nuke Kinship and LD, or if it is necessary to keep n{Samples, Variants}Used, it should be a simple wrapper class with the integer value and the underlying keyed matrix. Get the structure in place to start, don't worry so much about documentation. The user-facing part should be pretty thin/lightweight.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2160#issuecomment-326643889
https://github.com/hail-is/hail/pull/2160#issuecomment-326643889:968,Usability,simpl,simple,968,"As I mentioned, I think this, plus KinshipMatrix and LDMatrix are getting lost in the domain-specific details. I suggest the following structure:; - an abstract Python `Matrix` class for numeric matrices. This should have (at least) three implementations: local, indexed-row and block. It should have read/write methods. It should support at least basic operations: *, +, -. They might not all be supported on all combination of implementations. There should be operations for converting between them. @danking is working on freeing us from Spark matrices and building on Breeze. You might coordinate here.; - a `Vector` class; - a `KeyedMatrix` which has row and column keys with schemas, or possibly a SymmetricKeyedMatrix to start if that is all we need (e.g. for Kinship and LD). This should again have read/write.; - then Eigen is just a KeyedMatrix with a Vector; - I'd nuke Kinship and LD, or if it is necessary to keep n{Samples, Variants}Used, it should be a simple wrapper class with the integer value and the underlying keyed matrix. Get the structure in place to start, don't worry so much about documentation. The user-facing part should be pretty thin/lightweight.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2160#issuecomment-326643889
https://github.com/hail-is/hail/pull/2171#issuecomment-326647606:369,Deployability,integrat,integrate,369,Hmm. OrderedRDD and OrderedPartitioner are being phased out in master. OrderedRDD2 and OrderedPartitioner2 are in. We should probably have an offline discussion about how the linear algebra routines are going to interact with the new RegionValue-based stuff. There seem to be two competing goals here: getting something working for UKB and building something that will integrate with the new 0.2 stuff. We should probably have a chat about how to navigate this.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2171#issuecomment-326647606
https://github.com/hail-is/hail/pull/2171#issuecomment-326647606:190,Integrability,rout,routines,190,Hmm. OrderedRDD and OrderedPartitioner are being phased out in master. OrderedRDD2 and OrderedPartitioner2 are in. We should probably have an offline discussion about how the linear algebra routines are going to interact with the new RegionValue-based stuff. There seem to be two competing goals here: getting something working for UKB and building something that will integrate with the new 0.2 stuff. We should probably have a chat about how to navigate this.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2171#issuecomment-326647606
https://github.com/hail-is/hail/pull/2171#issuecomment-326647606:369,Integrability,integrat,integrate,369,Hmm. OrderedRDD and OrderedPartitioner are being phased out in master. OrderedRDD2 and OrderedPartitioner2 are in. We should probably have an offline discussion about how the linear algebra routines are going to interact with the new RegionValue-based stuff. There seem to be two competing goals here: getting something working for UKB and building something that will integrate with the new 0.2 stuff. We should probably have a chat about how to navigate this.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2171#issuecomment-326647606
https://github.com/hail-is/hail/pull/2173#issuecomment-327232866:132,Testability,test,test,132,"@jbloom22 This is a good change. Could you please check in a small VDS from 0.1 (perhaps name it as `0.1-commithash.vds`) and add a test that checks for a `HailException` containing the text ""invalid metadata""?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2173#issuecomment-327232866
https://github.com/hail-is/hail/pull/2173#issuecomment-327335081:85,Testability,test,test,85,"I added a tiny 0.1 VDS formed from regressionLinear.vcf, forcing 2 partitions, and a test in VSMSuite. Back to you.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2173#issuecomment-327335081
https://github.com/hail-is/hail/pull/2173#issuecomment-327467484:54,Security,hash,hash,54,"@jbloom22 sorry, I meant could you include the commit hash in the VDS's name in case we ever have to go back to the commit used to generate it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2173#issuecomment-327467484
https://github.com/hail-is/hail/pull/2177#issuecomment-326646865:50,Modifiability,refactor,refactored,50,Closing until Eigen PR is ready again and this is refactored accordingly.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2177#issuecomment-326646865
https://github.com/hail-is/hail/issues/2178#issuecomment-326819191:34,Testability,test,test,34,"@konradjk thanks for the succinct test case, I can reproduce.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2178#issuecomment-326819191
https://github.com/hail-is/hail/issues/2178#issuecomment-326819470:160,Availability,error,error,160,@konradjk @jtkoskel Ah the issue is two-fold: the compiler doesn't automatically cast types to booleans AND (perhaps more importantly) it doesn't signal a type error when the condition of an if expression is not a boolean. I'll look into this more on Monday.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2178#issuecomment-326819470
https://github.com/hail-is/hail/issues/2178#issuecomment-327032041:24,Availability,Error,Error,24,"@danking I then get; ```Error summary: HailException: expression has wrong type: expected `Int', got Boolean```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2178#issuecomment-327032041
https://github.com/hail-is/hail/pull/2185#issuecomment-326970456:182,Integrability,wrap,wrapper,182,This quote from the 2.12.0 collections docs is as depressing and still seemingly misguided:. > (Since version 2.12.0) mutable.Stack is an inelegant and potentially poorly-performing wrapper around List. Use a List assigned to a var instead.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2185#issuecomment-326970456
https://github.com/hail-is/hail/pull/2185#issuecomment-326970456:171,Performance,perform,performing,171,This quote from the 2.12.0 collections docs is as depressing and still seemingly misguided:. > (Since version 2.12.0) mutable.Stack is an inelegant and potentially poorly-performing wrapper around List. Use a List assigned to a var instead.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2185#issuecomment-326970456
https://github.com/hail-is/hail/pull/2202#issuecomment-327510614:16,Testability,test,tests,16,should make the tests significantly faster by removing the slowest one.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2202#issuecomment-327510614
https://github.com/hail-is/hail/pull/2204#issuecomment-328148402:122,Deployability,pipeline,pipelines,122,"I don't think it is bad to have both. They have two different use cases. I envisioned `head` as being a mechanism to test pipelines on small amounts of data. `take` seems to be useful if someone actually wants to look at each object in the first n rows of data. However, it does add extra methods to VariantDataset when `take` is equivalent to `head().collect()`. Thinking back to the group/ungroup discussion, we decided to add those methods even though they could be implemented by the user in expr. However, I think those operations were more complicated than `take`. I don't have strong feelings either way.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2204#issuecomment-328148402
https://github.com/hail-is/hail/pull/2204#issuecomment-328148402:117,Testability,test,test,117,"I don't think it is bad to have both. They have two different use cases. I envisioned `head` as being a mechanism to test pipelines on small amounts of data. `take` seems to be useful if someone actually wants to look at each object in the first n rows of data. However, it does add extra methods to VariantDataset when `take` is equivalent to `head().collect()`. Thinking back to the group/ungroup discussion, we decided to add those methods even though they could be implemented by the user in expr. However, I think those operations were more complicated than `take`. I don't have strong feelings either way.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2204#issuecomment-328148402
https://github.com/hail-is/hail/pull/2205#issuecomment-328296634:25,Deployability,patch,patch,25,"@jigold looks good after patch, thanks! back to you",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2205#issuecomment-328296634
https://github.com/hail-is/hail/issues/2206#issuecomment-328648857:113,Testability,test,test,113,I took a look at what we are currently outputting. I think this is relatively straightforward except for the HWE test. I don't know of a multiallelic version of HWE. A simple approach would be to compute HWE for each alternate allele compared to the reference allele. Where this gets tricky is how to handle heterozygotes where the second allele is not the reference allele. Example: 1/2 genotype.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2206#issuecomment-328648857
https://github.com/hail-is/hail/issues/2206#issuecomment-328648857:168,Usability,simpl,simple,168,I took a look at what we are currently outputting. I think this is relatively straightforward except for the HWE test. I don't know of a multiallelic version of HWE. A simple approach would be to compute HWE for each alternate allele compared to the reference allele. Where this gets tricky is how to handle heterozygotes where the second allele is not the reference allele. Example: 1/2 genotype.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2206#issuecomment-328648857
https://github.com/hail-is/hail/pull/2208#issuecomment-332347245:266,Integrability,interface,interface,266,"The to-do list is roughly. - [ ] Get genome reference type in Variant, Interval, and Locus constructors in function registry; - [ ] Add default reference to HailContext ; - [ ] Add default reference to a bunch of RDD methods; - [ ] Expose genome reference in Python interface with import methods and as an input argument to TVariant(), etc.; - [ ] Make sure #2226 solves the problem of variant, locus, and interval methods having the correct function generated dependent on the genome reference; - [ ] Double check that if a user adds a new genome reference, it is visible on all workers.; - [ ] Add GenomeReference python class to documentation; - [ ] Convert GenomeReference -> ReferenceGenome (Jon's request); - [ ] Remove methods from Variant that do not take a GenomeReference as a parameter (Right now, everything is still hardcoded as GRCh37). I vaguely remember some debate on whether these functions should be removed from Variant completely and instead only called from GenomeReference.; - [ ] At some point, we may want to change Variant etc. so they store the contigIndex rather than the contig.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2208#issuecomment-332347245
https://github.com/hail-is/hail/pull/2208#issuecomment-332347245:461,Integrability,depend,dependent,461,"The to-do list is roughly. - [ ] Get genome reference type in Variant, Interval, and Locus constructors in function registry; - [ ] Add default reference to HailContext ; - [ ] Add default reference to a bunch of RDD methods; - [ ] Expose genome reference in Python interface with import methods and as an input argument to TVariant(), etc.; - [ ] Make sure #2226 solves the problem of variant, locus, and interval methods having the correct function generated dependent on the genome reference; - [ ] Double check that if a user adds a new genome reference, it is visible on all workers.; - [ ] Add GenomeReference python class to documentation; - [ ] Convert GenomeReference -> ReferenceGenome (Jon's request); - [ ] Remove methods from Variant that do not take a GenomeReference as a parameter (Right now, everything is still hardcoded as GRCh37). I vaguely remember some debate on whether these functions should be removed from Variant completely and instead only called from GenomeReference.; - [ ] At some point, we may want to change Variant etc. so they store the contigIndex rather than the contig.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2208#issuecomment-332347245
https://github.com/hail-is/hail/pull/2208#issuecomment-332347245:232,Security,Expose,Expose,232,"The to-do list is roughly. - [ ] Get genome reference type in Variant, Interval, and Locus constructors in function registry; - [ ] Add default reference to HailContext ; - [ ] Add default reference to a bunch of RDD methods; - [ ] Expose genome reference in Python interface with import methods and as an input argument to TVariant(), etc.; - [ ] Make sure #2226 solves the problem of variant, locus, and interval methods having the correct function generated dependent on the genome reference; - [ ] Double check that if a user adds a new genome reference, it is visible on all workers.; - [ ] Add GenomeReference python class to documentation; - [ ] Convert GenomeReference -> ReferenceGenome (Jon's request); - [ ] Remove methods from Variant that do not take a GenomeReference as a parameter (Right now, everything is still hardcoded as GRCh37). I vaguely remember some debate on whether these functions should be removed from Variant completely and instead only called from GenomeReference.; - [ ] At some point, we may want to change Variant etc. so they store the contigIndex rather than the contig.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2208#issuecomment-332347245
https://github.com/hail-is/hail/pull/2209#issuecomment-328142662:29,Availability,down,down,29,How does the history slow it down? It's just a wrapper.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2209#issuecomment-328142662
https://github.com/hail-is/hail/pull/2209#issuecomment-328142662:47,Integrability,wrap,wrapper,47,How does the history slow it down? It's just a wrapper.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2209#issuecomment-328142662
https://github.com/hail-is/hail/pull/2209#issuecomment-328143714:151,Modifiability,extend,extend,151,"All the args for each genotype and struct are converted to strings with repr and stored. For certain things like genotype there's no reason to have it extend history_mixin, since we can produce a sensible `repr` without recording the args.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2209#issuecomment-328143714
https://github.com/hail-is/hail/pull/2214#issuecomment-331990089:44,Testability,test,tests,44,"This looks good. Can you replace all of the tests of the form `uf.find(1) == uf.find(2)` with `sameSet(1, 2)`?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2214#issuecomment-331990089
https://github.com/hail-is/hail/issues/2217#issuecomment-328882377:43,Security,hash,hashes,43,"Somehow our CI server started using 8-char hashes in some places, and 7 in others. Should have this fixed later today!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2217#issuecomment-328882377
https://github.com/hail-is/hail/pull/2218#issuecomment-332209074:171,Security,access,access,171,"Thanks Tim!. It is easy to fix the Kryo serializers, but the function we need (require) is protected, so we need to use reflection or put something in the Kryo package to access it. Java serializers are trickier. Best I can think of is to have a thread-local pool of something like 8KB blocks to copy to/from.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2218#issuecomment-332209074
https://github.com/hail-is/hail/pull/2224#issuecomment-332360962:260,Safety,Unsafe,Unsafe,260,I think I now understand what you're looking for. I set out to build a drop-in replacement for the current AST so that when Jackie's python UI changes were done we could hook this up in place of AST. I will instead build something that will operate on the new Unsafe representations you're introducing. I'll close for now because after removing `DetailedTypeInfo` many tests are broken because the current IR has no way to return `NA` to its caller. I'll reopen when I have something that includes primitives for the Unsafe data.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2224#issuecomment-332360962
https://github.com/hail-is/hail/pull/2224#issuecomment-332360962:517,Safety,Unsafe,Unsafe,517,I think I now understand what you're looking for. I set out to build a drop-in replacement for the current AST so that when Jackie's python UI changes were done we could hook this up in place of AST. I will instead build something that will operate on the new Unsafe representations you're introducing. I'll close for now because after removing `DetailedTypeInfo` many tests are broken because the current IR has no way to return `NA` to its caller. I'll reopen when I have something that includes primitives for the Unsafe data.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2224#issuecomment-332360962
https://github.com/hail-is/hail/pull/2224#issuecomment-332360962:369,Testability,test,tests,369,I think I now understand what you're looking for. I set out to build a drop-in replacement for the current AST so that when Jackie's python UI changes were done we could hook this up in place of AST. I will instead build something that will operate on the new Unsafe representations you're introducing. I'll close for now because after removing `DetailedTypeInfo` many tests are broken because the current IR has no way to return `NA` to its caller. I'll reopen when I have something that includes primitives for the Unsafe data.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2224#issuecomment-332360962
https://github.com/hail-is/hail/pull/2225#issuecomment-331205348:89,Integrability,interface,interface,89,Why are we keeping both if they're almost exactly the same thing? To prep for the python interface?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2225#issuecomment-331205348
https://github.com/hail-is/hail/pull/2225#issuecomment-331238111:49,Deployability,update,updated,49,"Yes, all of that (export changes, transmute, and updated select) was part of my plan. I was trying to keep the PRs short. This one is already 250 lines. If the issue is the method name `select_fields`, then I can change that now.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2225#issuecomment-331238111
https://github.com/hail-is/hail/pull/2225#issuecomment-331990417:43,Integrability,interface,interface,43,Closing this for now. Want to rethink this interface.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2225#issuecomment-331990417
https://github.com/hail-is/hail/pull/2226#issuecomment-334160156:717,Security,access,access,717,"Because in every application I know of, I want the binding not the top-level type. In `str` those coincide, but in the other applications, they don't. For example:. Example 1: From cseed/ordrdd2rb, I needed the type we're aggregating over to copy. I used your idiom, but my solution, it looks like:. ```; registerDependentAggregator(""take"", () => {; val t = TT.t; (n: Int) => new TakeAggregator(t, n); }, ...)(; aggregableHr(TTHr), int32Hr, arrayHr(TTHr)); ```. Yours would look like:. ```; registerDependentAggregator(""take"", (aggt: Type, argt: Type) => (n: Int) => new TakeAggregator(aggt.asInstanceOf[TAggregable].elementType, n), ...)(...); ```; Which do you prefer?. Example 2: this was motivated by the need to access the genome reference in operations on types like Variant, etc. Here's an example, my way:. ```; registerDependentMethod(""inXPar"", () => {; val gr = GR.gr; (x: Variant) => gr.inXPar(x); }, ...)(variantHr(GR), boolHr); ```. and your way:. ```; registerDependentMethod(""inXPar"", (vt: Type) => (x: Variant) => vt.asInstanceOf[Variant].gr.inXPar(v) }, ...)(variantHr(GR), boolHr); ```. This is what I mean by ""digging"". It gets worse, for example, with something like Variant unsplit: `unsplit(Array[Variant(GR)]): Variant(GR)` (assuming unsplit is implemented on the reference, which wouldn't necessarily be the case). I'll reiterate, the main point is that, in all the examples I'm aware of, we actually want the value of the binding directly and not the substituted type.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2226#issuecomment-334160156
https://github.com/hail-is/hail/pull/2226#issuecomment-334178886:219,Usability,simpl,simple,219,"These examples suggest to me that the main problem is loss of type specificity in the substituted type. As for digging through the fields of `TVariant`, I personally am not bothered by `vt.gr.inXPar _`. I don't see any simple way to preserve the fact that `vt` will be a `TVariant`. I'll modify it to the approach you suggested.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2226#issuecomment-334178886
https://github.com/hail-is/hail/issues/2232#issuecomment-422371999:32,Availability,error,error,32,we added a base case with nicer error,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2232#issuecomment-422371999
https://github.com/hail-is/hail/pull/2236#issuecomment-330897057:57,Testability,test,tests,57,@cseed looks like something is wrong I the docs / python tests.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2236#issuecomment-330897057
https://github.com/hail-is/hail/pull/2239#issuecomment-334154778:138,Testability,benchmark,benchmark,138,"> If this fix makes UK Biobank import too slow. Looks good, that's my only concern. With the persist, I think it should be OK, but can we benchmark to verify? A before/after `bgen_import().count()` on a small but non-trivial example should suffice. We'll be running again soon rather than later, esp. since we just got approved for all the phenotypes (!)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2239#issuecomment-334154778
https://github.com/hail-is/hail/pull/2239#issuecomment-334155210:37,Performance,perform,performance,37,"This should have almost no effect on performance, since we already scan the thing for partitioning",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2239#issuecomment-334155210
https://github.com/hail-is/hail/pull/2239#issuecomment-337996806:161,Deployability,configurat,configuration,161,"@cseed This PR can be merged. I ran the comparison on the cloud between current master and this branch with UKBB Wave 1 Chr21 (20GB) with the exact same cluster configuration (Liam's default settings). Ran this command:. ```; %%timeit -n 1. hc.import_bgen(bgen_file, sample_file = sample_file).count(); ```. Got 3min21sec for master and 3min24sec for my branch.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2239#issuecomment-337996806
https://github.com/hail-is/hail/pull/2239#issuecomment-337996806:161,Modifiability,config,configuration,161,"@cseed This PR can be merged. I ran the comparison on the cloud between current master and this branch with UKBB Wave 1 Chr21 (20GB) with the exact same cluster configuration (Liam's default settings). Ran this command:. ```; %%timeit -n 1. hc.import_bgen(bgen_file, sample_file = sample_file).count(); ```. Got 3min21sec for master and 3min24sec for my branch.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2239#issuecomment-337996806
https://github.com/hail-is/hail/pull/2243#issuecomment-331479504:344,Integrability,depend,dependency,344,"Ok, @jigold looks like the only sensible way to do this is to add an. ```; import pytz; ```; ```; now = datetime.datetime.utcnow().replace(tzinfo=pytz.utc); ```; According to a note in the Python 2.7 docs [there are no tzinfo instances in the standard library](https://docs.python.org/2/library/datetime.html#tzinfo-objects). We should add the dependency on pytz to [environment.yml](https://github.com/hail-is/hail/blob/master/python/hail/environment.yml).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2243#issuecomment-331479504
https://github.com/hail-is/hail/pull/2243#issuecomment-331485632:34,Integrability,message,message,34,"Oh hmm, just read @danking's last message. Well, up to you all. I don't think it matters as much as long as it's a consistent time, and well-documented.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2243#issuecomment-331485632
https://github.com/hail-is/hail/pull/2243#issuecomment-331923128:143,Integrability,depend,dependencies,143,"@danking If Konrad is fine with this for now and Python 3 will fix the issue, I think we should keep this PR as is and avoid adding additional dependencies. I'll add checking the time zone to the 0.2 to-do list and we can revisit once we've switched to Python 3.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2243#issuecomment-331923128
https://github.com/hail-is/hail/pull/2243#issuecomment-331923128:119,Safety,avoid,avoid,119,"@danking If Konrad is fine with this for now and Python 3 will fix the issue, I think we should keep this PR as is and avoid adding additional dependencies. I'll add checking the time zone to the 0.2 to-do list and we can revisit once we've switched to Python 3.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2243#issuecomment-331923128
https://github.com/hail-is/hail/pull/2244#issuecomment-337717963:119,Integrability,wrap,wrapper,119,"Looks my comment got lost! Sorry. I said, I'd prefer we didn't copy the HailContext whole hog, but just write a simple wrapper that calls from hail2.HailContext to hail.HailContext, so something like:. ```; class HailContext:; def __init__(args...):; self.hc1 = hail.HailContext(args...). def import_bgen(args...):; return self.hc1.import_bgen(args...).to_hail2(); ```. etc. I don't think you even need docs unless there is something specifically different between the two. That way, we won't need to maintain two versions for things like doc changes and we won't get confused about which one is the ""real"" HailContext. Then, when we're ready to switch over, we can pull the docs across and throw away the stub.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2244#issuecomment-337717963
https://github.com/hail-is/hail/pull/2244#issuecomment-337717963:706,Testability,stub,stub,706,"Looks my comment got lost! Sorry. I said, I'd prefer we didn't copy the HailContext whole hog, but just write a simple wrapper that calls from hail2.HailContext to hail.HailContext, so something like:. ```; class HailContext:; def __init__(args...):; self.hc1 = hail.HailContext(args...). def import_bgen(args...):; return self.hc1.import_bgen(args...).to_hail2(); ```. etc. I don't think you even need docs unless there is something specifically different between the two. That way, we won't need to maintain two versions for things like doc changes and we won't get confused about which one is the ""real"" HailContext. Then, when we're ready to switch over, we can pull the docs across and throw away the stub.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2244#issuecomment-337717963
https://github.com/hail-is/hail/pull/2244#issuecomment-337717963:112,Usability,simpl,simple,112,"Looks my comment got lost! Sorry. I said, I'd prefer we didn't copy the HailContext whole hog, but just write a simple wrapper that calls from hail2.HailContext to hail.HailContext, so something like:. ```; class HailContext:; def __init__(args...):; self.hc1 = hail.HailContext(args...). def import_bgen(args...):; return self.hc1.import_bgen(args...).to_hail2(); ```. etc. I don't think you even need docs unless there is something specifically different between the two. That way, we won't need to maintain two versions for things like doc changes and we won't get confused about which one is the ""real"" HailContext. Then, when we're ready to switch over, we can pull the docs across and throw away the stub.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2244#issuecomment-337717963
https://github.com/hail-is/hail/pull/2246#issuecomment-332519180:182,Testability,log,logistic,182,"@catoverdrive I looked over this, but in a diff vs ordrdd2rb where I can't make comments. Can you reopen this as a PR against cseed:ordrdd2rb and I'll review it there? Sorry for the logistic difficulty on this one.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2246#issuecomment-332519180
https://github.com/hail-is/hail/pull/2248#issuecomment-332370854:43,Availability,toler,tolerance,43,Addressed comments (apart from question on tolerance),MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2248#issuecomment-332370854
https://github.com/hail-is/hail/pull/2248#issuecomment-332873098:111,Integrability,rout,routes,111,I added an separate test of correctness of toKeyGsWeightRdd since this function is used in both the Hail and R routes in the end-to-end comparison,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2248#issuecomment-332873098
https://github.com/hail-is/hail/pull/2248#issuecomment-332873098:20,Testability,test,test,20,I added an separate test of correctness of toKeyGsWeightRdd since this function is used in both the Hail and R routes in the end-to-end comparison,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2248#issuecomment-332873098
https://github.com/hail-is/hail/pull/2248#issuecomment-334005938:127,Testability,log,logisticSkat,127,"My attempts to restructure as a class led to more complexity, largely due to serialization of class values. I've instead moved logisticSkat and linearSkat into the apply def which removed parameter passing and code duplication. I left `computeKeyGsWeightRdd` outside the apply as moving it in complicates testing. I've also changed maxSize to default to 46340, which is `floor(sqrt(Int.MaxValue))`, and I set maxEntriesForSmallN to be the min of maxSize^2 and 8000^2.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2248#issuecomment-334005938
https://github.com/hail-is/hail/pull/2248#issuecomment-334005938:305,Testability,test,testing,305,"My attempts to restructure as a class led to more complexity, largely due to serialization of class values. I've instead moved logisticSkat and linearSkat into the apply def which removed parameter passing and code duplication. I left `computeKeyGsWeightRdd` outside the apply as moving it in complicates testing. I've also changed maxSize to default to 46340, which is `floor(sqrt(Int.MaxValue))`, and I set maxEntriesForSmallN to be the min of maxSize^2 and 8000^2.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2248#issuecomment-334005938
https://github.com/hail-is/hail/pull/2249#issuecomment-331572653:42,Performance,perform,performances,42,"A quick and dirty local test of different performances:; ```; 2017-09-22 18:05:57 Hail: INFO: baldingnichols: generating genotypes for 20 populations, 1000 samples, and 10000 variants...; [Stage 0:> (0 + 10) / 10]2017-09-22 18:05:58 Hail: INFO: Coerced sorted dataset; [Stage 374:==========================================> (3 + 1) / 4]. phi 27.4091310501. 2017-09-22 18:06:24 Hail: INFO: baldingnichols: generating genotypes for 20 populations, 1000 samples, and 10000 variants...; 2017-09-22 18:06:24 Hail: INFO: Coerced sorted dataset; [Stage 735:==========================================> (3 + 1) / 4]. phik2 34.3392460346. 2017-09-22 18:06:58 Hail: INFO: baldingnichols: generating genotypes for 20 populations, 1000 samples, and 10000 variants...; 2017-09-22 18:06:59 Hail: INFO: Coerced sorted dataset; [Stage 1192:==========================================> (3 + 1) / 4]. phik2k0 67.0002729893. 2017-09-22 18:08:05 Hail: INFO: baldingnichols: generating genotypes for 20 populations, 1000 samples, and 10000 variants...; 2017-09-22 18:08:06 Hail: INFO: Coerced sorted dataset; [Stage 1561:==========================================> (3 + 1) / 4]. all 102.006611109. ```. Time is in seconds. The most painful operation is clearly k0, but I bet most people will only want phi, maybe phi and k2.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2249#issuecomment-331572653
https://github.com/hail-is/hail/pull/2249#issuecomment-331572653:24,Testability,test,test,24,"A quick and dirty local test of different performances:; ```; 2017-09-22 18:05:57 Hail: INFO: baldingnichols: generating genotypes for 20 populations, 1000 samples, and 10000 variants...; [Stage 0:> (0 + 10) / 10]2017-09-22 18:05:58 Hail: INFO: Coerced sorted dataset; [Stage 374:==========================================> (3 + 1) / 4]. phi 27.4091310501. 2017-09-22 18:06:24 Hail: INFO: baldingnichols: generating genotypes for 20 populations, 1000 samples, and 10000 variants...; 2017-09-22 18:06:24 Hail: INFO: Coerced sorted dataset; [Stage 735:==========================================> (3 + 1) / 4]. phik2 34.3392460346. 2017-09-22 18:06:58 Hail: INFO: baldingnichols: generating genotypes for 20 populations, 1000 samples, and 10000 variants...; 2017-09-22 18:06:59 Hail: INFO: Coerced sorted dataset; [Stage 1192:==========================================> (3 + 1) / 4]. phik2k0 67.0002729893. 2017-09-22 18:08:05 Hail: INFO: baldingnichols: generating genotypes for 20 populations, 1000 samples, and 10000 variants...; 2017-09-22 18:08:06 Hail: INFO: Coerced sorted dataset; [Stage 1561:==========================================> (3 + 1) / 4]. all 102.006611109. ```. Time is in seconds. The most painful operation is clearly k0, but I bet most people will only want phi, maybe phi and k2.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2249#issuecomment-331572653
https://github.com/hail-is/hail/pull/2249#issuecomment-331572653:1230,Usability,clear,clearly,1230,"A quick and dirty local test of different performances:; ```; 2017-09-22 18:05:57 Hail: INFO: baldingnichols: generating genotypes for 20 populations, 1000 samples, and 10000 variants...; [Stage 0:> (0 + 10) / 10]2017-09-22 18:05:58 Hail: INFO: Coerced sorted dataset; [Stage 374:==========================================> (3 + 1) / 4]. phi 27.4091310501. 2017-09-22 18:06:24 Hail: INFO: baldingnichols: generating genotypes for 20 populations, 1000 samples, and 10000 variants...; 2017-09-22 18:06:24 Hail: INFO: Coerced sorted dataset; [Stage 735:==========================================> (3 + 1) / 4]. phik2 34.3392460346. 2017-09-22 18:06:58 Hail: INFO: baldingnichols: generating genotypes for 20 populations, 1000 samples, and 10000 variants...; 2017-09-22 18:06:59 Hail: INFO: Coerced sorted dataset; [Stage 1192:==========================================> (3 + 1) / 4]. phik2k0 67.0002729893. 2017-09-22 18:08:05 Hail: INFO: baldingnichols: generating genotypes for 20 populations, 1000 samples, and 10000 variants...; 2017-09-22 18:08:06 Hail: INFO: Coerced sorted dataset; [Stage 1561:==========================================> (3 + 1) / 4]. all 102.006611109. ```. Time is in seconds. The most painful operation is clearly k0, but I bet most people will only want phi, maybe phi and k2.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2249#issuecomment-331572653
https://github.com/hail-is/hail/pull/2249#issuecomment-332245478:62,Usability,simpl,simplify,62,@catoverdrive review after #2238 goes in because this PR will simplify after #2238 merges.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2249#issuecomment-332245478
https://github.com/hail-is/hail/pull/2253#issuecomment-332664586:80,Availability,error,errors,80,"I've addressed the comments, but I can't run the benchmark anymore, I get weird errors about partitions being empty that I expected to be non-empty. I will continue to investigate.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2253#issuecomment-332664586
https://github.com/hail-is/hail/pull/2253#issuecomment-332664586:49,Testability,benchmark,benchmark,49,"I've addressed the comments, but I can't run the benchmark anymore, I get weird errors about partitions being empty that I expected to be non-empty. I will continue to investigate.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2253#issuecomment-332664586
https://github.com/hail-is/hail/pull/2253#issuecomment-334887071:0,Testability,Benchmark,Benchmark,0,Benchmark is now like 80s. Not sure why it got slower from before.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2253#issuecomment-334887071
https://github.com/hail-is/hail/pull/2254#issuecomment-332244947:29,Availability,failure,failures,29,Closing while I resolve test failures and do some clean up,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2254#issuecomment-332244947
https://github.com/hail-is/hail/pull/2254#issuecomment-332244947:24,Testability,test,test,24,Closing while I resolve test failures and do some clean up,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2254#issuecomment-332244947
https://github.com/hail-is/hail/pull/2256#issuecomment-332298462:26,Usability,clear,clearer,26,"Sorry, I should have been clearer. I think the first line shouldn't have any ""#""s and for the following lines, ""###"" is fine.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2256#issuecomment-332298462
https://github.com/hail-is/hail/pull/2262#issuecomment-332887472:332,Performance,perform,perform,332,"`Gen` expressions are generally OK because they are not executed until they're used in a `forall`. The issue with `DeNovoSuite` was that the `HailContext` is referenced by a function that produces a `Gen`, so it triggers `HailContext` initialization in order to produce the `Gen` itself (whereas the returned `Gen` doesn't actually perform any computation until its used in a `forall`).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2262#issuecomment-332887472
https://github.com/hail-is/hail/pull/2270#issuecomment-333918892:48,Testability,test,tests,48,closing while I figure out what happened to the tests.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2270#issuecomment-333918892
https://github.com/hail-is/hail/pull/2270#issuecomment-334234954:10,Testability,test,test,10,@jbloom22 test fail was due to `NaN != NaN`. I improved the test.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2270#issuecomment-334234954
https://github.com/hail-is/hail/pull/2270#issuecomment-334234954:60,Testability,test,test,60,@jbloom22 test fail was due to `NaN != NaN`. I improved the test.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2270#issuecomment-334234954
https://github.com/hail-is/hail/pull/2270#issuecomment-335644547:112,Testability,test,test,112,@cseed done. @jbloom22 I believe I've addressed everything except for the PCs spark matrix comment and making a test value be a field.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2270#issuecomment-335644547
https://github.com/hail-is/hail/pull/2270#issuecomment-335896198:60,Testability,test,test,60,Remaining issues:; - *WithIndexRespectsTransposition should test indices.; - Not currently using Gen.denseMatrix; - isn't the block size always smaller than the size?; - rebase changes in LDMatrix; - rename arbitraryHailBlockMatrix to arbitraryBlockMatrix,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2270#issuecomment-335896198
https://github.com/hail-is/hail/pull/2270#issuecomment-337358741:65,Testability,test,test,65,"> Remaining issues:; >; > *WithIndexRespectsTransposition should test indices. Done. > Not currently using Gen.denseMatrix. Done. > isn't the block size always smaller than the size?. Good point. I took the square root of `Gen.interestingPosInt` to put them on the same length scale. This seems to generate OK results:. I ran the matrix generator 100 times [1] and found not terrible results. Unfortunately there's a preponderance of 31s, which comes whenever the random int exceeds 1000. Perhaps `interestingPosInt` is too often `Int.MaxValue` for use as a side length:; ```; def interestingPosInt: Gen[Int] = oneOfGen(; oneOf(1, 2, Int.MaxValue - 1, Int.MaxValue),; choose(1, 100),; posInt); ```. I also looked into the multipliable matrices method which similarly needs a `blockSize`, but this time the length scale is `x^1/3` because I have to generate a cube that fits in the Generator's `size`. I modified this to use the cubic root of an `Gen.interestingPosInt` as the `blockSize`. The results look not terrible [2]. > rebase changes in LDMatrix. done. > rename arbitraryHailBlockMatrix to arbitraryBlockMatrix. done. ## Footnotes. [1] Side length and `blockSize` of `squareBlockMatrixGen`:; ```; 6 46340; 31 1; 31 6; 2 38034; 31 15952; 1 36238; 31 1; 9 9; 3 28651; 31 2; 31 22272; 3 1; 6 46340; 31 26784; 31 27398; 8 46340; 31 1; 31 9; 31 32687; 1 39405; 9 11037; 31 46340; 31 10892; 9 25211; 1 46340; 7 7; 5 46340; 31 34790; 7 7; 8 46340; 31 46340; 1 2; 31 22021; 6 46340; 31 46340; 8 43459; 6 39273; 4 45617; 4 14821; 8 1; 31 7; 31 46340; 31 8; 31 24342; 31 34365; 31 42445; 6 8; 9 38891; 31 43108; 31 46142; 31 41962; 1 17392; 8 6; 31 46340; 31 4; 1 3; 31 43917; 3 44938; 7 1; 5 20769; 31 43156; 31 7; 31 21938; 31 45249; 1 31406; 1 40071; 31 7; 1 41043; 1 9; 1 1; 9 1; 31 1; 31 46022; 10 40633; 8 46340; 31 46340; 1 8; 1 42934; 31 1; 1 9; 3 1; 31 46340; 31 39641; 31 36241; 31 7; 31 1; 31 5; 31 43977; 31 4; 31 46340; 31 28129; 31 24906; 31 1; 31 7; 1 38660; 31 36026; 1 39369; 31 5; 31 18",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2270#issuecomment-337358741
https://github.com/hail-is/hail/pull/2274#issuecomment-333975584:47,Availability,fault,fault,47,@johnc1231 oh john this is definitely not your fault :P I lead you astray,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2274#issuecomment-333975584
https://github.com/hail-is/hail/pull/2276#issuecomment-334883633:501,Deployability,update,updates,501,"@cseed I made these changes apart from splitting out the idiom, which I'd like to do once both this and HailBlockMatrix are in 0.1, before PR against 0.2. I pulled in RichSparkMatrix with asBreeze conversion (also used to convert Spark to Breeze without copy in LMM branch...though maybe that won't be necessary with HailBlockMatrix), so if you don't want to leave that in, I can remove by backing off to `.toArray`, or remove when HailBlockMatrix is in (or wait until the latter is in; Dan just made updates on that which I'll review tomorrow). Is the additional check on kryo registrator a meaningful breaking change on 0.1?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2276#issuecomment-334883633
https://github.com/hail-is/hail/pull/2279#issuecomment-334795157:13,Integrability,interface,interface,13,"Reverted the interface for `select`, `drop`, and `key_by` to requiring a str or list of str rather than varargs. This is because having default values specified by a kwarg was interacting poorly with the varargs. Python3 supports this better. https://stackoverflow.com/questions/13821877/function-call-with-named-unnamed-and-variable-arguments-in-python",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2279#issuecomment-334795157
https://github.com/hail-is/hail/pull/2279#issuecomment-334795157:325,Modifiability,variab,variable-arguments-in-python,325,"Reverted the interface for `select`, `drop`, and `key_by` to requiring a str or list of str rather than varargs. This is because having default values specified by a kwarg was interacting poorly with the varargs. Python3 supports this better. https://stackoverflow.com/questions/13821877/function-call-with-named-unnamed-and-variable-arguments-in-python",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2279#issuecomment-334795157
https://github.com/hail-is/hail/pull/2280#issuecomment-335470740:46,Integrability,depend,dependent,46,@danking Should I review this now? Or is this dependent on #2270?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2280#issuecomment-335470740
https://github.com/hail-is/hail/pull/2285#issuecomment-335862234:164,Availability,down,down,164,@cseed is this how it should work? seems odd to put `null` as position. I also notice that `filterSamplesMask` does some custom stuff. Will this change slow things down unnecessarily if `drop_samples` is not used immediately after a read?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2285#issuecomment-335862234
https://github.com/hail-is/hail/pull/2285#issuecomment-336261462:133,Availability,down,down,133,"Yes. > seems odd to put null as position. I agree. That's why we need your new IR with no positions!. > Will this change slow things down unnecessarily if drop_samples is not used immediately after a read?. Yes, possibly a little, since FilterSamples needs to handle the case where not all samples are filtered. Options: specialize the case in FilterSamples when the condition is false (or true -- no-op) or add a DropSamples node. I prefer the former. FilterSamples is somewhat better in the coming OrderedRDD2/RegionValueBuilder stuff. The implementation has almost no overhead for when the condition is false. I say leave this as is and we'll pick that up when my later PRs go in.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2285#issuecomment-336261462
https://github.com/hail-is/hail/pull/2288#issuecomment-336538490:52,Security,Hash,Hashing,52,"I'll start reviewing functions based on ""High Speed Hashing for Integers and Strings"" so you can assign that PR to me.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2288#issuecomment-336538490
https://github.com/hail-is/hail/pull/2294#issuecomment-336480884:25,Testability,test,test,25,Addressed comments. That test was messed up. Added typecheck and fixed everything up so it passes.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2294#issuecomment-336480884
https://github.com/hail-is/hail/pull/2299#issuecomment-336567541:25,Testability,test,testRegionValue,25,"Addressed both comments: testRegionValue now tests all types, not just structs, and exercises the visitor (by calling pretty).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2299#issuecomment-336567541
https://github.com/hail-is/hail/pull/2299#issuecomment-336567541:45,Testability,test,tests,45,"Addressed both comments: testRegionValue now tests all types, not just structs, and exercises the visitor (by calling pretty).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2299#issuecomment-336567541
https://github.com/hail-is/hail/pull/2299#issuecomment-336900902:471,Energy Efficiency,allocate,allocate,471,"@catoverdrive I dismissed your review because I added more changes to address your comment on the FIXME. I think addRegionValue now does a minimal amount of work. In particular, if you write add a region value at the top level to the same region (rvb.start(t); rvb.addRegionValue(rv); rvb.end), it doesn't modify the region but simply sets start = rv.offset. This means that rvb.start can't actually do anything, and some other add routines need to check if they need to allocate. This adds some overhead that should get compiled away in the staged version. I also improved the tests to test adding to the same as well as a different region.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2299#issuecomment-336900902
https://github.com/hail-is/hail/pull/2299#issuecomment-336900902:432,Integrability,rout,routines,432,"@catoverdrive I dismissed your review because I added more changes to address your comment on the FIXME. I think addRegionValue now does a minimal amount of work. In particular, if you write add a region value at the top level to the same region (rvb.start(t); rvb.addRegionValue(rv); rvb.end), it doesn't modify the region but simply sets start = rv.offset. This means that rvb.start can't actually do anything, and some other add routines need to check if they need to allocate. This adds some overhead that should get compiled away in the staged version. I also improved the tests to test adding to the same as well as a different region.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2299#issuecomment-336900902
https://github.com/hail-is/hail/pull/2299#issuecomment-336900902:578,Testability,test,tests,578,"@catoverdrive I dismissed your review because I added more changes to address your comment on the FIXME. I think addRegionValue now does a minimal amount of work. In particular, if you write add a region value at the top level to the same region (rvb.start(t); rvb.addRegionValue(rv); rvb.end), it doesn't modify the region but simply sets start = rv.offset. This means that rvb.start can't actually do anything, and some other add routines need to check if they need to allocate. This adds some overhead that should get compiled away in the staged version. I also improved the tests to test adding to the same as well as a different region.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2299#issuecomment-336900902
https://github.com/hail-is/hail/pull/2299#issuecomment-336900902:587,Testability,test,test,587,"@catoverdrive I dismissed your review because I added more changes to address your comment on the FIXME. I think addRegionValue now does a minimal amount of work. In particular, if you write add a region value at the top level to the same region (rvb.start(t); rvb.addRegionValue(rv); rvb.end), it doesn't modify the region but simply sets start = rv.offset. This means that rvb.start can't actually do anything, and some other add routines need to check if they need to allocate. This adds some overhead that should get compiled away in the staged version. I also improved the tests to test adding to the same as well as a different region.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2299#issuecomment-336900902
https://github.com/hail-is/hail/pull/2299#issuecomment-336900902:328,Usability,simpl,simply,328,"@catoverdrive I dismissed your review because I added more changes to address your comment on the FIXME. I think addRegionValue now does a minimal amount of work. In particular, if you write add a region value at the top level to the same region (rvb.start(t); rvb.addRegionValue(rv); rvb.end), it doesn't modify the region but simply sets start = rv.offset. This means that rvb.start can't actually do anything, and some other add routines need to check if they need to allocate. This adds some overhead that should get compiled away in the staged version. I also improved the tests to test adding to the same as well as a different region.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2299#issuecomment-336900902
https://github.com/hail-is/hail/pull/2299#issuecomment-336949521:352,Availability,error,errors,352,"OK, I improved the tests two ways:. 1. I allocate a random amount of memory in the region to start so things don't always start at offset 0. 2. I test addRegionValue adding a value at the top level and and a nested level (by allocating a non-unsafe Row when t == TStruct) so it calls through to RVB.addRow. I verified it would have caught the previous errors, and it caught another error (toOff was wrong in addRegionValue because we called currentOffset before allocateRoot). Hopefully good to go now.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2299#issuecomment-336949521
https://github.com/hail-is/hail/pull/2299#issuecomment-336949521:382,Availability,error,error,382,"OK, I improved the tests two ways:. 1. I allocate a random amount of memory in the region to start so things don't always start at offset 0. 2. I test addRegionValue adding a value at the top level and and a nested level (by allocating a non-unsafe Row when t == TStruct) so it calls through to RVB.addRow. I verified it would have caught the previous errors, and it caught another error (toOff was wrong in addRegionValue because we called currentOffset before allocateRoot). Hopefully good to go now.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2299#issuecomment-336949521
https://github.com/hail-is/hail/pull/2299#issuecomment-336949521:41,Energy Efficiency,allocate,allocate,41,"OK, I improved the tests two ways:. 1. I allocate a random amount of memory in the region to start so things don't always start at offset 0. 2. I test addRegionValue adding a value at the top level and and a nested level (by allocating a non-unsafe Row when t == TStruct) so it calls through to RVB.addRow. I verified it would have caught the previous errors, and it caught another error (toOff was wrong in addRegionValue because we called currentOffset before allocateRoot). Hopefully good to go now.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2299#issuecomment-336949521
https://github.com/hail-is/hail/pull/2299#issuecomment-336949521:462,Energy Efficiency,allocate,allocateRoot,462,"OK, I improved the tests two ways:. 1. I allocate a random amount of memory in the region to start so things don't always start at offset 0. 2. I test addRegionValue adding a value at the top level and and a nested level (by allocating a non-unsafe Row when t == TStruct) so it calls through to RVB.addRow. I verified it would have caught the previous errors, and it caught another error (toOff was wrong in addRegionValue because we called currentOffset before allocateRoot). Hopefully good to go now.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2299#issuecomment-336949521
https://github.com/hail-is/hail/pull/2299#issuecomment-336949521:242,Safety,unsafe,unsafe,242,"OK, I improved the tests two ways:. 1. I allocate a random amount of memory in the region to start so things don't always start at offset 0. 2. I test addRegionValue adding a value at the top level and and a nested level (by allocating a non-unsafe Row when t == TStruct) so it calls through to RVB.addRow. I verified it would have caught the previous errors, and it caught another error (toOff was wrong in addRegionValue because we called currentOffset before allocateRoot). Hopefully good to go now.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2299#issuecomment-336949521
https://github.com/hail-is/hail/pull/2299#issuecomment-336949521:19,Testability,test,tests,19,"OK, I improved the tests two ways:. 1. I allocate a random amount of memory in the region to start so things don't always start at offset 0. 2. I test addRegionValue adding a value at the top level and and a nested level (by allocating a non-unsafe Row when t == TStruct) so it calls through to RVB.addRow. I verified it would have caught the previous errors, and it caught another error (toOff was wrong in addRegionValue because we called currentOffset before allocateRoot). Hopefully good to go now.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2299#issuecomment-336949521
https://github.com/hail-is/hail/pull/2299#issuecomment-336949521:146,Testability,test,test,146,"OK, I improved the tests two ways:. 1. I allocate a random amount of memory in the region to start so things don't always start at offset 0. 2. I test addRegionValue adding a value at the top level and and a nested level (by allocating a non-unsafe Row when t == TStruct) so it calls through to RVB.addRow. I verified it would have caught the previous errors, and it caught another error (toOff was wrong in addRegionValue because we called currentOffset before allocateRoot). Hopefully good to go now.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2299#issuecomment-336949521
https://github.com/hail-is/hail/pull/2300#issuecomment-340895757:328,Deployability,update,update,328,"Thanks Shuli, and apologies for the delay! I've taken your changes to the parameters and added some additional fixes in #2377 directly on @johnc1231 branch, which should be reviewed and merged to master this week. I'll be in touch once that's in, and from there, you can make future PRs against master for our review to improve/update Nirvana in Hail.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2300#issuecomment-340895757
https://github.com/hail-is/hail/pull/2301#issuecomment-337368303:37,Deployability,pipeline,pipeline,37,bump. I have a stack of these in the pipeline and want to keep them moving.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2301#issuecomment-337368303
https://github.com/hail-is/hail/pull/2302#issuecomment-337420156:102,Energy Efficiency,schedul,schedule,102,https://github.com/hail-is/hail/pull/2301 is now in. This should be ready for a look. How's your ASHG schedule? Let me know if you want me to give this to someone else.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2302#issuecomment-337420156
https://github.com/hail-is/hail/pull/2302#issuecomment-337749177:78,Integrability,depend,dependent-pull-requests-in-github-possible,78,"This is a useful discussion: https://stackoverflow.com/questions/26619478/are-dependent-pull-requests-in-github-possible. If I create multiple, stacked branches in hail-is/hail and PR them against each other, NOT master (except the first one), then they can be reviewed independently. I might start trying to do this. I still have a bunch more PRs on this RegionValue stuff. :-/",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2302#issuecomment-337749177
https://github.com/hail-is/hail/pull/2308#issuecomment-337927797:454,Integrability,depend,dependent,454,"Uh-oh, so this built on a previous PR that @tpoterba was reviewing: https://github.com/hail-is/hail/pull/2302. I was afraid this was going to happen at some point. @tpoterba I'd still like your input on the OrderedRDD2 stuff (and any comments you had on the region value stuff) and I will address it with a new round of changes. I'm going to close that pull request but you can still comment there. In the future we should use stacked branches for inter-dependent PRs. See my comment on that PR for a link to a description. I'm going to try to PR the remaining OrderedRDD2 stuff that way.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2308#issuecomment-337927797
https://github.com/hail-is/hail/issues/2314#issuecomment-384085976:871,Availability,down,download,871,"""the implementations should rely directly on java.util.Random"" Umm, why? From my outsiders perspective I would have assumed that high quality software worked on by the Broad Institute would use a half decent Random Number Generator (RNG). . If I had time to spend on this I would be pushing to change it to something else, perhaps the Apache Commons RNG: commons.apache.org/proper/commons-rng/userguide/rng.html I'm not a Java programmer though, and don't really aspire to be. . The C++ standard rand() function is also well known to be quite bad, though C++11 distributions use an ok implementation (I think default is Mersenne Twister, but there are also other options http://en.cppreference.com/w/cpp/numeric/random). In some C code I was replacing rand() and found this nice library: http://www.pcg-random.org/ no Java implementation though http://www.pcg-random.org/download.html#java-implementation T.T, but the PCG algorithm is actually really simple to implement. The PCG site is worth exploring in general to understand the important differences between RNGs. The GNU Scientific Library also provides C/C++ coders with some RNG implementations https://www.gnu.org/software/gsl/manual/html_node/Random-Number-Generation.html . I realize that it is quite early in development (in terms of versioning, 0.2) so maybe this seems like an insignificant thing, but I also hear that it is actively being used, so.... it also may not matter much, I just would like to bring some attention to it in case it hasn't been considered because I know that the RNG is something that is frequently overlooked.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2314#issuecomment-384085976
https://github.com/hail-is/hail/issues/2314#issuecomment-384085976:951,Usability,simpl,simple,951,"""the implementations should rely directly on java.util.Random"" Umm, why? From my outsiders perspective I would have assumed that high quality software worked on by the Broad Institute would use a half decent Random Number Generator (RNG). . If I had time to spend on this I would be pushing to change it to something else, perhaps the Apache Commons RNG: commons.apache.org/proper/commons-rng/userguide/rng.html I'm not a Java programmer though, and don't really aspire to be. . The C++ standard rand() function is also well known to be quite bad, though C++11 distributions use an ok implementation (I think default is Mersenne Twister, but there are also other options http://en.cppreference.com/w/cpp/numeric/random). In some C code I was replacing rand() and found this nice library: http://www.pcg-random.org/ no Java implementation though http://www.pcg-random.org/download.html#java-implementation T.T, but the PCG algorithm is actually really simple to implement. The PCG site is worth exploring in general to understand the important differences between RNGs. The GNU Scientific Library also provides C/C++ coders with some RNG implementations https://www.gnu.org/software/gsl/manual/html_node/Random-Number-Generation.html . I realize that it is quite early in development (in terms of versioning, 0.2) so maybe this seems like an insignificant thing, but I also hear that it is actively being used, so.... it also may not matter much, I just would like to bring some attention to it in case it hasn't been considered because I know that the RNG is something that is frequently overlooked.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2314#issuecomment-384085976
https://github.com/hail-is/hail/issues/2314#issuecomment-384139281:763,Energy Efficiency,efficient,efficient,763,"@ttbek, thanks for the comment and concern,. > ""the implementations should rely directly on java.util.Random"" Umm, why? From my outsiders perspective I would have assumed that high quality software worked on by the Broad Institute would use a half decent Random Number Generator (RNG). The phrase ""should rely directly on `java.util.Random`"" was referring to not accepting a source of Randomness as a parameter. It was unnecessarily specific, we're sorry that lead to your confusion. We would be happy to accept a pull request that resolves this issue by building an RNG on more theoretically sound primitives as we have done for [hash functions](https://github.com/hail-is/hail/blob/master/src/main/scala/is/hail/utils/HashMethods.scala) or by using an existing efficient random number generator, such as the ones provided by Apache.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2314#issuecomment-384139281
https://github.com/hail-is/hail/issues/2314#issuecomment-384139281:631,Security,hash,hash,631,"@ttbek, thanks for the comment and concern,. > ""the implementations should rely directly on java.util.Random"" Umm, why? From my outsiders perspective I would have assumed that high quality software worked on by the Broad Institute would use a half decent Random Number Generator (RNG). The phrase ""should rely directly on `java.util.Random`"" was referring to not accepting a source of Randomness as a parameter. It was unnecessarily specific, we're sorry that lead to your confusion. We would be happy to accept a pull request that resolves this issue by building an RNG on more theoretically sound primitives as we have done for [hash functions](https://github.com/hail-is/hail/blob/master/src/main/scala/is/hail/utils/HashMethods.scala) or by using an existing efficient random number generator, such as the ones provided by Apache.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2314#issuecomment-384139281
https://github.com/hail-is/hail/issues/2314#issuecomment-384139281:720,Security,Hash,HashMethods,720,"@ttbek, thanks for the comment and concern,. > ""the implementations should rely directly on java.util.Random"" Umm, why? From my outsiders perspective I would have assumed that high quality software worked on by the Broad Institute would use a half decent Random Number Generator (RNG). The phrase ""should rely directly on `java.util.Random`"" was referring to not accepting a source of Randomness as a parameter. It was unnecessarily specific, we're sorry that lead to your confusion. We would be happy to accept a pull request that resolves this issue by building an RNG on more theoretically sound primitives as we have done for [hash functions](https://github.com/hail-is/hail/blob/master/src/main/scala/is/hail/utils/HashMethods.scala) or by using an existing efficient random number generator, such as the ones provided by Apache.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2314#issuecomment-384139281
https://github.com/hail-is/hail/issues/2314#issuecomment-422362729:43,Performance,perform,performance,43,BN is now implemented in Python. Improving performance will now involve improving general infrastructure for the IR / execution engine,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2314#issuecomment-422362729
https://github.com/hail-is/hail/pull/2317#issuecomment-337983661:55,Safety,unsafe,unsafeInsert,55,I'm going to stack this PR because I need to build on `unsafeInsert`. Will reopen from a branch on hail-is/hail.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2317#issuecomment-337983661
https://github.com/hail-is/hail/pull/2322#issuecomment-339350297:0,Availability,ping,ping,0,ping,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2322#issuecomment-339350297
https://github.com/hail-is/hail/pull/2323#issuecomment-339088324:0,Deployability,Update,Updated,0,"Updated docs, check the value of f at the endpoints have opposite sign.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2323#issuecomment-339088324
https://github.com/hail-is/hail/pull/2342#issuecomment-340501283:48,Performance,perform,performance,48,Closing since this isn't on the winning side of performance yet.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2342#issuecomment-340501283
https://github.com/hail-is/hail/pull/2353#issuecomment-339469069:10,Testability,test,test,10,"yeah, my ""test setup"" before the doc tests was wrong (I used ""vds1"" instead of ""vds"")",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2353#issuecomment-339469069
https://github.com/hail-is/hail/pull/2353#issuecomment-339469069:37,Testability,test,tests,37,"yeah, my ""test setup"" before the doc tests was wrong (I used ""vds1"" instead of ""vds"")",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2353#issuecomment-339469069
https://github.com/hail-is/hail/pull/2359#issuecomment-339549140:71,Availability,robust,robust,71,@tpoterba I also got rid of max_shift and (hopefully) made things more robust. Can you take a quick look to see if you're happy with what I did?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2359#issuecomment-339549140
https://github.com/hail-is/hail/pull/2359#issuecomment-340653113:48,Testability,test,tests,48,"Yes, there was a conflict. I've resolved it and tests are running now.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2359#issuecomment-340653113
https://github.com/hail-is/hail/pull/2360#issuecomment-340047873:46,Integrability,depend,dependent,46,"> but not the thunk of thunking. You mean the dependent aggregators? The issue is the copy code needs access to the type that was matched in the TVariable. The TVariable binding is cleaned on every function match, which is long before the code is executed on a worker. Therefore, we need to run some code to capture the TVariable binding just after the match happens. That's what the extra level of thunking is about.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2360#issuecomment-340047873
https://github.com/hail-is/hail/pull/2360#issuecomment-340047873:102,Security,access,access,102,"> but not the thunk of thunking. You mean the dependent aggregators? The issue is the copy code needs access to the type that was matched in the TVariable. The TVariable binding is cleaned on every function match, which is long before the code is executed on a worker. Therefore, we need to run some code to capture the TVariable binding just after the match happens. That's what the extra level of thunking is about.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2360#issuecomment-340047873
https://github.com/hail-is/hail/pull/2366#issuecomment-339832499:151,Modifiability,parameteriz,parameterize,151,I also made a bit of a restructuring to all `BlockMatrix` `Gen`erators because you can't use default arguments with overloaded methods but I wanted to parameterize everything by an element `Gen`.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2366#issuecomment-339832499
https://github.com/hail-is/hail/pull/2367#issuecomment-340074758:54,Deployability,update,updated,54,"Now passing by killing safety on readPartitions, I've updated the comment above.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2367#issuecomment-340074758
https://github.com/hail-is/hail/pull/2367#issuecomment-340074758:23,Safety,safe,safety,23,"Now passing by killing safety on readPartitions, I've updated the comment above.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2367#issuecomment-340074758
https://github.com/hail-is/hail/pull/2368#issuecomment-340856253:63,Integrability,interface,interface,63,Is there any reason not to give `HardCallView` an `Array`-like interface? E.g.; ```scala; def apply(i: Int): Option[Int] = {; setGenotype(i); if (hasGT) Some(getGT) else None; }; ```; That seems like a much more comfortable view interface.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2368#issuecomment-340856253
https://github.com/hail-is/hail/pull/2368#issuecomment-340856253:229,Integrability,interface,interface,229,Is there any reason not to give `HardCallView` an `Array`-like interface? E.g.; ```scala; def apply(i: Int): Option[Int] = {; setGenotype(i); if (hasGT) Some(getGT) else None; }; ```; That seems like a much more comfortable view interface.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2368#issuecomment-340856253
https://github.com/hail-is/hail/pull/2368#issuecomment-340901365:181,Energy Efficiency,allocate,allocate,181,"Re: this interface:; ```scala; def apply(i: Int): Option[Int] = {; setGenotype(i); if (hasGT) Some(getGT) else None; }; ```; It's entirely for performance reasons. We never want to allocate or process `Option`s anywhere, and there's some overhead we can avoid with calling `setGenotype(i)` twice if we use two methods for `hasGtIdx(i: Int): Boolean ` and `getGtIdx(I: Int): Int`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2368#issuecomment-340901365
https://github.com/hail-is/hail/pull/2368#issuecomment-340901365:9,Integrability,interface,interface,9,"Re: this interface:; ```scala; def apply(i: Int): Option[Int] = {; setGenotype(i); if (hasGT) Some(getGT) else None; }; ```; It's entirely for performance reasons. We never want to allocate or process `Option`s anywhere, and there's some overhead we can avoid with calling `setGenotype(i)` twice if we use two methods for `hasGtIdx(i: Int): Boolean ` and `getGtIdx(I: Int): Int`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2368#issuecomment-340901365
https://github.com/hail-is/hail/pull/2368#issuecomment-340901365:143,Performance,perform,performance,143,"Re: this interface:; ```scala; def apply(i: Int): Option[Int] = {; setGenotype(i); if (hasGT) Some(getGT) else None; }; ```; It's entirely for performance reasons. We never want to allocate or process `Option`s anywhere, and there's some overhead we can avoid with calling `setGenotype(i)` twice if we use two methods for `hasGtIdx(i: Int): Boolean ` and `getGtIdx(I: Int): Int`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2368#issuecomment-340901365
https://github.com/hail-is/hail/pull/2368#issuecomment-340901365:254,Safety,avoid,avoid,254,"Re: this interface:; ```scala; def apply(i: Int): Option[Int] = {; setGenotype(i); if (hasGT) Some(getGT) else None; }; ```; It's entirely for performance reasons. We never want to allocate or process `Option`s anywhere, and there's some overhead we can avoid with calling `setGenotype(i)` twice if we use two methods for `hasGtIdx(i: Int): Boolean ` and `getGtIdx(I: Int): Int`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2368#issuecomment-340901365
https://github.com/hail-is/hail/pull/2369#issuecomment-341190936:55,Testability,log,log,55,"Ah, nice -- it had been a little while since I've done log arithmetic and it was fun to work out the formula equivalence :)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2369#issuecomment-341190936
https://github.com/hail-is/hail/pull/2374#issuecomment-340212371:55,Availability,error,errors,55,"It would be easy to implement TDT, de novo, and mendel errors in expr using this, I think.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2374#issuecomment-340212371
https://github.com/hail-is/hail/pull/2374#issuecomment-340212405:10,Performance,perform,performance,10,"(with bad performance, probably. And this would probably insert a join in the DAG if someone wants to use it to filter)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2374#issuecomment-340212405
https://github.com/hail-is/hail/pull/2374#issuecomment-344966947:83,Testability,test,tests,83,Bump. Will be awesome to get this in. Let me know if you want help. Looks like the tests are passing but there's a python problem.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2374#issuecomment-344966947
https://github.com/hail-is/hail/pull/2377#issuecomment-340889701:261,Deployability,configurat,configuration,261,"I've rebased John's branch, added the default block_size change by @shulik7 at Nirvana, and made a few additional small changes including adding the @typecheck_method and @record_method decorators (the latter is now required, else history goes histrionic). The configuration file, init script, and resource files are in`gs://hail-common/nirvana`. The init script `gs://hail-common/nirvana/nirvana-init-GRCh37.sh` makes local copies of the resource files and .net: ; ```; #!/bin/bash. mkdir -p /nirvana/Data/Cache; mkdir -p /nirvana/Data/References; mkdir -p /nirvana/Data/SupplementaryDatabase. #Data is copied for use with Nirvana 1.6.2 as of June 19 2017; gsutil -m cp -r gs://hail-common/nirvana/Data/Cache/24/GRCh37 /nirvana/Data/Cache; gsutil -m cp gs://hail-common/nirvana/Data/References/5/Homo_sapiens.GRCh37.Nirvana.dat /nirvana/Data/References; gsutil -m cp -r gs://hail-common/nirvana/Data/SupplementaryDatabase/39/GRCh37 /nirvana/Data/SupplementaryDatabase; gsutil -m cp -r gs://hail-common/nirvana/netcoreapp1.1 /nirvana; gsutil -m cp gs://hail-common/nirvana/nirvana-cloud-GRCh37.properties /nirvana. chmod -R 777 /nirvana. apt-get -y install curl libunwind8 gettext; curl -sSL -o dotnet.tar.gz https://go.microsoft.com/fwlink/?linkid=843453; mkdir -p /opt/dotnet && sudo tar zxf dotnet.tar.gz -C /opt/dotnet; ln -s /opt/dotnet/dotnet /usr/local/bin; ```. The properties file `nirvana-cloud-GRCh37.properties` points Nirvana to these local resources:; ```; hail.nirvana.location = /nirvana/netcoreapp1.1/Nirvana.dll; hail.nirvana.cache = /nirvana/Data/Cache/GRCh37/Ensembl84; hail.nirvana.reference = /nirvana/Data/References/Homo_sapiens.GRCh37.Nirvana.dat; hail.nirvana.supplementaryAnnotationDirectory = /nirvana/Data/SupplementaryDatabase/GRCh37; ```. I started a cluster with the init script and ran Nirvana on all of `profile225.vcf`, and later exported results for just a region bounding the gene CABIN1:; ```; from hail import *; hc = (HailContext()). (hc; .import_vcf(path='gs:/",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2377#issuecomment-340889701
https://github.com/hail-is/hail/pull/2377#issuecomment-340889701:1149,Deployability,install,install,1149,"d @record_method decorators (the latter is now required, else history goes histrionic). The configuration file, init script, and resource files are in`gs://hail-common/nirvana`. The init script `gs://hail-common/nirvana/nirvana-init-GRCh37.sh` makes local copies of the resource files and .net: ; ```; #!/bin/bash. mkdir -p /nirvana/Data/Cache; mkdir -p /nirvana/Data/References; mkdir -p /nirvana/Data/SupplementaryDatabase. #Data is copied for use with Nirvana 1.6.2 as of June 19 2017; gsutil -m cp -r gs://hail-common/nirvana/Data/Cache/24/GRCh37 /nirvana/Data/Cache; gsutil -m cp gs://hail-common/nirvana/Data/References/5/Homo_sapiens.GRCh37.Nirvana.dat /nirvana/Data/References; gsutil -m cp -r gs://hail-common/nirvana/Data/SupplementaryDatabase/39/GRCh37 /nirvana/Data/SupplementaryDatabase; gsutil -m cp -r gs://hail-common/nirvana/netcoreapp1.1 /nirvana; gsutil -m cp gs://hail-common/nirvana/nirvana-cloud-GRCh37.properties /nirvana. chmod -R 777 /nirvana. apt-get -y install curl libunwind8 gettext; curl -sSL -o dotnet.tar.gz https://go.microsoft.com/fwlink/?linkid=843453; mkdir -p /opt/dotnet && sudo tar zxf dotnet.tar.gz -C /opt/dotnet; ln -s /opt/dotnet/dotnet /usr/local/bin; ```. The properties file `nirvana-cloud-GRCh37.properties` points Nirvana to these local resources:; ```; hail.nirvana.location = /nirvana/netcoreapp1.1/Nirvana.dll; hail.nirvana.cache = /nirvana/Data/Cache/GRCh37/Ensembl84; hail.nirvana.reference = /nirvana/Data/References/Homo_sapiens.GRCh37.Nirvana.dat; hail.nirvana.supplementaryAnnotationDirectory = /nirvana/Data/SupplementaryDatabase/GRCh37; ```. I started a cluster with the init script and ran Nirvana on all of `profile225.vcf`, and later exported results for just a region bounding the gene CABIN1:; ```; from hail import *; hc = (HailContext()). (hc; .import_vcf(path='gs://jbloom/profile225.vcf.bgz'); .filter_multi(); .nirvana(block_size=10000, config='/nirvana/nirvana-cloud-GRCh37.properties'); .variants_table(); .filter(expr='v.start > ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2377#issuecomment-340889701
https://github.com/hail-is/hail/pull/2377#issuecomment-340889701:261,Modifiability,config,configuration,261,"I've rebased John's branch, added the default block_size change by @shulik7 at Nirvana, and made a few additional small changes including adding the @typecheck_method and @record_method decorators (the latter is now required, else history goes histrionic). The configuration file, init script, and resource files are in`gs://hail-common/nirvana`. The init script `gs://hail-common/nirvana/nirvana-init-GRCh37.sh` makes local copies of the resource files and .net: ; ```; #!/bin/bash. mkdir -p /nirvana/Data/Cache; mkdir -p /nirvana/Data/References; mkdir -p /nirvana/Data/SupplementaryDatabase. #Data is copied for use with Nirvana 1.6.2 as of June 19 2017; gsutil -m cp -r gs://hail-common/nirvana/Data/Cache/24/GRCh37 /nirvana/Data/Cache; gsutil -m cp gs://hail-common/nirvana/Data/References/5/Homo_sapiens.GRCh37.Nirvana.dat /nirvana/Data/References; gsutil -m cp -r gs://hail-common/nirvana/Data/SupplementaryDatabase/39/GRCh37 /nirvana/Data/SupplementaryDatabase; gsutil -m cp -r gs://hail-common/nirvana/netcoreapp1.1 /nirvana; gsutil -m cp gs://hail-common/nirvana/nirvana-cloud-GRCh37.properties /nirvana. chmod -R 777 /nirvana. apt-get -y install curl libunwind8 gettext; curl -sSL -o dotnet.tar.gz https://go.microsoft.com/fwlink/?linkid=843453; mkdir -p /opt/dotnet && sudo tar zxf dotnet.tar.gz -C /opt/dotnet; ln -s /opt/dotnet/dotnet /usr/local/bin; ```. The properties file `nirvana-cloud-GRCh37.properties` points Nirvana to these local resources:; ```; hail.nirvana.location = /nirvana/netcoreapp1.1/Nirvana.dll; hail.nirvana.cache = /nirvana/Data/Cache/GRCh37/Ensembl84; hail.nirvana.reference = /nirvana/Data/References/Homo_sapiens.GRCh37.Nirvana.dat; hail.nirvana.supplementaryAnnotationDirectory = /nirvana/Data/SupplementaryDatabase/GRCh37; ```. I started a cluster with the init script and ran Nirvana on all of `profile225.vcf`, and later exported results for just a region bounding the gene CABIN1:; ```; from hail import *; hc = (HailContext()). (hc; .import_vcf(path='gs:/",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2377#issuecomment-340889701
https://github.com/hail-is/hail/pull/2377#issuecomment-340889701:2075,Modifiability,config,config,2075,"cloud-GRCh37.properties /nirvana. chmod -R 777 /nirvana. apt-get -y install curl libunwind8 gettext; curl -sSL -o dotnet.tar.gz https://go.microsoft.com/fwlink/?linkid=843453; mkdir -p /opt/dotnet && sudo tar zxf dotnet.tar.gz -C /opt/dotnet; ln -s /opt/dotnet/dotnet /usr/local/bin; ```. The properties file `nirvana-cloud-GRCh37.properties` points Nirvana to these local resources:; ```; hail.nirvana.location = /nirvana/netcoreapp1.1/Nirvana.dll; hail.nirvana.cache = /nirvana/Data/Cache/GRCh37/Ensembl84; hail.nirvana.reference = /nirvana/Data/References/Homo_sapiens.GRCh37.Nirvana.dat; hail.nirvana.supplementaryAnnotationDirectory = /nirvana/Data/SupplementaryDatabase/GRCh37; ```. I started a cluster with the init script and ran Nirvana on all of `profile225.vcf`, and later exported results for just a region bounding the gene CABIN1:; ```; from hail import *; hc = (HailContext()). (hc; .import_vcf(path='gs://jbloom/profile225.vcf.bgz'); .filter_multi(); .nirvana(block_size=10000, config='/nirvana/nirvana-cloud-GRCh37.properties'); .variants_table(); .filter(expr='v.start > 24430000 && v.start < 24580000'); .export(output='gs://jbloom/nirvana_cabin1.tsv')); ```. The top-level categories show reasonable-looking variation, except for ""clinvar"" and ""genes"" which are all `null` valued. Comparing a few variants in [gnomad](http://gnomad.broadinstitute.org/gene/ENSG00000099991), the annotations line up nicely. Here's an example of a common missense variant:; ```; 22:24468386:G:A	{""rsid"":null,""qual"":38350.97,""filters"":null,""info"":{""AC"":[306],""AF"":[0.061],""AN"":5018,""BaseQRankSum"":26.807,""ClippingRankSum"":-0.538,""DP"":22432,""DS"":null,""FS"":1.203,""HaplotypeScore"":null,""InbreedingCoeff"":0.0335,""MLEAC"":[309],""MLEAF"":[0.062],""MQ"":59.13,""MQ0"":0,""MQRankSum"":16.406,""QD"":14.9,""ReadPosRankSum"":-0.637,""set"":null},""nirvana"":{""chromosome"":""22"",""refAllele"":""G"",""position"":24468386,""altAlleles"":[""A""],""cytogeneticBand"":""22q11.23"",""filters"":null,""variants"":[{""altAllele"":""A"",""refAllele"":""G"",""chro",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2377#issuecomment-340889701
https://github.com/hail-is/hail/pull/2377#issuecomment-340889701:507,Performance,Cache,Cache,507,"I've rebased John's branch, added the default block_size change by @shulik7 at Nirvana, and made a few additional small changes including adding the @typecheck_method and @record_method decorators (the latter is now required, else history goes histrionic). The configuration file, init script, and resource files are in`gs://hail-common/nirvana`. The init script `gs://hail-common/nirvana/nirvana-init-GRCh37.sh` makes local copies of the resource files and .net: ; ```; #!/bin/bash. mkdir -p /nirvana/Data/Cache; mkdir -p /nirvana/Data/References; mkdir -p /nirvana/Data/SupplementaryDatabase. #Data is copied for use with Nirvana 1.6.2 as of June 19 2017; gsutil -m cp -r gs://hail-common/nirvana/Data/Cache/24/GRCh37 /nirvana/Data/Cache; gsutil -m cp gs://hail-common/nirvana/Data/References/5/Homo_sapiens.GRCh37.Nirvana.dat /nirvana/Data/References; gsutil -m cp -r gs://hail-common/nirvana/Data/SupplementaryDatabase/39/GRCh37 /nirvana/Data/SupplementaryDatabase; gsutil -m cp -r gs://hail-common/nirvana/netcoreapp1.1 /nirvana; gsutil -m cp gs://hail-common/nirvana/nirvana-cloud-GRCh37.properties /nirvana. chmod -R 777 /nirvana. apt-get -y install curl libunwind8 gettext; curl -sSL -o dotnet.tar.gz https://go.microsoft.com/fwlink/?linkid=843453; mkdir -p /opt/dotnet && sudo tar zxf dotnet.tar.gz -C /opt/dotnet; ln -s /opt/dotnet/dotnet /usr/local/bin; ```. The properties file `nirvana-cloud-GRCh37.properties` points Nirvana to these local resources:; ```; hail.nirvana.location = /nirvana/netcoreapp1.1/Nirvana.dll; hail.nirvana.cache = /nirvana/Data/Cache/GRCh37/Ensembl84; hail.nirvana.reference = /nirvana/Data/References/Homo_sapiens.GRCh37.Nirvana.dat; hail.nirvana.supplementaryAnnotationDirectory = /nirvana/Data/SupplementaryDatabase/GRCh37; ```. I started a cluster with the init script and ran Nirvana on all of `profile225.vcf`, and later exported results for just a region bounding the gene CABIN1:; ```; from hail import *; hc = (HailContext()). (hc; .import_vcf(path='gs:/",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2377#issuecomment-340889701
https://github.com/hail-is/hail/pull/2377#issuecomment-340889701:704,Performance,Cache,Cache,704,"I've rebased John's branch, added the default block_size change by @shulik7 at Nirvana, and made a few additional small changes including adding the @typecheck_method and @record_method decorators (the latter is now required, else history goes histrionic). The configuration file, init script, and resource files are in`gs://hail-common/nirvana`. The init script `gs://hail-common/nirvana/nirvana-init-GRCh37.sh` makes local copies of the resource files and .net: ; ```; #!/bin/bash. mkdir -p /nirvana/Data/Cache; mkdir -p /nirvana/Data/References; mkdir -p /nirvana/Data/SupplementaryDatabase. #Data is copied for use with Nirvana 1.6.2 as of June 19 2017; gsutil -m cp -r gs://hail-common/nirvana/Data/Cache/24/GRCh37 /nirvana/Data/Cache; gsutil -m cp gs://hail-common/nirvana/Data/References/5/Homo_sapiens.GRCh37.Nirvana.dat /nirvana/Data/References; gsutil -m cp -r gs://hail-common/nirvana/Data/SupplementaryDatabase/39/GRCh37 /nirvana/Data/SupplementaryDatabase; gsutil -m cp -r gs://hail-common/nirvana/netcoreapp1.1 /nirvana; gsutil -m cp gs://hail-common/nirvana/nirvana-cloud-GRCh37.properties /nirvana. chmod -R 777 /nirvana. apt-get -y install curl libunwind8 gettext; curl -sSL -o dotnet.tar.gz https://go.microsoft.com/fwlink/?linkid=843453; mkdir -p /opt/dotnet && sudo tar zxf dotnet.tar.gz -C /opt/dotnet; ln -s /opt/dotnet/dotnet /usr/local/bin; ```. The properties file `nirvana-cloud-GRCh37.properties` points Nirvana to these local resources:; ```; hail.nirvana.location = /nirvana/netcoreapp1.1/Nirvana.dll; hail.nirvana.cache = /nirvana/Data/Cache/GRCh37/Ensembl84; hail.nirvana.reference = /nirvana/Data/References/Homo_sapiens.GRCh37.Nirvana.dat; hail.nirvana.supplementaryAnnotationDirectory = /nirvana/Data/SupplementaryDatabase/GRCh37; ```. I started a cluster with the init script and ran Nirvana on all of `profile225.vcf`, and later exported results for just a region bounding the gene CABIN1:; ```; from hail import *; hc = (HailContext()). (hc; .import_vcf(path='gs:/",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2377#issuecomment-340889701
https://github.com/hail-is/hail/pull/2377#issuecomment-340889701:734,Performance,Cache,Cache,734,"I've rebased John's branch, added the default block_size change by @shulik7 at Nirvana, and made a few additional small changes including adding the @typecheck_method and @record_method decorators (the latter is now required, else history goes histrionic). The configuration file, init script, and resource files are in`gs://hail-common/nirvana`. The init script `gs://hail-common/nirvana/nirvana-init-GRCh37.sh` makes local copies of the resource files and .net: ; ```; #!/bin/bash. mkdir -p /nirvana/Data/Cache; mkdir -p /nirvana/Data/References; mkdir -p /nirvana/Data/SupplementaryDatabase. #Data is copied for use with Nirvana 1.6.2 as of June 19 2017; gsutil -m cp -r gs://hail-common/nirvana/Data/Cache/24/GRCh37 /nirvana/Data/Cache; gsutil -m cp gs://hail-common/nirvana/Data/References/5/Homo_sapiens.GRCh37.Nirvana.dat /nirvana/Data/References; gsutil -m cp -r gs://hail-common/nirvana/Data/SupplementaryDatabase/39/GRCh37 /nirvana/Data/SupplementaryDatabase; gsutil -m cp -r gs://hail-common/nirvana/netcoreapp1.1 /nirvana; gsutil -m cp gs://hail-common/nirvana/nirvana-cloud-GRCh37.properties /nirvana. chmod -R 777 /nirvana. apt-get -y install curl libunwind8 gettext; curl -sSL -o dotnet.tar.gz https://go.microsoft.com/fwlink/?linkid=843453; mkdir -p /opt/dotnet && sudo tar zxf dotnet.tar.gz -C /opt/dotnet; ln -s /opt/dotnet/dotnet /usr/local/bin; ```. The properties file `nirvana-cloud-GRCh37.properties` points Nirvana to these local resources:; ```; hail.nirvana.location = /nirvana/netcoreapp1.1/Nirvana.dll; hail.nirvana.cache = /nirvana/Data/Cache/GRCh37/Ensembl84; hail.nirvana.reference = /nirvana/Data/References/Homo_sapiens.GRCh37.Nirvana.dat; hail.nirvana.supplementaryAnnotationDirectory = /nirvana/Data/SupplementaryDatabase/GRCh37; ```. I started a cluster with the init script and ran Nirvana on all of `profile225.vcf`, and later exported results for just a region bounding the gene CABIN1:; ```; from hail import *; hc = (HailContext()). (hc; .import_vcf(path='gs:/",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2377#issuecomment-340889701
https://github.com/hail-is/hail/pull/2377#issuecomment-340889701:1544,Performance,cache,cache,1544,"ta/SupplementaryDatabase. #Data is copied for use with Nirvana 1.6.2 as of June 19 2017; gsutil -m cp -r gs://hail-common/nirvana/Data/Cache/24/GRCh37 /nirvana/Data/Cache; gsutil -m cp gs://hail-common/nirvana/Data/References/5/Homo_sapiens.GRCh37.Nirvana.dat /nirvana/Data/References; gsutil -m cp -r gs://hail-common/nirvana/Data/SupplementaryDatabase/39/GRCh37 /nirvana/Data/SupplementaryDatabase; gsutil -m cp -r gs://hail-common/nirvana/netcoreapp1.1 /nirvana; gsutil -m cp gs://hail-common/nirvana/nirvana-cloud-GRCh37.properties /nirvana. chmod -R 777 /nirvana. apt-get -y install curl libunwind8 gettext; curl -sSL -o dotnet.tar.gz https://go.microsoft.com/fwlink/?linkid=843453; mkdir -p /opt/dotnet && sudo tar zxf dotnet.tar.gz -C /opt/dotnet; ln -s /opt/dotnet/dotnet /usr/local/bin; ```. The properties file `nirvana-cloud-GRCh37.properties` points Nirvana to these local resources:; ```; hail.nirvana.location = /nirvana/netcoreapp1.1/Nirvana.dll; hail.nirvana.cache = /nirvana/Data/Cache/GRCh37/Ensembl84; hail.nirvana.reference = /nirvana/Data/References/Homo_sapiens.GRCh37.Nirvana.dat; hail.nirvana.supplementaryAnnotationDirectory = /nirvana/Data/SupplementaryDatabase/GRCh37; ```. I started a cluster with the init script and ran Nirvana on all of `profile225.vcf`, and later exported results for just a region bounding the gene CABIN1:; ```; from hail import *; hc = (HailContext()). (hc; .import_vcf(path='gs://jbloom/profile225.vcf.bgz'); .filter_multi(); .nirvana(block_size=10000, config='/nirvana/nirvana-cloud-GRCh37.properties'); .variants_table(); .filter(expr='v.start > 24430000 && v.start < 24580000'); .export(output='gs://jbloom/nirvana_cabin1.tsv')); ```. The top-level categories show reasonable-looking variation, except for ""clinvar"" and ""genes"" which are all `null` valued. Comparing a few variants in [gnomad](http://gnomad.broadinstitute.org/gene/ENSG00000099991), the annotations line up nicely. Here's an example of a common missense variant:; ```; 22:244683",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2377#issuecomment-340889701
https://github.com/hail-is/hail/pull/2377#issuecomment-340889701:1566,Performance,Cache,Cache,1566,"ta/SupplementaryDatabase. #Data is copied for use with Nirvana 1.6.2 as of June 19 2017; gsutil -m cp -r gs://hail-common/nirvana/Data/Cache/24/GRCh37 /nirvana/Data/Cache; gsutil -m cp gs://hail-common/nirvana/Data/References/5/Homo_sapiens.GRCh37.Nirvana.dat /nirvana/Data/References; gsutil -m cp -r gs://hail-common/nirvana/Data/SupplementaryDatabase/39/GRCh37 /nirvana/Data/SupplementaryDatabase; gsutil -m cp -r gs://hail-common/nirvana/netcoreapp1.1 /nirvana; gsutil -m cp gs://hail-common/nirvana/nirvana-cloud-GRCh37.properties /nirvana. chmod -R 777 /nirvana. apt-get -y install curl libunwind8 gettext; curl -sSL -o dotnet.tar.gz https://go.microsoft.com/fwlink/?linkid=843453; mkdir -p /opt/dotnet && sudo tar zxf dotnet.tar.gz -C /opt/dotnet; ln -s /opt/dotnet/dotnet /usr/local/bin; ```. The properties file `nirvana-cloud-GRCh37.properties` points Nirvana to these local resources:; ```; hail.nirvana.location = /nirvana/netcoreapp1.1/Nirvana.dll; hail.nirvana.cache = /nirvana/Data/Cache/GRCh37/Ensembl84; hail.nirvana.reference = /nirvana/Data/References/Homo_sapiens.GRCh37.Nirvana.dat; hail.nirvana.supplementaryAnnotationDirectory = /nirvana/Data/SupplementaryDatabase/GRCh37; ```. I started a cluster with the init script and ran Nirvana on all of `profile225.vcf`, and later exported results for just a region bounding the gene CABIN1:; ```; from hail import *; hc = (HailContext()). (hc; .import_vcf(path='gs://jbloom/profile225.vcf.bgz'); .filter_multi(); .nirvana(block_size=10000, config='/nirvana/nirvana-cloud-GRCh37.properties'); .variants_table(); .filter(expr='v.start > 24430000 && v.start < 24580000'); .export(output='gs://jbloom/nirvana_cabin1.tsv')); ```. The top-level categories show reasonable-looking variation, except for ""clinvar"" and ""genes"" which are all `null` valued. Comparing a few variants in [gnomad](http://gnomad.broadinstitute.org/gene/ENSG00000099991), the annotations line up nicely. Here's an example of a common missense variant:; ```; 22:244683",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2377#issuecomment-340889701
https://github.com/hail-is/hail/pull/2377#issuecomment-340889701:6447,Security,validat,validating,6447,"""hgnc"":""CABIN1"",""consequence"":[""missense_variant""],""hgvsc"":""ENST00000263119.5:c.2558G>A"",""hgvsp"":""ENSP00000263119.5:p.(Arg853Gln)"",""isCanonical"":null,""polyPhenScore"":0.625,""polyPhenPrediction"":""possibly damaging"",""proteinId"":""ENSP00000263119.5"",""proteinPos"":""853"",""siftScore"":0.01,""siftPrediction"":""deleterious""},{""transcript"":""ENST00000405822.2"",""bioType"":""protein_coding"",""aminoAcids"":""R/Q"",""cDnaPos"":""2502"",""codons"":""cGg/cAg"",""cdsPos"":""2408"",""exons"":""17/36"",""introns"":null,""geneId"":""ENSG00000099991"",""hgnc"":""CABIN1"",""consequence"":[""missense_variant""],""hgvsc"":""ENST00000405822.2:c.2408G>A"",""hgvsp"":""ENSP00000384694.2:p.(Arg803Gln)"",""isCanonical"":null,""polyPhenScore"":0.94,""polyPhenPrediction"":""probably damaging"",""proteinId"":""ENSP00000384694.2"",""proteinPos"":""803"",""siftScore"":0.02,""siftPrediction"":""deleterious""},{""transcript"":""ENST00000398319.2"",""bioType"":""protein_coding"",""aminoAcids"":""R/Q"",""cDnaPos"":""2943"",""codons"":""cGg/cAg"",""cdsPos"":""2558"",""exons"":""18/37"",""introns"":null,""geneId"":""ENSG00000099991"",""hgnc"":""CABIN1"",""consequence"":[""missense_variant""],""hgvsc"":""ENST00000398319.2:c.2558G>A"",""hgvsp"":""ENSP00000381364.2:p.(Arg853Gln)"",""isCanonical"":true,""polyPhenScore"":0.625,""polyPhenPrediction"":""possibly damaging"",""proteinId"":""ENSP00000381364.2"",""proteinPos"":""853"",""siftScore"":0.01,""siftPrediction"":""deleterious""},{""transcript"":""ENST00000484593.1"",""bioType"":""retained_intron"",""aminoAcids"":null,""cDnaPos"":null,""codons"":null,""cdsPos"":null,""exons"":null,""introns"":null,""geneId"":""ENSG00000099991"",""hgnc"":""CABIN1"",""consequence"":[""downstream_gene_variant""],""hgvsc"":null,""hgvsp"":null,""isCanonical"":null,""polyPhenScore"":null,""polyPhenPrediction"":null,""proteinId"":null,""proteinPos"":null,""siftScore"":null,""siftPrediction"":null}]},""genes"":null}]}}; ```. I've added the experimental warning until there is some form of automated testing in place (perhaps validating that consistency is maintained against a fixed output file that's been otherwise reviewed by Nirvana). Note that this method is modeled on VEP.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2377#issuecomment-340889701
https://github.com/hail-is/hail/pull/2377#issuecomment-340889701:6421,Testability,test,testing,6421,"""hgnc"":""CABIN1"",""consequence"":[""missense_variant""],""hgvsc"":""ENST00000263119.5:c.2558G>A"",""hgvsp"":""ENSP00000263119.5:p.(Arg853Gln)"",""isCanonical"":null,""polyPhenScore"":0.625,""polyPhenPrediction"":""possibly damaging"",""proteinId"":""ENSP00000263119.5"",""proteinPos"":""853"",""siftScore"":0.01,""siftPrediction"":""deleterious""},{""transcript"":""ENST00000405822.2"",""bioType"":""protein_coding"",""aminoAcids"":""R/Q"",""cDnaPos"":""2502"",""codons"":""cGg/cAg"",""cdsPos"":""2408"",""exons"":""17/36"",""introns"":null,""geneId"":""ENSG00000099991"",""hgnc"":""CABIN1"",""consequence"":[""missense_variant""],""hgvsc"":""ENST00000405822.2:c.2408G>A"",""hgvsp"":""ENSP00000384694.2:p.(Arg803Gln)"",""isCanonical"":null,""polyPhenScore"":0.94,""polyPhenPrediction"":""probably damaging"",""proteinId"":""ENSP00000384694.2"",""proteinPos"":""803"",""siftScore"":0.02,""siftPrediction"":""deleterious""},{""transcript"":""ENST00000398319.2"",""bioType"":""protein_coding"",""aminoAcids"":""R/Q"",""cDnaPos"":""2943"",""codons"":""cGg/cAg"",""cdsPos"":""2558"",""exons"":""18/37"",""introns"":null,""geneId"":""ENSG00000099991"",""hgnc"":""CABIN1"",""consequence"":[""missense_variant""],""hgvsc"":""ENST00000398319.2:c.2558G>A"",""hgvsp"":""ENSP00000381364.2:p.(Arg853Gln)"",""isCanonical"":true,""polyPhenScore"":0.625,""polyPhenPrediction"":""possibly damaging"",""proteinId"":""ENSP00000381364.2"",""proteinPos"":""853"",""siftScore"":0.01,""siftPrediction"":""deleterious""},{""transcript"":""ENST00000484593.1"",""bioType"":""retained_intron"",""aminoAcids"":null,""cDnaPos"":null,""codons"":null,""cdsPos"":null,""exons"":null,""introns"":null,""geneId"":""ENSG00000099991"",""hgnc"":""CABIN1"",""consequence"":[""downstream_gene_variant""],""hgvsc"":null,""hgvsp"":null,""isCanonical"":null,""polyPhenScore"":null,""polyPhenPrediction"":null,""proteinId"":null,""proteinPos"":null,""siftScore"":null,""siftPrediction"":null}]},""genes"":null}]}}; ```. I've added the experimental warning until there is some form of automated testing in place (perhaps validating that consistency is maintained against a fixed output file that's been otherwise reviewed by Nirvana). Note that this method is modeled on VEP.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2377#issuecomment-340889701
https://github.com/hail-is/hail/issues/2378#issuecomment-349722748:82,Integrability,interface,interfaces,82,"We're moving in the other direction, actually -- we're removing the nice mirrored interfaces in python/scala and replacing them with super fast `sun.misc.unsafe`-based infrastructure and native routines. It's not a good time investment to make a scala interface as nice as the Python interface right now.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2378#issuecomment-349722748
https://github.com/hail-is/hail/issues/2378#issuecomment-349722748:194,Integrability,rout,routines,194,"We're moving in the other direction, actually -- we're removing the nice mirrored interfaces in python/scala and replacing them with super fast `sun.misc.unsafe`-based infrastructure and native routines. It's not a good time investment to make a scala interface as nice as the Python interface right now.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2378#issuecomment-349722748
https://github.com/hail-is/hail/issues/2378#issuecomment-349722748:252,Integrability,interface,interface,252,"We're moving in the other direction, actually -- we're removing the nice mirrored interfaces in python/scala and replacing them with super fast `sun.misc.unsafe`-based infrastructure and native routines. It's not a good time investment to make a scala interface as nice as the Python interface right now.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2378#issuecomment-349722748
https://github.com/hail-is/hail/issues/2378#issuecomment-349722748:284,Integrability,interface,interface,284,"We're moving in the other direction, actually -- we're removing the nice mirrored interfaces in python/scala and replacing them with super fast `sun.misc.unsafe`-based infrastructure and native routines. It's not a good time investment to make a scala interface as nice as the Python interface right now.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2378#issuecomment-349722748
https://github.com/hail-is/hail/issues/2378#issuecomment-349722748:154,Safety,unsafe,unsafe,154,"We're moving in the other direction, actually -- we're removing the nice mirrored interfaces in python/scala and replacing them with super fast `sun.misc.unsafe`-based infrastructure and native routines. It's not a good time investment to make a scala interface as nice as the Python interface right now.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2378#issuecomment-349722748
https://github.com/hail-is/hail/pull/2384#issuecomment-342374655:56,Testability,test,tests,56,@danking I think I've finally fixed everything s.t. the tests are passing,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2384#issuecomment-342374655
https://github.com/hail-is/hail/pull/2385#issuecomment-341597070:139,Modifiability,variab,variables,139,"needs to be rebased. also I originally tried to leave things uninitialized but the ASM byte code verifier disapproved of referencing local variables it couldn't prove would have the correct type (i.e. because it was potentially uninitialized it was treated as having type `.`, I guess byte code doesn't actually have type annotations on registers?)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2385#issuecomment-341597070
https://github.com/hail-is/hail/pull/2386#issuecomment-342701706:94,Testability,test,tests,94,"Hope you don't mind, I fixed a bug (rename conflict) and merged in the last two stages. Final tests running now.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2386#issuecomment-342701706
https://github.com/hail-is/hail/pull/2414#issuecomment-343611350:311,Availability,error,error,311,"This should always produce a valid VCF with respect to: https://samtools.github.io/hts-specs/VCFv4.2.pdf. I've changed the behavior of export_vcf so that, like FORMAT field types, unsupported INFO field types must be explicitly converted to String by the user if the user really wants to export them. With good error messages, I think this will cause less confusion.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2414#issuecomment-343611350
https://github.com/hail-is/hail/pull/2414#issuecomment-343611350:317,Integrability,message,messages,317,"This should always produce a valid VCF with respect to: https://samtools.github.io/hts-specs/VCFv4.2.pdf. I've changed the behavior of export_vcf so that, like FORMAT field types, unsupported INFO field types must be explicitly converted to String by the user if the user really wants to export them. With good error messages, I think this will cause less confusion.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2414#issuecomment-343611350
https://github.com/hail-is/hail/pull/2416#issuecomment-343640495:391,Performance,Load,LoadVCF,391,"This is failing because AD and PL arrays are (properly, I would argue) being dropped by buildGenotypeExtractor because their elements aren't required. This won't work unless import_vcf sets requiredness on import. Here is a possible diff (which is probably subsumed by your next PR) which fixes some (but maybe not all) of the failing tests:. ```; diff --git a/src/main/scala/is/hail/io/vcf/LoadVCF.scala b/src/main/scala/is/hail/io/vcf/LoadVCF.scala; index 77f6c72..fadc936 100644; --- a/src/main/scala/is/hail/io/vcf/LoadVCF.scala; +++ b/src/main/scala/is/hail/io/vcf/LoadVCF.scala; @@ -109,7 +109,7 @@ object LoadVCF {; (line.getType == VCFHeaderLineType.Flag && line.getCount == 0))); Field(id, baseType, i, attrs); else; - Field(id, TArray(baseType), i, attrs); + Field(id, TArray(!baseType), i, attrs); }; ; def headerSignature[T <: VCFCompoundHeaderLine](lines: java.util.Collection[T],; @@ -124,10 +124,10 @@ object LoadVCF {; callFields: Set[String] = Set.empty[String]): (TStruct, Int) = {; val canonicalFields = Array(; ""GT"" -> TCall(),; - ""AD"" -> TArray(TInt32()),; + ""AD"" -> TArray(!TInt32()),; ""DP"" -> TInt32(),; ""GQ"" -> TInt32(),; - ""PL"" -> TArray(TInt32())); + ""PL"" -> TArray(!TInt32())); ; val raw = headerSignature(lines, callFields); ; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2416#issuecomment-343640495
https://github.com/hail-is/hail/pull/2416#issuecomment-343640495:437,Performance,Load,LoadVCF,437,"This is failing because AD and PL arrays are (properly, I would argue) being dropped by buildGenotypeExtractor because their elements aren't required. This won't work unless import_vcf sets requiredness on import. Here is a possible diff (which is probably subsumed by your next PR) which fixes some (but maybe not all) of the failing tests:. ```; diff --git a/src/main/scala/is/hail/io/vcf/LoadVCF.scala b/src/main/scala/is/hail/io/vcf/LoadVCF.scala; index 77f6c72..fadc936 100644; --- a/src/main/scala/is/hail/io/vcf/LoadVCF.scala; +++ b/src/main/scala/is/hail/io/vcf/LoadVCF.scala; @@ -109,7 +109,7 @@ object LoadVCF {; (line.getType == VCFHeaderLineType.Flag && line.getCount == 0))); Field(id, baseType, i, attrs); else; - Field(id, TArray(baseType), i, attrs); + Field(id, TArray(!baseType), i, attrs); }; ; def headerSignature[T <: VCFCompoundHeaderLine](lines: java.util.Collection[T],; @@ -124,10 +124,10 @@ object LoadVCF {; callFields: Set[String] = Set.empty[String]): (TStruct, Int) = {; val canonicalFields = Array(; ""GT"" -> TCall(),; - ""AD"" -> TArray(TInt32()),; + ""AD"" -> TArray(!TInt32()),; ""DP"" -> TInt32(),; ""GQ"" -> TInt32(),; - ""PL"" -> TArray(TInt32())); + ""PL"" -> TArray(!TInt32())); ; val raw = headerSignature(lines, callFields); ; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2416#issuecomment-343640495
https://github.com/hail-is/hail/pull/2416#issuecomment-343640495:519,Performance,Load,LoadVCF,519,"This is failing because AD and PL arrays are (properly, I would argue) being dropped by buildGenotypeExtractor because their elements aren't required. This won't work unless import_vcf sets requiredness on import. Here is a possible diff (which is probably subsumed by your next PR) which fixes some (but maybe not all) of the failing tests:. ```; diff --git a/src/main/scala/is/hail/io/vcf/LoadVCF.scala b/src/main/scala/is/hail/io/vcf/LoadVCF.scala; index 77f6c72..fadc936 100644; --- a/src/main/scala/is/hail/io/vcf/LoadVCF.scala; +++ b/src/main/scala/is/hail/io/vcf/LoadVCF.scala; @@ -109,7 +109,7 @@ object LoadVCF {; (line.getType == VCFHeaderLineType.Flag && line.getCount == 0))); Field(id, baseType, i, attrs); else; - Field(id, TArray(baseType), i, attrs); + Field(id, TArray(!baseType), i, attrs); }; ; def headerSignature[T <: VCFCompoundHeaderLine](lines: java.util.Collection[T],; @@ -124,10 +124,10 @@ object LoadVCF {; callFields: Set[String] = Set.empty[String]): (TStruct, Int) = {; val canonicalFields = Array(; ""GT"" -> TCall(),; - ""AD"" -> TArray(TInt32()),; + ""AD"" -> TArray(!TInt32()),; ""DP"" -> TInt32(),; ""GQ"" -> TInt32(),; - ""PL"" -> TArray(TInt32())); + ""PL"" -> TArray(!TInt32())); ; val raw = headerSignature(lines, callFields); ; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2416#issuecomment-343640495
https://github.com/hail-is/hail/pull/2416#issuecomment-343640495:570,Performance,Load,LoadVCF,570,"This is failing because AD and PL arrays are (properly, I would argue) being dropped by buildGenotypeExtractor because their elements aren't required. This won't work unless import_vcf sets requiredness on import. Here is a possible diff (which is probably subsumed by your next PR) which fixes some (but maybe not all) of the failing tests:. ```; diff --git a/src/main/scala/is/hail/io/vcf/LoadVCF.scala b/src/main/scala/is/hail/io/vcf/LoadVCF.scala; index 77f6c72..fadc936 100644; --- a/src/main/scala/is/hail/io/vcf/LoadVCF.scala; +++ b/src/main/scala/is/hail/io/vcf/LoadVCF.scala; @@ -109,7 +109,7 @@ object LoadVCF {; (line.getType == VCFHeaderLineType.Flag && line.getCount == 0))); Field(id, baseType, i, attrs); else; - Field(id, TArray(baseType), i, attrs); + Field(id, TArray(!baseType), i, attrs); }; ; def headerSignature[T <: VCFCompoundHeaderLine](lines: java.util.Collection[T],; @@ -124,10 +124,10 @@ object LoadVCF {; callFields: Set[String] = Set.empty[String]): (TStruct, Int) = {; val canonicalFields = Array(; ""GT"" -> TCall(),; - ""AD"" -> TArray(TInt32()),; + ""AD"" -> TArray(!TInt32()),; ""DP"" -> TInt32(),; ""GQ"" -> TInt32(),; - ""PL"" -> TArray(TInt32())); + ""PL"" -> TArray(!TInt32())); ; val raw = headerSignature(lines, callFields); ; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2416#issuecomment-343640495
https://github.com/hail-is/hail/pull/2416#issuecomment-343640495:612,Performance,Load,LoadVCF,612,"This is failing because AD and PL arrays are (properly, I would argue) being dropped by buildGenotypeExtractor because their elements aren't required. This won't work unless import_vcf sets requiredness on import. Here is a possible diff (which is probably subsumed by your next PR) which fixes some (but maybe not all) of the failing tests:. ```; diff --git a/src/main/scala/is/hail/io/vcf/LoadVCF.scala b/src/main/scala/is/hail/io/vcf/LoadVCF.scala; index 77f6c72..fadc936 100644; --- a/src/main/scala/is/hail/io/vcf/LoadVCF.scala; +++ b/src/main/scala/is/hail/io/vcf/LoadVCF.scala; @@ -109,7 +109,7 @@ object LoadVCF {; (line.getType == VCFHeaderLineType.Flag && line.getCount == 0))); Field(id, baseType, i, attrs); else; - Field(id, TArray(baseType), i, attrs); + Field(id, TArray(!baseType), i, attrs); }; ; def headerSignature[T <: VCFCompoundHeaderLine](lines: java.util.Collection[T],; @@ -124,10 +124,10 @@ object LoadVCF {; callFields: Set[String] = Set.empty[String]): (TStruct, Int) = {; val canonicalFields = Array(; ""GT"" -> TCall(),; - ""AD"" -> TArray(TInt32()),; + ""AD"" -> TArray(!TInt32()),; ""DP"" -> TInt32(),; ""GQ"" -> TInt32(),; - ""PL"" -> TArray(TInt32())); + ""PL"" -> TArray(!TInt32())); ; val raw = headerSignature(lines, callFields); ; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2416#issuecomment-343640495
https://github.com/hail-is/hail/pull/2416#issuecomment-343640495:924,Performance,Load,LoadVCF,924,"This is failing because AD and PL arrays are (properly, I would argue) being dropped by buildGenotypeExtractor because their elements aren't required. This won't work unless import_vcf sets requiredness on import. Here is a possible diff (which is probably subsumed by your next PR) which fixes some (but maybe not all) of the failing tests:. ```; diff --git a/src/main/scala/is/hail/io/vcf/LoadVCF.scala b/src/main/scala/is/hail/io/vcf/LoadVCF.scala; index 77f6c72..fadc936 100644; --- a/src/main/scala/is/hail/io/vcf/LoadVCF.scala; +++ b/src/main/scala/is/hail/io/vcf/LoadVCF.scala; @@ -109,7 +109,7 @@ object LoadVCF {; (line.getType == VCFHeaderLineType.Flag && line.getCount == 0))); Field(id, baseType, i, attrs); else; - Field(id, TArray(baseType), i, attrs); + Field(id, TArray(!baseType), i, attrs); }; ; def headerSignature[T <: VCFCompoundHeaderLine](lines: java.util.Collection[T],; @@ -124,10 +124,10 @@ object LoadVCF {; callFields: Set[String] = Set.empty[String]): (TStruct, Int) = {; val canonicalFields = Array(; ""GT"" -> TCall(),; - ""AD"" -> TArray(TInt32()),; + ""AD"" -> TArray(!TInt32()),; ""DP"" -> TInt32(),; ""GQ"" -> TInt32(),; - ""PL"" -> TArray(TInt32())); + ""PL"" -> TArray(!TInt32())); ; val raw = headerSignature(lines, callFields); ; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2416#issuecomment-343640495
https://github.com/hail-is/hail/pull/2416#issuecomment-343640495:335,Testability,test,tests,335,"This is failing because AD and PL arrays are (properly, I would argue) being dropped by buildGenotypeExtractor because their elements aren't required. This won't work unless import_vcf sets requiredness on import. Here is a possible diff (which is probably subsumed by your next PR) which fixes some (but maybe not all) of the failing tests:. ```; diff --git a/src/main/scala/is/hail/io/vcf/LoadVCF.scala b/src/main/scala/is/hail/io/vcf/LoadVCF.scala; index 77f6c72..fadc936 100644; --- a/src/main/scala/is/hail/io/vcf/LoadVCF.scala; +++ b/src/main/scala/is/hail/io/vcf/LoadVCF.scala; @@ -109,7 +109,7 @@ object LoadVCF {; (line.getType == VCFHeaderLineType.Flag && line.getCount == 0))); Field(id, baseType, i, attrs); else; - Field(id, TArray(baseType), i, attrs); + Field(id, TArray(!baseType), i, attrs); }; ; def headerSignature[T <: VCFCompoundHeaderLine](lines: java.util.Collection[T],; @@ -124,10 +124,10 @@ object LoadVCF {; callFields: Set[String] = Set.empty[String]): (TStruct, Int) = {; val canonicalFields = Array(; ""GT"" -> TCall(),; - ""AD"" -> TArray(TInt32()),; + ""AD"" -> TArray(!TInt32()),; ""DP"" -> TInt32(),; ""GQ"" -> TInt32(),; - ""PL"" -> TArray(TInt32())); + ""PL"" -> TArray(!TInt32())); ; val raw = headerSignature(lines, callFields); ; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2416#issuecomment-343640495
https://github.com/hail-is/hail/pull/2417#issuecomment-343800938:181,Deployability,patch,patch,181,"Spark doesn't have per-type requiredness but a nullable flag on array elements and struct fields. You just needed to set our required status based on their struct fields. Here is a patch that fixes it:. ```; diff --git a/src/main/scala/is/hail/expr/AnnotationImpex.scala b/src/main/scala/is/hail/expr/AnnotationImpex.scala; index 5039471..4cedfd8 100644; --- a/src/main/scala/is/hail/expr/AnnotationImpex.scala; +++ b/src/main/scala/is/hail/expr/AnnotationImpex.scala; @@ -45,11 +45,11 @@ object SparkAnnotationImpex extends AnnotationImpex[DataType, Any] {; case DoubleType => TFloat64(); case StringType => TString(); case BinaryType => TBinary(); - case ArrayType(elementType, _) => TArray(importType(elementType)); + case ArrayType(elementType, containsNull) => TArray(importType(elementType).setRequired(!containsNull)); case StructType(fields) =>; TStruct(fields.zipWithIndex; .map { case (f, i) =>; - (f.name, importType(f.dataType)); + (f.name, importType(f.dataType).setRequired(!f.nullable)); }: _*); }; ; diff --git a/src/test/scala/is/hail/methods/KeyTableSuite.scala b/src/test/scala/is/hail/methods/KeyTableSuite.scala; index 8a46826..dbb3485 100644; --- a/src/test/scala/is/hail/methods/KeyTableSuite.scala; +++ b/src/test/scala/is/hail/methods/KeyTableSuite.scala; @@ -380,9 +380,9 @@ class KeyTableSuite extends SparkSuite {; .flatten(); ; val df = kt.toDF(sqlContext); -// df.printSchema(); -// df.show(); - val kt2 = KeyTable.fromDF(hc, df); + df.printSchema(); + df.show(); + val kt2 = KeyTable.fromDF(hc, df, key = Array(""v"")); assert(kt2.same(kt)); }; ; ```. We should require the KeyTable row type to be required. We've always worked internally with the invariant that rows themselves can't be missing. (If they were, they wouldn't be in the table.) I commented in the print statements to see what was going on. You should probably delete them. I also had to set the key in `fromDF` the key isn't represented in DataFrames.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2417#issuecomment-343800938
https://github.com/hail-is/hail/pull/2417#issuecomment-343800938:517,Modifiability,extend,extends,517,"Spark doesn't have per-type requiredness but a nullable flag on array elements and struct fields. You just needed to set our required status based on their struct fields. Here is a patch that fixes it:. ```; diff --git a/src/main/scala/is/hail/expr/AnnotationImpex.scala b/src/main/scala/is/hail/expr/AnnotationImpex.scala; index 5039471..4cedfd8 100644; --- a/src/main/scala/is/hail/expr/AnnotationImpex.scala; +++ b/src/main/scala/is/hail/expr/AnnotationImpex.scala; @@ -45,11 +45,11 @@ object SparkAnnotationImpex extends AnnotationImpex[DataType, Any] {; case DoubleType => TFloat64(); case StringType => TString(); case BinaryType => TBinary(); - case ArrayType(elementType, _) => TArray(importType(elementType)); + case ArrayType(elementType, containsNull) => TArray(importType(elementType).setRequired(!containsNull)); case StructType(fields) =>; TStruct(fields.zipWithIndex; .map { case (f, i) =>; - (f.name, importType(f.dataType)); + (f.name, importType(f.dataType).setRequired(!f.nullable)); }: _*); }; ; diff --git a/src/test/scala/is/hail/methods/KeyTableSuite.scala b/src/test/scala/is/hail/methods/KeyTableSuite.scala; index 8a46826..dbb3485 100644; --- a/src/test/scala/is/hail/methods/KeyTableSuite.scala; +++ b/src/test/scala/is/hail/methods/KeyTableSuite.scala; @@ -380,9 +380,9 @@ class KeyTableSuite extends SparkSuite {; .flatten(); ; val df = kt.toDF(sqlContext); -// df.printSchema(); -// df.show(); - val kt2 = KeyTable.fromDF(hc, df); + df.printSchema(); + df.show(); + val kt2 = KeyTable.fromDF(hc, df, key = Array(""v"")); assert(kt2.same(kt)); }; ; ```. We should require the KeyTable row type to be required. We've always worked internally with the invariant that rows themselves can't be missing. (If they were, they wouldn't be in the table.) I commented in the print statements to see what was going on. You should probably delete them. I also had to set the key in `fromDF` the key isn't represented in DataFrames.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2417#issuecomment-343800938
https://github.com/hail-is/hail/pull/2417#issuecomment-343800938:1321,Modifiability,extend,extends,1321,"Spark doesn't have per-type requiredness but a nullable flag on array elements and struct fields. You just needed to set our required status based on their struct fields. Here is a patch that fixes it:. ```; diff --git a/src/main/scala/is/hail/expr/AnnotationImpex.scala b/src/main/scala/is/hail/expr/AnnotationImpex.scala; index 5039471..4cedfd8 100644; --- a/src/main/scala/is/hail/expr/AnnotationImpex.scala; +++ b/src/main/scala/is/hail/expr/AnnotationImpex.scala; @@ -45,11 +45,11 @@ object SparkAnnotationImpex extends AnnotationImpex[DataType, Any] {; case DoubleType => TFloat64(); case StringType => TString(); case BinaryType => TBinary(); - case ArrayType(elementType, _) => TArray(importType(elementType)); + case ArrayType(elementType, containsNull) => TArray(importType(elementType).setRequired(!containsNull)); case StructType(fields) =>; TStruct(fields.zipWithIndex; .map { case (f, i) =>; - (f.name, importType(f.dataType)); + (f.name, importType(f.dataType).setRequired(!f.nullable)); }: _*); }; ; diff --git a/src/test/scala/is/hail/methods/KeyTableSuite.scala b/src/test/scala/is/hail/methods/KeyTableSuite.scala; index 8a46826..dbb3485 100644; --- a/src/test/scala/is/hail/methods/KeyTableSuite.scala; +++ b/src/test/scala/is/hail/methods/KeyTableSuite.scala; @@ -380,9 +380,9 @@ class KeyTableSuite extends SparkSuite {; .flatten(); ; val df = kt.toDF(sqlContext); -// df.printSchema(); -// df.show(); - val kt2 = KeyTable.fromDF(hc, df); + df.printSchema(); + df.show(); + val kt2 = KeyTable.fromDF(hc, df, key = Array(""v"")); assert(kt2.same(kt)); }; ; ```. We should require the KeyTable row type to be required. We've always worked internally with the invariant that rows themselves can't be missing. (If they were, they wouldn't be in the table.) I commented in the print statements to see what was going on. You should probably delete them. I also had to set the key in `fromDF` the key isn't represented in DataFrames.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2417#issuecomment-343800938
https://github.com/hail-is/hail/pull/2417#issuecomment-343800938:1033,Testability,test,test,1033,"Spark doesn't have per-type requiredness but a nullable flag on array elements and struct fields. You just needed to set our required status based on their struct fields. Here is a patch that fixes it:. ```; diff --git a/src/main/scala/is/hail/expr/AnnotationImpex.scala b/src/main/scala/is/hail/expr/AnnotationImpex.scala; index 5039471..4cedfd8 100644; --- a/src/main/scala/is/hail/expr/AnnotationImpex.scala; +++ b/src/main/scala/is/hail/expr/AnnotationImpex.scala; @@ -45,11 +45,11 @@ object SparkAnnotationImpex extends AnnotationImpex[DataType, Any] {; case DoubleType => TFloat64(); case StringType => TString(); case BinaryType => TBinary(); - case ArrayType(elementType, _) => TArray(importType(elementType)); + case ArrayType(elementType, containsNull) => TArray(importType(elementType).setRequired(!containsNull)); case StructType(fields) =>; TStruct(fields.zipWithIndex; .map { case (f, i) =>; - (f.name, importType(f.dataType)); + (f.name, importType(f.dataType).setRequired(!f.nullable)); }: _*); }; ; diff --git a/src/test/scala/is/hail/methods/KeyTableSuite.scala b/src/test/scala/is/hail/methods/KeyTableSuite.scala; index 8a46826..dbb3485 100644; --- a/src/test/scala/is/hail/methods/KeyTableSuite.scala; +++ b/src/test/scala/is/hail/methods/KeyTableSuite.scala; @@ -380,9 +380,9 @@ class KeyTableSuite extends SparkSuite {; .flatten(); ; val df = kt.toDF(sqlContext); -// df.printSchema(); -// df.show(); - val kt2 = KeyTable.fromDF(hc, df); + df.printSchema(); + df.show(); + val kt2 = KeyTable.fromDF(hc, df, key = Array(""v"")); assert(kt2.same(kt)); }; ; ```. We should require the KeyTable row type to be required. We've always worked internally with the invariant that rows themselves can't be missing. (If they were, they wouldn't be in the table.) I commented in the print statements to see what was going on. You should probably delete them. I also had to set the key in `fromDF` the key isn't represented in DataFrames.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2417#issuecomment-343800938
https://github.com/hail-is/hail/pull/2417#issuecomment-343800938:1086,Testability,test,test,1086,"Spark doesn't have per-type requiredness but a nullable flag on array elements and struct fields. You just needed to set our required status based on their struct fields. Here is a patch that fixes it:. ```; diff --git a/src/main/scala/is/hail/expr/AnnotationImpex.scala b/src/main/scala/is/hail/expr/AnnotationImpex.scala; index 5039471..4cedfd8 100644; --- a/src/main/scala/is/hail/expr/AnnotationImpex.scala; +++ b/src/main/scala/is/hail/expr/AnnotationImpex.scala; @@ -45,11 +45,11 @@ object SparkAnnotationImpex extends AnnotationImpex[DataType, Any] {; case DoubleType => TFloat64(); case StringType => TString(); case BinaryType => TBinary(); - case ArrayType(elementType, _) => TArray(importType(elementType)); + case ArrayType(elementType, containsNull) => TArray(importType(elementType).setRequired(!containsNull)); case StructType(fields) =>; TStruct(fields.zipWithIndex; .map { case (f, i) =>; - (f.name, importType(f.dataType)); + (f.name, importType(f.dataType).setRequired(!f.nullable)); }: _*); }; ; diff --git a/src/test/scala/is/hail/methods/KeyTableSuite.scala b/src/test/scala/is/hail/methods/KeyTableSuite.scala; index 8a46826..dbb3485 100644; --- a/src/test/scala/is/hail/methods/KeyTableSuite.scala; +++ b/src/test/scala/is/hail/methods/KeyTableSuite.scala; @@ -380,9 +380,9 @@ class KeyTableSuite extends SparkSuite {; .flatten(); ; val df = kt.toDF(sqlContext); -// df.printSchema(); -// df.show(); - val kt2 = KeyTable.fromDF(hc, df); + df.printSchema(); + df.show(); + val kt2 = KeyTable.fromDF(hc, df, key = Array(""v"")); assert(kt2.same(kt)); }; ; ```. We should require the KeyTable row type to be required. We've always worked internally with the invariant that rows themselves can't be missing. (If they were, they wouldn't be in the table.) I commented in the print statements to see what was going on. You should probably delete them. I also had to set the key in `fromDF` the key isn't represented in DataFrames.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2417#issuecomment-343800938
https://github.com/hail-is/hail/pull/2417#issuecomment-343800938:1175,Testability,test,test,1175,"Spark doesn't have per-type requiredness but a nullable flag on array elements and struct fields. You just needed to set our required status based on their struct fields. Here is a patch that fixes it:. ```; diff --git a/src/main/scala/is/hail/expr/AnnotationImpex.scala b/src/main/scala/is/hail/expr/AnnotationImpex.scala; index 5039471..4cedfd8 100644; --- a/src/main/scala/is/hail/expr/AnnotationImpex.scala; +++ b/src/main/scala/is/hail/expr/AnnotationImpex.scala; @@ -45,11 +45,11 @@ object SparkAnnotationImpex extends AnnotationImpex[DataType, Any] {; case DoubleType => TFloat64(); case StringType => TString(); case BinaryType => TBinary(); - case ArrayType(elementType, _) => TArray(importType(elementType)); + case ArrayType(elementType, containsNull) => TArray(importType(elementType).setRequired(!containsNull)); case StructType(fields) =>; TStruct(fields.zipWithIndex; .map { case (f, i) =>; - (f.name, importType(f.dataType)); + (f.name, importType(f.dataType).setRequired(!f.nullable)); }: _*); }; ; diff --git a/src/test/scala/is/hail/methods/KeyTableSuite.scala b/src/test/scala/is/hail/methods/KeyTableSuite.scala; index 8a46826..dbb3485 100644; --- a/src/test/scala/is/hail/methods/KeyTableSuite.scala; +++ b/src/test/scala/is/hail/methods/KeyTableSuite.scala; @@ -380,9 +380,9 @@ class KeyTableSuite extends SparkSuite {; .flatten(); ; val df = kt.toDF(sqlContext); -// df.printSchema(); -// df.show(); - val kt2 = KeyTable.fromDF(hc, df); + df.printSchema(); + df.show(); + val kt2 = KeyTable.fromDF(hc, df, key = Array(""v"")); assert(kt2.same(kt)); }; ; ```. We should require the KeyTable row type to be required. We've always worked internally with the invariant that rows themselves can't be missing. (If they were, they wouldn't be in the table.) I commented in the print statements to see what was going on. You should probably delete them. I also had to set the key in `fromDF` the key isn't represented in DataFrames.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2417#issuecomment-343800938
https://github.com/hail-is/hail/pull/2417#issuecomment-343800938:1233,Testability,test,test,1233,"Spark doesn't have per-type requiredness but a nullable flag on array elements and struct fields. You just needed to set our required status based on their struct fields. Here is a patch that fixes it:. ```; diff --git a/src/main/scala/is/hail/expr/AnnotationImpex.scala b/src/main/scala/is/hail/expr/AnnotationImpex.scala; index 5039471..4cedfd8 100644; --- a/src/main/scala/is/hail/expr/AnnotationImpex.scala; +++ b/src/main/scala/is/hail/expr/AnnotationImpex.scala; @@ -45,11 +45,11 @@ object SparkAnnotationImpex extends AnnotationImpex[DataType, Any] {; case DoubleType => TFloat64(); case StringType => TString(); case BinaryType => TBinary(); - case ArrayType(elementType, _) => TArray(importType(elementType)); + case ArrayType(elementType, containsNull) => TArray(importType(elementType).setRequired(!containsNull)); case StructType(fields) =>; TStruct(fields.zipWithIndex; .map { case (f, i) =>; - (f.name, importType(f.dataType)); + (f.name, importType(f.dataType).setRequired(!f.nullable)); }: _*); }; ; diff --git a/src/test/scala/is/hail/methods/KeyTableSuite.scala b/src/test/scala/is/hail/methods/KeyTableSuite.scala; index 8a46826..dbb3485 100644; --- a/src/test/scala/is/hail/methods/KeyTableSuite.scala; +++ b/src/test/scala/is/hail/methods/KeyTableSuite.scala; @@ -380,9 +380,9 @@ class KeyTableSuite extends SparkSuite {; .flatten(); ; val df = kt.toDF(sqlContext); -// df.printSchema(); -// df.show(); - val kt2 = KeyTable.fromDF(hc, df); + df.printSchema(); + df.show(); + val kt2 = KeyTable.fromDF(hc, df, key = Array(""v"")); assert(kt2.same(kt)); }; ; ```. We should require the KeyTable row type to be required. We've always worked internally with the invariant that rows themselves can't be missing. (If they were, they wouldn't be in the table.) I commented in the print statements to see what was going on. You should probably delete them. I also had to set the key in `fromDF` the key isn't represented in DataFrames.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2417#issuecomment-343800938
https://github.com/hail-is/hail/pull/2417#issuecomment-343800938:1549,Testability,assert,assert,1549,"Spark doesn't have per-type requiredness but a nullable flag on array elements and struct fields. You just needed to set our required status based on their struct fields. Here is a patch that fixes it:. ```; diff --git a/src/main/scala/is/hail/expr/AnnotationImpex.scala b/src/main/scala/is/hail/expr/AnnotationImpex.scala; index 5039471..4cedfd8 100644; --- a/src/main/scala/is/hail/expr/AnnotationImpex.scala; +++ b/src/main/scala/is/hail/expr/AnnotationImpex.scala; @@ -45,11 +45,11 @@ object SparkAnnotationImpex extends AnnotationImpex[DataType, Any] {; case DoubleType => TFloat64(); case StringType => TString(); case BinaryType => TBinary(); - case ArrayType(elementType, _) => TArray(importType(elementType)); + case ArrayType(elementType, containsNull) => TArray(importType(elementType).setRequired(!containsNull)); case StructType(fields) =>; TStruct(fields.zipWithIndex; .map { case (f, i) =>; - (f.name, importType(f.dataType)); + (f.name, importType(f.dataType).setRequired(!f.nullable)); }: _*); }; ; diff --git a/src/test/scala/is/hail/methods/KeyTableSuite.scala b/src/test/scala/is/hail/methods/KeyTableSuite.scala; index 8a46826..dbb3485 100644; --- a/src/test/scala/is/hail/methods/KeyTableSuite.scala; +++ b/src/test/scala/is/hail/methods/KeyTableSuite.scala; @@ -380,9 +380,9 @@ class KeyTableSuite extends SparkSuite {; .flatten(); ; val df = kt.toDF(sqlContext); -// df.printSchema(); -// df.show(); - val kt2 = KeyTable.fromDF(hc, df); + df.printSchema(); + df.show(); + val kt2 = KeyTable.fromDF(hc, df, key = Array(""v"")); assert(kt2.same(kt)); }; ; ```. We should require the KeyTable row type to be required. We've always worked internally with the invariant that rows themselves can't be missing. (If they were, they wouldn't be in the table.) I commented in the print statements to see what was going on. You should probably delete them. I also had to set the key in `fromDF` the key isn't represented in DataFrames.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2417#issuecomment-343800938
https://github.com/hail-is/hail/pull/2421#issuecomment-343983297:18,Availability,error,error,18,"Example VCF parse error now looks like:. ```; Error summary: HailException: sample.vcf:column 1862: invalid character 'x' in integer literal; ... :80,0:80:13:0,13,2219 0/1:65,19:94:9x9:233,0,1732 0/0:34,3:45:74:0,74,12 ...; ^; offending line: 20	10273694	.	CT	C	29059.60	VQSRTrancheINDEL97.00to99.00	HWP...; see the Hail log for the full offending line; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2421#issuecomment-343983297
https://github.com/hail-is/hail/pull/2421#issuecomment-343983297:46,Availability,Error,Error,46,"Example VCF parse error now looks like:. ```; Error summary: HailException: sample.vcf:column 1862: invalid character 'x' in integer literal; ... :80,0:80:13:0,13,2219 0/1:65,19:94:9x9:233,0,1732 0/0:34,3:45:74:0,74,12 ...; ^; offending line: 20	10273694	.	CT	C	29059.60	VQSRTrancheINDEL97.00to99.00	HWP...; see the Hail log for the full offending line; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2421#issuecomment-343983297
https://github.com/hail-is/hail/pull/2421#issuecomment-343983297:321,Testability,log,log,321,"Example VCF parse error now looks like:. ```; Error summary: HailException: sample.vcf:column 1862: invalid character 'x' in integer literal; ... :80,0:80:13:0,13,2219 0/1:65,19:94:9x9:233,0,1732 0/0:34,3:45:74:0,74,12 ...; ^; offending line: 20	10273694	.	CT	C	29059.60	VQSRTrancheINDEL97.00to99.00	HWP...; see the Hail log for the full offending line; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2421#issuecomment-343983297
https://github.com/hail-is/hail/pull/2422#issuecomment-343779308:42,Availability,error,error,42,"You removed the ""wasSplit"" requirement so error is not thrown in BiallelicMethodSuite:. ```; interceptRequire {; multi.variantQC(); }; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2422#issuecomment-343779308
https://github.com/hail-is/hail/pull/2422#issuecomment-343950744:11,Testability,test,test,11,"Is there a test of VariantQC on multi-allelics? You say it's an out-of-date requirement but I'm confused how this works. We match gt to 0, 1, 2 in the VariantQCCombiner.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2422#issuecomment-343950744
https://github.com/hail-is/hail/pull/2422#issuecomment-343985863:8,Testability,test,test,8,put the test back in,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2422#issuecomment-343985863
https://github.com/hail-is/hail/pull/2422#issuecomment-344035511:24,Testability,test,test,24,"@jbloom22 OK, I put the test back in.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2422#issuecomment-344035511
https://github.com/hail-is/hail/pull/2423#issuecomment-347624179:302,Integrability,wrap,wrapper,302,"I used `RegionValueVariant` to clean up some of the code, and fixed a couple of bugs from #2451 in the process. I also replaced the `aggregatePartitions` method I wrote in e5f87c3 following @danking's comment, which was defined on `OrderedRDD2`, with `aggregateWithContext`, which is defined on a rich wrapper around `RDD`. I put it in the spark package to get access to private methods, making the implementation cleaner. It is now a simple modification of the implementation of `RDD.aggregate`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2423#issuecomment-347624179
https://github.com/hail-is/hail/pull/2423#issuecomment-347624179:361,Security,access,access,361,"I used `RegionValueVariant` to clean up some of the code, and fixed a couple of bugs from #2451 in the process. I also replaced the `aggregatePartitions` method I wrote in e5f87c3 following @danking's comment, which was defined on `OrderedRDD2`, with `aggregateWithContext`, which is defined on a rich wrapper around `RDD`. I put it in the spark package to get access to private methods, making the implementation cleaner. It is now a simple modification of the implementation of `RDD.aggregate`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2423#issuecomment-347624179
https://github.com/hail-is/hail/pull/2423#issuecomment-347624179:435,Usability,simpl,simple,435,"I used `RegionValueVariant` to clean up some of the code, and fixed a couple of bugs from #2451 in the process. I also replaced the `aggregatePartitions` method I wrote in e5f87c3 following @danking's comment, which was defined on `OrderedRDD2`, with `aggregateWithContext`, which is defined on a rich wrapper around `RDD`. I put it in the spark package to get access to private methods, making the implementation cleaner. It is now a simple modification of the implementation of `RDD.aggregate`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2423#issuecomment-347624179
https://github.com/hail-is/hail/pull/2424#issuecomment-344368487:15,Deployability,update,updateKey,15,@catoverdrive `updateKey` is the method you're looking for in the unsafe case.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2424#issuecomment-344368487
https://github.com/hail-is/hail/pull/2424#issuecomment-344368487:66,Safety,unsafe,unsafe,66,@catoverdrive `updateKey` is the method you're looking for in the unsafe case.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2424#issuecomment-344368487
https://github.com/hail-is/hail/pull/2428#issuecomment-344269060:136,Security,access,accessors,136,I think the only additions I would need to use this in #2423 for summarize are `getNAlleles: Int` and `getAltAlleles: Array[AltAllele]` accessors.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2428#issuecomment-344269060
https://github.com/hail-is/hail/pull/2428#issuecomment-344369282:274,Security,access,access,274,"Ideally, I should be able to work directly from an `AltAlleleView`. But then I would have to copy all of the `isInsertion`, `isDeletion`, etc., methods from `AltAllele`, which feels wrong. As it's only a per-variant allocation, I think allocating `AltAllele` objects to get access to those methods is the right compromise currently, though I'm certainly open to alternatives.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2428#issuecomment-344369282
https://github.com/hail-is/hail/pull/2431#issuecomment-344159074:41,Performance,load,loadmatrix,41,@catoverdrive I rebased and pulled your `loadmatrix` branch. I will review.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2431#issuecomment-344159074
https://github.com/hail-is/hail/pull/2434#issuecomment-344609522:251,Integrability,wrap,wrappers,251,"This looks like it would work. Do you think think that after the region value transition, the `Variant`, `AltAllele`, etc., classes will be replaced with their associated views? Or if there were still a need for the Scala objects, maybe they could be wrappers around a small region and a view, so that the view classes become the single location for associated methods.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2434#issuecomment-344609522
https://github.com/hail-is/hail/pull/2434#issuecomment-344634493:721,Usability,simpl,simplified,721,"> This looks like it would work. Do you think think that after the region value transition, the Variant, AltAllele, etc., classes will be replaced with their associated views?. I think the classes and the views are roughly the same thing. Make the AltAllele, Variant, etc. classes abstract, and have a concrete implementation (in terms of Scala types) and another mutable one in terms of a RegionValue. See my altAllele comment above. I'm not completely happy with the existing type hierarchy. In particular, the way things are stored now, the contig and start are duplicated in the row (pk vs k) and the ref is duplicated per allele. We did this so AltAllele was a sensible object, but I think this can be rethought and simplified, esp. as we move stuff into the expr language. I still think `Locus` is good (but it should be a `Long`, the global genomic position on the reference) and Variant should be split apart where the alleles are just an `Array[String]` which contains all the alleles including ref. Then the row type for a variant indexed data set should look like:. ```; Struct {; locus: Locus [= Long],; alleles: Array[String],; va: ...; gs: Array[...]; }; ```. Then the question becomes, how do we formulate things like `isSNP`? Does it become `isSNP(alleles, i)`? Is it enough to hang the genome reference off the Locus type and the alleles? Also, we don't carry types with Python values which might cause problems, e.g. rendering Locus. @tpoterba might have thoughts on this, too.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2434#issuecomment-344634493
https://github.com/hail-is/hail/pull/2440#issuecomment-345032622:19,Modifiability,rewrite,rewrite,19,"cool, I'll proably rewrite the tests using that. the option for 1 already exists in `LoadMatrix.apply`; I just haven't exposed it to HailContext because there's a lot of stuff there already and I couldn't figure out what the name of the flag should be (currently, it's hasRowKeyLabel but I don't feel like that's super descriptive) but I could do that.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2440#issuecomment-345032622
https://github.com/hail-is/hail/pull/2440#issuecomment-345032622:85,Performance,Load,LoadMatrix,85,"cool, I'll proably rewrite the tests using that. the option for 1 already exists in `LoadMatrix.apply`; I just haven't exposed it to HailContext because there's a lot of stuff there already and I couldn't figure out what the name of the flag should be (currently, it's hasRowKeyLabel but I don't feel like that's super descriptive) but I could do that.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2440#issuecomment-345032622
https://github.com/hail-is/hail/pull/2440#issuecomment-345032622:119,Security,expose,exposed,119,"cool, I'll proably rewrite the tests using that. the option for 1 already exists in `LoadMatrix.apply`; I just haven't exposed it to HailContext because there's a lot of stuff there already and I couldn't figure out what the name of the flag should be (currently, it's hasRowKeyLabel but I don't feel like that's super descriptive) but I could do that.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2440#issuecomment-345032622
https://github.com/hail-is/hail/pull/2440#issuecomment-345032622:31,Testability,test,tests,31,"cool, I'll proably rewrite the tests using that. the option for 1 already exists in `LoadMatrix.apply`; I just haven't exposed it to HailContext because there's a lot of stuff there already and I couldn't figure out what the name of the flag should be (currently, it's hasRowKeyLabel but I don't feel like that's super descriptive) but I could do that.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2440#issuecomment-345032622
https://github.com/hail-is/hail/pull/2451#issuecomment-345801639:160,Integrability,interface,interface,160,"@catoverdrive here's the replacement for #2441, I had to create a couple shim classes to get JSON parsing to work  because you can't `jsonValue.extract[T]` an interface T (see `JSONAnnotationImpex`).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2451#issuecomment-345801639
https://github.com/hail-is/hail/pull/2451#issuecomment-345880084:36,Usability,simpl,simplified,36,@catoverdrive @tpoterba rebased and simplified. have at it.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2451#issuecomment-345880084
https://github.com/hail-is/hail/pull/2454#issuecomment-348531819:57,Integrability,interface,interface,57,"Overall this is good, but I think we should simplify the interface. 1. Require `entry_to_double`. Don't support genotypes or do normalization. 2. Only have the one version that returns the triple. The user can reannotate the original dataset if that's what they want. 3. Write a `VariantDataset.genotype_matrix_pca` in Python that looks at the `.GT` field and does the necessary normalization before calling `pca`. This should be written completely in Python.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2454#issuecomment-348531819
https://github.com/hail-is/hail/pull/2454#issuecomment-348531819:44,Usability,simpl,simplify,44,"Overall this is good, but I think we should simplify the interface. 1. Require `entry_to_double`. Don't support genotypes or do normalization. 2. Only have the one version that returns the triple. The user can reannotate the original dataset if that's what they want. 3. Write a `VariantDataset.genotype_matrix_pca` in Python that looks at the `.GT` field and does the necessary normalization before calling `pca`. This should be written completely in Python.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2454#issuecomment-348531819
https://github.com/hail-is/hail/pull/2454#issuecomment-348532963:93,Safety,avoid,avoids,93,"How do you feel about:; 1. if entry_to_double = None, then assume entries are doubles (which avoids having to go through the expr parser); 2. `inserted here just because GitHub automatically numbers my 3. to a 2.`; 3. instead of VariantDataset.genotype_matrix_pca, have VariantDataset.normalized_hardcalls (or just a .normalize_by_variant, since vds.hardcalls already exists) that does the normalization, such that it would instead be vds.hardcalls.normalize.pca()?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2454#issuecomment-348532963
https://github.com/hail-is/hail/pull/2454#issuecomment-348534152:110,Integrability,interface,interface,110,"Although it's possible for entries to be a scalar type like double right now, that won't be possible in 0.2's interface -- they'll always be structs, which follows from lifting all fields out to be top-level. How about something like this:. ```python; vds = hwe_normalize(vds.GT) # adds field gt_norm or something; loadings, pcs, eigenvalues = pca(vds.gt_norm); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2454#issuecomment-348534152
https://github.com/hail-is/hail/pull/2454#issuecomment-348534152:315,Performance,load,loadings,315,"Although it's possible for entries to be a scalar type like double right now, that won't be possible in 0.2's interface -- they'll always be structs, which follows from lifting all fields out to be top-level. How about something like this:. ```python; vds = hwe_normalize(vds.GT) # adds field gt_norm or something; loadings, pcs, eigenvalues = pca(vds.gt_norm); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2454#issuecomment-348534152
https://github.com/hail-is/hail/pull/2454#issuecomment-348539919:148,Performance,load,loadings,148,"Regarding having only one version that returns the triple (V, S, U), returning the eigenvalues S is no extra work. For the record, computing U (the loadings) given V requires multiplying the input m x n RowMatrix A times an n x k Breeze matrix: U = A * (V * S^-1). k is small so this is RowMatrix multiply is done with a broadcast (rather than BlockMatrix with shuffle).; ```; if (computeU) {; // N = Vk * Sk^{-1}; val N = new BDM[Double](n, sk, Arrays.copyOfRange(u.data, 0, n * sk)); var i = 0; var j = 0; while (j < sk) {; i = 0; val sigma = sigmas(j); while (i < n) {; N(i, j) /= sigma; i += 1; }; j += 1; }; val U = this.multiply(Matrices.fromBreeze(N)); SingularValueDecomposition(U, s, V); } else {; SingularValueDecomposition(null, s, V); }; ```; This extra step ought to be fast relative to computing V since the later requires many rounds of such multiplications.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2454#issuecomment-348539919
https://github.com/hail-is/hail/pull/2454#issuecomment-348580540:101,Performance,load,loadings,101,"so I can remove the computeEigenvalues option and just always return them, but I'm less clear on the loadings. @tpoterba are you suggesting that I can remove the computeLoadings option because the computation is lazy? Does passing the KeyTable object through to python count as ""using"", though?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2454#issuecomment-348580540
https://github.com/hail-is/hail/pull/2454#issuecomment-348580540:88,Usability,clear,clear,88,"so I can remove the computeEigenvalues option and just always return them, but I'm less clear on the loadings. @tpoterba are you suggesting that I can remove the computeLoadings option because the computation is lazy? Does passing the KeyTable object through to python count as ""using"", though?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2454#issuecomment-348580540
https://github.com/hail-is/hail/pull/2454#issuecomment-348587603:58,Performance,load,loadings,58,"lazy, meaning it's an RDD. The computation to produce row loadings won't happen unless you perform an action on it, like count or something. Passing a reference through Python is fine.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2454#issuecomment-348587603
https://github.com/hail-is/hail/pull/2454#issuecomment-348587603:91,Performance,perform,perform,91,"lazy, meaning it's an RDD. The computation to produce row loadings won't happen unless you perform an action on it, like count or something. Passing a reference through Python is fine.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2454#issuecomment-348587603
https://github.com/hail-is/hail/pull/2455#issuecomment-346422442:143,Testability,assert,assert,143,"@danking @tpoterba OK, I think I fixed this. I. - stripped out all support for required types in promoteNumeric matching the rest of expr, and assert that there are none,; - deeply strip all required types from types in the symbol table in the EvalContext constructor,; - don't generate required types in an the sample, variant annotations or on any struct fields in the genotype annotations in VSM.gen. Happy?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2455#issuecomment-346422442
https://github.com/hail-is/hail/pull/2456#issuecomment-345867674:13,Testability,test,test,13,I will add a test for this as a separate PR bug I want to get it in to get Konrad unblocked.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2456#issuecomment-345867674
https://github.com/hail-is/hail/pull/2456#issuecomment-345872854:69,Deployability,integrat,integrating,69,Thanks! Fix worked (I just rolled a custom jar) so don't worry about integrating immediately on my account.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2456#issuecomment-345872854
https://github.com/hail-is/hail/pull/2456#issuecomment-345872854:69,Integrability,integrat,integrating,69,Thanks! Fix worked (I just rolled a custom jar) so don't worry about integrating immediately on my account.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2456#issuecomment-345872854
https://github.com/hail-is/hail/pull/2458#issuecomment-346038240:37,Performance,load,load,37,Re-assigned to Amanda to balance the load from Patrick.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2458#issuecomment-346038240
https://github.com/hail-is/hail/pull/2459#issuecomment-346149083:22,Testability,test,tests,22,Fixed. I'll debug the tests shortly.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2459#issuecomment-346149083
https://github.com/hail-is/hail/pull/2471#issuecomment-346980881:30,Testability,test,tests,30,There's also a call to it in `tests/tests.py`.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2471#issuecomment-346980881
https://github.com/hail-is/hail/pull/2471#issuecomment-346980881:36,Testability,test,tests,36,There's also a call to it in `tests/tests.py`.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2471#issuecomment-346980881
https://github.com/hail-is/hail/pull/2476#issuecomment-347668454:48,Testability,assert,asserts,48,"I think your comment was good, I'm going to add asserts but haven't gotten to it yet. Thanks!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2476#issuecomment-347668454
https://github.com/hail-is/hail/pull/2479#issuecomment-347063979:11,Integrability,depend,depends,11,This kinda depends on #2480,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2479#issuecomment-347063979
https://github.com/hail-is/hail/pull/2480#issuecomment-347072699:111,Modifiability,rewrite,rewrite,111,"I addressed some comments. I still need to:; - expose hts_genotype_schema in python, and; - figure out what to rewrite instead of ""genotype"" in the VariantDataset docs.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2480#issuecomment-347072699
https://github.com/hail-is/hail/pull/2480#issuecomment-347072699:47,Security,expose,expose,47,"I addressed some comments. I still need to:; - expose hts_genotype_schema in python, and; - figure out what to rewrite instead of ""genotype"" in the VariantDataset docs.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2480#issuecomment-347072699
https://github.com/hail-is/hail/pull/2480#issuecomment-348611190:7,Testability,test,tests,7,Python tests fixed.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2480#issuecomment-348611190
https://github.com/hail-is/hail/pull/2492#issuecomment-347998000:151,Integrability,interface,interface,151,"And I should note that I've only implemented summation aggregators right now. The non-lambda-taking-ones should follow easily if we're happy with this interface. The lambda-taking-ones shouldn't be too bad either, just a bit more work.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2492#issuecomment-347998000
https://github.com/hail-is/hail/pull/2494#issuecomment-348243800:135,Usability,feedback,feedback,135,"@jigold you won the PR lottery, definitely ask me if you find something unclear (which may suggest ways to improve it). We can ask for feedback from @cseed or @tpoterba on the Spark question above.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2494#issuecomment-348243800
https://github.com/hail-is/hail/pull/2494#issuecomment-348580922:25,Deployability,update,update,25,"addressed comments, will update with results on realistic data shortly",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2494#issuecomment-348580922
https://github.com/hail-is/hail/pull/2497#issuecomment-348280201:34,Integrability,interface,interfaces,34,"@catoverdrive and I discussed 0.2 interfaces and agreed that the single_key logic will be stripped from group_rows_by and group_cols_by, and we'll add explode_rows and explode_cols. This will happen in a future PR",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2497#issuecomment-348280201
https://github.com/hail-is/hail/pull/2497#issuecomment-348280201:76,Testability,log,logic,76,"@catoverdrive and I discussed 0.2 interfaces and agreed that the single_key logic will be stripped from group_rows_by and group_cols_by, and we'll add explode_rows and explode_cols. This will happen in a future PR",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2497#issuecomment-348280201
https://github.com/hail-is/hail/pull/2497#issuecomment-348369590:85,Modifiability,extend,extended,85,"Right. Overlapping genes is handled by the `single_key=False` case that I used in my extended 0.1 doc example for linreg burden, but you said you were thinking to remove that case and use explode so I didn't think it worth using that exact example. People will want to use explode, groupBy and linreg / logreg together to test genes for association, so that may be a nice example in groupVariantsBy. So I'm fine with holding off on more examples until this and explode are merged, and then we can revisit together.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2497#issuecomment-348369590
https://github.com/hail-is/hail/pull/2497#issuecomment-348369590:303,Testability,log,logreg,303,"Right. Overlapping genes is handled by the `single_key=False` case that I used in my extended 0.1 doc example for linreg burden, but you said you were thinking to remove that case and use explode so I didn't think it worth using that exact example. People will want to use explode, groupBy and linreg / logreg together to test genes for association, so that may be a nice example in groupVariantsBy. So I'm fine with holding off on more examples until this and explode are merged, and then we can revisit together.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2497#issuecomment-348369590
https://github.com/hail-is/hail/pull/2497#issuecomment-348369590:322,Testability,test,test,322,"Right. Overlapping genes is handled by the `single_key=False` case that I used in my extended 0.1 doc example for linreg burden, but you said you were thinking to remove that case and use explode so I didn't think it worth using that exact example. People will want to use explode, groupBy and linreg / logreg together to test genes for association, so that may be a nice example in groupVariantsBy. So I'm fine with holding off on more examples until this and explode are merged, and then we can revisit together.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2497#issuecomment-348369590
https://github.com/hail-is/hail/pull/2497#issuecomment-348701713:19,Availability,failure,failure,19,"regarding doc test failure, you need `g.DP`, not `g.dp`",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2497#issuecomment-348701713
https://github.com/hail-is/hail/pull/2497#issuecomment-348701713:14,Testability,test,test,14,"regarding doc test failure, you need `g.DP`, not `g.dp`",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2497#issuecomment-348701713
https://github.com/hail-is/hail/pull/2505#issuecomment-348619118:0,Availability,ping,ping,0,ping @jbloom22,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2505#issuecomment-348619118
https://github.com/hail-is/hail/pull/2511#issuecomment-348577509:162,Energy Efficiency,allocate,allocated,162,"cc: @cseed Not sure how you feel about this. We've talked about making tests easy to write a few times. This solution isn't prefect because nested structures get allocated twice. For example:. ```scala; addStruct(region, ""foo"", addStruct(region, ""bar"", 3)); ```. Allocates the struct with field ""bar"" first, then allocates the outer struct, copying in the value of the inner struct. I think there's a better way to do this using a builder pattern (basically an AST for RegionValues, which is basically the IR? dunno, there's more thought needed here), but it would take more work than I was willing to put in for my tests.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2511#issuecomment-348577509
https://github.com/hail-is/hail/pull/2511#issuecomment-348577509:263,Energy Efficiency,Allocate,Allocates,263,"cc: @cseed Not sure how you feel about this. We've talked about making tests easy to write a few times. This solution isn't prefect because nested structures get allocated twice. For example:. ```scala; addStruct(region, ""foo"", addStruct(region, ""bar"", 3)); ```. Allocates the struct with field ""bar"" first, then allocates the outer struct, copying in the value of the inner struct. I think there's a better way to do this using a builder pattern (basically an AST for RegionValues, which is basically the IR? dunno, there's more thought needed here), but it would take more work than I was willing to put in for my tests.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2511#issuecomment-348577509
https://github.com/hail-is/hail/pull/2511#issuecomment-348577509:313,Energy Efficiency,allocate,allocates,313,"cc: @cseed Not sure how you feel about this. We've talked about making tests easy to write a few times. This solution isn't prefect because nested structures get allocated twice. For example:. ```scala; addStruct(region, ""foo"", addStruct(region, ""bar"", 3)); ```. Allocates the struct with field ""bar"" first, then allocates the outer struct, copying in the value of the inner struct. I think there's a better way to do this using a builder pattern (basically an AST for RegionValues, which is basically the IR? dunno, there's more thought needed here), but it would take more work than I was willing to put in for my tests.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2511#issuecomment-348577509
https://github.com/hail-is/hail/pull/2511#issuecomment-348577509:71,Testability,test,tests,71,"cc: @cseed Not sure how you feel about this. We've talked about making tests easy to write a few times. This solution isn't prefect because nested structures get allocated twice. For example:. ```scala; addStruct(region, ""foo"", addStruct(region, ""bar"", 3)); ```. Allocates the struct with field ""bar"" first, then allocates the outer struct, copying in the value of the inner struct. I think there's a better way to do this using a builder pattern (basically an AST for RegionValues, which is basically the IR? dunno, there's more thought needed here), but it would take more work than I was willing to put in for my tests.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2511#issuecomment-348577509
https://github.com/hail-is/hail/pull/2511#issuecomment-348577509:616,Testability,test,tests,616,"cc: @cseed Not sure how you feel about this. We've talked about making tests easy to write a few times. This solution isn't prefect because nested structures get allocated twice. For example:. ```scala; addStruct(region, ""foo"", addStruct(region, ""bar"", 3)); ```. Allocates the struct with field ""bar"" first, then allocates the outer struct, copying in the value of the inner struct. I think there's a better way to do this using a builder pattern (basically an AST for RegionValues, which is basically the IR? dunno, there's more thought needed here), but it would take more work than I was willing to put in for my tests.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2511#issuecomment-348577509
https://github.com/hail-is/hail/pull/2514#issuecomment-348577859:32,Integrability,interface,interface,32,"cc: @cseed, this is my proposed interface and a couple of examples of aggregators for region values.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2514#issuecomment-348577859
https://github.com/hail-is/hail/pull/2514#issuecomment-349092532:24,Availability,robust,robust,24,Mmm. Yes. I need a more robust IR testing plan. I think testing these individually will be more painful than testing them in the context of IR expressions.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2514#issuecomment-349092532
https://github.com/hail-is/hail/pull/2514#issuecomment-349092532:34,Testability,test,testing,34,Mmm. Yes. I need a more robust IR testing plan. I think testing these individually will be more painful than testing them in the context of IR expressions.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2514#issuecomment-349092532
https://github.com/hail-is/hail/pull/2514#issuecomment-349092532:56,Testability,test,testing,56,Mmm. Yes. I need a more robust IR testing plan. I think testing these individually will be more painful than testing them in the context of IR expressions.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2514#issuecomment-349092532
https://github.com/hail-is/hail/pull/2514#issuecomment-349092532:109,Testability,test,testing,109,Mmm. Yes. I need a more robust IR testing plan. I think testing these individually will be more painful than testing them in the context of IR expressions.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2514#issuecomment-349092532
https://github.com/hail-is/hail/pull/2516#issuecomment-348644288:37,Safety,Unsafe,UnsafeOrdering,37,@patrick-schultz Maybe I should make UnsafeOrdering a separate PR...,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2516#issuecomment-348644288
https://github.com/hail-is/hail/pull/2516#issuecomment-348696868:6,Safety,Unsafe,UnsafeOrdering,6,"Yeah, UnsafeOrdering feels like a separate PR. I'll focus on the IR sets for now, so you can give that half to me. You can give the UnsafeOrdering half to me too, but it would still be helpful to me to keep them separate.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2516#issuecomment-348696868
https://github.com/hail-is/hail/pull/2516#issuecomment-348696868:132,Safety,Unsafe,UnsafeOrdering,132,"Yeah, UnsafeOrdering feels like a separate PR. I'll focus on the IR sets for now, so you can give that half to me. You can give the UnsafeOrdering half to me too, but it would still be helpful to me to keep them separate.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2516#issuecomment-348696868
https://github.com/hail-is/hail/pull/2516#issuecomment-349039141:13,Safety,Unsafe,UnsafeOrdering,13,I extracted `UnsafeOrdering` into #2519.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2516#issuecomment-349039141
https://github.com/hail-is/hail/pull/2516#issuecomment-350801948:65,Energy Efficiency,adapt,adapted,65,This needs to be recreated once #2519 (on which this depends) is adapted to handle GenomeReference.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2516#issuecomment-350801948
https://github.com/hail-is/hail/pull/2516#issuecomment-350801948:53,Integrability,depend,depends,53,This needs to be recreated once #2519 (on which this depends) is adapted to handle GenomeReference.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2516#issuecomment-350801948
https://github.com/hail-is/hail/pull/2516#issuecomment-350801948:65,Modifiability,adapt,adapted,65,This needs to be recreated once #2519 (on which this depends) is adapted to handle GenomeReference.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2516#issuecomment-350801948
https://github.com/hail-is/hail/pull/2526#issuecomment-349848923:693,Performance,load,load,693,"We're about 50% slower than numpy for large matmul, but closer to parity on IO:. ```; ('running:', 'write A'); ('write A', [0.4459199905395508, 0.4475231170654297, 0.4485299587249756]); ('running:', 'write B'); ('write B', [4.432413816452026, 4.644207954406738, 4.646740913391113]); ('running:', 'mul'); ('mul', [29.40219783782959, 28.894094944000244, 28.81586503982544]); ```. ```; import timeit; import numpy as np. def time(name, f, number=1, repeat=3):; print('running:', name); d = timeit.repeat(f, number=number, repeat=repeat); print(name, d). def writeA():; np.save('A.npy', np.random.rand(5000, 8000)). def writeB():; np.save('B.npy', np.random.rand(8000, 50000)). def mul():; A = np.load('A.npy'); B = np.load('B.npy'); np.save('product.npy', np.dot(A, B)). time('write A', writeA); time('write B', writeB); time('mul', mul); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2526#issuecomment-349848923
https://github.com/hail-is/hail/pull/2526#issuecomment-349848923:715,Performance,load,load,715,"We're about 50% slower than numpy for large matmul, but closer to parity on IO:. ```; ('running:', 'write A'); ('write A', [0.4459199905395508, 0.4475231170654297, 0.4485299587249756]); ('running:', 'write B'); ('write B', [4.432413816452026, 4.644207954406738, 4.646740913391113]); ('running:', 'mul'); ('mul', [29.40219783782959, 28.894094944000244, 28.81586503982544]); ```. ```; import timeit; import numpy as np. def time(name, f, number=1, repeat=3):; print('running:', name); d = timeit.repeat(f, number=number, repeat=repeat); print(name, d). def writeA():; np.save('A.npy', np.random.rand(5000, 8000)). def writeB():; np.save('B.npy', np.random.rand(8000, 50000)). def mul():; A = np.load('A.npy'); B = np.load('B.npy'); np.save('product.npy', np.dot(A, B)). time('write A', writeA); time('write B', writeB); time('mul', mul); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2526#issuecomment-349848923
https://github.com/hail-is/hail/issues/2527#issuecomment-355985783:205,Availability,failure,failure,205,"Update to this, tried running the same script with the bgen file as v1.2 instead (was v1.1 in initial posted issue), but it gives the same issue/stack trace:. ```; SparkException: Job aborted due to stage failure: Task 1.0 in stage 5.0 (TID 2681) had a not serializable result: is.hail.io.bgen.Bgen12GenotypeIterator; Serialization stack:; 	- object not serializable (class: is.hail.io.bgen.Bgen12GenotypeIterator, value: Bgen12GenotypeIterator(0/0:.:.:.:GP=0.99798583984375,0.00201416015625,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:; ```; ```; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apac",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2527#issuecomment-355985783
https://github.com/hail-is/hail/issues/2527#issuecomment-355985783:7161,Availability,error,error,7161," mesos/standalone and LOCAL_DIRS in YARN).; 18/01/08 13:51:03 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/home/ludvig/Programs/hail/jars/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 18/01/08 13:51:03 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/home/ludvig/Programs/hail/jars/hail-all-spark.jar' as a work-around.; 18/01/08 13:51:03 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/home/ludvig/Programs/hail/jars/hail-all-spark.jar' as a work-around.; 18/01/08 13:51:03 WARN Utils: Your hostname, <my computer name> resolves to a loopback address: <my local IP>; using <my IP> instead (on interface enp3s0); 18/01/08 13:51:03 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address; ```. And the other initialize hail like this (crashes with the stack trace/error in the issue):; ```; from pyspark import *; from hail import *; conf = SparkConf(); conf.set('spark.sql.files.maxPartitionBytes','60000000000') ; conf.set('spark.sql.files.openCostInBytes','60000000000') ; conf.set('spark.driver.cores','1') #test with 1 core; sc = SparkContext(conf=conf); hc = HailContext(sc); ```. With startup messages looking like this:; ```; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; 18/01/08 15:16:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 18/01/08 15:16:23 WARN SparkConf: In Spark 1.0 and later spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone and LOCAL_DIRS in YARN).; 18/01/08 15:16:23 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/home/ludvig/Programs/hail/jars/hail-all-spark.jar",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2527#issuecomment-355985783
https://github.com/hail-is/hail/issues/2527#issuecomment-355985783:0,Deployability,Update,Update,0,"Update to this, tried running the same script with the bgen file as v1.2 instead (was v1.1 in initial posted issue), but it gives the same issue/stack trace:. ```; SparkException: Job aborted due to stage failure: Task 1.0 in stage 5.0 (TID 2681) had a not serializable result: is.hail.io.bgen.Bgen12GenotypeIterator; Serialization stack:; 	- object not serializable (class: is.hail.io.bgen.Bgen12GenotypeIterator, value: Bgen12GenotypeIterator(0/0:.:.:.:GP=0.99798583984375,0.00201416015625,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:; ```; ```; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apac",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2527#issuecomment-355985783
https://github.com/hail-is/hail/issues/2527#issuecomment-355985783:591,Energy Efficiency,schedul,scheduler,591,"Update to this, tried running the same script with the bgen file as v1.2 instead (was v1.1 in initial posted issue), but it gives the same issue/stack trace:. ```; SparkException: Job aborted due to stage failure: Task 1.0 in stage 5.0 (TID 2681) had a not serializable result: is.hail.io.bgen.Bgen12GenotypeIterator; Serialization stack:; 	- object not serializable (class: is.hail.io.bgen.Bgen12GenotypeIterator, value: Bgen12GenotypeIterator(0/0:.:.:.:GP=0.99798583984375,0.00201416015625,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:; ```; ```; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apac",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2527#issuecomment-355985783
https://github.com/hail-is/hail/issues/2527#issuecomment-355985783:631,Energy Efficiency,schedul,scheduler,631,"Update to this, tried running the same script with the bgen file as v1.2 instead (was v1.1 in initial posted issue), but it gives the same issue/stack trace:. ```; SparkException: Job aborted due to stage failure: Task 1.0 in stage 5.0 (TID 2681) had a not serializable result: is.hail.io.bgen.Bgen12GenotypeIterator; Serialization stack:; 	- object not serializable (class: is.hail.io.bgen.Bgen12GenotypeIterator, value: Bgen12GenotypeIterator(0/0:.:.:.:GP=0.99798583984375,0.00201416015625,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:; ```; ```; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apac",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2527#issuecomment-355985783
https://github.com/hail-is/hail/issues/2527#issuecomment-355985783:730,Energy Efficiency,schedul,scheduler,730,"Update to this, tried running the same script with the bgen file as v1.2 instead (was v1.1 in initial posted issue), but it gives the same issue/stack trace:. ```; SparkException: Job aborted due to stage failure: Task 1.0 in stage 5.0 (TID 2681) had a not serializable result: is.hail.io.bgen.Bgen12GenotypeIterator; Serialization stack:; 	- object not serializable (class: is.hail.io.bgen.Bgen12GenotypeIterator, value: Bgen12GenotypeIterator(0/0:.:.:.:GP=0.99798583984375,0.00201416015625,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:; ```; ```; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apac",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2527#issuecomment-355985783
https://github.com/hail-is/hail/issues/2527#issuecomment-355985783:828,Energy Efficiency,schedul,scheduler,828,"Update to this, tried running the same script with the bgen file as v1.2 instead (was v1.1 in initial posted issue), but it gives the same issue/stack trace:. ```; SparkException: Job aborted due to stage failure: Task 1.0 in stage 5.0 (TID 2681) had a not serializable result: is.hail.io.bgen.Bgen12GenotypeIterator; Serialization stack:; 	- object not serializable (class: is.hail.io.bgen.Bgen12GenotypeIterator, value: Bgen12GenotypeIterator(0/0:.:.:.:GP=0.99798583984375,0.00201416015625,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:; ```; ```; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apac",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2527#issuecomment-355985783
https://github.com/hail-is/hail/issues/2527#issuecomment-355985783:1082,Energy Efficiency,schedul,scheduler,1082,"1.1 in initial posted issue), but it gives the same issue/stack trace:. ```; SparkException: Job aborted due to stage failure: Task 1.0 in stage 5.0 (TID 2681) had a not serializable result: is.hail.io.bgen.Bgen12GenotypeIterator; Serialization stack:; 	- object not serializable (class: is.hail.io.bgen.Bgen12GenotypeIterator, value: Bgen12GenotypeIterator(0/0:.:.:.:GP=0.99798583984375,0.00201416015625,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:; ```; ```; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); 	at org.apache.spark.SparkConte",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2527#issuecomment-355985783
https://github.com/hail-is/hail/issues/2527#issuecomment-355985783:1163,Energy Efficiency,schedul,scheduler,1163,"kException: Job aborted due to stage failure: Task 1.0 in stage 5.0 (TID 2681) had a not serializable result: is.hail.io.bgen.Bgen12GenotypeIterator; Serialization stack:; 	- object not serializable (class: is.hail.io.bgen.Bgen12GenotypeIterator, value: Bgen12GenotypeIterator(0/0:.:.:.:GP=0.99798583984375,0.00201416015625,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:; ```; ```; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1906); 	at org.apache.spark.rdd.PairRDDFunctions$$an",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2527#issuecomment-355985783
https://github.com/hail-is/hail/issues/2527#issuecomment-355985783:1269,Energy Efficiency,schedul,scheduler,1269,"lt: is.hail.io.bgen.Bgen12GenotypeIterator; Serialization stack:; 	- object not serializable (class: is.hail.io.bgen.Bgen12GenotypeIterator, value: Bgen12GenotypeIterator(0/0:.:.:.:GP=0.99798583984375,0.00201416015625,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:; ```; ```; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1906); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply$mcV$sp(PairRDDFunctions.scala:1219); 	at org.apache.spark.rdd.PairRDDFun",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2527#issuecomment-355985783
https://github.com/hail-is/hail/issues/2527#issuecomment-355985783:1419,Energy Efficiency,schedul,scheduler,1419,"en12GenotypeIterator(0/0:.:.:.:GP=0.99798583984375,0.00201416015625,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:; ```; ```; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1906); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply$mcV$sp(PairRDDFunctions.scala:1219); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply(PairRDDFunctions.scala:1161); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.app",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2527#issuecomment-355985783
https://github.com/hail-is/hail/issues/2527#issuecomment-355985783:1508,Energy Efficiency,schedul,scheduler,1508,",0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:; ```; ```; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1906); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply$mcV$sp(PairRDDFunctions.scala:1219); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply(PairRDDFunctions.scala:1161); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply(PairRDDFunctions.scala:1161); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RD",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2527#issuecomment-355985783
https://github.com/hail-is/hail/issues/2527#issuecomment-355985783:1606,Energy Efficiency,schedul,scheduler,1606,er.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1906); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply$mcV$sp(PairRDDFunctions.scala:1219); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply(PairRDDFunctions.scala:1161); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply(PairRDDFunctions.scala:1161); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScop,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2527#issuecomment-355985783
https://github.com/hail-is/hail/issues/2527#issuecomment-355985783:1702,Energy Efficiency,schedul,scheduler,1702,; 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1906); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply$mcV$sp(PairRDDFunctions.scala:1219); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply(PairRDDFunctions.scala:1161); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply(PairRDDFunctions.scala:1161); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358); 	at org.apache.spark.rdd.Pa,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2527#issuecomment-355985783
https://github.com/hail-is/hail/issues/2527#issuecomment-355985783:1867,Energy Efficiency,schedul,scheduler,1867,.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1906); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply$mcV$sp(PairRDDFunctions.scala:1219); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply(PairRDDFunctions.scala:1161); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply(PairRDDFunctions.scala:1161); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358); 	at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1161); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply$mcV$sp(PairRDDFunctions.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2527#issuecomment-355985783
https://github.com/hail-is/hail/issues/2527#issuecomment-355985783:5665,Integrability,message,messages,5665," is.hail.keytable.KeyTable.export(KeyTable.scala:537); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748). ```. I instead tried to run the same code in two separate jupyter notebooks, with the same code inside but different ways to initialize the hailcontext, one like this (works and exports):. ```; from hail import *; hc = HailContext(); ```; With startup messages looking like this:. ```; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; 18/01/08 13:51:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 18/01/08 13:51:03 WARN SparkConf: In Spark 1.0 and later spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone and LOCAL_DIRS in YARN).; 18/01/08 13:51:03 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/home/ludvig/Programs/hail/jars/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 18/01/08 13:51:03 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/home/ludvig/Programs/ha",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2527#issuecomment-355985783
https://github.com/hail-is/hail/issues/2527#issuecomment-355985783:6978,Integrability,interface,interface,6978,"form... using builtin-java classes where applicable; 18/01/08 13:51:03 WARN SparkConf: In Spark 1.0 and later spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone and LOCAL_DIRS in YARN).; 18/01/08 13:51:03 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/home/ludvig/Programs/hail/jars/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 18/01/08 13:51:03 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/home/ludvig/Programs/hail/jars/hail-all-spark.jar' as a work-around.; 18/01/08 13:51:03 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/home/ludvig/Programs/hail/jars/hail-all-spark.jar' as a work-around.; 18/01/08 13:51:03 WARN Utils: Your hostname, <my computer name> resolves to a loopback address: <my local IP>; using <my IP> instead (on interface enp3s0); 18/01/08 13:51:03 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address; ```. And the other initialize hail like this (crashes with the stack trace/error in the issue):; ```; from pyspark import *; from hail import *; conf = SparkConf(); conf.set('spark.sql.files.maxPartitionBytes','60000000000') ; conf.set('spark.sql.files.openCostInBytes','60000000000') ; conf.set('spark.driver.cores','1') #test with 1 core; sc = SparkContext(conf=conf); hc = HailContext(sc); ```. With startup messages looking like this:; ```; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; 18/01/08 15:16:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 18/01/08 15:16:23 WARN SparkConf: In Spark 1.0 and later spark.local.dir will be overridden by the value set by the ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2527#issuecomment-355985783
https://github.com/hail-is/hail/issues/2527#issuecomment-355985783:7497,Integrability,message,messages,7497,"; ; 18/01/08 13:51:03 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/home/ludvig/Programs/hail/jars/hail-all-spark.jar' as a work-around.; 18/01/08 13:51:03 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/home/ludvig/Programs/hail/jars/hail-all-spark.jar' as a work-around.; 18/01/08 13:51:03 WARN Utils: Your hostname, <my computer name> resolves to a loopback address: <my local IP>; using <my IP> instead (on interface enp3s0); 18/01/08 13:51:03 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address; ```. And the other initialize hail like this (crashes with the stack trace/error in the issue):; ```; from pyspark import *; from hail import *; conf = SparkConf(); conf.set('spark.sql.files.maxPartitionBytes','60000000000') ; conf.set('spark.sql.files.openCostInBytes','60000000000') ; conf.set('spark.driver.cores','1') #test with 1 core; sc = SparkContext(conf=conf); hc = HailContext(sc); ```. With startup messages looking like this:; ```; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; 18/01/08 15:16:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 18/01/08 15:16:23 WARN SparkConf: In Spark 1.0 and later spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone and LOCAL_DIRS in YARN).; 18/01/08 15:16:23 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/home/ludvig/Programs/hail/jars/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 18/01/08 15:16:23 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/home/ludvig/Programs/hail/jars/hail-all-spark.jar' as a work-around.; 18/01/08 15:16:2",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2527#issuecomment-355985783
https://github.com/hail-is/hail/issues/2527#issuecomment-355985783:8810,Integrability,interface,interface,8810,"like this (crashes with the stack trace/error in the issue):; ```; from pyspark import *; from hail import *; conf = SparkConf(); conf.set('spark.sql.files.maxPartitionBytes','60000000000') ; conf.set('spark.sql.files.openCostInBytes','60000000000') ; conf.set('spark.driver.cores','1') #test with 1 core; sc = SparkContext(conf=conf); hc = HailContext(sc); ```. With startup messages looking like this:; ```; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; 18/01/08 15:16:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 18/01/08 15:16:23 WARN SparkConf: In Spark 1.0 and later spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone and LOCAL_DIRS in YARN).; 18/01/08 15:16:23 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/home/ludvig/Programs/hail/jars/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 18/01/08 15:16:23 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/home/ludvig/Programs/hail/jars/hail-all-spark.jar' as a work-around.; 18/01/08 15:16:23 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/home/ludvig/Programs/hail/jars/hail-all-spark.jar' as a work-around.; 18/01/08 15:16:23 WARN Utils: Your hostname, <my computer name> resolves to a loopback address: <my local IP>; using <my IP> instead (on interface enp3s0); 18/01/08 15:16:23 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address; 18/01/08 15:16:23 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.; 18/01/08 15:16:23 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2527#issuecomment-355985783
https://github.com/hail-is/hail/issues/2527#issuecomment-355985783:5924,Performance,load,load,5924,"cessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748). ```. I instead tried to run the same code in two separate jupyter notebooks, with the same code inside but different ways to initialize the hailcontext, one like this (works and exports):. ```; from hail import *; hc = HailContext(); ```; With startup messages looking like this:. ```; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; 18/01/08 13:51:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 18/01/08 13:51:03 WARN SparkConf: In Spark 1.0 and later spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone and LOCAL_DIRS in YARN).; 18/01/08 13:51:03 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/home/ludvig/Programs/hail/jars/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 18/01/08 13:51:03 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/home/ludvig/Programs/hail/jars/hail-all-spark.jar' as a work-around.; 18/01/08 13:51:03 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/home/ludvig/Programs/hail/jars/hail-all-spark.jar' as a work-around.; 18/01/08 13:51:03 WARN Utils: Your hostname, <my computer name> resolves to a l",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2527#issuecomment-355985783
https://github.com/hail-is/hail/issues/2527#issuecomment-355985783:7756,Performance,load,load,7756,"traClassPath' to '/home/ludvig/Programs/hail/jars/hail-all-spark.jar' as a work-around.; 18/01/08 13:51:03 WARN Utils: Your hostname, <my computer name> resolves to a loopback address: <my local IP>; using <my IP> instead (on interface enp3s0); 18/01/08 13:51:03 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address; ```. And the other initialize hail like this (crashes with the stack trace/error in the issue):; ```; from pyspark import *; from hail import *; conf = SparkConf(); conf.set('spark.sql.files.maxPartitionBytes','60000000000') ; conf.set('spark.sql.files.openCostInBytes','60000000000') ; conf.set('spark.driver.cores','1') #test with 1 core; sc = SparkContext(conf=conf); hc = HailContext(sc); ```. With startup messages looking like this:; ```; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; 18/01/08 15:16:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 18/01/08 15:16:23 WARN SparkConf: In Spark 1.0 and later spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone and LOCAL_DIRS in YARN).; 18/01/08 15:16:23 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/home/ludvig/Programs/hail/jars/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 18/01/08 15:16:23 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/home/ludvig/Programs/hail/jars/hail-all-spark.jar' as a work-around.; 18/01/08 15:16:23 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/home/ludvig/Programs/hail/jars/hail-all-spark.jar' as a work-around.; 18/01/08 15:16:23 WARN Utils: Your hostname, <my computer name> resolves to a l",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2527#issuecomment-355985783
https://github.com/hail-is/hail/issues/2527#issuecomment-355985783:184,Safety,abort,aborted,184,"Update to this, tried running the same script with the bgen file as v1.2 instead (was v1.1 in initial posted issue), but it gives the same issue/stack trace:. ```; SparkException: Job aborted due to stage failure: Task 1.0 in stage 5.0 (TID 2681) had a not serializable result: is.hail.io.bgen.Bgen12GenotypeIterator; Serialization stack:; 	- object not serializable (class: is.hail.io.bgen.Bgen12GenotypeIterator, value: Bgen12GenotypeIterator(0/0:.:.:.:GP=0.99798583984375,0.00201416015625,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:; ```; ```; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apac",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2527#issuecomment-355985783
https://github.com/hail-is/hail/issues/2527#issuecomment-355985783:762,Safety,abort,abortStage,762,"Update to this, tried running the same script with the bgen file as v1.2 instead (was v1.1 in initial posted issue), but it gives the same issue/stack trace:. ```; SparkException: Job aborted due to stage failure: Task 1.0 in stage 5.0 (TID 2681) had a not serializable result: is.hail.io.bgen.Bgen12GenotypeIterator; Serialization stack:; 	- object not serializable (class: is.hail.io.bgen.Bgen12GenotypeIterator, value: Bgen12GenotypeIterator(0/0:.:.:.:GP=0.99798583984375,0.00201416015625,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:; ```; ```; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apac",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2527#issuecomment-355985783
https://github.com/hail-is/hail/issues/2527#issuecomment-355985783:860,Safety,abort,abortStage,860,"Update to this, tried running the same script with the bgen file as v1.2 instead (was v1.1 in initial posted issue), but it gives the same issue/stack trace:. ```; SparkException: Job aborted due to stage failure: Task 1.0 in stage 5.0 (TID 2681) had a not serializable result: is.hail.io.bgen.Bgen12GenotypeIterator; Serialization stack:; 	- object not serializable (class: is.hail.io.bgen.Bgen12GenotypeIterator, value: Bgen12GenotypeIterator(0/0:.:.:.:GP=0.99798583984375,0.00201416015625,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:; ```; ```; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apac",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2527#issuecomment-355985783
https://github.com/hail-is/hail/issues/2527#issuecomment-355985783:1105,Safety,abort,abortStage,1105,"but it gives the same issue/stack trace:. ```; SparkException: Job aborted due to stage failure: Task 1.0 in stage 5.0 (TID 2681) had a not serializable result: is.hail.io.bgen.Bgen12GenotypeIterator; Serialization stack:; 	- object not serializable (class: is.hail.io.bgen.Bgen12GenotypeIterator, value: Bgen12GenotypeIterator(0/0:.:.:.:GP=0.99798583984375,0.00201416015625,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:; ```; ```; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2527#issuecomment-355985783
https://github.com/hail-is/hail/issues/2527#issuecomment-355985783:6273,Safety,detect,detected,6273,"and.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748). ```. I instead tried to run the same code in two separate jupyter notebooks, with the same code inside but different ways to initialize the hailcontext, one like this (works and exports):. ```; from hail import *; hc = HailContext(); ```; With startup messages looking like this:. ```; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; 18/01/08 13:51:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 18/01/08 13:51:03 WARN SparkConf: In Spark 1.0 and later spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone and LOCAL_DIRS in YARN).; 18/01/08 13:51:03 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/home/ludvig/Programs/hail/jars/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 18/01/08 13:51:03 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/home/ludvig/Programs/hail/jars/hail-all-spark.jar' as a work-around.; 18/01/08 13:51:03 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/home/ludvig/Programs/hail/jars/hail-all-spark.jar' as a work-around.; 18/01/08 13:51:03 WARN Utils: Your hostname, <my computer name> resolves to a loopback address: <my local IP>; using <my IP> instead (on interface enp3s0); 18/01/08 13:51:03 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address; ```. And the other initialize hail like this (crashes with the stack trace/error in the issue):; ```; from pyspark import *; from hail import *; conf = SparkConf(); conf.set('spark.sql.files.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2527#issuecomment-355985783
https://github.com/hail-is/hail/issues/2527#issuecomment-355985783:8105,Safety,detect,detected,8105,"tialize hail like this (crashes with the stack trace/error in the issue):; ```; from pyspark import *; from hail import *; conf = SparkConf(); conf.set('spark.sql.files.maxPartitionBytes','60000000000') ; conf.set('spark.sql.files.openCostInBytes','60000000000') ; conf.set('spark.driver.cores','1') #test with 1 core; sc = SparkContext(conf=conf); hc = HailContext(sc); ```. With startup messages looking like this:; ```; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; 18/01/08 15:16:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 18/01/08 15:16:23 WARN SparkConf: In Spark 1.0 and later spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone and LOCAL_DIRS in YARN).; 18/01/08 15:16:23 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/home/ludvig/Programs/hail/jars/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 18/01/08 15:16:23 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/home/ludvig/Programs/hail/jars/hail-all-spark.jar' as a work-around.; 18/01/08 15:16:23 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/home/ludvig/Programs/hail/jars/hail-all-spark.jar' as a work-around.; 18/01/08 15:16:23 WARN Utils: Your hostname, <my computer name> resolves to a loopback address: <my local IP>; using <my IP> instead (on interface enp3s0); 18/01/08 15:16:23 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address; 18/01/08 15:16:23 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.; 18/01/08 15:16:23 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting por",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2527#issuecomment-355985783
https://github.com/hail-is/hail/issues/2527#issuecomment-355985783:5796,Testability,log,log,5796,"hodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748). ```. I instead tried to run the same code in two separate jupyter notebooks, with the same code inside but different ways to initialize the hailcontext, one like this (works and exports):. ```; from hail import *; hc = HailContext(); ```; With startup messages looking like this:. ```; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; 18/01/08 13:51:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 18/01/08 13:51:03 WARN SparkConf: In Spark 1.0 and later spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone and LOCAL_DIRS in YARN).; 18/01/08 13:51:03 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/home/ludvig/Programs/hail/jars/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 18/01/08 13:51:03 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/home/ludvig/Programs/hail/jars/hail-all-spark.jar' as a work-around.; 18/01/08 13:51:03 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/home/ludvig/Programs/",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2527#issuecomment-355985783
https://github.com/hail-is/hail/issues/2527#issuecomment-355985783:5828,Testability,log,logging,5828,"sorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748). ```. I instead tried to run the same code in two separate jupyter notebooks, with the same code inside but different ways to initialize the hailcontext, one like this (works and exports):. ```; from hail import *; hc = HailContext(); ```; With startup messages looking like this:. ```; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; 18/01/08 13:51:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 18/01/08 13:51:03 WARN SparkConf: In Spark 1.0 and later spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone and LOCAL_DIRS in YARN).; 18/01/08 13:51:03 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/home/ludvig/Programs/hail/jars/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 18/01/08 13:51:03 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/home/ludvig/Programs/hail/jars/hail-all-spark.jar' as a work-around.; 18/01/08 13:51:03 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/home/ludvig/Programs/hail/jars/hail-all-spark.jar' as a work-a",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2527#issuecomment-355985783
https://github.com/hail-is/hail/issues/2527#issuecomment-355985783:7409,Testability,test,test,7409,"ath to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 18/01/08 13:51:03 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/home/ludvig/Programs/hail/jars/hail-all-spark.jar' as a work-around.; 18/01/08 13:51:03 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/home/ludvig/Programs/hail/jars/hail-all-spark.jar' as a work-around.; 18/01/08 13:51:03 WARN Utils: Your hostname, <my computer name> resolves to a loopback address: <my local IP>; using <my IP> instead (on interface enp3s0); 18/01/08 13:51:03 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address; ```. And the other initialize hail like this (crashes with the stack trace/error in the issue):; ```; from pyspark import *; from hail import *; conf = SparkConf(); conf.set('spark.sql.files.maxPartitionBytes','60000000000') ; conf.set('spark.sql.files.openCostInBytes','60000000000') ; conf.set('spark.driver.cores','1') #test with 1 core; sc = SparkContext(conf=conf); hc = HailContext(sc); ```. With startup messages looking like this:; ```; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; 18/01/08 15:16:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 18/01/08 15:16:23 WARN SparkConf: In Spark 1.0 and later spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone and LOCAL_DIRS in YARN).; 18/01/08 15:16:23 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/home/ludvig/Programs/hail/jars/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 18/01/08 15:16:23 WARN SparkConf: Setting 'spark.executor.extra",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2527#issuecomment-355985783
https://github.com/hail-is/hail/issues/2527#issuecomment-355985783:7628,Testability,log,log,7628,"home/ludvig/Programs/hail/jars/hail-all-spark.jar' as a work-around.; 18/01/08 13:51:03 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/home/ludvig/Programs/hail/jars/hail-all-spark.jar' as a work-around.; 18/01/08 13:51:03 WARN Utils: Your hostname, <my computer name> resolves to a loopback address: <my local IP>; using <my IP> instead (on interface enp3s0); 18/01/08 13:51:03 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address; ```. And the other initialize hail like this (crashes with the stack trace/error in the issue):; ```; from pyspark import *; from hail import *; conf = SparkConf(); conf.set('spark.sql.files.maxPartitionBytes','60000000000') ; conf.set('spark.sql.files.openCostInBytes','60000000000') ; conf.set('spark.driver.cores','1') #test with 1 core; sc = SparkContext(conf=conf); hc = HailContext(sc); ```. With startup messages looking like this:; ```; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; 18/01/08 15:16:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 18/01/08 15:16:23 WARN SparkConf: In Spark 1.0 and later spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone and LOCAL_DIRS in YARN).; 18/01/08 15:16:23 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/home/ludvig/Programs/hail/jars/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 18/01/08 15:16:23 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/home/ludvig/Programs/hail/jars/hail-all-spark.jar' as a work-around.; 18/01/08 15:16:23 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/home/ludvig/Programs/",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2527#issuecomment-355985783
https://github.com/hail-is/hail/issues/2527#issuecomment-355985783:7660,Testability,log,logging,7660,"spark.jar' as a work-around.; 18/01/08 13:51:03 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/home/ludvig/Programs/hail/jars/hail-all-spark.jar' as a work-around.; 18/01/08 13:51:03 WARN Utils: Your hostname, <my computer name> resolves to a loopback address: <my local IP>; using <my IP> instead (on interface enp3s0); 18/01/08 13:51:03 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address; ```. And the other initialize hail like this (crashes with the stack trace/error in the issue):; ```; from pyspark import *; from hail import *; conf = SparkConf(); conf.set('spark.sql.files.maxPartitionBytes','60000000000') ; conf.set('spark.sql.files.openCostInBytes','60000000000') ; conf.set('spark.driver.cores','1') #test with 1 core; sc = SparkContext(conf=conf); hc = HailContext(sc); ```. With startup messages looking like this:; ```; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; 18/01/08 15:16:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 18/01/08 15:16:23 WARN SparkConf: In Spark 1.0 and later spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone and LOCAL_DIRS in YARN).; 18/01/08 15:16:23 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/home/ludvig/Programs/hail/jars/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 18/01/08 15:16:23 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/home/ludvig/Programs/hail/jars/hail-all-spark.jar' as a work-around.; 18/01/08 15:16:23 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/home/ludvig/Programs/hail/jars/hail-all-spark.jar' as a work-a",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2527#issuecomment-355985783
https://github.com/hail-is/hail/pull/2531#issuecomment-350003512:18,Availability,failure,failure,18,looking into test failure,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2531#issuecomment-350003512
https://github.com/hail-is/hail/pull/2531#issuecomment-350003512:13,Testability,test,test,13,looking into test failure,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2531#issuecomment-350003512
https://github.com/hail-is/hail/pull/2531#issuecomment-350128393:49,Integrability,interface,interface,49,"I added 64KB buffer, but I'm unsure of the right interface (should the caller pass in the byte buffer as well?) and location (RichDenseMatrixDouble is quite specific) for these functions. In compute on WriteBlocksRDD, I create a byte buffer of the same size in bytes as the entire IndexedRow, and re-use it for every row. This limits the number of cols to 268 million or so (~2^28) which I don't see us exceeding anytime soon. I could instead use the writeDoubles function but then I'd want to change the interface to pass in the byte buffer so it's not recreated for every row. What do you think is most reasonable?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2531#issuecomment-350128393
https://github.com/hail-is/hail/pull/2531#issuecomment-350128393:505,Integrability,interface,interface,505,"I added 64KB buffer, but I'm unsure of the right interface (should the caller pass in the byte buffer as well?) and location (RichDenseMatrixDouble is quite specific) for these functions. In compute on WriteBlocksRDD, I create a byte buffer of the same size in bytes as the entire IndexedRow, and re-use it for every row. This limits the number of cols to 268 million or so (~2^28) which I don't see us exceeding anytime soon. I could instead use the writeDoubles function but then I'd want to change the interface to pass in the byte buffer so it's not recreated for every row. What do you think is most reasonable?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2531#issuecomment-350128393
https://github.com/hail-is/hail/pull/2542#issuecomment-350358236:156,Usability,clear,clear,156,"Personally, I'm not a fan of the `n` prefix that Spark and friends use everywhere they what ""number of"". I think `rows` (the Breeze naming style) is always clear in context.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2542#issuecomment-350358236
https://github.com/hail-is/hail/pull/2544#issuecomment-350392288:11,Testability,test,tests,11,"@cseed the tests compare skat and R which computes stats one group at a time, so I can compare product / explode / skat to product / explode / rskat, but thats still only testing skat and product / explode independently. I could get some numbers out from the previous version with single_key=True and hardcode those into a test of the new version. I'd added testToKeyGsWeightRdd() specifically to check that the grouping by key checks out. I think it'd make more sense to expand that test to a case that uses product / explode. Do you agree?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2544#issuecomment-350392288
https://github.com/hail-is/hail/pull/2544#issuecomment-350392288:172,Testability,test,testing,172,"@cseed the tests compare skat and R which computes stats one group at a time, so I can compare product / explode / skat to product / explode / rskat, but thats still only testing skat and product / explode independently. I could get some numbers out from the previous version with single_key=True and hardcode those into a test of the new version. I'd added testToKeyGsWeightRdd() specifically to check that the grouping by key checks out. I think it'd make more sense to expand that test to a case that uses product / explode. Do you agree?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2544#issuecomment-350392288
https://github.com/hail-is/hail/pull/2544#issuecomment-350392288:324,Testability,test,test,324,"@cseed the tests compare skat and R which computes stats one group at a time, so I can compare product / explode / skat to product / explode / rskat, but thats still only testing skat and product / explode independently. I could get some numbers out from the previous version with single_key=True and hardcode those into a test of the new version. I'd added testToKeyGsWeightRdd() specifically to check that the grouping by key checks out. I think it'd make more sense to expand that test to a case that uses product / explode. Do you agree?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2544#issuecomment-350392288
https://github.com/hail-is/hail/pull/2544#issuecomment-350392288:359,Testability,test,testToKeyGsWeightRdd,359,"@cseed the tests compare skat and R which computes stats one group at a time, so I can compare product / explode / skat to product / explode / rskat, but thats still only testing skat and product / explode independently. I could get some numbers out from the previous version with single_key=True and hardcode those into a test of the new version. I'd added testToKeyGsWeightRdd() specifically to check that the grouping by key checks out. I think it'd make more sense to expand that test to a case that uses product / explode. Do you agree?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2544#issuecomment-350392288
https://github.com/hail-is/hail/pull/2544#issuecomment-350392288:485,Testability,test,test,485,"@cseed the tests compare skat and R which computes stats one group at a time, so I can compare product / explode / skat to product / explode / rskat, but thats still only testing skat and product / explode independently. I could get some numbers out from the previous version with single_key=True and hardcode those into a test of the new version. I'd added testToKeyGsWeightRdd() specifically to check that the grouping by key checks out. I think it'd make more sense to expand that test to a case that uses product / explode. Do you agree?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2544#issuecomment-350392288
https://github.com/hail-is/hail/pull/2544#issuecomment-350511538:33,Testability,test,testToKeyGsWeightRdd,33,See comment above. I've modified testToKeyGsWeightRdd to include interaction with explode. The test will fail until #2549 goes in since it used `toSet()`.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2544#issuecomment-350511538
https://github.com/hail-is/hail/pull/2544#issuecomment-350511538:95,Testability,test,test,95,See comment above. I've modified testToKeyGsWeightRdd to include interaction with explode. The test will fail until #2549 goes in since it used `toSet()`.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2544#issuecomment-350511538
https://github.com/hail-is/hail/pull/2544#issuecomment-350770505:173,Testability,test,testing,173,"@catoverdrive I pushed more improvements just as you approved, would you mind taking a look at them as well (it's minimal). Sorry about that, thanks! I also want to clarify testing with Cotton before merging, let me know if you have any thoughts on the matter.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2544#issuecomment-350770505
https://github.com/hail-is/hail/pull/2544#issuecomment-350838973:45,Testability,test,testToKeyGsWeightRdd,45,"@cseed please see comments above and look at testToKeyGsWeightRdd(), let me know if you think it's enough. (I was able to rip out the SparseVector code that was supporting the GT case as well now that we've gone generic)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2544#issuecomment-350838973
https://github.com/hail-is/hail/pull/2544#issuecomment-351097552:41,Integrability,interface,interface,41,"I'm merging this so Sali can use the new interface and better performance, and I am going to add an additional test in another PR.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2544#issuecomment-351097552
https://github.com/hail-is/hail/pull/2544#issuecomment-351097552:62,Performance,perform,performance,62,"I'm merging this so Sali can use the new interface and better performance, and I am going to add an additional test in another PR.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2544#issuecomment-351097552
https://github.com/hail-is/hail/pull/2544#issuecomment-351097552:111,Testability,test,test,111,"I'm merging this so Sali can use the new interface and better performance, and I am going to add an additional test in another PR.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2544#issuecomment-351097552
https://github.com/hail-is/hail/pull/2545#issuecomment-350357452:141,Performance,optimiz,optimizer,141,"@catoverdrive I still need to give you someway to uniformly use either a compiled AST or a compiled IR, but maybe you can start playing with optimizer things with this. Adding a constant propagation pass to the IR would be neat. I've got some PR review to do first though.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2545#issuecomment-350357452
https://github.com/hail-is/hail/pull/2546#issuecomment-350494085:53,Availability,failure,failure,53,"Sorry for cutoff review line, I remarked on the test failure in a comment. You also need to rebase.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2546#issuecomment-350494085
https://github.com/hail-is/hail/pull/2546#issuecomment-350494085:48,Testability,test,test,48,"Sorry for cutoff review line, I remarked on the test failure in a comment. You also need to rebase.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2546#issuecomment-350494085
https://github.com/hail-is/hail/pull/2547#issuecomment-350560408:129,Availability,avail,available,129,"Search `.zipWithIndex()` and you'll see five places we used Spark's zipWithIndex, which triggers a job. When partitionCounts are available I think we could avoid that.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2547#issuecomment-350560408
https://github.com/hail-is/hail/pull/2547#issuecomment-350560408:156,Safety,avoid,avoid,156,"Search `.zipWithIndex()` and you'll see five places we used Spark's zipWithIndex, which triggers a job. When partitionCounts are available I think we could avoid that.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2547#issuecomment-350560408
https://github.com/hail-is/hail/pull/2551#issuecomment-350557712:140,Deployability,install,installed,140,"Also in this PR, I've started using [numpy style docstrings](http://www.sphinx-doc.org/en/stable/ext/example_numpy.html#example-numpy), and installed `sphinxcontrib-napoleon` on the CI server to support them.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2551#issuecomment-350557712
https://github.com/hail-is/hail/pull/2551#issuecomment-350557759:6,Integrability,depend,depends,6,"Also, depends on #2548",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2551#issuecomment-350557759
https://github.com/hail-is/hail/pull/2552#issuecomment-350601600:0,Integrability,Depend,Depends,0,Depends on #2551,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2552#issuecomment-350601600
https://github.com/hail-is/hail/pull/2552#issuecomment-351194636:14,Integrability,depend,dependency,14,closing until dependency is in.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2552#issuecomment-351194636
https://github.com/hail-is/hail/pull/2555#issuecomment-350868684:1049,Availability,avail,available,1049,"This is better, but I want to go more extreme:. - get rid of TransformedRegionValueAggregator and ZippedRegionValueAggregator. This is a compiler backend. Too much abstraction in your output! Let's compile that shit away.; - ExtractAggregators should return an Array[AggSum]. These are expressions ending in AggSum containing aggregator operations (filter, map, etc.) defined in terms of the aggregated element and associated context.; - Add a function AggSum => RegionValueAggregator. This is the way to generalize: make AggSum into Agg(op: AggOp) where AggOp (like unary and binary op) are all the possible aggregator types, and there is a function that maps the op to the corresponding RegionValueAggregator*; - compiling the Array[AggSum] should product a function that takes the array of aggregators and a single value (with context) of the collection we're aggregating over and updates them with that element. *I think you need an array of arguments to handle things like call_stats which are evaluated in the aggregator scope (the only scope available to evaluate something). Imagine you have `gs.filter(g => g.GT.isHet()).map(g => g.DP).sum() + gs.flatMap(g => g.PL).sum()`. The Array[AggSum] will be. ```; Array(AggSum(AggMap(; AggFilter(AggIn(...), ; ""g"", g.GT.isHet()),; ""g"", (getField (Ref ""g"") ""DP""),; AggSum(AggFlatMap(AggIn(...),; ""g"", (getField (Ref ""g"") ""PL))); ```. The generated function should look like:. ```; def f(aggs: Array[AggSum], region: MemoryBuffer, g: Long, mg: Boolean, ...) {; if (g.GT.isHet()) { // RV-ified, of course; val DP = g.DP // actually fieldOffset; aggs(0).seqOp(DP); }; for (PLi in g.PL) { // actually elementOffset; aggs(1).seqOp(PLi); }; }; ```. This is straight-line and should be fast. It immediately allows you to do common subexpression elimination on aggregator prefixes which is something that is quite common, that is, if you have `gs.filter(g => g.isHet).map(g => g.DP).mean() < 10 gs.filter.map(g => g.GQ).mean() < 50` then in the aggregation fu",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2555#issuecomment-350868684
https://github.com/hail-is/hail/pull/2555#issuecomment-350868684:884,Deployability,update,updates,884,"This is better, but I want to go more extreme:. - get rid of TransformedRegionValueAggregator and ZippedRegionValueAggregator. This is a compiler backend. Too much abstraction in your output! Let's compile that shit away.; - ExtractAggregators should return an Array[AggSum]. These are expressions ending in AggSum containing aggregator operations (filter, map, etc.) defined in terms of the aggregated element and associated context.; - Add a function AggSum => RegionValueAggregator. This is the way to generalize: make AggSum into Agg(op: AggOp) where AggOp (like unary and binary op) are all the possible aggregator types, and there is a function that maps the op to the corresponding RegionValueAggregator*; - compiling the Array[AggSum] should product a function that takes the array of aggregators and a single value (with context) of the collection we're aggregating over and updates them with that element. *I think you need an array of arguments to handle things like call_stats which are evaluated in the aggregator scope (the only scope available to evaluate something). Imagine you have `gs.filter(g => g.GT.isHet()).map(g => g.DP).sum() + gs.flatMap(g => g.PL).sum()`. The Array[AggSum] will be. ```; Array(AggSum(AggMap(; AggFilter(AggIn(...), ; ""g"", g.GT.isHet()),; ""g"", (getField (Ref ""g"") ""DP""),; AggSum(AggFlatMap(AggIn(...),; ""g"", (getField (Ref ""g"") ""PL))); ```. The generated function should look like:. ```; def f(aggs: Array[AggSum], region: MemoryBuffer, g: Long, mg: Boolean, ...) {; if (g.GT.isHet()) { // RV-ified, of course; val DP = g.DP // actually fieldOffset; aggs(0).seqOp(DP); }; for (PLi in g.PL) { // actually elementOffset; aggs(1).seqOp(PLi); }; }; ```. This is straight-line and should be fast. It immediately allows you to do common subexpression elimination on aggregator prefixes which is something that is quite common, that is, if you have `gs.filter(g => g.isHet).map(g => g.DP).mean() < 10 gs.filter.map(g => g.GQ).mean() < 50` then in the aggregation fu",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2555#issuecomment-350868684
https://github.com/hail-is/hail/pull/2555#issuecomment-350868684:2049,Testability,test,test,2049,"nValueAggregator. This is a compiler backend. Too much abstraction in your output! Let's compile that shit away.; - ExtractAggregators should return an Array[AggSum]. These are expressions ending in AggSum containing aggregator operations (filter, map, etc.) defined in terms of the aggregated element and associated context.; - Add a function AggSum => RegionValueAggregator. This is the way to generalize: make AggSum into Agg(op: AggOp) where AggOp (like unary and binary op) are all the possible aggregator types, and there is a function that maps the op to the corresponding RegionValueAggregator*; - compiling the Array[AggSum] should product a function that takes the array of aggregators and a single value (with context) of the collection we're aggregating over and updates them with that element. *I think you need an array of arguments to handle things like call_stats which are evaluated in the aggregator scope (the only scope available to evaluate something). Imagine you have `gs.filter(g => g.GT.isHet()).map(g => g.DP).sum() + gs.flatMap(g => g.PL).sum()`. The Array[AggSum] will be. ```; Array(AggSum(AggMap(; AggFilter(AggIn(...), ; ""g"", g.GT.isHet()),; ""g"", (getField (Ref ""g"") ""DP""),; AggSum(AggFlatMap(AggIn(...),; ""g"", (getField (Ref ""g"") ""PL))); ```. The generated function should look like:. ```; def f(aggs: Array[AggSum], region: MemoryBuffer, g: Long, mg: Boolean, ...) {; if (g.GT.isHet()) { // RV-ified, of course; val DP = g.DP // actually fieldOffset; aggs(0).seqOp(DP); }; for (PLi in g.PL) { // actually elementOffset; aggs(1).seqOp(PLi); }; }; ```. This is straight-line and should be fast. It immediately allows you to do common subexpression elimination on aggregator prefixes which is something that is quite common, that is, if you have `gs.filter(g => g.isHet).map(g => g.DP).mean() < 10 gs.filter.map(g => g.GQ).mean() < 50` then in the aggregation function you can do:. ```; if (g.isHet) { // only test once!; aggs(0).seqOp(g.DP); aggs(1).seqOp(g.GQ); }; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2555#issuecomment-350868684
https://github.com/hail-is/hail/pull/2556#issuecomment-351586270:53,Testability,test,tests,53,Looks like it needs a rebase before it can rerun the tests. I'll take another look once it is passing.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2556#issuecomment-351586270
https://github.com/hail-is/hail/pull/2557#issuecomment-351511340:210,Integrability,wrap,wrapped,210,"oops. It's probably defined below in the same file. It's a decorator that calls `to_expr` on each argument of the function before calling the function. That way, Python values like ints and bools and so on get wrapped without having to do so explicitly inside the function.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2557#issuecomment-351511340
https://github.com/hail-is/hail/pull/2559#issuecomment-351252274:206,Availability,down,down,206,"I addressed comments apart from improving the tests on VSM. There are two options regarding plan for writing out a Spark IRM:; 1) just delete it; 2) keep it, pass partStarts through for efficiency, and cut down on code duplication. I tried the latter, creating KeyedIndexedRowMatrix as abstraction to handle both PCA and writing, and pushing common structure to an object WriteBlocksRDD.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2559#issuecomment-351252274
https://github.com/hail-is/hail/pull/2559#issuecomment-351252274:46,Testability,test,tests,46,"I addressed comments apart from improving the tests on VSM. There are two options regarding plan for writing out a Spark IRM:; 1) just delete it; 2) keep it, pass partStarts through for efficiency, and cut down on code duplication. I tried the latter, creating KeyedIndexedRowMatrix as abstraction to handle both PCA and writing, and pushing common structure to an object WriteBlocksRDD.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2559#issuecomment-351252274
https://github.com/hail-is/hail/pull/2564#issuecomment-351422628:5,Availability,failure,failures,5,"Test failures seem odd, they don't seem to use FilterSamples?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2564#issuecomment-351422628
https://github.com/hail-is/hail/pull/2564#issuecomment-351422628:0,Testability,Test,Test,0,"Test failures seem odd, they don't seem to use FilterSamples?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2564#issuecomment-351422628
https://github.com/hail-is/hail/pull/2564#issuecomment-351443642:14,Performance,load,loadPrimitive,14,That was it. `loadPrimitive` also needed a call to `fundamentalType`.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2564#issuecomment-351443642
https://github.com/hail-is/hail/pull/2569#issuecomment-351811149:362,Testability,log,logic,362,"A couple of notes:. - I moved the actual writing of the InsnNodes to the method's InsnList onto the MethodBuilder (MethodBuilder.close()) itself, per Dan's suggestion. This is a little weird because it gets called in fb.classAsBytes(), and so calling it earlier will basically add the instructions again, and we should never do this. I'm thinking of adding some logic to check that a method isn't ""closed"", or at least clearing out the instruction buffer afterwards.; - I want to implement `<init>` in terms of the method builder, but we don't have a way to deal with Unit return types well yet. Dan's made a crack at this as part of #2555, so I'm going to hold off on that until I can use that.; - We realized that the auto-adding of a return op at the end of the method was causing some extra bytecode to be added at the end of the method if you explicitly called Code._return() to return the last Code object in the method. We decided that keeping the return op in MethodBuilder and just not calling _return unless returning in the middle of a method was nicer, since Scala doesn't use return x either.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2569#issuecomment-351811149
https://github.com/hail-is/hail/pull/2569#issuecomment-351811149:419,Usability,clear,clearing,419,"A couple of notes:. - I moved the actual writing of the InsnNodes to the method's InsnList onto the MethodBuilder (MethodBuilder.close()) itself, per Dan's suggestion. This is a little weird because it gets called in fb.classAsBytes(), and so calling it earlier will basically add the instructions again, and we should never do this. I'm thinking of adding some logic to check that a method isn't ""closed"", or at least clearing out the instruction buffer afterwards.; - I want to implement `<init>` in terms of the method builder, but we don't have a way to deal with Unit return types well yet. Dan's made a crack at this as part of #2555, so I'm going to hold off on that until I can use that.; - We realized that the auto-adding of a return op at the end of the method was causing some extra bytecode to be added at the end of the method if you explicitly called Code._return() to return the last Code object in the method. We decided that keeping the return op in MethodBuilder and just not calling _return unless returning in the middle of a method was nicer, since Scala doesn't use return x either.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2569#issuecomment-351811149
https://github.com/hail-is/hail/pull/2580#issuecomment-352192050:87,Testability,test,tests,87,"The point of this PR was to just build up a shell we can add to, not to fully move the tests over yet. There's more functionality we have to add to Hail2 first.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2580#issuecomment-352192050
https://github.com/hail-is/hail/pull/2582#issuecomment-352084718:28,Integrability,interface,interface,28,"to 0.1, you mean? That's an interface change :|",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2582#issuecomment-352084718
https://github.com/hail-is/hail/pull/2586#issuecomment-352182040:25,Testability,test,testsetup,25,You could also add a `.. testsetup::` directive to import it here.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2586#issuecomment-352182040
https://github.com/hail-is/hail/pull/2588#issuecomment-352128339:22,Testability,test,tests,22,"OK, I verified python tests pass. Should be ready for a look.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2588#issuecomment-352128339
https://github.com/hail-is/hail/pull/2588#issuecomment-352157852:158,Integrability,interface,interface,158,I don't especially like renaming the Python hail1 api classes KeyTable -> Table and VariantDataset -> MatrixTable. I basically feel like we should leave that interface untouched until we delete it.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2588#issuecomment-352157852
https://github.com/hail-is/hail/pull/2588#issuecomment-352159175:44,Energy Efficiency,energy,energy,44,"I agree completely. No point in putting any energy into hail1. I think we can do that sooner rather than later. As soon as the current devel users (basically Robert, Konrad and maybe Laurent) can use hail2 instead of hail1, it goes, even if hail2 is still a bit rough and in flux. (It is devel, after all.)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2588#issuecomment-352159175
https://github.com/hail-is/hail/pull/2588#issuecomment-352190554:991,Deployability,integrat,integrate,991,"y current rough list of things to be done before hail2 is as usable as hail1. It's still pretty long!. ## Necessary code work:; - Add the rest of the core methods from VDS/KT to api2 (#2591 does most for KT, order_by is the only outstanding KT method that's not moved to table there. Same needs to be done for VDS, this isn't too hard); - Add the non-core methods to `hail.methods` / `hail.genetics.methods`; - some stuff here is much harder than the rest, like `filter_alleles`; - This is mostly just labor, but some require more thought than others, like moving TDT to use hail2 expr; - Support intervals in the `index_*` methods. It's possible now to join by locus, but not using the `annotateLociTable` fast path.; - Move to Python 3 so argument order is preserved; - Test the hail2 api much more rigorously than we do now (at the very least, call each parameter branch for each method!; - Typecheck the expression language. This isn't super trivial, and making a nice system to integrate our `typecheck` module and expressions will require some thoughtful design work.; - Some more organization around the package: monkey patching with `import hail.genetics` is an idea I like, but want to think about the edge cases first. ## Documentation; - Document the `index_*` methods / joins; - Translate the _Hail Overview_ tutorial; - Make new tutorials to replace the 2 expr ones we have; - Fill in docs on api2 methods (they're not all there yet); - Fill in docs on expression language (things like __mul__ on NumericExpression haven't been documented); - Write ""integrative docs"" that provide how-tos for common types of workflows. Show the power of annotate / select / group_by/aggregate, etc. ## Longer term QoL:; - Move over tests to Python as much as possible. I looked at the linear regression suite and it can be moved entirely into Python without many problems.; - Write a type parser in Python. The nested calls into the JVM for Type._from_java make the library feel extremely sluggish on tee",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2588#issuecomment-352190554
https://github.com/hail-is/hail/pull/2588#issuecomment-352190554:1135,Deployability,patch,patching,1135,"ry code work:; - Add the rest of the core methods from VDS/KT to api2 (#2591 does most for KT, order_by is the only outstanding KT method that's not moved to table there. Same needs to be done for VDS, this isn't too hard); - Add the non-core methods to `hail.methods` / `hail.genetics.methods`; - some stuff here is much harder than the rest, like `filter_alleles`; - This is mostly just labor, but some require more thought than others, like moving TDT to use hail2 expr; - Support intervals in the `index_*` methods. It's possible now to join by locus, but not using the `annotateLociTable` fast path.; - Move to Python 3 so argument order is preserved; - Test the hail2 api much more rigorously than we do now (at the very least, call each parameter branch for each method!; - Typecheck the expression language. This isn't super trivial, and making a nice system to integrate our `typecheck` module and expressions will require some thoughtful design work.; - Some more organization around the package: monkey patching with `import hail.genetics` is an idea I like, but want to think about the edge cases first. ## Documentation; - Document the `index_*` methods / joins; - Translate the _Hail Overview_ tutorial; - Make new tutorials to replace the 2 expr ones we have; - Fill in docs on api2 methods (they're not all there yet); - Fill in docs on expression language (things like __mul__ on NumericExpression haven't been documented); - Write ""integrative docs"" that provide how-tos for common types of workflows. Show the power of annotate / select / group_by/aggregate, etc. ## Longer term QoL:; - Move over tests to Python as much as possible. I looked at the linear regression suite and it can be moved entirely into Python without many problems.; - Write a type parser in Python. The nested calls into the JVM for Type._from_java make the library feel extremely sluggish on teensy data.; - Integrate RV with C/C++, so we can transmit data much more efficiently between Python and Java.; - R",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2588#issuecomment-352190554
https://github.com/hail-is/hail/pull/2588#issuecomment-352190554:1571,Deployability,integrat,integrative,1571,"not moved to table there. Same needs to be done for VDS, this isn't too hard); - Add the non-core methods to `hail.methods` / `hail.genetics.methods`; - some stuff here is much harder than the rest, like `filter_alleles`; - This is mostly just labor, but some require more thought than others, like moving TDT to use hail2 expr; - Support intervals in the `index_*` methods. It's possible now to join by locus, but not using the `annotateLociTable` fast path.; - Move to Python 3 so argument order is preserved; - Test the hail2 api much more rigorously than we do now (at the very least, call each parameter branch for each method!; - Typecheck the expression language. This isn't super trivial, and making a nice system to integrate our `typecheck` module and expressions will require some thoughtful design work.; - Some more organization around the package: monkey patching with `import hail.genetics` is an idea I like, but want to think about the edge cases first. ## Documentation; - Document the `index_*` methods / joins; - Translate the _Hail Overview_ tutorial; - Make new tutorials to replace the 2 expr ones we have; - Fill in docs on api2 methods (they're not all there yet); - Fill in docs on expression language (things like __mul__ on NumericExpression haven't been documented); - Write ""integrative docs"" that provide how-tos for common types of workflows. Show the power of annotate / select / group_by/aggregate, etc. ## Longer term QoL:; - Move over tests to Python as much as possible. I looked at the linear regression suite and it can be moved entirely into Python without many problems.; - Write a type parser in Python. The nested calls into the JVM for Type._from_java make the library feel extremely sluggish on teensy data.; - Integrate RV with C/C++, so we can transmit data much more efficiently between Python and Java.; - Rethink the expr language function registry, because many functions there can be implemented in terms of others in Python.; - add back in de novo",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2588#issuecomment-352190554
https://github.com/hail-is/hail/pull/2588#issuecomment-352190554:2022,Deployability,Integrat,Integrate,2022,"not moved to table there. Same needs to be done for VDS, this isn't too hard); - Add the non-core methods to `hail.methods` / `hail.genetics.methods`; - some stuff here is much harder than the rest, like `filter_alleles`; - This is mostly just labor, but some require more thought than others, like moving TDT to use hail2 expr; - Support intervals in the `index_*` methods. It's possible now to join by locus, but not using the `annotateLociTable` fast path.; - Move to Python 3 so argument order is preserved; - Test the hail2 api much more rigorously than we do now (at the very least, call each parameter branch for each method!; - Typecheck the expression language. This isn't super trivial, and making a nice system to integrate our `typecheck` module and expressions will require some thoughtful design work.; - Some more organization around the package: monkey patching with `import hail.genetics` is an idea I like, but want to think about the edge cases first. ## Documentation; - Document the `index_*` methods / joins; - Translate the _Hail Overview_ tutorial; - Make new tutorials to replace the 2 expr ones we have; - Fill in docs on api2 methods (they're not all there yet); - Fill in docs on expression language (things like __mul__ on NumericExpression haven't been documented); - Write ""integrative docs"" that provide how-tos for common types of workflows. Show the power of annotate / select / group_by/aggregate, etc. ## Longer term QoL:; - Move over tests to Python as much as possible. I looked at the linear regression suite and it can be moved entirely into Python without many problems.; - Write a type parser in Python. The nested calls into the JVM for Type._from_java make the library feel extremely sluggish on teensy data.; - Integrate RV with C/C++, so we can transmit data much more efficiently between Python and Java.; - Rethink the expr language function registry, because many functions there can be implemented in terms of others in Python.; - add back in de novo",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2588#issuecomment-352190554
https://github.com/hail-is/hail/pull/2588#issuecomment-352190554:1650,Energy Efficiency,power,power,1650,"not moved to table there. Same needs to be done for VDS, this isn't too hard); - Add the non-core methods to `hail.methods` / `hail.genetics.methods`; - some stuff here is much harder than the rest, like `filter_alleles`; - This is mostly just labor, but some require more thought than others, like moving TDT to use hail2 expr; - Support intervals in the `index_*` methods. It's possible now to join by locus, but not using the `annotateLociTable` fast path.; - Move to Python 3 so argument order is preserved; - Test the hail2 api much more rigorously than we do now (at the very least, call each parameter branch for each method!; - Typecheck the expression language. This isn't super trivial, and making a nice system to integrate our `typecheck` module and expressions will require some thoughtful design work.; - Some more organization around the package: monkey patching with `import hail.genetics` is an idea I like, but want to think about the edge cases first. ## Documentation; - Document the `index_*` methods / joins; - Translate the _Hail Overview_ tutorial; - Make new tutorials to replace the 2 expr ones we have; - Fill in docs on api2 methods (they're not all there yet); - Fill in docs on expression language (things like __mul__ on NumericExpression haven't been documented); - Write ""integrative docs"" that provide how-tos for common types of workflows. Show the power of annotate / select / group_by/aggregate, etc. ## Longer term QoL:; - Move over tests to Python as much as possible. I looked at the linear regression suite and it can be moved entirely into Python without many problems.; - Write a type parser in Python. The nested calls into the JVM for Type._from_java make the library feel extremely sluggish on teensy data.; - Integrate RV with C/C++, so we can transmit data much more efficiently between Python and Java.; - Rethink the expr language function registry, because many functions there can be implemented in terms of others in Python.; - add back in de novo",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2588#issuecomment-352190554
https://github.com/hail-is/hail/pull/2588#issuecomment-352190554:2081,Energy Efficiency,efficient,efficiently,2081,"not moved to table there. Same needs to be done for VDS, this isn't too hard); - Add the non-core methods to `hail.methods` / `hail.genetics.methods`; - some stuff here is much harder than the rest, like `filter_alleles`; - This is mostly just labor, but some require more thought than others, like moving TDT to use hail2 expr; - Support intervals in the `index_*` methods. It's possible now to join by locus, but not using the `annotateLociTable` fast path.; - Move to Python 3 so argument order is preserved; - Test the hail2 api much more rigorously than we do now (at the very least, call each parameter branch for each method!; - Typecheck the expression language. This isn't super trivial, and making a nice system to integrate our `typecheck` module and expressions will require some thoughtful design work.; - Some more organization around the package: monkey patching with `import hail.genetics` is an idea I like, but want to think about the edge cases first. ## Documentation; - Document the `index_*` methods / joins; - Translate the _Hail Overview_ tutorial; - Make new tutorials to replace the 2 expr ones we have; - Fill in docs on api2 methods (they're not all there yet); - Fill in docs on expression language (things like __mul__ on NumericExpression haven't been documented); - Write ""integrative docs"" that provide how-tos for common types of workflows. Show the power of annotate / select / group_by/aggregate, etc. ## Longer term QoL:; - Move over tests to Python as much as possible. I looked at the linear regression suite and it can be moved entirely into Python without many problems.; - Write a type parser in Python. The nested calls into the JVM for Type._from_java make the library feel extremely sluggish on teensy data.; - Integrate RV with C/C++, so we can transmit data much more efficiently between Python and Java.; - Rethink the expr language function registry, because many functions there can be implemented in terms of others in Python.; - add back in de novo",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2588#issuecomment-352190554
https://github.com/hail-is/hail/pull/2588#issuecomment-352190554:991,Integrability,integrat,integrate,991,"y current rough list of things to be done before hail2 is as usable as hail1. It's still pretty long!. ## Necessary code work:; - Add the rest of the core methods from VDS/KT to api2 (#2591 does most for KT, order_by is the only outstanding KT method that's not moved to table there. Same needs to be done for VDS, this isn't too hard); - Add the non-core methods to `hail.methods` / `hail.genetics.methods`; - some stuff here is much harder than the rest, like `filter_alleles`; - This is mostly just labor, but some require more thought than others, like moving TDT to use hail2 expr; - Support intervals in the `index_*` methods. It's possible now to join by locus, but not using the `annotateLociTable` fast path.; - Move to Python 3 so argument order is preserved; - Test the hail2 api much more rigorously than we do now (at the very least, call each parameter branch for each method!; - Typecheck the expression language. This isn't super trivial, and making a nice system to integrate our `typecheck` module and expressions will require some thoughtful design work.; - Some more organization around the package: monkey patching with `import hail.genetics` is an idea I like, but want to think about the edge cases first. ## Documentation; - Document the `index_*` methods / joins; - Translate the _Hail Overview_ tutorial; - Make new tutorials to replace the 2 expr ones we have; - Fill in docs on api2 methods (they're not all there yet); - Fill in docs on expression language (things like __mul__ on NumericExpression haven't been documented); - Write ""integrative docs"" that provide how-tos for common types of workflows. Show the power of annotate / select / group_by/aggregate, etc. ## Longer term QoL:; - Move over tests to Python as much as possible. I looked at the linear regression suite and it can be moved entirely into Python without many problems.; - Write a type parser in Python. The nested calls into the JVM for Type._from_java make the library feel extremely sluggish on tee",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2588#issuecomment-352190554
https://github.com/hail-is/hail/pull/2588#issuecomment-352190554:1571,Integrability,integrat,integrative,1571,"not moved to table there. Same needs to be done for VDS, this isn't too hard); - Add the non-core methods to `hail.methods` / `hail.genetics.methods`; - some stuff here is much harder than the rest, like `filter_alleles`; - This is mostly just labor, but some require more thought than others, like moving TDT to use hail2 expr; - Support intervals in the `index_*` methods. It's possible now to join by locus, but not using the `annotateLociTable` fast path.; - Move to Python 3 so argument order is preserved; - Test the hail2 api much more rigorously than we do now (at the very least, call each parameter branch for each method!; - Typecheck the expression language. This isn't super trivial, and making a nice system to integrate our `typecheck` module and expressions will require some thoughtful design work.; - Some more organization around the package: monkey patching with `import hail.genetics` is an idea I like, but want to think about the edge cases first. ## Documentation; - Document the `index_*` methods / joins; - Translate the _Hail Overview_ tutorial; - Make new tutorials to replace the 2 expr ones we have; - Fill in docs on api2 methods (they're not all there yet); - Fill in docs on expression language (things like __mul__ on NumericExpression haven't been documented); - Write ""integrative docs"" that provide how-tos for common types of workflows. Show the power of annotate / select / group_by/aggregate, etc. ## Longer term QoL:; - Move over tests to Python as much as possible. I looked at the linear regression suite and it can be moved entirely into Python without many problems.; - Write a type parser in Python. The nested calls into the JVM for Type._from_java make the library feel extremely sluggish on teensy data.; - Integrate RV with C/C++, so we can transmit data much more efficiently between Python and Java.; - Rethink the expr language function registry, because many functions there can be implemented in terms of others in Python.; - add back in de novo",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2588#issuecomment-352190554
https://github.com/hail-is/hail/pull/2588#issuecomment-352190554:2022,Integrability,Integrat,Integrate,2022,"not moved to table there. Same needs to be done for VDS, this isn't too hard); - Add the non-core methods to `hail.methods` / `hail.genetics.methods`; - some stuff here is much harder than the rest, like `filter_alleles`; - This is mostly just labor, but some require more thought than others, like moving TDT to use hail2 expr; - Support intervals in the `index_*` methods. It's possible now to join by locus, but not using the `annotateLociTable` fast path.; - Move to Python 3 so argument order is preserved; - Test the hail2 api much more rigorously than we do now (at the very least, call each parameter branch for each method!; - Typecheck the expression language. This isn't super trivial, and making a nice system to integrate our `typecheck` module and expressions will require some thoughtful design work.; - Some more organization around the package: monkey patching with `import hail.genetics` is an idea I like, but want to think about the edge cases first. ## Documentation; - Document the `index_*` methods / joins; - Translate the _Hail Overview_ tutorial; - Make new tutorials to replace the 2 expr ones we have; - Fill in docs on api2 methods (they're not all there yet); - Fill in docs on expression language (things like __mul__ on NumericExpression haven't been documented); - Write ""integrative docs"" that provide how-tos for common types of workflows. Show the power of annotate / select / group_by/aggregate, etc. ## Longer term QoL:; - Move over tests to Python as much as possible. I looked at the linear regression suite and it can be moved entirely into Python without many problems.; - Write a type parser in Python. The nested calls into the JVM for Type._from_java make the library feel extremely sluggish on teensy data.; - Integrate RV with C/C++, so we can transmit data much more efficiently between Python and Java.; - Rethink the expr language function registry, because many functions there can be implemented in terms of others in Python.; - add back in de novo",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2588#issuecomment-352190554
https://github.com/hail-is/hail/pull/2588#issuecomment-352190554:780,Testability,Test,Test,780,"Here's my current rough list of things to be done before hail2 is as usable as hail1. It's still pretty long!. ## Necessary code work:; - Add the rest of the core methods from VDS/KT to api2 (#2591 does most for KT, order_by is the only outstanding KT method that's not moved to table there. Same needs to be done for VDS, this isn't too hard); - Add the non-core methods to `hail.methods` / `hail.genetics.methods`; - some stuff here is much harder than the rest, like `filter_alleles`; - This is mostly just labor, but some require more thought than others, like moving TDT to use hail2 expr; - Support intervals in the `index_*` methods. It's possible now to join by locus, but not using the `annotateLociTable` fast path.; - Move to Python 3 so argument order is preserved; - Test the hail2 api much more rigorously than we do now (at the very least, call each parameter branch for each method!; - Typecheck the expression language. This isn't super trivial, and making a nice system to integrate our `typecheck` module and expressions will require some thoughtful design work.; - Some more organization around the package: monkey patching with `import hail.genetics` is an idea I like, but want to think about the edge cases first. ## Documentation; - Document the `index_*` methods / joins; - Translate the _Hail Overview_ tutorial; - Make new tutorials to replace the 2 expr ones we have; - Fill in docs on api2 methods (they're not all there yet); - Fill in docs on expression language (things like __mul__ on NumericExpression haven't been documented); - Write ""integrative docs"" that provide how-tos for common types of workflows. Show the power of annotate / select / group_by/aggregate, etc. ## Longer term QoL:; - Move over tests to Python as much as possible. I looked at the linear regression suite and it can be moved entirely into Python without many problems.; - Write a type parser in Python. The nested calls into the JVM for Type._from_java make the library feel extremely sluggis",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2588#issuecomment-352190554
https://github.com/hail-is/hail/pull/2588#issuecomment-352190554:1737,Testability,test,tests,1737,"not moved to table there. Same needs to be done for VDS, this isn't too hard); - Add the non-core methods to `hail.methods` / `hail.genetics.methods`; - some stuff here is much harder than the rest, like `filter_alleles`; - This is mostly just labor, but some require more thought than others, like moving TDT to use hail2 expr; - Support intervals in the `index_*` methods. It's possible now to join by locus, but not using the `annotateLociTable` fast path.; - Move to Python 3 so argument order is preserved; - Test the hail2 api much more rigorously than we do now (at the very least, call each parameter branch for each method!; - Typecheck the expression language. This isn't super trivial, and making a nice system to integrate our `typecheck` module and expressions will require some thoughtful design work.; - Some more organization around the package: monkey patching with `import hail.genetics` is an idea I like, but want to think about the edge cases first. ## Documentation; - Document the `index_*` methods / joins; - Translate the _Hail Overview_ tutorial; - Make new tutorials to replace the 2 expr ones we have; - Fill in docs on api2 methods (they're not all there yet); - Fill in docs on expression language (things like __mul__ on NumericExpression haven't been documented); - Write ""integrative docs"" that provide how-tos for common types of workflows. Show the power of annotate / select / group_by/aggregate, etc. ## Longer term QoL:; - Move over tests to Python as much as possible. I looked at the linear regression suite and it can be moved entirely into Python without many problems.; - Write a type parser in Python. The nested calls into the JVM for Type._from_java make the library feel extremely sluggish on teensy data.; - Integrate RV with C/C++, so we can transmit data much more efficiently between Python and Java.; - Rethink the expr language function registry, because many functions there can be implemented in terms of others in Python.; - add back in de novo",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2588#issuecomment-352190554
https://github.com/hail-is/hail/pull/2588#issuecomment-352190554:69,Usability,usab,usable,69,"Here's my current rough list of things to be done before hail2 is as usable as hail1. It's still pretty long!. ## Necessary code work:; - Add the rest of the core methods from VDS/KT to api2 (#2591 does most for KT, order_by is the only outstanding KT method that's not moved to table there. Same needs to be done for VDS, this isn't too hard); - Add the non-core methods to `hail.methods` / `hail.genetics.methods`; - some stuff here is much harder than the rest, like `filter_alleles`; - This is mostly just labor, but some require more thought than others, like moving TDT to use hail2 expr; - Support intervals in the `index_*` methods. It's possible now to join by locus, but not using the `annotateLociTable` fast path.; - Move to Python 3 so argument order is preserved; - Test the hail2 api much more rigorously than we do now (at the very least, call each parameter branch for each method!; - Typecheck the expression language. This isn't super trivial, and making a nice system to integrate our `typecheck` module and expressions will require some thoughtful design work.; - Some more organization around the package: monkey patching with `import hail.genetics` is an idea I like, but want to think about the edge cases first. ## Documentation; - Document the `index_*` methods / joins; - Translate the _Hail Overview_ tutorial; - Make new tutorials to replace the 2 expr ones we have; - Fill in docs on api2 methods (they're not all there yet); - Fill in docs on expression language (things like __mul__ on NumericExpression haven't been documented); - Write ""integrative docs"" that provide how-tos for common types of workflows. Show the power of annotate / select / group_by/aggregate, etc. ## Longer term QoL:; - Move over tests to Python as much as possible. I looked at the linear regression suite and it can be moved entirely into Python without many problems.; - Write a type parser in Python. The nested calls into the JVM for Type._from_java make the library feel extremely sluggis",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2588#issuecomment-352190554
https://github.com/hail-is/hail/pull/2590#issuecomment-352192930:40,Testability,test,tests,40,"I'm happy with this. And as we move our tests out of Scala and into Python, things will make even more sense.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2590#issuecomment-352192930
https://github.com/hail-is/hail/pull/2590#issuecomment-352193460:16,Testability,test,tests,16,"Good point, re: tests. OK, I'll go ahead and do the rest of the methods.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2590#issuecomment-352193460
https://github.com/hail-is/hail/pull/2591#issuecomment-353443048:0,Integrability,Depend,Depends,0,Depends on bug fix in #2620,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2591#issuecomment-353443048
https://github.com/hail-is/hail/issues/2604#issuecomment-354512643:145,Modifiability,config,config,145,"I've verified that the latest devel Python zip doesn't have hail2. When I `gradle archiveZip` locally, I do have hail2. Odd... I'll look into CI config.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2604#issuecomment-354512643
https://github.com/hail-is/hail/pull/2605#issuecomment-352825562:18,Testability,test,tests,18,I've expanded the tests and fixed the join logic. It'll be much easier to test when we can easily define our own row/col keys with the `annotate/select` methods.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2605#issuecomment-352825562
https://github.com/hail-is/hail/pull/2605#issuecomment-352825562:43,Testability,log,logic,43,I've expanded the tests and fixed the join logic. It'll be much easier to test when we can easily define our own row/col keys with the `annotate/select` methods.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2605#issuecomment-352825562
https://github.com/hail-is/hail/pull/2605#issuecomment-352825562:74,Testability,test,test,74,I've expanded the tests and fixed the join logic. It'll be much easier to test when we can easily define our own row/col keys with the `annotate/select` methods.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2605#issuecomment-352825562
https://github.com/hail-is/hail/pull/2622#issuecomment-353471832:0,Integrability,Depend,Depends,0,"Depends on #2619 (already approved, will go in soon)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2622#issuecomment-353471832
https://github.com/hail-is/hail/pull/2623#issuecomment-358755729:7,Availability,ping,ping,7,@cseed ping,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2623#issuecomment-358755729
https://github.com/hail-is/hail/pull/2623#issuecomment-359107778:7,Availability,ping,ping,7,@cseed ping,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2623#issuecomment-359107778
https://github.com/hail-is/hail/pull/2623#issuecomment-359279810:36,Usability,simpl,simplify,36,"One more thing: I feel like you can simplify some additional stuff by getting rid of the T parameter on CodeAggregator and call the invoke instance that takes arrays of `Class`es and `Code`s. That way, you don't have to track T. Again, I think you can get the necessary types from the ApplyAggOp instance.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2623#issuecomment-359279810
https://github.com/hail-is/hail/pull/2623#issuecomment-359557958:167,Safety,avoid,avoiding,167,"Ah, yeah it looks a fair bit better now that I pushed the all-arity AggOp all the way through. To remove `T`, I need to a `Type => Class[_]` function, which I've been avoiding. I did manage to remove the whole `[Nothing]` hack without doing this though.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2623#issuecomment-359557958
https://github.com/hail-is/hail/pull/2623#issuecomment-359558221:31,Safety,avoid,avoiding,31,I don't have a good reason for avoiding `Type => Class[_]` it just feels wrong somehow. I think: non-primitive types have Scala reifications that we never want to produce.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2623#issuecomment-359558221
https://github.com/hail-is/hail/pull/2628#issuecomment-354845912:24,Performance,perform,performance,24,"closing while I compare performance to filter(rows, cols) in new branch",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2628#issuecomment-354845912
https://github.com/hail-is/hail/pull/2630#issuecomment-353794485:105,Testability,test,test,105,@tpoterba I didn't see that you fixed this already. I was going to make a PR that includes an additional test. Please add the test to your commit or I can make a separate PR. https://github.com/jigold/hail/commit/024482f2917ee887542c90219b60aa67c9e96f5d,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2630#issuecomment-353794485
https://github.com/hail-is/hail/pull/2630#issuecomment-353794485:126,Testability,test,test,126,@tpoterba I didn't see that you fixed this already. I was going to make a PR that includes an additional test. Please add the test to your commit or I can make a separate PR. https://github.com/jigold/hail/commit/024482f2917ee887542c90219b60aa67c9e96f5d,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2630#issuecomment-353794485
https://github.com/hail-is/hail/pull/2630#issuecomment-353795965:14,Testability,test,test,14,I'll add your test on my branch. Sorry for the communication breakdown!,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2630#issuecomment-353795965
https://github.com/hail-is/hail/pull/2630#issuecomment-353816303:15,Testability,test,test,15,Added Jackie's test!,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2630#issuecomment-353816303
https://github.com/hail-is/hail/pull/2637#issuecomment-354891277:214,Availability,error,errors,214,"That's handled in the typechecker on `StringExpression.matches` -- we don't generate `RegexMatch` AST nodes anywhere else. However, there's still a problem that I haven't yet resolved -- it's possible to get parse errors if the string given doesn't parse to a valid 0.1-expr-language string literal. I think there might be additional unescaping going on somewhere in the python/java connector. Still, I think we should merge this in and figure out how to solve this problem later.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2637#issuecomment-354891277
https://github.com/hail-is/hail/pull/2638#issuecomment-356122522:321,Testability,test,test,321,"@cseed I moved unwrapping of the nested insert before the TableAnnotate node, as we talked about. The code is pretty messy and I'm still tidying it up, but it's now there if you wanted to take a look. re: splats---I talked to Tim about this earlier and he didn't think that annotate needed to support them, but I added a test case anyway and it seems to work fine.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2638#issuecomment-356122522
https://github.com/hail-is/hail/pull/2639#issuecomment-356088106:47,Integrability,depend,dependency,47,2.1.0 test was removed from CI (and as a merge dependency),MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2639#issuecomment-356088106
https://github.com/hail-is/hail/pull/2639#issuecomment-356088106:6,Testability,test,test,6,2.1.0 test was removed from CI (and as a merge dependency),MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2639#issuecomment-356088106
https://github.com/hail-is/hail/pull/2649#issuecomment-355347069:62,Performance,optimiz,optimized,62,"I was going to suggest we leave this out for 0.2. With better-optimized tables, there will be very little reason to have one-dimensional matrices.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2649#issuecomment-355347069
https://github.com/hail-is/hail/pull/2649#issuecomment-355362499:167,Integrability,interface,interface,167,"I'm obviously sympathetic to this (I've even argued matrix should not have row/col annotations at all!) But I have a few questions about how this will work:. The main interface problem I see is that there are naturally columnless matrices in our domain (sites files). This PR was motivated by some code that Konrad sent me. Are we going to have two versions of VEP and export_vcf, for example?. Second, it seems we can have either interface purity or performance in the short term. I loosely think the latter is better (I would) so we can productively move people off 0.1 even if that means the interface is less stable (e.g. eventually we'll deprecate/remove the drop functions). I want to say I can be convinced otherwise, but changing a range join to a table shuffle seems like a non-starter.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2649#issuecomment-355362499
https://github.com/hail-is/hail/pull/2649#issuecomment-355362499:431,Integrability,interface,interface,431,"I'm obviously sympathetic to this (I've even argued matrix should not have row/col annotations at all!) But I have a few questions about how this will work:. The main interface problem I see is that there are naturally columnless matrices in our domain (sites files). This PR was motivated by some code that Konrad sent me. Are we going to have two versions of VEP and export_vcf, for example?. Second, it seems we can have either interface purity or performance in the short term. I loosely think the latter is better (I would) so we can productively move people off 0.1 even if that means the interface is less stable (e.g. eventually we'll deprecate/remove the drop functions). I want to say I can be convinced otherwise, but changing a range join to a table shuffle seems like a non-starter.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2649#issuecomment-355362499
https://github.com/hail-is/hail/pull/2649#issuecomment-355362499:595,Integrability,interface,interface,595,"I'm obviously sympathetic to this (I've even argued matrix should not have row/col annotations at all!) But I have a few questions about how this will work:. The main interface problem I see is that there are naturally columnless matrices in our domain (sites files). This PR was motivated by some code that Konrad sent me. Are we going to have two versions of VEP and export_vcf, for example?. Second, it seems we can have either interface purity or performance in the short term. I loosely think the latter is better (I would) so we can productively move people off 0.1 even if that means the interface is less stable (e.g. eventually we'll deprecate/remove the drop functions). I want to say I can be convinced otherwise, but changing a range join to a table shuffle seems like a non-starter.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2649#issuecomment-355362499
https://github.com/hail-is/hail/pull/2649#issuecomment-355362499:451,Performance,perform,performance,451,"I'm obviously sympathetic to this (I've even argued matrix should not have row/col annotations at all!) But I have a few questions about how this will work:. The main interface problem I see is that there are naturally columnless matrices in our domain (sites files). This PR was motivated by some code that Konrad sent me. Are we going to have two versions of VEP and export_vcf, for example?. Second, it seems we can have either interface purity or performance in the short term. I loosely think the latter is better (I would) so we can productively move people off 0.1 even if that means the interface is less stable (e.g. eventually we'll deprecate/remove the drop functions). I want to say I can be convinced otherwise, but changing a range join to a table shuffle seems like a non-starter.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2649#issuecomment-355362499
https://github.com/hail-is/hail/pull/2649#issuecomment-355363719:74,Deployability,release,released,74,"Alright, I'm OK with that. Let's see if we can remove these before 0.2 is released. If not, that's fine too.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2649#issuecomment-355363719
https://github.com/hail-is/hail/pull/2650#issuecomment-355372066:136,Performance,load,load,136,"@tpoterba FYI, I added MatrixTable._same (I never thought that should be user-visible.) and set min_block_size=0 in the tests so we can load sample.vcf with more than one partition. Let me know if you have objections.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2650#issuecomment-355372066
https://github.com/hail-is/hail/pull/2650#issuecomment-355372066:120,Testability,test,tests,120,"@tpoterba FYI, I added MatrixTable._same (I never thought that should be user-visible.) and set min_block_size=0 in the tests so we can load sample.vcf with more than one partition. Let me know if you have objections.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2650#issuecomment-355372066
https://github.com/hail-is/hail/issues/2653#issuecomment-355436505:57,Deployability,patch,patch,57,"yeah, if/else should be wrapped in parens. Will submit a patch.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2653#issuecomment-355436505
https://github.com/hail-is/hail/issues/2653#issuecomment-355436505:24,Integrability,wrap,wrapped,24,"yeah, if/else should be wrapped in parens. Will submit a patch.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2653#issuecomment-355436505
https://github.com/hail-is/hail/pull/2656#issuecomment-355463197:24,Deployability,deploy,deployed,24,Also removed 2.1.0 from deployed versions. When this goes in I'll remove the CI tests againt 2.1.0.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2656#issuecomment-355463197
https://github.com/hail-is/hail/pull/2656#issuecomment-355463197:80,Testability,test,tests,80,Also removed 2.1.0 from deployed versions. When this goes in I'll remove the CI tests againt 2.1.0.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2656#issuecomment-355463197
https://github.com/hail-is/hail/pull/2656#issuecomment-355617537:56,Deployability,patch,patch,56,"So overall plan is:. - get 2.2.0 build support in (this patch); - stop testing 2.1.0 once it isn't being deployed,; - start testing 2.2.0 (I will need to update the CI image to install Spark 2.2.0),; - add 2.2.0 to the list of deployed versions,; - make Spark 2.2.0/Dataproc 1.2 the version in cloudtools,; - drop testing/deploy support for 2.0.2. Did I miss anything?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2656#issuecomment-355617537
https://github.com/hail-is/hail/pull/2656#issuecomment-355617537:105,Deployability,deploy,deployed,105,"So overall plan is:. - get 2.2.0 build support in (this patch); - stop testing 2.1.0 once it isn't being deployed,; - start testing 2.2.0 (I will need to update the CI image to install Spark 2.2.0),; - add 2.2.0 to the list of deployed versions,; - make Spark 2.2.0/Dataproc 1.2 the version in cloudtools,; - drop testing/deploy support for 2.0.2. Did I miss anything?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2656#issuecomment-355617537
https://github.com/hail-is/hail/pull/2656#issuecomment-355617537:154,Deployability,update,update,154,"So overall plan is:. - get 2.2.0 build support in (this patch); - stop testing 2.1.0 once it isn't being deployed,; - start testing 2.2.0 (I will need to update the CI image to install Spark 2.2.0),; - add 2.2.0 to the list of deployed versions,; - make Spark 2.2.0/Dataproc 1.2 the version in cloudtools,; - drop testing/deploy support for 2.0.2. Did I miss anything?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2656#issuecomment-355617537
https://github.com/hail-is/hail/pull/2656#issuecomment-355617537:177,Deployability,install,install,177,"So overall plan is:. - get 2.2.0 build support in (this patch); - stop testing 2.1.0 once it isn't being deployed,; - start testing 2.2.0 (I will need to update the CI image to install Spark 2.2.0),; - add 2.2.0 to the list of deployed versions,; - make Spark 2.2.0/Dataproc 1.2 the version in cloudtools,; - drop testing/deploy support for 2.0.2. Did I miss anything?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2656#issuecomment-355617537
https://github.com/hail-is/hail/pull/2656#issuecomment-355617537:227,Deployability,deploy,deployed,227,"So overall plan is:. - get 2.2.0 build support in (this patch); - stop testing 2.1.0 once it isn't being deployed,; - start testing 2.2.0 (I will need to update the CI image to install Spark 2.2.0),; - add 2.2.0 to the list of deployed versions,; - make Spark 2.2.0/Dataproc 1.2 the version in cloudtools,; - drop testing/deploy support for 2.0.2. Did I miss anything?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2656#issuecomment-355617537
https://github.com/hail-is/hail/pull/2656#issuecomment-355617537:322,Deployability,deploy,deploy,322,"So overall plan is:. - get 2.2.0 build support in (this patch); - stop testing 2.1.0 once it isn't being deployed,; - start testing 2.2.0 (I will need to update the CI image to install Spark 2.2.0),; - add 2.2.0 to the list of deployed versions,; - make Spark 2.2.0/Dataproc 1.2 the version in cloudtools,; - drop testing/deploy support for 2.0.2. Did I miss anything?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2656#issuecomment-355617537
https://github.com/hail-is/hail/pull/2656#issuecomment-355617537:71,Testability,test,testing,71,"So overall plan is:. - get 2.2.0 build support in (this patch); - stop testing 2.1.0 once it isn't being deployed,; - start testing 2.2.0 (I will need to update the CI image to install Spark 2.2.0),; - add 2.2.0 to the list of deployed versions,; - make Spark 2.2.0/Dataproc 1.2 the version in cloudtools,; - drop testing/deploy support for 2.0.2. Did I miss anything?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2656#issuecomment-355617537
https://github.com/hail-is/hail/pull/2656#issuecomment-355617537:124,Testability,test,testing,124,"So overall plan is:. - get 2.2.0 build support in (this patch); - stop testing 2.1.0 once it isn't being deployed,; - start testing 2.2.0 (I will need to update the CI image to install Spark 2.2.0),; - add 2.2.0 to the list of deployed versions,; - make Spark 2.2.0/Dataproc 1.2 the version in cloudtools,; - drop testing/deploy support for 2.0.2. Did I miss anything?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2656#issuecomment-355617537
https://github.com/hail-is/hail/pull/2656#issuecomment-355617537:314,Testability,test,testing,314,"So overall plan is:. - get 2.2.0 build support in (this patch); - stop testing 2.1.0 once it isn't being deployed,; - start testing 2.2.0 (I will need to update the CI image to install Spark 2.2.0),; - add 2.2.0 to the list of deployed versions,; - make Spark 2.2.0/Dataproc 1.2 the version in cloudtools,; - drop testing/deploy support for 2.0.2. Did I miss anything?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2656#issuecomment-355617537
https://github.com/hail-is/hail/pull/2657#issuecomment-356039630:34,Performance,queue,queue,34,"Ready for another look, I rewrote queue as a linked list. I'll add `linkedlistof()` typecheckers later, when we fix the typecheck copying problem.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2657#issuecomment-356039630
https://github.com/hail-is/hail/pull/2659#issuecomment-355762347:0,Integrability,Depend,Depends,0,Depends on #2657,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2659#issuecomment-355762347
https://github.com/hail-is/hail/pull/2662#issuecomment-355769072:48,Testability,test,test,48,"On second thought, should there be at least one test where `expr != None`?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2662#issuecomment-355769072
https://github.com/hail-is/hail/pull/2662#issuecomment-355776793:8,Testability,test,test,8,added a test.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2662#issuecomment-355776793
https://github.com/hail-is/hail/pull/2662#issuecomment-355830837:28,Testability,test,test,28,"good call on requesting the test, it was broken!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2662#issuecomment-355830837
https://github.com/hail-is/hail/pull/2664#issuecomment-355828218:90,Energy Efficiency,efficient,efficiently,90,"We need to expand union_cols (previously join) to take varargs of dataset, and to execute efficiently.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2664#issuecomment-355828218
https://github.com/hail-is/hail/pull/2697#issuecomment-357055805:38,Testability,test,test,38,"@tpoterba @jbloom22 I figured out the test problem---GRM currently filters out all variants that are all gt=0 or gt=2, which is not what the old code did. (The old code kept them in as all-zero rows). This means that the number of variants used to scale the the normalized genotypes is different, and so that's why we were seeing the different behavior against PLINK. I don't particularly want to count the old dataset pre-filter, and this is what we're doing for PCA, so I think that it's probably the correct thing to do in this case, also. Maybe I can just put a note in the docs that grm will filter out all monomorphic sites?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2697#issuecomment-357055805
https://github.com/hail-is/hail/pull/2701#issuecomment-357036272:9,Integrability,interface,interface,9,Docs and interface looks good to me!,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2701#issuecomment-357036272
https://github.com/hail-is/hail/pull/2701#issuecomment-357081571:110,Usability,intuit,intuitive,110,"Ok, I like all but `view_join_X` - I hate it less than what it was before (i.e. `index_X`) but it's not super intuitive",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2701#issuecomment-357081571
https://github.com/hail-is/hail/pull/2701#issuecomment-357081710:44,Security,expose,exposed,44,"yeah, still deciding if that should even be exposed.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2701#issuecomment-357081710
https://github.com/hail-is/hail/pull/2722#issuecomment-358198437:95,Availability,failure,failure,95,"Fails with:; ```; Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 491 in stage 1.0 failed 20 times, most recent failure: Lost task 491.19 in stage 1.0 (TID 17951, exomes-sw-gf9k.c.broad-mpg-gnomad.internal): java.lang.IndexOutOfBoundsException: 3; 	at is.hail.annotations.UnsafeRow.isNullAt(UnsafeRow.scala:294); 	at is.hail.annotations.UnsafeRow.get(UnsafeRow.scala:254); 	at is.hail.variant.MatrixTable$$anonfun$59$$anonfun$apply$42.apply(MatrixTable.scala:871); 	at is.hail.variant.MatrixTable$$anonfun$59$$anonfun$apply$42.apply(MatrixTable.scala:860); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.next(OrderedRVD.scala:637); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.next(OrderedRVD.scala:631); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.foreach(OrderedRVD.scala:631); 	at is.hail.io.RichRDDRegionValue$.writeRowsPartition(RowStore.scala:510); 	at is.hail.io.RichRDDRegionValue$$anonfun$writeRows$extension$1.apply(RowStore.scala:526); 	at is.hail.io.RichRDDRegionValue$$anonfun$writeRows$extension$1.apply(RowStore.scala:526); 	at is.hail.utils.richUtils.RichRDD$$anonfun$5.apply(RichRDD.scala:207); 	at is.hail.utils.richUtils.RichRDD$$anonfun$5.apply(RichRDD.scala:198); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:820); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:820); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2722#issuecomment-358198437
https://github.com/hail-is/hail/pull/2722#issuecomment-358198437:155,Availability,failure,failure,155,"Fails with:; ```; Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 491 in stage 1.0 failed 20 times, most recent failure: Lost task 491.19 in stage 1.0 (TID 17951, exomes-sw-gf9k.c.broad-mpg-gnomad.internal): java.lang.IndexOutOfBoundsException: 3; 	at is.hail.annotations.UnsafeRow.isNullAt(UnsafeRow.scala:294); 	at is.hail.annotations.UnsafeRow.get(UnsafeRow.scala:254); 	at is.hail.variant.MatrixTable$$anonfun$59$$anonfun$apply$42.apply(MatrixTable.scala:871); 	at is.hail.variant.MatrixTable$$anonfun$59$$anonfun$apply$42.apply(MatrixTable.scala:860); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.next(OrderedRVD.scala:637); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.next(OrderedRVD.scala:631); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.foreach(OrderedRVD.scala:631); 	at is.hail.io.RichRDDRegionValue$.writeRowsPartition(RowStore.scala:510); 	at is.hail.io.RichRDDRegionValue$$anonfun$writeRows$extension$1.apply(RowStore.scala:526); 	at is.hail.io.RichRDDRegionValue$$anonfun$writeRows$extension$1.apply(RowStore.scala:526); 	at is.hail.utils.richUtils.RichRDD$$anonfun$5.apply(RichRDD.scala:207); 	at is.hail.utils.richUtils.RichRDD$$anonfun$5.apply(RichRDD.scala:198); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:820); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:820); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2722#issuecomment-358198437
https://github.com/hail-is/hail/pull/2722#issuecomment-358198437:7097,Availability,Error,Error,7097,"ow.get(UnsafeRow.scala:254); 	at is.hail.variant.MatrixTable$$anonfun$59$$anonfun$apply$42.apply(MatrixTable.scala:871); 	at is.hail.variant.MatrixTable$$anonfun$59$$anonfun$apply$42.apply(MatrixTable.scala:860); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.next(OrderedRVD.scala:637); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.next(OrderedRVD.scala:631); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.foreach(OrderedRVD.scala:631); 	at is.hail.io.RichRDDRegionValue$.writeRowsPartition(RowStore.scala:510); 	at is.hail.io.RichRDDRegionValue$$anonfun$writeRows$extension$1.apply(RowStore.scala:526); 	at is.hail.io.RichRDDRegionValue$$anonfun$writeRows$extension$1.apply(RowStore.scala:526); 	at is.hail.utils.richUtils.RichRDD$$anonfun$5.apply(RichRDD.scala:207); 	at is.hail.utils.richUtils.RichRDD$$anonfun$5.apply(RichRDD.scala:198); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:820); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:820); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). Hail version: devel-df17cef; Error summary: IndexOutOfBoundsException: 3; ```; (NB: a custom VEP/LOFTEE, but that shouldn't matter - ran same thing on `devel-cd48e11` and it worked fine)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2722#issuecomment-358198437
https://github.com/hail-is/hail/pull/2722#issuecomment-358198437:1806,Energy Efficiency,schedul,scheduler,1806,D.scala:631); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.foreach(OrderedRVD.scala:631); 	at is.hail.io.RichRDDRegionValue$.writeRowsPartition(RowStore.scala:510); 	at is.hail.io.RichRDDRegionValue$$anonfun$writeRows$extension$1.apply(RowStore.scala:526); 	at is.hail.io.RichRDDRegionValue$$anonfun$writeRows$extension$1.apply(RowStore.scala:526); 	at is.hail.utils.richUtils.RichRDD$$anonfun$5.apply(RichRDD.scala:207); 	at is.hail.utils.richUtils.RichRDD$$anonfun$5.apply(RichRDD.scala:198); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:820); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:820); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spa,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2722#issuecomment-358198437
https://github.com/hail-is/hail/pull/2722#issuecomment-358198437:1878,Energy Efficiency,schedul,scheduler,1878,:893); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.foreach(OrderedRVD.scala:631); 	at is.hail.io.RichRDDRegionValue$.writeRowsPartition(RowStore.scala:510); 	at is.hail.io.RichRDDRegionValue$$anonfun$writeRows$extension$1.apply(RowStore.scala:526); 	at is.hail.io.RichRDDRegionValue$$anonfun$writeRows$extension$1.apply(RowStore.scala:526); 	at is.hail.utils.richUtils.RichRDD$$anonfun$5.apply(RichRDD.scala:207); 	at is.hail.utils.richUtils.RichRDD$$anonfun$5.apply(RichRDD.scala:198); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:820); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:820); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGSchedu,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2722#issuecomment-358198437
https://github.com/hail-is/hail/pull/2722#issuecomment-358198437:2242,Energy Efficiency,schedul,scheduler,2242,ls.richUtils.RichRDD$$anonfun$5.apply(RichRDD.scala:207); 	at is.hail.utils.richUtils.RichRDD$$anonfun$5.apply(RichRDD.scala:198); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:820); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:820); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apa,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2722#issuecomment-358198437
https://github.com/hail-is/hail/pull/2722#issuecomment-358198437:2282,Energy Efficiency,schedul,scheduler,2282,at is.hail.utils.richUtils.RichRDD$$anonfun$5.apply(RichRDD.scala:198); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:820); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:820); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2722#issuecomment-358198437
https://github.com/hail-is/hail/pull/2722#issuecomment-358198437:2381,Energy Efficiency,schedul,scheduler,2381,apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:820); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:820); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProces,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2722#issuecomment-358198437
https://github.com/hail-is/hail/pull/2722#issuecomment-358198437:2479,Energy Efficiency,schedul,scheduler,2479, org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:820); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoo,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2722#issuecomment-358198437
https://github.com/hail-is/hail/pull/2722#issuecomment-358198437:2733,Energy Efficiency,schedul,scheduler,2733,.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); 	at org.apache.spark.SparkConte,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2722#issuecomment-358198437
https://github.com/hail-is/hail/pull/2722#issuecomment-358198437:2814,Energy Efficiency,schedul,scheduler,2814,ultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1899); 	at org.apache.spark.SparkContext.runJob(Spar,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2722#issuecomment-358198437
https://github.com/hail-is/hail/pull/2722#issuecomment-358198437:2920,Energy Efficiency,schedul,scheduler,2920,he.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1899); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1913); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:912); 	at org.apache,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2722#issuecomment-358198437
https://github.com/hail-is/hail/pull/2722#issuecomment-358198437:3070,Energy Efficiency,schedul,scheduler,3070,t java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1899); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1913); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:912); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:11,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2722#issuecomment-358198437
https://github.com/hail-is/hail/pull/2722#issuecomment-358198437:3159,Energy Efficiency,schedul,scheduler,3159,va.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1899); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1913); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:912); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358); 	at org.apache.spark.rdd.RDD.c,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2722#issuecomment-358198437
https://github.com/hail-is/hail/pull/2722#issuecomment-358198437:3257,Energy Efficiency,schedul,scheduler,3257,er.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1899); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1913); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:912); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358); 	at org.apache.spark.rdd.RDD.collect(RDD.scala:911); 	at is.hail.utils.richUtils.RichRDD$.writePartitions$extension(RichRDD.scal,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2722#issuecomment-358198437
https://github.com/hail-is/hail/pull/2722#issuecomment-358198437:3353,Energy Efficiency,schedul,scheduler,3353,; 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1899); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1913); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:912); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358); 	at org.apache.spark.rdd.RDD.collect(RDD.scala:911); 	at is.hail.utils.richUtils.RichRDD$.writePartitions$extension(RichRDD.scala:209); 	at is.hail.io.RichRDDRegionValue$.writeRows$extension(RowStore.scala:526); 	at is.hail.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2722#issuecomment-358198437
https://github.com/hail-is/hail/pull/2722#issuecomment-358198437:3518,Energy Efficiency,schedul,scheduler,3518,.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1899); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1913); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:912); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358); 	at org.apache.spark.rdd.RDD.collect(RDD.scala:911); 	at is.hail.utils.richUtils.RichRDD$.writePartitions$extension(RichRDD.scala:209); 	at is.hail.io.RichRDDRegionValue$.writeRows$extension(RowStore.scala:526); 	at is.hail.variant.MatrixTable.write(MatrixTable.scala:2393); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(N,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2722#issuecomment-358198437
https://github.com/hail-is/hail/pull/2722#issuecomment-358198437:6673,Energy Efficiency,schedul,scheduler,6673,"ow.get(UnsafeRow.scala:254); 	at is.hail.variant.MatrixTable$$anonfun$59$$anonfun$apply$42.apply(MatrixTable.scala:871); 	at is.hail.variant.MatrixTable$$anonfun$59$$anonfun$apply$42.apply(MatrixTable.scala:860); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.next(OrderedRVD.scala:637); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.next(OrderedRVD.scala:631); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.foreach(OrderedRVD.scala:631); 	at is.hail.io.RichRDDRegionValue$.writeRowsPartition(RowStore.scala:510); 	at is.hail.io.RichRDDRegionValue$$anonfun$writeRows$extension$1.apply(RowStore.scala:526); 	at is.hail.io.RichRDDRegionValue$$anonfun$writeRows$extension$1.apply(RowStore.scala:526); 	at is.hail.utils.richUtils.RichRDD$$anonfun$5.apply(RichRDD.scala:207); 	at is.hail.utils.richUtils.RichRDD$$anonfun$5.apply(RichRDD.scala:198); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:820); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:820); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). Hail version: devel-df17cef; Error summary: IndexOutOfBoundsException: 3; ```; (NB: a custom VEP/LOFTEE, but that shouldn't matter - ran same thing on `devel-cd48e11` and it worked fine)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2722#issuecomment-358198437
https://github.com/hail-is/hail/pull/2722#issuecomment-358198437:6745,Energy Efficiency,schedul,scheduler,6745,"ow.get(UnsafeRow.scala:254); 	at is.hail.variant.MatrixTable$$anonfun$59$$anonfun$apply$42.apply(MatrixTable.scala:871); 	at is.hail.variant.MatrixTable$$anonfun$59$$anonfun$apply$42.apply(MatrixTable.scala:860); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.next(OrderedRVD.scala:637); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.next(OrderedRVD.scala:631); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.foreach(OrderedRVD.scala:631); 	at is.hail.io.RichRDDRegionValue$.writeRowsPartition(RowStore.scala:510); 	at is.hail.io.RichRDDRegionValue$$anonfun$writeRows$extension$1.apply(RowStore.scala:526); 	at is.hail.io.RichRDDRegionValue$$anonfun$writeRows$extension$1.apply(RowStore.scala:526); 	at is.hail.utils.richUtils.RichRDD$$anonfun$5.apply(RichRDD.scala:207); 	at is.hail.utils.richUtils.RichRDD$$anonfun$5.apply(RichRDD.scala:198); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:820); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:820); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). Hail version: devel-df17cef; Error summary: IndexOutOfBoundsException: 3; ```; (NB: a custom VEP/LOFTEE, but that shouldn't matter - ran same thing on `devel-cd48e11` and it worked fine)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2722#issuecomment-358198437
https://github.com/hail-is/hail/pull/2722#issuecomment-358198437:2002,Performance,concurren,concurrent,2002,.writeRowsPartition(RowStore.scala:510); 	at is.hail.io.RichRDDRegionValue$$anonfun$writeRows$extension$1.apply(RowStore.scala:526); 	at is.hail.io.RichRDDRegionValue$$anonfun$writeRows$extension$1.apply(RowStore.scala:526); 	at is.hail.utils.richUtils.RichRDD$$anonfun$5.apply(RichRDD.scala:207); 	at is.hail.utils.richUtils.RichRDD$$anonfun$5.apply(RichRDD.scala:198); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:820); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:820); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2722#issuecomment-358198437
https://github.com/hail-is/hail/pull/2722#issuecomment-358198437:2087,Performance,concurren,concurrent,2087,riteRows$extension$1.apply(RowStore.scala:526); 	at is.hail.io.RichRDDRegionValue$$anonfun$writeRows$extension$1.apply(RowStore.scala:526); 	at is.hail.utils.richUtils.RichRDD$$anonfun$5.apply(RichRDD.scala:207); 	at is.hail.utils.richUtils.RichRDD$$anonfun$5.apply(RichRDD.scala:198); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:820); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:820); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2722#issuecomment-358198437
https://github.com/hail-is/hail/pull/2722#issuecomment-358198437:6869,Performance,concurren,concurrent,6869,"ow.get(UnsafeRow.scala:254); 	at is.hail.variant.MatrixTable$$anonfun$59$$anonfun$apply$42.apply(MatrixTable.scala:871); 	at is.hail.variant.MatrixTable$$anonfun$59$$anonfun$apply$42.apply(MatrixTable.scala:860); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.next(OrderedRVD.scala:637); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.next(OrderedRVD.scala:631); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.foreach(OrderedRVD.scala:631); 	at is.hail.io.RichRDDRegionValue$.writeRowsPartition(RowStore.scala:510); 	at is.hail.io.RichRDDRegionValue$$anonfun$writeRows$extension$1.apply(RowStore.scala:526); 	at is.hail.io.RichRDDRegionValue$$anonfun$writeRows$extension$1.apply(RowStore.scala:526); 	at is.hail.utils.richUtils.RichRDD$$anonfun$5.apply(RichRDD.scala:207); 	at is.hail.utils.richUtils.RichRDD$$anonfun$5.apply(RichRDD.scala:198); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:820); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:820); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). Hail version: devel-df17cef; Error summary: IndexOutOfBoundsException: 3; ```; (NB: a custom VEP/LOFTEE, but that shouldn't matter - ran same thing on `devel-cd48e11` and it worked fine)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2722#issuecomment-358198437
https://github.com/hail-is/hail/pull/2722#issuecomment-358198437:6954,Performance,concurren,concurrent,6954,"ow.get(UnsafeRow.scala:254); 	at is.hail.variant.MatrixTable$$anonfun$59$$anonfun$apply$42.apply(MatrixTable.scala:871); 	at is.hail.variant.MatrixTable$$anonfun$59$$anonfun$apply$42.apply(MatrixTable.scala:860); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.next(OrderedRVD.scala:637); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.next(OrderedRVD.scala:631); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.foreach(OrderedRVD.scala:631); 	at is.hail.io.RichRDDRegionValue$.writeRowsPartition(RowStore.scala:510); 	at is.hail.io.RichRDDRegionValue$$anonfun$writeRows$extension$1.apply(RowStore.scala:526); 	at is.hail.io.RichRDDRegionValue$$anonfun$writeRows$extension$1.apply(RowStore.scala:526); 	at is.hail.utils.richUtils.RichRDD$$anonfun$5.apply(RichRDD.scala:207); 	at is.hail.utils.richUtils.RichRDD$$anonfun$5.apply(RichRDD.scala:198); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:820); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:820); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). Hail version: devel-df17cef; Error summary: IndexOutOfBoundsException: 3; ```; (NB: a custom VEP/LOFTEE, but that shouldn't matter - ran same thing on `devel-cd48e11` and it worked fine)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2722#issuecomment-358198437
https://github.com/hail-is/hail/pull/2722#issuecomment-358198437:74,Safety,abort,aborted,74,"Fails with:; ```; Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 491 in stage 1.0 failed 20 times, most recent failure: Lost task 491.19 in stage 1.0 (TID 17951, exomes-sw-gf9k.c.broad-mpg-gnomad.internal): java.lang.IndexOutOfBoundsException: 3; 	at is.hail.annotations.UnsafeRow.isNullAt(UnsafeRow.scala:294); 	at is.hail.annotations.UnsafeRow.get(UnsafeRow.scala:254); 	at is.hail.variant.MatrixTable$$anonfun$59$$anonfun$apply$42.apply(MatrixTable.scala:871); 	at is.hail.variant.MatrixTable$$anonfun$59$$anonfun$apply$42.apply(MatrixTable.scala:860); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.next(OrderedRVD.scala:637); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.next(OrderedRVD.scala:631); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.foreach(OrderedRVD.scala:631); 	at is.hail.io.RichRDDRegionValue$.writeRowsPartition(RowStore.scala:510); 	at is.hail.io.RichRDDRegionValue$$anonfun$writeRows$extension$1.apply(RowStore.scala:526); 	at is.hail.io.RichRDDRegionValue$$anonfun$writeRows$extension$1.apply(RowStore.scala:526); 	at is.hail.utils.richUtils.RichRDD$$anonfun$5.apply(RichRDD.scala:207); 	at is.hail.utils.richUtils.RichRDD$$anonfun$5.apply(RichRDD.scala:198); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:820); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:820); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2722#issuecomment-358198437
https://github.com/hail-is/hail/pull/2722#issuecomment-358198437:315,Safety,Unsafe,UnsafeRow,315,"Fails with:; ```; Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 491 in stage 1.0 failed 20 times, most recent failure: Lost task 491.19 in stage 1.0 (TID 17951, exomes-sw-gf9k.c.broad-mpg-gnomad.internal): java.lang.IndexOutOfBoundsException: 3; 	at is.hail.annotations.UnsafeRow.isNullAt(UnsafeRow.scala:294); 	at is.hail.annotations.UnsafeRow.get(UnsafeRow.scala:254); 	at is.hail.variant.MatrixTable$$anonfun$59$$anonfun$apply$42.apply(MatrixTable.scala:871); 	at is.hail.variant.MatrixTable$$anonfun$59$$anonfun$apply$42.apply(MatrixTable.scala:860); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.next(OrderedRVD.scala:637); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.next(OrderedRVD.scala:631); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.foreach(OrderedRVD.scala:631); 	at is.hail.io.RichRDDRegionValue$.writeRowsPartition(RowStore.scala:510); 	at is.hail.io.RichRDDRegionValue$$anonfun$writeRows$extension$1.apply(RowStore.scala:526); 	at is.hail.io.RichRDDRegionValue$$anonfun$writeRows$extension$1.apply(RowStore.scala:526); 	at is.hail.utils.richUtils.RichRDD$$anonfun$5.apply(RichRDD.scala:207); 	at is.hail.utils.richUtils.RichRDD$$anonfun$5.apply(RichRDD.scala:198); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:820); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:820); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2722#issuecomment-358198437
https://github.com/hail-is/hail/pull/2722#issuecomment-358198437:334,Safety,Unsafe,UnsafeRow,334,"Fails with:; ```; Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 491 in stage 1.0 failed 20 times, most recent failure: Lost task 491.19 in stage 1.0 (TID 17951, exomes-sw-gf9k.c.broad-mpg-gnomad.internal): java.lang.IndexOutOfBoundsException: 3; 	at is.hail.annotations.UnsafeRow.isNullAt(UnsafeRow.scala:294); 	at is.hail.annotations.UnsafeRow.get(UnsafeRow.scala:254); 	at is.hail.variant.MatrixTable$$anonfun$59$$anonfun$apply$42.apply(MatrixTable.scala:871); 	at is.hail.variant.MatrixTable$$anonfun$59$$anonfun$apply$42.apply(MatrixTable.scala:860); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.next(OrderedRVD.scala:637); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.next(OrderedRVD.scala:631); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.foreach(OrderedRVD.scala:631); 	at is.hail.io.RichRDDRegionValue$.writeRowsPartition(RowStore.scala:510); 	at is.hail.io.RichRDDRegionValue$$anonfun$writeRows$extension$1.apply(RowStore.scala:526); 	at is.hail.io.RichRDDRegionValue$$anonfun$writeRows$extension$1.apply(RowStore.scala:526); 	at is.hail.utils.richUtils.RichRDD$$anonfun$5.apply(RichRDD.scala:207); 	at is.hail.utils.richUtils.RichRDD$$anonfun$5.apply(RichRDD.scala:198); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:820); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:820); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2722#issuecomment-358198437
https://github.com/hail-is/hail/pull/2722#issuecomment-358198437:380,Safety,Unsafe,UnsafeRow,380,"Fails with:; ```; Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 491 in stage 1.0 failed 20 times, most recent failure: Lost task 491.19 in stage 1.0 (TID 17951, exomes-sw-gf9k.c.broad-mpg-gnomad.internal): java.lang.IndexOutOfBoundsException: 3; 	at is.hail.annotations.UnsafeRow.isNullAt(UnsafeRow.scala:294); 	at is.hail.annotations.UnsafeRow.get(UnsafeRow.scala:254); 	at is.hail.variant.MatrixTable$$anonfun$59$$anonfun$apply$42.apply(MatrixTable.scala:871); 	at is.hail.variant.MatrixTable$$anonfun$59$$anonfun$apply$42.apply(MatrixTable.scala:860); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.next(OrderedRVD.scala:637); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.next(OrderedRVD.scala:631); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.foreach(OrderedRVD.scala:631); 	at is.hail.io.RichRDDRegionValue$.writeRowsPartition(RowStore.scala:510); 	at is.hail.io.RichRDDRegionValue$$anonfun$writeRows$extension$1.apply(RowStore.scala:526); 	at is.hail.io.RichRDDRegionValue$$anonfun$writeRows$extension$1.apply(RowStore.scala:526); 	at is.hail.utils.richUtils.RichRDD$$anonfun$5.apply(RichRDD.scala:207); 	at is.hail.utils.richUtils.RichRDD$$anonfun$5.apply(RichRDD.scala:198); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:820); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:820); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2722#issuecomment-358198437
https://github.com/hail-is/hail/pull/2722#issuecomment-358198437:394,Safety,Unsafe,UnsafeRow,394,"Fails with:; ```; Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 491 in stage 1.0 failed 20 times, most recent failure: Lost task 491.19 in stage 1.0 (TID 17951, exomes-sw-gf9k.c.broad-mpg-gnomad.internal): java.lang.IndexOutOfBoundsException: 3; 	at is.hail.annotations.UnsafeRow.isNullAt(UnsafeRow.scala:294); 	at is.hail.annotations.UnsafeRow.get(UnsafeRow.scala:254); 	at is.hail.variant.MatrixTable$$anonfun$59$$anonfun$apply$42.apply(MatrixTable.scala:871); 	at is.hail.variant.MatrixTable$$anonfun$59$$anonfun$apply$42.apply(MatrixTable.scala:860); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.next(OrderedRVD.scala:637); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.next(OrderedRVD.scala:631); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.foreach(OrderedRVD.scala:631); 	at is.hail.io.RichRDDRegionValue$.writeRowsPartition(RowStore.scala:510); 	at is.hail.io.RichRDDRegionValue$$anonfun$writeRows$extension$1.apply(RowStore.scala:526); 	at is.hail.io.RichRDDRegionValue$$anonfun$writeRows$extension$1.apply(RowStore.scala:526); 	at is.hail.utils.richUtils.RichRDD$$anonfun$5.apply(RichRDD.scala:207); 	at is.hail.utils.richUtils.RichRDD$$anonfun$5.apply(RichRDD.scala:198); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:820); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:820); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2722#issuecomment-358198437
https://github.com/hail-is/hail/pull/2722#issuecomment-358198437:2413,Safety,abort,abortStage,2413,anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:820); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:820); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGSche,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2722#issuecomment-358198437
https://github.com/hail-is/hail/pull/2722#issuecomment-358198437:2511,Safety,abort,abortStage,2511,RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:820); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.ap,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2722#issuecomment-358198437
https://github.com/hail-is/hail/pull/2722#issuecomment-358198437:2756,Safety,abort,abortStage,2756,(RDD.scala:283); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2722#issuecomment-358198437
https://github.com/hail-is/hail/pull/2722#issuecomment-358198437:5182,Safety,Unsafe,UnsafeRow,5182,	at is.hail.utils.richUtils.RichRDD$.writePartitions$extension(RichRDD.scala:209); 	at is.hail.io.RichRDDRegionValue$.writeRows$extension(RowStore.scala:526); 	at is.hail.variant.MatrixTable.write(MatrixTable.scala:2393); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748)java.lang.IndexOutOfBoundsException: 3; 	at is.hail.annotations.UnsafeRow.isNullAt(UnsafeRow.scala:294); 	at is.hail.annotations.UnsafeRow.get(UnsafeRow.scala:254); 	at is.hail.variant.MatrixTable$$anonfun$59$$anonfun$apply$42.apply(MatrixTable.scala:871); 	at is.hail.variant.MatrixTable$$anonfun$59$$anonfun$apply$42.apply(MatrixTable.scala:860); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.next(OrderedRVD.scala:637); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.next(OrderedRVD.scala:631); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.foreach(OrderedRVD.scala:631); 	at is.hail.io.RichRDDRegionValue$.writeRowsPartition(RowStore.scala:510); 	at is.hail.io.RichRDDRegionValue$$anonfun$writeRows$extension$1.apply(RowStore.scala:526); 	at is.hail.io.RichRDDRegionValue$$anonfun$writeRows$extension$1.apply(RowStore.scala:526); 	at is.hail.utils.richUtils.RichRDD$$anonfun$5.apply(RichRDD.scala:207); 	at is.hail.uti,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2722#issuecomment-358198437
https://github.com/hail-is/hail/pull/2722#issuecomment-358198437:5201,Safety,Unsafe,UnsafeRow,5201,ils.richUtils.RichRDD$.writePartitions$extension(RichRDD.scala:209); 	at is.hail.io.RichRDDRegionValue$.writeRows$extension(RowStore.scala:526); 	at is.hail.variant.MatrixTable.write(MatrixTable.scala:2393); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748)java.lang.IndexOutOfBoundsException: 3; 	at is.hail.annotations.UnsafeRow.isNullAt(UnsafeRow.scala:294); 	at is.hail.annotations.UnsafeRow.get(UnsafeRow.scala:254); 	at is.hail.variant.MatrixTable$$anonfun$59$$anonfun$apply$42.apply(MatrixTable.scala:871); 	at is.hail.variant.MatrixTable$$anonfun$59$$anonfun$apply$42.apply(MatrixTable.scala:860); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.next(OrderedRVD.scala:637); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.next(OrderedRVD.scala:631); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.foreach(OrderedRVD.scala:631); 	at is.hail.io.RichRDDRegionValue$.writeRowsPartition(RowStore.scala:510); 	at is.hail.io.RichRDDRegionValue$$anonfun$writeRows$extension$1.apply(RowStore.scala:526); 	at is.hail.io.RichRDDRegionValue$$anonfun$writeRows$extension$1.apply(RowStore.scala:526); 	at is.hail.utils.richUtils.RichRDD$$anonfun$5.apply(RichRDD.scala:207); 	at is.hail.utils.richUtils.Ri,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2722#issuecomment-358198437
https://github.com/hail-is/hail/pull/2722#issuecomment-358198437:5247,Safety,Unsafe,UnsafeRow,5247,chRDD.scala:209); 	at is.hail.io.RichRDDRegionValue$.writeRows$extension(RowStore.scala:526); 	at is.hail.variant.MatrixTable.write(MatrixTable.scala:2393); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748)java.lang.IndexOutOfBoundsException: 3; 	at is.hail.annotations.UnsafeRow.isNullAt(UnsafeRow.scala:294); 	at is.hail.annotations.UnsafeRow.get(UnsafeRow.scala:254); 	at is.hail.variant.MatrixTable$$anonfun$59$$anonfun$apply$42.apply(MatrixTable.scala:871); 	at is.hail.variant.MatrixTable$$anonfun$59$$anonfun$apply$42.apply(MatrixTable.scala:860); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.next(OrderedRVD.scala:637); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.next(OrderedRVD.scala:631); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.foreach(OrderedRVD.scala:631); 	at is.hail.io.RichRDDRegionValue$.writeRowsPartition(RowStore.scala:510); 	at is.hail.io.RichRDDRegionValue$$anonfun$writeRows$extension$1.apply(RowStore.scala:526); 	at is.hail.io.RichRDDRegionValue$$anonfun$writeRows$extension$1.apply(RowStore.scala:526); 	at is.hail.utils.richUtils.RichRDD$$anonfun$5.apply(RichRDD.scala:207); 	at is.hail.utils.richUtils.RichRDD$$anonfun$5.apply(RichRDD.scala:198); 	at org,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2722#issuecomment-358198437
https://github.com/hail-is/hail/pull/2722#issuecomment-358198437:5261,Safety,Unsafe,UnsafeRow,5261,209); 	at is.hail.io.RichRDDRegionValue$.writeRows$extension(RowStore.scala:526); 	at is.hail.variant.MatrixTable.write(MatrixTable.scala:2393); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748)java.lang.IndexOutOfBoundsException: 3; 	at is.hail.annotations.UnsafeRow.isNullAt(UnsafeRow.scala:294); 	at is.hail.annotations.UnsafeRow.get(UnsafeRow.scala:254); 	at is.hail.variant.MatrixTable$$anonfun$59$$anonfun$apply$42.apply(MatrixTable.scala:871); 	at is.hail.variant.MatrixTable$$anonfun$59$$anonfun$apply$42.apply(MatrixTable.scala:860); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.next(OrderedRVD.scala:637); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.next(OrderedRVD.scala:631); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.foreach(OrderedRVD.scala:631); 	at is.hail.io.RichRDDRegionValue$.writeRowsPartition(RowStore.scala:510); 	at is.hail.io.RichRDDRegionValue$$anonfun$writeRows$extension$1.apply(RowStore.scala:526); 	at is.hail.io.RichRDDRegionValue$$anonfun$writeRows$extension$1.apply(RowStore.scala:526); 	at is.hail.utils.richUtils.RichRDD$$anonfun$5.apply(RichRDD.scala:207); 	at is.hail.utils.richUtils.RichRDD$$anonfun$5.apply(RichRDD.scala:198); 	at org.apache.spar,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2722#issuecomment-358198437
https://github.com/hail-is/hail/pull/2722#issuecomment-358354804:0,Testability,Test,Testing,0,Testing on Nirvana now,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2722#issuecomment-358354804
https://github.com/hail-is/hail/pull/2722#issuecomment-358385663:17,Deployability,pipeline,pipeline,17,Successfully ran pipeline in #2377 and found identical output.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2722#issuecomment-358385663
https://github.com/hail-is/hail/pull/2724#issuecomment-358734769:82,Deployability,update,updated,82,"Addressed comments. In addition to your other comments, I required unique IDs and updated the docs to reflect the chain in variant join.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2724#issuecomment-358734769
https://github.com/hail-is/hail/pull/2725#issuecomment-358866976:4,Integrability,depend,depends,4,"Now depends on https://github.com/hail-is/hail/pull/2723, last pending rv-conversion PR. > +275 2,223. Aw, yiss. @tpoterba Do you want to do the honors on this or should I spin the wheel?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2725#issuecomment-358866976
https://github.com/hail-is/hail/issues/2734#issuecomment-358096966:305,Availability,redundant,redundant,305,"@catoverdrive this came up while Konrad and I were trying to understand a discrepancy with PCA in python sklearn, which automatically mean centers. This simplest solution would be to add a map that mean centers between irm and computeSVD here:; `val svd = irm.computeSVD(k, computeLoadings)`; But this is redundant when the data is already mean-centered, as in pca_of_normalized_genotypes. Let's discuss when you're back and I can make the changes and update the docs which need some work anyhow.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2734#issuecomment-358096966
https://github.com/hail-is/hail/issues/2734#issuecomment-358096966:452,Deployability,update,update,452,"@catoverdrive this came up while Konrad and I were trying to understand a discrepancy with PCA in python sklearn, which automatically mean centers. This simplest solution would be to add a map that mean centers between irm and computeSVD here:; `val svd = irm.computeSVD(k, computeLoadings)`; But this is redundant when the data is already mean-centered, as in pca_of_normalized_genotypes. Let's discuss when you're back and I can make the changes and update the docs which need some work anyhow.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2734#issuecomment-358096966
https://github.com/hail-is/hail/issues/2734#issuecomment-358096966:305,Safety,redund,redundant,305,"@catoverdrive this came up while Konrad and I were trying to understand a discrepancy with PCA in python sklearn, which automatically mean centers. This simplest solution would be to add a map that mean centers between irm and computeSVD here:; `val svd = irm.computeSVD(k, computeLoadings)`; But this is redundant when the data is already mean-centered, as in pca_of_normalized_genotypes. Let's discuss when you're back and I can make the changes and update the docs which need some work anyhow.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2734#issuecomment-358096966
https://github.com/hail-is/hail/issues/2734#issuecomment-358096966:153,Usability,simpl,simplest,153,"@catoverdrive this came up while Konrad and I were trying to understand a discrepancy with PCA in python sklearn, which automatically mean centers. This simplest solution would be to add a map that mean centers between irm and computeSVD here:; `val svd = irm.computeSVD(k, computeLoadings)`; But this is redundant when the data is already mean-centered, as in pca_of_normalized_genotypes. Let's discuss when you're back and I can make the changes and update the docs which need some work anyhow.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2734#issuecomment-358096966
https://github.com/hail-is/hail/issues/2743#issuecomment-358467186:93,Availability,error,error,93,"okay, so this must be some problem with the code, not the file format. Can you reproduce the error in the current version from the new files?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2743#issuecomment-358467186
https://github.com/hail-is/hail/issues/2743#issuecomment-358477102:76,Deployability,pipeline,pipeline,76,"yes, exact same problem. The VDSs are:; `gs://future-variant-calling/future-pipeline/future.vds`; and; `gs://future-variant-calling/old-pipeline/past.vds`. You should have access in case you want to try things.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2743#issuecomment-358477102
https://github.com/hail-is/hail/issues/2743#issuecomment-358477102:136,Deployability,pipeline,pipeline,136,"yes, exact same problem. The VDSs are:; `gs://future-variant-calling/future-pipeline/future.vds`; and; `gs://future-variant-calling/old-pipeline/past.vds`. You should have access in case you want to try things.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2743#issuecomment-358477102
https://github.com/hail-is/hail/issues/2743#issuecomment-358477102:172,Security,access,access,172,"yes, exact same problem. The VDSs are:; `gs://future-variant-calling/future-pipeline/future.vds`; and; `gs://future-variant-calling/old-pipeline/past.vds`. You should have access in case you want to try things.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2743#issuecomment-358477102
https://github.com/hail-is/hail/issues/2743#issuecomment-359552294:75,Deployability,pipeline,pipeline,75,So it seems like the problem is with ; `gs://future-variant-calling/future-pipeline/future.vds`. trying to run `sample_qc` on it also fails in exactly the same way...,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2743#issuecomment-359552294
https://github.com/hail-is/hail/pull/2751#issuecomment-359146225:480,Availability,down,down,480,"@jbloom I passed a 500x500 matrix and a 5000x5000 matrix of zeros from Scala. The 500x500 matrix took ~.3 seconds, and the 5000x5000 matrix took ~30 seconds to pass through. Almost all of this is spent retrieving the byte array from Java -> Python, so I don't know if we'll be able to get this noticeably faster. The 0x100000 threshold for breaking up the blocks of bytes (semi-arbitrarily) because larger blocks caused me to run out of heap space, but wiggling that value up and down seems not to really affect the amount of time it takes.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2751#issuecomment-359146225
https://github.com/hail-is/hail/issues/2763#issuecomment-360660531:15,Usability,clear,clear,15,Thanks for the clear bug report @uqrmaie1! Let me know if you have any more trouble.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2763#issuecomment-360660531
https://github.com/hail-is/hail/pull/2768#issuecomment-359282910:64,Testability,test,tests,64,"I've gut-renovated the TDT implementation and improved docs and tests. The t=0, u=0 case is now handed generically, giving NaN and NaN instead of 0.0 and 1.0 for chi2 and pval. I've also normalized the pedigree and trio fields/functions to be consistent with the other changes.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2768#issuecomment-359282910
https://github.com/hail-is/hail/issues/2777#issuecomment-359417991:117,Modifiability,variab,variable,117,"How's this?; ```; info(s""Running linear regression per row on $n samples for ${ y.cols } response ${ plural(y.cols, ""variable"") } y,\n""; + s"" with input variable x, intercept, and ${ k - 1 } additional ${ plural(k - 1, ""covariate"") }...""); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2777#issuecomment-359417991
https://github.com/hail-is/hail/issues/2777#issuecomment-359417991:153,Modifiability,variab,variable,153,"How's this?; ```; info(s""Running linear regression per row on $n samples for ${ y.cols } response ${ plural(y.cols, ""variable"") } y,\n""; + s"" with input variable x, intercept, and ${ k - 1 } additional ${ plural(k - 1, ""covariate"") }...""); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2777#issuecomment-359417991
https://github.com/hail-is/hail/pull/2783#issuecomment-360241486:37,Testability,log,logreg,37,@jbloom22 Could you double check my `logreg` language?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2783#issuecomment-360241486
https://github.com/hail-is/hail/pull/2787#issuecomment-359798042:92,Security,hash,hash-orders,92,"The Table ones are kinda broken because they get reordered because the `Struct` constructor hash-orders the fields. This means that `df.row.dtype != df.schema`, which is bad. We can fix this by moving to python 3",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2787#issuecomment-359798042
https://github.com/hail-is/hail/pull/2804#issuecomment-361132177:147,Performance,Load,LoadMatrix,147,@tpoterba @danking fyi I changed the base branch back to master. I don't think it'll be a bad rebase since the changes are pretty much isolated to LoadMatrix.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2804#issuecomment-361132177
https://github.com/hail-is/hail/pull/2804#issuecomment-366001940:71,Integrability,interface,interface,71,"@danking this is ready for a look now!. There's some slight changes to interface, etc to take advantage of the new key design--mostly now it takes row fields instead of an expr. There's also a small fix to some of the partitioner/interval stuff. The python interface is gone now, and I'll put it back in a separate PR, with real docs this time. And I pulled out all the parsing logic into its own thing.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2804#issuecomment-366001940
https://github.com/hail-is/hail/pull/2804#issuecomment-366001940:257,Integrability,interface,interface,257,"@danking this is ready for a look now!. There's some slight changes to interface, etc to take advantage of the new key design--mostly now it takes row fields instead of an expr. There's also a small fix to some of the partitioner/interval stuff. The python interface is gone now, and I'll put it back in a separate PR, with real docs this time. And I pulled out all the parsing logic into its own thing.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2804#issuecomment-366001940
https://github.com/hail-is/hail/pull/2804#issuecomment-366001940:378,Testability,log,logic,378,"@danking this is ready for a look now!. There's some slight changes to interface, etc to take advantage of the new key design--mostly now it takes row fields instead of an expr. There's also a small fix to some of the partitioner/interval stuff. The python interface is gone now, and I'll put it back in a separate PR, with real docs this time. And I pulled out all the parsing logic into its own thing.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2804#issuecomment-366001940
https://github.com/hail-is/hail/pull/2812#issuecomment-361300529:4,Testability,test,test,4,The test is broken.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2812#issuecomment-361300529
https://github.com/hail-is/hail/pull/2812#issuecomment-361667453:20,Testability,test,tests,20,"@jigold I fixed the tests (things got broken rebasing onto breaking, unsurprisingly). I also incorporated a change to `Table.view_join_rows` allowing for implicit joins with `Locus` and `Interval` keyed tables into `Variant` keyed datasets (cf. @cseed @tpoterba), which I needed for the skat test.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2812#issuecomment-361667453
https://github.com/hail-is/hail/pull/2812#issuecomment-361667453:292,Testability,test,test,292,"@jigold I fixed the tests (things got broken rebasing onto breaking, unsurprisingly). I also incorporated a change to `Table.view_join_rows` allowing for implicit joins with `Locus` and `Interval` keyed tables into `Variant` keyed datasets (cf. @cseed @tpoterba), which I needed for the skat test.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2812#issuecomment-361667453
https://github.com/hail-is/hail/pull/2816#issuecomment-360953858:125,Integrability,depend,depended,125,"UI won't let me respond about the tests comment. I removed the api1.tests.py file, but left the api1 code because it's still depended on and we should extract that separately.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2816#issuecomment-360953858
https://github.com/hail-is/hail/pull/2816#issuecomment-360953858:34,Testability,test,tests,34,"UI won't let me respond about the tests comment. I removed the api1.tests.py file, but left the api1 code because it's still depended on and we should extract that separately.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2816#issuecomment-360953858
https://github.com/hail-is/hail/pull/2816#issuecomment-360953858:68,Testability,test,tests,68,"UI won't let me respond about the tests comment. I removed the api1.tests.py file, but left the api1 code because it's still depended on and we should extract that separately.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2816#issuecomment-360953858
https://github.com/hail-is/hail/pull/2820#issuecomment-360908387:166,Integrability,message,message,166,"Instead of creating a hail context, I've exposed the top level `init` and `stop` methods in hail2. . Env.hc() will call init if it's not been called yet, and print a message about initializing with default params.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2820#issuecomment-360908387
https://github.com/hail-is/hail/pull/2820#issuecomment-360908387:41,Security,expose,exposed,41,"Instead of creating a hail context, I've exposed the top level `init` and `stop` methods in hail2. . Env.hc() will call init if it's not been called yet, and print a message about initializing with default params.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2820#issuecomment-360908387
https://github.com/hail-is/hail/pull/2821#issuecomment-360964083:57,Testability,test,test,57,"@danking you are a golden god. that is all. also, i will test it out for you this weekend",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2821#issuecomment-360964083
https://github.com/hail-is/hail/pull/2821#issuecomment-362299166:112,Deployability,release,release,112,"Konrad got his relatedness estimates, so I'm tabling this PR until I have more time to clean it up for a proper release into 0.2.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2821#issuecomment-362299166
https://github.com/hail-is/hail/pull/2825#issuecomment-362082473:87,Availability,error,error,87,"I don't disagree. However, we need toString on (scalar) Type because they are used for error messages all over. MatrixTable used to have a bunch of separate types, now it just has a MatrixType. I think some error messages could now use the matrix type. Python also has some matrix type printing logic, these should probably get unified. Once I have printing for the user, it seemed easier to write a (admittedly small) parser than a separate to/from JSON. I admit, apart from user error messages, JSON is natural since that's what we're storing in the metadata file. Do you have a concrete suggestion? I'm not sure quite what to do that's better than this.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2825#issuecomment-362082473
https://github.com/hail-is/hail/pull/2825#issuecomment-362082473:207,Availability,error,error,207,"I don't disagree. However, we need toString on (scalar) Type because they are used for error messages all over. MatrixTable used to have a bunch of separate types, now it just has a MatrixType. I think some error messages could now use the matrix type. Python also has some matrix type printing logic, these should probably get unified. Once I have printing for the user, it seemed easier to write a (admittedly small) parser than a separate to/from JSON. I admit, apart from user error messages, JSON is natural since that's what we're storing in the metadata file. Do you have a concrete suggestion? I'm not sure quite what to do that's better than this.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2825#issuecomment-362082473
https://github.com/hail-is/hail/pull/2825#issuecomment-362082473:481,Availability,error,error,481,"I don't disagree. However, we need toString on (scalar) Type because they are used for error messages all over. MatrixTable used to have a bunch of separate types, now it just has a MatrixType. I think some error messages could now use the matrix type. Python also has some matrix type printing logic, these should probably get unified. Once I have printing for the user, it seemed easier to write a (admittedly small) parser than a separate to/from JSON. I admit, apart from user error messages, JSON is natural since that's what we're storing in the metadata file. Do you have a concrete suggestion? I'm not sure quite what to do that's better than this.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2825#issuecomment-362082473
https://github.com/hail-is/hail/pull/2825#issuecomment-362082473:93,Integrability,message,messages,93,"I don't disagree. However, we need toString on (scalar) Type because they are used for error messages all over. MatrixTable used to have a bunch of separate types, now it just has a MatrixType. I think some error messages could now use the matrix type. Python also has some matrix type printing logic, these should probably get unified. Once I have printing for the user, it seemed easier to write a (admittedly small) parser than a separate to/from JSON. I admit, apart from user error messages, JSON is natural since that's what we're storing in the metadata file. Do you have a concrete suggestion? I'm not sure quite what to do that's better than this.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2825#issuecomment-362082473
https://github.com/hail-is/hail/pull/2825#issuecomment-362082473:213,Integrability,message,messages,213,"I don't disagree. However, we need toString on (scalar) Type because they are used for error messages all over. MatrixTable used to have a bunch of separate types, now it just has a MatrixType. I think some error messages could now use the matrix type. Python also has some matrix type printing logic, these should probably get unified. Once I have printing for the user, it seemed easier to write a (admittedly small) parser than a separate to/from JSON. I admit, apart from user error messages, JSON is natural since that's what we're storing in the metadata file. Do you have a concrete suggestion? I'm not sure quite what to do that's better than this.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2825#issuecomment-362082473
https://github.com/hail-is/hail/pull/2825#issuecomment-362082473:487,Integrability,message,messages,487,"I don't disagree. However, we need toString on (scalar) Type because they are used for error messages all over. MatrixTable used to have a bunch of separate types, now it just has a MatrixType. I think some error messages could now use the matrix type. Python also has some matrix type printing logic, these should probably get unified. Once I have printing for the user, it seemed easier to write a (admittedly small) parser than a separate to/from JSON. I admit, apart from user error messages, JSON is natural since that's what we're storing in the metadata file. Do you have a concrete suggestion? I'm not sure quite what to do that's better than this.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2825#issuecomment-362082473
https://github.com/hail-is/hail/pull/2825#issuecomment-362082473:295,Testability,log,logic,295,"I don't disagree. However, we need toString on (scalar) Type because they are used for error messages all over. MatrixTable used to have a bunch of separate types, now it just has a MatrixType. I think some error messages could now use the matrix type. Python also has some matrix type printing logic, these should probably get unified. Once I have printing for the user, it seemed easier to write a (admittedly small) parser than a separate to/from JSON. I admit, apart from user error messages, JSON is natural since that's what we're storing in the metadata file. Do you have a concrete suggestion? I'm not sure quite what to do that's better than this.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2825#issuecomment-362082473
https://github.com/hail-is/hail/pull/2828#issuecomment-362842294:80,Integrability,interface,interface,80,"I pushed some additional commits:. - added UnpartitionedRVD, made RVD a cleaner interface; - improved the RVDSpec to/from JSON conversion; - added RVD.write that returns an rvdSpec + stats (partition counts)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2828#issuecomment-362842294
https://github.com/hail-is/hail/pull/2829#issuecomment-361425978:429,Testability,test,tests,429,"@tpoterba I fiat assigned you, let me know if you want me to spin the wheel of review fortune instead. doctest_setup.py has these four lines commented out:. ````; # geneskt = methods.import_interval_list('data/genes.interval_list'); # genekt = methods.import_interval_list('data/gene.interval_list'); # ds = ds.annotate_rows(genes = ???); # ds = ds.annotate_rows(gene = genekt[ds.v.locus()]); ```. which will be used by the skat tests/docs (https://github.com/hail-is/hail/pull/2812) and maybe some burden tests/examples? They require interval joins (@patrick-schultz is working on that) and product=True (I will make a separate PR). But since things are working now, I thought I'd try to get this in first.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2829#issuecomment-361425978
https://github.com/hail-is/hail/pull/2829#issuecomment-361425978:506,Testability,test,tests,506,"@tpoterba I fiat assigned you, let me know if you want me to spin the wheel of review fortune instead. doctest_setup.py has these four lines commented out:. ````; # geneskt = methods.import_interval_list('data/genes.interval_list'); # genekt = methods.import_interval_list('data/gene.interval_list'); # ds = ds.annotate_rows(genes = ???); # ds = ds.annotate_rows(gene = genekt[ds.v.locus()]); ```. which will be used by the skat tests/docs (https://github.com/hail-is/hail/pull/2812) and maybe some burden tests/examples? They require interval joins (@patrick-schultz is working on that) and product=True (I will make a separate PR). But since things are working now, I thought I'd try to get this in first.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2829#issuecomment-361425978
https://github.com/hail-is/hail/pull/2829#issuecomment-361434958:74,Availability,down,down,74,"To clarify, that :-1: is my finger hovering over the button. Not a thumbs down",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2829#issuecomment-361434958
https://github.com/hail-is/hail/pull/2841#issuecomment-362351992:28,Testability,test,test,28,I ported the `import_plink` test to methods/tests.py in #2843,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2841#issuecomment-362351992
https://github.com/hail-is/hail/pull/2841#issuecomment-362351992:44,Testability,test,tests,44,I ported the `import_plink` test to methods/tests.py in #2843,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2841#issuecomment-362351992
https://github.com/hail-is/hail/pull/2842#issuecomment-362325035:65,Testability,test,tests,65,"@jbloom22 Ah right of course, I inadvertently had required 2.2.0 tests for 0.1, which doesn't support 2.2.0. Requirement off.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2842#issuecomment-362325035
https://github.com/hail-is/hail/pull/2848#issuecomment-363553946:25,Availability,down,down,25,"I pushed the logic #2861 down so I can remove this copy. I'll add that change to that PR once this is merged (good catch) since I may need to rebase anyway. See here:; https://github.com/hail-is/hail/pull/2861/files#diff-912e03c9c34a874ecdc0e520a13cb572R133. This avoids the copy if the BDM is compact, which blocks always are. If the BDM is not compact, then we could add logic to stream out the bytes without an intermediate compactification but I don't want to add that complexity now.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2848#issuecomment-363553946
https://github.com/hail-is/hail/pull/2848#issuecomment-363553946:264,Safety,avoid,avoids,264,"I pushed the logic #2861 down so I can remove this copy. I'll add that change to that PR once this is merged (good catch) since I may need to rebase anyway. See here:; https://github.com/hail-is/hail/pull/2861/files#diff-912e03c9c34a874ecdc0e520a13cb572R133. This avoids the copy if the BDM is compact, which blocks always are. If the BDM is not compact, then we could add logic to stream out the bytes without an intermediate compactification but I don't want to add that complexity now.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2848#issuecomment-363553946
https://github.com/hail-is/hail/pull/2848#issuecomment-363553946:13,Testability,log,logic,13,"I pushed the logic #2861 down so I can remove this copy. I'll add that change to that PR once this is merged (good catch) since I may need to rebase anyway. See here:; https://github.com/hail-is/hail/pull/2861/files#diff-912e03c9c34a874ecdc0e520a13cb572R133. This avoids the copy if the BDM is compact, which blocks always are. If the BDM is not compact, then we could add logic to stream out the bytes without an intermediate compactification but I don't want to add that complexity now.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2848#issuecomment-363553946
https://github.com/hail-is/hail/pull/2848#issuecomment-363553946:373,Testability,log,logic,373,"I pushed the logic #2861 down so I can remove this copy. I'll add that change to that PR once this is merged (good catch) since I may need to rebase anyway. See here:; https://github.com/hail-is/hail/pull/2861/files#diff-912e03c9c34a874ecdc0e520a13cb572R133. This avoids the copy if the BDM is compact, which blocks always are. If the BDM is not compact, then we could add logic to stream out the bytes without an intermediate compactification but I don't want to add that complexity now.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2848#issuecomment-363553946
https://github.com/hail-is/hail/pull/2852#issuecomment-362778686:256,Performance,optimiz,optimize,256,I actually quite like this with `tablify`. [Take a look at the differences before/after `tablify`](https://github.com/hail-is/hail/pull/2852/commits/31c48bfb8417279b28aa738dab6b56deb0c0b1e2). `tablify` obviously leads to heinous join graphs. We'll need to optimize these.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2852#issuecomment-362778686
https://github.com/hail-is/hail/pull/2852#issuecomment-363841964:368,Availability,down,down,368,"I wanted to chime in on this briefly because I think it a good example use case and its design will influence many future methods, so it is important to get the design right. Thoughts:. - the underscore stuff is a non-starter in my opinion, and too clever by half. A lot of my feedback on your stuff is guided by the general heuristic that you should start by writing down the code you want, and then decide how to implement. You'd never want to write this _ stuff if you didn't have to. - I'm still not quite sure what tablify does (in part because the name is too clever by half and in part because it doesn't appear to always return tables). - But I think the idea of tablify is something we want, which is to convert (possibly indexed expressions) back into relational objects (Table, MatrixTable) because the latter support a wider set of operations and don't have the ""source mismatch problem"". Tim and I discussed this yesterday and we suggest the following interface:. ```; t = build_table(); .set_globals(x = 5, batch = batch); .set_rows(locus = locus, aaf = aaf); .build(); ```. and. ```; mt = build_table_matix(); .set_globals(dataset = dataset); .set_rows(locus = locus, aaf = aaf); .set_entries(GT = GT); .build(); ```. where the input expressions for each part must all come from the same source (or be compatible, e.g., constants) and the resulting (matrix) table inherits the keys from the original table. I think there is an unresolved question about how to handle potential name conflicts (e.g. a column key named locus).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2852#issuecomment-363841964
https://github.com/hail-is/hail/pull/2852#issuecomment-363841964:965,Integrability,interface,interface,965,"I wanted to chime in on this briefly because I think it a good example use case and its design will influence many future methods, so it is important to get the design right. Thoughts:. - the underscore stuff is a non-starter in my opinion, and too clever by half. A lot of my feedback on your stuff is guided by the general heuristic that you should start by writing down the code you want, and then decide how to implement. You'd never want to write this _ stuff if you didn't have to. - I'm still not quite sure what tablify does (in part because the name is too clever by half and in part because it doesn't appear to always return tables). - But I think the idea of tablify is something we want, which is to convert (possibly indexed expressions) back into relational objects (Table, MatrixTable) because the latter support a wider set of operations and don't have the ""source mismatch problem"". Tim and I discussed this yesterday and we suggest the following interface:. ```; t = build_table(); .set_globals(x = 5, batch = batch); .set_rows(locus = locus, aaf = aaf); .build(); ```. and. ```; mt = build_table_matix(); .set_globals(dataset = dataset); .set_rows(locus = locus, aaf = aaf); .set_entries(GT = GT); .build(); ```. where the input expressions for each part must all come from the same source (or be compatible, e.g., constants) and the resulting (matrix) table inherits the keys from the original table. I think there is an unresolved question about how to handle potential name conflicts (e.g. a column key named locus).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2852#issuecomment-363841964
https://github.com/hail-is/hail/pull/2852#issuecomment-363841964:1379,Modifiability,inherit,inherits,1379,"I wanted to chime in on this briefly because I think it a good example use case and its design will influence many future methods, so it is important to get the design right. Thoughts:. - the underscore stuff is a non-starter in my opinion, and too clever by half. A lot of my feedback on your stuff is guided by the general heuristic that you should start by writing down the code you want, and then decide how to implement. You'd never want to write this _ stuff if you didn't have to. - I'm still not quite sure what tablify does (in part because the name is too clever by half and in part because it doesn't appear to always return tables). - But I think the idea of tablify is something we want, which is to convert (possibly indexed expressions) back into relational objects (Table, MatrixTable) because the latter support a wider set of operations and don't have the ""source mismatch problem"". Tim and I discussed this yesterday and we suggest the following interface:. ```; t = build_table(); .set_globals(x = 5, batch = batch); .set_rows(locus = locus, aaf = aaf); .build(); ```. and. ```; mt = build_table_matix(); .set_globals(dataset = dataset); .set_rows(locus = locus, aaf = aaf); .set_entries(GT = GT); .build(); ```. where the input expressions for each part must all come from the same source (or be compatible, e.g., constants) and the resulting (matrix) table inherits the keys from the original table. I think there is an unresolved question about how to handle potential name conflicts (e.g. a column key named locus).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2852#issuecomment-363841964
https://github.com/hail-is/hail/pull/2852#issuecomment-363841964:277,Usability,feedback,feedback,277,"I wanted to chime in on this briefly because I think it a good example use case and its design will influence many future methods, so it is important to get the design right. Thoughts:. - the underscore stuff is a non-starter in my opinion, and too clever by half. A lot of my feedback on your stuff is guided by the general heuristic that you should start by writing down the code you want, and then decide how to implement. You'd never want to write this _ stuff if you didn't have to. - I'm still not quite sure what tablify does (in part because the name is too clever by half and in part because it doesn't appear to always return tables). - But I think the idea of tablify is something we want, which is to convert (possibly indexed expressions) back into relational objects (Table, MatrixTable) because the latter support a wider set of operations and don't have the ""source mismatch problem"". Tim and I discussed this yesterday and we suggest the following interface:. ```; t = build_table(); .set_globals(x = 5, batch = batch); .set_rows(locus = locus, aaf = aaf); .build(); ```. and. ```; mt = build_table_matix(); .set_globals(dataset = dataset); .set_rows(locus = locus, aaf = aaf); .set_entries(GT = GT); .build(); ```. where the input expressions for each part must all come from the same source (or be compatible, e.g., constants) and the resulting (matrix) table inherits the keys from the original table. I think there is an unresolved question about how to handle potential name conflicts (e.g. a column key named locus).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2852#issuecomment-363841964
https://github.com/hail-is/hail/pull/2852#issuecomment-363841964:303,Usability,guid,guided,303,"I wanted to chime in on this briefly because I think it a good example use case and its design will influence many future methods, so it is important to get the design right. Thoughts:. - the underscore stuff is a non-starter in my opinion, and too clever by half. A lot of my feedback on your stuff is guided by the general heuristic that you should start by writing down the code you want, and then decide how to implement. You'd never want to write this _ stuff if you didn't have to. - I'm still not quite sure what tablify does (in part because the name is too clever by half and in part because it doesn't appear to always return tables). - But I think the idea of tablify is something we want, which is to convert (possibly indexed expressions) back into relational objects (Table, MatrixTable) because the latter support a wider set of operations and don't have the ""source mismatch problem"". Tim and I discussed this yesterday and we suggest the following interface:. ```; t = build_table(); .set_globals(x = 5, batch = batch); .set_rows(locus = locus, aaf = aaf); .build(); ```. and. ```; mt = build_table_matix(); .set_globals(dataset = dataset); .set_rows(locus = locus, aaf = aaf); .set_entries(GT = GT); .build(); ```. where the input expressions for each part must all come from the same source (or be compatible, e.g., constants) and the resulting (matrix) table inherits the keys from the original table. I think there is an unresolved question about how to handle potential name conflicts (e.g. a column key named locus).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2852#issuecomment-363841964
https://github.com/hail-is/hail/pull/2854#issuecomment-362826137:36,Testability,test,test,36,"Pushed a few more commits:. - added test reading vds/cols is is the same as cols_table; - propagate globals through cols_table(), rows_table()",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2854#issuecomment-362826137
https://github.com/hail-is/hail/pull/2858#issuecomment-364814856:295,Modifiability,polymorphi,polymorphic,295,"@danking @catoverdrive OK, I think it's ready for another review. I made the suggested changes, as well as the changes we talked about on Tuesday during check-in. There is a ton of indirection now, which might be confusing but is good for future expansion. The matrix and table metadata are now polymorphic `RelationalSpec`s and have a `name` field so new relational types can be added. Here is `sample.hmt/metadata.json.gz`:. ```; {; ""components"": {; ""cols"": {; ""rel_path"": ""cols\/rows"",; ""name"": ""RVDComponentSpec""; },; ""rows"": ...,; ""partition_counts"": {; ""counts"": [; 346; ],; ""name"": ""PartitionCountsComponentSpec""; }; },; ""matrix_type"": ...,; ""references_rel_path"": ""references"",; ""hail_version"": ""devel-e6ef439"",; ""file_version"": 65536,; ""name"": ""MatrixTableSpec""; }; ```. A MT has currently has five components: globals, cols, rows, entries and partition_counts. The first four are `RVDComponents`, the counts its own thing. I wanted to make the references a component, but they need to be loaded before the types are parse, so `RelationalSpec`s have a path to the references. Components are future expandable. The MT directory structure has metadata and four directories for each main component which is a Table directory. Those directory names are stored in the metadata, so they can be changed or even point elsewhere. A Table directory has two directories: globals and rows, which are RVDs. Again, the directories are stored in the metadata and I use that here: the globals RVD for rows and cols tables are the rows RVD of the globals table of the MT (if you can understand this sentence you've got a handle on this PR.). RVDs now store their own metadata, the RVDSpec. A sample rows RVD metadata for the rows table of an MT, `sample.hmt/rows/rows/metadata.json.gz` looks like:. ```; {; ""jRangeBounds"": [],; ""partFiles"": [; ""part-0""; ],; ""codecSpec"": ...,; ""orvdType"": ...,; ""name"": ""OrderedRVDSpec""; }; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2858#issuecomment-364814856
https://github.com/hail-is/hail/pull/2858#issuecomment-364814856:998,Performance,load,loaded,998,"@danking @catoverdrive OK, I think it's ready for another review. I made the suggested changes, as well as the changes we talked about on Tuesday during check-in. There is a ton of indirection now, which might be confusing but is good for future expansion. The matrix and table metadata are now polymorphic `RelationalSpec`s and have a `name` field so new relational types can be added. Here is `sample.hmt/metadata.json.gz`:. ```; {; ""components"": {; ""cols"": {; ""rel_path"": ""cols\/rows"",; ""name"": ""RVDComponentSpec""; },; ""rows"": ...,; ""partition_counts"": {; ""counts"": [; 346; ],; ""name"": ""PartitionCountsComponentSpec""; }; },; ""matrix_type"": ...,; ""references_rel_path"": ""references"",; ""hail_version"": ""devel-e6ef439"",; ""file_version"": 65536,; ""name"": ""MatrixTableSpec""; }; ```. A MT has currently has five components: globals, cols, rows, entries and partition_counts. The first four are `RVDComponents`, the counts its own thing. I wanted to make the references a component, but they need to be loaded before the types are parse, so `RelationalSpec`s have a path to the references. Components are future expandable. The MT directory structure has metadata and four directories for each main component which is a Table directory. Those directory names are stored in the metadata, so they can be changed or even point elsewhere. A Table directory has two directories: globals and rows, which are RVDs. Again, the directories are stored in the metadata and I use that here: the globals RVD for rows and cols tables are the rows RVD of the globals table of the MT (if you can understand this sentence you've got a handle on this PR.). RVDs now store their own metadata, the RVDSpec. A sample rows RVD metadata for the rows table of an MT, `sample.hmt/rows/rows/metadata.json.gz` looks like:. ```; {; ""jRangeBounds"": [],; ""partFiles"": [; ""part-0""; ],; ""codecSpec"": ...,; ""orvdType"": ...,; ""name"": ""OrderedRVDSpec""; }; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2858#issuecomment-364814856
https://github.com/hail-is/hail/pull/2858#issuecomment-364973969:16,Integrability,message,messages,16,"I believe fixes messages need to be in the PR message body to work, so I've added it there.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2858#issuecomment-364973969
https://github.com/hail-is/hail/pull/2858#issuecomment-364973969:46,Integrability,message,message,46,"I believe fixes messages need to be in the PR message body to work, so I've added it there.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2858#issuecomment-364973969
https://github.com/hail-is/hail/pull/2869#issuecomment-364135133:22,Integrability,interface,interface,22,"Taking a look at this interface, and I think I prefer it to your other suggestion (lambda va and ga). One question: with `sm = SplitMulti(ds)` - This will now be a class modified in-place with `sm.update_rows()` rather than `sm = sm.update_rows()` (or annotate_rows)?. I ask because it's a bit different from the rest of the `ds` interface and might be a tad bit confusing.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2869#issuecomment-364135133
https://github.com/hail-is/hail/pull/2869#issuecomment-364135133:330,Integrability,interface,interface,330,"Taking a look at this interface, and I think I prefer it to your other suggestion (lambda va and ga). One question: with `sm = SplitMulti(ds)` - This will now be a class modified in-place with `sm.update_rows()` rather than `sm = sm.update_rows()` (or annotate_rows)?. I ask because it's a bit different from the rest of the `ds` interface and might be a tad bit confusing.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2869#issuecomment-364135133
https://github.com/hail-is/hail/pull/2869#issuecomment-364199693:209,Deployability,update,update,209,"The immutable approach is fine, but we should implement it properly so the user doesn't get surprised when an old binding of the object is mutated through a new binding of the object. And there's the issue of update not really being annotate.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2869#issuecomment-364199693
https://github.com/hail-is/hail/issues/2876#issuecomment-369430474:44,Testability,test,test,44,"BinarySearch no longer exists. #2974 adds a test for this case, I believe.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2876#issuecomment-369430474
https://github.com/hail-is/hail/pull/2884#issuecomment-365378540:125,Security,expose,exposed,125,"I don't want to add a larger test to scala, since we're ripping it all out of scala soon. Currently this functionality isn't exposed to Python, and it should be tested when it's exposed.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2884#issuecomment-365378540
https://github.com/hail-is/hail/pull/2884#issuecomment-365378540:178,Security,expose,exposed,178,"I don't want to add a larger test to scala, since we're ripping it all out of scala soon. Currently this functionality isn't exposed to Python, and it should be tested when it's exposed.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2884#issuecomment-365378540
https://github.com/hail-is/hail/pull/2884#issuecomment-365378540:29,Testability,test,test,29,"I don't want to add a larger test to scala, since we're ripping it all out of scala soon. Currently this functionality isn't exposed to Python, and it should be tested when it's exposed.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2884#issuecomment-365378540
https://github.com/hail-is/hail/pull/2884#issuecomment-365378540:161,Testability,test,tested,161,"I don't want to add a larger test to scala, since we're ripping it all out of scala soon. Currently this functionality isn't exposed to Python, and it should be tested when it's exposed.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2884#issuecomment-365378540
https://github.com/hail-is/hail/pull/2886#issuecomment-364619280:82,Modifiability,refactor,refactoring,82,"Sorry for the large diff, it's a conceptually small change that required a lot of refactoring!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2886#issuecomment-364619280
https://github.com/hail-is/hail/pull/2890#issuecomment-366455460:82,Deployability,pipeline,pipeline,82,@cseed I'll close this and just ask for feedback on the branch diff once I have a pipeline working end-to-end and thoughts on proper integration.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2890#issuecomment-366455460
https://github.com/hail-is/hail/pull/2890#issuecomment-366455460:133,Deployability,integrat,integration,133,@cseed I'll close this and just ask for feedback on the branch diff once I have a pipeline working end-to-end and thoughts on proper integration.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2890#issuecomment-366455460
https://github.com/hail-is/hail/pull/2890#issuecomment-366455460:133,Integrability,integrat,integration,133,@cseed I'll close this and just ask for feedback on the branch diff once I have a pipeline working end-to-end and thoughts on proper integration.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2890#issuecomment-366455460
https://github.com/hail-is/hail/pull/2890#issuecomment-366455460:40,Usability,feedback,feedback,40,@cseed I'll close this and just ask for feedback on the branch diff once I have a pipeline working end-to-end and thoughts on proper integration.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2890#issuecomment-366455460
https://github.com/hail-is/hail/pull/2892#issuecomment-365430172:73,Integrability,interface,interface,73,"@konradjk group_by/aggregate is doing something pretty different, so the interface there is totally what you want. I'd be open to renaming these things `query` like they were, but I think Cotton has a strong preference for aggregate.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2892#issuecomment-365430172
https://github.com/hail-is/hail/pull/2893#issuecomment-365318621:5,Deployability,update,updated,5,I've updated docs and code to ensure that NaN and infinite values are caught.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2893#issuecomment-365318621
https://github.com/hail-is/hail/pull/2901#issuecomment-367128376:174,Availability,down,down,174,"no need to apologize for this! there was extra code hanging around that just added noise, so more work was definitely required. It's also good for my own development to slow down and be more attentive to that kind of thing sometimes :)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2901#issuecomment-367128376
https://github.com/hail-is/hail/pull/2908#issuecomment-367150888:12,Testability,test,testing,12,"rebased and testing locally first, then will push and let ol' CI have a go",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2908#issuecomment-367150888
https://github.com/hail-is/hail/pull/2916#issuecomment-366339845:25,Availability,error,error,25,I did try it out and the error messages are WAY better!,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2916#issuecomment-366339845
https://github.com/hail-is/hail/pull/2916#issuecomment-366339845:31,Integrability,message,messages,31,I did try it out and the error messages are WAY better!,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2916#issuecomment-366339845
https://github.com/hail-is/hail/pull/2922#issuecomment-368339680:41,Performance,perform,performance,41,"@tpoterba did you still want me to check performance on exac metadata? If so, I'll do that tomorrow.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2922#issuecomment-368339680
https://github.com/hail-is/hail/pull/2922#issuecomment-368346661:240,Testability,test,test,240,"> I made changes to TBaseStruct, etc. so that types is now a val. I timed it locally for profile225 with import_vcf().count() and compared it with master. Ah, yeah, I totally misread that and thought it was timing read/count. We do need to test that -- this change involves making `types` a virtual function call rather than an array reference. I assume the JIT will make it fast, but we need to be sure since that's used in critical places.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2922#issuecomment-368346661
https://github.com/hail-is/hail/pull/2923#issuecomment-367442418:115,Deployability,update,update,115,I made the docs build in docs/<hailVersion> so the header links work in either local build or the web site. I will update the master branch docs deploy script when this is ready to go in.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2923#issuecomment-367442418
https://github.com/hail-is/hail/pull/2923#issuecomment-367442418:145,Deployability,deploy,deploy,145,I made the docs build in docs/<hailVersion> so the header links work in either local build or the web site. I will update the master branch docs deploy script when this is ready to go in.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2923#issuecomment-367442418
https://github.com/hail-is/hail/pull/2930#issuecomment-366829913:87,Availability,error,error,87,"I've addressed the two comments: now using an `entry_fields` parameter and throwing an error if 'dosage' is requested and any variant is multi-allelic. Docs updated accordingly. I considered setting dosage on multi-allelics to missing rather than throwing an error, but I think error is safest since I could imagine the missingness leading to QC confusion, and if users want dosage in the presence of multi-allelics than they should either use a custom expression or split and then use `hl.gp_dosage`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2930#issuecomment-366829913
https://github.com/hail-is/hail/pull/2930#issuecomment-366829913:259,Availability,error,error,259,"I've addressed the two comments: now using an `entry_fields` parameter and throwing an error if 'dosage' is requested and any variant is multi-allelic. Docs updated accordingly. I considered setting dosage on multi-allelics to missing rather than throwing an error, but I think error is safest since I could imagine the missingness leading to QC confusion, and if users want dosage in the presence of multi-allelics than they should either use a custom expression or split and then use `hl.gp_dosage`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2930#issuecomment-366829913
https://github.com/hail-is/hail/pull/2930#issuecomment-366829913:278,Availability,error,error,278,"I've addressed the two comments: now using an `entry_fields` parameter and throwing an error if 'dosage' is requested and any variant is multi-allelic. Docs updated accordingly. I considered setting dosage on multi-allelics to missing rather than throwing an error, but I think error is safest since I could imagine the missingness leading to QC confusion, and if users want dosage in the presence of multi-allelics than they should either use a custom expression or split and then use `hl.gp_dosage`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2930#issuecomment-366829913
https://github.com/hail-is/hail/pull/2930#issuecomment-366829913:157,Deployability,update,updated,157,"I've addressed the two comments: now using an `entry_fields` parameter and throwing an error if 'dosage' is requested and any variant is multi-allelic. Docs updated accordingly. I considered setting dosage on multi-allelics to missing rather than throwing an error, but I think error is safest since I could imagine the missingness leading to QC confusion, and if users want dosage in the presence of multi-allelics than they should either use a custom expression or split and then use `hl.gp_dosage`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2930#issuecomment-366829913
https://github.com/hail-is/hail/pull/2930#issuecomment-366829913:287,Safety,safe,safest,287,"I've addressed the two comments: now using an `entry_fields` parameter and throwing an error if 'dosage' is requested and any variant is multi-allelic. Docs updated accordingly. I considered setting dosage on multi-allelics to missing rather than throwing an error, but I think error is safest since I could imagine the missingness leading to QC confusion, and if users want dosage in the presence of multi-allelics than they should either use a custom expression or split and then use `hl.gp_dosage`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2930#issuecomment-366829913
https://github.com/hail-is/hail/pull/2930#issuecomment-367113994:54,Usability,simpl,simple,54,"@jigold addressed your comments and, after seeing how simple it'd be to do, I came around to your point that I might as well make the same change in v1.1. Simplified the docs accordingly. We still may want to drop v1.1 at some point but Cotton agrees there is no urgency while it's not causing problems.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2930#issuecomment-367113994
https://github.com/hail-is/hail/pull/2930#issuecomment-367113994:155,Usability,Simpl,Simplified,155,"@jigold addressed your comments and, after seeing how simple it'd be to do, I came around to your point that I might as well make the same change in v1.1. Simplified the docs accordingly. We still may want to drop v1.1 at some point but Cotton agrees there is no urgency while it's not causing problems.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2930#issuecomment-367113994
https://github.com/hail-is/hail/pull/2936#issuecomment-367163174:145,Safety,redund,redundancy,145,"You can push back on the extra flush to align the block row with the buffer. It shouldn't matter too much either way, but to the extent there is redundancy per row (as there will be in UKBB LD case) I figure alignment is a net positive.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2936#issuecomment-367163174
https://github.com/hail-is/hail/pull/2950#issuecomment-367424171:4,Testability,test,tests,4,"ok, tests added. Let me know if you can think of other cases that should get tested as well.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2950#issuecomment-367424171
https://github.com/hail-is/hail/pull/2950#issuecomment-367424171:77,Testability,test,tested,77,"ok, tests added. Let me know if you can think of other cases that should get tested as well.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2950#issuecomment-367424171
https://github.com/hail-is/hail/pull/2952#issuecomment-369289579:38,Availability,error,errors,38,There's a seemingly endless stream of errors hidden by not testing impute_sex...,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2952#issuecomment-369289579
https://github.com/hail-is/hail/pull/2952#issuecomment-369289579:59,Testability,test,testing,59,There's a seemingly endless stream of errors hidden by not testing impute_sex...,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2952#issuecomment-369289579
https://github.com/hail-is/hail/pull/2955#issuecomment-367512565:8,Performance,load,loaders,8,"Now all loaders have class names `Load*` and all Suites have class names `Import*Suite` and `Export*Suite`. Plink, BGEN, and GEN were inconsistent within and with VCF, Matrix, GDB, MatrixParser, etc",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2955#issuecomment-367512565
https://github.com/hail-is/hail/pull/2955#issuecomment-367512565:34,Performance,Load,Load,34,"Now all loaders have class names `Load*` and all Suites have class names `Import*Suite` and `Export*Suite`. Plink, BGEN, and GEN were inconsistent within and with VCF, Matrix, GDB, MatrixParser, etc",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2955#issuecomment-367512565
https://github.com/hail-is/hail/pull/2956#issuecomment-367550024:20,Testability,log,logo,20,This fixes the hail logo and navbar disappearing when the level of page nesting is greater than 1. Check it works by making sure all of the links on the navbar are working and the logo is there on a page like Genetics Methods.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2956#issuecomment-367550024
https://github.com/hail-is/hail/pull/2956#issuecomment-367550024:180,Testability,log,logo,180,This fixes the hail logo and navbar disappearing when the level of page nesting is greater than 1. Check it works by making sure all of the links on the navbar are working and the logo is there on a page like Genetics Methods.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2956#issuecomment-367550024
https://github.com/hail-is/hail/pull/2958#issuecomment-369635244:83,Deployability,patch,patch,83,@cseed do you want me to make the changes and push to this branch? Or I can make a patch for you.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2958#issuecomment-369635244
https://github.com/hail-is/hail/pull/2961#issuecomment-367779655:0,Testability,test,tests,0,"tests should pass when this re-runs, ready for review.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2961#issuecomment-367779655
https://github.com/hail-is/hail/pull/2965#issuecomment-369418966:19,Modifiability,evolve,evolves,19,Closing while this evolves.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2965#issuecomment-369418966
https://github.com/hail-is/hail/issues/2970#issuecomment-408638988:45,Security,expose,expose,45,This was for a different purpose - it was to expose the globals as a separate one row table. But I don't think that's necessary and am happy to close,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2970#issuecomment-408638988
https://github.com/hail-is/hail/pull/2975#issuecomment-368108496:477,Availability,down,down,477,"@tpoterba That example loses the singletons (nodes with no edges that are not passed to the maximal_independent_set method). With the old method, we worked around this by collecting all the nodes in python (both nodes with edges and singleton nodes) and then filtering to remove the nodes returned by maximal_independent_set. But collecting all the nodes in python and then passing them to filter_rows is slow. So I'm moving the logic of collecting all the nodes and filtering down to Scala.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2975#issuecomment-368108496
https://github.com/hail-is/hail/pull/2975#issuecomment-368108496:429,Testability,log,logic,429,"@tpoterba That example loses the singletons (nodes with no edges that are not passed to the maximal_independent_set method). With the old method, we worked around this by collecting all the nodes in python (both nodes with edges and singleton nodes) and then filtering to remove the nodes returned by maximal_independent_set. But collecting all the nodes in python and then passing them to filter_rows is slow. So I'm moving the logic of collecting all the nodes and filtering down to Scala.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2975#issuecomment-368108496
https://github.com/hail-is/hail/pull/2975#issuecomment-368139225:668,Testability,log,logic,668,"My original motivation for this was to speed up the following code in LD prune: . ```; related_nodes = edges.aggregate(agg.collect_as_set(agg.explode([edges['i'], edges['j']]))); related_nodes_to_keep = maximal_independent_set(edges['i'], edges['j']); related_nodes_to_remove = related_nodes - set(related_nodes_to_keep). pruned_ds = (locally_pruned_ds; .filter_rows(functions.broadcast(related_nodes_to_remove); .contains(locally_pruned_ds.variant_idx), ; keep=False)); ```; It's my understanding that the last line of this code is slow because passing a large python list over py4j is slow. Adding a keep/remove flag to maximal_independent_set would address the set logic and slowness of collecting the set of nodes, but not the other speed issue, since maximal_independent_set would still return a python list. . I could add the keep/remove flag, and also edit the method on the Scala side to create and return a new single-column Table of nodes to remove. Is this preferable?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2975#issuecomment-368139225
https://github.com/hail-is/hail/pull/2975#issuecomment-368139620:79,Safety,avoid,avoid,79,"Sorry to be naive, I haven't really bumped into this method much. We can still avoid python lists by returning a table with one column instead of a set!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2975#issuecomment-368139620
https://github.com/hail-is/hail/pull/2975#issuecomment-368139786:20,Integrability,interface,interface,20,That's a super nice interface.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2975#issuecomment-368139786
https://github.com/hail-is/hail/issues/2978#issuecomment-370497953:26,Deployability,install,install,26,I second this one. Had to install the `parsimonious` module which was missing from my Anaconda Python.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2978#issuecomment-370497953
https://github.com/hail-is/hail/issues/2978#issuecomment-370498224:31,Testability,test,test,31,I think we really just need to test/maintain this file and point to it in the docs:; https://github.com/hail-is/hail/blob/master/python/hail/environment.yml. Would that have helped?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2978#issuecomment-370498224
https://github.com/hail-is/hail/issues/2978#issuecomment-370499062:61,Deployability,install,installing,61,"Yes, it would. Slightly unfair test in my case because I was installing a dev build in preparation for the workshop Cotton is giving tomorrow, but thought I should report it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2978#issuecomment-370499062
https://github.com/hail-is/hail/issues/2978#issuecomment-370499062:31,Testability,test,test,31,"Yes, it would. Slightly unfair test in my case because I was installing a dev build in preparation for the workshop Cotton is giving tomorrow, but thought I should report it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2978#issuecomment-370499062
https://github.com/hail-is/hail/issues/2978#issuecomment-378608438:96,Usability,feedback,feedback,96,the getting_started docs now point to using conda envs with the environment.yml. Thanks for the feedback @verdurin!,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/2978#issuecomment-378608438
https://github.com/hail-is/hail/pull/2985#issuecomment-368348981:177,Availability,redundant,redundant,177,"Removing a plural, for example:. movies = movies.explode('genres', name='genre'). I feel like this is natural and will be pretty common so it should be easy. Yes, I agree it is redundant. The alternative is:. movies = movies.explode('genres').rename({'genres': 'genre'}). which duplicates the column being exploded. If we're happy with the latter, I'm happy to close this.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2985#issuecomment-368348981
https://github.com/hail-is/hail/pull/2985#issuecomment-368348981:177,Safety,redund,redundant,177,"Removing a plural, for example:. movies = movies.explode('genres', name='genre'). I feel like this is natural and will be pretty common so it should be easy. Yes, I agree it is redundant. The alternative is:. movies = movies.explode('genres').rename({'genres': 'genre'}). which duplicates the column being exploded. If we're happy with the latter, I'm happy to close this.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2985#issuecomment-368348981
https://github.com/hail-is/hail/pull/2985#issuecomment-368351765:44,Modifiability,extend,extend,44,just one thing to think about -- we plan to extend table.explode to handle nested fields like matrixtable.explode_rows and cols. What are the semantics of `name` in this context? Does it rename the deepest field? That seems reasonable to me.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2985#issuecomment-368351765
https://github.com/hail-is/hail/pull/2995#issuecomment-369619464:84,Integrability,interface,interface,84,"refactored the four block matrix operators to match for now, I'll later change this interface to be numpy-like and match local matrix",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2995#issuecomment-369619464
https://github.com/hail-is/hail/pull/2995#issuecomment-369619464:0,Modifiability,refactor,refactored,0,"refactored the four block matrix operators to match for now, I'll later change this interface to be numpy-like and match local matrix",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2995#issuecomment-369619464
https://github.com/hail-is/hail/pull/2998#issuecomment-368885298:0,Testability,test,test,0,test how?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2998#issuecomment-368885298
https://github.com/hail-is/hail/pull/2998#issuecomment-368885849:327,Availability,error,error,327,"I did make sure it renders as I intended, and the round trip test means it produces valid type grammar. but I'm hesitant to add a test for exact characters, since if we want to change spacing or something cosmetic then we have to change the test. I feel the same way about assertRaisesRegex checks -- we should be able to make error messages nicer.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2998#issuecomment-368885849
https://github.com/hail-is/hail/pull/2998#issuecomment-368885849:333,Integrability,message,messages,333,"I did make sure it renders as I intended, and the round trip test means it produces valid type grammar. but I'm hesitant to add a test for exact characters, since if we want to change spacing or something cosmetic then we have to change the test. I feel the same way about assertRaisesRegex checks -- we should be able to make error messages nicer.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2998#issuecomment-368885849
https://github.com/hail-is/hail/pull/2998#issuecomment-368885849:61,Testability,test,test,61,"I did make sure it renders as I intended, and the round trip test means it produces valid type grammar. but I'm hesitant to add a test for exact characters, since if we want to change spacing or something cosmetic then we have to change the test. I feel the same way about assertRaisesRegex checks -- we should be able to make error messages nicer.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2998#issuecomment-368885849
https://github.com/hail-is/hail/pull/2998#issuecomment-368885849:130,Testability,test,test,130,"I did make sure it renders as I intended, and the round trip test means it produces valid type grammar. but I'm hesitant to add a test for exact characters, since if we want to change spacing or something cosmetic then we have to change the test. I feel the same way about assertRaisesRegex checks -- we should be able to make error messages nicer.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2998#issuecomment-368885849
https://github.com/hail-is/hail/pull/2998#issuecomment-368885849:241,Testability,test,test,241,"I did make sure it renders as I intended, and the round trip test means it produces valid type grammar. but I'm hesitant to add a test for exact characters, since if we want to change spacing or something cosmetic then we have to change the test. I feel the same way about assertRaisesRegex checks -- we should be able to make error messages nicer.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2998#issuecomment-368885849
https://github.com/hail-is/hail/pull/2998#issuecomment-368885849:273,Testability,assert,assertRaisesRegex,273,"I did make sure it renders as I intended, and the round trip test means it produces valid type grammar. but I'm hesitant to add a test for exact characters, since if we want to change spacing or something cosmetic then we have to change the test. I feel the same way about assertRaisesRegex checks -- we should be able to make error messages nicer.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/2998#issuecomment-368885849
https://github.com/hail-is/hail/pull/3000#issuecomment-369023286:19,Testability,log,logreg,19,"All of the linreg, logreg, lmm, skat field names need to be converted. Feel free to push back for future PR.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3000#issuecomment-369023286
https://github.com/hail-is/hail/issues/3001#issuecomment-368912193:21,Deployability,update,update,21,Ok thank you for the update let me try 2.2.0 . Highly appreciate a quick reply.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3001#issuecomment-368912193
https://github.com/hail-is/hail/issues/3001#issuecomment-375939652:71,Availability,error,error,71,"Using the Master branch version and Spark 2.2.1, I am getting the same error. Is Spark 2.2,1 supported? Any suggestions?. ```; /gradlew -Dspark.version=2.2.1 shadowJar archiveZip; fdf130b2f5d4. FAILURE: Build failed with an exception. * Where:; Build file '/restricted/projectnb/genpro/github/hail/build.gradle' line: 57. * What went wrong:; A problem occurred evaluating root project 'hail'.; > Unknown Spark version 2.2.1. Set breeze.version and py4j.version properties for Spark 2.2.1. * Try:; Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. BUILD FAILED. Total time: 6.187 secs; ```; ```; env|grep SPARK; SPARK_HOME=/share/pkg/spark/2.2.1/install; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3001#issuecomment-375939652
https://github.com/hail-is/hail/issues/3001#issuecomment-375939652:194,Availability,FAILURE,FAILURE,194,"Using the Master branch version and Spark 2.2.1, I am getting the same error. Is Spark 2.2,1 supported? Any suggestions?. ```; /gradlew -Dspark.version=2.2.1 shadowJar archiveZip; fdf130b2f5d4. FAILURE: Build failed with an exception. * Where:; Build file '/restricted/projectnb/genpro/github/hail/build.gradle' line: 57. * What went wrong:; A problem occurred evaluating root project 'hail'.; > Unknown Spark version 2.2.1. Set breeze.version and py4j.version properties for Spark 2.2.1. * Try:; Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. BUILD FAILED. Total time: 6.187 secs; ```; ```; env|grep SPARK; SPARK_HOME=/share/pkg/spark/2.2.1/install; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3001#issuecomment-375939652
https://github.com/hail-is/hail/issues/3001#issuecomment-375939652:706,Deployability,install,install,706,"Using the Master branch version and Spark 2.2.1, I am getting the same error. Is Spark 2.2,1 supported? Any suggestions?. ```; /gradlew -Dspark.version=2.2.1 shadowJar archiveZip; fdf130b2f5d4. FAILURE: Build failed with an exception. * Where:; Build file '/restricted/projectnb/genpro/github/hail/build.gradle' line: 57. * What went wrong:; A problem occurred evaluating root project 'hail'.; > Unknown Spark version 2.2.1. Set breeze.version and py4j.version properties for Spark 2.2.1. * Try:; Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. BUILD FAILED. Total time: 6.187 secs; ```; ```; env|grep SPARK; SPARK_HOME=/share/pkg/spark/2.2.1/install; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3001#issuecomment-375939652
https://github.com/hail-is/hail/issues/3001#issuecomment-375939652:596,Testability,log,log,596,"Using the Master branch version and Spark 2.2.1, I am getting the same error. Is Spark 2.2,1 supported? Any suggestions?. ```; /gradlew -Dspark.version=2.2.1 shadowJar archiveZip; fdf130b2f5d4. FAILURE: Build failed with an exception. * Where:; Build file '/restricted/projectnb/genpro/github/hail/build.gradle' line: 57. * What went wrong:; A problem occurred evaluating root project 'hail'.; > Unknown Spark version 2.2.1. Set breeze.version and py4j.version properties for Spark 2.2.1. * Try:; Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. BUILD FAILED. Total time: 6.187 secs; ```; ```; env|grep SPARK; SPARK_HOME=/share/pkg/spark/2.2.1/install; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3001#issuecomment-375939652
https://github.com/hail-is/hail/issues/3001#issuecomment-375979411:180,Availability,down,download,180,Thanks! That helped. There a couple of other issues that came up that required some tinkering. I list them below in case any one runs into them also. 1. curl failed when trying to download the ibsimdpp lib. The workaround was to download it with wget and move it to the Make Directory. ```; wget --no-check-certificate https://storage.googleapis.com/hail-common/libsimdpp-2.0-rc2.tar.gz; mv libsimdpp-2.0-rc2.tar.gz src/main/c; ```. 2. Needed to compile with newer version of gcc; ```; module load gcc/7.2.0; ./gradlew -Dspark.version=2.2.1 -Dpy4j.version=0.10.4 -Dbreeze.version=0.13.1 shadowJar archiveZip. ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3001#issuecomment-375979411
https://github.com/hail-is/hail/issues/3001#issuecomment-375979411:229,Availability,down,download,229,Thanks! That helped. There a couple of other issues that came up that required some tinkering. I list them below in case any one runs into them also. 1. curl failed when trying to download the ibsimdpp lib. The workaround was to download it with wget and move it to the Make Directory. ```; wget --no-check-certificate https://storage.googleapis.com/hail-common/libsimdpp-2.0-rc2.tar.gz; mv libsimdpp-2.0-rc2.tar.gz src/main/c; ```. 2. Needed to compile with newer version of gcc; ```; module load gcc/7.2.0; ./gradlew -Dspark.version=2.2.1 -Dpy4j.version=0.10.4 -Dbreeze.version=0.13.1 shadowJar archiveZip. ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3001#issuecomment-375979411
https://github.com/hail-is/hail/issues/3001#issuecomment-375979411:493,Performance,load,load,493,Thanks! That helped. There a couple of other issues that came up that required some tinkering. I list them below in case any one runs into them also. 1. curl failed when trying to download the ibsimdpp lib. The workaround was to download it with wget and move it to the Make Directory. ```; wget --no-check-certificate https://storage.googleapis.com/hail-common/libsimdpp-2.0-rc2.tar.gz; mv libsimdpp-2.0-rc2.tar.gz src/main/c; ```. 2. Needed to compile with newer version of gcc; ```; module load gcc/7.2.0; ./gradlew -Dspark.version=2.2.1 -Dpy4j.version=0.10.4 -Dbreeze.version=0.13.1 shadowJar archiveZip. ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3001#issuecomment-375979411
https://github.com/hail-is/hail/issues/3001#issuecomment-375979411:307,Security,certificate,certificate,307,Thanks! That helped. There a couple of other issues that came up that required some tinkering. I list them below in case any one runs into them also. 1. curl failed when trying to download the ibsimdpp lib. The workaround was to download it with wget and move it to the Make Directory. ```; wget --no-check-certificate https://storage.googleapis.com/hail-common/libsimdpp-2.0-rc2.tar.gz; mv libsimdpp-2.0-rc2.tar.gz src/main/c; ```. 2. Needed to compile with newer version of gcc; ```; module load gcc/7.2.0; ./gradlew -Dspark.version=2.2.1 -Dpy4j.version=0.10.4 -Dbreeze.version=0.13.1 shadowJar archiveZip. ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3001#issuecomment-375979411
https://github.com/hail-is/hail/issues/3001#issuecomment-908358179:89,Availability,FAILURE,FAILURE,89,`./gradlew -Dspark.version=3.1.1 shadowJar archiveZip`; failed for the main branch. ```; FAILURE: Build failed with an exception. * What went wrong:; Task 'archiveZip' not found in root project 'hail'.; ```. any suggestion?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3001#issuecomment-908358179
https://github.com/hail-is/hail/issues/3001#issuecomment-908570000:184,Deployability,deploy,deploy,184,"> Are you running that `gradlew` command directly? You should be using `make`. https://hail.is/docs/0.2/getting_started_developing.html. I followed the steps on the site but failed to deploy to aws ; `; Invalid input: Exception in thread ""main"" java.io.FileNotFoundException: No such file or directory 's3://xxxxx/artifacts/hail-python.zip'`",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3001#issuecomment-908570000
https://github.com/hail-is/hail/issues/3001#issuecomment-908575361:197,Deployability,deploy,deploy,197,"Ok, this is seeming not related to this closed github issue. Can you make a post on our support forum: https://discuss.hail.is/ explaining what step went wrong (I'm not sure where you're trying to deploy to AWS or what your installation procedure is here)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3001#issuecomment-908575361
https://github.com/hail-is/hail/issues/3001#issuecomment-908575361:224,Deployability,install,installation,224,"Ok, this is seeming not related to this closed github issue. Can you make a post on our support forum: https://discuss.hail.is/ explaining what step went wrong (I'm not sure where you're trying to deploy to AWS or what your installation procedure is here)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3001#issuecomment-908575361
https://github.com/hail-is/hail/pull/3004#issuecomment-369286513:17,Usability,clear,clear,17,Should have been clear about that though!!,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3004#issuecomment-369286513
https://github.com/hail-is/hail/issues/3015#issuecomment-373027311:40,Availability,error,error,40,Yep! Loaded it up and it worked without error. Thanks!,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3015#issuecomment-373027311
https://github.com/hail-is/hail/issues/3015#issuecomment-373027311:5,Performance,Load,Loaded,5,Yep! Loaded it up and it worked without error. Thanks!,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3015#issuecomment-373027311
https://github.com/hail-is/hail/pull/3019#issuecomment-369657687:14,Availability,failure,failure,14,also see test failure,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3019#issuecomment-369657687
https://github.com/hail-is/hail/pull/3019#issuecomment-369657687:9,Testability,test,test,9,also see test failure,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3019#issuecomment-369657687
https://github.com/hail-is/hail/pull/3027#issuecomment-369460837:53,Testability,test,tests,53,"I implemented Table.globals, too, and added a couple tests.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3027#issuecomment-369460837
https://github.com/hail-is/hail/issues/3038#issuecomment-369615427:60,Availability,error,error,60,(can fix by defining `def __iter__` on MT/Table to throw an error),MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3038#issuecomment-369615427
https://github.com/hail-is/hail/pull/3043#issuecomment-369993008:278,Performance,load,load,278,"I'm not really sure, either. I figured as long as every type was in there somewhere at least once and some things were missing, it would be fine. This is just to check backward compatibility, so it's hard to imagine that (1) the current version passes all the tests, (2) it can load a reasonable collections of types and values from an old version, but (3) only, say, missing calls are broken.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3043#issuecomment-369993008
https://github.com/hail-is/hail/pull/3043#issuecomment-369993008:260,Testability,test,tests,260,"I'm not really sure, either. I figured as long as every type was in there somewhere at least once and some things were missing, it would be fine. This is just to check backward compatibility, so it's hard to imagine that (1) the current version passes all the tests, (2) it can load a reasonable collections of types and values from an old version, but (3) only, say, missing calls are broken.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3043#issuecomment-369993008
https://github.com/hail-is/hail/issues/3053#issuecomment-369956421:11,Deployability,pipeline,pipeline,11,"Oh and the pipeline is a series of:; ```; next_vds = hl.read_matrix_table('{}/parts/part_{}.vds'.format(root, base)); next_vds = next_vds.select_rows(next_vds.row_id); vds = vds.union_cols(next_vds); ```; (about 30 of them and then a write)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3053#issuecomment-369956421
https://github.com/hail-is/hail/issues/3053#issuecomment-419655426:84,Availability,error,errors,84,"Hi @konradjk Did you ever determine a cause of this? I am seeing very, very similar errors in an unrelated project (but also executing in GCP).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3053#issuecomment-419655426
https://github.com/hail-is/hail/issues/3053#issuecomment-419657089:149,Deployability,pipeline,pipeline,149,"No, the framework has changed a lot since then so it just works now. My guess for why this happens would be memory issues, but not sure. What's your pipeline?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3053#issuecomment-419657089
https://github.com/hail-is/hail/issues/3053#issuecomment-419967871:172,Deployability,upgrade,upgrade,172,"@konradjk Yes, sadly I can reproduce it 100% of the time. I won't be actively working on this for the time being, and I'll hope that when I come back to it a JDK and/or OS upgrade on the dataproc side has fixed it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3053#issuecomment-419967871
https://github.com/hail-is/hail/issues/3053#issuecomment-419972098:175,Availability,toler,tolerate,175,"are you sure it's a dataproc problem?. If scalding is using java unsafe in a not-guaranteed-to-work way, then a core dump s totally possible. Example - the JVM will sometimes tolerate misaligned floats/ints, and sometimes will crash.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3053#issuecomment-419972098
https://github.com/hail-is/hail/issues/3053#issuecomment-419972098:65,Safety,unsafe,unsafe,65,"are you sure it's a dataproc problem?. If scalding is using java unsafe in a not-guaranteed-to-work way, then a core dump s totally possible. Example - the JVM will sometimes tolerate misaligned floats/ints, and sometimes will crash.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3053#issuecomment-419972098
https://github.com/hail-is/hail/issues/3053#issuecomment-444135177:135,Modifiability,config,config,135,"@tpoterba @konradjk A workaround for this issue, should you encounter it again, is to disable the conscrypt library with this dataproc config:. `dataproc:dataproc.conscrypt.provider.enable: 'false'`. Capturing a core file provided a little more detail, but google support cannot explain why it happens. Cheers.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3053#issuecomment-444135177
https://github.com/hail-is/hail/issues/3053#issuecomment-444175470:29,Deployability,update,update,29,"huh, interesting. Thanks for update!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3053#issuecomment-444175470
https://github.com/hail-is/hail/pull/3054#issuecomment-371308286:123,Testability,test,tests,123,@cseed I changed `includeStart` to `includesStart` everywhere except the JSON because it broke the backwards compatibility tests. Let me know if you'd prefer I only renamed the Python attributes.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3054#issuecomment-371308286
https://github.com/hail-is/hail/pull/3055#issuecomment-369985720:254,Availability,error,errors,254,"top_level references are references to things that should be in the EvalContext. top_level=False are references intermediate variables. Inside the view_join_x stuff, we constructed top_level=False references to things like `row` and `va`, so these threw errors if used inside aggregators. I'll add a test for this.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3055#issuecomment-369985720
https://github.com/hail-is/hail/pull/3055#issuecomment-369985720:125,Modifiability,variab,variables,125,"top_level references are references to things that should be in the EvalContext. top_level=False are references intermediate variables. Inside the view_join_x stuff, we constructed top_level=False references to things like `row` and `va`, so these threw errors if used inside aggregators. I'll add a test for this.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3055#issuecomment-369985720
https://github.com/hail-is/hail/pull/3055#issuecomment-369985720:300,Testability,test,test,300,"top_level references are references to things that should be in the EvalContext. top_level=False are references intermediate variables. Inside the view_join_x stuff, we constructed top_level=False references to things like `row` and `va`, so these threw errors if used inside aggregators. I'll add a test for this.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3055#issuecomment-369985720
https://github.com/hail-is/hail/pull/3055#issuecomment-369986005:179,Availability,error,error,179,"your intuition is exactly what we're doing. We look for bind and lambda AST nodes, add those to the declared scope. If we find a `top_level=False` reference not in that scope, we error.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3055#issuecomment-369986005
https://github.com/hail-is/hail/pull/3055#issuecomment-369986005:5,Usability,intuit,intuition,5,"your intuition is exactly what we're doing. We look for bind and lambda AST nodes, add those to the declared scope. If we find a `top_level=False` reference not in that scope, we error.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3055#issuecomment-369986005
https://github.com/hail-is/hail/pull/3056#issuecomment-370023129:19,Testability,test,tests,19,You'll need to fix tests that use sample id annotation from balding nichols model.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3056#issuecomment-370023129
https://github.com/hail-is/hail/pull/3062#issuecomment-370081471:24,Usability,simpl,simplifying,24,"What do you think about simplifying the name to `annotation`? I think that's just as clear as `annotationFromRG`, especially as the RG is optional.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3062#issuecomment-370081471
https://github.com/hail-is/hail/pull/3062#issuecomment-370081471:85,Usability,clear,clear,85,"What do you think about simplifying the name to `annotation`? I think that's just as clear as `annotationFromRG`, especially as the RG is optional.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3062#issuecomment-370081471
https://github.com/hail-is/hail/pull/3064#issuecomment-370149825:288,Deployability,update,updates,288,"We may want to use NumPy ndarray as local matrix now, to avoid interface duplication and grab all its functionality, even if there's a performance hit in moving between Python and Java (worst case, we go through disk). I'm going to close this while we strategize, will PR the BlockMatrix updates separately.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3064#issuecomment-370149825
https://github.com/hail-is/hail/pull/3064#issuecomment-370149825:63,Integrability,interface,interface,63,"We may want to use NumPy ndarray as local matrix now, to avoid interface duplication and grab all its functionality, even if there's a performance hit in moving between Python and Java (worst case, we go through disk). I'm going to close this while we strategize, will PR the BlockMatrix updates separately.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3064#issuecomment-370149825
https://github.com/hail-is/hail/pull/3064#issuecomment-370149825:135,Performance,perform,performance,135,"We may want to use NumPy ndarray as local matrix now, to avoid interface duplication and grab all its functionality, even if there's a performance hit in moving between Python and Java (worst case, we go through disk). I'm going to close this while we strategize, will PR the BlockMatrix updates separately.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3064#issuecomment-370149825
https://github.com/hail-is/hail/pull/3064#issuecomment-370149825:57,Safety,avoid,avoid,57,"We may want to use NumPy ndarray as local matrix now, to avoid interface duplication and grab all its functionality, even if there's a performance hit in moving between Python and Java (worst case, we go through disk). I'm going to close this while we strategize, will PR the BlockMatrix updates separately.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3064#issuecomment-370149825
https://github.com/hail-is/hail/pull/3065#issuecomment-370182016:40,Deployability,update,update,40,will add this to the style guide when I update it,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3065#issuecomment-370182016
https://github.com/hail-is/hail/pull/3065#issuecomment-370182016:27,Usability,guid,guide,27,will add this to the style guide when I update it,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3065#issuecomment-370182016
https://github.com/hail-is/hail/pull/3066#issuecomment-370152354:11,Availability,error,errors,11,And mendel errors (which still needs to be rewritten in Python),MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3066#issuecomment-370152354
https://github.com/hail-is/hail/pull/3072#issuecomment-370569833:276,Availability,robust,robust,276,"Comments addressed. You asked about scalars so I've rounded that out with support for any combination of scalar and block matrix, as well as unary + and -, testing in notebook along the way. I've marked the class with experimental.rst until I've stabilized the interface with robust testing of all operations in subsequent broadcasting PR. I fixed the process_joins bug as noted, but stopped there in this PR since just switching to select_entries will end up calling the expression machinery twice. The right solution requires simultaneous changes on the Scala side. I'll make a PR to check if `entry_expr` is a field, if not to use `select_entries` to make it one, and then change `MatrixTable.writeBlockMatrix` to take a field rather than an expression. Sound good?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3072#issuecomment-370569833
https://github.com/hail-is/hail/pull/3072#issuecomment-370569833:261,Integrability,interface,interface,261,"Comments addressed. You asked about scalars so I've rounded that out with support for any combination of scalar and block matrix, as well as unary + and -, testing in notebook along the way. I've marked the class with experimental.rst until I've stabilized the interface with robust testing of all operations in subsequent broadcasting PR. I fixed the process_joins bug as noted, but stopped there in this PR since just switching to select_entries will end up calling the expression machinery twice. The right solution requires simultaneous changes on the Scala side. I'll make a PR to check if `entry_expr` is a field, if not to use `select_entries` to make it one, and then change `MatrixTable.writeBlockMatrix` to take a field rather than an expression. Sound good?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3072#issuecomment-370569833
https://github.com/hail-is/hail/pull/3072#issuecomment-370569833:156,Testability,test,testing,156,"Comments addressed. You asked about scalars so I've rounded that out with support for any combination of scalar and block matrix, as well as unary + and -, testing in notebook along the way. I've marked the class with experimental.rst until I've stabilized the interface with robust testing of all operations in subsequent broadcasting PR. I fixed the process_joins bug as noted, but stopped there in this PR since just switching to select_entries will end up calling the expression machinery twice. The right solution requires simultaneous changes on the Scala side. I'll make a PR to check if `entry_expr` is a field, if not to use `select_entries` to make it one, and then change `MatrixTable.writeBlockMatrix` to take a field rather than an expression. Sound good?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3072#issuecomment-370569833
https://github.com/hail-is/hail/pull/3072#issuecomment-370569833:283,Testability,test,testing,283,"Comments addressed. You asked about scalars so I've rounded that out with support for any combination of scalar and block matrix, as well as unary + and -, testing in notebook along the way. I've marked the class with experimental.rst until I've stabilized the interface with robust testing of all operations in subsequent broadcasting PR. I fixed the process_joins bug as noted, but stopped there in this PR since just switching to select_entries will end up calling the expression machinery twice. The right solution requires simultaneous changes on the Scala side. I'll make a PR to check if `entry_expr` is a field, if not to use `select_entries` to make it one, and then change `MatrixTable.writeBlockMatrix` to take a field rather than an expression. Sound good?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3072#issuecomment-370569833
https://github.com/hail-is/hail/issues/3074#issuecomment-370494908:8892,Energy Efficiency,reduce,reduceByKey,8892,t.scala:285); 	at org.apache.spark.rdd.UnionRDD.getPartitions(UnionRDD.scala:84); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250); 	at scala.Option.getOrElse(Option.scala:121); 	at org.apache.spark.rdd.RDD.partitions(RDD.scala:250); 	at org.apache.spark.Partitioner$$anonfun$defaultPartitioner$2.apply(Partitioner.scala:66); 	at org.apache.spark.Partitioner$$anonfun$defaultPartitioner$2.apply(Partitioner.scala:66); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.immutable.List.foreach(List.scala:381); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.immutable.List.map(List.scala:285); 	at org.apache.spark.Partitioner$.defaultPartitioner(Partitioner.scala:66); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3.apply(PairRDDFunctions.scala:329); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3.apply(PairRDDFunctions.scala:329); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); 	at org.apache.spark.rdd.PairRDDFunctions.reduceByKey(PairRDDFunctions.scala:328); 	at is.hail.methods.MendelErrors.nErrorPerNuclearFamily(MendelErrors.scala:145); 	at is.hail.methods.MendelErrors.fMendelKT(MendelErrors.scala:184); 	at is.hail.variant.MatrixTable.mendelErrors(MatrixTable.scala:1913); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodI,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3074#issuecomment-370494908
https://github.com/hail-is/hail/issues/3074#issuecomment-370494908:8992,Energy Efficiency,reduce,reduceByKey,8992,rk.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250); 	at scala.Option.getOrElse(Option.scala:121); 	at org.apache.spark.rdd.RDD.partitions(RDD.scala:250); 	at org.apache.spark.Partitioner$$anonfun$defaultPartitioner$2.apply(Partitioner.scala:66); 	at org.apache.spark.Partitioner$$anonfun$defaultPartitioner$2.apply(Partitioner.scala:66); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.immutable.List.foreach(List.scala:381); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.immutable.List.map(List.scala:285); 	at org.apache.spark.Partitioner$.defaultPartitioner(Partitioner.scala:66); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3.apply(PairRDDFunctions.scala:329); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3.apply(PairRDDFunctions.scala:329); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); 	at org.apache.spark.rdd.PairRDDFunctions.reduceByKey(PairRDDFunctions.scala:328); 	at is.hail.methods.MendelErrors.nErrorPerNuclearFamily(MendelErrors.scala:145); 	at is.hail.methods.MendelErrors.fMendelKT(MendelErrors.scala:184); 	at is.hail.variant.MatrixTable.mendelErrors(MatrixTable.scala:1913); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3074#issuecomment-370494908
https://github.com/hail-is/hail/issues/3074#issuecomment-370494908:9306,Energy Efficiency,reduce,reduceByKey,9306,pply(Partitioner.scala:66); 	at org.apache.spark.Partitioner$$anonfun$defaultPartitioner$2.apply(Partitioner.scala:66); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.immutable.List.foreach(List.scala:381); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.immutable.List.map(List.scala:285); 	at org.apache.spark.Partitioner$.defaultPartitioner(Partitioner.scala:66); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3.apply(PairRDDFunctions.scala:329); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3.apply(PairRDDFunctions.scala:329); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); 	at org.apache.spark.rdd.PairRDDFunctions.reduceByKey(PairRDDFunctions.scala:328); 	at is.hail.methods.MendelErrors.nErrorPerNuclearFamily(MendelErrors.scala:145); 	at is.hail.methods.MendelErrors.fMendelKT(MendelErrors.scala:184); 	at is.hail.variant.MatrixTable.mendelErrors(MatrixTable.scala:1913); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3074#issuecomment-370494908
https://github.com/hail-is/hail/issues/3074#issuecomment-370494908:70,Testability,Assert,AssertionError,70,Got through that now. Now hitting:; ```; Java stack trace:; java.lang.AssertionError: assertion failed; 	at scala.Predef$.assert(Predef.scala:156); 	at is.hail.rvd.OrderedRVDPartitioner.getPartitionPK(OrderedRVDPartitioner.scala:59); 	at is.hail.sparkextras.OrderedDependency$.getDependencies(OrderedRDD2.scala:22); 	at is.hail.sparkextras.OrderedJoinDistinctRDD2$$anonfun$getPartitions$1.apply(OrderedRDD2.scala:42); 	at is.hail.sparkextras.OrderedJoinDistinctRDD2$$anonfun$getPartitions$1.apply(OrderedRDD2.scala:39); 	at scala.Array$.tabulate(Array.scala:331); 	at is.hail.sparkextras.OrderedJoinDistinctRDD2.getPartitions(OrderedRDD2.scala:39); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250); 	at scala.Option.getOrElse(Option.scala:121); 	at org.apache.spark.rdd.RDD.partitions(RDD.scala:250); 	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250); 	at scala.Option.getOrElse(Option.scala:121); 	at org.apache.spark.rdd.RDD.partitions(RDD.scala:250); 	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250); 	at scala.Option.getOrElse(Option.scala:121); 	at org.apache.spark.rdd.RDD.partitions(RDD.scala:250); 	at org.apache.spark.rdd.RDD.getNumPartitions(RDD.scala:266); 	at is.hail.rvd.RVD$class.getNumPartitions(RVD.scala:128); 	at is.hail.rvd.OrderedRVD.getNumPartitions(OrderedRVD.scala:19); 	at is.hail.sparkextras.OrderedJoinDistinctRDD2.getPartitions(OrderedRDD2.scala:39); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250); 	at scala.Option.getOr,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3074#issuecomment-370494908
https://github.com/hail-is/hail/issues/3074#issuecomment-370494908:86,Testability,assert,assertion,86,Got through that now. Now hitting:; ```; Java stack trace:; java.lang.AssertionError: assertion failed; 	at scala.Predef$.assert(Predef.scala:156); 	at is.hail.rvd.OrderedRVDPartitioner.getPartitionPK(OrderedRVDPartitioner.scala:59); 	at is.hail.sparkextras.OrderedDependency$.getDependencies(OrderedRDD2.scala:22); 	at is.hail.sparkextras.OrderedJoinDistinctRDD2$$anonfun$getPartitions$1.apply(OrderedRDD2.scala:42); 	at is.hail.sparkextras.OrderedJoinDistinctRDD2$$anonfun$getPartitions$1.apply(OrderedRDD2.scala:39); 	at scala.Array$.tabulate(Array.scala:331); 	at is.hail.sparkextras.OrderedJoinDistinctRDD2.getPartitions(OrderedRDD2.scala:39); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250); 	at scala.Option.getOrElse(Option.scala:121); 	at org.apache.spark.rdd.RDD.partitions(RDD.scala:250); 	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250); 	at scala.Option.getOrElse(Option.scala:121); 	at org.apache.spark.rdd.RDD.partitions(RDD.scala:250); 	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250); 	at scala.Option.getOrElse(Option.scala:121); 	at org.apache.spark.rdd.RDD.partitions(RDD.scala:250); 	at org.apache.spark.rdd.RDD.getNumPartitions(RDD.scala:266); 	at is.hail.rvd.RVD$class.getNumPartitions(RVD.scala:128); 	at is.hail.rvd.OrderedRVD.getNumPartitions(OrderedRVD.scala:19); 	at is.hail.sparkextras.OrderedJoinDistinctRDD2.getPartitions(OrderedRDD2.scala:39); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250); 	at scala.Option.getOr,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3074#issuecomment-370494908
https://github.com/hail-is/hail/issues/3074#issuecomment-370494908:122,Testability,assert,assert,122,Got through that now. Now hitting:; ```; Java stack trace:; java.lang.AssertionError: assertion failed; 	at scala.Predef$.assert(Predef.scala:156); 	at is.hail.rvd.OrderedRVDPartitioner.getPartitionPK(OrderedRVDPartitioner.scala:59); 	at is.hail.sparkextras.OrderedDependency$.getDependencies(OrderedRDD2.scala:22); 	at is.hail.sparkextras.OrderedJoinDistinctRDD2$$anonfun$getPartitions$1.apply(OrderedRDD2.scala:42); 	at is.hail.sparkextras.OrderedJoinDistinctRDD2$$anonfun$getPartitions$1.apply(OrderedRDD2.scala:39); 	at scala.Array$.tabulate(Array.scala:331); 	at is.hail.sparkextras.OrderedJoinDistinctRDD2.getPartitions(OrderedRDD2.scala:39); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250); 	at scala.Option.getOrElse(Option.scala:121); 	at org.apache.spark.rdd.RDD.partitions(RDD.scala:250); 	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250); 	at scala.Option.getOrElse(Option.scala:121); 	at org.apache.spark.rdd.RDD.partitions(RDD.scala:250); 	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250); 	at scala.Option.getOrElse(Option.scala:121); 	at org.apache.spark.rdd.RDD.partitions(RDD.scala:250); 	at org.apache.spark.rdd.RDD.getNumPartitions(RDD.scala:266); 	at is.hail.rvd.RVD$class.getNumPartitions(RVD.scala:128); 	at is.hail.rvd.OrderedRVD.getNumPartitions(OrderedRVD.scala:19); 	at is.hail.sparkextras.OrderedJoinDistinctRDD2.getPartitions(OrderedRDD2.scala:39); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250); 	at scala.Option.getOr,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3074#issuecomment-370494908
https://github.com/hail-is/hail/pull/3080#issuecomment-370538411:39,Safety,avoid,avoid,39,Should `group_by_key` be `implode`? To avoid confusion with `group_by`,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3080#issuecomment-370538411
https://github.com/hail-is/hail/pull/3094#issuecomment-372663141:63,Modifiability,rewrite,rewrite,63,Umm... it just dropped two of my comments. Give me a minute to rewrite them.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3094#issuecomment-372663141
https://github.com/hail-is/hail/pull/3094#issuecomment-372717222:580,Deployability,pipeline,pipelines,580,"I went with your suggestions, changing `until` to `to` and using `foldLeft` rather than `flatMap` since it's cleaner on memory (even if slightly slower still). We can always speed these back up in any use case where they become a bottleneck, but right now they won't be. In @maccum 's pruning case there is a rectangle (window) per variant, but also a more appropriate single-pass algorithm. Definitely a performance hit on a rather heinous example using my original code versus your versions, but it's nothing compared to the distributed block matrix computations that follow in pipelines:; ```; val gp = GridPartitioner(512, 100000, 100000); val rnd = new scala.util.Random; def rects = Array.fill(100000){; val i = rnd.nextInt(90000); val j = rnd.nextInt(20000); Array[Long](i, i + 10000, i, i + 10000); }. outer: keep; inner: array. time: 66.642ms; time: 66.549ms; time: 64.039ms; time: 74.439ms. outer: for; inner: array. time: 1.251s; time: 1.389s; time: 1.439s; time: 1.353s. outer: keep; inner: for. time: 723.906ms; time: 715.612ms; time: 721.161ms; time: 707.852ms. outer: for; inner: for. time: 1.820s; time: 1.842s; time: 2.011s; time: 1.718s; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3094#issuecomment-372717222
https://github.com/hail-is/hail/pull/3094#issuecomment-372717222:230,Performance,bottleneck,bottleneck,230,"I went with your suggestions, changing `until` to `to` and using `foldLeft` rather than `flatMap` since it's cleaner on memory (even if slightly slower still). We can always speed these back up in any use case where they become a bottleneck, but right now they won't be. In @maccum 's pruning case there is a rectangle (window) per variant, but also a more appropriate single-pass algorithm. Definitely a performance hit on a rather heinous example using my original code versus your versions, but it's nothing compared to the distributed block matrix computations that follow in pipelines:; ```; val gp = GridPartitioner(512, 100000, 100000); val rnd = new scala.util.Random; def rects = Array.fill(100000){; val i = rnd.nextInt(90000); val j = rnd.nextInt(20000); Array[Long](i, i + 10000, i, i + 10000); }. outer: keep; inner: array. time: 66.642ms; time: 66.549ms; time: 64.039ms; time: 74.439ms. outer: for; inner: array. time: 1.251s; time: 1.389s; time: 1.439s; time: 1.353s. outer: keep; inner: for. time: 723.906ms; time: 715.612ms; time: 721.161ms; time: 707.852ms. outer: for; inner: for. time: 1.820s; time: 1.842s; time: 2.011s; time: 1.718s; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3094#issuecomment-372717222
https://github.com/hail-is/hail/pull/3094#issuecomment-372717222:405,Performance,perform,performance,405,"I went with your suggestions, changing `until` to `to` and using `foldLeft` rather than `flatMap` since it's cleaner on memory (even if slightly slower still). We can always speed these back up in any use case where they become a bottleneck, but right now they won't be. In @maccum 's pruning case there is a rectangle (window) per variant, but also a more appropriate single-pass algorithm. Definitely a performance hit on a rather heinous example using my original code versus your versions, but it's nothing compared to the distributed block matrix computations that follow in pipelines:; ```; val gp = GridPartitioner(512, 100000, 100000); val rnd = new scala.util.Random; def rects = Array.fill(100000){; val i = rnd.nextInt(90000); val j = rnd.nextInt(20000); Array[Long](i, i + 10000, i, i + 10000); }. outer: keep; inner: array. time: 66.642ms; time: 66.549ms; time: 64.039ms; time: 74.439ms. outer: for; inner: array. time: 1.251s; time: 1.389s; time: 1.439s; time: 1.353s. outer: keep; inner: for. time: 723.906ms; time: 715.612ms; time: 721.161ms; time: 707.852ms. outer: for; inner: for. time: 1.820s; time: 1.842s; time: 2.011s; time: 1.718s; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3094#issuecomment-372717222
https://github.com/hail-is/hail/pull/3094#issuecomment-372723395:315,Performance,perform,performance,315,"Interesting to see the benchmarks, thanks. I didn't realize there were any per-variant usages, I figured these were per-RDD. That makes me more okay with the original, but it's completely up to you. On a side note, I can't wait until we can work in C++, where using library facilities to simplify code isn't such a performance hit!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3094#issuecomment-372723395
https://github.com/hail-is/hail/pull/3094#issuecomment-372723395:23,Testability,benchmark,benchmarks,23,"Interesting to see the benchmarks, thanks. I didn't realize there were any per-variant usages, I figured these were per-RDD. That makes me more okay with the original, but it's completely up to you. On a side note, I can't wait until we can work in C++, where using library facilities to simplify code isn't such a performance hit!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3094#issuecomment-372723395
https://github.com/hail-is/hail/pull/3094#issuecomment-372723395:288,Usability,simpl,simplify,288,"Interesting to see the benchmarks, thanks. I didn't realize there were any per-variant usages, I figured these were per-RDD. That makes me more okay with the original, but it's completely up to you. On a side note, I can't wait until we can work in C++, where using library facilities to simplify code isn't such a performance hit!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3094#issuecomment-372723395
https://github.com/hail-is/hail/pull/3094#issuecomment-372727351:4,Performance,perform,performance,4,"The performance difference is driven by the number of rectangles and their size relative to block size. One use case is to partition the genome into perhaps 2k LD blocks, so 2k rectangles. Another use case is to view the genome as perhaps 10k overlapping windows. These will be handled fine. A third (as in @maccum LD prune) is to view each variant as having its own window around it, where the lower and upper bounds increase as the variant index increases. In that case, I think the algorithm should exploit the ordered-ness anyway.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3094#issuecomment-372727351
https://github.com/hail-is/hail/pull/3094#issuecomment-372728393:1053,Testability,assert,assert,1053,"Faster versions for the record:; ``` ; // returns all blocks intersecting the rectangle [firstRow, lastRow] x [firstCol, lastCol]; def rectangularBlocks(firstRow: Long, lastRow: Long, firstCol: Long, lastCol: Long): Array[Int] = {; require(firstRow >= 0 && firstRow <= lastRow && lastRow <= nRows); require(firstCol >= 0 && firstCol <= lastCol && lastCol <= nCols); ; val firstBlockRow = blockIndex(firstRow); val lastBlockRow = blockIndex(lastRow); val firstBlockCol = blockIndex(firstCol); val lastBlockCol = blockIndex(lastCol). val blocks = new Array[Int]((lastBlockRow - firstBlockRow + 1) * (lastBlockCol - firstBlockCol + 1)); ; var k = 0; var j = firstBlockCol; while (j <= lastBlockCol) {; val offset = j * nBlockRows; var i = firstBlockRow; while (i <= lastBlockRow) {; blocks(k) = offset + i; k += 1; i += 1; }; j += 1; }; ; blocks; }. // returns all blocks intersecting the union of rectangles; def rectangularBlocks(rectangles: Array[Array[Long]]): Array[Int] = {; val keep = new Array[Boolean](numPartitions); ; rectangles.foreach { r =>; assert(r.length == 4); val rBlocks = rectangularBlocks(r(0), r(1), r(2), r(3)); var i = 0; while (i < rBlocks.length) {; keep(rBlocks(i)) = true; i += 1; }; }; ; val blocks = new ArrayBuilder[Int](); var block = 0; while (block < numPartitions) {; if (keep(block)); blocks += block; block += 1; }; ; blocks.result(); }; }; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3094#issuecomment-372728393
https://github.com/hail-is/hail/pull/3095#issuecomment-371984225:98,Performance,cache,cache,98,@danking do you have an intuition for what the block size and capacity defaults should be for the cache?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3095#issuecomment-371984225
https://github.com/hail-is/hail/pull/3095#issuecomment-371984225:24,Usability,intuit,intuition,24,@danking do you have an intuition for what the block size and capacity defaults should be for the cache?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3095#issuecomment-371984225
https://github.com/hail-is/hail/pull/3095#issuecomment-371992384:104,Performance,cache,cache,104,"I do not. It's sort of hard to say without knowing how much memory the user is willing to devote to the cache, right?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3095#issuecomment-371992384
https://github.com/hail-is/hail/pull/3095#issuecomment-372359670:48,Testability,test,tested,48,@danking @tpoterba This should be good to go. I tested it on the cloud.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3095#issuecomment-372359670
https://github.com/hail-is/hail/pull/3096#issuecomment-371534813:241,Modifiability,plugin,plugin,241,"It looks like nose is a dead project. There's nose2, but judging by https://www.reddit.com/r/Python/comments/50nqlp/is_nose_still_relevant_how_about_unittest/ it isn't very widely used. Pytest seems to be most popular, and it has a coverage plugin https://pypi.python.org/pypi/pytest-cov. But if nose is working, maybe it's fine to go with it for now.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3096#issuecomment-371534813
https://github.com/hail-is/hail/pull/3096#issuecomment-371535328:132,Testability,test,testing,132,"yeah, I saw that. Not quite sure what to think -- nose seems to do what we need for now, so maybe we don't need a highly maintained testing framework?. At least in the short term, this seems OK to me. I'll spend some time looking into pytest though.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3096#issuecomment-371535328
https://github.com/hail-is/hail/pull/3096#issuecomment-371837536:113,Availability,echo,echo,113,"This seems fine now (the alternative is to continue using unittest which seems not loved for some reason?). I'll echo patrick that I would prefer we live on a test framework that's maintained. [nose2](http://nose2.readthedocs.io/en/latest/) seems to be a maintained project, but that reddit thread is hot for `pytest`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3096#issuecomment-371837536
https://github.com/hail-is/hail/pull/3096#issuecomment-371837536:159,Testability,test,test,159,"This seems fine now (the alternative is to continue using unittest which seems not loved for some reason?). I'll echo patrick that I would prefer we live on a test framework that's maintained. [nose2](http://nose2.readthedocs.io/en/latest/) seems to be a maintained project, but that reddit thread is hot for `pytest`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3096#issuecomment-371837536
https://github.com/hail-is/hail/pull/3111#issuecomment-371883548:226,Modifiability,extend,extend,226,"This PR and comments like these:. ```; // head, next, and hasNext are not meant to be used directly, only to enable; // FlipbookIterator to be used where an Iterator is expected.; ```. make me think FlipbookIterator shouldn't extend Iterator, but should have an explicit `toIterator` method.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3111#issuecomment-371883548
https://github.com/hail-is/hail/pull/3114#issuecomment-371968730:168,Usability,feedback,feedback,168,"Ack, this isn't working as written in cluster mode on GCP due to different meaning of file names locally and through Hadoop. I'll think on it but would also appreciate feedback before I go further on this branch.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3114#issuecomment-371968730
https://github.com/hail-is/hail/pull/3114#issuecomment-372165433:642,Integrability,interoperab,interoperability,642,"I've removed the Python `tempfile` approach in favor of adding `new_local_temp_file` to utils and a corresponding function to HailContext in Scala, which currently hardcodes `file:///temp` as the local temp directory. It may be more natural to have a localTmpDir on HailContext like we have tmpDir. ; I see there is a notion of local temp files on TempDir on the Scala side, but it doesn't seem to be used on the Python side. I also don't see if/where we wipe temp files on exit. In any case, I've tested that now it all works nicely on GCP, so ready for feedback/review. I think factoring through `tofile` and `fromfile` is useful for wider interoperability for the same reason that NumPy exposes them, but it's also good if you dont want to actually load the NumPy array into driver memory but just save it to read/copy later, or to load it multiple time without recomputing the BlockMatrix. And I've provided the simpler interface of `to_numpy` and `from_numpy` for the common case. I suspect that (de)serializing over the network and building the local matrix dominates local read/write, so that using a socket isn't going to do much better. I can profile more closely if/when we feel it's high priority to make this faster still.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3114#issuecomment-372165433
https://github.com/hail-is/hail/pull/3114#issuecomment-372165433:925,Integrability,interface,interface,925,"I've removed the Python `tempfile` approach in favor of adding `new_local_temp_file` to utils and a corresponding function to HailContext in Scala, which currently hardcodes `file:///temp` as the local temp directory. It may be more natural to have a localTmpDir on HailContext like we have tmpDir. ; I see there is a notion of local temp files on TempDir on the Scala side, but it doesn't seem to be used on the Python side. I also don't see if/where we wipe temp files on exit. In any case, I've tested that now it all works nicely on GCP, so ready for feedback/review. I think factoring through `tofile` and `fromfile` is useful for wider interoperability for the same reason that NumPy exposes them, but it's also good if you dont want to actually load the NumPy array into driver memory but just save it to read/copy later, or to load it multiple time without recomputing the BlockMatrix. And I've provided the simpler interface of `to_numpy` and `from_numpy` for the common case. I suspect that (de)serializing over the network and building the local matrix dominates local read/write, so that using a socket isn't going to do much better. I can profile more closely if/when we feel it's high priority to make this faster still.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3114#issuecomment-372165433
https://github.com/hail-is/hail/pull/3114#issuecomment-372165433:753,Performance,load,load,753,"I've removed the Python `tempfile` approach in favor of adding `new_local_temp_file` to utils and a corresponding function to HailContext in Scala, which currently hardcodes `file:///temp` as the local temp directory. It may be more natural to have a localTmpDir on HailContext like we have tmpDir. ; I see there is a notion of local temp files on TempDir on the Scala side, but it doesn't seem to be used on the Python side. I also don't see if/where we wipe temp files on exit. In any case, I've tested that now it all works nicely on GCP, so ready for feedback/review. I think factoring through `tofile` and `fromfile` is useful for wider interoperability for the same reason that NumPy exposes them, but it's also good if you dont want to actually load the NumPy array into driver memory but just save it to read/copy later, or to load it multiple time without recomputing the BlockMatrix. And I've provided the simpler interface of `to_numpy` and `from_numpy` for the common case. I suspect that (de)serializing over the network and building the local matrix dominates local read/write, so that using a socket isn't going to do much better. I can profile more closely if/when we feel it's high priority to make this faster still.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3114#issuecomment-372165433
https://github.com/hail-is/hail/pull/3114#issuecomment-372165433:836,Performance,load,load,836,"I've removed the Python `tempfile` approach in favor of adding `new_local_temp_file` to utils and a corresponding function to HailContext in Scala, which currently hardcodes `file:///temp` as the local temp directory. It may be more natural to have a localTmpDir on HailContext like we have tmpDir. ; I see there is a notion of local temp files on TempDir on the Scala side, but it doesn't seem to be used on the Python side. I also don't see if/where we wipe temp files on exit. In any case, I've tested that now it all works nicely on GCP, so ready for feedback/review. I think factoring through `tofile` and `fromfile` is useful for wider interoperability for the same reason that NumPy exposes them, but it's also good if you dont want to actually load the NumPy array into driver memory but just save it to read/copy later, or to load it multiple time without recomputing the BlockMatrix. And I've provided the simpler interface of `to_numpy` and `from_numpy` for the common case. I suspect that (de)serializing over the network and building the local matrix dominates local read/write, so that using a socket isn't going to do much better. I can profile more closely if/when we feel it's high priority to make this faster still.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3114#issuecomment-372165433
https://github.com/hail-is/hail/pull/3114#issuecomment-372165433:690,Security,expose,exposes,690,"I've removed the Python `tempfile` approach in favor of adding `new_local_temp_file` to utils and a corresponding function to HailContext in Scala, which currently hardcodes `file:///temp` as the local temp directory. It may be more natural to have a localTmpDir on HailContext like we have tmpDir. ; I see there is a notion of local temp files on TempDir on the Scala side, but it doesn't seem to be used on the Python side. I also don't see if/where we wipe temp files on exit. In any case, I've tested that now it all works nicely on GCP, so ready for feedback/review. I think factoring through `tofile` and `fromfile` is useful for wider interoperability for the same reason that NumPy exposes them, but it's also good if you dont want to actually load the NumPy array into driver memory but just save it to read/copy later, or to load it multiple time without recomputing the BlockMatrix. And I've provided the simpler interface of `to_numpy` and `from_numpy` for the common case. I suspect that (de)serializing over the network and building the local matrix dominates local read/write, so that using a socket isn't going to do much better. I can profile more closely if/when we feel it's high priority to make this faster still.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3114#issuecomment-372165433
https://github.com/hail-is/hail/pull/3114#issuecomment-372165433:498,Testability,test,tested,498,"I've removed the Python `tempfile` approach in favor of adding `new_local_temp_file` to utils and a corresponding function to HailContext in Scala, which currently hardcodes `file:///temp` as the local temp directory. It may be more natural to have a localTmpDir on HailContext like we have tmpDir. ; I see there is a notion of local temp files on TempDir on the Scala side, but it doesn't seem to be used on the Python side. I also don't see if/where we wipe temp files on exit. In any case, I've tested that now it all works nicely on GCP, so ready for feedback/review. I think factoring through `tofile` and `fromfile` is useful for wider interoperability for the same reason that NumPy exposes them, but it's also good if you dont want to actually load the NumPy array into driver memory but just save it to read/copy later, or to load it multiple time without recomputing the BlockMatrix. And I've provided the simpler interface of `to_numpy` and `from_numpy` for the common case. I suspect that (de)serializing over the network and building the local matrix dominates local read/write, so that using a socket isn't going to do much better. I can profile more closely if/when we feel it's high priority to make this faster still.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3114#issuecomment-372165433
https://github.com/hail-is/hail/pull/3114#issuecomment-372165433:555,Usability,feedback,feedback,555,"I've removed the Python `tempfile` approach in favor of adding `new_local_temp_file` to utils and a corresponding function to HailContext in Scala, which currently hardcodes `file:///temp` as the local temp directory. It may be more natural to have a localTmpDir on HailContext like we have tmpDir. ; I see there is a notion of local temp files on TempDir on the Scala side, but it doesn't seem to be used on the Python side. I also don't see if/where we wipe temp files on exit. In any case, I've tested that now it all works nicely on GCP, so ready for feedback/review. I think factoring through `tofile` and `fromfile` is useful for wider interoperability for the same reason that NumPy exposes them, but it's also good if you dont want to actually load the NumPy array into driver memory but just save it to read/copy later, or to load it multiple time without recomputing the BlockMatrix. And I've provided the simpler interface of `to_numpy` and `from_numpy` for the common case. I suspect that (de)serializing over the network and building the local matrix dominates local read/write, so that using a socket isn't going to do much better. I can profile more closely if/when we feel it's high priority to make this faster still.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3114#issuecomment-372165433
https://github.com/hail-is/hail/pull/3114#issuecomment-372165433:917,Usability,simpl,simpler,917,"I've removed the Python `tempfile` approach in favor of adding `new_local_temp_file` to utils and a corresponding function to HailContext in Scala, which currently hardcodes `file:///temp` as the local temp directory. It may be more natural to have a localTmpDir on HailContext like we have tmpDir. ; I see there is a notion of local temp files on TempDir on the Scala side, but it doesn't seem to be used on the Python side. I also don't see if/where we wipe temp files on exit. In any case, I've tested that now it all works nicely on GCP, so ready for feedback/review. I think factoring through `tofile` and `fromfile` is useful for wider interoperability for the same reason that NumPy exposes them, but it's also good if you dont want to actually load the NumPy array into driver memory but just save it to read/copy later, or to load it multiple time without recomputing the BlockMatrix. And I've provided the simpler interface of `to_numpy` and `from_numpy` for the common case. I suspect that (de)serializing over the network and building the local matrix dominates local read/write, so that using a socket isn't going to do much better. I can profile more closely if/when we feel it's high priority to make this faster still.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3114#issuecomment-372165433
https://github.com/hail-is/hail/pull/3114#issuecomment-373213036:278,Testability,test,tests,278,"- separated `BlockMatrix.from_entry_expr` (a classmethod that uses a temp file) and `BlockMatrix.write_from_entry_expr` (a staticmethod that takes a path); - added buffers specifically for handling Doubles, removed StreamingRawBlockingBuffer, etc; - moved RichDenseMatrixDouble tests from BlockMatrixSuite to its own suite, now also testing condition of the file being shorten than expected",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3114#issuecomment-373213036
https://github.com/hail-is/hail/pull/3114#issuecomment-373213036:333,Testability,test,testing,333,"- separated `BlockMatrix.from_entry_expr` (a classmethod that uses a temp file) and `BlockMatrix.write_from_entry_expr` (a staticmethod that takes a path); - added buffers specifically for handling Doubles, removed StreamingRawBlockingBuffer, etc; - moved RichDenseMatrixDouble tests from BlockMatrixSuite to its own suite, now also testing condition of the file being shorten than expected",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3114#issuecomment-373213036
https://github.com/hail-is/hail/pull/3114#issuecomment-373451854:277,Deployability,pipeline,pipeline,277,"I'm currently expanding BlockMatrix binary ops to work naturally between BlockMatrix and 2d ndarray, with the useful ones for LMM being broadcasting ndarray over rows or columns of BlockMatrix. That'll round out the linear algebra, so that next week I'll begin refactoring the pipeline, with the interesting bits being the form of Python form of the small ""global model"" (initially using Scala side as black box) and then applying the local model to the pair or RowMatrices `X` and `PX` (read from BlockMatrices) to get per variant results.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3114#issuecomment-373451854
https://github.com/hail-is/hail/pull/3114#issuecomment-373451854:261,Modifiability,refactor,refactoring,261,"I'm currently expanding BlockMatrix binary ops to work naturally between BlockMatrix and 2d ndarray, with the useful ones for LMM being broadcasting ndarray over rows or columns of BlockMatrix. That'll round out the linear algebra, so that next week I'll begin refactoring the pipeline, with the interesting bits being the form of Python form of the small ""global model"" (initially using Scala side as black box) and then applying the local model to the pair or RowMatrices `X` and `PX` (read from BlockMatrices) to get per variant results.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3114#issuecomment-373451854
https://github.com/hail-is/hail/pull/3122#issuecomment-372087212:30,Testability,test,testing,30,"Yes, will do. FYI, I included testing info here: https://github.com/hail-is/hail/pull/2377",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3122#issuecomment-372087212
https://github.com/hail-is/hail/pull/3122#issuecomment-372137231:129,Availability,error,error,129,"I've merged fixes to two old bugs and one new bug:; - `typecheck_method` => `typecheck`; - an extra `rvb.startStruct()`; - match error for `alleles: Array[String]` to `IndexedSeq[_]` in `RegionValueBuilder.addAnnotation`. (apologies, I meant to PR rather rather than merge directly but forgot to change cseed to origin). Adding; ```; --init gs://hail-common/nirvana/nirvana-init-GRCh37.sh; ```; at cluster startup and running; ```; import hail as hl; mt = hl.import_vcf(path='gs://jbloom/profile225.vcf.bgz'); mt = mt.filter_rows(hl.len(mt.alleles) == 2); ht = hl.nirvana(mt, config='/nirvana/nirvana-cloud-GRCh37.properties', block_size=10000).rows(); (ht.filter((ht.locus.position > 24430000) & (ht.locus.position < 24580000)); .export(output='gs://jbloom/nirvana_cabin1_3.tsv')); ```; yields the same output as before modulo superficial changes to our representation of variant and flattening of `va` to `rsid	qual	filters	info	nirvana`. Here's an examplar now:; ```; locus	alleles	rsid	qual	filters	info	nirvana; 22:24468386	[""G"",""A""]	NA	3.8351e+04	NA	{""AC"":[306],""AF"":[0.061],""AN"":5018,""BaseQRankSum"":26.807,""ClippingRankSum"":-0.538,""DP"":22432,""DS"":null,""FS"":1.203,""HaplotypeScore"":null,""InbreedingCoeff"":0.0335,""MLEAC"":[309],""MLEAF"":[0.062],""MQ"":59.13,""MQ0"":0,""MQRankSum"":16.406,""QD"":14.9,""ReadPosRankSum"":-0.637,""set"":null}	{""chromosome"":""22"",""refAllele"":""G"",""position"":24468386,""altAlleles"":[""A""],""cytogeneticBand"":""22q11.23"",""quality"":null,""filters"":null,""jointSomaticNormalQuality"":null,""copyNumber"":null,""strandBias"":null,""recalibratedQuality"":null,""variants"":[{""altAllele"":""A"",""refAllele"":""G"",""chromosome"":""22"",""begin"":24468386,""end"":24468386,""phylopScore"":3.457,""isReferenceMinor"":null,""variantType"":""SNV"",""vid"":""22:24468386:A"",""isRecomposed"":null,""regulatoryRegions"":null,""clinvar"":null,""cosmic"":[{""id"":""COSM3759087"",""isAlleleSpecific"":true,""refAllele"":""G"",""altAllele"":""A"",""gene"":""CABIN1"",""sampleCount"":2,""studies"":[{""id"":376,""histology"":""carcinoma"",""primarySite"":""large intestine""},{""id",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3122#issuecomment-372137231
https://github.com/hail-is/hail/pull/3122#issuecomment-372137231:576,Modifiability,config,config,576,"I've merged fixes to two old bugs and one new bug:; - `typecheck_method` => `typecheck`; - an extra `rvb.startStruct()`; - match error for `alleles: Array[String]` to `IndexedSeq[_]` in `RegionValueBuilder.addAnnotation`. (apologies, I meant to PR rather rather than merge directly but forgot to change cseed to origin). Adding; ```; --init gs://hail-common/nirvana/nirvana-init-GRCh37.sh; ```; at cluster startup and running; ```; import hail as hl; mt = hl.import_vcf(path='gs://jbloom/profile225.vcf.bgz'); mt = mt.filter_rows(hl.len(mt.alleles) == 2); ht = hl.nirvana(mt, config='/nirvana/nirvana-cloud-GRCh37.properties', block_size=10000).rows(); (ht.filter((ht.locus.position > 24430000) & (ht.locus.position < 24580000)); .export(output='gs://jbloom/nirvana_cabin1_3.tsv')); ```; yields the same output as before modulo superficial changes to our representation of variant and flattening of `va` to `rsid	qual	filters	info	nirvana`. Here's an examplar now:; ```; locus	alleles	rsid	qual	filters	info	nirvana; 22:24468386	[""G"",""A""]	NA	3.8351e+04	NA	{""AC"":[306],""AF"":[0.061],""AN"":5018,""BaseQRankSum"":26.807,""ClippingRankSum"":-0.538,""DP"":22432,""DS"":null,""FS"":1.203,""HaplotypeScore"":null,""InbreedingCoeff"":0.0335,""MLEAC"":[309],""MLEAF"":[0.062],""MQ"":59.13,""MQ0"":0,""MQRankSum"":16.406,""QD"":14.9,""ReadPosRankSum"":-0.637,""set"":null}	{""chromosome"":""22"",""refAllele"":""G"",""position"":24468386,""altAlleles"":[""A""],""cytogeneticBand"":""22q11.23"",""quality"":null,""filters"":null,""jointSomaticNormalQuality"":null,""copyNumber"":null,""strandBias"":null,""recalibratedQuality"":null,""variants"":[{""altAllele"":""A"",""refAllele"":""G"",""chromosome"":""22"",""begin"":24468386,""end"":24468386,""phylopScore"":3.457,""isReferenceMinor"":null,""variantType"":""SNV"",""vid"":""22:24468386:A"",""isRecomposed"":null,""regulatoryRegions"":null,""clinvar"":null,""cosmic"":[{""id"":""COSM3759087"",""isAlleleSpecific"":true,""refAllele"":""G"",""altAllele"":""A"",""gene"":""CABIN1"",""sampleCount"":2,""studies"":[{""id"":376,""histology"":""carcinoma"",""primarySite"":""large intestine""},{""id",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3122#issuecomment-372137231
https://github.com/hail-is/hail/pull/3122#issuecomment-372146159:61,Testability,test,tests,61,"Changes look good, thanks for that! We need to add automated tests if we're going to keep this functionality.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3122#issuecomment-372146159
https://github.com/hail-is/hail/pull/3130#issuecomment-372654665:117,Modifiability,extend,extend,117,you'll notice that BroadcastValue requires the type but doesn't do anything with it -- this is to make it trivial to extend it to expose something like `broadcastRegionValue`,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3130#issuecomment-372654665
https://github.com/hail-is/hail/pull/3130#issuecomment-372654665:130,Security,expose,expose,130,you'll notice that BroadcastValue requires the type but doesn't do anything with it -- this is to make it trivial to extend it to expose something like `broadcastRegionValue`,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3130#issuecomment-372654665
https://github.com/hail-is/hail/pull/3135#issuecomment-372781039:0,Testability,Test,Tested,0,"Tested. Details: I VEP annnotated (multi-allelic) sample2.vcf with master and this branch. 3 variants have * alleles. I verified the datasets were the same after filtering out those 3 variants. (In fact, the VEP output was in the same for them, too, I think because * was the last allele so the allele indices didn't change.)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3135#issuecomment-372781039
https://github.com/hail-is/hail/pull/3138#issuecomment-373043373:673,Availability,error,error,673,"I have looked at https://github.com/agronholm/sphinx-autodoc-typehints, yes. One of the major problems with it right now is that it doesn't work with forward references, like this in matrixtable:; ```python; @typecheck_method(exprs=oneof(str, Expression),; named_exprs=expr_any); def group_rows_by(self,; *exprs: Tuple[Union[Expression, str]],; **named_exprs: NamedExprs) -> 'GroupedMatrixTable':; ```. The reason it doesn't work is the decorator. The forward reference strings are evaluated in the module of the function after the module is fully imported, and in this case the module is the module of the _decorator_, not _group_rows_by_. So GroupedMatrixTable is a name error. There are a few solutions:; - Don't use decorators anywhere. This requires a lot of work to fully port over typechecking to typecheck2, which I'm now not totally sure is even the right thing.; - A bit hacky: import `hail` in the typecheck module and use fully clarified paths in forward references.; - see if we can eagerly evaluate the hints in the typecheck module and set them on the decorated function.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3138#issuecomment-373043373
https://github.com/hail-is/hail/pull/3138#issuecomment-373051517:145,Usability,undo,undo,145,"Ok, I think I get it now. The hacky solution (import `hail` in `typecheck`) doesn't seem too bad, especially if we document it so we remember to undo it if we find a better solution.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3138#issuecomment-373051517
https://github.com/hail-is/hail/pull/3151#issuecomment-373180986:152,Energy Efficiency,allocate,allocated,152,@jbloom22 I realized that updating the length of the array after creating it doesn't work because of the variable size of the missingness bits that get allocated.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3151#issuecomment-373180986
https://github.com/hail-is/hail/pull/3151#issuecomment-373180986:105,Modifiability,variab,variable,105,@jbloom22 I realized that updating the length of the array after creating it doesn't work because of the variable size of the missingness bits that get allocated.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3151#issuecomment-373180986
https://github.com/hail-is/hail/pull/3154#issuecomment-373415063:76,Testability,test,tests,76,"Yeah, I debated this, but they are pretty nice and we use them a lot in our tests. @tpoterba thoughts?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3154#issuecomment-373415063
https://github.com/hail-is/hail/pull/3159#issuecomment-373723920:418,Usability,simpl,simple,418,"We should discuss the struct ordering in person. I think there are orderings that can be defined on the space of all tuples (since the names don't matter) of arbitrary lengths, which are very helpful in working with changing keys and partition keys. In principle, it should be easy to repartition an OrderedRVD with a longer partition key to a partitioner with a shorter partition key, but currently that doesn't look simple to do. I tried to lay the groundwork here to make that trivial.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3159#issuecomment-373723920
https://github.com/hail-is/hail/pull/3159#issuecomment-373773742:113,Availability,down,downcastToPK,113,"Speaking of not understanding what keys mean, I found what looks to me like a bug, but I'm not sure. `OrderedRVD.downcastToPK` creates an `OrderedRVD` for which `typ.kType` is different from `partitioner.kType`. It's triggering the assert I made in `RepartitionedOrderedRDD2` that says the new key must be a prefix of the old, to ensure that no sorting needs to be done. I want to make join keys parameters of `OrderedRVD.join`, allowing them to be different from the partitioner keys. I was putting that off for a later PR, but now I think I might need to do that to fix this.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3159#issuecomment-373773742
https://github.com/hail-is/hail/pull/3159#issuecomment-373773742:232,Testability,assert,assert,232,"Speaking of not understanding what keys mean, I found what looks to me like a bug, but I'm not sure. `OrderedRVD.downcastToPK` creates an `OrderedRVD` for which `typ.kType` is different from `partitioner.kType`. It's triggering the assert I made in `RepartitionedOrderedRDD2` that says the new key must be a prefix of the old, to ensure that no sorting needs to be done. I want to make join keys parameters of `OrderedRVD.join`, allowing them to be different from the partitioner keys. I was putting that off for a later PR, but now I think I might need to do that to fix this.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3159#issuecomment-373773742
https://github.com/hail-is/hail/pull/3159#issuecomment-374660245:53,Availability,down,downcastToPK,53,"I addressed most of your comments. I also fixed the `downcastToPK` problem by getting rid of it, instead adding a `KeyedOrderedRVD` which has a join key in addition to an ordering key.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3159#issuecomment-374660245
https://github.com/hail-is/hail/pull/3164#issuecomment-374276131:6,Testability,test,tests,6,added tests,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3164#issuecomment-374276131
https://github.com/hail-is/hail/pull/3164#issuecomment-374383075:55,Testability,test,test,55,"rebased on diagonal bug fix, added the Python diagonal test back in",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3164#issuecomment-374383075
https://github.com/hail-is/hail/pull/3172#issuecomment-377559347:1061,Integrability,message,message,1061,"First, @cristinaluengoagullo, thank you for your contribution! This is awesome. Second, I think this PR will need a little work before it can go in. Let me describe the situation:. We have now stopped work on Hail 0.1 and are now making only critical bug fixes. I think we can accept small feature additions, but we're optimizing for stability over features now. All new development has moved to master/0.2 beta. If you do make changes to 0.1, they should be forward ported to 0.2 if you want them to be carried forward. In addition, there are two problems with your PR:. 1. It is quite large. We prefer contributions to be single conceptual units. For example, a change to VEP should be separate from additions to the function registry. 2. The diff is somewhat confusing and I'm not 100% sure what is going on. It appears to include a large number of our own changes, it looks like from this commit: https://github.com/hail-is/hail/pull/3172/commits/e6f0b7f3a854f0fd64857876ab04375e570ba09f. However, given that the commit is under your name with a new commit message, I can't tell where those changes originated. Also, at least some (all?) of those changes already appear in 0.1, so I'm not sure why Github is displaying them, for example: https://github.com/hail-is/hail/pull/3172/files#diff-f11d07953ac5cd8bd8d4d3fd135a3efbR11. I think squashing your changes (and just your changes) and rebasing them onto the current 0.1 HEAD will fix the problem. Then we can take a closer look at the changes. Finally, it looks like your changed the VEP schema because you're invoking it with extra plugins. I think that's a no-go for us, but you could modify the VEP command (through an argument or in the properties file) to specify an alternate schema.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3172#issuecomment-377559347
https://github.com/hail-is/hail/pull/3172#issuecomment-377559347:1589,Modifiability,plugin,plugins,1589,"First, @cristinaluengoagullo, thank you for your contribution! This is awesome. Second, I think this PR will need a little work before it can go in. Let me describe the situation:. We have now stopped work on Hail 0.1 and are now making only critical bug fixes. I think we can accept small feature additions, but we're optimizing for stability over features now. All new development has moved to master/0.2 beta. If you do make changes to 0.1, they should be forward ported to 0.2 if you want them to be carried forward. In addition, there are two problems with your PR:. 1. It is quite large. We prefer contributions to be single conceptual units. For example, a change to VEP should be separate from additions to the function registry. 2. The diff is somewhat confusing and I'm not 100% sure what is going on. It appears to include a large number of our own changes, it looks like from this commit: https://github.com/hail-is/hail/pull/3172/commits/e6f0b7f3a854f0fd64857876ab04375e570ba09f. However, given that the commit is under your name with a new commit message, I can't tell where those changes originated. Also, at least some (all?) of those changes already appear in 0.1, so I'm not sure why Github is displaying them, for example: https://github.com/hail-is/hail/pull/3172/files#diff-f11d07953ac5cd8bd8d4d3fd135a3efbR11. I think squashing your changes (and just your changes) and rebasing them onto the current 0.1 HEAD will fix the problem. Then we can take a closer look at the changes. Finally, it looks like your changed the VEP schema because you're invoking it with extra plugins. I think that's a no-go for us, but you could modify the VEP command (through an argument or in the properties file) to specify an alternate schema.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3172#issuecomment-377559347
https://github.com/hail-is/hail/pull/3172#issuecomment-377559347:319,Performance,optimiz,optimizing,319,"First, @cristinaluengoagullo, thank you for your contribution! This is awesome. Second, I think this PR will need a little work before it can go in. Let me describe the situation:. We have now stopped work on Hail 0.1 and are now making only critical bug fixes. I think we can accept small feature additions, but we're optimizing for stability over features now. All new development has moved to master/0.2 beta. If you do make changes to 0.1, they should be forward ported to 0.2 if you want them to be carried forward. In addition, there are two problems with your PR:. 1. It is quite large. We prefer contributions to be single conceptual units. For example, a change to VEP should be separate from additions to the function registry. 2. The diff is somewhat confusing and I'm not 100% sure what is going on. It appears to include a large number of our own changes, it looks like from this commit: https://github.com/hail-is/hail/pull/3172/commits/e6f0b7f3a854f0fd64857876ab04375e570ba09f. However, given that the commit is under your name with a new commit message, I can't tell where those changes originated. Also, at least some (all?) of those changes already appear in 0.1, so I'm not sure why Github is displaying them, for example: https://github.com/hail-is/hail/pull/3172/files#diff-f11d07953ac5cd8bd8d4d3fd135a3efbR11. I think squashing your changes (and just your changes) and rebasing them onto the current 0.1 HEAD will fix the problem. Then we can take a closer look at the changes. Finally, it looks like your changed the VEP schema because you're invoking it with extra plugins. I think that's a no-go for us, but you could modify the VEP command (through an argument or in the properties file) to specify an alternate schema.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3172#issuecomment-377559347
https://github.com/hail-is/hail/pull/3179#issuecomment-374385002:49,Deployability,update,updated,49,Sorry about that! Didn't realize it needed to be updated in 2 places.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3179#issuecomment-374385002
https://github.com/hail-is/hail/pull/3185#issuecomment-379121683:1579,Energy Efficiency,efficient,efficient,1579,"Sadness. I spent two hours writing a longer version of this in browser and lost this comment and all my previous comments due to errant click. So now I'm summarizing in an editor and pasting (the other comments may no longer be relevant):. If I understand correctly, you want to filter the entries table to only include pairs of indicies that on the same contig and within some radius of one another. And you want to compute the minimal set of blocks to cover these pairs, which seems at odds with coalescing intervals. Meditating on your code, I think the core mathematical function to pull out is:. ```; // positions is non-decreasing, radius is non-negative.; // for each index i, compute the largest index j such that position[j] - position[i] <= radius; def computeUpperIndexBounds(positions: Array[Int], radius: Int): Array[Int]; ```. Suppose we have a Table with two fields (both keys), the second of which has type Int. Group by the first field and collect values to get `groupedPositions: Array[Array[Int]]`. Then get the absolute first index of each group with:; ```; val firstIndices = groupedPositions.init.map(_.length).scanLeft(0L)(_ + _); ```; Then:; ```; val rightWindows: Array[(Int, Int)] = (firstIndices, groupedPositions).zipped.map { case (i, positions) =>; positions.zip(computeRightWindows(positions, radius).map(i + _) }. val blocksToKeep = computeRectangles(rightWindows.map( (i, j) => Array(i, j, i, j) ); ```. Since `i <= j` by construction, these are exactly the upper triangular blocks you need. Note that this approach is more general but also more efficient by operating directly on arrays of integers. The incoming table doesn't need to be indexed, just properly ordered. And you no longer need upperTriangularBlocks. It'd be great to also have computeLowerIndexBounds, which you could implement in terms of computeUpperIndexBounds on the reversed and negated array. What do you think? Let me know if I've misunderstood!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3185#issuecomment-379121683
https://github.com/hail-is/hail/pull/3185#issuecomment-379135882:301,Deployability,pipeline,pipeline,301,"Revised: You can switch the map and collect order to get more parallelism: groupBy, mapValues with computeUpperIndexBounds, collect, shift relative upper bound indices to absolute upper bound indices, zipWithIndex, feed into computeRectangles. Once we have durable partitionStarts on table, the whole pipeline can be done on the workers, with a final reduce to concatenate the blocksToKeep.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3185#issuecomment-379135882
https://github.com/hail-is/hail/pull/3185#issuecomment-379135882:351,Energy Efficiency,reduce,reduce,351,"Revised: You can switch the map and collect order to get more parallelism: groupBy, mapValues with computeUpperIndexBounds, collect, shift relative upper bound indices to absolute upper bound indices, zipWithIndex, feed into computeRectangles. Once we have durable partitionStarts on table, the whole pipeline can be done on the workers, with a final reduce to concatenate the blocksToKeep.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3185#issuecomment-379135882
https://github.com/hail-is/hail/pull/3186#issuecomment-374449723:436,Modifiability,rewrite,rewrite,436,"1. Move the classes into is.hail.rvd. They aren't used anywhere else, are they?. 2. @maccum is working over LD prune, the GeneralRDD stuff shouldn't be necessary anymore. I think she's just working on optimization, so I feel like her current code is an improvement and should go in before the performance improvements are ready. 3. I agree, but, yeah, SKAT can't go until we get expr ndarray. 4. MatrixTable.same just uses zip, you can rewrite it in terms of zip based on my above comments. You might also need a version of zip that returns a RDD[T]. Compare RVD.map and RVD.mapPartitions. 5. I think the right thing here is an OrderedRVD.orderedIntervalJoin. Compare @patrick-schultz recent OrderedRVD.orderedJoin (pending): https://github.com/hail-is/hail/pull/3159/files#diff-b173fb9bd584d50afcfa6724954ef3b5R127",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3186#issuecomment-374449723
https://github.com/hail-is/hail/pull/3186#issuecomment-374449723:201,Performance,optimiz,optimization,201,"1. Move the classes into is.hail.rvd. They aren't used anywhere else, are they?. 2. @maccum is working over LD prune, the GeneralRDD stuff shouldn't be necessary anymore. I think she's just working on optimization, so I feel like her current code is an improvement and should go in before the performance improvements are ready. 3. I agree, but, yeah, SKAT can't go until we get expr ndarray. 4. MatrixTable.same just uses zip, you can rewrite it in terms of zip based on my above comments. You might also need a version of zip that returns a RDD[T]. Compare RVD.map and RVD.mapPartitions. 5. I think the right thing here is an OrderedRVD.orderedIntervalJoin. Compare @patrick-schultz recent OrderedRVD.orderedJoin (pending): https://github.com/hail-is/hail/pull/3159/files#diff-b173fb9bd584d50afcfa6724954ef3b5R127",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3186#issuecomment-374449723
https://github.com/hail-is/hail/pull/3186#issuecomment-374449723:293,Performance,perform,performance,293,"1. Move the classes into is.hail.rvd. They aren't used anywhere else, are they?. 2. @maccum is working over LD prune, the GeneralRDD stuff shouldn't be necessary anymore. I think she's just working on optimization, so I feel like her current code is an improvement and should go in before the performance improvements are ready. 3. I agree, but, yeah, SKAT can't go until we get expr ndarray. 4. MatrixTable.same just uses zip, you can rewrite it in terms of zip based on my above comments. You might also need a version of zip that returns a RDD[T]. Compare RVD.map and RVD.mapPartitions. 5. I think the right thing here is an OrderedRVD.orderedIntervalJoin. Compare @patrick-schultz recent OrderedRVD.orderedJoin (pending): https://github.com/hail-is/hail/pull/3159/files#diff-b173fb9bd584d50afcfa6724954ef3b5R127",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3186#issuecomment-374449723
https://github.com/hail-is/hail/pull/3186#issuecomment-375368023:7,Availability,ping,ping,7,"@cseed ping, stacked PRs have proven unsuccessful in the past, so I'm keeping the rest of my work gated, but I'd like to start moving things into master. Can you take a look at the latest changes and confirm if you're cool punting on points 1-5 until later?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3186#issuecomment-375368023
https://github.com/hail-is/hail/pull/3186#issuecomment-375789138:30,Availability,down,downcastToPK,30,Why did you need to add back `downcastToPK` and `upcast`? I tried to make those unnecessary with `KeyedOrderedRVD`.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3186#issuecomment-375789138
https://github.com/hail-is/hail/pull/3186#issuecomment-375789384:24,Availability,failure,failure,24,"@patrick-schultz rebase failure, I'll remove.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3186#issuecomment-375789384
https://github.com/hail-is/hail/pull/3186#issuecomment-375802364:60,Testability,test,tests,60,"Removed those, which also addressed cotton's comments. When tests pass I'll merge and then push the next PR up!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3186#issuecomment-375802364
https://github.com/hail-is/hail/pull/3206#issuecomment-375136911:33,Integrability,interface,interface,33,"Yeah, amazing how far the Python interface has come!. Here are the essential changes:; ```; val popOfSample_n = DenseMatrix.zeros[Double](if (mixture) K else 1, N); if (mixture) {; val popDistRV = Dirichlet(popDist_k); (0 until N).foreach(j => popOfSample_n(::, j) := popDistRV.draw()); } else {; popDist_k :/= sum(popDist_k); val popDistRV = Multinomial(popDist_k); (0 until N).foreach(j => popOfSample_n(0, j) = popDistRV.draw()); }; ```; ```; val p =; if (mixture); popOfSample_nBc.value(::, i) dot popAF_k; else; popAF_k(popOfSample_nBc.value(0, i).toInt); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3206#issuecomment-375136911
https://github.com/hail-is/hail/pull/3206#issuecomment-375313469:23,Security,expose,expose,23,"Would it make sense to expose the `a` parameter, to make it easier to move between the three examples you showed? The `mixture` parameter could just be floating point rather than boolean, treating the default `mixture=0` case specially.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3206#issuecomment-375313469
https://github.com/hail-is/hail/pull/3210#issuecomment-375776769:33,Testability,test,tests,33,"@jigold I made sure that all the tests from `hail.tests.test_expr.Tests.test_cond` are both passing and going through the IR (except the first one, which has strings).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3210#issuecomment-375776769
https://github.com/hail-is/hail/pull/3210#issuecomment-375776769:50,Testability,test,tests,50,"@jigold I made sure that all the tests from `hail.tests.test_expr.Tests.test_cond` are both passing and going through the IR (except the first one, which has strings).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3210#issuecomment-375776769
https://github.com/hail-is/hail/pull/3210#issuecomment-375776769:66,Testability,Test,Tests,66,"@jigold I made sure that all the tests from `hail.tests.test_expr.Tests.test_cond` are both passing and going through the IR (except the first one, which has strings).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3210#issuecomment-375776769
https://github.com/hail-is/hail/pull/3211#issuecomment-376013809:6,Usability,clear,clear,6,"To be clear, I'm approving the Python code, and the fact that it runs to completion (will check for correctness shortly). Someone else might want to look over the Scala code changes)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3211#issuecomment-376013809
https://github.com/hail-is/hail/pull/3211#issuecomment-376385065:622,Availability,toler,tolerance,622,"I now pass the scores_table through as a Table rather than localizing and passing through colKeys, colKeyType, and scores annotations. The column key can now be any type. Both string and integer keys are tested from Python. However, `requireUniqueSamples` still requires a single string ID (this was the remaining problem of going generic), so I've removed this check and would appreciate feedback on the best approach to checking uniqueness, preferably on the localized `keys` in PCRelate so as not to trigger additional actions. I could use keyType.valuesSimilar to compare any two elements...it's a bit weird to have a tolerance on floats here. As noted, I'm also a bit wary that I'm relying on `scores` from `pca` to be in the same order as the columns on the matrix table. This is currently true, but could change. @danking I think the joins in `fuse` should also be zipPartitions, I've noted it in a FIXME. I'm also concerned that the number of diagonal blocks is an upper bound on parallelism for the matrix multiply. We should be able to fix that by immediately writing and then reading phi.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3211#issuecomment-376385065
https://github.com/hail-is/hail/pull/3211#issuecomment-376385065:204,Testability,test,tested,204,"I now pass the scores_table through as a Table rather than localizing and passing through colKeys, colKeyType, and scores annotations. The column key can now be any type. Both string and integer keys are tested from Python. However, `requireUniqueSamples` still requires a single string ID (this was the remaining problem of going generic), so I've removed this check and would appreciate feedback on the best approach to checking uniqueness, preferably on the localized `keys` in PCRelate so as not to trigger additional actions. I could use keyType.valuesSimilar to compare any two elements...it's a bit weird to have a tolerance on floats here. As noted, I'm also a bit wary that I'm relying on `scores` from `pca` to be in the same order as the columns on the matrix table. This is currently true, but could change. @danking I think the joins in `fuse` should also be zipPartitions, I've noted it in a FIXME. I'm also concerned that the number of diagonal blocks is an upper bound on parallelism for the matrix multiply. We should be able to fix that by immediately writing and then reading phi.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3211#issuecomment-376385065
https://github.com/hail-is/hail/pull/3211#issuecomment-376385065:389,Usability,feedback,feedback,389,"I now pass the scores_table through as a Table rather than localizing and passing through colKeys, colKeyType, and scores annotations. The column key can now be any type. Both string and integer keys are tested from Python. However, `requireUniqueSamples` still requires a single string ID (this was the remaining problem of going generic), so I've removed this check and would appreciate feedback on the best approach to checking uniqueness, preferably on the localized `keys` in PCRelate so as not to trigger additional actions. I could use keyType.valuesSimilar to compare any two elements...it's a bit weird to have a tolerance on floats here. As noted, I'm also a bit wary that I'm relying on `scores` from `pca` to be in the same order as the columns on the matrix table. This is currently true, but could change. @danking I think the joins in `fuse` should also be zipPartitions, I've noted it in a FIXME. I'm also concerned that the number of diagonal blocks is an upper bound on parallelism for the matrix multiply. We should be able to fix that by immediately writing and then reading phi.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3211#issuecomment-376385065
https://github.com/hail-is/hail/pull/3211#issuecomment-376725104:483,Availability,toler,tolerances,483,"Changes since last review:; - Method now takes expressions for call and (optionally) scores.; - Block matrix and table of scores annotated and collected from source.cols() sent to Python, processed using int indices, column names restored on python side (thanks @tpoterba); - Fixed bug that silently dropped `n_samples / block_size` proportion of pairs, Python test checks it; - Extended Python tests to compare k and scores paths, test counts, min_kinship, maf, block_size; - Tuned tolerances on comparison with R from Python; - Extended to general column key, removing unique key check, noted in docs; - MEMORY_AND_DISK caching as default (thanks @konradjk) on Scala side; - The diagonal fix meant phi is computed with parallelism up to the number of diagonal blocks, rather than parallelism 1. But that's still likely a bottleneck as phi requires computing and point-wise dividing two big gram matrices. I now write phi to disk and read it back in, which squares the parallelism up to the number of blocks in phi. I think this should also improve the stability of the many downstream calculations derived from phi, esp. if pre-emptibles are used. No longer cacheing phi, but I left caching on the other matrices. @konradjk let us know how this version compares next time you run it.; - Noted in FIXME room for further improvement when fusing blocks: `replace join with zipPartitions, throw away lower triangular blocks sooner, avoid the nulls`; - Updated docs accordingly; - Deleted a bunch of code in PCRelate and PCRelateSuite",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3211#issuecomment-376725104
https://github.com/hail-is/hail/pull/3211#issuecomment-376725104:1076,Availability,down,downstream,1076,"Changes since last review:; - Method now takes expressions for call and (optionally) scores.; - Block matrix and table of scores annotated and collected from source.cols() sent to Python, processed using int indices, column names restored on python side (thanks @tpoterba); - Fixed bug that silently dropped `n_samples / block_size` proportion of pairs, Python test checks it; - Extended Python tests to compare k and scores paths, test counts, min_kinship, maf, block_size; - Tuned tolerances on comparison with R from Python; - Extended to general column key, removing unique key check, noted in docs; - MEMORY_AND_DISK caching as default (thanks @konradjk) on Scala side; - The diagonal fix meant phi is computed with parallelism up to the number of diagonal blocks, rather than parallelism 1. But that's still likely a bottleneck as phi requires computing and point-wise dividing two big gram matrices. I now write phi to disk and read it back in, which squares the parallelism up to the number of blocks in phi. I think this should also improve the stability of the many downstream calculations derived from phi, esp. if pre-emptibles are used. No longer cacheing phi, but I left caching on the other matrices. @konradjk let us know how this version compares next time you run it.; - Noted in FIXME room for further improvement when fusing blocks: `replace join with zipPartitions, throw away lower triangular blocks sooner, avoid the nulls`; - Updated docs accordingly; - Deleted a bunch of code in PCRelate and PCRelateSuite",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3211#issuecomment-376725104
https://github.com/hail-is/hail/pull/3211#issuecomment-376725104:1450,Deployability,Update,Updated,1450,"Changes since last review:; - Method now takes expressions for call and (optionally) scores.; - Block matrix and table of scores annotated and collected from source.cols() sent to Python, processed using int indices, column names restored on python side (thanks @tpoterba); - Fixed bug that silently dropped `n_samples / block_size` proportion of pairs, Python test checks it; - Extended Python tests to compare k and scores paths, test counts, min_kinship, maf, block_size; - Tuned tolerances on comparison with R from Python; - Extended to general column key, removing unique key check, noted in docs; - MEMORY_AND_DISK caching as default (thanks @konradjk) on Scala side; - The diagonal fix meant phi is computed with parallelism up to the number of diagonal blocks, rather than parallelism 1. But that's still likely a bottleneck as phi requires computing and point-wise dividing two big gram matrices. I now write phi to disk and read it back in, which squares the parallelism up to the number of blocks in phi. I think this should also improve the stability of the many downstream calculations derived from phi, esp. if pre-emptibles are used. No longer cacheing phi, but I left caching on the other matrices. @konradjk let us know how this version compares next time you run it.; - Noted in FIXME room for further improvement when fusing blocks: `replace join with zipPartitions, throw away lower triangular blocks sooner, avoid the nulls`; - Updated docs accordingly; - Deleted a bunch of code in PCRelate and PCRelateSuite",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3211#issuecomment-376725104
https://github.com/hail-is/hail/pull/3211#issuecomment-376725104:379,Modifiability,Extend,Extended,379,"Changes since last review:; - Method now takes expressions for call and (optionally) scores.; - Block matrix and table of scores annotated and collected from source.cols() sent to Python, processed using int indices, column names restored on python side (thanks @tpoterba); - Fixed bug that silently dropped `n_samples / block_size` proportion of pairs, Python test checks it; - Extended Python tests to compare k and scores paths, test counts, min_kinship, maf, block_size; - Tuned tolerances on comparison with R from Python; - Extended to general column key, removing unique key check, noted in docs; - MEMORY_AND_DISK caching as default (thanks @konradjk) on Scala side; - The diagonal fix meant phi is computed with parallelism up to the number of diagonal blocks, rather than parallelism 1. But that's still likely a bottleneck as phi requires computing and point-wise dividing two big gram matrices. I now write phi to disk and read it back in, which squares the parallelism up to the number of blocks in phi. I think this should also improve the stability of the many downstream calculations derived from phi, esp. if pre-emptibles are used. No longer cacheing phi, but I left caching on the other matrices. @konradjk let us know how this version compares next time you run it.; - Noted in FIXME room for further improvement when fusing blocks: `replace join with zipPartitions, throw away lower triangular blocks sooner, avoid the nulls`; - Updated docs accordingly; - Deleted a bunch of code in PCRelate and PCRelateSuite",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3211#issuecomment-376725104
https://github.com/hail-is/hail/pull/3211#issuecomment-376725104:530,Modifiability,Extend,Extended,530,"Changes since last review:; - Method now takes expressions for call and (optionally) scores.; - Block matrix and table of scores annotated and collected from source.cols() sent to Python, processed using int indices, column names restored on python side (thanks @tpoterba); - Fixed bug that silently dropped `n_samples / block_size` proportion of pairs, Python test checks it; - Extended Python tests to compare k and scores paths, test counts, min_kinship, maf, block_size; - Tuned tolerances on comparison with R from Python; - Extended to general column key, removing unique key check, noted in docs; - MEMORY_AND_DISK caching as default (thanks @konradjk) on Scala side; - The diagonal fix meant phi is computed with parallelism up to the number of diagonal blocks, rather than parallelism 1. But that's still likely a bottleneck as phi requires computing and point-wise dividing two big gram matrices. I now write phi to disk and read it back in, which squares the parallelism up to the number of blocks in phi. I think this should also improve the stability of the many downstream calculations derived from phi, esp. if pre-emptibles are used. No longer cacheing phi, but I left caching on the other matrices. @konradjk let us know how this version compares next time you run it.; - Noted in FIXME room for further improvement when fusing blocks: `replace join with zipPartitions, throw away lower triangular blocks sooner, avoid the nulls`; - Updated docs accordingly; - Deleted a bunch of code in PCRelate and PCRelateSuite",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3211#issuecomment-376725104
https://github.com/hail-is/hail/pull/3211#issuecomment-376725104:477,Performance,Tune,Tuned,477,"Changes since last review:; - Method now takes expressions for call and (optionally) scores.; - Block matrix and table of scores annotated and collected from source.cols() sent to Python, processed using int indices, column names restored on python side (thanks @tpoterba); - Fixed bug that silently dropped `n_samples / block_size` proportion of pairs, Python test checks it; - Extended Python tests to compare k and scores paths, test counts, min_kinship, maf, block_size; - Tuned tolerances on comparison with R from Python; - Extended to general column key, removing unique key check, noted in docs; - MEMORY_AND_DISK caching as default (thanks @konradjk) on Scala side; - The diagonal fix meant phi is computed with parallelism up to the number of diagonal blocks, rather than parallelism 1. But that's still likely a bottleneck as phi requires computing and point-wise dividing two big gram matrices. I now write phi to disk and read it back in, which squares the parallelism up to the number of blocks in phi. I think this should also improve the stability of the many downstream calculations derived from phi, esp. if pre-emptibles are used. No longer cacheing phi, but I left caching on the other matrices. @konradjk let us know how this version compares next time you run it.; - Noted in FIXME room for further improvement when fusing blocks: `replace join with zipPartitions, throw away lower triangular blocks sooner, avoid the nulls`; - Updated docs accordingly; - Deleted a bunch of code in PCRelate and PCRelateSuite",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3211#issuecomment-376725104
https://github.com/hail-is/hail/pull/3211#issuecomment-376725104:823,Performance,bottleneck,bottleneck,823,"Changes since last review:; - Method now takes expressions for call and (optionally) scores.; - Block matrix and table of scores annotated and collected from source.cols() sent to Python, processed using int indices, column names restored on python side (thanks @tpoterba); - Fixed bug that silently dropped `n_samples / block_size` proportion of pairs, Python test checks it; - Extended Python tests to compare k and scores paths, test counts, min_kinship, maf, block_size; - Tuned tolerances on comparison with R from Python; - Extended to general column key, removing unique key check, noted in docs; - MEMORY_AND_DISK caching as default (thanks @konradjk) on Scala side; - The diagonal fix meant phi is computed with parallelism up to the number of diagonal blocks, rather than parallelism 1. But that's still likely a bottleneck as phi requires computing and point-wise dividing two big gram matrices. I now write phi to disk and read it back in, which squares the parallelism up to the number of blocks in phi. I think this should also improve the stability of the many downstream calculations derived from phi, esp. if pre-emptibles are used. No longer cacheing phi, but I left caching on the other matrices. @konradjk let us know how this version compares next time you run it.; - Noted in FIXME room for further improvement when fusing blocks: `replace join with zipPartitions, throw away lower triangular blocks sooner, avoid the nulls`; - Updated docs accordingly; - Deleted a bunch of code in PCRelate and PCRelateSuite",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3211#issuecomment-376725104
https://github.com/hail-is/hail/pull/3211#issuecomment-376725104:1160,Performance,cache,cacheing,1160,"Changes since last review:; - Method now takes expressions for call and (optionally) scores.; - Block matrix and table of scores annotated and collected from source.cols() sent to Python, processed using int indices, column names restored on python side (thanks @tpoterba); - Fixed bug that silently dropped `n_samples / block_size` proportion of pairs, Python test checks it; - Extended Python tests to compare k and scores paths, test counts, min_kinship, maf, block_size; - Tuned tolerances on comparison with R from Python; - Extended to general column key, removing unique key check, noted in docs; - MEMORY_AND_DISK caching as default (thanks @konradjk) on Scala side; - The diagonal fix meant phi is computed with parallelism up to the number of diagonal blocks, rather than parallelism 1. But that's still likely a bottleneck as phi requires computing and point-wise dividing two big gram matrices. I now write phi to disk and read it back in, which squares the parallelism up to the number of blocks in phi. I think this should also improve the stability of the many downstream calculations derived from phi, esp. if pre-emptibles are used. No longer cacheing phi, but I left caching on the other matrices. @konradjk let us know how this version compares next time you run it.; - Noted in FIXME room for further improvement when fusing blocks: `replace join with zipPartitions, throw away lower triangular blocks sooner, avoid the nulls`; - Updated docs accordingly; - Deleted a bunch of code in PCRelate and PCRelateSuite",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3211#issuecomment-376725104
https://github.com/hail-is/hail/pull/3211#issuecomment-376725104:1430,Safety,avoid,avoid,1430,"Changes since last review:; - Method now takes expressions for call and (optionally) scores.; - Block matrix and table of scores annotated and collected from source.cols() sent to Python, processed using int indices, column names restored on python side (thanks @tpoterba); - Fixed bug that silently dropped `n_samples / block_size` proportion of pairs, Python test checks it; - Extended Python tests to compare k and scores paths, test counts, min_kinship, maf, block_size; - Tuned tolerances on comparison with R from Python; - Extended to general column key, removing unique key check, noted in docs; - MEMORY_AND_DISK caching as default (thanks @konradjk) on Scala side; - The diagonal fix meant phi is computed with parallelism up to the number of diagonal blocks, rather than parallelism 1. But that's still likely a bottleneck as phi requires computing and point-wise dividing two big gram matrices. I now write phi to disk and read it back in, which squares the parallelism up to the number of blocks in phi. I think this should also improve the stability of the many downstream calculations derived from phi, esp. if pre-emptibles are used. No longer cacheing phi, but I left caching on the other matrices. @konradjk let us know how this version compares next time you run it.; - Noted in FIXME room for further improvement when fusing blocks: `replace join with zipPartitions, throw away lower triangular blocks sooner, avoid the nulls`; - Updated docs accordingly; - Deleted a bunch of code in PCRelate and PCRelateSuite",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3211#issuecomment-376725104
https://github.com/hail-is/hail/pull/3211#issuecomment-376725104:361,Testability,test,test,361,"Changes since last review:; - Method now takes expressions for call and (optionally) scores.; - Block matrix and table of scores annotated and collected from source.cols() sent to Python, processed using int indices, column names restored on python side (thanks @tpoterba); - Fixed bug that silently dropped `n_samples / block_size` proportion of pairs, Python test checks it; - Extended Python tests to compare k and scores paths, test counts, min_kinship, maf, block_size; - Tuned tolerances on comparison with R from Python; - Extended to general column key, removing unique key check, noted in docs; - MEMORY_AND_DISK caching as default (thanks @konradjk) on Scala side; - The diagonal fix meant phi is computed with parallelism up to the number of diagonal blocks, rather than parallelism 1. But that's still likely a bottleneck as phi requires computing and point-wise dividing two big gram matrices. I now write phi to disk and read it back in, which squares the parallelism up to the number of blocks in phi. I think this should also improve the stability of the many downstream calculations derived from phi, esp. if pre-emptibles are used. No longer cacheing phi, but I left caching on the other matrices. @konradjk let us know how this version compares next time you run it.; - Noted in FIXME room for further improvement when fusing blocks: `replace join with zipPartitions, throw away lower triangular blocks sooner, avoid the nulls`; - Updated docs accordingly; - Deleted a bunch of code in PCRelate and PCRelateSuite",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3211#issuecomment-376725104
https://github.com/hail-is/hail/pull/3211#issuecomment-376725104:395,Testability,test,tests,395,"Changes since last review:; - Method now takes expressions for call and (optionally) scores.; - Block matrix and table of scores annotated and collected from source.cols() sent to Python, processed using int indices, column names restored on python side (thanks @tpoterba); - Fixed bug that silently dropped `n_samples / block_size` proportion of pairs, Python test checks it; - Extended Python tests to compare k and scores paths, test counts, min_kinship, maf, block_size; - Tuned tolerances on comparison with R from Python; - Extended to general column key, removing unique key check, noted in docs; - MEMORY_AND_DISK caching as default (thanks @konradjk) on Scala side; - The diagonal fix meant phi is computed with parallelism up to the number of diagonal blocks, rather than parallelism 1. But that's still likely a bottleneck as phi requires computing and point-wise dividing two big gram matrices. I now write phi to disk and read it back in, which squares the parallelism up to the number of blocks in phi. I think this should also improve the stability of the many downstream calculations derived from phi, esp. if pre-emptibles are used. No longer cacheing phi, but I left caching on the other matrices. @konradjk let us know how this version compares next time you run it.; - Noted in FIXME room for further improvement when fusing blocks: `replace join with zipPartitions, throw away lower triangular blocks sooner, avoid the nulls`; - Updated docs accordingly; - Deleted a bunch of code in PCRelate and PCRelateSuite",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3211#issuecomment-376725104
https://github.com/hail-is/hail/pull/3211#issuecomment-376725104:432,Testability,test,test,432,"Changes since last review:; - Method now takes expressions for call and (optionally) scores.; - Block matrix and table of scores annotated and collected from source.cols() sent to Python, processed using int indices, column names restored on python side (thanks @tpoterba); - Fixed bug that silently dropped `n_samples / block_size` proportion of pairs, Python test checks it; - Extended Python tests to compare k and scores paths, test counts, min_kinship, maf, block_size; - Tuned tolerances on comparison with R from Python; - Extended to general column key, removing unique key check, noted in docs; - MEMORY_AND_DISK caching as default (thanks @konradjk) on Scala side; - The diagonal fix meant phi is computed with parallelism up to the number of diagonal blocks, rather than parallelism 1. But that's still likely a bottleneck as phi requires computing and point-wise dividing two big gram matrices. I now write phi to disk and read it back in, which squares the parallelism up to the number of blocks in phi. I think this should also improve the stability of the many downstream calculations derived from phi, esp. if pre-emptibles are used. No longer cacheing phi, but I left caching on the other matrices. @konradjk let us know how this version compares next time you run it.; - Noted in FIXME room for further improvement when fusing blocks: `replace join with zipPartitions, throw away lower triangular blocks sooner, avoid the nulls`; - Updated docs accordingly; - Deleted a bunch of code in PCRelate and PCRelateSuite",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3211#issuecomment-376725104
https://github.com/hail-is/hail/pull/3213#issuecomment-375765956:11,Testability,test,tests,11,"The python tests picked up a bunch of things in OrderedRVD where the type gets serialized within a map[Partitions]. I'm leaving the type Serializable for now, but I know at least @tpoterba was talking about wanting to make that non-serializable, too",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3213#issuecomment-375765956
https://github.com/hail-is/hail/pull/3234#issuecomment-376664624:25,Availability,error,error,25,Could you please fix the error messages? See above.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3234#issuecomment-376664624
https://github.com/hail-is/hail/pull/3234#issuecomment-376664624:31,Integrability,message,messages,31,Could you please fix the error messages? See above.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3234#issuecomment-376664624
https://github.com/hail-is/hail/pull/3240#issuecomment-376892673:0,Integrability,Depend,Depends,0,Depends on #3245,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3240#issuecomment-376892673
https://github.com/hail-is/hail/pull/3258#issuecomment-377379681:270,Testability,log,logging,270,"I think the force_ir flag would be good. I had a hallway conversation with Dan today about how even though our changes are partially designed to give us control over memory, we actually have _no idea_ what our memory usage patterns look like. I think we should add some logging information about region sizes. It could be very illuminating.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3258#issuecomment-377379681
https://github.com/hail-is/hail/pull/3262#issuecomment-377599353:204,Availability,error,error,204,I changed PCA and toIndexRowMatrix to take a field. Now these all use select_entries so no need to analyze keys or process joins. But I still check that the expression has a matrix table source with good error message using `matrix_table_source`.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3262#issuecomment-377599353
https://github.com/hail-is/hail/pull/3262#issuecomment-377599353:210,Integrability,message,message,210,I changed PCA and toIndexRowMatrix to take a field. Now these all use select_entries so no need to analyze keys or process joins. But I still check that the expression has a matrix table source with good error message using `matrix_table_source`.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3262#issuecomment-377599353
https://github.com/hail-is/hail/pull/3262#issuecomment-377693701:0,Deployability,Update,Updated,0,Updated so PCA avoids select when the expression is a field (similar to BlockMatrix.write_from_entry_expr). Hopefully good to go now.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3262#issuecomment-377693701
https://github.com/hail-is/hail/pull/3262#issuecomment-377693701:15,Safety,avoid,avoids,15,Updated so PCA avoids select when the expression is a field (similar to BlockMatrix.write_from_entry_expr). Hopefully good to go now.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3262#issuecomment-377693701
https://github.com/hail-is/hail/pull/3262#issuecomment-377698921:309,Performance,perform,performance,309,"I've moved `check_entry_indexed` outside the conditional and added a note to remove the conditional entirely once select_entries on a field is free. I think it's reasonable to keep the conditional until then, at least in the block matrix case where needlessly invoking the compiler on every double may effect performance. If you feel strongly, I'll remove it from PCA and test the performance impact on write BlockMatrix (though I'd rather just leave the latter unperturbed).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3262#issuecomment-377698921
https://github.com/hail-is/hail/pull/3262#issuecomment-377698921:381,Performance,perform,performance,381,"I've moved `check_entry_indexed` outside the conditional and added a note to remove the conditional entirely once select_entries on a field is free. I think it's reasonable to keep the conditional until then, at least in the block matrix case where needlessly invoking the compiler on every double may effect performance. If you feel strongly, I'll remove it from PCA and test the performance impact on write BlockMatrix (though I'd rather just leave the latter unperturbed).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3262#issuecomment-377698921
https://github.com/hail-is/hail/pull/3262#issuecomment-377698921:372,Testability,test,test,372,"I've moved `check_entry_indexed` outside the conditional and added a note to remove the conditional entirely once select_entries on a field is free. I think it's reasonable to keep the conditional until then, at least in the block matrix case where needlessly invoking the compiler on every double may effect performance. If you feel strongly, I'll remove it from PCA and test the performance impact on write BlockMatrix (though I'd rather just leave the latter unperturbed).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3262#issuecomment-377698921
https://github.com/hail-is/hail/pull/3266#issuecomment-377697212:91,Deployability,integrat,integrated,91,"@jbloom22 can you review this? You know most about Nirvana interop. Also, how do we get it integrated into cloudtools?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3266#issuecomment-377697212
https://github.com/hail-is/hail/pull/3266#issuecomment-377697212:91,Integrability,integrat,integrated,91,"@jbloom22 can you review this? You know most about Nirvana interop. Also, how do we get it integrated into cloudtools?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3266#issuecomment-377697212
https://github.com/hail-is/hail/pull/3266#issuecomment-379095695:14,Deployability,update,updates,14,Closing while updates are made.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3266#issuecomment-379095695
https://github.com/hail-is/hail/pull/3266#issuecomment-379110828:8,Deployability,update,updated,8,"We just updated Nirvana public repository with the bugfix being merged with develop branch. (https://github.com/Illumina/Nirvana/tree/develop). I just realized that the supplementary annotation data haven't been updated (regenerated) yet, so no need to update the JSON schema in Nirvana.scala. This feature branch is good for testing current version of Nirvana (develop branch) and supplementary files.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3266#issuecomment-379110828
https://github.com/hail-is/hail/pull/3266#issuecomment-379110828:212,Deployability,update,updated,212,"We just updated Nirvana public repository with the bugfix being merged with develop branch. (https://github.com/Illumina/Nirvana/tree/develop). I just realized that the supplementary annotation data haven't been updated (regenerated) yet, so no need to update the JSON schema in Nirvana.scala. This feature branch is good for testing current version of Nirvana (develop branch) and supplementary files.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3266#issuecomment-379110828
https://github.com/hail-is/hail/pull/3266#issuecomment-379110828:253,Deployability,update,update,253,"We just updated Nirvana public repository with the bugfix being merged with develop branch. (https://github.com/Illumina/Nirvana/tree/develop). I just realized that the supplementary annotation data haven't been updated (regenerated) yet, so no need to update the JSON schema in Nirvana.scala. This feature branch is good for testing current version of Nirvana (develop branch) and supplementary files.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3266#issuecomment-379110828
https://github.com/hail-is/hail/pull/3266#issuecomment-379110828:326,Testability,test,testing,326,"We just updated Nirvana public repository with the bugfix being merged with develop branch. (https://github.com/Illumina/Nirvana/tree/develop). I just realized that the supplementary annotation data haven't been updated (regenerated) yet, so no need to update the JSON schema in Nirvana.scala. This feature branch is good for testing current version of Nirvana (develop branch) and supplementary files.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3266#issuecomment-379110828
https://github.com/hail-is/hail/pull/3266#issuecomment-379138339:605,Deployability,update,update,605,"Great! So here's what the docs look like now:; https://hail.is/docs/devel/methods/genetics.html#hail.methods.nirvana. Here's the Python source:; https://github.com/hail-is/hail/blob/master/python/hail/methods/qc.py. You can see the built docs of this PR by clicking on Details next to the passing 2.2.0 test, and then clicking on Docs, e.g.:; https://ci.hail.is/viewLog.html?buildId=63354&buildTypeId=HailSourceCode_PRsOnly_HailTestJarSpark220&tab=report_project8_Docs. I'd appreciate if you could:; - ensure the docs are still accurate and add information on what version(s) of Nirvana is compatible.; - update the schema in the documentation to match your changes in Scala; - try running the same pipeline with a few block sizes to see whether its reasonable to reduce the default block size so that users will get more parallelism by default. I suspect a user with a 1 million variant VCF would prefer running 100 cores with 10k variants each to 2 cores with 500k variants each. I'd be surprised if the per-block overhead is so high to outweigh the benefit.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3266#issuecomment-379138339
https://github.com/hail-is/hail/pull/3266#issuecomment-379138339:699,Deployability,pipeline,pipeline,699,"Great! So here's what the docs look like now:; https://hail.is/docs/devel/methods/genetics.html#hail.methods.nirvana. Here's the Python source:; https://github.com/hail-is/hail/blob/master/python/hail/methods/qc.py. You can see the built docs of this PR by clicking on Details next to the passing 2.2.0 test, and then clicking on Docs, e.g.:; https://ci.hail.is/viewLog.html?buildId=63354&buildTypeId=HailSourceCode_PRsOnly_HailTestJarSpark220&tab=report_project8_Docs. I'd appreciate if you could:; - ensure the docs are still accurate and add information on what version(s) of Nirvana is compatible.; - update the schema in the documentation to match your changes in Scala; - try running the same pipeline with a few block sizes to see whether its reasonable to reduce the default block size so that users will get more parallelism by default. I suspect a user with a 1 million variant VCF would prefer running 100 cores with 10k variants each to 2 cores with 500k variants each. I'd be surprised if the per-block overhead is so high to outweigh the benefit.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3266#issuecomment-379138339
https://github.com/hail-is/hail/pull/3266#issuecomment-379138339:764,Energy Efficiency,reduce,reduce,764,"Great! So here's what the docs look like now:; https://hail.is/docs/devel/methods/genetics.html#hail.methods.nirvana. Here's the Python source:; https://github.com/hail-is/hail/blob/master/python/hail/methods/qc.py. You can see the built docs of this PR by clicking on Details next to the passing 2.2.0 test, and then clicking on Docs, e.g.:; https://ci.hail.is/viewLog.html?buildId=63354&buildTypeId=HailSourceCode_PRsOnly_HailTestJarSpark220&tab=report_project8_Docs. I'd appreciate if you could:; - ensure the docs are still accurate and add information on what version(s) of Nirvana is compatible.; - update the schema in the documentation to match your changes in Scala; - try running the same pipeline with a few block sizes to see whether its reasonable to reduce the default block size so that users will get more parallelism by default. I suspect a user with a 1 million variant VCF would prefer running 100 cores with 10k variants each to 2 cores with 500k variants each. I'd be surprised if the per-block overhead is so high to outweigh the benefit.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3266#issuecomment-379138339
https://github.com/hail-is/hail/pull/3266#issuecomment-379138339:303,Testability,test,test,303,"Great! So here's what the docs look like now:; https://hail.is/docs/devel/methods/genetics.html#hail.methods.nirvana. Here's the Python source:; https://github.com/hail-is/hail/blob/master/python/hail/methods/qc.py. You can see the built docs of this PR by clicking on Details next to the passing 2.2.0 test, and then clicking on Docs, e.g.:; https://ci.hail.is/viewLog.html?buildId=63354&buildTypeId=HailSourceCode_PRsOnly_HailTestJarSpark220&tab=report_project8_Docs. I'd appreciate if you could:; - ensure the docs are still accurate and add information on what version(s) of Nirvana is compatible.; - update the schema in the documentation to match your changes in Scala; - try running the same pipeline with a few block sizes to see whether its reasonable to reduce the default block size so that users will get more parallelism by default. I suspect a user with a 1 million variant VCF would prefer running 100 cores with 10k variants each to 2 cores with 500k variants each. I'd be surprised if the per-block overhead is so high to outweigh the benefit.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3266#issuecomment-379138339
https://github.com/hail-is/hail/pull/3266#issuecomment-386617096:82,Testability,test,test,82,@shulik7 just checking in. Thanks for updating the docs! Have you had a chance to test the block size?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3266#issuecomment-386617096
https://github.com/hail-is/hail/pull/3266#issuecomment-386642917:50,Performance,perform,performance,50,"@jbloom22 We lost our AWS EC2 instance I used for performance testing previously. I tried to build HAIL on our cluster, but was out of luck due to some Python issues. We just get another EC2 instance very recently and I haven't had a chance to test the block size yet. One thing I want to mention is that every Nirvana process will spend several seconds on reading the Cache file and Nirvana can process 10k+ variants per second (on my laptop). (I deleted my estimation as it is incorrect... ) So Nirvana prefers larger chunks of data due to the overhead of loading Cache file and relatively faster annotation speed. With other possible overhead like disk I/O (I tested HAIL with Spark running in Standalone mode, which may not be ideal) and merging the results of different Nirvana process, more Nirvana processes do not always lead a shorter processing time.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3266#issuecomment-386642917
https://github.com/hail-is/hail/pull/3266#issuecomment-386642917:369,Performance,Cache,Cache,369,"@jbloom22 We lost our AWS EC2 instance I used for performance testing previously. I tried to build HAIL on our cluster, but was out of luck due to some Python issues. We just get another EC2 instance very recently and I haven't had a chance to test the block size yet. One thing I want to mention is that every Nirvana process will spend several seconds on reading the Cache file and Nirvana can process 10k+ variants per second (on my laptop). (I deleted my estimation as it is incorrect... ) So Nirvana prefers larger chunks of data due to the overhead of loading Cache file and relatively faster annotation speed. With other possible overhead like disk I/O (I tested HAIL with Spark running in Standalone mode, which may not be ideal) and merging the results of different Nirvana process, more Nirvana processes do not always lead a shorter processing time.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3266#issuecomment-386642917
https://github.com/hail-is/hail/pull/3266#issuecomment-386642917:558,Performance,load,loading,558,"@jbloom22 We lost our AWS EC2 instance I used for performance testing previously. I tried to build HAIL on our cluster, but was out of luck due to some Python issues. We just get another EC2 instance very recently and I haven't had a chance to test the block size yet. One thing I want to mention is that every Nirvana process will spend several seconds on reading the Cache file and Nirvana can process 10k+ variants per second (on my laptop). (I deleted my estimation as it is incorrect... ) So Nirvana prefers larger chunks of data due to the overhead of loading Cache file and relatively faster annotation speed. With other possible overhead like disk I/O (I tested HAIL with Spark running in Standalone mode, which may not be ideal) and merging the results of different Nirvana process, more Nirvana processes do not always lead a shorter processing time.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3266#issuecomment-386642917
https://github.com/hail-is/hail/pull/3266#issuecomment-386642917:566,Performance,Cache,Cache,566,"@jbloom22 We lost our AWS EC2 instance I used for performance testing previously. I tried to build HAIL on our cluster, but was out of luck due to some Python issues. We just get another EC2 instance very recently and I haven't had a chance to test the block size yet. One thing I want to mention is that every Nirvana process will spend several seconds on reading the Cache file and Nirvana can process 10k+ variants per second (on my laptop). (I deleted my estimation as it is incorrect... ) So Nirvana prefers larger chunks of data due to the overhead of loading Cache file and relatively faster annotation speed. With other possible overhead like disk I/O (I tested HAIL with Spark running in Standalone mode, which may not be ideal) and merging the results of different Nirvana process, more Nirvana processes do not always lead a shorter processing time.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3266#issuecomment-386642917
https://github.com/hail-is/hail/pull/3266#issuecomment-386642917:62,Testability,test,testing,62,"@jbloom22 We lost our AWS EC2 instance I used for performance testing previously. I tried to build HAIL on our cluster, but was out of luck due to some Python issues. We just get another EC2 instance very recently and I haven't had a chance to test the block size yet. One thing I want to mention is that every Nirvana process will spend several seconds on reading the Cache file and Nirvana can process 10k+ variants per second (on my laptop). (I deleted my estimation as it is incorrect... ) So Nirvana prefers larger chunks of data due to the overhead of loading Cache file and relatively faster annotation speed. With other possible overhead like disk I/O (I tested HAIL with Spark running in Standalone mode, which may not be ideal) and merging the results of different Nirvana process, more Nirvana processes do not always lead a shorter processing time.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3266#issuecomment-386642917
https://github.com/hail-is/hail/pull/3266#issuecomment-386642917:244,Testability,test,test,244,"@jbloom22 We lost our AWS EC2 instance I used for performance testing previously. I tried to build HAIL on our cluster, but was out of luck due to some Python issues. We just get another EC2 instance very recently and I haven't had a chance to test the block size yet. One thing I want to mention is that every Nirvana process will spend several seconds on reading the Cache file and Nirvana can process 10k+ variants per second (on my laptop). (I deleted my estimation as it is incorrect... ) So Nirvana prefers larger chunks of data due to the overhead of loading Cache file and relatively faster annotation speed. With other possible overhead like disk I/O (I tested HAIL with Spark running in Standalone mode, which may not be ideal) and merging the results of different Nirvana process, more Nirvana processes do not always lead a shorter processing time.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3266#issuecomment-386642917
https://github.com/hail-is/hail/pull/3266#issuecomment-386642917:663,Testability,test,tested,663,"@jbloom22 We lost our AWS EC2 instance I used for performance testing previously. I tried to build HAIL on our cluster, but was out of luck due to some Python issues. We just get another EC2 instance very recently and I haven't had a chance to test the block size yet. One thing I want to mention is that every Nirvana process will spend several seconds on reading the Cache file and Nirvana can process 10k+ variants per second (on my laptop). (I deleted my estimation as it is incorrect... ) So Nirvana prefers larger chunks of data due to the overhead of loading Cache file and relatively faster annotation speed. With other possible overhead like disk I/O (I tested HAIL with Spark running in Standalone mode, which may not be ideal) and merging the results of different Nirvana process, more Nirvana processes do not always lead a shorter processing time.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3266#issuecomment-386642917
https://github.com/hail-is/hail/pull/3266#issuecomment-391058985:97,Energy Efficiency,reduce,reduce,97,@jbloom22 That would be great. We have made Nirvana even faster recently. Also we are working on reduce the overhead (i.e. time used to load the Cache) for each Nirvana process. I will test on the best blockSize again when this is done.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3266#issuecomment-391058985
https://github.com/hail-is/hail/pull/3266#issuecomment-391058985:136,Performance,load,load,136,@jbloom22 That would be great. We have made Nirvana even faster recently. Also we are working on reduce the overhead (i.e. time used to load the Cache) for each Nirvana process. I will test on the best blockSize again when this is done.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3266#issuecomment-391058985
https://github.com/hail-is/hail/pull/3266#issuecomment-391058985:145,Performance,Cache,Cache,145,@jbloom22 That would be great. We have made Nirvana even faster recently. Also we are working on reduce the overhead (i.e. time used to load the Cache) for each Nirvana process. I will test on the best blockSize again when this is done.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3266#issuecomment-391058985
https://github.com/hail-is/hail/pull/3266#issuecomment-391058985:185,Testability,test,test,185,@jbloom22 That would be great. We have made Nirvana even faster recently. Also we are working on reduce the overhead (i.e. time used to load the Cache) for each Nirvana process. I will test on the best blockSize again when this is done.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3266#issuecomment-391058985
https://github.com/hail-is/hail/issues/3273#issuecomment-377699456:38,Deployability,install,installed,38,"@danking what do you think is best? I installed them from `R 3.4.0` with:; ```; source(""https://bioconductor.org/biocLite.R""); biocLite(""GENESIS""); biocLite(""SNPRelate""); biocLite(""GWASTools""); ```; But you also mentioned some incompatibility with the latest version of R.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3273#issuecomment-377699456
https://github.com/hail-is/hail/issues/3273#issuecomment-377700023:38,Deployability,install,installing,38,"I think we also need to be clear when installing something that will break everyone's local tests (email, dev post, something).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3273#issuecomment-377700023
https://github.com/hail-is/hail/issues/3273#issuecomment-377700023:92,Testability,test,tests,92,"I think we also need to be clear when installing something that will break everyone's local tests (email, dev post, something).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3273#issuecomment-377700023
https://github.com/hail-is/hail/issues/3273#issuecomment-377700023:27,Usability,clear,clear,27,"I think we also need to be clear when installing something that will break everyone's local tests (email, dev post, something).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3273#issuecomment-377700023
https://github.com/hail-is/hail/issues/3273#issuecomment-377701057:250,Availability,Error,Error,250,"```; * installing *source* package ncdf4 ...; ** package ncdf4 successfully unpacked and MD5 sums checked; configure.ac: starting; checking for nc-config... no; -----------------------------------------------------------------------------------; Error, nc-config not found or not executable. This is a script that comes with the; netcdf library, version 4.1-beta2 or later, and must be present for configuration; to succeed. If you installed the netcdf library (and nc-config) in a standard location, nc-config; should be found automatically. Otherwise, you can specify the full path and name of; the nc-config script by passing the --with-nc-config=/full/path/nc-config argument; flag to the configure script. For example:. ./configure --with-nc-config=/sw/dist/netcdf4/bin/nc-config. Special note for R users:; -------------------------; To pass the configure flag to R, use something like this:. R CMD INSTALL --configure-args=""--with-nc-config=/home/joe/bin/nc-config"" ncdf4. where you should replace /home/joe/bin etc. with the location where you have; installed the nc-config script that came with the netcdf 4 distribution.; -----------------------------------------------------------------------------------; ERROR: configuration failed for package ncdf4; * removing /usr/local/lib/R/3.3/site-library/ncdf4; ERROR: dependency ncdf4 is not available for package GWASTools; * removing /usr/local/lib/R/3.3/site-library/GWASTools; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3273#issuecomment-377701057
https://github.com/hail-is/hail/issues/3273#issuecomment-377701057:1221,Availability,ERROR,ERROR,1221,"```; * installing *source* package ncdf4 ...; ** package ncdf4 successfully unpacked and MD5 sums checked; configure.ac: starting; checking for nc-config... no; -----------------------------------------------------------------------------------; Error, nc-config not found or not executable. This is a script that comes with the; netcdf library, version 4.1-beta2 or later, and must be present for configuration; to succeed. If you installed the netcdf library (and nc-config) in a standard location, nc-config; should be found automatically. Otherwise, you can specify the full path and name of; the nc-config script by passing the --with-nc-config=/full/path/nc-config argument; flag to the configure script. For example:. ./configure --with-nc-config=/sw/dist/netcdf4/bin/nc-config. Special note for R users:; -------------------------; To pass the configure flag to R, use something like this:. R CMD INSTALL --configure-args=""--with-nc-config=/home/joe/bin/nc-config"" ncdf4. where you should replace /home/joe/bin etc. with the location where you have; installed the nc-config script that came with the netcdf 4 distribution.; -----------------------------------------------------------------------------------; ERROR: configuration failed for package ncdf4; * removing /usr/local/lib/R/3.3/site-library/ncdf4; ERROR: dependency ncdf4 is not available for package GWASTools; * removing /usr/local/lib/R/3.3/site-library/GWASTools; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3273#issuecomment-377701057
https://github.com/hail-is/hail/issues/3273#issuecomment-377701057:1324,Availability,ERROR,ERROR,1324,"```; * installing *source* package ncdf4 ...; ** package ncdf4 successfully unpacked and MD5 sums checked; configure.ac: starting; checking for nc-config... no; -----------------------------------------------------------------------------------; Error, nc-config not found or not executable. This is a script that comes with the; netcdf library, version 4.1-beta2 or later, and must be present for configuration; to succeed. If you installed the netcdf library (and nc-config) in a standard location, nc-config; should be found automatically. Otherwise, you can specify the full path and name of; the nc-config script by passing the --with-nc-config=/full/path/nc-config argument; flag to the configure script. For example:. ./configure --with-nc-config=/sw/dist/netcdf4/bin/nc-config. Special note for R users:; -------------------------; To pass the configure flag to R, use something like this:. R CMD INSTALL --configure-args=""--with-nc-config=/home/joe/bin/nc-config"" ncdf4. where you should replace /home/joe/bin etc. with the location where you have; installed the nc-config script that came with the netcdf 4 distribution.; -----------------------------------------------------------------------------------; ERROR: configuration failed for package ncdf4; * removing /usr/local/lib/R/3.3/site-library/ncdf4; ERROR: dependency ncdf4 is not available for package GWASTools; * removing /usr/local/lib/R/3.3/site-library/GWASTools; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3273#issuecomment-377701057
https://github.com/hail-is/hail/issues/3273#issuecomment-377701057:1357,Availability,avail,available,1357,"```; * installing *source* package ncdf4 ...; ** package ncdf4 successfully unpacked and MD5 sums checked; configure.ac: starting; checking for nc-config... no; -----------------------------------------------------------------------------------; Error, nc-config not found or not executable. This is a script that comes with the; netcdf library, version 4.1-beta2 or later, and must be present for configuration; to succeed. If you installed the netcdf library (and nc-config) in a standard location, nc-config; should be found automatically. Otherwise, you can specify the full path and name of; the nc-config script by passing the --with-nc-config=/full/path/nc-config argument; flag to the configure script. For example:. ./configure --with-nc-config=/sw/dist/netcdf4/bin/nc-config. Special note for R users:; -------------------------; To pass the configure flag to R, use something like this:. R CMD INSTALL --configure-args=""--with-nc-config=/home/joe/bin/nc-config"" ncdf4. where you should replace /home/joe/bin etc. with the location where you have; installed the nc-config script that came with the netcdf 4 distribution.; -----------------------------------------------------------------------------------; ERROR: configuration failed for package ncdf4; * removing /usr/local/lib/R/3.3/site-library/ncdf4; ERROR: dependency ncdf4 is not available for package GWASTools; * removing /usr/local/lib/R/3.3/site-library/GWASTools; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3273#issuecomment-377701057
https://github.com/hail-is/hail/issues/3273#issuecomment-377701057:7,Deployability,install,installing,7,"```; * installing *source* package ncdf4 ...; ** package ncdf4 successfully unpacked and MD5 sums checked; configure.ac: starting; checking for nc-config... no; -----------------------------------------------------------------------------------; Error, nc-config not found or not executable. This is a script that comes with the; netcdf library, version 4.1-beta2 or later, and must be present for configuration; to succeed. If you installed the netcdf library (and nc-config) in a standard location, nc-config; should be found automatically. Otherwise, you can specify the full path and name of; the nc-config script by passing the --with-nc-config=/full/path/nc-config argument; flag to the configure script. For example:. ./configure --with-nc-config=/sw/dist/netcdf4/bin/nc-config. Special note for R users:; -------------------------; To pass the configure flag to R, use something like this:. R CMD INSTALL --configure-args=""--with-nc-config=/home/joe/bin/nc-config"" ncdf4. where you should replace /home/joe/bin etc. with the location where you have; installed the nc-config script that came with the netcdf 4 distribution.; -----------------------------------------------------------------------------------; ERROR: configuration failed for package ncdf4; * removing /usr/local/lib/R/3.3/site-library/ncdf4; ERROR: dependency ncdf4 is not available for package GWASTools; * removing /usr/local/lib/R/3.3/site-library/GWASTools; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3273#issuecomment-377701057
https://github.com/hail-is/hail/issues/3273#issuecomment-377701057:402,Deployability,configurat,configuration,402,"```; * installing *source* package ncdf4 ...; ** package ncdf4 successfully unpacked and MD5 sums checked; configure.ac: starting; checking for nc-config... no; -----------------------------------------------------------------------------------; Error, nc-config not found or not executable. This is a script that comes with the; netcdf library, version 4.1-beta2 or later, and must be present for configuration; to succeed. If you installed the netcdf library (and nc-config) in a standard location, nc-config; should be found automatically. Otherwise, you can specify the full path and name of; the nc-config script by passing the --with-nc-config=/full/path/nc-config argument; flag to the configure script. For example:. ./configure --with-nc-config=/sw/dist/netcdf4/bin/nc-config. Special note for R users:; -------------------------; To pass the configure flag to R, use something like this:. R CMD INSTALL --configure-args=""--with-nc-config=/home/joe/bin/nc-config"" ncdf4. where you should replace /home/joe/bin etc. with the location where you have; installed the nc-config script that came with the netcdf 4 distribution.; -----------------------------------------------------------------------------------; ERROR: configuration failed for package ncdf4; * removing /usr/local/lib/R/3.3/site-library/ncdf4; ERROR: dependency ncdf4 is not available for package GWASTools; * removing /usr/local/lib/R/3.3/site-library/GWASTools; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3273#issuecomment-377701057
https://github.com/hail-is/hail/issues/3273#issuecomment-377701057:436,Deployability,install,installed,436,"```; * installing *source* package ncdf4 ...; ** package ncdf4 successfully unpacked and MD5 sums checked; configure.ac: starting; checking for nc-config... no; -----------------------------------------------------------------------------------; Error, nc-config not found or not executable. This is a script that comes with the; netcdf library, version 4.1-beta2 or later, and must be present for configuration; to succeed. If you installed the netcdf library (and nc-config) in a standard location, nc-config; should be found automatically. Otherwise, you can specify the full path and name of; the nc-config script by passing the --with-nc-config=/full/path/nc-config argument; flag to the configure script. For example:. ./configure --with-nc-config=/sw/dist/netcdf4/bin/nc-config. Special note for R users:; -------------------------; To pass the configure flag to R, use something like this:. R CMD INSTALL --configure-args=""--with-nc-config=/home/joe/bin/nc-config"" ncdf4. where you should replace /home/joe/bin etc. with the location where you have; installed the nc-config script that came with the netcdf 4 distribution.; -----------------------------------------------------------------------------------; ERROR: configuration failed for package ncdf4; * removing /usr/local/lib/R/3.3/site-library/ncdf4; ERROR: dependency ncdf4 is not available for package GWASTools; * removing /usr/local/lib/R/3.3/site-library/GWASTools; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3273#issuecomment-377701057
https://github.com/hail-is/hail/issues/3273#issuecomment-377701057:909,Deployability,INSTALL,INSTALL,909,"```; * installing *source* package ncdf4 ...; ** package ncdf4 successfully unpacked and MD5 sums checked; configure.ac: starting; checking for nc-config... no; -----------------------------------------------------------------------------------; Error, nc-config not found or not executable. This is a script that comes with the; netcdf library, version 4.1-beta2 or later, and must be present for configuration; to succeed. If you installed the netcdf library (and nc-config) in a standard location, nc-config; should be found automatically. Otherwise, you can specify the full path and name of; the nc-config script by passing the --with-nc-config=/full/path/nc-config argument; flag to the configure script. For example:. ./configure --with-nc-config=/sw/dist/netcdf4/bin/nc-config. Special note for R users:; -------------------------; To pass the configure flag to R, use something like this:. R CMD INSTALL --configure-args=""--with-nc-config=/home/joe/bin/nc-config"" ncdf4. where you should replace /home/joe/bin etc. with the location where you have; installed the nc-config script that came with the netcdf 4 distribution.; -----------------------------------------------------------------------------------; ERROR: configuration failed for package ncdf4; * removing /usr/local/lib/R/3.3/site-library/ncdf4; ERROR: dependency ncdf4 is not available for package GWASTools; * removing /usr/local/lib/R/3.3/site-library/GWASTools; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3273#issuecomment-377701057
https://github.com/hail-is/hail/issues/3273#issuecomment-377701057:1062,Deployability,install,installed,1062,"```; * installing *source* package ncdf4 ...; ** package ncdf4 successfully unpacked and MD5 sums checked; configure.ac: starting; checking for nc-config... no; -----------------------------------------------------------------------------------; Error, nc-config not found or not executable. This is a script that comes with the; netcdf library, version 4.1-beta2 or later, and must be present for configuration; to succeed. If you installed the netcdf library (and nc-config) in a standard location, nc-config; should be found automatically. Otherwise, you can specify the full path and name of; the nc-config script by passing the --with-nc-config=/full/path/nc-config argument; flag to the configure script. For example:. ./configure --with-nc-config=/sw/dist/netcdf4/bin/nc-config. Special note for R users:; -------------------------; To pass the configure flag to R, use something like this:. R CMD INSTALL --configure-args=""--with-nc-config=/home/joe/bin/nc-config"" ncdf4. where you should replace /home/joe/bin etc. with the location where you have; installed the nc-config script that came with the netcdf 4 distribution.; -----------------------------------------------------------------------------------; ERROR: configuration failed for package ncdf4; * removing /usr/local/lib/R/3.3/site-library/ncdf4; ERROR: dependency ncdf4 is not available for package GWASTools; * removing /usr/local/lib/R/3.3/site-library/GWASTools; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3273#issuecomment-377701057
https://github.com/hail-is/hail/issues/3273#issuecomment-377701057:1228,Deployability,configurat,configuration,1228,"```; * installing *source* package ncdf4 ...; ** package ncdf4 successfully unpacked and MD5 sums checked; configure.ac: starting; checking for nc-config... no; -----------------------------------------------------------------------------------; Error, nc-config not found or not executable. This is a script that comes with the; netcdf library, version 4.1-beta2 or later, and must be present for configuration; to succeed. If you installed the netcdf library (and nc-config) in a standard location, nc-config; should be found automatically. Otherwise, you can specify the full path and name of; the nc-config script by passing the --with-nc-config=/full/path/nc-config argument; flag to the configure script. For example:. ./configure --with-nc-config=/sw/dist/netcdf4/bin/nc-config. Special note for R users:; -------------------------; To pass the configure flag to R, use something like this:. R CMD INSTALL --configure-args=""--with-nc-config=/home/joe/bin/nc-config"" ncdf4. where you should replace /home/joe/bin etc. with the location where you have; installed the nc-config script that came with the netcdf 4 distribution.; -----------------------------------------------------------------------------------; ERROR: configuration failed for package ncdf4; * removing /usr/local/lib/R/3.3/site-library/ncdf4; ERROR: dependency ncdf4 is not available for package GWASTools; * removing /usr/local/lib/R/3.3/site-library/GWASTools; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3273#issuecomment-377701057
https://github.com/hail-is/hail/issues/3273#issuecomment-377701057:1331,Integrability,depend,dependency,1331,"```; * installing *source* package ncdf4 ...; ** package ncdf4 successfully unpacked and MD5 sums checked; configure.ac: starting; checking for nc-config... no; -----------------------------------------------------------------------------------; Error, nc-config not found or not executable. This is a script that comes with the; netcdf library, version 4.1-beta2 or later, and must be present for configuration; to succeed. If you installed the netcdf library (and nc-config) in a standard location, nc-config; should be found automatically. Otherwise, you can specify the full path and name of; the nc-config script by passing the --with-nc-config=/full/path/nc-config argument; flag to the configure script. For example:. ./configure --with-nc-config=/sw/dist/netcdf4/bin/nc-config. Special note for R users:; -------------------------; To pass the configure flag to R, use something like this:. R CMD INSTALL --configure-args=""--with-nc-config=/home/joe/bin/nc-config"" ncdf4. where you should replace /home/joe/bin etc. with the location where you have; installed the nc-config script that came with the netcdf 4 distribution.; -----------------------------------------------------------------------------------; ERROR: configuration failed for package ncdf4; * removing /usr/local/lib/R/3.3/site-library/ncdf4; ERROR: dependency ncdf4 is not available for package GWASTools; * removing /usr/local/lib/R/3.3/site-library/GWASTools; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3273#issuecomment-377701057
https://github.com/hail-is/hail/issues/3273#issuecomment-377701057:111,Modifiability,config,configure,111,"```; * installing *source* package ncdf4 ...; ** package ncdf4 successfully unpacked and MD5 sums checked; configure.ac: starting; checking for nc-config... no; -----------------------------------------------------------------------------------; Error, nc-config not found or not executable. This is a script that comes with the; netcdf library, version 4.1-beta2 or later, and must be present for configuration; to succeed. If you installed the netcdf library (and nc-config) in a standard location, nc-config; should be found automatically. Otherwise, you can specify the full path and name of; the nc-config script by passing the --with-nc-config=/full/path/nc-config argument; flag to the configure script. For example:. ./configure --with-nc-config=/sw/dist/netcdf4/bin/nc-config. Special note for R users:; -------------------------; To pass the configure flag to R, use something like this:. R CMD INSTALL --configure-args=""--with-nc-config=/home/joe/bin/nc-config"" ncdf4. where you should replace /home/joe/bin etc. with the location where you have; installed the nc-config script that came with the netcdf 4 distribution.; -----------------------------------------------------------------------------------; ERROR: configuration failed for package ncdf4; * removing /usr/local/lib/R/3.3/site-library/ncdf4; ERROR: dependency ncdf4 is not available for package GWASTools; * removing /usr/local/lib/R/3.3/site-library/GWASTools; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3273#issuecomment-377701057
https://github.com/hail-is/hail/issues/3273#issuecomment-377701057:151,Modifiability,config,config,151,"```; * installing *source* package ncdf4 ...; ** package ncdf4 successfully unpacked and MD5 sums checked; configure.ac: starting; checking for nc-config... no; -----------------------------------------------------------------------------------; Error, nc-config not found or not executable. This is a script that comes with the; netcdf library, version 4.1-beta2 or later, and must be present for configuration; to succeed. If you installed the netcdf library (and nc-config) in a standard location, nc-config; should be found automatically. Otherwise, you can specify the full path and name of; the nc-config script by passing the --with-nc-config=/full/path/nc-config argument; flag to the configure script. For example:. ./configure --with-nc-config=/sw/dist/netcdf4/bin/nc-config. Special note for R users:; -------------------------; To pass the configure flag to R, use something like this:. R CMD INSTALL --configure-args=""--with-nc-config=/home/joe/bin/nc-config"" ncdf4. where you should replace /home/joe/bin etc. with the location where you have; installed the nc-config script that came with the netcdf 4 distribution.; -----------------------------------------------------------------------------------; ERROR: configuration failed for package ncdf4; * removing /usr/local/lib/R/3.3/site-library/ncdf4; ERROR: dependency ncdf4 is not available for package GWASTools; * removing /usr/local/lib/R/3.3/site-library/GWASTools; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3273#issuecomment-377701057
https://github.com/hail-is/hail/issues/3273#issuecomment-377701057:260,Modifiability,config,config,260,"```; * installing *source* package ncdf4 ...; ** package ncdf4 successfully unpacked and MD5 sums checked; configure.ac: starting; checking for nc-config... no; -----------------------------------------------------------------------------------; Error, nc-config not found or not executable. This is a script that comes with the; netcdf library, version 4.1-beta2 or later, and must be present for configuration; to succeed. If you installed the netcdf library (and nc-config) in a standard location, nc-config; should be found automatically. Otherwise, you can specify the full path and name of; the nc-config script by passing the --with-nc-config=/full/path/nc-config argument; flag to the configure script. For example:. ./configure --with-nc-config=/sw/dist/netcdf4/bin/nc-config. Special note for R users:; -------------------------; To pass the configure flag to R, use something like this:. R CMD INSTALL --configure-args=""--with-nc-config=/home/joe/bin/nc-config"" ncdf4. where you should replace /home/joe/bin etc. with the location where you have; installed the nc-config script that came with the netcdf 4 distribution.; -----------------------------------------------------------------------------------; ERROR: configuration failed for package ncdf4; * removing /usr/local/lib/R/3.3/site-library/ncdf4; ERROR: dependency ncdf4 is not available for package GWASTools; * removing /usr/local/lib/R/3.3/site-library/GWASTools; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3273#issuecomment-377701057
https://github.com/hail-is/hail/issues/3273#issuecomment-377701057:402,Modifiability,config,configuration,402,"```; * installing *source* package ncdf4 ...; ** package ncdf4 successfully unpacked and MD5 sums checked; configure.ac: starting; checking for nc-config... no; -----------------------------------------------------------------------------------; Error, nc-config not found or not executable. This is a script that comes with the; netcdf library, version 4.1-beta2 or later, and must be present for configuration; to succeed. If you installed the netcdf library (and nc-config) in a standard location, nc-config; should be found automatically. Otherwise, you can specify the full path and name of; the nc-config script by passing the --with-nc-config=/full/path/nc-config argument; flag to the configure script. For example:. ./configure --with-nc-config=/sw/dist/netcdf4/bin/nc-config. Special note for R users:; -------------------------; To pass the configure flag to R, use something like this:. R CMD INSTALL --configure-args=""--with-nc-config=/home/joe/bin/nc-config"" ncdf4. where you should replace /home/joe/bin etc. with the location where you have; installed the nc-config script that came with the netcdf 4 distribution.; -----------------------------------------------------------------------------------; ERROR: configuration failed for package ncdf4; * removing /usr/local/lib/R/3.3/site-library/ncdf4; ERROR: dependency ncdf4 is not available for package GWASTools; * removing /usr/local/lib/R/3.3/site-library/GWASTools; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3273#issuecomment-377701057
https://github.com/hail-is/hail/issues/3273#issuecomment-377701057:473,Modifiability,config,config,473,"```; * installing *source* package ncdf4 ...; ** package ncdf4 successfully unpacked and MD5 sums checked; configure.ac: starting; checking for nc-config... no; -----------------------------------------------------------------------------------; Error, nc-config not found or not executable. This is a script that comes with the; netcdf library, version 4.1-beta2 or later, and must be present for configuration; to succeed. If you installed the netcdf library (and nc-config) in a standard location, nc-config; should be found automatically. Otherwise, you can specify the full path and name of; the nc-config script by passing the --with-nc-config=/full/path/nc-config argument; flag to the configure script. For example:. ./configure --with-nc-config=/sw/dist/netcdf4/bin/nc-config. Special note for R users:; -------------------------; To pass the configure flag to R, use something like this:. R CMD INSTALL --configure-args=""--with-nc-config=/home/joe/bin/nc-config"" ncdf4. where you should replace /home/joe/bin etc. with the location where you have; installed the nc-config script that came with the netcdf 4 distribution.; -----------------------------------------------------------------------------------; ERROR: configuration failed for package ncdf4; * removing /usr/local/lib/R/3.3/site-library/ncdf4; ERROR: dependency ncdf4 is not available for package GWASTools; * removing /usr/local/lib/R/3.3/site-library/GWASTools; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3273#issuecomment-377701057
https://github.com/hail-is/hail/issues/3273#issuecomment-377701057:508,Modifiability,config,config,508,"```; * installing *source* package ncdf4 ...; ** package ncdf4 successfully unpacked and MD5 sums checked; configure.ac: starting; checking for nc-config... no; -----------------------------------------------------------------------------------; Error, nc-config not found or not executable. This is a script that comes with the; netcdf library, version 4.1-beta2 or later, and must be present for configuration; to succeed. If you installed the netcdf library (and nc-config) in a standard location, nc-config; should be found automatically. Otherwise, you can specify the full path and name of; the nc-config script by passing the --with-nc-config=/full/path/nc-config argument; flag to the configure script. For example:. ./configure --with-nc-config=/sw/dist/netcdf4/bin/nc-config. Special note for R users:; -------------------------; To pass the configure flag to R, use something like this:. R CMD INSTALL --configure-args=""--with-nc-config=/home/joe/bin/nc-config"" ncdf4. where you should replace /home/joe/bin etc. with the location where you have; installed the nc-config script that came with the netcdf 4 distribution.; -----------------------------------------------------------------------------------; ERROR: configuration failed for package ncdf4; * removing /usr/local/lib/R/3.3/site-library/ncdf4; ERROR: dependency ncdf4 is not available for package GWASTools; * removing /usr/local/lib/R/3.3/site-library/GWASTools; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3273#issuecomment-377701057
https://github.com/hail-is/hail/issues/3273#issuecomment-377701057:608,Modifiability,config,config,608,"```; * installing *source* package ncdf4 ...; ** package ncdf4 successfully unpacked and MD5 sums checked; configure.ac: starting; checking for nc-config... no; -----------------------------------------------------------------------------------; Error, nc-config not found or not executable. This is a script that comes with the; netcdf library, version 4.1-beta2 or later, and must be present for configuration; to succeed. If you installed the netcdf library (and nc-config) in a standard location, nc-config; should be found automatically. Otherwise, you can specify the full path and name of; the nc-config script by passing the --with-nc-config=/full/path/nc-config argument; flag to the configure script. For example:. ./configure --with-nc-config=/sw/dist/netcdf4/bin/nc-config. Special note for R users:; -------------------------; To pass the configure flag to R, use something like this:. R CMD INSTALL --configure-args=""--with-nc-config=/home/joe/bin/nc-config"" ncdf4. where you should replace /home/joe/bin etc. with the location where you have; installed the nc-config script that came with the netcdf 4 distribution.; -----------------------------------------------------------------------------------; ERROR: configuration failed for package ncdf4; * removing /usr/local/lib/R/3.3/site-library/ncdf4; ERROR: dependency ncdf4 is not available for package GWASTools; * removing /usr/local/lib/R/3.3/site-library/GWASTools; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3273#issuecomment-377701057
https://github.com/hail-is/hail/issues/3273#issuecomment-377701057:647,Modifiability,config,config,647,"```; * installing *source* package ncdf4 ...; ** package ncdf4 successfully unpacked and MD5 sums checked; configure.ac: starting; checking for nc-config... no; -----------------------------------------------------------------------------------; Error, nc-config not found or not executable. This is a script that comes with the; netcdf library, version 4.1-beta2 or later, and must be present for configuration; to succeed. If you installed the netcdf library (and nc-config) in a standard location, nc-config; should be found automatically. Otherwise, you can specify the full path and name of; the nc-config script by passing the --with-nc-config=/full/path/nc-config argument; flag to the configure script. For example:. ./configure --with-nc-config=/sw/dist/netcdf4/bin/nc-config. Special note for R users:; -------------------------; To pass the configure flag to R, use something like this:. R CMD INSTALL --configure-args=""--with-nc-config=/home/joe/bin/nc-config"" ncdf4. where you should replace /home/joe/bin etc. with the location where you have; installed the nc-config script that came with the netcdf 4 distribution.; -----------------------------------------------------------------------------------; ERROR: configuration failed for package ncdf4; * removing /usr/local/lib/R/3.3/site-library/ncdf4; ERROR: dependency ncdf4 is not available for package GWASTools; * removing /usr/local/lib/R/3.3/site-library/GWASTools; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3273#issuecomment-377701057
https://github.com/hail-is/hail/issues/3273#issuecomment-377701057:668,Modifiability,config,config,668,"```; * installing *source* package ncdf4 ...; ** package ncdf4 successfully unpacked and MD5 sums checked; configure.ac: starting; checking for nc-config... no; -----------------------------------------------------------------------------------; Error, nc-config not found or not executable. This is a script that comes with the; netcdf library, version 4.1-beta2 or later, and must be present for configuration; to succeed. If you installed the netcdf library (and nc-config) in a standard location, nc-config; should be found automatically. Otherwise, you can specify the full path and name of; the nc-config script by passing the --with-nc-config=/full/path/nc-config argument; flag to the configure script. For example:. ./configure --with-nc-config=/sw/dist/netcdf4/bin/nc-config. Special note for R users:; -------------------------; To pass the configure flag to R, use something like this:. R CMD INSTALL --configure-args=""--with-nc-config=/home/joe/bin/nc-config"" ncdf4. where you should replace /home/joe/bin etc. with the location where you have; installed the nc-config script that came with the netcdf 4 distribution.; -----------------------------------------------------------------------------------; ERROR: configuration failed for package ncdf4; * removing /usr/local/lib/R/3.3/site-library/ncdf4; ERROR: dependency ncdf4 is not available for package GWASTools; * removing /usr/local/lib/R/3.3/site-library/GWASTools; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3273#issuecomment-377701057
https://github.com/hail-is/hail/issues/3273#issuecomment-377701057:697,Modifiability,config,configure,697,"```; * installing *source* package ncdf4 ...; ** package ncdf4 successfully unpacked and MD5 sums checked; configure.ac: starting; checking for nc-config... no; -----------------------------------------------------------------------------------; Error, nc-config not found or not executable. This is a script that comes with the; netcdf library, version 4.1-beta2 or later, and must be present for configuration; to succeed. If you installed the netcdf library (and nc-config) in a standard location, nc-config; should be found automatically. Otherwise, you can specify the full path and name of; the nc-config script by passing the --with-nc-config=/full/path/nc-config argument; flag to the configure script. For example:. ./configure --with-nc-config=/sw/dist/netcdf4/bin/nc-config. Special note for R users:; -------------------------; To pass the configure flag to R, use something like this:. R CMD INSTALL --configure-args=""--with-nc-config=/home/joe/bin/nc-config"" ncdf4. where you should replace /home/joe/bin etc. with the location where you have; installed the nc-config script that came with the netcdf 4 distribution.; -----------------------------------------------------------------------------------; ERROR: configuration failed for package ncdf4; * removing /usr/local/lib/R/3.3/site-library/ncdf4; ERROR: dependency ncdf4 is not available for package GWASTools; * removing /usr/local/lib/R/3.3/site-library/GWASTools; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3273#issuecomment-377701057
https://github.com/hail-is/hail/issues/3273#issuecomment-377701057:731,Modifiability,config,configure,731,"```; * installing *source* package ncdf4 ...; ** package ncdf4 successfully unpacked and MD5 sums checked; configure.ac: starting; checking for nc-config... no; -----------------------------------------------------------------------------------; Error, nc-config not found or not executable. This is a script that comes with the; netcdf library, version 4.1-beta2 or later, and must be present for configuration; to succeed. If you installed the netcdf library (and nc-config) in a standard location, nc-config; should be found automatically. Otherwise, you can specify the full path and name of; the nc-config script by passing the --with-nc-config=/full/path/nc-config argument; flag to the configure script. For example:. ./configure --with-nc-config=/sw/dist/netcdf4/bin/nc-config. Special note for R users:; -------------------------; To pass the configure flag to R, use something like this:. R CMD INSTALL --configure-args=""--with-nc-config=/home/joe/bin/nc-config"" ncdf4. where you should replace /home/joe/bin etc. with the location where you have; installed the nc-config script that came with the netcdf 4 distribution.; -----------------------------------------------------------------------------------; ERROR: configuration failed for package ncdf4; * removing /usr/local/lib/R/3.3/site-library/ncdf4; ERROR: dependency ncdf4 is not available for package GWASTools; * removing /usr/local/lib/R/3.3/site-library/GWASTools; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3273#issuecomment-377701057
https://github.com/hail-is/hail/issues/3273#issuecomment-377701057:751,Modifiability,config,config,751,"```; * installing *source* package ncdf4 ...; ** package ncdf4 successfully unpacked and MD5 sums checked; configure.ac: starting; checking for nc-config... no; -----------------------------------------------------------------------------------; Error, nc-config not found or not executable. This is a script that comes with the; netcdf library, version 4.1-beta2 or later, and must be present for configuration; to succeed. If you installed the netcdf library (and nc-config) in a standard location, nc-config; should be found automatically. Otherwise, you can specify the full path and name of; the nc-config script by passing the --with-nc-config=/full/path/nc-config argument; flag to the configure script. For example:. ./configure --with-nc-config=/sw/dist/netcdf4/bin/nc-config. Special note for R users:; -------------------------; To pass the configure flag to R, use something like this:. R CMD INSTALL --configure-args=""--with-nc-config=/home/joe/bin/nc-config"" ncdf4. where you should replace /home/joe/bin etc. with the location where you have; installed the nc-config script that came with the netcdf 4 distribution.; -----------------------------------------------------------------------------------; ERROR: configuration failed for package ncdf4; * removing /usr/local/lib/R/3.3/site-library/ncdf4; ERROR: dependency ncdf4 is not available for package GWASTools; * removing /usr/local/lib/R/3.3/site-library/GWASTools; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3273#issuecomment-377701057
https://github.com/hail-is/hail/issues/3273#issuecomment-377701057:782,Modifiability,config,config,782,"```; * installing *source* package ncdf4 ...; ** package ncdf4 successfully unpacked and MD5 sums checked; configure.ac: starting; checking for nc-config... no; -----------------------------------------------------------------------------------; Error, nc-config not found or not executable. This is a script that comes with the; netcdf library, version 4.1-beta2 or later, and must be present for configuration; to succeed. If you installed the netcdf library (and nc-config) in a standard location, nc-config; should be found automatically. Otherwise, you can specify the full path and name of; the nc-config script by passing the --with-nc-config=/full/path/nc-config argument; flag to the configure script. For example:. ./configure --with-nc-config=/sw/dist/netcdf4/bin/nc-config. Special note for R users:; -------------------------; To pass the configure flag to R, use something like this:. R CMD INSTALL --configure-args=""--with-nc-config=/home/joe/bin/nc-config"" ncdf4. where you should replace /home/joe/bin etc. with the location where you have; installed the nc-config script that came with the netcdf 4 distribution.; -----------------------------------------------------------------------------------; ERROR: configuration failed for package ncdf4; * removing /usr/local/lib/R/3.3/site-library/ncdf4; ERROR: dependency ncdf4 is not available for package GWASTools; * removing /usr/local/lib/R/3.3/site-library/GWASTools; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3273#issuecomment-377701057
https://github.com/hail-is/hail/issues/3273#issuecomment-377701057:856,Modifiability,config,configure,856,"```; * installing *source* package ncdf4 ...; ** package ncdf4 successfully unpacked and MD5 sums checked; configure.ac: starting; checking for nc-config... no; -----------------------------------------------------------------------------------; Error, nc-config not found or not executable. This is a script that comes with the; netcdf library, version 4.1-beta2 or later, and must be present for configuration; to succeed. If you installed the netcdf library (and nc-config) in a standard location, nc-config; should be found automatically. Otherwise, you can specify the full path and name of; the nc-config script by passing the --with-nc-config=/full/path/nc-config argument; flag to the configure script. For example:. ./configure --with-nc-config=/sw/dist/netcdf4/bin/nc-config. Special note for R users:; -------------------------; To pass the configure flag to R, use something like this:. R CMD INSTALL --configure-args=""--with-nc-config=/home/joe/bin/nc-config"" ncdf4. where you should replace /home/joe/bin etc. with the location where you have; installed the nc-config script that came with the netcdf 4 distribution.; -----------------------------------------------------------------------------------; ERROR: configuration failed for package ncdf4; * removing /usr/local/lib/R/3.3/site-library/ncdf4; ERROR: dependency ncdf4 is not available for package GWASTools; * removing /usr/local/lib/R/3.3/site-library/GWASTools; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3273#issuecomment-377701057
https://github.com/hail-is/hail/issues/3273#issuecomment-377701057:919,Modifiability,config,configure-args,919,"```; * installing *source* package ncdf4 ...; ** package ncdf4 successfully unpacked and MD5 sums checked; configure.ac: starting; checking for nc-config... no; -----------------------------------------------------------------------------------; Error, nc-config not found or not executable. This is a script that comes with the; netcdf library, version 4.1-beta2 or later, and must be present for configuration; to succeed. If you installed the netcdf library (and nc-config) in a standard location, nc-config; should be found automatically. Otherwise, you can specify the full path and name of; the nc-config script by passing the --with-nc-config=/full/path/nc-config argument; flag to the configure script. For example:. ./configure --with-nc-config=/sw/dist/netcdf4/bin/nc-config. Special note for R users:; -------------------------; To pass the configure flag to R, use something like this:. R CMD INSTALL --configure-args=""--with-nc-config=/home/joe/bin/nc-config"" ncdf4. where you should replace /home/joe/bin etc. with the location where you have; installed the nc-config script that came with the netcdf 4 distribution.; -----------------------------------------------------------------------------------; ERROR: configuration failed for package ncdf4; * removing /usr/local/lib/R/3.3/site-library/ncdf4; ERROR: dependency ncdf4 is not available for package GWASTools; * removing /usr/local/lib/R/3.3/site-library/GWASTools; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3273#issuecomment-377701057
https://github.com/hail-is/hail/issues/3273#issuecomment-377701057:945,Modifiability,config,config,945,"```; * installing *source* package ncdf4 ...; ** package ncdf4 successfully unpacked and MD5 sums checked; configure.ac: starting; checking for nc-config... no; -----------------------------------------------------------------------------------; Error, nc-config not found or not executable. This is a script that comes with the; netcdf library, version 4.1-beta2 or later, and must be present for configuration; to succeed. If you installed the netcdf library (and nc-config) in a standard location, nc-config; should be found automatically. Otherwise, you can specify the full path and name of; the nc-config script by passing the --with-nc-config=/full/path/nc-config argument; flag to the configure script. For example:. ./configure --with-nc-config=/sw/dist/netcdf4/bin/nc-config. Special note for R users:; -------------------------; To pass the configure flag to R, use something like this:. R CMD INSTALL --configure-args=""--with-nc-config=/home/joe/bin/nc-config"" ncdf4. where you should replace /home/joe/bin etc. with the location where you have; installed the nc-config script that came with the netcdf 4 distribution.; -----------------------------------------------------------------------------------; ERROR: configuration failed for package ncdf4; * removing /usr/local/lib/R/3.3/site-library/ncdf4; ERROR: dependency ncdf4 is not available for package GWASTools; * removing /usr/local/lib/R/3.3/site-library/GWASTools; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3273#issuecomment-377701057
https://github.com/hail-is/hail/issues/3273#issuecomment-377701057:969,Modifiability,config,config,969,"```; * installing *source* package ncdf4 ...; ** package ncdf4 successfully unpacked and MD5 sums checked; configure.ac: starting; checking for nc-config... no; -----------------------------------------------------------------------------------; Error, nc-config not found or not executable. This is a script that comes with the; netcdf library, version 4.1-beta2 or later, and must be present for configuration; to succeed. If you installed the netcdf library (and nc-config) in a standard location, nc-config; should be found automatically. Otherwise, you can specify the full path and name of; the nc-config script by passing the --with-nc-config=/full/path/nc-config argument; flag to the configure script. For example:. ./configure --with-nc-config=/sw/dist/netcdf4/bin/nc-config. Special note for R users:; -------------------------; To pass the configure flag to R, use something like this:. R CMD INSTALL --configure-args=""--with-nc-config=/home/joe/bin/nc-config"" ncdf4. where you should replace /home/joe/bin etc. with the location where you have; installed the nc-config script that came with the netcdf 4 distribution.; -----------------------------------------------------------------------------------; ERROR: configuration failed for package ncdf4; * removing /usr/local/lib/R/3.3/site-library/ncdf4; ERROR: dependency ncdf4 is not available for package GWASTools; * removing /usr/local/lib/R/3.3/site-library/GWASTools; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3273#issuecomment-377701057
https://github.com/hail-is/hail/issues/3273#issuecomment-377701057:1079,Modifiability,config,config,1079,"```; * installing *source* package ncdf4 ...; ** package ncdf4 successfully unpacked and MD5 sums checked; configure.ac: starting; checking for nc-config... no; -----------------------------------------------------------------------------------; Error, nc-config not found or not executable. This is a script that comes with the; netcdf library, version 4.1-beta2 or later, and must be present for configuration; to succeed. If you installed the netcdf library (and nc-config) in a standard location, nc-config; should be found automatically. Otherwise, you can specify the full path and name of; the nc-config script by passing the --with-nc-config=/full/path/nc-config argument; flag to the configure script. For example:. ./configure --with-nc-config=/sw/dist/netcdf4/bin/nc-config. Special note for R users:; -------------------------; To pass the configure flag to R, use something like this:. R CMD INSTALL --configure-args=""--with-nc-config=/home/joe/bin/nc-config"" ncdf4. where you should replace /home/joe/bin etc. with the location where you have; installed the nc-config script that came with the netcdf 4 distribution.; -----------------------------------------------------------------------------------; ERROR: configuration failed for package ncdf4; * removing /usr/local/lib/R/3.3/site-library/ncdf4; ERROR: dependency ncdf4 is not available for package GWASTools; * removing /usr/local/lib/R/3.3/site-library/GWASTools; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3273#issuecomment-377701057
https://github.com/hail-is/hail/issues/3273#issuecomment-377701057:1228,Modifiability,config,configuration,1228,"```; * installing *source* package ncdf4 ...; ** package ncdf4 successfully unpacked and MD5 sums checked; configure.ac: starting; checking for nc-config... no; -----------------------------------------------------------------------------------; Error, nc-config not found or not executable. This is a script that comes with the; netcdf library, version 4.1-beta2 or later, and must be present for configuration; to succeed. If you installed the netcdf library (and nc-config) in a standard location, nc-config; should be found automatically. Otherwise, you can specify the full path and name of; the nc-config script by passing the --with-nc-config=/full/path/nc-config argument; flag to the configure script. For example:. ./configure --with-nc-config=/sw/dist/netcdf4/bin/nc-config. Special note for R users:; -------------------------; To pass the configure flag to R, use something like this:. R CMD INSTALL --configure-args=""--with-nc-config=/home/joe/bin/nc-config"" ncdf4. where you should replace /home/joe/bin etc. with the location where you have; installed the nc-config script that came with the netcdf 4 distribution.; -----------------------------------------------------------------------------------; ERROR: configuration failed for package ncdf4; * removing /usr/local/lib/R/3.3/site-library/ncdf4; ERROR: dependency ncdf4 is not available for package GWASTools; * removing /usr/local/lib/R/3.3/site-library/GWASTools; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3273#issuecomment-377701057
https://github.com/hail-is/hail/issues/3273#issuecomment-377701080:11,Availability,error,error,11,I get this error trying to install GWASTools,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3273#issuecomment-377701080
https://github.com/hail-is/hail/issues/3273#issuecomment-377701080:27,Deployability,install,install,27,I get this error trying to install GWASTools,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3273#issuecomment-377701080
https://github.com/hail-is/hail/issues/3273#issuecomment-377930321:35,Deployability,install,installable,35,"Yeah. As it stands, PCRelate isn't installable without some effort on modern systems. IIRC, I enabled some by-default-disabled repositories on the cloud machines and then installed the netCDF package. I think the package is named `ncdf`. After this, you should be able to install the packages using `biocLite` as above.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3273#issuecomment-377930321
https://github.com/hail-is/hail/issues/3273#issuecomment-377930321:171,Deployability,install,installed,171,"Yeah. As it stands, PCRelate isn't installable without some effort on modern systems. IIRC, I enabled some by-default-disabled repositories on the cloud machines and then installed the netCDF package. I think the package is named `ncdf`. After this, you should be able to install the packages using `biocLite` as above.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3273#issuecomment-377930321
https://github.com/hail-is/hail/issues/3273#issuecomment-377930321:272,Deployability,install,install,272,"Yeah. As it stands, PCRelate isn't installable without some effort on modern systems. IIRC, I enabled some by-default-disabled repositories on the cloud machines and then installed the netCDF package. I think the package is named `ncdf`. After this, you should be able to install the packages using `biocLite` as above.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3273#issuecomment-377930321
https://github.com/hail-is/hail/issues/3273#issuecomment-377930479:232,Deployability,install,installed,232,"It looks like it's called `netcdf` on `brew`. ```; dking@wmb16-359 # brew info netcdf; netcdf: stable 4.6.0 (bottled); Libraries and data formats for array-oriented scientific data; https://www.unidata.ucar.edu/software/netcdf; Not installed; From: https://github.com/Homebrew/homebrew-core/blob/master/Formula/netcdf.rb; ==> Dependencies; Build: cmake ; Required: hdf5 , gcc ; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3273#issuecomment-377930479
https://github.com/hail-is/hail/issues/3273#issuecomment-377930479:326,Integrability,Depend,Dependencies,326,"It looks like it's called `netcdf` on `brew`. ```; dking@wmb16-359 # brew info netcdf; netcdf: stable 4.6.0 (bottled); Libraries and data formats for array-oriented scientific data; https://www.unidata.ucar.edu/software/netcdf; Not installed; From: https://github.com/Homebrew/homebrew-core/blob/master/Formula/netcdf.rb; ==> Dependencies; Build: cmake ; Required: hdf5 , gcc ; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3273#issuecomment-377930479
https://github.com/hail-is/hail/pull/3274#issuecomment-377931559:60,Deployability,canary,canary,60,"@jbloom22 @tpoterba this makes me uncomfortable, we have no canary if PCRelate starts failing or if any of the infrastructure on which it depends starts failing. What is the long term plan?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3274#issuecomment-377931559
https://github.com/hail-is/hail/pull/3274#issuecomment-377931559:138,Integrability,depend,depends,138,"@jbloom22 @tpoterba this makes me uncomfortable, we have no canary if PCRelate starts failing or if any of the infrastructure on which it depends starts failing. What is the long term plan?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3274#issuecomment-377931559
https://github.com/hail-is/hail/pull/3274#issuecomment-377932960:289,Deployability,install,install,289,"I think one of the following needs to happen:; 1. we document the pc relate setup sufficiently; 2. we precompute results somewhere that PC-Relate runs and test against that. I feel strongly that any PRs that introduce new testing dependencies must also include the relevant information to install those dependencies, probably in the ""getting started developing"" doc or somewhere like that.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3274#issuecomment-377932960
https://github.com/hail-is/hail/pull/3274#issuecomment-377932960:230,Integrability,depend,dependencies,230,"I think one of the following needs to happen:; 1. we document the pc relate setup sufficiently; 2. we precompute results somewhere that PC-Relate runs and test against that. I feel strongly that any PRs that introduce new testing dependencies must also include the relevant information to install those dependencies, probably in the ""getting started developing"" doc or somewhere like that.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3274#issuecomment-377932960
https://github.com/hail-is/hail/pull/3274#issuecomment-377932960:303,Integrability,depend,dependencies,303,"I think one of the following needs to happen:; 1. we document the pc relate setup sufficiently; 2. we precompute results somewhere that PC-Relate runs and test against that. I feel strongly that any PRs that introduce new testing dependencies must also include the relevant information to install those dependencies, probably in the ""getting started developing"" doc or somewhere like that.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3274#issuecomment-377932960
https://github.com/hail-is/hail/pull/3274#issuecomment-377932960:155,Testability,test,test,155,"I think one of the following needs to happen:; 1. we document the pc relate setup sufficiently; 2. we precompute results somewhere that PC-Relate runs and test against that. I feel strongly that any PRs that introduce new testing dependencies must also include the relevant information to install those dependencies, probably in the ""getting started developing"" doc or somewhere like that.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3274#issuecomment-377932960
https://github.com/hail-is/hail/pull/3274#issuecomment-377932960:222,Testability,test,testing,222,"I think one of the following needs to happen:; 1. we document the pc relate setup sufficiently; 2. we precompute results somewhere that PC-Relate runs and test against that. I feel strongly that any PRs that introduce new testing dependencies must also include the relevant information to install those dependencies, probably in the ""getting started developing"" doc or somewhere like that.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3274#issuecomment-377932960
https://github.com/hail-is/hail/issues/3276#issuecomment-380222316:14,Availability,down,down,14,"I've narrowed down where the problem is. `agg.explode` is not treating missing values correctly. This is true if both PL is missing or the entry is missing (filtered out). `agg.explode` is equivalent to `flatMap` aggregator in Scala. This will pass:; `agg.counter(agg.explode(hl.empty_array(hl.tint32)))`. This will fail:; `agg.counter(agg.explode(hl.null(tarray(tint32))))`. This will pass:; ```; e = mt.entries().select('locus', 'alleles', 's', 'PL'); e = e.filter(hl.is_defined(e.PL)); e.aggregate(hl.agg.counter(hl.agg.explode(e.PL))); ```. I tried looking at the `flatMap` function registry function. It looks like the non-aggregator version has `flattenOrNull`, but not the aggregator version. @danking @catoverdrive can you look at the `flatMap` code both in the function registry and the IR to make sure missing values are handled correctly?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3276#issuecomment-380222316
https://github.com/hail-is/hail/pull/3281#issuecomment-377948180:6,Deployability,install,install,6,`brew install netcdf` installed a version of gcc that messed a bunch of stuff up.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3281#issuecomment-377948180
https://github.com/hail-is/hail/pull/3281#issuecomment-377948180:22,Deployability,install,installed,22,`brew install netcdf` installed a version of gcc that messed a bunch of stuff up.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3281#issuecomment-377948180
https://github.com/hail-is/hail/pull/3281#issuecomment-377950025:130,Testability,test,test,130,"also, I followed the above instructions and still getting ; ```; subprocess.CalledProcessError: Command '['Rscript', './../../src/test/resources/is/hail/methods/runPcRelate.R', '/tmp/hail.WisHflMEcWvF/g1y2e25Ei0', '0.0']' returned non-zero exit status 1.; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3281#issuecomment-377950025
https://github.com/hail-is/hail/pull/3281#issuecomment-377952235:107,Availability,down,downloadable,107,"Since netcdf broke my R installation, I upgraded R. Now to revert to 3.3.1, I'm trying to install from the downloadable tarball and running into a bunch of errors. Is this worth it? Why don't we just test against a static results file?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3281#issuecomment-377952235
https://github.com/hail-is/hail/pull/3281#issuecomment-377952235:156,Availability,error,errors,156,"Since netcdf broke my R installation, I upgraded R. Now to revert to 3.3.1, I'm trying to install from the downloadable tarball and running into a bunch of errors. Is this worth it? Why don't we just test against a static results file?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3281#issuecomment-377952235
https://github.com/hail-is/hail/pull/3281#issuecomment-377952235:24,Deployability,install,installation,24,"Since netcdf broke my R installation, I upgraded R. Now to revert to 3.3.1, I'm trying to install from the downloadable tarball and running into a bunch of errors. Is this worth it? Why don't we just test against a static results file?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3281#issuecomment-377952235
https://github.com/hail-is/hail/pull/3281#issuecomment-377952235:40,Deployability,upgrade,upgraded,40,"Since netcdf broke my R installation, I upgraded R. Now to revert to 3.3.1, I'm trying to install from the downloadable tarball and running into a bunch of errors. Is this worth it? Why don't we just test against a static results file?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3281#issuecomment-377952235
https://github.com/hail-is/hail/pull/3281#issuecomment-377952235:90,Deployability,install,install,90,"Since netcdf broke my R installation, I upgraded R. Now to revert to 3.3.1, I'm trying to install from the downloadable tarball and running into a bunch of errors. Is this worth it? Why don't we just test against a static results file?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3281#issuecomment-377952235
https://github.com/hail-is/hail/pull/3281#issuecomment-377952235:200,Testability,test,test,200,"Since netcdf broke my R installation, I upgraded R. Now to revert to 3.3.1, I'm trying to install from the downloadable tarball and running into a bunch of errors. Is this worth it? Why don't we just test against a static results file?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3281#issuecomment-377952235
https://github.com/hail-is/hail/pull/3281#issuecomment-379044933:10,Availability,ping,ping,10,"@tpoterba ping, are you cool with the page I mentioned?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3281#issuecomment-379044933
https://github.com/hail-is/hail/pull/3281#issuecomment-379045312:62,Availability,error,errors,62,I still haven't managed to set it up to work from that. I hit errors while installing the Genesis stuff,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3281#issuecomment-379045312
https://github.com/hail-is/hail/pull/3281#issuecomment-379045312:75,Deployability,install,installing,75,I still haven't managed to set it up to work from that. I hit errors while installing the Genesis stuff,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3281#issuecomment-379045312
https://github.com/hail-is/hail/pull/3281#issuecomment-379056688:30,Deployability,install,installed,30,"I already have these packages installed, and there was no `netcdf` issue with my version of R. @maccum is going to install the latest version of R fresh and try to add all the packages and see if tests pass. Thanks Meredith!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3281#issuecomment-379056688
https://github.com/hail-is/hail/pull/3281#issuecomment-379056688:115,Deployability,install,install,115,"I already have these packages installed, and there was no `netcdf` issue with my version of R. @maccum is going to install the latest version of R fresh and try to add all the packages and see if tests pass. Thanks Meredith!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3281#issuecomment-379056688
https://github.com/hail-is/hail/pull/3281#issuecomment-379056688:196,Testability,test,tests,196,"I already have these packages installed, and there was no `netcdf` issue with my version of R. @maccum is going to install the latest version of R fresh and try to add all the packages and see if tests pass. Thanks Meredith!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3281#issuecomment-379056688
https://github.com/hail-is/hail/pull/3281#issuecomment-379060977:70,Testability,test,test,70,The instructions for the code to run in R worked to get the pc relate test passing. I didn't get an issue with ncdf or netcdf.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3281#issuecomment-379060977
https://github.com/hail-is/hail/pull/3286#issuecomment-378015179:72,Availability,error,error,72,see gitter. Possible different Python semantics on windows throw a name error at `__all__.extend(genetics.__all__)`,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3286#issuecomment-378015179
https://github.com/hail-is/hail/pull/3286#issuecomment-378015179:90,Modifiability,extend,extend,90,see gitter. Possible different Python semantics on windows throw a name error at `__all__.extend(genetics.__all__)`,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3286#issuecomment-378015179
https://github.com/hail-is/hail/pull/3289#issuecomment-378452971:30,Integrability,interface,interface,30,"Given the breaking changes to interface, I'll make a discuss post and alert in various channels when merging. @liameabbott this may significantly improve performance when you pass a field as `x` in regression. I'll follow up directly.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3289#issuecomment-378452971
https://github.com/hail-is/hail/pull/3289#issuecomment-378452971:154,Performance,perform,performance,154,"Given the breaking changes to interface, I'll make a discuss post and alert in various channels when merging. @liameabbott this may significantly improve performance when you pass a field as `x` in regression. I'll follow up directly.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3289#issuecomment-378452971
https://github.com/hail-is/hail/pull/3301#issuecomment-379274927:51,Testability,test,tests,51,"> Calls to Region's constructors should only be in tests or by the RVDContext. Also, I think Region() is still called in the WriteableRegionValue constructor.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3301#issuecomment-379274927
https://github.com/hail-is/hail/pull/3301#issuecomment-379276463:20,Integrability,rout,route,20,Going the small PRs route.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3301#issuecomment-379276463
https://github.com/hail-is/hail/issues/3302#issuecomment-379259962:230,Usability,simpl,simple,230,"Looking over the tutorial, it looks like the primitive functionality we would need to add are versions of intersect and merge. Once we have ordered point-interval joins (annotateRowsIntervalTable), I think both of these should be simple additions. It looks like most of the other bedtools functionality could be implemented in Python on top of those primitives.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3302#issuecomment-379259962
https://github.com/hail-is/hail/issues/3302#issuecomment-379294711:556,Energy Efficiency,power,powerful,556,"Thanks for the list @agladstein, that was helpful. (I love the pictures in their docs!). Of that list, I don't think closest could be built using only intersect and merge. I have some thoughts about how we might implement closest, but that looks like the trickiest function to scale up. > But for a Hail user, it would be awesome to have those implemented in a way we can easily call!. Absolutely! We're moving to an organization where as much of the higher level functionality as possible is implemented in Python, in libraries of methods built using the powerful core Hail 0.2 language. I'm just thinking about how much needs to be added to the core language to enable something like a bedtools emulation library to be built.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3302#issuecomment-379294711
https://github.com/hail-is/hail/pull/3308#issuecomment-380197516:201,Performance,load,loaded,201,"@cseed @danking as far as I can tell, asm doesn't give you a way to look at class/method size and you have to external stuff. So the problem with the constant pool is that with structs, two things are loaded as constants; the index and the offset. I think it's kind of hard to work around this, especially on the `GetField` side.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3308#issuecomment-380197516
https://github.com/hail-is/hail/pull/3310#issuecomment-379887987:9,Testability,test,tested,9,it's not tested,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3310#issuecomment-379887987
https://github.com/hail-is/hail/pull/3310#issuecomment-379888005:13,Testability,test,test,13,I'll write a test,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3310#issuecomment-379888005
https://github.com/hail-is/hail/pull/3310#issuecomment-379903357:124,Testability,test,tests,124,I had to add `TrivialContext` which is just a dummy context for when I'm not really using regions. I guess I could also add tests that use the context in some meaningful way. The tension is that the context-using-functionality should already be tested via MatrixTable and Table.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3310#issuecomment-379903357
https://github.com/hail-is/hail/pull/3310#issuecomment-379903357:245,Testability,test,tested,245,I had to add `TrivialContext` which is just a dummy context for when I'm not really using regions. I guess I could also add tests that use the context in some meaningful way. The tension is that the context-using-functionality should already be tested via MatrixTable and Table.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3310#issuecomment-379903357
https://github.com/hail-is/hail/pull/3322#issuecomment-379576871:63,Testability,test,tests,63,"Obviously. I think we've loosely decoupled review from passing tests in practice. If the code looks good, you can approve it, and I will merge in when it is fixed. If the fix is non-trivial, it is on the author to dismiss and request additional review.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3322#issuecomment-379576871
https://github.com/hail-is/hail/pull/3322#issuecomment-379580976:9,Availability,failure,failures,9,"re: test failures, that policy makes sense.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3322#issuecomment-379580976
https://github.com/hail-is/hail/pull/3322#issuecomment-379580976:4,Testability,test,test,4,"re: test failures, that policy makes sense.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3322#issuecomment-379580976
https://github.com/hail-is/hail/pull/3335#issuecomment-379866339:35,Usability,simpl,simplified,35,"Nice, and then steps 4 - 8 will be simplified / accelerated by #3185. I think once you've revised the latter, you'll find it cleaner to work in terms of indices the whole way through (no 7), indexing the MatrixTable rows to apply the final filter in 10.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3335#issuecomment-379866339
https://github.com/hail-is/hail/pull/3335#issuecomment-380555221:165,Deployability,pipeline,pipeline,165,"Finally, it'd be nice if you can post timings (which I think you have) in the PR: master, vs this branch with a brief description of the timing setup (and maybe the pipeline you're using to time). Thanks!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3335#issuecomment-380555221
https://github.com/hail-is/hail/pull/3335#issuecomment-382885782:0,Testability,benchmark,benchmarks,0,"benchmarks:. Dataset with 12,000 variants: . Master: **122 seconds**; 6352 variants remain after first local prune ; 6329 variants remain after second local prune ; 5793 remain after global prune. This branch: **195 seconds** (ran 3 times); 6352 variants remain after local prune; 5866 variants remain after final prune. Timing of individual parts for this branch: ; Local prune : ~ 62 seconds; Filtering the matrix table to the locally pruned variants : ~ 20 seconds.; Block matrix of standardized genotypes : ~14 seconds.; Correlation matrix (matrix multiply) : ~67 seconds ; Entries table: ~13 seconds; Annotating entries table, computing maximal independent set, filtering final result: ~17 sec. Dataset with 25,965 variants:. Master : **270 seconds**; 12,691 variants (after first local prune) ; 12,590 (after second local prune) ; 11,749 (after global prune). This branch: **503 seconds**; 12,691 (after local prune) ; 11,851 (after final prune). Local prune : 83 seconds; Filter matrix table : 37 seconds; Block Matrix: 24 seconds; Correlation Matrix: 265 seconds; Entries Table: 47 seconds; Annotate entries table, MIS, filter after MIS : 44 seconds",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3335#issuecomment-382885782
https://github.com/hail-is/hail/pull/3335#issuecomment-383291647:66,Testability,benchmark,benchmark,66,will be interesting to see how rebase incorporating #3185 affects benchmark,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3335#issuecomment-383291647
https://github.com/hail-is/hail/pull/3335#issuecomment-385265623:54,Performance,load,loading,54,"Oy! If you `grep netlib hail.log`, do you see natives loading or failing to load? I'll check on my end too.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3335#issuecomment-385265623
https://github.com/hail-is/hail/pull/3335#issuecomment-385265623:76,Performance,load,load,76,"Oy! If you `grep netlib hail.log`, do you see natives loading or failing to load? I'll check on my end too.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3335#issuecomment-385265623
https://github.com/hail-is/hail/pull/3335#issuecomment-385265623:29,Testability,log,log,29,"Oy! If you `grep netlib hail.log`, do you see natives loading or failing to load? I'll check on my end too.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3335#issuecomment-385265623
https://github.com/hail-is/hail/pull/3335#issuecomment-385266528:93,Performance,load,load,93,"Indeed, I'm getting similar timing and also:; ```; 2018-04-29 13:15:04 BLAS: WARN: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS; 2018-04-29 13:15:04 BLAS: WARN: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS; ```; We still have it in the Dataproc image. I wonder what happened locally.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3335#issuecomment-385266528
https://github.com/hail-is/hail/pull/3335#issuecomment-385266528:204,Performance,load,load,204,"Indeed, I'm getting similar timing and also:; ```; 2018-04-29 13:15:04 BLAS: WARN: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS; 2018-04-29 13:15:04 BLAS: WARN: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS; ```; We still have it in the Dataproc image. I wonder what happened locally.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3335#issuecomment-385266528
https://github.com/hail-is/hail/pull/3335#issuecomment-385266926:27,Availability,down,down,27,"This would also be slowing down some of the tests on laptops. Not sure about the CI, I don't see `hail.log` published as a CI artifact.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3335#issuecomment-385266926
https://github.com/hail-is/hail/pull/3335#issuecomment-385266926:44,Testability,test,tests,44,"This would also be slowing down some of the tests on laptops. Not sure about the CI, I don't see `hail.log` published as a CI artifact.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3335#issuecomment-385266926
https://github.com/hail-is/hail/pull/3335#issuecomment-385266926:103,Testability,log,log,103,"This would also be slowing down some of the tests on laptops. Not sure about the CI, I don't see `hail.log` published as a CI artifact.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3335#issuecomment-385266926
https://github.com/hail-is/hail/pull/3335#issuecomment-385283210:79,Performance,load,load,79,"Yeah, that's it. Not surprised. ```; 2018-04-29 12:41:16 BLAS: WARN: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS; 2018-04-29 12:41:16 BLAS: WARN: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS; ```. I'm on linux. I'll try to investigate what's going on tonight.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3335#issuecomment-385283210
https://github.com/hail-is/hail/pull/3335#issuecomment-385283210:190,Performance,load,load,190,"Yeah, that's it. Not surprised. ```; 2018-04-29 12:41:16 BLAS: WARN: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS; 2018-04-29 12:41:16 BLAS: WARN: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS; ```. I'm on linux. I'll try to investigate what's going on tonight.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3335#issuecomment-385283210
https://github.com/hail-is/hail/pull/3335#issuecomment-385310865:38,Integrability,depend,dependencies,38,"OK, if I add the following additional dependencies in gradle:. ```; 	include(dependency('net.sourceforge.f2j:arpack_combined_all:0.1')); 	include(dependency('com.github.fommil.netlib:native_system-java:1.1')); 	include(dependency('com.github.fommil.netlib:netlib-native_system-linux-x86_64:1.1')); 	include(dependency('com.github.fommil.netlib:netlib-native_ref-linux-x86_64:1.1')); 	include(dependency('com.github.fommil:jniloader:1.1')); ```. it correctly loads on Linux:. > 2018-04-30 00:13:07 JniLoader: INFO: successfully loaded /tmp/jniloader8608320282306924695netlib-native_system-linux-x86_64.so. I'll test the analog on OSX tomorrow. Are you sure we're getting natives on Dataproc now? This definitely worked in the past. I get a 4x speedup (in the 1024 cases):. 214 ms  19.2 ms per loop (mean  std. dev. of 7 runs, 1 loop each). Now we're only 35x slower.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3335#issuecomment-385310865
https://github.com/hail-is/hail/pull/3335#issuecomment-385310865:77,Integrability,depend,dependency,77,"OK, if I add the following additional dependencies in gradle:. ```; 	include(dependency('net.sourceforge.f2j:arpack_combined_all:0.1')); 	include(dependency('com.github.fommil.netlib:native_system-java:1.1')); 	include(dependency('com.github.fommil.netlib:netlib-native_system-linux-x86_64:1.1')); 	include(dependency('com.github.fommil.netlib:netlib-native_ref-linux-x86_64:1.1')); 	include(dependency('com.github.fommil:jniloader:1.1')); ```. it correctly loads on Linux:. > 2018-04-30 00:13:07 JniLoader: INFO: successfully loaded /tmp/jniloader8608320282306924695netlib-native_system-linux-x86_64.so. I'll test the analog on OSX tomorrow. Are you sure we're getting natives on Dataproc now? This definitely worked in the past. I get a 4x speedup (in the 1024 cases):. 214 ms  19.2 ms per loop (mean  std. dev. of 7 runs, 1 loop each). Now we're only 35x slower.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3335#issuecomment-385310865
https://github.com/hail-is/hail/pull/3335#issuecomment-385310865:146,Integrability,depend,dependency,146,"OK, if I add the following additional dependencies in gradle:. ```; 	include(dependency('net.sourceforge.f2j:arpack_combined_all:0.1')); 	include(dependency('com.github.fommil.netlib:native_system-java:1.1')); 	include(dependency('com.github.fommil.netlib:netlib-native_system-linux-x86_64:1.1')); 	include(dependency('com.github.fommil.netlib:netlib-native_ref-linux-x86_64:1.1')); 	include(dependency('com.github.fommil:jniloader:1.1')); ```. it correctly loads on Linux:. > 2018-04-30 00:13:07 JniLoader: INFO: successfully loaded /tmp/jniloader8608320282306924695netlib-native_system-linux-x86_64.so. I'll test the analog on OSX tomorrow. Are you sure we're getting natives on Dataproc now? This definitely worked in the past. I get a 4x speedup (in the 1024 cases):. 214 ms  19.2 ms per loop (mean  std. dev. of 7 runs, 1 loop each). Now we're only 35x slower.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3335#issuecomment-385310865
https://github.com/hail-is/hail/pull/3335#issuecomment-385310865:219,Integrability,depend,dependency,219,"OK, if I add the following additional dependencies in gradle:. ```; 	include(dependency('net.sourceforge.f2j:arpack_combined_all:0.1')); 	include(dependency('com.github.fommil.netlib:native_system-java:1.1')); 	include(dependency('com.github.fommil.netlib:netlib-native_system-linux-x86_64:1.1')); 	include(dependency('com.github.fommil.netlib:netlib-native_ref-linux-x86_64:1.1')); 	include(dependency('com.github.fommil:jniloader:1.1')); ```. it correctly loads on Linux:. > 2018-04-30 00:13:07 JniLoader: INFO: successfully loaded /tmp/jniloader8608320282306924695netlib-native_system-linux-x86_64.so. I'll test the analog on OSX tomorrow. Are you sure we're getting natives on Dataproc now? This definitely worked in the past. I get a 4x speedup (in the 1024 cases):. 214 ms  19.2 ms per loop (mean  std. dev. of 7 runs, 1 loop each). Now we're only 35x slower.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3335#issuecomment-385310865
https://github.com/hail-is/hail/pull/3335#issuecomment-385310865:307,Integrability,depend,dependency,307,"OK, if I add the following additional dependencies in gradle:. ```; 	include(dependency('net.sourceforge.f2j:arpack_combined_all:0.1')); 	include(dependency('com.github.fommil.netlib:native_system-java:1.1')); 	include(dependency('com.github.fommil.netlib:netlib-native_system-linux-x86_64:1.1')); 	include(dependency('com.github.fommil.netlib:netlib-native_ref-linux-x86_64:1.1')); 	include(dependency('com.github.fommil:jniloader:1.1')); ```. it correctly loads on Linux:. > 2018-04-30 00:13:07 JniLoader: INFO: successfully loaded /tmp/jniloader8608320282306924695netlib-native_system-linux-x86_64.so. I'll test the analog on OSX tomorrow. Are you sure we're getting natives on Dataproc now? This definitely worked in the past. I get a 4x speedup (in the 1024 cases):. 214 ms  19.2 ms per loop (mean  std. dev. of 7 runs, 1 loop each). Now we're only 35x slower.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3335#issuecomment-385310865
https://github.com/hail-is/hail/pull/3335#issuecomment-385310865:392,Integrability,depend,dependency,392,"OK, if I add the following additional dependencies in gradle:. ```; 	include(dependency('net.sourceforge.f2j:arpack_combined_all:0.1')); 	include(dependency('com.github.fommil.netlib:native_system-java:1.1')); 	include(dependency('com.github.fommil.netlib:netlib-native_system-linux-x86_64:1.1')); 	include(dependency('com.github.fommil.netlib:netlib-native_ref-linux-x86_64:1.1')); 	include(dependency('com.github.fommil:jniloader:1.1')); ```. it correctly loads on Linux:. > 2018-04-30 00:13:07 JniLoader: INFO: successfully loaded /tmp/jniloader8608320282306924695netlib-native_system-linux-x86_64.so. I'll test the analog on OSX tomorrow. Are you sure we're getting natives on Dataproc now? This definitely worked in the past. I get a 4x speedup (in the 1024 cases):. 214 ms  19.2 ms per loop (mean  std. dev. of 7 runs, 1 loop each). Now we're only 35x slower.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3335#issuecomment-385310865
https://github.com/hail-is/hail/pull/3335#issuecomment-385310865:458,Performance,load,loads,458,"OK, if I add the following additional dependencies in gradle:. ```; 	include(dependency('net.sourceforge.f2j:arpack_combined_all:0.1')); 	include(dependency('com.github.fommil.netlib:native_system-java:1.1')); 	include(dependency('com.github.fommil.netlib:netlib-native_system-linux-x86_64:1.1')); 	include(dependency('com.github.fommil.netlib:netlib-native_ref-linux-x86_64:1.1')); 	include(dependency('com.github.fommil:jniloader:1.1')); ```. it correctly loads on Linux:. > 2018-04-30 00:13:07 JniLoader: INFO: successfully loaded /tmp/jniloader8608320282306924695netlib-native_system-linux-x86_64.so. I'll test the analog on OSX tomorrow. Are you sure we're getting natives on Dataproc now? This definitely worked in the past. I get a 4x speedup (in the 1024 cases):. 214 ms  19.2 ms per loop (mean  std. dev. of 7 runs, 1 loop each). Now we're only 35x slower.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3335#issuecomment-385310865
https://github.com/hail-is/hail/pull/3335#issuecomment-385310865:527,Performance,load,loaded,527,"OK, if I add the following additional dependencies in gradle:. ```; 	include(dependency('net.sourceforge.f2j:arpack_combined_all:0.1')); 	include(dependency('com.github.fommil.netlib:native_system-java:1.1')); 	include(dependency('com.github.fommil.netlib:netlib-native_system-linux-x86_64:1.1')); 	include(dependency('com.github.fommil.netlib:netlib-native_ref-linux-x86_64:1.1')); 	include(dependency('com.github.fommil:jniloader:1.1')); ```. it correctly loads on Linux:. > 2018-04-30 00:13:07 JniLoader: INFO: successfully loaded /tmp/jniloader8608320282306924695netlib-native_system-linux-x86_64.so. I'll test the analog on OSX tomorrow. Are you sure we're getting natives on Dataproc now? This definitely worked in the past. I get a 4x speedup (in the 1024 cases):. 214 ms  19.2 ms per loop (mean  std. dev. of 7 runs, 1 loop each). Now we're only 35x slower.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3335#issuecomment-385310865
https://github.com/hail-is/hail/pull/3335#issuecomment-385310865:610,Testability,test,test,610,"OK, if I add the following additional dependencies in gradle:. ```; 	include(dependency('net.sourceforge.f2j:arpack_combined_all:0.1')); 	include(dependency('com.github.fommil.netlib:native_system-java:1.1')); 	include(dependency('com.github.fommil.netlib:netlib-native_system-linux-x86_64:1.1')); 	include(dependency('com.github.fommil.netlib:netlib-native_ref-linux-x86_64:1.1')); 	include(dependency('com.github.fommil:jniloader:1.1')); ```. it correctly loads on Linux:. > 2018-04-30 00:13:07 JniLoader: INFO: successfully loaded /tmp/jniloader8608320282306924695netlib-native_system-linux-x86_64.so. I'll test the analog on OSX tomorrow. Are you sure we're getting natives on Dataproc now? This definitely worked in the past. I get a 4x speedup (in the 1024 cases):. 214 ms  19.2 ms per loop (mean  std. dev. of 7 runs, 1 loop each). Now we're only 35x slower.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3335#issuecomment-385310865
https://github.com/hail-is/hail/pull/3335#issuecomment-385311049:17,Usability,clear,clearly,17,"With natives, it clearly isn't dominated by the matrix multiply and I get something comparable to master: ~33 (master) vs ~36 (this branch, plus some fixes I will suggest in comments) on an example I cooked up (10K variants already mostly independent, a bad case for ld_prune).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3335#issuecomment-385311049
https://github.com/hail-is/hail/pull/3335#issuecomment-385312301:278,Modifiability,flexible,flexible,278,Another thing to explore is how much the block matrix write is spending in compression. That might not be helping out overall. It might be worth modifying BlockMatrix to make the compression optional (and add some features from Matrix/Table will make the file format a bit more flexible.),MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3335#issuecomment-385312301
https://github.com/hail-is/hail/pull/3335#issuecomment-385312916:26,Testability,log,log,26,"Also, a quick look at the log shows some AST operations you're using don't have IR conversions, namely: annotate, drop, abs and contains (which @catoverdrive has a PR for: https://github.com/hail-is/hail/pull/3458). Those would be good additions (maybe as a separate PR.)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3335#issuecomment-385312916
https://github.com/hail-is/hail/issues/3342#issuecomment-380210064:78,Deployability,update,update,78,"I eventually found the command line below that worked. It would be helpful to update the Getting Started page to include any necessary command line --conf parameters. ` spark-submit --jars build/libs/hail-all-spark.jar --conf ""spark.driver.extraClassPath=file:///restricted/projectnb/genpro/github/hail/build/libs/hail-all-spark.jar"" --conf ""spark.executor.extraClassPath=file:////restricted/projectnb/genpro/github/hail/build/libs/hail-all-spark.jar"" --conf spark.kryo.registrator=is.hail.kryo.HailKryoRegistrator --py-files build/distributions/hail-python.zip --num-executors 6 test.py; `",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3342#issuecomment-380210064
https://github.com/hail-is/hail/issues/3342#issuecomment-380210064:580,Testability,test,test,580,"I eventually found the command line below that worked. It would be helpful to update the Getting Started page to include any necessary command line --conf parameters. ` spark-submit --jars build/libs/hail-all-spark.jar --conf ""spark.driver.extraClassPath=file:///restricted/projectnb/genpro/github/hail/build/libs/hail-all-spark.jar"" --conf ""spark.executor.extraClassPath=file:////restricted/projectnb/genpro/github/hail/build/libs/hail-all-spark.jar"" --conf spark.kryo.registrator=is.hail.kryo.HailKryoRegistrator --py-files build/distributions/hail-python.zip --num-executors 6 test.py; `",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3342#issuecomment-380210064
https://github.com/hail-is/hail/issues/3342#issuecomment-380560144:108,Deployability,update,update,108,"Yes, it was the two extraClassPaths that got it running. It would make sense that the --jars parameter also update the paths.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3342#issuecomment-380560144
https://github.com/hail-is/hail/issues/3342#issuecomment-391751782:4,Deployability,update,updated,4,The updated documents look good.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3342#issuecomment-391751782
https://github.com/hail-is/hail/pull/3344#issuecomment-380532502:33,Testability,test,tests,33,"You and @jigold both with these ""tests"". ![dr. evil making air quotes gif](https://media.giphy.com/media/qs6ev2pm8g9dS/giphy.gif)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3344#issuecomment-380532502
https://github.com/hail-is/hail/pull/3348#issuecomment-380924677:10,Availability,ping,ping,10,@jbloom22 ping a ding ding,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3348#issuecomment-380924677
https://github.com/hail-is/hail/pull/3353#issuecomment-380450020:43,Deployability,update,updated,43,Hmm. I see that `Annotation.copy` has been updated to not rely on `Region`s. I'll reimplement these methods in terms of `Annotation.copy`,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3353#issuecomment-380450020
https://github.com/hail-is/hail/pull/3353#issuecomment-380454955:23,Safety,Safe,SafeRow,23,"Oh, huh. There's also `SafeRow` which seems to duplicate `safeFromBaseStructRegionValue`. I prefer all this functionality to be in one spot. @cseed @catoverdrive thoughts? The options seem to be:. - `Annotation.safeFromRegionValue`, `.safeFromBaseStructRegionValue`, `.safeFromArrayRegionValue`; - `SafeRow.read`, `SafeRow.apply`, `SafeIndexedSeq` (naming?). I prefer methods on `Annotation`, though I'm open to shorter names. I always found it peculiar that `UnsafeRow.read` didn't read an `UnsafeRow` (it reads an `Annotation`).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3353#issuecomment-380454955
https://github.com/hail-is/hail/pull/3353#issuecomment-380454955:58,Safety,safe,safeFromBaseStructRegionValue,58,"Oh, huh. There's also `SafeRow` which seems to duplicate `safeFromBaseStructRegionValue`. I prefer all this functionality to be in one spot. @cseed @catoverdrive thoughts? The options seem to be:. - `Annotation.safeFromRegionValue`, `.safeFromBaseStructRegionValue`, `.safeFromArrayRegionValue`; - `SafeRow.read`, `SafeRow.apply`, `SafeIndexedSeq` (naming?). I prefer methods on `Annotation`, though I'm open to shorter names. I always found it peculiar that `UnsafeRow.read` didn't read an `UnsafeRow` (it reads an `Annotation`).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3353#issuecomment-380454955
https://github.com/hail-is/hail/pull/3353#issuecomment-380454955:211,Safety,safe,safeFromRegionValue,211,"Oh, huh. There's also `SafeRow` which seems to duplicate `safeFromBaseStructRegionValue`. I prefer all this functionality to be in one spot. @cseed @catoverdrive thoughts? The options seem to be:. - `Annotation.safeFromRegionValue`, `.safeFromBaseStructRegionValue`, `.safeFromArrayRegionValue`; - `SafeRow.read`, `SafeRow.apply`, `SafeIndexedSeq` (naming?). I prefer methods on `Annotation`, though I'm open to shorter names. I always found it peculiar that `UnsafeRow.read` didn't read an `UnsafeRow` (it reads an `Annotation`).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3353#issuecomment-380454955
https://github.com/hail-is/hail/pull/3353#issuecomment-380454955:235,Safety,safe,safeFromBaseStructRegionValue,235,"Oh, huh. There's also `SafeRow` which seems to duplicate `safeFromBaseStructRegionValue`. I prefer all this functionality to be in one spot. @cseed @catoverdrive thoughts? The options seem to be:. - `Annotation.safeFromRegionValue`, `.safeFromBaseStructRegionValue`, `.safeFromArrayRegionValue`; - `SafeRow.read`, `SafeRow.apply`, `SafeIndexedSeq` (naming?). I prefer methods on `Annotation`, though I'm open to shorter names. I always found it peculiar that `UnsafeRow.read` didn't read an `UnsafeRow` (it reads an `Annotation`).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3353#issuecomment-380454955
https://github.com/hail-is/hail/pull/3353#issuecomment-380454955:269,Safety,safe,safeFromArrayRegionValue,269,"Oh, huh. There's also `SafeRow` which seems to duplicate `safeFromBaseStructRegionValue`. I prefer all this functionality to be in one spot. @cseed @catoverdrive thoughts? The options seem to be:. - `Annotation.safeFromRegionValue`, `.safeFromBaseStructRegionValue`, `.safeFromArrayRegionValue`; - `SafeRow.read`, `SafeRow.apply`, `SafeIndexedSeq` (naming?). I prefer methods on `Annotation`, though I'm open to shorter names. I always found it peculiar that `UnsafeRow.read` didn't read an `UnsafeRow` (it reads an `Annotation`).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3353#issuecomment-380454955
https://github.com/hail-is/hail/pull/3353#issuecomment-380454955:299,Safety,Safe,SafeRow,299,"Oh, huh. There's also `SafeRow` which seems to duplicate `safeFromBaseStructRegionValue`. I prefer all this functionality to be in one spot. @cseed @catoverdrive thoughts? The options seem to be:. - `Annotation.safeFromRegionValue`, `.safeFromBaseStructRegionValue`, `.safeFromArrayRegionValue`; - `SafeRow.read`, `SafeRow.apply`, `SafeIndexedSeq` (naming?). I prefer methods on `Annotation`, though I'm open to shorter names. I always found it peculiar that `UnsafeRow.read` didn't read an `UnsafeRow` (it reads an `Annotation`).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3353#issuecomment-380454955
https://github.com/hail-is/hail/pull/3353#issuecomment-380454955:315,Safety,Safe,SafeRow,315,"Oh, huh. There's also `SafeRow` which seems to duplicate `safeFromBaseStructRegionValue`. I prefer all this functionality to be in one spot. @cseed @catoverdrive thoughts? The options seem to be:. - `Annotation.safeFromRegionValue`, `.safeFromBaseStructRegionValue`, `.safeFromArrayRegionValue`; - `SafeRow.read`, `SafeRow.apply`, `SafeIndexedSeq` (naming?). I prefer methods on `Annotation`, though I'm open to shorter names. I always found it peculiar that `UnsafeRow.read` didn't read an `UnsafeRow` (it reads an `Annotation`).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3353#issuecomment-380454955
https://github.com/hail-is/hail/pull/3353#issuecomment-380454955:332,Safety,Safe,SafeIndexedSeq,332,"Oh, huh. There's also `SafeRow` which seems to duplicate `safeFromBaseStructRegionValue`. I prefer all this functionality to be in one spot. @cseed @catoverdrive thoughts? The options seem to be:. - `Annotation.safeFromRegionValue`, `.safeFromBaseStructRegionValue`, `.safeFromArrayRegionValue`; - `SafeRow.read`, `SafeRow.apply`, `SafeIndexedSeq` (naming?). I prefer methods on `Annotation`, though I'm open to shorter names. I always found it peculiar that `UnsafeRow.read` didn't read an `UnsafeRow` (it reads an `Annotation`).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3353#issuecomment-380454955
https://github.com/hail-is/hail/pull/3353#issuecomment-380454955:460,Safety,Unsafe,UnsafeRow,460,"Oh, huh. There's also `SafeRow` which seems to duplicate `safeFromBaseStructRegionValue`. I prefer all this functionality to be in one spot. @cseed @catoverdrive thoughts? The options seem to be:. - `Annotation.safeFromRegionValue`, `.safeFromBaseStructRegionValue`, `.safeFromArrayRegionValue`; - `SafeRow.read`, `SafeRow.apply`, `SafeIndexedSeq` (naming?). I prefer methods on `Annotation`, though I'm open to shorter names. I always found it peculiar that `UnsafeRow.read` didn't read an `UnsafeRow` (it reads an `Annotation`).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3353#issuecomment-380454955
https://github.com/hail-is/hail/pull/3353#issuecomment-380454955:492,Safety,Unsafe,UnsafeRow,492,"Oh, huh. There's also `SafeRow` which seems to duplicate `safeFromBaseStructRegionValue`. I prefer all this functionality to be in one spot. @cseed @catoverdrive thoughts? The options seem to be:. - `Annotation.safeFromRegionValue`, `.safeFromBaseStructRegionValue`, `.safeFromArrayRegionValue`; - `SafeRow.read`, `SafeRow.apply`, `SafeIndexedSeq` (naming?). I prefer methods on `Annotation`, though I'm open to shorter names. I always found it peculiar that `UnsafeRow.read` didn't read an `UnsafeRow` (it reads an `Annotation`).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3353#issuecomment-380454955
https://github.com/hail-is/hail/pull/3353#issuecomment-380507900:1,Safety,Safe,SafeIndexedSeq,1,`SafeIndexedSeq` would need to be added.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3353#issuecomment-380507900
https://github.com/hail-is/hail/pull/3354#issuecomment-380514682:12,Energy Efficiency,power,power,12,"Behond! The power of IR. All this PR does is move the RVB-based computation for filter entries to a fully IR-driven computation. Timing of:. ```; ds = hl.read_matrix_table('gnomad.mt'); ds = ds.filter_entries((ds.GQ > 40) & (ds.DP > 30)); ds._force_count_rows(); ```. run on a shard of gnomAD (~5GB). master:. ```; real	2m20.295s; user	0m0.421s; sys	0m0.034s; ```. filterentriesir:. ```; real	1m48.399s; user	0m0.411s; sys	0m0.046s; ```. (Two timings each, both +/- <1s.). 23% improvement.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3354#issuecomment-380514682
https://github.com/hail-is/hail/pull/3354#issuecomment-380560073:16,Testability,benchmark,benchmark,16,Poached! I will benchmark my version too.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3354#issuecomment-380560073
https://github.com/hail-is/hail/pull/3354#issuecomment-380560289:60,Testability,test,tests,60,I implemented it in python and just moved filter entries to tests in scala,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3354#issuecomment-380560289
https://github.com/hail-is/hail/pull/3357#issuecomment-380965877:5,Performance,load,loader,5,"the `loader` code is currently just a chunk of code---it gets run whenever it's invoked. When I put it into emit, I was going to protect it from getting run every time the function was evaluated with some checking, but I can put it directly into this function instead--that might be better.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3357#issuecomment-380965877
https://github.com/hail-is/hail/pull/3357#issuecomment-380967820:131,Testability,log,logic,131,ugh actually doing this is not super straightforward! so unless you have super strong objections to this I'll probably jut put the logic directly into emit.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3357#issuecomment-380967820
https://github.com/hail-is/hail/pull/3357#issuecomment-380969334:137,Integrability,rout,route,137,"does that mean the genome reference is getting parsed once per evaluation? That's a pretty expensive thing to do. I'm OK with going this route for now, but we should make a list of things that we need to fix asap when our infrastructure allows.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3357#issuecomment-380969334
https://github.com/hail-is/hail/pull/3357#issuecomment-380970181:218,Performance,load,loader,218,"no, its just a question of where we put the checking logic. When we add a reference genome in Emit, we'll probably just have to set some boolean flag that tells us if something has already been set, and only call the `loader` code if it hasn't been set.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3357#issuecomment-380970181
https://github.com/hail-is/hail/pull/3357#issuecomment-380970181:53,Testability,log,logic,53,"no, its just a question of where we put the checking logic. When we add a reference genome in Emit, we'll probably just have to set some boolean flag that tells us if something has already been set, and only call the `loader` code if it hasn't been set.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3357#issuecomment-380970181
https://github.com/hail-is/hail/pull/3364#issuecomment-380973165:31,Testability,test,tests,31,I confirmed with @jbloom22 the tests I modified should be `absolute=True`.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3364#issuecomment-380973165
https://github.com/hail-is/hail/pull/3365#issuecomment-381180739:1131,Deployability,release,released,1131,"I think tying the reset to the iterator is a mistake. First, iterator is the wrong abstraction here. Whole-stage code generation should use the aggregator/array strategy we're using in Emit to generate nothing, conditionals and loops for map, filter and flatMap, respectively. Ideally read ... do stuff ... write will generate an RDD with no per-element iterators at all. I want to make sure this picture is clear. Second, we want to vectorize in the database sense: we want to process multiple rows together in batches. Then overall structure of a stage is a loop over the batches, and and a loop within batches. Thus, the common case should not be we reset after every element, so I think it's the wrong direction to bake it in. The place where we do this should be interface points with the Spark stack which should be looked at with scorn and derision and as the organizing model. Finally, this points to an ongoing difference in our views about the meaning of context. I see context as serving two purposes (neither of which involve reset):. - First, context is a set of resources needed to process a partition that should be released when the partition is complete. For example, I'm working on GenomicsDB which needs to localize a GenomicsDB shard to a local file that needs to be cleaned up when the partition is complete. - Second, it is a way to tell an iterator where to return its value. (This is the ""current"" region business.). I'd be happy to separate these, but I don't see clean way. In no case do I see generic logic to manage the lifetime of regions (e.g. knowing when to call reset) inside the Context.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3365#issuecomment-381180739
https://github.com/hail-is/hail/pull/3365#issuecomment-381180739:768,Integrability,interface,interface,768,"I think tying the reset to the iterator is a mistake. First, iterator is the wrong abstraction here. Whole-stage code generation should use the aggregator/array strategy we're using in Emit to generate nothing, conditionals and loops for map, filter and flatMap, respectively. Ideally read ... do stuff ... write will generate an RDD with no per-element iterators at all. I want to make sure this picture is clear. Second, we want to vectorize in the database sense: we want to process multiple rows together in batches. Then overall structure of a stage is a loop over the batches, and and a loop within batches. Thus, the common case should not be we reset after every element, so I think it's the wrong direction to bake it in. The place where we do this should be interface points with the Spark stack which should be looked at with scorn and derision and as the organizing model. Finally, this points to an ongoing difference in our views about the meaning of context. I see context as serving two purposes (neither of which involve reset):. - First, context is a set of resources needed to process a partition that should be released when the partition is complete. For example, I'm working on GenomicsDB which needs to localize a GenomicsDB shard to a local file that needs to be cleaned up when the partition is complete. - Second, it is a way to tell an iterator where to return its value. (This is the ""current"" region business.). I'd be happy to separate these, but I don't see clean way. In no case do I see generic logic to manage the lifetime of regions (e.g. knowing when to call reset) inside the Context.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3365#issuecomment-381180739
https://github.com/hail-is/hail/pull/3365#issuecomment-381180739:1528,Testability,log,logic,1528,"I think tying the reset to the iterator is a mistake. First, iterator is the wrong abstraction here. Whole-stage code generation should use the aggregator/array strategy we're using in Emit to generate nothing, conditionals and loops for map, filter and flatMap, respectively. Ideally read ... do stuff ... write will generate an RDD with no per-element iterators at all. I want to make sure this picture is clear. Second, we want to vectorize in the database sense: we want to process multiple rows together in batches. Then overall structure of a stage is a loop over the batches, and and a loop within batches. Thus, the common case should not be we reset after every element, so I think it's the wrong direction to bake it in. The place where we do this should be interface points with the Spark stack which should be looked at with scorn and derision and as the organizing model. Finally, this points to an ongoing difference in our views about the meaning of context. I see context as serving two purposes (neither of which involve reset):. - First, context is a set of resources needed to process a partition that should be released when the partition is complete. For example, I'm working on GenomicsDB which needs to localize a GenomicsDB shard to a local file that needs to be cleaned up when the partition is complete. - Second, it is a way to tell an iterator where to return its value. (This is the ""current"" region business.). I'd be happy to separate these, but I don't see clean way. In no case do I see generic logic to manage the lifetime of regions (e.g. knowing when to call reset) inside the Context.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3365#issuecomment-381180739
https://github.com/hail-is/hail/pull/3365#issuecomment-381180739:408,Usability,clear,clear,408,"I think tying the reset to the iterator is a mistake. First, iterator is the wrong abstraction here. Whole-stage code generation should use the aggregator/array strategy we're using in Emit to generate nothing, conditionals and loops for map, filter and flatMap, respectively. Ideally read ... do stuff ... write will generate an RDD with no per-element iterators at all. I want to make sure this picture is clear. Second, we want to vectorize in the database sense: we want to process multiple rows together in batches. Then overall structure of a stage is a loop over the batches, and and a loop within batches. Thus, the common case should not be we reset after every element, so I think it's the wrong direction to bake it in. The place where we do this should be interface points with the Spark stack which should be looked at with scorn and derision and as the organizing model. Finally, this points to an ongoing difference in our views about the meaning of context. I see context as serving two purposes (neither of which involve reset):. - First, context is a set of resources needed to process a partition that should be released when the partition is complete. For example, I'm working on GenomicsDB which needs to localize a GenomicsDB shard to a local file that needs to be cleaned up when the partition is complete. - Second, it is a way to tell an iterator where to return its value. (This is the ""current"" region business.). I'd be happy to separate these, but I don't see clean way. In no case do I see generic logic to manage the lifetime of regions (e.g. knowing when to call reset) inside the Context.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3365#issuecomment-381180739
https://github.com/hail-is/hail/pull/3381#issuecomment-381608025:0,Integrability,depend,depends,0,depends on #3377,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3381#issuecomment-381608025
https://github.com/hail-is/hail/pull/3381#issuecomment-381610766:74,Testability,log,logistic,74,"This PR rips the EvalContext machinery out of regression methods (linear, logistic, mixed, SKAT). Done as part of the effort detailed here: http://dev.hail.is/t/path-to-get-rid-of-ast/90/7",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3381#issuecomment-381610766
https://github.com/hail-is/hail/pull/3387#issuecomment-381986471:34,Availability,error,error,34,"ah, good point. yes, it caused an error on range_matrix_table(1, 1). _force_count_rows()",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3387#issuecomment-381986471
https://github.com/hail-is/hail/pull/3391#issuecomment-382377269:23,Availability,down,down,23,@cseed I shrunk the PR down to the minimal code change and it's still failing the `LDPruneSuite.testNoPrune` test. Do I misunderstand how to use the Encoder/Decorder stuff?. The failure isn't an assertion error. I've somehow changed the number of records that result from an LDPrune.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3391#issuecomment-382377269
https://github.com/hail-is/hail/pull/3391#issuecomment-382377269:178,Availability,failure,failure,178,@cseed I shrunk the PR down to the minimal code change and it's still failing the `LDPruneSuite.testNoPrune` test. Do I misunderstand how to use the Encoder/Decorder stuff?. The failure isn't an assertion error. I've somehow changed the number of records that result from an LDPrune.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3391#issuecomment-382377269
https://github.com/hail-is/hail/pull/3391#issuecomment-382377269:205,Availability,error,error,205,@cseed I shrunk the PR down to the minimal code change and it's still failing the `LDPruneSuite.testNoPrune` test. Do I misunderstand how to use the Encoder/Decorder stuff?. The failure isn't an assertion error. I've somehow changed the number of records that result from an LDPrune.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3391#issuecomment-382377269
https://github.com/hail-is/hail/pull/3391#issuecomment-382377269:96,Testability,test,testNoPrune,96,@cseed I shrunk the PR down to the minimal code change and it's still failing the `LDPruneSuite.testNoPrune` test. Do I misunderstand how to use the Encoder/Decorder stuff?. The failure isn't an assertion error. I've somehow changed the number of records that result from an LDPrune.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3391#issuecomment-382377269
https://github.com/hail-is/hail/pull/3391#issuecomment-382377269:109,Testability,test,test,109,@cseed I shrunk the PR down to the minimal code change and it's still failing the `LDPruneSuite.testNoPrune` test. Do I misunderstand how to use the Encoder/Decorder stuff?. The failure isn't an assertion error. I've somehow changed the number of records that result from an LDPrune.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3391#issuecomment-382377269
https://github.com/hail-is/hail/pull/3391#issuecomment-382377269:195,Testability,assert,assertion,195,@cseed I shrunk the PR down to the minimal code change and it's still failing the `LDPruneSuite.testNoPrune` test. Do I misunderstand how to use the Encoder/Decorder stuff?. The failure isn't an assertion error. I've somehow changed the number of records that result from an LDPrune.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3391#issuecomment-382377269
https://github.com/hail-is/hail/pull/3392#issuecomment-382172344:14,Integrability,depend,dependent,14,closing until dependent PRs are merged:; - https://github.com/hail-is/hail/pull/3390; - https://github.com/hail-is/hail/pull/3389,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3392#issuecomment-382172344
https://github.com/hail-is/hail/pull/3397#issuecomment-386605198:31,Deployability,update,updated,31,"Closing to refactor, will open updated PR shortly.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3397#issuecomment-386605198
https://github.com/hail-is/hail/pull/3397#issuecomment-386605198:11,Modifiability,refactor,refactor,11,"Closing to refactor, will open updated PR shortly.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3397#issuecomment-386605198
https://github.com/hail-is/hail/issues/3413#issuecomment-386162935:848,Modifiability,variab,variable,848,"@tpoterba Is this any progress on this issue? We have a bunch of VCFs generated by SV programs ( Delly, GenomeStrip, Manta and Lumpy) that have imprecise SV variants that use these type of field formats. . VCF 4.2 spec; ```; 1.2.5 Alternative allele field format; Symbolic alternate alleles for imprecise structural variants:; ##ALT=<ID=type,Description=description>; The ID field indicates the type of structural variant, and can be a colon-separated list of types and subtypes. ID; values are case sensitive strings and may not contain whitespace or angle brackets. The first level type must be one; of the following:;  DEL Deletion relative to the reference;  INS Insertion of novel sequence relative to the reference;  DUP Region of elevated copy number relative to the reference; 2;  INV Inversion of reference sequence;  CNV Copy number variable region (may be both deletion and duplication); The CNV category should not be used when a more specific category can be applied. Reserved subtypes include:;  DUP:TANDEM Tandem duplication;  DEL:ME Deletion of mobile element relative to the reference;  INS:ME Insertion of a mobile element relative to the reference ; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3413#issuecomment-386162935
https://github.com/hail-is/hail/issues/3413#issuecomment-386181958:73,Availability,error,error,73,"Amanda added some stuff so that `hl.is_snp` and friends will run without error for these alleles, but we never support to scala for sampleqc. I'll do that now. I think I'll just relax this error to treat ""invalid"" (which includes symbolic at the moment) alleles the same as ""Complex"" alleles, which aren't counted toward any sampleqc field.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3413#issuecomment-386181958
https://github.com/hail-is/hail/issues/3413#issuecomment-386181958:189,Availability,error,error,189,"Amanda added some stuff so that `hl.is_snp` and friends will run without error for these alleles, but we never support to scala for sampleqc. I'll do that now. I think I'll just relax this error to treat ""invalid"" (which includes symbolic at the moment) alleles the same as ""Complex"" alleles, which aren't counted toward any sampleqc field.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3413#issuecomment-386181958
https://github.com/hail-is/hail/pull/3414#issuecomment-383174303:15,Availability,failure,failures,15,looking at the failures.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3414#issuecomment-383174303
https://github.com/hail-is/hail/pull/3414#issuecomment-383178762:30,Usability,clear,clear,30,Ah. One of them is the region.clear bug rear'ing its head in a new form. At least for that one I know roughly where to look.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3414#issuecomment-383178762
https://github.com/hail-is/hail/pull/3414#issuecomment-383200056:38,Usability,clear,clear,38,Ok squashed the LDPrune one. I forgot clear in persist. (Still on the stack is to figure out why not clearing causes all these weird issues.),MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3414#issuecomment-383200056
https://github.com/hail-is/hail/pull/3414#issuecomment-383200056:101,Usability,clear,clearing,101,Ok squashed the LDPrune one. I forgot clear in persist. (Still on the stack is to figure out why not clearing causes all these weird issues.),MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3414#issuecomment-383200056
https://github.com/hail-is/hail/pull/3414#issuecomment-383249693:96,Testability,test,tests,96,"Also, I wanna take another run through on Monday before we merge this. I think it will pass the tests, but I also think it needs another careful look to ensure its resetting in all the right places and serializing in all the right places.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3414#issuecomment-383249693
https://github.com/hail-is/hail/pull/3414#issuecomment-385520903:55,Availability,failure,failures,55,I'll take another look. Looks like you're hitting some failures in Python now.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3414#issuecomment-385520903
https://github.com/hail-is/hail/pull/3414#issuecomment-386497740:198,Availability,down,downs,198,"CI had a hiccup. I hope this will finally pass, unless the latest master-merge introduced more issues. Needs a careful walk through tomorrow to ensure everything is in place and no unnecessary slow downs were added.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3414#issuecomment-386497740
https://github.com/hail-is/hail/pull/3417#issuecomment-383200453:54,Integrability,message,message,54,"I can't figure out why I'm still getting this warning message:; ```; 2018-04-20 15:31:39 Hail: WARN: modified row key, rescanning to compute ordering...; 2018-04-20 15:31:39 Hail: INFO: Coerced sorted dataset; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3417#issuecomment-383200453
https://github.com/hail-is/hail/pull/3417#issuecomment-383622964:144,Testability,Test,TestUtils,144,"I'm concerned about merging this PR if it's going to resort the dataset. I don't see why I am getting that warning even with the code I have in TestUtils (below). Maybe there is a problem somewhere else?. ```; def exportPlink(mt: MatrixTable, path: String): Unit = {; mt.selectCols(""""""{fam_id: ""0"", id: sa.s, mat_id: ""0"", pat_id: ""0"", is_female: ""0"", pheno: ""NA""}""""""); .annotateRowsExpr(; ""varid"" -> """"""let l = va.locus and a = va.alleles in [l.contig, str(l.position), a[0], a[1]].mkString("":"")"""""",; ""pos_morgan"" -> ""0""); .exportPlink(path); }; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3417#issuecomment-383622964
https://github.com/hail-is/hail/pull/3417#issuecomment-385512355:50,Availability,down,down,50,I changed my PR so the tests will run. I narrowed down the change in behavior occurs when removing just the commit #3426. Should we look into this further?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3417#issuecomment-385512355
https://github.com/hail-is/hail/pull/3417#issuecomment-385512355:23,Testability,test,tests,23,I changed my PR so the tests will run. I narrowed down the change in behavior occurs when removing just the commit #3426. Should we look into this further?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3417#issuecomment-385512355
https://github.com/hail-is/hail/pull/3421#issuecomment-383730398:58,Availability,down,down,58,"FWIW, the per-row copy was super painful. Once I filtered down to the only the things I needed, I saw ~10X speedups in some cases. Will be good to get rid of it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3421#issuecomment-383730398
https://github.com/hail-is/hail/pull/3422#issuecomment-383611333:115,Deployability,update,update,115,"@jigold Yes, since the CompileWithAggregators interface changed. Whichever goes in first, the other can rebase and update?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3422#issuecomment-383611333
https://github.com/hail-is/hail/pull/3422#issuecomment-383611333:46,Integrability,interface,interface,46,"@jigold Yes, since the CompileWithAggregators interface changed. Whichever goes in first, the other can rebase and update?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3422#issuecomment-383611333
https://github.com/hail-is/hail/pull/3424#issuecomment-383742072:24,Availability,error,error,24,There's a new assertion error.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3424#issuecomment-383742072
https://github.com/hail-is/hail/pull/3424#issuecomment-383742072:14,Testability,assert,assertion,14,There's a new assertion error.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3424#issuecomment-383742072
https://github.com/hail-is/hail/pull/3425#issuecomment-383929900:77,Safety,avoid,avoid,77,"The reason I didn't put it all into Python is because I thought we wanted to avoid transferring a huge array with py4j from Scala to Python to just use `annotateGlobals` to add it back to the table in Python, which will transfer it back to Scala. Am I missing something?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3425#issuecomment-383929900
https://github.com/hail-is/hail/pull/3425#issuecomment-384077392:816,Integrability,interface,interface,816,"@cseed ; >Second, I feel like for the tiebreaker we should just have a node weight (Float64) and just take the node with the larger weight to break ties. @danking Would that handle the cases you're aware of? (e.g. LD pruning but keeping the variants with the largest p-values.). This is how I originally wanted to implement this. I tried to pitch this to a couple analysts (I remember talking to Raymond in particular) and they were not having it. The tools they were using (or building themselves) did a somewhat ad-hoc tie breaking (I'm not sure their tie-breaking always induced a total ordering on nodes). I don't think providing a weight is sufficient for their purposes (or at least, it's not how they want to write it). I do think having weights would be cool too, but I think we have to preserve the current interface. This obviously creates a bit of a snag because currently we collect to `Annotation` and the IR compiler only operates on `RegionValue`. To eliminate AST from this method, we need to encode, collect, and decode on master such that `T`s in the BinaryHeap are `RegionValue`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3425#issuecomment-384077392
https://github.com/hail-is/hail/pull/3425#issuecomment-385024493:178,Integrability,interface,interface,178,"OK, I have a suggestion: the schema for the input to MIS should be node1, node2, [optional v float64], where node1 should be preferred if v >= 0. This is the same as the current interface but we just compute the tiebreaker for each edge, instead of lazily. That gets rid of the expression language. There could be a separate weight-based version that takes edges (node1, node2) and weights (node1, w), where then v = w[node1] - w[node2].",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3425#issuecomment-385024493
https://github.com/hail-is/hail/pull/3425#issuecomment-385088990:24,Usability,clear,clearly,24,"Ah, got it. Pairwise is clearly no good. OK, one last question: what are the using for keys that they can compute the scores purely from the keys?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3425#issuecomment-385088990
https://github.com/hail-is/hail/pull/3431#issuecomment-384131910:93,Testability,test,tests,93,"@jigold one of these commits (the last one, I believe?) borrows a line from #3427 to get the tests working. I can wait for that to go in and then remove from this, if you prefer.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3431#issuecomment-384131910
https://github.com/hail-is/hail/pull/3442#issuecomment-385969197:119,Testability,test,tests,119,"> This is probably fine for now that we don't have sameWithinTolerance for unkeyed tables. _same is only used by us in tests. If we want that functionality, then the table must be keyed and the keyed field won't be approximately compared for equality. Weird, Github isn't letting me respond to this comment. Are you requesting a change? To make `Table.same` require the table to by keyed? I'm okay with that, I just want to clarify.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3442#issuecomment-385969197
https://github.com/hail-is/hail/pull/3442#issuecomment-385975067:183,Testability,log,logic,183,"My thought was no change was needed because it's an internal method and a convenience function to have approximately the same. If someone needs it, then they can add more complicated logic later. Whichever you think is best is fine with me.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3442#issuecomment-385975067
https://github.com/hail-is/hail/issues/3446#issuecomment-384667398:95,Deployability,pipeline,pipeline,95,The problem seems to be a MatrixFilterEntries from the stack trace above. can we have the full pipeline?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-384667398
https://github.com/hail-is/hail/issues/3446#issuecomment-384671627:1024,Availability,failure,failure,1024,"ce for Amanda:; ```; Traceback (most recent call last):; File ""/tmp/3c5f402fed564ccd85257c0919d4bffb/assign_subpops.py"", line 157, in <module>; main(args); File ""/tmp/3c5f402fed564ccd85257c0919d4bffb/assign_subpops.py"", line 98, in main; pca_mt = hl.ld_prune(pca_mt, r2=0.1, n_cores=args.num_cores); File ""<decorator-gen-788>"", line 2, in ld_prune; File ""/tmp/3c5f402fed564ccd85257c0919d4bffb/hail-devel-38dbf156b630.zip/hail/typecheck/check.py"", line 490, in _typecheck; File ""/tmp/3c5f402fed564ccd85257c0919d4bffb/hail-devel-38dbf156b630.zip/hail/methods/statgen.py"", line 2918, in ld_prune; File ""/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/tmp/3c5f402fed564ccd85257c0919d4bffb/hail-devel-38dbf156b630.zip/hail/utils/java.py"", line 196, in deco; hail.utils.java.FatalError: ClassCastException: is.hail.codegen.generated.C14 cannot be cast to is.hail.asm4s.AsmFunction2. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 530 in stage 9.0 failed 20 times, most recent failure: Lost task 530.19 in stage 9.0 (TID 19101, gt1-w-78.c.broad-mpg-gnomad.internal, executor 199): java.lang.ClassCastException: is.hail.codegen.generated.C14 cannot be cast to is.hail.asm4s.AsmFunction2; 	at is.hail.io.CompiledPackDecoder.readRegionValue(RowStore.scala:643); 	at is.hail.rvd.RVD$$anonfun$7$$anonfun$apply$8$$anonfun$apply$9$$anonfun$apply$10.apply(RVD.scala:222); 	at is.hail.rvd.RVD$$anonfun$7$$anonfun$apply$8$$anonfun$apply$9$$anonfun$apply$10.apply(RVD.scala:221); 	at is.hail.utils.package$.using(package.scala:577); 	at is.hail.rvd.RVD$$anonfun$7$$anonfun$apply$8$$anonfun$apply$9.apply(RVD.scala:221); 	at is.hail.rvd.RVD$$anonfun$7$$anonfun$apply$8$$anonfun$apply$9.apply(RVD.scala:220); 	at is.hail.utils.package$.using(package.scala:577); 	at is.hail.rvd.RVD$$anonfun$7$$anonfun$apply$8.apply(RVD.scala:220); 	at is.hail.rvd.RVD$$anonfun$7$$anonfun$apply$8.apply(RVD.scala:218); 	at scala.collection.I",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-384671627
https://github.com/hail-is/hail/issues/3446#issuecomment-384671627:1084,Availability,failure,failure,1084,"""/tmp/3c5f402fed564ccd85257c0919d4bffb/assign_subpops.py"", line 157, in <module>; main(args); File ""/tmp/3c5f402fed564ccd85257c0919d4bffb/assign_subpops.py"", line 98, in main; pca_mt = hl.ld_prune(pca_mt, r2=0.1, n_cores=args.num_cores); File ""<decorator-gen-788>"", line 2, in ld_prune; File ""/tmp/3c5f402fed564ccd85257c0919d4bffb/hail-devel-38dbf156b630.zip/hail/typecheck/check.py"", line 490, in _typecheck; File ""/tmp/3c5f402fed564ccd85257c0919d4bffb/hail-devel-38dbf156b630.zip/hail/methods/statgen.py"", line 2918, in ld_prune; File ""/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/tmp/3c5f402fed564ccd85257c0919d4bffb/hail-devel-38dbf156b630.zip/hail/utils/java.py"", line 196, in deco; hail.utils.java.FatalError: ClassCastException: is.hail.codegen.generated.C14 cannot be cast to is.hail.asm4s.AsmFunction2. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 530 in stage 9.0 failed 20 times, most recent failure: Lost task 530.19 in stage 9.0 (TID 19101, gt1-w-78.c.broad-mpg-gnomad.internal, executor 199): java.lang.ClassCastException: is.hail.codegen.generated.C14 cannot be cast to is.hail.asm4s.AsmFunction2; 	at is.hail.io.CompiledPackDecoder.readRegionValue(RowStore.scala:643); 	at is.hail.rvd.RVD$$anonfun$7$$anonfun$apply$8$$anonfun$apply$9$$anonfun$apply$10.apply(RVD.scala:222); 	at is.hail.rvd.RVD$$anonfun$7$$anonfun$apply$8$$anonfun$apply$9$$anonfun$apply$10.apply(RVD.scala:221); 	at is.hail.utils.package$.using(package.scala:577); 	at is.hail.rvd.RVD$$anonfun$7$$anonfun$apply$8$$anonfun$apply$9.apply(RVD.scala:221); 	at is.hail.rvd.RVD$$anonfun$7$$anonfun$apply$8$$anonfun$apply$9.apply(RVD.scala:220); 	at is.hail.utils.package$.using(package.scala:577); 	at is.hail.rvd.RVD$$anonfun$7$$anonfun$apply$8.apply(RVD.scala:220); 	at is.hail.rvd.RVD$$anonfun$7$$anonfun$apply$8.apply(RVD.scala:218); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collectio",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-384671627
https://github.com/hail-is/hail/issues/3446#issuecomment-384671627:7465,Availability,Error,Error,7465,"nfun$7$$anonfun$apply$8.apply(RVD.scala:218); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1795); 	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1158); 	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1158); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Hail version: devel-e6de08e; Error summary: ClassCastException: is.hail.codegen.generated.C14 cannot be cast to is.hail.asm4s.AsmFunction2; ERROR: (gcloud.dataproc.jobs.submit.pyspark) Job [3c5f402fed564ccd85257c0919d4bffb] entered state [ERROR] while waiting for [DONE].; Traceback (most recent call last):; File ""pyhail.py"", line 128, in <module>; main(args, pass_through_args); File ""pyhail.py"", line 109, in main; subprocess.check_output(job); File ""/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/subprocess.py"", line 573, in check_output; raise CalledProcessError(retcode, cmd, output=output); subprocess.CalledProcessError: Command '['gcloud', 'dataproc', 'jobs', 'submit', 'pyspark', '/Users/gtiao/gnomad_qc/hail/sample_qc/assign_subpops.py', '--cluster', 'gt1', '--files=gs://hail-common/builds/devel/jars/hail-devel-38dbf156b630-Spark-2.2.0.jar', '--py-files=gs://hail-common/builds/devel/python/hail-devel-38dbf156b630.zip,/var/folders/rn/t2xcx1ps4h96txll46qkkfsj2q8bnl/T/pyscripts_fYVAte.zip', '--p",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-384671627
https://github.com/hail-is/hail/issues/3446#issuecomment-384671627:7576,Availability,ERROR,ERROR,7576,"9); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1795); 	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1158); 	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1158); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Hail version: devel-e6de08e; Error summary: ClassCastException: is.hail.codegen.generated.C14 cannot be cast to is.hail.asm4s.AsmFunction2; ERROR: (gcloud.dataproc.jobs.submit.pyspark) Job [3c5f402fed564ccd85257c0919d4bffb] entered state [ERROR] while waiting for [DONE].; Traceback (most recent call last):; File ""pyhail.py"", line 128, in <module>; main(args, pass_through_args); File ""pyhail.py"", line 109, in main; subprocess.check_output(job); File ""/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/subprocess.py"", line 573, in check_output; raise CalledProcessError(retcode, cmd, output=output); subprocess.CalledProcessError: Command '['gcloud', 'dataproc', 'jobs', 'submit', 'pyspark', '/Users/gtiao/gnomad_qc/hail/sample_qc/assign_subpops.py', '--cluster', 'gt1', '--files=gs://hail-common/builds/devel/jars/hail-devel-38dbf156b630-Spark-2.2.0.jar', '--py-files=gs://hail-common/builds/devel/python/hail-devel-38dbf156b630.zip,/var/folders/rn/t2xcx1ps4h96txll46qkkfsj2q8bnl/T/pyscripts_fYVAte.zip', '--properties=spark.executor.extraClassPath=./hail-devel-38dbf156b630-Spark-2.2.0.jar,spark.driver.extraClassPat",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-384671627
https://github.com/hail-is/hail/issues/3446#issuecomment-384671627:7675,Availability,ERROR,ERROR,7675,".spark.util.Utils$.getIteratorSize(Utils.scala:1795); 	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1158); 	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1158); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Hail version: devel-e6de08e; Error summary: ClassCastException: is.hail.codegen.generated.C14 cannot be cast to is.hail.asm4s.AsmFunction2; ERROR: (gcloud.dataproc.jobs.submit.pyspark) Job [3c5f402fed564ccd85257c0919d4bffb] entered state [ERROR] while waiting for [DONE].; Traceback (most recent call last):; File ""pyhail.py"", line 128, in <module>; main(args, pass_through_args); File ""pyhail.py"", line 109, in main; subprocess.check_output(job); File ""/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/subprocess.py"", line 573, in check_output; raise CalledProcessError(retcode, cmd, output=output); subprocess.CalledProcessError: Command '['gcloud', 'dataproc', 'jobs', 'submit', 'pyspark', '/Users/gtiao/gnomad_qc/hail/sample_qc/assign_subpops.py', '--cluster', 'gt1', '--files=gs://hail-common/builds/devel/jars/hail-devel-38dbf156b630-Spark-2.2.0.jar', '--py-files=gs://hail-common/builds/devel/python/hail-devel-38dbf156b630.zip,/var/folders/rn/t2xcx1ps4h96txll46qkkfsj2q8bnl/T/pyscripts_fYVAte.zip', '--properties=spark.executor.extraClassPath=./hail-devel-38dbf156b630-Spark-2.2.0.jar,spark.driver.extraClassPath=./hail-devel-38dbf156b630-Spark-2.2.0.jar,spark.files=./hail-devel-38dbf156b630-S",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-384671627
https://github.com/hail-is/hail/issues/3446#issuecomment-384671627:2521,Energy Efficiency,schedul,scheduler,2521,n$apply$9$$anonfun$apply$10.apply(RVD.scala:221); 	at is.hail.utils.package$.using(package.scala:577); 	at is.hail.rvd.RVD$$anonfun$7$$anonfun$apply$8$$anonfun$apply$9.apply(RVD.scala:221); 	at is.hail.rvd.RVD$$anonfun$7$$anonfun$apply$8$$anonfun$apply$9.apply(RVD.scala:220); 	at is.hail.utils.package$.using(package.scala:577); 	at is.hail.rvd.RVD$$anonfun$7$$anonfun$apply$8.apply(RVD.scala:220); 	at is.hail.rvd.RVD$$anonfun$7$$anonfun$apply$8.apply(RVD.scala:218); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1795); 	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1158); 	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1158); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.sp,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-384671627
https://github.com/hail-is/hail/issues/3446#issuecomment-384671627:2593,Energy Efficiency,schedul,scheduler,2593,age$.using(package.scala:577); 	at is.hail.rvd.RVD$$anonfun$7$$anonfun$apply$8$$anonfun$apply$9.apply(RVD.scala:221); 	at is.hail.rvd.RVD$$anonfun$7$$anonfun$apply$8$$anonfun$apply$9.apply(RVD.scala:220); 	at is.hail.utils.package$.using(package.scala:577); 	at is.hail.rvd.RVD$$anonfun$7$$anonfun$apply$8.apply(RVD.scala:220); 	at is.hail.rvd.RVD$$anonfun$7$$anonfun$apply$8.apply(RVD.scala:218); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1795); 	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1158); 	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1158); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGSched,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-384671627
https://github.com/hail-is/hail/issues/3446#issuecomment-384671627:2958,Energy Efficiency,schedul,scheduler,2958,un$apply$8.apply(RVD.scala:218); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1795); 	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1158); 	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1158); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apa,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-384671627
https://github.com/hail-is/hail/issues/3446#issuecomment-384671627:2998,Energy Efficiency,schedul,scheduler,2998,tor$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1795); 	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1158); 	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1158); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-384671627
https://github.com/hail-is/hail/issues/3446#issuecomment-384671627:3097,Energy Efficiency,schedul,scheduler,3097,xt(Iterator.scala:444); 	at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1795); 	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1158); 	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1158); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); 	at org.apache.spark.scheduler.DAGSchedulerEventProces,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-384671627
https://github.com/hail-is/hail/issues/3446#issuecomment-384671627:3195,Energy Efficiency,schedul,scheduler,3195,g.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1158); 	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1158); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoo,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-384671627
https://github.com/hail-is/hail/issues/3446#issuecomment-384671627:3449,Energy Efficiency,schedul,scheduler,3449,nfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2029); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2050); 	at org.apache.spark.SparkConte,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-384671627
https://github.com/hail-is/hail/issues/3446#issuecomment-384671627:3530,Energy Efficiency,schedul,scheduler,3530,ltTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2029); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2050); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2069); 	at org.apache.spark.SparkContext.runJob(Spar,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-384671627
https://github.com/hail-is/hail/issues/3446#issuecomment-384671627:3636,Energy Efficiency,schedul,scheduler,3636,he.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2029); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2050); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2069); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2094); 	at org.apache.spark.rdd.RDD.count(RDD.scala:1158); 	at is.hail.rvd.RVD$class.count(,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-384671627
https://github.com/hail-is/hail/issues/3446#issuecomment-384671627:3786,Energy Efficiency,schedul,scheduler,3786,t java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2029); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2050); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2069); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2094); 	at org.apache.spark.rdd.RDD.count(RDD.scala:1158); 	at is.hail.rvd.RVD$class.count(RVD.scala:183); 	at is.hail.rvd.OrderedRVD.count(OrderedRVD.scala:19); 	at is.hail.methods.LDPrune$$anonfun$9.apply(LDPrune.scala:471); 	at is.hail.me,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-384671627
https://github.com/hail-is/hail/issues/3446#issuecomment-384671627:3875,Energy Efficiency,schedul,scheduler,3875,va.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2029); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2050); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2069); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2094); 	at org.apache.spark.rdd.RDD.count(RDD.scala:1158); 	at is.hail.rvd.RVD$class.count(RVD.scala:183); 	at is.hail.rvd.OrderedRVD.count(OrderedRVD.scala:19); 	at is.hail.methods.LDPrune$$anonfun$9.apply(LDPrune.scala:471); 	at is.hail.methods.LDPrune$$anonfun$9.apply(LDPrune.scala:469); 	at is.hail.utils.package$.time(packag,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-384671627
https://github.com/hail-is/hail/issues/3446#issuecomment-384671627:3973,Energy Efficiency,schedul,scheduler,3973,er.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2029); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2050); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2069); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2094); 	at org.apache.spark.rdd.RDD.count(RDD.scala:1158); 	at is.hail.rvd.RVD$class.count(RVD.scala:183); 	at is.hail.rvd.OrderedRVD.count(OrderedRVD.scala:19); 	at is.hail.methods.LDPrune$$anonfun$9.apply(LDPrune.scala:471); 	at is.hail.methods.LDPrune$$anonfun$9.apply(LDPrune.scala:469); 	at is.hail.utils.package$.time(package.scala:82); 	at is.hail.methods.LDPrune$.apply(LDPrune.scala:469); 	at is.hail.methods.LDPrune.ap,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-384671627
https://github.com/hail-is/hail/issues/3446#issuecomment-384671627:4069,Energy Efficiency,schedul,scheduler,4069,; 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2029); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2050); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2069); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2094); 	at org.apache.spark.rdd.RDD.count(RDD.scala:1158); 	at is.hail.rvd.RVD$class.count(RVD.scala:183); 	at is.hail.rvd.OrderedRVD.count(OrderedRVD.scala:19); 	at is.hail.methods.LDPrune$$anonfun$9.apply(LDPrune.scala:471); 	at is.hail.methods.LDPrune$$anonfun$9.apply(LDPrune.scala:469); 	at is.hail.utils.package$.time(package.scala:82); 	at is.hail.methods.LDPrune$.apply(LDPrune.scala:469); 	at is.hail.methods.LDPrune.apply(LDPrune.scala); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.ref,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-384671627
https://github.com/hail-is/hail/issues/3446#issuecomment-384671627:4234,Energy Efficiency,schedul,scheduler,4234,.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2029); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2050); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2069); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2094); 	at org.apache.spark.rdd.RDD.count(RDD.scala:1158); 	at is.hail.rvd.RVD$class.count(RVD.scala:183); 	at is.hail.rvd.OrderedRVD.count(OrderedRVD.scala:19); 	at is.hail.methods.LDPrune$$anonfun$9.apply(LDPrune.scala:471); 	at is.hail.methods.LDPrune$$anonfun$9.apply(LDPrune.scala:469); 	at is.hail.utils.package$.time(package.scala:82); 	at is.hail.methods.LDPrune$.apply(LDPrune.scala:469); 	at is.hail.methods.LDPrune.apply(LDPrune.scala); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	a,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-384671627
https://github.com/hail-is/hail/issues/3446#issuecomment-384671627:7040,Energy Efficiency,schedul,scheduler,7040,"n$apply$9$$anonfun$apply$10.apply(RVD.scala:221); 	at is.hail.utils.package$.using(package.scala:577); 	at is.hail.rvd.RVD$$anonfun$7$$anonfun$apply$8$$anonfun$apply$9.apply(RVD.scala:221); 	at is.hail.rvd.RVD$$anonfun$7$$anonfun$apply$8$$anonfun$apply$9.apply(RVD.scala:220); 	at is.hail.utils.package$.using(package.scala:577); 	at is.hail.rvd.RVD$$anonfun$7$$anonfun$apply$8.apply(RVD.scala:220); 	at is.hail.rvd.RVD$$anonfun$7$$anonfun$apply$8.apply(RVD.scala:218); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1795); 	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1158); 	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1158); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Hail version: devel-e6de08e; Error summary: ClassCastException: is.hail.codegen.generated.C14 cannot be cast to is.hail.asm4s.AsmFunction2; ERROR: (gcloud.dataproc.jobs.submit.pyspark) Job [3c5f402fed564ccd85257c0919d4bffb] entered state [ERROR] while waiting for [DONE].; Traceback (most recent call last):; File ""pyhail.py"", line 128, in <module>; main(args, pass_through_args); File ""pyhail.py"", line 109, in main; subprocess.check_output(job); File ""/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/subprocess.py"", line 573, in check_output; raise CalledProcessError(retcode, cmd, ou",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-384671627
https://github.com/hail-is/hail/issues/3446#issuecomment-384671627:7112,Energy Efficiency,schedul,scheduler,7112,"age$.using(package.scala:577); 	at is.hail.rvd.RVD$$anonfun$7$$anonfun$apply$8$$anonfun$apply$9.apply(RVD.scala:221); 	at is.hail.rvd.RVD$$anonfun$7$$anonfun$apply$8$$anonfun$apply$9.apply(RVD.scala:220); 	at is.hail.utils.package$.using(package.scala:577); 	at is.hail.rvd.RVD$$anonfun$7$$anonfun$apply$8.apply(RVD.scala:220); 	at is.hail.rvd.RVD$$anonfun$7$$anonfun$apply$8.apply(RVD.scala:218); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1795); 	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1158); 	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1158); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Hail version: devel-e6de08e; Error summary: ClassCastException: is.hail.codegen.generated.C14 cannot be cast to is.hail.asm4s.AsmFunction2; ERROR: (gcloud.dataproc.jobs.submit.pyspark) Job [3c5f402fed564ccd85257c0919d4bffb] entered state [ERROR] while waiting for [DONE].; Traceback (most recent call last):; File ""pyhail.py"", line 128, in <module>; main(args, pass_through_args); File ""pyhail.py"", line 109, in main; subprocess.check_output(job); File ""/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/subprocess.py"", line 573, in check_output; raise CalledProcessError(retcode, cmd, output=output); subprocess.CalledProcessError: Command '['gcloud', 'datapr",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-384671627
https://github.com/hail-is/hail/issues/3446#issuecomment-384671627:2718,Performance,concurren,concurrent,2718,hail.rvd.RVD$$anonfun$7$$anonfun$apply$8$$anonfun$apply$9.apply(RVD.scala:220); 	at is.hail.utils.package$.using(package.scala:577); 	at is.hail.rvd.RVD$$anonfun$7$$anonfun$apply$8.apply(RVD.scala:220); 	at is.hail.rvd.RVD$$anonfun$7$$anonfun$apply$8.apply(RVD.scala:218); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1795); 	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1158); 	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1158); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-384671627
https://github.com/hail-is/hail/issues/3446#issuecomment-384671627:2803,Performance,concurren,concurrent,2803,s.hail.utils.package$.using(package.scala:577); 	at is.hail.rvd.RVD$$anonfun$7$$anonfun$apply$8.apply(RVD.scala:220); 	at is.hail.rvd.RVD$$anonfun$7$$anonfun$apply$8.apply(RVD.scala:218); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1795); 	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1158); 	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1158); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-384671627
https://github.com/hail-is/hail/issues/3446#issuecomment-384671627:7237,Performance,concurren,concurrent,7237,"hail.rvd.RVD$$anonfun$7$$anonfun$apply$8$$anonfun$apply$9.apply(RVD.scala:220); 	at is.hail.utils.package$.using(package.scala:577); 	at is.hail.rvd.RVD$$anonfun$7$$anonfun$apply$8.apply(RVD.scala:220); 	at is.hail.rvd.RVD$$anonfun$7$$anonfun$apply$8.apply(RVD.scala:218); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1795); 	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1158); 	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1158); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Hail version: devel-e6de08e; Error summary: ClassCastException: is.hail.codegen.generated.C14 cannot be cast to is.hail.asm4s.AsmFunction2; ERROR: (gcloud.dataproc.jobs.submit.pyspark) Job [3c5f402fed564ccd85257c0919d4bffb] entered state [ERROR] while waiting for [DONE].; Traceback (most recent call last):; File ""pyhail.py"", line 128, in <module>; main(args, pass_through_args); File ""pyhail.py"", line 109, in main; subprocess.check_output(job); File ""/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/subprocess.py"", line 573, in check_output; raise CalledProcessError(retcode, cmd, output=output); subprocess.CalledProcessError: Command '['gcloud', 'dataproc', 'jobs', 'submit', 'pyspark', '/Users/gtiao/gnomad_qc/hail/sample_qc/assign_subpops.py', '--cluster', 'gt1', '--files=gs:/",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-384671627
https://github.com/hail-is/hail/issues/3446#issuecomment-384671627:7322,Performance,concurren,concurrent,7322,"s.hail.utils.package$.using(package.scala:577); 	at is.hail.rvd.RVD$$anonfun$7$$anonfun$apply$8.apply(RVD.scala:220); 	at is.hail.rvd.RVD$$anonfun$7$$anonfun$apply$8.apply(RVD.scala:218); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1795); 	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1158); 	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1158); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Hail version: devel-e6de08e; Error summary: ClassCastException: is.hail.codegen.generated.C14 cannot be cast to is.hail.asm4s.AsmFunction2; ERROR: (gcloud.dataproc.jobs.submit.pyspark) Job [3c5f402fed564ccd85257c0919d4bffb] entered state [ERROR] while waiting for [DONE].; Traceback (most recent call last):; File ""pyhail.py"", line 128, in <module>; main(args, pass_through_args); File ""pyhail.py"", line 109, in main; subprocess.check_output(job); File ""/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/subprocess.py"", line 573, in check_output; raise CalledProcessError(retcode, cmd, output=output); subprocess.CalledProcessError: Command '['gcloud', 'dataproc', 'jobs', 'submit', 'pyspark', '/Users/gtiao/gnomad_qc/hail/sample_qc/assign_subpops.py', '--cluster', 'gt1', '--files=gs://hail-common/builds/devel/jars/hail-devel-38dbf156b630-Spark-2.2.0.jar', '--py-files=",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-384671627
https://github.com/hail-is/hail/issues/3446#issuecomment-384671627:1003,Safety,abort,aborted,1003,"ce for Amanda:; ```; Traceback (most recent call last):; File ""/tmp/3c5f402fed564ccd85257c0919d4bffb/assign_subpops.py"", line 157, in <module>; main(args); File ""/tmp/3c5f402fed564ccd85257c0919d4bffb/assign_subpops.py"", line 98, in main; pca_mt = hl.ld_prune(pca_mt, r2=0.1, n_cores=args.num_cores); File ""<decorator-gen-788>"", line 2, in ld_prune; File ""/tmp/3c5f402fed564ccd85257c0919d4bffb/hail-devel-38dbf156b630.zip/hail/typecheck/check.py"", line 490, in _typecheck; File ""/tmp/3c5f402fed564ccd85257c0919d4bffb/hail-devel-38dbf156b630.zip/hail/methods/statgen.py"", line 2918, in ld_prune; File ""/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/tmp/3c5f402fed564ccd85257c0919d4bffb/hail-devel-38dbf156b630.zip/hail/utils/java.py"", line 196, in deco; hail.utils.java.FatalError: ClassCastException: is.hail.codegen.generated.C14 cannot be cast to is.hail.asm4s.AsmFunction2. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 530 in stage 9.0 failed 20 times, most recent failure: Lost task 530.19 in stage 9.0 (TID 19101, gt1-w-78.c.broad-mpg-gnomad.internal, executor 199): java.lang.ClassCastException: is.hail.codegen.generated.C14 cannot be cast to is.hail.asm4s.AsmFunction2; 	at is.hail.io.CompiledPackDecoder.readRegionValue(RowStore.scala:643); 	at is.hail.rvd.RVD$$anonfun$7$$anonfun$apply$8$$anonfun$apply$9$$anonfun$apply$10.apply(RVD.scala:222); 	at is.hail.rvd.RVD$$anonfun$7$$anonfun$apply$8$$anonfun$apply$9$$anonfun$apply$10.apply(RVD.scala:221); 	at is.hail.utils.package$.using(package.scala:577); 	at is.hail.rvd.RVD$$anonfun$7$$anonfun$apply$8$$anonfun$apply$9.apply(RVD.scala:221); 	at is.hail.rvd.RVD$$anonfun$7$$anonfun$apply$8$$anonfun$apply$9.apply(RVD.scala:220); 	at is.hail.utils.package$.using(package.scala:577); 	at is.hail.rvd.RVD$$anonfun$7$$anonfun$apply$8.apply(RVD.scala:220); 	at is.hail.rvd.RVD$$anonfun$7$$anonfun$apply$8.apply(RVD.scala:218); 	at scala.collection.I",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-384671627
https://github.com/hail-is/hail/issues/3446#issuecomment-384671627:3129,Safety,abort,abortStage,3129,; 	at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1795); 	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1158); 	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1158); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGSche,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-384671627
https://github.com/hail-is/hail/issues/3446#issuecomment-384671627:3227,Safety,abort,abortStage,3227,$$anonfun$count$1.apply(RDD.scala:1158); 	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1158); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.ap,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-384671627
https://github.com/hail-is/hail/issues/3446#issuecomment-384671627:3472,Safety,abort,abortStage,3472,xt.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2029); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2050); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-384671627
https://github.com/hail-is/hail/issues/3446#issuecomment-384671627:8775,Testability,log,log-levels,8775,"nJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Hail version: devel-e6de08e; Error summary: ClassCastException: is.hail.codegen.generated.C14 cannot be cast to is.hail.asm4s.AsmFunction2; ERROR: (gcloud.dataproc.jobs.submit.pyspark) Job [3c5f402fed564ccd85257c0919d4bffb] entered state [ERROR] while waiting for [DONE].; Traceback (most recent call last):; File ""pyhail.py"", line 128, in <module>; main(args, pass_through_args); File ""pyhail.py"", line 109, in main; subprocess.check_output(job); File ""/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/subprocess.py"", line 573, in check_output; raise CalledProcessError(retcode, cmd, output=output); subprocess.CalledProcessError: Command '['gcloud', 'dataproc', 'jobs', 'submit', 'pyspark', '/Users/gtiao/gnomad_qc/hail/sample_qc/assign_subpops.py', '--cluster', 'gt1', '--files=gs://hail-common/builds/devel/jars/hail-devel-38dbf156b630-Spark-2.2.0.jar', '--py-files=gs://hail-common/builds/devel/python/hail-devel-38dbf156b630.zip,/var/folders/rn/t2xcx1ps4h96txll46qkkfsj2q8bnl/T/pyscripts_fYVAte.zip', '--properties=spark.executor.extraClassPath=./hail-devel-38dbf156b630-Spark-2.2.0.jar,spark.driver.extraClassPath=./hail-devel-38dbf156b630-Spark-2.2.0.jar,spark.files=./hail-devel-38dbf156b630-Spark-2.2.0.jar,spark.submit.pyFiles=./gs://hail-common/builds/devel/python/hail-devel-38dbf156b630.zip', '--driver-log-levels', 'root=FATAL,is.hail=INFO', '--', '--population', 'eur', '--overwrite']' returned non-zero exit status 1; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-384671627
https://github.com/hail-is/hail/issues/3446#issuecomment-384672067:888,Testability,log,logger,888,"And the block it's failing on:. ```; if not args.skip_filtering:; pruned_mt = hl.read_matrix_table(qc_mt_path('joint', ld_pruned=True)); exome_project_table = hl.read_table(qc_ht_path('exomes', 'hard_filters')).select('data_type', 's', 'project_id'); genome_project_table = hl.read_table(qc_ht_path('genomes', 'hard_filters')).select('data_type', 's', 'project_id'); project_table = exome_project_table.union(genome_project_table); exome_pop_table = hl.read_table(qc_ht_path('exomes', 'pop_platform')).select('data_type', 's', 'pop'); genome_pop_table = hl.read_table(qc_ht_path('genomes', 'pop_platform')).select('data_type', 's', 'pop'); pop_table = exome_pop_table.union(genome_pop_table); pop_table = pop_table.annotate(project_id=project_table[pop_table.key].project_id); pruned_mt = pruned_mt.annotate_cols(meta=pop_table[pruned_mt.col_key]); variants, samples = pruned_mt.count(); logger.info(f'{samples} samples, {variants} variants found in original joint MT'). if args.population == 'all':; sample_criteria = True; elif args.population == 'eur':; sample_criteria = (pruned_mt.meta.pop == ""nfe"") | (pruned_mt.meta.pop == ""fin""); else:; sample_criteria = pruned_mt.meta.pop == args.population. pruned_mt = pruned_mt.filter_cols(sample_criteria); variants, samples = pruned_mt.count(); logger.info(f'{samples} samples, {variants} variants found in {args.population} in joint MT'). pca_mt, related_mt = split_mt_by_relatedness(pruned_mt). pca_mt = pca_mt.filter_rows((hl.agg.mean(pca_mt.GT.n_alt_alleles()) / 2 > 0.001) &; (hl.agg.fraction(hl.is_defined(pca_mt.GT)) > 0.999)); pca_mt = hl.ld_prune(pca_mt, r2=0.1, n_cores=args.num_cores); related_mt = related_mt.filter_rows(hl.is_defined(pca_mt[related_mt.row_key, :])); pca_mt.write(f""{qc_temp_data_prefix('joint')}.{args.population}.unrelated.filtered.mt"", args.overwrite); related_mt.write(f""{qc_temp_data_prefix('joint')}.{args.population}.related.filtered.mt"", args.overwrite). ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-384672067
https://github.com/hail-is/hail/issues/3446#issuecomment-384672067:1293,Testability,log,logger,1293,"And the block it's failing on:. ```; if not args.skip_filtering:; pruned_mt = hl.read_matrix_table(qc_mt_path('joint', ld_pruned=True)); exome_project_table = hl.read_table(qc_ht_path('exomes', 'hard_filters')).select('data_type', 's', 'project_id'); genome_project_table = hl.read_table(qc_ht_path('genomes', 'hard_filters')).select('data_type', 's', 'project_id'); project_table = exome_project_table.union(genome_project_table); exome_pop_table = hl.read_table(qc_ht_path('exomes', 'pop_platform')).select('data_type', 's', 'pop'); genome_pop_table = hl.read_table(qc_ht_path('genomes', 'pop_platform')).select('data_type', 's', 'pop'); pop_table = exome_pop_table.union(genome_pop_table); pop_table = pop_table.annotate(project_id=project_table[pop_table.key].project_id); pruned_mt = pruned_mt.annotate_cols(meta=pop_table[pruned_mt.col_key]); variants, samples = pruned_mt.count(); logger.info(f'{samples} samples, {variants} variants found in original joint MT'). if args.population == 'all':; sample_criteria = True; elif args.population == 'eur':; sample_criteria = (pruned_mt.meta.pop == ""nfe"") | (pruned_mt.meta.pop == ""fin""); else:; sample_criteria = pruned_mt.meta.pop == args.population. pruned_mt = pruned_mt.filter_cols(sample_criteria); variants, samples = pruned_mt.count(); logger.info(f'{samples} samples, {variants} variants found in {args.population} in joint MT'). pca_mt, related_mt = split_mt_by_relatedness(pruned_mt). pca_mt = pca_mt.filter_rows((hl.agg.mean(pca_mt.GT.n_alt_alleles()) / 2 > 0.001) &; (hl.agg.fraction(hl.is_defined(pca_mt.GT)) > 0.999)); pca_mt = hl.ld_prune(pca_mt, r2=0.1, n_cores=args.num_cores); related_mt = related_mt.filter_rows(hl.is_defined(pca_mt[related_mt.row_key, :])); pca_mt.write(f""{qc_temp_data_prefix('joint')}.{args.population}.unrelated.filtered.mt"", args.overwrite); related_mt.write(f""{qc_temp_data_prefix('joint')}.{args.population}.related.filtered.mt"", args.overwrite). ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-384672067
https://github.com/hail-is/hail/issues/3446#issuecomment-384674539:46,Deployability,pipeline,pipeline,46,AFAIK there are no filter_entries in @gtiao's pipeline,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-384674539
https://github.com/hail-is/hail/issues/3446#issuecomment-385847410:1086,Availability,failure,failure,1086,"on-autosomes for `concordance`. Importing two VCFs, splitting multi, and `describe()`, `count()`, and `_force_count_rows()` all behave as expected. ```; import hail as hl. giab_gs_path = 'gs://xxxxxxxx'; giab_ds = hl.import_vcf(giab_gs_path, reference_genome='GRCh38'); giab_sm = hl.SplitMulti(giab_ds); giab_ds = giab_sm.result(); giab_ds.describe(); gaib_ds.count(); gaib_ds._force_count_rows(); # all good. sent_gs_path = 'gs://xxxxxxxxxxx'; sent_ds = hl.import_vcf(sent_gs_path, reference_genome='GRCh38'); sent_sm = hl.SplitMulti(sent_ds); sent_ds = sent_sm.result(); sent_ds.describe(); sent_ds.count(); sent_ds._force_count_rows(); # all good. # then this gives the stack trace below. giab_22_ds = hl.filter_intervals(giab_ds, [hl.parse_locus_interval('chr22', reference_genome='GRCh38')]); ```. Stack trace:. ```; FatalError: ClassCastException: is.hail.codegen.generated.C29 cannot be cast to is.hail.asm4s.AsmFunction5. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 19.0 failed 20 times, most recent failure: Lost task 0.19 in stage 19.0 (TID 312, gilson-validation-test-2-w-4.c.perfect-atrium-179917.internal, executor 2): java.lang.ClassCastException: is.hail.codegen.generated.C29 cannot be cast to is.hail.asm4s.AsmFunction5; 	at is.hail.expr.TableMapRows$$anonfun$execute$5.apply(Relational.scala:1641); 	at is.hail.expr.TableMapRows$$anonfun$execute$5.apply(Relational.scala:1637); 	at is.hail.sparkextras.ContextRDD$$anonfun$mapPartitions$1.apply(ContextRDD.scala:151); 	at is.hail.sparkextras.ContextRDD$$anonfun$mapPartitions$1.apply(ContextRDD.scala:151); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$19.apply(ContextRDD.scala:280); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$19.apply(ContextRDD.scala:280); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$19$$anonfun$apply$20.apply(ContextRDD.scala:280); 	at is.hail.sparkextras.Con",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-385847410
https://github.com/hail-is/hail/issues/3446#issuecomment-385847410:1145,Availability,failure,failure,1145," multi, and `describe()`, `count()`, and `_force_count_rows()` all behave as expected. ```; import hail as hl. giab_gs_path = 'gs://xxxxxxxx'; giab_ds = hl.import_vcf(giab_gs_path, reference_genome='GRCh38'); giab_sm = hl.SplitMulti(giab_ds); giab_ds = giab_sm.result(); giab_ds.describe(); gaib_ds.count(); gaib_ds._force_count_rows(); # all good. sent_gs_path = 'gs://xxxxxxxxxxx'; sent_ds = hl.import_vcf(sent_gs_path, reference_genome='GRCh38'); sent_sm = hl.SplitMulti(sent_ds); sent_ds = sent_sm.result(); sent_ds.describe(); sent_ds.count(); sent_ds._force_count_rows(); # all good. # then this gives the stack trace below. giab_22_ds = hl.filter_intervals(giab_ds, [hl.parse_locus_interval('chr22', reference_genome='GRCh38')]); ```. Stack trace:. ```; FatalError: ClassCastException: is.hail.codegen.generated.C29 cannot be cast to is.hail.asm4s.AsmFunction5. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 19.0 failed 20 times, most recent failure: Lost task 0.19 in stage 19.0 (TID 312, gilson-validation-test-2-w-4.c.perfect-atrium-179917.internal, executor 2): java.lang.ClassCastException: is.hail.codegen.generated.C29 cannot be cast to is.hail.asm4s.AsmFunction5; 	at is.hail.expr.TableMapRows$$anonfun$execute$5.apply(Relational.scala:1641); 	at is.hail.expr.TableMapRows$$anonfun$execute$5.apply(Relational.scala:1637); 	at is.hail.sparkextras.ContextRDD$$anonfun$mapPartitions$1.apply(ContextRDD.scala:151); 	at is.hail.sparkextras.ContextRDD$$anonfun$mapPartitions$1.apply(ContextRDD.scala:151); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$19.apply(ContextRDD.scala:280); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$19.apply(ContextRDD.scala:280); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$19$$anonfun$apply$20.apply(ContextRDD.scala:280); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$19$$anonfun",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-385847410
https://github.com/hail-is/hail/issues/3446#issuecomment-385847410:9561,Availability,Error,Error,9561,ly$20.apply(ContextRDD.scala:280); 	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); 	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); 	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); 	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); 	at scala.collection.AbstractIterator.to(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); 	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); 	at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Hail version: devel-76c42fe; Error summary: ClassCastException: is.hail.codegen.generated.C29 cannot be cast to is.hail.asm4s.AsmFunction5; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-385847410
https://github.com/hail-is/hail/issues/3446#issuecomment-385847410:3605,Energy Efficiency,schedul,scheduler,3605,ic.Growable$class.$plus$plus$eq(Growable.scala:59); 	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); 	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); 	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); 	at scala.collection.AbstractIterator.to(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); 	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); 	at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.sp,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-385847410
https://github.com/hail-is/hail/issues/3446#issuecomment-385847410:3677,Energy Efficiency,schedul,scheduler,3677,.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); 	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); 	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); 	at scala.collection.AbstractIterator.to(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); 	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); 	at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGSched,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-385847410
https://github.com/hail-is/hail/issues/3446#issuecomment-385847410:4042,Energy Efficiency,schedul,scheduler,4042,ollection.AbstractIterator.toBuffer(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); 	at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apa,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-385847410
https://github.com/hail-is/hail/issues/3446#issuecomment-385847410:4082,Energy Efficiency,schedul,scheduler,4082,at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); 	at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-385847410
https://github.com/hail-is/hail/issues/3446#issuecomment-385847410:4181,Energy Efficiency,schedul,scheduler,4181,t scala.collection.AbstractIterator.toArray(Iterator.scala:1336); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); 	at org.apache.spark.scheduler.DAGSchedulerEventProces,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-385847410
https://github.com/hail-is/hail/issues/3446#issuecomment-385847410:4279,Energy Efficiency,schedul,scheduler,4279,onfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoo,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-385847410
https://github.com/hail-is/hail/issues/3446#issuecomment-385847410:4533,Energy Efficiency,schedul,scheduler,4533,nfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2029); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2050); 	at org.apache.spark.SparkConte,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-385847410
https://github.com/hail-is/hail/issues/3446#issuecomment-385847410:4614,Energy Efficiency,schedul,scheduler,4614,ltTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2029); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2050); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2069); 	at org.apache.spark.SparkContext.runJob(Spar,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-385847410
https://github.com/hail-is/hail/issues/3446#issuecomment-385847410:4720,Energy Efficiency,schedul,scheduler,4720,he.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2029); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2050); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2069); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2094); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:936); 	at org.apache,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-385847410
https://github.com/hail-is/hail/issues/3446#issuecomment-385847410:4870,Energy Efficiency,schedul,scheduler,4870,t java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2029); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2050); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2069); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2094); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:936); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:11,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-385847410
https://github.com/hail-is/hail/issues/3446#issuecomment-385847410:4959,Energy Efficiency,schedul,scheduler,4959,va.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2029); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2050); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2069); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2094); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:936); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); 	at org.apache.spark.rdd.RDD.c,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-385847410
https://github.com/hail-is/hail/issues/3446#issuecomment-385847410:5057,Energy Efficiency,schedul,scheduler,5057,er.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2029); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2050); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2069); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2094); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:936); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); 	at org.apache.spark.rdd.RDD.collect(RDD.scala:935); 	at is.hail.table.Table.collect(Table.scala:841); 	at is.hail.table.Table.c,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-385847410
https://github.com/hail-is/hail/issues/3446#issuecomment-385847410:5153,Energy Efficiency,schedul,scheduler,5153,; 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2029); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2050); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2069); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2094); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:936); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); 	at org.apache.spark.rdd.RDD.collect(RDD.scala:935); 	at is.hail.table.Table.collect(Table.scala:841); 	at is.hail.table.Table.collectJSON(Table.scala:844); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	a,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-385847410
https://github.com/hail-is/hail/issues/3446#issuecomment-385847410:5318,Energy Efficiency,schedul,scheduler,5318,.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2029); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2050); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2069); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2094); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:936); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); 	at org.apache.spark.rdd.RDD.collect(RDD.scala:935); 	at is.hail.table.Table.collect(Table.scala:841); 	at is.hail.table.Table.collectJSON(Table.scala:844); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.jav,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-385847410
https://github.com/hail-is/hail/issues/3446#issuecomment-385847410:9136,Energy Efficiency,schedul,scheduler,9136,ly$20.apply(ContextRDD.scala:280); 	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); 	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); 	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); 	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); 	at scala.collection.AbstractIterator.to(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); 	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); 	at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Hail version: devel-76c42fe; Error summary: ClassCastException: is.hail.codegen.generated.C29 cannot be cast to is.hail.asm4s.AsmFunction5; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-385847410
https://github.com/hail-is/hail/issues/3446#issuecomment-385847410:9208,Energy Efficiency,schedul,scheduler,9208,ly$20.apply(ContextRDD.scala:280); 	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); 	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); 	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); 	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); 	at scala.collection.AbstractIterator.to(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); 	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); 	at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Hail version: devel-76c42fe; Error summary: ClassCastException: is.hail.codegen.generated.C29 cannot be cast to is.hail.asm4s.AsmFunction5; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-385847410
https://github.com/hail-is/hail/issues/3446#issuecomment-385847410:3802,Performance,concurren,concurrent,3802,.scala:48); 	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); 	at scala.collection.AbstractIterator.to(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); 	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); 	at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-385847410
https://github.com/hail-is/hail/issues/3446#issuecomment-385847410:3887,Performance,concurren,concurrent,3887, 	at scala.collection.AbstractIterator.to(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); 	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); 	at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-385847410
https://github.com/hail-is/hail/issues/3446#issuecomment-385847410:9333,Performance,concurren,concurrent,9333,ly$20.apply(ContextRDD.scala:280); 	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); 	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); 	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); 	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); 	at scala.collection.AbstractIterator.to(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); 	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); 	at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Hail version: devel-76c42fe; Error summary: ClassCastException: is.hail.codegen.generated.C29 cannot be cast to is.hail.asm4s.AsmFunction5; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-385847410
https://github.com/hail-is/hail/issues/3446#issuecomment-385847410:9418,Performance,concurren,concurrent,9418,ly$20.apply(ContextRDD.scala:280); 	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); 	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); 	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); 	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); 	at scala.collection.AbstractIterator.to(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); 	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); 	at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Hail version: devel-76c42fe; Error summary: ClassCastException: is.hail.codegen.generated.C29 cannot be cast to is.hail.asm4s.AsmFunction5; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-385847410
https://github.com/hail-is/hail/issues/3446#issuecomment-385847410:1065,Safety,abort,aborted,1065,"on-autosomes for `concordance`. Importing two VCFs, splitting multi, and `describe()`, `count()`, and `_force_count_rows()` all behave as expected. ```; import hail as hl. giab_gs_path = 'gs://xxxxxxxx'; giab_ds = hl.import_vcf(giab_gs_path, reference_genome='GRCh38'); giab_sm = hl.SplitMulti(giab_ds); giab_ds = giab_sm.result(); giab_ds.describe(); gaib_ds.count(); gaib_ds._force_count_rows(); # all good. sent_gs_path = 'gs://xxxxxxxxxxx'; sent_ds = hl.import_vcf(sent_gs_path, reference_genome='GRCh38'); sent_sm = hl.SplitMulti(sent_ds); sent_ds = sent_sm.result(); sent_ds.describe(); sent_ds.count(); sent_ds._force_count_rows(); # all good. # then this gives the stack trace below. giab_22_ds = hl.filter_intervals(giab_ds, [hl.parse_locus_interval('chr22', reference_genome='GRCh38')]); ```. Stack trace:. ```; FatalError: ClassCastException: is.hail.codegen.generated.C29 cannot be cast to is.hail.asm4s.AsmFunction5. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 19.0 failed 20 times, most recent failure: Lost task 0.19 in stage 19.0 (TID 312, gilson-validation-test-2-w-4.c.perfect-atrium-179917.internal, executor 2): java.lang.ClassCastException: is.hail.codegen.generated.C29 cannot be cast to is.hail.asm4s.AsmFunction5; 	at is.hail.expr.TableMapRows$$anonfun$execute$5.apply(Relational.scala:1641); 	at is.hail.expr.TableMapRows$$anonfun$execute$5.apply(Relational.scala:1637); 	at is.hail.sparkextras.ContextRDD$$anonfun$mapPartitions$1.apply(ContextRDD.scala:151); 	at is.hail.sparkextras.ContextRDD$$anonfun$mapPartitions$1.apply(ContextRDD.scala:151); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$19.apply(ContextRDD.scala:280); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$19.apply(ContextRDD.scala:280); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$19$$anonfun$apply$20.apply(ContextRDD.scala:280); 	at is.hail.sparkextras.Con",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-385847410
https://github.com/hail-is/hail/issues/3446#issuecomment-385847410:4213,Safety,abort,abortStage,4213,tractIterator.toArray(Iterator.scala:1336); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGSche,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-385847410
https://github.com/hail-is/hail/issues/3446#issuecomment-385847410:4311,Safety,abort,abortStage,4311,un$13.apply(RDD.scala:936); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.ap,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-385847410
https://github.com/hail-is/hail/issues/3446#issuecomment-385847410:4556,Safety,abort,abortStage,4556,xt.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2029); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2050); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-385847410
https://github.com/hail-is/hail/issues/3446#issuecomment-385847410:1200,Security,validat,validation-test-,1200,"` all behave as expected. ```; import hail as hl. giab_gs_path = 'gs://xxxxxxxx'; giab_ds = hl.import_vcf(giab_gs_path, reference_genome='GRCh38'); giab_sm = hl.SplitMulti(giab_ds); giab_ds = giab_sm.result(); giab_ds.describe(); gaib_ds.count(); gaib_ds._force_count_rows(); # all good. sent_gs_path = 'gs://xxxxxxxxxxx'; sent_ds = hl.import_vcf(sent_gs_path, reference_genome='GRCh38'); sent_sm = hl.SplitMulti(sent_ds); sent_ds = sent_sm.result(); sent_ds.describe(); sent_ds.count(); sent_ds._force_count_rows(); # all good. # then this gives the stack trace below. giab_22_ds = hl.filter_intervals(giab_ds, [hl.parse_locus_interval('chr22', reference_genome='GRCh38')]); ```. Stack trace:. ```; FatalError: ClassCastException: is.hail.codegen.generated.C29 cannot be cast to is.hail.asm4s.AsmFunction5. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 19.0 failed 20 times, most recent failure: Lost task 0.19 in stage 19.0 (TID 312, gilson-validation-test-2-w-4.c.perfect-atrium-179917.internal, executor 2): java.lang.ClassCastException: is.hail.codegen.generated.C29 cannot be cast to is.hail.asm4s.AsmFunction5; 	at is.hail.expr.TableMapRows$$anonfun$execute$5.apply(Relational.scala:1641); 	at is.hail.expr.TableMapRows$$anonfun$execute$5.apply(Relational.scala:1637); 	at is.hail.sparkextras.ContextRDD$$anonfun$mapPartitions$1.apply(ContextRDD.scala:151); 	at is.hail.sparkextras.ContextRDD$$anonfun$mapPartitions$1.apply(ContextRDD.scala:151); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$19.apply(ContextRDD.scala:280); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$19.apply(ContextRDD.scala:280); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$19$$anonfun$apply$20.apply(ContextRDD.scala:280); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$19$$anonfun$apply$20.apply(ContextRDD.scala:280); 	at scala.collection.It",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-385847410
https://github.com/hail-is/hail/issues/3446#issuecomment-385847410:1211,Testability,test,test-,1211,"` all behave as expected. ```; import hail as hl. giab_gs_path = 'gs://xxxxxxxx'; giab_ds = hl.import_vcf(giab_gs_path, reference_genome='GRCh38'); giab_sm = hl.SplitMulti(giab_ds); giab_ds = giab_sm.result(); giab_ds.describe(); gaib_ds.count(); gaib_ds._force_count_rows(); # all good. sent_gs_path = 'gs://xxxxxxxxxxx'; sent_ds = hl.import_vcf(sent_gs_path, reference_genome='GRCh38'); sent_sm = hl.SplitMulti(sent_ds); sent_ds = sent_sm.result(); sent_ds.describe(); sent_ds.count(); sent_ds._force_count_rows(); # all good. # then this gives the stack trace below. giab_22_ds = hl.filter_intervals(giab_ds, [hl.parse_locus_interval('chr22', reference_genome='GRCh38')]); ```. Stack trace:. ```; FatalError: ClassCastException: is.hail.codegen.generated.C29 cannot be cast to is.hail.asm4s.AsmFunction5. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 19.0 failed 20 times, most recent failure: Lost task 0.19 in stage 19.0 (TID 312, gilson-validation-test-2-w-4.c.perfect-atrium-179917.internal, executor 2): java.lang.ClassCastException: is.hail.codegen.generated.C29 cannot be cast to is.hail.asm4s.AsmFunction5; 	at is.hail.expr.TableMapRows$$anonfun$execute$5.apply(Relational.scala:1641); 	at is.hail.expr.TableMapRows$$anonfun$execute$5.apply(Relational.scala:1637); 	at is.hail.sparkextras.ContextRDD$$anonfun$mapPartitions$1.apply(ContextRDD.scala:151); 	at is.hail.sparkextras.ContextRDD$$anonfun$mapPartitions$1.apply(ContextRDD.scala:151); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$19.apply(ContextRDD.scala:280); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$19.apply(ContextRDD.scala:280); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$19$$anonfun$apply$20.apply(ContextRDD.scala:280); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$19$$anonfun$apply$20.apply(ContextRDD.scala:280); 	at scala.collection.It",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-385847410
https://github.com/hail-is/hail/issues/3448#issuecomment-385763925:56,Energy Efficiency,allocate,allocates,56,"added something that skips the field parsing, but still allocates an entry array.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3448#issuecomment-385763925
https://github.com/hail-is/hail/pull/3450#issuecomment-385005092:55,Testability,test,tests,55,Close for now? Doesn't make sense to merge if it makes tests slower.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3450#issuecomment-385005092
https://github.com/hail-is/hail/pull/3450#issuecomment-385008102:38,Performance,cache,cache,38,"Timing is not clear, gonna try an LRU cache. I will close until I have time to work on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3450#issuecomment-385008102
https://github.com/hail-is/hail/pull/3450#issuecomment-385008102:14,Usability,clear,clear,14,"Timing is not clear, gonna try an LRU cache. I will close until I have time to work on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3450#issuecomment-385008102
https://github.com/hail-is/hail/pull/3455#issuecomment-385023610:7,Testability,test,tested,7,"FYI, I tested this by hand on a small example against ES 6.2.4.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3455#issuecomment-385023610
https://github.com/hail-is/hail/issues/3463#issuecomment-385433303:86,Availability,error,error,86,"Increasing the executor memory per core to 20G/core seemed to help get by this memory error. . It would be useful to have some rule of thumbs for estimating memory requirements based on number of samples and variants. spark-submit --verbose --master yarn --deploy-mode client \; --num-executors 12\; --executor-cores 4\; --jars $JAR \; --conf spark.kryo.registrator=is.hail.kryo.HailKryoRegistrator \; --conf ""spark.driver.extraClassPath=$JAR"" \; --conf ""spark.executor.extraClassPath=$JAR"" \; --executor-memory 80G\; --driver-memory 60g\; --driver-cores 1\; --name ""$1"" \; --conf spark.yarn.executor.memoryOverhead=8000 \; --conf spark.network.timeout=600 \; --conf spark.executor.heartbeatInterval=120\",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3463#issuecomment-385433303
https://github.com/hail-is/hail/issues/3463#issuecomment-385433303:682,Availability,heartbeat,heartbeatInterval,682,"Increasing the executor memory per core to 20G/core seemed to help get by this memory error. . It would be useful to have some rule of thumbs for estimating memory requirements based on number of samples and variants. spark-submit --verbose --master yarn --deploy-mode client \; --num-executors 12\; --executor-cores 4\; --jars $JAR \; --conf spark.kryo.registrator=is.hail.kryo.HailKryoRegistrator \; --conf ""spark.driver.extraClassPath=$JAR"" \; --conf ""spark.executor.extraClassPath=$JAR"" \; --executor-memory 80G\; --driver-memory 60g\; --driver-cores 1\; --name ""$1"" \; --conf spark.yarn.executor.memoryOverhead=8000 \; --conf spark.network.timeout=600 \; --conf spark.executor.heartbeatInterval=120\",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3463#issuecomment-385433303
https://github.com/hail-is/hail/issues/3463#issuecomment-385433303:257,Deployability,deploy,deploy-mode,257,"Increasing the executor memory per core to 20G/core seemed to help get by this memory error. . It would be useful to have some rule of thumbs for estimating memory requirements based on number of samples and variants. spark-submit --verbose --master yarn --deploy-mode client \; --num-executors 12\; --executor-cores 4\; --jars $JAR \; --conf spark.kryo.registrator=is.hail.kryo.HailKryoRegistrator \; --conf ""spark.driver.extraClassPath=$JAR"" \; --conf ""spark.executor.extraClassPath=$JAR"" \; --executor-memory 80G\; --driver-memory 60g\; --driver-cores 1\; --name ""$1"" \; --conf spark.yarn.executor.memoryOverhead=8000 \; --conf spark.network.timeout=600 \; --conf spark.executor.heartbeatInterval=120\",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3463#issuecomment-385433303
https://github.com/hail-is/hail/issues/3463#issuecomment-385433303:645,Safety,timeout,timeout,645,"Increasing the executor memory per core to 20G/core seemed to help get by this memory error. . It would be useful to have some rule of thumbs for estimating memory requirements based on number of samples and variants. spark-submit --verbose --master yarn --deploy-mode client \; --num-executors 12\; --executor-cores 4\; --jars $JAR \; --conf spark.kryo.registrator=is.hail.kryo.HailKryoRegistrator \; --conf ""spark.driver.extraClassPath=$JAR"" \; --conf ""spark.executor.extraClassPath=$JAR"" \; --executor-memory 80G\; --driver-memory 60g\; --driver-cores 1\; --name ""$1"" \; --conf spark.yarn.executor.memoryOverhead=8000 \; --conf spark.network.timeout=600 \; --conf spark.executor.heartbeatInterval=120\",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3463#issuecomment-385433303
https://github.com/hail-is/hail/issues/3465#issuecomment-385281263:299,Availability,error,error,299,"Ok I just looked at the scala code, and this must have happened around the sex chromosomes when my dataset shifted to haploid (or more specifically, a mix of haploid and diploid calls for male and female). I'll write in the workaround for my own pipeline, but you might want to have a more explicit error message.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3465#issuecomment-385281263
https://github.com/hail-is/hail/issues/3465#issuecomment-385281263:246,Deployability,pipeline,pipeline,246,"Ok I just looked at the scala code, and this must have happened around the sex chromosomes when my dataset shifted to haploid (or more specifically, a mix of haploid and diploid calls for male and female). I'll write in the workaround for my own pipeline, but you might want to have a more explicit error message.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3465#issuecomment-385281263
https://github.com/hail-is/hail/issues/3465#issuecomment-385281263:305,Integrability,message,message,305,"Ok I just looked at the scala code, and this must have happened around the sex chromosomes when my dataset shifted to haploid (or more specifically, a mix of haploid and diploid calls for male and female). I'll write in the workaround for my own pipeline, but you might want to have a more explicit error message.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3465#issuecomment-385281263
https://github.com/hail-is/hail/issues/3465#issuecomment-386372161:30,Availability,error,error,30,"I'd probably suggest a better error message if possible, but if you don't want to, go ahead and close",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3465#issuecomment-386372161
https://github.com/hail-is/hail/issues/3465#issuecomment-386372161:36,Integrability,message,message,36,"I'd probably suggest a better error message if possible, but if you don't want to, go ahead and close",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3465#issuecomment-386372161
https://github.com/hail-is/hail/pull/3466#issuecomment-385812703:12,Testability,test,tests,12,Now passing tests,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3466#issuecomment-385812703
https://github.com/hail-is/hail/issues/3467#issuecomment-386413979:447,Performance,load,loading,447,"In Hail, we need to know the dataset schema statically (e.g. when run `import_vcf` before you process the data). There are two ways to do it: use the header or impute. Impute means scanning the entire dataset (it may be the very last variant has a field that appears nowhere else in the file). Even more, you need to scan all the genotypes to determine the the types since types aren't declared outside of the header. We have an impute option for loading TSVs, but not for VCFs. I agree it would be good to add. I'm going to close this in favor of this issue: https://github.com/hail-is/hail/issues/3499",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3467#issuecomment-386413979
https://github.com/hail-is/hail/pull/3477#issuecomment-385539018:60,Testability,log,log-of-breaking-changes-in-,60,"cool, put the post in this tread:; http://discuss.hail.is/t/log-of-breaking-changes-in-0-2-beta/454",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3477#issuecomment-385539018
https://github.com/hail-is/hail/pull/3477#issuecomment-386075467:70,Deployability,update,updated,70,"The handling for covariates in the top of linreg/logreg was broken. I updated, can you double-check?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3477#issuecomment-386075467
https://github.com/hail-is/hail/pull/3477#issuecomment-386075467:49,Testability,log,logreg,49,"The handling for covariates in the top of linreg/logreg was broken. I updated, can you double-check?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3477#issuecomment-386075467
https://github.com/hail-is/hail/pull/3485#issuecomment-387058400:21,Testability,test,test,21,Actually deleted the test altogether. It's an overlap with another test in aggregatorsuite,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3485#issuecomment-387058400
https://github.com/hail-is/hail/pull/3485#issuecomment-387058400:67,Testability,test,test,67,Actually deleted the test altogether. It's an overlap with another test in aggregatorsuite,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3485#issuecomment-387058400
https://github.com/hail-is/hail/issues/3486#issuecomment-386410873:28,Performance,perform,performance,28,"Then lift it is. For gnomAD performance, this is critical for @konradjk. I will think about what's involved.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3486#issuecomment-386410873
https://github.com/hail-is/hail/issues/3486#issuecomment-386411966:107,Safety,avoid,avoids,107,"We could follow the style of the rest of the IR with `CallStatsAggOp(a: IR, name: String, body: IR)` (this avoids an IR lambda). We'd still need to compile and emit the `body` and pass it as a JVM object to the aggregator.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3486#issuecomment-386411966
https://github.com/hail-is/hail/pull/3487#issuecomment-386750335:105,Availability,down,down,105,I added the MatrixRead as an input and changed range to take into account the dropRows and dropCols push down.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3487#issuecomment-386750335
https://github.com/hail-is/hail/pull/3487#issuecomment-387232397:54,Performance,optimiz,optimize,54,"Ah, right. Eventually we can remove those when we can optimize them away, but I guess we need them now",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3487#issuecomment-387232397
https://github.com/hail-is/hail/pull/3489#issuecomment-387263813:45,Integrability,interface,interface,45,Why is this a breaking change? It's the same interface as before with additional optional parameters.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3489#issuecomment-387263813
https://github.com/hail-is/hail/pull/3489#issuecomment-387349360:42,Integrability,interface,interface,42,"ah, you're totally right. Didn't read the interface diff closely enough.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3489#issuecomment-387349360
https://github.com/hail-is/hail/pull/3489#issuecomment-387722899:42,Integrability,interface,interface,42,"ah, you're totally right. Didn't read the interface diff closely enough.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3489#issuecomment-387722899
https://github.com/hail-is/hail/issues/3490#issuecomment-386639531:1271,Availability,error,error,1271,"@jjfarrell Thanks for the information! This will be very helpful as I try to tease out what the issue is here. Also, I'm sorry my initial response was curt! I was a bit tired at the time and probably shouldn't have been responding to GitHub issues . Hail's version of pc-relate does not identify an initial set of related and unrelated individuals. The R `pcrelate` implementation (the official / reference implementation by the authors of the paper) does this to identify a set of individuals on which to run the principal components analysis. It is not entirely clear to me why this is necessary, and we don't currently have a mechanism for doing so (since pc_relate _is_ our mechanism for determining related and unrelated individuals when there is population structure in the data set). If you have prior knowledge about related samples, you might try filtering to an known unrelated set and computing the scores from that set. I'm curious if that makes any difference in the results. Your invocations look very reasonable. I'll get in touch with the gnomAD team here at the broad to learn more about their experiences with pc_relate and see if I can better understand what's happening with the replicate samples. It's definitely possible there is an implementation error; however, I also want to rule out that the pc_relate model itself isn't breaking down here.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3490#issuecomment-386639531
https://github.com/hail-is/hail/issues/3490#issuecomment-386639531:1358,Availability,down,down,1358,"@jjfarrell Thanks for the information! This will be very helpful as I try to tease out what the issue is here. Also, I'm sorry my initial response was curt! I was a bit tired at the time and probably shouldn't have been responding to GitHub issues . Hail's version of pc-relate does not identify an initial set of related and unrelated individuals. The R `pcrelate` implementation (the official / reference implementation by the authors of the paper) does this to identify a set of individuals on which to run the principal components analysis. It is not entirely clear to me why this is necessary, and we don't currently have a mechanism for doing so (since pc_relate _is_ our mechanism for determining related and unrelated individuals when there is population structure in the data set). If you have prior knowledge about related samples, you might try filtering to an known unrelated set and computing the scores from that set. I'm curious if that makes any difference in the results. Your invocations look very reasonable. I'll get in touch with the gnomAD team here at the broad to learn more about their experiences with pc_relate and see if I can better understand what's happening with the replicate samples. It's definitely possible there is an implementation error; however, I also want to rule out that the pc_relate model itself isn't breaking down here.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3490#issuecomment-386639531
https://github.com/hail-is/hail/issues/3490#issuecomment-386639531:565,Usability,clear,clear,565,"@jjfarrell Thanks for the information! This will be very helpful as I try to tease out what the issue is here. Also, I'm sorry my initial response was curt! I was a bit tired at the time and probably shouldn't have been responding to GitHub issues . Hail's version of pc-relate does not identify an initial set of related and unrelated individuals. The R `pcrelate` implementation (the official / reference implementation by the authors of the paper) does this to identify a set of individuals on which to run the principal components analysis. It is not entirely clear to me why this is necessary, and we don't currently have a mechanism for doing so (since pc_relate _is_ our mechanism for determining related and unrelated individuals when there is population structure in the data set). If you have prior knowledge about related samples, you might try filtering to an known unrelated set and computing the scores from that set. I'm curious if that makes any difference in the results. Your invocations look very reasonable. I'll get in touch with the gnomAD team here at the broad to learn more about their experiences with pc_relate and see if I can better understand what's happening with the replicate samples. It's definitely possible there is an implementation error; however, I also want to rule out that the pc_relate model itself isn't breaking down here.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3490#issuecomment-386639531
https://github.com/hail-is/hail/issues/3490#issuecomment-386639531:1089,Usability,learn,learn,1089,"@jjfarrell Thanks for the information! This will be very helpful as I try to tease out what the issue is here. Also, I'm sorry my initial response was curt! I was a bit tired at the time and probably shouldn't have been responding to GitHub issues . Hail's version of pc-relate does not identify an initial set of related and unrelated individuals. The R `pcrelate` implementation (the official / reference implementation by the authors of the paper) does this to identify a set of individuals on which to run the principal components analysis. It is not entirely clear to me why this is necessary, and we don't currently have a mechanism for doing so (since pc_relate _is_ our mechanism for determining related and unrelated individuals when there is population structure in the data set). If you have prior knowledge about related samples, you might try filtering to an known unrelated set and computing the scores from that set. I'm curious if that makes any difference in the results. Your invocations look very reasonable. I'll get in touch with the gnomAD team here at the broad to learn more about their experiences with pc_relate and see if I can better understand what's happening with the replicate samples. It's definitely possible there is an implementation error; however, I also want to rule out that the pc_relate model itself isn't breaking down here.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3490#issuecomment-386639531
https://github.com/hail-is/hail/issues/3490#issuecomment-386642665:119,Deployability,pipeline,pipeline,119,This data is from 25-35x whole genome sequencing data aligned to the hg38 reference. The VCF was generated by the GATK pipeline. The vcf used to create the pruned dataset was limited to SNVs and so it did not contain any indels or multallelic sites.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3490#issuecomment-386642665
https://github.com/hail-is/hail/issues/3490#issuecomment-387091122:352,Safety,predict,predicts,352,"Hmm. Am I correctly reading from this that there are 8 of the exact same genome in the dataset?. I am feeling more confident that this is a symptom of the model. Theoretically, if a group of replicates were perfectly separated from the rest of the dataset by a PC or group of PCs, then the estimator for kinship will get zero's because the  perfectly predicts the genotype.; <img width=""825"" alt=""screen shot 2018-05-07 at 10 44 55 am"" src=""https://user-images.githubusercontent.com/106194/39707912-af6d2bac-51e3-11e8-928b-4dc8d08474b2.png"">. It seems a little odd that 8 samples out of 5000 would manage to get at least one PC to differentiate them from the rest of the dataset. However, if that _is_ happening, then it follows that PC-Relate would dramatically decrease the estimated kinship because all the shared alleles are being marked as markers of ancestral relatedness rather than familial relatedness. Basically, it would be interesting to see the _ancestral_ relatedness as well. If you plot the top 10 PCs and color the replicates a different color, are they clearly separated by any of the PCs?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3490#issuecomment-387091122
https://github.com/hail-is/hail/issues/3490#issuecomment-387091122:1072,Usability,clear,clearly,1072,"Hmm. Am I correctly reading from this that there are 8 of the exact same genome in the dataset?. I am feeling more confident that this is a symptom of the model. Theoretically, if a group of replicates were perfectly separated from the rest of the dataset by a PC or group of PCs, then the estimator for kinship will get zero's because the  perfectly predicts the genotype.; <img width=""825"" alt=""screen shot 2018-05-07 at 10 44 55 am"" src=""https://user-images.githubusercontent.com/106194/39707912-af6d2bac-51e3-11e8-928b-4dc8d08474b2.png"">. It seems a little odd that 8 samples out of 5000 would manage to get at least one PC to differentiate them from the rest of the dataset. However, if that _is_ happening, then it follows that PC-Relate would dramatically decrease the estimated kinship because all the shared alleles are being marked as markers of ancestral relatedness rather than familial relatedness. Basically, it would be interesting to see the _ancestral_ relatedness as well. If you plot the top 10 PCs and color the replicates a different color, are they clearly separated by any of the PCs?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3490#issuecomment-387091122
https://github.com/hail-is/hail/issues/3490#issuecomment-388150598:234,Availability,down,down,234,"@jjfarrell I've been working with some other Broadies that also noted unusual results in Hail's PC-Relate. In this case, we found that about a quarter of variants being used in PC-Relate had terrible HWE p-values. We're tracking this down a bit as a possible explanation for the poor performance of PC-Relate.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3490#issuecomment-388150598
https://github.com/hail-is/hail/issues/3490#issuecomment-388150598:284,Performance,perform,performance,284,"@jjfarrell I've been working with some other Broadies that also noted unusual results in Hail's PC-Relate. In this case, we found that about a quarter of variants being used in PC-Relate had terrible HWE p-values. We're tracking this down a bit as a possible explanation for the poor performance of PC-Relate.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3490#issuecomment-388150598
https://github.com/hail-is/hail/issues/3490#issuecomment-390736100:146,Usability,clear,clear,146,"@danking I have a tab delimited file of pc-air pcs to try to run with the hail pc-relate (with header--SampleId, PC1, PC2,...PC10) . But I am not clear on the format of the scores_table.scores object needed to pass to pc-relate. Is it sorted by SampleId or indexed somehow? What are the steps in Hail to create that table from a tab delimited file? . `rel = hl.pc_relate(dataset.GT, 0.01,scores_expr=scores_table[dataset.col_key].scores, min_kinship=0.1)`",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3490#issuecomment-390736100
https://github.com/hail-is/hail/issues/3490#issuecomment-390759209:329,Performance,load,load,329,"Hey @jjfarrell,. Awesome! Thanks for the continued debugging support! So the `scores_expr` argument to [`hl.methods.pc_relate`](https://hail.is/docs/devel/methods/genetics.html?highlight=pc_relate#hail.methods.pc_relate) should be a numeric array. Every row must have the same length. All the scores must be non-missing. You can load a TSV into hail with [`hl.import_table`](https://hail.is/docs/devel/methods/impex.html?highlight=import_table#hail.methods.import_table). So in your case you probably want:; ```python; import hail as hl; scores = hl.import_table('/path/to/foo.tsv', impute=True); scores = scores.key_by('SampleId'); scores = scores.transmute(scores=[scores.PC1, scores.PC2, ..., scores.PC10]); dataset = # ...; rel = hl.pc_relate(; dataset.GT,; 0.02, ; scores_expr=scores[dataset.col_key].scores,; min_kinship=0.1); ```; ---; > Is it sorted by SampleId or indexed somehow?. So, the expression `scores_table[dataset.col_key]` indexes your TSV (loaded into Hail as a Table) by the column key of your dataset (the sample id). For this expression to make sense you have to define a key on your scores_table. I did that with `.key_by('SampleId')`. Since your `col_key` is also (I assume) a sample id they will be matched up as you expect. If the sample ids were mangled or changed by one of the tools that were used to generate the TSV, you'll need to un-mangle them, which you can, of course, use Hail to do as well, using something like `scores.key_by(scores.sample_id[0:10])` to take the first ten characters.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3490#issuecomment-390759209
https://github.com/hail-is/hail/issues/3490#issuecomment-390759209:960,Performance,load,loaded,960,"Hey @jjfarrell,. Awesome! Thanks for the continued debugging support! So the `scores_expr` argument to [`hl.methods.pc_relate`](https://hail.is/docs/devel/methods/genetics.html?highlight=pc_relate#hail.methods.pc_relate) should be a numeric array. Every row must have the same length. All the scores must be non-missing. You can load a TSV into hail with [`hl.import_table`](https://hail.is/docs/devel/methods/impex.html?highlight=import_table#hail.methods.import_table). So in your case you probably want:; ```python; import hail as hl; scores = hl.import_table('/path/to/foo.tsv', impute=True); scores = scores.key_by('SampleId'); scores = scores.transmute(scores=[scores.PC1, scores.PC2, ..., scores.PC10]); dataset = # ...; rel = hl.pc_relate(; dataset.GT,; 0.02, ; scores_expr=scores[dataset.col_key].scores,; min_kinship=0.1); ```; ---; > Is it sorted by SampleId or indexed somehow?. So, the expression `scores_table[dataset.col_key]` indexes your TSV (loaded into Hail as a Table) by the column key of your dataset (the sample id). For this expression to make sense you have to define a key on your scores_table. I did that with `.key_by('SampleId')`. Since your `col_key` is also (I assume) a sample id they will be matched up as you expect. If the sample ids were mangled or changed by one of the tools that were used to generate the TSV, you'll need to un-mangle them, which you can, of course, use Hail to do as well, using something like `scores.key_by(scores.sample_id[0:10])` to take the first ten characters.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3490#issuecomment-390759209
https://github.com/hail-is/hail/issues/3490#issuecomment-391739992:439,Availability,down,down,439,"@jjfarrell Thanks for sharing that! This is really interesting information. I'm quite surprised, but the evidence is pointing to there being a PC that largely separates those 8 replicates from the entire remaining dataset (!!!). I'm personally quite surprised that 8 samples out of thousands could pull this off, but that definitely seems to be the issue, given that the PCs from PC-AiR avoid the issue. Thank you so much for hunting this down! It's very valuable information for us. ### Next Steps . So, clearly we need a solution for users that have substantial numbers of related individuals in their source dataset (especially if the pedigrees are unknown). For your _particular_ use case, I can add a blurb to the docs that recommends removing known replicates _before_ PCA and then projecting them using the loadings from PCA. A longer term solution is to simply implement PC-AiR in hail. I skimmed the implementation section of the paper earlier this week and it looks very straightforward. It seems to boil down to using the KING estimator to estimate relatedness, compute PCA on unrelated individuals, project related individuals into unrelated PC space. Finally, we can use pc_relate to improve on our original estimates of relatedness from KING. The timeline for the latter thing is kind of unclear and a bit further out given some other work I need to finish. I'll get the documentation improvement in this week. Is there anything else I can do that would have helped you avoid this issue? Is there anything else you need to resolve the issue now?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3490#issuecomment-391739992
https://github.com/hail-is/hail/issues/3490#issuecomment-391739992:1015,Availability,down,down,1015,"@jjfarrell Thanks for sharing that! This is really interesting information. I'm quite surprised, but the evidence is pointing to there being a PC that largely separates those 8 replicates from the entire remaining dataset (!!!). I'm personally quite surprised that 8 samples out of thousands could pull this off, but that definitely seems to be the issue, given that the PCs from PC-AiR avoid the issue. Thank you so much for hunting this down! It's very valuable information for us. ### Next Steps . So, clearly we need a solution for users that have substantial numbers of related individuals in their source dataset (especially if the pedigrees are unknown). For your _particular_ use case, I can add a blurb to the docs that recommends removing known replicates _before_ PCA and then projecting them using the loadings from PCA. A longer term solution is to simply implement PC-AiR in hail. I skimmed the implementation section of the paper earlier this week and it looks very straightforward. It seems to boil down to using the KING estimator to estimate relatedness, compute PCA on unrelated individuals, project related individuals into unrelated PC space. Finally, we can use pc_relate to improve on our original estimates of relatedness from KING. The timeline for the latter thing is kind of unclear and a bit further out given some other work I need to finish. I'll get the documentation improvement in this week. Is there anything else I can do that would have helped you avoid this issue? Is there anything else you need to resolve the issue now?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3490#issuecomment-391739992
https://github.com/hail-is/hail/issues/3490#issuecomment-391739992:814,Performance,load,loadings,814,"@jjfarrell Thanks for sharing that! This is really interesting information. I'm quite surprised, but the evidence is pointing to there being a PC that largely separates those 8 replicates from the entire remaining dataset (!!!). I'm personally quite surprised that 8 samples out of thousands could pull this off, but that definitely seems to be the issue, given that the PCs from PC-AiR avoid the issue. Thank you so much for hunting this down! It's very valuable information for us. ### Next Steps . So, clearly we need a solution for users that have substantial numbers of related individuals in their source dataset (especially if the pedigrees are unknown). For your _particular_ use case, I can add a blurb to the docs that recommends removing known replicates _before_ PCA and then projecting them using the loadings from PCA. A longer term solution is to simply implement PC-AiR in hail. I skimmed the implementation section of the paper earlier this week and it looks very straightforward. It seems to boil down to using the KING estimator to estimate relatedness, compute PCA on unrelated individuals, project related individuals into unrelated PC space. Finally, we can use pc_relate to improve on our original estimates of relatedness from KING. The timeline for the latter thing is kind of unclear and a bit further out given some other work I need to finish. I'll get the documentation improvement in this week. Is there anything else I can do that would have helped you avoid this issue? Is there anything else you need to resolve the issue now?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3490#issuecomment-391739992
https://github.com/hail-is/hail/issues/3490#issuecomment-391739992:387,Safety,avoid,avoid,387,"@jjfarrell Thanks for sharing that! This is really interesting information. I'm quite surprised, but the evidence is pointing to there being a PC that largely separates those 8 replicates from the entire remaining dataset (!!!). I'm personally quite surprised that 8 samples out of thousands could pull this off, but that definitely seems to be the issue, given that the PCs from PC-AiR avoid the issue. Thank you so much for hunting this down! It's very valuable information for us. ### Next Steps . So, clearly we need a solution for users that have substantial numbers of related individuals in their source dataset (especially if the pedigrees are unknown). For your _particular_ use case, I can add a blurb to the docs that recommends removing known replicates _before_ PCA and then projecting them using the loadings from PCA. A longer term solution is to simply implement PC-AiR in hail. I skimmed the implementation section of the paper earlier this week and it looks very straightforward. It seems to boil down to using the KING estimator to estimate relatedness, compute PCA on unrelated individuals, project related individuals into unrelated PC space. Finally, we can use pc_relate to improve on our original estimates of relatedness from KING. The timeline for the latter thing is kind of unclear and a bit further out given some other work I need to finish. I'll get the documentation improvement in this week. Is there anything else I can do that would have helped you avoid this issue? Is there anything else you need to resolve the issue now?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3490#issuecomment-391739992
https://github.com/hail-is/hail/issues/3490#issuecomment-391739992:1484,Safety,avoid,avoid,1484,"@jjfarrell Thanks for sharing that! This is really interesting information. I'm quite surprised, but the evidence is pointing to there being a PC that largely separates those 8 replicates from the entire remaining dataset (!!!). I'm personally quite surprised that 8 samples out of thousands could pull this off, but that definitely seems to be the issue, given that the PCs from PC-AiR avoid the issue. Thank you so much for hunting this down! It's very valuable information for us. ### Next Steps . So, clearly we need a solution for users that have substantial numbers of related individuals in their source dataset (especially if the pedigrees are unknown). For your _particular_ use case, I can add a blurb to the docs that recommends removing known replicates _before_ PCA and then projecting them using the loadings from PCA. A longer term solution is to simply implement PC-AiR in hail. I skimmed the implementation section of the paper earlier this week and it looks very straightforward. It seems to boil down to using the KING estimator to estimate relatedness, compute PCA on unrelated individuals, project related individuals into unrelated PC space. Finally, we can use pc_relate to improve on our original estimates of relatedness from KING. The timeline for the latter thing is kind of unclear and a bit further out given some other work I need to finish. I'll get the documentation improvement in this week. Is there anything else I can do that would have helped you avoid this issue? Is there anything else you need to resolve the issue now?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3490#issuecomment-391739992
https://github.com/hail-is/hail/issues/3490#issuecomment-391739992:505,Usability,clear,clearly,505,"@jjfarrell Thanks for sharing that! This is really interesting information. I'm quite surprised, but the evidence is pointing to there being a PC that largely separates those 8 replicates from the entire remaining dataset (!!!). I'm personally quite surprised that 8 samples out of thousands could pull this off, but that definitely seems to be the issue, given that the PCs from PC-AiR avoid the issue. Thank you so much for hunting this down! It's very valuable information for us. ### Next Steps . So, clearly we need a solution for users that have substantial numbers of related individuals in their source dataset (especially if the pedigrees are unknown). For your _particular_ use case, I can add a blurb to the docs that recommends removing known replicates _before_ PCA and then projecting them using the loadings from PCA. A longer term solution is to simply implement PC-AiR in hail. I skimmed the implementation section of the paper earlier this week and it looks very straightforward. It seems to boil down to using the KING estimator to estimate relatedness, compute PCA on unrelated individuals, project related individuals into unrelated PC space. Finally, we can use pc_relate to improve on our original estimates of relatedness from KING. The timeline for the latter thing is kind of unclear and a bit further out given some other work I need to finish. I'll get the documentation improvement in this week. Is there anything else I can do that would have helped you avoid this issue? Is there anything else you need to resolve the issue now?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3490#issuecomment-391739992
https://github.com/hail-is/hail/issues/3490#issuecomment-391739992:862,Usability,simpl,simply,862,"@jjfarrell Thanks for sharing that! This is really interesting information. I'm quite surprised, but the evidence is pointing to there being a PC that largely separates those 8 replicates from the entire remaining dataset (!!!). I'm personally quite surprised that 8 samples out of thousands could pull this off, but that definitely seems to be the issue, given that the PCs from PC-AiR avoid the issue. Thank you so much for hunting this down! It's very valuable information for us. ### Next Steps . So, clearly we need a solution for users that have substantial numbers of related individuals in their source dataset (especially if the pedigrees are unknown). For your _particular_ use case, I can add a blurb to the docs that recommends removing known replicates _before_ PCA and then projecting them using the loadings from PCA. A longer term solution is to simply implement PC-AiR in hail. I skimmed the implementation section of the paper earlier this week and it looks very straightforward. It seems to boil down to using the KING estimator to estimate relatedness, compute PCA on unrelated individuals, project related individuals into unrelated PC space. Finally, we can use pc_relate to improve on our original estimates of relatedness from KING. The timeline for the latter thing is kind of unclear and a bit further out given some other work I need to finish. I'll get the documentation improvement in this week. Is there anything else I can do that would have helped you avoid this issue? Is there anything else you need to resolve the issue now?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3490#issuecomment-391739992
https://github.com/hail-is/hail/issues/3490#issuecomment-391760451:864,Testability,test,test,864,"@danking danking There is a lot of things going on in this dataset that makes PCs challenging. This has 3 replicate related samples (mother and 2 children). It also contains EA, AA and Dominicans. So there is lots of recent admixture. Among the 5000 samples, there are 800 related samples. We ran eigenstrat with the 5000 samples + 2500 1000 genomes samples and those PCs look good. . So I am not sure it is the replicates that are the underlying cause. It may simply be the lack of the 1000 Genomes samples in the dataset for the PCs. I am will try adding the 1000 genomes samples to see if that fixes things. If that works, the docs would just need to recommend merging in the 1000 genomes data. I will get back to you on those results. That would be great to implement PC-Air in Hail to help streamline the processing of this type of dataset! I will be glad to test it out.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3490#issuecomment-391760451
https://github.com/hail-is/hail/issues/3490#issuecomment-391760451:461,Usability,simpl,simply,461,"@danking danking There is a lot of things going on in this dataset that makes PCs challenging. This has 3 replicate related samples (mother and 2 children). It also contains EA, AA and Dominicans. So there is lots of recent admixture. Among the 5000 samples, there are 800 related samples. We ran eigenstrat with the 5000 samples + 2500 1000 genomes samples and those PCs look good. . So I am not sure it is the replicates that are the underlying cause. It may simply be the lack of the 1000 Genomes samples in the dataset for the PCs. I am will try adding the 1000 genomes samples to see if that fixes things. If that works, the docs would just need to recommend merging in the 1000 genomes data. I will get back to you on those results. That would be great to implement PC-Air in Hail to help streamline the processing of this type of dataset! I will be glad to test it out.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3490#issuecomment-391760451
https://github.com/hail-is/hail/issues/3490#issuecomment-1182425769:67,Deployability,update,updates,67,Hi! Found this long closed thread but had a related question - any updates on implementing PC-Air in Hail in the intervening years by any chance?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3490#issuecomment-1182425769
https://github.com/hail-is/hail/issues/3490#issuecomment-1284296019:183,Performance,load,loadings,183,You will use the principal components space that you learned from the unrelated samples. You can project the withheld samples by summing over all variants and multiplying the variant loadings by the withheld samples' GTs.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3490#issuecomment-1284296019
https://github.com/hail-is/hail/issues/3490#issuecomment-1284296019:53,Usability,learn,learned,53,You will use the principal components space that you learned from the unrelated samples. You can project the withheld samples by summing over all variants and multiplying the variant loadings by the withheld samples' GTs.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3490#issuecomment-1284296019
https://github.com/hail-is/hail/issues/3490#issuecomment-1298367803:156,Performance,load,loadings,156,"Thanks !! Can you please let us know about how to accomplish ""You can project the withheld samples by summing over all variants and multiplying the variant loadings by the withheld samples' GTs."" in Hail?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3490#issuecomment-1298367803
https://github.com/hail-is/hail/issues/3490#issuecomment-1298562226:309,Performance,load,loadings,309,Try using [`hl.experimental.pc_project`](https://hail.is/docs/0.2/experimental/index.html#hail.experimental.pc_project). You can also compute this yourself as follows. Note this assumes biallelic SNPs.; ```python3; # the loadings_table is the third return value from hwe_normalized_pca; mt = mt.annotate_rows(loadings = loadings_table[mt.row_key]); mt = mt.filter_rows(hl.is_defined(mt.loadings)); mt = hl.variant_qc(mt); n_variants = mt.count_rows(); gt_norm = (mt.GT.n_alt_alleles() - 2 * mt.AF[1]) / hl.sqrt(n_variants * 2 * mt.AF[1] * (1 - mt.AF[1])); mt = mt.annotate_cols(scores=hl.agg.array_sum(mt.loadings * gt_norm)).cols(); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3490#issuecomment-1298562226
https://github.com/hail-is/hail/issues/3490#issuecomment-1298562226:386,Performance,load,loadings,386,Try using [`hl.experimental.pc_project`](https://hail.is/docs/0.2/experimental/index.html#hail.experimental.pc_project). You can also compute this yourself as follows. Note this assumes biallelic SNPs.; ```python3; # the loadings_table is the third return value from hwe_normalized_pca; mt = mt.annotate_rows(loadings = loadings_table[mt.row_key]); mt = mt.filter_rows(hl.is_defined(mt.loadings)); mt = hl.variant_qc(mt); n_variants = mt.count_rows(); gt_norm = (mt.GT.n_alt_alleles() - 2 * mt.AF[1]) / hl.sqrt(n_variants * 2 * mt.AF[1] * (1 - mt.AF[1])); mt = mt.annotate_cols(scores=hl.agg.array_sum(mt.loadings * gt_norm)).cols(); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3490#issuecomment-1298562226
https://github.com/hail-is/hail/issues/3490#issuecomment-1298562226:605,Performance,load,loadings,605,Try using [`hl.experimental.pc_project`](https://hail.is/docs/0.2/experimental/index.html#hail.experimental.pc_project). You can also compute this yourself as follows. Note this assumes biallelic SNPs.; ```python3; # the loadings_table is the third return value from hwe_normalized_pca; mt = mt.annotate_rows(loadings = loadings_table[mt.row_key]); mt = mt.filter_rows(hl.is_defined(mt.loadings)); mt = hl.variant_qc(mt); n_variants = mt.count_rows(); gt_norm = (mt.GT.n_alt_alleles() - 2 * mt.AF[1]) / hl.sqrt(n_variants * 2 * mt.AF[1] * (1 - mt.AF[1])); mt = mt.annotate_cols(scores=hl.agg.array_sum(mt.loadings * gt_norm)).cols(); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3490#issuecomment-1298562226
https://github.com/hail-is/hail/pull/3491#issuecomment-386425195:175,Availability,error,erroring,175,"I'd argue this is a nicer UX - Having an ""invalid"" or ""unknown"" type lets people with weird alleles (and people do have weird alleles) actually run their pipelines instead of erroring out.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3491#issuecomment-386425195
https://github.com/hail-is/hail/pull/3491#issuecomment-386425195:154,Deployability,pipeline,pipelines,154,"I'd argue this is a nicer UX - Having an ""invalid"" or ""unknown"" type lets people with weird alleles (and people do have weird alleles) actually run their pipelines instead of erroring out.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3491#issuecomment-386425195
https://github.com/hail-is/hail/pull/3491#issuecomment-386425195:26,Usability,UX,UX,26,"I'd argue this is a nicer UX - Having an ""invalid"" or ""unknown"" type lets people with weird alleles (and people do have weird alleles) actually run their pipelines instead of erroring out.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3491#issuecomment-386425195
https://github.com/hail-is/hail/pull/3491#issuecomment-386427843:82,Modifiability,refactor,refactor,82,`hl.allele_type` could also return missing for invalid input. But I don't want to refactor all the scala if we're just going to remove it,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3491#issuecomment-386427843
https://github.com/hail-is/hail/issues/3492#issuecomment-386354483:19,Security,intrusion,intrusion,19,"no. That fixed the intrusion of this bug into the Expression.take/show/collect stuff, but it's still a problem.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3492#issuecomment-386354483
https://github.com/hail-is/hail/issues/3499#issuecomment-386690550:151,Performance,load,loading,151,"@armartin did, see the linked issue. While I think supporting this is the right thing in some sense, would make things easier for first-time users and loading small data sets without thinking too much, I have mixed feelings about spending time on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3499#issuecomment-386690550
https://github.com/hail-is/hail/pull/3500#issuecomment-386445838:26,Energy Efficiency,adapt,adaptation,26,@jigold this is a minimal adaptation of #3466 which avoids exposing RowMatrix by putting an export command on BlockMatrix.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3500#issuecomment-386445838
https://github.com/hail-is/hail/pull/3500#issuecomment-386445838:26,Modifiability,adapt,adaptation,26,@jigold this is a minimal adaptation of #3466 which avoids exposing RowMatrix by putting an export command on BlockMatrix.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3500#issuecomment-386445838
https://github.com/hail-is/hail/pull/3500#issuecomment-386445838:52,Safety,avoid,avoids,52,@jigold this is a minimal adaptation of #3466 which avoids exposing RowMatrix by putting an export command on BlockMatrix.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3500#issuecomment-386445838
https://github.com/hail-is/hail/pull/3503#issuecomment-386721940:92,Modifiability,inherit,inheritance,92,"I borrowed the MissingArrayBuilder from #3458. I tried to unify this with ArrayBuilder with inheritance / trait, but was having trouble doing so.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3503#issuecomment-386721940
https://github.com/hail-is/hail/pull/3503#issuecomment-386722408:8,Testability,benchmark,benchmark,8,Can you benchmark this on profile225?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3503#issuecomment-386722408
https://github.com/hail-is/hail/issues/3508#issuecomment-386942393:80,Availability,error,error,80,"Ah I didn't see you had posted this a couple of days ago. I'm also getting this error on the pipeline below (which works on ~15K genomes, but not ~125K exomes):; ```; mt = mt.select_cols(group_membership=tuple(x[1] for x in sample_group_filters), project_id=mt.meta.project_id); mt = mt.select_rows(*mt.row_key); mt = mt.select_entries(n_alt=mt.GT.n_alt_alleles(), adj=mt.adj). frequency_expression = []; for i in range(len(sample_group_filters)):; subgroup_dict = sample_group_filters[i][0]; subgroup_dict['group'] = 'adj'. freq_expression = hl.struct(; ac=hl.agg.sum(hl.agg.filter(mt.group_membership[i] & mt.adj, mt.n_alt)),; an=2 * hl.agg.count_where(mt.group_membership[i] & mt.adj & hl.is_defined(mt.n_alt)),; hom=hl.agg.count_where(mt.group_membership[i] & mt.adj & (mt.n_alt == 2)),; meta=subgroup_dict; ); frequency_expression.append(freq_expression); freq_expression = hl.struct(; ac=hl.agg.sum(mt.n_alt),; an=2 * hl.agg.count_where(hl.is_defined(mt.n_alt)),; hom=hl.agg.count_where(mt.n_alt == 2),; meta={'group': 'raw'}; ); frequency_expression.insert(1, freq_expression). mt = mt.annotate_rows(freq=frequency_expression); mt.rows().write(); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3508#issuecomment-386942393
https://github.com/hail-is/hail/issues/3508#issuecomment-386942393:93,Deployability,pipeline,pipeline,93,"Ah I didn't see you had posted this a couple of days ago. I'm also getting this error on the pipeline below (which works on ~15K genomes, but not ~125K exomes):; ```; mt = mt.select_cols(group_membership=tuple(x[1] for x in sample_group_filters), project_id=mt.meta.project_id); mt = mt.select_rows(*mt.row_key); mt = mt.select_entries(n_alt=mt.GT.n_alt_alleles(), adj=mt.adj). frequency_expression = []; for i in range(len(sample_group_filters)):; subgroup_dict = sample_group_filters[i][0]; subgroup_dict['group'] = 'adj'. freq_expression = hl.struct(; ac=hl.agg.sum(hl.agg.filter(mt.group_membership[i] & mt.adj, mt.n_alt)),; an=2 * hl.agg.count_where(mt.group_membership[i] & mt.adj & hl.is_defined(mt.n_alt)),; hom=hl.agg.count_where(mt.group_membership[i] & mt.adj & (mt.n_alt == 2)),; meta=subgroup_dict; ); frequency_expression.append(freq_expression); freq_expression = hl.struct(; ac=hl.agg.sum(mt.n_alt),; an=2 * hl.agg.count_where(hl.is_defined(mt.n_alt)),; hom=hl.agg.count_where(mt.n_alt == 2),; meta={'group': 'raw'}; ); frequency_expression.insert(1, freq_expression). mt = mt.annotate_rows(freq=frequency_expression); mt.rows().write(); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3508#issuecomment-386942393
https://github.com/hail-is/hail/issues/3508#issuecomment-387561493:20,Availability,error,error,20,"I just got the same error running my [slightly altered] code again, but I stupidly didn't save the error output. I'm running it again and will let you know if I encounter another error!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3508#issuecomment-387561493
https://github.com/hail-is/hail/issues/3508#issuecomment-387561493:99,Availability,error,error,99,"I just got the same error running my [slightly altered] code again, but I stupidly didn't save the error output. I'm running it again and will let you know if I encounter another error!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3508#issuecomment-387561493
https://github.com/hail-is/hail/issues/3508#issuecomment-387561493:179,Availability,error,error,179,"I just got the same error running my [slightly altered] code again, but I stupidly didn't save the error output. I'm running it again and will let you know if I encounter another error!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3508#issuecomment-387561493
https://github.com/hail-is/hail/issues/3508#issuecomment-387563681:2031,Availability,down,down,2031,"ge(1, 10)}. # import bgen(s); mt = hl.methods.import_bgen('gs://fc-7d5088b4-7673-45b5-95c2-17ae00a04183/imputed/ukb_imp_chr{22}_v3.bgen',; ['dosage'],; sample_file='gs://phenotype_31063/ukb31063.imputed_v3.autosomes.sample',; contig_recoding=contigs). # load scoring sample; sampleids = hl.import_table('gs://ukb31063-mega-gwas/hail-0.1/qc/ukb31063.gwas_samples.txt', delimiter='\s+').key_by('s'). # merge sumstats on bgen matrixtable; mt = mt.annotate_rows(ss=sumstats[mt.locus]). # handle strand/sign flips -- score in terms of alt allele; mt = mt.annotate_rows(beta = hl.case(); .when(((mt.alleles[0] == mt.ss.nt1) &; (mt.alleles[1] == mt.ss.nt2)) |; ((flip_text(mt.alleles[0]) == mt.ss.nt1) &; (flip_text(mt.alleles[1]) == mt.ss.nt2)),; (-1*mt.ss.ldpred_inf_beta)); .when(((mt.alleles[0] == mt.ss.nt2) &; (mt.alleles[1] == mt.ss.nt1)) |; ((flip_text(mt.alleles[0]) == mt.ss.nt2) &; (flip_text(mt.alleles[1]) == mt.ss.nt1)),; mt.ss.ldpred_inf_beta); .or_missing()). # filter bgen matrixtable down to only SNPs with betas; mt = mt.filter_rows(hl.is_defined(mt.beta)). # filter bgen matrixtable to only include people in scoring sample; mt = mt.filter_cols(hl.is_defined(sampleids[mt.s])). # score sample; mt = mt.annotate_cols(prs=hl.agg.sum(mt.beta * mt.dosage)). # write out table with sample IDs and PRS scores; mt.cols().export('gs://ukbb_prs/prs/UKB_'+pheno+'_PRS_22.txt'). parser = argparse.ArgumentParser(); parser.add_argument(""--phenotype"", help=""name of the sumstat phenotype""); args = parser.parse_args(). try:; start = time.time(); main(args.phenotype); end = time.time(); message = ""Success! Job was completed in %s"" % time.strftime(""%H:%M:%S"", time.gmtime(end - start)); send_message(message); except Exception as e:; send_message(""Fail.""); ```. ""Failure Reason"":; ```; Job aborted due to stage failure: Task 98 in stage 13.0 failed 20 times, most recent failure: Lost task 98.19 in stage 13.0 (TID 22699, ccarey-sw-xt4j.c.ukbb-robinson.internal, executor 68): java.lang.NegativeArrayS",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3508#issuecomment-387563681
https://github.com/hail-is/hail/issues/3508#issuecomment-387563681:2799,Availability,Failure,Failure,2799,".nt2) &; (mt.alleles[1] == mt.ss.nt1)) |; ((flip_text(mt.alleles[0]) == mt.ss.nt2) &; (flip_text(mt.alleles[1]) == mt.ss.nt1)),; mt.ss.ldpred_inf_beta); .or_missing()). # filter bgen matrixtable down to only SNPs with betas; mt = mt.filter_rows(hl.is_defined(mt.beta)). # filter bgen matrixtable to only include people in scoring sample; mt = mt.filter_cols(hl.is_defined(sampleids[mt.s])). # score sample; mt = mt.annotate_cols(prs=hl.agg.sum(mt.beta * mt.dosage)). # write out table with sample IDs and PRS scores; mt.cols().export('gs://ukbb_prs/prs/UKB_'+pheno+'_PRS_22.txt'). parser = argparse.ArgumentParser(); parser.add_argument(""--phenotype"", help=""name of the sumstat phenotype""); args = parser.parse_args(). try:; start = time.time(); main(args.phenotype); end = time.time(); message = ""Success! Job was completed in %s"" % time.strftime(""%H:%M:%S"", time.gmtime(end - start)); send_message(message); except Exception as e:; send_message(""Fail.""); ```. ""Failure Reason"":; ```; Job aborted due to stage failure: Task 98 in stage 13.0 failed 20 times, most recent failure: Lost task 98.19 in stage 13.0 (TID 22699, ccarey-sw-xt4j.c.ukbb-robinson.internal, executor 68): java.lang.NegativeArraySizeException; 	at java.util.Arrays.copyOf(Arrays.java:3236); 	at is.hail.annotations.Region.ensure(Region.scala:139); 	at is.hail.annotations.Region.allocate(Region.scala:152); 	at is.hail.annotations.Region.allocate(Region.scala:159); 	at is.hail.expr.types.TContainer.allocate(TContainer.scala:127); 	at is.hail.annotations.RegionValueBuilder.fixupArray(RegionValueBuilder.scala:278); 	at is.hail.annotations.RegionValueBuilder.addRegionValue(RegionValueBuilder.scala:432); 	at is.hail.expr.MatrixMapRows$$anonfun$25$$anonfun$apply$19.apply(Relational.scala:815); 	at is.hail.expr.MatrixMapRows$$anonfun$25$$anonfun$apply$19.apply(Relational.scala:804); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.rv",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3508#issuecomment-387563681
https://github.com/hail-is/hail/issues/3508#issuecomment-387563681:2847,Availability,failure,failure,2847,".nt2) &; (mt.alleles[1] == mt.ss.nt1)) |; ((flip_text(mt.alleles[0]) == mt.ss.nt2) &; (flip_text(mt.alleles[1]) == mt.ss.nt1)),; mt.ss.ldpred_inf_beta); .or_missing()). # filter bgen matrixtable down to only SNPs with betas; mt = mt.filter_rows(hl.is_defined(mt.beta)). # filter bgen matrixtable to only include people in scoring sample; mt = mt.filter_cols(hl.is_defined(sampleids[mt.s])). # score sample; mt = mt.annotate_cols(prs=hl.agg.sum(mt.beta * mt.dosage)). # write out table with sample IDs and PRS scores; mt.cols().export('gs://ukbb_prs/prs/UKB_'+pheno+'_PRS_22.txt'). parser = argparse.ArgumentParser(); parser.add_argument(""--phenotype"", help=""name of the sumstat phenotype""); args = parser.parse_args(). try:; start = time.time(); main(args.phenotype); end = time.time(); message = ""Success! Job was completed in %s"" % time.strftime(""%H:%M:%S"", time.gmtime(end - start)); send_message(message); except Exception as e:; send_message(""Fail.""); ```. ""Failure Reason"":; ```; Job aborted due to stage failure: Task 98 in stage 13.0 failed 20 times, most recent failure: Lost task 98.19 in stage 13.0 (TID 22699, ccarey-sw-xt4j.c.ukbb-robinson.internal, executor 68): java.lang.NegativeArraySizeException; 	at java.util.Arrays.copyOf(Arrays.java:3236); 	at is.hail.annotations.Region.ensure(Region.scala:139); 	at is.hail.annotations.Region.allocate(Region.scala:152); 	at is.hail.annotations.Region.allocate(Region.scala:159); 	at is.hail.expr.types.TContainer.allocate(TContainer.scala:127); 	at is.hail.annotations.RegionValueBuilder.fixupArray(RegionValueBuilder.scala:278); 	at is.hail.annotations.RegionValueBuilder.addRegionValue(RegionValueBuilder.scala:432); 	at is.hail.expr.MatrixMapRows$$anonfun$25$$anonfun$apply$19.apply(Relational.scala:815); 	at is.hail.expr.MatrixMapRows$$anonfun$25$$anonfun$apply$19.apply(Relational.scala:804); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.rv",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3508#issuecomment-387563681
https://github.com/hail-is/hail/issues/3508#issuecomment-387563681:2907,Availability,failure,failure,2907,"]) == mt.ss.nt2) &; (flip_text(mt.alleles[1]) == mt.ss.nt1)),; mt.ss.ldpred_inf_beta); .or_missing()). # filter bgen matrixtable down to only SNPs with betas; mt = mt.filter_rows(hl.is_defined(mt.beta)). # filter bgen matrixtable to only include people in scoring sample; mt = mt.filter_cols(hl.is_defined(sampleids[mt.s])). # score sample; mt = mt.annotate_cols(prs=hl.agg.sum(mt.beta * mt.dosage)). # write out table with sample IDs and PRS scores; mt.cols().export('gs://ukbb_prs/prs/UKB_'+pheno+'_PRS_22.txt'). parser = argparse.ArgumentParser(); parser.add_argument(""--phenotype"", help=""name of the sumstat phenotype""); args = parser.parse_args(). try:; start = time.time(); main(args.phenotype); end = time.time(); message = ""Success! Job was completed in %s"" % time.strftime(""%H:%M:%S"", time.gmtime(end - start)); send_message(message); except Exception as e:; send_message(""Fail.""); ```. ""Failure Reason"":; ```; Job aborted due to stage failure: Task 98 in stage 13.0 failed 20 times, most recent failure: Lost task 98.19 in stage 13.0 (TID 22699, ccarey-sw-xt4j.c.ukbb-robinson.internal, executor 68): java.lang.NegativeArraySizeException; 	at java.util.Arrays.copyOf(Arrays.java:3236); 	at is.hail.annotations.Region.ensure(Region.scala:139); 	at is.hail.annotations.Region.allocate(Region.scala:152); 	at is.hail.annotations.Region.allocate(Region.scala:159); 	at is.hail.expr.types.TContainer.allocate(TContainer.scala:127); 	at is.hail.annotations.RegionValueBuilder.fixupArray(RegionValueBuilder.scala:278); 	at is.hail.annotations.RegionValueBuilder.addRegionValue(RegionValueBuilder.scala:432); 	at is.hail.expr.MatrixMapRows$$anonfun$25$$anonfun$apply$19.apply(Relational.scala:815); 	at is.hail.expr.MatrixMapRows$$anonfun$25$$anonfun$apply$19.apply(Relational.scala:804); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.next(OrderedRVD.scala:914);",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3508#issuecomment-387563681
https://github.com/hail-is/hail/issues/3508#issuecomment-387563681:6595,Availability,error,error,6595,35); 	at is.hail.sparkextras.ContextRDD$$anonfun$6.apply(ContextRDD.scala:234); 	at scala.Function1$$anonfun$andThen$1.apply(Function1.scala:52); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; ```. _All_ of my workers had this error:; ```; java.lang.NegativeArraySizeException; 	at java.util.Arrays.copyOf(Arrays.java:3236); 	at is.hail.annotations.Region.ensure(Region.scala:139); 	at is.hail.annotations.Region.allocate(Region.scala:152); 	at is.hail.annotations.Region.allocate(Region.scala:159); 	at is.hail.expr.types.TContainer.allocate(TContainer.scala:127); 	at is.hail.annotations.RegionValueBuilder.fixupArray(RegionValueBuilder.scala:278); 	at is.hail.annotations.RegionValueBuilder.addRegionValue(RegionValueBuilder.scala:432); 	at is.hail.expr.MatrixMapRows$$anonfun$25$$anonfun$apply$19.apply(Relational.scala:815); 	at is.hail.expr.MatrixMapRows$$anonfun$25$$anonfun$apply$19.apply(Relational.scala:804); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.next(OrderedRVD.scala:914); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.next(OrderedRVD.scala:908); 	at scala,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3508#issuecomment-387563681
https://github.com/hail-is/hail/issues/3508#issuecomment-387563681:3186,Energy Efficiency,allocate,allocate,3186,"hl.is_defined(sampleids[mt.s])). # score sample; mt = mt.annotate_cols(prs=hl.agg.sum(mt.beta * mt.dosage)). # write out table with sample IDs and PRS scores; mt.cols().export('gs://ukbb_prs/prs/UKB_'+pheno+'_PRS_22.txt'). parser = argparse.ArgumentParser(); parser.add_argument(""--phenotype"", help=""name of the sumstat phenotype""); args = parser.parse_args(). try:; start = time.time(); main(args.phenotype); end = time.time(); message = ""Success! Job was completed in %s"" % time.strftime(""%H:%M:%S"", time.gmtime(end - start)); send_message(message); except Exception as e:; send_message(""Fail.""); ```. ""Failure Reason"":; ```; Job aborted due to stage failure: Task 98 in stage 13.0 failed 20 times, most recent failure: Lost task 98.19 in stage 13.0 (TID 22699, ccarey-sw-xt4j.c.ukbb-robinson.internal, executor 68): java.lang.NegativeArraySizeException; 	at java.util.Arrays.copyOf(Arrays.java:3236); 	at is.hail.annotations.Region.ensure(Region.scala:139); 	at is.hail.annotations.Region.allocate(Region.scala:152); 	at is.hail.annotations.Region.allocate(Region.scala:159); 	at is.hail.expr.types.TContainer.allocate(TContainer.scala:127); 	at is.hail.annotations.RegionValueBuilder.fixupArray(RegionValueBuilder.scala:278); 	at is.hail.annotations.RegionValueBuilder.addRegionValue(RegionValueBuilder.scala:432); 	at is.hail.expr.MatrixMapRows$$anonfun$25$$anonfun$apply$19.apply(Relational.scala:815); 	at is.hail.expr.MatrixMapRows$$anonfun$25$$anonfun$apply$19.apply(Relational.scala:804); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.next(OrderedRVD.scala:914); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.next(OrderedRVD.scala:908); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.rv",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3508#issuecomment-387563681
https://github.com/hail-is/hail/issues/3508#issuecomment-387563681:3245,Energy Efficiency,allocate,allocate,3245,"notate_cols(prs=hl.agg.sum(mt.beta * mt.dosage)). # write out table with sample IDs and PRS scores; mt.cols().export('gs://ukbb_prs/prs/UKB_'+pheno+'_PRS_22.txt'). parser = argparse.ArgumentParser(); parser.add_argument(""--phenotype"", help=""name of the sumstat phenotype""); args = parser.parse_args(). try:; start = time.time(); main(args.phenotype); end = time.time(); message = ""Success! Job was completed in %s"" % time.strftime(""%H:%M:%S"", time.gmtime(end - start)); send_message(message); except Exception as e:; send_message(""Fail.""); ```. ""Failure Reason"":; ```; Job aborted due to stage failure: Task 98 in stage 13.0 failed 20 times, most recent failure: Lost task 98.19 in stage 13.0 (TID 22699, ccarey-sw-xt4j.c.ukbb-robinson.internal, executor 68): java.lang.NegativeArraySizeException; 	at java.util.Arrays.copyOf(Arrays.java:3236); 	at is.hail.annotations.Region.ensure(Region.scala:139); 	at is.hail.annotations.Region.allocate(Region.scala:152); 	at is.hail.annotations.Region.allocate(Region.scala:159); 	at is.hail.expr.types.TContainer.allocate(TContainer.scala:127); 	at is.hail.annotations.RegionValueBuilder.fixupArray(RegionValueBuilder.scala:278); 	at is.hail.annotations.RegionValueBuilder.addRegionValue(RegionValueBuilder.scala:432); 	at is.hail.expr.MatrixMapRows$$anonfun$25$$anonfun$apply$19.apply(Relational.scala:815); 	at is.hail.expr.MatrixMapRows$$anonfun$25$$anonfun$apply$19.apply(Relational.scala:804); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.next(OrderedRVD.scala:914); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.next(OrderedRVD.scala:908); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.next(OrderedRVD.scal",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3508#issuecomment-387563681
https://github.com/hail-is/hail/issues/3508#issuecomment-387563681:3307,Energy Efficiency,allocate,allocate,3307,"ble with sample IDs and PRS scores; mt.cols().export('gs://ukbb_prs/prs/UKB_'+pheno+'_PRS_22.txt'). parser = argparse.ArgumentParser(); parser.add_argument(""--phenotype"", help=""name of the sumstat phenotype""); args = parser.parse_args(). try:; start = time.time(); main(args.phenotype); end = time.time(); message = ""Success! Job was completed in %s"" % time.strftime(""%H:%M:%S"", time.gmtime(end - start)); send_message(message); except Exception as e:; send_message(""Fail.""); ```. ""Failure Reason"":; ```; Job aborted due to stage failure: Task 98 in stage 13.0 failed 20 times, most recent failure: Lost task 98.19 in stage 13.0 (TID 22699, ccarey-sw-xt4j.c.ukbb-robinson.internal, executor 68): java.lang.NegativeArraySizeException; 	at java.util.Arrays.copyOf(Arrays.java:3236); 	at is.hail.annotations.Region.ensure(Region.scala:139); 	at is.hail.annotations.Region.allocate(Region.scala:152); 	at is.hail.annotations.Region.allocate(Region.scala:159); 	at is.hail.expr.types.TContainer.allocate(TContainer.scala:127); 	at is.hail.annotations.RegionValueBuilder.fixupArray(RegionValueBuilder.scala:278); 	at is.hail.annotations.RegionValueBuilder.addRegionValue(RegionValueBuilder.scala:432); 	at is.hail.expr.MatrixMapRows$$anonfun$25$$anonfun$apply$19.apply(Relational.scala:815); 	at is.hail.expr.MatrixMapRows$$anonfun$25$$anonfun$apply$19.apply(Relational.scala:804); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.next(OrderedRVD.scala:914); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.next(OrderedRVD.scala:908); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.next(OrderedRVD.scala:914); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.nex",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3508#issuecomment-387563681
https://github.com/hail-is/hail/issues/3508#issuecomment-387563681:6145,Energy Efficiency,schedul,scheduler,6145,TraversableOnce$class.aggregate(TraversableOnce.scala:214); 	at scala.collection.AbstractIterator.aggregate(Iterator.scala:1336); 	at is.hail.sparkextras.ContextRDD$$anonfun$6$$anonfun$apply$11.apply(ContextRDD.scala:237); 	at is.hail.sparkextras.ContextRDD$$anonfun$6$$anonfun$apply$11.apply(ContextRDD.scala:235); 	at is.hail.utils.package$.using(package.scala:577); 	at is.hail.sparkextras.ContextRDD$$anonfun$6.apply(ContextRDD.scala:235); 	at is.hail.sparkextras.ContextRDD$$anonfun$6.apply(ContextRDD.scala:234); 	at scala.Function1$$anonfun$andThen$1.apply(Function1.scala:52); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; ```. _All_ of my workers had this error:; ```; java.lang.NegativeArraySizeException; 	at java.util.Arrays.copyOf(Arrays.java:3236); 	at is.hail.annotations.Region.ensure(Region.scala:139); 	at is.hail.annotations.Region.allocate(Region.scala:152); 	at is.hail.annotations.Region.allocate(Region.scala:159); 	at is.hail.expr.types.TContainer.allocate(TContainer.scala:127); 	at is.hail.annotations.RegionValueBuilder.fixupArray(RegionValueBuilder.scala:278); 	at is.hail.annotations.RegionValueBuilder.addRegionValue(RegionValueBuilder.scala:432); 	at is.hail.expr.MatrixMapRows$$anonfun$25,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3508#issuecomment-387563681
https://github.com/hail-is/hail/issues/3508#issuecomment-387563681:6217,Energy Efficiency,schedul,scheduler,6217,llection.AbstractIterator.aggregate(Iterator.scala:1336); 	at is.hail.sparkextras.ContextRDD$$anonfun$6$$anonfun$apply$11.apply(ContextRDD.scala:237); 	at is.hail.sparkextras.ContextRDD$$anonfun$6$$anonfun$apply$11.apply(ContextRDD.scala:235); 	at is.hail.utils.package$.using(package.scala:577); 	at is.hail.sparkextras.ContextRDD$$anonfun$6.apply(ContextRDD.scala:235); 	at is.hail.sparkextras.ContextRDD$$anonfun$6.apply(ContextRDD.scala:234); 	at scala.Function1$$anonfun$andThen$1.apply(Function1.scala:52); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; ```. _All_ of my workers had this error:; ```; java.lang.NegativeArraySizeException; 	at java.util.Arrays.copyOf(Arrays.java:3236); 	at is.hail.annotations.Region.ensure(Region.scala:139); 	at is.hail.annotations.Region.allocate(Region.scala:152); 	at is.hail.annotations.Region.allocate(Region.scala:159); 	at is.hail.expr.types.TContainer.allocate(TContainer.scala:127); 	at is.hail.annotations.RegionValueBuilder.fixupArray(RegionValueBuilder.scala:278); 	at is.hail.annotations.RegionValueBuilder.addRegionValue(RegionValueBuilder.scala:432); 	at is.hail.expr.MatrixMapRows$$anonfun$25$$anonfun$apply$19.apply(Relational.scala:815); 	at is.hail.expr.MatrixM,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3508#issuecomment-387563681
https://github.com/hail-is/hail/issues/3508#issuecomment-387563681:6781,Energy Efficiency,allocate,allocate,6781,$anonfun$apply$23.apply(RDD.scala:797); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; ```. _All_ of my workers had this error:; ```; java.lang.NegativeArraySizeException; 	at java.util.Arrays.copyOf(Arrays.java:3236); 	at is.hail.annotations.Region.ensure(Region.scala:139); 	at is.hail.annotations.Region.allocate(Region.scala:152); 	at is.hail.annotations.Region.allocate(Region.scala:159); 	at is.hail.expr.types.TContainer.allocate(TContainer.scala:127); 	at is.hail.annotations.RegionValueBuilder.fixupArray(RegionValueBuilder.scala:278); 	at is.hail.annotations.RegionValueBuilder.addRegionValue(RegionValueBuilder.scala:432); 	at is.hail.expr.MatrixMapRows$$anonfun$25$$anonfun$apply$19.apply(Relational.scala:815); 	at is.hail.expr.MatrixMapRows$$anonfun$25$$anonfun$apply$19.apply(Relational.scala:804); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.next(OrderedRVD.scala:914); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.next(OrderedRVD.scala:908); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.rv,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3508#issuecomment-387563681
https://github.com/hail-is/hail/issues/3508#issuecomment-387563681:6840,Energy Efficiency,allocate,allocate,6840,k.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; ```. _All_ of my workers had this error:; ```; java.lang.NegativeArraySizeException; 	at java.util.Arrays.copyOf(Arrays.java:3236); 	at is.hail.annotations.Region.ensure(Region.scala:139); 	at is.hail.annotations.Region.allocate(Region.scala:152); 	at is.hail.annotations.Region.allocate(Region.scala:159); 	at is.hail.expr.types.TContainer.allocate(TContainer.scala:127); 	at is.hail.annotations.RegionValueBuilder.fixupArray(RegionValueBuilder.scala:278); 	at is.hail.annotations.RegionValueBuilder.addRegionValue(RegionValueBuilder.scala:432); 	at is.hail.expr.MatrixMapRows$$anonfun$25$$anonfun$apply$19.apply(Relational.scala:815); 	at is.hail.expr.MatrixMapRows$$anonfun$25$$anonfun$apply$19.apply(Relational.scala:804); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.next(OrderedRVD.scala:914); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.next(OrderedRVD.scala:908); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.next(OrderedRVD.scal,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3508#issuecomment-387563681
https://github.com/hail-is/hail/issues/3508#issuecomment-387563681:6902,Energy Efficiency,allocate,allocate,6902,cala:797); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; ```. _All_ of my workers had this error:; ```; java.lang.NegativeArraySizeException; 	at java.util.Arrays.copyOf(Arrays.java:3236); 	at is.hail.annotations.Region.ensure(Region.scala:139); 	at is.hail.annotations.Region.allocate(Region.scala:152); 	at is.hail.annotations.Region.allocate(Region.scala:159); 	at is.hail.expr.types.TContainer.allocate(TContainer.scala:127); 	at is.hail.annotations.RegionValueBuilder.fixupArray(RegionValueBuilder.scala:278); 	at is.hail.annotations.RegionValueBuilder.addRegionValue(RegionValueBuilder.scala:432); 	at is.hail.expr.MatrixMapRows$$anonfun$25$$anonfun$apply$19.apply(Relational.scala:815); 	at is.hail.expr.MatrixMapRows$$anonfun$25$$anonfun$apply$19.apply(Relational.scala:804); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.next(OrderedRVD.scala:914); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.next(OrderedRVD.scala:908); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.next(OrderedRVD.scala:914); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.nex,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3508#issuecomment-387563681
https://github.com/hail-is/hail/issues/3508#issuecomment-387563681:9740,Energy Efficiency,schedul,scheduler,9740,at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.hasNext(OrderedRVD.scala:911); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.hasNext(OrderedRVD.scala:911); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157); 	at scala.collection.AbstractIterator.foldLeft(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.aggregate(TraversableOnce.scala:214); 	at scala.collection.AbstractIterator.aggregate(Iterator.scala:1336); 	at is.hail.sparkextras.ContextRDD$$anonfun$6$$anonfun$apply$11.apply(ContextRDD.scala:237); 	at is.hail.sparkextras.ContextRDD$$anonfun$6$$anonfun$apply$11.apply(ContextRDD.scala:235); 	at is.hail.utils.package$.using(package.scala:577); 	at is.hail.sparkextras.ContextRDD$$anonfun$6.apply(ContextRDD.scala:235); 	at is.hail.sparkextras.ContextRDD$$anonfun$6.apply(ContextRDD.scala:234); 	at scala.Function1$$anonfun$andThen$1.apply(Function1.scala:52); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3508#issuecomment-387563681
https://github.com/hail-is/hail/issues/3508#issuecomment-387563681:9812,Energy Efficiency,schedul,scheduler,9812,at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.hasNext(OrderedRVD.scala:911); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.hasNext(OrderedRVD.scala:911); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157); 	at scala.collection.AbstractIterator.foldLeft(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.aggregate(TraversableOnce.scala:214); 	at scala.collection.AbstractIterator.aggregate(Iterator.scala:1336); 	at is.hail.sparkextras.ContextRDD$$anonfun$6$$anonfun$apply$11.apply(ContextRDD.scala:237); 	at is.hail.sparkextras.ContextRDD$$anonfun$6$$anonfun$apply$11.apply(ContextRDD.scala:235); 	at is.hail.utils.package$.using(package.scala:577); 	at is.hail.sparkextras.ContextRDD$$anonfun$6.apply(ContextRDD.scala:235); 	at is.hail.sparkextras.ContextRDD$$anonfun$6.apply(ContextRDD.scala:234); 	at scala.Function1$$anonfun$andThen$1.apply(Function1.scala:52); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3508#issuecomment-387563681
https://github.com/hail-is/hail/issues/3508#issuecomment-387563681:2623,Integrability,message,message,2623,".ss.nt1) &; (mt.alleles[1] == mt.ss.nt2)) |; ((flip_text(mt.alleles[0]) == mt.ss.nt1) &; (flip_text(mt.alleles[1]) == mt.ss.nt2)),; (-1*mt.ss.ldpred_inf_beta)); .when(((mt.alleles[0] == mt.ss.nt2) &; (mt.alleles[1] == mt.ss.nt1)) |; ((flip_text(mt.alleles[0]) == mt.ss.nt2) &; (flip_text(mt.alleles[1]) == mt.ss.nt1)),; mt.ss.ldpred_inf_beta); .or_missing()). # filter bgen matrixtable down to only SNPs with betas; mt = mt.filter_rows(hl.is_defined(mt.beta)). # filter bgen matrixtable to only include people in scoring sample; mt = mt.filter_cols(hl.is_defined(sampleids[mt.s])). # score sample; mt = mt.annotate_cols(prs=hl.agg.sum(mt.beta * mt.dosage)). # write out table with sample IDs and PRS scores; mt.cols().export('gs://ukbb_prs/prs/UKB_'+pheno+'_PRS_22.txt'). parser = argparse.ArgumentParser(); parser.add_argument(""--phenotype"", help=""name of the sumstat phenotype""); args = parser.parse_args(). try:; start = time.time(); main(args.phenotype); end = time.time(); message = ""Success! Job was completed in %s"" % time.strftime(""%H:%M:%S"", time.gmtime(end - start)); send_message(message); except Exception as e:; send_message(""Fail.""); ```. ""Failure Reason"":; ```; Job aborted due to stage failure: Task 98 in stage 13.0 failed 20 times, most recent failure: Lost task 98.19 in stage 13.0 (TID 22699, ccarey-sw-xt4j.c.ukbb-robinson.internal, executor 68): java.lang.NegativeArraySizeException; 	at java.util.Arrays.copyOf(Arrays.java:3236); 	at is.hail.annotations.Region.ensure(Region.scala:139); 	at is.hail.annotations.Region.allocate(Region.scala:152); 	at is.hail.annotations.Region.allocate(Region.scala:159); 	at is.hail.expr.types.TContainer.allocate(TContainer.scala:127); 	at is.hail.annotations.RegionValueBuilder.fixupArray(RegionValueBuilder.scala:278); 	at is.hail.annotations.RegionValueBuilder.addRegionValue(RegionValueBuilder.scala:432); 	at is.hail.expr.MatrixMapRows$$anonfun$25$$anonfun$apply$19.apply(Relational.scala:815); 	at is.hail.expr.MatrixMapRows$$anonfun$25",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3508#issuecomment-387563681
https://github.com/hail-is/hail/issues/3508#issuecomment-387563681:2736,Integrability,message,message,2736,"mt.alleles[1]) == mt.ss.nt2)),; (-1*mt.ss.ldpred_inf_beta)); .when(((mt.alleles[0] == mt.ss.nt2) &; (mt.alleles[1] == mt.ss.nt1)) |; ((flip_text(mt.alleles[0]) == mt.ss.nt2) &; (flip_text(mt.alleles[1]) == mt.ss.nt1)),; mt.ss.ldpred_inf_beta); .or_missing()). # filter bgen matrixtable down to only SNPs with betas; mt = mt.filter_rows(hl.is_defined(mt.beta)). # filter bgen matrixtable to only include people in scoring sample; mt = mt.filter_cols(hl.is_defined(sampleids[mt.s])). # score sample; mt = mt.annotate_cols(prs=hl.agg.sum(mt.beta * mt.dosage)). # write out table with sample IDs and PRS scores; mt.cols().export('gs://ukbb_prs/prs/UKB_'+pheno+'_PRS_22.txt'). parser = argparse.ArgumentParser(); parser.add_argument(""--phenotype"", help=""name of the sumstat phenotype""); args = parser.parse_args(). try:; start = time.time(); main(args.phenotype); end = time.time(); message = ""Success! Job was completed in %s"" % time.strftime(""%H:%M:%S"", time.gmtime(end - start)); send_message(message); except Exception as e:; send_message(""Fail.""); ```. ""Failure Reason"":; ```; Job aborted due to stage failure: Task 98 in stage 13.0 failed 20 times, most recent failure: Lost task 98.19 in stage 13.0 (TID 22699, ccarey-sw-xt4j.c.ukbb-robinson.internal, executor 68): java.lang.NegativeArraySizeException; 	at java.util.Arrays.copyOf(Arrays.java:3236); 	at is.hail.annotations.Region.ensure(Region.scala:139); 	at is.hail.annotations.Region.allocate(Region.scala:152); 	at is.hail.annotations.Region.allocate(Region.scala:159); 	at is.hail.expr.types.TContainer.allocate(TContainer.scala:127); 	at is.hail.annotations.RegionValueBuilder.fixupArray(RegionValueBuilder.scala:278); 	at is.hail.annotations.RegionValueBuilder.addRegionValue(RegionValueBuilder.scala:432); 	at is.hail.expr.MatrixMapRows$$anonfun$25$$anonfun$apply$19.apply(Relational.scala:815); 	at is.hail.expr.MatrixMapRows$$anonfun$25$$anonfun$apply$19.apply(Relational.scala:804); 	at scala.collection.Iterator$$anon$11.next(Iterator",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3508#issuecomment-387563681
https://github.com/hail-is/hail/issues/3508#issuecomment-387563681:404,Performance,load,load,404,"Code: . ```; import hail as hl; import time; import argparse; from slack_utils import send_message. def flip_text(base):; """"""; :param StringExpression base: Expression of a single base; :return: StringExpression of flipped base; :rtype: StringExpression; """"""; return hl.cond(base == 'A', 'T',; hl.cond(base == 'T', 'A',; hl.cond(base == 'C', 'G',; hl.cond(base == 'G', 'C', base)))). def main(pheno):; # load ldpred sumstats file; sumstats = hl.import_table('gs://ukbb_prs/sumstats/UKB_'+pheno+'_LDPred.txt', delimiter='\s+', impute=True, min_partitions=100). # create locus and alleles columns and key by locus; sumstats = (sumstats.annotate(locus=hl.parse_locus(sumstats.chrom[6:] + "":"" + hl.str(sumstats.pos)),; alleles=[sumstats.nt1,sumstats.nt2]); .key_by('locus')). # write the sumstats table; sumstats.write('gs://ukbb_prs/sumstats/temp.kt', overwrite=True). # read the sumstats table; sumstats = hl.read_table('gs://ukbb_prs/sumstats/temp.kt'). # remove leading zeros from contigs; contigs = {'0{}'.format(x):str(x) for x in range(1, 10)}. # import bgen(s); mt = hl.methods.import_bgen('gs://fc-7d5088b4-7673-45b5-95c2-17ae00a04183/imputed/ukb_imp_chr{22}_v3.bgen',; ['dosage'],; sample_file='gs://phenotype_31063/ukb31063.imputed_v3.autosomes.sample',; contig_recoding=contigs). # load scoring sample; sampleids = hl.import_table('gs://ukb31063-mega-gwas/hail-0.1/qc/ukb31063.gwas_samples.txt', delimiter='\s+').key_by('s'). # merge sumstats on bgen matrixtable; mt = mt.annotate_rows(ss=sumstats[mt.locus]). # handle strand/sign flips -- score in terms of alt allele; mt = mt.annotate_rows(beta = hl.case(); .when(((mt.alleles[0] == mt.ss.nt1) &; (mt.alleles[1] == mt.ss.nt2)) |; ((flip_text(mt.alleles[0]) == mt.ss.nt1) &; (flip_text(mt.alleles[1]) == mt.ss.nt2)),; (-1*mt.ss.ldpred_inf_beta)); .when(((mt.alleles[0] == mt.ss.nt2) &; (mt.alleles[1] == mt.ss.nt1)) |; ((flip_text(mt.alleles[0]) == mt.ss.nt2) &; (flip_text(mt.alleles[1]) == mt.ss.nt1)),; mt.ss.ldpred_inf_beta); .or_missing(",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3508#issuecomment-387563681
https://github.com/hail-is/hail/issues/3508#issuecomment-387563681:1290,Performance,load,load,1290," == 'T', 'A',; hl.cond(base == 'C', 'G',; hl.cond(base == 'G', 'C', base)))). def main(pheno):; # load ldpred sumstats file; sumstats = hl.import_table('gs://ukbb_prs/sumstats/UKB_'+pheno+'_LDPred.txt', delimiter='\s+', impute=True, min_partitions=100). # create locus and alleles columns and key by locus; sumstats = (sumstats.annotate(locus=hl.parse_locus(sumstats.chrom[6:] + "":"" + hl.str(sumstats.pos)),; alleles=[sumstats.nt1,sumstats.nt2]); .key_by('locus')). # write the sumstats table; sumstats.write('gs://ukbb_prs/sumstats/temp.kt', overwrite=True). # read the sumstats table; sumstats = hl.read_table('gs://ukbb_prs/sumstats/temp.kt'). # remove leading zeros from contigs; contigs = {'0{}'.format(x):str(x) for x in range(1, 10)}. # import bgen(s); mt = hl.methods.import_bgen('gs://fc-7d5088b4-7673-45b5-95c2-17ae00a04183/imputed/ukb_imp_chr{22}_v3.bgen',; ['dosage'],; sample_file='gs://phenotype_31063/ukb31063.imputed_v3.autosomes.sample',; contig_recoding=contigs). # load scoring sample; sampleids = hl.import_table('gs://ukb31063-mega-gwas/hail-0.1/qc/ukb31063.gwas_samples.txt', delimiter='\s+').key_by('s'). # merge sumstats on bgen matrixtable; mt = mt.annotate_rows(ss=sumstats[mt.locus]). # handle strand/sign flips -- score in terms of alt allele; mt = mt.annotate_rows(beta = hl.case(); .when(((mt.alleles[0] == mt.ss.nt1) &; (mt.alleles[1] == mt.ss.nt2)) |; ((flip_text(mt.alleles[0]) == mt.ss.nt1) &; (flip_text(mt.alleles[1]) == mt.ss.nt2)),; (-1*mt.ss.ldpred_inf_beta)); .when(((mt.alleles[0] == mt.ss.nt2) &; (mt.alleles[1] == mt.ss.nt1)) |; ((flip_text(mt.alleles[0]) == mt.ss.nt2) &; (flip_text(mt.alleles[1]) == mt.ss.nt1)),; mt.ss.ldpred_inf_beta); .or_missing()). # filter bgen matrixtable down to only SNPs with betas; mt = mt.filter_rows(hl.is_defined(mt.beta)). # filter bgen matrixtable to only include people in scoring sample; mt = mt.filter_cols(hl.is_defined(sampleids[mt.s])). # score sample; mt = mt.annotate_cols(prs=hl.agg.sum(mt.beta * mt.dosage)). # wr",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3508#issuecomment-387563681
https://github.com/hail-is/hail/issues/3508#issuecomment-387563681:6342,Performance,concurren,concurrent,6342,ly(ContextRDD.scala:237); 	at is.hail.sparkextras.ContextRDD$$anonfun$6$$anonfun$apply$11.apply(ContextRDD.scala:235); 	at is.hail.utils.package$.using(package.scala:577); 	at is.hail.sparkextras.ContextRDD$$anonfun$6.apply(ContextRDD.scala:235); 	at is.hail.sparkextras.ContextRDD$$anonfun$6.apply(ContextRDD.scala:234); 	at scala.Function1$$anonfun$andThen$1.apply(Function1.scala:52); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; ```. _All_ of my workers had this error:; ```; java.lang.NegativeArraySizeException; 	at java.util.Arrays.copyOf(Arrays.java:3236); 	at is.hail.annotations.Region.ensure(Region.scala:139); 	at is.hail.annotations.Region.allocate(Region.scala:152); 	at is.hail.annotations.Region.allocate(Region.scala:159); 	at is.hail.expr.types.TContainer.allocate(TContainer.scala:127); 	at is.hail.annotations.RegionValueBuilder.fixupArray(RegionValueBuilder.scala:278); 	at is.hail.annotations.RegionValueBuilder.addRegionValue(RegionValueBuilder.scala:432); 	at is.hail.expr.MatrixMapRows$$anonfun$25$$anonfun$apply$19.apply(Relational.scala:815); 	at is.hail.expr.MatrixMapRows$$anonfun$25$$anonfun$apply$19.apply(Relational.scala:804); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:4,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3508#issuecomment-387563681
https://github.com/hail-is/hail/issues/3508#issuecomment-387563681:6427,Performance,concurren,concurrent,6427,y$11.apply(ContextRDD.scala:235); 	at is.hail.utils.package$.using(package.scala:577); 	at is.hail.sparkextras.ContextRDD$$anonfun$6.apply(ContextRDD.scala:235); 	at is.hail.sparkextras.ContextRDD$$anonfun$6.apply(ContextRDD.scala:234); 	at scala.Function1$$anonfun$andThen$1.apply(Function1.scala:52); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; ```. _All_ of my workers had this error:; ```; java.lang.NegativeArraySizeException; 	at java.util.Arrays.copyOf(Arrays.java:3236); 	at is.hail.annotations.Region.ensure(Region.scala:139); 	at is.hail.annotations.Region.allocate(Region.scala:152); 	at is.hail.annotations.Region.allocate(Region.scala:159); 	at is.hail.expr.types.TContainer.allocate(TContainer.scala:127); 	at is.hail.annotations.RegionValueBuilder.fixupArray(RegionValueBuilder.scala:278); 	at is.hail.annotations.RegionValueBuilder.addRegionValue(RegionValueBuilder.scala:432); 	at is.hail.expr.MatrixMapRows$$anonfun$25$$anonfun$apply$19.apply(Relational.scala:815); 	at is.hail.expr.MatrixMapRows$$anonfun$25$$anonfun$apply$19.apply(Relational.scala:804); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.rvd,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3508#issuecomment-387563681
https://github.com/hail-is/hail/issues/3508#issuecomment-387563681:9937,Performance,concurren,concurrent,9937,at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.hasNext(OrderedRVD.scala:911); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.hasNext(OrderedRVD.scala:911); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157); 	at scala.collection.AbstractIterator.foldLeft(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.aggregate(TraversableOnce.scala:214); 	at scala.collection.AbstractIterator.aggregate(Iterator.scala:1336); 	at is.hail.sparkextras.ContextRDD$$anonfun$6$$anonfun$apply$11.apply(ContextRDD.scala:237); 	at is.hail.sparkextras.ContextRDD$$anonfun$6$$anonfun$apply$11.apply(ContextRDD.scala:235); 	at is.hail.utils.package$.using(package.scala:577); 	at is.hail.sparkextras.ContextRDD$$anonfun$6.apply(ContextRDD.scala:235); 	at is.hail.sparkextras.ContextRDD$$anonfun$6.apply(ContextRDD.scala:234); 	at scala.Function1$$anonfun$andThen$1.apply(Function1.scala:52); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3508#issuecomment-387563681
https://github.com/hail-is/hail/issues/3508#issuecomment-387563681:10022,Performance,concurren,concurrent,10022,at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.hasNext(OrderedRVD.scala:911); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.hasNext(OrderedRVD.scala:911); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157); 	at scala.collection.AbstractIterator.foldLeft(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.aggregate(TraversableOnce.scala:214); 	at scala.collection.AbstractIterator.aggregate(Iterator.scala:1336); 	at is.hail.sparkextras.ContextRDD$$anonfun$6$$anonfun$apply$11.apply(ContextRDD.scala:237); 	at is.hail.sparkextras.ContextRDD$$anonfun$6$$anonfun$apply$11.apply(ContextRDD.scala:235); 	at is.hail.utils.package$.using(package.scala:577); 	at is.hail.sparkextras.ContextRDD$$anonfun$6.apply(ContextRDD.scala:235); 	at is.hail.sparkextras.ContextRDD$$anonfun$6.apply(ContextRDD.scala:234); 	at scala.Function1$$anonfun$andThen$1.apply(Function1.scala:52); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3508#issuecomment-387563681
https://github.com/hail-is/hail/issues/3508#issuecomment-387563681:2826,Safety,abort,aborted,2826,".nt2) &; (mt.alleles[1] == mt.ss.nt1)) |; ((flip_text(mt.alleles[0]) == mt.ss.nt2) &; (flip_text(mt.alleles[1]) == mt.ss.nt1)),; mt.ss.ldpred_inf_beta); .or_missing()). # filter bgen matrixtable down to only SNPs with betas; mt = mt.filter_rows(hl.is_defined(mt.beta)). # filter bgen matrixtable to only include people in scoring sample; mt = mt.filter_cols(hl.is_defined(sampleids[mt.s])). # score sample; mt = mt.annotate_cols(prs=hl.agg.sum(mt.beta * mt.dosage)). # write out table with sample IDs and PRS scores; mt.cols().export('gs://ukbb_prs/prs/UKB_'+pheno+'_PRS_22.txt'). parser = argparse.ArgumentParser(); parser.add_argument(""--phenotype"", help=""name of the sumstat phenotype""); args = parser.parse_args(). try:; start = time.time(); main(args.phenotype); end = time.time(); message = ""Success! Job was completed in %s"" % time.strftime(""%H:%M:%S"", time.gmtime(end - start)); send_message(message); except Exception as e:; send_message(""Fail.""); ```. ""Failure Reason"":; ```; Job aborted due to stage failure: Task 98 in stage 13.0 failed 20 times, most recent failure: Lost task 98.19 in stage 13.0 (TID 22699, ccarey-sw-xt4j.c.ukbb-robinson.internal, executor 68): java.lang.NegativeArraySizeException; 	at java.util.Arrays.copyOf(Arrays.java:3236); 	at is.hail.annotations.Region.ensure(Region.scala:139); 	at is.hail.annotations.Region.allocate(Region.scala:152); 	at is.hail.annotations.Region.allocate(Region.scala:159); 	at is.hail.expr.types.TContainer.allocate(TContainer.scala:127); 	at is.hail.annotations.RegionValueBuilder.fixupArray(RegionValueBuilder.scala:278); 	at is.hail.annotations.RegionValueBuilder.addRegionValue(RegionValueBuilder.scala:432); 	at is.hail.expr.MatrixMapRows$$anonfun$25$$anonfun$apply$19.apply(Relational.scala:815); 	at is.hail.expr.MatrixMapRows$$anonfun$25$$anonfun$apply$19.apply(Relational.scala:804); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.rv",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3508#issuecomment-387563681
https://github.com/hail-is/hail/issues/3508#issuecomment-388847560:41,Security,hash,hash,41,@ce-carey Do you know which hail version hash you were running?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3508#issuecomment-388847560
https://github.com/hail-is/hail/issues/3508#issuecomment-388871629:40,Security,hash,hash,40,"@danking Unfortunately I didn't get the hash, but I was running whatever version was the default 6 days ago. Started the cluster using `--version devel --spark 2.2.0`, no specific hash specified.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3508#issuecomment-388871629
https://github.com/hail-is/hail/issues/3508#issuecomment-388871629:180,Security,hash,hash,180,"@danking Unfortunately I didn't get the hash, but I was running whatever version was the default 6 days ago. Started the cluster using `--version devel --spark 2.2.0`, no specific hash specified.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3508#issuecomment-388871629
https://github.com/hail-is/hail/issues/3516#issuecomment-388387318:7,Performance,cache,cache,7,"if you cache x before the keyby, I think it would work",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3516#issuecomment-388387318
https://github.com/hail-is/hail/pull/3518#issuecomment-388498058:143,Testability,log,log-of-breaking-changes-in-,143,nice! don't forget to make a discuss post once this goes in! (I think a post on this thread is probably sufficient?). http://discuss.hail.is/t/log-of-breaking-changes-in-0-2-beta/454/6,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3518#issuecomment-388498058
https://github.com/hail-is/hail/pull/3521#issuecomment-387199916:424,Availability,failure,failure,424,"Verified that before #3510 was merged into master, if this PR had been added to master, it would have caught the issue. The stack trace directly fingers the EmitPackDecoder, which is exactly what one would hope to happen:. ```; FatalError: AssertionError: assertion failed: PackDecoder compilation should happen on master, but happened on worker. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 3 in stage 3.0 failed 1 times, most recent failure: Lost task 3.0 in stage 3.0 (TID 18, localhost, executor driver): java.lang.AssertionError: assertion failed: PackDecoder compilation should happen on master, but happened on worker; 	at scala.Predef$.assert(Predef.scala:170); 	at is.hail.asm4s.FunctionBuilder.result(FunctionBuilder.scala:291); 	at is.hail.io.EmitPackDecoder$.apply(RowStore.scala:637); 	at is.hail.io.PackCodecSpec.buildDecoder(RowStore.scala:110); 	at is.hail.HailContext$$anonfun$10.apply(HailContext.scala:550); 	at is.hail.HailContext$$anonfun$10.apply(HailContext.scala:546); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$19.apply(ContextRDD.scala:282); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$19.apply(ContextRDD.scala:282); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3521#issuecomment-387199916
https://github.com/hail-is/hail/pull/3521#issuecomment-387199916:481,Availability,failure,failure,481,"Verified that before #3510 was merged into master, if this PR had been added to master, it would have caught the issue. The stack trace directly fingers the EmitPackDecoder, which is exactly what one would hope to happen:. ```; FatalError: AssertionError: assertion failed: PackDecoder compilation should happen on master, but happened on worker. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 3 in stage 3.0 failed 1 times, most recent failure: Lost task 3.0 in stage 3.0 (TID 18, localhost, executor driver): java.lang.AssertionError: assertion failed: PackDecoder compilation should happen on master, but happened on worker; 	at scala.Predef$.assert(Predef.scala:170); 	at is.hail.asm4s.FunctionBuilder.result(FunctionBuilder.scala:291); 	at is.hail.io.EmitPackDecoder$.apply(RowStore.scala:637); 	at is.hail.io.PackCodecSpec.buildDecoder(RowStore.scala:110); 	at is.hail.HailContext$$anonfun$10.apply(HailContext.scala:550); 	at is.hail.HailContext$$anonfun$10.apply(HailContext.scala:546); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$19.apply(ContextRDD.scala:282); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$19.apply(ContextRDD.scala:282); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3521#issuecomment-387199916
https://github.com/hail-is/hail/pull/3521#issuecomment-387199916:403,Safety,abort,aborted,403,"Verified that before #3510 was merged into master, if this PR had been added to master, it would have caught the issue. The stack trace directly fingers the EmitPackDecoder, which is exactly what one would hope to happen:. ```; FatalError: AssertionError: assertion failed: PackDecoder compilation should happen on master, but happened on worker. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 3 in stage 3.0 failed 1 times, most recent failure: Lost task 3.0 in stage 3.0 (TID 18, localhost, executor driver): java.lang.AssertionError: assertion failed: PackDecoder compilation should happen on master, but happened on worker; 	at scala.Predef$.assert(Predef.scala:170); 	at is.hail.asm4s.FunctionBuilder.result(FunctionBuilder.scala:291); 	at is.hail.io.EmitPackDecoder$.apply(RowStore.scala:637); 	at is.hail.io.PackCodecSpec.buildDecoder(RowStore.scala:110); 	at is.hail.HailContext$$anonfun$10.apply(HailContext.scala:550); 	at is.hail.HailContext$$anonfun$10.apply(HailContext.scala:546); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$19.apply(ContextRDD.scala:282); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$19.apply(ContextRDD.scala:282); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3521#issuecomment-387199916
https://github.com/hail-is/hail/pull/3521#issuecomment-387199916:240,Testability,Assert,AssertionError,240,"Verified that before #3510 was merged into master, if this PR had been added to master, it would have caught the issue. The stack trace directly fingers the EmitPackDecoder, which is exactly what one would hope to happen:. ```; FatalError: AssertionError: assertion failed: PackDecoder compilation should happen on master, but happened on worker. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 3 in stage 3.0 failed 1 times, most recent failure: Lost task 3.0 in stage 3.0 (TID 18, localhost, executor driver): java.lang.AssertionError: assertion failed: PackDecoder compilation should happen on master, but happened on worker; 	at scala.Predef$.assert(Predef.scala:170); 	at is.hail.asm4s.FunctionBuilder.result(FunctionBuilder.scala:291); 	at is.hail.io.EmitPackDecoder$.apply(RowStore.scala:637); 	at is.hail.io.PackCodecSpec.buildDecoder(RowStore.scala:110); 	at is.hail.HailContext$$anonfun$10.apply(HailContext.scala:550); 	at is.hail.HailContext$$anonfun$10.apply(HailContext.scala:546); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$19.apply(ContextRDD.scala:282); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$19.apply(ContextRDD.scala:282); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3521#issuecomment-387199916
https://github.com/hail-is/hail/pull/3521#issuecomment-387199916:256,Testability,assert,assertion,256,"Verified that before #3510 was merged into master, if this PR had been added to master, it would have caught the issue. The stack trace directly fingers the EmitPackDecoder, which is exactly what one would hope to happen:. ```; FatalError: AssertionError: assertion failed: PackDecoder compilation should happen on master, but happened on worker. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 3 in stage 3.0 failed 1 times, most recent failure: Lost task 3.0 in stage 3.0 (TID 18, localhost, executor driver): java.lang.AssertionError: assertion failed: PackDecoder compilation should happen on master, but happened on worker; 	at scala.Predef$.assert(Predef.scala:170); 	at is.hail.asm4s.FunctionBuilder.result(FunctionBuilder.scala:291); 	at is.hail.io.EmitPackDecoder$.apply(RowStore.scala:637); 	at is.hail.io.PackCodecSpec.buildDecoder(RowStore.scala:110); 	at is.hail.HailContext$$anonfun$10.apply(HailContext.scala:550); 	at is.hail.HailContext$$anonfun$10.apply(HailContext.scala:546); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$19.apply(ContextRDD.scala:282); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$19.apply(ContextRDD.scala:282); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3521#issuecomment-387199916
https://github.com/hail-is/hail/pull/3521#issuecomment-387199916:565,Testability,Assert,AssertionError,565,"Verified that before #3510 was merged into master, if this PR had been added to master, it would have caught the issue. The stack trace directly fingers the EmitPackDecoder, which is exactly what one would hope to happen:. ```; FatalError: AssertionError: assertion failed: PackDecoder compilation should happen on master, but happened on worker. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 3 in stage 3.0 failed 1 times, most recent failure: Lost task 3.0 in stage 3.0 (TID 18, localhost, executor driver): java.lang.AssertionError: assertion failed: PackDecoder compilation should happen on master, but happened on worker; 	at scala.Predef$.assert(Predef.scala:170); 	at is.hail.asm4s.FunctionBuilder.result(FunctionBuilder.scala:291); 	at is.hail.io.EmitPackDecoder$.apply(RowStore.scala:637); 	at is.hail.io.PackCodecSpec.buildDecoder(RowStore.scala:110); 	at is.hail.HailContext$$anonfun$10.apply(HailContext.scala:550); 	at is.hail.HailContext$$anonfun$10.apply(HailContext.scala:546); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$19.apply(ContextRDD.scala:282); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$19.apply(ContextRDD.scala:282); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3521#issuecomment-387199916
https://github.com/hail-is/hail/pull/3521#issuecomment-387199916:581,Testability,assert,assertion,581,"Verified that before #3510 was merged into master, if this PR had been added to master, it would have caught the issue. The stack trace directly fingers the EmitPackDecoder, which is exactly what one would hope to happen:. ```; FatalError: AssertionError: assertion failed: PackDecoder compilation should happen on master, but happened on worker. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 3 in stage 3.0 failed 1 times, most recent failure: Lost task 3.0 in stage 3.0 (TID 18, localhost, executor driver): java.lang.AssertionError: assertion failed: PackDecoder compilation should happen on master, but happened on worker; 	at scala.Predef$.assert(Predef.scala:170); 	at is.hail.asm4s.FunctionBuilder.result(FunctionBuilder.scala:291); 	at is.hail.io.EmitPackDecoder$.apply(RowStore.scala:637); 	at is.hail.io.PackCodecSpec.buildDecoder(RowStore.scala:110); 	at is.hail.HailContext$$anonfun$10.apply(HailContext.scala:550); 	at is.hail.HailContext$$anonfun$10.apply(HailContext.scala:546); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$19.apply(ContextRDD.scala:282); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$19.apply(ContextRDD.scala:282); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3521#issuecomment-387199916
https://github.com/hail-is/hail/pull/3521#issuecomment-387199916:690,Testability,assert,assert,690,"Verified that before #3510 was merged into master, if this PR had been added to master, it would have caught the issue. The stack trace directly fingers the EmitPackDecoder, which is exactly what one would hope to happen:. ```; FatalError: AssertionError: assertion failed: PackDecoder compilation should happen on master, but happened on worker. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 3 in stage 3.0 failed 1 times, most recent failure: Lost task 3.0 in stage 3.0 (TID 18, localhost, executor driver): java.lang.AssertionError: assertion failed: PackDecoder compilation should happen on master, but happened on worker; 	at scala.Predef$.assert(Predef.scala:170); 	at is.hail.asm4s.FunctionBuilder.result(FunctionBuilder.scala:291); 	at is.hail.io.EmitPackDecoder$.apply(RowStore.scala:637); 	at is.hail.io.PackCodecSpec.buildDecoder(RowStore.scala:110); 	at is.hail.HailContext$$anonfun$10.apply(HailContext.scala:550); 	at is.hail.HailContext$$anonfun$10.apply(HailContext.scala:546); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$19.apply(ContextRDD.scala:282); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$19.apply(ContextRDD.scala:282); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3521#issuecomment-387199916
https://github.com/hail-is/hail/pull/3522#issuecomment-387188320:21,Deployability,pipeline,pipeline,21,Verified on konrad's pipeline.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3522#issuecomment-387188320
https://github.com/hail-is/hail/pull/3537#issuecomment-388564861:179,Availability,down,download,179,"OK, I think I've addressed all the comments. I made some additional changes:. - pipe input file directly into tar instead of writing to disk (writing to SSDs, I get ~100MB/s/core download saturating gs://),; - report records read,; - directly create OrderedRVD instead of coercing,; - updated GenomicsDB to latest: 0.9.2-proto-3.0.0-beta-1+ed318f7e815 which involved revising GenomicsDBFeatureReader ctor call",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3537#issuecomment-388564861
https://github.com/hail-is/hail/pull/3537#issuecomment-388564861:285,Deployability,update,updated,285,"OK, I think I've addressed all the comments. I made some additional changes:. - pipe input file directly into tar instead of writing to disk (writing to SSDs, I get ~100MB/s/core download saturating gs://),; - report records read,; - directly create OrderedRVD instead of coercing,; - updated GenomicsDB to latest: 0.9.2-proto-3.0.0-beta-1+ed318f7e815 which involved revising GenomicsDBFeatureReader ctor call",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3537#issuecomment-388564861
https://github.com/hail-is/hail/pull/3546#issuecomment-388891343:133,Testability,test,tests,133,"This all looks ok to me except for the two ""global"" params. I think if you fix that both in the Compile; and the call, and it passes tests, then we're good to go.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3546#issuecomment-388891343
https://github.com/hail-is/hail/pull/3546#issuecomment-389964885:26,Testability,test,test,26,"For posterity, I ran this test:; ```python; ds = hl.read_matrix_table('gs://danking/ALL.chip.omni_broad_sanger_combined.20140818.snps.genotypes-hail-bff300d475ac.mt'); gp = (ds.group_rows_by(contig=ds.locus.contig, pos=ds.locus.position/1000); .aggregate(n_non_ref = hl.agg.count_where(ds.GT.is_non_ref()))); gp = gp.filter_entries((gp.n_non_ref != 0) & hl.is_defined(gp.n_non_ref)); gp.n_non_ref.show(); ```; ```bash; (hail) 1 dking@wmb16-359 # gsutil du -sh gs://danking/ALL.chip.omni_broad_sanger_combined.20140818.snps.genotypes-hail-bff300d475ac.mt; 1.23 GiB gs://danking/ALL.chip.omni_broad_sanger_combined.20140818.snps.genotypes-hail-bff300d475ac.mt; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3546#issuecomment-389964885
https://github.com/hail-is/hail/pull/3546#issuecomment-390226011:0,Availability,ping,ping,0,ping @rcownie,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3546#issuecomment-390226011
https://github.com/hail-is/hail/pull/3552#issuecomment-388694213:114,Testability,test,tests,114,"You're the reviewer: you're the boss. I switched to the second style. I also added missingness cases to the Scala tests, found and fixed a couple of bugs, including the FilterArray behavior (if the condition is true, even on NA elements, the NA elements should remain). Added corresponding tests.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3552#issuecomment-388694213
https://github.com/hail-is/hail/pull/3552#issuecomment-388694213:290,Testability,test,tests,290,"You're the reviewer: you're the boss. I switched to the second style. I also added missingness cases to the Scala tests, found and fixed a couple of bugs, including the FilterArray behavior (if the condition is true, even on NA elements, the NA elements should remain). Added corresponding tests.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3552#issuecomment-388694213
https://github.com/hail-is/hail/pull/3554#issuecomment-392903907:252,Testability,test,tests,252,"This PR:; * adds the IR functions listed above,; * adds an `ascending` flag to the `ArraySort` IR node, to support the `sort(array<T>,bool): array<T>` function,; * adds a thorough `ArrayFunctionsSuite`, which is my proposed model of how to organize IR tests, and; * fixes a few bugs found by the new tests, which I think were all in the array indexing functions. In particular, I made sure that the interpreter and compiler throw the same exceptions in the same cases. If there's too much going on, I don't think it would be too difficult to split into smaller pieces.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3554#issuecomment-392903907
https://github.com/hail-is/hail/pull/3554#issuecomment-392903907:300,Testability,test,tests,300,"This PR:; * adds the IR functions listed above,; * adds an `ascending` flag to the `ArraySort` IR node, to support the `sort(array<T>,bool): array<T>` function,; * adds a thorough `ArrayFunctionsSuite`, which is my proposed model of how to organize IR tests, and; * fixes a few bugs found by the new tests, which I think were all in the array indexing functions. In particular, I made sure that the interpreter and compiler throw the same exceptions in the same cases. If there's too much going on, I don't think it would be too difficult to split into smaller pieces.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3554#issuecomment-392903907
https://github.com/hail-is/hail/pull/3567#issuecomment-388563769:224,Performance,perform,performance,224,"On 100M row Table created with:. ```; import hail as hl; mt = hl.utils.range_table(10000000, n_partitions=32); mt = mt.annotate(sq = mt.idx * mt.idx, name = hl.str(mt.idx)); mt.write('long.ht', overwrite=True); ```. I timed performance. ```; In [2]: %%timeit; ...: hl.read_table('long.ht')._force_count(); ```. which was identical:. outputmetrics: 5.41 s  131 ms per loop (mean  std. dev. of 7 runs, 1 loop each); master: 5.41 s  118 ms per loop (mean  std. dev. of 7 runs, 1 loop each). Since I'm adding output metrics here, I also time writing 1M rows. Nearly identical:. master: 2.88 s  80 ms per loop (mean  std. dev. of 7 runs, 1 loop each); outputmetrics: 2.89 s  81 ms per loop (mean  std. dev. of 7 runs, 1 loop each)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3567#issuecomment-388563769
https://github.com/hail-is/hail/pull/3575#issuecomment-388949541:25,Testability,log,log-of-breaking-changes-in-,25,http://discuss.hail.is/t/log-of-breaking-changes-in-0-2-beta/454/8,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3575#issuecomment-388949541
https://github.com/hail-is/hail/pull/3582#issuecomment-389883212:37,Testability,test,tests,37,"I also feel like we should have some tests that assert correctness of very simple comparisons. Like 0 < 1, NA != 1, NA == NA. Do these exist in python?. In the pain of my recent work on contextrdd and off heap regions I've spent a lot of time reducing our test cases to actual minimal examples. It would save engineering time in the long run to add simple, tiny examples every time we make changes or add functionality.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3582#issuecomment-389883212
https://github.com/hail-is/hail/pull/3582#issuecomment-389883212:48,Testability,assert,assert,48,"I also feel like we should have some tests that assert correctness of very simple comparisons. Like 0 < 1, NA != 1, NA == NA. Do these exist in python?. In the pain of my recent work on contextrdd and off heap regions I've spent a lot of time reducing our test cases to actual minimal examples. It would save engineering time in the long run to add simple, tiny examples every time we make changes or add functionality.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3582#issuecomment-389883212
https://github.com/hail-is/hail/pull/3582#issuecomment-389883212:256,Testability,test,test,256,"I also feel like we should have some tests that assert correctness of very simple comparisons. Like 0 < 1, NA != 1, NA == NA. Do these exist in python?. In the pain of my recent work on contextrdd and off heap regions I've spent a lot of time reducing our test cases to actual minimal examples. It would save engineering time in the long run to add simple, tiny examples every time we make changes or add functionality.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3582#issuecomment-389883212
https://github.com/hail-is/hail/pull/3582#issuecomment-389883212:75,Usability,simpl,simple,75,"I also feel like we should have some tests that assert correctness of very simple comparisons. Like 0 < 1, NA != 1, NA == NA. Do these exist in python?. In the pain of my recent work on contextrdd and off heap regions I've spent a lot of time reducing our test cases to actual minimal examples. It would save engineering time in the long run to add simple, tiny examples every time we make changes or add functionality.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3582#issuecomment-389883212
https://github.com/hail-is/hail/pull/3582#issuecomment-389883212:349,Usability,simpl,simple,349,"I also feel like we should have some tests that assert correctness of very simple comparisons. Like 0 < 1, NA != 1, NA == NA. Do these exist in python?. In the pain of my recent work on contextrdd and off heap regions I've spent a lot of time reducing our test cases to actual minimal examples. It would save engineering time in the long run to add simple, tiny examples every time we make changes or add functionality.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3582#issuecomment-389883212
https://github.com/hail-is/hail/issues/3585#issuecomment-389245636:50,Availability,error,error,50,"Hi @rmporsch,. I'm sorry you're experiencing this error. I've resolved this in https://github.com/hail-is/hail/pull/3589 . After that PR is merged, it should be available in the GS bucket no more than an hour later.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3585#issuecomment-389245636
https://github.com/hail-is/hail/issues/3585#issuecomment-389245636:161,Availability,avail,available,161,"Hi @rmporsch,. I'm sorry you're experiencing this error. I've resolved this in https://github.com/hail-is/hail/pull/3589 . After that PR is merged, it should be available in the GS bucket no more than an hour later.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3585#issuecomment-389245636
https://github.com/hail-is/hail/pull/3595#issuecomment-389530695:80,Performance,queue,queue,80,"@rcownie you have to set an ""assignee"" for a PR to be placed in the appropriate queue on https://hail.is/tools/pr-scorecard.html, I've assigned cseed to this one for you.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3595#issuecomment-389530695
https://github.com/hail-is/hail/pull/3595#issuecomment-390062140:107,Availability,down,down,107,"The NativePtr test runs fine as a single test, but it fails when I run all the tests. I'm trying to track; down the problem. Somehow the (anonymous) global data in NativePtr.cpp is getting corrupted.; I can make it pass tests by reinitializing that data, but I really want to figure out how it gets corrupted; because that could cause trouble elsewhere.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3595#issuecomment-390062140
https://github.com/hail-is/hail/pull/3595#issuecomment-390062140:14,Testability,test,test,14,"The NativePtr test runs fine as a single test, but it fails when I run all the tests. I'm trying to track; down the problem. Somehow the (anonymous) global data in NativePtr.cpp is getting corrupted.; I can make it pass tests by reinitializing that data, but I really want to figure out how it gets corrupted; because that could cause trouble elsewhere.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3595#issuecomment-390062140
https://github.com/hail-is/hail/pull/3595#issuecomment-390062140:41,Testability,test,test,41,"The NativePtr test runs fine as a single test, but it fails when I run all the tests. I'm trying to track; down the problem. Somehow the (anonymous) global data in NativePtr.cpp is getting corrupted.; I can make it pass tests by reinitializing that data, but I really want to figure out how it gets corrupted; because that could cause trouble elsewhere.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3595#issuecomment-390062140
https://github.com/hail-is/hail/pull/3595#issuecomment-390062140:79,Testability,test,tests,79,"The NativePtr test runs fine as a single test, but it fails when I run all the tests. I'm trying to track; down the problem. Somehow the (anonymous) global data in NativePtr.cpp is getting corrupted.; I can make it pass tests by reinitializing that data, but I really want to figure out how it gets corrupted; because that could cause trouble elsewhere.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3595#issuecomment-390062140
https://github.com/hail-is/hail/pull/3595#issuecomment-390062140:220,Testability,test,tests,220,"The NativePtr test runs fine as a single test, but it fails when I run all the tests. I'm trying to track; down the problem. Somehow the (anonymous) global data in NativePtr.cpp is getting corrupted.; I can make it pass tests by reinitializing that data, but I really want to figure out how it gets corrupted; because that could cause trouble elsewhere.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3595#issuecomment-390062140
https://github.com/hail-is/hail/pull/3609#issuecomment-390215942:2,Testability,test,tested,2,"I tested it against this:. ```; ht = hl.read_table('gs://danking/ALL.chip.omni_broad_sanger_combined.20140818.snps.genotypes-hail-bff300d475ac-sites.t'); context_mt = hl.read_matrix_table('gs://danking/ALL.chip.omni_broad_sanger_combined.20140818.snps.genotypes-hail-bff300d475ac.mt'); ht.annotate(**context_mt[ht.key, :])._force_count(); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3609#issuecomment-390215942
https://github.com/hail-is/hail/pull/3610#issuecomment-389733708:79,Testability,test,test,79,"It didn't fail, it failed IR conversion. I don't have an automated strategy to test if something is going through the IR or not. In this case, I verified it works by checking the log for the Fraction IR.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3610#issuecomment-389733708
https://github.com/hail-is/hail/pull/3610#issuecomment-389733708:179,Testability,log,log,179,"It didn't fail, it failed IR conversion. I don't have an automated strategy to test if something is going through the IR or not. In this case, I verified it works by checking the log for the Fraction IR.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3610#issuecomment-389733708
https://github.com/hail-is/hail/pull/3611#issuecomment-389940384:45,Testability,log,logic,45,"Thanks for the feedback, I've simplified the logic, made the python test more comprehensive, and made element retrieval more direct and applicable to sparse block matrices. I'll clarify that the latter is supported in the sparse case as soon as #3539 goes in.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3611#issuecomment-389940384
https://github.com/hail-is/hail/pull/3611#issuecomment-389940384:68,Testability,test,test,68,"Thanks for the feedback, I've simplified the logic, made the python test more comprehensive, and made element retrieval more direct and applicable to sparse block matrices. I'll clarify that the latter is supported in the sparse case as soon as #3539 goes in.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3611#issuecomment-389940384
https://github.com/hail-is/hail/pull/3611#issuecomment-389940384:15,Usability,feedback,feedback,15,"Thanks for the feedback, I've simplified the logic, made the python test more comprehensive, and made element retrieval more direct and applicable to sparse block matrices. I'll clarify that the latter is supported in the sparse case as soon as #3539 goes in.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3611#issuecomment-389940384
https://github.com/hail-is/hail/pull/3611#issuecomment-389940384:30,Usability,simpl,simplified,30,"Thanks for the feedback, I've simplified the logic, made the python test more comprehensive, and made element retrieval more direct and applicable to sparse block matrices. I'll clarify that the latter is supported in the sparse case as soon as #3539 goes in.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3611#issuecomment-389940384
https://github.com/hail-is/hail/issues/3612#issuecomment-389885493:187,Performance,perform,performance,187,"I think Tim is right about the cause. And I prefer to keep no default entry so that users arent surprised that theyve lost information from the bgen. And the docs already say For best performance, include precisely those fields required for your analysis.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3612#issuecomment-389885493
https://github.com/hail-is/hail/issues/3612#issuecomment-389888267:11,Performance,perform,performance,11,"> For best performance, include precisely those fields required for your analysis. We'll be able to do this automatically very soon.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3612#issuecomment-389888267
https://github.com/hail-is/hail/pull/3613#issuecomment-390661244:31,Testability,test,test,31,@jigold I removed the pca_join test here. Might make more sense for that change to be part of the pca test rework.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3613#issuecomment-390661244
https://github.com/hail-is/hail/pull/3613#issuecomment-390661244:102,Testability,test,test,102,@jigold I removed the pca_join test here. Might make more sense for that change to be part of the pca test rework.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3613#issuecomment-390661244
https://github.com/hail-is/hail/pull/3620#issuecomment-390841993:101,Availability,failure,failure,101,"@tpoterba I had everything working locally, but hadn't updated master. Unfortunately, there's a test failure in the new test you added for `index_globals` and I can't figure out how to fix it. I tried creating the environment separately and the `pli` field was there. Could you please take a look?. ```; _____________ [doctest] hail.matrixtable.MatrixTable.index_globals _____________; [gw0] darwin -- Python 3.6.1 //anaconda/envs/py36/bin/python; UNEXPECTED EXCEPTION: AttributeError(""StructExpression instance has no field, method, or property 'pli'\n Hint: use 'describe()' to show the names of all data fields."",); Traceback (most recent call last):. File ""//anaconda/envs/py36/lib/python3.6/doctest.py"", line 1330, in __run; compileflags, 1), test.globs). File ""<doctest hail.matrixtable.MatrixTable.index_globals[0]>"", line 1, in <module>. File ""/Users/jigold/hail/build/tmp/doctest/python/hail/expr/expressions/typed_expressions.py"", line 1161, in __getattr__; raise AttributeError(get_nice_attr_error(self, item)). AttributeError: StructExpression instance has no field, method, or property 'pli'; Hint: use 'describe()' to show the names of all data fields. /Users/jigold/hail/build/tmp/doctest/python/hail/matrixtable.py:2197: UnexpectedException; ============== 1 failed, 420 passed, 13 skipped in 79.03 seconds ===============; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3620#issuecomment-390841993
https://github.com/hail-is/hail/pull/3620#issuecomment-390841993:55,Deployability,update,updated,55,"@tpoterba I had everything working locally, but hadn't updated master. Unfortunately, there's a test failure in the new test you added for `index_globals` and I can't figure out how to fix it. I tried creating the environment separately and the `pli` field was there. Could you please take a look?. ```; _____________ [doctest] hail.matrixtable.MatrixTable.index_globals _____________; [gw0] darwin -- Python 3.6.1 //anaconda/envs/py36/bin/python; UNEXPECTED EXCEPTION: AttributeError(""StructExpression instance has no field, method, or property 'pli'\n Hint: use 'describe()' to show the names of all data fields."",); Traceback (most recent call last):. File ""//anaconda/envs/py36/lib/python3.6/doctest.py"", line 1330, in __run; compileflags, 1), test.globs). File ""<doctest hail.matrixtable.MatrixTable.index_globals[0]>"", line 1, in <module>. File ""/Users/jigold/hail/build/tmp/doctest/python/hail/expr/expressions/typed_expressions.py"", line 1161, in __getattr__; raise AttributeError(get_nice_attr_error(self, item)). AttributeError: StructExpression instance has no field, method, or property 'pli'; Hint: use 'describe()' to show the names of all data fields. /Users/jigold/hail/build/tmp/doctest/python/hail/matrixtable.py:2197: UnexpectedException; ============== 1 failed, 420 passed, 13 skipped in 79.03 seconds ===============; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3620#issuecomment-390841993
https://github.com/hail-is/hail/pull/3620#issuecomment-390841993:96,Testability,test,test,96,"@tpoterba I had everything working locally, but hadn't updated master. Unfortunately, there's a test failure in the new test you added for `index_globals` and I can't figure out how to fix it. I tried creating the environment separately and the `pli` field was there. Could you please take a look?. ```; _____________ [doctest] hail.matrixtable.MatrixTable.index_globals _____________; [gw0] darwin -- Python 3.6.1 //anaconda/envs/py36/bin/python; UNEXPECTED EXCEPTION: AttributeError(""StructExpression instance has no field, method, or property 'pli'\n Hint: use 'describe()' to show the names of all data fields."",); Traceback (most recent call last):. File ""//anaconda/envs/py36/lib/python3.6/doctest.py"", line 1330, in __run; compileflags, 1), test.globs). File ""<doctest hail.matrixtable.MatrixTable.index_globals[0]>"", line 1, in <module>. File ""/Users/jigold/hail/build/tmp/doctest/python/hail/expr/expressions/typed_expressions.py"", line 1161, in __getattr__; raise AttributeError(get_nice_attr_error(self, item)). AttributeError: StructExpression instance has no field, method, or property 'pli'; Hint: use 'describe()' to show the names of all data fields. /Users/jigold/hail/build/tmp/doctest/python/hail/matrixtable.py:2197: UnexpectedException; ============== 1 failed, 420 passed, 13 skipped in 79.03 seconds ===============; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3620#issuecomment-390841993
https://github.com/hail-is/hail/pull/3620#issuecomment-390841993:120,Testability,test,test,120,"@tpoterba I had everything working locally, but hadn't updated master. Unfortunately, there's a test failure in the new test you added for `index_globals` and I can't figure out how to fix it. I tried creating the environment separately and the `pli` field was there. Could you please take a look?. ```; _____________ [doctest] hail.matrixtable.MatrixTable.index_globals _____________; [gw0] darwin -- Python 3.6.1 //anaconda/envs/py36/bin/python; UNEXPECTED EXCEPTION: AttributeError(""StructExpression instance has no field, method, or property 'pli'\n Hint: use 'describe()' to show the names of all data fields."",); Traceback (most recent call last):. File ""//anaconda/envs/py36/lib/python3.6/doctest.py"", line 1330, in __run; compileflags, 1), test.globs). File ""<doctest hail.matrixtable.MatrixTable.index_globals[0]>"", line 1, in <module>. File ""/Users/jigold/hail/build/tmp/doctest/python/hail/expr/expressions/typed_expressions.py"", line 1161, in __getattr__; raise AttributeError(get_nice_attr_error(self, item)). AttributeError: StructExpression instance has no field, method, or property 'pli'; Hint: use 'describe()' to show the names of all data fields. /Users/jigold/hail/build/tmp/doctest/python/hail/matrixtable.py:2197: UnexpectedException; ============== 1 failed, 420 passed, 13 skipped in 79.03 seconds ===============; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3620#issuecomment-390841993
https://github.com/hail-is/hail/pull/3620#issuecomment-390841993:748,Testability,test,test,748,"@tpoterba I had everything working locally, but hadn't updated master. Unfortunately, there's a test failure in the new test you added for `index_globals` and I can't figure out how to fix it. I tried creating the environment separately and the `pli` field was there. Could you please take a look?. ```; _____________ [doctest] hail.matrixtable.MatrixTable.index_globals _____________; [gw0] darwin -- Python 3.6.1 //anaconda/envs/py36/bin/python; UNEXPECTED EXCEPTION: AttributeError(""StructExpression instance has no field, method, or property 'pli'\n Hint: use 'describe()' to show the names of all data fields."",); Traceback (most recent call last):. File ""//anaconda/envs/py36/lib/python3.6/doctest.py"", line 1330, in __run; compileflags, 1), test.globs). File ""<doctest hail.matrixtable.MatrixTable.index_globals[0]>"", line 1, in <module>. File ""/Users/jigold/hail/build/tmp/doctest/python/hail/expr/expressions/typed_expressions.py"", line 1161, in __getattr__; raise AttributeError(get_nice_attr_error(self, item)). AttributeError: StructExpression instance has no field, method, or property 'pli'; Hint: use 'describe()' to show the names of all data fields. /Users/jigold/hail/build/tmp/doctest/python/hail/matrixtable.py:2197: UnexpectedException; ============== 1 failed, 420 passed, 13 skipped in 79.03 seconds ===============; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3620#issuecomment-390841993
https://github.com/hail-is/hail/pull/3620#issuecomment-390842250:3,Testability,test,test,3,"To test locally, `./gradlew --daemon doctest`",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3620#issuecomment-390842250
https://github.com/hail-is/hail/pull/3625#issuecomment-390296315:6,Modifiability,flexible,flexible,6,~more flexible~ more better,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3625#issuecomment-390296315
https://github.com/hail-is/hail/pull/3625#issuecomment-390310387:12,Testability,test,test,12,I removed a test that asserted it didn't work on datasets with unknown fields. Maybe we should print a warning with the list of fields that weren't modified?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3625#issuecomment-390310387
https://github.com/hail-is/hail/pull/3625#issuecomment-390310387:22,Testability,assert,asserted,22,I removed a test that asserted it didn't work on datasets with unknown fields. Maybe we should print a warning with the list of fields that weren't modified?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3625#issuecomment-390310387
https://github.com/hail-is/hail/pull/3629#issuecomment-392932165:142,Availability,error,error,142,"Btw the docs say `If `mt` contains an entry field `GT` of type :py:data:`.tcall`, then the following fields are computed:` but the code would error out if it didn't have it",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3629#issuecomment-392932165
https://github.com/hail-is/hail/pull/3629#issuecomment-392957336:48,Testability,log,log-of-breaking-changes-in-,48,"Oh, breaking change  http://discuss.hail.is/t/log-of-breaking-changes-in-0-2-beta/454",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3629#issuecomment-392957336
https://github.com/hail-is/hail/pull/3637#issuecomment-392147738:2025,Availability,Error,Error,2025,"text_mt_path).drop('a_index', 'was_split'); context_mt = context_mt.annotate_rows(vep=context_mt.vep.drop('colocated_variants')); context_mt = hl.filter_intervals(context_mt, [hl.parse_locus_interval('1-22')]); ht.annotate(**context_mt[ht.key, :]).write(output_ht_path, overwrite); ```; gives:; ```; Java stack trace:; java.lang.ArrayIndexOutOfBoundsException: 1; at is.hail.annotations.Annotation$$anonfun$copy$1.apply(Annotation.scala:46); at is.hail.annotations.Annotation$$anonfun$copy$1.apply(Annotation.scala:46); at scala.Array$.tabulate(Array.scala:331); at is.hail.annotations.Annotation$.copy(Annotation.scala:46); at is.hail.rvd.OrderedRVDPartitioner.enlargeToRange(OrderedRVDPartitioner.scala:133); at is.hail.rvd.KeyedOrderedRVD.orderedJoin(KeyedOrderedRVD.scala:35); at is.hail.rvd.OrderedRVD.orderedJoin(OrderedRVD.scala:119); at is.hail.expr.TableJoin.execute(Relational.scala:1828); at is.hail.expr.TableMapRows.execute(Relational.scala:1859); at is.hail.expr.ir.Interpret$.apply(Interpret.scala:465); at is.hail.expr.ir.Interpret$.apply(Interpret.scala:39); at is.hail.expr.ir.Interpret$.apply(Interpret.scala:15); at is.hail.table.Table.write(Table.scala:899); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); at py4j.Gateway.invoke(Gateway.java:280); at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); at py4j.commands.CallCommand.execute(CallCommand.java:79); at py4j.GatewayConnection.run(GatewayConnection.java:214); at java.lang.Thread.run(Thread.java:748). Hail version: devel-ce257b532e2c; Error summary: ArrayIndexOutOfBoundsException: 1; ```; (this doesn't happen on master)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3637#issuecomment-392147738
https://github.com/hail-is/hail/pull/3637#issuecomment-392746870:106,Availability,mask,masked,106,"This ArrayIndexOutOfBounds is caused by a larger design flaw in Tables and ordering, which was previously masked by the horrible coerce-or-shuffle-every-time we were doing. Will try to nail it down today.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3637#issuecomment-392746870
https://github.com/hail-is/hail/pull/3637#issuecomment-392746870:193,Availability,down,down,193,"This ArrayIndexOutOfBounds is caused by a larger design flaw in Tables and ordering, which was previously masked by the horrible coerce-or-shuffle-every-time we were doing. Will try to nail it down today.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3637#issuecomment-392746870
https://github.com/hail-is/hail/issues/3639#issuecomment-391115483:6,Usability,clear,clear,6,"To be clear `.select_globals()` fixes the problem, but...",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3639#issuecomment-391115483
https://github.com/hail-is/hail/issues/3641#issuecomment-391440637:0,Deployability,UPDATE,UPDATE,0,"UPDATE:; It's not shuffling region values, but we're still doing a full shuffle to reorder instead of doing a map-side combine. This is _very_ bad. Take the case that you're aggregating to a single key -- this will shuffle ALL THE DATA into a single partition.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3641#issuecomment-391440637
https://github.com/hail-is/hail/issues/3645#issuecomment-391497730:264,Energy Efficiency,efficient,efficient,264,"The current execution of ; ```; mt.group_rows_by(mt.gene); .aggregate(...); ```; will be emitted as a `MatrixMapRows` (to re-key) followed by a `MatrixAggregateRowsByKey`. This means that the dataset will be shuffled _in full_ to re-sort by gene, before doing the efficient collapsing in `MatrixAggregateRowsByKey`. This is really bad. We need to be doing map-side combines. The preferred execution would be one of two options:; 1. scan to compute the OrderedPartitioner for the new key. Aggregate to this partitioner.; 2. Aggregate to a HashPartitioner. Both of these things involve new map-side combiner architecture which we haven't built yet, but this is important.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3645#issuecomment-391497730
https://github.com/hail-is/hail/issues/3645#issuecomment-391497730:538,Security,Hash,HashPartitioner,538,"The current execution of ; ```; mt.group_rows_by(mt.gene); .aggregate(...); ```; will be emitted as a `MatrixMapRows` (to re-key) followed by a `MatrixAggregateRowsByKey`. This means that the dataset will be shuffled _in full_ to re-sort by gene, before doing the efficient collapsing in `MatrixAggregateRowsByKey`. This is really bad. We need to be doing map-side combines. The preferred execution would be one of two options:; 1. scan to compute the OrderedPartitioner for the new key. Aggregate to this partitioner.; 2. Aggregate to a HashPartitioner. Both of these things involve new map-side combiner architecture which we haven't built yet, but this is important.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3645#issuecomment-391497730
https://github.com/hail-is/hail/issues/3648#issuecomment-391577744:65,Testability,assert,asserts,65,Also that step=0 fails (@patrick-schultz has some nice exception asserts coming for the IR tests),MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3648#issuecomment-391577744
https://github.com/hail-is/hail/issues/3648#issuecomment-391577744:91,Testability,test,tests,91,Also that step=0 fails (@patrick-schultz has some nice exception asserts coming for the IR tests),MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3648#issuecomment-391577744
https://github.com/hail-is/hail/pull/3655#issuecomment-397121048:163,Energy Efficiency,reduce,reduce,163,"I suggest that you might be able to debug this by tweaking in ways which stimulate the; large-block and transition-between-chunks behavior more frequently, e.g. - reduce the chunk size to 256 bytes. - maybe do two malloc()s for each chunk, to try to force malloc() to give you non-contiguous; addresses.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3655#issuecomment-397121048
https://github.com/hail-is/hail/pull/3662#issuecomment-392173394:47,Security,expose,exposed,47,"@tpoterba I realized that hl.index is actually exposed in python, so I added it back in. I don't think it's documented, though.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3662#issuecomment-392173394
https://github.com/hail-is/hail/pull/3667#issuecomment-392303741:98,Performance,perform,performance,98,"I pushed some addition changes: push requestedType into TableRead, expose (private) in Python for performance testing. On a chunk of gnomAD sites file, read count went from 19s (all fields) to 12s (keys + 1 int field). The Python changes should get removed once prune dead fields goes in. MatrixRead will require a bit more work (with the recent unification of matrix read/import IR nodes).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3667#issuecomment-392303741
https://github.com/hail-is/hail/pull/3667#issuecomment-392303741:67,Security,expose,expose,67,"I pushed some addition changes: push requestedType into TableRead, expose (private) in Python for performance testing. On a chunk of gnomAD sites file, read count went from 19s (all fields) to 12s (keys + 1 int field). The Python changes should get removed once prune dead fields goes in. MatrixRead will require a bit more work (with the recent unification of matrix read/import IR nodes).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3667#issuecomment-392303741
https://github.com/hail-is/hail/pull/3667#issuecomment-392303741:110,Testability,test,testing,110,"I pushed some addition changes: push requestedType into TableRead, expose (private) in Python for performance testing. On a chunk of gnomAD sites file, read count went from 19s (all fields) to 12s (keys + 1 int field). The Python changes should get removed once prune dead fields goes in. MatrixRead will require a bit more work (with the recent unification of matrix read/import IR nodes).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3667#issuecomment-392303741
https://github.com/hail-is/hail/issues/3668#issuecomment-392342812:94,Availability,down,downsamplings,94,"The output of ht.describe():; ```. ----------------------------------------; Global fields:; 'downsamplings': array<int32> ; ----------------------------------------; Row fields:; 'locus': locus<GRCh37> ; 'alleles': array<str> ; 'freq': array<struct {; AC: array<int32>, ; AF: array<float64>, ; AN: int32, ; homozygote_count: array<int32>, ; meta: dict<str, str>; }> ; 'project_max': array<struct {; AC: array<int32>, ; AF: array<float64>, ; AN: int32, ; homozygote_count: array<int32>, ; project: str; }> ; ----------------------------------------; Key: ['locus', 'alleles']; ----------------------------------------; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3668#issuecomment-392342812
https://github.com/hail-is/hail/pull/3669#issuecomment-392413464:0,Deployability,Update,Updated,0,"Updated to break up struct construction when building the decoder. Tweaks the size estimates so the method size is 2-4K on some large examples. @tpoterba @konradjk I retimed loading a small subset of fields with this change. I'm not quite sure why things changed so much, but I now see about 4.5x improvement on read, which is more in line with (and even better than) what I was hoping:. ```; In [2]: t = hl.read_table('sites.ht', _row_fields=['locus', 'alleles', 'AN_AFR']). In [3]: %%timeit; ...: t._force_count(); ...: ; 3.43 s  54.6 ms per loop (mean  std. dev. of 7 runs, 1 loop each). In [4]: t = hl.read_table('sites.ht'). In [5]: %%timeit; ...: t._force_count(); ...: ; 15.3 s  45.6 ms per loop (mean  std. dev. of 7 runs, 1 loop each); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3669#issuecomment-392413464
https://github.com/hail-is/hail/pull/3669#issuecomment-392413464:174,Performance,load,loading,174,"Updated to break up struct construction when building the decoder. Tweaks the size estimates so the method size is 2-4K on some large examples. @tpoterba @konradjk I retimed loading a small subset of fields with this change. I'm not quite sure why things changed so much, but I now see about 4.5x improvement on read, which is more in line with (and even better than) what I was hoping:. ```; In [2]: t = hl.read_table('sites.ht', _row_fields=['locus', 'alleles', 'AN_AFR']). In [3]: %%timeit; ...: t._force_count(); ...: ; 3.43 s  54.6 ms per loop (mean  std. dev. of 7 runs, 1 loop each). In [4]: t = hl.read_table('sites.ht'). In [5]: %%timeit; ...: t._force_count(); ...: ; 15.3 s  45.6 ms per loop (mean  std. dev. of 7 runs, 1 loop each); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3669#issuecomment-392413464
https://github.com/hail-is/hail/pull/3669#issuecomment-392413962:119,Energy Efficiency,allocate,allocate,119,"@catoverdrive FYI, I had to switch two newLocal to newField in StagedRegionValueBuilder. This is because if you try to allocate in a new method builder (inside wrapToMethod, say), the local will go into the method builder the SRVB was originally constructed with which is the wrong one. Probably SRVB should not have a method builder but a class builder and allocate should take the MethodBuilder we're emitting the allocation into.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3669#issuecomment-392413962
https://github.com/hail-is/hail/pull/3669#issuecomment-392413962:358,Energy Efficiency,allocate,allocate,358,"@catoverdrive FYI, I had to switch two newLocal to newField in StagedRegionValueBuilder. This is because if you try to allocate in a new method builder (inside wrapToMethod, say), the local will go into the method builder the SRVB was originally constructed with which is the wrong one. Probably SRVB should not have a method builder but a class builder and allocate should take the MethodBuilder we're emitting the allocation into.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3669#issuecomment-392413962
https://github.com/hail-is/hail/pull/3669#issuecomment-392413962:160,Integrability,wrap,wrapToMethod,160,"@catoverdrive FYI, I had to switch two newLocal to newField in StagedRegionValueBuilder. This is because if you try to allocate in a new method builder (inside wrapToMethod, say), the local will go into the method builder the SRVB was originally constructed with which is the wrong one. Probably SRVB should not have a method builder but a class builder and allocate should take the MethodBuilder we're emitting the allocation into.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3669#issuecomment-392413962
https://github.com/hail-is/hail/pull/3671#issuecomment-392871508:163,Energy Efficiency,reduce,reduce,163,"Ok, I've split out the element-wise special ops to their own test so now there are two logical groups. I also moved assert_eq and assert_close to the top level to reduce repetitive defs and `self.assertTrue(np.array_equal(...to.numpy(),...)`. Plus a bit more structure in the top docs.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3671#issuecomment-392871508
https://github.com/hail-is/hail/pull/3671#issuecomment-392871508:61,Testability,test,test,61,"Ok, I've split out the element-wise special ops to their own test so now there are two logical groups. I also moved assert_eq and assert_close to the top level to reduce repetitive defs and `self.assertTrue(np.array_equal(...to.numpy(),...)`. Plus a bit more structure in the top docs.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3671#issuecomment-392871508
https://github.com/hail-is/hail/pull/3671#issuecomment-392871508:87,Testability,log,logical,87,"Ok, I've split out the element-wise special ops to their own test so now there are two logical groups. I also moved assert_eq and assert_close to the top level to reduce repetitive defs and `self.assertTrue(np.array_equal(...to.numpy(),...)`. Plus a bit more structure in the top docs.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3671#issuecomment-392871508
https://github.com/hail-is/hail/pull/3671#issuecomment-392871508:196,Testability,assert,assertTrue,196,"Ok, I've split out the element-wise special ops to their own test so now there are two logical groups. I also moved assert_eq and assert_close to the top level to reduce repetitive defs and `self.assertTrue(np.array_equal(...to.numpy(),...)`. Plus a bit more structure in the top docs.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3671#issuecomment-392871508
https://github.com/hail-is/hail/issues/3673#issuecomment-392912868:45,Availability,error,error,45,The only related problem I can find is a bad error when trying to drop a key field from tables.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3673#issuecomment-392912868
https://github.com/hail-is/hail/issues/3673#issuecomment-392915045:14,Availability,error,error,14,"actually that error isn't even so bad, it says ""drop"" in it. I'm closing this! ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3673#issuecomment-392915045
https://github.com/hail-is/hail/issues/3673#issuecomment-392915822:17,Availability,error,error,17,"Wait, there's no error. Shouldn't this drop alleles though? Transmute I thought did...",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3673#issuecomment-392915822
https://github.com/hail-is/hail/issues/3685#issuecomment-393174426:154,Performance,load,load,154,"Oh, that's a dumb and easily fixed bug. Sorry about that. The enlargeToRange should only be used for right and outer joins. With that fixed, it will only load partitions from the right that could possibly overlap those of the left. There is definitely room for optimization in making a smart choice of partitioner for the join result, not just using the (possibly enlarged) left partitioner, but that is a harder problem.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3685#issuecomment-393174426
https://github.com/hail-is/hail/issues/3685#issuecomment-393174426:261,Performance,optimiz,optimization,261,"Oh, that's a dumb and easily fixed bug. Sorry about that. The enlargeToRange should only be used for right and outer joins. With that fixed, it will only load partitions from the right that could possibly overlap those of the left. There is definitely room for optimization in making a smart choice of partitioner for the join result, not just using the (possibly enlarged) left partitioner, but that is a harder problem.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3685#issuecomment-393174426
https://github.com/hail-is/hail/issues/3690#issuecomment-393366147:32,Performance,optimiz,optimize,32,This actually lets us compile / optimize across aggregations!,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3690#issuecomment-393366147
https://github.com/hail-is/hail/pull/3694#issuecomment-401136470:161,Safety,safe,safe,161,"I backed out the more subtle pieces to get a basic sort on write in now. Sorry, I should have done that sooner. When I didn't have an easy answer for why it was safe to remove that requirement, I realized I needed to do some work solidifying the partitioner semantics. I'm getting closer on that front, but I'm constantly amazed how tricky it is!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3694#issuecomment-401136470
https://github.com/hail-is/hail/issues/3696#issuecomment-393678445:128,Availability,error,error,128,@tpoterba is it obvious why this went wrong? Are `case` expressions allowed to have missing default statements (and we throw an error if we don't match anything?),MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3696#issuecomment-393678445
https://github.com/hail-is/hail/issues/3696#issuecomment-393680136:23,Availability,error,error,23,We could throw a nicer error,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3696#issuecomment-393680136
https://github.com/hail-is/hail/pull/3697#issuecomment-393889443:376,Availability,failure,failures,376,"I changed the block_size to default (4096) because a 1024 means 4x the number of open files per task for `BlockMatrix.write_from_entry_expr`. On UKBB, that's about 500 open files, each with its own write buffer (64MB on by default on GCP) so Hadoop fails spectacularly. Liam reports that `ld_prune` succeeds with 50k samples (and ~280k markers), and succeeds but with lots of failures with 75k samples, and fails completely with 100k samples. He just tried again with 459k samples reducing the write buffer size to 1MB, and it still failed there, but I'm hopeful the larger block size will help. We'll try 100k again soon.; ` --properties 'core:fs.gs.io.buffersize.write=1048576,core:fs.gs.io.buffersize=8388608' \`",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3697#issuecomment-393889443
https://github.com/hail-is/hail/pull/3697#issuecomment-393929082:103,Testability,assert,assertion,103,"In `relativeUpperIndexBounds`, the positions won't be sorted unless we sort them, so that cannot be an assertion. Yes, re-keying by contig means we don't have a guarantee that the positions aren't re-ordered within their groups, but since we sort inside `relativeUpperIndexBounds`, this ensures that they are sorted and that they therefore match the ordering in the block matrix. The sorting doesn't screw up the alignment with the block matrix, because the sorting is what guarantees the alignment with the block matrix.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3697#issuecomment-393929082
https://github.com/hail-is/hail/pull/3697#issuecomment-393947795:132,Availability,failure,failure,132,"@maccum I made block_size an optional parameter, can you take a quick look before i merge? Using the larger block size fixed hadoop failure in UKBB case, but a smaller block size may still be preferable for fewer samples to increase write parallelism, so best to make it settable.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3697#issuecomment-393947795
https://github.com/hail-is/hail/pull/3697#issuecomment-393976813:136,Availability,error,errors,136,"This looks fine. Could possibly put something in the Notes section of the docs to address changing block size if folks are running into errors with Hadoop, but if most people will be successful with the default, then I guess it's not necessary.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3697#issuecomment-393976813
https://github.com/hail-is/hail/pull/3697#issuecomment-394003822:127,Availability,error,error,127,"I've reworked the docs, breaking the description into three stages and describing strategies for dealing with the Hadoop write error.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3697#issuecomment-394003822
https://github.com/hail-is/hail/pull/3698#issuecomment-393986893:0,Availability,ping,ping,0,ping @jigold would be stellar if you can look at it before end of day today :3,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3698#issuecomment-393986893
https://github.com/hail-is/hail/issues/3699#issuecomment-550356741:101,Deployability,integrat,integration,101,I'll pick this one up in medium term since NDArray stuff has involved a lot of fleshing out of numpy integration,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3699#issuecomment-550356741
https://github.com/hail-is/hail/issues/3699#issuecomment-550356741:101,Integrability,integrat,integration,101,I'll pick this one up in medium term since NDArray stuff has involved a lot of fleshing out of numpy integration,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3699#issuecomment-550356741
https://github.com/hail-is/hail/pull/3700#issuecomment-394033932:114,Availability,error,error,114,@jigold could your recent changes have prevented doctest from flagging this? Erm. Well. This must be a really old error.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3700#issuecomment-394033932
https://github.com/hail-is/hail/pull/3704#issuecomment-394407542:250,Deployability,update,updated,250,"@jbloom22 This line is wrong:; https://github.com/hail-is/hail/blob/master/src/main/scala/is/hail/utils/Graph.scala#L80; `l` and `r` should be tuples (i.e. rows). When the IR route was added, it was modified to take tuples, but the AST route was not updated.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3704#issuecomment-394407542
https://github.com/hail-is/hail/pull/3704#issuecomment-394407542:175,Integrability,rout,route,175,"@jbloom22 This line is wrong:; https://github.com/hail-is/hail/blob/master/src/main/scala/is/hail/utils/Graph.scala#L80; `l` and `r` should be tuples (i.e. rows). When the IR route was added, it was modified to take tuples, but the AST route was not updated.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3704#issuecomment-394407542
https://github.com/hail-is/hail/pull/3704#issuecomment-394407542:236,Integrability,rout,route,236,"@jbloom22 This line is wrong:; https://github.com/hail-is/hail/blob/master/src/main/scala/is/hail/utils/Graph.scala#L80; `l` and `r` should be tuples (i.e. rows). When the IR route was added, it was modified to take tuples, but the AST route was not updated.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3704#issuecomment-394407542
https://github.com/hail-is/hail/pull/3704#issuecomment-394413114:129,Testability,test,test,129,"@maccum you were right that there are multiple variants at the same position, so `position = 0` can filter. (this also means the test for `r2=1.0, bp_window_size=0` is getting lucky, since you could, in principle, have perfectly correlated variants at the same position)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3704#issuecomment-394413114
https://github.com/hail-is/hail/pull/3704#issuecomment-394434300:13,Testability,test,test,13,"Yes, so that test should be rewritten. We could manufacture a small dataset inline to run it on.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3704#issuecomment-394434300
https://github.com/hail-is/hail/pull/3704#issuecomment-394866711:15,Testability,test,test,15,I switched the test to use a balding_nichols_model dataset (positions are unique) with `r2=0.1`.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3704#issuecomment-394866711
https://github.com/hail-is/hail/pull/3704#issuecomment-395110967:78,Integrability,rout,route,78,What's the plan to address the bug you found in maximal independent set's AST route?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3704#issuecomment-395110967
https://github.com/hail-is/hail/pull/3704#issuecomment-395117104:171,Performance,perform,performance,171,"It's good that you documented it in #3706. When fixed I can simplify `tie_breaker` to `hl.signum(r.twice_maf - l.twice_maf)`, but I don't expect that to make a noticeable performance difference in the scheme of the full computation so it's not my highest priority.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3704#issuecomment-395117104
https://github.com/hail-is/hail/pull/3704#issuecomment-395117104:60,Usability,simpl,simplify,60,"It's good that you documented it in #3706. When fixed I can simplify `tie_breaker` to `hl.signum(r.twice_maf - l.twice_maf)`, but I don't expect that to make a noticeable performance difference in the scheme of the full computation so it's not my highest priority.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3704#issuecomment-395117104
https://github.com/hail-is/hail/issues/3706#issuecomment-394395696:601,Integrability,wrap,wrapper,601,"Actually, it's even more broken. it expects there to be fields called `i` and `j`.; ```; import hail as hl; t = hl.utils.range_table(10); t = t.annotate(foo= t.idx // 2); hl.methods.maximal_independent_set(t.idx, t.foo, tie_breaker = lambda i, j: hl.signum(i - j)) ; ```; ```; ---------------------------------------------------------------------------; LookupError Traceback (most recent call last); <ipython-input-11-de5acf23a36f> in <module>(); ----> 1 hl.methods.maximal_independent_set(t.idx, t.foo, tie_breaker = lambda i, j: hl.signum(i - j)). ~/projects/hail/python/hail/typecheck/check.py in wrapper(*args, **kwargs); 545 def wrapper(*args, **kwargs):; 546 args_, kwargs_ = check_all(f, args, kwargs, checkers, is_method=is_method); --> 547 return f(*args_, **kwargs_); 548 ; 549 update_wrapper(wrapper, f). ~/projects/hail/python/hail/methods/misc.py in maximal_independent_set(i, j, keep, tie_breaker); 139 .select()); 140 ; --> 141 edges = t.key_by(None).select('i', 'j'); 142 nodes_in_set = Env.hail().utils.Graph.maximalIndependentSet(edges._jt.collect(), node_t._jtype, joption(tie_breaker_hql)); 143 . ~/projects/hail/python/hail/typecheck/check.py in wrapper(*args, **kwargs); 545 def wrapper(*args, **kwargs):; 546 args_, kwargs_ = check_all(f, args, kwargs, checkers, is_method=is_method); --> 547 return f(*args_, **kwargs_); 548 ; 549 update_wrapper(wrapper, f). ~/projects/hail/python/hail/table.py in select(self, *exprs, **named_exprs); 863 row = get_select_exprs('Table.select',; 864 exprs, named_exprs, self._row_indices,; --> 865 protect_keys=True); 866 return self._select('Table.select', value_struct=hl.struct(**row)); 867 . ~/projects/hail/python/hail/utils/misc.py in get_select_exprs(caller, exprs, named_exprs, indices, protect_keys); 314 def get_select_exprs(caller, exprs, named_exprs, indices, protect_keys=True):; 315 from hail.expr.expressions import to_expr, ExpressionException, TopLevelReference, Select; --> 316 exprs = [to_expr(e) if not isinstance(e, str) ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3706#issuecomment-394395696
https://github.com/hail-is/hail/issues/3706#issuecomment-394395696:635,Integrability,wrap,wrapper,635,"Actually, it's even more broken. it expects there to be fields called `i` and `j`.; ```; import hail as hl; t = hl.utils.range_table(10); t = t.annotate(foo= t.idx // 2); hl.methods.maximal_independent_set(t.idx, t.foo, tie_breaker = lambda i, j: hl.signum(i - j)) ; ```; ```; ---------------------------------------------------------------------------; LookupError Traceback (most recent call last); <ipython-input-11-de5acf23a36f> in <module>(); ----> 1 hl.methods.maximal_independent_set(t.idx, t.foo, tie_breaker = lambda i, j: hl.signum(i - j)). ~/projects/hail/python/hail/typecheck/check.py in wrapper(*args, **kwargs); 545 def wrapper(*args, **kwargs):; 546 args_, kwargs_ = check_all(f, args, kwargs, checkers, is_method=is_method); --> 547 return f(*args_, **kwargs_); 548 ; 549 update_wrapper(wrapper, f). ~/projects/hail/python/hail/methods/misc.py in maximal_independent_set(i, j, keep, tie_breaker); 139 .select()); 140 ; --> 141 edges = t.key_by(None).select('i', 'j'); 142 nodes_in_set = Env.hail().utils.Graph.maximalIndependentSet(edges._jt.collect(), node_t._jtype, joption(tie_breaker_hql)); 143 . ~/projects/hail/python/hail/typecheck/check.py in wrapper(*args, **kwargs); 545 def wrapper(*args, **kwargs):; 546 args_, kwargs_ = check_all(f, args, kwargs, checkers, is_method=is_method); --> 547 return f(*args_, **kwargs_); 548 ; 549 update_wrapper(wrapper, f). ~/projects/hail/python/hail/table.py in select(self, *exprs, **named_exprs); 863 row = get_select_exprs('Table.select',; 864 exprs, named_exprs, self._row_indices,; --> 865 protect_keys=True); 866 return self._select('Table.select', value_struct=hl.struct(**row)); 867 . ~/projects/hail/python/hail/utils/misc.py in get_select_exprs(caller, exprs, named_exprs, indices, protect_keys); 314 def get_select_exprs(caller, exprs, named_exprs, indices, protect_keys=True):; 315 from hail.expr.expressions import to_expr, ExpressionException, TopLevelReference, Select; --> 316 exprs = [to_expr(e) if not isinstance(e, str) ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3706#issuecomment-394395696
https://github.com/hail-is/hail/issues/3706#issuecomment-394395696:804,Integrability,wrap,wrapper,804,"Actually, it's even more broken. it expects there to be fields called `i` and `j`.; ```; import hail as hl; t = hl.utils.range_table(10); t = t.annotate(foo= t.idx // 2); hl.methods.maximal_independent_set(t.idx, t.foo, tie_breaker = lambda i, j: hl.signum(i - j)) ; ```; ```; ---------------------------------------------------------------------------; LookupError Traceback (most recent call last); <ipython-input-11-de5acf23a36f> in <module>(); ----> 1 hl.methods.maximal_independent_set(t.idx, t.foo, tie_breaker = lambda i, j: hl.signum(i - j)). ~/projects/hail/python/hail/typecheck/check.py in wrapper(*args, **kwargs); 545 def wrapper(*args, **kwargs):; 546 args_, kwargs_ = check_all(f, args, kwargs, checkers, is_method=is_method); --> 547 return f(*args_, **kwargs_); 548 ; 549 update_wrapper(wrapper, f). ~/projects/hail/python/hail/methods/misc.py in maximal_independent_set(i, j, keep, tie_breaker); 139 .select()); 140 ; --> 141 edges = t.key_by(None).select('i', 'j'); 142 nodes_in_set = Env.hail().utils.Graph.maximalIndependentSet(edges._jt.collect(), node_t._jtype, joption(tie_breaker_hql)); 143 . ~/projects/hail/python/hail/typecheck/check.py in wrapper(*args, **kwargs); 545 def wrapper(*args, **kwargs):; 546 args_, kwargs_ = check_all(f, args, kwargs, checkers, is_method=is_method); --> 547 return f(*args_, **kwargs_); 548 ; 549 update_wrapper(wrapper, f). ~/projects/hail/python/hail/table.py in select(self, *exprs, **named_exprs); 863 row = get_select_exprs('Table.select',; 864 exprs, named_exprs, self._row_indices,; --> 865 protect_keys=True); 866 return self._select('Table.select', value_struct=hl.struct(**row)); 867 . ~/projects/hail/python/hail/utils/misc.py in get_select_exprs(caller, exprs, named_exprs, indices, protect_keys); 314 def get_select_exprs(caller, exprs, named_exprs, indices, protect_keys=True):; 315 from hail.expr.expressions import to_expr, ExpressionException, TopLevelReference, Select; --> 316 exprs = [to_expr(e) if not isinstance(e, str) ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3706#issuecomment-394395696
https://github.com/hail-is/hail/issues/3706#issuecomment-394395696:1168,Integrability,wrap,wrapper,1168,"```; ---------------------------------------------------------------------------; LookupError Traceback (most recent call last); <ipython-input-11-de5acf23a36f> in <module>(); ----> 1 hl.methods.maximal_independent_set(t.idx, t.foo, tie_breaker = lambda i, j: hl.signum(i - j)). ~/projects/hail/python/hail/typecheck/check.py in wrapper(*args, **kwargs); 545 def wrapper(*args, **kwargs):; 546 args_, kwargs_ = check_all(f, args, kwargs, checkers, is_method=is_method); --> 547 return f(*args_, **kwargs_); 548 ; 549 update_wrapper(wrapper, f). ~/projects/hail/python/hail/methods/misc.py in maximal_independent_set(i, j, keep, tie_breaker); 139 .select()); 140 ; --> 141 edges = t.key_by(None).select('i', 'j'); 142 nodes_in_set = Env.hail().utils.Graph.maximalIndependentSet(edges._jt.collect(), node_t._jtype, joption(tie_breaker_hql)); 143 . ~/projects/hail/python/hail/typecheck/check.py in wrapper(*args, **kwargs); 545 def wrapper(*args, **kwargs):; 546 args_, kwargs_ = check_all(f, args, kwargs, checkers, is_method=is_method); --> 547 return f(*args_, **kwargs_); 548 ; 549 update_wrapper(wrapper, f). ~/projects/hail/python/hail/table.py in select(self, *exprs, **named_exprs); 863 row = get_select_exprs('Table.select',; 864 exprs, named_exprs, self._row_indices,; --> 865 protect_keys=True); 866 return self._select('Table.select', value_struct=hl.struct(**row)); 867 . ~/projects/hail/python/hail/utils/misc.py in get_select_exprs(caller, exprs, named_exprs, indices, protect_keys); 314 def get_select_exprs(caller, exprs, named_exprs, indices, protect_keys=True):; 315 from hail.expr.expressions import to_expr, ExpressionException, TopLevelReference, Select; --> 316 exprs = [to_expr(e) if not isinstance(e, str) else indices.source[e] for e in exprs]; 317 named_exprs = {k: to_expr(v) for k, v in named_exprs.items()}; 318 assignments = OrderedDict(). ~/projects/hail/python/hail/utils/misc.py in <listcomp>(.0); 314 def get_select_exprs(caller, exprs, named_exprs, indices, protect_k",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3706#issuecomment-394395696
https://github.com/hail-is/hail/issues/3706#issuecomment-394395696:1202,Integrability,wrap,wrapper,1202,"```; ---------------------------------------------------------------------------; LookupError Traceback (most recent call last); <ipython-input-11-de5acf23a36f> in <module>(); ----> 1 hl.methods.maximal_independent_set(t.idx, t.foo, tie_breaker = lambda i, j: hl.signum(i - j)). ~/projects/hail/python/hail/typecheck/check.py in wrapper(*args, **kwargs); 545 def wrapper(*args, **kwargs):; 546 args_, kwargs_ = check_all(f, args, kwargs, checkers, is_method=is_method); --> 547 return f(*args_, **kwargs_); 548 ; 549 update_wrapper(wrapper, f). ~/projects/hail/python/hail/methods/misc.py in maximal_independent_set(i, j, keep, tie_breaker); 139 .select()); 140 ; --> 141 edges = t.key_by(None).select('i', 'j'); 142 nodes_in_set = Env.hail().utils.Graph.maximalIndependentSet(edges._jt.collect(), node_t._jtype, joption(tie_breaker_hql)); 143 . ~/projects/hail/python/hail/typecheck/check.py in wrapper(*args, **kwargs); 545 def wrapper(*args, **kwargs):; 546 args_, kwargs_ = check_all(f, args, kwargs, checkers, is_method=is_method); --> 547 return f(*args_, **kwargs_); 548 ; 549 update_wrapper(wrapper, f). ~/projects/hail/python/hail/table.py in select(self, *exprs, **named_exprs); 863 row = get_select_exprs('Table.select',; 864 exprs, named_exprs, self._row_indices,; --> 865 protect_keys=True); 866 return self._select('Table.select', value_struct=hl.struct(**row)); 867 . ~/projects/hail/python/hail/utils/misc.py in get_select_exprs(caller, exprs, named_exprs, indices, protect_keys); 314 def get_select_exprs(caller, exprs, named_exprs, indices, protect_keys=True):; 315 from hail.expr.expressions import to_expr, ExpressionException, TopLevelReference, Select; --> 316 exprs = [to_expr(e) if not isinstance(e, str) else indices.source[e] for e in exprs]; 317 named_exprs = {k: to_expr(v) for k, v in named_exprs.items()}; 318 assignments = OrderedDict(). ~/projects/hail/python/hail/utils/misc.py in <listcomp>(.0); 314 def get_select_exprs(caller, exprs, named_exprs, indices, protect_k",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3706#issuecomment-394395696
https://github.com/hail-is/hail/issues/3706#issuecomment-394395696:1371,Integrability,wrap,wrapper,1371,"```; ---------------------------------------------------------------------------; LookupError Traceback (most recent call last); <ipython-input-11-de5acf23a36f> in <module>(); ----> 1 hl.methods.maximal_independent_set(t.idx, t.foo, tie_breaker = lambda i, j: hl.signum(i - j)). ~/projects/hail/python/hail/typecheck/check.py in wrapper(*args, **kwargs); 545 def wrapper(*args, **kwargs):; 546 args_, kwargs_ = check_all(f, args, kwargs, checkers, is_method=is_method); --> 547 return f(*args_, **kwargs_); 548 ; 549 update_wrapper(wrapper, f). ~/projects/hail/python/hail/methods/misc.py in maximal_independent_set(i, j, keep, tie_breaker); 139 .select()); 140 ; --> 141 edges = t.key_by(None).select('i', 'j'); 142 nodes_in_set = Env.hail().utils.Graph.maximalIndependentSet(edges._jt.collect(), node_t._jtype, joption(tie_breaker_hql)); 143 . ~/projects/hail/python/hail/typecheck/check.py in wrapper(*args, **kwargs); 545 def wrapper(*args, **kwargs):; 546 args_, kwargs_ = check_all(f, args, kwargs, checkers, is_method=is_method); --> 547 return f(*args_, **kwargs_); 548 ; 549 update_wrapper(wrapper, f). ~/projects/hail/python/hail/table.py in select(self, *exprs, **named_exprs); 863 row = get_select_exprs('Table.select',; 864 exprs, named_exprs, self._row_indices,; --> 865 protect_keys=True); 866 return self._select('Table.select', value_struct=hl.struct(**row)); 867 . ~/projects/hail/python/hail/utils/misc.py in get_select_exprs(caller, exprs, named_exprs, indices, protect_keys); 314 def get_select_exprs(caller, exprs, named_exprs, indices, protect_keys=True):; 315 from hail.expr.expressions import to_expr, ExpressionException, TopLevelReference, Select; --> 316 exprs = [to_expr(e) if not isinstance(e, str) else indices.source[e] for e in exprs]; 317 named_exprs = {k: to_expr(v) for k, v in named_exprs.items()}; 318 assignments = OrderedDict(). ~/projects/hail/python/hail/utils/misc.py in <listcomp>(.0); 314 def get_select_exprs(caller, exprs, named_exprs, indices, protect_k",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3706#issuecomment-394395696
https://github.com/hail-is/hail/pull/3718#issuecomment-396297556:945,Safety,avoid,avoided,945,"I have a fairly bad case of PTSD around over-use of std::unique_ptr and std::move at; Oracle/Endeca. I think std::unique_ptr<T> is deeply confusing and evil because, in the; simplest terms, it doesn't have the normal semantics of a ""pointer"", i.e. two or more pointers; can refer to a single object. And that problem becomes massively aggravated in the; almost-universal situation of ""borrowing"" a pointer for the duration of a procedure call. Once you let std::unique_ptr<T> into your code, it can creep out into a whole lot of places; where it adds complexity and confusion without solving any real problem. In this particular case, the complexity of managing the memory chunks isn't that hard,; they all get cleaned up by the Region destructor, and adding another layer of software; with the Chunk class seems to obscure rather than clarify what is happening. C++11 added some wonderful features, and some lousy ones. std::unique_ptr is best avoided.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3718#issuecomment-396297556
https://github.com/hail-is/hail/pull/3718#issuecomment-396297556:174,Usability,simpl,simplest,174,"I have a fairly bad case of PTSD around over-use of std::unique_ptr and std::move at; Oracle/Endeca. I think std::unique_ptr<T> is deeply confusing and evil because, in the; simplest terms, it doesn't have the normal semantics of a ""pointer"", i.e. two or more pointers; can refer to a single object. And that problem becomes massively aggravated in the; almost-universal situation of ""borrowing"" a pointer for the duration of a procedure call. Once you let std::unique_ptr<T> into your code, it can creep out into a whole lot of places; where it adds complexity and confusion without solving any real problem. In this particular case, the complexity of managing the memory chunks isn't that hard,; they all get cleaned up by the Region destructor, and adding another layer of software; with the Chunk class seems to obscure rather than clarify what is happening. C++11 added some wonderful features, and some lousy ones. std::unique_ptr is best avoided.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3718#issuecomment-396297556
https://github.com/hail-is/hail/pull/3718#issuecomment-396320515:1145,Performance,perform,performance,1145,"On std::unique_ptr, I may be a contrarian, but I don't care what the ""C++ community"" thinks about it.; If you buy into using std::unique_ptr<T>, then everyone who writes or reads the code has to get ; their head around the massively confusing and counter-intuitive concept of move semantics (a ; form of assignment which modifies the source) *and* the somewhat bizarre terminology and syntax; used to express that in C++. And then you get into a whole host of associated design decisions (I'm holding this as a unique_ptr,; but I want to pass it to a function - should I pass it as a raw pointer ? a raw reference ? a reference; to the unique_ptr ?). . I would be fine with that extra learning curve and complexity if unique_ptr<T> solved a difficult; problem. But - by definition! - it doesn't. It only works for the easy case where you have one; pointer to each object. And anywhere that you *might* want to use unique_ptr<T>, shared_ptr<T> provides a superset; of the functionality at only a small extra cost in memory and runtime. So my rule is, if you need; a smart pointer, use shared_ptr<T>. And if there's some place where the memory or performance; cost of shared_ptr<T> is truly proved to be painful, then use a few raw pointers where absolutely; necessary.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3718#issuecomment-396320515
https://github.com/hail-is/hail/pull/3718#issuecomment-396320515:255,Usability,intuit,intuitive,255,"On std::unique_ptr, I may be a contrarian, but I don't care what the ""C++ community"" thinks about it.; If you buy into using std::unique_ptr<T>, then everyone who writes or reads the code has to get ; their head around the massively confusing and counter-intuitive concept of move semantics (a ; form of assignment which modifies the source) *and* the somewhat bizarre terminology and syntax; used to express that in C++. And then you get into a whole host of associated design decisions (I'm holding this as a unique_ptr,; but I want to pass it to a function - should I pass it as a raw pointer ? a raw reference ? a reference; to the unique_ptr ?). . I would be fine with that extra learning curve and complexity if unique_ptr<T> solved a difficult; problem. But - by definition! - it doesn't. It only works for the easy case where you have one; pointer to each object. And anywhere that you *might* want to use unique_ptr<T>, shared_ptr<T> provides a superset; of the functionality at only a small extra cost in memory and runtime. So my rule is, if you need; a smart pointer, use shared_ptr<T>. And if there's some place where the memory or performance; cost of shared_ptr<T> is truly proved to be painful, then use a few raw pointers where absolutely; necessary.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3718#issuecomment-396320515
https://github.com/hail-is/hail/pull/3718#issuecomment-396320515:685,Usability,learn,learning,685,"On std::unique_ptr, I may be a contrarian, but I don't care what the ""C++ community"" thinks about it.; If you buy into using std::unique_ptr<T>, then everyone who writes or reads the code has to get ; their head around the massively confusing and counter-intuitive concept of move semantics (a ; form of assignment which modifies the source) *and* the somewhat bizarre terminology and syntax; used to express that in C++. And then you get into a whole host of associated design decisions (I'm holding this as a unique_ptr,; but I want to pass it to a function - should I pass it as a raw pointer ? a raw reference ? a reference; to the unique_ptr ?). . I would be fine with that extra learning curve and complexity if unique_ptr<T> solved a difficult; problem. But - by definition! - it doesn't. It only works for the easy case where you have one; pointer to each object. And anywhere that you *might* want to use unique_ptr<T>, shared_ptr<T> provides a superset; of the functionality at only a small extra cost in memory and runtime. So my rule is, if you need; a smart pointer, use shared_ptr<T>. And if there's some place where the memory or performance; cost of shared_ptr<T> is truly proved to be painful, then use a few raw pointers where absolutely; necessary.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3718#issuecomment-396320515
https://github.com/hail-is/hail/pull/3718#issuecomment-396669638:452,Deployability,integrat,integrated,452,"I want to respond to some of your objections to unique_ptr. > If you buy into using std::unique_ptr, then everyone who writes or reads the code has to get; their head around the massively confusing and counter-intuitive concept of move semantics (a; form of assignment which modifies the source) and the somewhat bizarre terminology and syntax; used to express that in C++. I agree that move semantics takes getting used to, but I think it is much too integrated into modern C++ to ignore, going far beyond unique_ptr. Writing interfaces that take advantage of move semantics requires understanding rvalue-references in more detail, but for users of those move-enabled interfaces I think the guidelines are easy to teach: a variable will only be modified by moving if it is explicitly tagged with a `std::move`, so all you have to remember is ""after a `std::move(foo)`, the variable `foo` may only be assigned to or deleted."". > And then you get into a whole host of associated design decisions (I'm holding this as a unique_ptr,; but I want to pass it to a function - should I pass it as a raw pointer ? a raw reference ? a reference; to the unique_ptr ?). Keeping in mind the model that letting a function/class `foo` hold a `unique_ptr<Widget>` means explicitly ""`foo` owns this Widget, and is responsible for deleting it or passing ownership somewhere else"", these questions have pretty clear answers. * If a function `bar` takes a `Widget` but isn't concerned with its lifetime management, it should take its argument as a `Widget*` or `Widget&`, with the usual reasoning to choose between them. The caller owns the widget, and the lifetime of `bar` is nested inside that of its caller, so lifetime management isn't an issue.; * If `bar` takes a `Widget` and needs to take ownership, it should take its argument as a `unique_ptr<Widget>`. This serves as documentation that the function is taking over responsibility for deleting the Widget, in a way enforced by the compiler.; * A `unique_ptr<Wid",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3718#issuecomment-396669638
https://github.com/hail-is/hail/pull/3718#issuecomment-396669638:452,Integrability,integrat,integrated,452,"I want to respond to some of your objections to unique_ptr. > If you buy into using std::unique_ptr, then everyone who writes or reads the code has to get; their head around the massively confusing and counter-intuitive concept of move semantics (a; form of assignment which modifies the source) and the somewhat bizarre terminology and syntax; used to express that in C++. I agree that move semantics takes getting used to, but I think it is much too integrated into modern C++ to ignore, going far beyond unique_ptr. Writing interfaces that take advantage of move semantics requires understanding rvalue-references in more detail, but for users of those move-enabled interfaces I think the guidelines are easy to teach: a variable will only be modified by moving if it is explicitly tagged with a `std::move`, so all you have to remember is ""after a `std::move(foo)`, the variable `foo` may only be assigned to or deleted."". > And then you get into a whole host of associated design decisions (I'm holding this as a unique_ptr,; but I want to pass it to a function - should I pass it as a raw pointer ? a raw reference ? a reference; to the unique_ptr ?). Keeping in mind the model that letting a function/class `foo` hold a `unique_ptr<Widget>` means explicitly ""`foo` owns this Widget, and is responsible for deleting it or passing ownership somewhere else"", these questions have pretty clear answers. * If a function `bar` takes a `Widget` but isn't concerned with its lifetime management, it should take its argument as a `Widget*` or `Widget&`, with the usual reasoning to choose between them. The caller owns the widget, and the lifetime of `bar` is nested inside that of its caller, so lifetime management isn't an issue.; * If `bar` takes a `Widget` and needs to take ownership, it should take its argument as a `unique_ptr<Widget>`. This serves as documentation that the function is taking over responsibility for deleting the Widget, in a way enforced by the compiler.; * A `unique_ptr<Wid",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3718#issuecomment-396669638
https://github.com/hail-is/hail/pull/3718#issuecomment-396669638:527,Integrability,interface,interfaces,527,"I want to respond to some of your objections to unique_ptr. > If you buy into using std::unique_ptr, then everyone who writes or reads the code has to get; their head around the massively confusing and counter-intuitive concept of move semantics (a; form of assignment which modifies the source) and the somewhat bizarre terminology and syntax; used to express that in C++. I agree that move semantics takes getting used to, but I think it is much too integrated into modern C++ to ignore, going far beyond unique_ptr. Writing interfaces that take advantage of move semantics requires understanding rvalue-references in more detail, but for users of those move-enabled interfaces I think the guidelines are easy to teach: a variable will only be modified by moving if it is explicitly tagged with a `std::move`, so all you have to remember is ""after a `std::move(foo)`, the variable `foo` may only be assigned to or deleted."". > And then you get into a whole host of associated design decisions (I'm holding this as a unique_ptr,; but I want to pass it to a function - should I pass it as a raw pointer ? a raw reference ? a reference; to the unique_ptr ?). Keeping in mind the model that letting a function/class `foo` hold a `unique_ptr<Widget>` means explicitly ""`foo` owns this Widget, and is responsible for deleting it or passing ownership somewhere else"", these questions have pretty clear answers. * If a function `bar` takes a `Widget` but isn't concerned with its lifetime management, it should take its argument as a `Widget*` or `Widget&`, with the usual reasoning to choose between them. The caller owns the widget, and the lifetime of `bar` is nested inside that of its caller, so lifetime management isn't an issue.; * If `bar` takes a `Widget` and needs to take ownership, it should take its argument as a `unique_ptr<Widget>`. This serves as documentation that the function is taking over responsibility for deleting the Widget, in a way enforced by the compiler.; * A `unique_ptr<Wid",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3718#issuecomment-396669638
https://github.com/hail-is/hail/pull/3718#issuecomment-396669638:669,Integrability,interface,interfaces,669,"I want to respond to some of your objections to unique_ptr. > If you buy into using std::unique_ptr, then everyone who writes or reads the code has to get; their head around the massively confusing and counter-intuitive concept of move semantics (a; form of assignment which modifies the source) and the somewhat bizarre terminology and syntax; used to express that in C++. I agree that move semantics takes getting used to, but I think it is much too integrated into modern C++ to ignore, going far beyond unique_ptr. Writing interfaces that take advantage of move semantics requires understanding rvalue-references in more detail, but for users of those move-enabled interfaces I think the guidelines are easy to teach: a variable will only be modified by moving if it is explicitly tagged with a `std::move`, so all you have to remember is ""after a `std::move(foo)`, the variable `foo` may only be assigned to or deleted."". > And then you get into a whole host of associated design decisions (I'm holding this as a unique_ptr,; but I want to pass it to a function - should I pass it as a raw pointer ? a raw reference ? a reference; to the unique_ptr ?). Keeping in mind the model that letting a function/class `foo` hold a `unique_ptr<Widget>` means explicitly ""`foo` owns this Widget, and is responsible for deleting it or passing ownership somewhere else"", these questions have pretty clear answers. * If a function `bar` takes a `Widget` but isn't concerned with its lifetime management, it should take its argument as a `Widget*` or `Widget&`, with the usual reasoning to choose between them. The caller owns the widget, and the lifetime of `bar` is nested inside that of its caller, so lifetime management isn't an issue.; * If `bar` takes a `Widget` and needs to take ownership, it should take its argument as a `unique_ptr<Widget>`. This serves as documentation that the function is taking over responsibility for deleting the Widget, in a way enforced by the compiler.; * A `unique_ptr<Wid",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3718#issuecomment-396669638
https://github.com/hail-is/hail/pull/3718#issuecomment-396669638:724,Modifiability,variab,variable,724,"I want to respond to some of your objections to unique_ptr. > If you buy into using std::unique_ptr, then everyone who writes or reads the code has to get; their head around the massively confusing and counter-intuitive concept of move semantics (a; form of assignment which modifies the source) and the somewhat bizarre terminology and syntax; used to express that in C++. I agree that move semantics takes getting used to, but I think it is much too integrated into modern C++ to ignore, going far beyond unique_ptr. Writing interfaces that take advantage of move semantics requires understanding rvalue-references in more detail, but for users of those move-enabled interfaces I think the guidelines are easy to teach: a variable will only be modified by moving if it is explicitly tagged with a `std::move`, so all you have to remember is ""after a `std::move(foo)`, the variable `foo` may only be assigned to or deleted."". > And then you get into a whole host of associated design decisions (I'm holding this as a unique_ptr,; but I want to pass it to a function - should I pass it as a raw pointer ? a raw reference ? a reference; to the unique_ptr ?). Keeping in mind the model that letting a function/class `foo` hold a `unique_ptr<Widget>` means explicitly ""`foo` owns this Widget, and is responsible for deleting it or passing ownership somewhere else"", these questions have pretty clear answers. * If a function `bar` takes a `Widget` but isn't concerned with its lifetime management, it should take its argument as a `Widget*` or `Widget&`, with the usual reasoning to choose between them. The caller owns the widget, and the lifetime of `bar` is nested inside that of its caller, so lifetime management isn't an issue.; * If `bar` takes a `Widget` and needs to take ownership, it should take its argument as a `unique_ptr<Widget>`. This serves as documentation that the function is taking over responsibility for deleting the Widget, in a way enforced by the compiler.; * A `unique_ptr<Wid",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3718#issuecomment-396669638
https://github.com/hail-is/hail/pull/3718#issuecomment-396669638:874,Modifiability,variab,variable,874,"I want to respond to some of your objections to unique_ptr. > If you buy into using std::unique_ptr, then everyone who writes or reads the code has to get; their head around the massively confusing and counter-intuitive concept of move semantics (a; form of assignment which modifies the source) and the somewhat bizarre terminology and syntax; used to express that in C++. I agree that move semantics takes getting used to, but I think it is much too integrated into modern C++ to ignore, going far beyond unique_ptr. Writing interfaces that take advantage of move semantics requires understanding rvalue-references in more detail, but for users of those move-enabled interfaces I think the guidelines are easy to teach: a variable will only be modified by moving if it is explicitly tagged with a `std::move`, so all you have to remember is ""after a `std::move(foo)`, the variable `foo` may only be assigned to or deleted."". > And then you get into a whole host of associated design decisions (I'm holding this as a unique_ptr,; but I want to pass it to a function - should I pass it as a raw pointer ? a raw reference ? a reference; to the unique_ptr ?). Keeping in mind the model that letting a function/class `foo` hold a `unique_ptr<Widget>` means explicitly ""`foo` owns this Widget, and is responsible for deleting it or passing ownership somewhere else"", these questions have pretty clear answers. * If a function `bar` takes a `Widget` but isn't concerned with its lifetime management, it should take its argument as a `Widget*` or `Widget&`, with the usual reasoning to choose between them. The caller owns the widget, and the lifetime of `bar` is nested inside that of its caller, so lifetime management isn't an issue.; * If `bar` takes a `Widget` and needs to take ownership, it should take its argument as a `unique_ptr<Widget>`. This serves as documentation that the function is taking over responsibility for deleting the Widget, in a way enforced by the compiler.; * A `unique_ptr<Wid",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3718#issuecomment-396669638
https://github.com/hail-is/hail/pull/3718#issuecomment-396669638:210,Usability,intuit,intuitive,210,"I want to respond to some of your objections to unique_ptr. > If you buy into using std::unique_ptr, then everyone who writes or reads the code has to get; their head around the massively confusing and counter-intuitive concept of move semantics (a; form of assignment which modifies the source) and the somewhat bizarre terminology and syntax; used to express that in C++. I agree that move semantics takes getting used to, but I think it is much too integrated into modern C++ to ignore, going far beyond unique_ptr. Writing interfaces that take advantage of move semantics requires understanding rvalue-references in more detail, but for users of those move-enabled interfaces I think the guidelines are easy to teach: a variable will only be modified by moving if it is explicitly tagged with a `std::move`, so all you have to remember is ""after a `std::move(foo)`, the variable `foo` may only be assigned to or deleted."". > And then you get into a whole host of associated design decisions (I'm holding this as a unique_ptr,; but I want to pass it to a function - should I pass it as a raw pointer ? a raw reference ? a reference; to the unique_ptr ?). Keeping in mind the model that letting a function/class `foo` hold a `unique_ptr<Widget>` means explicitly ""`foo` owns this Widget, and is responsible for deleting it or passing ownership somewhere else"", these questions have pretty clear answers. * If a function `bar` takes a `Widget` but isn't concerned with its lifetime management, it should take its argument as a `Widget*` or `Widget&`, with the usual reasoning to choose between them. The caller owns the widget, and the lifetime of `bar` is nested inside that of its caller, so lifetime management isn't an issue.; * If `bar` takes a `Widget` and needs to take ownership, it should take its argument as a `unique_ptr<Widget>`. This serves as documentation that the function is taking over responsibility for deleting the Widget, in a way enforced by the compiler.; * A `unique_ptr<Wid",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3718#issuecomment-396669638
https://github.com/hail-is/hail/pull/3718#issuecomment-396669638:692,Usability,guid,guidelines,692,"I want to respond to some of your objections to unique_ptr. > If you buy into using std::unique_ptr, then everyone who writes or reads the code has to get; their head around the massively confusing and counter-intuitive concept of move semantics (a; form of assignment which modifies the source) and the somewhat bizarre terminology and syntax; used to express that in C++. I agree that move semantics takes getting used to, but I think it is much too integrated into modern C++ to ignore, going far beyond unique_ptr. Writing interfaces that take advantage of move semantics requires understanding rvalue-references in more detail, but for users of those move-enabled interfaces I think the guidelines are easy to teach: a variable will only be modified by moving if it is explicitly tagged with a `std::move`, so all you have to remember is ""after a `std::move(foo)`, the variable `foo` may only be assigned to or deleted."". > And then you get into a whole host of associated design decisions (I'm holding this as a unique_ptr,; but I want to pass it to a function - should I pass it as a raw pointer ? a raw reference ? a reference; to the unique_ptr ?). Keeping in mind the model that letting a function/class `foo` hold a `unique_ptr<Widget>` means explicitly ""`foo` owns this Widget, and is responsible for deleting it or passing ownership somewhere else"", these questions have pretty clear answers. * If a function `bar` takes a `Widget` but isn't concerned with its lifetime management, it should take its argument as a `Widget*` or `Widget&`, with the usual reasoning to choose between them. The caller owns the widget, and the lifetime of `bar` is nested inside that of its caller, so lifetime management isn't an issue.; * If `bar` takes a `Widget` and needs to take ownership, it should take its argument as a `unique_ptr<Widget>`. This serves as documentation that the function is taking over responsibility for deleting the Widget, in a way enforced by the compiler.; * A `unique_ptr<Wid",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3718#issuecomment-396669638
https://github.com/hail-is/hail/pull/3718#issuecomment-396669638:1391,Usability,clear,clear,1391,"es the source) and the somewhat bizarre terminology and syntax; used to express that in C++. I agree that move semantics takes getting used to, but I think it is much too integrated into modern C++ to ignore, going far beyond unique_ptr. Writing interfaces that take advantage of move semantics requires understanding rvalue-references in more detail, but for users of those move-enabled interfaces I think the guidelines are easy to teach: a variable will only be modified by moving if it is explicitly tagged with a `std::move`, so all you have to remember is ""after a `std::move(foo)`, the variable `foo` may only be assigned to or deleted."". > And then you get into a whole host of associated design decisions (I'm holding this as a unique_ptr,; but I want to pass it to a function - should I pass it as a raw pointer ? a raw reference ? a reference; to the unique_ptr ?). Keeping in mind the model that letting a function/class `foo` hold a `unique_ptr<Widget>` means explicitly ""`foo` owns this Widget, and is responsible for deleting it or passing ownership somewhere else"", these questions have pretty clear answers. * If a function `bar` takes a `Widget` but isn't concerned with its lifetime management, it should take its argument as a `Widget*` or `Widget&`, with the usual reasoning to choose between them. The caller owns the widget, and the lifetime of `bar` is nested inside that of its caller, so lifetime management isn't an issue.; * If `bar` takes a `Widget` and needs to take ownership, it should take its argument as a `unique_ptr<Widget>`. This serves as documentation that the function is taking over responsibility for deleting the Widget, in a way enforced by the compiler.; * A `unique_ptr<Widget>*` or `unique_ptr<Widget>&` is an in-out parameter, where the function needs to be able to point the pointer somewhere else.; * A const pointer or reference to a unique_ptr should never be used. Just pass a raw pointer or reference. Essentially the same rubric should be used ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3718#issuecomment-396669638
https://github.com/hail-is/hail/pull/3718#issuecomment-396669638:2365,Usability,simpl,simply,2365,"ar` takes a `Widget` but isn't concerned with its lifetime management, it should take its argument as a `Widget*` or `Widget&`, with the usual reasoning to choose between them. The caller owns the widget, and the lifetime of `bar` is nested inside that of its caller, so lifetime management isn't an issue.; * If `bar` takes a `Widget` and needs to take ownership, it should take its argument as a `unique_ptr<Widget>`. This serves as documentation that the function is taking over responsibility for deleting the Widget, in a way enforced by the compiler.; * A `unique_ptr<Widget>*` or `unique_ptr<Widget>&` is an in-out parameter, where the function needs to be able to point the pointer somewhere else.; * A const pointer or reference to a unique_ptr should never be used. Just pass a raw pointer or reference. Essentially the same rubric should be used for shared_ptr, replacing ""take ownership"" with ""share ownership"". If a function is simply using a value and isn't concerned with its lifetime management, it should be taking a raw pointer or reference, not a shared_ptr. It should be completely agnostic what method the caller is using to manage the lifetime of the object. Herb Sutter gives his typical thorough analysis of this question [here](https://herbsutter.com/2013/06/05/gotw-91-solution-smart-pointer-parameters/). > I would be fine with that extra learning curve and complexity if unique_ptr solved a difficult; problem. But - by definition! - it doesn't. It only works for the easy case where you have one; pointer to each object. The invariant that unique_ptr is designed to keep isn't that there is only one pointer to each object. There can be any number of aliases, changing over time, but at any time exactly one must be a unique_ptr, which documents which alias is the ""owner"". The design of and idioms around unique_ptr ensure that all non-owning aliases have lifetimes which are nested inside the lifetime of the owning pointer, and that ownership can be passed around unam",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3718#issuecomment-396669638
https://github.com/hail-is/hail/pull/3718#issuecomment-396669638:2790,Usability,learn,learning,2790," between them. The caller owns the widget, and the lifetime of `bar` is nested inside that of its caller, so lifetime management isn't an issue.; * If `bar` takes a `Widget` and needs to take ownership, it should take its argument as a `unique_ptr<Widget>`. This serves as documentation that the function is taking over responsibility for deleting the Widget, in a way enforced by the compiler.; * A `unique_ptr<Widget>*` or `unique_ptr<Widget>&` is an in-out parameter, where the function needs to be able to point the pointer somewhere else.; * A const pointer or reference to a unique_ptr should never be used. Just pass a raw pointer or reference. Essentially the same rubric should be used for shared_ptr, replacing ""take ownership"" with ""share ownership"". If a function is simply using a value and isn't concerned with its lifetime management, it should be taking a raw pointer or reference, not a shared_ptr. It should be completely agnostic what method the caller is using to manage the lifetime of the object. Herb Sutter gives his typical thorough analysis of this question [here](https://herbsutter.com/2013/06/05/gotw-91-solution-smart-pointer-parameters/). > I would be fine with that extra learning curve and complexity if unique_ptr solved a difficult; problem. But - by definition! - it doesn't. It only works for the easy case where you have one; pointer to each object. The invariant that unique_ptr is designed to keep isn't that there is only one pointer to each object. There can be any number of aliases, changing over time, but at any time exactly one must be a unique_ptr, which documents which alias is the ""owner"". The design of and idioms around unique_ptr ensure that all non-owning aliases have lifetimes which are nested inside the lifetime of the owning pointer, and that ownership can be passed around unambiguously. I think the problem that they solve is in large part documentation of API, and the rest is letting the type system help enforce an essential invariant.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3718#issuecomment-396669638
https://github.com/hail-is/hail/pull/3718#issuecomment-396683489:1993,Deployability,Update,Update,1993,"e any of the hard problems (whereas shared_ptr; very much does). Now I realize that people writing books about C++ write a good deal about move semantics and; unique_ptr. My interpretation is that there's a lot of writing about it because it involves concepts; which simply don't occur in any other commonly-used languages, and as such it requires a; good deal of explanation and justification because it's peculiar and unfamiliar. I suggest that; other languages haven't invented this concept because it's a) confusing and b) not particularly; useful. There's one really good thing you get from move semantics: the ability to resize a std::vector<T>; or std::unordered_map<T> without constructing deep copies of each T object. In the cases; where that's useful, it's very useful for optimizing performance without totally bypassing all your; abstraction mechanisms. The other ways people attempt to exploit move semantics are IMO; just a bad idea: if you want to pass around a large expensive-to-create object, then do it the; Java way by putting it on the heap and passing around some kind of reference, and *everyone* can understand it, not just experts in modern C++. Another angle on this debate would be to look at some open-source C++ projects and see how; often they actually use unique_ptr and/or std::move. My guess is that it's much less common; in practice than you might think from reading books about C++, because the overlap between; ""object ownership is passed around"" and ""... but we always know precisely who has ownership""; is not a very big part of the design space - compared to a whole lot of ""always owned by the object which created it"" and ""used in several places at once and we don't know who will be the last to drop it"". [Update: the LLVM codebase, including tests, is 2.00M lines of C++ (.h and .cpp files), of which; ""unique_ptr"" occurs 4500 times, and ""std::move"" 3558 times. That's a ""unique_ptr"" on average once every 444 lines, and ""std::move"" once every 562 lines.]",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3718#issuecomment-396683489
https://github.com/hail-is/hail/pull/3718#issuecomment-396683489:1027,Performance,optimiz,optimizing,1027,"ember of the ""getting things done"" community than the; ""modern C++"" community. I have seen std::unique_ptr used in practice, and it was a bad experience.; And I stand by my contention that it doesn't solve any of the hard problems (whereas shared_ptr; very much does). Now I realize that people writing books about C++ write a good deal about move semantics and; unique_ptr. My interpretation is that there's a lot of writing about it because it involves concepts; which simply don't occur in any other commonly-used languages, and as such it requires a; good deal of explanation and justification because it's peculiar and unfamiliar. I suggest that; other languages haven't invented this concept because it's a) confusing and b) not particularly; useful. There's one really good thing you get from move semantics: the ability to resize a std::vector<T>; or std::unordered_map<T> without constructing deep copies of each T object. In the cases; where that's useful, it's very useful for optimizing performance without totally bypassing all your; abstraction mechanisms. The other ways people attempt to exploit move semantics are IMO; just a bad idea: if you want to pass around a large expensive-to-create object, then do it the; Java way by putting it on the heap and passing around some kind of reference, and *everyone* can understand it, not just experts in modern C++. Another angle on this debate would be to look at some open-source C++ projects and see how; often they actually use unique_ptr and/or std::move. My guess is that it's much less common; in practice than you might think from reading books about C++, because the overlap between; ""object ownership is passed around"" and ""... but we always know precisely who has ownership""; is not a very big part of the design space - compared to a whole lot of ""always owned by the object which created it"" and ""used in several places at once and we don't know who will be the last to drop it"". [Update: the LLVM codebase, including tests, is ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3718#issuecomment-396683489
https://github.com/hail-is/hail/pull/3718#issuecomment-396683489:1038,Performance,perform,performance,1038,"ember of the ""getting things done"" community than the; ""modern C++"" community. I have seen std::unique_ptr used in practice, and it was a bad experience.; And I stand by my contention that it doesn't solve any of the hard problems (whereas shared_ptr; very much does). Now I realize that people writing books about C++ write a good deal about move semantics and; unique_ptr. My interpretation is that there's a lot of writing about it because it involves concepts; which simply don't occur in any other commonly-used languages, and as such it requires a; good deal of explanation and justification because it's peculiar and unfamiliar. I suggest that; other languages haven't invented this concept because it's a) confusing and b) not particularly; useful. There's one really good thing you get from move semantics: the ability to resize a std::vector<T>; or std::unordered_map<T> without constructing deep copies of each T object. In the cases; where that's useful, it's very useful for optimizing performance without totally bypassing all your; abstraction mechanisms. The other ways people attempt to exploit move semantics are IMO; just a bad idea: if you want to pass around a large expensive-to-create object, then do it the; Java way by putting it on the heap and passing around some kind of reference, and *everyone* can understand it, not just experts in modern C++. Another angle on this debate would be to look at some open-source C++ projects and see how; often they actually use unique_ptr and/or std::move. My guess is that it's much less common; in practice than you might think from reading books about C++, because the overlap between; ""object ownership is passed around"" and ""... but we always know precisely who has ownership""; is not a very big part of the design space - compared to a whole lot of ""always owned by the object which created it"" and ""used in several places at once and we don't know who will be the last to drop it"". [Update: the LLVM codebase, including tests, is ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3718#issuecomment-396683489
https://github.com/hail-is/hail/pull/3718#issuecomment-396683489:2030,Testability,test,tests,2030,"e any of the hard problems (whereas shared_ptr; very much does). Now I realize that people writing books about C++ write a good deal about move semantics and; unique_ptr. My interpretation is that there's a lot of writing about it because it involves concepts; which simply don't occur in any other commonly-used languages, and as such it requires a; good deal of explanation and justification because it's peculiar and unfamiliar. I suggest that; other languages haven't invented this concept because it's a) confusing and b) not particularly; useful. There's one really good thing you get from move semantics: the ability to resize a std::vector<T>; or std::unordered_map<T> without constructing deep copies of each T object. In the cases; where that's useful, it's very useful for optimizing performance without totally bypassing all your; abstraction mechanisms. The other ways people attempt to exploit move semantics are IMO; just a bad idea: if you want to pass around a large expensive-to-create object, then do it the; Java way by putting it on the heap and passing around some kind of reference, and *everyone* can understand it, not just experts in modern C++. Another angle on this debate would be to look at some open-source C++ projects and see how; often they actually use unique_ptr and/or std::move. My guess is that it's much less common; in practice than you might think from reading books about C++, because the overlap between; ""object ownership is passed around"" and ""... but we always know precisely who has ownership""; is not a very big part of the design space - compared to a whole lot of ""always owned by the object which created it"" and ""used in several places at once and we don't know who will be the last to drop it"". [Update: the LLVM codebase, including tests, is 2.00M lines of C++ (.h and .cpp files), of which; ""unique_ptr"" occurs 4500 times, and ""std::move"" 3558 times. That's a ""unique_ptr"" on average once every 444 lines, and ""std::move"" once every 562 lines.]",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3718#issuecomment-396683489
https://github.com/hail-is/hail/pull/3718#issuecomment-396683489:11,Usability,simpl,simple,11,"I guess in simple terms I'm more of a member of the ""getting things done"" community than the; ""modern C++"" community. I have seen std::unique_ptr used in practice, and it was a bad experience.; And I stand by my contention that it doesn't solve any of the hard problems (whereas shared_ptr; very much does). Now I realize that people writing books about C++ write a good deal about move semantics and; unique_ptr. My interpretation is that there's a lot of writing about it because it involves concepts; which simply don't occur in any other commonly-used languages, and as such it requires a; good deal of explanation and justification because it's peculiar and unfamiliar. I suggest that; other languages haven't invented this concept because it's a) confusing and b) not particularly; useful. There's one really good thing you get from move semantics: the ability to resize a std::vector<T>; or std::unordered_map<T> without constructing deep copies of each T object. In the cases; where that's useful, it's very useful for optimizing performance without totally bypassing all your; abstraction mechanisms. The other ways people attempt to exploit move semantics are IMO; just a bad idea: if you want to pass around a large expensive-to-create object, then do it the; Java way by putting it on the heap and passing around some kind of reference, and *everyone* can understand it, not just experts in modern C++. Another angle on this debate would be to look at some open-source C++ projects and see how; often they actually use unique_ptr and/or std::move. My guess is that it's much less common; in practice than you might think from reading books about C++, because the overlap between; ""object ownership is passed around"" and ""... but we always know precisely who has ownership""; is not a very big part of the design space - compared to a whole lot of ""always owned by the object which created it"" and ""used in several places at once and we don't know who will be the last to drop it"". [Update: ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3718#issuecomment-396683489
https://github.com/hail-is/hail/pull/3718#issuecomment-396683489:510,Usability,simpl,simply,510,"I guess in simple terms I'm more of a member of the ""getting things done"" community than the; ""modern C++"" community. I have seen std::unique_ptr used in practice, and it was a bad experience.; And I stand by my contention that it doesn't solve any of the hard problems (whereas shared_ptr; very much does). Now I realize that people writing books about C++ write a good deal about move semantics and; unique_ptr. My interpretation is that there's a lot of writing about it because it involves concepts; which simply don't occur in any other commonly-used languages, and as such it requires a; good deal of explanation and justification because it's peculiar and unfamiliar. I suggest that; other languages haven't invented this concept because it's a) confusing and b) not particularly; useful. There's one really good thing you get from move semantics: the ability to resize a std::vector<T>; or std::unordered_map<T> without constructing deep copies of each T object. In the cases; where that's useful, it's very useful for optimizing performance without totally bypassing all your; abstraction mechanisms. The other ways people attempt to exploit move semantics are IMO; just a bad idea: if you want to pass around a large expensive-to-create object, then do it the; Java way by putting it on the heap and passing around some kind of reference, and *everyone* can understand it, not just experts in modern C++. Another angle on this debate would be to look at some open-source C++ projects and see how; often they actually use unique_ptr and/or std::move. My guess is that it's much less common; in practice than you might think from reading books about C++, because the overlap between; ""object ownership is passed around"" and ""... but we always know precisely who has ownership""; is not a very big part of the design space - compared to a whole lot of ""always owned by the object which created it"" and ""used in several places at once and we don't know who will be the last to drop it"". [Update: ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3718#issuecomment-396683489
https://github.com/hail-is/hail/pull/3718#issuecomment-397410855:512,Performance,perform,performance,512,"OK, I think I'm done. To be honest, I don't like the latest version any better than what I had a week; ago: expressing the buffer management with ownership and move semantics results in about 30-40; extra lines of code to do something which was expressed more concisely in the naked-pointer; version (and we've taken it from being understandable to most programmers, to being understandable only by people familiar with C++ ownership/move-semantics idioms). And I don't; think there's going to be any measurable performance improvement from what we started with. But it is what it is.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3718#issuecomment-397410855
https://github.com/hail-is/hail/pull/3720#issuecomment-395741181:197,Integrability,depend,depends,197,"@danking I'm pretty sure using UnsafeRows doesn't work in this case. When I changed from UnsafeRow to SafeRow, the tests were passing on a saved random dataset that wasn't previously working. This depends on #3724 so you can ignore changes in Relational.scala and the python tests.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3720#issuecomment-395741181
https://github.com/hail-is/hail/pull/3720#issuecomment-395741181:31,Safety,Unsafe,UnsafeRows,31,"@danking I'm pretty sure using UnsafeRows doesn't work in this case. When I changed from UnsafeRow to SafeRow, the tests were passing on a saved random dataset that wasn't previously working. This depends on #3724 so you can ignore changes in Relational.scala and the python tests.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3720#issuecomment-395741181
https://github.com/hail-is/hail/pull/3720#issuecomment-395741181:89,Safety,Unsafe,UnsafeRow,89,"@danking I'm pretty sure using UnsafeRows doesn't work in this case. When I changed from UnsafeRow to SafeRow, the tests were passing on a saved random dataset that wasn't previously working. This depends on #3724 so you can ignore changes in Relational.scala and the python tests.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3720#issuecomment-395741181
https://github.com/hail-is/hail/pull/3720#issuecomment-395741181:102,Safety,Safe,SafeRow,102,"@danking I'm pretty sure using UnsafeRows doesn't work in this case. When I changed from UnsafeRow to SafeRow, the tests were passing on a saved random dataset that wasn't previously working. This depends on #3724 so you can ignore changes in Relational.scala and the python tests.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3720#issuecomment-395741181
https://github.com/hail-is/hail/pull/3720#issuecomment-395741181:115,Testability,test,tests,115,"@danking I'm pretty sure using UnsafeRows doesn't work in this case. When I changed from UnsafeRow to SafeRow, the tests were passing on a saved random dataset that wasn't previously working. This depends on #3724 so you can ignore changes in Relational.scala and the python tests.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3720#issuecomment-395741181
https://github.com/hail-is/hail/pull/3720#issuecomment-395741181:275,Testability,test,tests,275,"@danking I'm pretty sure using UnsafeRows doesn't work in this case. When I changed from UnsafeRow to SafeRow, the tests were passing on a saved random dataset that wasn't previously working. This depends on #3724 so you can ignore changes in Relational.scala and the python tests.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3720#issuecomment-395741181
https://github.com/hail-is/hail/pull/3720#issuecomment-397801185:26,Testability,test,test,26,@cseed I changed the BGEN test to work in the case where entries table does not return rows with missing entries. Feel free to ignore my comment on your BGEN PR #3743 with regards to this test.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3720#issuecomment-397801185
https://github.com/hail-is/hail/pull/3720#issuecomment-397801185:188,Testability,test,test,188,@cseed I changed the BGEN test to work in the case where entries table does not return rows with missing entries. Feel free to ignore my comment on your BGEN PR #3743 with regards to this test.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3720#issuecomment-397801185
https://github.com/hail-is/hail/pull/3727#issuecomment-397281018:495,Energy Efficiency,allocate,allocate,495,"@danking Sorry to keep making you break things out, but it is really helpful for me and the changes will go in faster. Can you make a separate PR with the following changes that don't relate to passing the indices and the new index code? Specifically, the following items from your list:. ```; added row_fields which prevents reading and allocation of LID and RSID (also improved python-type-checking for row_fields and entry_fields). I changed several asserts to if's with fatals, so as not to allocate strings. We no longer copy the genotype data into a buffer in the block reader. This was forcing the fastKeys to do an unnecessary data copy. I changed the contract on BgenRecord to require that getValue is called to ""consume"" the record before the next record is taken. getValue(null) just skips bytes (no copy, no decompression). I added RegionValueBuilder.unsafeAdvance which can be used when you're creating an array of empty structs but don't want to do all the unnecessary RVB bookkeeping work. I use RegionValueBuilder.unsafeAdvance to make loading a BGEN without entry fields very fast. I fixed Table.index to not trigger a partition key info gathering; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3727#issuecomment-397281018
https://github.com/hail-is/hail/pull/3727#issuecomment-397281018:660,Integrability,contract,contract,660,"@danking Sorry to keep making you break things out, but it is really helpful for me and the changes will go in faster. Can you make a separate PR with the following changes that don't relate to passing the indices and the new index code? Specifically, the following items from your list:. ```; added row_fields which prevents reading and allocation of LID and RSID (also improved python-type-checking for row_fields and entry_fields). I changed several asserts to if's with fatals, so as not to allocate strings. We no longer copy the genotype data into a buffer in the block reader. This was forcing the fastKeys to do an unnecessary data copy. I changed the contract on BgenRecord to require that getValue is called to ""consume"" the record before the next record is taken. getValue(null) just skips bytes (no copy, no decompression). I added RegionValueBuilder.unsafeAdvance which can be used when you're creating an array of empty structs but don't want to do all the unnecessary RVB bookkeeping work. I use RegionValueBuilder.unsafeAdvance to make loading a BGEN without entry fields very fast. I fixed Table.index to not trigger a partition key info gathering; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3727#issuecomment-397281018
https://github.com/hail-is/hail/pull/3727#issuecomment-397281018:1052,Performance,load,loading,1052,"@danking Sorry to keep making you break things out, but it is really helpful for me and the changes will go in faster. Can you make a separate PR with the following changes that don't relate to passing the indices and the new index code? Specifically, the following items from your list:. ```; added row_fields which prevents reading and allocation of LID and RSID (also improved python-type-checking for row_fields and entry_fields). I changed several asserts to if's with fatals, so as not to allocate strings. We no longer copy the genotype data into a buffer in the block reader. This was forcing the fastKeys to do an unnecessary data copy. I changed the contract on BgenRecord to require that getValue is called to ""consume"" the record before the next record is taken. getValue(null) just skips bytes (no copy, no decompression). I added RegionValueBuilder.unsafeAdvance which can be used when you're creating an array of empty structs but don't want to do all the unnecessary RVB bookkeeping work. I use RegionValueBuilder.unsafeAdvance to make loading a BGEN without entry fields very fast. I fixed Table.index to not trigger a partition key info gathering; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3727#issuecomment-397281018
https://github.com/hail-is/hail/pull/3727#issuecomment-397281018:863,Safety,unsafe,unsafeAdvance,863,"@danking Sorry to keep making you break things out, but it is really helpful for me and the changes will go in faster. Can you make a separate PR with the following changes that don't relate to passing the indices and the new index code? Specifically, the following items from your list:. ```; added row_fields which prevents reading and allocation of LID and RSID (also improved python-type-checking for row_fields and entry_fields). I changed several asserts to if's with fatals, so as not to allocate strings. We no longer copy the genotype data into a buffer in the block reader. This was forcing the fastKeys to do an unnecessary data copy. I changed the contract on BgenRecord to require that getValue is called to ""consume"" the record before the next record is taken. getValue(null) just skips bytes (no copy, no decompression). I added RegionValueBuilder.unsafeAdvance which can be used when you're creating an array of empty structs but don't want to do all the unnecessary RVB bookkeeping work. I use RegionValueBuilder.unsafeAdvance to make loading a BGEN without entry fields very fast. I fixed Table.index to not trigger a partition key info gathering; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3727#issuecomment-397281018
https://github.com/hail-is/hail/pull/3727#issuecomment-397281018:1030,Safety,unsafe,unsafeAdvance,1030,"@danking Sorry to keep making you break things out, but it is really helpful for me and the changes will go in faster. Can you make a separate PR with the following changes that don't relate to passing the indices and the new index code? Specifically, the following items from your list:. ```; added row_fields which prevents reading and allocation of LID and RSID (also improved python-type-checking for row_fields and entry_fields). I changed several asserts to if's with fatals, so as not to allocate strings. We no longer copy the genotype data into a buffer in the block reader. This was forcing the fastKeys to do an unnecessary data copy. I changed the contract on BgenRecord to require that getValue is called to ""consume"" the record before the next record is taken. getValue(null) just skips bytes (no copy, no decompression). I added RegionValueBuilder.unsafeAdvance which can be used when you're creating an array of empty structs but don't want to do all the unnecessary RVB bookkeeping work. I use RegionValueBuilder.unsafeAdvance to make loading a BGEN without entry fields very fast. I fixed Table.index to not trigger a partition key info gathering; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3727#issuecomment-397281018
https://github.com/hail-is/hail/pull/3727#issuecomment-397281018:453,Testability,assert,asserts,453,"@danking Sorry to keep making you break things out, but it is really helpful for me and the changes will go in faster. Can you make a separate PR with the following changes that don't relate to passing the indices and the new index code? Specifically, the following items from your list:. ```; added row_fields which prevents reading and allocation of LID and RSID (also improved python-type-checking for row_fields and entry_fields). I changed several asserts to if's with fatals, so as not to allocate strings. We no longer copy the genotype data into a buffer in the block reader. This was forcing the fastKeys to do an unnecessary data copy. I changed the contract on BgenRecord to require that getValue is called to ""consume"" the record before the next record is taken. getValue(null) just skips bytes (no copy, no decompression). I added RegionValueBuilder.unsafeAdvance which can be used when you're creating an array of empty structs but don't want to do all the unnecessary RVB bookkeeping work. I use RegionValueBuilder.unsafeAdvance to make loading a BGEN without entry fields very fast. I fixed Table.index to not trigger a partition key info gathering; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3727#issuecomment-397281018
https://github.com/hail-is/hail/pull/3730#issuecomment-396303716:4,Testability,test,tests,4,The tests are failing. I'll look at it again once the tests are passing.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3730#issuecomment-396303716
https://github.com/hail-is/hail/pull/3730#issuecomment-396303716:54,Testability,test,tests,54,The tests are failing. I'll look at it again once the tests are passing.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3730#issuecomment-396303716
https://github.com/hail-is/hail/pull/3730#issuecomment-396372654:14,Availability,failure,failure,14,"The assertion failure in `mendel_errors` was due to a bug in `TableKeyBy` that was only triggered in this PR because the IR version of `Table.aggregateByKey` maintains an `OrderedRVD`, hence uses the `ordered` branch. The `key_by('s')` after the `group_by('s', 'fam').aggregate(...)` was leaving the partition key as both fields. h/t @patrick-schultz for seeing the faulty `TableKeyBy`, since `nPartitionKeys=None` means that all key fields are partition keys.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3730#issuecomment-396372654
https://github.com/hail-is/hail/pull/3730#issuecomment-396372654:366,Availability,fault,faulty,366,"The assertion failure in `mendel_errors` was due to a bug in `TableKeyBy` that was only triggered in this PR because the IR version of `Table.aggregateByKey` maintains an `OrderedRVD`, hence uses the `ordered` branch. The `key_by('s')` after the `group_by('s', 'fam').aggregate(...)` was leaving the partition key as both fields. h/t @patrick-schultz for seeing the faulty `TableKeyBy`, since `nPartitionKeys=None` means that all key fields are partition keys.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3730#issuecomment-396372654
https://github.com/hail-is/hail/pull/3730#issuecomment-396372654:4,Testability,assert,assertion,4,"The assertion failure in `mendel_errors` was due to a bug in `TableKeyBy` that was only triggered in this PR because the IR version of `Table.aggregateByKey` maintains an `OrderedRVD`, hence uses the `ordered` branch. The `key_by('s')` after the `group_by('s', 'fam').aggregate(...)` was leaving the partition key as both fields. h/t @patrick-schultz for seeing the faulty `TableKeyBy`, since `nPartitionKeys=None` means that all key fields are partition keys.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3730#issuecomment-396372654
https://github.com/hail-is/hail/pull/3730#issuecomment-397160205:202,Testability,test,test,202,"@jigold it's passing. Its critical to process the group and agg joins at the same time, and to not reprocess the group joins or re-analyze when updating the key to the groups. ive added an additional test to confirm that it works when joins happen on both group and agg expressions (with the group expression of a different type (bool) than the original key (int) so that it would fail if key_by were done before processing the agg joins). I'll work on fixing the matrix table versions in another PR.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3730#issuecomment-397160205
https://github.com/hail-is/hail/pull/3743#issuecomment-396455388:17,Testability,test,testBgenImportRandom,17,"Ah, I also nuked testBgenImportRandom with no replacement. Is there any reason to think Gavin's example is not a complete test?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3743#issuecomment-396455388
https://github.com/hail-is/hail/pull/3743#issuecomment-396455388:122,Testability,test,test,122,"Ah, I also nuked testBgenImportRandom with no replacement. Is there any reason to think Gavin's example is not a complete test?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3743#issuecomment-396455388
https://github.com/hail-is/hail/pull/3743#issuecomment-396568789:194,Testability,test,test,194,"Looking at the corresponding `GEN` file, it looks like there's one missing value (first variant, first sample) and the rest of the values are close to 1. I think we're better off creating a new test dataset with random data. You can do this with `balding_nichols.export_gen` and then import/export with qctool.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3743#issuecomment-396568789
https://github.com/hail-is/hail/pull/3743#issuecomment-397625683:60,Testability,test,tests,60,"There were some somewhat complicated merge conflicts in the tests, so if you could keep an eye out for mistakes there (e.g. dropped tests) that'd be awesome.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3743#issuecomment-397625683
https://github.com/hail-is/hail/pull/3743#issuecomment-397625683:132,Testability,test,tests,132,"There were some somewhat complicated merge conflicts in the tests, so if you could keep an eye out for mistakes there (e.g. dropped tests) that'd be awesome.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3743#issuecomment-397625683
https://github.com/hail-is/hail/pull/3745#issuecomment-396989892:29,Testability,test,tests,29,I think this is fine without tests if the issues I was seeing were in the interpreter.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3745#issuecomment-396989892
https://github.com/hail-is/hail/issues/3748#issuecomment-396727910:18,Testability,test,test,18,And I'll add this test.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3748#issuecomment-396727910
https://github.com/hail-is/hail/pull/3749#issuecomment-396753521:129,Availability,error,error,129,"Yes, it failed on master. It was failing in OrderedRVDType, because the key `idx` didn't match the partition key `[idx, a]`. The error only happens if `idx` is in both the old and new key.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3749#issuecomment-396753521
https://github.com/hail-is/hail/pull/3749#issuecomment-396754583:58,Availability,failure,failure,58,I've simplified / improved the test to show both modes of failure that indeed occur on master.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3749#issuecomment-396754583
https://github.com/hail-is/hail/pull/3749#issuecomment-396754583:31,Testability,test,test,31,I've simplified / improved the test to show both modes of failure that indeed occur on master.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3749#issuecomment-396754583
https://github.com/hail-is/hail/pull/3749#issuecomment-396754583:5,Usability,simpl,simplified,5,I've simplified / improved the test to show both modes of failure that indeed occur on master.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3749#issuecomment-396754583
https://github.com/hail-is/hail/pull/3751#issuecomment-397052753:28,Availability,error,error,28,"There's still a compilation error. Otherwise, it's good to go.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3751#issuecomment-397052753
https://github.com/hail-is/hail/issues/3756#issuecomment-422360127:239,Integrability,interface,interface,239,"I'm not sure this is a good idea -- repartition shuffle=False should basically be treated as giving something a maximum number of output partitions, which could be smaller. Still need to figure out where partitions fit into the relational interface.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3756#issuecomment-422360127
https://github.com/hail-is/hail/issues/3760#issuecomment-397472784:31,Availability,error,error,31,Got it. +1 for a more specific error message if possible.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3760#issuecomment-397472784
https://github.com/hail-is/hail/issues/3760#issuecomment-397472784:37,Integrability,message,message,37,Got it. +1 for a more specific error message if possible.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3760#issuecomment-397472784
https://github.com/hail-is/hail/issues/3763#issuecomment-400038312:57,Testability,test,test,57,Did you add the example above or similar as a regression test?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3763#issuecomment-400038312
https://github.com/hail-is/hail/pull/3773#issuecomment-398157431:55,Performance,optimiz,optimization,55,I totally wanted this when I originally wrote the bgen optimization.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3773#issuecomment-398157431
https://github.com/hail-is/hail/pull/3776#issuecomment-398354200:53,Testability,test,test,53,"Oh I guess uniroot is wrong, that's why I added this test . I'll fix.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3776#issuecomment-398354200
https://github.com/hail-is/hail/pull/3779#issuecomment-398382290:55,Integrability,message,message,55,Can you add a test that drops rsid and lid fields? See message above.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3779#issuecomment-398382290
https://github.com/hail-is/hail/pull/3779#issuecomment-398382290:14,Testability,test,test,14,Can you add a test that drops rsid and lid fields? See message above.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3779#issuecomment-398382290
https://github.com/hail-is/hail/pull/3783#issuecomment-398382857:48,Modifiability,refactor,refactor,48,Also @cseed @jigold your thoughts on this small refactor appreciated if you have time.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3783#issuecomment-398382857
https://github.com/hail-is/hail/issues/3785#issuecomment-399807879:49,Deployability,update,update,49,"Though I may instead modify the test first, will update here.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3785#issuecomment-399807879
https://github.com/hail-is/hail/issues/3785#issuecomment-399807879:32,Testability,test,test,32,"Though I may instead modify the test first, will update here.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3785#issuecomment-399807879
https://github.com/hail-is/hail/issues/3785#issuecomment-399810479:15,Testability,test,test,15,I reworked the test so no longer connected to this issue,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3785#issuecomment-399810479
https://github.com/hail-is/hail/issues/3790#issuecomment-400290111:833,Safety,Unsafe,UnsafeIndexedSeq,833,"I've been looking into why this is happening. The problem is triggered in VEP.scala, line 350 (even though this line succeeds when `csq=False`). The first two calls are successful (i.e. lines 348349):; ```scala; rvb.addAnnotation(vepRowType.types(0), v.asInstanceOf[Row].get(0)); rvb.addAnnotation(vepRowType.types(1), v.asInstanceOf[Row].get(1)); ```; but the last one fails:; ```scala; rvb.addAnnotation(vepRowType.types(2), vep); ```. In my experiments, `vepRowType` has the value `struct{locus: locus<GRCh37>, alleles: array<str>, vep: array<str>}`. `vep`'s string representation is also `array<str>`, so I'm not sure what's causing the issue. The exception is actually generated in `RegionValueBuilder.scala`, in the `addAnnotation` method. In the pattern match on type, the `TArray` case is correctly matched on, but neither `UnsafeIndexedSeq` or `IndexedSeq[Annotation]` then match, so we get the `MatchError`. I'm afraid I don't know enough about Hail's type system. Is there a case missing from the `TArray` match, or are the current ones correct and the annotations are being created wrong?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3790#issuecomment-400290111
https://github.com/hail-is/hail/issues/3790#issuecomment-400290957:43,Deployability,deploy,deployment,43,"We don't automate VEP tests as part of our deployment, though -- could I ask you to test the fix later today when it goes in?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3790#issuecomment-400290957
https://github.com/hail-is/hail/issues/3790#issuecomment-400290957:22,Testability,test,tests,22,"We don't automate VEP tests as part of our deployment, though -- could I ask you to test the fix later today when it goes in?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3790#issuecomment-400290957
https://github.com/hail-is/hail/issues/3790#issuecomment-400290957:84,Testability,test,test,84,"We don't automate VEP tests as part of our deployment, though -- could I ask you to test the fix later today when it goes in?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3790#issuecomment-400290957
https://github.com/hail-is/hail/issues/3790#issuecomment-400314076:231,Modifiability,refactor,refactoring,231,"Great, thank you! I've just checked out your branch and will do some manual testing this morning and let you know how that goes. I noticed that the VEP logic didn't have test coverage right now, but had a few ideas for some modest refactoring so unit tests are possible. I'll see if I can get that working!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3790#issuecomment-400314076
https://github.com/hail-is/hail/issues/3790#issuecomment-400314076:76,Testability,test,testing,76,"Great, thank you! I've just checked out your branch and will do some manual testing this morning and let you know how that goes. I noticed that the VEP logic didn't have test coverage right now, but had a few ideas for some modest refactoring so unit tests are possible. I'll see if I can get that working!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3790#issuecomment-400314076
https://github.com/hail-is/hail/issues/3790#issuecomment-400314076:152,Testability,log,logic,152,"Great, thank you! I've just checked out your branch and will do some manual testing this morning and let you know how that goes. I noticed that the VEP logic didn't have test coverage right now, but had a few ideas for some modest refactoring so unit tests are possible. I'll see if I can get that working!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3790#issuecomment-400314076
https://github.com/hail-is/hail/issues/3790#issuecomment-400314076:170,Testability,test,test,170,"Great, thank you! I've just checked out your branch and will do some manual testing this morning and let you know how that goes. I noticed that the VEP logic didn't have test coverage right now, but had a few ideas for some modest refactoring so unit tests are possible. I'll see if I can get that working!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3790#issuecomment-400314076
https://github.com/hail-is/hail/issues/3790#issuecomment-400314076:251,Testability,test,tests,251,"Great, thank you! I've just checked out your branch and will do some manual testing this morning and let you know how that goes. I noticed that the VEP logic didn't have test coverage right now, but had a few ideas for some modest refactoring so unit tests are possible. I'll see if I can get that working!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3790#issuecomment-400314076
https://github.com/hail-is/hail/pull/3792#issuecomment-398748205:5,Testability,test,tests,5,nice tests.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3792#issuecomment-398748205
https://github.com/hail-is/hail/pull/3798#issuecomment-398886335:27,Testability,test,testing,27,hmm I'm not sure how we're testing combOps right now. @jigold do you know?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3798#issuecomment-398886335
https://github.com/hail-is/hail/pull/3798#issuecomment-398888424:25,Testability,test,tested,25,"The combOps aren't being tested in the AggregatorsSuite, which uses the interpreter. I think we could change lines 389-397 in Interpret.Scala to do a combOp by splitting AggElements and creating a new aggregator for each split and then doing a combOp with a fold at the end. Let me know if this doesn't make sense.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3798#issuecomment-398888424
https://github.com/hail-is/hail/pull/3816#issuecomment-399561532:109,Testability,test,test,109,"sortBy is called by hl.sorted in Python in the case you give it a comparison function. You should be able to test it from Python (there are not tests, I just checked.)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3816#issuecomment-399561532
https://github.com/hail-is/hail/pull/3816#issuecomment-399561532:144,Testability,test,tests,144,"sortBy is called by hl.sorted in Python in the case you give it a comparison function. You should be able to test it from Python (there are not tests, I just checked.)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3816#issuecomment-399561532
https://github.com/hail-is/hail/pull/3822#issuecomment-400073198:23,Integrability,interface,interface,23,"The current aggregator interface assumes copy is the same as creating a new, uninitialized aggregator of the same class. This is used when copying aggregators to have one per sample when aggregating over rows for example. It is used in `MatrixAggregateRowsByKey`, `MatrixAggregateColsByKey`, and `MatrixMapCols`. I think my `deepCopy` would result in the same functionality because the aggregator being copied is uninitialized. I would be okay with changing `deepCopy` to `copy` and removing the existing `copy` methods or renaming it to something else. @cseed Do you have thoughts on this?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3822#issuecomment-400073198
https://github.com/hail-is/hail/pull/3824#issuecomment-399712664:117,Usability,simpl,simplify,117,"I want to explore having a KeyedSeqOp IR class instead of the key as an argument to the SeqOp IR. I think that would simplify the code, especially if we have a second kind of SeqOp such as windowed. I can't remember why this didn't work before when I tried it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3824#issuecomment-399712664
https://github.com/hail-is/hail/pull/3840#issuecomment-401560032:25,Availability,error,error,25,you've got a compilation error,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3840#issuecomment-401560032
https://github.com/hail-is/hail/pull/3840#issuecomment-401624633:6,Availability,error,error,6,match error on ReadMatrix,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3840#issuecomment-401624633
https://github.com/hail-is/hail/pull/3840#issuecomment-401758997:4,Integrability,depend,depends,4,now depends on #3880,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3840#issuecomment-401758997
https://github.com/hail-is/hail/pull/3857#issuecomment-400791168:28,Availability,error,error,28,You're getting an assertion error in MatrixIR,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3857#issuecomment-400791168
https://github.com/hail-is/hail/pull/3857#issuecomment-400791168:18,Testability,assert,assertion,18,You're getting an assertion error in MatrixIR,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3857#issuecomment-400791168
https://github.com/hail-is/hail/issues/3862#issuecomment-401760799:15,Performance,perform,performance,15,we can get the performance back in the short term with a 2-line change moving decompression from advance() to getValue() -- the `data` field isn't used anywhere in `advance`.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3862#issuecomment-401760799
https://github.com/hail-is/hail/issues/3862#issuecomment-401787058:199,Performance,perform,performance,199,"I think Tim's suggestion and Cotton's #1 are the same, basically? Stash the (possibly) uncompressed bytes in `data` and then decompress only in `getValue` if necessary. This gets us back to previous performance, but we still pay to copy the data even if we never read it. If this is impacting people, we should do that because it seems low-risk and high-value. As I think we all do, I prefer #3 as the long term solution. I found spreading the code across two methods a little confusing. I think ideally there would be just one method that decodes and writes into the RVB. I can pick up a proper re-write this/next week.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3862#issuecomment-401787058
https://github.com/hail-is/hail/issues/3862#issuecomment-401787058:340,Safety,risk,risk,340,"I think Tim's suggestion and Cotton's #1 are the same, basically? Stash the (possibly) uncompressed bytes in `data` and then decompress only in `getValue` if necessary. This gets us back to previous performance, but we still pay to copy the data even if we never read it. If this is impacting people, we should do that because it seems low-risk and high-value. As I think we all do, I prefer #3 as the long term solution. I found spreading the code across two methods a little confusing. I think ideally there would be just one method that decodes and writes into the RVB. I can pick up a proper re-write this/next week.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3862#issuecomment-401787058
https://github.com/hail-is/hail/issues/3862#issuecomment-401795671:75,Modifiability,refactor,refactored,75,"Yeah, the laziness worked until just recently. I broke the laziness when I refactored things for Caitlin.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3862#issuecomment-401795671
https://github.com/hail-is/hail/pull/3872#issuecomment-401411707:22,Deployability,update,update,22,"Oops, I still have to update the `vep` docs.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3872#issuecomment-401411707
https://github.com/hail-is/hail/pull/3872#issuecomment-401417677:0,Deployability,Update,Updated,0,Updated docs. Should be good to go.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3872#issuecomment-401417677
https://github.com/hail-is/hail/pull/3872#issuecomment-401421444:49,Testability,test,tested,49,looks fine to me. @konradjk can you approve once tested? thanks!,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3872#issuecomment-401421444
https://github.com/hail-is/hail/pull/3872#issuecomment-409783596:106,Testability,test,tests,106,what's my review responsibility here? Standard review process? How does this interact with Jon setting up tests?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3872#issuecomment-409783596
https://github.com/hail-is/hail/pull/3872#issuecomment-410486447:89,Testability,test,tests,89,"@tpoterba @jbloom22 I think you're off the hook for the moment, we're waiting on Jon for tests. Once this goes in, I'll rebase/revise mine.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3872#issuecomment-410486447
https://github.com/hail-is/hail/pull/3872#issuecomment-412219934:65,Testability,test,test,65,"@tpoterba OK, this is ready for review. It passes with Jon's VEP test setup:. ```; Checking 'hl.vep' replicates on 'gs://hail-common/vep/vep/vep_examplars/vep_35d9e30.mt'; 2018-08-10 22:02:28 Hail: INFO: vep: annotated 1196 variants; TEST PASSED; ```. invoked as:. ```; actual = hl.vep(expected.select(), 'gs://hail-common/vep/vep/vep85-gcloud.json'); ```. I will prepare a discuss post for when it is ready to merge.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3872#issuecomment-412219934
https://github.com/hail-is/hail/pull/3872#issuecomment-412219934:234,Testability,TEST,TEST,234,"@tpoterba OK, this is ready for review. It passes with Jon's VEP test setup:. ```; Checking 'hl.vep' replicates on 'gs://hail-common/vep/vep/vep_examplars/vep_35d9e30.mt'; 2018-08-10 22:02:28 Hail: INFO: vep: annotated 1196 variants; TEST PASSED; ```. invoked as:. ```; actual = hl.vep(expected.select(), 'gs://hail-common/vep/vep/vep85-gcloud.json'); ```. I will prepare a discuss post for when it is ready to merge.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3872#issuecomment-412219934
https://github.com/hail-is/hail/pull/3873#issuecomment-401440022:152,Availability,robust,robust,152,"@liameabbott I think you should go ahead and merge #3859. Once this is in, you can then use `locus_windows` to simplify, reduce memory req, and be more robust to catching out-of-order loci.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3873#issuecomment-401440022
https://github.com/hail-is/hail/pull/3873#issuecomment-401440022:121,Energy Efficiency,reduce,reduce,121,"@liameabbott I think you should go ahead and merge #3859. Once this is in, you can then use `locus_windows` to simplify, reduce memory req, and be more robust to catching out-of-order loci.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3873#issuecomment-401440022
https://github.com/hail-is/hail/pull/3873#issuecomment-401440022:111,Usability,simpl,simplify,111,"@liameabbott I think you should go ahead and merge #3859. Once this is in, you can then use `locus_windows` to simplify, reduce memory req, and be more robust to catching out-of-order loci.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3873#issuecomment-401440022
https://github.com/hail-is/hail/pull/3873#issuecomment-401468652:900,Performance,perform,performance,900,"I'd argue that it's broadly useful, but rather the issue is that it's useful at a lower level of abstraction (e.g. how it's used in `ld_prune`, composed with `sparsify_row_intervals`). So I see why the `hl` namespace is may be too high level, but it's also strange to put in experimental a function that is used in non-experimental (as well as experimental) methods. One option is to underscore the method for use outside experimental, but expose through the experimental module. Another is to put it in a submodule, like genetics. I'd like to expose more high-level applications directly (e.g. an `ld_matrix` function that takes an optional `radius` and `coord_expr` and returns the sparse block matrix), and we can think about re-implementing in terms of scans once they come online (deriving the stops from the starts) and zipping the intervals and blocks without ever localizing should memory or performance be an issue.; I don't want to hide it entirely in the meantime as several groups want to make use of it already.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3873#issuecomment-401468652
https://github.com/hail-is/hail/pull/3873#issuecomment-401468652:440,Security,expose,expose,440,"I'd argue that it's broadly useful, but rather the issue is that it's useful at a lower level of abstraction (e.g. how it's used in `ld_prune`, composed with `sparsify_row_intervals`). So I see why the `hl` namespace is may be too high level, but it's also strange to put in experimental a function that is used in non-experimental (as well as experimental) methods. One option is to underscore the method for use outside experimental, but expose through the experimental module. Another is to put it in a submodule, like genetics. I'd like to expose more high-level applications directly (e.g. an `ld_matrix` function that takes an optional `radius` and `coord_expr` and returns the sparse block matrix), and we can think about re-implementing in terms of scans once they come online (deriving the stops from the starts) and zipping the intervals and blocks without ever localizing should memory or performance be an issue.; I don't want to hide it entirely in the meantime as several groups want to make use of it already.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3873#issuecomment-401468652
https://github.com/hail-is/hail/pull/3873#issuecomment-401468652:544,Security,expose,expose,544,"I'd argue that it's broadly useful, but rather the issue is that it's useful at a lower level of abstraction (e.g. how it's used in `ld_prune`, composed with `sparsify_row_intervals`). So I see why the `hl` namespace is may be too high level, but it's also strange to put in experimental a function that is used in non-experimental (as well as experimental) methods. One option is to underscore the method for use outside experimental, but expose through the experimental module. Another is to put it in a submodule, like genetics. I'd like to expose more high-level applications directly (e.g. an `ld_matrix` function that takes an optional `radius` and `coord_expr` and returns the sparse block matrix), and we can think about re-implementing in terms of scans once they come online (deriving the stops from the starts) and zipping the intervals and blocks without ever localizing should memory or performance be an issue.; I don't want to hide it entirely in the meantime as several groups want to make use of it already.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3873#issuecomment-401468652
https://github.com/hail-is/hail/pull/3873#issuecomment-401470955:172,Modifiability,flexible,flexible,172,"@jigold I assigned to you since this essentially re-opens #3715 with your comments addressed. After experimenting, I felt that it didn't make sense at this point to design flexible ndarray checking at the level of typecheckers. The requirements vary quite a bit between these two functions. If you feel strongly, let's discuss. I'll leave Tim's review un-dismissed until we've agreed where to put these functions, but no need to wait on it w.r.t reviewing (once you're back).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3873#issuecomment-401470955
https://github.com/hail-is/hail/pull/3873#issuecomment-402296977:122,Testability,test,tests,122,@tpoterba please take a look at the last commit: I created `linalg/utils` and put both functions inside. I also moved the tests to `test_linalg`. Are you happy with these changes?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3873#issuecomment-402296977
https://github.com/hail-is/hail/pull/3873#issuecomment-403562202:227,Testability,test,test,227,"@jigold poke on re-review, I addressed your commends in 667ff7e, created and moved the functions to linalg/utils in 3fdeaa1, and broke out the bit that finds the contig start indices into its own function in ec3a50f so I could test its behavior more rigorously. @tpoterba poking again on whether you're happy with where I moved the command (see above)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3873#issuecomment-403562202
https://github.com/hail-is/hail/pull/3875#issuecomment-401478918:24,Testability,test,test,24,"I prefer ""of"" to ""for"" (test of equilibrium like test of independence). I made all the other changes.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3875#issuecomment-401478918
https://github.com/hail-is/hail/pull/3875#issuecomment-401478918:49,Testability,test,test,49,"I prefer ""of"" to ""for"" (test of equilibrium like test of independence). I made all the other changes.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3875#issuecomment-401478918
https://github.com/hail-is/hail/pull/3877#issuecomment-401560878:22,Testability,test,tests,22,how did this pass the tests on the CI server?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3877#issuecomment-401560878
https://github.com/hail-is/hail/pull/3877#issuecomment-401561119:18,Availability,error,error,18,This is a compile error. MatrixIR has partitionCounts as an Option[IndexedSeq[String]],MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3877#issuecomment-401561119
https://github.com/hail-is/hail/pull/3877#issuecomment-401561153:57,Testability,test,tested,57,Master is failing because of this. Somehow the CI server tested the wrong thing...,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3877#issuecomment-401561153
https://github.com/hail-is/hail/pull/3877#issuecomment-401561294:146,Performance,race condition,race condition,146,"Oh, sorry, I see the problem. I had a PR recently that changed the Array to IndexedSeq, it seems like this didn't get retested/blocked. The usual race condition (although I don't know why this didn't get re-run, that was ages ago.) We really need to drop TC and get a better model.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3877#issuecomment-401561294
https://github.com/hail-is/hail/issues/3886#issuecomment-401931653:48,Availability,error,error,48,"Indeed, if i do `hl.literal()`, I get the right error message:; ```; hail.expr.expressions.base_expression.ExpressionException: Hail does not support heterogeneous dicts: found dict with values of types [dtype('str'), dtype('int32')]; ```; But fixing the value types upstream removes the requirement for `hl.literal()` and works",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3886#issuecomment-401931653
https://github.com/hail-is/hail/issues/3886#issuecomment-401931653:54,Integrability,message,message,54,"Indeed, if i do `hl.literal()`, I get the right error message:; ```; hail.expr.expressions.base_expression.ExpressionException: Hail does not support heterogeneous dicts: found dict with values of types [dtype('str'), dtype('int32')]; ```; But fixing the value types upstream removes the requirement for `hl.literal()` and works",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3886#issuecomment-401931653
https://github.com/hail-is/hail/pull/3887#issuecomment-402119610:23,Testability,test,test,23,I really like that the test methods mirror the source code structure. Were there other changes? I see this `..helpers` thing collects a few different test related things. Seems good.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3887#issuecomment-402119610
https://github.com/hail-is/hail/pull/3887#issuecomment-402119610:150,Testability,test,test,150,I really like that the test methods mirror the source code structure. Were there other changes? I see this `..helpers` thing collects a few different test related things. Seems good.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3887#issuecomment-402119610
https://github.com/hail-is/hail/pull/3887#issuecomment-402121286:89,Safety,avoid,avoid,89,"ah, I should have enumerated the changes besides motion. . I renamed utils to helpers to avoid a name conflict. ; I moved a few things like get_dataset to helpers, which deleted a bunch of duplicated code. I also deleted a few of the ColumnTests in test_api that were already covered by test_expr, and moved the rest into that module.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3887#issuecomment-402121286
https://github.com/hail-is/hail/pull/3887#issuecomment-402164003:107,Testability,test,test,107,"Nice, I think this is a giant improvement. There are still spots where the pairing between source file and test file isn't exact, but hopefully having it most of the way there will encourage better modularization of both the source and tests over time (broken windows and all that).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3887#issuecomment-402164003
https://github.com/hail-is/hail/pull/3887#issuecomment-402164003:236,Testability,test,tests,236,"Nice, I think this is a giant improvement. There are still spots where the pairing between source file and test file isn't exact, but hopefully having it most of the way there will encourage better modularization of both the source and tests over time (broken windows and all that).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3887#issuecomment-402164003
https://github.com/hail-is/hail/pull/3887#issuecomment-402165304:123,Testability,test,test,123,"ah, also -- one more semantic change. I made stopTestHailContext a no-op, so we don't have to reinitialize Spark for every test module. This is OK, right? We have very few modifications to global state -- reference genomes are the only one I can think of.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3887#issuecomment-402165304
https://github.com/hail-is/hail/pull/3887#issuecomment-402166053:154,Testability,test,test,154,"And conversely, the fact that test_table is split up suggests to me that table.py should probably be split to match. But this pr should probably stick to test reorganization.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3887#issuecomment-402166053
https://github.com/hail-is/hail/pull/3891#issuecomment-402858809:420,Availability,down,down,420,"So I'm moderately unhappy with this for various reasons, and almost didn't PR it. We don't generally respect IR identity (e.g. optimize copies everything), so I'm not sure how useful memoizing partition counts on the IR actually is. We could try to carry this information forward inside copy. In that cases that (MatrixIR child) has the same partition counts as child, we can actually push the computed partition counts down into child. But all of this is getting pretty complicated ... just to optimize count? I wonder if it is worth it. Yes, Count and PartitionCounts have different requirements. I think we either need both, or we need to recognize in (Sum (PartitionCounts child)) that child doesn't need to preserve order. (An analysis pass that determines which IR need to preserve order in general will be better than determining this syntactically from context with a rule like (Count (Unkey child)). How do you optimize (Count (Filter (Unkey ...))?). Hmm.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3891#issuecomment-402858809
https://github.com/hail-is/hail/pull/3891#issuecomment-402858809:127,Performance,optimiz,optimize,127,"So I'm moderately unhappy with this for various reasons, and almost didn't PR it. We don't generally respect IR identity (e.g. optimize copies everything), so I'm not sure how useful memoizing partition counts on the IR actually is. We could try to carry this information forward inside copy. In that cases that (MatrixIR child) has the same partition counts as child, we can actually push the computed partition counts down into child. But all of this is getting pretty complicated ... just to optimize count? I wonder if it is worth it. Yes, Count and PartitionCounts have different requirements. I think we either need both, or we need to recognize in (Sum (PartitionCounts child)) that child doesn't need to preserve order. (An analysis pass that determines which IR need to preserve order in general will be better than determining this syntactically from context with a rule like (Count (Unkey child)). How do you optimize (Count (Filter (Unkey ...))?). Hmm.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3891#issuecomment-402858809
https://github.com/hail-is/hail/pull/3891#issuecomment-402858809:495,Performance,optimiz,optimize,495,"So I'm moderately unhappy with this for various reasons, and almost didn't PR it. We don't generally respect IR identity (e.g. optimize copies everything), so I'm not sure how useful memoizing partition counts on the IR actually is. We could try to carry this information forward inside copy. In that cases that (MatrixIR child) has the same partition counts as child, we can actually push the computed partition counts down into child. But all of this is getting pretty complicated ... just to optimize count? I wonder if it is worth it. Yes, Count and PartitionCounts have different requirements. I think we either need both, or we need to recognize in (Sum (PartitionCounts child)) that child doesn't need to preserve order. (An analysis pass that determines which IR need to preserve order in general will be better than determining this syntactically from context with a rule like (Count (Unkey child)). How do you optimize (Count (Filter (Unkey ...))?). Hmm.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3891#issuecomment-402858809
https://github.com/hail-is/hail/pull/3891#issuecomment-402858809:920,Performance,optimiz,optimize,920,"So I'm moderately unhappy with this for various reasons, and almost didn't PR it. We don't generally respect IR identity (e.g. optimize copies everything), so I'm not sure how useful memoizing partition counts on the IR actually is. We could try to carry this information forward inside copy. In that cases that (MatrixIR child) has the same partition counts as child, we can actually push the computed partition counts down into child. But all of this is getting pretty complicated ... just to optimize count? I wonder if it is worth it. Yes, Count and PartitionCounts have different requirements. I think we either need both, or we need to recognize in (Sum (PartitionCounts child)) that child doesn't need to preserve order. (An analysis pass that determines which IR need to preserve order in general will be better than determining this syntactically from context with a rule like (Count (Unkey child)). How do you optimize (Count (Filter (Unkey ...))?). Hmm.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3891#issuecomment-402858809
https://github.com/hail-is/hail/pull/3893#issuecomment-403986055:147,Usability,clear,clearer,147,"@patrick-schultz So, I made the change. It doesn't change the speed to get the keys (which was already at ~ SSD read speed). I'm not sure it's any clearer. Is there another way I could have done it?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3893#issuecomment-403986055
https://github.com/hail-is/hail/pull/3893#issuecomment-404156507:807,Integrability,interface,interface,807,"All that messy state twiddling is because Scala's `Iterator` is the wrong model for most things we use it for, which is why I made `FlipbookIterator`. Using that, what you have would become; ```scala; private class BgenRecordStateMachine(; ctx: RVDContext,; p: BgenPartition,; settings: BgenSettings; ) extends StateMachine[RegionValue] {; private[this] val bfis = p.makeInputStream; private[this] val rv = RegionValue(ctx.region); private[this] val rvb = ctx.rvb; ; def isValid: Boolean = p.isValid; def value: RegionValue = rv; def advance() { p.advance(); findNextVariant() }; private def findNextVariant() {; // same as existing advance(), but without advancing p; }. findNextVariant() // make sure iterator is initialized in first valid state; }; ```; giving `BgenPartition` a `FlipbookIterator` style interface, with `isValid`, `value`, and `advance()` instead of `hasNext()` and `next()`. Then to create a new iterator `FlipbookIterator(new BgenRecordStateMachine(...))`. But honestly, what you had was clear enough, so if you benchmarked and the allocation isn't an issue, you should do whatever you find most readable. I've been conditioned to avoid `Option` in low-level code, but I don't have a good intuition for when it is or isn't actually a problem.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3893#issuecomment-404156507
https://github.com/hail-is/hail/pull/3893#issuecomment-404156507:303,Modifiability,extend,extends,303,"All that messy state twiddling is because Scala's `Iterator` is the wrong model for most things we use it for, which is why I made `FlipbookIterator`. Using that, what you have would become; ```scala; private class BgenRecordStateMachine(; ctx: RVDContext,; p: BgenPartition,; settings: BgenSettings; ) extends StateMachine[RegionValue] {; private[this] val bfis = p.makeInputStream; private[this] val rv = RegionValue(ctx.region); private[this] val rvb = ctx.rvb; ; def isValid: Boolean = p.isValid; def value: RegionValue = rv; def advance() { p.advance(); findNextVariant() }; private def findNextVariant() {; // same as existing advance(), but without advancing p; }. findNextVariant() // make sure iterator is initialized in first valid state; }; ```; giving `BgenPartition` a `FlipbookIterator` style interface, with `isValid`, `value`, and `advance()` instead of `hasNext()` and `next()`. Then to create a new iterator `FlipbookIterator(new BgenRecordStateMachine(...))`. But honestly, what you had was clear enough, so if you benchmarked and the allocation isn't an issue, you should do whatever you find most readable. I've been conditioned to avoid `Option` in low-level code, but I don't have a good intuition for when it is or isn't actually a problem.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3893#issuecomment-404156507
https://github.com/hail-is/hail/pull/3893#issuecomment-404156507:1153,Safety,avoid,avoid,1153,"All that messy state twiddling is because Scala's `Iterator` is the wrong model for most things we use it for, which is why I made `FlipbookIterator`. Using that, what you have would become; ```scala; private class BgenRecordStateMachine(; ctx: RVDContext,; p: BgenPartition,; settings: BgenSettings; ) extends StateMachine[RegionValue] {; private[this] val bfis = p.makeInputStream; private[this] val rv = RegionValue(ctx.region); private[this] val rvb = ctx.rvb; ; def isValid: Boolean = p.isValid; def value: RegionValue = rv; def advance() { p.advance(); findNextVariant() }; private def findNextVariant() {; // same as existing advance(), but without advancing p; }. findNextVariant() // make sure iterator is initialized in first valid state; }; ```; giving `BgenPartition` a `FlipbookIterator` style interface, with `isValid`, `value`, and `advance()` instead of `hasNext()` and `next()`. Then to create a new iterator `FlipbookIterator(new BgenRecordStateMachine(...))`. But honestly, what you had was clear enough, so if you benchmarked and the allocation isn't an issue, you should do whatever you find most readable. I've been conditioned to avoid `Option` in low-level code, but I don't have a good intuition for when it is or isn't actually a problem.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3893#issuecomment-404156507
https://github.com/hail-is/hail/pull/3893#issuecomment-404156507:1034,Testability,benchmark,benchmarked,1034,"All that messy state twiddling is because Scala's `Iterator` is the wrong model for most things we use it for, which is why I made `FlipbookIterator`. Using that, what you have would become; ```scala; private class BgenRecordStateMachine(; ctx: RVDContext,; p: BgenPartition,; settings: BgenSettings; ) extends StateMachine[RegionValue] {; private[this] val bfis = p.makeInputStream; private[this] val rv = RegionValue(ctx.region); private[this] val rvb = ctx.rvb; ; def isValid: Boolean = p.isValid; def value: RegionValue = rv; def advance() { p.advance(); findNextVariant() }; private def findNextVariant() {; // same as existing advance(), but without advancing p; }. findNextVariant() // make sure iterator is initialized in first valid state; }; ```; giving `BgenPartition` a `FlipbookIterator` style interface, with `isValid`, `value`, and `advance()` instead of `hasNext()` and `next()`. Then to create a new iterator `FlipbookIterator(new BgenRecordStateMachine(...))`. But honestly, what you had was clear enough, so if you benchmarked and the allocation isn't an issue, you should do whatever you find most readable. I've been conditioned to avoid `Option` in low-level code, but I don't have a good intuition for when it is or isn't actually a problem.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3893#issuecomment-404156507
https://github.com/hail-is/hail/pull/3893#issuecomment-404156507:1010,Usability,clear,clear,1010,"All that messy state twiddling is because Scala's `Iterator` is the wrong model for most things we use it for, which is why I made `FlipbookIterator`. Using that, what you have would become; ```scala; private class BgenRecordStateMachine(; ctx: RVDContext,; p: BgenPartition,; settings: BgenSettings; ) extends StateMachine[RegionValue] {; private[this] val bfis = p.makeInputStream; private[this] val rv = RegionValue(ctx.region); private[this] val rvb = ctx.rvb; ; def isValid: Boolean = p.isValid; def value: RegionValue = rv; def advance() { p.advance(); findNextVariant() }; private def findNextVariant() {; // same as existing advance(), but without advancing p; }. findNextVariant() // make sure iterator is initialized in first valid state; }; ```; giving `BgenPartition` a `FlipbookIterator` style interface, with `isValid`, `value`, and `advance()` instead of `hasNext()` and `next()`. Then to create a new iterator `FlipbookIterator(new BgenRecordStateMachine(...))`. But honestly, what you had was clear enough, so if you benchmarked and the allocation isn't an issue, you should do whatever you find most readable. I've been conditioned to avoid `Option` in low-level code, but I don't have a good intuition for when it is or isn't actually a problem.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3893#issuecomment-404156507
https://github.com/hail-is/hail/pull/3893#issuecomment-404156507:1211,Usability,intuit,intuition,1211,"All that messy state twiddling is because Scala's `Iterator` is the wrong model for most things we use it for, which is why I made `FlipbookIterator`. Using that, what you have would become; ```scala; private class BgenRecordStateMachine(; ctx: RVDContext,; p: BgenPartition,; settings: BgenSettings; ) extends StateMachine[RegionValue] {; private[this] val bfis = p.makeInputStream; private[this] val rv = RegionValue(ctx.region); private[this] val rvb = ctx.rvb; ; def isValid: Boolean = p.isValid; def value: RegionValue = rv; def advance() { p.advance(); findNextVariant() }; private def findNextVariant() {; // same as existing advance(), but without advancing p; }. findNextVariant() // make sure iterator is initialized in first valid state; }; ```; giving `BgenPartition` a `FlipbookIterator` style interface, with `isValid`, `value`, and `advance()` instead of `hasNext()` and `next()`. Then to create a new iterator `FlipbookIterator(new BgenRecordStateMachine(...))`. But honestly, what you had was clear enough, so if you benchmarked and the allocation isn't an issue, you should do whatever you find most readable. I've been conditioned to avoid `Option` in low-level code, but I don't have a good intuition for when it is or isn't actually a problem.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3893#issuecomment-404156507
https://github.com/hail-is/hail/pull/3893#issuecomment-404172614:79,Safety,avoid,avoiding,79,"@patrick-schultz ah, I think this looks a fair bit better. And I'm in favor of avoiding allocations when it's easy. Generally, I think per-row allocations don't hurt us too much, but it's not hard to avoid it with this.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3893#issuecomment-404172614
https://github.com/hail-is/hail/pull/3893#issuecomment-404172614:200,Safety,avoid,avoid,200,"@patrick-schultz ah, I think this looks a fair bit better. And I'm in favor of avoiding allocations when it's easy. Generally, I think per-row allocations don't hurt us too much, but it's not hard to avoid it with this.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3893#issuecomment-404172614
https://github.com/hail-is/hail/pull/3895#issuecomment-402918034:29,Testability,test,tests,29,You should also include some tests.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3895#issuecomment-402918034
https://github.com/hail-is/hail/pull/3895#issuecomment-405244577:6,Testability,test,test,6,scala test is failing due to failed typecheck I think,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3895#issuecomment-405244577
https://github.com/hail-is/hail/pull/3895#issuecomment-405725628:7,Testability,test,tests,7,@cseed tests pass,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3895#issuecomment-405725628
https://github.com/hail-is/hail/pull/3896#issuecomment-403049982:76,Modifiability,parameteriz,parameterized,76,"Now, as in, after this change, or now as in generally?. MatrixRead is now a parameterized IR. It has three public parameters: it has a requested type (typ) and it can drop the rows or columns. It also has a reader that produces a matrix value based on those parameters. There are currently two readers: MatrixRangeReader and MatrixNativeReader (reading a .mt file). MatrixIR.{read, range} produce these MatrixRead nodes from suitable inputs. I didn't follow this in Python, so Python has MatrixRead (corresponding to reading a .mt) and MatrixRange, which have the ""suitable"" inputs and the parser calls MatrixIR.{read, range} when parsing them. Although TableRead isn't organized this way, I did add a TableIR.read. The problem here is that MatrixNativeReader has the spec that comes from reading the metadata, so either I need to (1) open and read the metadata in Python (duplicating the metadata parsing logic), (2) call into Scala to read the metadata, but then re-encode it when I serialize the IR node, or (3) don't include the spec in the serialized form and let Scala read the metadata when parsing. I chose (3).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3896#issuecomment-403049982
https://github.com/hail-is/hail/pull/3896#issuecomment-403049982:906,Testability,log,logic,906,"Now, as in, after this change, or now as in generally?. MatrixRead is now a parameterized IR. It has three public parameters: it has a requested type (typ) and it can drop the rows or columns. It also has a reader that produces a matrix value based on those parameters. There are currently two readers: MatrixRangeReader and MatrixNativeReader (reading a .mt file). MatrixIR.{read, range} produce these MatrixRead nodes from suitable inputs. I didn't follow this in Python, so Python has MatrixRead (corresponding to reading a .mt) and MatrixRange, which have the ""suitable"" inputs and the parser calls MatrixIR.{read, range} when parsing them. Although TableRead isn't organized this way, I did add a TableIR.read. The problem here is that MatrixNativeReader has the spec that comes from reading the metadata, so either I need to (1) open and read the metadata in Python (duplicating the metadata parsing logic), (2) call into Scala to read the metadata, but then re-encode it when I serialize the IR node, or (3) don't include the spec in the serialized form and let Scala read the metadata when parsing. I chose (3).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3896#issuecomment-403049982
https://github.com/hail-is/hail/pull/3896#issuecomment-403056631:129,Integrability,interface,interface,129,"Yeah, I was having the same trouble. The moral now is the printed representation should roughly have the same information as the interface call that generated it (read_matrix_table, import_vcf, etc.) I made the ""requested type"" optional in the printed representation, and None means use the full type coming from the file.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3896#issuecomment-403056631
https://github.com/hail-is/hail/pull/3896#issuecomment-403951998:40,Testability,test,tests,40,We also need Python-side MatrixIR parse tests. I will add those in a separate PR (not that the corresponding work on the Scala side is done).,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3896#issuecomment-403951998
https://github.com/hail-is/hail/issues/3900#issuecomment-403211589:35,Availability,error,error,35,http://discuss.hail.is/t/sample-qc-error/556,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3900#issuecomment-403211589
https://github.com/hail-is/hail/issues/3901#issuecomment-403295450:223,Deployability,update,update,223,"This is probably a memory leak. Your build is from 2 months ago, and there are several commits since then that change memory management and fix bugs. I'm nearly certain this problem won't exist in the latest build! Can you update? The current build will also be MUCH faster in many cases.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3901#issuecomment-403295450
https://github.com/hail-is/hail/pull/3912#issuecomment-403844335:51,Usability,clear,clearer,51,We could add a warning to the docs to make it even clearer.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3912#issuecomment-403844335
https://github.com/hail-is/hail/pull/3913#issuecomment-409089478:4,Testability,test,testing,4,"VEP testing. I think to start we should:; - get a few hundred random variants, half genome-wide and half exome (human and mouse) in a handful of partitions,; - VEP them with the current master (81, 85, 37, 38, m38) and save that in a bucket and/or test resources,; - write a script to spin up Dataproc clusters and re-VEP and compare. Same for Nirvana. @jbloom22 Can you do this? I'm going to assign the VEP/Nirvana test PR to you. This is a good first step.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3913#issuecomment-409089478
https://github.com/hail-is/hail/pull/3913#issuecomment-409089478:248,Testability,test,test,248,"VEP testing. I think to start we should:; - get a few hundred random variants, half genome-wide and half exome (human and mouse) in a handful of partitions,; - VEP them with the current master (81, 85, 37, 38, m38) and save that in a bucket and/or test resources,; - write a script to spin up Dataproc clusters and re-VEP and compare. Same for Nirvana. @jbloom22 Can you do this? I'm going to assign the VEP/Nirvana test PR to you. This is a good first step.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3913#issuecomment-409089478
https://github.com/hail-is/hail/pull/3913#issuecomment-409089478:416,Testability,test,test,416,"VEP testing. I think to start we should:; - get a few hundred random variants, half genome-wide and half exome (human and mouse) in a handful of partitions,; - VEP them with the current master (81, 85, 37, 38, m38) and save that in a bucket and/or test resources,; - write a script to spin up Dataproc clusters and re-VEP and compare. Same for Nirvana. @jbloom22 Can you do this? I'm going to assign the VEP/Nirvana test PR to you. This is a good first step.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3913#issuecomment-409089478
https://github.com/hail-is/hail/issues/3922#issuecomment-411533395:248,Energy Efficiency,reduce,reduce,248,"@tpoterba I apologize for replying late. . I ran the code, and it does not seem to work. Hail seems to upload everything but the Jupyter notebook cell does not stop running, or it is just taking time. It seems to be stuck on: `Running Spark job 1: reduce at TextTableReader.scala:147`",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3922#issuecomment-411533395
https://github.com/hail-is/hail/pull/3939#issuecomment-406155895:88,Usability,clear,clearer,88,closing this because i ripped some stuff out prematurely and i'm not sure it's actually clearer to have this as a separate PR,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3939#issuecomment-406155895
https://github.com/hail-is/hail/pull/3945#issuecomment-405771538:108,Testability,test,test,108,"@jigold The initial scan now seems comparable, doing just `bgen_import` I get:. 0.1:; vds = hc.import_bgen('test.bgen'); real	0m29.815s; user	0m0.260s; sys	0m0.368s. 0.2:; mt = hl.import_bgen('test.bgen', ['dosage']); real	0m26.712s; user	0m0.705s; sys	0m0.119s. This is on 4 cores with a 37GB test BGEN. 0.2 seems ~15% faster now. Can you rerun the time test again once this goes and and verify you get a reasonable number of partitions to get parallelism (I'm seeing 293.) Thanks!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3945#issuecomment-405771538
https://github.com/hail-is/hail/pull/3945#issuecomment-405771538:193,Testability,test,test,193,"@jigold The initial scan now seems comparable, doing just `bgen_import` I get:. 0.1:; vds = hc.import_bgen('test.bgen'); real	0m29.815s; user	0m0.260s; sys	0m0.368s. 0.2:; mt = hl.import_bgen('test.bgen', ['dosage']); real	0m26.712s; user	0m0.705s; sys	0m0.119s. This is on 4 cores with a 37GB test BGEN. 0.2 seems ~15% faster now. Can you rerun the time test again once this goes and and verify you get a reasonable number of partitions to get parallelism (I'm seeing 293.) Thanks!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3945#issuecomment-405771538
https://github.com/hail-is/hail/pull/3945#issuecomment-405771538:294,Testability,test,test,294,"@jigold The initial scan now seems comparable, doing just `bgen_import` I get:. 0.1:; vds = hc.import_bgen('test.bgen'); real	0m29.815s; user	0m0.260s; sys	0m0.368s. 0.2:; mt = hl.import_bgen('test.bgen', ['dosage']); real	0m26.712s; user	0m0.705s; sys	0m0.119s. This is on 4 cores with a 37GB test BGEN. 0.2 seems ~15% faster now. Can you rerun the time test again once this goes and and verify you get a reasonable number of partitions to get parallelism (I'm seeing 293.) Thanks!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3945#issuecomment-405771538
https://github.com/hail-is/hail/pull/3945#issuecomment-405771538:355,Testability,test,test,355,"@jigold The initial scan now seems comparable, doing just `bgen_import` I get:. 0.1:; vds = hc.import_bgen('test.bgen'); real	0m29.815s; user	0m0.260s; sys	0m0.368s. 0.2:; mt = hl.import_bgen('test.bgen', ['dosage']); real	0m26.712s; user	0m0.705s; sys	0m0.119s. This is on 4 cores with a 37GB test BGEN. 0.2 seems ~15% faster now. Can you rerun the time test again once this goes and and verify you get a reasonable number of partitions to get parallelism (I'm seeing 293.) Thanks!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3945#issuecomment-405771538
https://github.com/hail-is/hail/pull/3945#issuecomment-405977581:25,Deployability,pipeline,pipeline,25,"@cseed Still running the pipeline, but can confirm I got 293 partitions for chr22 and the import step took about 1 minute. ```; 2018-07-18 15:39:30 Hail: INFO: Number of BGEN files parsed: 1; 2018-07-18 15:39:30 Hail: INFO: Number of samples in BGEN files: 487409; 2018-07-18 15:39:30 Hail: INFO: Number of variants across all BGEN files: 1255683; 2018-07-18 15:40:37 Hail: INFO: Coerced almost-sorted dataset; 2018-07-18 15:40:39 Hail: INFO: interval filter loaded 5 of 293 partitions; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3945#issuecomment-405977581
https://github.com/hail-is/hail/pull/3945#issuecomment-405977581:459,Performance,load,loaded,459,"@cseed Still running the pipeline, but can confirm I got 293 partitions for chr22 and the import step took about 1 minute. ```; 2018-07-18 15:39:30 Hail: INFO: Number of BGEN files parsed: 1; 2018-07-18 15:39:30 Hail: INFO: Number of samples in BGEN files: 487409; 2018-07-18 15:39:30 Hail: INFO: Number of variants across all BGEN files: 1255683; 2018-07-18 15:40:37 Hail: INFO: Coerced almost-sorted dataset; 2018-07-18 15:40:39 Hail: INFO: interval filter loaded 5 of 293 partitions; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3945#issuecomment-405977581
https://github.com/hail-is/hail/pull/3945#issuecomment-405978394:249,Usability,simpl,simpler,249,"Great, thanks Jackie! Do you remember about how long the import step took for 0.1?. Second, you're running many linear regressions, right? If those still fail (or run much slower than 0.1), can you also try just a single linear regression? That's a simpler baseline to start with.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3945#issuecomment-405978394
https://github.com/hail-is/hail/pull/3945#issuecomment-405979965:1106,Modifiability,variab,variables,1106,"sed: 1; 2018-06-26 01:47:57 Hail: INFO: Number of samples in BGEN files: 487409; 2018-06-26 01:47:57 Hail: INFO: Number of variants across all BGEN files: 1255683; 2018-06-26 01:49:08 Hail: INFO: Coerced almost-sorted dataset; 2018-06-26 01:49:08 Hail: INFO: No multiallelics detected.; 2018-06-26 01:49:09 Hail: INFO: interval filter loaded 27 of 586 partitions; ```. I'll kill what I have and run a single regression, since this will take a long time.; ```; 2018-07-18 15:39:30 Hail: INFO: Number of BGEN files parsed: 1; 2018-07-18 15:39:30 Hail: INFO: Number of samples in BGEN files: 487409; 2018-07-18 15:39:30 Hail: INFO: Number of variants across all BGEN files: 1255683; 2018-07-18 15:40:37 Hail: INFO: Coerced almost-sorted dataset; 2018-07-18 15:40:39 Hail: INFO: interval filter loaded 5 of 293 partitions; 2018-07-18 15:43:13 Hail: WARN: 126215 of 487409 samples have a missing phenotype or covariate.; 2018-07-18 15:43:13 Hail: INFO: linear_regression: running on 361194 samples for 110 response variables y,; with input variable x, intercept, and 25 additional covariates...; 2018-07-18 15:44:06 Hail: WARN: 132571 of 487409 samples have a missing phenotype or covariate.; 2018-07-18 15:44:06 Hail: INFO: linear_regression: running on 354838 samples for 1 response variable y,; with input variable x, intercept, and 25 additional covariates...; 2018-07-18 15:44:59 Hail: WARN: 132781 of 487409 samples have a missing phenotype or covariate.; 2018-07-18 15:44:59 Hail: INFO: linear_regression: running on 354628 samples for 1 response variable y,; with input variable x, intercept, and 25 additional covariates...; 2018-07-18 15:45:42 Hail: WARN: 133165 of 487409 samples have a missing phenotype or covariate.; 2018-07-18 15:45:42 Hail: INFO: linear_regression: running on 354244 samples for 1 response variable y,; with input variable x, intercept, and 25 additional covariates...; 2018-07-18 15:46:57 Hail: WARN: 132601 of 487409 samples have a missing phenotype or covariate.; 2018-0",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3945#issuecomment-405979965
https://github.com/hail-is/hail/pull/3945#issuecomment-405979965:1131,Modifiability,variab,variable,1131,"sed: 1; 2018-06-26 01:47:57 Hail: INFO: Number of samples in BGEN files: 487409; 2018-06-26 01:47:57 Hail: INFO: Number of variants across all BGEN files: 1255683; 2018-06-26 01:49:08 Hail: INFO: Coerced almost-sorted dataset; 2018-06-26 01:49:08 Hail: INFO: No multiallelics detected.; 2018-06-26 01:49:09 Hail: INFO: interval filter loaded 27 of 586 partitions; ```. I'll kill what I have and run a single regression, since this will take a long time.; ```; 2018-07-18 15:39:30 Hail: INFO: Number of BGEN files parsed: 1; 2018-07-18 15:39:30 Hail: INFO: Number of samples in BGEN files: 487409; 2018-07-18 15:39:30 Hail: INFO: Number of variants across all BGEN files: 1255683; 2018-07-18 15:40:37 Hail: INFO: Coerced almost-sorted dataset; 2018-07-18 15:40:39 Hail: INFO: interval filter loaded 5 of 293 partitions; 2018-07-18 15:43:13 Hail: WARN: 126215 of 487409 samples have a missing phenotype or covariate.; 2018-07-18 15:43:13 Hail: INFO: linear_regression: running on 361194 samples for 110 response variables y,; with input variable x, intercept, and 25 additional covariates...; 2018-07-18 15:44:06 Hail: WARN: 132571 of 487409 samples have a missing phenotype or covariate.; 2018-07-18 15:44:06 Hail: INFO: linear_regression: running on 354838 samples for 1 response variable y,; with input variable x, intercept, and 25 additional covariates...; 2018-07-18 15:44:59 Hail: WARN: 132781 of 487409 samples have a missing phenotype or covariate.; 2018-07-18 15:44:59 Hail: INFO: linear_regression: running on 354628 samples for 1 response variable y,; with input variable x, intercept, and 25 additional covariates...; 2018-07-18 15:45:42 Hail: WARN: 133165 of 487409 samples have a missing phenotype or covariate.; 2018-07-18 15:45:42 Hail: INFO: linear_regression: running on 354244 samples for 1 response variable y,; with input variable x, intercept, and 25 additional covariates...; 2018-07-18 15:46:57 Hail: WARN: 132601 of 487409 samples have a missing phenotype or covariate.; 2018-0",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3945#issuecomment-405979965
https://github.com/hail-is/hail/pull/3945#issuecomment-405979965:1376,Modifiability,variab,variable,1376,"lics detected.; 2018-06-26 01:49:09 Hail: INFO: interval filter loaded 27 of 586 partitions; ```. I'll kill what I have and run a single regression, since this will take a long time.; ```; 2018-07-18 15:39:30 Hail: INFO: Number of BGEN files parsed: 1; 2018-07-18 15:39:30 Hail: INFO: Number of samples in BGEN files: 487409; 2018-07-18 15:39:30 Hail: INFO: Number of variants across all BGEN files: 1255683; 2018-07-18 15:40:37 Hail: INFO: Coerced almost-sorted dataset; 2018-07-18 15:40:39 Hail: INFO: interval filter loaded 5 of 293 partitions; 2018-07-18 15:43:13 Hail: WARN: 126215 of 487409 samples have a missing phenotype or covariate.; 2018-07-18 15:43:13 Hail: INFO: linear_regression: running on 361194 samples for 110 response variables y,; with input variable x, intercept, and 25 additional covariates...; 2018-07-18 15:44:06 Hail: WARN: 132571 of 487409 samples have a missing phenotype or covariate.; 2018-07-18 15:44:06 Hail: INFO: linear_regression: running on 354838 samples for 1 response variable y,; with input variable x, intercept, and 25 additional covariates...; 2018-07-18 15:44:59 Hail: WARN: 132781 of 487409 samples have a missing phenotype or covariate.; 2018-07-18 15:44:59 Hail: INFO: linear_regression: running on 354628 samples for 1 response variable y,; with input variable x, intercept, and 25 additional covariates...; 2018-07-18 15:45:42 Hail: WARN: 133165 of 487409 samples have a missing phenotype or covariate.; 2018-07-18 15:45:42 Hail: INFO: linear_regression: running on 354244 samples for 1 response variable y,; with input variable x, intercept, and 25 additional covariates...; 2018-07-18 15:46:57 Hail: WARN: 132601 of 487409 samples have a missing phenotype or covariate.; 2018-07-18 15:46:57 Hail: INFO: linear_regression: running on 354808 samples for 1 response variable y,; with input variable x, intercept, and 25 additional covariates...; ```. Also, the default parallelism in 0.1 was better for the same interval: 27 partitions to 5 partition",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3945#issuecomment-405979965
https://github.com/hail-is/hail/pull/3945#issuecomment-405979965:1400,Modifiability,variab,variable,1400,"lics detected.; 2018-06-26 01:49:09 Hail: INFO: interval filter loaded 27 of 586 partitions; ```. I'll kill what I have and run a single regression, since this will take a long time.; ```; 2018-07-18 15:39:30 Hail: INFO: Number of BGEN files parsed: 1; 2018-07-18 15:39:30 Hail: INFO: Number of samples in BGEN files: 487409; 2018-07-18 15:39:30 Hail: INFO: Number of variants across all BGEN files: 1255683; 2018-07-18 15:40:37 Hail: INFO: Coerced almost-sorted dataset; 2018-07-18 15:40:39 Hail: INFO: interval filter loaded 5 of 293 partitions; 2018-07-18 15:43:13 Hail: WARN: 126215 of 487409 samples have a missing phenotype or covariate.; 2018-07-18 15:43:13 Hail: INFO: linear_regression: running on 361194 samples for 110 response variables y,; with input variable x, intercept, and 25 additional covariates...; 2018-07-18 15:44:06 Hail: WARN: 132571 of 487409 samples have a missing phenotype or covariate.; 2018-07-18 15:44:06 Hail: INFO: linear_regression: running on 354838 samples for 1 response variable y,; with input variable x, intercept, and 25 additional covariates...; 2018-07-18 15:44:59 Hail: WARN: 132781 of 487409 samples have a missing phenotype or covariate.; 2018-07-18 15:44:59 Hail: INFO: linear_regression: running on 354628 samples for 1 response variable y,; with input variable x, intercept, and 25 additional covariates...; 2018-07-18 15:45:42 Hail: WARN: 133165 of 487409 samples have a missing phenotype or covariate.; 2018-07-18 15:45:42 Hail: INFO: linear_regression: running on 354244 samples for 1 response variable y,; with input variable x, intercept, and 25 additional covariates...; 2018-07-18 15:46:57 Hail: WARN: 132601 of 487409 samples have a missing phenotype or covariate.; 2018-07-18 15:46:57 Hail: INFO: linear_regression: running on 354808 samples for 1 response variable y,; with input variable x, intercept, and 25 additional covariates...; ```. Also, the default parallelism in 0.1 was better for the same interval: 27 partitions to 5 partition",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3945#issuecomment-405979965
https://github.com/hail-is/hail/pull/3945#issuecomment-405979965:1645,Modifiability,variab,variable,1645,"cs detected.; 2018-06-26 01:49:09 Hail: INFO: interval filter loaded 27 of 586 partitions; ```. I'll kill what I have and run a single regression, since this will take a long time.; ```; 2018-07-18 15:39:30 Hail: INFO: Number of BGEN files parsed: 1; 2018-07-18 15:39:30 Hail: INFO: Number of samples in BGEN files: 487409; 2018-07-18 15:39:30 Hail: INFO: Number of variants across all BGEN files: 1255683; 2018-07-18 15:40:37 Hail: INFO: Coerced almost-sorted dataset; 2018-07-18 15:40:39 Hail: INFO: interval filter loaded 5 of 293 partitions; 2018-07-18 15:43:13 Hail: WARN: 126215 of 487409 samples have a missing phenotype or covariate.; 2018-07-18 15:43:13 Hail: INFO: linear_regression: running on 361194 samples for 110 response variables y,; with input variable x, intercept, and 25 additional covariates...; 2018-07-18 15:44:06 Hail: WARN: 132571 of 487409 samples have a missing phenotype or covariate.; 2018-07-18 15:44:06 Hail: INFO: linear_regression: running on 354838 samples for 1 response variable y,; with input variable x, intercept, and 25 additional covariates...; 2018-07-18 15:44:59 Hail: WARN: 132781 of 487409 samples have a missing phenotype or covariate.; 2018-07-18 15:44:59 Hail: INFO: linear_regression: running on 354628 samples for 1 response variable y,; with input variable x, intercept, and 25 additional covariates...; 2018-07-18 15:45:42 Hail: WARN: 133165 of 487409 samples have a missing phenotype or covariate.; 2018-07-18 15:45:42 Hail: INFO: linear_regression: running on 354244 samples for 1 response variable y,; with input variable x, intercept, and 25 additional covariates...; 2018-07-18 15:46:57 Hail: WARN: 132601 of 487409 samples have a missing phenotype or covariate.; 2018-07-18 15:46:57 Hail: INFO: linear_regression: running on 354808 samples for 1 response variable y,; with input variable x, intercept, and 25 additional covariates...; ```. Also, the default parallelism in 0.1 was better for the same interval: 27 partitions to 5 partitions.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3945#issuecomment-405979965
https://github.com/hail-is/hail/pull/3945#issuecomment-405979965:1669,Modifiability,variab,variable,1669,"cs detected.; 2018-06-26 01:49:09 Hail: INFO: interval filter loaded 27 of 586 partitions; ```. I'll kill what I have and run a single regression, since this will take a long time.; ```; 2018-07-18 15:39:30 Hail: INFO: Number of BGEN files parsed: 1; 2018-07-18 15:39:30 Hail: INFO: Number of samples in BGEN files: 487409; 2018-07-18 15:39:30 Hail: INFO: Number of variants across all BGEN files: 1255683; 2018-07-18 15:40:37 Hail: INFO: Coerced almost-sorted dataset; 2018-07-18 15:40:39 Hail: INFO: interval filter loaded 5 of 293 partitions; 2018-07-18 15:43:13 Hail: WARN: 126215 of 487409 samples have a missing phenotype or covariate.; 2018-07-18 15:43:13 Hail: INFO: linear_regression: running on 361194 samples for 110 response variables y,; with input variable x, intercept, and 25 additional covariates...; 2018-07-18 15:44:06 Hail: WARN: 132571 of 487409 samples have a missing phenotype or covariate.; 2018-07-18 15:44:06 Hail: INFO: linear_regression: running on 354838 samples for 1 response variable y,; with input variable x, intercept, and 25 additional covariates...; 2018-07-18 15:44:59 Hail: WARN: 132781 of 487409 samples have a missing phenotype or covariate.; 2018-07-18 15:44:59 Hail: INFO: linear_regression: running on 354628 samples for 1 response variable y,; with input variable x, intercept, and 25 additional covariates...; 2018-07-18 15:45:42 Hail: WARN: 133165 of 487409 samples have a missing phenotype or covariate.; 2018-07-18 15:45:42 Hail: INFO: linear_regression: running on 354244 samples for 1 response variable y,; with input variable x, intercept, and 25 additional covariates...; 2018-07-18 15:46:57 Hail: WARN: 132601 of 487409 samples have a missing phenotype or covariate.; 2018-07-18 15:46:57 Hail: INFO: linear_regression: running on 354808 samples for 1 response variable y,; with input variable x, intercept, and 25 additional covariates...; ```. Also, the default parallelism in 0.1 was better for the same interval: 27 partitions to 5 partitions.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3945#issuecomment-405979965
https://github.com/hail-is/hail/pull/3945#issuecomment-405979965:1914,Modifiability,variab,variable,1914,"cs detected.; 2018-06-26 01:49:09 Hail: INFO: interval filter loaded 27 of 586 partitions; ```. I'll kill what I have and run a single regression, since this will take a long time.; ```; 2018-07-18 15:39:30 Hail: INFO: Number of BGEN files parsed: 1; 2018-07-18 15:39:30 Hail: INFO: Number of samples in BGEN files: 487409; 2018-07-18 15:39:30 Hail: INFO: Number of variants across all BGEN files: 1255683; 2018-07-18 15:40:37 Hail: INFO: Coerced almost-sorted dataset; 2018-07-18 15:40:39 Hail: INFO: interval filter loaded 5 of 293 partitions; 2018-07-18 15:43:13 Hail: WARN: 126215 of 487409 samples have a missing phenotype or covariate.; 2018-07-18 15:43:13 Hail: INFO: linear_regression: running on 361194 samples for 110 response variables y,; with input variable x, intercept, and 25 additional covariates...; 2018-07-18 15:44:06 Hail: WARN: 132571 of 487409 samples have a missing phenotype or covariate.; 2018-07-18 15:44:06 Hail: INFO: linear_regression: running on 354838 samples for 1 response variable y,; with input variable x, intercept, and 25 additional covariates...; 2018-07-18 15:44:59 Hail: WARN: 132781 of 487409 samples have a missing phenotype or covariate.; 2018-07-18 15:44:59 Hail: INFO: linear_regression: running on 354628 samples for 1 response variable y,; with input variable x, intercept, and 25 additional covariates...; 2018-07-18 15:45:42 Hail: WARN: 133165 of 487409 samples have a missing phenotype or covariate.; 2018-07-18 15:45:42 Hail: INFO: linear_regression: running on 354244 samples for 1 response variable y,; with input variable x, intercept, and 25 additional covariates...; 2018-07-18 15:46:57 Hail: WARN: 132601 of 487409 samples have a missing phenotype or covariate.; 2018-07-18 15:46:57 Hail: INFO: linear_regression: running on 354808 samples for 1 response variable y,; with input variable x, intercept, and 25 additional covariates...; ```. Also, the default parallelism in 0.1 was better for the same interval: 27 partitions to 5 partitions.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3945#issuecomment-405979965
https://github.com/hail-is/hail/pull/3945#issuecomment-405979965:1938,Modifiability,variab,variable,1938,"cs detected.; 2018-06-26 01:49:09 Hail: INFO: interval filter loaded 27 of 586 partitions; ```. I'll kill what I have and run a single regression, since this will take a long time.; ```; 2018-07-18 15:39:30 Hail: INFO: Number of BGEN files parsed: 1; 2018-07-18 15:39:30 Hail: INFO: Number of samples in BGEN files: 487409; 2018-07-18 15:39:30 Hail: INFO: Number of variants across all BGEN files: 1255683; 2018-07-18 15:40:37 Hail: INFO: Coerced almost-sorted dataset; 2018-07-18 15:40:39 Hail: INFO: interval filter loaded 5 of 293 partitions; 2018-07-18 15:43:13 Hail: WARN: 126215 of 487409 samples have a missing phenotype or covariate.; 2018-07-18 15:43:13 Hail: INFO: linear_regression: running on 361194 samples for 110 response variables y,; with input variable x, intercept, and 25 additional covariates...; 2018-07-18 15:44:06 Hail: WARN: 132571 of 487409 samples have a missing phenotype or covariate.; 2018-07-18 15:44:06 Hail: INFO: linear_regression: running on 354838 samples for 1 response variable y,; with input variable x, intercept, and 25 additional covariates...; 2018-07-18 15:44:59 Hail: WARN: 132781 of 487409 samples have a missing phenotype or covariate.; 2018-07-18 15:44:59 Hail: INFO: linear_regression: running on 354628 samples for 1 response variable y,; with input variable x, intercept, and 25 additional covariates...; 2018-07-18 15:45:42 Hail: WARN: 133165 of 487409 samples have a missing phenotype or covariate.; 2018-07-18 15:45:42 Hail: INFO: linear_regression: running on 354244 samples for 1 response variable y,; with input variable x, intercept, and 25 additional covariates...; 2018-07-18 15:46:57 Hail: WARN: 132601 of 487409 samples have a missing phenotype or covariate.; 2018-07-18 15:46:57 Hail: INFO: linear_regression: running on 354808 samples for 1 response variable y,; with input variable x, intercept, and 25 additional covariates...; ```. Also, the default parallelism in 0.1 was better for the same interval: 27 partitions to 5 partitions.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3945#issuecomment-405979965
https://github.com/hail-is/hail/pull/3945#issuecomment-405979965:2183,Modifiability,variab,variable,2183,"cs detected.; 2018-06-26 01:49:09 Hail: INFO: interval filter loaded 27 of 586 partitions; ```. I'll kill what I have and run a single regression, since this will take a long time.; ```; 2018-07-18 15:39:30 Hail: INFO: Number of BGEN files parsed: 1; 2018-07-18 15:39:30 Hail: INFO: Number of samples in BGEN files: 487409; 2018-07-18 15:39:30 Hail: INFO: Number of variants across all BGEN files: 1255683; 2018-07-18 15:40:37 Hail: INFO: Coerced almost-sorted dataset; 2018-07-18 15:40:39 Hail: INFO: interval filter loaded 5 of 293 partitions; 2018-07-18 15:43:13 Hail: WARN: 126215 of 487409 samples have a missing phenotype or covariate.; 2018-07-18 15:43:13 Hail: INFO: linear_regression: running on 361194 samples for 110 response variables y,; with input variable x, intercept, and 25 additional covariates...; 2018-07-18 15:44:06 Hail: WARN: 132571 of 487409 samples have a missing phenotype or covariate.; 2018-07-18 15:44:06 Hail: INFO: linear_regression: running on 354838 samples for 1 response variable y,; with input variable x, intercept, and 25 additional covariates...; 2018-07-18 15:44:59 Hail: WARN: 132781 of 487409 samples have a missing phenotype or covariate.; 2018-07-18 15:44:59 Hail: INFO: linear_regression: running on 354628 samples for 1 response variable y,; with input variable x, intercept, and 25 additional covariates...; 2018-07-18 15:45:42 Hail: WARN: 133165 of 487409 samples have a missing phenotype or covariate.; 2018-07-18 15:45:42 Hail: INFO: linear_regression: running on 354244 samples for 1 response variable y,; with input variable x, intercept, and 25 additional covariates...; 2018-07-18 15:46:57 Hail: WARN: 132601 of 487409 samples have a missing phenotype or covariate.; 2018-07-18 15:46:57 Hail: INFO: linear_regression: running on 354808 samples for 1 response variable y,; with input variable x, intercept, and 25 additional covariates...; ```. Also, the default parallelism in 0.1 was better for the same interval: 27 partitions to 5 partitions.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3945#issuecomment-405979965
https://github.com/hail-is/hail/pull/3945#issuecomment-405979965:2207,Modifiability,variab,variable,2207,"cs detected.; 2018-06-26 01:49:09 Hail: INFO: interval filter loaded 27 of 586 partitions; ```. I'll kill what I have and run a single regression, since this will take a long time.; ```; 2018-07-18 15:39:30 Hail: INFO: Number of BGEN files parsed: 1; 2018-07-18 15:39:30 Hail: INFO: Number of samples in BGEN files: 487409; 2018-07-18 15:39:30 Hail: INFO: Number of variants across all BGEN files: 1255683; 2018-07-18 15:40:37 Hail: INFO: Coerced almost-sorted dataset; 2018-07-18 15:40:39 Hail: INFO: interval filter loaded 5 of 293 partitions; 2018-07-18 15:43:13 Hail: WARN: 126215 of 487409 samples have a missing phenotype or covariate.; 2018-07-18 15:43:13 Hail: INFO: linear_regression: running on 361194 samples for 110 response variables y,; with input variable x, intercept, and 25 additional covariates...; 2018-07-18 15:44:06 Hail: WARN: 132571 of 487409 samples have a missing phenotype or covariate.; 2018-07-18 15:44:06 Hail: INFO: linear_regression: running on 354838 samples for 1 response variable y,; with input variable x, intercept, and 25 additional covariates...; 2018-07-18 15:44:59 Hail: WARN: 132781 of 487409 samples have a missing phenotype or covariate.; 2018-07-18 15:44:59 Hail: INFO: linear_regression: running on 354628 samples for 1 response variable y,; with input variable x, intercept, and 25 additional covariates...; 2018-07-18 15:45:42 Hail: WARN: 133165 of 487409 samples have a missing phenotype or covariate.; 2018-07-18 15:45:42 Hail: INFO: linear_regression: running on 354244 samples for 1 response variable y,; with input variable x, intercept, and 25 additional covariates...; 2018-07-18 15:46:57 Hail: WARN: 132601 of 487409 samples have a missing phenotype or covariate.; 2018-07-18 15:46:57 Hail: INFO: linear_regression: running on 354808 samples for 1 response variable y,; with input variable x, intercept, and 25 additional covariates...; ```. Also, the default parallelism in 0.1 was better for the same interval: 27 partitions to 5 partitions.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3945#issuecomment-405979965
https://github.com/hail-is/hail/pull/3945#issuecomment-405979965:431,Performance,load,loaded,431,"Looks like slightly slower in 0.1; ```; 2018-06-26 01:47:57 Hail: INFO: Number of BGEN files parsed: 1; 2018-06-26 01:47:57 Hail: INFO: Number of samples in BGEN files: 487409; 2018-06-26 01:47:57 Hail: INFO: Number of variants across all BGEN files: 1255683; 2018-06-26 01:49:08 Hail: INFO: Coerced almost-sorted dataset; 2018-06-26 01:49:08 Hail: INFO: No multiallelics detected.; 2018-06-26 01:49:09 Hail: INFO: interval filter loaded 27 of 586 partitions; ```. I'll kill what I have and run a single regression, since this will take a long time.; ```; 2018-07-18 15:39:30 Hail: INFO: Number of BGEN files parsed: 1; 2018-07-18 15:39:30 Hail: INFO: Number of samples in BGEN files: 487409; 2018-07-18 15:39:30 Hail: INFO: Number of variants across all BGEN files: 1255683; 2018-07-18 15:40:37 Hail: INFO: Coerced almost-sorted dataset; 2018-07-18 15:40:39 Hail: INFO: interval filter loaded 5 of 293 partitions; 2018-07-18 15:43:13 Hail: WARN: 126215 of 487409 samples have a missing phenotype or covariate.; 2018-07-18 15:43:13 Hail: INFO: linear_regression: running on 361194 samples for 110 response variables y,; with input variable x, intercept, and 25 additional covariates...; 2018-07-18 15:44:06 Hail: WARN: 132571 of 487409 samples have a missing phenotype or covariate.; 2018-07-18 15:44:06 Hail: INFO: linear_regression: running on 354838 samples for 1 response variable y,; with input variable x, intercept, and 25 additional covariates...; 2018-07-18 15:44:59 Hail: WARN: 132781 of 487409 samples have a missing phenotype or covariate.; 2018-07-18 15:44:59 Hail: INFO: linear_regression: running on 354628 samples for 1 response variable y,; with input variable x, intercept, and 25 additional covariates...; 2018-07-18 15:45:42 Hail: WARN: 133165 of 487409 samples have a missing phenotype or covariate.; 2018-07-18 15:45:42 Hail: INFO: linear_regression: running on 354244 samples for 1 response variable y,; with input variable x, intercept, and 25 additional covariates...; 2018-07",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3945#issuecomment-405979965
https://github.com/hail-is/hail/pull/3945#issuecomment-405979965:887,Performance,load,loaded,887,"Looks like slightly slower in 0.1; ```; 2018-06-26 01:47:57 Hail: INFO: Number of BGEN files parsed: 1; 2018-06-26 01:47:57 Hail: INFO: Number of samples in BGEN files: 487409; 2018-06-26 01:47:57 Hail: INFO: Number of variants across all BGEN files: 1255683; 2018-06-26 01:49:08 Hail: INFO: Coerced almost-sorted dataset; 2018-06-26 01:49:08 Hail: INFO: No multiallelics detected.; 2018-06-26 01:49:09 Hail: INFO: interval filter loaded 27 of 586 partitions; ```. I'll kill what I have and run a single regression, since this will take a long time.; ```; 2018-07-18 15:39:30 Hail: INFO: Number of BGEN files parsed: 1; 2018-07-18 15:39:30 Hail: INFO: Number of samples in BGEN files: 487409; 2018-07-18 15:39:30 Hail: INFO: Number of variants across all BGEN files: 1255683; 2018-07-18 15:40:37 Hail: INFO: Coerced almost-sorted dataset; 2018-07-18 15:40:39 Hail: INFO: interval filter loaded 5 of 293 partitions; 2018-07-18 15:43:13 Hail: WARN: 126215 of 487409 samples have a missing phenotype or covariate.; 2018-07-18 15:43:13 Hail: INFO: linear_regression: running on 361194 samples for 110 response variables y,; with input variable x, intercept, and 25 additional covariates...; 2018-07-18 15:44:06 Hail: WARN: 132571 of 487409 samples have a missing phenotype or covariate.; 2018-07-18 15:44:06 Hail: INFO: linear_regression: running on 354838 samples for 1 response variable y,; with input variable x, intercept, and 25 additional covariates...; 2018-07-18 15:44:59 Hail: WARN: 132781 of 487409 samples have a missing phenotype or covariate.; 2018-07-18 15:44:59 Hail: INFO: linear_regression: running on 354628 samples for 1 response variable y,; with input variable x, intercept, and 25 additional covariates...; 2018-07-18 15:45:42 Hail: WARN: 133165 of 487409 samples have a missing phenotype or covariate.; 2018-07-18 15:45:42 Hail: INFO: linear_regression: running on 354244 samples for 1 response variable y,; with input variable x, intercept, and 25 additional covariates...; 2018-07",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3945#issuecomment-405979965
https://github.com/hail-is/hail/pull/3945#issuecomment-405979965:372,Safety,detect,detected,372,"Looks like slightly slower in 0.1; ```; 2018-06-26 01:47:57 Hail: INFO: Number of BGEN files parsed: 1; 2018-06-26 01:47:57 Hail: INFO: Number of samples in BGEN files: 487409; 2018-06-26 01:47:57 Hail: INFO: Number of variants across all BGEN files: 1255683; 2018-06-26 01:49:08 Hail: INFO: Coerced almost-sorted dataset; 2018-06-26 01:49:08 Hail: INFO: No multiallelics detected.; 2018-06-26 01:49:09 Hail: INFO: interval filter loaded 27 of 586 partitions; ```. I'll kill what I have and run a single regression, since this will take a long time.; ```; 2018-07-18 15:39:30 Hail: INFO: Number of BGEN files parsed: 1; 2018-07-18 15:39:30 Hail: INFO: Number of samples in BGEN files: 487409; 2018-07-18 15:39:30 Hail: INFO: Number of variants across all BGEN files: 1255683; 2018-07-18 15:40:37 Hail: INFO: Coerced almost-sorted dataset; 2018-07-18 15:40:39 Hail: INFO: interval filter loaded 5 of 293 partitions; 2018-07-18 15:43:13 Hail: WARN: 126215 of 487409 samples have a missing phenotype or covariate.; 2018-07-18 15:43:13 Hail: INFO: linear_regression: running on 361194 samples for 110 response variables y,; with input variable x, intercept, and 25 additional covariates...; 2018-07-18 15:44:06 Hail: WARN: 132571 of 487409 samples have a missing phenotype or covariate.; 2018-07-18 15:44:06 Hail: INFO: linear_regression: running on 354838 samples for 1 response variable y,; with input variable x, intercept, and 25 additional covariates...; 2018-07-18 15:44:59 Hail: WARN: 132781 of 487409 samples have a missing phenotype or covariate.; 2018-07-18 15:44:59 Hail: INFO: linear_regression: running on 354628 samples for 1 response variable y,; with input variable x, intercept, and 25 additional covariates...; 2018-07-18 15:45:42 Hail: WARN: 133165 of 487409 samples have a missing phenotype or covariate.; 2018-07-18 15:45:42 Hail: INFO: linear_regression: running on 354244 samples for 1 response variable y,; with input variable x, intercept, and 25 additional covariates...; 2018-07",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3945#issuecomment-405979965
https://github.com/hail-is/hail/issues/3946#issuecomment-405779642:74,Deployability,update,update,74,"Hail 0.1 isn't tested against or believed to work with Spark 2.2. Can you update to Hail 0.2 (devel)? 0.1 will be fully deprecated when 0.2 is released, and is already in its end of life process.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3946#issuecomment-405779642
https://github.com/hail-is/hail/issues/3946#issuecomment-405779642:143,Deployability,release,released,143,"Hail 0.1 isn't tested against or believed to work with Spark 2.2. Can you update to Hail 0.2 (devel)? 0.1 will be fully deprecated when 0.2 is released, and is already in its end of life process.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3946#issuecomment-405779642
https://github.com/hail-is/hail/issues/3946#issuecomment-405779642:15,Testability,test,tested,15,"Hail 0.1 isn't tested against or believed to work with Spark 2.2. Can you update to Hail 0.2 (devel)? 0.1 will be fully deprecated when 0.2 is released, and is already in its end of life process.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3946#issuecomment-405779642
https://github.com/hail-is/hail/issues/3946#issuecomment-405779805:82,Energy Efficiency,efficient,efficient,82,"I'd also recommend that you leave files as BGEN if possible, as it's an extremely efficient format for encoding huge amounts of imputed genotype data.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3946#issuecomment-405779805
https://github.com/hail-is/hail/pull/3948#issuecomment-405962693:163,Integrability,interface,interface,163,"Rebased, should be ready for a look. I included the compile the decoder once change in this PR. I left in the entry and row field arguments so as not to break the interface, but we can reasonably delete those now that it is playing nicely with the field pruner.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3948#issuecomment-405962693
https://github.com/hail-is/hail/pull/3948#issuecomment-407168009:39,Testability,test,testng,39,@danking I tried the latest version of testng and it didn't fix the problem see my PR #3964,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3948#issuecomment-407168009
https://github.com/hail-is/hail/issues/3953#issuecomment-406016947:14,Performance,perform,perform,14,all our joins perform horribly if both sides don't have a reasonable number of partitions,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3953#issuecomment-406016947
https://github.com/hail-is/hail/issues/3953#issuecomment-406017529:137,Deployability,pipeline,pipeline,137,"There will probably still be a lot of partitions, but those that remain only include rows with keys matching those in `pcloadings`. This pipeline includes the special bgen variant filtering I added.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3953#issuecomment-406017529
https://github.com/hail-is/hail/issues/3953#issuecomment-406020938:60,Performance,perform,performance,60,I imagine a mismatch in number of partitions still causes a performance issue?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3953#issuecomment-406020938
https://github.com/hail-is/hail/issues/3955#issuecomment-406297780:27,Deployability,upgrade,upgraded,27,"I have a branch where I've upgraded the dependency to libsimdpp-2.1 and resolved issues around depreciation warnings, this does solve the issue. We would need to discuss if we want to upgrade the dependency, and benchmark against the new version to see if it causes any performance regression. Branch is [here](https://github.com/chrisvittal/hail/tree/libsimdpp-2.1)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3955#issuecomment-406297780
https://github.com/hail-is/hail/issues/3955#issuecomment-406297780:184,Deployability,upgrade,upgrade,184,"I have a branch where I've upgraded the dependency to libsimdpp-2.1 and resolved issues around depreciation warnings, this does solve the issue. We would need to discuss if we want to upgrade the dependency, and benchmark against the new version to see if it causes any performance regression. Branch is [here](https://github.com/chrisvittal/hail/tree/libsimdpp-2.1)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3955#issuecomment-406297780
https://github.com/hail-is/hail/issues/3955#issuecomment-406297780:40,Integrability,depend,dependency,40,"I have a branch where I've upgraded the dependency to libsimdpp-2.1 and resolved issues around depreciation warnings, this does solve the issue. We would need to discuss if we want to upgrade the dependency, and benchmark against the new version to see if it causes any performance regression. Branch is [here](https://github.com/chrisvittal/hail/tree/libsimdpp-2.1)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3955#issuecomment-406297780
https://github.com/hail-is/hail/issues/3955#issuecomment-406297780:196,Integrability,depend,dependency,196,"I have a branch where I've upgraded the dependency to libsimdpp-2.1 and resolved issues around depreciation warnings, this does solve the issue. We would need to discuss if we want to upgrade the dependency, and benchmark against the new version to see if it causes any performance regression. Branch is [here](https://github.com/chrisvittal/hail/tree/libsimdpp-2.1)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3955#issuecomment-406297780
https://github.com/hail-is/hail/issues/3955#issuecomment-406297780:270,Performance,perform,performance,270,"I have a branch where I've upgraded the dependency to libsimdpp-2.1 and resolved issues around depreciation warnings, this does solve the issue. We would need to discuss if we want to upgrade the dependency, and benchmark against the new version to see if it causes any performance regression. Branch is [here](https://github.com/chrisvittal/hail/tree/libsimdpp-2.1)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3955#issuecomment-406297780
https://github.com/hail-is/hail/issues/3955#issuecomment-406297780:212,Testability,benchmark,benchmark,212,"I have a branch where I've upgraded the dependency to libsimdpp-2.1 and resolved issues around depreciation warnings, this does solve the issue. We would need to discuss if we want to upgrade the dependency, and benchmark against the new version to see if it causes any performance regression. Branch is [here](https://github.com/chrisvittal/hail/tree/libsimdpp-2.1)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3955#issuecomment-406297780
https://github.com/hail-is/hail/pull/3972#issuecomment-407388967:36,Deployability,update,updates,36,@tpoterba this PR now also contains updates to the Python docs for additional plotting functions,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3972#issuecomment-407388967
https://github.com/hail-is/hail/pull/3973#issuecomment-407205066:219,Availability,reliab,reliably,219,"I'm not sure quite what we want to do about the DLLs under prebuilt. In the world of dynamic-generated C++, you're going to be linking C++ code compiled on; the master node against libhail. And that isn't going to work reliably if the libhail is; prebuilt, with no guarantees about which compiler/version is used either for the libhail,; or for the dynamic-generated code. The current kludge is that src/main/c/Makefile copies newly-built libraries into prebuilt -; so that *if* you've built from source, then those will be compiled with your compiler.; But it's going to be a crapshoot if you haven't built from source, because the prebuilt; libraries may not work a) against whatever libstdc++.so you have, and b) against your; fresh dynamic-compiled C++.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-407205066
https://github.com/hail-is/hail/pull/3973#issuecomment-408479218:415,Availability,robust,robust,415,"The design of NativeModule's handling of files (which may involve several worker threads; each trying to initialize their own NativeModule referring to the same DLL) assumed that; /bin/mv would do an atomic rename to replace an old DLL with a newer version. But on; MacOS /bin/mv is non-atomic, and leaves a window between deleting the old file and ; replacing it with the new one. I'm working on details of a more robust file-synchronization scheme, once that's ok I'll; backport it here and also address the review comments.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-408479218
https://github.com/hail-is/hail/pull/3973#issuecomment-408479218:427,Integrability,synchroniz,synchronization,427,"The design of NativeModule's handling of files (which may involve several worker threads; each trying to initialize their own NativeModule referring to the same DLL) assumed that; /bin/mv would do an atomic rename to replace an old DLL with a newer version. But on; MacOS /bin/mv is non-atomic, and leaves a window between deleting the old file and ; replacing it with the new one. I'm working on details of a more robust file-synchronization scheme, once that's ok I'll; backport it here and also address the review comments.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-408479218
https://github.com/hail-is/hail/pull/3973#issuecomment-409695090:102,Testability,test,test,102,"- Backported some changes needed to unpack C++ headers from a jar (which doesn't happen; in the Scala test environment, but is essential for running w/ Spark). - Made various changes in response to review comments. I still have a chunk of work to do on the src/main/c/Makefile and building libraries; which can run on both C++ ABI v2 (gcc-5.x and later) and C++ ABI v1 (gcc-4.x, in particular; gcc-4.8.3 as on CI machines).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-409695090
https://github.com/hail-is/hail/pull/3973#issuecomment-410014637:26,Testability,test,testing,26,This ABI thing needs good testing that is hard to do with our current infrastructure. I almost don't want to merge this until we are actually running tests on a GCP dataproc cluster.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-410014637
https://github.com/hail-is/hail/pull/3973#issuecomment-410014637:150,Testability,test,tests,150,This ABI thing needs good testing that is hard to do with our current infrastructure. I almost don't want to merge this until we are actually running tests on a GCP dataproc cluster.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-410014637
https://github.com/hail-is/hail/pull/3973#issuecomment-410111491:797,Availability,down,down,797,"After spending a couple of hours reading about g++ ABI versions, I'm feeling much less; positive about the plan of building multiple libraries. It seems there are 11 different ABI versions; (most of them are minor bugfixes which were never default behavior for any version of g++,; but still ...). I'm mulling an alternative plan of saying ""well, you've got to have g++, c++, or clang++ somewhere; on your $PATH, or else you've got to define CXX, and also make, but I've got the C++ sources in the ; jarfile and I'll build you a fresh libboot.so and libhail.so if I haven't done it already"". That would involve a little bit more jarfile/Resource magic - but nothing any harder than I've already; done with the header files; avoid a big testing headache; and I hope get us past the whole; ""locking-down"" argument. And then at a later date I'll think about how to have the option of packaging; a recent clang so that we can get C++17 (and perhaps more consistent compile speed than g++); across a wide range on Linuxes. Accordingly I'll close this for now and re-open it when I have a working solution for the library issue.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-410111491
https://github.com/hail-is/hail/pull/3973#issuecomment-410111491:724,Safety,avoid,avoid,724,"After spending a couple of hours reading about g++ ABI versions, I'm feeling much less; positive about the plan of building multiple libraries. It seems there are 11 different ABI versions; (most of them are minor bugfixes which were never default behavior for any version of g++,; but still ...). I'm mulling an alternative plan of saying ""well, you've got to have g++, c++, or clang++ somewhere; on your $PATH, or else you've got to define CXX, and also make, but I've got the C++ sources in the ; jarfile and I'll build you a fresh libboot.so and libhail.so if I haven't done it already"". That would involve a little bit more jarfile/Resource magic - but nothing any harder than I've already; done with the header files; avoid a big testing headache; and I hope get us past the whole; ""locking-down"" argument. And then at a later date I'll think about how to have the option of packaging; a recent clang so that we can get C++17 (and perhaps more consistent compile speed than g++); across a wide range on Linuxes. Accordingly I'll close this for now and re-open it when I have a working solution for the library issue.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-410111491
https://github.com/hail-is/hail/pull/3973#issuecomment-410111491:736,Testability,test,testing,736,"After spending a couple of hours reading about g++ ABI versions, I'm feeling much less; positive about the plan of building multiple libraries. It seems there are 11 different ABI versions; (most of them are minor bugfixes which were never default behavior for any version of g++,; but still ...). I'm mulling an alternative plan of saying ""well, you've got to have g++, c++, or clang++ somewhere; on your $PATH, or else you've got to define CXX, and also make, but I've got the C++ sources in the ; jarfile and I'll build you a fresh libboot.so and libhail.so if I haven't done it already"". That would involve a little bit more jarfile/Resource magic - but nothing any harder than I've already; done with the header files; avoid a big testing headache; and I hope get us past the whole; ""locking-down"" argument. And then at a later date I'll think about how to have the option of packaging; a recent clang so that we can get C++17 (and perhaps more consistent compile speed than g++); across a wide range on Linuxes. Accordingly I'll close this for now and re-open it when I have a working solution for the library issue.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-410111491
https://github.com/hail-is/hail/pull/3973#issuecomment-410112135:334,Deployability,upgrade,upgrade,334,"> I still have a chunk of work to do on the src/main/c/Makefile and building libraries; which can run on both C++ ABI v2 (gcc-5.x and later) and C++ ABI v1 (gcc-4.x, in particular; gcc-4.8.3 as on CI machines). This seems like a waste. Also, weren't we going to standardize on c++17? We should never see ABI v1, should we? You should upgrade the CI machine (or wait until @danking's new CI goes live.)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-410112135
https://github.com/hail-is/hail/pull/3973#issuecomment-410112524:76,Integrability,depend,dependencies,76,Just saw your final comment. Do you see a problem with shipping our C++ ABI dependencies?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-410112524
https://github.com/hail-is/hail/pull/3973#issuecomment-410127709:237,Availability,error,error,237,"We have a difference of opinion about the risks involved in using whatever; compiler happens to show up as $(CXX); to try to compile arbitrarily large auto-generated C++ files, and maybe; about what happens when that fails; and gives an error message about something in the middle of 12000 lines of; code that bears no obvious relationship; to what the user is doing. Or when that compiler takes 15 minutes to; compile it. It's the C++ equivalent of; the JVM ""no, that's just too much bytecode"". Or worst of all, it compiles; it but the code gives the wrong answers; because that particular compiler has a bug, and we never tested the; combination of our codegen with *that*; compiler/version. A couple of years ago I was seeing g++ take 40-60 seconds to compile; something that clang did in 2 seconds; (fairly heavily templated code generated for an SQL query, so very much in; the same ballpark as parts of Hail),; which contributes to my concern about this, especially on linux where g++; is the default. So in the long run I expect we'll ship a compiler, or specify a compiler.; But that becomes a problem in itself; if we want the shipped compiler to work on a variety of OS'es. When I did; that before it was all Ubuntu-14.04; and Ubuntu-16.04, and it was manageable to build it for two platforms. On Thu, Aug 2, 2018 at 9:59 PM cseed <notifications@github.com> wrote:. > *@cseed* commented on this pull request.; > ------------------------------; >; > In src/main/c/NativeModule.cpp; > <https://github.com/hail-is/hail/pull/3973#discussion_r207422997>:; >; > > +}; > +; > +std::string strip_suffix(const std::string& s, const char* suffix) {; > + size_t len = s.length();; > + size_t n = strlen(suffix);; > + if ((n > len) || (strncmp(&s[len-n], suffix, n) != 0)) return s;; > + return std::string(s, 0, len-n);; > +}; > +; > +std::string get_cxx_name() {; > + char* p = ::getenv(""CXX"");; > + if (p) return std::string(p);; > + // We prefer clang because it has faster compile; > + auto s = run",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-410127709
https://github.com/hail-is/hail/pull/3973#issuecomment-410127709:243,Integrability,message,message,243,"We have a difference of opinion about the risks involved in using whatever; compiler happens to show up as $(CXX); to try to compile arbitrarily large auto-generated C++ files, and maybe; about what happens when that fails; and gives an error message about something in the middle of 12000 lines of; code that bears no obvious relationship; to what the user is doing. Or when that compiler takes 15 minutes to; compile it. It's the C++ equivalent of; the JVM ""no, that's just too much bytecode"". Or worst of all, it compiles; it but the code gives the wrong answers; because that particular compiler has a bug, and we never tested the; combination of our codegen with *that*; compiler/version. A couple of years ago I was seeing g++ take 40-60 seconds to compile; something that clang did in 2 seconds; (fairly heavily templated code generated for an SQL query, so very much in; the same ballpark as parts of Hail),; which contributes to my concern about this, especially on linux where g++; is the default. So in the long run I expect we'll ship a compiler, or specify a compiler.; But that becomes a problem in itself; if we want the shipped compiler to work on a variety of OS'es. When I did; that before it was all Ubuntu-14.04; and Ubuntu-16.04, and it was manageable to build it for two platforms. On Thu, Aug 2, 2018 at 9:59 PM cseed <notifications@github.com> wrote:. > *@cseed* commented on this pull request.; > ------------------------------; >; > In src/main/c/NativeModule.cpp; > <https://github.com/hail-is/hail/pull/3973#discussion_r207422997>:; >; > > +}; > +; > +std::string strip_suffix(const std::string& s, const char* suffix) {; > + size_t len = s.length();; > + size_t n = strlen(suffix);; > + if ((n > len) || (strncmp(&s[len-n], suffix, n) != 0)) return s;; > + return std::string(s, 0, len-n);; > +}; > +; > +std::string get_cxx_name() {; > + char* p = ::getenv(""CXX"");; > + if (p) return std::string(p);; > + // We prefer clang because it has faster compile; > + auto s = run",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-410127709
https://github.com/hail-is/hail/pull/3973#issuecomment-410127709:3008,Performance,cache,cached,3008," <https://github.com/hail-is/hail/pull/3973#discussion_r207422997>:; >; > > +}; > +; > +std::string strip_suffix(const std::string& s, const char* suffix) {; > + size_t len = s.length();; > + size_t n = strlen(suffix);; > + if ((n > len) || (strncmp(&s[len-n], suffix, n) != 0)) return s;; > + return std::string(s, 0, len-n);; > +}; > +; > +std::string get_cxx_name() {; > + char* p = ::getenv(""CXX"");; > + if (p) return std::string(p);; > + // We prefer clang because it has faster compile; > + auto s = run_shell_get_first_line(""which clang"");; > + if (strstr(s.c_str(), ""clang"")) return s;; > + s = run_shell_get_first_line(""which g++"");; >; > I'm lazy and I want to save my thinking for stuff where I can really; > provide value (like building a whole stage code generator, or designing a; > new format to speed up the decoder!) If there are standards, I want to use; > them so I don't have to think unless I have a strong reason to think they; > won't work for me. It also makes communicating with others easier who are; > expecting the same standards. So I'd just kick out a Makefile and call make; > on it like I would for any project (and maybe print out some helpful info; > when it fails like the make command, the path to the Makefile and maybe the; > environment). I didn't realize it would be such a hard sell because I; > thought I was proposing the easy path which was the least work. I like the; > easy path! And if it means we can get this in and start building on it, all; > the better.; >; > The cached Makefile isn't actually reused. ... It's occasionally useful to; > run it by hand for debugging.; >; > Ah, thanks for clarifying. Definitely.; >; > ; > You are receiving this because you modified the open/close state.; > Reply to this email directly, view it on GitHub; > <https://github.com/hail-is/hail/pull/3973#discussion_r207422997>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AJzExsJ8Hk-GuvDywoKPy8DF_SSBqgG-ks5uM66RgaJpZM4VbZpP>; > .; >",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-410127709
https://github.com/hail-is/hail/pull/3973#issuecomment-410127709:42,Safety,risk,risks,42,"We have a difference of opinion about the risks involved in using whatever; compiler happens to show up as $(CXX); to try to compile arbitrarily large auto-generated C++ files, and maybe; about what happens when that fails; and gives an error message about something in the middle of 12000 lines of; code that bears no obvious relationship; to what the user is doing. Or when that compiler takes 15 minutes to; compile it. It's the C++ equivalent of; the JVM ""no, that's just too much bytecode"". Or worst of all, it compiles; it but the code gives the wrong answers; because that particular compiler has a bug, and we never tested the; combination of our codegen with *that*; compiler/version. A couple of years ago I was seeing g++ take 40-60 seconds to compile; something that clang did in 2 seconds; (fairly heavily templated code generated for an SQL query, so very much in; the same ballpark as parts of Hail),; which contributes to my concern about this, especially on linux where g++; is the default. So in the long run I expect we'll ship a compiler, or specify a compiler.; But that becomes a problem in itself; if we want the shipped compiler to work on a variety of OS'es. When I did; that before it was all Ubuntu-14.04; and Ubuntu-16.04, and it was manageable to build it for two platforms. On Thu, Aug 2, 2018 at 9:59 PM cseed <notifications@github.com> wrote:. > *@cseed* commented on this pull request.; > ------------------------------; >; > In src/main/c/NativeModule.cpp; > <https://github.com/hail-is/hail/pull/3973#discussion_r207422997>:; >; > > +}; > +; > +std::string strip_suffix(const std::string& s, const char* suffix) {; > + size_t len = s.length();; > + size_t n = strlen(suffix);; > + if ((n > len) || (strncmp(&s[len-n], suffix, n) != 0)) return s;; > + return std::string(s, 0, len-n);; > +}; > +; > +std::string get_cxx_name() {; > + char* p = ::getenv(""CXX"");; > + if (p) return std::string(p);; > + // We prefer clang because it has faster compile; > + auto s = run",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-410127709
https://github.com/hail-is/hail/pull/3973#issuecomment-410127709:624,Testability,test,tested,624,"We have a difference of opinion about the risks involved in using whatever; compiler happens to show up as $(CXX); to try to compile arbitrarily large auto-generated C++ files, and maybe; about what happens when that fails; and gives an error message about something in the middle of 12000 lines of; code that bears no obvious relationship; to what the user is doing. Or when that compiler takes 15 minutes to; compile it. It's the C++ equivalent of; the JVM ""no, that's just too much bytecode"". Or worst of all, it compiles; it but the code gives the wrong answers; because that particular compiler has a bug, and we never tested the; combination of our codegen with *that*; compiler/version. A couple of years ago I was seeing g++ take 40-60 seconds to compile; something that clang did in 2 seconds; (fairly heavily templated code generated for an SQL query, so very much in; the same ballpark as parts of Hail),; which contributes to my concern about this, especially on linux where g++; is the default. So in the long run I expect we'll ship a compiler, or specify a compiler.; But that becomes a problem in itself; if we want the shipped compiler to work on a variety of OS'es. When I did; that before it was all Ubuntu-14.04; and Ubuntu-16.04, and it was manageable to build it for two platforms. On Thu, Aug 2, 2018 at 9:59 PM cseed <notifications@github.com> wrote:. > *@cseed* commented on this pull request.; > ------------------------------; >; > In src/main/c/NativeModule.cpp; > <https://github.com/hail-is/hail/pull/3973#discussion_r207422997>:; >; > > +}; > +; > +std::string strip_suffix(const std::string& s, const char* suffix) {; > + size_t len = s.length();; > + size_t n = strlen(suffix);; > + if ((n > len) || (strncmp(&s[len-n], suffix, n) != 0)) return s;; > + return std::string(s, 0, len-n);; > +}; > +; > +std::string get_cxx_name() {; > + char* p = ::getenv(""CXX"");; > + if (p) return std::string(p);; > + // We prefer clang because it has faster compile; > + auto s = run",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-410127709
https://github.com/hail-is/hail/pull/3973#issuecomment-410134414:1515,Availability,down,download,1515," directly to your last comment. > We have a difference of opinion about the risks. I think I'd say we have a difference of opinion about the importance of the risks. I'm well aware of the potential pitfalls you list there, and more. I just don't think they're a very big deal. I'm also aware of a shit ton of things that are vastly more important than what we're arguing about and we're not talking about those. Let's talk about goals for the project and the landscape of technical risk in our next 1:1. This is assuming we're controlling the compiler in the packaged distribution and on the cloud, we're testing representative user pipelines against gcc and clang, so the scenario you're imagining is either a Hail developer or someone who is sophisticated enough to maintain a Spark cluster (1000x worse configuration nonsense than we're arguing about here, I promise) who is either (1) running old or obscure compiler, or (2) ran into a bug that had test coverage. You're worrying about (1)? What's the worst that will happen, seriously? We'll get a bug report? Let's make sure the compiler version is in the log. > A couple of years ago; > g++ take 40-60 seconds to compile; > fairly heavily templated cod. Can we avoid heavily (or even moderately) templated code? I'm already nervous long-term about the latency of the C++ compiler overhead and if I'm being honest would prefer to generate LLVM IR directly into memory. We should ship whatever compiler is best on the cloud and in the download package. That already covers a vast majority of our users. If clang is the clear winner, we can make that clear in the documentation and maybe warn about gcc it on startup. > But that becomes a problem in itself if we want the shipped compiler to work on a variety of OS'es. Variety isn't a requirement. We don't need to make this hard for ourselves. Let's have two versions: OSX and a recent linux. If we're getting a lot of requests/questions/issues about older versions of linux, we can reevaluate.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-410134414
https://github.com/hail-is/hail/pull/3973#issuecomment-410134414:658,Deployability,pipeline,pipelines,658,"Strange, I can't reply to directly to your last comment. > We have a difference of opinion about the risks. I think I'd say we have a difference of opinion about the importance of the risks. I'm well aware of the potential pitfalls you list there, and more. I just don't think they're a very big deal. I'm also aware of a shit ton of things that are vastly more important than what we're arguing about and we're not talking about those. Let's talk about goals for the project and the landscape of technical risk in our next 1:1. This is assuming we're controlling the compiler in the packaged distribution and on the cloud, we're testing representative user pipelines against gcc and clang, so the scenario you're imagining is either a Hail developer or someone who is sophisticated enough to maintain a Spark cluster (1000x worse configuration nonsense than we're arguing about here, I promise) who is either (1) running old or obscure compiler, or (2) ran into a bug that had test coverage. You're worrying about (1)? What's the worst that will happen, seriously? We'll get a bug report? Let's make sure the compiler version is in the log. > A couple of years ago; > g++ take 40-60 seconds to compile; > fairly heavily templated cod. Can we avoid heavily (or even moderately) templated code? I'm already nervous long-term about the latency of the C++ compiler overhead and if I'm being honest would prefer to generate LLVM IR directly into memory. We should ship whatever compiler is best on the cloud and in the download package. That already covers a vast majority of our users. If clang is the clear winner, we can make that clear in the documentation and maybe warn about gcc it on startup. > But that becomes a problem in itself if we want the shipped compiler to work on a variety of OS'es. Variety isn't a requirement. We don't need to make this hard for ourselves. Let's have two versions: OSX and a recent linux. If we're getting a lot of requests/questions/issues about older versions of l",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-410134414
https://github.com/hail-is/hail/pull/3973#issuecomment-410134414:831,Deployability,configurat,configuration,831,"Strange, I can't reply to directly to your last comment. > We have a difference of opinion about the risks. I think I'd say we have a difference of opinion about the importance of the risks. I'm well aware of the potential pitfalls you list there, and more. I just don't think they're a very big deal. I'm also aware of a shit ton of things that are vastly more important than what we're arguing about and we're not talking about those. Let's talk about goals for the project and the landscape of technical risk in our next 1:1. This is assuming we're controlling the compiler in the packaged distribution and on the cloud, we're testing representative user pipelines against gcc and clang, so the scenario you're imagining is either a Hail developer or someone who is sophisticated enough to maintain a Spark cluster (1000x worse configuration nonsense than we're arguing about here, I promise) who is either (1) running old or obscure compiler, or (2) ran into a bug that had test coverage. You're worrying about (1)? What's the worst that will happen, seriously? We'll get a bug report? Let's make sure the compiler version is in the log. > A couple of years ago; > g++ take 40-60 seconds to compile; > fairly heavily templated cod. Can we avoid heavily (or even moderately) templated code? I'm already nervous long-term about the latency of the C++ compiler overhead and if I'm being honest would prefer to generate LLVM IR directly into memory. We should ship whatever compiler is best on the cloud and in the download package. That already covers a vast majority of our users. If clang is the clear winner, we can make that clear in the documentation and maybe warn about gcc it on startup. > But that becomes a problem in itself if we want the shipped compiler to work on a variety of OS'es. Variety isn't a requirement. We don't need to make this hard for ourselves. Let's have two versions: OSX and a recent linux. If we're getting a lot of requests/questions/issues about older versions of l",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-410134414
https://github.com/hail-is/hail/pull/3973#issuecomment-410134414:831,Modifiability,config,configuration,831,"Strange, I can't reply to directly to your last comment. > We have a difference of opinion about the risks. I think I'd say we have a difference of opinion about the importance of the risks. I'm well aware of the potential pitfalls you list there, and more. I just don't think they're a very big deal. I'm also aware of a shit ton of things that are vastly more important than what we're arguing about and we're not talking about those. Let's talk about goals for the project and the landscape of technical risk in our next 1:1. This is assuming we're controlling the compiler in the packaged distribution and on the cloud, we're testing representative user pipelines against gcc and clang, so the scenario you're imagining is either a Hail developer or someone who is sophisticated enough to maintain a Spark cluster (1000x worse configuration nonsense than we're arguing about here, I promise) who is either (1) running old or obscure compiler, or (2) ran into a bug that had test coverage. You're worrying about (1)? What's the worst that will happen, seriously? We'll get a bug report? Let's make sure the compiler version is in the log. > A couple of years ago; > g++ take 40-60 seconds to compile; > fairly heavily templated cod. Can we avoid heavily (or even moderately) templated code? I'm already nervous long-term about the latency of the C++ compiler overhead and if I'm being honest would prefer to generate LLVM IR directly into memory. We should ship whatever compiler is best on the cloud and in the download package. That already covers a vast majority of our users. If clang is the clear winner, we can make that clear in the documentation and maybe warn about gcc it on startup. > But that becomes a problem in itself if we want the shipped compiler to work on a variety of OS'es. Variety isn't a requirement. We don't need to make this hard for ourselves. Let's have two versions: OSX and a recent linux. If we're getting a lot of requests/questions/issues about older versions of l",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-410134414
https://github.com/hail-is/hail/pull/3973#issuecomment-410134414:1334,Performance,latency,latency,1334," directly to your last comment. > We have a difference of opinion about the risks. I think I'd say we have a difference of opinion about the importance of the risks. I'm well aware of the potential pitfalls you list there, and more. I just don't think they're a very big deal. I'm also aware of a shit ton of things that are vastly more important than what we're arguing about and we're not talking about those. Let's talk about goals for the project and the landscape of technical risk in our next 1:1. This is assuming we're controlling the compiler in the packaged distribution and on the cloud, we're testing representative user pipelines against gcc and clang, so the scenario you're imagining is either a Hail developer or someone who is sophisticated enough to maintain a Spark cluster (1000x worse configuration nonsense than we're arguing about here, I promise) who is either (1) running old or obscure compiler, or (2) ran into a bug that had test coverage. You're worrying about (1)? What's the worst that will happen, seriously? We'll get a bug report? Let's make sure the compiler version is in the log. > A couple of years ago; > g++ take 40-60 seconds to compile; > fairly heavily templated cod. Can we avoid heavily (or even moderately) templated code? I'm already nervous long-term about the latency of the C++ compiler overhead and if I'm being honest would prefer to generate LLVM IR directly into memory. We should ship whatever compiler is best on the cloud and in the download package. That already covers a vast majority of our users. If clang is the clear winner, we can make that clear in the documentation and maybe warn about gcc it on startup. > But that becomes a problem in itself if we want the shipped compiler to work on a variety of OS'es. Variety isn't a requirement. We don't need to make this hard for ourselves. Let's have two versions: OSX and a recent linux. If we're getting a lot of requests/questions/issues about older versions of linux, we can reevaluate.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-410134414
https://github.com/hail-is/hail/pull/3973#issuecomment-410134414:101,Safety,risk,risks,101,"Strange, I can't reply to directly to your last comment. > We have a difference of opinion about the risks. I think I'd say we have a difference of opinion about the importance of the risks. I'm well aware of the potential pitfalls you list there, and more. I just don't think they're a very big deal. I'm also aware of a shit ton of things that are vastly more important than what we're arguing about and we're not talking about those. Let's talk about goals for the project and the landscape of technical risk in our next 1:1. This is assuming we're controlling the compiler in the packaged distribution and on the cloud, we're testing representative user pipelines against gcc and clang, so the scenario you're imagining is either a Hail developer or someone who is sophisticated enough to maintain a Spark cluster (1000x worse configuration nonsense than we're arguing about here, I promise) who is either (1) running old or obscure compiler, or (2) ran into a bug that had test coverage. You're worrying about (1)? What's the worst that will happen, seriously? We'll get a bug report? Let's make sure the compiler version is in the log. > A couple of years ago; > g++ take 40-60 seconds to compile; > fairly heavily templated cod. Can we avoid heavily (or even moderately) templated code? I'm already nervous long-term about the latency of the C++ compiler overhead and if I'm being honest would prefer to generate LLVM IR directly into memory. We should ship whatever compiler is best on the cloud and in the download package. That already covers a vast majority of our users. If clang is the clear winner, we can make that clear in the documentation and maybe warn about gcc it on startup. > But that becomes a problem in itself if we want the shipped compiler to work on a variety of OS'es. Variety isn't a requirement. We don't need to make this hard for ourselves. Let's have two versions: OSX and a recent linux. If we're getting a lot of requests/questions/issues about older versions of l",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-410134414
https://github.com/hail-is/hail/pull/3973#issuecomment-410134414:184,Safety,risk,risks,184,"Strange, I can't reply to directly to your last comment. > We have a difference of opinion about the risks. I think I'd say we have a difference of opinion about the importance of the risks. I'm well aware of the potential pitfalls you list there, and more. I just don't think they're a very big deal. I'm also aware of a shit ton of things that are vastly more important than what we're arguing about and we're not talking about those. Let's talk about goals for the project and the landscape of technical risk in our next 1:1. This is assuming we're controlling the compiler in the packaged distribution and on the cloud, we're testing representative user pipelines against gcc and clang, so the scenario you're imagining is either a Hail developer or someone who is sophisticated enough to maintain a Spark cluster (1000x worse configuration nonsense than we're arguing about here, I promise) who is either (1) running old or obscure compiler, or (2) ran into a bug that had test coverage. You're worrying about (1)? What's the worst that will happen, seriously? We'll get a bug report? Let's make sure the compiler version is in the log. > A couple of years ago; > g++ take 40-60 seconds to compile; > fairly heavily templated cod. Can we avoid heavily (or even moderately) templated code? I'm already nervous long-term about the latency of the C++ compiler overhead and if I'm being honest would prefer to generate LLVM IR directly into memory. We should ship whatever compiler is best on the cloud and in the download package. That already covers a vast majority of our users. If clang is the clear winner, we can make that clear in the documentation and maybe warn about gcc it on startup. > But that becomes a problem in itself if we want the shipped compiler to work on a variety of OS'es. Variety isn't a requirement. We don't need to make this hard for ourselves. Let's have two versions: OSX and a recent linux. If we're getting a lot of requests/questions/issues about older versions of l",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-410134414
https://github.com/hail-is/hail/pull/3973#issuecomment-410134414:507,Safety,risk,risk,507,"Strange, I can't reply to directly to your last comment. > We have a difference of opinion about the risks. I think I'd say we have a difference of opinion about the importance of the risks. I'm well aware of the potential pitfalls you list there, and more. I just don't think they're a very big deal. I'm also aware of a shit ton of things that are vastly more important than what we're arguing about and we're not talking about those. Let's talk about goals for the project and the landscape of technical risk in our next 1:1. This is assuming we're controlling the compiler in the packaged distribution and on the cloud, we're testing representative user pipelines against gcc and clang, so the scenario you're imagining is either a Hail developer or someone who is sophisticated enough to maintain a Spark cluster (1000x worse configuration nonsense than we're arguing about here, I promise) who is either (1) running old or obscure compiler, or (2) ran into a bug that had test coverage. You're worrying about (1)? What's the worst that will happen, seriously? We'll get a bug report? Let's make sure the compiler version is in the log. > A couple of years ago; > g++ take 40-60 seconds to compile; > fairly heavily templated cod. Can we avoid heavily (or even moderately) templated code? I'm already nervous long-term about the latency of the C++ compiler overhead and if I'm being honest would prefer to generate LLVM IR directly into memory. We should ship whatever compiler is best on the cloud and in the download package. That already covers a vast majority of our users. If clang is the clear winner, we can make that clear in the documentation and maybe warn about gcc it on startup. > But that becomes a problem in itself if we want the shipped compiler to work on a variety of OS'es. Variety isn't a requirement. We don't need to make this hard for ourselves. Let's have two versions: OSX and a recent linux. If we're getting a lot of requests/questions/issues about older versions of l",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-410134414
https://github.com/hail-is/hail/pull/3973#issuecomment-410134414:1243,Safety,avoid,avoid,1243," directly to your last comment. > We have a difference of opinion about the risks. I think I'd say we have a difference of opinion about the importance of the risks. I'm well aware of the potential pitfalls you list there, and more. I just don't think they're a very big deal. I'm also aware of a shit ton of things that are vastly more important than what we're arguing about and we're not talking about those. Let's talk about goals for the project and the landscape of technical risk in our next 1:1. This is assuming we're controlling the compiler in the packaged distribution and on the cloud, we're testing representative user pipelines against gcc and clang, so the scenario you're imagining is either a Hail developer or someone who is sophisticated enough to maintain a Spark cluster (1000x worse configuration nonsense than we're arguing about here, I promise) who is either (1) running old or obscure compiler, or (2) ran into a bug that had test coverage. You're worrying about (1)? What's the worst that will happen, seriously? We'll get a bug report? Let's make sure the compiler version is in the log. > A couple of years ago; > g++ take 40-60 seconds to compile; > fairly heavily templated cod. Can we avoid heavily (or even moderately) templated code? I'm already nervous long-term about the latency of the C++ compiler overhead and if I'm being honest would prefer to generate LLVM IR directly into memory. We should ship whatever compiler is best on the cloud and in the download package. That already covers a vast majority of our users. If clang is the clear winner, we can make that clear in the documentation and maybe warn about gcc it on startup. > But that becomes a problem in itself if we want the shipped compiler to work on a variety of OS'es. Variety isn't a requirement. We don't need to make this hard for ourselves. Let's have two versions: OSX and a recent linux. If we're getting a lot of requests/questions/issues about older versions of linux, we can reevaluate.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-410134414
https://github.com/hail-is/hail/pull/3973#issuecomment-410134414:630,Testability,test,testing,630,"Strange, I can't reply to directly to your last comment. > We have a difference of opinion about the risks. I think I'd say we have a difference of opinion about the importance of the risks. I'm well aware of the potential pitfalls you list there, and more. I just don't think they're a very big deal. I'm also aware of a shit ton of things that are vastly more important than what we're arguing about and we're not talking about those. Let's talk about goals for the project and the landscape of technical risk in our next 1:1. This is assuming we're controlling the compiler in the packaged distribution and on the cloud, we're testing representative user pipelines against gcc and clang, so the scenario you're imagining is either a Hail developer or someone who is sophisticated enough to maintain a Spark cluster (1000x worse configuration nonsense than we're arguing about here, I promise) who is either (1) running old or obscure compiler, or (2) ran into a bug that had test coverage. You're worrying about (1)? What's the worst that will happen, seriously? We'll get a bug report? Let's make sure the compiler version is in the log. > A couple of years ago; > g++ take 40-60 seconds to compile; > fairly heavily templated cod. Can we avoid heavily (or even moderately) templated code? I'm already nervous long-term about the latency of the C++ compiler overhead and if I'm being honest would prefer to generate LLVM IR directly into memory. We should ship whatever compiler is best on the cloud and in the download package. That already covers a vast majority of our users. If clang is the clear winner, we can make that clear in the documentation and maybe warn about gcc it on startup. > But that becomes a problem in itself if we want the shipped compiler to work on a variety of OS'es. Variety isn't a requirement. We don't need to make this hard for ourselves. Let's have two versions: OSX and a recent linux. If we're getting a lot of requests/questions/issues about older versions of l",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-410134414
https://github.com/hail-is/hail/pull/3973#issuecomment-410134414:978,Testability,test,test,978,"Strange, I can't reply to directly to your last comment. > We have a difference of opinion about the risks. I think I'd say we have a difference of opinion about the importance of the risks. I'm well aware of the potential pitfalls you list there, and more. I just don't think they're a very big deal. I'm also aware of a shit ton of things that are vastly more important than what we're arguing about and we're not talking about those. Let's talk about goals for the project and the landscape of technical risk in our next 1:1. This is assuming we're controlling the compiler in the packaged distribution and on the cloud, we're testing representative user pipelines against gcc and clang, so the scenario you're imagining is either a Hail developer or someone who is sophisticated enough to maintain a Spark cluster (1000x worse configuration nonsense than we're arguing about here, I promise) who is either (1) running old or obscure compiler, or (2) ran into a bug that had test coverage. You're worrying about (1)? What's the worst that will happen, seriously? We'll get a bug report? Let's make sure the compiler version is in the log. > A couple of years ago; > g++ take 40-60 seconds to compile; > fairly heavily templated cod. Can we avoid heavily (or even moderately) templated code? I'm already nervous long-term about the latency of the C++ compiler overhead and if I'm being honest would prefer to generate LLVM IR directly into memory. We should ship whatever compiler is best on the cloud and in the download package. That already covers a vast majority of our users. If clang is the clear winner, we can make that clear in the documentation and maybe warn about gcc it on startup. > But that becomes a problem in itself if we want the shipped compiler to work on a variety of OS'es. Variety isn't a requirement. We don't need to make this hard for ourselves. Let's have two versions: OSX and a recent linux. If we're getting a lot of requests/questions/issues about older versions of l",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-410134414
https://github.com/hail-is/hail/pull/3973#issuecomment-410134414:1137,Testability,log,log,1137," directly to your last comment. > We have a difference of opinion about the risks. I think I'd say we have a difference of opinion about the importance of the risks. I'm well aware of the potential pitfalls you list there, and more. I just don't think they're a very big deal. I'm also aware of a shit ton of things that are vastly more important than what we're arguing about and we're not talking about those. Let's talk about goals for the project and the landscape of technical risk in our next 1:1. This is assuming we're controlling the compiler in the packaged distribution and on the cloud, we're testing representative user pipelines against gcc and clang, so the scenario you're imagining is either a Hail developer or someone who is sophisticated enough to maintain a Spark cluster (1000x worse configuration nonsense than we're arguing about here, I promise) who is either (1) running old or obscure compiler, or (2) ran into a bug that had test coverage. You're worrying about (1)? What's the worst that will happen, seriously? We'll get a bug report? Let's make sure the compiler version is in the log. > A couple of years ago; > g++ take 40-60 seconds to compile; > fairly heavily templated cod. Can we avoid heavily (or even moderately) templated code? I'm already nervous long-term about the latency of the C++ compiler overhead and if I'm being honest would prefer to generate LLVM IR directly into memory. We should ship whatever compiler is best on the cloud and in the download package. That already covers a vast majority of our users. If clang is the clear winner, we can make that clear in the documentation and maybe warn about gcc it on startup. > But that becomes a problem in itself if we want the shipped compiler to work on a variety of OS'es. Variety isn't a requirement. We don't need to make this hard for ourselves. Let's have two versions: OSX and a recent linux. If we're getting a lot of requests/questions/issues about older versions of linux, we can reevaluate.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-410134414
https://github.com/hail-is/hail/pull/3973#issuecomment-410134414:1599,Usability,clear,clear,1599," directly to your last comment. > We have a difference of opinion about the risks. I think I'd say we have a difference of opinion about the importance of the risks. I'm well aware of the potential pitfalls you list there, and more. I just don't think they're a very big deal. I'm also aware of a shit ton of things that are vastly more important than what we're arguing about and we're not talking about those. Let's talk about goals for the project and the landscape of technical risk in our next 1:1. This is assuming we're controlling the compiler in the packaged distribution and on the cloud, we're testing representative user pipelines against gcc and clang, so the scenario you're imagining is either a Hail developer or someone who is sophisticated enough to maintain a Spark cluster (1000x worse configuration nonsense than we're arguing about here, I promise) who is either (1) running old or obscure compiler, or (2) ran into a bug that had test coverage. You're worrying about (1)? What's the worst that will happen, seriously? We'll get a bug report? Let's make sure the compiler version is in the log. > A couple of years ago; > g++ take 40-60 seconds to compile; > fairly heavily templated cod. Can we avoid heavily (or even moderately) templated code? I'm already nervous long-term about the latency of the C++ compiler overhead and if I'm being honest would prefer to generate LLVM IR directly into memory. We should ship whatever compiler is best on the cloud and in the download package. That already covers a vast majority of our users. If clang is the clear winner, we can make that clear in the documentation and maybe warn about gcc it on startup. > But that becomes a problem in itself if we want the shipped compiler to work on a variety of OS'es. Variety isn't a requirement. We don't need to make this hard for ourselves. Let's have two versions: OSX and a recent linux. If we're getting a lot of requests/questions/issues about older versions of linux, we can reevaluate.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-410134414
https://github.com/hail-is/hail/pull/3973#issuecomment-410134414:1630,Usability,clear,clear,1630," directly to your last comment. > We have a difference of opinion about the risks. I think I'd say we have a difference of opinion about the importance of the risks. I'm well aware of the potential pitfalls you list there, and more. I just don't think they're a very big deal. I'm also aware of a shit ton of things that are vastly more important than what we're arguing about and we're not talking about those. Let's talk about goals for the project and the landscape of technical risk in our next 1:1. This is assuming we're controlling the compiler in the packaged distribution and on the cloud, we're testing representative user pipelines against gcc and clang, so the scenario you're imagining is either a Hail developer or someone who is sophisticated enough to maintain a Spark cluster (1000x worse configuration nonsense than we're arguing about here, I promise) who is either (1) running old or obscure compiler, or (2) ran into a bug that had test coverage. You're worrying about (1)? What's the worst that will happen, seriously? We'll get a bug report? Let's make sure the compiler version is in the log. > A couple of years ago; > g++ take 40-60 seconds to compile; > fairly heavily templated cod. Can we avoid heavily (or even moderately) templated code? I'm already nervous long-term about the latency of the C++ compiler overhead and if I'm being honest would prefer to generate LLVM IR directly into memory. We should ship whatever compiler is best on the cloud and in the download package. That already covers a vast majority of our users. If clang is the clear winner, we can make that clear in the documentation and maybe warn about gcc it on startup. > But that becomes a problem in itself if we want the shipped compiler to work on a variety of OS'es. Variety isn't a requirement. We don't need to make this hard for ourselves. Let's have two versions: OSX and a recent linux. If we're getting a lot of requests/questions/issues about older versions of linux, we can reevaluate.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-410134414
https://github.com/hail-is/hail/pull/3973#issuecomment-410235287:1380,Availability,error,error,1380,".; It's just one step short of using containers - but since it doesn't require; a containerized OS, I think it works; for laptops etc. I believe the package could have all the stuff we currently manage my; manual install, viz JDK, Spark, Python-3.6,; R, R packages, as well as Hail and a friendly-C++17-capable compiler. All; without perturbing anything else; on the system. See https://bitnami.com. I took a similar approach at PhysicsSpeed, though without using any bitnami; tools because we had less than; zero dollars :-(. I don't know if this adds any value in the containerized/cloud environment,; where custom machine images; are presumably the way to go. But it makes setup easy for standalone use. Regards; Richard. On Thu, Aug 2, 2018 at 10:44 PM Richard Cownie <rcownie@broadinstitute.org>; wrote:. > We have a difference of opinion about the risks involved in using whatever; > compiler happens to show up as $(CXX); > to try to compile arbitrarily large auto-generated C++ files, and maybe; > about what happens when that fails; > and gives an error message about something in the middle of 12000 lines of; > code that bears no obvious relationship; > to what the user is doing. Or when that compiler takes 15 minutes to; > compile it. It's the C++ equivalent of; > the JVM ""no, that's just too much bytecode"". Or worst of all, it compiles; > it but the code gives the wrong answers; > because that particular compiler has a bug, and we never tested the; > combination of our codegen with *that*; > compiler/version.; >; > A couple of years ago I was seeing g++ take 40-60 seconds to compile; > something that clang did in 2 seconds; > (fairly heavily templated code generated for an SQL query, so very much in; > the same ballpark as parts of Hail),; > which contributes to my concern about this, especially on linux where g++; > is the default.; >; > So in the long run I expect we'll ship a compiler, or specify a compiler.; > But that becomes a problem in itself; > if we want the sh",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-410235287
https://github.com/hail-is/hail/pull/3973#issuecomment-410235287:159,Deployability,install,installs,159,"On the issue of how to give people a standardized environment with Hail +; compiler + everything else, one; approach is to build a Bitnami package, which then installs itself into a; directory tree with zero/minimal; dependencies or interactions with anything outside its tree. I've used; that for web services like Jenkins.; It's just one step short of using containers - but since it doesn't require; a containerized OS, I think it works; for laptops etc. I believe the package could have all the stuff we currently manage my; manual install, viz JDK, Spark, Python-3.6,; R, R packages, as well as Hail and a friendly-C++17-capable compiler. All; without perturbing anything else; on the system. See https://bitnami.com. I took a similar approach at PhysicsSpeed, though without using any bitnami; tools because we had less than; zero dollars :-(. I don't know if this adds any value in the containerized/cloud environment,; where custom machine images; are presumably the way to go. But it makes setup easy for standalone use. Regards; Richard. On Thu, Aug 2, 2018 at 10:44 PM Richard Cownie <rcownie@broadinstitute.org>; wrote:. > We have a difference of opinion about the risks involved in using whatever; > compiler happens to show up as $(CXX); > to try to compile arbitrarily large auto-generated C++ files, and maybe; > about what happens when that fails; > and gives an error message about something in the middle of 12000 lines of; > code that bears no obvious relationship; > to what the user is doing. Or when that compiler takes 15 minutes to; > compile it. It's the C++ equivalent of; > the JVM ""no, that's just too much bytecode"". Or worst of all, it compiles; > it but the code gives the wrong answers; > because that particular compiler has a bug, and we never tested the; > combination of our codegen with *that*; > compiler/version.; >; > A couple of years ago I was seeing g++ take 40-60 seconds to compile; > something that clang did in 2 seconds; > (fairly heavily templated cod",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-410235287
https://github.com/hail-is/hail/pull/3973#issuecomment-410235287:536,Deployability,install,install,536,"On the issue of how to give people a standardized environment with Hail +; compiler + everything else, one; approach is to build a Bitnami package, which then installs itself into a; directory tree with zero/minimal; dependencies or interactions with anything outside its tree. I've used; that for web services like Jenkins.; It's just one step short of using containers - but since it doesn't require; a containerized OS, I think it works; for laptops etc. I believe the package could have all the stuff we currently manage my; manual install, viz JDK, Spark, Python-3.6,; R, R packages, as well as Hail and a friendly-C++17-capable compiler. All; without perturbing anything else; on the system. See https://bitnami.com. I took a similar approach at PhysicsSpeed, though without using any bitnami; tools because we had less than; zero dollars :-(. I don't know if this adds any value in the containerized/cloud environment,; where custom machine images; are presumably the way to go. But it makes setup easy for standalone use. Regards; Richard. On Thu, Aug 2, 2018 at 10:44 PM Richard Cownie <rcownie@broadinstitute.org>; wrote:. > We have a difference of opinion about the risks involved in using whatever; > compiler happens to show up as $(CXX); > to try to compile arbitrarily large auto-generated C++ files, and maybe; > about what happens when that fails; > and gives an error message about something in the middle of 12000 lines of; > code that bears no obvious relationship; > to what the user is doing. Or when that compiler takes 15 minutes to; > compile it. It's the C++ equivalent of; > the JVM ""no, that's just too much bytecode"". Or worst of all, it compiles; > it but the code gives the wrong answers; > because that particular compiler has a bug, and we never tested the; > combination of our codegen with *that*; > compiler/version.; >; > A couple of years ago I was seeing g++ take 40-60 seconds to compile; > something that clang did in 2 seconds; > (fairly heavily templated cod",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-410235287
https://github.com/hail-is/hail/pull/3973#issuecomment-410235287:217,Integrability,depend,dependencies,217,"On the issue of how to give people a standardized environment with Hail +; compiler + everything else, one; approach is to build a Bitnami package, which then installs itself into a; directory tree with zero/minimal; dependencies or interactions with anything outside its tree. I've used; that for web services like Jenkins.; It's just one step short of using containers - but since it doesn't require; a containerized OS, I think it works; for laptops etc. I believe the package could have all the stuff we currently manage my; manual install, viz JDK, Spark, Python-3.6,; R, R packages, as well as Hail and a friendly-C++17-capable compiler. All; without perturbing anything else; on the system. See https://bitnami.com. I took a similar approach at PhysicsSpeed, though without using any bitnami; tools because we had less than; zero dollars :-(. I don't know if this adds any value in the containerized/cloud environment,; where custom machine images; are presumably the way to go. But it makes setup easy for standalone use. Regards; Richard. On Thu, Aug 2, 2018 at 10:44 PM Richard Cownie <rcownie@broadinstitute.org>; wrote:. > We have a difference of opinion about the risks involved in using whatever; > compiler happens to show up as $(CXX); > to try to compile arbitrarily large auto-generated C++ files, and maybe; > about what happens when that fails; > and gives an error message about something in the middle of 12000 lines of; > code that bears no obvious relationship; > to what the user is doing. Or when that compiler takes 15 minutes to; > compile it. It's the C++ equivalent of; > the JVM ""no, that's just too much bytecode"". Or worst of all, it compiles; > it but the code gives the wrong answers; > because that particular compiler has a bug, and we never tested the; > combination of our codegen with *that*; > compiler/version.; >; > A couple of years ago I was seeing g++ take 40-60 seconds to compile; > something that clang did in 2 seconds; > (fairly heavily templated cod",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-410235287
https://github.com/hail-is/hail/pull/3973#issuecomment-410235287:1386,Integrability,message,message,1386,".; It's just one step short of using containers - but since it doesn't require; a containerized OS, I think it works; for laptops etc. I believe the package could have all the stuff we currently manage my; manual install, viz JDK, Spark, Python-3.6,; R, R packages, as well as Hail and a friendly-C++17-capable compiler. All; without perturbing anything else; on the system. See https://bitnami.com. I took a similar approach at PhysicsSpeed, though without using any bitnami; tools because we had less than; zero dollars :-(. I don't know if this adds any value in the containerized/cloud environment,; where custom machine images; are presumably the way to go. But it makes setup easy for standalone use. Regards; Richard. On Thu, Aug 2, 2018 at 10:44 PM Richard Cownie <rcownie@broadinstitute.org>; wrote:. > We have a difference of opinion about the risks involved in using whatever; > compiler happens to show up as $(CXX); > to try to compile arbitrarily large auto-generated C++ files, and maybe; > about what happens when that fails; > and gives an error message about something in the middle of 12000 lines of; > code that bears no obvious relationship; > to what the user is doing. Or when that compiler takes 15 minutes to; > compile it. It's the C++ equivalent of; > the JVM ""no, that's just too much bytecode"". Or worst of all, it compiles; > it but the code gives the wrong answers; > because that particular compiler has a bug, and we never tested the; > combination of our codegen with *that*; > compiler/version.; >; > A couple of years ago I was seeing g++ take 40-60 seconds to compile; > something that clang did in 2 seconds; > (fairly heavily templated code generated for an SQL query, so very much in; > the same ballpark as parts of Hail),; > which contributes to my concern about this, especially on linux where g++; > is the default.; >; > So in the long run I expect we'll ship a compiler, or specify a compiler.; > But that becomes a problem in itself; > if we want the sh",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-410235287
https://github.com/hail-is/hail/pull/3973#issuecomment-410235287:4246,Performance,cache,cached,4246,"cussion_r207422997>:; >>; >> > +}; >> +; >> +std::string strip_suffix(const std::string& s, const char* suffix) {; >> + size_t len = s.length();; >> + size_t n = strlen(suffix);; >> + if ((n > len) || (strncmp(&s[len-n], suffix, n) != 0)) return s;; >> + return std::string(s, 0, len-n);; >> +}; >> +; >> +std::string get_cxx_name() {; >> + char* p = ::getenv(""CXX"");; >> + if (p) return std::string(p);; >> + // We prefer clang because it has faster compile; >> + auto s = run_shell_get_first_line(""which clang"");; >> + if (strstr(s.c_str(), ""clang"")) return s;; >> + s = run_shell_get_first_line(""which g++"");; >>; >> I'm lazy and I want to save my thinking for stuff where I can really; >> provide value (like building a whole stage code generator, or designing a; >> new format to speed up the decoder!) If there are standards, I want to use; >> them so I don't have to think unless I have a strong reason to think they; >> won't work for me. It also makes communicating with others easier who are; >> expecting the same standards. So I'd just kick out a Makefile and call make; >> on it like I would for any project (and maybe print out some helpful info; >> when it fails like the make command, the path to the Makefile and maybe the; >> environment). I didn't realize it would be such a hard sell because I; >> thought I was proposing the easy path which was the least work. I like the; >> easy path! And if it means we can get this in and start building on it, all; >> the better.; >>; >> The cached Makefile isn't actually reused. ... It's occasionally useful; >> to run it by hand for debugging.; >>; >> Ah, thanks for clarifying. Definitely.; >>; >> ; >> You are receiving this because you modified the open/close state.; >> Reply to this email directly, view it on GitHub; >> <https://github.com/hail-is/hail/pull/3973#discussion_r207422997>, or mute; >> the thread; >> <https://github.com/notifications/unsubscribe-auth/AJzExsJ8Hk-GuvDywoKPy8DF_SSBqgG-ks5uM66RgaJpZM4VbZpP>; >> .; >>; >",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-410235287
https://github.com/hail-is/hail/pull/3973#issuecomment-410235287:1177,Safety,risk,risks,1177,".; It's just one step short of using containers - but since it doesn't require; a containerized OS, I think it works; for laptops etc. I believe the package could have all the stuff we currently manage my; manual install, viz JDK, Spark, Python-3.6,; R, R packages, as well as Hail and a friendly-C++17-capable compiler. All; without perturbing anything else; on the system. See https://bitnami.com. I took a similar approach at PhysicsSpeed, though without using any bitnami; tools because we had less than; zero dollars :-(. I don't know if this adds any value in the containerized/cloud environment,; where custom machine images; are presumably the way to go. But it makes setup easy for standalone use. Regards; Richard. On Thu, Aug 2, 2018 at 10:44 PM Richard Cownie <rcownie@broadinstitute.org>; wrote:. > We have a difference of opinion about the risks involved in using whatever; > compiler happens to show up as $(CXX); > to try to compile arbitrarily large auto-generated C++ files, and maybe; > about what happens when that fails; > and gives an error message about something in the middle of 12000 lines of; > code that bears no obvious relationship; > to what the user is doing. Or when that compiler takes 15 minutes to; > compile it. It's the C++ equivalent of; > the JVM ""no, that's just too much bytecode"". Or worst of all, it compiles; > it but the code gives the wrong answers; > because that particular compiler has a bug, and we never tested the; > combination of our codegen with *that*; > compiler/version.; >; > A couple of years ago I was seeing g++ take 40-60 seconds to compile; > something that clang did in 2 seconds; > (fairly heavily templated code generated for an SQL query, so very much in; > the same ballpark as parts of Hail),; > which contributes to my concern about this, especially on linux where g++; > is the default.; >; > So in the long run I expect we'll ship a compiler, or specify a compiler.; > But that becomes a problem in itself; > if we want the sh",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-410235287
https://github.com/hail-is/hail/pull/3973#issuecomment-410235287:1779,Testability,test,tested,1779,"at PhysicsSpeed, though without using any bitnami; tools because we had less than; zero dollars :-(. I don't know if this adds any value in the containerized/cloud environment,; where custom machine images; are presumably the way to go. But it makes setup easy for standalone use. Regards; Richard. On Thu, Aug 2, 2018 at 10:44 PM Richard Cownie <rcownie@broadinstitute.org>; wrote:. > We have a difference of opinion about the risks involved in using whatever; > compiler happens to show up as $(CXX); > to try to compile arbitrarily large auto-generated C++ files, and maybe; > about what happens when that fails; > and gives an error message about something in the middle of 12000 lines of; > code that bears no obvious relationship; > to what the user is doing. Or when that compiler takes 15 minutes to; > compile it. It's the C++ equivalent of; > the JVM ""no, that's just too much bytecode"". Or worst of all, it compiles; > it but the code gives the wrong answers; > because that particular compiler has a bug, and we never tested the; > combination of our codegen with *that*; > compiler/version.; >; > A couple of years ago I was seeing g++ take 40-60 seconds to compile; > something that clang did in 2 seconds; > (fairly heavily templated code generated for an SQL query, so very much in; > the same ballpark as parts of Hail),; > which contributes to my concern about this, especially on linux where g++; > is the default.; >; > So in the long run I expect we'll ship a compiler, or specify a compiler.; > But that becomes a problem in itself; > if we want the shipped compiler to work on a variety of OS'es. When I did; > that before it was all Ubuntu-14.04; > and Ubuntu-16.04, and it was manageable to build it for two platforms.; >; >; > On Thu, Aug 2, 2018 at 9:59 PM cseed <notifications@github.com> wrote:; >; >> *@cseed* commented on this pull request.; >> ------------------------------; >>; >> In src/main/c/NativeModule.cpp; >> <https://github.com/hail-is/hail/pull/3973#discuss",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-410235287
https://github.com/hail-is/hail/pull/3973#issuecomment-410319504:174,Availability,avail,available,174,"fmtlib looks promising, but. a) I'm not keen to mix in non-standard third-party source code into our; codebase; unless it's a significant win over the functionality that is; available everywhere; and familiar to everyone. printf has been getting the job done for; decades. b) the speed test shows it still slower than printf (iirc 1.56s vs; 1.35s), just not a; *lot* slower (whereas C++ iostreams are very slow). On Fri, Aug 3, 2018 at 10:45 AM Patrick Schultz <notifications@github.com>; wrote:. > *@patrick-schultz* commented on this pull request.; > ------------------------------; >; > In src/main/c/NativeModule.cpp; > <https://github.com/hail-is/hail/pull/3973#discussion_r207566438>:; >; > > +#include <sys/stat.h>; > +#include <sys/time.h>; > +#include <unistd.h>; > +#include <atomic>; > +#include <memory>; > +#include <mutex>; > +#include <iostream>; > +#include <sstream>; > +#include <string>; > +#include <vector>; > +; > +#if 0; > +#define D(fmt, ...) { \; > + char buf[1024]; \; > + sprintf(buf, fmt, ##__VA_ARGS__); \; > + fprintf(stderr, ""DEBUG: %s,%d: %s"", __FILE__, __LINE__, buf); \; >; > @cseed <https://github.com/cseed> suggested using the fmt library (; > https://github.com/fmtlib/fmt), which I believe is being proposed for; > standardization. That is my preference also. It appears to be as safe as; > IOstreams and as fast as printf. It supports both Python style and C; > style formatting, e.g.; >; > fmt::print(""Hello, {}!"", ""world""); // uses Python-like format string syntaxfmt::printf(""Hello, %s!"", ""world""); // uses printf format string syntax; >; > Format strings are checked at compile time, as are argument types.; >; > ; > You are receiving this because you modified the open/close state.; > Reply to this email directly, view it on GitHub; > <https://github.com/hail-is/hail/pull/3973#discussion_r207566438>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AJzExrljAAlcA6ksqZiNPyOw8wgC0hheks5uNGH7gaJpZM4VbZpP>; > .; >",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-410319504
https://github.com/hail-is/hail/pull/3973#issuecomment-410319504:1319,Safety,safe,safe,1319,"fmtlib looks promising, but. a) I'm not keen to mix in non-standard third-party source code into our; codebase; unless it's a significant win over the functionality that is; available everywhere; and familiar to everyone. printf has been getting the job done for; decades. b) the speed test shows it still slower than printf (iirc 1.56s vs; 1.35s), just not a; *lot* slower (whereas C++ iostreams are very slow). On Fri, Aug 3, 2018 at 10:45 AM Patrick Schultz <notifications@github.com>; wrote:. > *@patrick-schultz* commented on this pull request.; > ------------------------------; >; > In src/main/c/NativeModule.cpp; > <https://github.com/hail-is/hail/pull/3973#discussion_r207566438>:; >; > > +#include <sys/stat.h>; > +#include <sys/time.h>; > +#include <unistd.h>; > +#include <atomic>; > +#include <memory>; > +#include <mutex>; > +#include <iostream>; > +#include <sstream>; > +#include <string>; > +#include <vector>; > +; > +#if 0; > +#define D(fmt, ...) { \; > + char buf[1024]; \; > + sprintf(buf, fmt, ##__VA_ARGS__); \; > + fprintf(stderr, ""DEBUG: %s,%d: %s"", __FILE__, __LINE__, buf); \; >; > @cseed <https://github.com/cseed> suggested using the fmt library (; > https://github.com/fmtlib/fmt), which I believe is being proposed for; > standardization. That is my preference also. It appears to be as safe as; > IOstreams and as fast as printf. It supports both Python style and C; > style formatting, e.g.; >; > fmt::print(""Hello, {}!"", ""world""); // uses Python-like format string syntaxfmt::printf(""Hello, %s!"", ""world""); // uses printf format string syntax; >; > Format strings are checked at compile time, as are argument types.; >; > ; > You are receiving this because you modified the open/close state.; > Reply to this email directly, view it on GitHub; > <https://github.com/hail-is/hail/pull/3973#discussion_r207566438>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AJzExrljAAlcA6ksqZiNPyOw8wgC0hheks5uNGH7gaJpZM4VbZpP>; > .; >",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-410319504
https://github.com/hail-is/hail/pull/3973#issuecomment-410319504:286,Testability,test,test,286,"fmtlib looks promising, but. a) I'm not keen to mix in non-standard third-party source code into our; codebase; unless it's a significant win over the functionality that is; available everywhere; and familiar to everyone. printf has been getting the job done for; decades. b) the speed test shows it still slower than printf (iirc 1.56s vs; 1.35s), just not a; *lot* slower (whereas C++ iostreams are very slow). On Fri, Aug 3, 2018 at 10:45 AM Patrick Schultz <notifications@github.com>; wrote:. > *@patrick-schultz* commented on this pull request.; > ------------------------------; >; > In src/main/c/NativeModule.cpp; > <https://github.com/hail-is/hail/pull/3973#discussion_r207566438>:; >; > > +#include <sys/stat.h>; > +#include <sys/time.h>; > +#include <unistd.h>; > +#include <atomic>; > +#include <memory>; > +#include <mutex>; > +#include <iostream>; > +#include <sstream>; > +#include <string>; > +#include <vector>; > +; > +#if 0; > +#define D(fmt, ...) { \; > + char buf[1024]; \; > + sprintf(buf, fmt, ##__VA_ARGS__); \; > + fprintf(stderr, ""DEBUG: %s,%d: %s"", __FILE__, __LINE__, buf); \; >; > @cseed <https://github.com/cseed> suggested using the fmt library (; > https://github.com/fmtlib/fmt), which I believe is being proposed for; > standardization. That is my preference also. It appears to be as safe as; > IOstreams and as fast as printf. It supports both Python style and C; > style formatting, e.g.; >; > fmt::print(""Hello, {}!"", ""world""); // uses Python-like format string syntaxfmt::printf(""Hello, %s!"", ""world""); // uses printf format string syntax; >; > Format strings are checked at compile time, as are argument types.; >; > ; > You are receiving this because you modified the open/close state.; > Reply to this email directly, view it on GitHub; > <https://github.com/hail-is/hail/pull/3973#discussion_r207566438>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AJzExrljAAlcA6ksqZiNPyOw8wgC0hheks5uNGH7gaJpZM4VbZpP>; > .; >",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-410319504
https://github.com/hail-is/hail/pull/3973#issuecomment-410321049:452,Security,access,access,452,"The default is to put the modules in ${HOME}/hail_modules, which in many; environments; would indeed be an NFS directory. It only goes to /tmp/hail_modules if; ${HOME} is undefined. The thinking behind this is that there's a huge amount of re-use of code; for an individual; from one Hail analysis to the next, but probably much less overlap between; different users.; And while multi-user sharing ought to work, it raises potential issues; about file access; permissions which seemed like trouble without a clear benefit. On Fri, Aug 3, 2018 at 10:49 AM Patrick Schultz <notifications@github.com>; wrote:. > *@patrick-schultz* commented on this pull request.; > ------------------------------; >; > In src/main/c/NativeModule.cpp; > <https://github.com/hail-is/hail/pull/3973#discussion_r207567962>:; >; > > +#include <string>; > +#include <vector>; > +; > +#if 0; > +#define D(fmt, ...) { \; > + char buf[1024]; \; > + sprintf(buf, fmt, ##__VA_ARGS__); \; > + fprintf(stderr, ""DEBUG: %s,%d: %s"", __FILE__, __LINE__, buf); \; > +}; > +#else; > +#define D(fmt, ...) { }; > +#endif; > +; > +namespace hail {; > +; > +namespace {; >; > The anonymous namespace can't be named, so no names introduced in an; > anonymous namespace can be referenced from outside the namespace. The; > exception is that on closing an anonymous namespace, it is automatically; > opened into the enclosing namespace. The typical use is to make things; > file-local.; >; > ; > You are receiving this because you modified the open/close state.; > Reply to this email directly, view it on GitHub; > <https://github.com/hail-is/hail/pull/3973#discussion_r207567962>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AJzExuxprnaVF62eonAgCjSmqAERvBJiks5uNGLtgaJpZM4VbZpP>; > .; >",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-410321049
https://github.com/hail-is/hail/pull/3973#issuecomment-410321049:508,Usability,clear,clear,508,"The default is to put the modules in ${HOME}/hail_modules, which in many; environments; would indeed be an NFS directory. It only goes to /tmp/hail_modules if; ${HOME} is undefined. The thinking behind this is that there's a huge amount of re-use of code; for an individual; from one Hail analysis to the next, but probably much less overlap between; different users.; And while multi-user sharing ought to work, it raises potential issues; about file access; permissions which seemed like trouble without a clear benefit. On Fri, Aug 3, 2018 at 10:49 AM Patrick Schultz <notifications@github.com>; wrote:. > *@patrick-schultz* commented on this pull request.; > ------------------------------; >; > In src/main/c/NativeModule.cpp; > <https://github.com/hail-is/hail/pull/3973#discussion_r207567962>:; >; > > +#include <string>; > +#include <vector>; > +; > +#if 0; > +#define D(fmt, ...) { \; > + char buf[1024]; \; > + sprintf(buf, fmt, ##__VA_ARGS__); \; > + fprintf(stderr, ""DEBUG: %s,%d: %s"", __FILE__, __LINE__, buf); \; > +}; > +#else; > +#define D(fmt, ...) { }; > +#endif; > +; > +namespace hail {; > +; > +namespace {; >; > The anonymous namespace can't be named, so no names introduced in an; > anonymous namespace can be referenced from outside the namespace. The; > exception is that on closing an anonymous namespace, it is automatically; > opened into the enclosing namespace. The typical use is to make things; > file-local.; >; > ; > You are receiving this because you modified the open/close state.; > Reply to this email directly, view it on GitHub; > <https://github.com/hail-is/hail/pull/3973#discussion_r207567962>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AJzExuxprnaVF62eonAgCjSmqAERvBJiks5uNGLtgaJpZM4VbZpP>; > .; >",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-410321049
https://github.com/hail-is/hail/pull/3973#issuecomment-410358596:1670,Availability,down,down,1670,"> The thinking behind this is that there's a huge amount of re-use of code for an individual from one Hail analysis to the next. So I'm not sure I buy this. Hail is a exploratory data analysis platform, it isn't a SQL engine running nightly billing reports. In particular, as we do whole stage optimization and code generation. It isn't clear to me how you do code-reuse when we're specializing each operation into the global context (happy to hear the plan). For example, tables that have many fields, you will need to load different ones for different queries and in general it is infeasible (exponential) to generate them all. Also, to get sharing you need to break the code up and now you're running the compiler multiple times which also seems bad. Given our focus on large-scale analysis, introducing optimization boundaries for code reuse seems like a bad trade off to me. A significant amount of analysis happens in the cloud where $HOME is ephemeral so you won't get savings between sessions. Finally, there are pipelines that are more standardized but it is my impression they are run on extremely large datasets (hours, overnight) in which case compilation speed isn't important. Finally, there's the complexity around locking that isn't easy and have real technical risk. A compiler cache potentially becomes more appealing in the context of an always-on service. There's no locking issue, and you can start to do things like speculative compilation (e.g. immediately start compiling the decoder (the full decoder? Hmm.) when a user opens the dataset.). I would say getting in a 3x decoder improvement is way more important than this. I would have punted it down the road and instrumented to estimate cache hit rates before building this out.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-410358596
https://github.com/hail-is/hail/pull/3973#issuecomment-410358596:1021,Deployability,pipeline,pipelines,1021,"> The thinking behind this is that there's a huge amount of re-use of code for an individual from one Hail analysis to the next. So I'm not sure I buy this. Hail is a exploratory data analysis platform, it isn't a SQL engine running nightly billing reports. In particular, as we do whole stage optimization and code generation. It isn't clear to me how you do code-reuse when we're specializing each operation into the global context (happy to hear the plan). For example, tables that have many fields, you will need to load different ones for different queries and in general it is infeasible (exponential) to generate them all. Also, to get sharing you need to break the code up and now you're running the compiler multiple times which also seems bad. Given our focus on large-scale analysis, introducing optimization boundaries for code reuse seems like a bad trade off to me. A significant amount of analysis happens in the cloud where $HOME is ephemeral so you won't get savings between sessions. Finally, there are pipelines that are more standardized but it is my impression they are run on extremely large datasets (hours, overnight) in which case compilation speed isn't important. Finally, there's the complexity around locking that isn't easy and have real technical risk. A compiler cache potentially becomes more appealing in the context of an always-on service. There's no locking issue, and you can start to do things like speculative compilation (e.g. immediately start compiling the decoder (the full decoder? Hmm.) when a user opens the dataset.). I would say getting in a 3x decoder improvement is way more important than this. I would have punted it down the road and instrumented to estimate cache hit rates before building this out.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-410358596
https://github.com/hail-is/hail/pull/3973#issuecomment-410358596:294,Performance,optimiz,optimization,294,"> The thinking behind this is that there's a huge amount of re-use of code for an individual from one Hail analysis to the next. So I'm not sure I buy this. Hail is a exploratory data analysis platform, it isn't a SQL engine running nightly billing reports. In particular, as we do whole stage optimization and code generation. It isn't clear to me how you do code-reuse when we're specializing each operation into the global context (happy to hear the plan). For example, tables that have many fields, you will need to load different ones for different queries and in general it is infeasible (exponential) to generate them all. Also, to get sharing you need to break the code up and now you're running the compiler multiple times which also seems bad. Given our focus on large-scale analysis, introducing optimization boundaries for code reuse seems like a bad trade off to me. A significant amount of analysis happens in the cloud where $HOME is ephemeral so you won't get savings between sessions. Finally, there are pipelines that are more standardized but it is my impression they are run on extremely large datasets (hours, overnight) in which case compilation speed isn't important. Finally, there's the complexity around locking that isn't easy and have real technical risk. A compiler cache potentially becomes more appealing in the context of an always-on service. There's no locking issue, and you can start to do things like speculative compilation (e.g. immediately start compiling the decoder (the full decoder? Hmm.) when a user opens the dataset.). I would say getting in a 3x decoder improvement is way more important than this. I would have punted it down the road and instrumented to estimate cache hit rates before building this out.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-410358596
https://github.com/hail-is/hail/pull/3973#issuecomment-410358596:520,Performance,load,load,520,"> The thinking behind this is that there's a huge amount of re-use of code for an individual from one Hail analysis to the next. So I'm not sure I buy this. Hail is a exploratory data analysis platform, it isn't a SQL engine running nightly billing reports. In particular, as we do whole stage optimization and code generation. It isn't clear to me how you do code-reuse when we're specializing each operation into the global context (happy to hear the plan). For example, tables that have many fields, you will need to load different ones for different queries and in general it is infeasible (exponential) to generate them all. Also, to get sharing you need to break the code up and now you're running the compiler multiple times which also seems bad. Given our focus on large-scale analysis, introducing optimization boundaries for code reuse seems like a bad trade off to me. A significant amount of analysis happens in the cloud where $HOME is ephemeral so you won't get savings between sessions. Finally, there are pipelines that are more standardized but it is my impression they are run on extremely large datasets (hours, overnight) in which case compilation speed isn't important. Finally, there's the complexity around locking that isn't easy and have real technical risk. A compiler cache potentially becomes more appealing in the context of an always-on service. There's no locking issue, and you can start to do things like speculative compilation (e.g. immediately start compiling the decoder (the full decoder? Hmm.) when a user opens the dataset.). I would say getting in a 3x decoder improvement is way more important than this. I would have punted it down the road and instrumented to estimate cache hit rates before building this out.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-410358596
https://github.com/hail-is/hail/pull/3973#issuecomment-410358596:807,Performance,optimiz,optimization,807,"> The thinking behind this is that there's a huge amount of re-use of code for an individual from one Hail analysis to the next. So I'm not sure I buy this. Hail is a exploratory data analysis platform, it isn't a SQL engine running nightly billing reports. In particular, as we do whole stage optimization and code generation. It isn't clear to me how you do code-reuse when we're specializing each operation into the global context (happy to hear the plan). For example, tables that have many fields, you will need to load different ones for different queries and in general it is infeasible (exponential) to generate them all. Also, to get sharing you need to break the code up and now you're running the compiler multiple times which also seems bad. Given our focus on large-scale analysis, introducing optimization boundaries for code reuse seems like a bad trade off to me. A significant amount of analysis happens in the cloud where $HOME is ephemeral so you won't get savings between sessions. Finally, there are pipelines that are more standardized but it is my impression they are run on extremely large datasets (hours, overnight) in which case compilation speed isn't important. Finally, there's the complexity around locking that isn't easy and have real technical risk. A compiler cache potentially becomes more appealing in the context of an always-on service. There's no locking issue, and you can start to do things like speculative compilation (e.g. immediately start compiling the decoder (the full decoder? Hmm.) when a user opens the dataset.). I would say getting in a 3x decoder improvement is way more important than this. I would have punted it down the road and instrumented to estimate cache hit rates before building this out.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-410358596
https://github.com/hail-is/hail/pull/3973#issuecomment-410358596:1295,Performance,cache,cache,1295,"> The thinking behind this is that there's a huge amount of re-use of code for an individual from one Hail analysis to the next. So I'm not sure I buy this. Hail is a exploratory data analysis platform, it isn't a SQL engine running nightly billing reports. In particular, as we do whole stage optimization and code generation. It isn't clear to me how you do code-reuse when we're specializing each operation into the global context (happy to hear the plan). For example, tables that have many fields, you will need to load different ones for different queries and in general it is infeasible (exponential) to generate them all. Also, to get sharing you need to break the code up and now you're running the compiler multiple times which also seems bad. Given our focus on large-scale analysis, introducing optimization boundaries for code reuse seems like a bad trade off to me. A significant amount of analysis happens in the cloud where $HOME is ephemeral so you won't get savings between sessions. Finally, there are pipelines that are more standardized but it is my impression they are run on extremely large datasets (hours, overnight) in which case compilation speed isn't important. Finally, there's the complexity around locking that isn't easy and have real technical risk. A compiler cache potentially becomes more appealing in the context of an always-on service. There's no locking issue, and you can start to do things like speculative compilation (e.g. immediately start compiling the decoder (the full decoder? Hmm.) when a user opens the dataset.). I would say getting in a 3x decoder improvement is way more important than this. I would have punted it down the road and instrumented to estimate cache hit rates before building this out.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-410358596
https://github.com/hail-is/hail/pull/3973#issuecomment-410358596:1713,Performance,cache,cache,1713,"> The thinking behind this is that there's a huge amount of re-use of code for an individual from one Hail analysis to the next. So I'm not sure I buy this. Hail is a exploratory data analysis platform, it isn't a SQL engine running nightly billing reports. In particular, as we do whole stage optimization and code generation. It isn't clear to me how you do code-reuse when we're specializing each operation into the global context (happy to hear the plan). For example, tables that have many fields, you will need to load different ones for different queries and in general it is infeasible (exponential) to generate them all. Also, to get sharing you need to break the code up and now you're running the compiler multiple times which also seems bad. Given our focus on large-scale analysis, introducing optimization boundaries for code reuse seems like a bad trade off to me. A significant amount of analysis happens in the cloud where $HOME is ephemeral so you won't get savings between sessions. Finally, there are pipelines that are more standardized but it is my impression they are run on extremely large datasets (hours, overnight) in which case compilation speed isn't important. Finally, there's the complexity around locking that isn't easy and have real technical risk. A compiler cache potentially becomes more appealing in the context of an always-on service. There's no locking issue, and you can start to do things like speculative compilation (e.g. immediately start compiling the decoder (the full decoder? Hmm.) when a user opens the dataset.). I would say getting in a 3x decoder improvement is way more important than this. I would have punted it down the road and instrumented to estimate cache hit rates before building this out.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-410358596
https://github.com/hail-is/hail/pull/3973#issuecomment-410358596:1278,Safety,risk,risk,1278,"> The thinking behind this is that there's a huge amount of re-use of code for an individual from one Hail analysis to the next. So I'm not sure I buy this. Hail is a exploratory data analysis platform, it isn't a SQL engine running nightly billing reports. In particular, as we do whole stage optimization and code generation. It isn't clear to me how you do code-reuse when we're specializing each operation into the global context (happy to hear the plan). For example, tables that have many fields, you will need to load different ones for different queries and in general it is infeasible (exponential) to generate them all. Also, to get sharing you need to break the code up and now you're running the compiler multiple times which also seems bad. Given our focus on large-scale analysis, introducing optimization boundaries for code reuse seems like a bad trade off to me. A significant amount of analysis happens in the cloud where $HOME is ephemeral so you won't get savings between sessions. Finally, there are pipelines that are more standardized but it is my impression they are run on extremely large datasets (hours, overnight) in which case compilation speed isn't important. Finally, there's the complexity around locking that isn't easy and have real technical risk. A compiler cache potentially becomes more appealing in the context of an always-on service. There's no locking issue, and you can start to do things like speculative compilation (e.g. immediately start compiling the decoder (the full decoder? Hmm.) when a user opens the dataset.). I would say getting in a 3x decoder improvement is way more important than this. I would have punted it down the road and instrumented to estimate cache hit rates before building this out.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-410358596
https://github.com/hail-is/hail/pull/3973#issuecomment-410358596:337,Usability,clear,clear,337,"> The thinking behind this is that there's a huge amount of re-use of code for an individual from one Hail analysis to the next. So I'm not sure I buy this. Hail is a exploratory data analysis platform, it isn't a SQL engine running nightly billing reports. In particular, as we do whole stage optimization and code generation. It isn't clear to me how you do code-reuse when we're specializing each operation into the global context (happy to hear the plan). For example, tables that have many fields, you will need to load different ones for different queries and in general it is infeasible (exponential) to generate them all. Also, to get sharing you need to break the code up and now you're running the compiler multiple times which also seems bad. Given our focus on large-scale analysis, introducing optimization boundaries for code reuse seems like a bad trade off to me. A significant amount of analysis happens in the cloud where $HOME is ephemeral so you won't get savings between sessions. Finally, there are pipelines that are more standardized but it is my impression they are run on extremely large datasets (hours, overnight) in which case compilation speed isn't important. Finally, there's the complexity around locking that isn't easy and have real technical risk. A compiler cache potentially becomes more appealing in the context of an always-on service. There's no locking issue, and you can start to do things like speculative compilation (e.g. immediately start compiling the decoder (the full decoder? Hmm.) when a user opens the dataset.). I would say getting in a 3x decoder improvement is way more important than this. I would have punted it down the road and instrumented to estimate cache hit rates before building this out.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-410358596
https://github.com/hail-is/hail/pull/3973#issuecomment-410367637:51,Availability,ping,ping,51,> one approach is to build a Bitnami package. I'll ping them to get a sense on pricing.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-410367637
https://github.com/hail-is/hail/pull/3973#issuecomment-410368037:291,Deployability,install,install,291,"> I don't know if this adds any value in the containerized/cloud environment, where custom machine images are presumably the way to go. Dan already dockerized our dependencies for the CI setup. I don't quite know what value it would add there, either. It seems good for letting other people install your application in the cloud, but isn't really a thing we do.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-410368037
https://github.com/hail-is/hail/pull/3973#issuecomment-410368037:163,Integrability,depend,dependencies,163,"> I don't know if this adds any value in the containerized/cloud environment, where custom machine images are presumably the way to go. Dan already dockerized our dependencies for the CI setup. I don't quite know what value it would add there, either. It seems good for letting other people install your application in the cloud, but isn't really a thing we do.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-410368037
https://github.com/hail-is/hail/pull/3973#issuecomment-412736583:84,Deployability,install,installed,84,"Reopening this after some changes, mostly to see whether it works with g++-4.8.3 as installed; on the CI machines. The src/main/c/Makefile now builds a libboot.so with -fabi-version=2, which should work against; systems with g++-3.4.0 or later, and both libhail_abi_v2.so and libhail_abi_v9.so. The NativeCode; initialization then figures out which one to load. In theory this should work on MacOS systems back to MacOS 10.9 (Mavericks), which was the first; to use libc++ instead of libstdc++, and on Linux systems with g++3.4.0 or later. By default these libraries are built with ""-march=sandybridge"", which would work on all MacBook Pro's; released since 2011 (and is also the first cpu with AVX). In the medium term I favor the idea of packaging a known good tested compiler into the release, but ; believe that probably won't become critical until we're attempting whole-stage compilation, since the; generated PackDecoder's so far are relatively straightforward code and max out at about 2K lines.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-412736583
https://github.com/hail-is/hail/pull/3973#issuecomment-412736583:643,Deployability,release,released,643,"Reopening this after some changes, mostly to see whether it works with g++-4.8.3 as installed; on the CI machines. The src/main/c/Makefile now builds a libboot.so with -fabi-version=2, which should work against; systems with g++-3.4.0 or later, and both libhail_abi_v2.so and libhail_abi_v9.so. The NativeCode; initialization then figures out which one to load. In theory this should work on MacOS systems back to MacOS 10.9 (Mavericks), which was the first; to use libc++ instead of libstdc++, and on Linux systems with g++3.4.0 or later. By default these libraries are built with ""-march=sandybridge"", which would work on all MacBook Pro's; released since 2011 (and is also the first cpu with AVX). In the medium term I favor the idea of packaging a known good tested compiler into the release, but ; believe that probably won't become critical until we're attempting whole-stage compilation, since the; generated PackDecoder's so far are relatively straightforward code and max out at about 2K lines.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-412736583
https://github.com/hail-is/hail/pull/3973#issuecomment-412736583:788,Deployability,release,release,788,"Reopening this after some changes, mostly to see whether it works with g++-4.8.3 as installed; on the CI machines. The src/main/c/Makefile now builds a libboot.so with -fabi-version=2, which should work against; systems with g++-3.4.0 or later, and both libhail_abi_v2.so and libhail_abi_v9.so. The NativeCode; initialization then figures out which one to load. In theory this should work on MacOS systems back to MacOS 10.9 (Mavericks), which was the first; to use libc++ instead of libstdc++, and on Linux systems with g++3.4.0 or later. By default these libraries are built with ""-march=sandybridge"", which would work on all MacBook Pro's; released since 2011 (and is also the first cpu with AVX). In the medium term I favor the idea of packaging a known good tested compiler into the release, but ; believe that probably won't become critical until we're attempting whole-stage compilation, since the; generated PackDecoder's so far are relatively straightforward code and max out at about 2K lines.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-412736583
https://github.com/hail-is/hail/pull/3973#issuecomment-412736583:356,Performance,load,load,356,"Reopening this after some changes, mostly to see whether it works with g++-4.8.3 as installed; on the CI machines. The src/main/c/Makefile now builds a libboot.so with -fabi-version=2, which should work against; systems with g++-3.4.0 or later, and both libhail_abi_v2.so and libhail_abi_v9.so. The NativeCode; initialization then figures out which one to load. In theory this should work on MacOS systems back to MacOS 10.9 (Mavericks), which was the first; to use libc++ instead of libstdc++, and on Linux systems with g++3.4.0 or later. By default these libraries are built with ""-march=sandybridge"", which would work on all MacBook Pro's; released since 2011 (and is also the first cpu with AVX). In the medium term I favor the idea of packaging a known good tested compiler into the release, but ; believe that probably won't become critical until we're attempting whole-stage compilation, since the; generated PackDecoder's so far are relatively straightforward code and max out at about 2K lines.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-412736583
https://github.com/hail-is/hail/pull/3973#issuecomment-412736583:763,Testability,test,tested,763,"Reopening this after some changes, mostly to see whether it works with g++-4.8.3 as installed; on the CI machines. The src/main/c/Makefile now builds a libboot.so with -fabi-version=2, which should work against; systems with g++-3.4.0 or later, and both libhail_abi_v2.so and libhail_abi_v9.so. The NativeCode; initialization then figures out which one to load. In theory this should work on MacOS systems back to MacOS 10.9 (Mavericks), which was the first; to use libc++ instead of libstdc++, and on Linux systems with g++3.4.0 or later. By default these libraries are built with ""-march=sandybridge"", which would work on all MacBook Pro's; released since 2011 (and is also the first cpu with AVX). In the medium term I favor the idea of packaging a known good tested compiler into the release, but ; believe that probably won't become critical until we're attempting whole-stage compilation, since the; generated PackDecoder's so far are relatively straightforward code and max out at about 2K lines.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-412736583
https://github.com/hail-is/hail/pull/3973#issuecomment-412742385:1453,Integrability,Depend,Depending,1453,"iltering in various; ways, then that may not be changed at all by changes to what happen in the real analysis; after the filtering. And this is also influenced by the medium-term goal of having a Hail service; which (amongst other things) can do simple analyses on small data in under ten seconds - in; that realm compilation time could become a critical factor as a serial bottleneck. [The place where persistent cacheing of compiled files helps most of all is in testing,; where you really are running the exact same queries over and over again on the same; small datasets, and in many cases after making small changes which only affect a few; of the queries]. b) We may actually have some version of the locking problem even if we don't try to reuse the files -; since we have several workers on a node, and possibly a master as well, all needing to put code; into a file (or wait for someone else to populate the file) so that they can load it. Depending on ; precisely how Spark manages things (which I wouldn't want to depend on too much anyway). In fact it's essential that all the workers share the same DLL file, because otherwise they'd be; trying to load multiple DLL's defining the same symbols. That aspect of it could be handled by; putting the files into a per-process directory and using in-memory (std::mutex) synchronization.; But y'know, given that we have to write the DLL's out, it just seemed natural to let them persist; (and until debugging it on MacOS, I thought I could manage it with nothing but atomic file-create; and atomic-rename, but that didn't quite pan out). As for writing LLVM IR, it can definitely be done, because that's what Endeca/Oracle did. But there; was such a huge learning curve that only 3 people ever did it successfully (I wasn't one of them),; and debugging seemed very unpleasant and slow. [It was also a masterful achievement in ; job-security-through-obscurity, because no-one in management was going to mess with the; two people who wrote it - u",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-412742385
https://github.com/hail-is/hail/pull/3973#issuecomment-412742385:1529,Integrability,depend,depend,1529,"iltering in various; ways, then that may not be changed at all by changes to what happen in the real analysis; after the filtering. And this is also influenced by the medium-term goal of having a Hail service; which (amongst other things) can do simple analyses on small data in under ten seconds - in; that realm compilation time could become a critical factor as a serial bottleneck. [The place where persistent cacheing of compiled files helps most of all is in testing,; where you really are running the exact same queries over and over again on the same; small datasets, and in many cases after making small changes which only affect a few; of the queries]. b) We may actually have some version of the locking problem even if we don't try to reuse the files -; since we have several workers on a node, and possibly a master as well, all needing to put code; into a file (or wait for someone else to populate the file) so that they can load it. Depending on ; precisely how Spark manages things (which I wouldn't want to depend on too much anyway). In fact it's essential that all the workers share the same DLL file, because otherwise they'd be; trying to load multiple DLL's defining the same symbols. That aspect of it could be handled by; putting the files into a per-process directory and using in-memory (std::mutex) synchronization.; But y'know, given that we have to write the DLL's out, it just seemed natural to let them persist; (and until debugging it on MacOS, I thought I could manage it with nothing but atomic file-create; and atomic-rename, but that didn't quite pan out). As for writing LLVM IR, it can definitely be done, because that's what Endeca/Oracle did. But there; was such a huge learning curve that only 3 people ever did it successfully (I wasn't one of them),; and debugging seemed very unpleasant and slow. [It was also a masterful achievement in ; job-security-through-obscurity, because no-one in management was going to mess with the; two people who wrote it - u",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-412742385
https://github.com/hail-is/hail/pull/3973#issuecomment-412742385:1831,Integrability,synchroniz,synchronization,1831," in under ten seconds - in; that realm compilation time could become a critical factor as a serial bottleneck. [The place where persistent cacheing of compiled files helps most of all is in testing,; where you really are running the exact same queries over and over again on the same; small datasets, and in many cases after making small changes which only affect a few; of the queries]. b) We may actually have some version of the locking problem even if we don't try to reuse the files -; since we have several workers on a node, and possibly a master as well, all needing to put code; into a file (or wait for someone else to populate the file) so that they can load it. Depending on ; precisely how Spark manages things (which I wouldn't want to depend on too much anyway). In fact it's essential that all the workers share the same DLL file, because otherwise they'd be; trying to load multiple DLL's defining the same symbols. That aspect of it could be handled by; putting the files into a per-process directory and using in-memory (std::mutex) synchronization.; But y'know, given that we have to write the DLL's out, it just seemed natural to let them persist; (and until debugging it on MacOS, I thought I could manage it with nothing but atomic file-create; and atomic-rename, but that didn't quite pan out). As for writing LLVM IR, it can definitely be done, because that's what Endeca/Oracle did. But there; was such a huge learning curve that only 3 people ever did it successfully (I wasn't one of them),; and debugging seemed very unpleasant and slow. [It was also a masterful achievement in ; job-security-through-obscurity, because no-one in management was going to mess with the; two people who wrote it - until the whole project got canned]. ... and in the time I was there, the Endeca/Oracle stuff wasn't distributed, which could be another; place where the generate-LLVM-IR needs some kind of extra glue for distributing compiled code,; whereas the conventional DLL's are trivial",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-412742385
https://github.com/hail-is/hail/pull/3973#issuecomment-412742385:36,Performance,cache,cacheing,36,"Replying to cseed on code-reuse and cacheing/locking. a) Even with whole-stage codegen, there's a possibility that during development a user; will be tweaking a query in ways which don't change all the stages. And in that case the re-use; would give hits on some stages. The plan is not really to aim at structuring things to get a; high level of re-use, but just to opportunistically exploit re-use which happens to occur -; e.g. if the early stages of an analysis involve reading an existing file and filtering in various; ways, then that may not be changed at all by changes to what happen in the real analysis; after the filtering. And this is also influenced by the medium-term goal of having a Hail service; which (amongst other things) can do simple analyses on small data in under ten seconds - in; that realm compilation time could become a critical factor as a serial bottleneck. [The place where persistent cacheing of compiled files helps most of all is in testing,; where you really are running the exact same queries over and over again on the same; small datasets, and in many cases after making small changes which only affect a few; of the queries]. b) We may actually have some version of the locking problem even if we don't try to reuse the files -; since we have several workers on a node, and possibly a master as well, all needing to put code; into a file (or wait for someone else to populate the file) so that they can load it. Depending on ; precisely how Spark manages things (which I wouldn't want to depend on too much anyway). In fact it's essential that all the workers share the same DLL file, because otherwise they'd be; trying to load multiple DLL's defining the same symbols. That aspect of it could be handled by; putting the files into a per-process directory and using in-memory (std::mutex) synchronization.; But y'know, given that we have to write the DLL's out, it just seemed natural to let them persist; (and until debugging it on MacOS, I thought I could m",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-412742385
https://github.com/hail-is/hail/pull/3973#issuecomment-412742385:878,Performance,bottleneck,bottleneck,878,"Replying to cseed on code-reuse and cacheing/locking. a) Even with whole-stage codegen, there's a possibility that during development a user; will be tweaking a query in ways which don't change all the stages. And in that case the re-use; would give hits on some stages. The plan is not really to aim at structuring things to get a; high level of re-use, but just to opportunistically exploit re-use which happens to occur -; e.g. if the early stages of an analysis involve reading an existing file and filtering in various; ways, then that may not be changed at all by changes to what happen in the real analysis; after the filtering. And this is also influenced by the medium-term goal of having a Hail service; which (amongst other things) can do simple analyses on small data in under ten seconds - in; that realm compilation time could become a critical factor as a serial bottleneck. [The place where persistent cacheing of compiled files helps most of all is in testing,; where you really are running the exact same queries over and over again on the same; small datasets, and in many cases after making small changes which only affect a few; of the queries]. b) We may actually have some version of the locking problem even if we don't try to reuse the files -; since we have several workers on a node, and possibly a master as well, all needing to put code; into a file (or wait for someone else to populate the file) so that they can load it. Depending on ; precisely how Spark manages things (which I wouldn't want to depend on too much anyway). In fact it's essential that all the workers share the same DLL file, because otherwise they'd be; trying to load multiple DLL's defining the same symbols. That aspect of it could be handled by; putting the files into a per-process directory and using in-memory (std::mutex) synchronization.; But y'know, given that we have to write the DLL's out, it just seemed natural to let them persist; (and until debugging it on MacOS, I thought I could m",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-412742385
https://github.com/hail-is/hail/pull/3973#issuecomment-412742385:918,Performance,cache,cacheing,918,"euse and cacheing/locking. a) Even with whole-stage codegen, there's a possibility that during development a user; will be tweaking a query in ways which don't change all the stages. And in that case the re-use; would give hits on some stages. The plan is not really to aim at structuring things to get a; high level of re-use, but just to opportunistically exploit re-use which happens to occur -; e.g. if the early stages of an analysis involve reading an existing file and filtering in various; ways, then that may not be changed at all by changes to what happen in the real analysis; after the filtering. And this is also influenced by the medium-term goal of having a Hail service; which (amongst other things) can do simple analyses on small data in under ten seconds - in; that realm compilation time could become a critical factor as a serial bottleneck. [The place where persistent cacheing of compiled files helps most of all is in testing,; where you really are running the exact same queries over and over again on the same; small datasets, and in many cases after making small changes which only affect a few; of the queries]. b) We may actually have some version of the locking problem even if we don't try to reuse the files -; since we have several workers on a node, and possibly a master as well, all needing to put code; into a file (or wait for someone else to populate the file) so that they can load it. Depending on ; precisely how Spark manages things (which I wouldn't want to depend on too much anyway). In fact it's essential that all the workers share the same DLL file, because otherwise they'd be; trying to load multiple DLL's defining the same symbols. That aspect of it could be handled by; putting the files into a per-process directory and using in-memory (std::mutex) synchronization.; But y'know, given that we have to write the DLL's out, it just seemed natural to let them persist; (and until debugging it on MacOS, I thought I could manage it with nothing but a",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-412742385
https://github.com/hail-is/hail/pull/3973#issuecomment-412742385:1444,Performance,load,load,1444,"turing things to get a; high level of re-use, but just to opportunistically exploit re-use which happens to occur -; e.g. if the early stages of an analysis involve reading an existing file and filtering in various; ways, then that may not be changed at all by changes to what happen in the real analysis; after the filtering. And this is also influenced by the medium-term goal of having a Hail service; which (amongst other things) can do simple analyses on small data in under ten seconds - in; that realm compilation time could become a critical factor as a serial bottleneck. [The place where persistent cacheing of compiled files helps most of all is in testing,; where you really are running the exact same queries over and over again on the same; small datasets, and in many cases after making small changes which only affect a few; of the queries]. b) We may actually have some version of the locking problem even if we don't try to reuse the files -; since we have several workers on a node, and possibly a master as well, all needing to put code; into a file (or wait for someone else to populate the file) so that they can load it. Depending on ; precisely how Spark manages things (which I wouldn't want to depend on too much anyway). In fact it's essential that all the workers share the same DLL file, because otherwise they'd be; trying to load multiple DLL's defining the same symbols. That aspect of it could be handled by; putting the files into a per-process directory and using in-memory (std::mutex) synchronization.; But y'know, given that we have to write the DLL's out, it just seemed natural to let them persist; (and until debugging it on MacOS, I thought I could manage it with nothing but atomic file-create; and atomic-rename, but that didn't quite pan out). As for writing LLVM IR, it can definitely be done, because that's what Endeca/Oracle did. But there; was such a huge learning curve that only 3 people ever did it successfully (I wasn't one of them),; and debugg",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-412742385
https://github.com/hail-is/hail/pull/3973#issuecomment-412742385:1665,Performance,load,load,1665,"g. And this is also influenced by the medium-term goal of having a Hail service; which (amongst other things) can do simple analyses on small data in under ten seconds - in; that realm compilation time could become a critical factor as a serial bottleneck. [The place where persistent cacheing of compiled files helps most of all is in testing,; where you really are running the exact same queries over and over again on the same; small datasets, and in many cases after making small changes which only affect a few; of the queries]. b) We may actually have some version of the locking problem even if we don't try to reuse the files -; since we have several workers on a node, and possibly a master as well, all needing to put code; into a file (or wait for someone else to populate the file) so that they can load it. Depending on ; precisely how Spark manages things (which I wouldn't want to depend on too much anyway). In fact it's essential that all the workers share the same DLL file, because otherwise they'd be; trying to load multiple DLL's defining the same symbols. That aspect of it could be handled by; putting the files into a per-process directory and using in-memory (std::mutex) synchronization.; But y'know, given that we have to write the DLL's out, it just seemed natural to let them persist; (and until debugging it on MacOS, I thought I could manage it with nothing but atomic file-create; and atomic-rename, but that didn't quite pan out). As for writing LLVM IR, it can definitely be done, because that's what Endeca/Oracle did. But there; was such a huge learning curve that only 3 people ever did it successfully (I wasn't one of them),; and debugging seemed very unpleasant and slow. [It was also a masterful achievement in ; job-security-through-obscurity, because no-one in management was going to mess with the; two people who wrote it - until the whole project got canned]. ... and in the time I was there, the Endeca/Oracle stuff wasn't distributed, which could be an",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-412742385
https://github.com/hail-is/hail/pull/3973#issuecomment-412742385:2392,Security,secur,security-through-obscurity,2392,"n load it. Depending on ; precisely how Spark manages things (which I wouldn't want to depend on too much anyway). In fact it's essential that all the workers share the same DLL file, because otherwise they'd be; trying to load multiple DLL's defining the same symbols. That aspect of it could be handled by; putting the files into a per-process directory and using in-memory (std::mutex) synchronization.; But y'know, given that we have to write the DLL's out, it just seemed natural to let them persist; (and until debugging it on MacOS, I thought I could manage it with nothing but atomic file-create; and atomic-rename, but that didn't quite pan out). As for writing LLVM IR, it can definitely be done, because that's what Endeca/Oracle did. But there; was such a huge learning curve that only 3 people ever did it successfully (I wasn't one of them),; and debugging seemed very unpleasant and slow. [It was also a masterful achievement in ; job-security-through-obscurity, because no-one in management was going to mess with the; two people who wrote it - until the whole project got canned]. ... and in the time I was there, the Endeca/Oracle stuff wasn't distributed, which could be another; place where the generate-LLVM-IR needs some kind of extra glue for distributing compiled code,; whereas the conventional DLL's are trivial to ship around. Not claiming that part of it is difficult,; just that it didn't happen at Oracle until long after I left. In contrast, at PhysicsSpeed it was fairly smooth to implement nice abstractions (dense-join-table,; hash-join-table, tuple-with-order) as template classes which could be tested and debugged; in a standalone environment, and then have simpler codegen using those abstractions. At least,; that's a good way to get a lot of functionality with modest effort - and it doesn't preclude migrating; towards a more complex codegen later. It's nice to be able to have templates as low-runtime-cost; abstractions, but you don't have to use them if yo",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-412742385
https://github.com/hail-is/hail/pull/3973#issuecomment-412742385:3003,Security,hash,hash-join-table,3003,"es into a per-process directory and using in-memory (std::mutex) synchronization.; But y'know, given that we have to write the DLL's out, it just seemed natural to let them persist; (and until debugging it on MacOS, I thought I could manage it with nothing but atomic file-create; and atomic-rename, but that didn't quite pan out). As for writing LLVM IR, it can definitely be done, because that's what Endeca/Oracle did. But there; was such a huge learning curve that only 3 people ever did it successfully (I wasn't one of them),; and debugging seemed very unpleasant and slow. [It was also a masterful achievement in ; job-security-through-obscurity, because no-one in management was going to mess with the; two people who wrote it - until the whole project got canned]. ... and in the time I was there, the Endeca/Oracle stuff wasn't distributed, which could be another; place where the generate-LLVM-IR needs some kind of extra glue for distributing compiled code,; whereas the conventional DLL's are trivial to ship around. Not claiming that part of it is difficult,; just that it didn't happen at Oracle until long after I left. In contrast, at PhysicsSpeed it was fairly smooth to implement nice abstractions (dense-join-table,; hash-join-table, tuple-with-order) as template classes which could be tested and debugged; in a standalone environment, and then have simpler codegen using those abstractions. At least,; that's a good way to get a lot of functionality with modest effort - and it doesn't preclude migrating; towards a more complex codegen later. It's nice to be able to have templates as low-runtime-cost; abstractions, but you don't have to use them if you don't want to. In short, most of the usual arguments about the benefits of HLL's apply. Plus the larger pool of; potential hires w/ C++ experience compared to the pool of people w/ lower-level/LLVM/IR/compiler-; internals expertise, and the possibility of very occasionally picking up useful fragments of open-source code.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-412742385
https://github.com/hail-is/hail/pull/3973#issuecomment-412742385:969,Testability,test,testing,969,"euse and cacheing/locking. a) Even with whole-stage codegen, there's a possibility that during development a user; will be tweaking a query in ways which don't change all the stages. And in that case the re-use; would give hits on some stages. The plan is not really to aim at structuring things to get a; high level of re-use, but just to opportunistically exploit re-use which happens to occur -; e.g. if the early stages of an analysis involve reading an existing file and filtering in various; ways, then that may not be changed at all by changes to what happen in the real analysis; after the filtering. And this is also influenced by the medium-term goal of having a Hail service; which (amongst other things) can do simple analyses on small data in under ten seconds - in; that realm compilation time could become a critical factor as a serial bottleneck. [The place where persistent cacheing of compiled files helps most of all is in testing,; where you really are running the exact same queries over and over again on the same; small datasets, and in many cases after making small changes which only affect a few; of the queries]. b) We may actually have some version of the locking problem even if we don't try to reuse the files -; since we have several workers on a node, and possibly a master as well, all needing to put code; into a file (or wait for someone else to populate the file) so that they can load it. Depending on ; precisely how Spark manages things (which I wouldn't want to depend on too much anyway). In fact it's essential that all the workers share the same DLL file, because otherwise they'd be; trying to load multiple DLL's defining the same symbols. That aspect of it could be handled by; putting the files into a per-process directory and using in-memory (std::mutex) synchronization.; But y'know, given that we have to write the DLL's out, it just seemed natural to let them persist; (and until debugging it on MacOS, I thought I could manage it with nothing but a",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-412742385
https://github.com/hail-is/hail/pull/3973#issuecomment-412742385:3073,Testability,test,tested,3073,"es into a per-process directory and using in-memory (std::mutex) synchronization.; But y'know, given that we have to write the DLL's out, it just seemed natural to let them persist; (and until debugging it on MacOS, I thought I could manage it with nothing but atomic file-create; and atomic-rename, but that didn't quite pan out). As for writing LLVM IR, it can definitely be done, because that's what Endeca/Oracle did. But there; was such a huge learning curve that only 3 people ever did it successfully (I wasn't one of them),; and debugging seemed very unpleasant and slow. [It was also a masterful achievement in ; job-security-through-obscurity, because no-one in management was going to mess with the; two people who wrote it - until the whole project got canned]. ... and in the time I was there, the Endeca/Oracle stuff wasn't distributed, which could be another; place where the generate-LLVM-IR needs some kind of extra glue for distributing compiled code,; whereas the conventional DLL's are trivial to ship around. Not claiming that part of it is difficult,; just that it didn't happen at Oracle until long after I left. In contrast, at PhysicsSpeed it was fairly smooth to implement nice abstractions (dense-join-table,; hash-join-table, tuple-with-order) as template classes which could be tested and debugged; in a standalone environment, and then have simpler codegen using those abstractions. At least,; that's a good way to get a lot of functionality with modest effort - and it doesn't preclude migrating; towards a more complex codegen later. It's nice to be able to have templates as low-runtime-cost; abstractions, but you don't have to use them if you don't want to. In short, most of the usual arguments about the benefits of HLL's apply. Plus the larger pool of; potential hires w/ C++ experience compared to the pool of people w/ lower-level/LLVM/IR/compiler-; internals expertise, and the possibility of very occasionally picking up useful fragments of open-source code.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-412742385
https://github.com/hail-is/hail/pull/3973#issuecomment-412742385:750,Usability,simpl,simple,750,"Replying to cseed on code-reuse and cacheing/locking. a) Even with whole-stage codegen, there's a possibility that during development a user; will be tweaking a query in ways which don't change all the stages. And in that case the re-use; would give hits on some stages. The plan is not really to aim at structuring things to get a; high level of re-use, but just to opportunistically exploit re-use which happens to occur -; e.g. if the early stages of an analysis involve reading an existing file and filtering in various; ways, then that may not be changed at all by changes to what happen in the real analysis; after the filtering. And this is also influenced by the medium-term goal of having a Hail service; which (amongst other things) can do simple analyses on small data in under ten seconds - in; that realm compilation time could become a critical factor as a serial bottleneck. [The place where persistent cacheing of compiled files helps most of all is in testing,; where you really are running the exact same queries over and over again on the same; small datasets, and in many cases after making small changes which only affect a few; of the queries]. b) We may actually have some version of the locking problem even if we don't try to reuse the files -; since we have several workers on a node, and possibly a master as well, all needing to put code; into a file (or wait for someone else to populate the file) so that they can load it. Depending on ; precisely how Spark manages things (which I wouldn't want to depend on too much anyway). In fact it's essential that all the workers share the same DLL file, because otherwise they'd be; trying to load multiple DLL's defining the same symbols. That aspect of it could be handled by; putting the files into a per-process directory and using in-memory (std::mutex) synchronization.; But y'know, given that we have to write the DLL's out, it just seemed natural to let them persist; (and until debugging it on MacOS, I thought I could m",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-412742385
https://github.com/hail-is/hail/pull/3973#issuecomment-412742385:2215,Usability,learn,learning,2215," -; since we have several workers on a node, and possibly a master as well, all needing to put code; into a file (or wait for someone else to populate the file) so that they can load it. Depending on ; precisely how Spark manages things (which I wouldn't want to depend on too much anyway). In fact it's essential that all the workers share the same DLL file, because otherwise they'd be; trying to load multiple DLL's defining the same symbols. That aspect of it could be handled by; putting the files into a per-process directory and using in-memory (std::mutex) synchronization.; But y'know, given that we have to write the DLL's out, it just seemed natural to let them persist; (and until debugging it on MacOS, I thought I could manage it with nothing but atomic file-create; and atomic-rename, but that didn't quite pan out). As for writing LLVM IR, it can definitely be done, because that's what Endeca/Oracle did. But there; was such a huge learning curve that only 3 people ever did it successfully (I wasn't one of them),; and debugging seemed very unpleasant and slow. [It was also a masterful achievement in ; job-security-through-obscurity, because no-one in management was going to mess with the; two people who wrote it - until the whole project got canned]. ... and in the time I was there, the Endeca/Oracle stuff wasn't distributed, which could be another; place where the generate-LLVM-IR needs some kind of extra glue for distributing compiled code,; whereas the conventional DLL's are trivial to ship around. Not claiming that part of it is difficult,; just that it didn't happen at Oracle until long after I left. In contrast, at PhysicsSpeed it was fairly smooth to implement nice abstractions (dense-join-table,; hash-join-table, tuple-with-order) as template classes which could be tested and debugged; in a standalone environment, and then have simpler codegen using those abstractions. At least,; that's a good way to get a lot of functionality with modest effort - and it ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-412742385
https://github.com/hail-is/hail/pull/3973#issuecomment-412742385:3137,Usability,simpl,simpler,3137,"es into a per-process directory and using in-memory (std::mutex) synchronization.; But y'know, given that we have to write the DLL's out, it just seemed natural to let them persist; (and until debugging it on MacOS, I thought I could manage it with nothing but atomic file-create; and atomic-rename, but that didn't quite pan out). As for writing LLVM IR, it can definitely be done, because that's what Endeca/Oracle did. But there; was such a huge learning curve that only 3 people ever did it successfully (I wasn't one of them),; and debugging seemed very unpleasant and slow. [It was also a masterful achievement in ; job-security-through-obscurity, because no-one in management was going to mess with the; two people who wrote it - until the whole project got canned]. ... and in the time I was there, the Endeca/Oracle stuff wasn't distributed, which could be another; place where the generate-LLVM-IR needs some kind of extra glue for distributing compiled code,; whereas the conventional DLL's are trivial to ship around. Not claiming that part of it is difficult,; just that it didn't happen at Oracle until long after I left. In contrast, at PhysicsSpeed it was fairly smooth to implement nice abstractions (dense-join-table,; hash-join-table, tuple-with-order) as template classes which could be tested and debugged; in a standalone environment, and then have simpler codegen using those abstractions. At least,; that's a good way to get a lot of functionality with modest effort - and it doesn't preclude migrating; towards a more complex codegen later. It's nice to be able to have templates as low-runtime-cost; abstractions, but you don't have to use them if you don't want to. In short, most of the usual arguments about the benefits of HLL's apply. Plus the larger pool of; potential hires w/ C++ experience compared to the pool of people w/ lower-level/LLVM/IR/compiler-; internals expertise, and the possibility of very occasionally picking up useful fragments of open-source code.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-412742385
https://github.com/hail-is/hail/pull/3973#issuecomment-413243985:12,Testability,test,test,12,"> the speed test shows it still slower than printf. FWIW, that benchmark is dominated by floating-point formatting where fmt falls back to `snprintf` at the moment. For other argument types fmt is faster than glibc's (s)printf. In particular, integer formatting is significantly faster: http://www.zverovich.net/2013/09/07/integer-to-string-conversion-in-cplusplus.html",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-413243985
https://github.com/hail-is/hail/pull/3973#issuecomment-413243985:63,Testability,benchmark,benchmark,63,"> the speed test shows it still slower than printf. FWIW, that benchmark is dominated by floating-point formatting where fmt falls back to `snprintf` at the moment. For other argument types fmt is faster than glibc's (s)printf. In particular, integer formatting is significantly faster: http://www.zverovich.net/2013/09/07/integer-to-string-conversion-in-cplusplus.html",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-413243985
https://github.com/hail-is/hail/pull/3973#issuecomment-413647683:201,Safety,safe,safe,201,"On my rowstore1 branch I now have it working with careful use of flock() (to steer clear of the cases; where NFS behavior diverges from local filesystems, using perl's rename command (which should; be safe assuming it uses the POSIX rename() syscall) to avoid having to lock/unlock from a Makefile. Also a bunch of Makefile changes to use commands from /bin or /usr/bin when they exist, but; otherwise to give a warning and pick up whatever might be found on $PATH. That seems a suitable; compromise between avoid-mysterious-behavior and give-best-effort-on-nonstandard-platform.; [In doing so, I noticed that I actually was picking up /Users/rcownie/anaconda2/envs/py36/bin/curl; rather than /usr/bin/curl - and I don't know whether there's any difference]. But current consensus is that we should figure out how to ship with a known-good compiler; and libraries, so I'm looking into that.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-413647683
https://github.com/hail-is/hail/pull/3973#issuecomment-413647683:254,Safety,avoid,avoid,254,"On my rowstore1 branch I now have it working with careful use of flock() (to steer clear of the cases; where NFS behavior diverges from local filesystems, using perl's rename command (which should; be safe assuming it uses the POSIX rename() syscall) to avoid having to lock/unlock from a Makefile. Also a bunch of Makefile changes to use commands from /bin or /usr/bin when they exist, but; otherwise to give a warning and pick up whatever might be found on $PATH. That seems a suitable; compromise between avoid-mysterious-behavior and give-best-effort-on-nonstandard-platform.; [In doing so, I noticed that I actually was picking up /Users/rcownie/anaconda2/envs/py36/bin/curl; rather than /usr/bin/curl - and I don't know whether there's any difference]. But current consensus is that we should figure out how to ship with a known-good compiler; and libraries, so I'm looking into that.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-413647683
https://github.com/hail-is/hail/pull/3973#issuecomment-413647683:508,Safety,avoid,avoid-mysterious-behavior,508,"On my rowstore1 branch I now have it working with careful use of flock() (to steer clear of the cases; where NFS behavior diverges from local filesystems, using perl's rename command (which should; be safe assuming it uses the POSIX rename() syscall) to avoid having to lock/unlock from a Makefile. Also a bunch of Makefile changes to use commands from /bin or /usr/bin when they exist, but; otherwise to give a warning and pick up whatever might be found on $PATH. That seems a suitable; compromise between avoid-mysterious-behavior and give-best-effort-on-nonstandard-platform.; [In doing so, I noticed that I actually was picking up /Users/rcownie/anaconda2/envs/py36/bin/curl; rather than /usr/bin/curl - and I don't know whether there's any difference]. But current consensus is that we should figure out how to ship with a known-good compiler; and libraries, so I'm looking into that.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-413647683
https://github.com/hail-is/hail/pull/3973#issuecomment-413647683:83,Usability,clear,clear,83,"On my rowstore1 branch I now have it working with careful use of flock() (to steer clear of the cases; where NFS behavior diverges from local filesystems, using perl's rename command (which should; be safe assuming it uses the POSIX rename() syscall) to avoid having to lock/unlock from a Makefile. Also a bunch of Makefile changes to use commands from /bin or /usr/bin when they exist, but; otherwise to give a warning and pick up whatever might be found on $PATH. That seems a suitable; compromise between avoid-mysterious-behavior and give-best-effort-on-nonstandard-platform.; [In doing so, I noticed that I actually was picking up /Users/rcownie/anaconda2/envs/py36/bin/curl; rather than /usr/bin/curl - and I don't know whether there's any difference]. But current consensus is that we should figure out how to ship with a known-good compiler; and libraries, so I'm looking into that.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-413647683
https://github.com/hail-is/hail/pull/3973#issuecomment-413997863:2069,Availability,error,error,2069," RV. 4. The hash function on (options, source) is now beefed up to cope with having only a; few distinct values of options; and is modified with the output of ""$(CXX) --version"",; so that when you upgrade your compiler, you won't get hits on modules compiled with the old; compiler. 5. build.gradle has a new target ""nativeLibPrebuilt"", for updating the prebuilt/lib/linux-x86-64; or prebuilt/lib/darwin. 6. The committed prebuilt libraries are built thus:. darwin - On my MacOS laptop, with the default (clang-based) compiler, -march=sandybridge; From my reading, I believe this should be compatible withall MacBook Pro's; released since 2011, and all versions of MacOS since 10.9 (the first to use; libc++ rather than libstdc++ as the default C++ library) - we're now at 10.13,; with 10.14 arriving some time in the fall. linux-x86-64 - Built on my home desktop running Ubuntu-16.04 LTS, and g++-5.0.4, with; -fabi-version=9. In theory this should work with all systems based on g++5.x and; later. I made some effort to move std::string out of the interfaces between prebuilt; and dynamic code, which gives it some chance of working on systems based on; g++-4.x, but haven't tested that. I'm planning to fire up VM's either in cloud or under VirtualBox, to test this against Ubuntu-14.04,; Ubuntu-18.04, and the latest stable RHEL, which should cover most of the bases. In the interest of getting this committed, I have not made changes relating to logging and; error messages. The DLL's are still in the jar, and I think it has to stay that way because; all nodes need to see libhail.so. The header files are also in the jar, and have to be; unpacked in a convoluted way, and that could probably be simplified if/when we change; the approach to packaging. Once this goes in, I can follow it with a PR which adds the NativePackDecoder in RowStore.scala,; controlled by whether environment variable ""HAIL_ENABLE_CPP_CODEGEN"" is defined; (so defaulting to using the JVM bytecode CompiledPackDecoder).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-413997863
https://github.com/hail-is/hail/pull/3973#issuecomment-413997863:802,Deployability,upgrade,upgrade,802,"Various changes:. 1. Locking is now done with a carefully restricted use of flock(), and the makefiles use; perl's rename command to get atomic rename, so they don't need to take locks. 2. The makefile conforms to the customary use-whatever-is-on-$PATH, with the slight wrinkle that; the full pathnames of the commands used will be visible in the build log - so if someone; picks up something weird we'll at least see it. 3. There is a cache of NativeModule objects, so that we won't do enormous numbers of; calls to dlopen/dlclose. This may help in shuffle code, which creates a new PackDecoder; for each RV. 4. The hash function on (options, source) is now beefed up to cope with having only a; few distinct values of options; and is modified with the output of ""$(CXX) --version"",; so that when you upgrade your compiler, you won't get hits on modules compiled with the old; compiler. 5. build.gradle has a new target ""nativeLibPrebuilt"", for updating the prebuilt/lib/linux-x86-64; or prebuilt/lib/darwin. 6. The committed prebuilt libraries are built thus:. darwin - On my MacOS laptop, with the default (clang-based) compiler, -march=sandybridge; From my reading, I believe this should be compatible withall MacBook Pro's; released since 2011, and all versions of MacOS since 10.9 (the first to use; libc++ rather than libstdc++ as the default C++ library) - we're now at 10.13,; with 10.14 arriving some time in the fall. linux-x86-64 - Built on my home desktop running Ubuntu-16.04 LTS, and g++-5.0.4, with; -fabi-version=9. In theory this should work with all systems based on g++5.x and; later. I made some effort to move std::string out of the interfaces between prebuilt; and dynamic code, which gives it some chance of working on systems based on; g++-4.x, but haven't tested that. I'm planning to fire up VM's either in cloud or under VirtualBox, to test this against Ubuntu-14.04,; Ubuntu-18.04, and the latest stable RHEL, which should cover most of the bases. In the interest of getti",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-413997863
https://github.com/hail-is/hail/pull/3973#issuecomment-413997863:1229,Deployability,release,released,1229," take locks. 2. The makefile conforms to the customary use-whatever-is-on-$PATH, with the slight wrinkle that; the full pathnames of the commands used will be visible in the build log - so if someone; picks up something weird we'll at least see it. 3. There is a cache of NativeModule objects, so that we won't do enormous numbers of; calls to dlopen/dlclose. This may help in shuffle code, which creates a new PackDecoder; for each RV. 4. The hash function on (options, source) is now beefed up to cope with having only a; few distinct values of options; and is modified with the output of ""$(CXX) --version"",; so that when you upgrade your compiler, you won't get hits on modules compiled with the old; compiler. 5. build.gradle has a new target ""nativeLibPrebuilt"", for updating the prebuilt/lib/linux-x86-64; or prebuilt/lib/darwin. 6. The committed prebuilt libraries are built thus:. darwin - On my MacOS laptop, with the default (clang-based) compiler, -march=sandybridge; From my reading, I believe this should be compatible withall MacBook Pro's; released since 2011, and all versions of MacOS since 10.9 (the first to use; libc++ rather than libstdc++ as the default C++ library) - we're now at 10.13,; with 10.14 arriving some time in the fall. linux-x86-64 - Built on my home desktop running Ubuntu-16.04 LTS, and g++-5.0.4, with; -fabi-version=9. In theory this should work with all systems based on g++5.x and; later. I made some effort to move std::string out of the interfaces between prebuilt; and dynamic code, which gives it some chance of working on systems based on; g++-4.x, but haven't tested that. I'm planning to fire up VM's either in cloud or under VirtualBox, to test this against Ubuntu-14.04,; Ubuntu-18.04, and the latest stable RHEL, which should cover most of the bases. In the interest of getting this committed, I have not made changes relating to logging and; error messages. The DLL's are still in the jar, and I think it has to stay that way because; all nodes ne",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-413997863
https://github.com/hail-is/hail/pull/3973#issuecomment-413997863:1655,Integrability,interface,interfaces,1655," RV. 4. The hash function on (options, source) is now beefed up to cope with having only a; few distinct values of options; and is modified with the output of ""$(CXX) --version"",; so that when you upgrade your compiler, you won't get hits on modules compiled with the old; compiler. 5. build.gradle has a new target ""nativeLibPrebuilt"", for updating the prebuilt/lib/linux-x86-64; or prebuilt/lib/darwin. 6. The committed prebuilt libraries are built thus:. darwin - On my MacOS laptop, with the default (clang-based) compiler, -march=sandybridge; From my reading, I believe this should be compatible withall MacBook Pro's; released since 2011, and all versions of MacOS since 10.9 (the first to use; libc++ rather than libstdc++ as the default C++ library) - we're now at 10.13,; with 10.14 arriving some time in the fall. linux-x86-64 - Built on my home desktop running Ubuntu-16.04 LTS, and g++-5.0.4, with; -fabi-version=9. In theory this should work with all systems based on g++5.x and; later. I made some effort to move std::string out of the interfaces between prebuilt; and dynamic code, which gives it some chance of working on systems based on; g++-4.x, but haven't tested that. I'm planning to fire up VM's either in cloud or under VirtualBox, to test this against Ubuntu-14.04,; Ubuntu-18.04, and the latest stable RHEL, which should cover most of the bases. In the interest of getting this committed, I have not made changes relating to logging and; error messages. The DLL's are still in the jar, and I think it has to stay that way because; all nodes need to see libhail.so. The header files are also in the jar, and have to be; unpacked in a convoluted way, and that could probably be simplified if/when we change; the approach to packaging. Once this goes in, I can follow it with a PR which adds the NativePackDecoder in RowStore.scala,; controlled by whether environment variable ""HAIL_ENABLE_CPP_CODEGEN"" is defined; (so defaulting to using the JVM bytecode CompiledPackDecoder).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-413997863
https://github.com/hail-is/hail/pull/3973#issuecomment-413997863:2075,Integrability,message,messages,2075," RV. 4. The hash function on (options, source) is now beefed up to cope with having only a; few distinct values of options; and is modified with the output of ""$(CXX) --version"",; so that when you upgrade your compiler, you won't get hits on modules compiled with the old; compiler. 5. build.gradle has a new target ""nativeLibPrebuilt"", for updating the prebuilt/lib/linux-x86-64; or prebuilt/lib/darwin. 6. The committed prebuilt libraries are built thus:. darwin - On my MacOS laptop, with the default (clang-based) compiler, -march=sandybridge; From my reading, I believe this should be compatible withall MacBook Pro's; released since 2011, and all versions of MacOS since 10.9 (the first to use; libc++ rather than libstdc++ as the default C++ library) - we're now at 10.13,; with 10.14 arriving some time in the fall. linux-x86-64 - Built on my home desktop running Ubuntu-16.04 LTS, and g++-5.0.4, with; -fabi-version=9. In theory this should work with all systems based on g++5.x and; later. I made some effort to move std::string out of the interfaces between prebuilt; and dynamic code, which gives it some chance of working on systems based on; g++-4.x, but haven't tested that. I'm planning to fire up VM's either in cloud or under VirtualBox, to test this against Ubuntu-14.04,; Ubuntu-18.04, and the latest stable RHEL, which should cover most of the bases. In the interest of getting this committed, I have not made changes relating to logging and; error messages. The DLL's are still in the jar, and I think it has to stay that way because; all nodes need to see libhail.so. The header files are also in the jar, and have to be; unpacked in a convoluted way, and that could probably be simplified if/when we change; the approach to packaging. Once this goes in, I can follow it with a PR which adds the NativePackDecoder in RowStore.scala,; controlled by whether environment variable ""HAIL_ENABLE_CPP_CODEGEN"" is defined; (so defaulting to using the JVM bytecode CompiledPackDecoder).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-413997863
https://github.com/hail-is/hail/pull/3973#issuecomment-413997863:2496,Modifiability,variab,variable,2496," RV. 4. The hash function on (options, source) is now beefed up to cope with having only a; few distinct values of options; and is modified with the output of ""$(CXX) --version"",; so that when you upgrade your compiler, you won't get hits on modules compiled with the old; compiler. 5. build.gradle has a new target ""nativeLibPrebuilt"", for updating the prebuilt/lib/linux-x86-64; or prebuilt/lib/darwin. 6. The committed prebuilt libraries are built thus:. darwin - On my MacOS laptop, with the default (clang-based) compiler, -march=sandybridge; From my reading, I believe this should be compatible withall MacBook Pro's; released since 2011, and all versions of MacOS since 10.9 (the first to use; libc++ rather than libstdc++ as the default C++ library) - we're now at 10.13,; with 10.14 arriving some time in the fall. linux-x86-64 - Built on my home desktop running Ubuntu-16.04 LTS, and g++-5.0.4, with; -fabi-version=9. In theory this should work with all systems based on g++5.x and; later. I made some effort to move std::string out of the interfaces between prebuilt; and dynamic code, which gives it some chance of working on systems based on; g++-4.x, but haven't tested that. I'm planning to fire up VM's either in cloud or under VirtualBox, to test this against Ubuntu-14.04,; Ubuntu-18.04, and the latest stable RHEL, which should cover most of the bases. In the interest of getting this committed, I have not made changes relating to logging and; error messages. The DLL's are still in the jar, and I think it has to stay that way because; all nodes need to see libhail.so. The header files are also in the jar, and have to be; unpacked in a convoluted way, and that could probably be simplified if/when we change; the approach to packaging. Once this goes in, I can follow it with a PR which adds the NativePackDecoder in RowStore.scala,; controlled by whether environment variable ""HAIL_ENABLE_CPP_CODEGEN"" is defined; (so defaulting to using the JVM bytecode CompiledPackDecoder).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-413997863
https://github.com/hail-is/hail/pull/3973#issuecomment-413997863:436,Performance,cache,cache,436,"Various changes:. 1. Locking is now done with a carefully restricted use of flock(), and the makefiles use; perl's rename command to get atomic rename, so they don't need to take locks. 2. The makefile conforms to the customary use-whatever-is-on-$PATH, with the slight wrinkle that; the full pathnames of the commands used will be visible in the build log - so if someone; picks up something weird we'll at least see it. 3. There is a cache of NativeModule objects, so that we won't do enormous numbers of; calls to dlopen/dlclose. This may help in shuffle code, which creates a new PackDecoder; for each RV. 4. The hash function on (options, source) is now beefed up to cope with having only a; few distinct values of options; and is modified with the output of ""$(CXX) --version"",; so that when you upgrade your compiler, you won't get hits on modules compiled with the old; compiler. 5. build.gradle has a new target ""nativeLibPrebuilt"", for updating the prebuilt/lib/linux-x86-64; or prebuilt/lib/darwin. 6. The committed prebuilt libraries are built thus:. darwin - On my MacOS laptop, with the default (clang-based) compiler, -march=sandybridge; From my reading, I believe this should be compatible withall MacBook Pro's; released since 2011, and all versions of MacOS since 10.9 (the first to use; libc++ rather than libstdc++ as the default C++ library) - we're now at 10.13,; with 10.14 arriving some time in the fall. linux-x86-64 - Built on my home desktop running Ubuntu-16.04 LTS, and g++-5.0.4, with; -fabi-version=9. In theory this should work with all systems based on g++5.x and; later. I made some effort to move std::string out of the interfaces between prebuilt; and dynamic code, which gives it some chance of working on systems based on; g++-4.x, but haven't tested that. I'm planning to fire up VM's either in cloud or under VirtualBox, to test this against Ubuntu-14.04,; Ubuntu-18.04, and the latest stable RHEL, which should cover most of the bases. In the interest of getti",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-413997863
https://github.com/hail-is/hail/pull/3973#issuecomment-413997863:617,Security,hash,hash,617,"Various changes:. 1. Locking is now done with a carefully restricted use of flock(), and the makefiles use; perl's rename command to get atomic rename, so they don't need to take locks. 2. The makefile conforms to the customary use-whatever-is-on-$PATH, with the slight wrinkle that; the full pathnames of the commands used will be visible in the build log - so if someone; picks up something weird we'll at least see it. 3. There is a cache of NativeModule objects, so that we won't do enormous numbers of; calls to dlopen/dlclose. This may help in shuffle code, which creates a new PackDecoder; for each RV. 4. The hash function on (options, source) is now beefed up to cope with having only a; few distinct values of options; and is modified with the output of ""$(CXX) --version"",; so that when you upgrade your compiler, you won't get hits on modules compiled with the old; compiler. 5. build.gradle has a new target ""nativeLibPrebuilt"", for updating the prebuilt/lib/linux-x86-64; or prebuilt/lib/darwin. 6. The committed prebuilt libraries are built thus:. darwin - On my MacOS laptop, with the default (clang-based) compiler, -march=sandybridge; From my reading, I believe this should be compatible withall MacBook Pro's; released since 2011, and all versions of MacOS since 10.9 (the first to use; libc++ rather than libstdc++ as the default C++ library) - we're now at 10.13,; with 10.14 arriving some time in the fall. linux-x86-64 - Built on my home desktop running Ubuntu-16.04 LTS, and g++-5.0.4, with; -fabi-version=9. In theory this should work with all systems based on g++5.x and; later. I made some effort to move std::string out of the interfaces between prebuilt; and dynamic code, which gives it some chance of working on systems based on; g++-4.x, but haven't tested that. I'm planning to fire up VM's either in cloud or under VirtualBox, to test this against Ubuntu-14.04,; Ubuntu-18.04, and the latest stable RHEL, which should cover most of the bases. In the interest of getti",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-413997863
https://github.com/hail-is/hail/pull/3973#issuecomment-413997863:353,Testability,log,log,353,"Various changes:. 1. Locking is now done with a carefully restricted use of flock(), and the makefiles use; perl's rename command to get atomic rename, so they don't need to take locks. 2. The makefile conforms to the customary use-whatever-is-on-$PATH, with the slight wrinkle that; the full pathnames of the commands used will be visible in the build log - so if someone; picks up something weird we'll at least see it. 3. There is a cache of NativeModule objects, so that we won't do enormous numbers of; calls to dlopen/dlclose. This may help in shuffle code, which creates a new PackDecoder; for each RV. 4. The hash function on (options, source) is now beefed up to cope with having only a; few distinct values of options; and is modified with the output of ""$(CXX) --version"",; so that when you upgrade your compiler, you won't get hits on modules compiled with the old; compiler. 5. build.gradle has a new target ""nativeLibPrebuilt"", for updating the prebuilt/lib/linux-x86-64; or prebuilt/lib/darwin. 6. The committed prebuilt libraries are built thus:. darwin - On my MacOS laptop, with the default (clang-based) compiler, -march=sandybridge; From my reading, I believe this should be compatible withall MacBook Pro's; released since 2011, and all versions of MacOS since 10.9 (the first to use; libc++ rather than libstdc++ as the default C++ library) - we're now at 10.13,; with 10.14 arriving some time in the fall. linux-x86-64 - Built on my home desktop running Ubuntu-16.04 LTS, and g++-5.0.4, with; -fabi-version=9. In theory this should work with all systems based on g++5.x and; later. I made some effort to move std::string out of the interfaces between prebuilt; and dynamic code, which gives it some chance of working on systems based on; g++-4.x, but haven't tested that. I'm planning to fire up VM's either in cloud or under VirtualBox, to test this against Ubuntu-14.04,; Ubuntu-18.04, and the latest stable RHEL, which should cover most of the bases. In the interest of getti",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-413997863
https://github.com/hail-is/hail/pull/3973#issuecomment-413997863:1782,Testability,test,tested,1782," RV. 4. The hash function on (options, source) is now beefed up to cope with having only a; few distinct values of options; and is modified with the output of ""$(CXX) --version"",; so that when you upgrade your compiler, you won't get hits on modules compiled with the old; compiler. 5. build.gradle has a new target ""nativeLibPrebuilt"", for updating the prebuilt/lib/linux-x86-64; or prebuilt/lib/darwin. 6. The committed prebuilt libraries are built thus:. darwin - On my MacOS laptop, with the default (clang-based) compiler, -march=sandybridge; From my reading, I believe this should be compatible withall MacBook Pro's; released since 2011, and all versions of MacOS since 10.9 (the first to use; libc++ rather than libstdc++ as the default C++ library) - we're now at 10.13,; with 10.14 arriving some time in the fall. linux-x86-64 - Built on my home desktop running Ubuntu-16.04 LTS, and g++-5.0.4, with; -fabi-version=9. In theory this should work with all systems based on g++5.x and; later. I made some effort to move std::string out of the interfaces between prebuilt; and dynamic code, which gives it some chance of working on systems based on; g++-4.x, but haven't tested that. I'm planning to fire up VM's either in cloud or under VirtualBox, to test this against Ubuntu-14.04,; Ubuntu-18.04, and the latest stable RHEL, which should cover most of the bases. In the interest of getting this committed, I have not made changes relating to logging and; error messages. The DLL's are still in the jar, and I think it has to stay that way because; all nodes need to see libhail.so. The header files are also in the jar, and have to be; unpacked in a convoluted way, and that could probably be simplified if/when we change; the approach to packaging. Once this goes in, I can follow it with a PR which adds the NativePackDecoder in RowStore.scala,; controlled by whether environment variable ""HAIL_ENABLE_CPP_CODEGEN"" is defined; (so defaulting to using the JVM bytecode CompiledPackDecoder).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-413997863
https://github.com/hail-is/hail/pull/3973#issuecomment-413997863:1864,Testability,test,test,1864," RV. 4. The hash function on (options, source) is now beefed up to cope with having only a; few distinct values of options; and is modified with the output of ""$(CXX) --version"",; so that when you upgrade your compiler, you won't get hits on modules compiled with the old; compiler. 5. build.gradle has a new target ""nativeLibPrebuilt"", for updating the prebuilt/lib/linux-x86-64; or prebuilt/lib/darwin. 6. The committed prebuilt libraries are built thus:. darwin - On my MacOS laptop, with the default (clang-based) compiler, -march=sandybridge; From my reading, I believe this should be compatible withall MacBook Pro's; released since 2011, and all versions of MacOS since 10.9 (the first to use; libc++ rather than libstdc++ as the default C++ library) - we're now at 10.13,; with 10.14 arriving some time in the fall. linux-x86-64 - Built on my home desktop running Ubuntu-16.04 LTS, and g++-5.0.4, with; -fabi-version=9. In theory this should work with all systems based on g++5.x and; later. I made some effort to move std::string out of the interfaces between prebuilt; and dynamic code, which gives it some chance of working on systems based on; g++-4.x, but haven't tested that. I'm planning to fire up VM's either in cloud or under VirtualBox, to test this against Ubuntu-14.04,; Ubuntu-18.04, and the latest stable RHEL, which should cover most of the bases. In the interest of getting this committed, I have not made changes relating to logging and; error messages. The DLL's are still in the jar, and I think it has to stay that way because; all nodes need to see libhail.so. The header files are also in the jar, and have to be; unpacked in a convoluted way, and that could probably be simplified if/when we change; the approach to packaging. Once this goes in, I can follow it with a PR which adds the NativePackDecoder in RowStore.scala,; controlled by whether environment variable ""HAIL_ENABLE_CPP_CODEGEN"" is defined; (so defaulting to using the JVM bytecode CompiledPackDecoder).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-413997863
https://github.com/hail-is/hail/pull/3973#issuecomment-413997863:2056,Testability,log,logging,2056," RV. 4. The hash function on (options, source) is now beefed up to cope with having only a; few distinct values of options; and is modified with the output of ""$(CXX) --version"",; so that when you upgrade your compiler, you won't get hits on modules compiled with the old; compiler. 5. build.gradle has a new target ""nativeLibPrebuilt"", for updating the prebuilt/lib/linux-x86-64; or prebuilt/lib/darwin. 6. The committed prebuilt libraries are built thus:. darwin - On my MacOS laptop, with the default (clang-based) compiler, -march=sandybridge; From my reading, I believe this should be compatible withall MacBook Pro's; released since 2011, and all versions of MacOS since 10.9 (the first to use; libc++ rather than libstdc++ as the default C++ library) - we're now at 10.13,; with 10.14 arriving some time in the fall. linux-x86-64 - Built on my home desktop running Ubuntu-16.04 LTS, and g++-5.0.4, with; -fabi-version=9. In theory this should work with all systems based on g++5.x and; later. I made some effort to move std::string out of the interfaces between prebuilt; and dynamic code, which gives it some chance of working on systems based on; g++-4.x, but haven't tested that. I'm planning to fire up VM's either in cloud or under VirtualBox, to test this against Ubuntu-14.04,; Ubuntu-18.04, and the latest stable RHEL, which should cover most of the bases. In the interest of getting this committed, I have not made changes relating to logging and; error messages. The DLL's are still in the jar, and I think it has to stay that way because; all nodes need to see libhail.so. The header files are also in the jar, and have to be; unpacked in a convoluted way, and that could probably be simplified if/when we change; the approach to packaging. Once this goes in, I can follow it with a PR which adds the NativePackDecoder in RowStore.scala,; controlled by whether environment variable ""HAIL_ENABLE_CPP_CODEGEN"" is defined; (so defaulting to using the JVM bytecode CompiledPackDecoder).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-413997863
https://github.com/hail-is/hail/pull/3973#issuecomment-413997863:2307,Usability,simpl,simplified,2307," RV. 4. The hash function on (options, source) is now beefed up to cope with having only a; few distinct values of options; and is modified with the output of ""$(CXX) --version"",; so that when you upgrade your compiler, you won't get hits on modules compiled with the old; compiler. 5. build.gradle has a new target ""nativeLibPrebuilt"", for updating the prebuilt/lib/linux-x86-64; or prebuilt/lib/darwin. 6. The committed prebuilt libraries are built thus:. darwin - On my MacOS laptop, with the default (clang-based) compiler, -march=sandybridge; From my reading, I believe this should be compatible withall MacBook Pro's; released since 2011, and all versions of MacOS since 10.9 (the first to use; libc++ rather than libstdc++ as the default C++ library) - we're now at 10.13,; with 10.14 arriving some time in the fall. linux-x86-64 - Built on my home desktop running Ubuntu-16.04 LTS, and g++-5.0.4, with; -fabi-version=9. In theory this should work with all systems based on g++5.x and; later. I made some effort to move std::string out of the interfaces between prebuilt; and dynamic code, which gives it some chance of working on systems based on; g++-4.x, but haven't tested that. I'm planning to fire up VM's either in cloud or under VirtualBox, to test this against Ubuntu-14.04,; Ubuntu-18.04, and the latest stable RHEL, which should cover most of the bases. In the interest of getting this committed, I have not made changes relating to logging and; error messages. The DLL's are still in the jar, and I think it has to stay that way because; all nodes need to see libhail.so. The header files are also in the jar, and have to be; unpacked in a convoluted way, and that could probably be simplified if/when we change; the approach to packaging. Once this goes in, I can follow it with a PR which adds the NativePackDecoder in RowStore.scala,; controlled by whether environment variable ""HAIL_ENABLE_CPP_CODEGEN"" is defined; (so defaulting to using the JVM bytecode CompiledPackDecoder).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-413997863
https://github.com/hail-is/hail/pull/3973#issuecomment-415067865:132,Integrability,synchroniz,synchronization,132,"Changed as requested. - files go in per-session directories with names of the form /tmp/hail_XXXXXX. - this eliminates interprocess synchronization; inter-thread synchronization is; by a std::map<std::string, std::mutex> giving a separate mutex coresponding; to each generated module. - it's now ""libhail.so"" and ""libhail.dylib"", without any abi qualification. The prebuilt; libhail.dylib should work on machines compatible with -march=sandybridge and; MacOS back to 10.9. - if you build from source, you can do ""./gradlew nativeLibPrebuilt"" to get; the libraries copied over for packaging into the jar(or copy them by hand, as; previously).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-415067865
https://github.com/hail-is/hail/pull/3973#issuecomment-415067865:162,Integrability,synchroniz,synchronization,162,"Changed as requested. - files go in per-session directories with names of the form /tmp/hail_XXXXXX. - this eliminates interprocess synchronization; inter-thread synchronization is; by a std::map<std::string, std::mutex> giving a separate mutex coresponding; to each generated module. - it's now ""libhail.so"" and ""libhail.dylib"", without any abi qualification. The prebuilt; libhail.dylib should work on machines compatible with -march=sandybridge and; MacOS back to 10.9. - if you build from source, you can do ""./gradlew nativeLibPrebuilt"" to get; the libraries copied over for packaging into the jar(or copy them by hand, as; previously).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-415067865
https://github.com/hail-is/hail/pull/3973#issuecomment-415089165:11,Usability,clear,clear,11,"Just to be clear, as much as possible we aim to keep the main source code free of historical inconsistencies. That applies doubly to pull requests, which should be single, semantically coherent units.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-415089165
https://github.com/hail-is/hail/pull/3973#issuecomment-415862955:73,Performance,load,loading,73,"It seems like the discussion on this PR has blown out Github's UI, haha, loading and navigating this page is increasingly painful. When you're ready for another look, do you mind squashing these changes and opening a new PR to start with a clean state?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-415862955
https://github.com/hail-is/hail/pull/3974#issuecomment-408132885:67,Deployability,pipeline,pipelines,67,"This added node performs the function that appears all over Python pipelines:; ```python; mt = mt.annotate_rows(foo = ht[mt.row_key]); ```; and ; ```; mt = mt.annotate_rows(foo = ht[mt.not_a_key_field]); ```. The code inside the execution is quite horrible when joining on a non-key field, but I expect it to be much faster than the previous Python implementation.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3974#issuecomment-408132885
https://github.com/hail-is/hail/pull/3974#issuecomment-408132885:16,Performance,perform,performs,16,"This added node performs the function that appears all over Python pipelines:; ```python; mt = mt.annotate_rows(foo = ht[mt.row_key]); ```; and ; ```; mt = mt.annotate_rows(foo = ht[mt.not_a_key_field]); ```. The code inside the execution is quite horrible when joining on a non-key field, but I expect it to be much faster than the previous Python implementation.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3974#issuecomment-408132885
https://github.com/hail-is/hail/pull/3974#issuecomment-408702565:156,Energy Efficiency,efficient,efficient,156,"@cseed can you take a look at this for rough structural comments? Happy to back out the `key` business and leave that in Python, but this will make it more efficient",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3974#issuecomment-408702565
https://github.com/hail-is/hail/pull/3974#issuecomment-409673277:80,Testability,test,tests,80,@rcownie I addressed your comments and added some comments in the code and more tests.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3974#issuecomment-409673277
https://github.com/hail-is/hail/pull/3974#issuecomment-410283581:124,Testability,test,tests,124,@danking reassigned you since Richard is on vacation. He approved it before I added a few more code comments and added more tests.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3974#issuecomment-410283581
https://github.com/hail-is/hail/pull/3974#issuecomment-410324020:65,Energy Efficiency,allocate,allocated,65,"Ok, I'm not sure I'll get to it today, been a bit PR review over-allocated. I can definitely look Monday.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3974#issuecomment-410324020
https://github.com/hail-is/hail/issues/3975#issuecomment-422359120:172,Energy Efficiency,efficient,efficient,172,"I'd propose closing this as a won't-fix. The PLINK format doesn't lend itself well to parallel import, and spending even an engineer-day supporting it in a way that's more efficient than what you wrote above doesn't seem worth it. Thoughts?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/3975#issuecomment-422359120
https://github.com/hail-is/hail/pull/3977#issuecomment-407268618:59,Integrability,interface,interface,59,"@rcownie I think this design is a reasonable compromise on interface, at least until linear algebra is in the compiler and we can ""cancel"" conversion from ndarray to BlockMatrix and back. The optimal `complexity_bound` will be hugely dependent on cluster setup. To aid user intuition, I made the unit in terms of a single dimension rather than dimension-cubed. I've found the divide-and-conquer eigh method (with memory proportional to elements) to be 2.5-3x faster than the RRR eigh method (with memory proportional to dimension) when run on laptop and GCP; it takes greater advantage of vectorized BLAS3 ops. Since we're CPU rather than RAM limited on a high-core GCP machine, I've set this up to use divide-and-conquer whenever it won't result in an overflow on `lwork` which is still an int32 in the Python stack (boo). @cseed please let me know if you have any high-level feedback",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3977#issuecomment-407268618
https://github.com/hail-is/hail/pull/3977#issuecomment-407268618:234,Integrability,depend,dependent,234,"@rcownie I think this design is a reasonable compromise on interface, at least until linear algebra is in the compiler and we can ""cancel"" conversion from ndarray to BlockMatrix and back. The optimal `complexity_bound` will be hugely dependent on cluster setup. To aid user intuition, I made the unit in terms of a single dimension rather than dimension-cubed. I've found the divide-and-conquer eigh method (with memory proportional to elements) to be 2.5-3x faster than the RRR eigh method (with memory proportional to dimension) when run on laptop and GCP; it takes greater advantage of vectorized BLAS3 ops. Since we're CPU rather than RAM limited on a high-core GCP machine, I've set this up to use divide-and-conquer whenever it won't result in an overflow on `lwork` which is still an int32 in the Python stack (boo). @cseed please let me know if you have any high-level feedback",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3977#issuecomment-407268618
https://github.com/hail-is/hail/pull/3977#issuecomment-407268618:274,Usability,intuit,intuition,274,"@rcownie I think this design is a reasonable compromise on interface, at least until linear algebra is in the compiler and we can ""cancel"" conversion from ndarray to BlockMatrix and back. The optimal `complexity_bound` will be hugely dependent on cluster setup. To aid user intuition, I made the unit in terms of a single dimension rather than dimension-cubed. I've found the divide-and-conquer eigh method (with memory proportional to elements) to be 2.5-3x faster than the RRR eigh method (with memory proportional to dimension) when run on laptop and GCP; it takes greater advantage of vectorized BLAS3 ops. Since we're CPU rather than RAM limited on a high-core GCP machine, I've set this up to use divide-and-conquer whenever it won't result in an overflow on `lwork` which is still an int32 in the Python stack (boo). @cseed please let me know if you have any high-level feedback",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3977#issuecomment-407268618
https://github.com/hail-is/hail/pull/3977#issuecomment-407268618:877,Usability,feedback,feedback,877,"@rcownie I think this design is a reasonable compromise on interface, at least until linear algebra is in the compiler and we can ""cancel"" conversion from ndarray to BlockMatrix and back. The optimal `complexity_bound` will be hugely dependent on cluster setup. To aid user intuition, I made the unit in terms of a single dimension rather than dimension-cubed. I've found the divide-and-conquer eigh method (with memory proportional to elements) to be 2.5-3x faster than the RRR eigh method (with memory proportional to dimension) when run on laptop and GCP; it takes greater advantage of vectorized BLAS3 ops. Since we're CPU rather than RAM limited on a high-core GCP machine, I've set this up to use divide-and-conquer whenever it won't result in an overflow on `lwork` which is still an int32 in the Python stack (boo). @cseed please let me know if you have any high-level feedback",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3977#issuecomment-407268618
https://github.com/hail-is/hail/pull/3990#issuecomment-407914682:114,Security,audit,audit,114,I'm not going to read 7000 lines of deletions. Fine with me if it passes! And fine to delete tests conditional on audit soon.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3990#issuecomment-407914682
https://github.com/hail-is/hail/pull/3990#issuecomment-407914682:93,Testability,test,tests,93,I'm not going to read 7000 lines of deletions. Fine with me if it passes! And fine to delete tests conditional on audit soon.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3990#issuecomment-407914682
https://github.com/hail-is/hail/pull/3993#issuecomment-409674187:20,Integrability,protocol,protocol,20,I'm not sure of the protocol regarding stacked PRs,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3993#issuecomment-409674187
https://github.com/hail-is/hail/pull/3996#issuecomment-408198375:45,Safety,unsafe,unsafe,45,I'm waiting for #3997 to pass so I can do an unsafe double merge though,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/3996#issuecomment-408198375
https://github.com/hail-is/hail/pull/4000#issuecomment-408235922:22,Availability,error,error,22,so this fixes a match error in that case?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/4000#issuecomment-408235922
https://github.com/hail-is/hail/issues/4001#issuecomment-408232868:18,Performance,optimiz,optimized,18,"Currently this is optimized to:. ```; (TableMapRows (idx) 1; (TableRange 5 5); (MakeStruct; (idx; (GetField idx; (Ref Struct{idx:Int32} row))); (x; (I32 5)))); ```. But clearly it should be an InsertFields, not a MakeStruct.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/4001#issuecomment-408232868
https://github.com/hail-is/hail/issues/4001#issuecomment-408232868:169,Usability,clear,clearly,169,"Currently this is optimized to:. ```; (TableMapRows (idx) 1; (TableRange 5 5); (MakeStruct; (idx; (GetField idx; (Ref Struct{idx:Int32} row))); (x; (I32 5)))); ```. But clearly it should be an InsertFields, not a MakeStruct.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/4001#issuecomment-408232868
https://github.com/hail-is/hail/pull/4004#issuecomment-408972048:51,Integrability,interface,interface,51,"Just a heads up, the docs aren't rendered. But the interface looks awesome!!!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/4004#issuecomment-408972048
https://github.com/hail-is/hail/pull/4004#issuecomment-408987889:41,Integrability,interface,interface,41,"Ha, no, was just curious as to where the interface settled. Not a show-stopper for me at the moment (though I'd probably use it later this week)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/4004#issuecomment-408987889
https://github.com/hail-is/hail/issues/4011#issuecomment-408512050:76,Availability,Error,Error,76,https://hail.zulipchat.com/#narrow/stream/123010-Hail-0.2E2.20support/topic/Error.20writing.20vcf,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/4011#issuecomment-408512050
https://github.com/hail-is/hail/pull/4013#issuecomment-408639182:71,Testability,test,test,71,"The one possible issue with this is if you try to run python from the /test/ dir, you'll import the test module instead. But that seems minor",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/4013#issuecomment-408639182
https://github.com/hail-is/hail/pull/4013#issuecomment-408639182:100,Testability,test,test,100,"The one possible issue with this is if you try to run python from the /test/ dir, you'll import the test module instead. But that seems minor",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/4013#issuecomment-408639182
https://github.com/hail-is/hail/issues/4014#issuecomment-425151198:11,Testability,test,testArrayFold,11,There's a `testArrayFold` in master already.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/4014#issuecomment-425151198
https://github.com/hail-is/hail/issues/4017#issuecomment-412199170:93,Performance,optimiz,optimization,93,"The part of this that's not solved by #4104 is the preservation of relational values through optimization passes. For example, we expect the following to be true:; ```; ht = hl.utils.range_table(10, 3); ht1 = ht.annotate(x=hl.rand_unif(0, 1)); ht1.x.collect()[:5] == ht1.head(5).x.collect(); ```. but since there exist two rules ; ```; case TableHead(TableMapRows(child, newRow, newKey, preservedKeyFields), n) =>; TableMapRows(TableHead(child, n), newRow, newKey, preservedKeyFields). case TableHead(tr@TableRange(nRows, nPar), n) =>; if (n < nRows) TableRange(n.toInt, (nPar.toFloat * n / nRows).toInt.max(1)) else tr; ```; the underlying `TableRange` changes partitioning through the optimization pass and the results differ.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/4017#issuecomment-412199170
https://github.com/hail-is/hail/issues/4017#issuecomment-412199170:687,Performance,optimiz,optimization,687,"The part of this that's not solved by #4104 is the preservation of relational values through optimization passes. For example, we expect the following to be true:; ```; ht = hl.utils.range_table(10, 3); ht1 = ht.annotate(x=hl.rand_unif(0, 1)); ht1.x.collect()[:5] == ht1.head(5).x.collect(); ```. but since there exist two rules ; ```; case TableHead(TableMapRows(child, newRow, newKey, preservedKeyFields), n) =>; TableMapRows(TableHead(child, n), newRow, newKey, preservedKeyFields). case TableHead(tr@TableRange(nRows, nPar), n) =>; if (n < nRows) TableRange(n.toInt, (nPar.toFloat * n / nRows).toInt.max(1)) else tr; ```; the underlying `TableRange` changes partitioning through the optimization pass and the results differ.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/4017#issuecomment-412199170
https://github.com/hail-is/hail/issues/4020#issuecomment-422943490:117,Performance,perform,performance,117,"Rude, the check boxes don't get marked automatically. Anyway, all of this is done except the meta GWAS which isn't a performance issue and I will create a separate issue for that.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/4020#issuecomment-422943490
https://github.com/hail-is/hail/issues/4021#issuecomment-422545491:32,Testability,test,testing,32,"First step: #4347 automates VEP testing (for vep85, GRCh37)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/4021#issuecomment-422545491
https://github.com/hail-is/hail/issues/4022#issuecomment-413280515:379,Integrability,interface,interface,379,"@cseed I went ahead and made a PR with the design I think is best. Basically, it's the same thing I proposed before `group_rows_by().aggregate_rows().aggregate_entries().result()`, but I kept `aggregate()` as an alias for `aggregate_entries.result`. I think this design is ideal so the common use case is shorter and we maintain backwards compatibility. . If you are ok with the interface, I'll go ahead and assign someone my PR.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/4022#issuecomment-413280515
https://github.com/hail-is/hail/issues/4026#issuecomment-420021337:91,Deployability,pipeline,pipelines,91,"Yes! I had a slight scare with foreign key/prefix joins, but it looks good now! All of our pipelines use tables and it appears to be on par with MT joins",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/4026#issuecomment-420021337
https://github.com/hail-is/hail/issues/4027#issuecomment-408647882:20,Security,access,access,20,"`[:, :]` is used to access the globals of one thing in another context",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/4027#issuecomment-408647882
https://github.com/hail-is/hail/issues/4027#issuecomment-408647913:23,Security,access,access,23,And why can't you just access `mt.globals`? (I guess that's the goal here?),MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/4027#issuecomment-408647913
https://github.com/hail-is/hail/issues/4027#issuecomment-408648225:55,Deployability,pipeline,pipeline,55,since 0.2 entered beta I'm not sure I've seen a single pipeline with globals manipulation,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/4027#issuecomment-408648225
https://github.com/hail-is/hail/issues/4027#issuecomment-408648344:257,Usability,feedback,feedback,257,"> I'm not sure people actually use globals, though. I not sure either. I'm pretty sure @konradjk, does but it may be to work around other issues that can be fixed separately. We're going to set up a regular (quarterly?) meeting with the data group for Hail feedback. We could ask this there.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/4027#issuecomment-408648344
https://github.com/hail-is/hail/issues/4027#issuecomment-408648644:79,Performance,optimiz,optimization,79,"Yeah, that seems reasonable but we'll need some infrastructure work (including optimization) to make that reasonable. Hmm.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/4027#issuecomment-408648644
https://github.com/hail-is/hail/issues/4028#issuecomment-410786746:92,Availability,down,down,92,Certainly appears to have fixed my issue. Pipeline that went from 11 to 25 mins is now back down to 11,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/4028#issuecomment-410786746
https://github.com/hail-is/hail/issues/4028#issuecomment-410786746:42,Deployability,Pipeline,Pipeline,42,Certainly appears to have fixed my issue. Pipeline that went from 11 to 25 mins is now back down to 11,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/4028#issuecomment-410786746
https://github.com/hail-is/hail/pull/4030#issuecomment-408697268:352,Availability,ERROR,ERROR,352,"I tried to benchmark 100M rows against Spark:. ```; $ spark-shell; scala> val df = spark.range(100000000); df: org.apache.spark.sql.Dataset[Long] = [id: bigint]. scala> val df2 = df.select(df.col(""id""), functions.rand().as(""x"")); df2: org.apache.spark.sql.DataFrame = [id: bigint, x: double]. scala> df2.write.parquet(""df2.parquet""); 18/07/29 13:47:09 ERROR Executor: Exception in task 2.0 in stage 0.0 (TID 2); Caused by: java.lang.OutOfMemoryError: Java heap space; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/4030#issuecomment-408697268
https://github.com/hail-is/hail/pull/4030#issuecomment-408697268:11,Testability,benchmark,benchmark,11,"I tried to benchmark 100M rows against Spark:. ```; $ spark-shell; scala> val df = spark.range(100000000); df: org.apache.spark.sql.Dataset[Long] = [id: bigint]. scala> val df2 = df.select(df.col(""id""), functions.rand().as(""x"")); df2: org.apache.spark.sql.DataFrame = [id: bigint, x: double]. scala> df2.write.parquet(""df2.parquet""); 18/07/29 13:47:09 ERROR Executor: Exception in task 2.0 in stage 0.0 (TID 2); Caused by: java.lang.OutOfMemoryError: Java heap space; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/4030#issuecomment-408697268
https://github.com/hail-is/hail/pull/4032#issuecomment-408850197:57,Usability,feedback,feedback,57,@tpoterba I'm assigning you since I've incorporated your feedback from when you reviewed these name changes before I separated them from the IR PR. I'll add a discuss post on breaking changes once this goes in.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/4032#issuecomment-408850197
https://github.com/hail-is/hail/pull/4032#issuecomment-409216569:170,Testability,test,test,170,that was the plan. done. http://discuss.hail.is/t/breaking-change-rename-of-methods-fields-ctt-chisq-hardy-weinberg-hardy-weinberg-p-variant-qc-transition-disequilibrium-test/590/2,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/4032#issuecomment-409216569
https://github.com/hail-is/hail/issues/4033#issuecomment-408956343:96,Availability,error,error,96,"@lfrancioli see the docs, `parallel` takes a string. The PR adds a typechecker to give a better error message to future you.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/4033#issuecomment-408956343
https://github.com/hail-is/hail/issues/4033#issuecomment-408956343:102,Integrability,message,message,102,"@lfrancioli see the docs, `parallel` takes a string. The PR adds a typechecker to give a better error message to future you.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/4033#issuecomment-408956343
https://github.com/hail-is/hail/issues/4033#issuecomment-408982088:97,Availability,error,error,97,Thank @jbloom22 ! Hadn't seen that this had change (was `bool` back in the days). And indeed the error message did not put me on the right track :),MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/4033#issuecomment-408982088
