id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/broadinstitute/gatk/pull/4044#issuecomment-356135455:26,Integrability,depend,dependency,26,OK! There was a transient dependency that bumped the `commons-math3` version. I've just pushed an update that should fix this.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4044#issuecomment-356135455
https://github.com/broadinstitute/gatk/pull/4044#issuecomment-356136768:58,Deployability,patch,patch,58,"Very minor comments, otherwise looks good. Thanks for the patch!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4044#issuecomment-356136768
https://github.com/broadinstitute/gatk/pull/4044#issuecomment-356142226:40,Usability,feedback,feedback,40,"Just pushed two commits to address your feedback, @droazen!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4044#issuecomment-356142226
https://github.com/broadinstitute/gatk/pull/4044#issuecomment-356143221:1569,Deployability,pipeline,pipelines,1569,======; Files 1056 1056 ; Lines 59150 59149 -1 ; Branches 9615 9616 +1 ; ===============================================; - Hits 46738 46487 -251 ; - Misses 8673 8932 +259 ; + Partials 3739 3730 -9; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4044?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...ngine/spark/datasources/ReferenceTwoBitSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4044/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvUmVmZXJlbmNlVHdvQml0U291cmNlLmphdmE=) | `90.909% <75%> (-9.091%)` | `6 <2> (-1)` | |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4044/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-75.51%)` | `0% <0%> (-17%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4044/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/4044/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...lbender/engine/datasources/ReferenceAPISource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4044/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `25.735% <0%> (-60.294%)` | `8% <0%> (-25%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4044/diff?src=pr&el=tree#diff-c3J,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4044#issuecomment-356143221
https://github.com/broadinstitute/gatk/pull/4044#issuecomment-356143221:1885,Testability,test,test,1885, | Complexity Δ | |; |---|---|---|---|; | [...ngine/spark/datasources/ReferenceTwoBitSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4044/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvUmVmZXJlbmNlVHdvQml0U291cmNlLmphdmE=) | `90.909% <75%> (-9.091%)` | `6 <2> (-1)` | |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4044/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-75.51%)` | `0% <0%> (-17%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4044/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/4044/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...lbender/engine/datasources/ReferenceAPISource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4044/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `25.735% <0%> (-60.294%)` | `8% <0%> (-25%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4044/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `54.194% <0%> (-24.516%)` | `30% <0%> (-9%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/4044/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vc,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4044#issuecomment-356143221
https://github.com/broadinstitute/gatk/pull/4044#issuecomment-356143221:3361,Testability,test,test,3361,YnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...lbender/engine/datasources/ReferenceAPISource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4044/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `25.735% <0%> (-60.294%)` | `8% <0%> (-25%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4044/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `54.194% <0%> (-24.516%)` | `30% <0%> (-9%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/4044/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `0% <0%> (-22.807%)` | `0% <0%> (-2%)` | |; | [...ender/engine/datasources/ReferenceMultiSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4044/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlTXVsdGlTb3VyY2UuamF2YQ==) | `61.538% <0%> (-11.538%)` | `9% <0%> (ø)` | |; | [...titute/hellbender/utils/test/MiniClusterUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4044/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L01pbmlDbHVzdGVyVXRpbHMuamF2YQ==) | `78.947% <0%> (-10.526%)` | `6% <0%> (-1%)` | |; | [...institute/hellbender/exceptions/UserException.java](https://codecov.io/gh/broadinstitute/gatk/pull/4044/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9leGNlcHRpb25zL1VzZXJFeGNlcHRpb24uamF2YQ==) | `66.406% <0%> (-3.125%)` | `3% <0%> (ø)` | |; | ... and [9 more](https://codecov.io/gh/broadinstitute/gatk/pull/4044/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4044#issuecomment-356143221
https://github.com/broadinstitute/gatk/pull/4045#issuecomment-355373868:242,Availability,down,downloads,242,"Nope, just oncotator. Not only that, only the CNV oncotator really needs it, since it uses a big docker image with some datasources baked-in. We could probably remove it from the M2 WDL, since that uses the typical oncotator docker image and downloads the datasources on the fly.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4045#issuecomment-355373868
https://github.com/broadinstitute/gatk/pull/4046#issuecomment-355405908:741,Deployability,Patch,Patch,741,"I have a run going now. On Jan 4, 2018 15:32, ""samuelklee"" <notifications@github.com> wrote:. > Placeholders for now. We can tweak the actual values once @LeeTL1220; > <https://github.com/leetl1220> checks effect on validation.; >; > Closes #4032 <https://github.com/broadinstitute/gatk/issues/4032>.; > ------------------------------; > You can view, comment on, or merge this pull request online at:; >; > https://github.com/broadinstitute/gatk/pull/4046; > Commit Summary; >; > - Changed default values for ModelSegments segmentation parameters.; >; > File Changes; >; > - *M* src/main/java/org/broadinstitute/hellbender/tools/copynumber/; > ModelSegments.java; > <https://github.com/broadinstitute/gatk/pull/4046/files#diff-0> (6); >; > Patch Links:; >; > - https://github.com/broadinstitute/gatk/pull/4046.patch; > - https://github.com/broadinstitute/gatk/pull/4046.diff; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/4046>, or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACDXk8coObtbYN125S1_BMBx1VnnmbF4ks5tHTVzgaJpZM4RTh_B>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4046#issuecomment-355405908
https://github.com/broadinstitute/gatk/pull/4046#issuecomment-355405908:811,Deployability,patch,patch,811,"I have a run going now. On Jan 4, 2018 15:32, ""samuelklee"" <notifications@github.com> wrote:. > Placeholders for now. We can tweak the actual values once @LeeTL1220; > <https://github.com/leetl1220> checks effect on validation.; >; > Closes #4032 <https://github.com/broadinstitute/gatk/issues/4032>.; > ------------------------------; > You can view, comment on, or merge this pull request online at:; >; > https://github.com/broadinstitute/gatk/pull/4046; > Commit Summary; >; > - Changed default values for ModelSegments segmentation parameters.; >; > File Changes; >; > - *M* src/main/java/org/broadinstitute/hellbender/tools/copynumber/; > ModelSegments.java; > <https://github.com/broadinstitute/gatk/pull/4046/files#diff-0> (6); >; > Patch Links:; >; > - https://github.com/broadinstitute/gatk/pull/4046.patch; > - https://github.com/broadinstitute/gatk/pull/4046.diff; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/4046>, or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACDXk8coObtbYN125S1_BMBx1VnnmbF4ks5tHTVzgaJpZM4RTh_B>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4046#issuecomment-355405908
https://github.com/broadinstitute/gatk/pull/4046#issuecomment-355405908:216,Security,validat,validation,216,"I have a run going now. On Jan 4, 2018 15:32, ""samuelklee"" <notifications@github.com> wrote:. > Placeholders for now. We can tweak the actual values once @LeeTL1220; > <https://github.com/leetl1220> checks effect on validation.; >; > Closes #4032 <https://github.com/broadinstitute/gatk/issues/4032>.; > ------------------------------; > You can view, comment on, or merge this pull request online at:; >; > https://github.com/broadinstitute/gatk/pull/4046; > Commit Summary; >; > - Changed default values for ModelSegments segmentation parameters.; >; > File Changes; >; > - *M* src/main/java/org/broadinstitute/hellbender/tools/copynumber/; > ModelSegments.java; > <https://github.com/broadinstitute/gatk/pull/4046/files#diff-0> (6); >; > Patch Links:; >; > - https://github.com/broadinstitute/gatk/pull/4046.patch; > - https://github.com/broadinstitute/gatk/pull/4046.diff; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/4046>, or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACDXk8coObtbYN125S1_BMBx1VnnmbF4ks5tHTVzgaJpZM4RTh_B>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4046#issuecomment-355405908
https://github.com/broadinstitute/gatk/pull/4046#issuecomment-355467989:38,Availability,rollback,rollback,38,"@LeeTL1220 Latest commit includes the rollback. I will create a separate branch for you that is rebased on sl_preprocess. Looking at it again, I initially described the change to you incorrectly. I thought it was ""similar CR || similar AF -> merge"" to ""similar CR && similar AF -> merge"", but that's not actually the case; it's instead ""similar according to credible interval 1 || similar according to credible interval 2 -> merge"" to ""similar according to credible interval 1 && similar according to credible interval 2 -> merge"". Probably the `&&` behavior is way too conservative, so I think rolling back to the `||` behavior would be fine for release. Let's double check with the validation just to be sure.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4046#issuecomment-355467989
https://github.com/broadinstitute/gatk/pull/4046#issuecomment-355467989:38,Deployability,rollback,rollback,38,"@LeeTL1220 Latest commit includes the rollback. I will create a separate branch for you that is rebased on sl_preprocess. Looking at it again, I initially described the change to you incorrectly. I thought it was ""similar CR || similar AF -> merge"" to ""similar CR && similar AF -> merge"", but that's not actually the case; it's instead ""similar according to credible interval 1 || similar according to credible interval 2 -> merge"" to ""similar according to credible interval 1 && similar according to credible interval 2 -> merge"". Probably the `&&` behavior is way too conservative, so I think rolling back to the `||` behavior would be fine for release. Let's double check with the validation just to be sure.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4046#issuecomment-355467989
https://github.com/broadinstitute/gatk/pull/4046#issuecomment-355467989:595,Deployability,rolling,rolling,595,"@LeeTL1220 Latest commit includes the rollback. I will create a separate branch for you that is rebased on sl_preprocess. Looking at it again, I initially described the change to you incorrectly. I thought it was ""similar CR || similar AF -> merge"" to ""similar CR && similar AF -> merge"", but that's not actually the case; it's instead ""similar according to credible interval 1 || similar according to credible interval 2 -> merge"" to ""similar according to credible interval 1 && similar according to credible interval 2 -> merge"". Probably the `&&` behavior is way too conservative, so I think rolling back to the `||` behavior would be fine for release. Let's double check with the validation just to be sure.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4046#issuecomment-355467989
https://github.com/broadinstitute/gatk/pull/4046#issuecomment-355467989:647,Deployability,release,release,647,"@LeeTL1220 Latest commit includes the rollback. I will create a separate branch for you that is rebased on sl_preprocess. Looking at it again, I initially described the change to you incorrectly. I thought it was ""similar CR || similar AF -> merge"" to ""similar CR && similar AF -> merge"", but that's not actually the case; it's instead ""similar according to credible interval 1 || similar according to credible interval 2 -> merge"" to ""similar according to credible interval 1 && similar according to credible interval 2 -> merge"". Probably the `&&` behavior is way too conservative, so I think rolling back to the `||` behavior would be fine for release. Let's double check with the validation just to be sure.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4046#issuecomment-355467989
https://github.com/broadinstitute/gatk/pull/4046#issuecomment-355467989:684,Security,validat,validation,684,"@LeeTL1220 Latest commit includes the rollback. I will create a separate branch for you that is rebased on sl_preprocess. Looking at it again, I initially described the change to you incorrectly. I thought it was ""similar CR || similar AF -> merge"" to ""similar CR && similar AF -> merge"", but that's not actually the case; it's instead ""similar according to credible interval 1 || similar according to credible interval 2 -> merge"" to ""similar according to credible interval 1 && similar according to credible interval 2 -> merge"". Probably the `&&` behavior is way too conservative, so I think rolling back to the `||` behavior would be fine for release. Let's double check with the validation just to be sure.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4046#issuecomment-355467989
https://github.com/broadinstitute/gatk/pull/4046#issuecomment-355468401:77,Security,validat,validation,77,"@LeeTL1220 OK, see the sl_change_model_segments_defaults_rebased branch. For validation, I'd say that sweeping the following should suffice:. Array[Float] kernel_variance_allele_fractions = [0.025, 0.05, 0.25]; Array[Float] smoothing_thresholds_allele_fraction = [2.0, 10.0, 50.0]; Array[Float] smoothing_thresholds_copy_ratio = [2.0, 10.0, 50.0]",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4046#issuecomment-355468401
https://github.com/broadinstitute/gatk/pull/4046#issuecomment-355665197:121,Security,validat,validation,121,"Merging this according to discussion with @LeeTL1220. We still need to investigate some possible regressions in the CRSP validation, but we should be good for prerelease on the CNV somatic side. There is one last branch (#4061) on the germline side, but I think we didn't plan on having gCNV ready for prerelease.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4046#issuecomment-355665197
https://github.com/broadinstitute/gatk/pull/4047#issuecomment-355479773:2505,Testability,test,test,2505, | [...ions/OptionalReferenceInputArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/4047/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL2FyZ3VtZW50Y29sbGVjdGlvbnMvT3B0aW9uYWxSZWZlcmVuY2VJbnB1dEFyZ3VtZW50Q29sbGVjdGlvbi5qYXZh) | `100% <0%> (ø)` | `6% <0%> (+1%)` | :arrow_up: |; | [...tcollections/ReferenceInputArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/4047/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL2FyZ3VtZW50Y29sbGVjdGlvbnMvUmVmZXJlbmNlSW5wdXRBcmd1bWVudENvbGxlY3Rpb24uamF2YQ==) | `100% <0%> (ø)` | `5% <0%> (+2%)` | :arrow_up: |; | [...stitute/hellbender/engine/ReferenceDataSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4047/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUmVmZXJlbmNlRGF0YVNvdXJjZS5qYXZh) | `80% <0%> (ø)` | `8% <0%> (+4%)` | :arrow_up: |; | [...titute/hellbender/utils/test/ArgumentsBuilder.java](https://codecov.io/gh/broadinstitute/gatk/pull/4047/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0FyZ3VtZW50c0J1aWxkZXIuamF2YQ==) | `100% <0%> (ø)` | `23% <0%> (+4%)` | :arrow_up: |; | [...er/tools/spark/sv/discovery/AlignmentInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/4047/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvQWxpZ25tZW50SW50ZXJ2YWwuamF2YQ==) | `91.064% <0%> (+0.426%)` | `66% <0%> (+1%)` | :arrow_up: |; | [...ions/RequiredReferenceInputArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/4047/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL2FyZ3VtZW50Y29sbGVjdGlvbnMvUmVxdWlyZWRSZWZlcmVuY2VJbnB1dEFyZ3VtZW50Q29sbGVjdGlvbi5qYXZh) | `87.5% <0%> (+1.786%)` | `5% <0%> (+1%)` | :arrow_up: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](ht,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4047#issuecomment-355479773
https://github.com/broadinstitute/gatk/pull/4047#issuecomment-355638919:345,Usability,simpl,simply,345,"Some clarification questions about the field AS_RAW_MQ. In the examples provided, the header line corresponding to this field is. ##INFO=<ID=AS_RAW_MQ,Number=A,Type=Float,Description=""Allele-specfic raw data for RMS Mapping Quality"">. The data lines contain entries similar to `AS_RAW_MQ=123769.00|3600.00|46800.00|0.00`. Is the AS_RAW_MQ field simply a vector of float?; - If yes; - Why is the '|' used as the delimiter? Why not simply use ','?; - Based on the entries, shouldn't the Number descriptor in the header line be 'R' instead of 'A'; - If no, i.e. AS_RAW_MQ can be a vector of vector of float (entries such as `AS_RAW_MQ=1,2|3,4,5|6|0.00` where `[1, 2]` corresponds to allele 0 (reference allele) etc.); - Shouldn't the Type descriptor in the header line be 'String' instead of 'Float'? (similar to the AS_RAW_\*RankSum fields)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4047#issuecomment-355638919
https://github.com/broadinstitute/gatk/pull/4047#issuecomment-355638919:430,Usability,simpl,simply,430,"Some clarification questions about the field AS_RAW_MQ. In the examples provided, the header line corresponding to this field is. ##INFO=<ID=AS_RAW_MQ,Number=A,Type=Float,Description=""Allele-specfic raw data for RMS Mapping Quality"">. The data lines contain entries similar to `AS_RAW_MQ=123769.00|3600.00|46800.00|0.00`. Is the AS_RAW_MQ field simply a vector of float?; - If yes; - Why is the '|' used as the delimiter? Why not simply use ','?; - Based on the entries, shouldn't the Number descriptor in the header line be 'R' instead of 'A'; - If no, i.e. AS_RAW_MQ can be a vector of vector of float (entries such as `AS_RAW_MQ=1,2|3,4,5|6|0.00` where `[1, 2]` corresponds to allele 0 (reference allele) etc.); - Shouldn't the Type descriptor in the header line be 'String' instead of 'Float'? (similar to the AS_RAW_\*RankSum fields)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4047#issuecomment-355638919
https://github.com/broadinstitute/gatk/pull/4047#issuecomment-355643907:78,Testability,test,tests,78,"Thanks @ldgauthier , I picked the header and data from files used in the GATK tests:; https://github.com/broadinstitute/gatk/blob/master/src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/NA12878.AS.chr20snippet.g.vcf. https://github.com/broadinstitute/gatk/blob/master/src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/testAlleleSpecificAnnotations.vcf. However, a different file in the GATK repo specifies AS_RAW_MQ as a String:; https://github.com/broadinstitute/gatk/blob/master/src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.testGVCFMode.gatk4.alleleSpecific.g.vcf. Currently, GenomicsDB can handle both cases (with a slight hack in the internal code), but wanted to check if I'm missing anything.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4047#issuecomment-355643907
https://github.com/broadinstitute/gatk/pull/4047#issuecomment-355643907:141,Testability,test,test,141,"Thanks @ldgauthier , I picked the header and data from files used in the GATK tests:; https://github.com/broadinstitute/gatk/blob/master/src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/NA12878.AS.chr20snippet.g.vcf. https://github.com/broadinstitute/gatk/blob/master/src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/testAlleleSpecificAnnotations.vcf. However, a different file in the GATK repo specifies AS_RAW_MQ as a String:; https://github.com/broadinstitute/gatk/blob/master/src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.testGVCFMode.gatk4.alleleSpecific.g.vcf. Currently, GenomicsDB can handle both cases (with a slight hack in the internal code), but wanted to check if I'm missing anything.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4047#issuecomment-355643907
https://github.com/broadinstitute/gatk/pull/4047#issuecomment-355643907:299,Testability,test,test,299,"Thanks @ldgauthier , I picked the header and data from files used in the GATK tests:; https://github.com/broadinstitute/gatk/blob/master/src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/NA12878.AS.chr20snippet.g.vcf. https://github.com/broadinstitute/gatk/blob/master/src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/testAlleleSpecificAnnotations.vcf. However, a different file in the GATK repo specifies AS_RAW_MQ as a String:; https://github.com/broadinstitute/gatk/blob/master/src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.testGVCFMode.gatk4.alleleSpecific.g.vcf. Currently, GenomicsDB can handle both cases (with a slight hack in the internal code), but wanted to check if I'm missing anything.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4047#issuecomment-355643907
https://github.com/broadinstitute/gatk/pull/4047#issuecomment-355643907:371,Testability,test,testAlleleSpecificAnnotations,371,"Thanks @ldgauthier , I picked the header and data from files used in the GATK tests:; https://github.com/broadinstitute/gatk/blob/master/src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/NA12878.AS.chr20snippet.g.vcf. https://github.com/broadinstitute/gatk/blob/master/src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/testAlleleSpecificAnnotations.vcf. However, a different file in the GATK repo specifies AS_RAW_MQ as a String:; https://github.com/broadinstitute/gatk/blob/master/src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.testGVCFMode.gatk4.alleleSpecific.g.vcf. Currently, GenomicsDB can handle both cases (with a slight hack in the internal code), but wanted to check if I'm missing anything.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4047#issuecomment-355643907
https://github.com/broadinstitute/gatk/pull/4047#issuecomment-355643907:538,Testability,test,test,538,"Thanks @ldgauthier , I picked the header and data from files used in the GATK tests:; https://github.com/broadinstitute/gatk/blob/master/src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/NA12878.AS.chr20snippet.g.vcf. https://github.com/broadinstitute/gatk/blob/master/src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/testAlleleSpecificAnnotations.vcf. However, a different file in the GATK repo specifies AS_RAW_MQ as a String:; https://github.com/broadinstitute/gatk/blob/master/src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.testGVCFMode.gatk4.alleleSpecific.g.vcf. Currently, GenomicsDB can handle both cases (with a slight hack in the internal code), but wanted to check if I'm missing anything.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4047#issuecomment-355643907
https://github.com/broadinstitute/gatk/pull/4047#issuecomment-355643907:614,Testability,test,testGVCFMode,614,"Thanks @ldgauthier , I picked the header and data from files used in the GATK tests:; https://github.com/broadinstitute/gatk/blob/master/src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/NA12878.AS.chr20snippet.g.vcf. https://github.com/broadinstitute/gatk/blob/master/src/test/resources/org/broadinstitute/hellbender/tools/walkers/CombineGVCFs/testAlleleSpecificAnnotations.vcf. However, a different file in the GATK repo specifies AS_RAW_MQ as a String:; https://github.com/broadinstitute/gatk/blob/master/src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.testGVCFMode.gatk4.alleleSpecific.g.vcf. Currently, GenomicsDB can handle both cases (with a slight hack in the internal code), but wanted to check if I'm missing anything.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4047#issuecomment-355643907
https://github.com/broadinstitute/gatk/pull/4047#issuecomment-355645173:36,Testability,test,test,36,I may have given James some dubious test data for CombineGVCFs. The header line in GATKVCFHeaderLines.java describes AS_RAW_MQ as having one string value. That's the version I would like to move forward with. I can fix the CombineGVCFs test data if that's causing a problem.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4047#issuecomment-355645173
https://github.com/broadinstitute/gatk/pull/4047#issuecomment-355645173:236,Testability,test,test,236,I may have given James some dubious test data for CombineGVCFs. The header line in GATKVCFHeaderLines.java describes AS_RAW_MQ as having one string value. That's the version I would like to move forward with. I can fix the CombineGVCFs test data if that's causing a problem.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4047#issuecomment-355645173
https://github.com/broadinstitute/gatk/pull/4047#issuecomment-355645211:98,Deployability,update,updated,98,"Yea, I believe the header mismatching has to do with the canonical header lines in the gatk being updated in the middle of this work. htsjdk doesn't discriminate between bad header line count fields so there are a number of sloppy header lines like this. I will update my genomicsDB branch to perform a proper check of the allele specific annotations based on the new version now.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4047#issuecomment-355645211
https://github.com/broadinstitute/gatk/pull/4047#issuecomment-355645211:262,Deployability,update,update,262,"Yea, I believe the header mismatching has to do with the canonical header lines in the gatk being updated in the middle of this work. htsjdk doesn't discriminate between bad header line count fields so there are a number of sloppy header lines like this. I will update my genomicsDB branch to perform a proper check of the allele specific annotations based on the new version now.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4047#issuecomment-355645211
https://github.com/broadinstitute/gatk/pull/4047#issuecomment-355645211:293,Performance,perform,perform,293,"Yea, I believe the header mismatching has to do with the canonical header lines in the gatk being updated in the middle of this work. htsjdk doesn't discriminate between bad header line count fields so there are a number of sloppy header lines like this. I will update my genomicsDB branch to perform a proper check of the allele specific annotations based on the new version now.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4047#issuecomment-355645211
https://github.com/broadinstitute/gatk/pull/4047#issuecomment-355786013:12,Testability,test,test,12,I forgot to test with the branch after Patrick's changes - using the pre-generated merged VCF header caused issues with BCF2Codec. I have now implemented a workaround.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4047#issuecomment-355786013
https://github.com/broadinstitute/gatk/pull/4047#issuecomment-355856775:35,Testability,test,tests,35,Insofar as its matching all of the tests that currently exist for allele specific annotations it appears to be working this time around (with a few changes to the vcf test suite to handle the the precision issues). I'm thinking this might be good. I will take a closer look before I merge it.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4047#issuecomment-355856775
https://github.com/broadinstitute/gatk/pull/4047#issuecomment-355856775:167,Testability,test,test,167,Insofar as its matching all of the tests that currently exist for allele specific annotations it appears to be working this time around (with a few changes to the vcf test suite to handle the the precision issues). I'm thinking this might be good. I will take a closer look before I merge it.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4047#issuecomment-355856775
https://github.com/broadinstitute/gatk/pull/4047#issuecomment-356037149:54,Deployability,release,release,54,"It has been decided to merge this branch in after the release so it can be more substantially tested. Since it is being pushed off, we should take a look at the precision issue for annotations. Would it be possible to limit the precision of the output annotations to 3 decimal points? It seems to be outputting a lot of annotations that end up being excessively long.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4047#issuecomment-356037149
https://github.com/broadinstitute/gatk/pull/4047#issuecomment-356037149:94,Testability,test,tested,94,"It has been decided to merge this branch in after the release so it can be more substantially tested. Since it is being pushed off, we should take a look at the precision issue for annotations. Would it be possible to limit the precision of the output annotations to 3 decimal points? It seems to be outputting a lot of annotations that end up being excessively long.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4047#issuecomment-356037149
https://github.com/broadinstitute/gatk/pull/4047#issuecomment-356085053:371,Safety,avoid,avoid,371,"I'm a big fan of the htsjdk precision code: https://github.com/samtools/htsjdk/blob/master/src/main/java/htsjdk/variant/vcf/VCFEncoder.java . That being said, fixed point is fine. We don't really need the precision of scientific for the standard GATK annotations. I would like the decimal point to always be present (somewhere I made an assumption about that in order to avoid a bunch of `instanceof` calls) and total number of digits being constant is good.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4047#issuecomment-356085053
https://github.com/broadinstitute/gatk/pull/4048#issuecomment-355489791:2160,Usability,Simpl,SimpleKeyXsvFuncotationFactory,2160, `89.474% <0%> (-2.526%)` | `23% <0%> (+8%)` | |; | [...ypecaller/AssemblyBasedCallerGenotypingEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/4048/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9Bc3NlbWJseUJhc2VkQ2FsbGVyR2Vub3R5cGluZ0VuZ2luZS5qYXZh) | `87.023% <0%> (-1.531%)` | `95% <0%> (+27%)` | |; | [...hellbender/tools/copynumber/DenoiseReadCounts.java](https://codecov.io/gh/broadinstitute/gatk/pull/4048/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL0Rlbm9pc2VSZWFkQ291bnRzLmphdmE=) | `88.889% <0%> (-0.3%)` | `17% <0%> (+8%)` | |; | [...broadinstitute/hellbender/utils/IntervalUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4048/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9JbnRlcnZhbFV0aWxzLmphdmE=) | `91.071% <0%> (-0.133%)` | `216% <0%> (+43%)` | |; | [...ataSources/xsv/SimpleKeyXsvFuncotationFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/4048/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL3hzdi9TaW1wbGVLZXlYc3ZGdW5jb3RhdGlvbkZhY3RvcnkuamF2YQ==) | `86.555% <0%> (-0.112%)` | `28% <0%> (+8%)` | |; | [...hellbender/tools/copynumber/AnnotateIntervals.java](https://codecov.io/gh/broadinstitute/gatk/pull/4048/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL0Fubm90YXRlSW50ZXJ2YWxzLmphdmE=) | `100% <0%> (ø)` | `12% <0%> (+5%)` | :arrow_up: |; | [...llbender/tools/copynumber/PreprocessIntervals.java](https://codecov.io/gh/broadinstitute/gatk/pull/4048/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL1ByZXByb2Nlc3NJbnRlcnZhbHMuamF2YQ==) | `100% <0%> (ø)` | `19% <0%> (+9%)` | :arrow_up: |; | [...er/formats/collections/AllelicCountCollection.java](https://codecov.io/gh/b,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4048#issuecomment-355489791
https://github.com/broadinstitute/gatk/issues/4055#issuecomment-928068102:413,Deployability,pipeline,pipelines,413,"Closing this issue for now, but I think this is an important point. For CNV and SV tools in general, we need to improve QC functionality. Capabilities for visualizing model output, particularly contig ploidy calling where sample quality and mosaicisms could negatively affect CNV calling, are critical. Warnings would be a bare minimum, but in practice I don't think this go far enough, as most of the time these pipelines are run at scale as WDLs, and users don't tend to check log output carefully. It'd be better to have up-front QC to filter out problematic samples before running the model.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4055#issuecomment-928068102
https://github.com/broadinstitute/gatk/issues/4055#issuecomment-928068102:479,Testability,log,log,479,"Closing this issue for now, but I think this is an important point. For CNV and SV tools in general, we need to improve QC functionality. Capabilities for visualizing model output, particularly contig ploidy calling where sample quality and mosaicisms could negatively affect CNV calling, are critical. Warnings would be a bare minimum, but in practice I don't think this go far enough, as most of the time these pipelines are run at scale as WDLs, and users don't tend to check log output carefully. It'd be better to have up-front QC to filter out problematic samples before running the model.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4055#issuecomment-928068102
https://github.com/broadinstitute/gatk/pull/4061#issuecomment-355645250:87,Security,hash,hash,87,"Good catch. I think hc7b2577_8 might be specific for linux64. We can try removing that hash, but I don't have a mac, so I can't test this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4061#issuecomment-355645250
https://github.com/broadinstitute/gatk/pull/4061#issuecomment-355645250:128,Testability,test,test,128,"Good catch. I think hc7b2577_8 might be specific for linux64. We can try removing that hash, but I don't have a mac, so I can't test this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4061#issuecomment-355645250
https://github.com/broadinstitute/gatk/pull/4061#issuecomment-355647907:35,Security,hash,hashes,35,"@cmnbroad I cleaned up some of the hashes and was able to create the conda environment locally. Can you try on your mac? We'll see if tests pass on Travis as well, then merge if all is good.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4061#issuecomment-355647907
https://github.com/broadinstitute/gatk/pull/4061#issuecomment-355647907:134,Testability,test,tests,134,"@cmnbroad I cleaned up some of the hashes and was able to create the conda environment locally. Can you try on your mac? We'll see if tests pass on Travis as well, then merge if all is good.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4061#issuecomment-355647907
https://github.com/broadinstitute/gatk/pull/4061#issuecomment-355648762:70,Testability,test,tests,70,"BTW, by ""works"" I mean I can create the env. I didn't try running the tests with the resulting env.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4061#issuecomment-355648762
https://github.com/broadinstitute/gatk/pull/4061#issuecomment-355649022:40,Integrability,message,message,40,@samuelklee Hold on - just saw the last message. Let me try using your .yml.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4061#issuecomment-355649022
https://github.com/broadinstitute/gatk/pull/4061#issuecomment-355652809:47,Availability,avail,available,47,"@cmnbroad Yeah, it looks like libgcc-ng is not available for osx64 at all. There is libgcc, but even that is only at 4.8.5 for osx64 (and at 7.2.0 for linux32/64). @mbabadi Do you know what the difference is between libgcc-ng and libgcc? (Even if libgcc is an acceptable subsititute, I'm not sure how to peg the different version numbers across linux and osx, and I'm not sure if there are differences between them.). Are we going to require use of the Docker?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4061#issuecomment-355652809
https://github.com/broadinstitute/gatk/issues/4062#issuecomment-355657888:121,Deployability,release,release,121,@kgururaj This seems to be a new issue in 0.8.1-proto-3.0.0-beta-1. We'll have to revert to the previous version for the release if we can't figure it out.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4062#issuecomment-355657888
https://github.com/broadinstitute/gatk/issues/4062#issuecomment-355663626:0,Deployability,install,installing,0,"installing libuuid manually by `brew install ossp-uuid` solves the problem, but we really want this statically linked into it so users aren't expected to do it themselves",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4062#issuecomment-355663626
https://github.com/broadinstitute/gatk/issues/4062#issuecomment-355663626:37,Deployability,install,install,37,"installing libuuid manually by `brew install ossp-uuid` solves the problem, but we really want this statically linked into it so users aren't expected to do it themselves",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4062#issuecomment-355663626
https://github.com/broadinstitute/gatk/pull/4063#issuecomment-355789698:44,Availability,failure,failure,44,@jonn-smith Can you make sure that the test failure is nothing to block merging?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4063#issuecomment-355789698
https://github.com/broadinstitute/gatk/pull/4063#issuecomment-355789698:39,Testability,test,test,39,@jonn-smith Can you make sure that the test failure is nothing to block merging?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4063#issuecomment-355789698
https://github.com/broadinstitute/gatk/pull/4063#issuecomment-355795000:36,Safety,timeout,timeout,36,"@jonn-smith @LeeTL1220 The CNV test timeout was a temporary issue, but its been fixed. I'm pretty sure if you rebase on current master, it will go away.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4063#issuecomment-355795000
https://github.com/broadinstitute/gatk/pull/4063#issuecomment-355795000:31,Testability,test,test,31,"@jonn-smith @LeeTL1220 The CNV test timeout was a temporary issue, but its been fixed. I'm pretty sure if you rebase on current master, it will go away.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4063#issuecomment-355795000
https://github.com/broadinstitute/gatk/pull/4063#issuecomment-356003861:48,Testability,test,tests,48,"Sounds good. I'll rebase on master and wait for tests to finish, then merge.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4063#issuecomment-356003861
https://github.com/broadinstitute/gatk/issues/4064#issuecomment-355666885:20,Availability,down,down,20,"Yeah I trimmed then down even further in #4061. Looks like they run about ~40 minutes now. This is just running a single iteration of gCNV in each of cohort (3 samples) and case mode, which is already kind of the bare minimum (2 tests---in comparison we run 8 such tests on the somatic side). We might be able to trim down the test data even further (to decrease the number of intervals), but I'm not sure why the tests are so slow on Travis in the first place. They run much faster locally.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4064#issuecomment-355666885
https://github.com/broadinstitute/gatk/issues/4064#issuecomment-355666885:318,Availability,down,down,318,"Yeah I trimmed then down even further in #4061. Looks like they run about ~40 minutes now. This is just running a single iteration of gCNV in each of cohort (3 samples) and case mode, which is already kind of the bare minimum (2 tests---in comparison we run 8 such tests on the somatic side). We might be able to trim down the test data even further (to decrease the number of intervals), but I'm not sure why the tests are so slow on Travis in the first place. They run much faster locally.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4064#issuecomment-355666885
https://github.com/broadinstitute/gatk/issues/4064#issuecomment-355666885:229,Testability,test,tests---in,229,"Yeah I trimmed then down even further in #4061. Looks like they run about ~40 minutes now. This is just running a single iteration of gCNV in each of cohort (3 samples) and case mode, which is already kind of the bare minimum (2 tests---in comparison we run 8 such tests on the somatic side). We might be able to trim down the test data even further (to decrease the number of intervals), but I'm not sure why the tests are so slow on Travis in the first place. They run much faster locally.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4064#issuecomment-355666885
https://github.com/broadinstitute/gatk/issues/4064#issuecomment-355666885:265,Testability,test,tests,265,"Yeah I trimmed then down even further in #4061. Looks like they run about ~40 minutes now. This is just running a single iteration of gCNV in each of cohort (3 samples) and case mode, which is already kind of the bare minimum (2 tests---in comparison we run 8 such tests on the somatic side). We might be able to trim down the test data even further (to decrease the number of intervals), but I'm not sure why the tests are so slow on Travis in the first place. They run much faster locally.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4064#issuecomment-355666885
https://github.com/broadinstitute/gatk/issues/4064#issuecomment-355666885:327,Testability,test,test,327,"Yeah I trimmed then down even further in #4061. Looks like they run about ~40 minutes now. This is just running a single iteration of gCNV in each of cohort (3 samples) and case mode, which is already kind of the bare minimum (2 tests---in comparison we run 8 such tests on the somatic side). We might be able to trim down the test data even further (to decrease the number of intervals), but I'm not sure why the tests are so slow on Travis in the first place. They run much faster locally.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4064#issuecomment-355666885
https://github.com/broadinstitute/gatk/issues/4064#issuecomment-355666885:414,Testability,test,tests,414,"Yeah I trimmed then down even further in #4061. Looks like they run about ~40 minutes now. This is just running a single iteration of gCNV in each of cohort (3 samples) and case mode, which is already kind of the bare minimum (2 tests---in comparison we run 8 such tests on the somatic side). We might be able to trim down the test data even further (to decrease the number of intervals), but I'm not sure why the tests are so slow on Travis in the first place. They run much faster locally.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4064#issuecomment-355666885
https://github.com/broadinstitute/gatk/issues/4064#issuecomment-355666988:99,Integrability,depend,dependency,99,Note that we can't merge #4061 until we make a decision about how to handle a missing osx64 python dependency. But we could easily cherry-pick the trimming of the tests.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4064#issuecomment-355666988
https://github.com/broadinstitute/gatk/issues/4064#issuecomment-355666988:163,Testability,test,tests,163,Note that we can't merge #4061 until we make a decision about how to handle a missing osx64 python dependency. But we could easily cherry-pick the trimming of the tests.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4064#issuecomment-355666988
https://github.com/broadinstitute/gatk/issues/4064#issuecomment-355669069:105,Testability,test,tests,105,"Also, I wouldn't worry about talking to the Travis people---this will give us more incentive to keep our tests short, which I think is a good thing...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4064#issuecomment-355669069
https://github.com/broadinstitute/gatk/issues/4064#issuecomment-355670255:76,Integrability,depend,dependencies,76,@samuelklee I'm not sure we need to hold up #4061 for the osx issue - those dependencies were introduced in #3925 and are already in master. I don't think #4061 makes them any worse.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4064#issuecomment-355670255
https://github.com/broadinstitute/gatk/pull/4066#issuecomment-355683067:59,Deployability,release,release,59,":+1: Thanks @kgururaj. We'll merge once tests pass and the release is in maven central. . How does this affect https://github.com/broadinstitute/gatk/pull/4047, by the way?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4066#issuecomment-355683067
https://github.com/broadinstitute/gatk/pull/4066#issuecomment-355683067:40,Testability,test,tests,40,":+1: Thanks @kgururaj. We'll merge once tests pass and the release is in maven central. . How does this affect https://github.com/broadinstitute/gatk/pull/4047, by the way?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4066#issuecomment-355683067
https://github.com/broadinstitute/gatk/pull/4066#issuecomment-355692567:262,Deployability,install,installing,262,"Doesn't affect it - there will be a new jar with the allele specific annotations feature enabled. The jar in that PR was a temp for James to test out. It might be that the temp jar also has the uuid dynamic linking issue on OSX. For now, James can workaround by installing the uuid library. The new jar I will upload once James gives the green signal will not have this issue.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4066#issuecomment-355692567
https://github.com/broadinstitute/gatk/pull/4066#issuecomment-355692567:338,Energy Efficiency,green,green,338,"Doesn't affect it - there will be a new jar with the allele specific annotations feature enabled. The jar in that PR was a temp for James to test out. It might be that the temp jar also has the uuid dynamic linking issue on OSX. For now, James can workaround by installing the uuid library. The new jar I will upload once James gives the green signal will not have this issue.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4066#issuecomment-355692567
https://github.com/broadinstitute/gatk/pull/4066#issuecomment-355692567:141,Testability,test,test,141,"Doesn't affect it - there will be a new jar with the allele specific annotations feature enabled. The jar in that PR was a temp for James to test out. It might be that the temp jar also has the uuid dynamic linking issue on OSX. For now, James can workaround by installing the uuid library. The new jar I will upload once James gives the green signal will not have this issue.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4066#issuecomment-355692567
https://github.com/broadinstitute/gatk/pull/4066#issuecomment-355695318:1566,Deployability,pipeline,pipelines,1566,======; Files 1074 1074 ; Lines 59186 59435 +249 ; Branches 9615 9686 +71 ; ==============================================; + Hits 46733 46962 +229 ; - Misses 8714 8719 +5 ; - Partials 3739 3754 +15; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4066?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/4066/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `50% <0%> (-30%)` | `1% <0%> (-2%)` | |; | [...er/tools/spark/sv/discovery/AlignmentInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/4066/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvQWxpZ25tZW50SW50ZXJ2YWwuamF2YQ==) | `91.064% <0%> (ø)` | `65% <0%> (-1%)` | :arrow_down: |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4066/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `66.667% <0%> (ø)` | `4% <0%> (+2%)` | :arrow_up: |; | [...itute/hellbender/tools/walkers/SplitIntervals.java](https://codecov.io/gh/broadinstitute/gatk/pull/4066/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL1NwbGl0SW50ZXJ2YWxzLmphdmE=) | `88.889% <0%> (+0.654%)` | `10% <0%> (+4%)` | :arrow_up: |; | [...r/tools/walkers/validation/RemoveNearbyIndels.java](https://codecov.io/gh/broadinstitute/gatk/pull/4066/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vUmVtb3ZlTmVhcmJ5SW5kZWxzLmphdmE=) | `91.429% <0%> (+0.952%)` | `9% <0%> (+4%)` | :arrow_up: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitu,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4066#issuecomment-355695318
https://github.com/broadinstitute/gatk/pull/4066#issuecomment-355695318:3413,Deployability,Update,UpdateVCFSequenceDictionary,3413, `10% <0%> (+4%)` | :arrow_up: |; | [...r/tools/walkers/validation/RemoveNearbyIndels.java](https://codecov.io/gh/broadinstitute/gatk/pull/4066/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vUmVtb3ZlTmVhcmJ5SW5kZWxzLmphdmE=) | `91.429% <0%> (+0.952%)` | `9% <0%> (+4%)` | :arrow_up: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4066/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `80% <0%> (+1.29%)` | `39% <0%> (ø)` | :arrow_down: |; | [...adinstitute/hellbender/tools/IndexFeatureFile.java](https://codecov.io/gh/broadinstitute/gatk/pull/4066/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9JbmRleEZlYXR1cmVGaWxlLmphdmE=) | `91.667% <0%> (+1.344%)` | `17% <0%> (+5%)` | :arrow_up: |; | [...r/tools/walkers/variantutils/ValidateVariants.java](https://codecov.io/gh/broadinstitute/gatk/pull/4066/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9WYWxpZGF0ZVZhcmlhbnRzLmphdmE=) | `85.465% <0%> (+2.608%)` | `58% <0%> (+24%)` | :arrow_up: |; | [...kers/variantutils/UpdateVCFSequenceDictionary.java](https://codecov.io/gh/broadinstitute/gatk/pull/4066/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9VcGRhdGVWQ0ZTZXF1ZW5jZURpY3Rpb25hcnkuamF2YQ==) | `89.873% <0%> (+2.917%)` | `23% <0%> (+9%)` | :arrow_up: |; | [...oadinstitute/hellbender/tools/GatherVcfsCloud.java](https://codecov.io/gh/broadinstitute/gatk/pull/4066/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9HYXRoZXJWY2ZzQ2xvdWQuamF2YQ==) | `77.656% <0%> (+6.845%)` | `54% <0%> (+14%)` | :arrow_up: |; | ... and [1 more](https://codecov.io/gh/broadinstitute/gatk/pull/4066/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4066#issuecomment-355695318
https://github.com/broadinstitute/gatk/pull/4066#issuecomment-355695318:2180,Security,validat,validation,2180, <0%> (-30%)` | `1% <0%> (-2%)` | |; | [...er/tools/spark/sv/discovery/AlignmentInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/4066/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvQWxpZ25tZW50SW50ZXJ2YWwuamF2YQ==) | `91.064% <0%> (ø)` | `65% <0%> (-1%)` | :arrow_down: |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4066/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `66.667% <0%> (ø)` | `4% <0%> (+2%)` | :arrow_up: |; | [...itute/hellbender/tools/walkers/SplitIntervals.java](https://codecov.io/gh/broadinstitute/gatk/pull/4066/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL1NwbGl0SW50ZXJ2YWxzLmphdmE=) | `88.889% <0%> (+0.654%)` | `10% <0%> (+4%)` | :arrow_up: |; | [...r/tools/walkers/validation/RemoveNearbyIndels.java](https://codecov.io/gh/broadinstitute/gatk/pull/4066/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vUmVtb3ZlTmVhcmJ5SW5kZWxzLmphdmE=) | `91.429% <0%> (+0.952%)` | `9% <0%> (+4%)` | :arrow_up: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4066/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `80% <0%> (+1.29%)` | `39% <0%> (ø)` | :arrow_down: |; | [...adinstitute/hellbender/tools/IndexFeatureFile.java](https://codecov.io/gh/broadinstitute/gatk/pull/4066/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9JbmRleEZlYXR1cmVGaWxlLmphdmE=) | `91.667% <0%> (+1.344%)` | `17% <0%> (+5%)` | :arrow_up: |; | [...r/tools/walkers/variantutils/ValidateVariants.java](https://codecov.io/gh/broadinstitute/gatk/pull/4066/diff?src=pr&,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4066#issuecomment-355695318
https://github.com/broadinstitute/gatk/pull/4066#issuecomment-355695318:3100,Security,Validat,ValidateVariants,3100,) | `88.889% <0%> (+0.654%)` | `10% <0%> (+4%)` | :arrow_up: |; | [...r/tools/walkers/validation/RemoveNearbyIndels.java](https://codecov.io/gh/broadinstitute/gatk/pull/4066/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vUmVtb3ZlTmVhcmJ5SW5kZWxzLmphdmE=) | `91.429% <0%> (+0.952%)` | `9% <0%> (+4%)` | :arrow_up: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4066/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `80% <0%> (+1.29%)` | `39% <0%> (ø)` | :arrow_down: |; | [...adinstitute/hellbender/tools/IndexFeatureFile.java](https://codecov.io/gh/broadinstitute/gatk/pull/4066/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9JbmRleEZlYXR1cmVGaWxlLmphdmE=) | `91.667% <0%> (+1.344%)` | `17% <0%> (+5%)` | :arrow_up: |; | [...r/tools/walkers/variantutils/ValidateVariants.java](https://codecov.io/gh/broadinstitute/gatk/pull/4066/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9WYWxpZGF0ZVZhcmlhbnRzLmphdmE=) | `85.465% <0%> (+2.608%)` | `58% <0%> (+24%)` | :arrow_up: |; | [...kers/variantutils/UpdateVCFSequenceDictionary.java](https://codecov.io/gh/broadinstitute/gatk/pull/4066/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9VcGRhdGVWQ0ZTZXF1ZW5jZURpY3Rpb25hcnkuamF2YQ==) | `89.873% <0%> (+2.917%)` | `23% <0%> (+9%)` | :arrow_up: |; | [...oadinstitute/hellbender/tools/GatherVcfsCloud.java](https://codecov.io/gh/broadinstitute/gatk/pull/4066/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9HYXRoZXJWY2ZzQ2xvdWQuamF2YQ==) | `77.656% <0%> (+6.845%)` | `54% <0%> (+14%)` | :arrow_up: |; | ... and [1 more](https://codecov.io/gh/broadinstitute/gatk/pull/4066,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4066#issuecomment-355695318
https://github.com/broadinstitute/gatk/pull/4068#issuecomment-355848563:3505,Deployability,pipeline,pipelines,3505,gh/broadinstitute/gatk/pull/4068/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9tZXRyaWNzL1F1YWxpdHlZaWVsZE1ldHJpY3NBcmd1bWVudENvbGxlY3Rpb24uamF2YQ==) | `100% <100%> (ø)` | `1 <0> (ø)` | :arrow_down: |; | [...dinstitute/hellbender/tools/spark/PileupSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4068/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QaWxldXBTcGFyay5qYXZh) | `98.148% <100%> (ø)` | `15 <0> (ø)` | :arrow_down: |; | [...lines/metrics/InsertSizeMetricsCollectorSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4068/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvbWV0cmljcy9JbnNlcnRTaXplTWV0cmljc0NvbGxlY3RvclNwYXJrLmphdmE=) | `86.364% <100%> (ø)` | `7 <1> (ø)` | :arrow_down: |; | [...ons/MetricAccumulationLevelArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/4068/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL2FyZ3VtZW50Y29sbGVjdGlvbnMvTWV0cmljQWNjdW11bGF0aW9uTGV2ZWxBcmd1bWVudENvbGxlY3Rpb24uamF2YQ==) | `100% <100%> (ø)` | `1 <0> (ø)` | :arrow_down: |; | [...pipelines/metrics/CollectMultipleMetricsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4068/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvbWV0cmljcy9Db2xsZWN0TXVsdGlwbGVNZXRyaWNzU3BhcmsuamF2YQ==) | `92.593% <100%> (ø)` | `9 <0> (ø)` | :arrow_down: |; | [...s/metrics/CollectBaseDistributionByCycleSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4068/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvbWV0cmljcy9Db2xsZWN0QmFzZURpc3RyaWJ1dGlvbkJ5Q3ljbGVTcGFyay5qYXZh) | `87.037% <100%> (ø)` | `9 <0> (ø)` | :arrow_down: |; | ... and [110 more](https://codecov.io/gh/broadinstitute/gatk/pull/4068/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4068#issuecomment-355848563
https://github.com/broadinstitute/gatk/pull/4068#issuecomment-356016486:26,Deployability,update,updates,26,@sooheelee thanks for the updates -- you did more work on this than myself haha ;-) I'll look into the two issues you mentioned.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4068#issuecomment-356016486
https://github.com/broadinstitute/gatk/pull/4068#issuecomment-356028074:91,Availability,error,error,91,"@mbabadi you're welcome! . About those two issues--I learned that with VPN on, Spark tools error locally (thanks to Steve). I turned off my VPN connection and am able to run PileupSpark locally. (There is an issue ticket on this at https://github.com/broadinstitute/gatk/issues/1534.). One other thing to note for PipeupSpark documentation--the tool will error if the output filename already exists. That is, unlike other GATK tools, it will not overwrite existing file names. Either this unusual behavior should be fixed or mentioned in the tooldoc. I'm testing this with dataproc now. When running locally, neither CollectBaseDistributionByCycleSpark nor CollectInsertSizeMetricsSpark output the PDF file. So this seems a bug and I'll put in an issue ticket if there isn't one already.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4068#issuecomment-356028074
https://github.com/broadinstitute/gatk/pull/4068#issuecomment-356028074:355,Availability,error,error,355,"@mbabadi you're welcome! . About those two issues--I learned that with VPN on, Spark tools error locally (thanks to Steve). I turned off my VPN connection and am able to run PileupSpark locally. (There is an issue ticket on this at https://github.com/broadinstitute/gatk/issues/1534.). One other thing to note for PipeupSpark documentation--the tool will error if the output filename already exists. That is, unlike other GATK tools, it will not overwrite existing file names. Either this unusual behavior should be fixed or mentioned in the tooldoc. I'm testing this with dataproc now. When running locally, neither CollectBaseDistributionByCycleSpark nor CollectInsertSizeMetricsSpark output the PDF file. So this seems a bug and I'll put in an issue ticket if there isn't one already.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4068#issuecomment-356028074
https://github.com/broadinstitute/gatk/pull/4068#issuecomment-356028074:555,Testability,test,testing,555,"@mbabadi you're welcome! . About those two issues--I learned that with VPN on, Spark tools error locally (thanks to Steve). I turned off my VPN connection and am able to run PileupSpark locally. (There is an issue ticket on this at https://github.com/broadinstitute/gatk/issues/1534.). One other thing to note for PipeupSpark documentation--the tool will error if the output filename already exists. That is, unlike other GATK tools, it will not overwrite existing file names. Either this unusual behavior should be fixed or mentioned in the tooldoc. I'm testing this with dataproc now. When running locally, neither CollectBaseDistributionByCycleSpark nor CollectInsertSizeMetricsSpark output the PDF file. So this seems a bug and I'll put in an issue ticket if there isn't one already.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4068#issuecomment-356028074
https://github.com/broadinstitute/gatk/pull/4068#issuecomment-356028074:53,Usability,learn,learned,53,"@mbabadi you're welcome! . About those two issues--I learned that with VPN on, Spark tools error locally (thanks to Steve). I turned off my VPN connection and am able to run PileupSpark locally. (There is an issue ticket on this at https://github.com/broadinstitute/gatk/issues/1534.). One other thing to note for PipeupSpark documentation--the tool will error if the output filename already exists. That is, unlike other GATK tools, it will not overwrite existing file names. Either this unusual behavior should be fixed or mentioned in the tooldoc. I'm testing this with dataproc now. When running locally, neither CollectBaseDistributionByCycleSpark nor CollectInsertSizeMetricsSpark output the PDF file. So this seems a bug and I'll put in an issue ticket if there isn't one already.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4068#issuecomment-356028074
https://github.com/broadinstitute/gatk/pull/4068#issuecomment-356031571:154,Availability,ping,ping,154,"@mbabadi you should get confirmation from @droazen for any changes--commits, merges. He was actively working on tools in this PR as of last night. Please ping him.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4068#issuecomment-356031571
https://github.com/broadinstitute/gatk/pull/4069#issuecomment-357288119:37,Testability,test,tests,37,"@davidbenjamin Feel free to merge if tests pass. For future reference, I'd like to start having automated tests for supported WDLs. Can you file an issue? Not required for this PR.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4069#issuecomment-357288119
https://github.com/broadinstitute/gatk/pull/4069#issuecomment-357288119:106,Testability,test,tests,106,"@davidbenjamin Feel free to merge if tests pass. For future reference, I'd like to start having automated tests for supported WDLs. Can you file an issue? Not required for this PR.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4069#issuecomment-357288119
https://github.com/broadinstitute/gatk/pull/4070#issuecomment-355848388:2497,Deployability,pipeline,pipelines,2497,9.565% <ø> (ø)` | `5 <0> (ø)` | :arrow_down: |; | [...ls/walkers/mutect/CreateSomaticPanelOfNormals.java](https://codecov.io/gh/broadinstitute/gatk/pull/4070/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9DcmVhdGVTb21hdGljUGFuZWxPZk5vcm1hbHMuamF2YQ==) | `87.273% <ø> (ø)` | `8 <0> (ø)` | :arrow_down: |; | [...itute/hellbender/tools/walkers/SplitIntervals.java](https://codecov.io/gh/broadinstitute/gatk/pull/4070/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL1NwbGl0SW50ZXJ2YWxzLmphdmE=) | `88.235% <ø> (ø)` | `6 <0> (ø)` | :arrow_down: |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/4070/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `22.807% <ø> (ø)` | `2 <0> (ø)` | :arrow_down: |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4070/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `66.667% <ø> (ø)` | `2 <0> (ø)` | :arrow_down: |; | [...k/pipelines/BwaAndMarkDuplicatesPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4070/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQndhQW5kTWFya0R1cGxpY2F0ZXNQaXBlbGluZVNwYXJrLmphdmE=) | `78.947% <ø> (ø)` | `4 <0> (ø)` | :arrow_down: |; | [...er/tools/walkers/variantutils/VariantsToTable.java](https://codecov.io/gh/broadinstitute/gatk/pull/4070/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9WYXJpYW50c1RvVGFibGUuamF2YQ==) | `93.182% <ø> (ø)` | `75 <0> (ø)` | :arrow_down: |; | [...r/tools/walkers/variantutils/ValidateVariants.java](https://codecov.io/,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4070#issuecomment-355848388
https://github.com/broadinstitute/gatk/pull/4070#issuecomment-355848388:2791,Deployability,pipeline,pipelines,2791,F2YQ==) | `87.273% <ø> (ø)` | `8 <0> (ø)` | :arrow_down: |; | [...itute/hellbender/tools/walkers/SplitIntervals.java](https://codecov.io/gh/broadinstitute/gatk/pull/4070/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL1NwbGl0SW50ZXJ2YWxzLmphdmE=) | `88.235% <ø> (ø)` | `6 <0> (ø)` | :arrow_down: |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/4070/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `22.807% <ø> (ø)` | `2 <0> (ø)` | :arrow_down: |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4070/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `66.667% <ø> (ø)` | `2 <0> (ø)` | :arrow_down: |; | [...k/pipelines/BwaAndMarkDuplicatesPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4070/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQndhQW5kTWFya0R1cGxpY2F0ZXNQaXBlbGluZVNwYXJrLmphdmE=) | `78.947% <ø> (ø)` | `4 <0> (ø)` | :arrow_down: |; | [...er/tools/walkers/variantutils/VariantsToTable.java](https://codecov.io/gh/broadinstitute/gatk/pull/4070/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9WYXJpYW50c1RvVGFibGUuamF2YQ==) | `93.182% <ø> (ø)` | `75 <0> (ø)` | :arrow_down: |; | [...r/tools/walkers/variantutils/ValidateVariants.java](https://codecov.io/gh/broadinstitute/gatk/pull/4070/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9WYWxpZGF0ZVZhcmlhbnRzLmphdmE=) | `82.857% <ø> (ø)` | `34 <0> (ø)` | :arrow_down: |; | [...broadinstitute/hellbender/tools/GetSampleName.java](https://codeco,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4070#issuecomment-355848388
https://github.com/broadinstitute/gatk/pull/4070#issuecomment-355848388:3461,Security,Validat,ValidateVariants,3461,35% <ø> (ø)` | `6 <0> (ø)` | :arrow_down: |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/4070/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `22.807% <ø> (ø)` | `2 <0> (ø)` | :arrow_down: |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4070/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `66.667% <ø> (ø)` | `2 <0> (ø)` | :arrow_down: |; | [...k/pipelines/BwaAndMarkDuplicatesPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4070/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQndhQW5kTWFya0R1cGxpY2F0ZXNQaXBlbGluZVNwYXJrLmphdmE=) | `78.947% <ø> (ø)` | `4 <0> (ø)` | :arrow_down: |; | [...er/tools/walkers/variantutils/VariantsToTable.java](https://codecov.io/gh/broadinstitute/gatk/pull/4070/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9WYXJpYW50c1RvVGFibGUuamF2YQ==) | `93.182% <ø> (ø)` | `75 <0> (ø)` | :arrow_down: |; | [...r/tools/walkers/variantutils/ValidateVariants.java](https://codecov.io/gh/broadinstitute/gatk/pull/4070/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9WYWxpZGF0ZVZhcmlhbnRzLmphdmE=) | `82.857% <ø> (ø)` | `34 <0> (ø)` | :arrow_down: |; | [...broadinstitute/hellbender/tools/GetSampleName.java](https://codecov.io/gh/broadinstitute/gatk/pull/4070/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9HZXRTYW1wbGVOYW1lLmphdmE=) | `62.5% <ø> (ø)` | `6 <0> (ø)` | :arrow_down: |; | ... and [36 more](https://codecov.io/gh/broadinstitute/gatk/pull/4070/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4070#issuecomment-355848388
https://github.com/broadinstitute/gatk/pull/4071#issuecomment-355862387:81,Testability,test,tests,81,"Actually, is `gatk` even in the `PATH` of the Docker image? (If not, this is why tests are now failing.) Should we add it? Otherwise, should we instead launch with `/gatk/gatk` in the WDLs and require they be used with the Docker?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4071#issuecomment-355862387
https://github.com/broadinstitute/gatk/pull/4071#issuecomment-356092508:257,Deployability,release,release,257,"Double checked with @lbergelson about adding `gatk` to the Docker `PATH`. Please feel free to revert if there was a reason why it wasn't already in the `PATH` or if I did it wrong. Also filed #4092 for the question for @jsotobroad, let's just address after release.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4071#issuecomment-356092508
https://github.com/broadinstitute/gatk/issues/4072#issuecomment-355870160:40,Usability,guid,guide,40,@samuelklee See upcoming WDL convention guide for GATK repo.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4072#issuecomment-355870160
https://github.com/broadinstitute/gatk/issues/4073#issuecomment-356088297:5,Deployability,update,updated,5,I've updated the commands that now use kebab:. [4] tumorA: GATK4 HC NOT seeing the G allele at 121 (but sees the C).; ```; gatk HaplotypeCaller \; 	-I tumorA.bam \; 	-R ref200.fasta \; 	-O gatk4_hc_tumorA.vcf.gz \; 	--max-assembly-region-size 40 \; 	--assembly-region-padding 10 \; 	--min-assembly-region-size 10 \; 	--debug; ```. [5] normal: GATK4 HC completely blind to the GG at 121; ```; gatk HaplotypeCaller \; 	-I normal.bam \; 	-R ref200.fasta \; 	-O gatk4_hc_normal.vcf.gz \; 	--max-assembly-region-size 40 \; 	--assembly-region-padding 10 \; 	--min-assembly-region-size 10 \; 	--debug; ```. [6] tumorB: GATK4 HC has no problem seeing the C allele at 121; ```; gatk HaplotypeCaller \; 	-I tumorB.bam \; 	-R ref200.fasta \; 	-O gatk4_hc_tumorB.vcf.gz \; 	--max-assembly-region-size 40 \; 	--assembly-region-padding 10 \; 	--min-assembly-region-size 10 \; 	--debug; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4073#issuecomment-356088297
https://github.com/broadinstitute/gatk/issues/4073#issuecomment-360515238:73,Deployability,pipeline,pipelines,73,"I've been thinking about this literal edge case. We now have metagenomic pipelines that are meant to align data to presumably extremely small references (bacteria, infectious agents, e.g. viri). These organisms have a different expectation for mutation/variant rates that my synthetic data could represent. I am unfamiliar with the details of the metagenomics pipelines except that it aligns reads to a giant conglomerate of different organisms. I forget whether the pipeline actually produces an alignment BAM or just a list of organisms--perhaps @mwalker174 could inform us. On the forum, we've had a few cases where we encourage folks to use our tools even when they work in other nonmammalian organisms such as bacteria. However, knowing how our assembler handles data at the edges of contigs, and how variants that are close together trigger alternate assumptions, e.g. the presence of an indel as I learned from @droazen, then I'd like to know how I should actually be informing our nonmammalian researchers. Whether they should or should not consider assembly-based calling, whether there are certain parameters they could employ to ensure calling some variant (even if wrong) rather than no variant within the confines of a small genome, or whether I should point them to a pileup caller, etc.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4073#issuecomment-360515238
https://github.com/broadinstitute/gatk/issues/4073#issuecomment-360515238:360,Deployability,pipeline,pipelines,360,"I've been thinking about this literal edge case. We now have metagenomic pipelines that are meant to align data to presumably extremely small references (bacteria, infectious agents, e.g. viri). These organisms have a different expectation for mutation/variant rates that my synthetic data could represent. I am unfamiliar with the details of the metagenomics pipelines except that it aligns reads to a giant conglomerate of different organisms. I forget whether the pipeline actually produces an alignment BAM or just a list of organisms--perhaps @mwalker174 could inform us. On the forum, we've had a few cases where we encourage folks to use our tools even when they work in other nonmammalian organisms such as bacteria. However, knowing how our assembler handles data at the edges of contigs, and how variants that are close together trigger alternate assumptions, e.g. the presence of an indel as I learned from @droazen, then I'd like to know how I should actually be informing our nonmammalian researchers. Whether they should or should not consider assembly-based calling, whether there are certain parameters they could employ to ensure calling some variant (even if wrong) rather than no variant within the confines of a small genome, or whether I should point them to a pileup caller, etc.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4073#issuecomment-360515238
https://github.com/broadinstitute/gatk/issues/4073#issuecomment-360515238:467,Deployability,pipeline,pipeline,467,"I've been thinking about this literal edge case. We now have metagenomic pipelines that are meant to align data to presumably extremely small references (bacteria, infectious agents, e.g. viri). These organisms have a different expectation for mutation/variant rates that my synthetic data could represent. I am unfamiliar with the details of the metagenomics pipelines except that it aligns reads to a giant conglomerate of different organisms. I forget whether the pipeline actually produces an alignment BAM or just a list of organisms--perhaps @mwalker174 could inform us. On the forum, we've had a few cases where we encourage folks to use our tools even when they work in other nonmammalian organisms such as bacteria. However, knowing how our assembler handles data at the edges of contigs, and how variants that are close together trigger alternate assumptions, e.g. the presence of an indel as I learned from @droazen, then I'd like to know how I should actually be informing our nonmammalian researchers. Whether they should or should not consider assembly-based calling, whether there are certain parameters they could employ to ensure calling some variant (even if wrong) rather than no variant within the confines of a small genome, or whether I should point them to a pileup caller, etc.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4073#issuecomment-360515238
https://github.com/broadinstitute/gatk/issues/4073#issuecomment-360515238:905,Usability,learn,learned,905,"I've been thinking about this literal edge case. We now have metagenomic pipelines that are meant to align data to presumably extremely small references (bacteria, infectious agents, e.g. viri). These organisms have a different expectation for mutation/variant rates that my synthetic data could represent. I am unfamiliar with the details of the metagenomics pipelines except that it aligns reads to a giant conglomerate of different organisms. I forget whether the pipeline actually produces an alignment BAM or just a list of organisms--perhaps @mwalker174 could inform us. On the forum, we've had a few cases where we encourage folks to use our tools even when they work in other nonmammalian organisms such as bacteria. However, knowing how our assembler handles data at the edges of contigs, and how variants that are close together trigger alternate assumptions, e.g. the presence of an indel as I learned from @droazen, then I'd like to know how I should actually be informing our nonmammalian researchers. Whether they should or should not consider assembly-based calling, whether there are certain parameters they could employ to ensure calling some variant (even if wrong) rather than no variant within the confines of a small genome, or whether I should point them to a pileup caller, etc.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4073#issuecomment-360515238
https://github.com/broadinstitute/gatk/issues/4074#issuecomment-356015168:115,Deployability,install,installed,115,"@samuelklee @cmnbroad I wonder whether we could get rid of libgcc-ng altogether? it automatically appeared after I installed the main dependencies. For what it's worth, I have a fully working mkl-enabled gcnv python env on my mac!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4074#issuecomment-356015168
https://github.com/broadinstitute/gatk/issues/4074#issuecomment-356015168:134,Integrability,depend,dependencies,134,"@samuelklee @cmnbroad I wonder whether we could get rid of libgcc-ng altogether? it automatically appeared after I installed the main dependencies. For what it's worth, I have a fully working mkl-enabled gcnv python env on my mac!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4074#issuecomment-356015168
https://github.com/broadinstitute/gatk/issues/4074#issuecomment-356016812:41,Deployability,install,installing,41,"@mbabadi Can you try removing libgcc-ng, installing the resulting environment (`./gradlew createPythonPackageArchive; conda env create -n gatk -f scripts/gatkcondaenv.yml`), and then verifying that gcnv runs as intended? If so, mind creating the PR?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4074#issuecomment-356016812
https://github.com/broadinstitute/gatk/issues/4076#issuecomment-358363817:22,Testability,test,tests,22,"this is done, jenkins tests are back up and running",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4076#issuecomment-358363817
https://github.com/broadinstitute/gatk/pull/4078#issuecomment-355870074:46,Deployability,integrat,integration,46,"Used to be used. Used to be tested through an integration test that is no longer, I guess. Merge away. @lbergelson",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4078#issuecomment-355870074
https://github.com/broadinstitute/gatk/pull/4078#issuecomment-355870074:46,Integrability,integrat,integration,46,"Used to be used. Used to be tested through an integration test that is no longer, I guess. Merge away. @lbergelson",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4078#issuecomment-355870074
https://github.com/broadinstitute/gatk/pull/4078#issuecomment-355870074:28,Testability,test,tested,28,"Used to be used. Used to be tested through an integration test that is no longer, I guess. Merge away. @lbergelson",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4078#issuecomment-355870074
https://github.com/broadinstitute/gatk/pull/4078#issuecomment-355870074:58,Testability,test,test,58,"Used to be used. Used to be tested through an integration test that is no longer, I guess. Merge away. @lbergelson",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4078#issuecomment-355870074
https://github.com/broadinstitute/gatk/issues/4081#issuecomment-356035257:134,Deployability,pipeline,pipeline,134,"@Sun-shan Currently it has to start with a bam file. You can use an unmapped bam file and then align it with bwa as part of the spark pipeline, but we can't currently read FASTQ directly. That's a feature we'd like to consider in the future.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4081#issuecomment-356035257
https://github.com/broadinstitute/gatk/issues/4081#issuecomment-356201563:35,Usability,simpl,simple,35,"@Sun-shan - I recently published a simple toolkit, ReadTools, for standardizing formats into an unmapped BAM that follow the specifications, starting from different FASTQ inputs (and others): single-end, pair-end, Illumina-legacy names, Casava read names, etc. Check it out in the [ReadTools documentation page](http://magicdgs.github.io/ReadTools/).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4081#issuecomment-356201563
https://github.com/broadinstitute/gatk/pull/4082#issuecomment-356017217:22,Availability,failure,failures,22,@jamesemery Some test failures here https://storage.googleapis.com/hellbender-test-logs/build_reports/master_16064.3/tests/test/index.html,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4082#issuecomment-356017217
https://github.com/broadinstitute/gatk/pull/4082#issuecomment-356017217:17,Testability,test,test,17,@jamesemery Some test failures here https://storage.googleapis.com/hellbender-test-logs/build_reports/master_16064.3/tests/test/index.html,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4082#issuecomment-356017217
https://github.com/broadinstitute/gatk/pull/4082#issuecomment-356017217:78,Testability,test,test-logs,78,@jamesemery Some test failures here https://storage.googleapis.com/hellbender-test-logs/build_reports/master_16064.3/tests/test/index.html,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4082#issuecomment-356017217
https://github.com/broadinstitute/gatk/pull/4082#issuecomment-356017217:117,Testability,test,tests,117,@jamesemery Some test failures here https://storage.googleapis.com/hellbender-test-logs/build_reports/master_16064.3/tests/test/index.html,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4082#issuecomment-356017217
https://github.com/broadinstitute/gatk/pull/4082#issuecomment-356017217:123,Testability,test,test,123,@jamesemery Some test failures here https://storage.googleapis.com/hellbender-test-logs/build_reports/master_16064.3/tests/test/index.html,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4082#issuecomment-356017217
https://github.com/broadinstitute/gatk/issues/4083#issuecomment-788084917:60,Usability,clear,clear,60,Does functotator support structural variants now? It is not clear from the documentation or this Github issue. Cheers!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4083#issuecomment-788084917
https://github.com/broadinstitute/gatk/pull/4084#issuecomment-356068331:64,Energy Efficiency,green,green,64,All tests have passed @lbergelson or whoever would like to give green light to merge.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4084#issuecomment-356068331
https://github.com/broadinstitute/gatk/pull/4084#issuecomment-356068331:4,Testability,test,tests,4,All tests have passed @lbergelson or whoever would like to give green light to merge.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4084#issuecomment-356068331
https://github.com/broadinstitute/gatk/issues/4086#issuecomment-356366388:110,Modifiability,rewrite,rewrite,110,"That sounds like a good thing to look at. If someone has already written it, it would be great to not have to rewrite it..",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4086#issuecomment-356366388
https://github.com/broadinstitute/gatk/pull/4087#issuecomment-356051662:1820,Deployability,pipeline,pipelines,1820,/broadinstitute/gatk/pull/4087?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...te/hellbender/utils/python/PythonExecutorBase.java](https://codecov.io/gh/broadinstitute/gatk/pull/4087/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9weXRob24vUHl0aG9uRXhlY3V0b3JCYXNlLmphdmE=) | `50% <100%> (-23.333%)` | `4 <0> (ø)` | |; | [.../hellbender/utils/python/PythonScriptExecutor.java](https://codecov.io/gh/broadinstitute/gatk/pull/4087/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9weXRob24vUHl0aG9uU2NyaXB0RXhlY3V0b3IuamF2YQ==) | `64.706% <100%> (ø)` | `9 <1> (ø)` | :arrow_down: |; | [...stitute/hellbender/tools/spark/ApplyBQSRSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4087/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9BcHBseUJRU1JTcGFyay5qYXZh) | `50% <0%> (-50%)` | `3% <0%> (ø)` | |; | [...ender/tools/spark/pipelines/BQSRPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4087/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQlFTUlBpcGVsaW5lU3BhcmsuamF2YQ==) | `55% <0%> (-45%)` | `5% <0%> (-3%)` | |; | [...ute/hellbender/tools/walkers/UnmarkDuplicates.java](https://codecov.io/gh/broadinstitute/gatk/pull/4087/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL1VubWFya0R1cGxpY2F0ZXMuamF2YQ==) | `45% <0%> (-45%)` | `5% <0%> (ø)` | |; | [...itute/hellbender/tools/walkers/bqsr/ApplyBQSR.java](https://codecov.io/gh/broadinstitute/gatk/pull/4087/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Jxc3IvQXBwbHlCUVNSLmphdmE=) | `52.381% <0%> (-39.286%)` | `5% <0%> (-1%)` | |; | [.../tools/walkers/validation/CountFalsePositives.java](https://codecov.io/gh/broadinstitute/gatk/pull/4087/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4087#issuecomment-356051662
https://github.com/broadinstitute/gatk/pull/4087#issuecomment-356051662:3314,Deployability,pipeline,pipelines,3314,Fyay9waXBlbGluZXMvQlFTUlBpcGVsaW5lU3BhcmsuamF2YQ==) | `55% <0%> (-45%)` | `5% <0%> (-3%)` | |; | [...ute/hellbender/tools/walkers/UnmarkDuplicates.java](https://codecov.io/gh/broadinstitute/gatk/pull/4087/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL1VubWFya0R1cGxpY2F0ZXMuamF2YQ==) | `45% <0%> (-45%)` | `5% <0%> (ø)` | |; | [...itute/hellbender/tools/walkers/bqsr/ApplyBQSR.java](https://codecov.io/gh/broadinstitute/gatk/pull/4087/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Jxc3IvQXBwbHlCUVNSLmphdmE=) | `52.381% <0%> (-39.286%)` | `5% <0%> (-1%)` | |; | [.../tools/walkers/validation/CountFalsePositives.java](https://codecov.io/gh/broadinstitute/gatk/pull/4087/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vQ291bnRGYWxzZVBvc2l0aXZlcy5qYXZh) | `56.863% <0%> (-36.686%)` | `4% <0%> (-3%)` | |; | [...ender/engine/MultiVariantWalkerGroupedOnStart.java](https://codecov.io/gh/broadinstitute/gatk/pull/4087/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvTXVsdGlWYXJpYW50V2Fsa2VyR3JvdXBlZE9uU3RhcnQuamF2YQ==) | `62% <0%> (-34.875%)` | `14% <0%> (-6%)` | |; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4087/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `54.545% <0%> (-34.816%)` | `10% <0%> (-2%)` | |; | [...lbender/tools/spark/pipelines/CountReadsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4087/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQ291bnRSZWFkc1NwYXJrLmphdmE=) | `56.25% <0%> (-33.75%)` | `4% <0%> (ø)` | |; | ... and [26 more](https://codecov.io/gh/broadinstitute/gatk/pull/4087/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4087#issuecomment-356051662
https://github.com/broadinstitute/gatk/pull/4087#issuecomment-356051662:3626,Deployability,pipeline,pipelines,3626,Fyay9waXBlbGluZXMvQlFTUlBpcGVsaW5lU3BhcmsuamF2YQ==) | `55% <0%> (-45%)` | `5% <0%> (-3%)` | |; | [...ute/hellbender/tools/walkers/UnmarkDuplicates.java](https://codecov.io/gh/broadinstitute/gatk/pull/4087/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL1VubWFya0R1cGxpY2F0ZXMuamF2YQ==) | `45% <0%> (-45%)` | `5% <0%> (ø)` | |; | [...itute/hellbender/tools/walkers/bqsr/ApplyBQSR.java](https://codecov.io/gh/broadinstitute/gatk/pull/4087/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Jxc3IvQXBwbHlCUVNSLmphdmE=) | `52.381% <0%> (-39.286%)` | `5% <0%> (-1%)` | |; | [.../tools/walkers/validation/CountFalsePositives.java](https://codecov.io/gh/broadinstitute/gatk/pull/4087/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vQ291bnRGYWxzZVBvc2l0aXZlcy5qYXZh) | `56.863% <0%> (-36.686%)` | `4% <0%> (-3%)` | |; | [...ender/engine/MultiVariantWalkerGroupedOnStart.java](https://codecov.io/gh/broadinstitute/gatk/pull/4087/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvTXVsdGlWYXJpYW50V2Fsa2VyR3JvdXBlZE9uU3RhcnQuamF2YQ==) | `62% <0%> (-34.875%)` | `14% <0%> (-6%)` | |; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4087/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `54.545% <0%> (-34.816%)` | `10% <0%> (-2%)` | |; | [...lbender/tools/spark/pipelines/CountReadsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4087/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQ291bnRSZWFkc1NwYXJrLmphdmE=) | `56.25% <0%> (-33.75%)` | `4% <0%> (ø)` | |; | ... and [26 more](https://codecov.io/gh/broadinstitute/gatk/pull/4087/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4087#issuecomment-356051662
https://github.com/broadinstitute/gatk/pull/4087#issuecomment-356051662:2695,Security,validat,validation,2695,JlbmRlci90b29scy9zcGFyay9BcHBseUJRU1JTcGFyay5qYXZh) | `50% <0%> (-50%)` | `3% <0%> (ø)` | |; | [...ender/tools/spark/pipelines/BQSRPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4087/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQlFTUlBpcGVsaW5lU3BhcmsuamF2YQ==) | `55% <0%> (-45%)` | `5% <0%> (-3%)` | |; | [...ute/hellbender/tools/walkers/UnmarkDuplicates.java](https://codecov.io/gh/broadinstitute/gatk/pull/4087/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL1VubWFya0R1cGxpY2F0ZXMuamF2YQ==) | `45% <0%> (-45%)` | `5% <0%> (ø)` | |; | [...itute/hellbender/tools/walkers/bqsr/ApplyBQSR.java](https://codecov.io/gh/broadinstitute/gatk/pull/4087/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Jxc3IvQXBwbHlCUVNSLmphdmE=) | `52.381% <0%> (-39.286%)` | `5% <0%> (-1%)` | |; | [.../tools/walkers/validation/CountFalsePositives.java](https://codecov.io/gh/broadinstitute/gatk/pull/4087/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vQ291bnRGYWxzZVBvc2l0aXZlcy5qYXZh) | `56.863% <0%> (-36.686%)` | `4% <0%> (-3%)` | |; | [...ender/engine/MultiVariantWalkerGroupedOnStart.java](https://codecov.io/gh/broadinstitute/gatk/pull/4087/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvTXVsdGlWYXJpYW50V2Fsa2VyR3JvdXBlZE9uU3RhcnQuamF2YQ==) | `62% <0%> (-34.875%)` | `14% <0%> (-6%)` | |; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4087/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `54.545% <0%> (-34.816%)` | `10% <0%> (-2%)` | |; | [...lbender/tools/spark/pipelines/CountReadsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pul,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4087#issuecomment-356051662
https://github.com/broadinstitute/gatk/pull/4087#issuecomment-356079886:1896,Deployability,install,installed,1896,"now that we've actually solved the full problem and someone has successfully run from this env on a mac. >>> import gcnvkernel; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/Users/cnorman/miniconda3/envs/gatk/lib/python3.6/site-packages/gcnvkernel/__init__.py"", line 1, in <module>; from pymc3 import __version__ as pymc3_version; File ""/Users/cnorman/miniconda3/envs/gatk/lib/python3.6/site-packages/pymc3/__init__.py"", line 12, in <module>; from .sampling import *; File ""/Users/cnorman/miniconda3/envs/gatk/lib/python3.6/site-packages/pymc3/sampling.py"", line 14, in <module>; from .plots.traceplot import traceplot; File ""/Users/cnorman/miniconda3/envs/gatk/lib/python3.6/site-packages/pymc3/plots/__init__.py"", line 1, in <module>; from .autocorrplot import autocorrplot; File ""/Users/cnorman/miniconda3/envs/gatk/lib/python3.6/site-packages/pymc3/plots/autocorrplot.py"", line 2, in <module>; import matplotlib.pyplot as plt; File ""/Users/cnorman/miniconda3/envs/gatk/lib/python3.6/site-packages/matplotlib/pyplot.py"", line 116, in <module>; _backend_mod, new_figure_manager, draw_if_interactive, _show = pylab_setup(); File ""/Users/cnorman/miniconda3/envs/gatk/lib/python3.6/site-packages/matplotlib/backends/__init__.py"", line 60, in pylab_setup; [backend_name], 0); File ""/Users/cnorman/miniconda3/envs/gatk/lib/python3.6/site-packages/matplotlib/backends/backend_macosx.py"", line 17, in <module>; from matplotlib.backends import _macosx; RuntimeError: Python is not installed as a framework. The Mac OS X backend will not be able to function correctly if Python is not installed as a framework. See the Python documentation for more information on installing Python as a framework on Mac OS X. Please either reinstall Python as a framework, or try one of the other backends. If you are using (Ana)Conda please install python.app and replace the use of 'python' with 'pythonw'. See 'Working with Matplotlib on OSX' in the Matplotlib FAQ for more information.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4087#issuecomment-356079886
https://github.com/broadinstitute/gatk/pull/4087#issuecomment-356079886:1999,Deployability,install,installed,1999,"now that we've actually solved the full problem and someone has successfully run from this env on a mac. >>> import gcnvkernel; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/Users/cnorman/miniconda3/envs/gatk/lib/python3.6/site-packages/gcnvkernel/__init__.py"", line 1, in <module>; from pymc3 import __version__ as pymc3_version; File ""/Users/cnorman/miniconda3/envs/gatk/lib/python3.6/site-packages/pymc3/__init__.py"", line 12, in <module>; from .sampling import *; File ""/Users/cnorman/miniconda3/envs/gatk/lib/python3.6/site-packages/pymc3/sampling.py"", line 14, in <module>; from .plots.traceplot import traceplot; File ""/Users/cnorman/miniconda3/envs/gatk/lib/python3.6/site-packages/pymc3/plots/__init__.py"", line 1, in <module>; from .autocorrplot import autocorrplot; File ""/Users/cnorman/miniconda3/envs/gatk/lib/python3.6/site-packages/pymc3/plots/autocorrplot.py"", line 2, in <module>; import matplotlib.pyplot as plt; File ""/Users/cnorman/miniconda3/envs/gatk/lib/python3.6/site-packages/matplotlib/pyplot.py"", line 116, in <module>; _backend_mod, new_figure_manager, draw_if_interactive, _show = pylab_setup(); File ""/Users/cnorman/miniconda3/envs/gatk/lib/python3.6/site-packages/matplotlib/backends/__init__.py"", line 60, in pylab_setup; [backend_name], 0); File ""/Users/cnorman/miniconda3/envs/gatk/lib/python3.6/site-packages/matplotlib/backends/backend_macosx.py"", line 17, in <module>; from matplotlib.backends import _macosx; RuntimeError: Python is not installed as a framework. The Mac OS X backend will not be able to function correctly if Python is not installed as a framework. See the Python documentation for more information on installing Python as a framework on Mac OS X. Please either reinstall Python as a framework, or try one of the other backends. If you are using (Ana)Conda please install python.app and replace the use of 'python' with 'pythonw'. See 'Working with Matplotlib on OSX' in the Matplotlib FAQ for more information.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4087#issuecomment-356079886
https://github.com/broadinstitute/gatk/pull/4087#issuecomment-356079886:2078,Deployability,install,installing,2078,"now that we've actually solved the full problem and someone has successfully run from this env on a mac. >>> import gcnvkernel; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/Users/cnorman/miniconda3/envs/gatk/lib/python3.6/site-packages/gcnvkernel/__init__.py"", line 1, in <module>; from pymc3 import __version__ as pymc3_version; File ""/Users/cnorman/miniconda3/envs/gatk/lib/python3.6/site-packages/pymc3/__init__.py"", line 12, in <module>; from .sampling import *; File ""/Users/cnorman/miniconda3/envs/gatk/lib/python3.6/site-packages/pymc3/sampling.py"", line 14, in <module>; from .plots.traceplot import traceplot; File ""/Users/cnorman/miniconda3/envs/gatk/lib/python3.6/site-packages/pymc3/plots/__init__.py"", line 1, in <module>; from .autocorrplot import autocorrplot; File ""/Users/cnorman/miniconda3/envs/gatk/lib/python3.6/site-packages/pymc3/plots/autocorrplot.py"", line 2, in <module>; import matplotlib.pyplot as plt; File ""/Users/cnorman/miniconda3/envs/gatk/lib/python3.6/site-packages/matplotlib/pyplot.py"", line 116, in <module>; _backend_mod, new_figure_manager, draw_if_interactive, _show = pylab_setup(); File ""/Users/cnorman/miniconda3/envs/gatk/lib/python3.6/site-packages/matplotlib/backends/__init__.py"", line 60, in pylab_setup; [backend_name], 0); File ""/Users/cnorman/miniconda3/envs/gatk/lib/python3.6/site-packages/matplotlib/backends/backend_macosx.py"", line 17, in <module>; from matplotlib.backends import _macosx; RuntimeError: Python is not installed as a framework. The Mac OS X backend will not be able to function correctly if Python is not installed as a framework. See the Python documentation for more information on installing Python as a framework on Mac OS X. Please either reinstall Python as a framework, or try one of the other backends. If you are using (Ana)Conda please install python.app and replace the use of 'python' with 'pythonw'. See 'Working with Matplotlib on OSX' in the Matplotlib FAQ for more information.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4087#issuecomment-356079886
https://github.com/broadinstitute/gatk/pull/4087#issuecomment-356079886:2240,Deployability,install,install,2240,"now that we've actually solved the full problem and someone has successfully run from this env on a mac. >>> import gcnvkernel; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/Users/cnorman/miniconda3/envs/gatk/lib/python3.6/site-packages/gcnvkernel/__init__.py"", line 1, in <module>; from pymc3 import __version__ as pymc3_version; File ""/Users/cnorman/miniconda3/envs/gatk/lib/python3.6/site-packages/pymc3/__init__.py"", line 12, in <module>; from .sampling import *; File ""/Users/cnorman/miniconda3/envs/gatk/lib/python3.6/site-packages/pymc3/sampling.py"", line 14, in <module>; from .plots.traceplot import traceplot; File ""/Users/cnorman/miniconda3/envs/gatk/lib/python3.6/site-packages/pymc3/plots/__init__.py"", line 1, in <module>; from .autocorrplot import autocorrplot; File ""/Users/cnorman/miniconda3/envs/gatk/lib/python3.6/site-packages/pymc3/plots/autocorrplot.py"", line 2, in <module>; import matplotlib.pyplot as plt; File ""/Users/cnorman/miniconda3/envs/gatk/lib/python3.6/site-packages/matplotlib/pyplot.py"", line 116, in <module>; _backend_mod, new_figure_manager, draw_if_interactive, _show = pylab_setup(); File ""/Users/cnorman/miniconda3/envs/gatk/lib/python3.6/site-packages/matplotlib/backends/__init__.py"", line 60, in pylab_setup; [backend_name], 0); File ""/Users/cnorman/miniconda3/envs/gatk/lib/python3.6/site-packages/matplotlib/backends/backend_macosx.py"", line 17, in <module>; from matplotlib.backends import _macosx; RuntimeError: Python is not installed as a framework. The Mac OS X backend will not be able to function correctly if Python is not installed as a framework. See the Python documentation for more information on installing Python as a framework on Mac OS X. Please either reinstall Python as a framework, or try one of the other backends. If you are using (Ana)Conda please install python.app and replace the use of 'python' with 'pythonw'. See 'Working with Matplotlib on OSX' in the Matplotlib FAQ for more information.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4087#issuecomment-356079886
https://github.com/broadinstitute/gatk/pull/4087#issuecomment-356079886:74,Testability,test,tests,74,"@mbabadi Thx. I think we need to take this, but have you actually run the tests on a Mac using this environment ? I can now create the environment with this change, but some of the python group tests fail when run from within it. If I just start Python with it activated and do ""import gcnvkernel"" or even ""import pymc3"", it fails. It might be a local issue - it would be comforting to know that we've actually solved the full problem and someone has successfully run from this env on a mac. >>> import gcnvkernel; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/Users/cnorman/miniconda3/envs/gatk/lib/python3.6/site-packages/gcnvkernel/__init__.py"", line 1, in <module>; from pymc3 import __version__ as pymc3_version; File ""/Users/cnorman/miniconda3/envs/gatk/lib/python3.6/site-packages/pymc3/__init__.py"", line 12, in <module>; from .sampling import *; File ""/Users/cnorman/miniconda3/envs/gatk/lib/python3.6/site-packages/pymc3/sampling.py"", line 14, in <module>; from .plots.traceplot import traceplot; File ""/Users/cnorman/miniconda3/envs/gatk/lib/python3.6/site-packages/pymc3/plots/__init__.py"", line 1, in <module>; from .autocorrplot import autocorrplot; File ""/Users/cnorman/miniconda3/envs/gatk/lib/python3.6/site-packages/pymc3/plots/autocorrplot.py"", line 2, in <module>; import matplotlib.pyplot as plt; File ""/Users/cnorman/miniconda3/envs/gatk/lib/python3.6/site-packages/matplotlib/pyplot.py"", line 116, in <module>; _backend_mod, new_figure_manager, draw_if_interactive, _show = pylab_setup(); File ""/Users/cnorman/miniconda3/envs/gatk/lib/python3.6/site-packages/matplotlib/backends/__init__.py"", line 60, in pylab_setup; [backend_name], 0); File ""/Users/cnorman/miniconda3/envs/gatk/lib/python3.6/site-packages/matplotlib/backends/backend_macosx.py"", line 17, in <module>; from matplotlib.backends import _macosx; RuntimeError: Python is not installed as a framework. The Mac OS X backend will not be able to function correctly if Python is not in",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4087#issuecomment-356079886
https://github.com/broadinstitute/gatk/pull/4087#issuecomment-356079886:194,Testability,test,tests,194,"@mbabadi Thx. I think we need to take this, but have you actually run the tests on a Mac using this environment ? I can now create the environment with this change, but some of the python group tests fail when run from within it. If I just start Python with it activated and do ""import gcnvkernel"" or even ""import pymc3"", it fails. It might be a local issue - it would be comforting to know that we've actually solved the full problem and someone has successfully run from this env on a mac. >>> import gcnvkernel; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/Users/cnorman/miniconda3/envs/gatk/lib/python3.6/site-packages/gcnvkernel/__init__.py"", line 1, in <module>; from pymc3 import __version__ as pymc3_version; File ""/Users/cnorman/miniconda3/envs/gatk/lib/python3.6/site-packages/pymc3/__init__.py"", line 12, in <module>; from .sampling import *; File ""/Users/cnorman/miniconda3/envs/gatk/lib/python3.6/site-packages/pymc3/sampling.py"", line 14, in <module>; from .plots.traceplot import traceplot; File ""/Users/cnorman/miniconda3/envs/gatk/lib/python3.6/site-packages/pymc3/plots/__init__.py"", line 1, in <module>; from .autocorrplot import autocorrplot; File ""/Users/cnorman/miniconda3/envs/gatk/lib/python3.6/site-packages/pymc3/plots/autocorrplot.py"", line 2, in <module>; import matplotlib.pyplot as plt; File ""/Users/cnorman/miniconda3/envs/gatk/lib/python3.6/site-packages/matplotlib/pyplot.py"", line 116, in <module>; _backend_mod, new_figure_manager, draw_if_interactive, _show = pylab_setup(); File ""/Users/cnorman/miniconda3/envs/gatk/lib/python3.6/site-packages/matplotlib/backends/__init__.py"", line 60, in pylab_setup; [backend_name], 0); File ""/Users/cnorman/miniconda3/envs/gatk/lib/python3.6/site-packages/matplotlib/backends/backend_macosx.py"", line 17, in <module>; from matplotlib.backends import _macosx; RuntimeError: Python is not installed as a framework. The Mac OS X backend will not be able to function correctly if Python is not in",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4087#issuecomment-356079886
https://github.com/broadinstitute/gatk/pull/4087#issuecomment-356109568:185,Deployability,install,installation,185,"@cmnbroad it turns out that this is a known issue of `matplotlib` on osx and conda environments: https://matplotlib.org/faq/osx_framework.html. On my MacBook, I used the base anaconda3 installation (which is ""installed as a framework"") and conda installed the required packages. When creating a virtual environment, however, the python is not installed as a framework on Mac and causes matplotlib to complain. One workaround is to (1) require the user to have an mini(ana)conda3 installation, and (2) on osx, use `pythonw` instead of `python` to execute python codes. The former is linked with a window manager library and supplies matplotlib with a GUI framework.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4087#issuecomment-356109568
https://github.com/broadinstitute/gatk/pull/4087#issuecomment-356109568:209,Deployability,install,installed,209,"@cmnbroad it turns out that this is a known issue of `matplotlib` on osx and conda environments: https://matplotlib.org/faq/osx_framework.html. On my MacBook, I used the base anaconda3 installation (which is ""installed as a framework"") and conda installed the required packages. When creating a virtual environment, however, the python is not installed as a framework on Mac and causes matplotlib to complain. One workaround is to (1) require the user to have an mini(ana)conda3 installation, and (2) on osx, use `pythonw` instead of `python` to execute python codes. The former is linked with a window manager library and supplies matplotlib with a GUI framework.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4087#issuecomment-356109568
https://github.com/broadinstitute/gatk/pull/4087#issuecomment-356109568:246,Deployability,install,installed,246,"@cmnbroad it turns out that this is a known issue of `matplotlib` on osx and conda environments: https://matplotlib.org/faq/osx_framework.html. On my MacBook, I used the base anaconda3 installation (which is ""installed as a framework"") and conda installed the required packages. When creating a virtual environment, however, the python is not installed as a framework on Mac and causes matplotlib to complain. One workaround is to (1) require the user to have an mini(ana)conda3 installation, and (2) on osx, use `pythonw` instead of `python` to execute python codes. The former is linked with a window manager library and supplies matplotlib with a GUI framework.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4087#issuecomment-356109568
https://github.com/broadinstitute/gatk/pull/4087#issuecomment-356109568:343,Deployability,install,installed,343,"@cmnbroad it turns out that this is a known issue of `matplotlib` on osx and conda environments: https://matplotlib.org/faq/osx_framework.html. On my MacBook, I used the base anaconda3 installation (which is ""installed as a framework"") and conda installed the required packages. When creating a virtual environment, however, the python is not installed as a framework on Mac and causes matplotlib to complain. One workaround is to (1) require the user to have an mini(ana)conda3 installation, and (2) on osx, use `pythonw` instead of `python` to execute python codes. The former is linked with a window manager library and supplies matplotlib with a GUI framework.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4087#issuecomment-356109568
https://github.com/broadinstitute/gatk/pull/4087#issuecomment-356109568:479,Deployability,install,installation,479,"@cmnbroad it turns out that this is a known issue of `matplotlib` on osx and conda environments: https://matplotlib.org/faq/osx_framework.html. On my MacBook, I used the base anaconda3 installation (which is ""installed as a framework"") and conda installed the required packages. When creating a virtual environment, however, the python is not installed as a framework on Mac and causes matplotlib to complain. One workaround is to (1) require the user to have an mini(ana)conda3 installation, and (2) on osx, use `pythonw` instead of `python` to execute python codes. The former is linked with a window manager library and supplies matplotlib with a GUI framework.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4087#issuecomment-356109568
https://github.com/broadinstitute/gatk/pull/4087#issuecomment-356110333:119,Deployability,install,installation-issue-with-matplotlib-python,119,"Yeah, there are a few stackoverflow and github threads about this issue.; https://stackoverflow.com/questions/21784641/installation-issue-with-matplotlib-python. I tried the suggestion there, and it resolved it. I wish I knew what introduced it though, because I previously was able to import gcnvkernel without doing this (though I don't recall when the last time I did so was):. Create a file ~/.matplotlib/matplotlibrc there and add the following code: backend: TkAgg",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4087#issuecomment-356110333
https://github.com/broadinstitute/gatk/pull/4087#issuecomment-356111971:514,Availability,failure,failure,514,"Ok, so I was able to run all the python tests using ~/.matplotlib/matplotlibrc. @mbabadi Wondering why you changed this to DO NOT MERGE. Do you have an alternative proposal ? Removing the libgcc-ng dependency doesn't solve the whole mac problem, but at least if we do remove it the workaround for the matplotlib part is easily conveyed. Also, @samuelklee @mbabadi, is there any visibility for end-users that they need to establish the conda env to run these tools (like in the doc summary, etc.). I'm guessing the failure mode for just running without the environment will be pretty cryptic.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4087#issuecomment-356111971
https://github.com/broadinstitute/gatk/pull/4087#issuecomment-356111971:198,Integrability,depend,dependency,198,"Ok, so I was able to run all the python tests using ~/.matplotlib/matplotlibrc. @mbabadi Wondering why you changed this to DO NOT MERGE. Do you have an alternative proposal ? Removing the libgcc-ng dependency doesn't solve the whole mac problem, but at least if we do remove it the workaround for the matplotlib part is easily conveyed. Also, @samuelklee @mbabadi, is there any visibility for end-users that they need to establish the conda env to run these tools (like in the doc summary, etc.). I'm guessing the failure mode for just running without the environment will be pretty cryptic.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4087#issuecomment-356111971
https://github.com/broadinstitute/gatk/pull/4087#issuecomment-356111971:40,Testability,test,tests,40,"Ok, so I was able to run all the python tests using ~/.matplotlib/matplotlibrc. @mbabadi Wondering why you changed this to DO NOT MERGE. Do you have an alternative proposal ? Removing the libgcc-ng dependency doesn't solve the whole mac problem, but at least if we do remove it the workaround for the matplotlib part is easily conveyed. Also, @samuelklee @mbabadi, is there any visibility for end-users that they need to establish the conda env to run these tools (like in the doc summary, etc.). I'm guessing the failure mode for just running without the environment will be pretty cryptic.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4087#issuecomment-356111971
https://github.com/broadinstitute/gatk/pull/4087#issuecomment-356113814:14,Testability,test,testing,14,"@cmnbroad I'm testing the alternative of using `pythonw` instead of `python`. It works on Mac. If also works on Linux (Docker), isn't it an easier fix?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4087#issuecomment-356113814
https://github.com/broadinstitute/gatk/pull/4087#issuecomment-356131086:85,Deployability,release,release,85,"Looks like this failed on travis. I think given that given the lateness of the hour (release wise), we might want to take the original change that removes the libgcc-ng dependency, since that passed on travis, and rely on the simple workarounds for osx, which we'll have to convey out-of-band. Anything that requires changing the docker image seems risky at this point, not to mention that the image is already at 5.2 gig, which is way over our desired target. @samuelklee Any thoughts on this ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4087#issuecomment-356131086
https://github.com/broadinstitute/gatk/pull/4087#issuecomment-356131086:169,Integrability,depend,dependency,169,"Looks like this failed on travis. I think given that given the lateness of the hour (release wise), we might want to take the original change that removes the libgcc-ng dependency, since that passed on travis, and rely on the simple workarounds for osx, which we'll have to convey out-of-band. Anything that requires changing the docker image seems risky at this point, not to mention that the image is already at 5.2 gig, which is way over our desired target. @samuelklee Any thoughts on this ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4087#issuecomment-356131086
https://github.com/broadinstitute/gatk/pull/4087#issuecomment-356131086:349,Safety,risk,risky,349,"Looks like this failed on travis. I think given that given the lateness of the hour (release wise), we might want to take the original change that removes the libgcc-ng dependency, since that passed on travis, and rely on the simple workarounds for osx, which we'll have to convey out-of-band. Anything that requires changing the docker image seems risky at this point, not to mention that the image is already at 5.2 gig, which is way over our desired target. @samuelklee Any thoughts on this ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4087#issuecomment-356131086
https://github.com/broadinstitute/gatk/pull/4087#issuecomment-356131086:226,Usability,simpl,simple,226,"Looks like this failed on travis. I think given that given the lateness of the hour (release wise), we might want to take the original change that removes the libgcc-ng dependency, since that passed on travis, and rely on the simple workarounds for osx, which we'll have to convey out-of-band. Anything that requires changing the docker image seems risky at this point, not to mention that the image is already at 5.2 gig, which is way over our desired target. @samuelklee Any thoughts on this ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4087#issuecomment-356131086
https://github.com/broadinstitute/gatk/pull/4087#issuecomment-356139074:161,Deployability,release,release,161,@cmnbroad @mbabadi Let’s go with the matplotlibrc workaround and add some documentation to the README and Javadoc for the tools. We can take a closer look after release.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4087#issuecomment-356139074
https://github.com/broadinstitute/gatk/pull/4091#issuecomment-356112798:1206,Deployability,pipeline,pipelines,1206,) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/f1e0349c2fc20df63a2f4e10b0288a0e25be0425?src=pr&el=desc) will **increase** coverage by `0.005%`.; > The diff coverage is `50%`. ```diff; @@ Coverage Diff @@; ## master #4091 +/- ##; ===============================================; + Coverage 78.999% 79.004% +0.005% ; - Complexity 16542 16543 +1 ; ===============================================; Files 1059 1059 ; Lines 59169 59169 ; Branches 9615 9615 ; ===============================================; + Hits 46743 46746 +3 ; + Misses 8687 8686 -1 ; + Partials 3739 3737 -2; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4091?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...stitute/hellbender/engine/spark/GATKSparkTool.java](https://codecov.io/gh/broadinstitute/gatk/pull/4091/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvR0FUS1NwYXJrVG9vbC5qYXZh) | `83.333% <0%> (ø)` | `56 <0> (ø)` | :arrow_down: |; | [...k/pipelines/BwaAndMarkDuplicatesPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4091/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQndhQW5kTWFya0R1cGxpY2F0ZXNQaXBlbGluZVNwYXJrLmphdmE=) | `78.947% <100%> (ø)` | `4 <0> (ø)` | :arrow_down: |; | [...er/tools/spark/sv/discovery/AlignmentInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/4091/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvQWxpZ25tZW50SW50ZXJ2YWwuamF2YQ==) | `91.064% <0%> (+0.851%)` | `65% <0%> (+1%)` | :arrow_up: |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/4091/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `90% <0%> (+10%)` | `3% <0%> (ø)` | :arrow_down: |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4091#issuecomment-356112798
https://github.com/broadinstitute/gatk/pull/4093#issuecomment-356107563:958,Usability,Simpl,SimpleInterval,958,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4093?src=pr&el=h1) Report; > Merging [#4093](https://codecov.io/gh/broadinstitute/gatk/pull/4093?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/e272a360493e7ec66876f86d61c58912381abf8d?src=pr&el=desc) will **increase** coverage by `0.003%`.; > The diff coverage is `85.714%`. ```diff; @@ Coverage Diff @@; ## master #4093 +/- ##; ===============================================; + Coverage 79.001% 79.004% +0.003% ; - Complexity 16539 16551 +12 ; ===============================================; Files 1056 1056 ; Lines 59183 59230 +47 ; Branches 9622 9633 +11 ; ===============================================; + Hits 46755 46794 +39 ; - Misses 8687 8691 +4 ; - Partials 3741 3745 +4; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4093?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...roadinstitute/hellbender/utils/SimpleInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/4093/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9TaW1wbGVJbnRlcnZhbC5qYXZh) | `93.182% <100%> (+0.078%)` | `48 <2> (+1)` | :arrow_up: |; | [...oadinstitute/hellbender/utils/GenomeLocParser.java](https://codecov.io/gh/broadinstitute/gatk/pull/4093/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9HZW5vbWVMb2NQYXJzZXIuamF2YQ==) | `84.848% <66.667%> (-5.234%)` | `57 <2> (ø)` | |; | [...broadinstitute/hellbender/utils/IntervalUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4093/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9JbnRlcnZhbFV0aWxzLmphdmE=) | `91.532% <91.429%> (-0.007%)` | `181 <9> (+8)` | |; | [...nder/utils/runtime/StreamingProcessController.java](https://codecov.io/gh/broadinstitute/gatk/pull/4093/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9ydW50aW1lL1N0cmVhbWl,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4093#issuecomment-356107563
https://github.com/broadinstitute/gatk/pull/4094#issuecomment-356110640:966,Security,Validat,ValidateBasicSomaticShortMutations,966,"I checked only the tools that are marked `no` in the `correct category in gatk --list` in the 0107Check_category_&_doc tab of https://docs.google.com/spreadsheets/d/19SvP6DHyXewm8Cd47WsM3NUku_czP2rkh4L_6fd-Nac/edit?usp=sharing. ## The following eight tools need fixing:. tool | category philosophically ok? | 2nd check, correct category in gatkDoc? | categorization fixed by https://github.com/broadinstitute/gatk/pull/4094?; -- | -- | -- | --; IndexFeatureFile | NO | y | no; still in Variant Manipulation but should be in Other.; CreateHadoopBamSplittingIndex | NO | y | no; still in Other but no longer with ConvertHeaderlessHadoopBamShardToBam; VariantAnnotator | y | DOES NOT SHOW UP | no; does not show up; FixCallsetSampleOrdering | MISSING | no | no; does not show up; DepthOfCoverage | y | DOES NOT SHOW UP | no; DiagnoseTargets | y | DOES NOT SHOW UP | no; GatherTranches | y | y | DOES NOT SHOW UP IN GATKDOC; shows up in correct category in gatk --list; ValidateBasicSomaticShortMutations | MISSING | no | DOES NOT SHOW UP IN GATKDOC; shows up in correct category in gatk --list. ## The following tools appear fixed by this PR:. tool | category philosophically ok? | 2nd check, correct category in gatkDoc? | categorization fixed by https://github.com/broadinstitute/gatk/pull/4094?; -- | -- | -- | --; CollectBaseDistributionByCycleSpark | y | y | y; ASEReadCounter | y | y | y; CountBases | y | y | y; CountBasesSpark | y | y | y; CountReads | y | y | y; CountReadsSpark | y | y | y; PileupSpark | y | y | y; CollectInsertSizeMetricsSpark | y | y | y; CollectMultipleMetricsSpark | y | y | y; CollectQualityYieldMetricsSpark | y | y | y; CompareBaseQualities | y | y | y; EstimateLibraryComplexityGATK | y | y | y; FilterLongReadAlignmentsSAMSpark | y | y | y; FlagStat | y | y | y; FlagStatSpark | y | y | y; MeanQualityByCycleSpark | y | y | y; QualityScoreDistributionSpark | y | y | y; GatherBQSRReports | y | y | y; ApplyBQSR | y | y | y; ApplyBQSRSpark | y | y | y; BaseRecalibrato",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4094#issuecomment-356110640
https://github.com/broadinstitute/gatk/pull/4094#issuecomment-356113187:1892,Deployability,pipeline,pipelines,1892,/variantutils/CalculateGenotypePosteriors.java](https://codecov.io/gh/broadinstitute/gatk/pull/4094/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9DYWxjdWxhdGVHZW5vdHlwZVBvc3RlcmlvcnMuamF2YQ==) | `85.915% <ø> (ø)` | `13 <0> (ø)` | :arrow_down: |; | [...stitute/hellbender/tools/HaplotypeCallerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4094/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9IYXBsb3R5cGVDYWxsZXJTcGFyay5qYXZh) | `82.022% <ø> (ø)` | `23 <0> (ø)` | :arrow_down: |; | [...tmutpileup/ValidateBasicSomaticShortMutations.java](https://codecov.io/gh/broadinstitute/gatk/pull/4094/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vYmFzaWNzaG9ydG11dHBpbGV1cC9WYWxpZGF0ZUJhc2ljU29tYXRpY1Nob3J0TXV0YXRpb25zLmphdmE=) | `85.965% <ø> (ø)` | `7 <0> (ø)` | :arrow_down: |; | [...pipelines/metrics/CollectMultipleMetricsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4094/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvbWV0cmljcy9Db2xsZWN0TXVsdGlwbGVNZXRyaWNzU3BhcmsuamF2YQ==) | `92.593% <ø> (ø)` | `9 <0> (ø)` | :arrow_down: |; | [...s/metrics/CollectBaseDistributionByCycleSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4094/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvbWV0cmljcy9Db2xsZWN0QmFzZURpc3RyaWJ1dGlvbkJ5Q3ljbGVTcGFyay5qYXZh) | `87.037% <ø> (ø)` | `9 <0> (ø)` | :arrow_down: |; | [...ute/hellbender/tools/FixCallSetSampleOrdering.java](https://codecov.io/gh/broadinstitute/gatk/pull/4094/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9GaXhDYWxsU2V0U2FtcGxlT3JkZXJpbmcuamF2YQ==) | `72.072% <ø> (ø)` | `24 <0> (ø)` | :arrow_down: |; | [...institute/hellbender/tools/spark/bwa/BwaSpark.java],MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4094#issuecomment-356113187
https://github.com/broadinstitute/gatk/pull/4094#issuecomment-356113187:3705,Deployability,pipeline,pipelines,3705,2xsZWN0TXVsdGlwbGVNZXRyaWNzU3BhcmsuamF2YQ==) | `92.593% <ø> (ø)` | `9 <0> (ø)` | :arrow_down: |; | [...s/metrics/CollectBaseDistributionByCycleSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4094/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvbWV0cmljcy9Db2xsZWN0QmFzZURpc3RyaWJ1dGlvbkJ5Q3ljbGVTcGFyay5qYXZh) | `87.037% <ø> (ø)` | `9 <0> (ø)` | :arrow_down: |; | [...ute/hellbender/tools/FixCallSetSampleOrdering.java](https://codecov.io/gh/broadinstitute/gatk/pull/4094/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9GaXhDYWxsU2V0U2FtcGxlT3JkZXJpbmcuamF2YQ==) | `72.072% <ø> (ø)` | `24 <0> (ø)` | :arrow_down: |; | [...institute/hellbender/tools/spark/bwa/BwaSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4094/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9id2EvQndhU3BhcmsuamF2YQ==) | `75% <ø> (ø)` | `5 <0> (ø)` | :arrow_down: |; | [...rg/broadinstitute/hellbender/tools/CountReads.java](https://codecov.io/gh/broadinstitute/gatk/pull/4094/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9Db3VudFJlYWRzLmphdmE=) | `100% <ø> (ø)` | `3 <0> (ø)` | :arrow_down: |; | [...org/broadinstitute/hellbender/tools/ClipReads.java](https://codecov.io/gh/broadinstitute/gatk/pull/4094/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9DbGlwUmVhZHMuamF2YQ==) | `90.385% <ø> (ø)` | `35 <0> (ø)` | :arrow_down: |; | [...ark/pipelines/metrics/MeanQualityByCycleSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4094/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvbWV0cmljcy9NZWFuUXVhbGl0eUJ5Q3ljbGVTcGFyay5qYXZh) | `90.816% <ø> (ø)` | `11 <0> (ø)` | :arrow_down: |; | ... and [46 more](https://codecov.io/gh/broadinstitute/gatk/pull/4094/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4094#issuecomment-356113187
https://github.com/broadinstitute/gatk/pull/4094#issuecomment-356113187:1542,Security,Validat,ValidateBasicSomaticShortMutations,1542,===================; Files 1059 1056 -3 ; Lines 59177 59149 -28 ; Branches 9616 9615 -1 ; ==============================================; - Hits 46750 46744 -6 ; + Misses 8689 8667 -22 ; Partials 3738 3738; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4094?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...kers/variantutils/CalculateGenotypePosteriors.java](https://codecov.io/gh/broadinstitute/gatk/pull/4094/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9DYWxjdWxhdGVHZW5vdHlwZVBvc3RlcmlvcnMuamF2YQ==) | `85.915% <ø> (ø)` | `13 <0> (ø)` | :arrow_down: |; | [...stitute/hellbender/tools/HaplotypeCallerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4094/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9IYXBsb3R5cGVDYWxsZXJTcGFyay5qYXZh) | `82.022% <ø> (ø)` | `23 <0> (ø)` | :arrow_down: |; | [...tmutpileup/ValidateBasicSomaticShortMutations.java](https://codecov.io/gh/broadinstitute/gatk/pull/4094/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vYmFzaWNzaG9ydG11dHBpbGV1cC9WYWxpZGF0ZUJhc2ljU29tYXRpY1Nob3J0TXV0YXRpb25zLmphdmE=) | `85.965% <ø> (ø)` | `7 <0> (ø)` | :arrow_down: |; | [...pipelines/metrics/CollectMultipleMetricsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4094/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvbWV0cmljcy9Db2xsZWN0TXVsdGlwbGVNZXRyaWNzU3BhcmsuamF2YQ==) | `92.593% <ø> (ø)` | `9 <0> (ø)` | :arrow_down: |; | [...s/metrics/CollectBaseDistributionByCycleSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4094/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvbWV0cmljcy9Db2xsZWN0QmFzZURpc3RyaWJ1dGlvbkJ5Q3ljbGVTcGFyay5qYXZh) | `87.037% <ø> (ø)` | `9 <0> (ø)` | :arrow_dow,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4094#issuecomment-356113187
https://github.com/broadinstitute/gatk/pull/4094#issuecomment-356120760:49,Testability,test,tests,49,"Ok, all done. I had to rebase again too. Pushed, tests running.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4094#issuecomment-356120760
https://github.com/broadinstitute/gatk/pull/4095#issuecomment-356133946:3102,Deployability,pipeline,pipelines,3102,(-0.91%)` | `15% <0%> (+6%)` | |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4095/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `75.258% <0%> (-0.252%)` | `17% <0%> (ø)` | |; | [...ry/prototype/FilterLongReadAlignmentsSAMSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4095/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvcHJvdG90eXBlL0ZpbHRlckxvbmdSZWFkQWxpZ25tZW50c1NBTVNwYXJrLmphdmE=) | `50.388% <0%> (ø)` | `28% <0%> (ø)` | :arrow_down: |; | [...er/tools/ConvertHeaderlessHadoopBamShardToBam.java](https://codecov.io/gh/broadinstitute/gatk/pull/4095/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9Db252ZXJ0SGVhZGVybGVzc0hhZG9vcEJhbVNoYXJkVG9CYW0uamF2YQ==) | `76.923% <0%> (ø)` | `2% <0%> (ø)` | :arrow_down: |; | [...lbender/tools/spark/pipelines/CountReadsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4095/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQ291bnRSZWFkc1NwYXJrLmphdmE=) | `90% <0%> (ø)` | `4% <0%> (ø)` | :arrow_down: |; | [...ute/hellbender/tools/FixCallSetSampleOrdering.java](https://codecov.io/gh/broadinstitute/gatk/pull/4095/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9GaXhDYWxsU2V0U2FtcGxlT3JkZXJpbmcuamF2YQ==) | `72.072% <0%> (ø)` | `24% <0%> (ø)` | :arrow_down: |; | [...rg/broadinstitute/hellbender/tools/CountReads.java](https://codecov.io/gh/broadinstitute/gatk/pull/4095/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9Db3VudFJlYWRzLmphdmE=) | `100% <0%> (ø)` | `3% <0%> (ø)` | :arrow_down: |; | ... and [34 more](https://codecov.io/gh/broadinstitute/gatk/pull/4095/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4095#issuecomment-356133946
https://github.com/broadinstitute/gatk/pull/4097#issuecomment-357995457:166,Testability,test,tests,166,"@lucidtronix I have a few comments on the on the java side of this, and want to do a review pass. Let me know if/when its ready for that (it may already be, now that tests are passing).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4097#issuecomment-357995457
https://github.com/broadinstitute/gatk/pull/4097#issuecomment-358429904:382,Testability,test,tests,382,"Responded to most of the comments, but still need to implement proper gatk style vcf writing from java. Also I copied @mbabadi's python package setup, but I havent been able to upload to pypi with setup_vqsr_cnn.py so for the time being I also have a setup.py inside the vqsr_cnn package which works with pypi, but hardcodes the version. I'm sure there is a better way. Some python tests failed but it seems to be a maven jar issue...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4097#issuecomment-358429904
https://github.com/broadinstitute/gatk/pull/4097#issuecomment-360524534:180,Safety,timeout,timeout,180,"@lucidtronix https://github.com/broadinstitute/gatk/pull/4218 is merged now so you should be able to rebase this on master. It looks like when you squashed you left in some of the timeout changes, so you'll have to resolve the resulting conflicts in favor of master.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4097#issuecomment-360524534
https://github.com/broadinstitute/gatk/pull/4097#issuecomment-360579001:25,Testability,test,tests,25,"Ok rebased on master, if tests pass do you think it's ready to merge?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4097#issuecomment-360579001
https://github.com/broadinstitute/gatk/pull/4097#issuecomment-360652766:259,Testability,test,tests,259,"@lucidtronix It looks like the StreamingPythonExecutorUnitTest and ProcessControllerUnitTest files are entirely removed now, instead of just being reverted (they had some stray changes included before). Those files need to be restored, then we can merge once tests pass again.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4097#issuecomment-360652766
https://github.com/broadinstitute/gatk/pull/4098#issuecomment-356266142:12,Integrability,message,message,12,"Old startup message:. ```; [January 9, 2018 6:01:50 AM EST] Executing as droazen@wmce6-e31 on Mac OS X 10.11.6 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_92-b14; Version: 4.beta.6-170-g9330d47-SNAPSHOT; HTSJDK Version: 2.13.2; Picard Version: 2.17.2; ```. New startup message:. ```; 07:02:34.565 INFO CountReads - ------------------------------------------------------------; 07:02:34.565 INFO CountReads - The Genome Analysis Toolkit (GATK) v4.beta.6-172-g929250b-SNAPSHOT; 07:02:34.565 INFO CountReads - For support and documentation go to https://software.broadinstitute.org/gatk/; 07:02:34.566 INFO CountReads - Executing as droazen@wmce6-e31 on Mac OS X v10.11.6 x86_64; 07:02:34.566 INFO CountReads - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_92-b14; 07:02:34.566 INFO CountReads - Start Date/Time: January 9, 2018 7:02:34 AM EST; 07:02:34.566 INFO CountReads - ------------------------------------------------------------; 07:02:34.566 INFO CountReads - ------------------------------------------------------------; 07:02:34.567 INFO CountReads - HTSJDK Version: 2.13.2; 07:02:34.567 INFO CountReads - Picard Version: 2.17.2; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4098#issuecomment-356266142
https://github.com/broadinstitute/gatk/pull/4098#issuecomment-356266142:273,Integrability,message,message,273,"Old startup message:. ```; [January 9, 2018 6:01:50 AM EST] Executing as droazen@wmce6-e31 on Mac OS X 10.11.6 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_92-b14; Version: 4.beta.6-170-g9330d47-SNAPSHOT; HTSJDK Version: 2.13.2; Picard Version: 2.17.2; ```. New startup message:. ```; 07:02:34.565 INFO CountReads - ------------------------------------------------------------; 07:02:34.565 INFO CountReads - The Genome Analysis Toolkit (GATK) v4.beta.6-172-g929250b-SNAPSHOT; 07:02:34.565 INFO CountReads - For support and documentation go to https://software.broadinstitute.org/gatk/; 07:02:34.566 INFO CountReads - Executing as droazen@wmce6-e31 on Mac OS X v10.11.6 x86_64; 07:02:34.566 INFO CountReads - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_92-b14; 07:02:34.566 INFO CountReads - Start Date/Time: January 9, 2018 7:02:34 AM EST; 07:02:34.566 INFO CountReads - ------------------------------------------------------------; 07:02:34.566 INFO CountReads - ------------------------------------------------------------; 07:02:34.567 INFO CountReads - HTSJDK Version: 2.13.2; 07:02:34.567 INFO CountReads - Picard Version: 2.17.2; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4098#issuecomment-356266142
https://github.com/broadinstitute/gatk/pull/4098#issuecomment-356290364:24,Availability,down,downstream,24,This is really nice for downstream projects! Thank you very much!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4098#issuecomment-356290364
https://github.com/broadinstitute/gatk/pull/4100#issuecomment-356297161:33,Deployability,release,release,33,"@magicDGS We're getting close to release time, so I'm afraid this will have to wait. Feel free to open a PR after 4.0 is out.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4100#issuecomment-356297161
https://github.com/broadinstitute/gatk/pull/4100#issuecomment-356297676:41,Deployability,release,releases,41,With which frequency will you make point-releases? I'm afraid that incompatibilities will make me stick to an unreleased GATK4 dependency!. I am preparing a PR at this moment to try to get it in!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4100#issuecomment-356297676
https://github.com/broadinstitute/gatk/pull/4100#issuecomment-356297676:127,Integrability,depend,dependency,127,With which frequency will you make point-releases? I'm afraid that incompatibilities will make me stick to an unreleased GATK4 dependency!. I am preparing a PR at this moment to try to get it in!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4100#issuecomment-356297676
https://github.com/broadinstitute/gatk/pull/4100#issuecomment-356314998:38,Deployability,release,releases,38,"Don't worry @magicDGS, I expect point releases will be pretty frequent, at least in the early days after the 4.0 release. I'd be very surprised if we don't do one within the next few weeks. Unfortunately our plate is full this morning and we can't accept any more patches before the release.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4100#issuecomment-356314998
https://github.com/broadinstitute/gatk/pull/4100#issuecomment-356314998:113,Deployability,release,release,113,"Don't worry @magicDGS, I expect point releases will be pretty frequent, at least in the early days after the 4.0 release. I'd be very surprised if we don't do one within the next few weeks. Unfortunately our plate is full this morning and we can't accept any more patches before the release.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4100#issuecomment-356314998
https://github.com/broadinstitute/gatk/pull/4100#issuecomment-356314998:264,Deployability,patch,patches,264,"Don't worry @magicDGS, I expect point releases will be pretty frequent, at least in the early days after the 4.0 release. I'd be very surprised if we don't do one within the next few weeks. Unfortunately our plate is full this morning and we can't accept any more patches before the release.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4100#issuecomment-356314998
https://github.com/broadinstitute/gatk/pull/4100#issuecomment-356314998:283,Deployability,release,release,283,"Don't worry @magicDGS, I expect point releases will be pretty frequent, at least in the early days after the 4.0 release. I'd be very surprised if we don't do one within the next few weeks. Unfortunately our plate is full this morning and we can't accept any more patches before the release.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4100#issuecomment-356314998
https://github.com/broadinstitute/gatk/issues/4101#issuecomment-381504458:236,Integrability,interface,interface,236,"I would like to have this feature for a new project that will rely on the built-in walkers of GATK. The main problem that I am facing is while grabbing the info from the METAINF file. For fixing this, I have a proposal:. * Create a new interface with the single method to print the startup message; * Create a base-class with the current code in GATK, which can be extended to override some parts of the startup message, but not all.; * Make a non-final static field in `CommandLineProgram` , which is settable. This could be set in the `Main` for toolkits (similarly to how the config file is set). The default will be the GATK implementation. If you agree with the proposal, let me know to implement it and submit a PR.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4101#issuecomment-381504458
https://github.com/broadinstitute/gatk/issues/4101#issuecomment-381504458:290,Integrability,message,message,290,"I would like to have this feature for a new project that will rely on the built-in walkers of GATK. The main problem that I am facing is while grabbing the info from the METAINF file. For fixing this, I have a proposal:. * Create a new interface with the single method to print the startup message; * Create a base-class with the current code in GATK, which can be extended to override some parts of the startup message, but not all.; * Make a non-final static field in `CommandLineProgram` , which is settable. This could be set in the `Main` for toolkits (similarly to how the config file is set). The default will be the GATK implementation. If you agree with the proposal, let me know to implement it and submit a PR.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4101#issuecomment-381504458
https://github.com/broadinstitute/gatk/issues/4101#issuecomment-381504458:412,Integrability,message,message,412,"I would like to have this feature for a new project that will rely on the built-in walkers of GATK. The main problem that I am facing is while grabbing the info from the METAINF file. For fixing this, I have a proposal:. * Create a new interface with the single method to print the startup message; * Create a base-class with the current code in GATK, which can be extended to override some parts of the startup message, but not all.; * Make a non-final static field in `CommandLineProgram` , which is settable. This could be set in the `Main` for toolkits (similarly to how the config file is set). The default will be the GATK implementation. If you agree with the proposal, let me know to implement it and submit a PR.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4101#issuecomment-381504458
https://github.com/broadinstitute/gatk/issues/4101#issuecomment-381504458:365,Modifiability,extend,extended,365,"I would like to have this feature for a new project that will rely on the built-in walkers of GATK. The main problem that I am facing is while grabbing the info from the METAINF file. For fixing this, I have a proposal:. * Create a new interface with the single method to print the startup message; * Create a base-class with the current code in GATK, which can be extended to override some parts of the startup message, but not all.; * Make a non-final static field in `CommandLineProgram` , which is settable. This could be set in the `Main` for toolkits (similarly to how the config file is set). The default will be the GATK implementation. If you agree with the proposal, let me know to implement it and submit a PR.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4101#issuecomment-381504458
https://github.com/broadinstitute/gatk/issues/4101#issuecomment-381504458:579,Modifiability,config,config,579,"I would like to have this feature for a new project that will rely on the built-in walkers of GATK. The main problem that I am facing is while grabbing the info from the METAINF file. For fixing this, I have a proposal:. * Create a new interface with the single method to print the startup message; * Create a base-class with the current code in GATK, which can be extended to override some parts of the startup message, but not all.; * Make a non-final static field in `CommandLineProgram` , which is settable. This could be set in the `Main` for toolkits (similarly to how the config file is set). The default will be the GATK implementation. If you agree with the proposal, let me know to implement it and submit a PR.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4101#issuecomment-381504458
https://github.com/broadinstitute/gatk/issues/4101#issuecomment-382900549:42,Usability,simpl,simple,42,@magicDGS I'd much prefer to keep this as simple as possible. It should be fairly easy to introduce a shim layer between the GATK walker classes and your tool classes that overrides whatever methods you'd like to customize. We could certainly consider changing the way the CommandLineProgram methods are factored if that helps.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4101#issuecomment-382900549
https://github.com/broadinstitute/gatk/issues/4101#issuecomment-382994646:359,Availability,down,downstream,359,"@cmnbroad - I am not concern about the methods, because they are perfectly configurable, and actually this issue is not that important for some of my projects (e.g., `ReadTools`), which does not use the base walker clases from GATK. Nevertheless, I guess that what @droazen is suggesting is quite important and I appreciate the interest for making better the downstream toolkits integration. Here, a real use case: I've just started to write a new toolkit that will use some walker classes from GATK (by now, `LocusWalker` or the `ReadSliderWalker` from #4682). With the current way of configuring the output, I will need to implement a layer for both walker classes (e.g., `MyLocusWalker` and `MyReadSliderWalker`) and use them in my implemented tools. In addition, I would like to bundle some tools from the GATK/Picard (`IndexFeatureFile `), but they would print inconsistent logs with the rest of my toolkits and they aren't overridable because the classes are final; thus, I would use a decorator over this tools to print the proper startup messages. After a while, I might implement a `VariantWalker`, which will require that I implement another layer (`MyVariantWalker`). Thus, I end up with a lot of naive classes implemented on top of the base walkers and wrappers around bundled GATK/Picard tools. This is very difficult to maintain, because if a change is done at the `CommandLineProgram` abstract class for the logging output (a new method, for example), I will need to update every naive class and wrapper if I bump the GATK version. In addition, extensions of my own toolkit (if any) would need to do the same, making the class-dependency tree so deep that it is difficult to follow (with GATK3, this problem was really driving me crazy when I tried to implement custom tools). On the other hand, there is another use case for the GATK itself: once barclay has a common class for CLP, GATK would be able to run directly Picard tools without the decorator; nevertheless, they will still n",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4101#issuecomment-382994646
https://github.com/broadinstitute/gatk/issues/4101#issuecomment-382994646:2169,Availability,down,downstream,2169,"e GATK/Picard (`IndexFeatureFile `), but they would print inconsistent logs with the rest of my toolkits and they aren't overridable because the classes are final; thus, I would use a decorator over this tools to print the proper startup messages. After a while, I might implement a `VariantWalker`, which will require that I implement another layer (`MyVariantWalker`). Thus, I end up with a lot of naive classes implemented on top of the base walkers and wrappers around bundled GATK/Picard tools. This is very difficult to maintain, because if a change is done at the `CommandLineProgram` abstract class for the logging output (a new method, for example), I will need to update every naive class and wrapper if I bump the GATK version. In addition, extensions of my own toolkit (if any) would need to do the same, making the class-dependency tree so deep that it is difficult to follow (with GATK3, this problem was really driving me crazy when I tried to implement custom tools). On the other hand, there is another use case for the GATK itself: once barclay has a common class for CLP, GATK would be able to run directly Picard tools without the decorator; nevertheless, they will still need it for the log output. This also gives me the impression that the configuration for the CLP output should be at the barclay level, to be shared between Picard/GATK/downstream toolkits to be able to combine them. I think that a way of managing that woul be a new field in the CLP consisting on an interface/abstract class, `CommandLineStartupFormatter`, with the same CLP methods for this kind of operations, that will be passed to the CLP on construction (in `Main`) and defaults to whatever base class is chosen. This will allow custom toolkits to override in their `Main` the formatter and thus make consistent the output of every tool. Another option is to use directly something like the Spring framework, but I think that it is quite complicated for API users without knowledge of Spring (like me).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4101#issuecomment-382994646
https://github.com/broadinstitute/gatk/issues/4101#issuecomment-382994646:379,Deployability,integrat,integration,379,"@cmnbroad - I am not concern about the methods, because they are perfectly configurable, and actually this issue is not that important for some of my projects (e.g., `ReadTools`), which does not use the base walker clases from GATK. Nevertheless, I guess that what @droazen is suggesting is quite important and I appreciate the interest for making better the downstream toolkits integration. Here, a real use case: I've just started to write a new toolkit that will use some walker classes from GATK (by now, `LocusWalker` or the `ReadSliderWalker` from #4682). With the current way of configuring the output, I will need to implement a layer for both walker classes (e.g., `MyLocusWalker` and `MyReadSliderWalker`) and use them in my implemented tools. In addition, I would like to bundle some tools from the GATK/Picard (`IndexFeatureFile `), but they would print inconsistent logs with the rest of my toolkits and they aren't overridable because the classes are final; thus, I would use a decorator over this tools to print the proper startup messages. After a while, I might implement a `VariantWalker`, which will require that I implement another layer (`MyVariantWalker`). Thus, I end up with a lot of naive classes implemented on top of the base walkers and wrappers around bundled GATK/Picard tools. This is very difficult to maintain, because if a change is done at the `CommandLineProgram` abstract class for the logging output (a new method, for example), I will need to update every naive class and wrapper if I bump the GATK version. In addition, extensions of my own toolkit (if any) would need to do the same, making the class-dependency tree so deep that it is difficult to follow (with GATK3, this problem was really driving me crazy when I tried to implement custom tools). On the other hand, there is another use case for the GATK itself: once barclay has a common class for CLP, GATK would be able to run directly Picard tools without the decorator; nevertheless, they will still n",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4101#issuecomment-382994646
https://github.com/broadinstitute/gatk/issues/4101#issuecomment-382994646:1482,Deployability,update,update,1482,"tarted to write a new toolkit that will use some walker classes from GATK (by now, `LocusWalker` or the `ReadSliderWalker` from #4682). With the current way of configuring the output, I will need to implement a layer for both walker classes (e.g., `MyLocusWalker` and `MyReadSliderWalker`) and use them in my implemented tools. In addition, I would like to bundle some tools from the GATK/Picard (`IndexFeatureFile `), but they would print inconsistent logs with the rest of my toolkits and they aren't overridable because the classes are final; thus, I would use a decorator over this tools to print the proper startup messages. After a while, I might implement a `VariantWalker`, which will require that I implement another layer (`MyVariantWalker`). Thus, I end up with a lot of naive classes implemented on top of the base walkers and wrappers around bundled GATK/Picard tools. This is very difficult to maintain, because if a change is done at the `CommandLineProgram` abstract class for the logging output (a new method, for example), I will need to update every naive class and wrapper if I bump the GATK version. In addition, extensions of my own toolkit (if any) would need to do the same, making the class-dependency tree so deep that it is difficult to follow (with GATK3, this problem was really driving me crazy when I tried to implement custom tools). On the other hand, there is another use case for the GATK itself: once barclay has a common class for CLP, GATK would be able to run directly Picard tools without the decorator; nevertheless, they will still need it for the log output. This also gives me the impression that the configuration for the CLP output should be at the barclay level, to be shared between Picard/GATK/downstream toolkits to be able to combine them. I think that a way of managing that woul be a new field in the CLP consisting on an interface/abstract class, `CommandLineStartupFormatter`, with the same CLP methods for this kind of operations, that will be p",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4101#issuecomment-382994646
https://github.com/broadinstitute/gatk/issues/4101#issuecomment-382994646:2071,Deployability,configurat,configuration,2071,"e GATK/Picard (`IndexFeatureFile `), but they would print inconsistent logs with the rest of my toolkits and they aren't overridable because the classes are final; thus, I would use a decorator over this tools to print the proper startup messages. After a while, I might implement a `VariantWalker`, which will require that I implement another layer (`MyVariantWalker`). Thus, I end up with a lot of naive classes implemented on top of the base walkers and wrappers around bundled GATK/Picard tools. This is very difficult to maintain, because if a change is done at the `CommandLineProgram` abstract class for the logging output (a new method, for example), I will need to update every naive class and wrapper if I bump the GATK version. In addition, extensions of my own toolkit (if any) would need to do the same, making the class-dependency tree so deep that it is difficult to follow (with GATK3, this problem was really driving me crazy when I tried to implement custom tools). On the other hand, there is another use case for the GATK itself: once barclay has a common class for CLP, GATK would be able to run directly Picard tools without the decorator; nevertheless, they will still need it for the log output. This also gives me the impression that the configuration for the CLP output should be at the barclay level, to be shared between Picard/GATK/downstream toolkits to be able to combine them. I think that a way of managing that woul be a new field in the CLP consisting on an interface/abstract class, `CommandLineStartupFormatter`, with the same CLP methods for this kind of operations, that will be passed to the CLP on construction (in `Main`) and defaults to whatever base class is chosen. This will allow custom toolkits to override in their `Main` the formatter and thus make consistent the output of every tool. Another option is to use directly something like the Spring framework, but I think that it is quite complicated for API users without knowledge of Spring (like me).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4101#issuecomment-382994646
https://github.com/broadinstitute/gatk/issues/4101#issuecomment-382994646:379,Integrability,integrat,integration,379,"@cmnbroad - I am not concern about the methods, because they are perfectly configurable, and actually this issue is not that important for some of my projects (e.g., `ReadTools`), which does not use the base walker clases from GATK. Nevertheless, I guess that what @droazen is suggesting is quite important and I appreciate the interest for making better the downstream toolkits integration. Here, a real use case: I've just started to write a new toolkit that will use some walker classes from GATK (by now, `LocusWalker` or the `ReadSliderWalker` from #4682). With the current way of configuring the output, I will need to implement a layer for both walker classes (e.g., `MyLocusWalker` and `MyReadSliderWalker`) and use them in my implemented tools. In addition, I would like to bundle some tools from the GATK/Picard (`IndexFeatureFile `), but they would print inconsistent logs with the rest of my toolkits and they aren't overridable because the classes are final; thus, I would use a decorator over this tools to print the proper startup messages. After a while, I might implement a `VariantWalker`, which will require that I implement another layer (`MyVariantWalker`). Thus, I end up with a lot of naive classes implemented on top of the base walkers and wrappers around bundled GATK/Picard tools. This is very difficult to maintain, because if a change is done at the `CommandLineProgram` abstract class for the logging output (a new method, for example), I will need to update every naive class and wrapper if I bump the GATK version. In addition, extensions of my own toolkit (if any) would need to do the same, making the class-dependency tree so deep that it is difficult to follow (with GATK3, this problem was really driving me crazy when I tried to implement custom tools). On the other hand, there is another use case for the GATK itself: once barclay has a common class for CLP, GATK would be able to run directly Picard tools without the decorator; nevertheless, they will still n",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4101#issuecomment-382994646
https://github.com/broadinstitute/gatk/issues/4101#issuecomment-382994646:1046,Integrability,message,messages,1046,"@cmnbroad - I am not concern about the methods, because they are perfectly configurable, and actually this issue is not that important for some of my projects (e.g., `ReadTools`), which does not use the base walker clases from GATK. Nevertheless, I guess that what @droazen is suggesting is quite important and I appreciate the interest for making better the downstream toolkits integration. Here, a real use case: I've just started to write a new toolkit that will use some walker classes from GATK (by now, `LocusWalker` or the `ReadSliderWalker` from #4682). With the current way of configuring the output, I will need to implement a layer for both walker classes (e.g., `MyLocusWalker` and `MyReadSliderWalker`) and use them in my implemented tools. In addition, I would like to bundle some tools from the GATK/Picard (`IndexFeatureFile `), but they would print inconsistent logs with the rest of my toolkits and they aren't overridable because the classes are final; thus, I would use a decorator over this tools to print the proper startup messages. After a while, I might implement a `VariantWalker`, which will require that I implement another layer (`MyVariantWalker`). Thus, I end up with a lot of naive classes implemented on top of the base walkers and wrappers around bundled GATK/Picard tools. This is very difficult to maintain, because if a change is done at the `CommandLineProgram` abstract class for the logging output (a new method, for example), I will need to update every naive class and wrapper if I bump the GATK version. In addition, extensions of my own toolkit (if any) would need to do the same, making the class-dependency tree so deep that it is difficult to follow (with GATK3, this problem was really driving me crazy when I tried to implement custom tools). On the other hand, there is another use case for the GATK itself: once barclay has a common class for CLP, GATK would be able to run directly Picard tools without the decorator; nevertheless, they will still n",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4101#issuecomment-382994646
https://github.com/broadinstitute/gatk/issues/4101#issuecomment-382994646:1265,Integrability,wrap,wrappers,1265,"ess, I guess that what @droazen is suggesting is quite important and I appreciate the interest for making better the downstream toolkits integration. Here, a real use case: I've just started to write a new toolkit that will use some walker classes from GATK (by now, `LocusWalker` or the `ReadSliderWalker` from #4682). With the current way of configuring the output, I will need to implement a layer for both walker classes (e.g., `MyLocusWalker` and `MyReadSliderWalker`) and use them in my implemented tools. In addition, I would like to bundle some tools from the GATK/Picard (`IndexFeatureFile `), but they would print inconsistent logs with the rest of my toolkits and they aren't overridable because the classes are final; thus, I would use a decorator over this tools to print the proper startup messages. After a while, I might implement a `VariantWalker`, which will require that I implement another layer (`MyVariantWalker`). Thus, I end up with a lot of naive classes implemented on top of the base walkers and wrappers around bundled GATK/Picard tools. This is very difficult to maintain, because if a change is done at the `CommandLineProgram` abstract class for the logging output (a new method, for example), I will need to update every naive class and wrapper if I bump the GATK version. In addition, extensions of my own toolkit (if any) would need to do the same, making the class-dependency tree so deep that it is difficult to follow (with GATK3, this problem was really driving me crazy when I tried to implement custom tools). On the other hand, there is another use case for the GATK itself: once barclay has a common class for CLP, GATK would be able to run directly Picard tools without the decorator; nevertheless, they will still need it for the log output. This also gives me the impression that the configuration for the CLP output should be at the barclay level, to be shared between Picard/GATK/downstream toolkits to be able to combine them. I think that a way of mana",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4101#issuecomment-382994646
https://github.com/broadinstitute/gatk/issues/4101#issuecomment-382994646:1511,Integrability,wrap,wrapper,1511,"tarted to write a new toolkit that will use some walker classes from GATK (by now, `LocusWalker` or the `ReadSliderWalker` from #4682). With the current way of configuring the output, I will need to implement a layer for both walker classes (e.g., `MyLocusWalker` and `MyReadSliderWalker`) and use them in my implemented tools. In addition, I would like to bundle some tools from the GATK/Picard (`IndexFeatureFile `), but they would print inconsistent logs with the rest of my toolkits and they aren't overridable because the classes are final; thus, I would use a decorator over this tools to print the proper startup messages. After a while, I might implement a `VariantWalker`, which will require that I implement another layer (`MyVariantWalker`). Thus, I end up with a lot of naive classes implemented on top of the base walkers and wrappers around bundled GATK/Picard tools. This is very difficult to maintain, because if a change is done at the `CommandLineProgram` abstract class for the logging output (a new method, for example), I will need to update every naive class and wrapper if I bump the GATK version. In addition, extensions of my own toolkit (if any) would need to do the same, making the class-dependency tree so deep that it is difficult to follow (with GATK3, this problem was really driving me crazy when I tried to implement custom tools). On the other hand, there is another use case for the GATK itself: once barclay has a common class for CLP, GATK would be able to run directly Picard tools without the decorator; nevertheless, they will still need it for the log output. This also gives me the impression that the configuration for the CLP output should be at the barclay level, to be shared between Picard/GATK/downstream toolkits to be able to combine them. I think that a way of managing that woul be a new field in the CLP consisting on an interface/abstract class, `CommandLineStartupFormatter`, with the same CLP methods for this kind of operations, that will be p",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4101#issuecomment-382994646
https://github.com/broadinstitute/gatk/issues/4101#issuecomment-382994646:1642,Integrability,depend,dependency,1642,"e.g., `MyLocusWalker` and `MyReadSliderWalker`) and use them in my implemented tools. In addition, I would like to bundle some tools from the GATK/Picard (`IndexFeatureFile `), but they would print inconsistent logs with the rest of my toolkits and they aren't overridable because the classes are final; thus, I would use a decorator over this tools to print the proper startup messages. After a while, I might implement a `VariantWalker`, which will require that I implement another layer (`MyVariantWalker`). Thus, I end up with a lot of naive classes implemented on top of the base walkers and wrappers around bundled GATK/Picard tools. This is very difficult to maintain, because if a change is done at the `CommandLineProgram` abstract class for the logging output (a new method, for example), I will need to update every naive class and wrapper if I bump the GATK version. In addition, extensions of my own toolkit (if any) would need to do the same, making the class-dependency tree so deep that it is difficult to follow (with GATK3, this problem was really driving me crazy when I tried to implement custom tools). On the other hand, there is another use case for the GATK itself: once barclay has a common class for CLP, GATK would be able to run directly Picard tools without the decorator; nevertheless, they will still need it for the log output. This also gives me the impression that the configuration for the CLP output should be at the barclay level, to be shared between Picard/GATK/downstream toolkits to be able to combine them. I think that a way of managing that woul be a new field in the CLP consisting on an interface/abstract class, `CommandLineStartupFormatter`, with the same CLP methods for this kind of operations, that will be passed to the CLP on construction (in `Main`) and defaults to whatever base class is chosen. This will allow custom toolkits to override in their `Main` the formatter and thus make consistent the output of every tool. Another option is to use ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4101#issuecomment-382994646
https://github.com/broadinstitute/gatk/issues/4101#issuecomment-382994646:2301,Integrability,interface,interface,2301,"e GATK/Picard (`IndexFeatureFile `), but they would print inconsistent logs with the rest of my toolkits and they aren't overridable because the classes are final; thus, I would use a decorator over this tools to print the proper startup messages. After a while, I might implement a `VariantWalker`, which will require that I implement another layer (`MyVariantWalker`). Thus, I end up with a lot of naive classes implemented on top of the base walkers and wrappers around bundled GATK/Picard tools. This is very difficult to maintain, because if a change is done at the `CommandLineProgram` abstract class for the logging output (a new method, for example), I will need to update every naive class and wrapper if I bump the GATK version. In addition, extensions of my own toolkit (if any) would need to do the same, making the class-dependency tree so deep that it is difficult to follow (with GATK3, this problem was really driving me crazy when I tried to implement custom tools). On the other hand, there is another use case for the GATK itself: once barclay has a common class for CLP, GATK would be able to run directly Picard tools without the decorator; nevertheless, they will still need it for the log output. This also gives me the impression that the configuration for the CLP output should be at the barclay level, to be shared between Picard/GATK/downstream toolkits to be able to combine them. I think that a way of managing that woul be a new field in the CLP consisting on an interface/abstract class, `CommandLineStartupFormatter`, with the same CLP methods for this kind of operations, that will be passed to the CLP on construction (in `Main`) and defaults to whatever base class is chosen. This will allow custom toolkits to override in their `Main` the formatter and thus make consistent the output of every tool. Another option is to use directly something like the Spring framework, but I think that it is quite complicated for API users without knowledge of Spring (like me).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4101#issuecomment-382994646
https://github.com/broadinstitute/gatk/issues/4101#issuecomment-382994646:75,Modifiability,config,configurable,75,"@cmnbroad - I am not concern about the methods, because they are perfectly configurable, and actually this issue is not that important for some of my projects (e.g., `ReadTools`), which does not use the base walker clases from GATK. Nevertheless, I guess that what @droazen is suggesting is quite important and I appreciate the interest for making better the downstream toolkits integration. Here, a real use case: I've just started to write a new toolkit that will use some walker classes from GATK (by now, `LocusWalker` or the `ReadSliderWalker` from #4682). With the current way of configuring the output, I will need to implement a layer for both walker classes (e.g., `MyLocusWalker` and `MyReadSliderWalker`) and use them in my implemented tools. In addition, I would like to bundle some tools from the GATK/Picard (`IndexFeatureFile `), but they would print inconsistent logs with the rest of my toolkits and they aren't overridable because the classes are final; thus, I would use a decorator over this tools to print the proper startup messages. After a while, I might implement a `VariantWalker`, which will require that I implement another layer (`MyVariantWalker`). Thus, I end up with a lot of naive classes implemented on top of the base walkers and wrappers around bundled GATK/Picard tools. This is very difficult to maintain, because if a change is done at the `CommandLineProgram` abstract class for the logging output (a new method, for example), I will need to update every naive class and wrapper if I bump the GATK version. In addition, extensions of my own toolkit (if any) would need to do the same, making the class-dependency tree so deep that it is difficult to follow (with GATK3, this problem was really driving me crazy when I tried to implement custom tools). On the other hand, there is another use case for the GATK itself: once barclay has a common class for CLP, GATK would be able to run directly Picard tools without the decorator; nevertheless, they will still n",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4101#issuecomment-382994646
https://github.com/broadinstitute/gatk/issues/4101#issuecomment-382994646:586,Modifiability,config,configuring,586,"@cmnbroad - I am not concern about the methods, because they are perfectly configurable, and actually this issue is not that important for some of my projects (e.g., `ReadTools`), which does not use the base walker clases from GATK. Nevertheless, I guess that what @droazen is suggesting is quite important and I appreciate the interest for making better the downstream toolkits integration. Here, a real use case: I've just started to write a new toolkit that will use some walker classes from GATK (by now, `LocusWalker` or the `ReadSliderWalker` from #4682). With the current way of configuring the output, I will need to implement a layer for both walker classes (e.g., `MyLocusWalker` and `MyReadSliderWalker`) and use them in my implemented tools. In addition, I would like to bundle some tools from the GATK/Picard (`IndexFeatureFile `), but they would print inconsistent logs with the rest of my toolkits and they aren't overridable because the classes are final; thus, I would use a decorator over this tools to print the proper startup messages. After a while, I might implement a `VariantWalker`, which will require that I implement another layer (`MyVariantWalker`). Thus, I end up with a lot of naive classes implemented on top of the base walkers and wrappers around bundled GATK/Picard tools. This is very difficult to maintain, because if a change is done at the `CommandLineProgram` abstract class for the logging output (a new method, for example), I will need to update every naive class and wrapper if I bump the GATK version. In addition, extensions of my own toolkit (if any) would need to do the same, making the class-dependency tree so deep that it is difficult to follow (with GATK3, this problem was really driving me crazy when I tried to implement custom tools). On the other hand, there is another use case for the GATK itself: once barclay has a common class for CLP, GATK would be able to run directly Picard tools without the decorator; nevertheless, they will still n",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4101#issuecomment-382994646
https://github.com/broadinstitute/gatk/issues/4101#issuecomment-382994646:2071,Modifiability,config,configuration,2071,"e GATK/Picard (`IndexFeatureFile `), but they would print inconsistent logs with the rest of my toolkits and they aren't overridable because the classes are final; thus, I would use a decorator over this tools to print the proper startup messages. After a while, I might implement a `VariantWalker`, which will require that I implement another layer (`MyVariantWalker`). Thus, I end up with a lot of naive classes implemented on top of the base walkers and wrappers around bundled GATK/Picard tools. This is very difficult to maintain, because if a change is done at the `CommandLineProgram` abstract class for the logging output (a new method, for example), I will need to update every naive class and wrapper if I bump the GATK version. In addition, extensions of my own toolkit (if any) would need to do the same, making the class-dependency tree so deep that it is difficult to follow (with GATK3, this problem was really driving me crazy when I tried to implement custom tools). On the other hand, there is another use case for the GATK itself: once barclay has a common class for CLP, GATK would be able to run directly Picard tools without the decorator; nevertheless, they will still need it for the log output. This also gives me the impression that the configuration for the CLP output should be at the barclay level, to be shared between Picard/GATK/downstream toolkits to be able to combine them. I think that a way of managing that woul be a new field in the CLP consisting on an interface/abstract class, `CommandLineStartupFormatter`, with the same CLP methods for this kind of operations, that will be passed to the CLP on construction (in `Main`) and defaults to whatever base class is chosen. This will allow custom toolkits to override in their `Main` the formatter and thus make consistent the output of every tool. Another option is to use directly something like the Spring framework, but I think that it is quite complicated for API users without knowledge of Spring (like me).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4101#issuecomment-382994646
https://github.com/broadinstitute/gatk/issues/4101#issuecomment-382994646:879,Testability,log,logs,879,"@cmnbroad - I am not concern about the methods, because they are perfectly configurable, and actually this issue is not that important for some of my projects (e.g., `ReadTools`), which does not use the base walker clases from GATK. Nevertheless, I guess that what @droazen is suggesting is quite important and I appreciate the interest for making better the downstream toolkits integration. Here, a real use case: I've just started to write a new toolkit that will use some walker classes from GATK (by now, `LocusWalker` or the `ReadSliderWalker` from #4682). With the current way of configuring the output, I will need to implement a layer for both walker classes (e.g., `MyLocusWalker` and `MyReadSliderWalker`) and use them in my implemented tools. In addition, I would like to bundle some tools from the GATK/Picard (`IndexFeatureFile `), but they would print inconsistent logs with the rest of my toolkits and they aren't overridable because the classes are final; thus, I would use a decorator over this tools to print the proper startup messages. After a while, I might implement a `VariantWalker`, which will require that I implement another layer (`MyVariantWalker`). Thus, I end up with a lot of naive classes implemented on top of the base walkers and wrappers around bundled GATK/Picard tools. This is very difficult to maintain, because if a change is done at the `CommandLineProgram` abstract class for the logging output (a new method, for example), I will need to update every naive class and wrapper if I bump the GATK version. In addition, extensions of my own toolkit (if any) would need to do the same, making the class-dependency tree so deep that it is difficult to follow (with GATK3, this problem was really driving me crazy when I tried to implement custom tools). On the other hand, there is another use case for the GATK itself: once barclay has a common class for CLP, GATK would be able to run directly Picard tools without the decorator; nevertheless, they will still n",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4101#issuecomment-382994646
https://github.com/broadinstitute/gatk/issues/4101#issuecomment-382994646:1423,Testability,log,logging,1423,"tarted to write a new toolkit that will use some walker classes from GATK (by now, `LocusWalker` or the `ReadSliderWalker` from #4682). With the current way of configuring the output, I will need to implement a layer for both walker classes (e.g., `MyLocusWalker` and `MyReadSliderWalker`) and use them in my implemented tools. In addition, I would like to bundle some tools from the GATK/Picard (`IndexFeatureFile `), but they would print inconsistent logs with the rest of my toolkits and they aren't overridable because the classes are final; thus, I would use a decorator over this tools to print the proper startup messages. After a while, I might implement a `VariantWalker`, which will require that I implement another layer (`MyVariantWalker`). Thus, I end up with a lot of naive classes implemented on top of the base walkers and wrappers around bundled GATK/Picard tools. This is very difficult to maintain, because if a change is done at the `CommandLineProgram` abstract class for the logging output (a new method, for example), I will need to update every naive class and wrapper if I bump the GATK version. In addition, extensions of my own toolkit (if any) would need to do the same, making the class-dependency tree so deep that it is difficult to follow (with GATK3, this problem was really driving me crazy when I tried to implement custom tools). On the other hand, there is another use case for the GATK itself: once barclay has a common class for CLP, GATK would be able to run directly Picard tools without the decorator; nevertheless, they will still need it for the log output. This also gives me the impression that the configuration for the CLP output should be at the barclay level, to be shared between Picard/GATK/downstream toolkits to be able to combine them. I think that a way of managing that woul be a new field in the CLP consisting on an interface/abstract class, `CommandLineStartupFormatter`, with the same CLP methods for this kind of operations, that will be p",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4101#issuecomment-382994646
https://github.com/broadinstitute/gatk/issues/4101#issuecomment-382994646:2016,Testability,log,log,2016,"e GATK/Picard (`IndexFeatureFile `), but they would print inconsistent logs with the rest of my toolkits and they aren't overridable because the classes are final; thus, I would use a decorator over this tools to print the proper startup messages. After a while, I might implement a `VariantWalker`, which will require that I implement another layer (`MyVariantWalker`). Thus, I end up with a lot of naive classes implemented on top of the base walkers and wrappers around bundled GATK/Picard tools. This is very difficult to maintain, because if a change is done at the `CommandLineProgram` abstract class for the logging output (a new method, for example), I will need to update every naive class and wrapper if I bump the GATK version. In addition, extensions of my own toolkit (if any) would need to do the same, making the class-dependency tree so deep that it is difficult to follow (with GATK3, this problem was really driving me crazy when I tried to implement custom tools). On the other hand, there is another use case for the GATK itself: once barclay has a common class for CLP, GATK would be able to run directly Picard tools without the decorator; nevertheless, they will still need it for the log output. This also gives me the impression that the configuration for the CLP output should be at the barclay level, to be shared between Picard/GATK/downstream toolkits to be able to combine them. I think that a way of managing that woul be a new field in the CLP consisting on an interface/abstract class, `CommandLineStartupFormatter`, with the same CLP methods for this kind of operations, that will be passed to the CLP on construction (in `Main`) and defaults to whatever base class is chosen. This will allow custom toolkits to override in their `Main` the formatter and thus make consistent the output of every tool. Another option is to use directly something like the Spring framework, but I think that it is quite complicated for API users without knowledge of Spring (like me).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4101#issuecomment-382994646
https://github.com/broadinstitute/gatk/pull/4103#issuecomment-359751419:56,Usability,simpl,simple,56,"@droazen - can you have a look to this one? It is quite simple, for organizing argument constants better (it will be super helpful for me for transition to the kebab-case arguments, which is a hight priority for me at the moment). Thank you!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4103#issuecomment-359751419
https://github.com/broadinstitute/gatk/pull/4103#issuecomment-360806542:321,Availability,error,error,321,"I also just noticed that tests are failing on the branch because they still reference the old constants in a number of places:. ```; symbol: variable READ_NAME_LONG_NAME; location: class ReadNameReadFilter; /gatk/src/test/java/org/broadinstitute/hellbender/cmdline/GATKPlugin/GATKReadFilterPluginDescriptorTest.java:117: error: cannot find symbol; { PlatformReadFilter.class.getSimpleName(), ""--"" + PlatformReadFilter.PL_FILTER_NAME_LONG_NAME, ""fakePlatform"" }, ; ```. You'll need to update these references in order to get tests passing.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4103#issuecomment-360806542
https://github.com/broadinstitute/gatk/pull/4103#issuecomment-360806542:484,Deployability,update,update,484,"I also just noticed that tests are failing on the branch because they still reference the old constants in a number of places:. ```; symbol: variable READ_NAME_LONG_NAME; location: class ReadNameReadFilter; /gatk/src/test/java/org/broadinstitute/hellbender/cmdline/GATKPlugin/GATKReadFilterPluginDescriptorTest.java:117: error: cannot find symbol; { PlatformReadFilter.class.getSimpleName(), ""--"" + PlatformReadFilter.PL_FILTER_NAME_LONG_NAME, ""fakePlatform"" }, ; ```. You'll need to update these references in order to get tests passing.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4103#issuecomment-360806542
https://github.com/broadinstitute/gatk/pull/4103#issuecomment-360806542:141,Modifiability,variab,variable,141,"I also just noticed that tests are failing on the branch because they still reference the old constants in a number of places:. ```; symbol: variable READ_NAME_LONG_NAME; location: class ReadNameReadFilter; /gatk/src/test/java/org/broadinstitute/hellbender/cmdline/GATKPlugin/GATKReadFilterPluginDescriptorTest.java:117: error: cannot find symbol; { PlatformReadFilter.class.getSimpleName(), ""--"" + PlatformReadFilter.PL_FILTER_NAME_LONG_NAME, ""fakePlatform"" }, ; ```. You'll need to update these references in order to get tests passing.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4103#issuecomment-360806542
https://github.com/broadinstitute/gatk/pull/4103#issuecomment-360806542:25,Testability,test,tests,25,"I also just noticed that tests are failing on the branch because they still reference the old constants in a number of places:. ```; symbol: variable READ_NAME_LONG_NAME; location: class ReadNameReadFilter; /gatk/src/test/java/org/broadinstitute/hellbender/cmdline/GATKPlugin/GATKReadFilterPluginDescriptorTest.java:117: error: cannot find symbol; { PlatformReadFilter.class.getSimpleName(), ""--"" + PlatformReadFilter.PL_FILTER_NAME_LONG_NAME, ""fakePlatform"" }, ; ```. You'll need to update these references in order to get tests passing.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4103#issuecomment-360806542
https://github.com/broadinstitute/gatk/pull/4103#issuecomment-360806542:217,Testability,test,test,217,"I also just noticed that tests are failing on the branch because they still reference the old constants in a number of places:. ```; symbol: variable READ_NAME_LONG_NAME; location: class ReadNameReadFilter; /gatk/src/test/java/org/broadinstitute/hellbender/cmdline/GATKPlugin/GATKReadFilterPluginDescriptorTest.java:117: error: cannot find symbol; { PlatformReadFilter.class.getSimpleName(), ""--"" + PlatformReadFilter.PL_FILTER_NAME_LONG_NAME, ""fakePlatform"" }, ; ```. You'll need to update these references in order to get tests passing.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4103#issuecomment-360806542
https://github.com/broadinstitute/gatk/pull/4103#issuecomment-360806542:524,Testability,test,tests,524,"I also just noticed that tests are failing on the branch because they still reference the old constants in a number of places:. ```; symbol: variable READ_NAME_LONG_NAME; location: class ReadNameReadFilter; /gatk/src/test/java/org/broadinstitute/hellbender/cmdline/GATKPlugin/GATKReadFilterPluginDescriptorTest.java:117: error: cannot find symbol; { PlatformReadFilter.class.getSimpleName(), ""--"" + PlatformReadFilter.PL_FILTER_NAME_LONG_NAME, ""fakePlatform"" }, ; ```. You'll need to update these references in order to get tests passing.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4103#issuecomment-360806542
https://github.com/broadinstitute/gatk/pull/4103#issuecomment-360850011:186,Availability,error,error,186,"Back to you @droazen - two things to ""discuss"" still:. * Is it still needed the test for the mapping quality arg? There was one failing, but I didn't realized because of the compilation error (you can check it in the ""Fix compilation"" commit.; * Should I pass some of the `StandardArgumentDefinitions` to the new class?. Thank you!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4103#issuecomment-360850011
https://github.com/broadinstitute/gatk/pull/4103#issuecomment-360850011:80,Testability,test,test,80,"Back to you @droazen - two things to ""discuss"" still:. * Is it still needed the test for the mapping quality arg? There was one failing, but I didn't realized because of the compilation error (you can check it in the ""Fix compilation"" commit.; * Should I pass some of the `StandardArgumentDefinitions` to the new class?. Thank you!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4103#issuecomment-360850011
https://github.com/broadinstitute/gatk/pull/4103#issuecomment-360851910:122,Deployability,release,release,122,"@magicDGS Please do add the additional test(s) for `MappingQualityReadFilter` in this branch. We've pushed back the point release until end of day on Monday, so there should be enough time. It's ok to move the additional read-filter-related constants to your new class, but I'd wait for tests to pass on the branch first before doing so.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4103#issuecomment-360851910
https://github.com/broadinstitute/gatk/pull/4103#issuecomment-360851910:39,Testability,test,test,39,"@magicDGS Please do add the additional test(s) for `MappingQualityReadFilter` in this branch. We've pushed back the point release until end of day on Monday, so there should be enough time. It's ok to move the additional read-filter-related constants to your new class, but I'd wait for tests to pass on the branch first before doing so.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4103#issuecomment-360851910
https://github.com/broadinstitute/gatk/pull/4103#issuecomment-360851910:287,Testability,test,tests,287,"@magicDGS Please do add the additional test(s) for `MappingQualityReadFilter` in this branch. We've pushed back the point release until end of day on Monday, so there should be enough time. It's ok to move the additional read-filter-related constants to your new class, but I'd wait for tests to pass on the branch first before doing so.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4103#issuecomment-360851910
https://github.com/broadinstitute/gatk/pull/4103#issuecomment-360858400:67,Deployability,release,release,67,"@droazen - perfect! Thanks for the information about the new point release. I added a new test for the `--maximum-mapping-quality` argument, as the `--minimum-mapping-quality` was already included. I will add another commit with the rest of the read-filter related constant to the new class. Once the test pass it will be ready for the next pass.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4103#issuecomment-360858400
https://github.com/broadinstitute/gatk/pull/4103#issuecomment-360858400:90,Testability,test,test,90,"@droazen - perfect! Thanks for the information about the new point release. I added a new test for the `--maximum-mapping-quality` argument, as the `--minimum-mapping-quality` was already included. I will add another commit with the rest of the read-filter related constant to the new class. Once the test pass it will be ready for the next pass.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4103#issuecomment-360858400
https://github.com/broadinstitute/gatk/pull/4103#issuecomment-360858400:301,Testability,test,test,301,"@droazen - perfect! Thanks for the information about the new point release. I added a new test for the `--maximum-mapping-quality` argument, as the `--minimum-mapping-quality` was already included. I will add another commit with the rest of the read-filter related constant to the new class. Once the test pass it will be ready for the next pass.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4103#issuecomment-360858400
https://github.com/broadinstitute/gatk/issues/4106#issuecomment-356986554:156,Performance,load,loader,156,"That sounds like a bad implementation from our side - apologies. We are working on fully fixing the Protobuf implementation. As part of that task, the temp loader/query JSON files will no longer be created (the vid and callset JSONs will still be needed).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4106#issuecomment-356986554
https://github.com/broadinstitute/gatk/pull/4107#issuecomment-356345394:2142,Availability,down,downsampling,2142,TcGFyay5qYXZh) | `0% <0%> (-82.022%)` | `0 <0> (-23)` | |; | [...r/utils/solver/UnivariateSolverJobDescription.java](https://codecov.io/gh/broadinstitute/gatk/pull/4107/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zb2x2ZXIvVW5pdmFyaWF0ZVNvbHZlckpvYkRlc2NyaXB0aW9uLmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-6%)` | |; | [...ools/spark/pathseq/loggers/PSFilterFileLogger.java](https://codecov.io/gh/broadinstitute/gatk/pull/4107/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL2xvZ2dlcnMvUFNGaWx0ZXJGaWxlTG9nZ2VyLmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-8%)` | |; | [...ender/tools/ApplyBQSRUniqueArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/4107/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9BcHBseUJRU1JVbmlxdWVBcmd1bWVudENvbGxlY3Rpb24uamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-2%)` | |; | [...ender/utils/downsampling/ReservoirDownsampler.java](https://codecov.io/gh/broadinstitute/gatk/pull/4107/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvUmVzZXJ2b2lyRG93bnNhbXBsZXIuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-21%)` | |; | [...er/tools/walkers/annotator/ReadPosRankSumTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/4107/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9SZWFkUG9zUmFua1N1bVRlc3QuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-10%)` | |; | [...ender/utils/codecs/sampileup/SAMPileupElement.java](https://codecov.io/gh/broadinstitute/gatk/pull/4107/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9jb2RlY3Mvc2FtcGlsZXVwL1NBTVBpbGV1cEVsZW1lbnQuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-3%)` | |; | [...metrics/QualityYieldMetricsArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/4107/diff?src=pr&e,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4107#issuecomment-356345394
https://github.com/broadinstitute/gatk/pull/4107#issuecomment-356345394:1541,Testability,log,loggers,1541,======================================; Files 1056 1056 ; Lines 59183 59637 +454 ; Branches 9622 9750 +128 ; ===============================================; - Hits 46755 7359 -39396 ; - Misses 8686 51158 +42472 ; + Partials 3742 1120 -2622; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4107?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...stitute/hellbender/tools/HaplotypeCallerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4107/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9IYXBsb3R5cGVDYWxsZXJTcGFyay5qYXZh) | `0% <0%> (-82.022%)` | `0 <0> (-23)` | |; | [...r/utils/solver/UnivariateSolverJobDescription.java](https://codecov.io/gh/broadinstitute/gatk/pull/4107/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zb2x2ZXIvVW5pdmFyaWF0ZVNvbHZlckpvYkRlc2NyaXB0aW9uLmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-6%)` | |; | [...ools/spark/pathseq/loggers/PSFilterFileLogger.java](https://codecov.io/gh/broadinstitute/gatk/pull/4107/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL2xvZ2dlcnMvUFNGaWx0ZXJGaWxlTG9nZ2VyLmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-8%)` | |; | [...ender/tools/ApplyBQSRUniqueArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/4107/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9BcHBseUJRU1JVbmlxdWVBcmd1bWVudENvbGxlY3Rpb24uamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-2%)` | |; | [...ender/utils/downsampling/ReservoirDownsampler.java](https://codecov.io/gh/broadinstitute/gatk/pull/4107/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvUmVzZXJ2b2lyRG93bnNhbXBsZXIuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-21%)` | |; | [...er/tools/walkers/annotator/ReadPosRankSumTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/4107/diff?src=p,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4107#issuecomment-356345394
https://github.com/broadinstitute/gatk/pull/4108#issuecomment-356352482:35,Testability,test,tests,35,:+1: looks good -- will merge once tests pass,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4108#issuecomment-356352482
https://github.com/broadinstitute/gatk/pull/4110#issuecomment-356410739:73,Deployability,release,release,73,"👍 Yea, I guess that fell through the cracks for a while because we don't release much",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4110#issuecomment-356410739
https://github.com/broadinstitute/gatk/issues/4111#issuecomment-375438021:3231,Availability,down,downstreamBreakpointRefPos,3231," `parseOneContig()` (needs testing because we need it for simple-re-interpretation for CPX variants) Note that `nextAlignmentMayBeInsertion()` is currently broken in the sense that when using this to filter out alignments whose ref span is contained by another, check if the two alignments involved are head/tail. - [x] `BreakpointsInference` & `BreakpointComplications`. - [x] `NovelAdjacencyAndAltHaplotype`; - [x] `toSimpleOrBNDTypes()`. - [x] `SimpleNovelAdjacencyAndChimericAlignmentEvidence`; - [x] serialization test. - [x] `AnnotatedVariantProducer`; - [x] `produceAnnotatedBNDmatesVcFromNovelAdjacency()`. - [x] `BreakEndVariantType`. - [ ] `SvDiscoverFromLocalAssemblyContigAlignmentsSpark` integration test; . ### update how variants are represented ; Implement the following representation changes that should make type-based evaluation easier; - [x] change `INSDUP` to`INS` when the duplicated ref region, denoted with annotation `DUP_REPEAT_UNIT_REF_SPAN`, is shorter than 50 bp.; - [x] change scarred deletion calls, which currently output as `DEL` with `INSSEQ` annotation, to one of these; - [x] `INS`/`DEL`, when deleted/inserted bases are < 50 bp and annotate accordingly; when type is determined as`INS`, the `POS` will be 1 base before the micro-deleted range and `END` will be end of the micro-deleted range, where the `REF` allele will be the corresponding reference bases.; - [x] two records `INS` and `DEL` when both are >= 50, share the same `POS`, and link by `EVENT`; - [ ] we are making a choice that treats duplication expansion as insertion. If decide to treat `DUP` as a separate 1st class type, we need to ; - [ ] shift the left breakpoint to the right by 1 base compared to the current implementation, and ; - [ ] `downstreamBreakpointRefPos = complication.getDupSeqRepeatUnitRefSpan().getEnd();`. ----------; ## CPX variant re-interpretation. Send cpx variant for re-interpretation of simple basic types, and check for consistency (this might be the difficult part)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4111#issuecomment-375438021
https://github.com/broadinstitute/gatk/issues/4111#issuecomment-375438021:0,Deployability,Update,Updated,0,"Updated plan. ----------; ## Small improvements in new interpretation tool; ; - [x] Output bam instead of sam for assembly alignments; - [x] Instead of creating directory, new interpretation tool writes files (behavior consistent with current interpretation tool); - [x] Prefix with sample name for output files' names; - [x] Add `INSLEN` annotation when there's `INSSEQ`; - [x] Clarify the boundary between `AlignedContig` and `AssemblyContigWithFineTunedAlignments`; - [x] Increase test coverage for `AssemblyContigAlignmentsConfigPicker`; ; ----------; ## Consolidate logic, bump test coverage and update how variants are represented. ### consolidate logic; When initially prototyped, there's redundancy in logic for simple variants, now it's time to consolidate. - [x] `AssemblyContigWithFineTunedAlignments`; - [x] `hasIncompletePicture()`. - [x] `AssemblyContigAlignmentSignatureClassifier`; - [x] Don't make so many splits; - [x] Reduce `RawTypes` into fewer cases; ; - [x] `ChimericAlignment`; - [x] update documentation; - [x] implement a `getCoordinateSortedRefSpans()`, and use in `BreakpointsInference`; - [x] `isNeitherSimpleTranslocationNorIncompletePicture()`; - [x] `extractSimpleChimera()`. ### bump test coverage; Once code above is consolidated, bump test coverage, particularly for the classes above and the following poorly-covered classes; - [x] `ChimericAlignment`; - [x] `isForwardStrandRepresentation()`; - [x] `splitPairStrongEnoughEvidenceForCA()` ; - [x] `parseOneContig()` (needs testing because we need it for simple-re-interpretation for CPX variants) Note that `nextAlignmentMayBeInsertion()` is currently broken in the sense that when using this to filter out alignments whose ref span is contained by another, check if the two alignments involved are head/tail. - [x] `BreakpointsInference` & `BreakpointComplications`. - [x] `NovelAdjacencyAndAltHaplotype`; - [x] `toSimpleOrBNDTypes()`. - [x] `SimpleNovelAdjacencyAndChimericAlignmentEvidence`; - [x] serialization ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4111#issuecomment-375438021
https://github.com/broadinstitute/gatk/issues/4111#issuecomment-375438021:601,Deployability,update,update,601,"Updated plan. ----------; ## Small improvements in new interpretation tool; ; - [x] Output bam instead of sam for assembly alignments; - [x] Instead of creating directory, new interpretation tool writes files (behavior consistent with current interpretation tool); - [x] Prefix with sample name for output files' names; - [x] Add `INSLEN` annotation when there's `INSSEQ`; - [x] Clarify the boundary between `AlignedContig` and `AssemblyContigWithFineTunedAlignments`; - [x] Increase test coverage for `AssemblyContigAlignmentsConfigPicker`; ; ----------; ## Consolidate logic, bump test coverage and update how variants are represented. ### consolidate logic; When initially prototyped, there's redundancy in logic for simple variants, now it's time to consolidate. - [x] `AssemblyContigWithFineTunedAlignments`; - [x] `hasIncompletePicture()`. - [x] `AssemblyContigAlignmentSignatureClassifier`; - [x] Don't make so many splits; - [x] Reduce `RawTypes` into fewer cases; ; - [x] `ChimericAlignment`; - [x] update documentation; - [x] implement a `getCoordinateSortedRefSpans()`, and use in `BreakpointsInference`; - [x] `isNeitherSimpleTranslocationNorIncompletePicture()`; - [x] `extractSimpleChimera()`. ### bump test coverage; Once code above is consolidated, bump test coverage, particularly for the classes above and the following poorly-covered classes; - [x] `ChimericAlignment`; - [x] `isForwardStrandRepresentation()`; - [x] `splitPairStrongEnoughEvidenceForCA()` ; - [x] `parseOneContig()` (needs testing because we need it for simple-re-interpretation for CPX variants) Note that `nextAlignmentMayBeInsertion()` is currently broken in the sense that when using this to filter out alignments whose ref span is contained by another, check if the two alignments involved are head/tail. - [x] `BreakpointsInference` & `BreakpointComplications`. - [x] `NovelAdjacencyAndAltHaplotype`; - [x] `toSimpleOrBNDTypes()`. - [x] `SimpleNovelAdjacencyAndChimericAlignmentEvidence`; - [x] serialization ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4111#issuecomment-375438021
https://github.com/broadinstitute/gatk/issues/4111#issuecomment-375438021:1008,Deployability,update,update,1008,"## Small improvements in new interpretation tool; ; - [x] Output bam instead of sam for assembly alignments; - [x] Instead of creating directory, new interpretation tool writes files (behavior consistent with current interpretation tool); - [x] Prefix with sample name for output files' names; - [x] Add `INSLEN` annotation when there's `INSSEQ`; - [x] Clarify the boundary between `AlignedContig` and `AssemblyContigWithFineTunedAlignments`; - [x] Increase test coverage for `AssemblyContigAlignmentsConfigPicker`; ; ----------; ## Consolidate logic, bump test coverage and update how variants are represented. ### consolidate logic; When initially prototyped, there's redundancy in logic for simple variants, now it's time to consolidate. - [x] `AssemblyContigWithFineTunedAlignments`; - [x] `hasIncompletePicture()`. - [x] `AssemblyContigAlignmentSignatureClassifier`; - [x] Don't make so many splits; - [x] Reduce `RawTypes` into fewer cases; ; - [x] `ChimericAlignment`; - [x] update documentation; - [x] implement a `getCoordinateSortedRefSpans()`, and use in `BreakpointsInference`; - [x] `isNeitherSimpleTranslocationNorIncompletePicture()`; - [x] `extractSimpleChimera()`. ### bump test coverage; Once code above is consolidated, bump test coverage, particularly for the classes above and the following poorly-covered classes; - [x] `ChimericAlignment`; - [x] `isForwardStrandRepresentation()`; - [x] `splitPairStrongEnoughEvidenceForCA()` ; - [x] `parseOneContig()` (needs testing because we need it for simple-re-interpretation for CPX variants) Note that `nextAlignmentMayBeInsertion()` is currently broken in the sense that when using this to filter out alignments whose ref span is contained by another, check if the two alignments involved are head/tail. - [x] `BreakpointsInference` & `BreakpointComplications`. - [x] `NovelAdjacencyAndAltHaplotype`; - [x] `toSimpleOrBNDTypes()`. - [x] `SimpleNovelAdjacencyAndChimericAlignmentEvidence`; - [x] serialization test. - [x] `AnnotatedVar",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4111#issuecomment-375438021
https://github.com/broadinstitute/gatk/issues/4111#issuecomment-375438021:2183,Deployability,integrat,integration,2183,"ePicture()`; - [x] `extractSimpleChimera()`. ### bump test coverage; Once code above is consolidated, bump test coverage, particularly for the classes above and the following poorly-covered classes; - [x] `ChimericAlignment`; - [x] `isForwardStrandRepresentation()`; - [x] `splitPairStrongEnoughEvidenceForCA()` ; - [x] `parseOneContig()` (needs testing because we need it for simple-re-interpretation for CPX variants) Note that `nextAlignmentMayBeInsertion()` is currently broken in the sense that when using this to filter out alignments whose ref span is contained by another, check if the two alignments involved are head/tail. - [x] `BreakpointsInference` & `BreakpointComplications`. - [x] `NovelAdjacencyAndAltHaplotype`; - [x] `toSimpleOrBNDTypes()`. - [x] `SimpleNovelAdjacencyAndChimericAlignmentEvidence`; - [x] serialization test. - [x] `AnnotatedVariantProducer`; - [x] `produceAnnotatedBNDmatesVcFromNovelAdjacency()`. - [x] `BreakEndVariantType`. - [ ] `SvDiscoverFromLocalAssemblyContigAlignmentsSpark` integration test; . ### update how variants are represented ; Implement the following representation changes that should make type-based evaluation easier; - [x] change `INSDUP` to`INS` when the duplicated ref region, denoted with annotation `DUP_REPEAT_UNIT_REF_SPAN`, is shorter than 50 bp.; - [x] change scarred deletion calls, which currently output as `DEL` with `INSSEQ` annotation, to one of these; - [x] `INS`/`DEL`, when deleted/inserted bases are < 50 bp and annotate accordingly; when type is determined as`INS`, the `POS` will be 1 base before the micro-deleted range and `END` will be end of the micro-deleted range, where the `REF` allele will be the corresponding reference bases.; - [x] two records `INS` and `DEL` when both are >= 50, share the same `POS`, and link by `EVENT`; - [ ] we are making a choice that treats duplication expansion as insertion. If decide to treat `DUP` as a separate 1st class type, we need to ; - [ ] shift the left breakpoint to the ri",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4111#issuecomment-375438021
https://github.com/broadinstitute/gatk/issues/4111#issuecomment-375438021:2207,Deployability,update,update,2207,"poorly-covered classes; - [x] `ChimericAlignment`; - [x] `isForwardStrandRepresentation()`; - [x] `splitPairStrongEnoughEvidenceForCA()` ; - [x] `parseOneContig()` (needs testing because we need it for simple-re-interpretation for CPX variants) Note that `nextAlignmentMayBeInsertion()` is currently broken in the sense that when using this to filter out alignments whose ref span is contained by another, check if the two alignments involved are head/tail. - [x] `BreakpointsInference` & `BreakpointComplications`. - [x] `NovelAdjacencyAndAltHaplotype`; - [x] `toSimpleOrBNDTypes()`. - [x] `SimpleNovelAdjacencyAndChimericAlignmentEvidence`; - [x] serialization test. - [x] `AnnotatedVariantProducer`; - [x] `produceAnnotatedBNDmatesVcFromNovelAdjacency()`. - [x] `BreakEndVariantType`. - [ ] `SvDiscoverFromLocalAssemblyContigAlignmentsSpark` integration test; . ### update how variants are represented ; Implement the following representation changes that should make type-based evaluation easier; - [x] change `INSDUP` to`INS` when the duplicated ref region, denoted with annotation `DUP_REPEAT_UNIT_REF_SPAN`, is shorter than 50 bp.; - [x] change scarred deletion calls, which currently output as `DEL` with `INSSEQ` annotation, to one of these; - [x] `INS`/`DEL`, when deleted/inserted bases are < 50 bp and annotate accordingly; when type is determined as`INS`, the `POS` will be 1 base before the micro-deleted range and `END` will be end of the micro-deleted range, where the `REF` allele will be the corresponding reference bases.; - [x] two records `INS` and `DEL` when both are >= 50, share the same `POS`, and link by `EVENT`; - [ ] we are making a choice that treats duplication expansion as insertion. If decide to treat `DUP` as a separate 1st class type, we need to ; - [ ] shift the left breakpoint to the right by 1 base compared to the current implementation, and ; - [ ] `downstreamBreakpointRefPos = complication.getDupSeqRepeatUnitRefSpan().getEnd();`. ----------; ## CPX varian",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4111#issuecomment-375438021
https://github.com/broadinstitute/gatk/issues/4111#issuecomment-375438021:937,Energy Efficiency,Reduce,Reduce,937,"## Small improvements in new interpretation tool; ; - [x] Output bam instead of sam for assembly alignments; - [x] Instead of creating directory, new interpretation tool writes files (behavior consistent with current interpretation tool); - [x] Prefix with sample name for output files' names; - [x] Add `INSLEN` annotation when there's `INSSEQ`; - [x] Clarify the boundary between `AlignedContig` and `AssemblyContigWithFineTunedAlignments`; - [x] Increase test coverage for `AssemblyContigAlignmentsConfigPicker`; ; ----------; ## Consolidate logic, bump test coverage and update how variants are represented. ### consolidate logic; When initially prototyped, there's redundancy in logic for simple variants, now it's time to consolidate. - [x] `AssemblyContigWithFineTunedAlignments`; - [x] `hasIncompletePicture()`. - [x] `AssemblyContigAlignmentSignatureClassifier`; - [x] Don't make so many splits; - [x] Reduce `RawTypes` into fewer cases; ; - [x] `ChimericAlignment`; - [x] update documentation; - [x] implement a `getCoordinateSortedRefSpans()`, and use in `BreakpointsInference`; - [x] `isNeitherSimpleTranslocationNorIncompletePicture()`; - [x] `extractSimpleChimera()`. ### bump test coverage; Once code above is consolidated, bump test coverage, particularly for the classes above and the following poorly-covered classes; - [x] `ChimericAlignment`; - [x] `isForwardStrandRepresentation()`; - [x] `splitPairStrongEnoughEvidenceForCA()` ; - [x] `parseOneContig()` (needs testing because we need it for simple-re-interpretation for CPX variants) Note that `nextAlignmentMayBeInsertion()` is currently broken in the sense that when using this to filter out alignments whose ref span is contained by another, check if the two alignments involved are head/tail. - [x] `BreakpointsInference` & `BreakpointComplications`. - [x] `NovelAdjacencyAndAltHaplotype`; - [x] `toSimpleOrBNDTypes()`. - [x] `SimpleNovelAdjacencyAndChimericAlignmentEvidence`; - [x] serialization test. - [x] `AnnotatedVar",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4111#issuecomment-375438021
https://github.com/broadinstitute/gatk/issues/4111#issuecomment-375438021:2183,Integrability,integrat,integration,2183,"ePicture()`; - [x] `extractSimpleChimera()`. ### bump test coverage; Once code above is consolidated, bump test coverage, particularly for the classes above and the following poorly-covered classes; - [x] `ChimericAlignment`; - [x] `isForwardStrandRepresentation()`; - [x] `splitPairStrongEnoughEvidenceForCA()` ; - [x] `parseOneContig()` (needs testing because we need it for simple-re-interpretation for CPX variants) Note that `nextAlignmentMayBeInsertion()` is currently broken in the sense that when using this to filter out alignments whose ref span is contained by another, check if the two alignments involved are head/tail. - [x] `BreakpointsInference` & `BreakpointComplications`. - [x] `NovelAdjacencyAndAltHaplotype`; - [x] `toSimpleOrBNDTypes()`. - [x] `SimpleNovelAdjacencyAndChimericAlignmentEvidence`; - [x] serialization test. - [x] `AnnotatedVariantProducer`; - [x] `produceAnnotatedBNDmatesVcFromNovelAdjacency()`. - [x] `BreakEndVariantType`. - [ ] `SvDiscoverFromLocalAssemblyContigAlignmentsSpark` integration test; . ### update how variants are represented ; Implement the following representation changes that should make type-based evaluation easier; - [x] change `INSDUP` to`INS` when the duplicated ref region, denoted with annotation `DUP_REPEAT_UNIT_REF_SPAN`, is shorter than 50 bp.; - [x] change scarred deletion calls, which currently output as `DEL` with `INSSEQ` annotation, to one of these; - [x] `INS`/`DEL`, when deleted/inserted bases are < 50 bp and annotate accordingly; when type is determined as`INS`, the `POS` will be 1 base before the micro-deleted range and `END` will be end of the micro-deleted range, where the `REF` allele will be the corresponding reference bases.; - [x] two records `INS` and `DEL` when both are >= 50, share the same `POS`, and link by `EVENT`; - [ ] we are making a choice that treats duplication expansion as insertion. If decide to treat `DUP` as a separate 1st class type, we need to ; - [ ] shift the left breakpoint to the ri",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4111#issuecomment-375438021
https://github.com/broadinstitute/gatk/issues/4111#issuecomment-375438021:696,Safety,redund,redundancy,696,"Updated plan. ----------; ## Small improvements in new interpretation tool; ; - [x] Output bam instead of sam for assembly alignments; - [x] Instead of creating directory, new interpretation tool writes files (behavior consistent with current interpretation tool); - [x] Prefix with sample name for output files' names; - [x] Add `INSLEN` annotation when there's `INSSEQ`; - [x] Clarify the boundary between `AlignedContig` and `AssemblyContigWithFineTunedAlignments`; - [x] Increase test coverage for `AssemblyContigAlignmentsConfigPicker`; ; ----------; ## Consolidate logic, bump test coverage and update how variants are represented. ### consolidate logic; When initially prototyped, there's redundancy in logic for simple variants, now it's time to consolidate. - [x] `AssemblyContigWithFineTunedAlignments`; - [x] `hasIncompletePicture()`. - [x] `AssemblyContigAlignmentSignatureClassifier`; - [x] Don't make so many splits; - [x] Reduce `RawTypes` into fewer cases; ; - [x] `ChimericAlignment`; - [x] update documentation; - [x] implement a `getCoordinateSortedRefSpans()`, and use in `BreakpointsInference`; - [x] `isNeitherSimpleTranslocationNorIncompletePicture()`; - [x] `extractSimpleChimera()`. ### bump test coverage; Once code above is consolidated, bump test coverage, particularly for the classes above and the following poorly-covered classes; - [x] `ChimericAlignment`; - [x] `isForwardStrandRepresentation()`; - [x] `splitPairStrongEnoughEvidenceForCA()` ; - [x] `parseOneContig()` (needs testing because we need it for simple-re-interpretation for CPX variants) Note that `nextAlignmentMayBeInsertion()` is currently broken in the sense that when using this to filter out alignments whose ref span is contained by another, check if the two alignments involved are head/tail. - [x] `BreakpointsInference` & `BreakpointComplications`. - [x] `NovelAdjacencyAndAltHaplotype`; - [x] `toSimpleOrBNDTypes()`. - [x] `SimpleNovelAdjacencyAndChimericAlignmentEvidence`; - [x] serialization ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4111#issuecomment-375438021
https://github.com/broadinstitute/gatk/issues/4111#issuecomment-375438021:484,Testability,test,test,484,"Updated plan. ----------; ## Small improvements in new interpretation tool; ; - [x] Output bam instead of sam for assembly alignments; - [x] Instead of creating directory, new interpretation tool writes files (behavior consistent with current interpretation tool); - [x] Prefix with sample name for output files' names; - [x] Add `INSLEN` annotation when there's `INSSEQ`; - [x] Clarify the boundary between `AlignedContig` and `AssemblyContigWithFineTunedAlignments`; - [x] Increase test coverage for `AssemblyContigAlignmentsConfigPicker`; ; ----------; ## Consolidate logic, bump test coverage and update how variants are represented. ### consolidate logic; When initially prototyped, there's redundancy in logic for simple variants, now it's time to consolidate. - [x] `AssemblyContigWithFineTunedAlignments`; - [x] `hasIncompletePicture()`. - [x] `AssemblyContigAlignmentSignatureClassifier`; - [x] Don't make so many splits; - [x] Reduce `RawTypes` into fewer cases; ; - [x] `ChimericAlignment`; - [x] update documentation; - [x] implement a `getCoordinateSortedRefSpans()`, and use in `BreakpointsInference`; - [x] `isNeitherSimpleTranslocationNorIncompletePicture()`; - [x] `extractSimpleChimera()`. ### bump test coverage; Once code above is consolidated, bump test coverage, particularly for the classes above and the following poorly-covered classes; - [x] `ChimericAlignment`; - [x] `isForwardStrandRepresentation()`; - [x] `splitPairStrongEnoughEvidenceForCA()` ; - [x] `parseOneContig()` (needs testing because we need it for simple-re-interpretation for CPX variants) Note that `nextAlignmentMayBeInsertion()` is currently broken in the sense that when using this to filter out alignments whose ref span is contained by another, check if the two alignments involved are head/tail. - [x] `BreakpointsInference` & `BreakpointComplications`. - [x] `NovelAdjacencyAndAltHaplotype`; - [x] `toSimpleOrBNDTypes()`. - [x] `SimpleNovelAdjacencyAndChimericAlignmentEvidence`; - [x] serialization ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4111#issuecomment-375438021
https://github.com/broadinstitute/gatk/issues/4111#issuecomment-375438021:571,Testability,log,logic,571,"Updated plan. ----------; ## Small improvements in new interpretation tool; ; - [x] Output bam instead of sam for assembly alignments; - [x] Instead of creating directory, new interpretation tool writes files (behavior consistent with current interpretation tool); - [x] Prefix with sample name for output files' names; - [x] Add `INSLEN` annotation when there's `INSSEQ`; - [x] Clarify the boundary between `AlignedContig` and `AssemblyContigWithFineTunedAlignments`; - [x] Increase test coverage for `AssemblyContigAlignmentsConfigPicker`; ; ----------; ## Consolidate logic, bump test coverage and update how variants are represented. ### consolidate logic; When initially prototyped, there's redundancy in logic for simple variants, now it's time to consolidate. - [x] `AssemblyContigWithFineTunedAlignments`; - [x] `hasIncompletePicture()`. - [x] `AssemblyContigAlignmentSignatureClassifier`; - [x] Don't make so many splits; - [x] Reduce `RawTypes` into fewer cases; ; - [x] `ChimericAlignment`; - [x] update documentation; - [x] implement a `getCoordinateSortedRefSpans()`, and use in `BreakpointsInference`; - [x] `isNeitherSimpleTranslocationNorIncompletePicture()`; - [x] `extractSimpleChimera()`. ### bump test coverage; Once code above is consolidated, bump test coverage, particularly for the classes above and the following poorly-covered classes; - [x] `ChimericAlignment`; - [x] `isForwardStrandRepresentation()`; - [x] `splitPairStrongEnoughEvidenceForCA()` ; - [x] `parseOneContig()` (needs testing because we need it for simple-re-interpretation for CPX variants) Note that `nextAlignmentMayBeInsertion()` is currently broken in the sense that when using this to filter out alignments whose ref span is contained by another, check if the two alignments involved are head/tail. - [x] `BreakpointsInference` & `BreakpointComplications`. - [x] `NovelAdjacencyAndAltHaplotype`; - [x] `toSimpleOrBNDTypes()`. - [x] `SimpleNovelAdjacencyAndChimericAlignmentEvidence`; - [x] serialization ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4111#issuecomment-375438021
https://github.com/broadinstitute/gatk/issues/4111#issuecomment-375438021:583,Testability,test,test,583,"Updated plan. ----------; ## Small improvements in new interpretation tool; ; - [x] Output bam instead of sam for assembly alignments; - [x] Instead of creating directory, new interpretation tool writes files (behavior consistent with current interpretation tool); - [x] Prefix with sample name for output files' names; - [x] Add `INSLEN` annotation when there's `INSSEQ`; - [x] Clarify the boundary between `AlignedContig` and `AssemblyContigWithFineTunedAlignments`; - [x] Increase test coverage for `AssemblyContigAlignmentsConfigPicker`; ; ----------; ## Consolidate logic, bump test coverage and update how variants are represented. ### consolidate logic; When initially prototyped, there's redundancy in logic for simple variants, now it's time to consolidate. - [x] `AssemblyContigWithFineTunedAlignments`; - [x] `hasIncompletePicture()`. - [x] `AssemblyContigAlignmentSignatureClassifier`; - [x] Don't make so many splits; - [x] Reduce `RawTypes` into fewer cases; ; - [x] `ChimericAlignment`; - [x] update documentation; - [x] implement a `getCoordinateSortedRefSpans()`, and use in `BreakpointsInference`; - [x] `isNeitherSimpleTranslocationNorIncompletePicture()`; - [x] `extractSimpleChimera()`. ### bump test coverage; Once code above is consolidated, bump test coverage, particularly for the classes above and the following poorly-covered classes; - [x] `ChimericAlignment`; - [x] `isForwardStrandRepresentation()`; - [x] `splitPairStrongEnoughEvidenceForCA()` ; - [x] `parseOneContig()` (needs testing because we need it for simple-re-interpretation for CPX variants) Note that `nextAlignmentMayBeInsertion()` is currently broken in the sense that when using this to filter out alignments whose ref span is contained by another, check if the two alignments involved are head/tail. - [x] `BreakpointsInference` & `BreakpointComplications`. - [x] `NovelAdjacencyAndAltHaplotype`; - [x] `toSimpleOrBNDTypes()`. - [x] `SimpleNovelAdjacencyAndChimericAlignmentEvidence`; - [x] serialization ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4111#issuecomment-375438021
https://github.com/broadinstitute/gatk/issues/4111#issuecomment-375438021:654,Testability,log,logic,654,"Updated plan. ----------; ## Small improvements in new interpretation tool; ; - [x] Output bam instead of sam for assembly alignments; - [x] Instead of creating directory, new interpretation tool writes files (behavior consistent with current interpretation tool); - [x] Prefix with sample name for output files' names; - [x] Add `INSLEN` annotation when there's `INSSEQ`; - [x] Clarify the boundary between `AlignedContig` and `AssemblyContigWithFineTunedAlignments`; - [x] Increase test coverage for `AssemblyContigAlignmentsConfigPicker`; ; ----------; ## Consolidate logic, bump test coverage and update how variants are represented. ### consolidate logic; When initially prototyped, there's redundancy in logic for simple variants, now it's time to consolidate. - [x] `AssemblyContigWithFineTunedAlignments`; - [x] `hasIncompletePicture()`. - [x] `AssemblyContigAlignmentSignatureClassifier`; - [x] Don't make so many splits; - [x] Reduce `RawTypes` into fewer cases; ; - [x] `ChimericAlignment`; - [x] update documentation; - [x] implement a `getCoordinateSortedRefSpans()`, and use in `BreakpointsInference`; - [x] `isNeitherSimpleTranslocationNorIncompletePicture()`; - [x] `extractSimpleChimera()`. ### bump test coverage; Once code above is consolidated, bump test coverage, particularly for the classes above and the following poorly-covered classes; - [x] `ChimericAlignment`; - [x] `isForwardStrandRepresentation()`; - [x] `splitPairStrongEnoughEvidenceForCA()` ; - [x] `parseOneContig()` (needs testing because we need it for simple-re-interpretation for CPX variants) Note that `nextAlignmentMayBeInsertion()` is currently broken in the sense that when using this to filter out alignments whose ref span is contained by another, check if the two alignments involved are head/tail. - [x] `BreakpointsInference` & `BreakpointComplications`. - [x] `NovelAdjacencyAndAltHaplotype`; - [x] `toSimpleOrBNDTypes()`. - [x] `SimpleNovelAdjacencyAndChimericAlignmentEvidence`; - [x] serialization ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4111#issuecomment-375438021
https://github.com/broadinstitute/gatk/issues/4111#issuecomment-375438021:710,Testability,log,logic,710,"Updated plan. ----------; ## Small improvements in new interpretation tool; ; - [x] Output bam instead of sam for assembly alignments; - [x] Instead of creating directory, new interpretation tool writes files (behavior consistent with current interpretation tool); - [x] Prefix with sample name for output files' names; - [x] Add `INSLEN` annotation when there's `INSSEQ`; - [x] Clarify the boundary between `AlignedContig` and `AssemblyContigWithFineTunedAlignments`; - [x] Increase test coverage for `AssemblyContigAlignmentsConfigPicker`; ; ----------; ## Consolidate logic, bump test coverage and update how variants are represented. ### consolidate logic; When initially prototyped, there's redundancy in logic for simple variants, now it's time to consolidate. - [x] `AssemblyContigWithFineTunedAlignments`; - [x] `hasIncompletePicture()`. - [x] `AssemblyContigAlignmentSignatureClassifier`; - [x] Don't make so many splits; - [x] Reduce `RawTypes` into fewer cases; ; - [x] `ChimericAlignment`; - [x] update documentation; - [x] implement a `getCoordinateSortedRefSpans()`, and use in `BreakpointsInference`; - [x] `isNeitherSimpleTranslocationNorIncompletePicture()`; - [x] `extractSimpleChimera()`. ### bump test coverage; Once code above is consolidated, bump test coverage, particularly for the classes above and the following poorly-covered classes; - [x] `ChimericAlignment`; - [x] `isForwardStrandRepresentation()`; - [x] `splitPairStrongEnoughEvidenceForCA()` ; - [x] `parseOneContig()` (needs testing because we need it for simple-re-interpretation for CPX variants) Note that `nextAlignmentMayBeInsertion()` is currently broken in the sense that when using this to filter out alignments whose ref span is contained by another, check if the two alignments involved are head/tail. - [x] `BreakpointsInference` & `BreakpointComplications`. - [x] `NovelAdjacencyAndAltHaplotype`; - [x] `toSimpleOrBNDTypes()`. - [x] `SimpleNovelAdjacencyAndChimericAlignmentEvidence`; - [x] serialization ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4111#issuecomment-375438021
https://github.com/broadinstitute/gatk/issues/4111#issuecomment-375438021:1217,Testability,test,test,1217," `AssemblyContigAlignmentsConfigPicker`; ; ----------; ## Consolidate logic, bump test coverage and update how variants are represented. ### consolidate logic; When initially prototyped, there's redundancy in logic for simple variants, now it's time to consolidate. - [x] `AssemblyContigWithFineTunedAlignments`; - [x] `hasIncompletePicture()`. - [x] `AssemblyContigAlignmentSignatureClassifier`; - [x] Don't make so many splits; - [x] Reduce `RawTypes` into fewer cases; ; - [x] `ChimericAlignment`; - [x] update documentation; - [x] implement a `getCoordinateSortedRefSpans()`, and use in `BreakpointsInference`; - [x] `isNeitherSimpleTranslocationNorIncompletePicture()`; - [x] `extractSimpleChimera()`. ### bump test coverage; Once code above is consolidated, bump test coverage, particularly for the classes above and the following poorly-covered classes; - [x] `ChimericAlignment`; - [x] `isForwardStrandRepresentation()`; - [x] `splitPairStrongEnoughEvidenceForCA()` ; - [x] `parseOneContig()` (needs testing because we need it for simple-re-interpretation for CPX variants) Note that `nextAlignmentMayBeInsertion()` is currently broken in the sense that when using this to filter out alignments whose ref span is contained by another, check if the two alignments involved are head/tail. - [x] `BreakpointsInference` & `BreakpointComplications`. - [x] `NovelAdjacencyAndAltHaplotype`; - [x] `toSimpleOrBNDTypes()`. - [x] `SimpleNovelAdjacencyAndChimericAlignmentEvidence`; - [x] serialization test. - [x] `AnnotatedVariantProducer`; - [x] `produceAnnotatedBNDmatesVcFromNovelAdjacency()`. - [x] `BreakEndVariantType`. - [ ] `SvDiscoverFromLocalAssemblyContigAlignmentsSpark` integration test; . ### update how variants are represented ; Implement the following representation changes that should make type-based evaluation easier; - [x] change `INSDUP` to`INS` when the duplicated ref region, denoted with annotation `DUP_REPEAT_UNIT_REF_SPAN`, is shorter than 50 bp.; - [x] change scarred del",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4111#issuecomment-375438021
https://github.com/broadinstitute/gatk/issues/4111#issuecomment-375438021:1270,Testability,test,test,1270," `AssemblyContigAlignmentsConfigPicker`; ; ----------; ## Consolidate logic, bump test coverage and update how variants are represented. ### consolidate logic; When initially prototyped, there's redundancy in logic for simple variants, now it's time to consolidate. - [x] `AssemblyContigWithFineTunedAlignments`; - [x] `hasIncompletePicture()`. - [x] `AssemblyContigAlignmentSignatureClassifier`; - [x] Don't make so many splits; - [x] Reduce `RawTypes` into fewer cases; ; - [x] `ChimericAlignment`; - [x] update documentation; - [x] implement a `getCoordinateSortedRefSpans()`, and use in `BreakpointsInference`; - [x] `isNeitherSimpleTranslocationNorIncompletePicture()`; - [x] `extractSimpleChimera()`. ### bump test coverage; Once code above is consolidated, bump test coverage, particularly for the classes above and the following poorly-covered classes; - [x] `ChimericAlignment`; - [x] `isForwardStrandRepresentation()`; - [x] `splitPairStrongEnoughEvidenceForCA()` ; - [x] `parseOneContig()` (needs testing because we need it for simple-re-interpretation for CPX variants) Note that `nextAlignmentMayBeInsertion()` is currently broken in the sense that when using this to filter out alignments whose ref span is contained by another, check if the two alignments involved are head/tail. - [x] `BreakpointsInference` & `BreakpointComplications`. - [x] `NovelAdjacencyAndAltHaplotype`; - [x] `toSimpleOrBNDTypes()`. - [x] `SimpleNovelAdjacencyAndChimericAlignmentEvidence`; - [x] serialization test. - [x] `AnnotatedVariantProducer`; - [x] `produceAnnotatedBNDmatesVcFromNovelAdjacency()`. - [x] `BreakEndVariantType`. - [ ] `SvDiscoverFromLocalAssemblyContigAlignmentsSpark` integration test; . ### update how variants are represented ; Implement the following representation changes that should make type-based evaluation easier; - [x] change `INSDUP` to`INS` when the duplicated ref region, denoted with annotation `DUP_REPEAT_UNIT_REF_SPAN`, is shorter than 50 bp.; - [x] change scarred del",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4111#issuecomment-375438021
https://github.com/broadinstitute/gatk/issues/4111#issuecomment-375438021:1509,Testability,test,testing,1509," `AssemblyContigAlignmentsConfigPicker`; ; ----------; ## Consolidate logic, bump test coverage and update how variants are represented. ### consolidate logic; When initially prototyped, there's redundancy in logic for simple variants, now it's time to consolidate. - [x] `AssemblyContigWithFineTunedAlignments`; - [x] `hasIncompletePicture()`. - [x] `AssemblyContigAlignmentSignatureClassifier`; - [x] Don't make so many splits; - [x] Reduce `RawTypes` into fewer cases; ; - [x] `ChimericAlignment`; - [x] update documentation; - [x] implement a `getCoordinateSortedRefSpans()`, and use in `BreakpointsInference`; - [x] `isNeitherSimpleTranslocationNorIncompletePicture()`; - [x] `extractSimpleChimera()`. ### bump test coverage; Once code above is consolidated, bump test coverage, particularly for the classes above and the following poorly-covered classes; - [x] `ChimericAlignment`; - [x] `isForwardStrandRepresentation()`; - [x] `splitPairStrongEnoughEvidenceForCA()` ; - [x] `parseOneContig()` (needs testing because we need it for simple-re-interpretation for CPX variants) Note that `nextAlignmentMayBeInsertion()` is currently broken in the sense that when using this to filter out alignments whose ref span is contained by another, check if the two alignments involved are head/tail. - [x] `BreakpointsInference` & `BreakpointComplications`. - [x] `NovelAdjacencyAndAltHaplotype`; - [x] `toSimpleOrBNDTypes()`. - [x] `SimpleNovelAdjacencyAndChimericAlignmentEvidence`; - [x] serialization test. - [x] `AnnotatedVariantProducer`; - [x] `produceAnnotatedBNDmatesVcFromNovelAdjacency()`. - [x] `BreakEndVariantType`. - [ ] `SvDiscoverFromLocalAssemblyContigAlignmentsSpark` integration test; . ### update how variants are represented ; Implement the following representation changes that should make type-based evaluation easier; - [x] change `INSDUP` to`INS` when the duplicated ref region, denoted with annotation `DUP_REPEAT_UNIT_REF_SPAN`, is shorter than 50 bp.; - [x] change scarred del",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4111#issuecomment-375438021
https://github.com/broadinstitute/gatk/issues/4111#issuecomment-375438021:2001,Testability,test,test,2001,"r cases; ; - [x] `ChimericAlignment`; - [x] update documentation; - [x] implement a `getCoordinateSortedRefSpans()`, and use in `BreakpointsInference`; - [x] `isNeitherSimpleTranslocationNorIncompletePicture()`; - [x] `extractSimpleChimera()`. ### bump test coverage; Once code above is consolidated, bump test coverage, particularly for the classes above and the following poorly-covered classes; - [x] `ChimericAlignment`; - [x] `isForwardStrandRepresentation()`; - [x] `splitPairStrongEnoughEvidenceForCA()` ; - [x] `parseOneContig()` (needs testing because we need it for simple-re-interpretation for CPX variants) Note that `nextAlignmentMayBeInsertion()` is currently broken in the sense that when using this to filter out alignments whose ref span is contained by another, check if the two alignments involved are head/tail. - [x] `BreakpointsInference` & `BreakpointComplications`. - [x] `NovelAdjacencyAndAltHaplotype`; - [x] `toSimpleOrBNDTypes()`. - [x] `SimpleNovelAdjacencyAndChimericAlignmentEvidence`; - [x] serialization test. - [x] `AnnotatedVariantProducer`; - [x] `produceAnnotatedBNDmatesVcFromNovelAdjacency()`. - [x] `BreakEndVariantType`. - [ ] `SvDiscoverFromLocalAssemblyContigAlignmentsSpark` integration test; . ### update how variants are represented ; Implement the following representation changes that should make type-based evaluation easier; - [x] change `INSDUP` to`INS` when the duplicated ref region, denoted with annotation `DUP_REPEAT_UNIT_REF_SPAN`, is shorter than 50 bp.; - [x] change scarred deletion calls, which currently output as `DEL` with `INSSEQ` annotation, to one of these; - [x] `INS`/`DEL`, when deleted/inserted bases are < 50 bp and annotate accordingly; when type is determined as`INS`, the `POS` will be 1 base before the micro-deleted range and `END` will be end of the micro-deleted range, where the `REF` allele will be the corresponding reference bases.; - [x] two records `INS` and `DEL` when both are >= 50, share the same `POS`, and lin",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4111#issuecomment-375438021
https://github.com/broadinstitute/gatk/issues/4111#issuecomment-375438021:2195,Testability,test,test,2195,"ePicture()`; - [x] `extractSimpleChimera()`. ### bump test coverage; Once code above is consolidated, bump test coverage, particularly for the classes above and the following poorly-covered classes; - [x] `ChimericAlignment`; - [x] `isForwardStrandRepresentation()`; - [x] `splitPairStrongEnoughEvidenceForCA()` ; - [x] `parseOneContig()` (needs testing because we need it for simple-re-interpretation for CPX variants) Note that `nextAlignmentMayBeInsertion()` is currently broken in the sense that when using this to filter out alignments whose ref span is contained by another, check if the two alignments involved are head/tail. - [x] `BreakpointsInference` & `BreakpointComplications`. - [x] `NovelAdjacencyAndAltHaplotype`; - [x] `toSimpleOrBNDTypes()`. - [x] `SimpleNovelAdjacencyAndChimericAlignmentEvidence`; - [x] serialization test. - [x] `AnnotatedVariantProducer`; - [x] `produceAnnotatedBNDmatesVcFromNovelAdjacency()`. - [x] `BreakEndVariantType`. - [ ] `SvDiscoverFromLocalAssemblyContigAlignmentsSpark` integration test; . ### update how variants are represented ; Implement the following representation changes that should make type-based evaluation easier; - [x] change `INSDUP` to`INS` when the duplicated ref region, denoted with annotation `DUP_REPEAT_UNIT_REF_SPAN`, is shorter than 50 bp.; - [x] change scarred deletion calls, which currently output as `DEL` with `INSSEQ` annotation, to one of these; - [x] `INS`/`DEL`, when deleted/inserted bases are < 50 bp and annotate accordingly; when type is determined as`INS`, the `POS` will be 1 base before the micro-deleted range and `END` will be end of the micro-deleted range, where the `REF` allele will be the corresponding reference bases.; - [x] two records `INS` and `DEL` when both are >= 50, share the same `POS`, and link by `EVENT`; - [ ] we are making a choice that treats duplication expansion as insertion. If decide to treat `DUP` as a separate 1st class type, we need to ; - [ ] shift the left breakpoint to the ri",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4111#issuecomment-375438021
https://github.com/broadinstitute/gatk/issues/4111#issuecomment-375438021:720,Usability,simpl,simple,720,"Updated plan. ----------; ## Small improvements in new interpretation tool; ; - [x] Output bam instead of sam for assembly alignments; - [x] Instead of creating directory, new interpretation tool writes files (behavior consistent with current interpretation tool); - [x] Prefix with sample name for output files' names; - [x] Add `INSLEN` annotation when there's `INSSEQ`; - [x] Clarify the boundary between `AlignedContig` and `AssemblyContigWithFineTunedAlignments`; - [x] Increase test coverage for `AssemblyContigAlignmentsConfigPicker`; ; ----------; ## Consolidate logic, bump test coverage and update how variants are represented. ### consolidate logic; When initially prototyped, there's redundancy in logic for simple variants, now it's time to consolidate. - [x] `AssemblyContigWithFineTunedAlignments`; - [x] `hasIncompletePicture()`. - [x] `AssemblyContigAlignmentSignatureClassifier`; - [x] Don't make so many splits; - [x] Reduce `RawTypes` into fewer cases; ; - [x] `ChimericAlignment`; - [x] update documentation; - [x] implement a `getCoordinateSortedRefSpans()`, and use in `BreakpointsInference`; - [x] `isNeitherSimpleTranslocationNorIncompletePicture()`; - [x] `extractSimpleChimera()`. ### bump test coverage; Once code above is consolidated, bump test coverage, particularly for the classes above and the following poorly-covered classes; - [x] `ChimericAlignment`; - [x] `isForwardStrandRepresentation()`; - [x] `splitPairStrongEnoughEvidenceForCA()` ; - [x] `parseOneContig()` (needs testing because we need it for simple-re-interpretation for CPX variants) Note that `nextAlignmentMayBeInsertion()` is currently broken in the sense that when using this to filter out alignments whose ref span is contained by another, check if the two alignments involved are head/tail. - [x] `BreakpointsInference` & `BreakpointComplications`. - [x] `NovelAdjacencyAndAltHaplotype`; - [x] `toSimpleOrBNDTypes()`. - [x] `SimpleNovelAdjacencyAndChimericAlignmentEvidence`; - [x] serialization ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4111#issuecomment-375438021
https://github.com/broadinstitute/gatk/issues/4111#issuecomment-375438021:1540,Usability,simpl,simple-re-interpretation,1540," `AssemblyContigAlignmentsConfigPicker`; ; ----------; ## Consolidate logic, bump test coverage and update how variants are represented. ### consolidate logic; When initially prototyped, there's redundancy in logic for simple variants, now it's time to consolidate. - [x] `AssemblyContigWithFineTunedAlignments`; - [x] `hasIncompletePicture()`. - [x] `AssemblyContigAlignmentSignatureClassifier`; - [x] Don't make so many splits; - [x] Reduce `RawTypes` into fewer cases; ; - [x] `ChimericAlignment`; - [x] update documentation; - [x] implement a `getCoordinateSortedRefSpans()`, and use in `BreakpointsInference`; - [x] `isNeitherSimpleTranslocationNorIncompletePicture()`; - [x] `extractSimpleChimera()`. ### bump test coverage; Once code above is consolidated, bump test coverage, particularly for the classes above and the following poorly-covered classes; - [x] `ChimericAlignment`; - [x] `isForwardStrandRepresentation()`; - [x] `splitPairStrongEnoughEvidenceForCA()` ; - [x] `parseOneContig()` (needs testing because we need it for simple-re-interpretation for CPX variants) Note that `nextAlignmentMayBeInsertion()` is currently broken in the sense that when using this to filter out alignments whose ref span is contained by another, check if the two alignments involved are head/tail. - [x] `BreakpointsInference` & `BreakpointComplications`. - [x] `NovelAdjacencyAndAltHaplotype`; - [x] `toSimpleOrBNDTypes()`. - [x] `SimpleNovelAdjacencyAndChimericAlignmentEvidence`; - [x] serialization test. - [x] `AnnotatedVariantProducer`; - [x] `produceAnnotatedBNDmatesVcFromNovelAdjacency()`. - [x] `BreakEndVariantType`. - [ ] `SvDiscoverFromLocalAssemblyContigAlignmentsSpark` integration test; . ### update how variants are represented ; Implement the following representation changes that should make type-based evaluation easier; - [x] change `INSDUP` to`INS` when the duplicated ref region, denoted with annotation `DUP_REPEAT_UNIT_REF_SPAN`, is shorter than 50 bp.; - [x] change scarred del",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4111#issuecomment-375438021
https://github.com/broadinstitute/gatk/issues/4111#issuecomment-375438021:1930,Usability,Simpl,SimpleNovelAdjacencyAndChimericAlignmentEvidence,1930,"r cases; ; - [x] `ChimericAlignment`; - [x] update documentation; - [x] implement a `getCoordinateSortedRefSpans()`, and use in `BreakpointsInference`; - [x] `isNeitherSimpleTranslocationNorIncompletePicture()`; - [x] `extractSimpleChimera()`. ### bump test coverage; Once code above is consolidated, bump test coverage, particularly for the classes above and the following poorly-covered classes; - [x] `ChimericAlignment`; - [x] `isForwardStrandRepresentation()`; - [x] `splitPairStrongEnoughEvidenceForCA()` ; - [x] `parseOneContig()` (needs testing because we need it for simple-re-interpretation for CPX variants) Note that `nextAlignmentMayBeInsertion()` is currently broken in the sense that when using this to filter out alignments whose ref span is contained by another, check if the two alignments involved are head/tail. - [x] `BreakpointsInference` & `BreakpointComplications`. - [x] `NovelAdjacencyAndAltHaplotype`; - [x] `toSimpleOrBNDTypes()`. - [x] `SimpleNovelAdjacencyAndChimericAlignmentEvidence`; - [x] serialization test. - [x] `AnnotatedVariantProducer`; - [x] `produceAnnotatedBNDmatesVcFromNovelAdjacency()`. - [x] `BreakEndVariantType`. - [ ] `SvDiscoverFromLocalAssemblyContigAlignmentsSpark` integration test; . ### update how variants are represented ; Implement the following representation changes that should make type-based evaluation easier; - [x] change `INSDUP` to`INS` when the duplicated ref region, denoted with annotation `DUP_REPEAT_UNIT_REF_SPAN`, is shorter than 50 bp.; - [x] change scarred deletion calls, which currently output as `DEL` with `INSSEQ` annotation, to one of these; - [x] `INS`/`DEL`, when deleted/inserted bases are < 50 bp and annotate accordingly; when type is determined as`INS`, the `POS` will be 1 base before the micro-deleted range and `END` will be end of the micro-deleted range, where the `REF` allele will be the corresponding reference bases.; - [x] two records `INS` and `DEL` when both are >= 50, share the same `POS`, and lin",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4111#issuecomment-375438021
https://github.com/broadinstitute/gatk/issues/4111#issuecomment-375438021:3402,Usability,simpl,simple,3402," `parseOneContig()` (needs testing because we need it for simple-re-interpretation for CPX variants) Note that `nextAlignmentMayBeInsertion()` is currently broken in the sense that when using this to filter out alignments whose ref span is contained by another, check if the two alignments involved are head/tail. - [x] `BreakpointsInference` & `BreakpointComplications`. - [x] `NovelAdjacencyAndAltHaplotype`; - [x] `toSimpleOrBNDTypes()`. - [x] `SimpleNovelAdjacencyAndChimericAlignmentEvidence`; - [x] serialization test. - [x] `AnnotatedVariantProducer`; - [x] `produceAnnotatedBNDmatesVcFromNovelAdjacency()`. - [x] `BreakEndVariantType`. - [ ] `SvDiscoverFromLocalAssemblyContigAlignmentsSpark` integration test; . ### update how variants are represented ; Implement the following representation changes that should make type-based evaluation easier; - [x] change `INSDUP` to`INS` when the duplicated ref region, denoted with annotation `DUP_REPEAT_UNIT_REF_SPAN`, is shorter than 50 bp.; - [x] change scarred deletion calls, which currently output as `DEL` with `INSSEQ` annotation, to one of these; - [x] `INS`/`DEL`, when deleted/inserted bases are < 50 bp and annotate accordingly; when type is determined as`INS`, the `POS` will be 1 base before the micro-deleted range and `END` will be end of the micro-deleted range, where the `REF` allele will be the corresponding reference bases.; - [x] two records `INS` and `DEL` when both are >= 50, share the same `POS`, and link by `EVENT`; - [ ] we are making a choice that treats duplication expansion as insertion. If decide to treat `DUP` as a separate 1st class type, we need to ; - [ ] shift the left breakpoint to the right by 1 base compared to the current implementation, and ; - [ ] `downstreamBreakpointRefPos = complication.getDupSeqRepeatUnitRefSpan().getEnd();`. ----------; ## CPX variant re-interpretation. Send cpx variant for re-interpretation of simple basic types, and check for consistency (this might be the difficult part)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4111#issuecomment-375438021
https://github.com/broadinstitute/gatk/issues/4111#issuecomment-401497712:0,Deployability,Update,Updated,0,Updated TODO list:. - [x] #4962 ; - [x] #4970; - [x] #4971; - [ ] #5077 . (optional):. - [ ] #4406 or make a PR to address #4684 ; - [ ] #4789,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4111#issuecomment-401497712
https://github.com/broadinstitute/gatk/issues/4112#issuecomment-357043845:76,Security,validat,validation,76,"@Sun-shan Hi, could you try running with the `--disable-sequence-dictionary-validation` command?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4112#issuecomment-357043845
https://github.com/broadinstitute/gatk/pull/4118#issuecomment-356754166:99,Availability,failure,failures,99,"@lbergelson @droazen Just noticed the M2 WDL test is failing here---is this similar to the CNV WDL failures you were seeing just before release?. ````; No output has been received in the last 10m0s, this potentially indicates a stalled build or something wrong with the build itself.; Check the details on how to adjust your build configuration on: https://docs.travis-ci.com/user/common-build-problems/#Build-times-out-because-no-output-was-received; The build has been terminated; ````. If so, this is definitely something I've seen more frequently lately. Not sure what the remedy is, but would probably be worth looking into soon so we don't lose too much time to intermittent failures.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4118#issuecomment-356754166
https://github.com/broadinstitute/gatk/pull/4118#issuecomment-356754166:681,Availability,failure,failures,681,"@lbergelson @droazen Just noticed the M2 WDL test is failing here---is this similar to the CNV WDL failures you were seeing just before release?. ````; No output has been received in the last 10m0s, this potentially indicates a stalled build or something wrong with the build itself.; Check the details on how to adjust your build configuration on: https://docs.travis-ci.com/user/common-build-problems/#Build-times-out-because-no-output-was-received; The build has been terminated; ````. If so, this is definitely something I've seen more frequently lately. Not sure what the remedy is, but would probably be worth looking into soon so we don't lose too much time to intermittent failures.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4118#issuecomment-356754166
https://github.com/broadinstitute/gatk/pull/4118#issuecomment-356754166:136,Deployability,release,release,136,"@lbergelson @droazen Just noticed the M2 WDL test is failing here---is this similar to the CNV WDL failures you were seeing just before release?. ````; No output has been received in the last 10m0s, this potentially indicates a stalled build or something wrong with the build itself.; Check the details on how to adjust your build configuration on: https://docs.travis-ci.com/user/common-build-problems/#Build-times-out-because-no-output-was-received; The build has been terminated; ````. If so, this is definitely something I've seen more frequently lately. Not sure what the remedy is, but would probably be worth looking into soon so we don't lose too much time to intermittent failures.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4118#issuecomment-356754166
https://github.com/broadinstitute/gatk/pull/4118#issuecomment-356754166:331,Deployability,configurat,configuration,331,"@lbergelson @droazen Just noticed the M2 WDL test is failing here---is this similar to the CNV WDL failures you were seeing just before release?. ````; No output has been received in the last 10m0s, this potentially indicates a stalled build or something wrong with the build itself.; Check the details on how to adjust your build configuration on: https://docs.travis-ci.com/user/common-build-problems/#Build-times-out-because-no-output-was-received; The build has been terminated; ````. If so, this is definitely something I've seen more frequently lately. Not sure what the remedy is, but would probably be worth looking into soon so we don't lose too much time to intermittent failures.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4118#issuecomment-356754166
https://github.com/broadinstitute/gatk/pull/4118#issuecomment-356754166:331,Modifiability,config,configuration,331,"@lbergelson @droazen Just noticed the M2 WDL test is failing here---is this similar to the CNV WDL failures you were seeing just before release?. ````; No output has been received in the last 10m0s, this potentially indicates a stalled build or something wrong with the build itself.; Check the details on how to adjust your build configuration on: https://docs.travis-ci.com/user/common-build-problems/#Build-times-out-because-no-output-was-received; The build has been terminated; ````. If so, this is definitely something I've seen more frequently lately. Not sure what the remedy is, but would probably be worth looking into soon so we don't lose too much time to intermittent failures.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4118#issuecomment-356754166
https://github.com/broadinstitute/gatk/pull/4118#issuecomment-356754166:45,Testability,test,test,45,"@lbergelson @droazen Just noticed the M2 WDL test is failing here---is this similar to the CNV WDL failures you were seeing just before release?. ````; No output has been received in the last 10m0s, this potentially indicates a stalled build or something wrong with the build itself.; Check the details on how to adjust your build configuration on: https://docs.travis-ci.com/user/common-build-problems/#Build-times-out-because-no-output-was-received; The build has been terminated; ````. If so, this is definitely something I've seen more frequently lately. Not sure what the remedy is, but would probably be worth looking into soon so we don't lose too much time to intermittent failures.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4118#issuecomment-356754166
https://github.com/broadinstitute/gatk/pull/4118#issuecomment-356761950:121,Security,access,access,121,"@samuelklee Yes, this looks similar to what happened in master yesterday. In that case it looked like a transient remote access issue during the docker build. Having said that, its strange that the two data points we have were both on M2 WDL build.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4118#issuecomment-356761950
https://github.com/broadinstitute/gatk/pull/4118#issuecomment-357038771:98,Testability,test,test,98,I opened https://github.com/broadinstitute/gatk/issues/4129 to keep track of this. If we can save test logs there when they happen maybe it will help shed light on the problem.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4118#issuecomment-357038771
https://github.com/broadinstitute/gatk/pull/4118#issuecomment-357038771:103,Testability,log,logs,103,I opened https://github.com/broadinstitute/gatk/issues/4129 to keep track of this. If we can save test logs there when they happen maybe it will help shed light on the problem.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4118#issuecomment-357038771
https://github.com/broadinstitute/gatk/pull/4118#issuecomment-358059593:140,Deployability,release,release,140,"Closing this one -- we don't want to strip out SNAPSHOT from the version in docs generated from an actual snapshot. . If docs for an actual release end up with SNAPSHOT in the version, you probably need to run with `-Drelease=true`.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4118#issuecomment-358059593
https://github.com/broadinstitute/gatk/pull/4119#issuecomment-358670326:1923,Usability,Simpl,SimpleSVType,1923,; |---|---|---|---|; | [...bender/tools/copynumber/CollectFragmentCounts.java](https://codecov.io/gh/broadinstitute/gatk/pull/4119/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL0NvbGxlY3RGcmFnbWVudENvdW50cy5qYXZh) | `85.507% <ø> (ø)` | `10 <0> (ø)` | :arrow_down: |; | [...ls/copynumber/models/MultidimensionalModeller.java](https://codecov.io/gh/broadinstitute/gatk/pull/4119/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL21vZGVscy9NdWx0aWRpbWVuc2lvbmFsTW9kZWxsZXIuamF2YQ==) | `76.271% <0%> (+1.656%)` | `13 <0> (+4)` | :arrow_up: |; | [...tools/walkers/mutect/SomaticLikelihoodsEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/4119/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9Tb21hdGljTGlrZWxpaG9vZHNFbmdpbmUuamF2YQ==) | `83.871% <0%> (-2.971%)` | `22% <0%> (+8%)` | |; | [...lbender/tools/spark/sv/discovery/SimpleSVType.java](https://codecov.io/gh/broadinstitute/gatk/pull/4119/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvU2ltcGxlU1ZUeXBlLmphdmE=) | `86.275% <0%> (-0.293%)` | `4% <0%> (+2%)` | |; | [...otator/dataSources/gencode/GencodeFuncotation.java](https://codecov.io/gh/broadinstitute/gatk/pull/4119/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL2dlbmNvZGUvR2VuY29kZUZ1bmNvdGF0aW9uLmphdmE=) | `57.505% <0%> (-0.176%)` | `293% <0%> (+174%)` | |; | [.../sv/StructuralVariationDiscoveryPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4119/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9TdHJ1Y3R1cmFsVmFyaWF0aW9uRGlzY292ZXJ5UGlwZWxpbmVTcGFyay5qYXZh) | `91.351% <0%> (-0.158%)` | `13% <0%> (+5%)` | |; | [...llbender/tools/copynumber/PreprocessIntervals.java](https://c,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4119#issuecomment-358670326
https://github.com/broadinstitute/gatk/issues/4120#issuecomment-356718095:782,Performance,load,loadNextAssemblyRegion,782,"I see the exception on most chromosomes, here's the one for chr1:. java.lang.IllegalArgumentException: Invalid interval. Contig:chr1 start:79293873 end:79293872; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:687); at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:37); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:49); at org.broadinstitute.hellbender.engine.AssemblyRegion.add(AssemblyRegion.java:335); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.fillNextAssemblyRegionWithReads(AssemblyRegionIterator.java:230); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.loadNextAssemblyRegion(AssemblyRegionIterator.java:194); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.next(AssemblyRegionIterator.java:135); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.next(AssemblyRegionIterator.java:34); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:290); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:271); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:893); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:136); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:152); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:195); at org.broadinstitute.hellbender.Main.main(Main.java:275)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4120#issuecomment-356718095
https://github.com/broadinstitute/gatk/issues/4120#issuecomment-356718095:207,Security,validat,validateArg,207,"I see the exception on most chromosomes, here's the one for chr1:. java.lang.IllegalArgumentException: Invalid interval. Contig:chr1 start:79293873 end:79293872; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:687); at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:37); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:49); at org.broadinstitute.hellbender.engine.AssemblyRegion.add(AssemblyRegion.java:335); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.fillNextAssemblyRegionWithReads(AssemblyRegionIterator.java:230); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.loadNextAssemblyRegion(AssemblyRegionIterator.java:194); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.next(AssemblyRegionIterator.java:135); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.next(AssemblyRegionIterator.java:34); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:290); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:271); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:893); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:136); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:152); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:195); at org.broadinstitute.hellbender.Main.main(Main.java:275)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4120#issuecomment-356718095
https://github.com/broadinstitute/gatk/issues/4120#issuecomment-356718095:290,Security,validat,validatePositions,290,"I see the exception on most chromosomes, here's the one for chr1:. java.lang.IllegalArgumentException: Invalid interval. Contig:chr1 start:79293873 end:79293872; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:687); at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:37); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:49); at org.broadinstitute.hellbender.engine.AssemblyRegion.add(AssemblyRegion.java:335); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.fillNextAssemblyRegionWithReads(AssemblyRegionIterator.java:230); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.loadNextAssemblyRegion(AssemblyRegionIterator.java:194); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.next(AssemblyRegionIterator.java:135); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.next(AssemblyRegionIterator.java:34); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:290); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:271); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:893); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:136); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:152); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:195); at org.broadinstitute.hellbender.Main.main(Main.java:275)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4120#issuecomment-356718095
https://github.com/broadinstitute/gatk/issues/4120#issuecomment-356718095:275,Usability,Simpl,SimpleInterval,275,"I see the exception on most chromosomes, here's the one for chr1:. java.lang.IllegalArgumentException: Invalid interval. Contig:chr1 start:79293873 end:79293872; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:687); at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:37); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:49); at org.broadinstitute.hellbender.engine.AssemblyRegion.add(AssemblyRegion.java:335); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.fillNextAssemblyRegionWithReads(AssemblyRegionIterator.java:230); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.loadNextAssemblyRegion(AssemblyRegionIterator.java:194); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.next(AssemblyRegionIterator.java:135); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.next(AssemblyRegionIterator.java:34); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:290); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:271); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:893); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:136); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:152); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:195); at org.broadinstitute.hellbender.Main.main(Main.java:275)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4120#issuecomment-356718095
https://github.com/broadinstitute/gatk/issues/4120#issuecomment-356718095:308,Usability,Simpl,SimpleInterval,308,"I see the exception on most chromosomes, here's the one for chr1:. java.lang.IllegalArgumentException: Invalid interval. Contig:chr1 start:79293873 end:79293872; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:687); at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:37); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:49); at org.broadinstitute.hellbender.engine.AssemblyRegion.add(AssemblyRegion.java:335); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.fillNextAssemblyRegionWithReads(AssemblyRegionIterator.java:230); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.loadNextAssemblyRegion(AssemblyRegionIterator.java:194); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.next(AssemblyRegionIterator.java:135); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.next(AssemblyRegionIterator.java:34); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:290); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:271); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:893); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:136); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:152); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:195); at org.broadinstitute.hellbender.Main.main(Main.java:275)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4120#issuecomment-356718095
https://github.com/broadinstitute/gatk/issues/4120#issuecomment-356718095:372,Usability,Simpl,SimpleInterval,372,"I see the exception on most chromosomes, here's the one for chr1:. java.lang.IllegalArgumentException: Invalid interval. Contig:chr1 start:79293873 end:79293872; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:687); at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:37); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:49); at org.broadinstitute.hellbender.engine.AssemblyRegion.add(AssemblyRegion.java:335); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.fillNextAssemblyRegionWithReads(AssemblyRegionIterator.java:230); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.loadNextAssemblyRegion(AssemblyRegionIterator.java:194); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.next(AssemblyRegionIterator.java:135); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.next(AssemblyRegionIterator.java:34); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:290); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:271); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:893); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:136); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:152); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:195); at org.broadinstitute.hellbender.Main.main(Main.java:275)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4120#issuecomment-356718095
https://github.com/broadinstitute/gatk/issues/4120#issuecomment-356718095:394,Usability,Simpl,SimpleInterval,394,"I see the exception on most chromosomes, here's the one for chr1:. java.lang.IllegalArgumentException: Invalid interval. Contig:chr1 start:79293873 end:79293872; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:687); at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:37); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:49); at org.broadinstitute.hellbender.engine.AssemblyRegion.add(AssemblyRegion.java:335); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.fillNextAssemblyRegionWithReads(AssemblyRegionIterator.java:230); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.loadNextAssemblyRegion(AssemblyRegionIterator.java:194); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.next(AssemblyRegionIterator.java:135); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.next(AssemblyRegionIterator.java:34); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:290); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:271); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:893); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:136); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:152); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:195); at org.broadinstitute.hellbender.Main.main(Main.java:275)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4120#issuecomment-356718095
https://github.com/broadinstitute/gatk/issues/4120#issuecomment-356718095:458,Usability,Simpl,SimpleInterval,458,"I see the exception on most chromosomes, here's the one for chr1:. java.lang.IllegalArgumentException: Invalid interval. Contig:chr1 start:79293873 end:79293872; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:687); at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:37); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:49); at org.broadinstitute.hellbender.engine.AssemblyRegion.add(AssemblyRegion.java:335); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.fillNextAssemblyRegionWithReads(AssemblyRegionIterator.java:230); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.loadNextAssemblyRegion(AssemblyRegionIterator.java:194); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.next(AssemblyRegionIterator.java:135); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.next(AssemblyRegionIterator.java:34); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:290); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:271); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:893); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:136); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:152); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:195); at org.broadinstitute.hellbender.Main.main(Main.java:275)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4120#issuecomment-356718095
https://github.com/broadinstitute/gatk/issues/4120#issuecomment-356718095:480,Usability,Simpl,SimpleInterval,480,"I see the exception on most chromosomes, here's the one for chr1:. java.lang.IllegalArgumentException: Invalid interval. Contig:chr1 start:79293873 end:79293872; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:687); at org.broadinstitute.hellbender.utils.SimpleInterval.validatePositions(SimpleInterval.java:61); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:37); at org.broadinstitute.hellbender.utils.SimpleInterval.<init>(SimpleInterval.java:49); at org.broadinstitute.hellbender.engine.AssemblyRegion.add(AssemblyRegion.java:335); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.fillNextAssemblyRegionWithReads(AssemblyRegionIterator.java:230); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.loadNextAssemblyRegion(AssemblyRegionIterator.java:194); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.next(AssemblyRegionIterator.java:135); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.next(AssemblyRegionIterator.java:34); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:290); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:271); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:893); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:136); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:152); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:195); at org.broadinstitute.hellbender.Main.main(Main.java:275)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4120#issuecomment-356718095
https://github.com/broadinstitute/gatk/issues/4122#issuecomment-459833697:627,Availability,mainten,maintenance,627,"Evaluation of THCA/STAD/LUAD TCGA WGS/WES CR concordance with SNP arrays was implemented on FC last summer and showed good performance. For WES, comparisons against GATK CNV and CODEX showed comparable to highly improved performance, respectively, with minimal parameter tuning. WGS comparisons were unavailable due to limitations of competing tools. This evaluation will be expanded to include CR/MAF concordance against PanCanAtlas ABSOLUTE results. Some curation of the samples could be performed; some batch effects were observed in some LC WGS LUAD samples. Comparisons to other tools will probably be removed for ease of maintenance. Will be adapted to fit into whatever framework arises from #4630; same goes for HCC1143 and CRSP validations.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4122#issuecomment-459833697
https://github.com/broadinstitute/gatk/issues/4122#issuecomment-459833697:648,Energy Efficiency,adapt,adapted,648,"Evaluation of THCA/STAD/LUAD TCGA WGS/WES CR concordance with SNP arrays was implemented on FC last summer and showed good performance. For WES, comparisons against GATK CNV and CODEX showed comparable to highly improved performance, respectively, with minimal parameter tuning. WGS comparisons were unavailable due to limitations of competing tools. This evaluation will be expanded to include CR/MAF concordance against PanCanAtlas ABSOLUTE results. Some curation of the samples could be performed; some batch effects were observed in some LC WGS LUAD samples. Comparisons to other tools will probably be removed for ease of maintenance. Will be adapted to fit into whatever framework arises from #4630; same goes for HCC1143 and CRSP validations.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4122#issuecomment-459833697
https://github.com/broadinstitute/gatk/issues/4122#issuecomment-459833697:648,Modifiability,adapt,adapted,648,"Evaluation of THCA/STAD/LUAD TCGA WGS/WES CR concordance with SNP arrays was implemented on FC last summer and showed good performance. For WES, comparisons against GATK CNV and CODEX showed comparable to highly improved performance, respectively, with minimal parameter tuning. WGS comparisons were unavailable due to limitations of competing tools. This evaluation will be expanded to include CR/MAF concordance against PanCanAtlas ABSOLUTE results. Some curation of the samples could be performed; some batch effects were observed in some LC WGS LUAD samples. Comparisons to other tools will probably be removed for ease of maintenance. Will be adapted to fit into whatever framework arises from #4630; same goes for HCC1143 and CRSP validations.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4122#issuecomment-459833697
https://github.com/broadinstitute/gatk/issues/4122#issuecomment-459833697:123,Performance,perform,performance,123,"Evaluation of THCA/STAD/LUAD TCGA WGS/WES CR concordance with SNP arrays was implemented on FC last summer and showed good performance. For WES, comparisons against GATK CNV and CODEX showed comparable to highly improved performance, respectively, with minimal parameter tuning. WGS comparisons were unavailable due to limitations of competing tools. This evaluation will be expanded to include CR/MAF concordance against PanCanAtlas ABSOLUTE results. Some curation of the samples could be performed; some batch effects were observed in some LC WGS LUAD samples. Comparisons to other tools will probably be removed for ease of maintenance. Will be adapted to fit into whatever framework arises from #4630; same goes for HCC1143 and CRSP validations.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4122#issuecomment-459833697
https://github.com/broadinstitute/gatk/issues/4122#issuecomment-459833697:221,Performance,perform,performance,221,"Evaluation of THCA/STAD/LUAD TCGA WGS/WES CR concordance with SNP arrays was implemented on FC last summer and showed good performance. For WES, comparisons against GATK CNV and CODEX showed comparable to highly improved performance, respectively, with minimal parameter tuning. WGS comparisons were unavailable due to limitations of competing tools. This evaluation will be expanded to include CR/MAF concordance against PanCanAtlas ABSOLUTE results. Some curation of the samples could be performed; some batch effects were observed in some LC WGS LUAD samples. Comparisons to other tools will probably be removed for ease of maintenance. Will be adapted to fit into whatever framework arises from #4630; same goes for HCC1143 and CRSP validations.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4122#issuecomment-459833697
https://github.com/broadinstitute/gatk/issues/4122#issuecomment-459833697:490,Performance,perform,performed,490,"Evaluation of THCA/STAD/LUAD TCGA WGS/WES CR concordance with SNP arrays was implemented on FC last summer and showed good performance. For WES, comparisons against GATK CNV and CODEX showed comparable to highly improved performance, respectively, with minimal parameter tuning. WGS comparisons were unavailable due to limitations of competing tools. This evaluation will be expanded to include CR/MAF concordance against PanCanAtlas ABSOLUTE results. Some curation of the samples could be performed; some batch effects were observed in some LC WGS LUAD samples. Comparisons to other tools will probably be removed for ease of maintenance. Will be adapted to fit into whatever framework arises from #4630; same goes for HCC1143 and CRSP validations.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4122#issuecomment-459833697
https://github.com/broadinstitute/gatk/issues/4122#issuecomment-459833697:737,Security,validat,validations,737,"Evaluation of THCA/STAD/LUAD TCGA WGS/WES CR concordance with SNP arrays was implemented on FC last summer and showed good performance. For WES, comparisons against GATK CNV and CODEX showed comparable to highly improved performance, respectively, with minimal parameter tuning. WGS comparisons were unavailable due to limitations of competing tools. This evaluation will be expanded to include CR/MAF concordance against PanCanAtlas ABSOLUTE results. Some curation of the samples could be performed; some batch effects were observed in some LC WGS LUAD samples. Comparisons to other tools will probably be removed for ease of maintenance. Will be adapted to fit into whatever framework arises from #4630; same goes for HCC1143 and CRSP validations.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4122#issuecomment-459833697
https://github.com/broadinstitute/gatk/issues/4122#issuecomment-461607380:526,Availability,down,down,526,"Note that no segmentation or resolution parameters have been tuned yet for either performance or runtime. Some of these are very easy wins. For example, `kernel-approximation-dimension` is set to a default of 100, and the time for segmentation scales roughly linearly with this (documentation erroneously states that the scaling is quadratic, this should be fixed---my bad). In practice, setting this to as little as 2 seems to work OK for some cases, so we should evaluate this more rigorously. This can cut WGS segmentation down from ~10 minutes (out of the total ~60 minutes for 250bp bins, typically) to ~1 minute.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4122#issuecomment-461607380
https://github.com/broadinstitute/gatk/issues/4122#issuecomment-461607380:61,Performance,tune,tuned,61,"Note that no segmentation or resolution parameters have been tuned yet for either performance or runtime. Some of these are very easy wins. For example, `kernel-approximation-dimension` is set to a default of 100, and the time for segmentation scales roughly linearly with this (documentation erroneously states that the scaling is quadratic, this should be fixed---my bad). In practice, setting this to as little as 2 seems to work OK for some cases, so we should evaluate this more rigorously. This can cut WGS segmentation down from ~10 minutes (out of the total ~60 minutes for 250bp bins, typically) to ~1 minute.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4122#issuecomment-461607380
https://github.com/broadinstitute/gatk/issues/4122#issuecomment-461607380:82,Performance,perform,performance,82,"Note that no segmentation or resolution parameters have been tuned yet for either performance or runtime. Some of these are very easy wins. For example, `kernel-approximation-dimension` is set to a default of 100, and the time for segmentation scales roughly linearly with this (documentation erroneously states that the scaling is quadratic, this should be fixed---my bad). In practice, setting this to as little as 2 seems to work OK for some cases, so we should evaluate this more rigorously. This can cut WGS segmentation down from ~10 minutes (out of the total ~60 minutes for 250bp bins, typically) to ~1 minute.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4122#issuecomment-461607380
https://github.com/broadinstitute/gatk/issues/4122#issuecomment-526272699:540,Availability,down,down,540,"Revamping the existing somatic validation pipeline needs to be done before development of the TH prototype can continue. - [ ] Identify test bed of TCGA samples from various tumor types. We can mix tumor-normal samples (as I've done at the counts/allelic-counts level in preliminary evaluations of the TH prototype) to expand the effective number of samples.; - [ ] Determine minimal version of current CGA ABSOLUTE pipeline (to be used as a baseline for comparison).; - [ ] Generate and manually curate ABSOLUTE results and narrow samples down to those with relatively robust solutions.; - [ ] Construct ModelSegments/M2 -> ABSOLUTE pipeline (will at least require minor development/tuning of ModelSegments output -> ABSOLUTE input conversion script, may also require germline tagging, see related #5804) and evaluate.; - [ ] Construct ModelSegments/M2 -> TH pipeline and evaluate.; - [ ] Remove unsupported code/tools. See https://github.com/broadinstitute/gatk/pull/5450#issuecomment-461431199 for a summary. We should make sure that any users that would be affected by this are notified and prepare accordingly.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4122#issuecomment-526272699
https://github.com/broadinstitute/gatk/issues/4122#issuecomment-526272699:570,Availability,robust,robust,570,"Revamping the existing somatic validation pipeline needs to be done before development of the TH prototype can continue. - [ ] Identify test bed of TCGA samples from various tumor types. We can mix tumor-normal samples (as I've done at the counts/allelic-counts level in preliminary evaluations of the TH prototype) to expand the effective number of samples.; - [ ] Determine minimal version of current CGA ABSOLUTE pipeline (to be used as a baseline for comparison).; - [ ] Generate and manually curate ABSOLUTE results and narrow samples down to those with relatively robust solutions.; - [ ] Construct ModelSegments/M2 -> ABSOLUTE pipeline (will at least require minor development/tuning of ModelSegments output -> ABSOLUTE input conversion script, may also require germline tagging, see related #5804) and evaluate.; - [ ] Construct ModelSegments/M2 -> TH pipeline and evaluate.; - [ ] Remove unsupported code/tools. See https://github.com/broadinstitute/gatk/pull/5450#issuecomment-461431199 for a summary. We should make sure that any users that would be affected by this are notified and prepare accordingly.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4122#issuecomment-526272699
https://github.com/broadinstitute/gatk/issues/4122#issuecomment-526272699:42,Deployability,pipeline,pipeline,42,"Revamping the existing somatic validation pipeline needs to be done before development of the TH prototype can continue. - [ ] Identify test bed of TCGA samples from various tumor types. We can mix tumor-normal samples (as I've done at the counts/allelic-counts level in preliminary evaluations of the TH prototype) to expand the effective number of samples.; - [ ] Determine minimal version of current CGA ABSOLUTE pipeline (to be used as a baseline for comparison).; - [ ] Generate and manually curate ABSOLUTE results and narrow samples down to those with relatively robust solutions.; - [ ] Construct ModelSegments/M2 -> ABSOLUTE pipeline (will at least require minor development/tuning of ModelSegments output -> ABSOLUTE input conversion script, may also require germline tagging, see related #5804) and evaluate.; - [ ] Construct ModelSegments/M2 -> TH pipeline and evaluate.; - [ ] Remove unsupported code/tools. See https://github.com/broadinstitute/gatk/pull/5450#issuecomment-461431199 for a summary. We should make sure that any users that would be affected by this are notified and prepare accordingly.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4122#issuecomment-526272699
https://github.com/broadinstitute/gatk/issues/4122#issuecomment-526272699:416,Deployability,pipeline,pipeline,416,"Revamping the existing somatic validation pipeline needs to be done before development of the TH prototype can continue. - [ ] Identify test bed of TCGA samples from various tumor types. We can mix tumor-normal samples (as I've done at the counts/allelic-counts level in preliminary evaluations of the TH prototype) to expand the effective number of samples.; - [ ] Determine minimal version of current CGA ABSOLUTE pipeline (to be used as a baseline for comparison).; - [ ] Generate and manually curate ABSOLUTE results and narrow samples down to those with relatively robust solutions.; - [ ] Construct ModelSegments/M2 -> ABSOLUTE pipeline (will at least require minor development/tuning of ModelSegments output -> ABSOLUTE input conversion script, may also require germline tagging, see related #5804) and evaluate.; - [ ] Construct ModelSegments/M2 -> TH pipeline and evaluate.; - [ ] Remove unsupported code/tools. See https://github.com/broadinstitute/gatk/pull/5450#issuecomment-461431199 for a summary. We should make sure that any users that would be affected by this are notified and prepare accordingly.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4122#issuecomment-526272699
https://github.com/broadinstitute/gatk/issues/4122#issuecomment-526272699:634,Deployability,pipeline,pipeline,634,"Revamping the existing somatic validation pipeline needs to be done before development of the TH prototype can continue. - [ ] Identify test bed of TCGA samples from various tumor types. We can mix tumor-normal samples (as I've done at the counts/allelic-counts level in preliminary evaluations of the TH prototype) to expand the effective number of samples.; - [ ] Determine minimal version of current CGA ABSOLUTE pipeline (to be used as a baseline for comparison).; - [ ] Generate and manually curate ABSOLUTE results and narrow samples down to those with relatively robust solutions.; - [ ] Construct ModelSegments/M2 -> ABSOLUTE pipeline (will at least require minor development/tuning of ModelSegments output -> ABSOLUTE input conversion script, may also require germline tagging, see related #5804) and evaluate.; - [ ] Construct ModelSegments/M2 -> TH pipeline and evaluate.; - [ ] Remove unsupported code/tools. See https://github.com/broadinstitute/gatk/pull/5450#issuecomment-461431199 for a summary. We should make sure that any users that would be affected by this are notified and prepare accordingly.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4122#issuecomment-526272699
https://github.com/broadinstitute/gatk/issues/4122#issuecomment-526272699:860,Deployability,pipeline,pipeline,860,"Revamping the existing somatic validation pipeline needs to be done before development of the TH prototype can continue. - [ ] Identify test bed of TCGA samples from various tumor types. We can mix tumor-normal samples (as I've done at the counts/allelic-counts level in preliminary evaluations of the TH prototype) to expand the effective number of samples.; - [ ] Determine minimal version of current CGA ABSOLUTE pipeline (to be used as a baseline for comparison).; - [ ] Generate and manually curate ABSOLUTE results and narrow samples down to those with relatively robust solutions.; - [ ] Construct ModelSegments/M2 -> ABSOLUTE pipeline (will at least require minor development/tuning of ModelSegments output -> ABSOLUTE input conversion script, may also require germline tagging, see related #5804) and evaluate.; - [ ] Construct ModelSegments/M2 -> TH pipeline and evaluate.; - [ ] Remove unsupported code/tools. See https://github.com/broadinstitute/gatk/pull/5450#issuecomment-461431199 for a summary. We should make sure that any users that would be affected by this are notified and prepare accordingly.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4122#issuecomment-526272699
https://github.com/broadinstitute/gatk/issues/4122#issuecomment-526272699:31,Security,validat,validation,31,"Revamping the existing somatic validation pipeline needs to be done before development of the TH prototype can continue. - [ ] Identify test bed of TCGA samples from various tumor types. We can mix tumor-normal samples (as I've done at the counts/allelic-counts level in preliminary evaluations of the TH prototype) to expand the effective number of samples.; - [ ] Determine minimal version of current CGA ABSOLUTE pipeline (to be used as a baseline for comparison).; - [ ] Generate and manually curate ABSOLUTE results and narrow samples down to those with relatively robust solutions.; - [ ] Construct ModelSegments/M2 -> ABSOLUTE pipeline (will at least require minor development/tuning of ModelSegments output -> ABSOLUTE input conversion script, may also require germline tagging, see related #5804) and evaluate.; - [ ] Construct ModelSegments/M2 -> TH pipeline and evaluate.; - [ ] Remove unsupported code/tools. See https://github.com/broadinstitute/gatk/pull/5450#issuecomment-461431199 for a summary. We should make sure that any users that would be affected by this are notified and prepare accordingly.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4122#issuecomment-526272699
https://github.com/broadinstitute/gatk/issues/4122#issuecomment-526272699:136,Testability,test,test,136,"Revamping the existing somatic validation pipeline needs to be done before development of the TH prototype can continue. - [ ] Identify test bed of TCGA samples from various tumor types. We can mix tumor-normal samples (as I've done at the counts/allelic-counts level in preliminary evaluations of the TH prototype) to expand the effective number of samples.; - [ ] Determine minimal version of current CGA ABSOLUTE pipeline (to be used as a baseline for comparison).; - [ ] Generate and manually curate ABSOLUTE results and narrow samples down to those with relatively robust solutions.; - [ ] Construct ModelSegments/M2 -> ABSOLUTE pipeline (will at least require minor development/tuning of ModelSegments output -> ABSOLUTE input conversion script, may also require germline tagging, see related #5804) and evaluate.; - [ ] Construct ModelSegments/M2 -> TH pipeline and evaluate.; - [ ] Remove unsupported code/tools. See https://github.com/broadinstitute/gatk/pull/5450#issuecomment-461431199 for a summary. We should make sure that any users that would be affected by this are notified and prepare accordingly.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4122#issuecomment-526272699
https://github.com/broadinstitute/gatk/issues/4123#issuecomment-362075071:134,Deployability,pipeline,pipeline,134,"Here is a recap of what we discussed today during the CNV meeting:. For the first round of evaluations we decided to run Germline CNV pipeline on TCGA exomes using a range of key hyperparameters (namely psi-t-scale and p-alt) and establish the base level performance metrics using output of GenomeSTRiP on matched WGS samples as ground truth. . @mbabadi could you come up with a good range of hyperparameter values that you think should be cross-validated?. In particular we need to:. - Dockerize tools we will be evaluating against (XHMM, CODEX2, CLAMMS, GenomeSTRiP); - Write a WDL that runs Germline CNV that scatters across range of key hyperparameters and outputs array of VCFs; - Write VCF processors for output of CLAMMS and CODEX2 ; - Write WDLs for running XHMM, CODEX2, CLAMMS and GenomeSTRiP that output VCFs; - Write WDL that takes results of the above and uses @mbabadi 's gCNV evaluation python modules(located here /dsde/working/mehrtash/gCNV_theano_eval) to output performance metrics; - Decide on an automatic evaluation framework. For the next round of evaluations we need to:. - Decide on appropriate metrics for evaluating performance on trios and write scripts that implement them; - Expand the range of hyperparameters in search space (possibly include different bin sizes, GC vs no GC correction, and fragment mid point coverage collection vs largest fragment overlap coverage collection); - Use gnomAD subset of matched WES/WGS pairs for validation",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4123#issuecomment-362075071
https://github.com/broadinstitute/gatk/issues/4123#issuecomment-362075071:255,Performance,perform,performance,255,"Here is a recap of what we discussed today during the CNV meeting:. For the first round of evaluations we decided to run Germline CNV pipeline on TCGA exomes using a range of key hyperparameters (namely psi-t-scale and p-alt) and establish the base level performance metrics using output of GenomeSTRiP on matched WGS samples as ground truth. . @mbabadi could you come up with a good range of hyperparameter values that you think should be cross-validated?. In particular we need to:. - Dockerize tools we will be evaluating against (XHMM, CODEX2, CLAMMS, GenomeSTRiP); - Write a WDL that runs Germline CNV that scatters across range of key hyperparameters and outputs array of VCFs; - Write VCF processors for output of CLAMMS and CODEX2 ; - Write WDLs for running XHMM, CODEX2, CLAMMS and GenomeSTRiP that output VCFs; - Write WDL that takes results of the above and uses @mbabadi 's gCNV evaluation python modules(located here /dsde/working/mehrtash/gCNV_theano_eval) to output performance metrics; - Decide on an automatic evaluation framework. For the next round of evaluations we need to:. - Decide on appropriate metrics for evaluating performance on trios and write scripts that implement them; - Expand the range of hyperparameters in search space (possibly include different bin sizes, GC vs no GC correction, and fragment mid point coverage collection vs largest fragment overlap coverage collection); - Use gnomAD subset of matched WES/WGS pairs for validation",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4123#issuecomment-362075071
https://github.com/broadinstitute/gatk/issues/4123#issuecomment-362075071:981,Performance,perform,performance,981,"Here is a recap of what we discussed today during the CNV meeting:. For the first round of evaluations we decided to run Germline CNV pipeline on TCGA exomes using a range of key hyperparameters (namely psi-t-scale and p-alt) and establish the base level performance metrics using output of GenomeSTRiP on matched WGS samples as ground truth. . @mbabadi could you come up with a good range of hyperparameter values that you think should be cross-validated?. In particular we need to:. - Dockerize tools we will be evaluating against (XHMM, CODEX2, CLAMMS, GenomeSTRiP); - Write a WDL that runs Germline CNV that scatters across range of key hyperparameters and outputs array of VCFs; - Write VCF processors for output of CLAMMS and CODEX2 ; - Write WDLs for running XHMM, CODEX2, CLAMMS and GenomeSTRiP that output VCFs; - Write WDL that takes results of the above and uses @mbabadi 's gCNV evaluation python modules(located here /dsde/working/mehrtash/gCNV_theano_eval) to output performance metrics; - Decide on an automatic evaluation framework. For the next round of evaluations we need to:. - Decide on appropriate metrics for evaluating performance on trios and write scripts that implement them; - Expand the range of hyperparameters in search space (possibly include different bin sizes, GC vs no GC correction, and fragment mid point coverage collection vs largest fragment overlap coverage collection); - Use gnomAD subset of matched WES/WGS pairs for validation",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4123#issuecomment-362075071
https://github.com/broadinstitute/gatk/issues/4123#issuecomment-362075071:1143,Performance,perform,performance,1143,"Here is a recap of what we discussed today during the CNV meeting:. For the first round of evaluations we decided to run Germline CNV pipeline on TCGA exomes using a range of key hyperparameters (namely psi-t-scale and p-alt) and establish the base level performance metrics using output of GenomeSTRiP on matched WGS samples as ground truth. . @mbabadi could you come up with a good range of hyperparameter values that you think should be cross-validated?. In particular we need to:. - Dockerize tools we will be evaluating against (XHMM, CODEX2, CLAMMS, GenomeSTRiP); - Write a WDL that runs Germline CNV that scatters across range of key hyperparameters and outputs array of VCFs; - Write VCF processors for output of CLAMMS and CODEX2 ; - Write WDLs for running XHMM, CODEX2, CLAMMS and GenomeSTRiP that output VCFs; - Write WDL that takes results of the above and uses @mbabadi 's gCNV evaluation python modules(located here /dsde/working/mehrtash/gCNV_theano_eval) to output performance metrics; - Decide on an automatic evaluation framework. For the next round of evaluations we need to:. - Decide on appropriate metrics for evaluating performance on trios and write scripts that implement them; - Expand the range of hyperparameters in search space (possibly include different bin sizes, GC vs no GC correction, and fragment mid point coverage collection vs largest fragment overlap coverage collection); - Use gnomAD subset of matched WES/WGS pairs for validation",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4123#issuecomment-362075071
https://github.com/broadinstitute/gatk/issues/4123#issuecomment-362075071:446,Security,validat,validated,446,"Here is a recap of what we discussed today during the CNV meeting:. For the first round of evaluations we decided to run Germline CNV pipeline on TCGA exomes using a range of key hyperparameters (namely psi-t-scale and p-alt) and establish the base level performance metrics using output of GenomeSTRiP on matched WGS samples as ground truth. . @mbabadi could you come up with a good range of hyperparameter values that you think should be cross-validated?. In particular we need to:. - Dockerize tools we will be evaluating against (XHMM, CODEX2, CLAMMS, GenomeSTRiP); - Write a WDL that runs Germline CNV that scatters across range of key hyperparameters and outputs array of VCFs; - Write VCF processors for output of CLAMMS and CODEX2 ; - Write WDLs for running XHMM, CODEX2, CLAMMS and GenomeSTRiP that output VCFs; - Write WDL that takes results of the above and uses @mbabadi 's gCNV evaluation python modules(located here /dsde/working/mehrtash/gCNV_theano_eval) to output performance metrics; - Decide on an automatic evaluation framework. For the next round of evaluations we need to:. - Decide on appropriate metrics for evaluating performance on trios and write scripts that implement them; - Expand the range of hyperparameters in search space (possibly include different bin sizes, GC vs no GC correction, and fragment mid point coverage collection vs largest fragment overlap coverage collection); - Use gnomAD subset of matched WES/WGS pairs for validation",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4123#issuecomment-362075071
https://github.com/broadinstitute/gatk/issues/4123#issuecomment-362075071:1462,Security,validat,validation,1462,"Here is a recap of what we discussed today during the CNV meeting:. For the first round of evaluations we decided to run Germline CNV pipeline on TCGA exomes using a range of key hyperparameters (namely psi-t-scale and p-alt) and establish the base level performance metrics using output of GenomeSTRiP on matched WGS samples as ground truth. . @mbabadi could you come up with a good range of hyperparameter values that you think should be cross-validated?. In particular we need to:. - Dockerize tools we will be evaluating against (XHMM, CODEX2, CLAMMS, GenomeSTRiP); - Write a WDL that runs Germline CNV that scatters across range of key hyperparameters and outputs array of VCFs; - Write VCF processors for output of CLAMMS and CODEX2 ; - Write WDLs for running XHMM, CODEX2, CLAMMS and GenomeSTRiP that output VCFs; - Write WDL that takes results of the above and uses @mbabadi 's gCNV evaluation python modules(located here /dsde/working/mehrtash/gCNV_theano_eval) to output performance metrics; - Decide on an automatic evaluation framework. For the next round of evaluations we need to:. - Decide on appropriate metrics for evaluating performance on trios and write scripts that implement them; - Expand the range of hyperparameters in search space (possibly include different bin sizes, GC vs no GC correction, and fragment mid point coverage collection vs largest fragment overlap coverage collection); - Use gnomAD subset of matched WES/WGS pairs for validation",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4123#issuecomment-362075071
https://github.com/broadinstitute/gatk/issues/4123#issuecomment-363518147:58,Availability,avail,available,58,"Also, let's use WDLs and Dockers from other groups, where available. In particular, I would hope that these are available for XHMM, GenomeSTRiP, and the tools that the Talkowski lab runs. We can discuss with @cwhelan today, but @asmirnov239 and @ldgauthier could you do some digging to see what the MacArthur lab has?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4123#issuecomment-363518147
https://github.com/broadinstitute/gatk/issues/4123#issuecomment-363518147:112,Availability,avail,available,112,"Also, let's use WDLs and Dockers from other groups, where available. In particular, I would hope that these are available for XHMM, GenomeSTRiP, and the tools that the Talkowski lab runs. We can discuss with @cwhelan today, but @asmirnov239 and @ldgauthier could you do some digging to see what the MacArthur lab has?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4123#issuecomment-363518147
https://github.com/broadinstitute/gatk/issues/4123#issuecomment-459834130:125,Energy Efficiency,adapt,adapted,125,@asmirnov239 and Jack Fu are currently developing tests using Talkowski-SV truth that will ultimately cover #5633. Should be adapted to fit into whatever framework arises from #4630.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4123#issuecomment-459834130
https://github.com/broadinstitute/gatk/issues/4123#issuecomment-459834130:125,Modifiability,adapt,adapted,125,@asmirnov239 and Jack Fu are currently developing tests using Talkowski-SV truth that will ultimately cover #5633. Should be adapted to fit into whatever framework arises from #4630.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4123#issuecomment-459834130
https://github.com/broadinstitute/gatk/issues/4123#issuecomment-459834130:50,Testability,test,tests,50,@asmirnov239 and Jack Fu are currently developing tests using Talkowski-SV truth that will ultimately cover #5633. Should be adapted to fit into whatever framework arises from #4630.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4123#issuecomment-459834130
https://github.com/broadinstitute/gatk/issues/4123#issuecomment-532500502:256,Deployability,pipeline,pipeline,256,"**The following work has been done:**; - We performed a round of evaluations against XHMM and cn.MOPS on a cohort of 160 samples from SFARI project (which is described in our ASHG poster). For ground truth we used a callset generated from Talkowski lab SV pipeline on matched whole genome samples. Unfortunately, SFARI cohort is not public and cannot be used for public facing evaluations.; - Some hyperparameter tweaking was necessary to achieve good performance. Hyperparameters changed were contained mostly only to `psi_t` parameter.; - We developed a clustering procedure that is based on coverage profile at the set of targets that are highly variable across different capture kits. ; - We found that filtering on a QS metric on a final callset significantly boosted the specificity while lowering sensitivity insignificantly.; - We developed a hyperparameter optimization framework prototype that could be used in a future for general optimizations of cost/performance parameters for all GATK pipelines.; - We resolved several memory issues that came up during validations. **A few issues were encountered along the way:**; - The sensitivity and specificity on multiallellic (common) sites was significantly lower than on rare events.; - Single target calling sensitivity was lower than 20%.; - Pipeline WDL required optimization in order to handle whole genome data, however these changes were not consolidated in the official WDL. **Currently the ongoing work is focused on the following:**; - Improving sensitivity/specificity of calls on common regions. One solution being tested involves setting a prior for common regions derived from a high quality callset. Second solution is to set a different filtering threshold for common regions.; - Consolidating validation scripts to process gCNV output and outputs of competing tools measure their performances against ground truth.; - Analyzing 1000 Genomes exomes, which could be potentially used for public facing automatic evaluations. **The",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4123#issuecomment-532500502
https://github.com/broadinstitute/gatk/issues/4123#issuecomment-532500502:1000,Deployability,pipeline,pipelines,1000,"**The following work has been done:**; - We performed a round of evaluations against XHMM and cn.MOPS on a cohort of 160 samples from SFARI project (which is described in our ASHG poster). For ground truth we used a callset generated from Talkowski lab SV pipeline on matched whole genome samples. Unfortunately, SFARI cohort is not public and cannot be used for public facing evaluations.; - Some hyperparameter tweaking was necessary to achieve good performance. Hyperparameters changed were contained mostly only to `psi_t` parameter.; - We developed a clustering procedure that is based on coverage profile at the set of targets that are highly variable across different capture kits. ; - We found that filtering on a QS metric on a final callset significantly boosted the specificity while lowering sensitivity insignificantly.; - We developed a hyperparameter optimization framework prototype that could be used in a future for general optimizations of cost/performance parameters for all GATK pipelines.; - We resolved several memory issues that came up during validations. **A few issues were encountered along the way:**; - The sensitivity and specificity on multiallellic (common) sites was significantly lower than on rare events.; - Single target calling sensitivity was lower than 20%.; - Pipeline WDL required optimization in order to handle whole genome data, however these changes were not consolidated in the official WDL. **Currently the ongoing work is focused on the following:**; - Improving sensitivity/specificity of calls on common regions. One solution being tested involves setting a prior for common regions derived from a high quality callset. Second solution is to set a different filtering threshold for common regions.; - Consolidating validation scripts to process gCNV output and outputs of competing tools measure their performances against ground truth.; - Analyzing 1000 Genomes exomes, which could be potentially used for public facing automatic evaluations. **The",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4123#issuecomment-532500502
https://github.com/broadinstitute/gatk/issues/4123#issuecomment-532500502:1302,Deployability,Pipeline,Pipeline,1302,"c facing evaluations.; - Some hyperparameter tweaking was necessary to achieve good performance. Hyperparameters changed were contained mostly only to `psi_t` parameter.; - We developed a clustering procedure that is based on coverage profile at the set of targets that are highly variable across different capture kits. ; - We found that filtering on a QS metric on a final callset significantly boosted the specificity while lowering sensitivity insignificantly.; - We developed a hyperparameter optimization framework prototype that could be used in a future for general optimizations of cost/performance parameters for all GATK pipelines.; - We resolved several memory issues that came up during validations. **A few issues were encountered along the way:**; - The sensitivity and specificity on multiallellic (common) sites was significantly lower than on rare events.; - Single target calling sensitivity was lower than 20%.; - Pipeline WDL required optimization in order to handle whole genome data, however these changes were not consolidated in the official WDL. **Currently the ongoing work is focused on the following:**; - Improving sensitivity/specificity of calls on common regions. One solution being tested involves setting a prior for common regions derived from a high quality callset. Second solution is to set a different filtering threshold for common regions.; - Consolidating validation scripts to process gCNV output and outputs of competing tools measure their performances against ground truth.; - Analyzing 1000 Genomes exomes, which could be potentially used for public facing automatic evaluations. **The following items are necessary done for automatic evaluation:** ; - Dataset + truth. We need an access to a high quality public cohort with matched whole genomes. These genomes have to have a corresponding high quality truth set generated from split-read/read-pair methods. From that cohort we need to find 50-200 relatively homogeneous samples.; - An established vali",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4123#issuecomment-532500502
https://github.com/broadinstitute/gatk/issues/4123#issuecomment-532500502:649,Modifiability,variab,variable,649,"**The following work has been done:**; - We performed a round of evaluations against XHMM and cn.MOPS on a cohort of 160 samples from SFARI project (which is described in our ASHG poster). For ground truth we used a callset generated from Talkowski lab SV pipeline on matched whole genome samples. Unfortunately, SFARI cohort is not public and cannot be used for public facing evaluations.; - Some hyperparameter tweaking was necessary to achieve good performance. Hyperparameters changed were contained mostly only to `psi_t` parameter.; - We developed a clustering procedure that is based on coverage profile at the set of targets that are highly variable across different capture kits. ; - We found that filtering on a QS metric on a final callset significantly boosted the specificity while lowering sensitivity insignificantly.; - We developed a hyperparameter optimization framework prototype that could be used in a future for general optimizations of cost/performance parameters for all GATK pipelines.; - We resolved several memory issues that came up during validations. **A few issues were encountered along the way:**; - The sensitivity and specificity on multiallellic (common) sites was significantly lower than on rare events.; - Single target calling sensitivity was lower than 20%.; - Pipeline WDL required optimization in order to handle whole genome data, however these changes were not consolidated in the official WDL. **Currently the ongoing work is focused on the following:**; - Improving sensitivity/specificity of calls on common regions. One solution being tested involves setting a prior for common regions derived from a high quality callset. Second solution is to set a different filtering threshold for common regions.; - Consolidating validation scripts to process gCNV output and outputs of competing tools measure their performances against ground truth.; - Analyzing 1000 Genomes exomes, which could be potentially used for public facing automatic evaluations. **The",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4123#issuecomment-532500502
https://github.com/broadinstitute/gatk/issues/4123#issuecomment-532500502:44,Performance,perform,performed,44,"**The following work has been done:**; - We performed a round of evaluations against XHMM and cn.MOPS on a cohort of 160 samples from SFARI project (which is described in our ASHG poster). For ground truth we used a callset generated from Talkowski lab SV pipeline on matched whole genome samples. Unfortunately, SFARI cohort is not public and cannot be used for public facing evaluations.; - Some hyperparameter tweaking was necessary to achieve good performance. Hyperparameters changed were contained mostly only to `psi_t` parameter.; - We developed a clustering procedure that is based on coverage profile at the set of targets that are highly variable across different capture kits. ; - We found that filtering on a QS metric on a final callset significantly boosted the specificity while lowering sensitivity insignificantly.; - We developed a hyperparameter optimization framework prototype that could be used in a future for general optimizations of cost/performance parameters for all GATK pipelines.; - We resolved several memory issues that came up during validations. **A few issues were encountered along the way:**; - The sensitivity and specificity on multiallellic (common) sites was significantly lower than on rare events.; - Single target calling sensitivity was lower than 20%.; - Pipeline WDL required optimization in order to handle whole genome data, however these changes were not consolidated in the official WDL. **Currently the ongoing work is focused on the following:**; - Improving sensitivity/specificity of calls on common regions. One solution being tested involves setting a prior for common regions derived from a high quality callset. Second solution is to set a different filtering threshold for common regions.; - Consolidating validation scripts to process gCNV output and outputs of competing tools measure their performances against ground truth.; - Analyzing 1000 Genomes exomes, which could be potentially used for public facing automatic evaluations. **The",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4123#issuecomment-532500502
https://github.com/broadinstitute/gatk/issues/4123#issuecomment-532500502:452,Performance,perform,performance,452,"**The following work has been done:**; - We performed a round of evaluations against XHMM and cn.MOPS on a cohort of 160 samples from SFARI project (which is described in our ASHG poster). For ground truth we used a callset generated from Talkowski lab SV pipeline on matched whole genome samples. Unfortunately, SFARI cohort is not public and cannot be used for public facing evaluations.; - Some hyperparameter tweaking was necessary to achieve good performance. Hyperparameters changed were contained mostly only to `psi_t` parameter.; - We developed a clustering procedure that is based on coverage profile at the set of targets that are highly variable across different capture kits. ; - We found that filtering on a QS metric on a final callset significantly boosted the specificity while lowering sensitivity insignificantly.; - We developed a hyperparameter optimization framework prototype that could be used in a future for general optimizations of cost/performance parameters for all GATK pipelines.; - We resolved several memory issues that came up during validations. **A few issues were encountered along the way:**; - The sensitivity and specificity on multiallellic (common) sites was significantly lower than on rare events.; - Single target calling sensitivity was lower than 20%.; - Pipeline WDL required optimization in order to handle whole genome data, however these changes were not consolidated in the official WDL. **Currently the ongoing work is focused on the following:**; - Improving sensitivity/specificity of calls on common regions. One solution being tested involves setting a prior for common regions derived from a high quality callset. Second solution is to set a different filtering threshold for common regions.; - Consolidating validation scripts to process gCNV output and outputs of competing tools measure their performances against ground truth.; - Analyzing 1000 Genomes exomes, which could be potentially used for public facing automatic evaluations. **The",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4123#issuecomment-532500502
https://github.com/broadinstitute/gatk/issues/4123#issuecomment-532500502:866,Performance,optimiz,optimization,866,"**The following work has been done:**; - We performed a round of evaluations against XHMM and cn.MOPS on a cohort of 160 samples from SFARI project (which is described in our ASHG poster). For ground truth we used a callset generated from Talkowski lab SV pipeline on matched whole genome samples. Unfortunately, SFARI cohort is not public and cannot be used for public facing evaluations.; - Some hyperparameter tweaking was necessary to achieve good performance. Hyperparameters changed were contained mostly only to `psi_t` parameter.; - We developed a clustering procedure that is based on coverage profile at the set of targets that are highly variable across different capture kits. ; - We found that filtering on a QS metric on a final callset significantly boosted the specificity while lowering sensitivity insignificantly.; - We developed a hyperparameter optimization framework prototype that could be used in a future for general optimizations of cost/performance parameters for all GATK pipelines.; - We resolved several memory issues that came up during validations. **A few issues were encountered along the way:**; - The sensitivity and specificity on multiallellic (common) sites was significantly lower than on rare events.; - Single target calling sensitivity was lower than 20%.; - Pipeline WDL required optimization in order to handle whole genome data, however these changes were not consolidated in the official WDL. **Currently the ongoing work is focused on the following:**; - Improving sensitivity/specificity of calls on common regions. One solution being tested involves setting a prior for common regions derived from a high quality callset. Second solution is to set a different filtering threshold for common regions.; - Consolidating validation scripts to process gCNV output and outputs of competing tools measure their performances against ground truth.; - Analyzing 1000 Genomes exomes, which could be potentially used for public facing automatic evaluations. **The",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4123#issuecomment-532500502
https://github.com/broadinstitute/gatk/issues/4123#issuecomment-532500502:942,Performance,optimiz,optimizations,942,"**The following work has been done:**; - We performed a round of evaluations against XHMM and cn.MOPS on a cohort of 160 samples from SFARI project (which is described in our ASHG poster). For ground truth we used a callset generated from Talkowski lab SV pipeline on matched whole genome samples. Unfortunately, SFARI cohort is not public and cannot be used for public facing evaluations.; - Some hyperparameter tweaking was necessary to achieve good performance. Hyperparameters changed were contained mostly only to `psi_t` parameter.; - We developed a clustering procedure that is based on coverage profile at the set of targets that are highly variable across different capture kits. ; - We found that filtering on a QS metric on a final callset significantly boosted the specificity while lowering sensitivity insignificantly.; - We developed a hyperparameter optimization framework prototype that could be used in a future for general optimizations of cost/performance parameters for all GATK pipelines.; - We resolved several memory issues that came up during validations. **A few issues were encountered along the way:**; - The sensitivity and specificity on multiallellic (common) sites was significantly lower than on rare events.; - Single target calling sensitivity was lower than 20%.; - Pipeline WDL required optimization in order to handle whole genome data, however these changes were not consolidated in the official WDL. **Currently the ongoing work is focused on the following:**; - Improving sensitivity/specificity of calls on common regions. One solution being tested involves setting a prior for common regions derived from a high quality callset. Second solution is to set a different filtering threshold for common regions.; - Consolidating validation scripts to process gCNV output and outputs of competing tools measure their performances against ground truth.; - Analyzing 1000 Genomes exomes, which could be potentially used for public facing automatic evaluations. **The",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4123#issuecomment-532500502
https://github.com/broadinstitute/gatk/issues/4123#issuecomment-532500502:964,Performance,perform,performance,964,"**The following work has been done:**; - We performed a round of evaluations against XHMM and cn.MOPS on a cohort of 160 samples from SFARI project (which is described in our ASHG poster). For ground truth we used a callset generated from Talkowski lab SV pipeline on matched whole genome samples. Unfortunately, SFARI cohort is not public and cannot be used for public facing evaluations.; - Some hyperparameter tweaking was necessary to achieve good performance. Hyperparameters changed were contained mostly only to `psi_t` parameter.; - We developed a clustering procedure that is based on coverage profile at the set of targets that are highly variable across different capture kits. ; - We found that filtering on a QS metric on a final callset significantly boosted the specificity while lowering sensitivity insignificantly.; - We developed a hyperparameter optimization framework prototype that could be used in a future for general optimizations of cost/performance parameters for all GATK pipelines.; - We resolved several memory issues that came up during validations. **A few issues were encountered along the way:**; - The sensitivity and specificity on multiallellic (common) sites was significantly lower than on rare events.; - Single target calling sensitivity was lower than 20%.; - Pipeline WDL required optimization in order to handle whole genome data, however these changes were not consolidated in the official WDL. **Currently the ongoing work is focused on the following:**; - Improving sensitivity/specificity of calls on common regions. One solution being tested involves setting a prior for common regions derived from a high quality callset. Second solution is to set a different filtering threshold for common regions.; - Consolidating validation scripts to process gCNV output and outputs of competing tools measure their performances against ground truth.; - Analyzing 1000 Genomes exomes, which could be potentially used for public facing automatic evaluations. **The",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4123#issuecomment-532500502
https://github.com/broadinstitute/gatk/issues/4123#issuecomment-532500502:1324,Performance,optimiz,optimization,1324,"c facing evaluations.; - Some hyperparameter tweaking was necessary to achieve good performance. Hyperparameters changed were contained mostly only to `psi_t` parameter.; - We developed a clustering procedure that is based on coverage profile at the set of targets that are highly variable across different capture kits. ; - We found that filtering on a QS metric on a final callset significantly boosted the specificity while lowering sensitivity insignificantly.; - We developed a hyperparameter optimization framework prototype that could be used in a future for general optimizations of cost/performance parameters for all GATK pipelines.; - We resolved several memory issues that came up during validations. **A few issues were encountered along the way:**; - The sensitivity and specificity on multiallellic (common) sites was significantly lower than on rare events.; - Single target calling sensitivity was lower than 20%.; - Pipeline WDL required optimization in order to handle whole genome data, however these changes were not consolidated in the official WDL. **Currently the ongoing work is focused on the following:**; - Improving sensitivity/specificity of calls on common regions. One solution being tested involves setting a prior for common regions derived from a high quality callset. Second solution is to set a different filtering threshold for common regions.; - Consolidating validation scripts to process gCNV output and outputs of competing tools measure their performances against ground truth.; - Analyzing 1000 Genomes exomes, which could be potentially used for public facing automatic evaluations. **The following items are necessary done for automatic evaluation:** ; - Dataset + truth. We need an access to a high quality public cohort with matched whole genomes. These genomes have to have a corresponding high quality truth set generated from split-read/read-pair methods. From that cohort we need to find 50-200 relatively homogeneous samples.; - An established vali",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4123#issuecomment-532500502
https://github.com/broadinstitute/gatk/issues/4123#issuecomment-532500502:1854,Performance,perform,performances,1854,"loped a clustering procedure that is based on coverage profile at the set of targets that are highly variable across different capture kits. ; - We found that filtering on a QS metric on a final callset significantly boosted the specificity while lowering sensitivity insignificantly.; - We developed a hyperparameter optimization framework prototype that could be used in a future for general optimizations of cost/performance parameters for all GATK pipelines.; - We resolved several memory issues that came up during validations. **A few issues were encountered along the way:**; - The sensitivity and specificity on multiallellic (common) sites was significantly lower than on rare events.; - Single target calling sensitivity was lower than 20%.; - Pipeline WDL required optimization in order to handle whole genome data, however these changes were not consolidated in the official WDL. **Currently the ongoing work is focused on the following:**; - Improving sensitivity/specificity of calls on common regions. One solution being tested involves setting a prior for common regions derived from a high quality callset. Second solution is to set a different filtering threshold for common regions.; - Consolidating validation scripts to process gCNV output and outputs of competing tools measure their performances against ground truth.; - Analyzing 1000 Genomes exomes, which could be potentially used for public facing automatic evaluations. **The following items are necessary done for automatic evaluation:** ; - Dataset + truth. We need an access to a high quality public cohort with matched whole genomes. These genomes have to have a corresponding high quality truth set generated from split-read/read-pair methods. From that cohort we need to find 50-200 relatively homogeneous samples.; - An established validation workflow that outputs a set predetermined metrics that are unlikely to change in a future. Such as a sensitivity/specificity stratified by event size and allelic frequency.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4123#issuecomment-532500502
https://github.com/broadinstitute/gatk/issues/4123#issuecomment-532500502:1068,Security,validat,validations,1068,"erformed a round of evaluations against XHMM and cn.MOPS on a cohort of 160 samples from SFARI project (which is described in our ASHG poster). For ground truth we used a callset generated from Talkowski lab SV pipeline on matched whole genome samples. Unfortunately, SFARI cohort is not public and cannot be used for public facing evaluations.; - Some hyperparameter tweaking was necessary to achieve good performance. Hyperparameters changed were contained mostly only to `psi_t` parameter.; - We developed a clustering procedure that is based on coverage profile at the set of targets that are highly variable across different capture kits. ; - We found that filtering on a QS metric on a final callset significantly boosted the specificity while lowering sensitivity insignificantly.; - We developed a hyperparameter optimization framework prototype that could be used in a future for general optimizations of cost/performance parameters for all GATK pipelines.; - We resolved several memory issues that came up during validations. **A few issues were encountered along the way:**; - The sensitivity and specificity on multiallellic (common) sites was significantly lower than on rare events.; - Single target calling sensitivity was lower than 20%.; - Pipeline WDL required optimization in order to handle whole genome data, however these changes were not consolidated in the official WDL. **Currently the ongoing work is focused on the following:**; - Improving sensitivity/specificity of calls on common regions. One solution being tested involves setting a prior for common regions derived from a high quality callset. Second solution is to set a different filtering threshold for common regions.; - Consolidating validation scripts to process gCNV output and outputs of competing tools measure their performances against ground truth.; - Analyzing 1000 Genomes exomes, which could be potentially used for public facing automatic evaluations. **The following items are necessary done for auto",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4123#issuecomment-532500502
https://github.com/broadinstitute/gatk/issues/4123#issuecomment-532500502:1767,Security,validat,validation,1767,"loped a clustering procedure that is based on coverage profile at the set of targets that are highly variable across different capture kits. ; - We found that filtering on a QS metric on a final callset significantly boosted the specificity while lowering sensitivity insignificantly.; - We developed a hyperparameter optimization framework prototype that could be used in a future for general optimizations of cost/performance parameters for all GATK pipelines.; - We resolved several memory issues that came up during validations. **A few issues were encountered along the way:**; - The sensitivity and specificity on multiallellic (common) sites was significantly lower than on rare events.; - Single target calling sensitivity was lower than 20%.; - Pipeline WDL required optimization in order to handle whole genome data, however these changes were not consolidated in the official WDL. **Currently the ongoing work is focused on the following:**; - Improving sensitivity/specificity of calls on common regions. One solution being tested involves setting a prior for common regions derived from a high quality callset. Second solution is to set a different filtering threshold for common regions.; - Consolidating validation scripts to process gCNV output and outputs of competing tools measure their performances against ground truth.; - Analyzing 1000 Genomes exomes, which could be potentially used for public facing automatic evaluations. **The following items are necessary done for automatic evaluation:** ; - Dataset + truth. We need an access to a high quality public cohort with matched whole genomes. These genomes have to have a corresponding high quality truth set generated from split-read/read-pair methods. From that cohort we need to find 50-200 relatively homogeneous samples.; - An established validation workflow that outputs a set predetermined metrics that are unlikely to change in a future. Such as a sensitivity/specificity stratified by event size and allelic frequency.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4123#issuecomment-532500502
https://github.com/broadinstitute/gatk/issues/4123#issuecomment-532500502:2097,Security,access,access,2097,"loped a clustering procedure that is based on coverage profile at the set of targets that are highly variable across different capture kits. ; - We found that filtering on a QS metric on a final callset significantly boosted the specificity while lowering sensitivity insignificantly.; - We developed a hyperparameter optimization framework prototype that could be used in a future for general optimizations of cost/performance parameters for all GATK pipelines.; - We resolved several memory issues that came up during validations. **A few issues were encountered along the way:**; - The sensitivity and specificity on multiallellic (common) sites was significantly lower than on rare events.; - Single target calling sensitivity was lower than 20%.; - Pipeline WDL required optimization in order to handle whole genome data, however these changes were not consolidated in the official WDL. **Currently the ongoing work is focused on the following:**; - Improving sensitivity/specificity of calls on common regions. One solution being tested involves setting a prior for common regions derived from a high quality callset. Second solution is to set a different filtering threshold for common regions.; - Consolidating validation scripts to process gCNV output and outputs of competing tools measure their performances against ground truth.; - Analyzing 1000 Genomes exomes, which could be potentially used for public facing automatic evaluations. **The following items are necessary done for automatic evaluation:** ; - Dataset + truth. We need an access to a high quality public cohort with matched whole genomes. These genomes have to have a corresponding high quality truth set generated from split-read/read-pair methods. From that cohort we need to find 50-200 relatively homogeneous samples.; - An established validation workflow that outputs a set predetermined metrics that are unlikely to change in a future. Such as a sensitivity/specificity stratified by event size and allelic frequency.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4123#issuecomment-532500502
https://github.com/broadinstitute/gatk/issues/4123#issuecomment-532500502:2365,Security,validat,validation,2365,"loped a clustering procedure that is based on coverage profile at the set of targets that are highly variable across different capture kits. ; - We found that filtering on a QS metric on a final callset significantly boosted the specificity while lowering sensitivity insignificantly.; - We developed a hyperparameter optimization framework prototype that could be used in a future for general optimizations of cost/performance parameters for all GATK pipelines.; - We resolved several memory issues that came up during validations. **A few issues were encountered along the way:**; - The sensitivity and specificity on multiallellic (common) sites was significantly lower than on rare events.; - Single target calling sensitivity was lower than 20%.; - Pipeline WDL required optimization in order to handle whole genome data, however these changes were not consolidated in the official WDL. **Currently the ongoing work is focused on the following:**; - Improving sensitivity/specificity of calls on common regions. One solution being tested involves setting a prior for common regions derived from a high quality callset. Second solution is to set a different filtering threshold for common regions.; - Consolidating validation scripts to process gCNV output and outputs of competing tools measure their performances against ground truth.; - Analyzing 1000 Genomes exomes, which could be potentially used for public facing automatic evaluations. **The following items are necessary done for automatic evaluation:** ; - Dataset + truth. We need an access to a high quality public cohort with matched whole genomes. These genomes have to have a corresponding high quality truth set generated from split-read/read-pair methods. From that cohort we need to find 50-200 relatively homogeneous samples.; - An established validation workflow that outputs a set predetermined metrics that are unlikely to change in a future. Such as a sensitivity/specificity stratified by event size and allelic frequency.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4123#issuecomment-532500502
https://github.com/broadinstitute/gatk/issues/4123#issuecomment-532500502:1584,Testability,test,tested,1584,"loped a clustering procedure that is based on coverage profile at the set of targets that are highly variable across different capture kits. ; - We found that filtering on a QS metric on a final callset significantly boosted the specificity while lowering sensitivity insignificantly.; - We developed a hyperparameter optimization framework prototype that could be used in a future for general optimizations of cost/performance parameters for all GATK pipelines.; - We resolved several memory issues that came up during validations. **A few issues were encountered along the way:**; - The sensitivity and specificity on multiallellic (common) sites was significantly lower than on rare events.; - Single target calling sensitivity was lower than 20%.; - Pipeline WDL required optimization in order to handle whole genome data, however these changes were not consolidated in the official WDL. **Currently the ongoing work is focused on the following:**; - Improving sensitivity/specificity of calls on common regions. One solution being tested involves setting a prior for common regions derived from a high quality callset. Second solution is to set a different filtering threshold for common regions.; - Consolidating validation scripts to process gCNV output and outputs of competing tools measure their performances against ground truth.; - Analyzing 1000 Genomes exomes, which could be potentially used for public facing automatic evaluations. **The following items are necessary done for automatic evaluation:** ; - Dataset + truth. We need an access to a high quality public cohort with matched whole genomes. These genomes have to have a corresponding high quality truth set generated from split-read/read-pair methods. From that cohort we need to find 50-200 relatively homogeneous samples.; - An established validation workflow that outputs a set predetermined metrics that are unlikely to change in a future. Such as a sensitivity/specificity stratified by event size and allelic frequency.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4123#issuecomment-532500502
https://github.com/broadinstitute/gatk/issues/4124#issuecomment-356968408:92,Availability,error,error,92,Hello @owensgl. Could you provide me with an example command line argument that causes this error? I would like to know more about where you are putting your genomcisDB. @kgururaj,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4124#issuecomment-356968408
https://github.com/broadinstitute/gatk/issues/4124#issuecomment-356983592:121,Testability,test,test,121,"Same question as Louis, which OS (or Docker image) are you running on?. Just FYI, we now have a repo and Travis setup to test out the jars for issues. The tests for this jar passed the last time - I have restarted the build (Ubuntu and MacOSX). https://travis-ci.org/kgururaj/TestGenomicsDBJar/builds/325659272",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4124#issuecomment-356983592
https://github.com/broadinstitute/gatk/issues/4124#issuecomment-356983592:155,Testability,test,tests,155,"Same question as Louis, which OS (or Docker image) are you running on?. Just FYI, we now have a repo and Travis setup to test out the jars for issues. The tests for this jar passed the last time - I have restarted the build (Ubuntu and MacOSX). https://travis-ci.org/kgururaj/TestGenomicsDBJar/builds/325659272",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4124#issuecomment-356983592
https://github.com/broadinstitute/gatk/issues/4124#issuecomment-356983592:276,Testability,Test,TestGenomicsDBJar,276,"Same question as Louis, which OS (or Docker image) are you running on?. Just FYI, we now have a repo and Travis setup to test out the jars for issues. The tests for this jar passed the last time - I have restarted the build (Ubuntu and MacOSX). https://travis-ci.org/kgururaj/TestGenomicsDBJar/builds/325659272",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4124#issuecomment-356983592
https://github.com/broadinstitute/gatk/issues/4124#issuecomment-356984584:204,Availability,error,error,204,"I suspect it's a different issue than #4062, but probably some similar library incompatibility issue. Unfortunately the stack trace doesn't have enough information in it. We should consider rewriting the error message for this so that we are sure to have the first cause reported, not just the `Could not load genomicsdb native library` message.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4124#issuecomment-356984584
https://github.com/broadinstitute/gatk/issues/4124#issuecomment-356984584:210,Integrability,message,message,210,"I suspect it's a different issue than #4062, but probably some similar library incompatibility issue. Unfortunately the stack trace doesn't have enough information in it. We should consider rewriting the error message for this so that we are sure to have the first cause reported, not just the `Could not load genomicsdb native library` message.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4124#issuecomment-356984584
https://github.com/broadinstitute/gatk/issues/4124#issuecomment-356984584:337,Integrability,message,message,337,"I suspect it's a different issue than #4062, but probably some similar library incompatibility issue. Unfortunately the stack trace doesn't have enough information in it. We should consider rewriting the error message for this so that we are sure to have the first cause reported, not just the `Could not load genomicsdb native library` message.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4124#issuecomment-356984584
https://github.com/broadinstitute/gatk/issues/4124#issuecomment-356984584:305,Performance,load,load,305,"I suspect it's a different issue than #4062, but probably some similar library incompatibility issue. Unfortunately the stack trace doesn't have enough information in it. We should consider rewriting the error message for this so that we are sure to have the first cause reported, not just the `Could not load genomicsdb native library` message.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4124#issuecomment-356984584
https://github.com/broadinstitute/gatk/issues/4124#issuecomment-356988842:265,Integrability,depend,dependencies,265,A check:; Can you clone https://github.com/kgururaj/TestGenomicsDBJar ?; ```; export GENOMICSDB_VERSION=0.8.1-proto-3.0.0-beta-1+uuid-static; curl -O http://repo1.maven.org/maven2/com/intel/genomicsdb/${GENOMICSDB_VERSION}/genomicsdb-${GENOMICSDB_VERSION}-jar-with-dependencies.jar; bash -x TestGenomicsDBJar/run_checks.sh; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4124#issuecomment-356988842
https://github.com/broadinstitute/gatk/issues/4124#issuecomment-356988842:52,Testability,Test,TestGenomicsDBJar,52,A check:; Can you clone https://github.com/kgururaj/TestGenomicsDBJar ?; ```; export GENOMICSDB_VERSION=0.8.1-proto-3.0.0-beta-1+uuid-static; curl -O http://repo1.maven.org/maven2/com/intel/genomicsdb/${GENOMICSDB_VERSION}/genomicsdb-${GENOMICSDB_VERSION}-jar-with-dependencies.jar; bash -x TestGenomicsDBJar/run_checks.sh; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4124#issuecomment-356988842
https://github.com/broadinstitute/gatk/issues/4124#issuecomment-356988842:291,Testability,Test,TestGenomicsDBJar,291,A check:; Can you clone https://github.com/kgururaj/TestGenomicsDBJar ?; ```; export GENOMICSDB_VERSION=0.8.1-proto-3.0.0-beta-1+uuid-static; curl -O http://repo1.maven.org/maven2/com/intel/genomicsdb/${GENOMICSDB_VERSION}/genomicsdb-${GENOMICSDB_VERSION}-jar-with-dependencies.jar; bash -x TestGenomicsDBJar/run_checks.sh; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4124#issuecomment-356988842
https://github.com/broadinstitute/gatk/issues/4124#issuecomment-357001828:351,Deployability,release,release,351,"Hi, ; This is the command I used:; `gatk GenomicsDBImport \; $tmp \; --genomicsdb-workspace-path /scratch/user/wild_gwas/$genomicsdb/${chr}_$pos \; --intervals $contig \; --batch-size 100`. $tmp is a list of 150 gvcfs. $contig is 100kb window in the genome. ; The OS version is:. > LSB; Version: n/a; Distributor ID: CentOS; Description: CentOS Linux release 7.4.1708 (Core); Release: 7.4.1708; Codename: Core. I'll try to do the tests kgururaj suggests.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4124#issuecomment-357001828
https://github.com/broadinstitute/gatk/issues/4124#issuecomment-357001828:376,Deployability,Release,Release,376,"Hi, ; This is the command I used:; `gatk GenomicsDBImport \; $tmp \; --genomicsdb-workspace-path /scratch/user/wild_gwas/$genomicsdb/${chr}_$pos \; --intervals $contig \; --batch-size 100`. $tmp is a list of 150 gvcfs. $contig is 100kb window in the genome. ; The OS version is:. > LSB; Version: n/a; Distributor ID: CentOS; Description: CentOS Linux release 7.4.1708 (Core); Release: 7.4.1708; Codename: Core. I'll try to do the tests kgururaj suggests.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4124#issuecomment-357001828
https://github.com/broadinstitute/gatk/issues/4124#issuecomment-357001828:430,Testability,test,tests,430,"Hi, ; This is the command I used:; `gatk GenomicsDBImport \; $tmp \; --genomicsdb-workspace-path /scratch/user/wild_gwas/$genomicsdb/${chr}_$pos \; --intervals $contig \; --batch-size 100`. $tmp is a list of 150 gvcfs. $contig is 100kb window in the genome. ; The OS version is:. > LSB; Version: n/a; Distributor ID: CentOS; Description: CentOS Linux release 7.4.1708 (Core); Release: 7.4.1708; Codename: Core. I'll try to do the tests kgururaj suggests.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4124#issuecomment-357001828
https://github.com/broadinstitute/gatk/issues/4124#issuecomment-357005071:1658,Deployability,install,installed,1658,"@kgururaj I ran the commands you suggested. . > [user@cedar5 bin]$ bash -x TestGenomicsDBJar/run_checks.sh; > + [[ hB != hxB ]]; > + XTRACE_STATE=-x; > + [[ hxB != hxB ]]; > + VERBOSE_STATE=+v; > + set +xv; > + unset XTRACE_STATE VERBOSE_STATE; > ++ uname -s; > + osname=Linux; > + jar xf genomicsdb--jar-with-dependencies.jar libtiledbgenomicsdb.so; > java.io.FileNotFoundException: genomicsdb--jar-with-dependencies.jar (No such file or directory); > at java.util.zip.ZipFile.open(Native Method); > at java.util.zip.ZipFile.<init>(ZipFile.java:219); > at java.util.zip.ZipFile.<init>(ZipFile.java:149); > at java.util.zip.ZipFile.<init>(ZipFile.java:120); > at sun.tools.jar.Main.extract(Main.java:1004); > at sun.tools.jar.Main.run(Main.java:305); > at sun.tools.jar.Main.main(Main.java:1288); > + jar xf genomicsdb--jar-with-dependencies.jar libtiledbgenomicsdb.dylib; > java.io.FileNotFoundException: genomicsdb--jar-with-dependencies.jar (No such file or directory); > at java.util.zip.ZipFile.open(Native Method); > at java.util.zip.ZipFile.<init>(ZipFile.java:219); > at java.util.zip.ZipFile.<init>(ZipFile.java:149); > at java.util.zip.ZipFile.<init>(ZipFile.java:120); > at sun.tools.jar.Main.extract(Main.java:1004); > at sun.tools.jar.Main.run(Main.java:305); > at sun.tools.jar.Main.main(Main.java:1288); > + '[' Linux == Darwin ']'; > + LIBRARY_SUFFIX=so; > + ldd libtiledbgenomicsdb.so; > ldd: ./libtiledbgenomicsdb.so: No such file or directory; > + md5sum libtiledbgenomicsdb.so; > md5sum: libtiledbgenomicsdb.so: No such file or directory. I'm using a compute canada server, so I don't have root access. The version of gatk4 I'm using was installed by their support team, and I load it using 'module load gatk'. I had that module loaded when I ran this test.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4124#issuecomment-357005071
https://github.com/broadinstitute/gatk/issues/4124#issuecomment-357005071:310,Integrability,depend,dependencies,310,"@kgururaj I ran the commands you suggested. . > [user@cedar5 bin]$ bash -x TestGenomicsDBJar/run_checks.sh; > + [[ hB != hxB ]]; > + XTRACE_STATE=-x; > + [[ hxB != hxB ]]; > + VERBOSE_STATE=+v; > + set +xv; > + unset XTRACE_STATE VERBOSE_STATE; > ++ uname -s; > + osname=Linux; > + jar xf genomicsdb--jar-with-dependencies.jar libtiledbgenomicsdb.so; > java.io.FileNotFoundException: genomicsdb--jar-with-dependencies.jar (No such file or directory); > at java.util.zip.ZipFile.open(Native Method); > at java.util.zip.ZipFile.<init>(ZipFile.java:219); > at java.util.zip.ZipFile.<init>(ZipFile.java:149); > at java.util.zip.ZipFile.<init>(ZipFile.java:120); > at sun.tools.jar.Main.extract(Main.java:1004); > at sun.tools.jar.Main.run(Main.java:305); > at sun.tools.jar.Main.main(Main.java:1288); > + jar xf genomicsdb--jar-with-dependencies.jar libtiledbgenomicsdb.dylib; > java.io.FileNotFoundException: genomicsdb--jar-with-dependencies.jar (No such file or directory); > at java.util.zip.ZipFile.open(Native Method); > at java.util.zip.ZipFile.<init>(ZipFile.java:219); > at java.util.zip.ZipFile.<init>(ZipFile.java:149); > at java.util.zip.ZipFile.<init>(ZipFile.java:120); > at sun.tools.jar.Main.extract(Main.java:1004); > at sun.tools.jar.Main.run(Main.java:305); > at sun.tools.jar.Main.main(Main.java:1288); > + '[' Linux == Darwin ']'; > + LIBRARY_SUFFIX=so; > + ldd libtiledbgenomicsdb.so; > ldd: ./libtiledbgenomicsdb.so: No such file or directory; > + md5sum libtiledbgenomicsdb.so; > md5sum: libtiledbgenomicsdb.so: No such file or directory. I'm using a compute canada server, so I don't have root access. The version of gatk4 I'm using was installed by their support team, and I load it using 'module load gatk'. I had that module loaded when I ran this test.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4124#issuecomment-357005071
https://github.com/broadinstitute/gatk/issues/4124#issuecomment-357005071:405,Integrability,depend,dependencies,405,"@kgururaj I ran the commands you suggested. . > [user@cedar5 bin]$ bash -x TestGenomicsDBJar/run_checks.sh; > + [[ hB != hxB ]]; > + XTRACE_STATE=-x; > + [[ hxB != hxB ]]; > + VERBOSE_STATE=+v; > + set +xv; > + unset XTRACE_STATE VERBOSE_STATE; > ++ uname -s; > + osname=Linux; > + jar xf genomicsdb--jar-with-dependencies.jar libtiledbgenomicsdb.so; > java.io.FileNotFoundException: genomicsdb--jar-with-dependencies.jar (No such file or directory); > at java.util.zip.ZipFile.open(Native Method); > at java.util.zip.ZipFile.<init>(ZipFile.java:219); > at java.util.zip.ZipFile.<init>(ZipFile.java:149); > at java.util.zip.ZipFile.<init>(ZipFile.java:120); > at sun.tools.jar.Main.extract(Main.java:1004); > at sun.tools.jar.Main.run(Main.java:305); > at sun.tools.jar.Main.main(Main.java:1288); > + jar xf genomicsdb--jar-with-dependencies.jar libtiledbgenomicsdb.dylib; > java.io.FileNotFoundException: genomicsdb--jar-with-dependencies.jar (No such file or directory); > at java.util.zip.ZipFile.open(Native Method); > at java.util.zip.ZipFile.<init>(ZipFile.java:219); > at java.util.zip.ZipFile.<init>(ZipFile.java:149); > at java.util.zip.ZipFile.<init>(ZipFile.java:120); > at sun.tools.jar.Main.extract(Main.java:1004); > at sun.tools.jar.Main.run(Main.java:305); > at sun.tools.jar.Main.main(Main.java:1288); > + '[' Linux == Darwin ']'; > + LIBRARY_SUFFIX=so; > + ldd libtiledbgenomicsdb.so; > ldd: ./libtiledbgenomicsdb.so: No such file or directory; > + md5sum libtiledbgenomicsdb.so; > md5sum: libtiledbgenomicsdb.so: No such file or directory. I'm using a compute canada server, so I don't have root access. The version of gatk4 I'm using was installed by their support team, and I load it using 'module load gatk'. I had that module loaded when I ran this test.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4124#issuecomment-357005071
https://github.com/broadinstitute/gatk/issues/4124#issuecomment-357005071:829,Integrability,depend,dependencies,829,"@kgururaj I ran the commands you suggested. . > [user@cedar5 bin]$ bash -x TestGenomicsDBJar/run_checks.sh; > + [[ hB != hxB ]]; > + XTRACE_STATE=-x; > + [[ hxB != hxB ]]; > + VERBOSE_STATE=+v; > + set +xv; > + unset XTRACE_STATE VERBOSE_STATE; > ++ uname -s; > + osname=Linux; > + jar xf genomicsdb--jar-with-dependencies.jar libtiledbgenomicsdb.so; > java.io.FileNotFoundException: genomicsdb--jar-with-dependencies.jar (No such file or directory); > at java.util.zip.ZipFile.open(Native Method); > at java.util.zip.ZipFile.<init>(ZipFile.java:219); > at java.util.zip.ZipFile.<init>(ZipFile.java:149); > at java.util.zip.ZipFile.<init>(ZipFile.java:120); > at sun.tools.jar.Main.extract(Main.java:1004); > at sun.tools.jar.Main.run(Main.java:305); > at sun.tools.jar.Main.main(Main.java:1288); > + jar xf genomicsdb--jar-with-dependencies.jar libtiledbgenomicsdb.dylib; > java.io.FileNotFoundException: genomicsdb--jar-with-dependencies.jar (No such file or directory); > at java.util.zip.ZipFile.open(Native Method); > at java.util.zip.ZipFile.<init>(ZipFile.java:219); > at java.util.zip.ZipFile.<init>(ZipFile.java:149); > at java.util.zip.ZipFile.<init>(ZipFile.java:120); > at sun.tools.jar.Main.extract(Main.java:1004); > at sun.tools.jar.Main.run(Main.java:305); > at sun.tools.jar.Main.main(Main.java:1288); > + '[' Linux == Darwin ']'; > + LIBRARY_SUFFIX=so; > + ldd libtiledbgenomicsdb.so; > ldd: ./libtiledbgenomicsdb.so: No such file or directory; > + md5sum libtiledbgenomicsdb.so; > md5sum: libtiledbgenomicsdb.so: No such file or directory. I'm using a compute canada server, so I don't have root access. The version of gatk4 I'm using was installed by their support team, and I load it using 'module load gatk'. I had that module loaded when I ran this test.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4124#issuecomment-357005071
https://github.com/broadinstitute/gatk/issues/4124#issuecomment-357005071:927,Integrability,depend,dependencies,927,"@kgururaj I ran the commands you suggested. . > [user@cedar5 bin]$ bash -x TestGenomicsDBJar/run_checks.sh; > + [[ hB != hxB ]]; > + XTRACE_STATE=-x; > + [[ hxB != hxB ]]; > + VERBOSE_STATE=+v; > + set +xv; > + unset XTRACE_STATE VERBOSE_STATE; > ++ uname -s; > + osname=Linux; > + jar xf genomicsdb--jar-with-dependencies.jar libtiledbgenomicsdb.so; > java.io.FileNotFoundException: genomicsdb--jar-with-dependencies.jar (No such file or directory); > at java.util.zip.ZipFile.open(Native Method); > at java.util.zip.ZipFile.<init>(ZipFile.java:219); > at java.util.zip.ZipFile.<init>(ZipFile.java:149); > at java.util.zip.ZipFile.<init>(ZipFile.java:120); > at sun.tools.jar.Main.extract(Main.java:1004); > at sun.tools.jar.Main.run(Main.java:305); > at sun.tools.jar.Main.main(Main.java:1288); > + jar xf genomicsdb--jar-with-dependencies.jar libtiledbgenomicsdb.dylib; > java.io.FileNotFoundException: genomicsdb--jar-with-dependencies.jar (No such file or directory); > at java.util.zip.ZipFile.open(Native Method); > at java.util.zip.ZipFile.<init>(ZipFile.java:219); > at java.util.zip.ZipFile.<init>(ZipFile.java:149); > at java.util.zip.ZipFile.<init>(ZipFile.java:120); > at sun.tools.jar.Main.extract(Main.java:1004); > at sun.tools.jar.Main.run(Main.java:305); > at sun.tools.jar.Main.main(Main.java:1288); > + '[' Linux == Darwin ']'; > + LIBRARY_SUFFIX=so; > + ldd libtiledbgenomicsdb.so; > ldd: ./libtiledbgenomicsdb.so: No such file or directory; > + md5sum libtiledbgenomicsdb.so; > md5sum: libtiledbgenomicsdb.so: No such file or directory. I'm using a compute canada server, so I don't have root access. The version of gatk4 I'm using was installed by their support team, and I load it using 'module load gatk'. I had that module loaded when I ran this test.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4124#issuecomment-357005071
https://github.com/broadinstitute/gatk/issues/4124#issuecomment-357005071:1697,Performance,load,load,1697,"@kgururaj I ran the commands you suggested. . > [user@cedar5 bin]$ bash -x TestGenomicsDBJar/run_checks.sh; > + [[ hB != hxB ]]; > + XTRACE_STATE=-x; > + [[ hxB != hxB ]]; > + VERBOSE_STATE=+v; > + set +xv; > + unset XTRACE_STATE VERBOSE_STATE; > ++ uname -s; > + osname=Linux; > + jar xf genomicsdb--jar-with-dependencies.jar libtiledbgenomicsdb.so; > java.io.FileNotFoundException: genomicsdb--jar-with-dependencies.jar (No such file or directory); > at java.util.zip.ZipFile.open(Native Method); > at java.util.zip.ZipFile.<init>(ZipFile.java:219); > at java.util.zip.ZipFile.<init>(ZipFile.java:149); > at java.util.zip.ZipFile.<init>(ZipFile.java:120); > at sun.tools.jar.Main.extract(Main.java:1004); > at sun.tools.jar.Main.run(Main.java:305); > at sun.tools.jar.Main.main(Main.java:1288); > + jar xf genomicsdb--jar-with-dependencies.jar libtiledbgenomicsdb.dylib; > java.io.FileNotFoundException: genomicsdb--jar-with-dependencies.jar (No such file or directory); > at java.util.zip.ZipFile.open(Native Method); > at java.util.zip.ZipFile.<init>(ZipFile.java:219); > at java.util.zip.ZipFile.<init>(ZipFile.java:149); > at java.util.zip.ZipFile.<init>(ZipFile.java:120); > at sun.tools.jar.Main.extract(Main.java:1004); > at sun.tools.jar.Main.run(Main.java:305); > at sun.tools.jar.Main.main(Main.java:1288); > + '[' Linux == Darwin ']'; > + LIBRARY_SUFFIX=so; > + ldd libtiledbgenomicsdb.so; > ldd: ./libtiledbgenomicsdb.so: No such file or directory; > + md5sum libtiledbgenomicsdb.so; > md5sum: libtiledbgenomicsdb.so: No such file or directory. I'm using a compute canada server, so I don't have root access. The version of gatk4 I'm using was installed by their support team, and I load it using 'module load gatk'. I had that module loaded when I ran this test.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4124#issuecomment-357005071
https://github.com/broadinstitute/gatk/issues/4124#issuecomment-357005071:1719,Performance,load,load,1719,"@kgururaj I ran the commands you suggested. . > [user@cedar5 bin]$ bash -x TestGenomicsDBJar/run_checks.sh; > + [[ hB != hxB ]]; > + XTRACE_STATE=-x; > + [[ hxB != hxB ]]; > + VERBOSE_STATE=+v; > + set +xv; > + unset XTRACE_STATE VERBOSE_STATE; > ++ uname -s; > + osname=Linux; > + jar xf genomicsdb--jar-with-dependencies.jar libtiledbgenomicsdb.so; > java.io.FileNotFoundException: genomicsdb--jar-with-dependencies.jar (No such file or directory); > at java.util.zip.ZipFile.open(Native Method); > at java.util.zip.ZipFile.<init>(ZipFile.java:219); > at java.util.zip.ZipFile.<init>(ZipFile.java:149); > at java.util.zip.ZipFile.<init>(ZipFile.java:120); > at sun.tools.jar.Main.extract(Main.java:1004); > at sun.tools.jar.Main.run(Main.java:305); > at sun.tools.jar.Main.main(Main.java:1288); > + jar xf genomicsdb--jar-with-dependencies.jar libtiledbgenomicsdb.dylib; > java.io.FileNotFoundException: genomicsdb--jar-with-dependencies.jar (No such file or directory); > at java.util.zip.ZipFile.open(Native Method); > at java.util.zip.ZipFile.<init>(ZipFile.java:219); > at java.util.zip.ZipFile.<init>(ZipFile.java:149); > at java.util.zip.ZipFile.<init>(ZipFile.java:120); > at sun.tools.jar.Main.extract(Main.java:1004); > at sun.tools.jar.Main.run(Main.java:305); > at sun.tools.jar.Main.main(Main.java:1288); > + '[' Linux == Darwin ']'; > + LIBRARY_SUFFIX=so; > + ldd libtiledbgenomicsdb.so; > ldd: ./libtiledbgenomicsdb.so: No such file or directory; > + md5sum libtiledbgenomicsdb.so; > md5sum: libtiledbgenomicsdb.so: No such file or directory. I'm using a compute canada server, so I don't have root access. The version of gatk4 I'm using was installed by their support team, and I load it using 'module load gatk'. I had that module loaded when I ran this test.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4124#issuecomment-357005071
https://github.com/broadinstitute/gatk/issues/4124#issuecomment-357005071:1749,Performance,load,loaded,1749,"@kgururaj I ran the commands you suggested. . > [user@cedar5 bin]$ bash -x TestGenomicsDBJar/run_checks.sh; > + [[ hB != hxB ]]; > + XTRACE_STATE=-x; > + [[ hxB != hxB ]]; > + VERBOSE_STATE=+v; > + set +xv; > + unset XTRACE_STATE VERBOSE_STATE; > ++ uname -s; > + osname=Linux; > + jar xf genomicsdb--jar-with-dependencies.jar libtiledbgenomicsdb.so; > java.io.FileNotFoundException: genomicsdb--jar-with-dependencies.jar (No such file or directory); > at java.util.zip.ZipFile.open(Native Method); > at java.util.zip.ZipFile.<init>(ZipFile.java:219); > at java.util.zip.ZipFile.<init>(ZipFile.java:149); > at java.util.zip.ZipFile.<init>(ZipFile.java:120); > at sun.tools.jar.Main.extract(Main.java:1004); > at sun.tools.jar.Main.run(Main.java:305); > at sun.tools.jar.Main.main(Main.java:1288); > + jar xf genomicsdb--jar-with-dependencies.jar libtiledbgenomicsdb.dylib; > java.io.FileNotFoundException: genomicsdb--jar-with-dependencies.jar (No such file or directory); > at java.util.zip.ZipFile.open(Native Method); > at java.util.zip.ZipFile.<init>(ZipFile.java:219); > at java.util.zip.ZipFile.<init>(ZipFile.java:149); > at java.util.zip.ZipFile.<init>(ZipFile.java:120); > at sun.tools.jar.Main.extract(Main.java:1004); > at sun.tools.jar.Main.run(Main.java:305); > at sun.tools.jar.Main.main(Main.java:1288); > + '[' Linux == Darwin ']'; > + LIBRARY_SUFFIX=so; > + ldd libtiledbgenomicsdb.so; > ldd: ./libtiledbgenomicsdb.so: No such file or directory; > + md5sum libtiledbgenomicsdb.so; > md5sum: libtiledbgenomicsdb.so: No such file or directory. I'm using a compute canada server, so I don't have root access. The version of gatk4 I'm using was installed by their support team, and I load it using 'module load gatk'. I had that module loaded when I ran this test.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4124#issuecomment-357005071
https://github.com/broadinstitute/gatk/issues/4124#issuecomment-357005071:1615,Security,access,access,1615,"@kgururaj I ran the commands you suggested. . > [user@cedar5 bin]$ bash -x TestGenomicsDBJar/run_checks.sh; > + [[ hB != hxB ]]; > + XTRACE_STATE=-x; > + [[ hxB != hxB ]]; > + VERBOSE_STATE=+v; > + set +xv; > + unset XTRACE_STATE VERBOSE_STATE; > ++ uname -s; > + osname=Linux; > + jar xf genomicsdb--jar-with-dependencies.jar libtiledbgenomicsdb.so; > java.io.FileNotFoundException: genomicsdb--jar-with-dependencies.jar (No such file or directory); > at java.util.zip.ZipFile.open(Native Method); > at java.util.zip.ZipFile.<init>(ZipFile.java:219); > at java.util.zip.ZipFile.<init>(ZipFile.java:149); > at java.util.zip.ZipFile.<init>(ZipFile.java:120); > at sun.tools.jar.Main.extract(Main.java:1004); > at sun.tools.jar.Main.run(Main.java:305); > at sun.tools.jar.Main.main(Main.java:1288); > + jar xf genomicsdb--jar-with-dependencies.jar libtiledbgenomicsdb.dylib; > java.io.FileNotFoundException: genomicsdb--jar-with-dependencies.jar (No such file or directory); > at java.util.zip.ZipFile.open(Native Method); > at java.util.zip.ZipFile.<init>(ZipFile.java:219); > at java.util.zip.ZipFile.<init>(ZipFile.java:149); > at java.util.zip.ZipFile.<init>(ZipFile.java:120); > at sun.tools.jar.Main.extract(Main.java:1004); > at sun.tools.jar.Main.run(Main.java:305); > at sun.tools.jar.Main.main(Main.java:1288); > + '[' Linux == Darwin ']'; > + LIBRARY_SUFFIX=so; > + ldd libtiledbgenomicsdb.so; > ldd: ./libtiledbgenomicsdb.so: No such file or directory; > + md5sum libtiledbgenomicsdb.so; > md5sum: libtiledbgenomicsdb.so: No such file or directory. I'm using a compute canada server, so I don't have root access. The version of gatk4 I'm using was installed by their support team, and I load it using 'module load gatk'. I had that module loaded when I ran this test.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4124#issuecomment-357005071
https://github.com/broadinstitute/gatk/issues/4124#issuecomment-357005071:75,Testability,Test,TestGenomicsDBJar,75,"@kgururaj I ran the commands you suggested. . > [user@cedar5 bin]$ bash -x TestGenomicsDBJar/run_checks.sh; > + [[ hB != hxB ]]; > + XTRACE_STATE=-x; > + [[ hxB != hxB ]]; > + VERBOSE_STATE=+v; > + set +xv; > + unset XTRACE_STATE VERBOSE_STATE; > ++ uname -s; > + osname=Linux; > + jar xf genomicsdb--jar-with-dependencies.jar libtiledbgenomicsdb.so; > java.io.FileNotFoundException: genomicsdb--jar-with-dependencies.jar (No such file or directory); > at java.util.zip.ZipFile.open(Native Method); > at java.util.zip.ZipFile.<init>(ZipFile.java:219); > at java.util.zip.ZipFile.<init>(ZipFile.java:149); > at java.util.zip.ZipFile.<init>(ZipFile.java:120); > at sun.tools.jar.Main.extract(Main.java:1004); > at sun.tools.jar.Main.run(Main.java:305); > at sun.tools.jar.Main.main(Main.java:1288); > + jar xf genomicsdb--jar-with-dependencies.jar libtiledbgenomicsdb.dylib; > java.io.FileNotFoundException: genomicsdb--jar-with-dependencies.jar (No such file or directory); > at java.util.zip.ZipFile.open(Native Method); > at java.util.zip.ZipFile.<init>(ZipFile.java:219); > at java.util.zip.ZipFile.<init>(ZipFile.java:149); > at java.util.zip.ZipFile.<init>(ZipFile.java:120); > at sun.tools.jar.Main.extract(Main.java:1004); > at sun.tools.jar.Main.run(Main.java:305); > at sun.tools.jar.Main.main(Main.java:1288); > + '[' Linux == Darwin ']'; > + LIBRARY_SUFFIX=so; > + ldd libtiledbgenomicsdb.so; > ldd: ./libtiledbgenomicsdb.so: No such file or directory; > + md5sum libtiledbgenomicsdb.so; > md5sum: libtiledbgenomicsdb.so: No such file or directory. I'm using a compute canada server, so I don't have root access. The version of gatk4 I'm using was installed by their support team, and I load it using 'module load gatk'. I had that module loaded when I ran this test.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4124#issuecomment-357005071
https://github.com/broadinstitute/gatk/issues/4124#issuecomment-357005071:1772,Testability,test,test,1772,"@kgururaj I ran the commands you suggested. . > [user@cedar5 bin]$ bash -x TestGenomicsDBJar/run_checks.sh; > + [[ hB != hxB ]]; > + XTRACE_STATE=-x; > + [[ hxB != hxB ]]; > + VERBOSE_STATE=+v; > + set +xv; > + unset XTRACE_STATE VERBOSE_STATE; > ++ uname -s; > + osname=Linux; > + jar xf genomicsdb--jar-with-dependencies.jar libtiledbgenomicsdb.so; > java.io.FileNotFoundException: genomicsdb--jar-with-dependencies.jar (No such file or directory); > at java.util.zip.ZipFile.open(Native Method); > at java.util.zip.ZipFile.<init>(ZipFile.java:219); > at java.util.zip.ZipFile.<init>(ZipFile.java:149); > at java.util.zip.ZipFile.<init>(ZipFile.java:120); > at sun.tools.jar.Main.extract(Main.java:1004); > at sun.tools.jar.Main.run(Main.java:305); > at sun.tools.jar.Main.main(Main.java:1288); > + jar xf genomicsdb--jar-with-dependencies.jar libtiledbgenomicsdb.dylib; > java.io.FileNotFoundException: genomicsdb--jar-with-dependencies.jar (No such file or directory); > at java.util.zip.ZipFile.open(Native Method); > at java.util.zip.ZipFile.<init>(ZipFile.java:219); > at java.util.zip.ZipFile.<init>(ZipFile.java:149); > at java.util.zip.ZipFile.<init>(ZipFile.java:120); > at sun.tools.jar.Main.extract(Main.java:1004); > at sun.tools.jar.Main.run(Main.java:305); > at sun.tools.jar.Main.main(Main.java:1288); > + '[' Linux == Darwin ']'; > + LIBRARY_SUFFIX=so; > + ldd libtiledbgenomicsdb.so; > ldd: ./libtiledbgenomicsdb.so: No such file or directory; > + md5sum libtiledbgenomicsdb.so; > md5sum: libtiledbgenomicsdb.so: No such file or directory. I'm using a compute canada server, so I don't have root access. The version of gatk4 I'm using was installed by their support team, and I load it using 'module load gatk'. I had that module loaded when I ran this test.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4124#issuecomment-357005071
https://github.com/broadinstitute/gatk/issues/4124#issuecomment-357064392:5,Deployability,update,updated,5,With updated command:. > [user@cedar5 bin]$ bash -x TestGenomicsDBJar/run_checks.sh; > + [[ hB != hxB ]]; > + XTRACE_STATE=-x; > + [[ hxB != hxB ]]; > + VERBOSE_STATE=+v; > + set +xv; > + unset XTRACE_STATE VERBOSE_STATE; > ++ uname -s; > + osname=Linux; > + jar xf genomicsdb-0.8.1-proto-3.0.0-beta-1+uuid-static-jar-with-dependencies.jar libtiledbgenomicsdb.so; > + jar xf genomicsdb-0.8.1-proto-3.0.0-beta-1+uuid-static-jar-with-dependencies.jar libtiledbgenomicsdb.dylib; > + '[' Linux == Darwin ']'; > + LIBRARY_SUFFIX=so; > + ldd libtiledbgenomicsdb.so; > ldd: warning: you do not have execution permission for `./libtiledbgenomicsdb.so'; > linux-vdso.so.1 (0x00007ffca79df000); > libpthread.so.0 => /cvmfs/soft.computecanada.ca/nix/store/77k5s2iy82zny2xazfsrrysbyifyy79b-glibc-2.24/lib/libpthread.so.0 (0x00007f146cb0c000); > libz.so.1 => not found; > libuuid.so.1 => not found; > librt.so.1 => /cvmfs/soft.computecanada.ca/nix/store/77k5s2iy82zny2xazfsrrysbyifyy79b-glibc-2.24/lib/librt.so.1 (0x00007f146c902000); > libm.so.6 => /cvmfs/soft.computecanada.ca/nix/store/77k5s2iy82zny2xazfsrrysbyifyy79b-glibc-2.24/lib/libm.so.6 (0x00007f146c5fd000); > libc.so.6 => /cvmfs/soft.computecanada.ca/nix/store/77k5s2iy82zny2xazfsrrysbyifyy79b-glibc-2.24/lib/libc.so.6 (0x00007f146c25f000); > /cvmfs/soft.computecanada.ca/nix/store/77k5s2iy82zny2xazfsrrysbyifyy79b-glibc-2.24/lib64/ld-linux-x86-64.so.2 (0x000055ddfd95d000); > + md5sum libtiledbgenomicsdb.so; > 83007be5ce8b0c832b539b21b6c0d68d libtiledbgenomicsdb.so,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4124#issuecomment-357064392
https://github.com/broadinstitute/gatk/issues/4124#issuecomment-357064392:323,Integrability,depend,dependencies,323,With updated command:. > [user@cedar5 bin]$ bash -x TestGenomicsDBJar/run_checks.sh; > + [[ hB != hxB ]]; > + XTRACE_STATE=-x; > + [[ hxB != hxB ]]; > + VERBOSE_STATE=+v; > + set +xv; > + unset XTRACE_STATE VERBOSE_STATE; > ++ uname -s; > + osname=Linux; > + jar xf genomicsdb-0.8.1-proto-3.0.0-beta-1+uuid-static-jar-with-dependencies.jar libtiledbgenomicsdb.so; > + jar xf genomicsdb-0.8.1-proto-3.0.0-beta-1+uuid-static-jar-with-dependencies.jar libtiledbgenomicsdb.dylib; > + '[' Linux == Darwin ']'; > + LIBRARY_SUFFIX=so; > + ldd libtiledbgenomicsdb.so; > ldd: warning: you do not have execution permission for `./libtiledbgenomicsdb.so'; > linux-vdso.so.1 (0x00007ffca79df000); > libpthread.so.0 => /cvmfs/soft.computecanada.ca/nix/store/77k5s2iy82zny2xazfsrrysbyifyy79b-glibc-2.24/lib/libpthread.so.0 (0x00007f146cb0c000); > libz.so.1 => not found; > libuuid.so.1 => not found; > librt.so.1 => /cvmfs/soft.computecanada.ca/nix/store/77k5s2iy82zny2xazfsrrysbyifyy79b-glibc-2.24/lib/librt.so.1 (0x00007f146c902000); > libm.so.6 => /cvmfs/soft.computecanada.ca/nix/store/77k5s2iy82zny2xazfsrrysbyifyy79b-glibc-2.24/lib/libm.so.6 (0x00007f146c5fd000); > libc.so.6 => /cvmfs/soft.computecanada.ca/nix/store/77k5s2iy82zny2xazfsrrysbyifyy79b-glibc-2.24/lib/libc.so.6 (0x00007f146c25f000); > /cvmfs/soft.computecanada.ca/nix/store/77k5s2iy82zny2xazfsrrysbyifyy79b-glibc-2.24/lib64/ld-linux-x86-64.so.2 (0x000055ddfd95d000); > + md5sum libtiledbgenomicsdb.so; > 83007be5ce8b0c832b539b21b6c0d68d libtiledbgenomicsdb.so,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4124#issuecomment-357064392
https://github.com/broadinstitute/gatk/issues/4124#issuecomment-357064392:432,Integrability,depend,dependencies,432,With updated command:. > [user@cedar5 bin]$ bash -x TestGenomicsDBJar/run_checks.sh; > + [[ hB != hxB ]]; > + XTRACE_STATE=-x; > + [[ hxB != hxB ]]; > + VERBOSE_STATE=+v; > + set +xv; > + unset XTRACE_STATE VERBOSE_STATE; > ++ uname -s; > + osname=Linux; > + jar xf genomicsdb-0.8.1-proto-3.0.0-beta-1+uuid-static-jar-with-dependencies.jar libtiledbgenomicsdb.so; > + jar xf genomicsdb-0.8.1-proto-3.0.0-beta-1+uuid-static-jar-with-dependencies.jar libtiledbgenomicsdb.dylib; > + '[' Linux == Darwin ']'; > + LIBRARY_SUFFIX=so; > + ldd libtiledbgenomicsdb.so; > ldd: warning: you do not have execution permission for `./libtiledbgenomicsdb.so'; > linux-vdso.so.1 (0x00007ffca79df000); > libpthread.so.0 => /cvmfs/soft.computecanada.ca/nix/store/77k5s2iy82zny2xazfsrrysbyifyy79b-glibc-2.24/lib/libpthread.so.0 (0x00007f146cb0c000); > libz.so.1 => not found; > libuuid.so.1 => not found; > librt.so.1 => /cvmfs/soft.computecanada.ca/nix/store/77k5s2iy82zny2xazfsrrysbyifyy79b-glibc-2.24/lib/librt.so.1 (0x00007f146c902000); > libm.so.6 => /cvmfs/soft.computecanada.ca/nix/store/77k5s2iy82zny2xazfsrrysbyifyy79b-glibc-2.24/lib/libm.so.6 (0x00007f146c5fd000); > libc.so.6 => /cvmfs/soft.computecanada.ca/nix/store/77k5s2iy82zny2xazfsrrysbyifyy79b-glibc-2.24/lib/libc.so.6 (0x00007f146c25f000); > /cvmfs/soft.computecanada.ca/nix/store/77k5s2iy82zny2xazfsrrysbyifyy79b-glibc-2.24/lib64/ld-linux-x86-64.so.2 (0x000055ddfd95d000); > + md5sum libtiledbgenomicsdb.so; > 83007be5ce8b0c832b539b21b6c0d68d libtiledbgenomicsdb.so,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4124#issuecomment-357064392
https://github.com/broadinstitute/gatk/issues/4124#issuecomment-357064392:52,Testability,Test,TestGenomicsDBJar,52,With updated command:. > [user@cedar5 bin]$ bash -x TestGenomicsDBJar/run_checks.sh; > + [[ hB != hxB ]]; > + XTRACE_STATE=-x; > + [[ hxB != hxB ]]; > + VERBOSE_STATE=+v; > + set +xv; > + unset XTRACE_STATE VERBOSE_STATE; > ++ uname -s; > + osname=Linux; > + jar xf genomicsdb-0.8.1-proto-3.0.0-beta-1+uuid-static-jar-with-dependencies.jar libtiledbgenomicsdb.so; > + jar xf genomicsdb-0.8.1-proto-3.0.0-beta-1+uuid-static-jar-with-dependencies.jar libtiledbgenomicsdb.dylib; > + '[' Linux == Darwin ']'; > + LIBRARY_SUFFIX=so; > + ldd libtiledbgenomicsdb.so; > ldd: warning: you do not have execution permission for `./libtiledbgenomicsdb.so'; > linux-vdso.so.1 (0x00007ffca79df000); > libpthread.so.0 => /cvmfs/soft.computecanada.ca/nix/store/77k5s2iy82zny2xazfsrrysbyifyy79b-glibc-2.24/lib/libpthread.so.0 (0x00007f146cb0c000); > libz.so.1 => not found; > libuuid.so.1 => not found; > librt.so.1 => /cvmfs/soft.computecanada.ca/nix/store/77k5s2iy82zny2xazfsrrysbyifyy79b-glibc-2.24/lib/librt.so.1 (0x00007f146c902000); > libm.so.6 => /cvmfs/soft.computecanada.ca/nix/store/77k5s2iy82zny2xazfsrrysbyifyy79b-glibc-2.24/lib/libm.so.6 (0x00007f146c5fd000); > libc.so.6 => /cvmfs/soft.computecanada.ca/nix/store/77k5s2iy82zny2xazfsrrysbyifyy79b-glibc-2.24/lib/libc.so.6 (0x00007f146c25f000); > /cvmfs/soft.computecanada.ca/nix/store/77k5s2iy82zny2xazfsrrysbyifyy79b-glibc-2.24/lib64/ld-linux-x86-64.so.2 (0x000055ddfd95d000); > + md5sum libtiledbgenomicsdb.so; > 83007be5ce8b0c832b539b21b6c0d68d libtiledbgenomicsdb.so,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4124#issuecomment-357064392
https://github.com/broadinstitute/gatk/issues/4124#issuecomment-357067214:64,Deployability,install,install,64,"Interesting, this is the first time that I have seen a CentOS-7 install without zlib and uuid - even the minimal installations include it. Your options are:; - Install zlib and uuid (yum -y install zlib libuuid); - Ask your admins whether these packages are installed in some other location. For example, if the zlib library is at /opt/my_install/lib64/libz.so, then you can set your environment variable LD_LIBRARY_PATH; ```; export LD_LIBRARY_PATH=/opt/my_install/lib64:/opt/my_install/lib:$LD_LIBRARY_PATH; ```; - Wait for the next GenomicsDB binary jar to show up",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4124#issuecomment-357067214
https://github.com/broadinstitute/gatk/issues/4124#issuecomment-357067214:113,Deployability,install,installations,113,"Interesting, this is the first time that I have seen a CentOS-7 install without zlib and uuid - even the minimal installations include it. Your options are:; - Install zlib and uuid (yum -y install zlib libuuid); - Ask your admins whether these packages are installed in some other location. For example, if the zlib library is at /opt/my_install/lib64/libz.so, then you can set your environment variable LD_LIBRARY_PATH; ```; export LD_LIBRARY_PATH=/opt/my_install/lib64:/opt/my_install/lib:$LD_LIBRARY_PATH; ```; - Wait for the next GenomicsDB binary jar to show up",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4124#issuecomment-357067214
https://github.com/broadinstitute/gatk/issues/4124#issuecomment-357067214:160,Deployability,Install,Install,160,"Interesting, this is the first time that I have seen a CentOS-7 install without zlib and uuid - even the minimal installations include it. Your options are:; - Install zlib and uuid (yum -y install zlib libuuid); - Ask your admins whether these packages are installed in some other location. For example, if the zlib library is at /opt/my_install/lib64/libz.so, then you can set your environment variable LD_LIBRARY_PATH; ```; export LD_LIBRARY_PATH=/opt/my_install/lib64:/opt/my_install/lib:$LD_LIBRARY_PATH; ```; - Wait for the next GenomicsDB binary jar to show up",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4124#issuecomment-357067214
https://github.com/broadinstitute/gatk/issues/4124#issuecomment-357067214:190,Deployability,install,install,190,"Interesting, this is the first time that I have seen a CentOS-7 install without zlib and uuid - even the minimal installations include it. Your options are:; - Install zlib and uuid (yum -y install zlib libuuid); - Ask your admins whether these packages are installed in some other location. For example, if the zlib library is at /opt/my_install/lib64/libz.so, then you can set your environment variable LD_LIBRARY_PATH; ```; export LD_LIBRARY_PATH=/opt/my_install/lib64:/opt/my_install/lib:$LD_LIBRARY_PATH; ```; - Wait for the next GenomicsDB binary jar to show up",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4124#issuecomment-357067214
https://github.com/broadinstitute/gatk/issues/4124#issuecomment-357067214:258,Deployability,install,installed,258,"Interesting, this is the first time that I have seen a CentOS-7 install without zlib and uuid - even the minimal installations include it. Your options are:; - Install zlib and uuid (yum -y install zlib libuuid); - Ask your admins whether these packages are installed in some other location. For example, if the zlib library is at /opt/my_install/lib64/libz.so, then you can set your environment variable LD_LIBRARY_PATH; ```; export LD_LIBRARY_PATH=/opt/my_install/lib64:/opt/my_install/lib:$LD_LIBRARY_PATH; ```; - Wait for the next GenomicsDB binary jar to show up",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4124#issuecomment-357067214
https://github.com/broadinstitute/gatk/issues/4124#issuecomment-357067214:396,Modifiability,variab,variable,396,"Interesting, this is the first time that I have seen a CentOS-7 install without zlib and uuid - even the minimal installations include it. Your options are:; - Install zlib and uuid (yum -y install zlib libuuid); - Ask your admins whether these packages are installed in some other location. For example, if the zlib library is at /opt/my_install/lib64/libz.so, then you can set your environment variable LD_LIBRARY_PATH; ```; export LD_LIBRARY_PATH=/opt/my_install/lib64:/opt/my_install/lib:$LD_LIBRARY_PATH; ```; - Wait for the next GenomicsDB binary jar to show up",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4124#issuecomment-357067214
https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357007880:78,Availability,error,erroring,78,"@stefandiederich What version of python are you running? That looks like it's erroring out when it hit's a type annotation, which is a python 3+ feature. I believe the CNV tools require python 3.6.2+.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357007880
https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357012782:178,Integrability,depend,dependencies,178,@stefandiederich There is a conda environment .yml file called gatkcondaenv.yml that is included with the distribution. It will establish the correct version of Python and other dependencies that are required for the CNV tools. You can find more detail about how to set this up [here](https://github.com/broadinstitute/gatk#requirements) (see the 3rd bullet point under Optional).,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357012782
https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357034364:977,Deployability,pipeline,pipeline,977,"@droazen @cmnbroad @mbabadi I generally agree with the sentiments expressed in #4127, except that I think it's OK to require a conda environment (or even use of the Docker) for these particular tools. How we should validate this requirement is another question. We can discuss more with @vdauwera. @stefandiederich Hopefully once you get the conda environment set up you will be able to run the tools. We would definitely appreciate any feedback you might be able to provide. Note that the gCNV model is relatively sophisticated, so there may be some parameters (which control the priors for the model as well as how inference is performed) that you will need to adjust for your data. Depending on the number of intervals/bins you are using and your memory constraints, you may also need to scatter across multiple GermlineCNVCaller runs; see how things are done in the WDLs here: https://github.com/broadinstitute/gatk/tree/master/scripts/cnv_wdl/germline. As you noted, this pipeline is still in beta. We are currently running several evaluations and hope to soon release some Best Practices recommendations for the aforementioned parameter values that should work well for various data types generated at the Broad. We will also have some blog or forum posts that explain the new CNV pipelines in more detail coming soon---stay tuned!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357034364
https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357034364:1066,Deployability,release,release,1066,"@droazen @cmnbroad @mbabadi I generally agree with the sentiments expressed in #4127, except that I think it's OK to require a conda environment (or even use of the Docker) for these particular tools. How we should validate this requirement is another question. We can discuss more with @vdauwera. @stefandiederich Hopefully once you get the conda environment set up you will be able to run the tools. We would definitely appreciate any feedback you might be able to provide. Note that the gCNV model is relatively sophisticated, so there may be some parameters (which control the priors for the model as well as how inference is performed) that you will need to adjust for your data. Depending on the number of intervals/bins you are using and your memory constraints, you may also need to scatter across multiple GermlineCNVCaller runs; see how things are done in the WDLs here: https://github.com/broadinstitute/gatk/tree/master/scripts/cnv_wdl/germline. As you noted, this pipeline is still in beta. We are currently running several evaluations and hope to soon release some Best Practices recommendations for the aforementioned parameter values that should work well for various data types generated at the Broad. We will also have some blog or forum posts that explain the new CNV pipelines in more detail coming soon---stay tuned!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357034364
https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357034364:1287,Deployability,pipeline,pipelines,1287,"@droazen @cmnbroad @mbabadi I generally agree with the sentiments expressed in #4127, except that I think it's OK to require a conda environment (or even use of the Docker) for these particular tools. How we should validate this requirement is another question. We can discuss more with @vdauwera. @stefandiederich Hopefully once you get the conda environment set up you will be able to run the tools. We would definitely appreciate any feedback you might be able to provide. Note that the gCNV model is relatively sophisticated, so there may be some parameters (which control the priors for the model as well as how inference is performed) that you will need to adjust for your data. Depending on the number of intervals/bins you are using and your memory constraints, you may also need to scatter across multiple GermlineCNVCaller runs; see how things are done in the WDLs here: https://github.com/broadinstitute/gatk/tree/master/scripts/cnv_wdl/germline. As you noted, this pipeline is still in beta. We are currently running several evaluations and hope to soon release some Best Practices recommendations for the aforementioned parameter values that should work well for various data types generated at the Broad. We will also have some blog or forum posts that explain the new CNV pipelines in more detail coming soon---stay tuned!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357034364
https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357034364:685,Integrability,Depend,Depending,685,"@droazen @cmnbroad @mbabadi I generally agree with the sentiments expressed in #4127, except that I think it's OK to require a conda environment (or even use of the Docker) for these particular tools. How we should validate this requirement is another question. We can discuss more with @vdauwera. @stefandiederich Hopefully once you get the conda environment set up you will be able to run the tools. We would definitely appreciate any feedback you might be able to provide. Note that the gCNV model is relatively sophisticated, so there may be some parameters (which control the priors for the model as well as how inference is performed) that you will need to adjust for your data. Depending on the number of intervals/bins you are using and your memory constraints, you may also need to scatter across multiple GermlineCNVCaller runs; see how things are done in the WDLs here: https://github.com/broadinstitute/gatk/tree/master/scripts/cnv_wdl/germline. As you noted, this pipeline is still in beta. We are currently running several evaluations and hope to soon release some Best Practices recommendations for the aforementioned parameter values that should work well for various data types generated at the Broad. We will also have some blog or forum posts that explain the new CNV pipelines in more detail coming soon---stay tuned!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357034364
https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357034364:630,Performance,perform,performed,630,"@droazen @cmnbroad @mbabadi I generally agree with the sentiments expressed in #4127, except that I think it's OK to require a conda environment (or even use of the Docker) for these particular tools. How we should validate this requirement is another question. We can discuss more with @vdauwera. @stefandiederich Hopefully once you get the conda environment set up you will be able to run the tools. We would definitely appreciate any feedback you might be able to provide. Note that the gCNV model is relatively sophisticated, so there may be some parameters (which control the priors for the model as well as how inference is performed) that you will need to adjust for your data. Depending on the number of intervals/bins you are using and your memory constraints, you may also need to scatter across multiple GermlineCNVCaller runs; see how things are done in the WDLs here: https://github.com/broadinstitute/gatk/tree/master/scripts/cnv_wdl/germline. As you noted, this pipeline is still in beta. We are currently running several evaluations and hope to soon release some Best Practices recommendations for the aforementioned parameter values that should work well for various data types generated at the Broad. We will also have some blog or forum posts that explain the new CNV pipelines in more detail coming soon---stay tuned!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357034364
https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357034364:1331,Performance,tune,tuned,1331,"@droazen @cmnbroad @mbabadi I generally agree with the sentiments expressed in #4127, except that I think it's OK to require a conda environment (or even use of the Docker) for these particular tools. How we should validate this requirement is another question. We can discuss more with @vdauwera. @stefandiederich Hopefully once you get the conda environment set up you will be able to run the tools. We would definitely appreciate any feedback you might be able to provide. Note that the gCNV model is relatively sophisticated, so there may be some parameters (which control the priors for the model as well as how inference is performed) that you will need to adjust for your data. Depending on the number of intervals/bins you are using and your memory constraints, you may also need to scatter across multiple GermlineCNVCaller runs; see how things are done in the WDLs here: https://github.com/broadinstitute/gatk/tree/master/scripts/cnv_wdl/germline. As you noted, this pipeline is still in beta. We are currently running several evaluations and hope to soon release some Best Practices recommendations for the aforementioned parameter values that should work well for various data types generated at the Broad. We will also have some blog or forum posts that explain the new CNV pipelines in more detail coming soon---stay tuned!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357034364
https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357034364:215,Security,validat,validate,215,"@droazen @cmnbroad @mbabadi I generally agree with the sentiments expressed in #4127, except that I think it's OK to require a conda environment (or even use of the Docker) for these particular tools. How we should validate this requirement is another question. We can discuss more with @vdauwera. @stefandiederich Hopefully once you get the conda environment set up you will be able to run the tools. We would definitely appreciate any feedback you might be able to provide. Note that the gCNV model is relatively sophisticated, so there may be some parameters (which control the priors for the model as well as how inference is performed) that you will need to adjust for your data. Depending on the number of intervals/bins you are using and your memory constraints, you may also need to scatter across multiple GermlineCNVCaller runs; see how things are done in the WDLs here: https://github.com/broadinstitute/gatk/tree/master/scripts/cnv_wdl/germline. As you noted, this pipeline is still in beta. We are currently running several evaluations and hope to soon release some Best Practices recommendations for the aforementioned parameter values that should work well for various data types generated at the Broad. We will also have some blog or forum posts that explain the new CNV pipelines in more detail coming soon---stay tuned!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357034364
https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357034364:437,Usability,feedback,feedback,437,"@droazen @cmnbroad @mbabadi I generally agree with the sentiments expressed in #4127, except that I think it's OK to require a conda environment (or even use of the Docker) for these particular tools. How we should validate this requirement is another question. We can discuss more with @vdauwera. @stefandiederich Hopefully once you get the conda environment set up you will be able to run the tools. We would definitely appreciate any feedback you might be able to provide. Note that the gCNV model is relatively sophisticated, so there may be some parameters (which control the priors for the model as well as how inference is performed) that you will need to adjust for your data. Depending on the number of intervals/bins you are using and your memory constraints, you may also need to scatter across multiple GermlineCNVCaller runs; see how things are done in the WDLs here: https://github.com/broadinstitute/gatk/tree/master/scripts/cnv_wdl/germline. As you noted, this pipeline is still in beta. We are currently running several evaluations and hope to soon release some Best Practices recommendations for the aforementioned parameter values that should work well for various data types generated at the Broad. We will also have some blog or forum posts that explain the new CNV pipelines in more detail coming soon---stay tuned!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357034364
https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357188460:102,Availability,error,error,102,"@cmnbroad Thanks for pointing to the conda environment file. I tried to install load it but the first error it gave me was ; ```; NoPackagesFoundError: Package missing in current linux-64 channels:; - intel-openmp 2018.0.0*; ```; so I installed this package by hand with ´conda install -c anaconda intel-openmp´ and afterwards tried to install the gatkcondaenv.yml again with ´conda env create -n gatk -f gatkcondaenv.yml´ . Unfortunately I run into the next error which says:. ```; root@k-hg-srv1:/BioinfSoftware# conda env create -n gatk -f gatkcondaenv.yml; Using Anaconda API: https://api.anaconda.org; Solving environment: done. Downloading and Extracting Packages; mkl-service 1.1.2: ################################################################################################################################################################################################################## | 100%; libgcc-ng 7.2.0: #################################################################################################################################################################################################################### | 100%; mkl 2018.0.1: ####################################################################################################################################################################################################################### | 100%; intel-openmp 2018.0.0: ############################################################################################################################################################################################################## | 100%; Preparing transaction: done; Verifying transaction: done; Executing transaction: done; Requirement 'build/gatkPythonPackageArchive.zip' looks like a filename, but the file does not exist; Processing ./build/gatkPythonPackageArchive.zip; Exception:; Traceback (most recent call last):; File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/basecommand.py"", lin",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357188460
https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357188460:459,Availability,error,error,459,"@cmnbroad Thanks for pointing to the conda environment file. I tried to install load it but the first error it gave me was ; ```; NoPackagesFoundError: Package missing in current linux-64 channels:; - intel-openmp 2018.0.0*; ```; so I installed this package by hand with ´conda install -c anaconda intel-openmp´ and afterwards tried to install the gatkcondaenv.yml again with ´conda env create -n gatk -f gatkcondaenv.yml´ . Unfortunately I run into the next error which says:. ```; root@k-hg-srv1:/BioinfSoftware# conda env create -n gatk -f gatkcondaenv.yml; Using Anaconda API: https://api.anaconda.org; Solving environment: done. Downloading and Extracting Packages; mkl-service 1.1.2: ################################################################################################################################################################################################################## | 100%; libgcc-ng 7.2.0: #################################################################################################################################################################################################################### | 100%; mkl 2018.0.1: ####################################################################################################################################################################################################################### | 100%; intel-openmp 2018.0.0: ############################################################################################################################################################################################################## | 100%; Preparing transaction: done; Verifying transaction: done; Executing transaction: done; Requirement 'build/gatkPythonPackageArchive.zip' looks like a filename, but the file does not exist; Processing ./build/gatkPythonPackageArchive.zip; Exception:; Traceback (most recent call last):; File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/basecommand.py"", lin",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357188460
https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357188460:634,Availability,Down,Downloading,634,"@cmnbroad Thanks for pointing to the conda environment file. I tried to install load it but the first error it gave me was ; ```; NoPackagesFoundError: Package missing in current linux-64 channels:; - intel-openmp 2018.0.0*; ```; so I installed this package by hand with ´conda install -c anaconda intel-openmp´ and afterwards tried to install the gatkcondaenv.yml again with ´conda env create -n gatk -f gatkcondaenv.yml´ . Unfortunately I run into the next error which says:. ```; root@k-hg-srv1:/BioinfSoftware# conda env create -n gatk -f gatkcondaenv.yml; Using Anaconda API: https://api.anaconda.org; Solving environment: done. Downloading and Extracting Packages; mkl-service 1.1.2: ################################################################################################################################################################################################################## | 100%; libgcc-ng 7.2.0: #################################################################################################################################################################################################################### | 100%; mkl 2018.0.1: ####################################################################################################################################################################################################################### | 100%; intel-openmp 2018.0.0: ############################################################################################################################################################################################################## | 100%; Preparing transaction: done; Verifying transaction: done; Executing transaction: done; Requirement 'build/gatkPythonPackageArchive.zip' looks like a filename, but the file does not exist; Processing ./build/gatkPythonPackageArchive.zip; Exception:; Traceback (most recent call last):; File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/basecommand.py"", lin",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357188460
https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357188460:2741,Availability,down,download,2741,"############################################ | 100%; Preparing transaction: done; Verifying transaction: done; Executing transaction: done; Requirement 'build/gatkPythonPackageArchive.zip' looks like a filename, but the file does not exist; Processing ./build/gatkPythonPackageArchive.zip; Exception:; Traceback (most recent call last):; File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/basecommand.py"", line 215, in main; status = self.run(options, args); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/commands/install.py"", line 335, in run; wb.build(autobuilding=True); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/wheel.py"", line 749, in build; self.requirement_set.prepare_files(self.finder); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/req/req_set.py"", line 380, in prepare_files; ignore_dependencies=self.ignore_dependencies)); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/req/req_set.py"", line 620, in _prepare_file; session=self.session, hashes=hashes); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/download.py"", line 809, in unpack_url; unpack_file_url(link, location, download_dir, hashes=hashes); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/download.py"", line 715, in unpack_file_url; unpack_file(from_path, location, content_type, link); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/utils/__init__.py"", line 599, in unpack_file; flatten=not filename.endswith('.whl'); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/utils/__init__.py"", line 482, in unzip_file; zipfp = open(filename, 'rb'); FileNotFoundError: [Errno 2] Datei oder Verzeichnis nicht gefunden: '/BioinfSoftware/build/gatkPythonPackageArchive.zip'. CondaValueError: pip returned an error; ```. Thanks also to all the other ones for their good hints for using germlineCNV caller.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357188460
https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357188460:2915,Availability,down,download,2915,"############################################ | 100%; Preparing transaction: done; Verifying transaction: done; Executing transaction: done; Requirement 'build/gatkPythonPackageArchive.zip' looks like a filename, but the file does not exist; Processing ./build/gatkPythonPackageArchive.zip; Exception:; Traceback (most recent call last):; File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/basecommand.py"", line 215, in main; status = self.run(options, args); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/commands/install.py"", line 335, in run; wb.build(autobuilding=True); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/wheel.py"", line 749, in build; self.requirement_set.prepare_files(self.finder); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/req/req_set.py"", line 380, in prepare_files; ignore_dependencies=self.ignore_dependencies)); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/req/req_set.py"", line 620, in _prepare_file; session=self.session, hashes=hashes); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/download.py"", line 809, in unpack_url; unpack_file_url(link, location, download_dir, hashes=hashes); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/download.py"", line 715, in unpack_file_url; unpack_file(from_path, location, content_type, link); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/utils/__init__.py"", line 599, in unpack_file; flatten=not filename.endswith('.whl'); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/utils/__init__.py"", line 482, in unzip_file; zipfp = open(filename, 'rb'); FileNotFoundError: [Errno 2] Datei oder Verzeichnis nicht gefunden: '/BioinfSoftware/build/gatkPythonPackageArchive.zip'. CondaValueError: pip returned an error; ```. Thanks also to all the other ones for their good hints for using germlineCNV caller.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357188460
https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357188460:3474,Availability,error,error,3474,"############################################ | 100%; Preparing transaction: done; Verifying transaction: done; Executing transaction: done; Requirement 'build/gatkPythonPackageArchive.zip' looks like a filename, but the file does not exist; Processing ./build/gatkPythonPackageArchive.zip; Exception:; Traceback (most recent call last):; File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/basecommand.py"", line 215, in main; status = self.run(options, args); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/commands/install.py"", line 335, in run; wb.build(autobuilding=True); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/wheel.py"", line 749, in build; self.requirement_set.prepare_files(self.finder); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/req/req_set.py"", line 380, in prepare_files; ignore_dependencies=self.ignore_dependencies)); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/req/req_set.py"", line 620, in _prepare_file; session=self.session, hashes=hashes); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/download.py"", line 809, in unpack_url; unpack_file_url(link, location, download_dir, hashes=hashes); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/download.py"", line 715, in unpack_file_url; unpack_file(from_path, location, content_type, link); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/utils/__init__.py"", line 599, in unpack_file; flatten=not filename.endswith('.whl'); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/utils/__init__.py"", line 482, in unzip_file; zipfp = open(filename, 'rb'); FileNotFoundError: [Errno 2] Datei oder Verzeichnis nicht gefunden: '/BioinfSoftware/build/gatkPythonPackageArchive.zip'. CondaValueError: pip returned an error; ```. Thanks also to all the other ones for their good hints for using germlineCNV caller.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357188460
https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357188460:72,Deployability,install,install,72,"@cmnbroad Thanks for pointing to the conda environment file. I tried to install load it but the first error it gave me was ; ```; NoPackagesFoundError: Package missing in current linux-64 channels:; - intel-openmp 2018.0.0*; ```; so I installed this package by hand with ´conda install -c anaconda intel-openmp´ and afterwards tried to install the gatkcondaenv.yml again with ´conda env create -n gatk -f gatkcondaenv.yml´ . Unfortunately I run into the next error which says:. ```; root@k-hg-srv1:/BioinfSoftware# conda env create -n gatk -f gatkcondaenv.yml; Using Anaconda API: https://api.anaconda.org; Solving environment: done. Downloading and Extracting Packages; mkl-service 1.1.2: ################################################################################################################################################################################################################## | 100%; libgcc-ng 7.2.0: #################################################################################################################################################################################################################### | 100%; mkl 2018.0.1: ####################################################################################################################################################################################################################### | 100%; intel-openmp 2018.0.0: ############################################################################################################################################################################################################## | 100%; Preparing transaction: done; Verifying transaction: done; Executing transaction: done; Requirement 'build/gatkPythonPackageArchive.zip' looks like a filename, but the file does not exist; Processing ./build/gatkPythonPackageArchive.zip; Exception:; Traceback (most recent call last):; File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/basecommand.py"", lin",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357188460
https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357188460:235,Deployability,install,installed,235,"@cmnbroad Thanks for pointing to the conda environment file. I tried to install load it but the first error it gave me was ; ```; NoPackagesFoundError: Package missing in current linux-64 channels:; - intel-openmp 2018.0.0*; ```; so I installed this package by hand with ´conda install -c anaconda intel-openmp´ and afterwards tried to install the gatkcondaenv.yml again with ´conda env create -n gatk -f gatkcondaenv.yml´ . Unfortunately I run into the next error which says:. ```; root@k-hg-srv1:/BioinfSoftware# conda env create -n gatk -f gatkcondaenv.yml; Using Anaconda API: https://api.anaconda.org; Solving environment: done. Downloading and Extracting Packages; mkl-service 1.1.2: ################################################################################################################################################################################################################## | 100%; libgcc-ng 7.2.0: #################################################################################################################################################################################################################### | 100%; mkl 2018.0.1: ####################################################################################################################################################################################################################### | 100%; intel-openmp 2018.0.0: ############################################################################################################################################################################################################## | 100%; Preparing transaction: done; Verifying transaction: done; Executing transaction: done; Requirement 'build/gatkPythonPackageArchive.zip' looks like a filename, but the file does not exist; Processing ./build/gatkPythonPackageArchive.zip; Exception:; Traceback (most recent call last):; File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/basecommand.py"", lin",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357188460
https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357188460:278,Deployability,install,install,278,"@cmnbroad Thanks for pointing to the conda environment file. I tried to install load it but the first error it gave me was ; ```; NoPackagesFoundError: Package missing in current linux-64 channels:; - intel-openmp 2018.0.0*; ```; so I installed this package by hand with ´conda install -c anaconda intel-openmp´ and afterwards tried to install the gatkcondaenv.yml again with ´conda env create -n gatk -f gatkcondaenv.yml´ . Unfortunately I run into the next error which says:. ```; root@k-hg-srv1:/BioinfSoftware# conda env create -n gatk -f gatkcondaenv.yml; Using Anaconda API: https://api.anaconda.org; Solving environment: done. Downloading and Extracting Packages; mkl-service 1.1.2: ################################################################################################################################################################################################################## | 100%; libgcc-ng 7.2.0: #################################################################################################################################################################################################################### | 100%; mkl 2018.0.1: ####################################################################################################################################################################################################################### | 100%; intel-openmp 2018.0.0: ############################################################################################################################################################################################################## | 100%; Preparing transaction: done; Verifying transaction: done; Executing transaction: done; Requirement 'build/gatkPythonPackageArchive.zip' looks like a filename, but the file does not exist; Processing ./build/gatkPythonPackageArchive.zip; Exception:; Traceback (most recent call last):; File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/basecommand.py"", lin",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357188460
https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357188460:336,Deployability,install,install,336,"@cmnbroad Thanks for pointing to the conda environment file. I tried to install load it but the first error it gave me was ; ```; NoPackagesFoundError: Package missing in current linux-64 channels:; - intel-openmp 2018.0.0*; ```; so I installed this package by hand with ´conda install -c anaconda intel-openmp´ and afterwards tried to install the gatkcondaenv.yml again with ´conda env create -n gatk -f gatkcondaenv.yml´ . Unfortunately I run into the next error which says:. ```; root@k-hg-srv1:/BioinfSoftware# conda env create -n gatk -f gatkcondaenv.yml; Using Anaconda API: https://api.anaconda.org; Solving environment: done. Downloading and Extracting Packages; mkl-service 1.1.2: ################################################################################################################################################################################################################## | 100%; libgcc-ng 7.2.0: #################################################################################################################################################################################################################### | 100%; mkl 2018.0.1: ####################################################################################################################################################################################################################### | 100%; intel-openmp 2018.0.0: ############################################################################################################################################################################################################## | 100%; Preparing transaction: done; Verifying transaction: done; Executing transaction: done; Requirement 'build/gatkPythonPackageArchive.zip' looks like a filename, but the file does not exist; Processing ./build/gatkPythonPackageArchive.zip; Exception:; Traceback (most recent call last):; File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/basecommand.py"", lin",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357188460
https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357188460:2133,Deployability,install,install,2133,"################ | 100%; mkl 2018.0.1: ####################################################################################################################################################################################################################### | 100%; intel-openmp 2018.0.0: ############################################################################################################################################################################################################## | 100%; Preparing transaction: done; Verifying transaction: done; Executing transaction: done; Requirement 'build/gatkPythonPackageArchive.zip' looks like a filename, but the file does not exist; Processing ./build/gatkPythonPackageArchive.zip; Exception:; Traceback (most recent call last):; File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/basecommand.py"", line 215, in main; status = self.run(options, args); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/commands/install.py"", line 335, in run; wb.build(autobuilding=True); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/wheel.py"", line 749, in build; self.requirement_set.prepare_files(self.finder); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/req/req_set.py"", line 380, in prepare_files; ignore_dependencies=self.ignore_dependencies)); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/req/req_set.py"", line 620, in _prepare_file; session=self.session, hashes=hashes); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/download.py"", line 809, in unpack_url; unpack_file_url(link, location, download_dir, hashes=hashes); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/download.py"", line 715, in unpack_file_url; unpack_file(from_path, location, content_type, link); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/utils/__init__.py"", line 599, in unpa",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357188460
https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357188460:80,Performance,load,load,80,"@cmnbroad Thanks for pointing to the conda environment file. I tried to install load it but the first error it gave me was ; ```; NoPackagesFoundError: Package missing in current linux-64 channels:; - intel-openmp 2018.0.0*; ```; so I installed this package by hand with ´conda install -c anaconda intel-openmp´ and afterwards tried to install the gatkcondaenv.yml again with ´conda env create -n gatk -f gatkcondaenv.yml´ . Unfortunately I run into the next error which says:. ```; root@k-hg-srv1:/BioinfSoftware# conda env create -n gatk -f gatkcondaenv.yml; Using Anaconda API: https://api.anaconda.org; Solving environment: done. Downloading and Extracting Packages; mkl-service 1.1.2: ################################################################################################################################################################################################################## | 100%; libgcc-ng 7.2.0: #################################################################################################################################################################################################################### | 100%; mkl 2018.0.1: ####################################################################################################################################################################################################################### | 100%; intel-openmp 2018.0.0: ############################################################################################################################################################################################################## | 100%; Preparing transaction: done; Verifying transaction: done; Executing transaction: done; Requirement 'build/gatkPythonPackageArchive.zip' looks like a filename, but the file does not exist; Processing ./build/gatkPythonPackageArchive.zip; Exception:; Traceback (most recent call last):; File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/basecommand.py"", lin",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357188460
https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357188460:2652,Security,hash,hashes,2652,"############################################ | 100%; Preparing transaction: done; Verifying transaction: done; Executing transaction: done; Requirement 'build/gatkPythonPackageArchive.zip' looks like a filename, but the file does not exist; Processing ./build/gatkPythonPackageArchive.zip; Exception:; Traceback (most recent call last):; File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/basecommand.py"", line 215, in main; status = self.run(options, args); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/commands/install.py"", line 335, in run; wb.build(autobuilding=True); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/wheel.py"", line 749, in build; self.requirement_set.prepare_files(self.finder); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/req/req_set.py"", line 380, in prepare_files; ignore_dependencies=self.ignore_dependencies)); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/req/req_set.py"", line 620, in _prepare_file; session=self.session, hashes=hashes); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/download.py"", line 809, in unpack_url; unpack_file_url(link, location, download_dir, hashes=hashes); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/download.py"", line 715, in unpack_file_url; unpack_file(from_path, location, content_type, link); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/utils/__init__.py"", line 599, in unpack_file; flatten=not filename.endswith('.whl'); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/utils/__init__.py"", line 482, in unzip_file; zipfp = open(filename, 'rb'); FileNotFoundError: [Errno 2] Datei oder Verzeichnis nicht gefunden: '/BioinfSoftware/build/gatkPythonPackageArchive.zip'. CondaValueError: pip returned an error; ```. Thanks also to all the other ones for their good hints for using germlineCNV caller.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357188460
https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357188460:2659,Security,hash,hashes,2659,"############################################ | 100%; Preparing transaction: done; Verifying transaction: done; Executing transaction: done; Requirement 'build/gatkPythonPackageArchive.zip' looks like a filename, but the file does not exist; Processing ./build/gatkPythonPackageArchive.zip; Exception:; Traceback (most recent call last):; File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/basecommand.py"", line 215, in main; status = self.run(options, args); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/commands/install.py"", line 335, in run; wb.build(autobuilding=True); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/wheel.py"", line 749, in build; self.requirement_set.prepare_files(self.finder); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/req/req_set.py"", line 380, in prepare_files; ignore_dependencies=self.ignore_dependencies)); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/req/req_set.py"", line 620, in _prepare_file; session=self.session, hashes=hashes); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/download.py"", line 809, in unpack_url; unpack_file_url(link, location, download_dir, hashes=hashes); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/download.py"", line 715, in unpack_file_url; unpack_file(from_path, location, content_type, link); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/utils/__init__.py"", line 599, in unpack_file; flatten=not filename.endswith('.whl'); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/utils/__init__.py"", line 482, in unzip_file; zipfp = open(filename, 'rb'); FileNotFoundError: [Errno 2] Datei oder Verzeichnis nicht gefunden: '/BioinfSoftware/build/gatkPythonPackageArchive.zip'. CondaValueError: pip returned an error; ```. Thanks also to all the other ones for their good hints for using germlineCNV caller.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357188460
https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357188460:2826,Security,hash,hashes,2826,"############################################ | 100%; Preparing transaction: done; Verifying transaction: done; Executing transaction: done; Requirement 'build/gatkPythonPackageArchive.zip' looks like a filename, but the file does not exist; Processing ./build/gatkPythonPackageArchive.zip; Exception:; Traceback (most recent call last):; File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/basecommand.py"", line 215, in main; status = self.run(options, args); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/commands/install.py"", line 335, in run; wb.build(autobuilding=True); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/wheel.py"", line 749, in build; self.requirement_set.prepare_files(self.finder); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/req/req_set.py"", line 380, in prepare_files; ignore_dependencies=self.ignore_dependencies)); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/req/req_set.py"", line 620, in _prepare_file; session=self.session, hashes=hashes); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/download.py"", line 809, in unpack_url; unpack_file_url(link, location, download_dir, hashes=hashes); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/download.py"", line 715, in unpack_file_url; unpack_file(from_path, location, content_type, link); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/utils/__init__.py"", line 599, in unpack_file; flatten=not filename.endswith('.whl'); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/utils/__init__.py"", line 482, in unzip_file; zipfp = open(filename, 'rb'); FileNotFoundError: [Errno 2] Datei oder Verzeichnis nicht gefunden: '/BioinfSoftware/build/gatkPythonPackageArchive.zip'. CondaValueError: pip returned an error; ```. Thanks also to all the other ones for their good hints for using germlineCNV caller.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357188460
https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357188460:2833,Security,hash,hashes,2833,"############################################ | 100%; Preparing transaction: done; Verifying transaction: done; Executing transaction: done; Requirement 'build/gatkPythonPackageArchive.zip' looks like a filename, but the file does not exist; Processing ./build/gatkPythonPackageArchive.zip; Exception:; Traceback (most recent call last):; File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/basecommand.py"", line 215, in main; status = self.run(options, args); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/commands/install.py"", line 335, in run; wb.build(autobuilding=True); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/wheel.py"", line 749, in build; self.requirement_set.prepare_files(self.finder); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/req/req_set.py"", line 380, in prepare_files; ignore_dependencies=self.ignore_dependencies)); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/req/req_set.py"", line 620, in _prepare_file; session=self.session, hashes=hashes); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/download.py"", line 809, in unpack_url; unpack_file_url(link, location, download_dir, hashes=hashes); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/download.py"", line 715, in unpack_file_url; unpack_file(from_path, location, content_type, link); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/utils/__init__.py"", line 599, in unpack_file; flatten=not filename.endswith('.whl'); File ""/BioinfSoftware/Anaconda/envs/gatk/lib/python3.6/site-packages/pip/utils/__init__.py"", line 482, in unzip_file; zipfp = open(filename, 'rb'); FileNotFoundError: [Errno 2] Datei oder Verzeichnis nicht gefunden: '/BioinfSoftware/build/gatkPythonPackageArchive.zip'. CondaValueError: pip returned an error; ```. Thanks also to all the other ones for their good hints for using germlineCNV caller.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357188460
https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357219710:236,Availability,error,error,236,@stefandiederich I think we forgot to mention that you need to create the GATK python package using “./gradlew createPythonPackageArchive” before creating the conda environment. I don’t think you should run into any further issues. The error with the intel-openmp package was most likely due to your Anaconda/Miniconda installation not being as up to date as the one our Docker image uses. (Note that using that image to run everything might be another option to consider.),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357219710
https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357219710:319,Deployability,install,installation,319,@stefandiederich I think we forgot to mention that you need to create the GATK python package using “./gradlew createPythonPackageArchive” before creating the conda environment. I don’t think you should run into any further issues. The error with the intel-openmp package was most likely due to your Anaconda/Miniconda installation not being as up to date as the one our Docker image uses. (Note that using that image to run everything might be another option to consider.),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357219710
https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357234489:309,Usability,guid,guide,309,@samuelklee Thanks for yor help. I created the ython package and could set up the conda environment. I activated it and run the command for DetermineGermlineContigPloidy again. Now it`s running :-). Thanks again for you very quick respons and high quality help! I am realy looking forward to the BestPractice guide for GermlineCNV calling. Thanks to all. ; I will close this issue now.; Stefan,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4125#issuecomment-357234489
https://github.com/broadinstitute/gatk/issues/4125#issuecomment-390329219:87,Availability,error,error,87,"Do I need to run this Python package in the GATK4.0.4.0 Docker? I am getting a similar error with DetermineGermlineContigPloidy while running within the Docker on a Linux Compute Engine VM.; ```; ...; 19:06:35.948 INFO DetermineGermlineContigPloidy - Aggregating read-count file /gatk/snail/gcnv_180517/coverage_1k/A19625.hc.soohee1k.hdf5 (24 / 24); 19:06:54.675 INFO DetermineGermlineContigPloidy - Shutting down engine; [May 18, 2018 7:06:54 PM UTC] org.broadinstitute.hellbender.tools.copynumber.DetermineGermlineContigPloidy done. Elapsed time: 1.83 minutes.; Runtime.totalMemory()=2822242304; org.broadinstitute.hellbender.utils.python.PythonScriptExecutorException: ; python exited with 1; Command Line: python /tmp/root/cohort_determine_ploidy_and_depth.8539868448285133842.py --sample_coverage_metadata=/tmp/root/samples-by-coverage-per-contig3023244219495833390.tsv --output_calls_path=/gatk/snail/gcnv_180517/ploidy/hc24_soohee1k_ploidy-calls --mapping_error_rate=1.000000e-02 --psi_s_scale=1.000000e-04 --mean_bias_sd=1.000000e-02 --psi_j_scale=1.000000e-03 --learning_rate=5.000000e-02 --adamax_beta1=9.000000e-01 --adamax_beta2=9.990000e-01 --log_emission_samples_per_round=2000 --log_emission_sampling_rounds=100 --log_emission_sampling_median_rel_error=5.000000e-04 --max_advi_iter_first_epoch=1000 --max_advi_iter_subsequent_epochs=1000 --min_training_epochs=20 --max_training_epochs=100 --initial_temperature=2.000000e+00 --num_thermal_epochs=20 --convergence_snr_averaging_window=5000 --convergence_snr_trigger_threshold=1.000000e-01 --convergence_snr_countdown_window=10 --max_calling_iters=1 --caller_update_convergence_threshold=1.000000e-03 --caller_admixing_rate=7.500000e-01 --disable_caller=false --disable_sampler=false --disable_annealing=false --interval_list=/tmp/root/intervals3258684972117897378.tsv --contig_ploidy_prior_table=/gatk/snail/gcnv/grch38_germline_CN_priors.tsv --output_model_path=/gatk/snail/gcnv_180517/ploidy/hc24_soohee1k_ploidy-model; Stdout: ; Stderr",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4125#issuecomment-390329219
https://github.com/broadinstitute/gatk/issues/4125#issuecomment-390329219:409,Availability,down,down,409,"Do I need to run this Python package in the GATK4.0.4.0 Docker? I am getting a similar error with DetermineGermlineContigPloidy while running within the Docker on a Linux Compute Engine VM.; ```; ...; 19:06:35.948 INFO DetermineGermlineContigPloidy - Aggregating read-count file /gatk/snail/gcnv_180517/coverage_1k/A19625.hc.soohee1k.hdf5 (24 / 24); 19:06:54.675 INFO DetermineGermlineContigPloidy - Shutting down engine; [May 18, 2018 7:06:54 PM UTC] org.broadinstitute.hellbender.tools.copynumber.DetermineGermlineContigPloidy done. Elapsed time: 1.83 minutes.; Runtime.totalMemory()=2822242304; org.broadinstitute.hellbender.utils.python.PythonScriptExecutorException: ; python exited with 1; Command Line: python /tmp/root/cohort_determine_ploidy_and_depth.8539868448285133842.py --sample_coverage_metadata=/tmp/root/samples-by-coverage-per-contig3023244219495833390.tsv --output_calls_path=/gatk/snail/gcnv_180517/ploidy/hc24_soohee1k_ploidy-calls --mapping_error_rate=1.000000e-02 --psi_s_scale=1.000000e-04 --mean_bias_sd=1.000000e-02 --psi_j_scale=1.000000e-03 --learning_rate=5.000000e-02 --adamax_beta1=9.000000e-01 --adamax_beta2=9.990000e-01 --log_emission_samples_per_round=2000 --log_emission_sampling_rounds=100 --log_emission_sampling_median_rel_error=5.000000e-04 --max_advi_iter_first_epoch=1000 --max_advi_iter_subsequent_epochs=1000 --min_training_epochs=20 --max_training_epochs=100 --initial_temperature=2.000000e+00 --num_thermal_epochs=20 --convergence_snr_averaging_window=5000 --convergence_snr_trigger_threshold=1.000000e-01 --convergence_snr_countdown_window=10 --max_calling_iters=1 --caller_update_convergence_threshold=1.000000e-03 --caller_admixing_rate=7.500000e-01 --disable_caller=false --disable_sampler=false --disable_annealing=false --interval_list=/tmp/root/intervals3258684972117897378.tsv --contig_ploidy_prior_table=/gatk/snail/gcnv/grch38_germline_CN_priors.tsv --output_model_path=/gatk/snail/gcnv_180517/ploidy/hc24_soohee1k_ploidy-model; Stdout: ; Stderr",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4125#issuecomment-390329219
https://github.com/broadinstitute/gatk/issues/4125#issuecomment-390329219:2313,Testability,assert,assert,2313,"irst_epoch=1000 --max_advi_iter_subsequent_epochs=1000 --min_training_epochs=20 --max_training_epochs=100 --initial_temperature=2.000000e+00 --num_thermal_epochs=20 --convergence_snr_averaging_window=5000 --convergence_snr_trigger_threshold=1.000000e-01 --convergence_snr_countdown_window=10 --max_calling_iters=1 --caller_update_convergence_threshold=1.000000e-03 --caller_admixing_rate=7.500000e-01 --disable_caller=false --disable_sampler=false --disable_annealing=false --interval_list=/tmp/root/intervals3258684972117897378.tsv --contig_ploidy_prior_table=/gatk/snail/gcnv/grch38_germline_CN_priors.tsv --output_model_path=/gatk/snail/gcnv_180517/ploidy/hc24_soohee1k_ploidy-model; Stdout: ; Stderr: Traceback (most recent call last):; File ""/tmp/root/cohort_determine_ploidy_and_depth.8539868448285133842.py"", line 78, in <module>; args.contig_ploidy_prior_table); File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/gcnvkernel/io/io_ploidy.py"", line 183, in get_contig_ploidy_prior_map_from_tsv_file; assert columns[0] == io_consts.ploidy_prior_contig_name_column; AssertionError. 	at org.broadinstitute.hellbender.utils.python.PythonExecutorBase.getScriptException(PythonExecutorBase.java:75); 	at org.broadinstitute.hellbender.utils.runtime.ScriptExecutor.executeCuratedArgs(ScriptExecutor.java:126); 	at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.executeArgs(PythonScriptExecutor.java:170); 	at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.executeScript(PythonScriptExecutor.java:151); 	at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.executeScript(PythonScriptExecutor.java:121); 	at org.broadinstitute.hellbender.tools.copynumber.DetermineGermlineContigPloidy.executeDeterminePloidyAndDepthPythonScript(DetermineGermlineContigPloidy.java:365); 	at org.broadinstitute.hellbender.tools.copynumber.DetermineGermlineContigPloidy.doWork(DetermineGermlineContigPloidy.java:263); 	at org.broadinstitute.hellbender.cmdline.Command",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4125#issuecomment-390329219
https://github.com/broadinstitute/gatk/issues/4125#issuecomment-390329219:2377,Testability,Assert,AssertionError,2377,"epochs=20 --max_training_epochs=100 --initial_temperature=2.000000e+00 --num_thermal_epochs=20 --convergence_snr_averaging_window=5000 --convergence_snr_trigger_threshold=1.000000e-01 --convergence_snr_countdown_window=10 --max_calling_iters=1 --caller_update_convergence_threshold=1.000000e-03 --caller_admixing_rate=7.500000e-01 --disable_caller=false --disable_sampler=false --disable_annealing=false --interval_list=/tmp/root/intervals3258684972117897378.tsv --contig_ploidy_prior_table=/gatk/snail/gcnv/grch38_germline_CN_priors.tsv --output_model_path=/gatk/snail/gcnv_180517/ploidy/hc24_soohee1k_ploidy-model; Stdout: ; Stderr: Traceback (most recent call last):; File ""/tmp/root/cohort_determine_ploidy_and_depth.8539868448285133842.py"", line 78, in <module>; args.contig_ploidy_prior_table); File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/gcnvkernel/io/io_ploidy.py"", line 183, in get_contig_ploidy_prior_map_from_tsv_file; assert columns[0] == io_consts.ploidy_prior_contig_name_column; AssertionError. 	at org.broadinstitute.hellbender.utils.python.PythonExecutorBase.getScriptException(PythonExecutorBase.java:75); 	at org.broadinstitute.hellbender.utils.runtime.ScriptExecutor.executeCuratedArgs(ScriptExecutor.java:126); 	at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.executeArgs(PythonScriptExecutor.java:170); 	at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.executeScript(PythonScriptExecutor.java:151); 	at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.executeScript(PythonScriptExecutor.java:121); 	at org.broadinstitute.hellbender.tools.copynumber.DetermineGermlineContigPloidy.executeDeterminePloidyAndDepthPythonScript(DetermineGermlineContigPloidy.java:365); 	at org.broadinstitute.hellbender.tools.copynumber.DetermineGermlineContigPloidy.doWork(DetermineGermlineContigPloidy.java:263); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:134); 	at org.broadinstitu",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4125#issuecomment-390329219
https://github.com/broadinstitute/gatk/issues/4125#issuecomment-392194430:12,Deployability,install,install,12,"I'm able to install Conda, run the yml and activate it locally. I don't know what's up with the Docker either.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4125#issuecomment-392194430
https://github.com/broadinstitute/gatk/issues/4125#issuecomment-434527279:89,Availability,error,error,89,"> Do I need to run this Python package in the GATK4.0.4.0 Docker? I am getting a similar error with DetermineGermlineContigPloidy while running within the Docker on a Linux Compute Engine VM.; > ; > ```; > ...; > 19:06:35.948 INFO DetermineGermlineContigPloidy - Aggregating read-count file /gatk/snail/gcnv_180517/coverage_1k/A19625.hc.soohee1k.hdf5 (24 / 24); > 19:06:54.675 INFO DetermineGermlineContigPloidy - Shutting down engine; > [May 18, 2018 7:06:54 PM UTC] org.broadinstitute.hellbender.tools.copynumber.DetermineGermlineContigPloidy done. Elapsed time: 1.83 minutes.; > Runtime.totalMemory()=2822242304; > org.broadinstitute.hellbender.utils.python.PythonScriptExecutorException: ; > python exited with 1; > Command Line: python /tmp/root/cohort_determine_ploidy_and_depth.8539868448285133842.py --sample_coverage_metadata=/tmp/root/samples-by-coverage-per-contig3023244219495833390.tsv --output_calls_path=/gatk/snail/gcnv_180517/ploidy/hc24_soohee1k_ploidy-calls --mapping_error_rate=1.000000e-02 --psi_s_scale=1.000000e-04 --mean_bias_sd=1.000000e-02 --psi_j_scale=1.000000e-03 --learning_rate=5.000000e-02 --adamax_beta1=9.000000e-01 --adamax_beta2=9.990000e-01 --log_emission_samples_per_round=2000 --log_emission_sampling_rounds=100 --log_emission_sampling_median_rel_error=5.000000e-04 --max_advi_iter_first_epoch=1000 --max_advi_iter_subsequent_epochs=1000 --min_training_epochs=20 --max_training_epochs=100 --initial_temperature=2.000000e+00 --num_thermal_epochs=20 --convergence_snr_averaging_window=5000 --convergence_snr_trigger_threshold=1.000000e-01 --convergence_snr_countdown_window=10 --max_calling_iters=1 --caller_update_convergence_threshold=1.000000e-03 --caller_admixing_rate=7.500000e-01 --disable_caller=false --disable_sampler=false --disable_annealing=false --interval_list=/tmp/root/intervals3258684972117897378.tsv --contig_ploidy_prior_table=/gatk/snail/gcnv/grch38_germline_CN_priors.tsv --output_model_path=/gatk/snail/gcnv_180517/ploidy/hc24_soohee1k_ploidy",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4125#issuecomment-434527279
https://github.com/broadinstitute/gatk/issues/4125#issuecomment-434527279:423,Availability,down,down,423,"> Do I need to run this Python package in the GATK4.0.4.0 Docker? I am getting a similar error with DetermineGermlineContigPloidy while running within the Docker on a Linux Compute Engine VM.; > ; > ```; > ...; > 19:06:35.948 INFO DetermineGermlineContigPloidy - Aggregating read-count file /gatk/snail/gcnv_180517/coverage_1k/A19625.hc.soohee1k.hdf5 (24 / 24); > 19:06:54.675 INFO DetermineGermlineContigPloidy - Shutting down engine; > [May 18, 2018 7:06:54 PM UTC] org.broadinstitute.hellbender.tools.copynumber.DetermineGermlineContigPloidy done. Elapsed time: 1.83 minutes.; > Runtime.totalMemory()=2822242304; > org.broadinstitute.hellbender.utils.python.PythonScriptExecutorException: ; > python exited with 1; > Command Line: python /tmp/root/cohort_determine_ploidy_and_depth.8539868448285133842.py --sample_coverage_metadata=/tmp/root/samples-by-coverage-per-contig3023244219495833390.tsv --output_calls_path=/gatk/snail/gcnv_180517/ploidy/hc24_soohee1k_ploidy-calls --mapping_error_rate=1.000000e-02 --psi_s_scale=1.000000e-04 --mean_bias_sd=1.000000e-02 --psi_j_scale=1.000000e-03 --learning_rate=5.000000e-02 --adamax_beta1=9.000000e-01 --adamax_beta2=9.990000e-01 --log_emission_samples_per_round=2000 --log_emission_sampling_rounds=100 --log_emission_sampling_median_rel_error=5.000000e-04 --max_advi_iter_first_epoch=1000 --max_advi_iter_subsequent_epochs=1000 --min_training_epochs=20 --max_training_epochs=100 --initial_temperature=2.000000e+00 --num_thermal_epochs=20 --convergence_snr_averaging_window=5000 --convergence_snr_trigger_threshold=1.000000e-01 --convergence_snr_countdown_window=10 --max_calling_iters=1 --caller_update_convergence_threshold=1.000000e-03 --caller_admixing_rate=7.500000e-01 --disable_caller=false --disable_sampler=false --disable_annealing=false --interval_list=/tmp/root/intervals3258684972117897378.tsv --contig_ploidy_prior_table=/gatk/snail/gcnv/grch38_germline_CN_priors.tsv --output_model_path=/gatk/snail/gcnv_180517/ploidy/hc24_soohee1k_ploidy",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4125#issuecomment-434527279
https://github.com/broadinstitute/gatk/issues/4125#issuecomment-434527279:2349,Testability,assert,assert,2349,"1000 --max_advi_iter_subsequent_epochs=1000 --min_training_epochs=20 --max_training_epochs=100 --initial_temperature=2.000000e+00 --num_thermal_epochs=20 --convergence_snr_averaging_window=5000 --convergence_snr_trigger_threshold=1.000000e-01 --convergence_snr_countdown_window=10 --max_calling_iters=1 --caller_update_convergence_threshold=1.000000e-03 --caller_admixing_rate=7.500000e-01 --disable_caller=false --disable_sampler=false --disable_annealing=false --interval_list=/tmp/root/intervals3258684972117897378.tsv --contig_ploidy_prior_table=/gatk/snail/gcnv/grch38_germline_CN_priors.tsv --output_model_path=/gatk/snail/gcnv_180517/ploidy/hc24_soohee1k_ploidy-model; > Stdout: ; > Stderr: Traceback (most recent call last):; > File ""/tmp/root/cohort_determine_ploidy_and_depth.8539868448285133842.py"", line 78, in <module>; > args.contig_ploidy_prior_table); > File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/gcnvkernel/io/io_ploidy.py"", line 183, in get_contig_ploidy_prior_map_from_tsv_file; > assert columns[0] == io_consts.ploidy_prior_contig_name_column; > AssertionError; > ; > 	at org.broadinstitute.hellbender.utils.python.PythonExecutorBase.getScriptException(PythonExecutorBase.java:75); > 	at org.broadinstitute.hellbender.utils.runtime.ScriptExecutor.executeCuratedArgs(ScriptExecutor.java:126); > 	at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.executeArgs(PythonScriptExecutor.java:170); > 	at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.executeScript(PythonScriptExecutor.java:151); > 	at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.executeScript(PythonScriptExecutor.java:121); > 	at org.broadinstitute.hellbender.tools.copynumber.DetermineGermlineContigPloidy.executeDeterminePloidyAndDepthPythonScript(DetermineGermlineContigPloidy.java:365); > 	at org.broadinstitute.hellbender.tools.copynumber.DetermineGermlineContigPloidy.doWork(DetermineGermlineContigPloidy.java:263); > 	at org.broadinstitute.hel",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4125#issuecomment-434527279
https://github.com/broadinstitute/gatk/issues/4125#issuecomment-434527279:2415,Testability,Assert,AssertionError,2415,"ning_epochs=100 --initial_temperature=2.000000e+00 --num_thermal_epochs=20 --convergence_snr_averaging_window=5000 --convergence_snr_trigger_threshold=1.000000e-01 --convergence_snr_countdown_window=10 --max_calling_iters=1 --caller_update_convergence_threshold=1.000000e-03 --caller_admixing_rate=7.500000e-01 --disable_caller=false --disable_sampler=false --disable_annealing=false --interval_list=/tmp/root/intervals3258684972117897378.tsv --contig_ploidy_prior_table=/gatk/snail/gcnv/grch38_germline_CN_priors.tsv --output_model_path=/gatk/snail/gcnv_180517/ploidy/hc24_soohee1k_ploidy-model; > Stdout: ; > Stderr: Traceback (most recent call last):; > File ""/tmp/root/cohort_determine_ploidy_and_depth.8539868448285133842.py"", line 78, in <module>; > args.contig_ploidy_prior_table); > File ""/opt/miniconda/envs/gatk/lib/python3.6/site-packages/gcnvkernel/io/io_ploidy.py"", line 183, in get_contig_ploidy_prior_map_from_tsv_file; > assert columns[0] == io_consts.ploidy_prior_contig_name_column; > AssertionError; > ; > 	at org.broadinstitute.hellbender.utils.python.PythonExecutorBase.getScriptException(PythonExecutorBase.java:75); > 	at org.broadinstitute.hellbender.utils.runtime.ScriptExecutor.executeCuratedArgs(ScriptExecutor.java:126); > 	at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.executeArgs(PythonScriptExecutor.java:170); > 	at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.executeScript(PythonScriptExecutor.java:151); > 	at org.broadinstitute.hellbender.utils.python.PythonScriptExecutor.executeScript(PythonScriptExecutor.java:121); > 	at org.broadinstitute.hellbender.tools.copynumber.DetermineGermlineContigPloidy.executeDeterminePloidyAndDepthPythonScript(DetermineGermlineContigPloidy.java:365); > 	at org.broadinstitute.hellbender.tools.copynumber.DetermineGermlineContigPloidy.doWork(DetermineGermlineContigPloidy.java:263); > 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:134); > 	at o",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4125#issuecomment-434527279
https://github.com/broadinstitute/gatk/issues/4127#issuecomment-357037432:18,Deployability,rolling,rolling,18,"As long as we are rolling with a single common environment across all tools, perhaps we could have a documentation annotation for tools that require it?. As I said in #4125, I vote against allowing users to configure their own environment. I really see no benefit to anyone---it's much easier on the users to just use the yml, and it's definitely much easier on us.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4127#issuecomment-357037432
https://github.com/broadinstitute/gatk/issues/4127#issuecomment-357037432:207,Modifiability,config,configure,207,"As long as we are rolling with a single common environment across all tools, perhaps we could have a documentation annotation for tools that require it?. As I said in #4125, I vote against allowing users to configure their own environment. I really see no benefit to anyone---it's much easier on the users to just use the yml, and it's definitely much easier on us.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4127#issuecomment-357037432
https://github.com/broadinstitute/gatk/pull/4128#issuecomment-357045030:42,Deployability,integrat,integration,42,"@davidbenjamin Can you implement a simple integration test for this arg, to ensure it doesn't break again?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4128#issuecomment-357045030
https://github.com/broadinstitute/gatk/pull/4128#issuecomment-357045030:42,Integrability,integrat,integration,42,"@davidbenjamin Can you implement a simple integration test for this arg, to ensure it doesn't break again?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4128#issuecomment-357045030
https://github.com/broadinstitute/gatk/pull/4128#issuecomment-357045030:54,Testability,test,test,54,"@davidbenjamin Can you implement a simple integration test for this arg, to ensure it doesn't break again?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4128#issuecomment-357045030
https://github.com/broadinstitute/gatk/pull/4128#issuecomment-357045030:35,Usability,simpl,simple,35,"@davidbenjamin Can you implement a simple integration test for this arg, to ensure it doesn't break again?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4128#issuecomment-357045030
https://github.com/broadinstitute/gatk/issues/4130#issuecomment-357059677:23,Modifiability,config,configure,23,"One thing to try is to configure cromwell to retain the log directory via a workflow option when we run the tests. Then at the end of the build we can copy them somewhere, either always, or via the travis after_failure entry in the build matrix. Then we'd be able to see exactly what failed in the travis environment.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4130#issuecomment-357059677
https://github.com/broadinstitute/gatk/issues/4130#issuecomment-357059677:56,Testability,log,log,56,"One thing to try is to configure cromwell to retain the log directory via a workflow option when we run the tests. Then at the end of the build we can copy them somewhere, either always, or via the travis after_failure entry in the build matrix. Then we'd be able to see exactly what failed in the travis environment.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4130#issuecomment-357059677
https://github.com/broadinstitute/gatk/issues/4130#issuecomment-357059677:108,Testability,test,tests,108,"One thing to try is to configure cromwell to retain the log directory via a workflow option when we run the tests. Then at the end of the build we can copy them somewhere, either always, or via the travis after_failure entry in the build matrix. Then we'd be able to see exactly what failed in the travis environment.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4130#issuecomment-357059677
https://github.com/broadinstitute/gatk/issues/4130#issuecomment-358056737:22,Testability,log,logs,22,I think uploading the logs to a bucket like we do with the test outputs is a good idea. There's an example of how to do it in the after_script block of the .travis.yml.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4130#issuecomment-358056737
https://github.com/broadinstitute/gatk/issues/4130#issuecomment-358056737:59,Testability,test,test,59,I think uploading the logs to a bucket like we do with the test outputs is a good idea. There's an example of how to do it in the after_script block of the .travis.yml.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4130#issuecomment-358056737
https://github.com/broadinstitute/gatk/issues/4131#issuecomment-357838062:8,Availability,error,errors,8,"Are the errors below part of this, when starting BwaSpark with spark-submit?; I activated ""--disable-sequence-dictionary-validation true"", but that doesn't help. It is very unclear, why a BAM is not recognized as a BAM file. I have tried all kinds of ways to make sure that it is a BAM and not a SAM file.; The documentation for BwaSpark also says ""BAM/SAM/CRAM file containing reads"", so if SAM files are really not possible, that should probably be changed.; ...; Even on verbosity DEBUG, the comments are not at all helpful to get at the problem.; E.g. ""Cannot retrieve file pointers within SAM text files.""; Is that a general statement about SAM files? Or does it only say, that in this specific SAM file (which is actually a BAM file), file pointers cannot be found?; What pointers are meant exactly?; How could this be fixed?. ```; ""SamReaderFactory	Unable to detect file format from input URL or stream, assuming SAM format.""; Which URL?; Which stream?; Why would this happen? What could be the error?; The SAM/BAM distinction seems very unclear. It would be more helpful, if some specific missing aspect (e.g. not queryname sorted) would be clearly declared as the culprit.; ...; 00:29 DEBUG: [kryo] Write: SAMFileHeader{VN=1.5, SO=queryname}; ...; WARNING	2018-01-16 02:11:25	SamReaderFactory	Unable to detect file format from input URL or stream, assuming SAM format.; ...; java.lang.UnsupportedOperationException: Cannot retrieve file pointers within SAM text files.; 	at htsjdk.samtools.SAMTextReader.getFilePointerSpanningReads(SAMTextReader.java:185); ...; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4131#issuecomment-357838062
https://github.com/broadinstitute/gatk/issues/4131#issuecomment-357838062:1002,Availability,error,error,1002,"Are the errors below part of this, when starting BwaSpark with spark-submit?; I activated ""--disable-sequence-dictionary-validation true"", but that doesn't help. It is very unclear, why a BAM is not recognized as a BAM file. I have tried all kinds of ways to make sure that it is a BAM and not a SAM file.; The documentation for BwaSpark also says ""BAM/SAM/CRAM file containing reads"", so if SAM files are really not possible, that should probably be changed.; ...; Even on verbosity DEBUG, the comments are not at all helpful to get at the problem.; E.g. ""Cannot retrieve file pointers within SAM text files.""; Is that a general statement about SAM files? Or does it only say, that in this specific SAM file (which is actually a BAM file), file pointers cannot be found?; What pointers are meant exactly?; How could this be fixed?. ```; ""SamReaderFactory	Unable to detect file format from input URL or stream, assuming SAM format.""; Which URL?; Which stream?; Why would this happen? What could be the error?; The SAM/BAM distinction seems very unclear. It would be more helpful, if some specific missing aspect (e.g. not queryname sorted) would be clearly declared as the culprit.; ...; 00:29 DEBUG: [kryo] Write: SAMFileHeader{VN=1.5, SO=queryname}; ...; WARNING	2018-01-16 02:11:25	SamReaderFactory	Unable to detect file format from input URL or stream, assuming SAM format.; ...; java.lang.UnsupportedOperationException: Cannot retrieve file pointers within SAM text files.; 	at htsjdk.samtools.SAMTextReader.getFilePointerSpanningReads(SAMTextReader.java:185); ...; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4131#issuecomment-357838062
https://github.com/broadinstitute/gatk/issues/4131#issuecomment-357838062:866,Safety,detect,detect,866,"Are the errors below part of this, when starting BwaSpark with spark-submit?; I activated ""--disable-sequence-dictionary-validation true"", but that doesn't help. It is very unclear, why a BAM is not recognized as a BAM file. I have tried all kinds of ways to make sure that it is a BAM and not a SAM file.; The documentation for BwaSpark also says ""BAM/SAM/CRAM file containing reads"", so if SAM files are really not possible, that should probably be changed.; ...; Even on verbosity DEBUG, the comments are not at all helpful to get at the problem.; E.g. ""Cannot retrieve file pointers within SAM text files.""; Is that a general statement about SAM files? Or does it only say, that in this specific SAM file (which is actually a BAM file), file pointers cannot be found?; What pointers are meant exactly?; How could this be fixed?. ```; ""SamReaderFactory	Unable to detect file format from input URL or stream, assuming SAM format.""; Which URL?; Which stream?; Why would this happen? What could be the error?; The SAM/BAM distinction seems very unclear. It would be more helpful, if some specific missing aspect (e.g. not queryname sorted) would be clearly declared as the culprit.; ...; 00:29 DEBUG: [kryo] Write: SAMFileHeader{VN=1.5, SO=queryname}; ...; WARNING	2018-01-16 02:11:25	SamReaderFactory	Unable to detect file format from input URL or stream, assuming SAM format.; ...; java.lang.UnsupportedOperationException: Cannot retrieve file pointers within SAM text files.; 	at htsjdk.samtools.SAMTextReader.getFilePointerSpanningReads(SAMTextReader.java:185); ...; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4131#issuecomment-357838062
https://github.com/broadinstitute/gatk/issues/4131#issuecomment-357838062:1312,Safety,detect,detect,1312,"Are the errors below part of this, when starting BwaSpark with spark-submit?; I activated ""--disable-sequence-dictionary-validation true"", but that doesn't help. It is very unclear, why a BAM is not recognized as a BAM file. I have tried all kinds of ways to make sure that it is a BAM and not a SAM file.; The documentation for BwaSpark also says ""BAM/SAM/CRAM file containing reads"", so if SAM files are really not possible, that should probably be changed.; ...; Even on verbosity DEBUG, the comments are not at all helpful to get at the problem.; E.g. ""Cannot retrieve file pointers within SAM text files.""; Is that a general statement about SAM files? Or does it only say, that in this specific SAM file (which is actually a BAM file), file pointers cannot be found?; What pointers are meant exactly?; How could this be fixed?. ```; ""SamReaderFactory	Unable to detect file format from input URL or stream, assuming SAM format.""; Which URL?; Which stream?; Why would this happen? What could be the error?; The SAM/BAM distinction seems very unclear. It would be more helpful, if some specific missing aspect (e.g. not queryname sorted) would be clearly declared as the culprit.; ...; 00:29 DEBUG: [kryo] Write: SAMFileHeader{VN=1.5, SO=queryname}; ...; WARNING	2018-01-16 02:11:25	SamReaderFactory	Unable to detect file format from input URL or stream, assuming SAM format.; ...; java.lang.UnsupportedOperationException: Cannot retrieve file pointers within SAM text files.; 	at htsjdk.samtools.SAMTextReader.getFilePointerSpanningReads(SAMTextReader.java:185); ...; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4131#issuecomment-357838062
https://github.com/broadinstitute/gatk/issues/4131#issuecomment-357838062:121,Security,validat,validation,121,"Are the errors below part of this, when starting BwaSpark with spark-submit?; I activated ""--disable-sequence-dictionary-validation true"", but that doesn't help. It is very unclear, why a BAM is not recognized as a BAM file. I have tried all kinds of ways to make sure that it is a BAM and not a SAM file.; The documentation for BwaSpark also says ""BAM/SAM/CRAM file containing reads"", so if SAM files are really not possible, that should probably be changed.; ...; Even on verbosity DEBUG, the comments are not at all helpful to get at the problem.; E.g. ""Cannot retrieve file pointers within SAM text files.""; Is that a general statement about SAM files? Or does it only say, that in this specific SAM file (which is actually a BAM file), file pointers cannot be found?; What pointers are meant exactly?; How could this be fixed?. ```; ""SamReaderFactory	Unable to detect file format from input URL or stream, assuming SAM format.""; Which URL?; Which stream?; Why would this happen? What could be the error?; The SAM/BAM distinction seems very unclear. It would be more helpful, if some specific missing aspect (e.g. not queryname sorted) would be clearly declared as the culprit.; ...; 00:29 DEBUG: [kryo] Write: SAMFileHeader{VN=1.5, SO=queryname}; ...; WARNING	2018-01-16 02:11:25	SamReaderFactory	Unable to detect file format from input URL or stream, assuming SAM format.; ...; java.lang.UnsupportedOperationException: Cannot retrieve file pointers within SAM text files.; 	at htsjdk.samtools.SAMTextReader.getFilePointerSpanningReads(SAMTextReader.java:185); ...; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4131#issuecomment-357838062
https://github.com/broadinstitute/gatk/issues/4131#issuecomment-357838062:1149,Usability,clear,clearly,1149,"Are the errors below part of this, when starting BwaSpark with spark-submit?; I activated ""--disable-sequence-dictionary-validation true"", but that doesn't help. It is very unclear, why a BAM is not recognized as a BAM file. I have tried all kinds of ways to make sure that it is a BAM and not a SAM file.; The documentation for BwaSpark also says ""BAM/SAM/CRAM file containing reads"", so if SAM files are really not possible, that should probably be changed.; ...; Even on verbosity DEBUG, the comments are not at all helpful to get at the problem.; E.g. ""Cannot retrieve file pointers within SAM text files.""; Is that a general statement about SAM files? Or does it only say, that in this specific SAM file (which is actually a BAM file), file pointers cannot be found?; What pointers are meant exactly?; How could this be fixed?. ```; ""SamReaderFactory	Unable to detect file format from input URL or stream, assuming SAM format.""; Which URL?; Which stream?; Why would this happen? What could be the error?; The SAM/BAM distinction seems very unclear. It would be more helpful, if some specific missing aspect (e.g. not queryname sorted) would be clearly declared as the culprit.; ...; 00:29 DEBUG: [kryo] Write: SAMFileHeader{VN=1.5, SO=queryname}; ...; WARNING	2018-01-16 02:11:25	SamReaderFactory	Unable to detect file format from input URL or stream, assuming SAM format.; ...; java.lang.UnsupportedOperationException: Cannot retrieve file pointers within SAM text files.; 	at htsjdk.samtools.SAMTextReader.getFilePointerSpanningReads(SAMTextReader.java:185); ...; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4131#issuecomment-357838062
https://github.com/broadinstitute/gatk/issues/4131#issuecomment-358365390:194,Availability,error,error,194,@nyl2002 What's your command line that's hitting problems? Are you trying to run BWA-MEM spark on a SAM file or on a BAM file? . I agree that we should change documentation and produce a better error message if it's failing on SAM files.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4131#issuecomment-358365390
https://github.com/broadinstitute/gatk/issues/4131#issuecomment-358365390:200,Integrability,message,message,200,@nyl2002 What's your command line that's hitting problems? Are you trying to run BWA-MEM spark on a SAM file or on a BAM file? . I agree that we should change documentation and produce a better error message if it's failing on SAM files.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4131#issuecomment-358365390
https://github.com/broadinstitute/gatk/pull/4132#issuecomment-357115303:44,Availability,failure,failures,44,@davidbenjamin Feel free to merge once test failures are resolved.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4132#issuecomment-357115303
https://github.com/broadinstitute/gatk/pull/4132#issuecomment-357115303:39,Testability,test,test,39,@davidbenjamin Feel free to merge once test failures are resolved.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4132#issuecomment-357115303
https://github.com/broadinstitute/gatk/pull/4132#issuecomment-357290124:3723,Usability,Simpl,SimpleInterval,3723,GUvaGVsbGJlbmRlci91dGlscy9oZWxwL0hlbHBDb25zdGFudHMuamF2YQ==) | `3.077% <0%> (-1.09%)` | `2% <0%> (+1%)` | |; | [...ools/spark/pathseq/PSFilterArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/4132/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BTRmlsdGVyQXJndW1lbnRDb2xsZWN0aW9uLmphdmE=) | `85.714% <0%> (-0.952%)` | `6% <0%> (+3%)` | |; | [...er/tools/ConvertHeaderlessHadoopBamShardToBam.java](https://codecov.io/gh/broadinstitute/gatk/pull/4132/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9Db252ZXJ0SGVhZGVybGVzc0hhZG9vcEJhbVNoYXJkVG9CYW0uamF2YQ==) | `76% <0%> (-0.923%)` | `3% <0%> (+1%)` | |; | [...ellbender/tools/spark/pathseq/PathSeqBwaSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4132/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BhdGhTZXFCd2FTcGFyay5qYXZh) | `66.667% <0%> (-0.725%)` | `13% <0%> (+6%)` | |; | [...dinstitute/hellbender/tools/walkers/qc/Pileup.java](https://codecov.io/gh/broadinstitute/gatk/pull/4132/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3FjL1BpbGV1cC5qYXZh) | `97.727% <0%> (-0.455%)` | `24% <0%> (+8%)` | |; | [...bender/tools/spark/pathseq/PathSeqFilterSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4132/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL1BhdGhTZXFGaWx0ZXJTcGFyay5qYXZh) | `82.979% <0%> (-0.355%)` | `8% <0%> (+4%)` | |; | [...roadinstitute/hellbender/utils/SimpleInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/4132/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9TaW1wbGVJbnRlcnZhbC5qYXZh) | `92.857% <0%> (-0.325%)` | `82% <0%> (+34%)` | |; | ... and [66 more](https://codecov.io/gh/broadinstitute/gatk/pull/4132/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4132#issuecomment-357290124
https://github.com/broadinstitute/gatk/issues/4133#issuecomment-357052981:19,Integrability,message,message,19,I commented on the message itself. The problem seems to be that we output some log messages to STDOUT that break piping. Picard puts them on STDERR.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4133#issuecomment-357052981
https://github.com/broadinstitute/gatk/issues/4133#issuecomment-357052981:83,Integrability,message,messages,83,I commented on the message itself. The problem seems to be that we output some log messages to STDOUT that break piping. Picard puts them on STDERR.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4133#issuecomment-357052981
https://github.com/broadinstitute/gatk/issues/4133#issuecomment-357052981:79,Testability,log,log,79,I commented on the message itself. The problem seems to be that we output some log messages to STDOUT that break piping. Picard puts them on STDERR.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4133#issuecomment-357052981
https://github.com/broadinstitute/gatk/issues/4136#issuecomment-358031279:92,Testability,test,test,92,@davidbenjamin Will you have time to do this one? The fix for this arg was merged without a test.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4136#issuecomment-358031279
https://github.com/broadinstitute/gatk/pull/4139#issuecomment-358285781:4681,Deployability,update,update,4681,"titute/gatk/pull/4139/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9NdXRlY3QyRW5naW5lLmphdmE=) | `89.33% <50%> (+1.17%)` | `43 <3> (ø)` | :arrow_down: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/4139/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `71.23% <0%> (-2.74%)` | `11% <0%> (ø)` | |; | [...er/tools/spark/sv/discovery/AlignmentInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/4139/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvQWxpZ25tZW50SW50ZXJ2YWwuamF2YQ==) | `89.27% <0%> (-0.39%)` | `73% <0%> (-1%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4139/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `80% <0%> (+3.22%)` | `39% <0%> (ø)` | :arrow_down: |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/4139/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `90% <0%> (+40%)` | `3% <0%> (+2%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4139?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4139?src=pr&el=footer). Last update [e12034a...af94877](https://codecov.io/gh/broadinstitute/gatk/pull/4139?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4139#issuecomment-358285781
https://github.com/broadinstitute/gatk/pull/4139#issuecomment-358285781:4584,Energy Efficiency,Power,Powered,4584,"titute/gatk/pull/4139/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9NdXRlY3QyRW5naW5lLmphdmE=) | `89.33% <50%> (+1.17%)` | `43 <3> (ø)` | :arrow_down: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/4139/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `71.23% <0%> (-2.74%)` | `11% <0%> (ø)` | |; | [...er/tools/spark/sv/discovery/AlignmentInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/4139/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvQWxpZ25tZW50SW50ZXJ2YWwuamF2YQ==) | `89.27% <0%> (-0.39%)` | `73% <0%> (-1%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4139/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `80% <0%> (+3.22%)` | `39% <0%> (ø)` | :arrow_down: |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/4139/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `90% <0%> (+40%)` | `3% <0%> (+2%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4139?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4139?src=pr&el=footer). Last update [e12034a...af94877](https://codecov.io/gh/broadinstitute/gatk/pull/4139?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4139#issuecomment-358285781
https://github.com/broadinstitute/gatk/pull/4139#issuecomment-358285781:4447,Usability,learn,learn,4447,"titute/gatk/pull/4139/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9NdXRlY3QyRW5naW5lLmphdmE=) | `89.33% <50%> (+1.17%)` | `43 <3> (ø)` | :arrow_down: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/4139/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `71.23% <0%> (-2.74%)` | `11% <0%> (ø)` | |; | [...er/tools/spark/sv/discovery/AlignmentInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/4139/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvQWxpZ25tZW50SW50ZXJ2YWwuamF2YQ==) | `89.27% <0%> (-0.39%)` | `73% <0%> (-1%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4139/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `80% <0%> (+3.22%)` | `39% <0%> (ø)` | :arrow_down: |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/4139/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `90% <0%> (+40%)` | `3% <0%> (+2%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4139?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4139?src=pr&el=footer). Last update [e12034a...af94877](https://codecov.io/gh/broadinstitute/gatk/pull/4139?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4139#issuecomment-358285781
https://github.com/broadinstitute/gatk/issues/4140#issuecomment-357313468:139,Deployability,Pipeline,Pipelines,139,You would not have access to docker container options when using the Google backend because the running of your image is all controlled by Pipelines API. You would be able to set that value when running on a local backend but thats probably not portable enough for your workflow.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4140#issuecomment-357313468
https://github.com/broadinstitute/gatk/issues/4140#issuecomment-357313468:245,Modifiability,portab,portable,245,You would not have access to docker container options when using the Google backend because the running of your image is all controlled by Pipelines API. You would be able to set that value when running on a local backend but thats probably not portable enough for your workflow.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4140#issuecomment-357313468
https://github.com/broadinstitute/gatk/issues/4140#issuecomment-357313468:19,Security,access,access,19,You would not have access to docker container options when using the Google backend because the running of your image is all controlled by Pipelines API. You would be able to set that value when running on a local backend but thats probably not portable enough for your workflow.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4140#issuecomment-357313468
https://github.com/broadinstitute/gatk/issues/4140#issuecomment-357324264:270,Availability,error,error,270,"OK. @LeeTL1220 How do you want to handle this? I'd strongly prefer to stick with data.table despite the GitHub issue above, since it's much faster than the usual read.table (e.g., 4 seconds vs. 45 seconds for your ~9.7M row WGS copy-ratio TSV that originally caused the error). Is there any other way we can increase /dev/shm size? @droazen @jamesemery @lbergelson Any thoughts?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4140#issuecomment-357324264
https://github.com/broadinstitute/gatk/issues/4140#issuecomment-357332912:533,Availability,error,error,533,"I hate to say it: ""45 seconds but works with WGS"" is better than ""4; seconds but doesn't work with WGS"". I'm open to suggestions, though. On Fri, Jan 12, 2018 at 2:29 PM, samuelklee <notifications@github.com>; wrote:. > OK. @LeeTL1220 <https://github.com/leetl1220> How do you want to handle; > this? I'd strongly prefer to stick with data.table despite the GitHub issue; > above, since it's much faster than the usual read.table (e.g., 4 seconds; > vs. 45 seconds for your ~9.7M row WGS copy-ratio TSV that originally caused; > the error).; >; > Is there any other way we can increase /dev/shm size? @droazen; > <https://github.com/droazen> @jamesemery <https://github.com/jamesemery>; > @lbergelson <https://github.com/lbergelson> Any thoughts?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/4140#issuecomment-357324264>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACDXkyJk2I2yxJOL7pV1UMN7egBCW7blks5tJ7GLgaJpZM4RclpR>; > .; >. -- ; Lee Lichtenstein; Broad Institute; 75 Ames Street, Room 8011A; Cambridge, MA 02142; 617 714 8632",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4140#issuecomment-357332912
https://github.com/broadinstitute/gatk/issues/4140#issuecomment-357337827:568,Security,expose,exposed,568,"To be clear, this will work perfectly fine as long as you have enough space in /dev/shm---which is typically true everywhere outside of our default Docker container. I'm loath to cripple a tool just because of limitations that are fundamentally elsewhere...let's just address those in the appropriate places. (Furthermore, I'm especially loath to write a plotting tool that takes ~5 minutes to generate a plot!) And yes, while it is not great that data.table forces us to use /dev/shm, I think `fread(""grep ..."")` is relatively standard. If `--shm-size` is indeed not exposed, why doesn't the Google backend scale /dev/shm or other tmpfs space with requested machine memory?. If there really is no other way around it, then all we're doing is filtering out the lines beginning with `@`. We could do this first by calling system commands within R to write to a temporary file, and then reading that back in with fread. This seems hacky to me, but I've confirmed that it works within the Docker. This will solve our immediate problem, but I still think it's worth taking a look at those other limitations elsewhere now as well.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4140#issuecomment-357337827
https://github.com/broadinstitute/gatk/issues/4140#issuecomment-357337827:6,Usability,clear,clear,6,"To be clear, this will work perfectly fine as long as you have enough space in /dev/shm---which is typically true everywhere outside of our default Docker container. I'm loath to cripple a tool just because of limitations that are fundamentally elsewhere...let's just address those in the appropriate places. (Furthermore, I'm especially loath to write a plotting tool that takes ~5 minutes to generate a plot!) And yes, while it is not great that data.table forces us to use /dev/shm, I think `fread(""grep ..."")` is relatively standard. If `--shm-size` is indeed not exposed, why doesn't the Google backend scale /dev/shm or other tmpfs space with requested machine memory?. If there really is no other way around it, then all we're doing is filtering out the lines beginning with `@`. We could do this first by calling system commands within R to write to a temporary file, and then reading that back in with fread. This seems hacky to me, but I've confirmed that it works within the Docker. This will solve our immediate problem, but I still think it's worth taking a look at those other limitations elsewhere now as well.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4140#issuecomment-357337827
https://github.com/broadinstitute/gatk/issues/4140#issuecomment-357349198:719,Security,expose,exposed,719,"We've had to do that in other places... On Fri, Jan 12, 2018 at 3:20 PM, samuelklee <notifications@github.com>; wrote:. > To be clear, this will work perfectly fine as long as you have enough; > space in /dev/shm---which is typically true everywhere outside of our; > default Docker container.; >; > I'm loath to cripple a tool just because of limitations that are; > fundamentally elsewhere...let's just address those in the appropriate; > places. (Furthermore, I'm especially loath to write a plotting tool that; > takes ~5 minutes to generate a plot!) And yes, while it is not great that; > data.table forces us to use /dev/shm, I think fread(""grep ..."") is; > relatively standard.; >; > If --shm-size is indeed not exposed, why doesn't the Google backend scale; > /dev/shm or other tmpfs space with requested machine memory?; >; > If there really is no other way around it, then all we're doing is; > filtering out the lines beginning with @. We could do this first by; > calling system commands within R to write to a temporary file, and then; > reading that back in with fread. This seems hacky to me, but I've confirmed; > that it works within the Docker. This will solve our immediate problem, but; > I still think it's worth taking a look at those other limitations elsewhere; > now as well.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/4140#issuecomment-357337827>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACDXkxNvcMcJfIhdlPhdU3vLHTiAVPPSks5tJ76mgaJpZM4RclpR>; > .; >. -- ; Lee Lichtenstein; Broad Institute; 75 Ames Street, Room 8011A; Cambridge, MA 02142; 617 714 8632",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4140#issuecomment-357349198
https://github.com/broadinstitute/gatk/issues/4140#issuecomment-357349198:128,Usability,clear,clear,128,"We've had to do that in other places... On Fri, Jan 12, 2018 at 3:20 PM, samuelklee <notifications@github.com>; wrote:. > To be clear, this will work perfectly fine as long as you have enough; > space in /dev/shm---which is typically true everywhere outside of our; > default Docker container.; >; > I'm loath to cripple a tool just because of limitations that are; > fundamentally elsewhere...let's just address those in the appropriate; > places. (Furthermore, I'm especially loath to write a plotting tool that; > takes ~5 minutes to generate a plot!) And yes, while it is not great that; > data.table forces us to use /dev/shm, I think fread(""grep ..."") is; > relatively standard.; >; > If --shm-size is indeed not exposed, why doesn't the Google backend scale; > /dev/shm or other tmpfs space with requested machine memory?; >; > If there really is no other way around it, then all we're doing is; > filtering out the lines beginning with @. We could do this first by; > calling system commands within R to write to a temporary file, and then; > reading that back in with fread. This seems hacky to me, but I've confirmed; > that it works within the Docker. This will solve our immediate problem, but; > I still think it's worth taking a look at those other limitations elsewhere; > now as well.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/4140#issuecomment-357337827>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACDXkxNvcMcJfIhdlPhdU3vLHTiAVPPSks5tJ76mgaJpZM4RclpR>; > .; >. -- ; Lee Lichtenstein; Broad Institute; 75 Ames Street, Room 8011A; Cambridge, MA 02142; 617 714 8632",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4140#issuecomment-357349198
https://github.com/broadinstitute/gatk/issues/4140#issuecomment-357375691:557,Deployability,Pipeline,Pipelines,557,"@lbergelson Sorry to be unclear---this isn't a GATK issue. For Cromwell, you can configure various options for each backend. For example, if you are running on a local backend with Docker, you can set a `submit-docker` attribute to specify the string that runs the Docker container; so to solve the above problem, you'd set this to include `--shm-size` and set it accordingly. However, according to @jsotobroad, you're not allowed such an attribute when submitting to Google cloud. If that's the case, then this is more of an issue with the Cromwell/Google Pipelines interface than the data.table package (although, as the discussion in the GitHub issue above shows, it'd be a simple fix on the data.table end, so I'm not sure why it's not addressed yet...) Changing the R script to get around the issue in this particular case is not unacceptably ugly, but you could imagine we might run into a similar problem in the future if anything else exceeds the 64MB /dev/shm limit and also cannot specify tmpfs. So perhaps we should take a look at the underlying issue.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4140#issuecomment-357375691
https://github.com/broadinstitute/gatk/issues/4140#issuecomment-357375691:567,Integrability,interface,interface,567,"@lbergelson Sorry to be unclear---this isn't a GATK issue. For Cromwell, you can configure various options for each backend. For example, if you are running on a local backend with Docker, you can set a `submit-docker` attribute to specify the string that runs the Docker container; so to solve the above problem, you'd set this to include `--shm-size` and set it accordingly. However, according to @jsotobroad, you're not allowed such an attribute when submitting to Google cloud. If that's the case, then this is more of an issue with the Cromwell/Google Pipelines interface than the data.table package (although, as the discussion in the GitHub issue above shows, it'd be a simple fix on the data.table end, so I'm not sure why it's not addressed yet...) Changing the R script to get around the issue in this particular case is not unacceptably ugly, but you could imagine we might run into a similar problem in the future if anything else exceeds the 64MB /dev/shm limit and also cannot specify tmpfs. So perhaps we should take a look at the underlying issue.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4140#issuecomment-357375691
https://github.com/broadinstitute/gatk/issues/4140#issuecomment-357375691:81,Modifiability,config,configure,81,"@lbergelson Sorry to be unclear---this isn't a GATK issue. For Cromwell, you can configure various options for each backend. For example, if you are running on a local backend with Docker, you can set a `submit-docker` attribute to specify the string that runs the Docker container; so to solve the above problem, you'd set this to include `--shm-size` and set it accordingly. However, according to @jsotobroad, you're not allowed such an attribute when submitting to Google cloud. If that's the case, then this is more of an issue with the Cromwell/Google Pipelines interface than the data.table package (although, as the discussion in the GitHub issue above shows, it'd be a simple fix on the data.table end, so I'm not sure why it's not addressed yet...) Changing the R script to get around the issue in this particular case is not unacceptably ugly, but you could imagine we might run into a similar problem in the future if anything else exceeds the 64MB /dev/shm limit and also cannot specify tmpfs. So perhaps we should take a look at the underlying issue.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4140#issuecomment-357375691
https://github.com/broadinstitute/gatk/issues/4140#issuecomment-357375691:677,Usability,simpl,simple,677,"@lbergelson Sorry to be unclear---this isn't a GATK issue. For Cromwell, you can configure various options for each backend. For example, if you are running on a local backend with Docker, you can set a `submit-docker` attribute to specify the string that runs the Docker container; so to solve the above problem, you'd set this to include `--shm-size` and set it accordingly. However, according to @jsotobroad, you're not allowed such an attribute when submitting to Google cloud. If that's the case, then this is more of an issue with the Cromwell/Google Pipelines interface than the data.table package (although, as the discussion in the GitHub issue above shows, it'd be a simple fix on the data.table end, so I'm not sure why it's not addressed yet...) Changing the R script to get around the issue in this particular case is not unacceptably ugly, but you could imagine we might run into a similar problem in the future if anything else exceeds the 64MB /dev/shm limit and also cannot specify tmpfs. So perhaps we should take a look at the underlying issue.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4140#issuecomment-357375691
https://github.com/broadinstitute/gatk/issues/4141#issuecomment-357353980:131,Availability,avail,available,131,"Yes, I saw that too and have a fix planned. Result:; The ""ins_del_inv.vcf"" is still produced but the experimental features are not available due to the exception. Cause:; gapped-alignment is split and after the split one of the child alignment is contained by another gap-free alignment in their read span.; The particular contig's alignment ([ribbon](http://genomeribbon.com/?perma=dUYn5Xecbc)). ```; asm024831:tig00025	16	chr17	26962248	60	121M1D142M1I165M62I130M482S	*	0	0	CAAATGTGAACATACAAAAAACAAATCAGAATGTGCCATTCTGATTTAAACTGCTTATTAGTTAATACCCTCAAGATAACATCTGGGTTCTTAGCTGCACTGAGTTAAGCCTACTTACATCTTTTTTGTCTTCCACTGCACTTTTCCTATCACATTACACTCCAGCAATACCAAGCTGTGCCGCCTTCTACCCCATTTCCACTATTTTGCCCCCGCCGCCGAGGCTTTTTGCCCCCGCTGCCGCGGCTTTCTCCCACAGCGGCTTTTTGCCCCCGCAGATGCAGCTTTCTCCTACCTCGCCTTTTTGCCCCCGCCGCCGCGGCTTTCTGCCGCCGCGGCTTTTTCCCCCACCGCCGTGGCTATTTACGGCTTTTTTCCCCCTGCTGCCGCGGCTTTTTGCCCCCTGCCGCCGCGACCTTTTGCCCCCGCCACCGCAGCTTTTTGCCCGCGCCTCCACGGCTTTTTGTCCCCGCCGCCACGGCTTTCGCCGACGCGGCTTTTTACCCCCGCCGCCACGGGTTTTGGCCGCCGCGGCTTTTTGCCCCCTCCCCCACGGCTTTTGCCTATGCGGCTTCTTGCCCCCGCCGCCGCGGGCTTTTTCCCCCGGCCGCGGCTTTTTGCTGCCGCTGCCGTGGTTTTTTGTCCCCGCTGCCGAAGCTTTTTGCCACCGCCGCCACTGCTTTTTGCGACTTTTTGCTCCCCCCACCGGGGCTTTTTACCTCCGTCGCCGCGGCTTTTTCCCCCACCACCGCGGCTTTTTGCCCCCGCCGCCGCTGCTTTTTGCAGCTTTTTGCCCCTGCCACCGCGGCTTTATGTGGTTTTTTGCCCGCGCCGCCGCGGCTTTTTGCCCACGCCGCCGCGGCTTTTAGCGGCTTTTTGCTCCTGCCGCCGCGGCTTTTTGCTCCTGCCGCCGCGGCTTTTTGCCCCCCGCCTCAGCGGCTTTCGGCCACCGCGTCTTTTTGCCCCCGCGGCCGCGGCTTTCTCCCACCGCGGCTTTTTGCCCTCGCCGCCGCAACTTTTTGCCTCCGCCGCCGAGTCTTTTTGCCCCCGCCACCATGGCTTTTTGCCCTCGCCGCTGCGCCTTTTTCCCTCCACGGCTTTTT	*	SA:Z:chr17,26962689,-,503S109M44I92M22D110M10I44M12D120M71S,60,123;chrUn_JTFH01000492v1_decoy,501,+,1097M6S,60,1;	MD:Z:101A11T7^T12G21C13G68C5A12C1T15C2C15T0G10T3T2T11T29C4T4T6C7C0A1C24T4G18A1C4G13A1A47C27T26	RG:Z:GATKSVContigAlignments	NM:i:97	AS:i:281	XS:i:182; asm024831:tig00025	2064	chr17	26962689	60	503H109M44I92M22D110M10I44M12D120M71H	*	0	0	CCCCCGCCGCCACGGGTTTTGGCCGCCGCGGCTTTTTGCCCCCTCCCCCACGGCTTTTGCCTATGCGGC",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4141#issuecomment-357353980
https://github.com/broadinstitute/gatk/issues/4141#issuecomment-357353980:4197,Deployability,pipeline,pipeline,4197,"CTCCTGCCGCCGCGGCTTTTTGCCCCCCGCCTCAGCGGCTTTCGGCCACCGCGTCTTTTTGCCCCCGCGGCCGCGGCTTTCTCCCACCGCGGCTTTTTGCCCTCGCCGCCGCAACTTTTTGCCTCCGCCGC	*	SA:Z:chr17,26962248,-,121M1D142M1I165M62I130M482S,60,97;chrUn_JTFH01000492v1_decoy,501,+,1097M6S,60,1;	MD:Z:13A1A47C27T27C8G0A0G12C43A4A8^CCGCGGCTTTCTGCTCCCGCCG26A26G2T7T9C3G0T22C2T16C0G0G0C18C6A2^GCCGCGGCTTTT5C26T24C0A17T4T9C9G0T17	RG:Z:GATKSVContigAlignments	NM:i:123	AS:i:148	XS:i:71; asm024831:tig00025	2048	chrUn_JTFH01000492v1_decoy	501	60	1097M6H	*	0	0	AAAAAGCCGTGGAGGGAAAAAGGCGCAGCGGCGAGGGCAAAAAGCCATGGTGGCGGGGGCAAAAAGACTCGGCGGCGGAGGCAAAAAGTTGCGGCGGCGAGGGCAAAAAGCCGCGGTGGGAGAAAGCCGCGGCCGCGGGGGCAAAAAGACGCGGTGGCCGAAAGCCGCTGAGGCGGGGGGCAAAAAGCCGCGGCGGCAGGAGCAAAAAGCCGCGGCGGCAGGAGCAAAAAGCCGCTAAAAGCCGCGGCGGCGTGGGCAAAAAGCCGCGGCGGCGCGGGCAAAAAACCACATAAAGCCGCGGTGGCAGGGGCAAAAAGCTGCAAAAAGCAGCGGCGGCGGGGGCAAAAAGCCGCGGTGGTGGGGGAAAAAGCCGCGGCGACGGAGGTAAAAAGCCCCGGTGGGGGGAGCAAAAAGTCGCAAAAAGCAGTGGCGGCGGTGGCAAAAAGCTTCGGCAGCGGGGACAAAAAACCACGGCAGCGGCAGCAAAAAGCCGCGGCCGGGGGAAAAAGCCCGCGGCGGCGGGGGCAAGAAGCCGCATAGGCAAAAGCCGTGGGGGAGGGGGCAAAAAGCCGCGGCGGCCAAAACCCGTGGCGGCGGGGGTAAAAAGCCGCGTCGGCGAAAGCCGTGGCGGCGGGGACAAAAAGCCGTGGAGGCGCGGGCAAAAAGCTGCGGTGGCGGGGGCAAAAGGTCGCGGCGGCAGGGGGCAAAAAGCCGCGGCAGCAGGGGGAAAAAAGCCGTAAATAGCCACGGCGGTGGGGGAAAAAGCCGCGGCGGCAGAAAGCCGCGGCGGCGGGGGCAAAAAGGCGAGGTAGGAGAAAGCTGCATCTGCGGGGGCAAAAAGCCGCTGTGGGAGAAAGCCGCGGCAGCGGGGGCAAAAAGCCTCGGCGGCGGGGGCAAAATAGTGGAAATGGGGTAGAAGGCGGCACAGCTTGGTATTGCTGGAGTGTAATGTGATAGGAAAAGTGCAGTGGAAGACAAAAAAGATGTAAGTAGGCTTAACTCAGTGCAGCTAAGAACCCAGATGTTATCTTGAGGGTATTAACTAATAAGCAGTTTAAATCAGAATGGCACATTCTGATTTGTTTTTTGTATGTTCA	*	SA:Z:chr17,26962248,-,121M1D142M1I165M62I130M482S,60,97;chr17,26962689,-,503S109M44I92M22D110M10I44M12D120M71S,60,123;	MD:Z:374A722	RG:Z:GATKSVContigAlignments	NM:i:1	AS:i:1092	XS:i:281; ```. Planned fix:; push the gap-split to an ever later stage. Temporary fix:; Run the pipeline with the line `--exp-variants-out-dir` in ""scripts/sv/runWholePipeline.sh"" deleted, this turns off the experimental feature.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4141#issuecomment-357353980
https://github.com/broadinstitute/gatk/issues/4141#issuecomment-357355467:65,Availability,failure,failure,65,"Let's remove the option from the script, then, if it's causing a failure on our primary benchmarking sample.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4141#issuecomment-357355467
https://github.com/broadinstitute/gatk/issues/4141#issuecomment-357355467:88,Testability,benchmark,benchmarking,88,"Let's remove the option from the script, then, if it's causing a failure on our primary benchmarking sample.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4141#issuecomment-357355467
https://github.com/broadinstitute/gatk/pull/4143#issuecomment-357364227:2185,Usability,Simpl,SimpleSVType,2185,50cy5qYXZh) | `94.737% <0%> (-5.263%)` | `4% <0%> (+2%)` | |; | [...tools/walkers/mutect/SomaticLikelihoodsEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/4143/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9Tb21hdGljTGlrZWxpaG9vZHNFbmdpbmUuamF2YQ==) | `83.871% <0%> (-2.971%)` | `25% <0%> (+11%)` | |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/4143/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `71.233% <0%> (-2.74%)` | `11% <0%> (ø)` | |; | [.../hellbender/utils/python/PythonScriptExecutor.java](https://codecov.io/gh/broadinstitute/gatk/pull/4143/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9weXRob24vUHl0aG9uU2NyaXB0RXhlY3V0b3IuamF2YQ==) | `63.636% <0%> (-1.07%)` | `10% <0%> (+1%)` | |; | [...lbender/tools/spark/sv/discovery/SimpleSVType.java](https://codecov.io/gh/broadinstitute/gatk/pull/4143/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvU2ltcGxlU1ZUeXBlLmphdmE=) | `86.275% <0%> (-0.293%)` | `4% <0%> (+2%)` | |; | [...otator/dataSources/gencode/GencodeFuncotation.java](https://codecov.io/gh/broadinstitute/gatk/pull/4143/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL2dlbmNvZGUvR2VuY29kZUZ1bmNvdGF0aW9uLmphdmE=) | `57.505% <0%> (-0.176%)` | `185% <0%> (+66%)` | |; | [...ls/walkers/mutect/M2FiltersArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/4143/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9NMkZpbHRlcnNBcmd1bWVudENvbGxlY3Rpb24uamF2YQ==) | `100% <0%> (ø)` | `1% <0%> (ø)` | :arrow_down: |; | [...llbender/tools/copynumber/PreprocessIntervals.java](https://codecov.i,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4143#issuecomment-357364227
https://github.com/broadinstitute/gatk/pull/4145#issuecomment-357386346:38,Testability,test,tests,38,@samuelklee looks good to me assuming tests pass. Feel free to merge.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4145#issuecomment-357386346
https://github.com/broadinstitute/gatk/pull/4147#issuecomment-357371881:90,Deployability,configurat,configuration,90,@cmnbroad I moved this message so it runs during the actual task execution rather than at configuration time.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4147#issuecomment-357371881
https://github.com/broadinstitute/gatk/pull/4147#issuecomment-357371881:23,Integrability,message,message,23,@cmnbroad I moved this message so it runs during the actual task execution rather than at configuration time.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4147#issuecomment-357371881
https://github.com/broadinstitute/gatk/pull/4147#issuecomment-357371881:90,Modifiability,config,configuration,90,@cmnbroad I moved this message so it runs during the actual task execution rather than at configuration time.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4147#issuecomment-357371881
https://github.com/broadinstitute/gatk/pull/4149#issuecomment-358059202:73,Testability,test,tests,73,@davidbenjamin An easy one for you. I think you can ignore failing cloud tests for the moment.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4149#issuecomment-358059202
https://github.com/broadinstitute/gatk/pull/4152#issuecomment-357485658:1571,Deployability,Integrat,IntegrationUtils,1571,====================; Files 1058 1057 -1 ; Lines 59682 59712 +30 ; Branches 9712 9723 +11 ; ===============================================; + Hits 46584 46879 +295 ; + Misses 9349 9078 -271 ; - Partials 3749 3755 +6; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4152?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...hellbender/utils/linalg/FourierLinearOperator.java](https://codecov.io/gh/broadinstitute/gatk/pull/4152/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9saW5hbGcvRm91cmllckxpbmVhck9wZXJhdG9yLmphdmE=) | `78.378% <ø> (ø)` | `12 <0> (ø)` | :arrow_down: |; | [...bender/utils/GATKProtectedVariantContextUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4152/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9HQVRLUHJvdGVjdGVkVmFyaWFudENvbnRleHRVdGlscy5qYXZh) | `65.746% <0%> (ø)` | `61 <0> (ø)` | :arrow_down: |; | [...adinstitute/hellbender/utils/IntegrationUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4152/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9JbnRlZ3JhdGlvblV0aWxzLmphdmE=) | `95.238% <100%> (ø)` | `5 <0> (ø)` | :arrow_down: |; | [...bender/tools/walkers/annotator/StrandArtifact.java](https://codecov.io/gh/broadinstitute/gatk/pull/4152/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9TdHJhbmRBcnRpZmFjdC5qYXZh) | `100% <100%> (ø)` | `29 <0> (ø)` | :arrow_down: |; | [...llbender/tools/walkers/annotator/ReadPosition.java](https://codecov.io/gh/broadinstitute/gatk/pull/4152/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9SZWFkUG9zaXRpb24uamF2YQ==) | `100% <100%> (ø)` | `8 <2> (ø)` | :arrow_down: |; | [...s/copynumber/models/AlleleFractionLikelihoods.java](https://codecov.io/gh/broadinstitute/gatk/pull/4152/diff?src=pr&el=tree#,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4152#issuecomment-357485658
https://github.com/broadinstitute/gatk/pull/4152#issuecomment-357485658:1571,Integrability,Integrat,IntegrationUtils,1571,====================; Files 1058 1057 -1 ; Lines 59682 59712 +30 ; Branches 9712 9723 +11 ; ===============================================; + Hits 46584 46879 +295 ; + Misses 9349 9078 -271 ; - Partials 3749 3755 +6; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4152?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...hellbender/utils/linalg/FourierLinearOperator.java](https://codecov.io/gh/broadinstitute/gatk/pull/4152/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9saW5hbGcvRm91cmllckxpbmVhck9wZXJhdG9yLmphdmE=) | `78.378% <ø> (ø)` | `12 <0> (ø)` | :arrow_down: |; | [...bender/utils/GATKProtectedVariantContextUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4152/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9HQVRLUHJvdGVjdGVkVmFyaWFudENvbnRleHRVdGlscy5qYXZh) | `65.746% <0%> (ø)` | `61 <0> (ø)` | :arrow_down: |; | [...adinstitute/hellbender/utils/IntegrationUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4152/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9JbnRlZ3JhdGlvblV0aWxzLmphdmE=) | `95.238% <100%> (ø)` | `5 <0> (ø)` | :arrow_down: |; | [...bender/tools/walkers/annotator/StrandArtifact.java](https://codecov.io/gh/broadinstitute/gatk/pull/4152/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9TdHJhbmRBcnRpZmFjdC5qYXZh) | `100% <100%> (ø)` | `29 <0> (ø)` | :arrow_down: |; | [...llbender/tools/walkers/annotator/ReadPosition.java](https://codecov.io/gh/broadinstitute/gatk/pull/4152/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9SZWFkUG9zaXRpb24uamF2YQ==) | `100% <100%> (ø)` | `8 <2> (ø)` | :arrow_down: |; | [...s/copynumber/models/AlleleFractionLikelihoods.java](https://codecov.io/gh/broadinstitute/gatk/pull/4152/diff?src=pr&el=tree#,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4152#issuecomment-357485658
https://github.com/broadinstitute/gatk/issues/4153#issuecomment-358057205:38,Testability,log,logic,38,"BTW, this is low-priority because the logic is only invoked for *SAM* files, not *BAM*s.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4153#issuecomment-358057205
https://github.com/broadinstitute/gatk/issues/4153#issuecomment-358089808:84,Usability,Simpl,SimpleInterval,84,"@tomwhite I'm confused by the following code in `samRecordOverlaps`:. ```java; for (SimpleInterval interval : intervals) {; if (record.getReadUnmappedFlag() && record.getAlignmentStart() != SAMRecord.NO_ALIGNMENT_START) {; int start = record.getAlignmentStart();; return interval.getStart() <= start && interval.getEnd() >= start;; } else if (interval.overlaps(record)) {; return true;; }; }; ```; If a record is unmapped (which necessarily implies that `getContig()` returns `null`), it checks whether its assigned start lies between the start and end of any interval in `traversalParameters` *regardless of that interval's contig*.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4153#issuecomment-358089808
https://github.com/broadinstitute/gatk/pull/4154#issuecomment-358031235:54,Safety,detect,detector,54,@droazen Adam did profiling that showed that overlaps detector was strictly better. We also had some suspicion that there was some bug lurking in the skip list implementation because of weird non-deterministic results of something that relied on it.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4154#issuecomment-358031235
https://github.com/broadinstitute/gatk/pull/4154#issuecomment-393933239:264,Testability,test,test,264,"@droazen When we left off you showed me how to use JProfiler (which I now use regularly) and had pointed me to instructions for running GATK on a Spark cluster. I realize I'm going to need another round of hand-holding, because I'm not sure which Spark cluster to test on, and I'm not sure which command to test. And beyond measuring total runtime and looking for any new hotspots in JProfiler I don't know what else to measure. Could I get some more help from someone on the engine team?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4154#issuecomment-393933239
https://github.com/broadinstitute/gatk/pull/4154#issuecomment-393933239:307,Testability,test,test,307,"@droazen When we left off you showed me how to use JProfiler (which I now use regularly) and had pointed me to instructions for running GATK on a Spark cluster. I realize I'm going to need another round of hand-holding, because I'm not sure which Spark cluster to test on, and I'm not sure which command to test. And beyond measuring total runtime and looking for any new hotspots in JProfiler I don't know what else to measure. Could I get some more help from someone on the engine team?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4154#issuecomment-393933239
https://github.com/broadinstitute/gatk/pull/4154#issuecomment-461935085:34,Performance,perform,performance,34,This is easily resolvable without performance profiling since the only remaining use of the `IntervalSkipList` was in `ContextShard` which is now also unused / untested. Removing context shard and rebasing.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4154#issuecomment-461935085
https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566789383:56,Deployability,install,install,56,I'm encountering the same bug. Linux OS. Brand new GATK install from github (17 Dec 2019).; Did you manage to figure anything out?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566789383
https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566793345:68,Availability,down,down,68,@jberghout If you post your actual output we might be able to track down your variant of the problem (the error message in the original post looks to me somewhat like a corrupt gradle cache: error reading /vsc-hard-mounts/leuven-user/304/vsc30484/.gradle/caches/modules-2/files-2.1/org.spire-math/spire_2.11/0.11.0/998b1c1d841baf4fc5d1b119ea55f165f6684ef5/spire_2.11-0.11.0.jar; error in opening zip file). Is it the `gatkTabComplete` task that is failing for you as well ?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566793345
https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566793345:106,Availability,error,error,106,@jberghout If you post your actual output we might be able to track down your variant of the problem (the error message in the original post looks to me somewhat like a corrupt gradle cache: error reading /vsc-hard-mounts/leuven-user/304/vsc30484/.gradle/caches/modules-2/files-2.1/org.spire-math/spire_2.11/0.11.0/998b1c1d841baf4fc5d1b119ea55f165f6684ef5/spire_2.11-0.11.0.jar; error in opening zip file). Is it the `gatkTabComplete` task that is failing for you as well ?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566793345
https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566793345:191,Availability,error,error,191,@jberghout If you post your actual output we might be able to track down your variant of the problem (the error message in the original post looks to me somewhat like a corrupt gradle cache: error reading /vsc-hard-mounts/leuven-user/304/vsc30484/.gradle/caches/modules-2/files-2.1/org.spire-math/spire_2.11/0.11.0/998b1c1d841baf4fc5d1b119ea55f165f6684ef5/spire_2.11-0.11.0.jar; error in opening zip file). Is it the `gatkTabComplete` task that is failing for you as well ?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566793345
https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566793345:379,Availability,error,error,379,@jberghout If you post your actual output we might be able to track down your variant of the problem (the error message in the original post looks to me somewhat like a corrupt gradle cache: error reading /vsc-hard-mounts/leuven-user/304/vsc30484/.gradle/caches/modules-2/files-2.1/org.spire-math/spire_2.11/0.11.0/998b1c1d841baf4fc5d1b119ea55f165f6684ef5/spire_2.11-0.11.0.jar; error in opening zip file). Is it the `gatkTabComplete` task that is failing for you as well ?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566793345
https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566793345:112,Integrability,message,message,112,@jberghout If you post your actual output we might be able to track down your variant of the problem (the error message in the original post looks to me somewhat like a corrupt gradle cache: error reading /vsc-hard-mounts/leuven-user/304/vsc30484/.gradle/caches/modules-2/files-2.1/org.spire-math/spire_2.11/0.11.0/998b1c1d841baf4fc5d1b119ea55f165f6684ef5/spire_2.11-0.11.0.jar; error in opening zip file). Is it the `gatkTabComplete` task that is failing for you as well ?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566793345
https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566793345:184,Performance,cache,cache,184,@jberghout If you post your actual output we might be able to track down your variant of the problem (the error message in the original post looks to me somewhat like a corrupt gradle cache: error reading /vsc-hard-mounts/leuven-user/304/vsc30484/.gradle/caches/modules-2/files-2.1/org.spire-math/spire_2.11/0.11.0/998b1c1d841baf4fc5d1b119ea55f165f6684ef5/spire_2.11-0.11.0.jar; error in opening zip file). Is it the `gatkTabComplete` task that is failing for you as well ?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566793345
https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566793345:255,Performance,cache,caches,255,@jberghout If you post your actual output we might be able to track down your variant of the problem (the error message in the original post looks to me somewhat like a corrupt gradle cache: error reading /vsc-hard-mounts/leuven-user/304/vsc30484/.gradle/caches/modules-2/files-2.1/org.spire-math/spire_2.11/0.11.0/998b1c1d841baf4fc5d1b119ea55f165f6684ef5/spire_2.11-0.11.0.jar; error in opening zip file). Is it the `gatkTabComplete` task that is failing for you as well ?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566793345
https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716:592,Availability,FAILURE,FAILURE,592,The concise message is:. ```; cb2@cb2-VirtualBox:~/gatk$ ./gradlew bundle; > Configure project :; Executing: git lfs pull --include src/main/resources/large. > Task :condaStandardEnvironmentDefinition; Created standard Conda environment yml file: gatkcondaenv.yml. > Task :pythonPackageArchive; Created GATK Python package archive in /home/cb2/gatk/build/gatkPythonPackageArchive.zip. > Task :gatkDoc FAILED; Unable to find the 'javadoc' executable. Tried the java home: /usr/lib/jvm/java-11-openjdk-amd64 and the PATH. We will assume the executable can be ran in the current working folder. FAILURE: Build failed with an exception. * What went wrong:; Execution failed for task ':gatkDoc'.; > Javadoc generation failed. Generated Javadoc options file (useful for troubleshooting): '/home/cb2/gatk/build/tmp/gatkDoc/javadoc.options'. * Try:; Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. Run with --scan to get full insights. * Get more help at https://help.gradle.org; ```. And stacktrace flag output looks like:. ```; `cb2@cb2-VirtualBox:~/gatk$ ./gradlew bundle --stacktrace; > Task :gatkDoc FAILED. FAILURE: Build failed with an exception. * What went wrong:; Execution failed for task ':gatkDoc'.; > Javadoc generation failed. Generated Javadoc options file (useful for troubleshooting): '/home/cb2/gatk/build/tmp/gatkDoc/javadoc.options'. * Try:; Run with --info or --debug option to get more log output. Run with --scan to get full insights. * Exception is:; org.gradle.api.tasks.TaskExecutionException: Execution failed for task ':gatkDoc'.; at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter$3.accept(ExecuteActionsTaskExecuter.java:166); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter$3.accept(ExecuteActionsTaskExecuter.java:163); at org.gradle.internal.Try$Failure.ifSuccessfulOrElse(Try.java:191); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(Execu,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716
https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716:1168,Availability,FAILURE,FAILURE,1168,entDefinition; Created standard Conda environment yml file: gatkcondaenv.yml. > Task :pythonPackageArchive; Created GATK Python package archive in /home/cb2/gatk/build/gatkPythonPackageArchive.zip. > Task :gatkDoc FAILED; Unable to find the 'javadoc' executable. Tried the java home: /usr/lib/jvm/java-11-openjdk-amd64 and the PATH. We will assume the executable can be ran in the current working folder. FAILURE: Build failed with an exception. * What went wrong:; Execution failed for task ':gatkDoc'.; > Javadoc generation failed. Generated Javadoc options file (useful for troubleshooting): '/home/cb2/gatk/build/tmp/gatkDoc/javadoc.options'. * Try:; Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. Run with --scan to get full insights. * Get more help at https://help.gradle.org; ```. And stacktrace flag output looks like:. ```; `cb2@cb2-VirtualBox:~/gatk$ ./gradlew bundle --stacktrace; > Task :gatkDoc FAILED. FAILURE: Build failed with an exception. * What went wrong:; Execution failed for task ':gatkDoc'.; > Javadoc generation failed. Generated Javadoc options file (useful for troubleshooting): '/home/cb2/gatk/build/tmp/gatkDoc/javadoc.options'. * Try:; Run with --info or --debug option to get more log output. Run with --scan to get full insights. * Exception is:; org.gradle.api.tasks.TaskExecutionException: Execution failed for task ':gatkDoc'.; at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter$3.accept(ExecuteActionsTaskExecuter.java:166); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter$3.accept(ExecuteActionsTaskExecuter.java:163); at org.gradle.internal.Try$Failure.ifSuccessfulOrElse(Try.java:191); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(ExecuteActionsTaskExecuter.java:156); at org.gradle.api.internal.tasks.execution.ValidatingTaskExecuter.execute(ValidatingTaskExecuter.java:62); at org.gradle.api.internal.tasks.execution.Skip,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716
https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716:1876,Availability,Failure,Failure,1876,the stack trace. Run with --info or --debug option to get more log output. Run with --scan to get full insights. * Get more help at https://help.gradle.org; ```. And stacktrace flag output looks like:. ```; `cb2@cb2-VirtualBox:~/gatk$ ./gradlew bundle --stacktrace; > Task :gatkDoc FAILED. FAILURE: Build failed with an exception. * What went wrong:; Execution failed for task ':gatkDoc'.; > Javadoc generation failed. Generated Javadoc options file (useful for troubleshooting): '/home/cb2/gatk/build/tmp/gatkDoc/javadoc.options'. * Try:; Run with --info or --debug option to get more log output. Run with --scan to get full insights. * Exception is:; org.gradle.api.tasks.TaskExecutionException: Execution failed for task ':gatkDoc'.; at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter$3.accept(ExecuteActionsTaskExecuter.java:166); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter$3.accept(ExecuteActionsTaskExecuter.java:163); at org.gradle.internal.Try$Failure.ifSuccessfulOrElse(Try.java:191); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(ExecuteActionsTaskExecuter.java:156); at org.gradle.api.internal.tasks.execution.ValidatingTaskExecuter.execute(ValidatingTaskExecuter.java:62); at org.gradle.api.internal.tasks.execution.SkipEmptySourceFilesTaskExecuter.execute(SkipEmptySourceFilesTaskExecuter.java:108); at org.gradle.api.internal.tasks.execution.ResolveBeforeExecutionOutputsTaskExecuter.execute(ResolveBeforeExecutionOutputsTaskExecuter.java:67); at org.gradle.api.internal.tasks.execution.ResolveAfterPreviousExecutionStateTaskExecuter.execute(ResolveAfterPreviousExecutionStateTaskExecuter.java:46); at org.gradle.api.internal.tasks.execution.CleanupStaleOutputsExecuter.execute(CleanupStaleOutputsExecuter.java:94); at org.gradle.api.internal.tasks.execution.FinalizePropertiesTaskExecuter.execute(FinalizePropertiesTaskExecuter.java:46); at org.gradle.api.internal.tasks.execution.ResolveTaskExecutionModeEx,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716
https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716:13577,Availability,error,error,13577,"t org.gradle.internal.execution.steps.CaptureStateBeforeExecutionStep.execute(CaptureStateBeforeExecutionStep.java:47); at org.gradle.internal.execution.impl.DefaultWorkExecutor.execute(DefaultWorkExecutor.java:33); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(ExecuteActionsTaskExecuter.java:140); ... 34 more; Caused by: org.gradle.process.internal.ExecException: A problem occurred starting process 'command 'javadoc''; at org.gradle.process.internal.DefaultExecHandle.execExceptionFor(DefaultExecHandle.java:237); at org.gradle.process.internal.DefaultExecHandle.setEndStateInfo(DefaultExecHandle.java:214); at org.gradle.process.internal.DefaultExecHandle.failed(DefaultExecHandle.java:364); at org.gradle.process.internal.ExecHandleRunner.run(ExecHandleRunner.java:87); at org.gradle.internal.operations.CurrentBuildOperationPreservingRunnable.run(CurrentBuildOperationPreservingRunnable.java:42); ... 3 more; Caused by: net.rubygrapefruit.platform.NativeException: Could not start 'javadoc'; at net.rubygrapefruit.platform.internal.DefaultProcessLauncher.start(DefaultProcessLauncher.java:27); at net.rubygrapefruit.platform.internal.WrapperProcessLauncher.start(WrapperProcessLauncher.java:36); at org.gradle.process.internal.ExecHandleRunner.startProcess(ExecHandleRunner.java:98); at org.gradle.process.internal.ExecHandleRunner.run(ExecHandleRunner.java:71); ... 4 more; Caused by: java.io.IOException: Cannot run program ""javadoc"" (in directory ""/home/cb2/gatk""): error=2, No such file or directory; at net.rubygrapefruit.platform.internal.DefaultProcessLauncher.start(DefaultProcessLauncher.java:25); ... 7 more; Caused by: java.io.IOException: error=2, No such file or directory; ... 8 more. * Get more help at https://help.gradle.org. BUILD FAILED in 1s; 5 actionable tasks: 1 executed, 4 up-to-date; `; ```; I'm open to it being a lot of things. For context, I'm just setting up GATK on a new Linux virtual machine, so some dependencies may not exist.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716
https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716:13759,Availability,error,error,13759,"t org.gradle.internal.execution.steps.CaptureStateBeforeExecutionStep.execute(CaptureStateBeforeExecutionStep.java:47); at org.gradle.internal.execution.impl.DefaultWorkExecutor.execute(DefaultWorkExecutor.java:33); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(ExecuteActionsTaskExecuter.java:140); ... 34 more; Caused by: org.gradle.process.internal.ExecException: A problem occurred starting process 'command 'javadoc''; at org.gradle.process.internal.DefaultExecHandle.execExceptionFor(DefaultExecHandle.java:237); at org.gradle.process.internal.DefaultExecHandle.setEndStateInfo(DefaultExecHandle.java:214); at org.gradle.process.internal.DefaultExecHandle.failed(DefaultExecHandle.java:364); at org.gradle.process.internal.ExecHandleRunner.run(ExecHandleRunner.java:87); at org.gradle.internal.operations.CurrentBuildOperationPreservingRunnable.run(CurrentBuildOperationPreservingRunnable.java:42); ... 3 more; Caused by: net.rubygrapefruit.platform.NativeException: Could not start 'javadoc'; at net.rubygrapefruit.platform.internal.DefaultProcessLauncher.start(DefaultProcessLauncher.java:27); at net.rubygrapefruit.platform.internal.WrapperProcessLauncher.start(WrapperProcessLauncher.java:36); at org.gradle.process.internal.ExecHandleRunner.startProcess(ExecHandleRunner.java:98); at org.gradle.process.internal.ExecHandleRunner.run(ExecHandleRunner.java:71); ... 4 more; Caused by: java.io.IOException: Cannot run program ""javadoc"" (in directory ""/home/cb2/gatk""): error=2, No such file or directory; at net.rubygrapefruit.platform.internal.DefaultProcessLauncher.start(DefaultProcessLauncher.java:25); ... 7 more; Caused by: java.io.IOException: error=2, No such file or directory; ... 8 more. * Get more help at https://help.gradle.org. BUILD FAILED in 1s; 5 actionable tasks: 1 executed, 4 up-to-date; `; ```; I'm open to it being a lot of things. For context, I'm just setting up GATK on a new Linux virtual machine, so some dependencies may not exist.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716
https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716:12,Integrability,message,message,12,The concise message is:. ```; cb2@cb2-VirtualBox:~/gatk$ ./gradlew bundle; > Configure project :; Executing: git lfs pull --include src/main/resources/large. > Task :condaStandardEnvironmentDefinition; Created standard Conda environment yml file: gatkcondaenv.yml. > Task :pythonPackageArchive; Created GATK Python package archive in /home/cb2/gatk/build/gatkPythonPackageArchive.zip. > Task :gatkDoc FAILED; Unable to find the 'javadoc' executable. Tried the java home: /usr/lib/jvm/java-11-openjdk-amd64 and the PATH. We will assume the executable can be ran in the current working folder. FAILURE: Build failed with an exception. * What went wrong:; Execution failed for task ':gatkDoc'.; > Javadoc generation failed. Generated Javadoc options file (useful for troubleshooting): '/home/cb2/gatk/build/tmp/gatkDoc/javadoc.options'. * Try:; Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. Run with --scan to get full insights. * Get more help at https://help.gradle.org; ```. And stacktrace flag output looks like:. ```; `cb2@cb2-VirtualBox:~/gatk$ ./gradlew bundle --stacktrace; > Task :gatkDoc FAILED. FAILURE: Build failed with an exception. * What went wrong:; Execution failed for task ':gatkDoc'.; > Javadoc generation failed. Generated Javadoc options file (useful for troubleshooting): '/home/cb2/gatk/build/tmp/gatkDoc/javadoc.options'. * Try:; Run with --info or --debug option to get more log output. Run with --scan to get full insights. * Exception is:; org.gradle.api.tasks.TaskExecutionException: Execution failed for task ':gatkDoc'.; at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter$3.accept(ExecuteActionsTaskExecuter.java:166); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter$3.accept(ExecuteActionsTaskExecuter.java:163); at org.gradle.internal.Try$Failure.ifSuccessfulOrElse(Try.java:191); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(Execu,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716
https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716:13242,Integrability,Wrap,WrapperProcessLauncher,13242,"t org.gradle.internal.execution.steps.CaptureStateBeforeExecutionStep.execute(CaptureStateBeforeExecutionStep.java:47); at org.gradle.internal.execution.impl.DefaultWorkExecutor.execute(DefaultWorkExecutor.java:33); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(ExecuteActionsTaskExecuter.java:140); ... 34 more; Caused by: org.gradle.process.internal.ExecException: A problem occurred starting process 'command 'javadoc''; at org.gradle.process.internal.DefaultExecHandle.execExceptionFor(DefaultExecHandle.java:237); at org.gradle.process.internal.DefaultExecHandle.setEndStateInfo(DefaultExecHandle.java:214); at org.gradle.process.internal.DefaultExecHandle.failed(DefaultExecHandle.java:364); at org.gradle.process.internal.ExecHandleRunner.run(ExecHandleRunner.java:87); at org.gradle.internal.operations.CurrentBuildOperationPreservingRunnable.run(CurrentBuildOperationPreservingRunnable.java:42); ... 3 more; Caused by: net.rubygrapefruit.platform.NativeException: Could not start 'javadoc'; at net.rubygrapefruit.platform.internal.DefaultProcessLauncher.start(DefaultProcessLauncher.java:27); at net.rubygrapefruit.platform.internal.WrapperProcessLauncher.start(WrapperProcessLauncher.java:36); at org.gradle.process.internal.ExecHandleRunner.startProcess(ExecHandleRunner.java:98); at org.gradle.process.internal.ExecHandleRunner.run(ExecHandleRunner.java:71); ... 4 more; Caused by: java.io.IOException: Cannot run program ""javadoc"" (in directory ""/home/cb2/gatk""): error=2, No such file or directory; at net.rubygrapefruit.platform.internal.DefaultProcessLauncher.start(DefaultProcessLauncher.java:25); ... 7 more; Caused by: java.io.IOException: error=2, No such file or directory; ... 8 more. * Get more help at https://help.gradle.org. BUILD FAILED in 1s; 5 actionable tasks: 1 executed, 4 up-to-date; `; ```; I'm open to it being a lot of things. For context, I'm just setting up GATK on a new Linux virtual machine, so some dependencies may not exist.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716
https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716:13271,Integrability,Wrap,WrapperProcessLauncher,13271,"t org.gradle.internal.execution.steps.CaptureStateBeforeExecutionStep.execute(CaptureStateBeforeExecutionStep.java:47); at org.gradle.internal.execution.impl.DefaultWorkExecutor.execute(DefaultWorkExecutor.java:33); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(ExecuteActionsTaskExecuter.java:140); ... 34 more; Caused by: org.gradle.process.internal.ExecException: A problem occurred starting process 'command 'javadoc''; at org.gradle.process.internal.DefaultExecHandle.execExceptionFor(DefaultExecHandle.java:237); at org.gradle.process.internal.DefaultExecHandle.setEndStateInfo(DefaultExecHandle.java:214); at org.gradle.process.internal.DefaultExecHandle.failed(DefaultExecHandle.java:364); at org.gradle.process.internal.ExecHandleRunner.run(ExecHandleRunner.java:87); at org.gradle.internal.operations.CurrentBuildOperationPreservingRunnable.run(CurrentBuildOperationPreservingRunnable.java:42); ... 3 more; Caused by: net.rubygrapefruit.platform.NativeException: Could not start 'javadoc'; at net.rubygrapefruit.platform.internal.DefaultProcessLauncher.start(DefaultProcessLauncher.java:27); at net.rubygrapefruit.platform.internal.WrapperProcessLauncher.start(WrapperProcessLauncher.java:36); at org.gradle.process.internal.ExecHandleRunner.startProcess(ExecHandleRunner.java:98); at org.gradle.process.internal.ExecHandleRunner.run(ExecHandleRunner.java:71); ... 4 more; Caused by: java.io.IOException: Cannot run program ""javadoc"" (in directory ""/home/cb2/gatk""): error=2, No such file or directory; at net.rubygrapefruit.platform.internal.DefaultProcessLauncher.start(DefaultProcessLauncher.java:25); ... 7 more; Caused by: java.io.IOException: error=2, No such file or directory; ... 8 more. * Get more help at https://help.gradle.org. BUILD FAILED in 1s; 5 actionable tasks: 1 executed, 4 up-to-date; `; ```; I'm open to it being a lot of things. For context, I'm just setting up GATK on a new Linux virtual machine, so some dependencies may not exist.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716
https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716:14041,Integrability,depend,dependencies,14041,"t org.gradle.internal.execution.steps.CaptureStateBeforeExecutionStep.execute(CaptureStateBeforeExecutionStep.java:47); at org.gradle.internal.execution.impl.DefaultWorkExecutor.execute(DefaultWorkExecutor.java:33); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(ExecuteActionsTaskExecuter.java:140); ... 34 more; Caused by: org.gradle.process.internal.ExecException: A problem occurred starting process 'command 'javadoc''; at org.gradle.process.internal.DefaultExecHandle.execExceptionFor(DefaultExecHandle.java:237); at org.gradle.process.internal.DefaultExecHandle.setEndStateInfo(DefaultExecHandle.java:214); at org.gradle.process.internal.DefaultExecHandle.failed(DefaultExecHandle.java:364); at org.gradle.process.internal.ExecHandleRunner.run(ExecHandleRunner.java:87); at org.gradle.internal.operations.CurrentBuildOperationPreservingRunnable.run(CurrentBuildOperationPreservingRunnable.java:42); ... 3 more; Caused by: net.rubygrapefruit.platform.NativeException: Could not start 'javadoc'; at net.rubygrapefruit.platform.internal.DefaultProcessLauncher.start(DefaultProcessLauncher.java:27); at net.rubygrapefruit.platform.internal.WrapperProcessLauncher.start(WrapperProcessLauncher.java:36); at org.gradle.process.internal.ExecHandleRunner.startProcess(ExecHandleRunner.java:98); at org.gradle.process.internal.ExecHandleRunner.run(ExecHandleRunner.java:71); ... 4 more; Caused by: java.io.IOException: Cannot run program ""javadoc"" (in directory ""/home/cb2/gatk""): error=2, No such file or directory; at net.rubygrapefruit.platform.internal.DefaultProcessLauncher.start(DefaultProcessLauncher.java:25); ... 7 more; Caused by: java.io.IOException: error=2, No such file or directory; ... 8 more. * Get more help at https://help.gradle.org. BUILD FAILED in 1s; 5 actionable tasks: 1 executed, 4 up-to-date; `; ```; I'm open to it being a lot of things. For context, I'm just setting up GATK on a new Linux virtual machine, so some dependencies may not exist.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716
https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716:77,Modifiability,Config,Configure,77,The concise message is:. ```; cb2@cb2-VirtualBox:~/gatk$ ./gradlew bundle; > Configure project :; Executing: git lfs pull --include src/main/resources/large. > Task :condaStandardEnvironmentDefinition; Created standard Conda environment yml file: gatkcondaenv.yml. > Task :pythonPackageArchive; Created GATK Python package archive in /home/cb2/gatk/build/gatkPythonPackageArchive.zip. > Task :gatkDoc FAILED; Unable to find the 'javadoc' executable. Tried the java home: /usr/lib/jvm/java-11-openjdk-amd64 and the PATH. We will assume the executable can be ran in the current working folder. FAILURE: Build failed with an exception. * What went wrong:; Execution failed for task ':gatkDoc'.; > Javadoc generation failed. Generated Javadoc options file (useful for troubleshooting): '/home/cb2/gatk/build/tmp/gatkDoc/javadoc.options'. * Try:; Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. Run with --scan to get full insights. * Get more help at https://help.gradle.org; ```. And stacktrace flag output looks like:. ```; `cb2@cb2-VirtualBox:~/gatk$ ./gradlew bundle --stacktrace; > Task :gatkDoc FAILED. FAILURE: Build failed with an exception. * What went wrong:; Execution failed for task ':gatkDoc'.; > Javadoc generation failed. Generated Javadoc options file (useful for troubleshooting): '/home/cb2/gatk/build/tmp/gatkDoc/javadoc.options'. * Try:; Run with --info or --debug option to get more log output. Run with --scan to get full insights. * Exception is:; org.gradle.api.tasks.TaskExecutionException: Execution failed for task ':gatkDoc'.; at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter$3.accept(ExecuteActionsTaskExecuter.java:166); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter$3.accept(ExecuteActionsTaskExecuter.java:163); at org.gradle.internal.Try$Failure.ifSuccessfulOrElse(Try.java:191); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(Execu,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716
https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716:5748,Performance,concurren,concurrent,5748,(DefaultTaskExecutionGraph.java:355); at org.gradle.execution.taskgraph.DefaultTaskExecutionGraph$InvokeNodeExecutorsAction.execute(DefaultTaskExecutionGraph.java:343); at org.gradle.execution.taskgraph.DefaultTaskExecutionGraph$BuildOperationAwareExecutionAction.execute(DefaultTaskExecutionGraph.java:336); at org.gradle.execution.taskgraph.DefaultTaskExecutionGraph$BuildOperationAwareExecutionAction.execute(DefaultTaskExecutionGraph.java:322); at org.gradle.execution.plan.DefaultPlanExecutor$ExecutorWorker$1.execute(DefaultPlanExecutor.java:134); at org.gradle.execution.plan.DefaultPlanExecutor$ExecutorWorker$1.execute(DefaultPlanExecutor.java:129); at org.gradle.execution.plan.DefaultPlanExecutor$ExecutorWorker.execute(DefaultPlanExecutor.java:202); at org.gradle.execution.plan.DefaultPlanExecutor$ExecutorWorker.executeNextNode(DefaultPlanExecutor.java:193); at org.gradle.execution.plan.DefaultPlanExecutor$ExecutorWorker.run(DefaultPlanExecutor.java:129); at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); Caused by: org.gradle.api.GradleException: Javadoc generation failed. Generated Javadoc options file (useful for troubleshooting): '/home/cb2/gatk/build/tmp/gatkDoc/javadoc.options'; at org.gradle.api.tasks.javadoc.internal.JavadocGenerator.execute(JavadocGenerator.java:58); at org.gradle.api.tasks.javadoc.internal.JavadocGenerator.execute(JavadocGenerator.java:31); at org.gradle.api.tasks.javadoc.Javadoc.executeExternalJavadoc(Javadoc.java:158); at org.gradle.api.tasks.javadoc.Javadoc.generate(Javadoc.java:146); at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at java.base/jdk.intern,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716
https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716:5855,Performance,concurren,concurrent,5855,eExecutorsAction.execute(DefaultTaskExecutionGraph.java:343); at org.gradle.execution.taskgraph.DefaultTaskExecutionGraph$BuildOperationAwareExecutionAction.execute(DefaultTaskExecutionGraph.java:336); at org.gradle.execution.taskgraph.DefaultTaskExecutionGraph$BuildOperationAwareExecutionAction.execute(DefaultTaskExecutionGraph.java:322); at org.gradle.execution.plan.DefaultPlanExecutor$ExecutorWorker$1.execute(DefaultPlanExecutor.java:134); at org.gradle.execution.plan.DefaultPlanExecutor$ExecutorWorker$1.execute(DefaultPlanExecutor.java:129); at org.gradle.execution.plan.DefaultPlanExecutor$ExecutorWorker.execute(DefaultPlanExecutor.java:202); at org.gradle.execution.plan.DefaultPlanExecutor$ExecutorWorker.executeNextNode(DefaultPlanExecutor.java:193); at org.gradle.execution.plan.DefaultPlanExecutor$ExecutorWorker.run(DefaultPlanExecutor.java:129); at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); Caused by: org.gradle.api.GradleException: Javadoc generation failed. Generated Javadoc options file (useful for troubleshooting): '/home/cb2/gatk/build/tmp/gatkDoc/javadoc.options'; at org.gradle.api.tasks.javadoc.internal.JavadocGenerator.execute(JavadocGenerator.java:58); at org.gradle.api.tasks.javadoc.internal.JavadocGenerator.execute(JavadocGenerator.java:31); at org.gradle.api.tasks.javadoc.Javadoc.executeExternalJavadoc(Javadoc.java:158); at org.gradle.api.tasks.javadoc.Javadoc.generate(Javadoc.java:146); at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at org.gradle.interna,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716
https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716:5945,Performance,concurren,concurrent,5945,graph.DefaultTaskExecutionGraph$BuildOperationAwareExecutionAction.execute(DefaultTaskExecutionGraph.java:336); at org.gradle.execution.taskgraph.DefaultTaskExecutionGraph$BuildOperationAwareExecutionAction.execute(DefaultTaskExecutionGraph.java:322); at org.gradle.execution.plan.DefaultPlanExecutor$ExecutorWorker$1.execute(DefaultPlanExecutor.java:134); at org.gradle.execution.plan.DefaultPlanExecutor$ExecutorWorker$1.execute(DefaultPlanExecutor.java:129); at org.gradle.execution.plan.DefaultPlanExecutor$ExecutorWorker.execute(DefaultPlanExecutor.java:202); at org.gradle.execution.plan.DefaultPlanExecutor$ExecutorWorker.executeNextNode(DefaultPlanExecutor.java:193); at org.gradle.execution.plan.DefaultPlanExecutor$ExecutorWorker.run(DefaultPlanExecutor.java:129); at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); Caused by: org.gradle.api.GradleException: Javadoc generation failed. Generated Javadoc options file (useful for troubleshooting): '/home/cb2/gatk/build/tmp/gatkDoc/javadoc.options'; at org.gradle.api.tasks.javadoc.internal.JavadocGenerator.execute(JavadocGenerator.java:58); at org.gradle.api.tasks.javadoc.internal.JavadocGenerator.execute(JavadocGenerator.java:31); at org.gradle.api.tasks.javadoc.Javadoc.executeExternalJavadoc(Javadoc.java:158); at org.gradle.api.tasks.javadoc.Javadoc.generate(Javadoc.java:146); at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at org.gradle.internal.reflect.JavaMethod.invoke(JavaMethod.java:103); at org.gradle.api.internal.project.taskf,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716
https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716:10202,Performance,Cache,CacheStep,10202,rg.gradle.internal.execution.steps.CleanupOutputsStep.execute(CleanupOutputsStep.java:35); at org.gradle.internal.execution.steps.ResolveInputChangesStep.execute(ResolveInputChangesStep.java:48); at org.gradle.internal.execution.steps.ResolveInputChangesStep.execute(ResolveInputChangesStep.java:33); at org.gradle.internal.execution.steps.CancelExecutionStep.execute(CancelExecutionStep.java:39); at org.gradle.internal.execution.steps.TimeoutStep.executeWithoutTimeout(TimeoutStep.java:73); at org.gradle.internal.execution.steps.TimeoutStep.execute(TimeoutStep.java:54); at org.gradle.internal.execution.steps.CatchExceptionStep.execute(CatchExceptionStep.java:35); at org.gradle.internal.execution.steps.CreateOutputsStep.execute(CreateOutputsStep.java:51); at org.gradle.internal.execution.steps.SnapshotOutputsStep.execute(SnapshotOutputsStep.java:45); at org.gradle.internal.execution.steps.SnapshotOutputsStep.execute(SnapshotOutputsStep.java:31); at org.gradle.internal.execution.steps.CacheStep.executeWithoutCache(CacheStep.java:208); at org.gradle.internal.execution.steps.CacheStep.execute(CacheStep.java:70); at org.gradle.internal.execution.steps.CacheStep.execute(CacheStep.java:45); at org.gradle.internal.execution.steps.BroadcastChangingOutputsStep.execute(BroadcastChangingOutputsStep.java:49); at org.gradle.internal.execution.steps.StoreSnapshotsStep.execute(StoreSnapshotsStep.java:43); at org.gradle.internal.execution.steps.StoreSnapshotsStep.execute(StoreSnapshotsStep.java:32); at org.gradle.internal.execution.steps.RecordOutputsStep.execute(RecordOutputsStep.java:38); at org.gradle.internal.execution.steps.RecordOutputsStep.execute(RecordOutputsStep.java:24); at org.gradle.internal.execution.steps.SkipUpToDateStep.executeBecause(SkipUpToDateStep.java:96); at org.gradle.internal.execution.steps.SkipUpToDateStep.lambda$execute$0(SkipUpToDateStep.java:89); at org.gradle.internal.execution.steps.SkipUpToDateStep.execute(SkipUpToDateStep.java:54); at org.gradle.intern,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716
https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716:10232,Performance,Cache,CacheStep,10232,xecution.steps.CleanupOutputsStep.execute(CleanupOutputsStep.java:35); at org.gradle.internal.execution.steps.ResolveInputChangesStep.execute(ResolveInputChangesStep.java:48); at org.gradle.internal.execution.steps.ResolveInputChangesStep.execute(ResolveInputChangesStep.java:33); at org.gradle.internal.execution.steps.CancelExecutionStep.execute(CancelExecutionStep.java:39); at org.gradle.internal.execution.steps.TimeoutStep.executeWithoutTimeout(TimeoutStep.java:73); at org.gradle.internal.execution.steps.TimeoutStep.execute(TimeoutStep.java:54); at org.gradle.internal.execution.steps.CatchExceptionStep.execute(CatchExceptionStep.java:35); at org.gradle.internal.execution.steps.CreateOutputsStep.execute(CreateOutputsStep.java:51); at org.gradle.internal.execution.steps.SnapshotOutputsStep.execute(SnapshotOutputsStep.java:45); at org.gradle.internal.execution.steps.SnapshotOutputsStep.execute(SnapshotOutputsStep.java:31); at org.gradle.internal.execution.steps.CacheStep.executeWithoutCache(CacheStep.java:208); at org.gradle.internal.execution.steps.CacheStep.execute(CacheStep.java:70); at org.gradle.internal.execution.steps.CacheStep.execute(CacheStep.java:45); at org.gradle.internal.execution.steps.BroadcastChangingOutputsStep.execute(BroadcastChangingOutputsStep.java:49); at org.gradle.internal.execution.steps.StoreSnapshotsStep.execute(StoreSnapshotsStep.java:43); at org.gradle.internal.execution.steps.StoreSnapshotsStep.execute(StoreSnapshotsStep.java:32); at org.gradle.internal.execution.steps.RecordOutputsStep.execute(RecordOutputsStep.java:38); at org.gradle.internal.execution.steps.RecordOutputsStep.execute(RecordOutputsStep.java:24); at org.gradle.internal.execution.steps.SkipUpToDateStep.executeBecause(SkipUpToDateStep.java:96); at org.gradle.internal.execution.steps.SkipUpToDateStep.lambda$execute$0(SkipUpToDateStep.java:89); at org.gradle.internal.execution.steps.SkipUpToDateStep.execute(SkipUpToDateStep.java:54); at org.gradle.internal.execution.steps.S,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716
https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716:10292,Performance,Cache,CacheStep,10292, at org.gradle.internal.execution.steps.ResolveInputChangesStep.execute(ResolveInputChangesStep.java:48); at org.gradle.internal.execution.steps.ResolveInputChangesStep.execute(ResolveInputChangesStep.java:33); at org.gradle.internal.execution.steps.CancelExecutionStep.execute(CancelExecutionStep.java:39); at org.gradle.internal.execution.steps.TimeoutStep.executeWithoutTimeout(TimeoutStep.java:73); at org.gradle.internal.execution.steps.TimeoutStep.execute(TimeoutStep.java:54); at org.gradle.internal.execution.steps.CatchExceptionStep.execute(CatchExceptionStep.java:35); at org.gradle.internal.execution.steps.CreateOutputsStep.execute(CreateOutputsStep.java:51); at org.gradle.internal.execution.steps.SnapshotOutputsStep.execute(SnapshotOutputsStep.java:45); at org.gradle.internal.execution.steps.SnapshotOutputsStep.execute(SnapshotOutputsStep.java:31); at org.gradle.internal.execution.steps.CacheStep.executeWithoutCache(CacheStep.java:208); at org.gradle.internal.execution.steps.CacheStep.execute(CacheStep.java:70); at org.gradle.internal.execution.steps.CacheStep.execute(CacheStep.java:45); at org.gradle.internal.execution.steps.BroadcastChangingOutputsStep.execute(BroadcastChangingOutputsStep.java:49); at org.gradle.internal.execution.steps.StoreSnapshotsStep.execute(StoreSnapshotsStep.java:43); at org.gradle.internal.execution.steps.StoreSnapshotsStep.execute(StoreSnapshotsStep.java:32); at org.gradle.internal.execution.steps.RecordOutputsStep.execute(RecordOutputsStep.java:38); at org.gradle.internal.execution.steps.RecordOutputsStep.execute(RecordOutputsStep.java:24); at org.gradle.internal.execution.steps.SkipUpToDateStep.executeBecause(SkipUpToDateStep.java:96); at org.gradle.internal.execution.steps.SkipUpToDateStep.lambda$execute$0(SkipUpToDateStep.java:89); at org.gradle.internal.execution.steps.SkipUpToDateStep.execute(SkipUpToDateStep.java:54); at org.gradle.internal.execution.steps.SkipUpToDateStep.execute(SkipUpToDateStep.java:38); at org.gradle.inter,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716
https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716:10310,Performance,Cache,CacheStep,10310,.internal.execution.steps.ResolveInputChangesStep.execute(ResolveInputChangesStep.java:48); at org.gradle.internal.execution.steps.ResolveInputChangesStep.execute(ResolveInputChangesStep.java:33); at org.gradle.internal.execution.steps.CancelExecutionStep.execute(CancelExecutionStep.java:39); at org.gradle.internal.execution.steps.TimeoutStep.executeWithoutTimeout(TimeoutStep.java:73); at org.gradle.internal.execution.steps.TimeoutStep.execute(TimeoutStep.java:54); at org.gradle.internal.execution.steps.CatchExceptionStep.execute(CatchExceptionStep.java:35); at org.gradle.internal.execution.steps.CreateOutputsStep.execute(CreateOutputsStep.java:51); at org.gradle.internal.execution.steps.SnapshotOutputsStep.execute(SnapshotOutputsStep.java:45); at org.gradle.internal.execution.steps.SnapshotOutputsStep.execute(SnapshotOutputsStep.java:31); at org.gradle.internal.execution.steps.CacheStep.executeWithoutCache(CacheStep.java:208); at org.gradle.internal.execution.steps.CacheStep.execute(CacheStep.java:70); at org.gradle.internal.execution.steps.CacheStep.execute(CacheStep.java:45); at org.gradle.internal.execution.steps.BroadcastChangingOutputsStep.execute(BroadcastChangingOutputsStep.java:49); at org.gradle.internal.execution.steps.StoreSnapshotsStep.execute(StoreSnapshotsStep.java:43); at org.gradle.internal.execution.steps.StoreSnapshotsStep.execute(StoreSnapshotsStep.java:32); at org.gradle.internal.execution.steps.RecordOutputsStep.execute(RecordOutputsStep.java:38); at org.gradle.internal.execution.steps.RecordOutputsStep.execute(RecordOutputsStep.java:24); at org.gradle.internal.execution.steps.SkipUpToDateStep.executeBecause(SkipUpToDateStep.java:96); at org.gradle.internal.execution.steps.SkipUpToDateStep.lambda$execute$0(SkipUpToDateStep.java:89); at org.gradle.internal.execution.steps.SkipUpToDateStep.execute(SkipUpToDateStep.java:54); at org.gradle.internal.execution.steps.SkipUpToDateStep.execute(SkipUpToDateStep.java:38); at org.gradle.internal.execution.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716
https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716:10369,Performance,Cache,CacheStep,10369,veInputChangesStep.java:48); at org.gradle.internal.execution.steps.ResolveInputChangesStep.execute(ResolveInputChangesStep.java:33); at org.gradle.internal.execution.steps.CancelExecutionStep.execute(CancelExecutionStep.java:39); at org.gradle.internal.execution.steps.TimeoutStep.executeWithoutTimeout(TimeoutStep.java:73); at org.gradle.internal.execution.steps.TimeoutStep.execute(TimeoutStep.java:54); at org.gradle.internal.execution.steps.CatchExceptionStep.execute(CatchExceptionStep.java:35); at org.gradle.internal.execution.steps.CreateOutputsStep.execute(CreateOutputsStep.java:51); at org.gradle.internal.execution.steps.SnapshotOutputsStep.execute(SnapshotOutputsStep.java:45); at org.gradle.internal.execution.steps.SnapshotOutputsStep.execute(SnapshotOutputsStep.java:31); at org.gradle.internal.execution.steps.CacheStep.executeWithoutCache(CacheStep.java:208); at org.gradle.internal.execution.steps.CacheStep.execute(CacheStep.java:70); at org.gradle.internal.execution.steps.CacheStep.execute(CacheStep.java:45); at org.gradle.internal.execution.steps.BroadcastChangingOutputsStep.execute(BroadcastChangingOutputsStep.java:49); at org.gradle.internal.execution.steps.StoreSnapshotsStep.execute(StoreSnapshotsStep.java:43); at org.gradle.internal.execution.steps.StoreSnapshotsStep.execute(StoreSnapshotsStep.java:32); at org.gradle.internal.execution.steps.RecordOutputsStep.execute(RecordOutputsStep.java:38); at org.gradle.internal.execution.steps.RecordOutputsStep.execute(RecordOutputsStep.java:24); at org.gradle.internal.execution.steps.SkipUpToDateStep.executeBecause(SkipUpToDateStep.java:96); at org.gradle.internal.execution.steps.SkipUpToDateStep.lambda$execute$0(SkipUpToDateStep.java:89); at org.gradle.internal.execution.steps.SkipUpToDateStep.execute(SkipUpToDateStep.java:54); at org.gradle.internal.execution.steps.SkipUpToDateStep.execute(SkipUpToDateStep.java:38); at org.gradle.internal.execution.steps.ResolveChangesStep.execute(ResolveChangesStep.java:76); a,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716
https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716:10387,Performance,Cache,CacheStep,10387,Step.java:48); at org.gradle.internal.execution.steps.ResolveInputChangesStep.execute(ResolveInputChangesStep.java:33); at org.gradle.internal.execution.steps.CancelExecutionStep.execute(CancelExecutionStep.java:39); at org.gradle.internal.execution.steps.TimeoutStep.executeWithoutTimeout(TimeoutStep.java:73); at org.gradle.internal.execution.steps.TimeoutStep.execute(TimeoutStep.java:54); at org.gradle.internal.execution.steps.CatchExceptionStep.execute(CatchExceptionStep.java:35); at org.gradle.internal.execution.steps.CreateOutputsStep.execute(CreateOutputsStep.java:51); at org.gradle.internal.execution.steps.SnapshotOutputsStep.execute(SnapshotOutputsStep.java:45); at org.gradle.internal.execution.steps.SnapshotOutputsStep.execute(SnapshotOutputsStep.java:31); at org.gradle.internal.execution.steps.CacheStep.executeWithoutCache(CacheStep.java:208); at org.gradle.internal.execution.steps.CacheStep.execute(CacheStep.java:70); at org.gradle.internal.execution.steps.CacheStep.execute(CacheStep.java:45); at org.gradle.internal.execution.steps.BroadcastChangingOutputsStep.execute(BroadcastChangingOutputsStep.java:49); at org.gradle.internal.execution.steps.StoreSnapshotsStep.execute(StoreSnapshotsStep.java:43); at org.gradle.internal.execution.steps.StoreSnapshotsStep.execute(StoreSnapshotsStep.java:32); at org.gradle.internal.execution.steps.RecordOutputsStep.execute(RecordOutputsStep.java:38); at org.gradle.internal.execution.steps.RecordOutputsStep.execute(RecordOutputsStep.java:24); at org.gradle.internal.execution.steps.SkipUpToDateStep.executeBecause(SkipUpToDateStep.java:96); at org.gradle.internal.execution.steps.SkipUpToDateStep.lambda$execute$0(SkipUpToDateStep.java:89); at org.gradle.internal.execution.steps.SkipUpToDateStep.execute(SkipUpToDateStep.java:54); at org.gradle.internal.execution.steps.SkipUpToDateStep.execute(SkipUpToDateStep.java:38); at org.gradle.internal.execution.steps.ResolveChangesStep.execute(ResolveChangesStep.java:76); at org.gradle.i,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716
https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716:9644,Safety,Timeout,TimeoutStep,9644,.ExecuteActionsTaskExecuter.access$200(ExecuteActionsTaskExecuter.java:93); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter$TaskExecution.execute(ExecuteActionsTaskExecuter.java:237); at org.gradle.internal.execution.steps.ExecuteStep.lambda$execute$1(ExecuteStep.java:33); at org.gradle.internal.execution.steps.ExecuteStep.execute(ExecuteStep.java:33); at org.gradle.internal.execution.steps.ExecuteStep.execute(ExecuteStep.java:26); at org.gradle.internal.execution.steps.CleanupOutputsStep.execute(CleanupOutputsStep.java:58); at org.gradle.internal.execution.steps.CleanupOutputsStep.execute(CleanupOutputsStep.java:35); at org.gradle.internal.execution.steps.ResolveInputChangesStep.execute(ResolveInputChangesStep.java:48); at org.gradle.internal.execution.steps.ResolveInputChangesStep.execute(ResolveInputChangesStep.java:33); at org.gradle.internal.execution.steps.CancelExecutionStep.execute(CancelExecutionStep.java:39); at org.gradle.internal.execution.steps.TimeoutStep.executeWithoutTimeout(TimeoutStep.java:73); at org.gradle.internal.execution.steps.TimeoutStep.execute(TimeoutStep.java:54); at org.gradle.internal.execution.steps.CatchExceptionStep.execute(CatchExceptionStep.java:35); at org.gradle.internal.execution.steps.CreateOutputsStep.execute(CreateOutputsStep.java:51); at org.gradle.internal.execution.steps.SnapshotOutputsStep.execute(SnapshotOutputsStep.java:45); at org.gradle.internal.execution.steps.SnapshotOutputsStep.execute(SnapshotOutputsStep.java:31); at org.gradle.internal.execution.steps.CacheStep.executeWithoutCache(CacheStep.java:208); at org.gradle.internal.execution.steps.CacheStep.execute(CacheStep.java:70); at org.gradle.internal.execution.steps.CacheStep.execute(CacheStep.java:45); at org.gradle.internal.execution.steps.BroadcastChangingOutputsStep.execute(BroadcastChangingOutputsStep.java:49); at org.gradle.internal.execution.steps.StoreSnapshotsStep.execute(StoreSnapshotsStep.java:43); at org.gradle.internal.execution.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716
https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716:9678,Safety,Timeout,TimeoutStep,9678,uter.access$200(ExecuteActionsTaskExecuter.java:93); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter$TaskExecution.execute(ExecuteActionsTaskExecuter.java:237); at org.gradle.internal.execution.steps.ExecuteStep.lambda$execute$1(ExecuteStep.java:33); at org.gradle.internal.execution.steps.ExecuteStep.execute(ExecuteStep.java:33); at org.gradle.internal.execution.steps.ExecuteStep.execute(ExecuteStep.java:26); at org.gradle.internal.execution.steps.CleanupOutputsStep.execute(CleanupOutputsStep.java:58); at org.gradle.internal.execution.steps.CleanupOutputsStep.execute(CleanupOutputsStep.java:35); at org.gradle.internal.execution.steps.ResolveInputChangesStep.execute(ResolveInputChangesStep.java:48); at org.gradle.internal.execution.steps.ResolveInputChangesStep.execute(ResolveInputChangesStep.java:33); at org.gradle.internal.execution.steps.CancelExecutionStep.execute(CancelExecutionStep.java:39); at org.gradle.internal.execution.steps.TimeoutStep.executeWithoutTimeout(TimeoutStep.java:73); at org.gradle.internal.execution.steps.TimeoutStep.execute(TimeoutStep.java:54); at org.gradle.internal.execution.steps.CatchExceptionStep.execute(CatchExceptionStep.java:35); at org.gradle.internal.execution.steps.CreateOutputsStep.execute(CreateOutputsStep.java:51); at org.gradle.internal.execution.steps.SnapshotOutputsStep.execute(SnapshotOutputsStep.java:45); at org.gradle.internal.execution.steps.SnapshotOutputsStep.execute(SnapshotOutputsStep.java:31); at org.gradle.internal.execution.steps.CacheStep.executeWithoutCache(CacheStep.java:208); at org.gradle.internal.execution.steps.CacheStep.execute(CacheStep.java:70); at org.gradle.internal.execution.steps.CacheStep.execute(CacheStep.java:45); at org.gradle.internal.execution.steps.BroadcastChangingOutputsStep.execute(BroadcastChangingOutputsStep.java:49); at org.gradle.internal.execution.steps.StoreSnapshotsStep.execute(StoreSnapshotsStep.java:43); at org.gradle.internal.execution.steps.StoreSnapshotsSte,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716
https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716:9739,Safety,Timeout,TimeoutStep,9739,nternal.tasks.execution.ExecuteActionsTaskExecuter$TaskExecution.execute(ExecuteActionsTaskExecuter.java:237); at org.gradle.internal.execution.steps.ExecuteStep.lambda$execute$1(ExecuteStep.java:33); at org.gradle.internal.execution.steps.ExecuteStep.execute(ExecuteStep.java:33); at org.gradle.internal.execution.steps.ExecuteStep.execute(ExecuteStep.java:26); at org.gradle.internal.execution.steps.CleanupOutputsStep.execute(CleanupOutputsStep.java:58); at org.gradle.internal.execution.steps.CleanupOutputsStep.execute(CleanupOutputsStep.java:35); at org.gradle.internal.execution.steps.ResolveInputChangesStep.execute(ResolveInputChangesStep.java:48); at org.gradle.internal.execution.steps.ResolveInputChangesStep.execute(ResolveInputChangesStep.java:33); at org.gradle.internal.execution.steps.CancelExecutionStep.execute(CancelExecutionStep.java:39); at org.gradle.internal.execution.steps.TimeoutStep.executeWithoutTimeout(TimeoutStep.java:73); at org.gradle.internal.execution.steps.TimeoutStep.execute(TimeoutStep.java:54); at org.gradle.internal.execution.steps.CatchExceptionStep.execute(CatchExceptionStep.java:35); at org.gradle.internal.execution.steps.CreateOutputsStep.execute(CreateOutputsStep.java:51); at org.gradle.internal.execution.steps.SnapshotOutputsStep.execute(SnapshotOutputsStep.java:45); at org.gradle.internal.execution.steps.SnapshotOutputsStep.execute(SnapshotOutputsStep.java:31); at org.gradle.internal.execution.steps.CacheStep.executeWithoutCache(CacheStep.java:208); at org.gradle.internal.execution.steps.CacheStep.execute(CacheStep.java:70); at org.gradle.internal.execution.steps.CacheStep.execute(CacheStep.java:45); at org.gradle.internal.execution.steps.BroadcastChangingOutputsStep.execute(BroadcastChangingOutputsStep.java:49); at org.gradle.internal.execution.steps.StoreSnapshotsStep.execute(StoreSnapshotsStep.java:43); at org.gradle.internal.execution.steps.StoreSnapshotsStep.execute(StoreSnapshotsStep.java:32); at org.gradle.internal.execution.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716
https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716:9759,Safety,Timeout,TimeoutStep,9759,ecution.ExecuteActionsTaskExecuter$TaskExecution.execute(ExecuteActionsTaskExecuter.java:237); at org.gradle.internal.execution.steps.ExecuteStep.lambda$execute$1(ExecuteStep.java:33); at org.gradle.internal.execution.steps.ExecuteStep.execute(ExecuteStep.java:33); at org.gradle.internal.execution.steps.ExecuteStep.execute(ExecuteStep.java:26); at org.gradle.internal.execution.steps.CleanupOutputsStep.execute(CleanupOutputsStep.java:58); at org.gradle.internal.execution.steps.CleanupOutputsStep.execute(CleanupOutputsStep.java:35); at org.gradle.internal.execution.steps.ResolveInputChangesStep.execute(ResolveInputChangesStep.java:48); at org.gradle.internal.execution.steps.ResolveInputChangesStep.execute(ResolveInputChangesStep.java:33); at org.gradle.internal.execution.steps.CancelExecutionStep.execute(CancelExecutionStep.java:39); at org.gradle.internal.execution.steps.TimeoutStep.executeWithoutTimeout(TimeoutStep.java:73); at org.gradle.internal.execution.steps.TimeoutStep.execute(TimeoutStep.java:54); at org.gradle.internal.execution.steps.CatchExceptionStep.execute(CatchExceptionStep.java:35); at org.gradle.internal.execution.steps.CreateOutputsStep.execute(CreateOutputsStep.java:51); at org.gradle.internal.execution.steps.SnapshotOutputsStep.execute(SnapshotOutputsStep.java:45); at org.gradle.internal.execution.steps.SnapshotOutputsStep.execute(SnapshotOutputsStep.java:31); at org.gradle.internal.execution.steps.CacheStep.executeWithoutCache(CacheStep.java:208); at org.gradle.internal.execution.steps.CacheStep.execute(CacheStep.java:70); at org.gradle.internal.execution.steps.CacheStep.execute(CacheStep.java:45); at org.gradle.internal.execution.steps.BroadcastChangingOutputsStep.execute(BroadcastChangingOutputsStep.java:49); at org.gradle.internal.execution.steps.StoreSnapshotsStep.execute(StoreSnapshotsStep.java:43); at org.gradle.internal.execution.steps.StoreSnapshotsStep.execute(StoreSnapshotsStep.java:32); at org.gradle.internal.execution.steps.RecordOutp,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716
https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716:2077,Security,Validat,ValidatingTaskExecuter,2077,2@cb2-VirtualBox:~/gatk$ ./gradlew bundle --stacktrace; > Task :gatkDoc FAILED. FAILURE: Build failed with an exception. * What went wrong:; Execution failed for task ':gatkDoc'.; > Javadoc generation failed. Generated Javadoc options file (useful for troubleshooting): '/home/cb2/gatk/build/tmp/gatkDoc/javadoc.options'. * Try:; Run with --info or --debug option to get more log output. Run with --scan to get full insights. * Exception is:; org.gradle.api.tasks.TaskExecutionException: Execution failed for task ':gatkDoc'.; at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter$3.accept(ExecuteActionsTaskExecuter.java:166); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter$3.accept(ExecuteActionsTaskExecuter.java:163); at org.gradle.internal.Try$Failure.ifSuccessfulOrElse(Try.java:191); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(ExecuteActionsTaskExecuter.java:156); at org.gradle.api.internal.tasks.execution.ValidatingTaskExecuter.execute(ValidatingTaskExecuter.java:62); at org.gradle.api.internal.tasks.execution.SkipEmptySourceFilesTaskExecuter.execute(SkipEmptySourceFilesTaskExecuter.java:108); at org.gradle.api.internal.tasks.execution.ResolveBeforeExecutionOutputsTaskExecuter.execute(ResolveBeforeExecutionOutputsTaskExecuter.java:67); at org.gradle.api.internal.tasks.execution.ResolveAfterPreviousExecutionStateTaskExecuter.execute(ResolveAfterPreviousExecutionStateTaskExecuter.java:46); at org.gradle.api.internal.tasks.execution.CleanupStaleOutputsExecuter.execute(CleanupStaleOutputsExecuter.java:94); at org.gradle.api.internal.tasks.execution.FinalizePropertiesTaskExecuter.execute(FinalizePropertiesTaskExecuter.java:46); at org.gradle.api.internal.tasks.execution.ResolveTaskExecutionModeExecuter.execute(ResolveTaskExecutionModeExecuter.java:95); at org.gradle.api.internal.tasks.execution.SkipTaskWithNoActionsExecuter.execute(SkipTaskWithNoActionsExecuter.java:57); at org.gradle.api.internal.tasks,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716
https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716:2108,Security,Validat,ValidatingTaskExecuter,2108,gradlew bundle --stacktrace; > Task :gatkDoc FAILED. FAILURE: Build failed with an exception. * What went wrong:; Execution failed for task ':gatkDoc'.; > Javadoc generation failed. Generated Javadoc options file (useful for troubleshooting): '/home/cb2/gatk/build/tmp/gatkDoc/javadoc.options'. * Try:; Run with --info or --debug option to get more log output. Run with --scan to get full insights. * Exception is:; org.gradle.api.tasks.TaskExecutionException: Execution failed for task ':gatkDoc'.; at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter$3.accept(ExecuteActionsTaskExecuter.java:166); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter$3.accept(ExecuteActionsTaskExecuter.java:163); at org.gradle.internal.Try$Failure.ifSuccessfulOrElse(Try.java:191); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(ExecuteActionsTaskExecuter.java:156); at org.gradle.api.internal.tasks.execution.ValidatingTaskExecuter.execute(ValidatingTaskExecuter.java:62); at org.gradle.api.internal.tasks.execution.SkipEmptySourceFilesTaskExecuter.execute(SkipEmptySourceFilesTaskExecuter.java:108); at org.gradle.api.internal.tasks.execution.ResolveBeforeExecutionOutputsTaskExecuter.execute(ResolveBeforeExecutionOutputsTaskExecuter.java:67); at org.gradle.api.internal.tasks.execution.ResolveAfterPreviousExecutionStateTaskExecuter.execute(ResolveAfterPreviousExecutionStateTaskExecuter.java:46); at org.gradle.api.internal.tasks.execution.CleanupStaleOutputsExecuter.execute(CleanupStaleOutputsExecuter.java:94); at org.gradle.api.internal.tasks.execution.FinalizePropertiesTaskExecuter.execute(FinalizePropertiesTaskExecuter.java:46); at org.gradle.api.internal.tasks.execution.ResolveTaskExecutionModeExecuter.execute(ResolveTaskExecutionModeExecuter.java:95); at org.gradle.api.internal.tasks.execution.SkipTaskWithNoActionsExecuter.execute(SkipTaskWithNoActionsExecuter.java:57); at org.gradle.api.internal.tasks.execution.SkipOnlyIfTaskEx,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716
https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716:8678,Security,access,access,8678,ltBuildOperationExecutor$RunnableBuildOperationWorker.execute(DefaultBuildOperationExecutor.java:394); at org.gradle.internal.operations.DefaultBuildOperationExecutor$1.execute(DefaultBuildOperationExecutor.java:165); at org.gradle.internal.operations.DefaultBuildOperationExecutor.execute(DefaultBuildOperationExecutor.java:250); at org.gradle.internal.operations.DefaultBuildOperationExecutor.execute(DefaultBuildOperationExecutor.java:158); at org.gradle.internal.operations.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:92); at org.gradle.internal.operations.DelegatingBuildOperationExecutor.run(DelegatingBuildOperationExecutor.java:31); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeAction(ExecuteActionsTaskExecuter.java:461); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeActions(ExecuteActionsTaskExecuter.java:444); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.access$200(ExecuteActionsTaskExecuter.java:93); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter$TaskExecution.execute(ExecuteActionsTaskExecuter.java:237); at org.gradle.internal.execution.steps.ExecuteStep.lambda$execute$1(ExecuteStep.java:33); at org.gradle.internal.execution.steps.ExecuteStep.execute(ExecuteStep.java:33); at org.gradle.internal.execution.steps.ExecuteStep.execute(ExecuteStep.java:26); at org.gradle.internal.execution.steps.CleanupOutputsStep.execute(CleanupOutputsStep.java:58); at org.gradle.internal.execution.steps.CleanupOutputsStep.execute(CleanupOutputsStep.java:35); at org.gradle.internal.execution.steps.ResolveInputChangesStep.execute(ResolveInputChangesStep.java:48); at org.gradle.internal.execution.steps.ResolveInputChangesStep.execute(ResolveInputChangesStep.java:33); at org.gradle.internal.execution.steps.CancelExecutionStep.execute(CancelExecutionStep.java:39); at org.gradle.internal.execution.steps.TimeoutStep.executeWithoutTimeout(TimeoutStep.java:73,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716
https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716:941,Testability,log,log,941,The concise message is:. ```; cb2@cb2-VirtualBox:~/gatk$ ./gradlew bundle; > Configure project :; Executing: git lfs pull --include src/main/resources/large. > Task :condaStandardEnvironmentDefinition; Created standard Conda environment yml file: gatkcondaenv.yml. > Task :pythonPackageArchive; Created GATK Python package archive in /home/cb2/gatk/build/gatkPythonPackageArchive.zip. > Task :gatkDoc FAILED; Unable to find the 'javadoc' executable. Tried the java home: /usr/lib/jvm/java-11-openjdk-amd64 and the PATH. We will assume the executable can be ran in the current working folder. FAILURE: Build failed with an exception. * What went wrong:; Execution failed for task ':gatkDoc'.; > Javadoc generation failed. Generated Javadoc options file (useful for troubleshooting): '/home/cb2/gatk/build/tmp/gatkDoc/javadoc.options'. * Try:; Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. Run with --scan to get full insights. * Get more help at https://help.gradle.org; ```. And stacktrace flag output looks like:. ```; `cb2@cb2-VirtualBox:~/gatk$ ./gradlew bundle --stacktrace; > Task :gatkDoc FAILED. FAILURE: Build failed with an exception. * What went wrong:; Execution failed for task ':gatkDoc'.; > Javadoc generation failed. Generated Javadoc options file (useful for troubleshooting): '/home/cb2/gatk/build/tmp/gatkDoc/javadoc.options'. * Try:; Run with --info or --debug option to get more log output. Run with --scan to get full insights. * Exception is:; org.gradle.api.tasks.TaskExecutionException: Execution failed for task ':gatkDoc'.; at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter$3.accept(ExecuteActionsTaskExecuter.java:166); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter$3.accept(ExecuteActionsTaskExecuter.java:163); at org.gradle.internal.Try$Failure.ifSuccessfulOrElse(Try.java:191); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(Execu,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716
https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716:1464,Testability,log,log,1464,utable. Tried the java home: /usr/lib/jvm/java-11-openjdk-amd64 and the PATH. We will assume the executable can be ran in the current working folder. FAILURE: Build failed with an exception. * What went wrong:; Execution failed for task ':gatkDoc'.; > Javadoc generation failed. Generated Javadoc options file (useful for troubleshooting): '/home/cb2/gatk/build/tmp/gatkDoc/javadoc.options'. * Try:; Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. Run with --scan to get full insights. * Get more help at https://help.gradle.org; ```. And stacktrace flag output looks like:. ```; `cb2@cb2-VirtualBox:~/gatk$ ./gradlew bundle --stacktrace; > Task :gatkDoc FAILED. FAILURE: Build failed with an exception. * What went wrong:; Execution failed for task ':gatkDoc'.; > Javadoc generation failed. Generated Javadoc options file (useful for troubleshooting): '/home/cb2/gatk/build/tmp/gatkDoc/javadoc.options'. * Try:; Run with --info or --debug option to get more log output. Run with --scan to get full insights. * Exception is:; org.gradle.api.tasks.TaskExecutionException: Execution failed for task ':gatkDoc'.; at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter$3.accept(ExecuteActionsTaskExecuter.java:166); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter$3.accept(ExecuteActionsTaskExecuter.java:163); at org.gradle.internal.Try$Failure.ifSuccessfulOrElse(Try.java:191); at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(ExecuteActionsTaskExecuter.java:156); at org.gradle.api.internal.tasks.execution.ValidatingTaskExecuter.execute(ValidatingTaskExecuter.java:62); at org.gradle.api.internal.tasks.execution.SkipEmptySourceFilesTaskExecuter.execute(SkipEmptySourceFilesTaskExecuter.java:108); at org.gradle.api.internal.tasks.execution.ResolveBeforeExecutionOutputsTaskExecuter.execute(ResolveBeforeExecutionOutputsTaskExecuter.java:67); at org.gradle.api.internal.t,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4155#issuecomment-566796716
https://github.com/broadinstitute/gatk/issues/4155#issuecomment-567036100:125,Deployability,install,installed,125,"@lbergelson Oh ok, good to know. @jberghout It looks like gradle can't find the `javadoc` app to run. Do you have a full JDK installed ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4155#issuecomment-567036100
https://github.com/broadinstitute/gatk/issues/4155#issuecomment-653704795:116,Deployability,install,install,116,"Strange. That looks fine. Sorry to keep asking question, but a) what operating system are you using? b) how did you install java? Every java 8 jdk should come with javadoc.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4155#issuecomment-653704795
https://github.com/broadinstitute/gatk/issues/4155#issuecomment-1420218938:13,Availability,error,error,13,getting same error; **Execution failed for task ':react-native-reanimated:androidJavadoc'.**; ### Javadoc generation failed. RN-0.71.1; any solution?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4155#issuecomment-1420218938
https://github.com/broadinstitute/gatk/issues/4156#issuecomment-357970316:152,Testability,test,tested-with-version-,152,"@Sun-shan Yes, you can clone this repo, and then follow [these](https://github.com/broadinstitute/gatk#creating-a-gatk-project-in-the-intellij-ide-last-tested-with-version-201624) instructions in the README.md to set up an IntelliJ project.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4156#issuecomment-357970316
https://github.com/broadinstitute/gatk/issues/4157#issuecomment-357973240:718,Testability,log,log,718,"Hi @stefandiederich,. Great that you were able to successfully run GermlineCNVCaller! @asmirnov239 is currently working on a postprocessing tool that will convert the raw generated results into VCFs. @mbabadi is also working on writing some more in-depth documentation on the tool and its probabilistic model. For now, you may be able to parse the raw results on your own. You are probably most interested in the contents of the ""*-calls"" directory. The root of this directory contains the interval list common to all samples; furthermore, each sample has its own subdirectory that contains text files that describe the sample-specific model-parameter posteriors. In particular, the ""log_q_c_tc.tsv"" file contains the log posteriors per copy-number state, with rows corresponding to the intervals in the aforementioned interval list. EDIT: I'm going to go ahead and close this issue. If you have further questions on general usage, it might be better to post in the forum (https://gatkforums.broadinstitute.org) so that other users can benefit from the higher visibility there. Typically, GitHub issues are better suited for detailed bug reports or specific feature requests.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4157#issuecomment-357973240
https://github.com/broadinstitute/gatk/issues/4158#issuecomment-358080124:355,Deployability,install,installed,355,"The segfault happens in `libgomp`:; ```; # Problematic frame:; # C [libgomp.so.1+0x7fab] omp_get_max_threads+0xb; ```; Here's similar issue, which also used Alpine Linux: https://github.com/bytedeco/javacv/issues/716. The resolution was to move to a different Linux distro. @apeltzer, assuming you want to use Alpine, please try running without `libgomp` installed. This will provide single-threaded AVX PairHMM, which will be faster than the Java PairHMM.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4158#issuecomment-358080124
https://github.com/broadinstitute/gatk/issues/4158#issuecomment-358082004:5,Testability,test,test,5,I'll test and let you know asap. Thanks for the hint!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4158#issuecomment-358082004
https://github.com/broadinstitute/gatk/issues/4158#issuecomment-367510121:79,Testability,log,logs,79,"Unfortunately, that doesn't resolve the issue. I'll see whether I can put some logs together to get you a better overview.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4158#issuecomment-367510121
https://github.com/broadinstitute/gatk/issues/4160#issuecomment-358887152:161,Deployability,release,release,161,Thanks for exercising this corner case - looks like TileDB internally used 256 chars for paths. Have increased that to 4096 (max for most filesystems). The next release will fix this.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4160#issuecomment-358887152
https://github.com/broadinstitute/gatk/issues/4161#issuecomment-358054994:594,Availability,down,down,594,"@owensgl Sorry you're running into problems. We typically speed up the process by running multiple GenotypeGVCF processes in parallel, subsetting by genomic intervals. GenotypeGVCFs isn't really multicore, you'll probably be best off giving each process 1 or 2 cores. (You'll see better performance with 2 since java has parallel garbage collection, but it might be more cost effective to run twice as many slower processes...) If you do that you'll want to run with `--only-output-calls-starting-in-intervals` enabled in order to avoid problems on the edges of intervals. . Things tend to bog down with many highly multi-allelic sites. If you have a population with very high diversity you may be hitting lots of sites like that. I'm not sure why it's as slow as you say it is though. It should be faster than 800bp / 30 minutes even with old qual. If you could provide a subset of your data we might be able to profile and see if there's some pathological case we're not handling well. I believe new-qual handles multi-allelic sites more efficiently which I suspect is why it's going faster.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4161#issuecomment-358054994
https://github.com/broadinstitute/gatk/issues/4161#issuecomment-358054994:1040,Energy Efficiency,efficient,efficiently,1040,"@owensgl Sorry you're running into problems. We typically speed up the process by running multiple GenotypeGVCF processes in parallel, subsetting by genomic intervals. GenotypeGVCFs isn't really multicore, you'll probably be best off giving each process 1 or 2 cores. (You'll see better performance with 2 since java has parallel garbage collection, but it might be more cost effective to run twice as many slower processes...) If you do that you'll want to run with `--only-output-calls-starting-in-intervals` enabled in order to avoid problems on the edges of intervals. . Things tend to bog down with many highly multi-allelic sites. If you have a population with very high diversity you may be hitting lots of sites like that. I'm not sure why it's as slow as you say it is though. It should be faster than 800bp / 30 minutes even with old qual. If you could provide a subset of your data we might be able to profile and see if there's some pathological case we're not handling well. I believe new-qual handles multi-allelic sites more efficiently which I suspect is why it's going faster.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4161#issuecomment-358054994
https://github.com/broadinstitute/gatk/issues/4161#issuecomment-358054994:287,Performance,perform,performance,287,"@owensgl Sorry you're running into problems. We typically speed up the process by running multiple GenotypeGVCF processes in parallel, subsetting by genomic intervals. GenotypeGVCFs isn't really multicore, you'll probably be best off giving each process 1 or 2 cores. (You'll see better performance with 2 since java has parallel garbage collection, but it might be more cost effective to run twice as many slower processes...) If you do that you'll want to run with `--only-output-calls-starting-in-intervals` enabled in order to avoid problems on the edges of intervals. . Things tend to bog down with many highly multi-allelic sites. If you have a population with very high diversity you may be hitting lots of sites like that. I'm not sure why it's as slow as you say it is though. It should be faster than 800bp / 30 minutes even with old qual. If you could provide a subset of your data we might be able to profile and see if there's some pathological case we're not handling well. I believe new-qual handles multi-allelic sites more efficiently which I suspect is why it's going faster.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4161#issuecomment-358054994
https://github.com/broadinstitute/gatk/issues/4161#issuecomment-358054994:531,Safety,avoid,avoid,531,"@owensgl Sorry you're running into problems. We typically speed up the process by running multiple GenotypeGVCF processes in parallel, subsetting by genomic intervals. GenotypeGVCFs isn't really multicore, you'll probably be best off giving each process 1 or 2 cores. (You'll see better performance with 2 since java has parallel garbage collection, but it might be more cost effective to run twice as many slower processes...) If you do that you'll want to run with `--only-output-calls-starting-in-intervals` enabled in order to avoid problems on the edges of intervals. . Things tend to bog down with many highly multi-allelic sites. If you have a population with very high diversity you may be hitting lots of sites like that. I'm not sure why it's as slow as you say it is though. It should be faster than 800bp / 30 minutes even with old qual. If you could provide a subset of your data we might be able to profile and see if there's some pathological case we're not handling well. I believe new-qual handles multi-allelic sites more efficiently which I suspect is why it's going faster.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4161#issuecomment-358054994
https://github.com/broadinstitute/gatk/issues/4162#issuecomment-357991567:147,Deployability,update,update,147,"I take it you're using GenomicsDBImport to combine the GVCFs? GenomicsDB doesn't support the allele-specific annotations just yet, but look for an update very soon: #3707 In the meantime, you can use CombineGVCFs in place of GenomicsDBImport if you need those allele-specific annotations.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4162#issuecomment-357991567
https://github.com/broadinstitute/gatk/issues/4163#issuecomment-358016315:69,Testability,test,test,69,It looks like something changed with the google reference api. Every test that uses it is failing. See https://storage.googleapis.com/hellbender-test-logs/build_reports/ll_issue3995_implement_metadata_16386.1/tests/test/index.html. . We should disable these until we can figure out what changed / what the fix is.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4163#issuecomment-358016315
https://github.com/broadinstitute/gatk/issues/4163#issuecomment-358016315:145,Testability,test,test-logs,145,It looks like something changed with the google reference api. Every test that uses it is failing. See https://storage.googleapis.com/hellbender-test-logs/build_reports/ll_issue3995_implement_metadata_16386.1/tests/test/index.html. . We should disable these until we can figure out what changed / what the fix is.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4163#issuecomment-358016315
https://github.com/broadinstitute/gatk/issues/4163#issuecomment-358016315:209,Testability,test,tests,209,It looks like something changed with the google reference api. Every test that uses it is failing. See https://storage.googleapis.com/hellbender-test-logs/build_reports/ll_issue3995_implement_metadata_16386.1/tests/test/index.html. . We should disable these until we can figure out what changed / what the fix is.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4163#issuecomment-358016315
https://github.com/broadinstitute/gatk/issues/4163#issuecomment-358016315:215,Testability,test,test,215,It looks like something changed with the google reference api. Every test that uses it is failing. See https://storage.googleapis.com/hellbender-test-logs/build_reports/ll_issue3995_implement_metadata_16386.1/tests/test/index.html. . We should disable these until we can figure out what changed / what the fix is.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4163#issuecomment-358016315
https://github.com/broadinstitute/gatk/issues/4163#issuecomment-358042689:98,Testability,test,tests,98,"As far as I can tell, they've just turned off the entire genomics api. I'm going to disable these tests immediately and then wait until I hear back from google to decide what to do in the future. . There's a support ticket [here](https://enterprise.google.com/supportcenter/managecases#Case/0016000000MNGDy/U-14725661).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4163#issuecomment-358042689
https://github.com/broadinstitute/gatk/issues/4163#issuecomment-358117141:4,Testability,test,tests,4,The tests are still failing on my machine.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4163#issuecomment-358117141
https://github.com/broadinstitute/gatk/issues/4164#issuecomment-358697586:40,Availability,avail,available,40,"It looks like at one point GATK 3.8 was available via the [homebrew science tap](https://github.com/ilovezfs/homebrew-science/blob/master/gatk.rb). I've tried adding their formula to my homebrew formula folder and installing via ``` brew install gatk.rb``` but there's a ton of errors. ```Updating Homebrew...; ==> Downloading https://github.com/broadgsa/gatk-protected/archive/3.8-1.tar.gz; Already downloaded: /Users/timothystiles/Library/Caches/Homebrew/gatk-3.8-1.tar.gz; ==> mvn package -Dmaven.repo.local=${PWD}/repo; Last 15 lines from /Users/timothystiles/Library/Logs/Homebrew/gatk/01.mvn:; [INFO] Scanning for projects...; [ERROR] [ERROR] Some problems were encountered while processing the POMs:; [FATAL] Non-parseable POM /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml, line 15, column 3; @; [ERROR] The build could not read 1 project -> [Help 1]; [ERROR]; [ERROR] The project org.broadinstitute.gatk:gatk-aggregator:[unknown-version] (/private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/pom.xml) has 1 error; [ERROR] Non-parseable POM /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml, line 15, column 3 -> [Help 2]; [ERROR]; [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.; [ERROR] Re-run Maven using the -X switch to enable full debug logging.; [ERROR]; [ERROR] For more information about the errors and possible solutions, please read the following articles:; [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/ProjectBuildingException; [ERROR] [Help 2] http://cwiki.apache.org/confluence/display",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4164#issuecomment-358697586
https://github.com/broadinstitute/gatk/issues/4164#issuecomment-358697586:278,Availability,error,errors,278,"It looks like at one point GATK 3.8 was available via the [homebrew science tap](https://github.com/ilovezfs/homebrew-science/blob/master/gatk.rb). I've tried adding their formula to my homebrew formula folder and installing via ``` brew install gatk.rb``` but there's a ton of errors. ```Updating Homebrew...; ==> Downloading https://github.com/broadgsa/gatk-protected/archive/3.8-1.tar.gz; Already downloaded: /Users/timothystiles/Library/Caches/Homebrew/gatk-3.8-1.tar.gz; ==> mvn package -Dmaven.repo.local=${PWD}/repo; Last 15 lines from /Users/timothystiles/Library/Logs/Homebrew/gatk/01.mvn:; [INFO] Scanning for projects...; [ERROR] [ERROR] Some problems were encountered while processing the POMs:; [FATAL] Non-parseable POM /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml, line 15, column 3; @; [ERROR] The build could not read 1 project -> [Help 1]; [ERROR]; [ERROR] The project org.broadinstitute.gatk:gatk-aggregator:[unknown-version] (/private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/pom.xml) has 1 error; [ERROR] Non-parseable POM /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml, line 15, column 3 -> [Help 2]; [ERROR]; [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.; [ERROR] Re-run Maven using the -X switch to enable full debug logging.; [ERROR]; [ERROR] For more information about the errors and possible solutions, please read the following articles:; [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/ProjectBuildingException; [ERROR] [Help 2] http://cwiki.apache.org/confluence/display",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4164#issuecomment-358697586
https://github.com/broadinstitute/gatk/issues/4164#issuecomment-358697586:315,Availability,Down,Downloading,315,"It looks like at one point GATK 3.8 was available via the [homebrew science tap](https://github.com/ilovezfs/homebrew-science/blob/master/gatk.rb). I've tried adding their formula to my homebrew formula folder and installing via ``` brew install gatk.rb``` but there's a ton of errors. ```Updating Homebrew...; ==> Downloading https://github.com/broadgsa/gatk-protected/archive/3.8-1.tar.gz; Already downloaded: /Users/timothystiles/Library/Caches/Homebrew/gatk-3.8-1.tar.gz; ==> mvn package -Dmaven.repo.local=${PWD}/repo; Last 15 lines from /Users/timothystiles/Library/Logs/Homebrew/gatk/01.mvn:; [INFO] Scanning for projects...; [ERROR] [ERROR] Some problems were encountered while processing the POMs:; [FATAL] Non-parseable POM /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml, line 15, column 3; @; [ERROR] The build could not read 1 project -> [Help 1]; [ERROR]; [ERROR] The project org.broadinstitute.gatk:gatk-aggregator:[unknown-version] (/private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/pom.xml) has 1 error; [ERROR] Non-parseable POM /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml, line 15, column 3 -> [Help 2]; [ERROR]; [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.; [ERROR] Re-run Maven using the -X switch to enable full debug logging.; [ERROR]; [ERROR] For more information about the errors and possible solutions, please read the following articles:; [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/ProjectBuildingException; [ERROR] [Help 2] http://cwiki.apache.org/confluence/display",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4164#issuecomment-358697586
https://github.com/broadinstitute/gatk/issues/4164#issuecomment-358697586:400,Availability,down,downloaded,400,"It looks like at one point GATK 3.8 was available via the [homebrew science tap](https://github.com/ilovezfs/homebrew-science/blob/master/gatk.rb). I've tried adding their formula to my homebrew formula folder and installing via ``` brew install gatk.rb``` but there's a ton of errors. ```Updating Homebrew...; ==> Downloading https://github.com/broadgsa/gatk-protected/archive/3.8-1.tar.gz; Already downloaded: /Users/timothystiles/Library/Caches/Homebrew/gatk-3.8-1.tar.gz; ==> mvn package -Dmaven.repo.local=${PWD}/repo; Last 15 lines from /Users/timothystiles/Library/Logs/Homebrew/gatk/01.mvn:; [INFO] Scanning for projects...; [ERROR] [ERROR] Some problems were encountered while processing the POMs:; [FATAL] Non-parseable POM /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml, line 15, column 3; @; [ERROR] The build could not read 1 project -> [Help 1]; [ERROR]; [ERROR] The project org.broadinstitute.gatk:gatk-aggregator:[unknown-version] (/private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/pom.xml) has 1 error; [ERROR] Non-parseable POM /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml, line 15, column 3 -> [Help 2]; [ERROR]; [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.; [ERROR] Re-run Maven using the -X switch to enable full debug logging.; [ERROR]; [ERROR] For more information about the errors and possible solutions, please read the following articles:; [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/ProjectBuildingException; [ERROR] [Help 2] http://cwiki.apache.org/confluence/display",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4164#issuecomment-358697586
https://github.com/broadinstitute/gatk/issues/4164#issuecomment-358697586:634,Availability,ERROR,ERROR,634,"It looks like at one point GATK 3.8 was available via the [homebrew science tap](https://github.com/ilovezfs/homebrew-science/blob/master/gatk.rb). I've tried adding their formula to my homebrew formula folder and installing via ``` brew install gatk.rb``` but there's a ton of errors. ```Updating Homebrew...; ==> Downloading https://github.com/broadgsa/gatk-protected/archive/3.8-1.tar.gz; Already downloaded: /Users/timothystiles/Library/Caches/Homebrew/gatk-3.8-1.tar.gz; ==> mvn package -Dmaven.repo.local=${PWD}/repo; Last 15 lines from /Users/timothystiles/Library/Logs/Homebrew/gatk/01.mvn:; [INFO] Scanning for projects...; [ERROR] [ERROR] Some problems were encountered while processing the POMs:; [FATAL] Non-parseable POM /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml, line 15, column 3; @; [ERROR] The build could not read 1 project -> [Help 1]; [ERROR]; [ERROR] The project org.broadinstitute.gatk:gatk-aggregator:[unknown-version] (/private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/pom.xml) has 1 error; [ERROR] Non-parseable POM /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml, line 15, column 3 -> [Help 2]; [ERROR]; [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.; [ERROR] Re-run Maven using the -X switch to enable full debug logging.; [ERROR]; [ERROR] For more information about the errors and possible solutions, please read the following articles:; [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/ProjectBuildingException; [ERROR] [Help 2] http://cwiki.apache.org/confluence/display",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4164#issuecomment-358697586
https://github.com/broadinstitute/gatk/issues/4164#issuecomment-358697586:642,Availability,ERROR,ERROR,642,"It looks like at one point GATK 3.8 was available via the [homebrew science tap](https://github.com/ilovezfs/homebrew-science/blob/master/gatk.rb). I've tried adding their formula to my homebrew formula folder and installing via ``` brew install gatk.rb``` but there's a ton of errors. ```Updating Homebrew...; ==> Downloading https://github.com/broadgsa/gatk-protected/archive/3.8-1.tar.gz; Already downloaded: /Users/timothystiles/Library/Caches/Homebrew/gatk-3.8-1.tar.gz; ==> mvn package -Dmaven.repo.local=${PWD}/repo; Last 15 lines from /Users/timothystiles/Library/Logs/Homebrew/gatk/01.mvn:; [INFO] Scanning for projects...; [ERROR] [ERROR] Some problems were encountered while processing the POMs:; [FATAL] Non-parseable POM /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml, line 15, column 3; @; [ERROR] The build could not read 1 project -> [Help 1]; [ERROR]; [ERROR] The project org.broadinstitute.gatk:gatk-aggregator:[unknown-version] (/private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/pom.xml) has 1 error; [ERROR] Non-parseable POM /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml, line 15, column 3 -> [Help 2]; [ERROR]; [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.; [ERROR] Re-run Maven using the -X switch to enable full debug logging.; [ERROR]; [ERROR] For more information about the errors and possible solutions, please read the following articles:; [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/ProjectBuildingException; [ERROR] [Help 2] http://cwiki.apache.org/confluence/display",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4164#issuecomment-358697586
https://github.com/broadinstitute/gatk/issues/4164#issuecomment-358697586:1021,Availability,ERROR,ERROR,1021,"ia the [homebrew science tap](https://github.com/ilovezfs/homebrew-science/blob/master/gatk.rb). I've tried adding their formula to my homebrew formula folder and installing via ``` brew install gatk.rb``` but there's a ton of errors. ```Updating Homebrew...; ==> Downloading https://github.com/broadgsa/gatk-protected/archive/3.8-1.tar.gz; Already downloaded: /Users/timothystiles/Library/Caches/Homebrew/gatk-3.8-1.tar.gz; ==> mvn package -Dmaven.repo.local=${PWD}/repo; Last 15 lines from /Users/timothystiles/Library/Logs/Homebrew/gatk/01.mvn:; [INFO] Scanning for projects...; [ERROR] [ERROR] Some problems were encountered while processing the POMs:; [FATAL] Non-parseable POM /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml, line 15, column 3; @; [ERROR] The build could not read 1 project -> [Help 1]; [ERROR]; [ERROR] The project org.broadinstitute.gatk:gatk-aggregator:[unknown-version] (/private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/pom.xml) has 1 error; [ERROR] Non-parseable POM /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml, line 15, column 3 -> [Help 2]; [ERROR]; [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.; [ERROR] Re-run Maven using the -X switch to enable full debug logging.; [ERROR]; [ERROR] For more information about the errors and possible solutions, please read the following articles:; [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/ProjectBuildingException; [ERROR] [Help 2] http://cwiki.apache.org/confluence/display/MAVEN/ModelParseException. READ THIS: https://doc",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4164#issuecomment-358697586
https://github.com/broadinstitute/gatk/issues/4164#issuecomment-358697586:1077,Availability,ERROR,ERROR,1077,"ia the [homebrew science tap](https://github.com/ilovezfs/homebrew-science/blob/master/gatk.rb). I've tried adding their formula to my homebrew formula folder and installing via ``` brew install gatk.rb``` but there's a ton of errors. ```Updating Homebrew...; ==> Downloading https://github.com/broadgsa/gatk-protected/archive/3.8-1.tar.gz; Already downloaded: /Users/timothystiles/Library/Caches/Homebrew/gatk-3.8-1.tar.gz; ==> mvn package -Dmaven.repo.local=${PWD}/repo; Last 15 lines from /Users/timothystiles/Library/Logs/Homebrew/gatk/01.mvn:; [INFO] Scanning for projects...; [ERROR] [ERROR] Some problems were encountered while processing the POMs:; [FATAL] Non-parseable POM /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml, line 15, column 3; @; [ERROR] The build could not read 1 project -> [Help 1]; [ERROR]; [ERROR] The project org.broadinstitute.gatk:gatk-aggregator:[unknown-version] (/private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/pom.xml) has 1 error; [ERROR] Non-parseable POM /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml, line 15, column 3 -> [Help 2]; [ERROR]; [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.; [ERROR] Re-run Maven using the -X switch to enable full debug logging.; [ERROR]; [ERROR] For more information about the errors and possible solutions, please read the following articles:; [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/ProjectBuildingException; [ERROR] [Help 2] http://cwiki.apache.org/confluence/display/MAVEN/ModelParseException. READ THIS: https://doc",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4164#issuecomment-358697586
https://github.com/broadinstitute/gatk/issues/4164#issuecomment-358697586:1086,Availability,ERROR,ERROR,1086,"ia the [homebrew science tap](https://github.com/ilovezfs/homebrew-science/blob/master/gatk.rb). I've tried adding their formula to my homebrew formula folder and installing via ``` brew install gatk.rb``` but there's a ton of errors. ```Updating Homebrew...; ==> Downloading https://github.com/broadgsa/gatk-protected/archive/3.8-1.tar.gz; Already downloaded: /Users/timothystiles/Library/Caches/Homebrew/gatk-3.8-1.tar.gz; ==> mvn package -Dmaven.repo.local=${PWD}/repo; Last 15 lines from /Users/timothystiles/Library/Logs/Homebrew/gatk/01.mvn:; [INFO] Scanning for projects...; [ERROR] [ERROR] Some problems were encountered while processing the POMs:; [FATAL] Non-parseable POM /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml, line 15, column 3; @; [ERROR] The build could not read 1 project -> [Help 1]; [ERROR]; [ERROR] The project org.broadinstitute.gatk:gatk-aggregator:[unknown-version] (/private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/pom.xml) has 1 error; [ERROR] Non-parseable POM /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml, line 15, column 3 -> [Help 2]; [ERROR]; [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.; [ERROR] Re-run Maven using the -X switch to enable full debug logging.; [ERROR]; [ERROR] For more information about the errors and possible solutions, please read the following articles:; [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/ProjectBuildingException; [ERROR] [Help 2] http://cwiki.apache.org/confluence/display/MAVEN/ModelParseException. READ THIS: https://doc",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4164#issuecomment-358697586
https://github.com/broadinstitute/gatk/issues/4164#issuecomment-358697586:1240,Availability,error,error,1240,"w formula folder and installing via ``` brew install gatk.rb``` but there's a ton of errors. ```Updating Homebrew...; ==> Downloading https://github.com/broadgsa/gatk-protected/archive/3.8-1.tar.gz; Already downloaded: /Users/timothystiles/Library/Caches/Homebrew/gatk-3.8-1.tar.gz; ==> mvn package -Dmaven.repo.local=${PWD}/repo; Last 15 lines from /Users/timothystiles/Library/Logs/Homebrew/gatk/01.mvn:; [INFO] Scanning for projects...; [ERROR] [ERROR] Some problems were encountered while processing the POMs:; [FATAL] Non-parseable POM /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml, line 15, column 3; @; [ERROR] The build could not read 1 project -> [Help 1]; [ERROR]; [ERROR] The project org.broadinstitute.gatk:gatk-aggregator:[unknown-version] (/private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/pom.xml) has 1 error; [ERROR] Non-parseable POM /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml, line 15, column 3 -> [Help 2]; [ERROR]; [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.; [ERROR] Re-run Maven using the -X switch to enable full debug logging.; [ERROR]; [ERROR] For more information about the errors and possible solutions, please read the following articles:; [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/ProjectBuildingException; [ERROR] [Help 2] http://cwiki.apache.org/confluence/display/MAVEN/ModelParseException. READ THIS: https://docs.brew.sh/Troubleshooting.html. Error: A newer Command Line Tools release is available.; Update them from Software Update in the App Store.```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4164#issuecomment-358697586
https://github.com/broadinstitute/gatk/issues/4164#issuecomment-358697586:1248,Availability,ERROR,ERROR,1248,"w formula folder and installing via ``` brew install gatk.rb``` but there's a ton of errors. ```Updating Homebrew...; ==> Downloading https://github.com/broadgsa/gatk-protected/archive/3.8-1.tar.gz; Already downloaded: /Users/timothystiles/Library/Caches/Homebrew/gatk-3.8-1.tar.gz; ==> mvn package -Dmaven.repo.local=${PWD}/repo; Last 15 lines from /Users/timothystiles/Library/Logs/Homebrew/gatk/01.mvn:; [INFO] Scanning for projects...; [ERROR] [ERROR] Some problems were encountered while processing the POMs:; [FATAL] Non-parseable POM /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml, line 15, column 3; @; [ERROR] The build could not read 1 project -> [Help 1]; [ERROR]; [ERROR] The project org.broadinstitute.gatk:gatk-aggregator:[unknown-version] (/private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/pom.xml) has 1 error; [ERROR] Non-parseable POM /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml, line 15, column 3 -> [Help 2]; [ERROR]; [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.; [ERROR] Re-run Maven using the -X switch to enable full debug logging.; [ERROR]; [ERROR] For more information about the errors and possible solutions, please read the following articles:; [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/ProjectBuildingException; [ERROR] [Help 2] http://cwiki.apache.org/confluence/display/MAVEN/ModelParseException. READ THIS: https://docs.brew.sh/Troubleshooting.html. Error: A newer Command Line Tools release is available.; Update them from Software Update in the App Store.```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4164#issuecomment-358697586
https://github.com/broadinstitute/gatk/issues/4164#issuecomment-358697586:1569,Availability,ERROR,ERROR,1569,"w formula folder and installing via ``` brew install gatk.rb``` but there's a ton of errors. ```Updating Homebrew...; ==> Downloading https://github.com/broadgsa/gatk-protected/archive/3.8-1.tar.gz; Already downloaded: /Users/timothystiles/Library/Caches/Homebrew/gatk-3.8-1.tar.gz; ==> mvn package -Dmaven.repo.local=${PWD}/repo; Last 15 lines from /Users/timothystiles/Library/Logs/Homebrew/gatk/01.mvn:; [INFO] Scanning for projects...; [ERROR] [ERROR] Some problems were encountered while processing the POMs:; [FATAL] Non-parseable POM /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml, line 15, column 3; @; [ERROR] The build could not read 1 project -> [Help 1]; [ERROR]; [ERROR] The project org.broadinstitute.gatk:gatk-aggregator:[unknown-version] (/private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/pom.xml) has 1 error; [ERROR] Non-parseable POM /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml, line 15, column 3 -> [Help 2]; [ERROR]; [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.; [ERROR] Re-run Maven using the -X switch to enable full debug logging.; [ERROR]; [ERROR] For more information about the errors and possible solutions, please read the following articles:; [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/ProjectBuildingException; [ERROR] [Help 2] http://cwiki.apache.org/confluence/display/MAVEN/ModelParseException. READ THIS: https://docs.brew.sh/Troubleshooting.html. Error: A newer Command Line Tools release is available.; Update them from Software Update in the App Store.```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4164#issuecomment-358697586
https://github.com/broadinstitute/gatk/issues/4164#issuecomment-358697586:1578,Availability,ERROR,ERROR,1578,"w formula folder and installing via ``` brew install gatk.rb``` but there's a ton of errors. ```Updating Homebrew...; ==> Downloading https://github.com/broadgsa/gatk-protected/archive/3.8-1.tar.gz; Already downloaded: /Users/timothystiles/Library/Caches/Homebrew/gatk-3.8-1.tar.gz; ==> mvn package -Dmaven.repo.local=${PWD}/repo; Last 15 lines from /Users/timothystiles/Library/Logs/Homebrew/gatk/01.mvn:; [INFO] Scanning for projects...; [ERROR] [ERROR] Some problems were encountered while processing the POMs:; [FATAL] Non-parseable POM /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml, line 15, column 3; @; [ERROR] The build could not read 1 project -> [Help 1]; [ERROR]; [ERROR] The project org.broadinstitute.gatk:gatk-aggregator:[unknown-version] (/private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/pom.xml) has 1 error; [ERROR] Non-parseable POM /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml, line 15, column 3 -> [Help 2]; [ERROR]; [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.; [ERROR] Re-run Maven using the -X switch to enable full debug logging.; [ERROR]; [ERROR] For more information about the errors and possible solutions, please read the following articles:; [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/ProjectBuildingException; [ERROR] [Help 2] http://cwiki.apache.org/confluence/display/MAVEN/ModelParseException. READ THIS: https://docs.brew.sh/Troubleshooting.html. Error: A newer Command Line Tools release is available.; Update them from Software Update in the App Store.```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4164#issuecomment-358697586
https://github.com/broadinstitute/gatk/issues/4164#issuecomment-358697586:1620,Availability,error,errors,1620,"w formula folder and installing via ``` brew install gatk.rb``` but there's a ton of errors. ```Updating Homebrew...; ==> Downloading https://github.com/broadgsa/gatk-protected/archive/3.8-1.tar.gz; Already downloaded: /Users/timothystiles/Library/Caches/Homebrew/gatk-3.8-1.tar.gz; ==> mvn package -Dmaven.repo.local=${PWD}/repo; Last 15 lines from /Users/timothystiles/Library/Logs/Homebrew/gatk/01.mvn:; [INFO] Scanning for projects...; [ERROR] [ERROR] Some problems were encountered while processing the POMs:; [FATAL] Non-parseable POM /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml, line 15, column 3; @; [ERROR] The build could not read 1 project -> [Help 1]; [ERROR]; [ERROR] The project org.broadinstitute.gatk:gatk-aggregator:[unknown-version] (/private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/pom.xml) has 1 error; [ERROR] Non-parseable POM /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml, line 15, column 3 -> [Help 2]; [ERROR]; [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.; [ERROR] Re-run Maven using the -X switch to enable full debug logging.; [ERROR]; [ERROR] For more information about the errors and possible solutions, please read the following articles:; [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/ProjectBuildingException; [ERROR] [Help 2] http://cwiki.apache.org/confluence/display/MAVEN/ModelParseException. READ THIS: https://docs.brew.sh/Troubleshooting.html. Error: A newer Command Line Tools release is available.; Update them from Software Update in the App Store.```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4164#issuecomment-358697586
https://github.com/broadinstitute/gatk/issues/4164#issuecomment-358697586:1663,Availability,ERROR,ERROR,1663,"w formula folder and installing via ``` brew install gatk.rb``` but there's a ton of errors. ```Updating Homebrew...; ==> Downloading https://github.com/broadgsa/gatk-protected/archive/3.8-1.tar.gz; Already downloaded: /Users/timothystiles/Library/Caches/Homebrew/gatk-3.8-1.tar.gz; ==> mvn package -Dmaven.repo.local=${PWD}/repo; Last 15 lines from /Users/timothystiles/Library/Logs/Homebrew/gatk/01.mvn:; [INFO] Scanning for projects...; [ERROR] [ERROR] Some problems were encountered while processing the POMs:; [FATAL] Non-parseable POM /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml, line 15, column 3; @; [ERROR] The build could not read 1 project -> [Help 1]; [ERROR]; [ERROR] The project org.broadinstitute.gatk:gatk-aggregator:[unknown-version] (/private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/pom.xml) has 1 error; [ERROR] Non-parseable POM /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml, line 15, column 3 -> [Help 2]; [ERROR]; [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.; [ERROR] Re-run Maven using the -X switch to enable full debug logging.; [ERROR]; [ERROR] For more information about the errors and possible solutions, please read the following articles:; [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/ProjectBuildingException; [ERROR] [Help 2] http://cwiki.apache.org/confluence/display/MAVEN/ModelParseException. READ THIS: https://docs.brew.sh/Troubleshooting.html. Error: A newer Command Line Tools release is available.; Update them from Software Update in the App Store.```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4164#issuecomment-358697586
https://github.com/broadinstitute/gatk/issues/4164#issuecomment-358697586:1735,Availability,ERROR,ERROR,1735,"w formula folder and installing via ``` brew install gatk.rb``` but there's a ton of errors. ```Updating Homebrew...; ==> Downloading https://github.com/broadgsa/gatk-protected/archive/3.8-1.tar.gz; Already downloaded: /Users/timothystiles/Library/Caches/Homebrew/gatk-3.8-1.tar.gz; ==> mvn package -Dmaven.repo.local=${PWD}/repo; Last 15 lines from /Users/timothystiles/Library/Logs/Homebrew/gatk/01.mvn:; [INFO] Scanning for projects...; [ERROR] [ERROR] Some problems were encountered while processing the POMs:; [FATAL] Non-parseable POM /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml, line 15, column 3; @; [ERROR] The build could not read 1 project -> [Help 1]; [ERROR]; [ERROR] The project org.broadinstitute.gatk:gatk-aggregator:[unknown-version] (/private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/pom.xml) has 1 error; [ERROR] Non-parseable POM /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml, line 15, column 3 -> [Help 2]; [ERROR]; [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.; [ERROR] Re-run Maven using the -X switch to enable full debug logging.; [ERROR]; [ERROR] For more information about the errors and possible solutions, please read the following articles:; [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/ProjectBuildingException; [ERROR] [Help 2] http://cwiki.apache.org/confluence/display/MAVEN/ModelParseException. READ THIS: https://docs.brew.sh/Troubleshooting.html. Error: A newer Command Line Tools release is available.; Update them from Software Update in the App Store.```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4164#issuecomment-358697586
https://github.com/broadinstitute/gatk/issues/4164#issuecomment-358697586:1744,Availability,ERROR,ERROR,1744,"w formula folder and installing via ``` brew install gatk.rb``` but there's a ton of errors. ```Updating Homebrew...; ==> Downloading https://github.com/broadgsa/gatk-protected/archive/3.8-1.tar.gz; Already downloaded: /Users/timothystiles/Library/Caches/Homebrew/gatk-3.8-1.tar.gz; ==> mvn package -Dmaven.repo.local=${PWD}/repo; Last 15 lines from /Users/timothystiles/Library/Logs/Homebrew/gatk/01.mvn:; [INFO] Scanning for projects...; [ERROR] [ERROR] Some problems were encountered while processing the POMs:; [FATAL] Non-parseable POM /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml, line 15, column 3; @; [ERROR] The build could not read 1 project -> [Help 1]; [ERROR]; [ERROR] The project org.broadinstitute.gatk:gatk-aggregator:[unknown-version] (/private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/pom.xml) has 1 error; [ERROR] Non-parseable POM /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml, line 15, column 3 -> [Help 2]; [ERROR]; [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.; [ERROR] Re-run Maven using the -X switch to enable full debug logging.; [ERROR]; [ERROR] For more information about the errors and possible solutions, please read the following articles:; [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/ProjectBuildingException; [ERROR] [Help 2] http://cwiki.apache.org/confluence/display/MAVEN/ModelParseException. READ THIS: https://docs.brew.sh/Troubleshooting.html. Error: A newer Command Line Tools release is available.; Update them from Software Update in the App Store.```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4164#issuecomment-358697586
https://github.com/broadinstitute/gatk/issues/4164#issuecomment-358697586:1782,Availability,error,errors,1782,"w formula folder and installing via ``` brew install gatk.rb``` but there's a ton of errors. ```Updating Homebrew...; ==> Downloading https://github.com/broadgsa/gatk-protected/archive/3.8-1.tar.gz; Already downloaded: /Users/timothystiles/Library/Caches/Homebrew/gatk-3.8-1.tar.gz; ==> mvn package -Dmaven.repo.local=${PWD}/repo; Last 15 lines from /Users/timothystiles/Library/Logs/Homebrew/gatk/01.mvn:; [INFO] Scanning for projects...; [ERROR] [ERROR] Some problems were encountered while processing the POMs:; [FATAL] Non-parseable POM /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml, line 15, column 3; @; [ERROR] The build could not read 1 project -> [Help 1]; [ERROR]; [ERROR] The project org.broadinstitute.gatk:gatk-aggregator:[unknown-version] (/private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/pom.xml) has 1 error; [ERROR] Non-parseable POM /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml, line 15, column 3 -> [Help 2]; [ERROR]; [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.; [ERROR] Re-run Maven using the -X switch to enable full debug logging.; [ERROR]; [ERROR] For more information about the errors and possible solutions, please read the following articles:; [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/ProjectBuildingException; [ERROR] [Help 2] http://cwiki.apache.org/confluence/display/MAVEN/ModelParseException. READ THIS: https://docs.brew.sh/Troubleshooting.html. Error: A newer Command Line Tools release is available.; Update them from Software Update in the App Store.```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4164#issuecomment-358697586
https://github.com/broadinstitute/gatk/issues/4164#issuecomment-358697586:1851,Availability,ERROR,ERROR,1851,"w formula folder and installing via ``` brew install gatk.rb``` but there's a ton of errors. ```Updating Homebrew...; ==> Downloading https://github.com/broadgsa/gatk-protected/archive/3.8-1.tar.gz; Already downloaded: /Users/timothystiles/Library/Caches/Homebrew/gatk-3.8-1.tar.gz; ==> mvn package -Dmaven.repo.local=${PWD}/repo; Last 15 lines from /Users/timothystiles/Library/Logs/Homebrew/gatk/01.mvn:; [INFO] Scanning for projects...; [ERROR] [ERROR] Some problems were encountered while processing the POMs:; [FATAL] Non-parseable POM /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml, line 15, column 3; @; [ERROR] The build could not read 1 project -> [Help 1]; [ERROR]; [ERROR] The project org.broadinstitute.gatk:gatk-aggregator:[unknown-version] (/private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/pom.xml) has 1 error; [ERROR] Non-parseable POM /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml, line 15, column 3 -> [Help 2]; [ERROR]; [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.; [ERROR] Re-run Maven using the -X switch to enable full debug logging.; [ERROR]; [ERROR] For more information about the errors and possible solutions, please read the following articles:; [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/ProjectBuildingException; [ERROR] [Help 2] http://cwiki.apache.org/confluence/display/MAVEN/ModelParseException. READ THIS: https://docs.brew.sh/Troubleshooting.html. Error: A newer Command Line Tools release is available.; Update them from Software Update in the App Store.```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4164#issuecomment-358697586
https://github.com/broadinstitute/gatk/issues/4164#issuecomment-358697586:1943,Availability,ERROR,ERROR,1943,"w formula folder and installing via ``` brew install gatk.rb``` but there's a ton of errors. ```Updating Homebrew...; ==> Downloading https://github.com/broadgsa/gatk-protected/archive/3.8-1.tar.gz; Already downloaded: /Users/timothystiles/Library/Caches/Homebrew/gatk-3.8-1.tar.gz; ==> mvn package -Dmaven.repo.local=${PWD}/repo; Last 15 lines from /Users/timothystiles/Library/Logs/Homebrew/gatk/01.mvn:; [INFO] Scanning for projects...; [ERROR] [ERROR] Some problems were encountered while processing the POMs:; [FATAL] Non-parseable POM /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml, line 15, column 3; @; [ERROR] The build could not read 1 project -> [Help 1]; [ERROR]; [ERROR] The project org.broadinstitute.gatk:gatk-aggregator:[unknown-version] (/private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/pom.xml) has 1 error; [ERROR] Non-parseable POM /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml, line 15, column 3 -> [Help 2]; [ERROR]; [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.; [ERROR] Re-run Maven using the -X switch to enable full debug logging.; [ERROR]; [ERROR] For more information about the errors and possible solutions, please read the following articles:; [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/ProjectBuildingException; [ERROR] [Help 2] http://cwiki.apache.org/confluence/display/MAVEN/ModelParseException. READ THIS: https://docs.brew.sh/Troubleshooting.html. Error: A newer Command Line Tools release is available.; Update them from Software Update in the App Store.```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4164#issuecomment-358697586
https://github.com/broadinstitute/gatk/issues/4164#issuecomment-358697586:2083,Availability,Error,Error,2083,"w formula folder and installing via ``` brew install gatk.rb``` but there's a ton of errors. ```Updating Homebrew...; ==> Downloading https://github.com/broadgsa/gatk-protected/archive/3.8-1.tar.gz; Already downloaded: /Users/timothystiles/Library/Caches/Homebrew/gatk-3.8-1.tar.gz; ==> mvn package -Dmaven.repo.local=${PWD}/repo; Last 15 lines from /Users/timothystiles/Library/Logs/Homebrew/gatk/01.mvn:; [INFO] Scanning for projects...; [ERROR] [ERROR] Some problems were encountered while processing the POMs:; [FATAL] Non-parseable POM /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml, line 15, column 3; @; [ERROR] The build could not read 1 project -> [Help 1]; [ERROR]; [ERROR] The project org.broadinstitute.gatk:gatk-aggregator:[unknown-version] (/private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/pom.xml) has 1 error; [ERROR] Non-parseable POM /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml, line 15, column 3 -> [Help 2]; [ERROR]; [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.; [ERROR] Re-run Maven using the -X switch to enable full debug logging.; [ERROR]; [ERROR] For more information about the errors and possible solutions, please read the following articles:; [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/ProjectBuildingException; [ERROR] [Help 2] http://cwiki.apache.org/confluence/display/MAVEN/ModelParseException. READ THIS: https://docs.brew.sh/Troubleshooting.html. Error: A newer Command Line Tools release is available.; Update them from Software Update in the App Store.```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4164#issuecomment-358697586
https://github.com/broadinstitute/gatk/issues/4164#issuecomment-358697586:2128,Availability,avail,available,2128,"w formula folder and installing via ``` brew install gatk.rb``` but there's a ton of errors. ```Updating Homebrew...; ==> Downloading https://github.com/broadgsa/gatk-protected/archive/3.8-1.tar.gz; Already downloaded: /Users/timothystiles/Library/Caches/Homebrew/gatk-3.8-1.tar.gz; ==> mvn package -Dmaven.repo.local=${PWD}/repo; Last 15 lines from /Users/timothystiles/Library/Logs/Homebrew/gatk/01.mvn:; [INFO] Scanning for projects...; [ERROR] [ERROR] Some problems were encountered while processing the POMs:; [FATAL] Non-parseable POM /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml, line 15, column 3; @; [ERROR] The build could not read 1 project -> [Help 1]; [ERROR]; [ERROR] The project org.broadinstitute.gatk:gatk-aggregator:[unknown-version] (/private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/pom.xml) has 1 error; [ERROR] Non-parseable POM /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml, line 15, column 3 -> [Help 2]; [ERROR]; [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.; [ERROR] Re-run Maven using the -X switch to enable full debug logging.; [ERROR]; [ERROR] For more information about the errors and possible solutions, please read the following articles:; [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/ProjectBuildingException; [ERROR] [Help 2] http://cwiki.apache.org/confluence/display/MAVEN/ModelParseException. READ THIS: https://docs.brew.sh/Troubleshooting.html. Error: A newer Command Line Tools release is available.; Update them from Software Update in the App Store.```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4164#issuecomment-358697586
https://github.com/broadinstitute/gatk/issues/4164#issuecomment-358697586:214,Deployability,install,installing,214,"It looks like at one point GATK 3.8 was available via the [homebrew science tap](https://github.com/ilovezfs/homebrew-science/blob/master/gatk.rb). I've tried adding their formula to my homebrew formula folder and installing via ``` brew install gatk.rb``` but there's a ton of errors. ```Updating Homebrew...; ==> Downloading https://github.com/broadgsa/gatk-protected/archive/3.8-1.tar.gz; Already downloaded: /Users/timothystiles/Library/Caches/Homebrew/gatk-3.8-1.tar.gz; ==> mvn package -Dmaven.repo.local=${PWD}/repo; Last 15 lines from /Users/timothystiles/Library/Logs/Homebrew/gatk/01.mvn:; [INFO] Scanning for projects...; [ERROR] [ERROR] Some problems were encountered while processing the POMs:; [FATAL] Non-parseable POM /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml, line 15, column 3; @; [ERROR] The build could not read 1 project -> [Help 1]; [ERROR]; [ERROR] The project org.broadinstitute.gatk:gatk-aggregator:[unknown-version] (/private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/pom.xml) has 1 error; [ERROR] Non-parseable POM /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml, line 15, column 3 -> [Help 2]; [ERROR]; [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.; [ERROR] Re-run Maven using the -X switch to enable full debug logging.; [ERROR]; [ERROR] For more information about the errors and possible solutions, please read the following articles:; [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/ProjectBuildingException; [ERROR] [Help 2] http://cwiki.apache.org/confluence/display",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4164#issuecomment-358697586
https://github.com/broadinstitute/gatk/issues/4164#issuecomment-358697586:238,Deployability,install,install,238,"It looks like at one point GATK 3.8 was available via the [homebrew science tap](https://github.com/ilovezfs/homebrew-science/blob/master/gatk.rb). I've tried adding their formula to my homebrew formula folder and installing via ``` brew install gatk.rb``` but there's a ton of errors. ```Updating Homebrew...; ==> Downloading https://github.com/broadgsa/gatk-protected/archive/3.8-1.tar.gz; Already downloaded: /Users/timothystiles/Library/Caches/Homebrew/gatk-3.8-1.tar.gz; ==> mvn package -Dmaven.repo.local=${PWD}/repo; Last 15 lines from /Users/timothystiles/Library/Logs/Homebrew/gatk/01.mvn:; [INFO] Scanning for projects...; [ERROR] [ERROR] Some problems were encountered while processing the POMs:; [FATAL] Non-parseable POM /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml, line 15, column 3; @; [ERROR] The build could not read 1 project -> [Help 1]; [ERROR]; [ERROR] The project org.broadinstitute.gatk:gatk-aggregator:[unknown-version] (/private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/pom.xml) has 1 error; [ERROR] Non-parseable POM /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml, line 15, column 3 -> [Help 2]; [ERROR]; [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.; [ERROR] Re-run Maven using the -X switch to enable full debug logging.; [ERROR]; [ERROR] For more information about the errors and possible solutions, please read the following articles:; [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/ProjectBuildingException; [ERROR] [Help 2] http://cwiki.apache.org/confluence/display",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4164#issuecomment-358697586
https://github.com/broadinstitute/gatk/issues/4164#issuecomment-358697586:2117,Deployability,release,release,2117,"w formula folder and installing via ``` brew install gatk.rb``` but there's a ton of errors. ```Updating Homebrew...; ==> Downloading https://github.com/broadgsa/gatk-protected/archive/3.8-1.tar.gz; Already downloaded: /Users/timothystiles/Library/Caches/Homebrew/gatk-3.8-1.tar.gz; ==> mvn package -Dmaven.repo.local=${PWD}/repo; Last 15 lines from /Users/timothystiles/Library/Logs/Homebrew/gatk/01.mvn:; [INFO] Scanning for projects...; [ERROR] [ERROR] Some problems were encountered while processing the POMs:; [FATAL] Non-parseable POM /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml, line 15, column 3; @; [ERROR] The build could not read 1 project -> [Help 1]; [ERROR]; [ERROR] The project org.broadinstitute.gatk:gatk-aggregator:[unknown-version] (/private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/pom.xml) has 1 error; [ERROR] Non-parseable POM /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml, line 15, column 3 -> [Help 2]; [ERROR]; [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.; [ERROR] Re-run Maven using the -X switch to enable full debug logging.; [ERROR]; [ERROR] For more information about the errors and possible solutions, please read the following articles:; [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/ProjectBuildingException; [ERROR] [Help 2] http://cwiki.apache.org/confluence/display/MAVEN/ModelParseException. READ THIS: https://docs.brew.sh/Troubleshooting.html. Error: A newer Command Line Tools release is available.; Update them from Software Update in the App Store.```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4164#issuecomment-358697586
https://github.com/broadinstitute/gatk/issues/4164#issuecomment-358697586:2140,Deployability,Update,Update,2140,"w formula folder and installing via ``` brew install gatk.rb``` but there's a ton of errors. ```Updating Homebrew...; ==> Downloading https://github.com/broadgsa/gatk-protected/archive/3.8-1.tar.gz; Already downloaded: /Users/timothystiles/Library/Caches/Homebrew/gatk-3.8-1.tar.gz; ==> mvn package -Dmaven.repo.local=${PWD}/repo; Last 15 lines from /Users/timothystiles/Library/Logs/Homebrew/gatk/01.mvn:; [INFO] Scanning for projects...; [ERROR] [ERROR] Some problems were encountered while processing the POMs:; [FATAL] Non-parseable POM /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml, line 15, column 3; @; [ERROR] The build could not read 1 project -> [Help 1]; [ERROR]; [ERROR] The project org.broadinstitute.gatk:gatk-aggregator:[unknown-version] (/private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/pom.xml) has 1 error; [ERROR] Non-parseable POM /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml, line 15, column 3 -> [Help 2]; [ERROR]; [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.; [ERROR] Re-run Maven using the -X switch to enable full debug logging.; [ERROR]; [ERROR] For more information about the errors and possible solutions, please read the following articles:; [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/ProjectBuildingException; [ERROR] [Help 2] http://cwiki.apache.org/confluence/display/MAVEN/ModelParseException. READ THIS: https://docs.brew.sh/Troubleshooting.html. Error: A newer Command Line Tools release is available.; Update them from Software Update in the App Store.```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4164#issuecomment-358697586
https://github.com/broadinstitute/gatk/issues/4164#issuecomment-358697586:2166,Deployability,Update,Update,2166,"w formula folder and installing via ``` brew install gatk.rb``` but there's a ton of errors. ```Updating Homebrew...; ==> Downloading https://github.com/broadgsa/gatk-protected/archive/3.8-1.tar.gz; Already downloaded: /Users/timothystiles/Library/Caches/Homebrew/gatk-3.8-1.tar.gz; ==> mvn package -Dmaven.repo.local=${PWD}/repo; Last 15 lines from /Users/timothystiles/Library/Logs/Homebrew/gatk/01.mvn:; [INFO] Scanning for projects...; [ERROR] [ERROR] Some problems were encountered while processing the POMs:; [FATAL] Non-parseable POM /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml, line 15, column 3; @; [ERROR] The build could not read 1 project -> [Help 1]; [ERROR]; [ERROR] The project org.broadinstitute.gatk:gatk-aggregator:[unknown-version] (/private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/pom.xml) has 1 error; [ERROR] Non-parseable POM /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml, line 15, column 3 -> [Help 2]; [ERROR]; [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.; [ERROR] Re-run Maven using the -X switch to enable full debug logging.; [ERROR]; [ERROR] For more information about the errors and possible solutions, please read the following articles:; [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/ProjectBuildingException; [ERROR] [Help 2] http://cwiki.apache.org/confluence/display/MAVEN/ModelParseException. READ THIS: https://docs.brew.sh/Troubleshooting.html. Error: A newer Command Line Tools release is available.; Update them from Software Update in the App Store.```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4164#issuecomment-358697586
https://github.com/broadinstitute/gatk/issues/4164#issuecomment-358697586:441,Performance,Cache,Caches,441,"It looks like at one point GATK 3.8 was available via the [homebrew science tap](https://github.com/ilovezfs/homebrew-science/blob/master/gatk.rb). I've tried adding their formula to my homebrew formula folder and installing via ``` brew install gatk.rb``` but there's a ton of errors. ```Updating Homebrew...; ==> Downloading https://github.com/broadgsa/gatk-protected/archive/3.8-1.tar.gz; Already downloaded: /Users/timothystiles/Library/Caches/Homebrew/gatk-3.8-1.tar.gz; ==> mvn package -Dmaven.repo.local=${PWD}/repo; Last 15 lines from /Users/timothystiles/Library/Logs/Homebrew/gatk/01.mvn:; [INFO] Scanning for projects...; [ERROR] [ERROR] Some problems were encountered while processing the POMs:; [FATAL] Non-parseable POM /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml, line 15, column 3; @; [ERROR] The build could not read 1 project -> [Help 1]; [ERROR]; [ERROR] The project org.broadinstitute.gatk:gatk-aggregator:[unknown-version] (/private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/pom.xml) has 1 error; [ERROR] Non-parseable POM /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml, line 15, column 3 -> [Help 2]; [ERROR]; [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.; [ERROR] Re-run Maven using the -X switch to enable full debug logging.; [ERROR]; [ERROR] For more information about the errors and possible solutions, please read the following articles:; [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/ProjectBuildingException; [ERROR] [Help 2] http://cwiki.apache.org/confluence/display",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4164#issuecomment-358697586
https://github.com/broadinstitute/gatk/issues/4164#issuecomment-358697586:572,Testability,Log,Logs,572,"It looks like at one point GATK 3.8 was available via the [homebrew science tap](https://github.com/ilovezfs/homebrew-science/blob/master/gatk.rb). I've tried adding their formula to my homebrew formula folder and installing via ``` brew install gatk.rb``` but there's a ton of errors. ```Updating Homebrew...; ==> Downloading https://github.com/broadgsa/gatk-protected/archive/3.8-1.tar.gz; Already downloaded: /Users/timothystiles/Library/Caches/Homebrew/gatk-3.8-1.tar.gz; ==> mvn package -Dmaven.repo.local=${PWD}/repo; Last 15 lines from /Users/timothystiles/Library/Logs/Homebrew/gatk/01.mvn:; [INFO] Scanning for projects...; [ERROR] [ERROR] Some problems were encountered while processing the POMs:; [FATAL] Non-parseable POM /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml, line 15, column 3; @; [ERROR] The build could not read 1 project -> [Help 1]; [ERROR]; [ERROR] The project org.broadinstitute.gatk:gatk-aggregator:[unknown-version] (/private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/pom.xml) has 1 error; [ERROR] Non-parseable POM /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml, line 15, column 3 -> [Help 2]; [ERROR]; [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.; [ERROR] Re-run Maven using the -X switch to enable full debug logging.; [ERROR]; [ERROR] For more information about the errors and possible solutions, please read the following articles:; [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/ProjectBuildingException; [ERROR] [Help 2] http://cwiki.apache.org/confluence/display",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4164#issuecomment-358697586
https://github.com/broadinstitute/gatk/issues/4164#issuecomment-358697586:1724,Testability,log,logging,1724,"w formula folder and installing via ``` brew install gatk.rb``` but there's a ton of errors. ```Updating Homebrew...; ==> Downloading https://github.com/broadgsa/gatk-protected/archive/3.8-1.tar.gz; Already downloaded: /Users/timothystiles/Library/Caches/Homebrew/gatk-3.8-1.tar.gz; ==> mvn package -Dmaven.repo.local=${PWD}/repo; Last 15 lines from /Users/timothystiles/Library/Logs/Homebrew/gatk/01.mvn:; [INFO] Scanning for projects...; [ERROR] [ERROR] Some problems were encountered while processing the POMs:; [FATAL] Non-parseable POM /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml, line 15, column 3; @; [ERROR] The build could not read 1 project -> [Help 1]; [ERROR]; [ERROR] The project org.broadinstitute.gatk:gatk-aggregator:[unknown-version] (/private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/pom.xml) has 1 error; [ERROR] Non-parseable POM /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml: unexpected character in markup < (position: END_TAG seen ...</artifactId>\n<<... @15:3) @ /private/tmp/gatk-20180118-71498-skz9cg/gatk-protected-3.8-1/public/gatk-root/pom.xml, line 15, column 3 -> [Help 2]; [ERROR]; [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.; [ERROR] Re-run Maven using the -X switch to enable full debug logging.; [ERROR]; [ERROR] For more information about the errors and possible solutions, please read the following articles:; [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/ProjectBuildingException; [ERROR] [Help 2] http://cwiki.apache.org/confluence/display/MAVEN/ModelParseException. READ THIS: https://docs.brew.sh/Troubleshooting.html. Error: A newer Command Line Tools release is available.; Update them from Software Update in the App Store.```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4164#issuecomment-358697586
https://github.com/broadinstitute/gatk/issues/4164#issuecomment-363218449:136,Deployability,release,release,136,"@TimothyStiles I never got back to you about this.. sorry! I think I pointed it out when we spoke in person, but there's a zip of every release attached to the release notes https://github.com/broadinstitute/gatk/releases",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4164#issuecomment-363218449
https://github.com/broadinstitute/gatk/issues/4164#issuecomment-363218449:160,Deployability,release,release,160,"@TimothyStiles I never got back to you about this.. sorry! I think I pointed it out when we spoke in person, but there's a zip of every release attached to the release notes https://github.com/broadinstitute/gatk/releases",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4164#issuecomment-363218449
https://github.com/broadinstitute/gatk/issues/4164#issuecomment-363218449:213,Deployability,release,releases,213,"@TimothyStiles I never got back to you about this.. sorry! I think I pointed it out when we spoke in person, but there's a zip of every release attached to the release notes https://github.com/broadinstitute/gatk/releases",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4164#issuecomment-363218449
https://github.com/broadinstitute/gatk/issues/4165#issuecomment-358055056:91,Deployability,toggle,toggle,91,"@lbergelson As discussed earlier today, that would be more awkward than the simple boolean toggle in the case of `-L`, since you really don't want to specify an alternate extension in that case, you just want to turn the expansion off completely.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4165#issuecomment-358055056
https://github.com/broadinstitute/gatk/issues/4165#issuecomment-358055056:76,Usability,simpl,simple,76,"@lbergelson As discussed earlier today, that would be more awkward than the simple boolean toggle in the case of `-L`, since you really don't want to specify an alternate extension in that case, you just want to turn the expansion off completely.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4165#issuecomment-358055056
https://github.com/broadinstitute/gatk/issues/4165#issuecomment-358058383:45,Deployability,toggle,toggle,45,I think I'm inclined towards just the simple toggle.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4165#issuecomment-358058383
https://github.com/broadinstitute/gatk/issues/4165#issuecomment-358058383:38,Usability,simpl,simple,38,I think I'm inclined towards just the simple toggle.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4165#issuecomment-358058383
https://github.com/broadinstitute/gatk/issues/4165#issuecomment-358058790:7,Deployability,toggle,toggle,7,"Simple toggle wins the day, by a vote of 2-1 :)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4165#issuecomment-358058790
https://github.com/broadinstitute/gatk/issues/4165#issuecomment-358058790:0,Usability,Simpl,Simple,0,"Simple toggle wins the day, by a vote of 2-1 :)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4165#issuecomment-358058790
https://github.com/broadinstitute/gatk/issues/4165#issuecomment-358475214:33,Deployability,toggle,toggle,33,"I suggest we start with just the toggle, since we have an immediate need for that. Finer-grained control can be addressed as part of the more general customization/delegation mechanism we've started in other PRs, and so clearly need.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4165#issuecomment-358475214
https://github.com/broadinstitute/gatk/issues/4165#issuecomment-358475214:220,Usability,clear,clearly,220,"I suggest we start with just the toggle, since we have an immediate need for that. Finer-grained control can be addressed as part of the more general customization/delegation mechanism we've started in other PRs, and so clearly need.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4165#issuecomment-358475214
https://github.com/broadinstitute/gatk/issues/4166#issuecomment-358264778:94,Integrability,interface,interface,94,"@lbergelson - regarding the single implementation of `GATKRead`, I would like to maintain the interface because I have some custom implementations. Although if it is true that HTSJDK will move to a version 3 based on interfaces, I can change my code to use the HTSJDK interfaces instead.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4166#issuecomment-358264778
https://github.com/broadinstitute/gatk/issues/4166#issuecomment-358264778:217,Integrability,interface,interfaces,217,"@lbergelson - regarding the single implementation of `GATKRead`, I would like to maintain the interface because I have some custom implementations. Although if it is true that HTSJDK will move to a version 3 based on interfaces, I can change my code to use the HTSJDK interfaces instead.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4166#issuecomment-358264778
https://github.com/broadinstitute/gatk/issues/4166#issuecomment-358264778:268,Integrability,interface,interfaces,268,"@lbergelson - regarding the single implementation of `GATKRead`, I would like to maintain the interface because I have some custom implementations. Although if it is true that HTSJDK will move to a version 3 based on interfaces, I can change my code to use the HTSJDK interfaces instead.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4166#issuecomment-358264778
https://github.com/broadinstitute/gatk/issues/4166#issuecomment-358325854:274,Energy Efficiency,adapt,adapter,274,"@magicDGS We will definitely be keeping the `GATKRead` interface around for the foreseeable future. When the HTSJDK 3.0 interfaces materialize we'll re-evaluate, but it's possible that we would continue to code against `GATKRead` even then, as our `SAMRecord` -> `GATKRead` adapter layer does some useful caching, and having our own interface has certain advantages (as well as disadvantages).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4166#issuecomment-358325854
https://github.com/broadinstitute/gatk/issues/4166#issuecomment-358325854:55,Integrability,interface,interface,55,"@magicDGS We will definitely be keeping the `GATKRead` interface around for the foreseeable future. When the HTSJDK 3.0 interfaces materialize we'll re-evaluate, but it's possible that we would continue to code against `GATKRead` even then, as our `SAMRecord` -> `GATKRead` adapter layer does some useful caching, and having our own interface has certain advantages (as well as disadvantages).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4166#issuecomment-358325854
https://github.com/broadinstitute/gatk/issues/4166#issuecomment-358325854:120,Integrability,interface,interfaces,120,"@magicDGS We will definitely be keeping the `GATKRead` interface around for the foreseeable future. When the HTSJDK 3.0 interfaces materialize we'll re-evaluate, but it's possible that we would continue to code against `GATKRead` even then, as our `SAMRecord` -> `GATKRead` adapter layer does some useful caching, and having our own interface has certain advantages (as well as disadvantages).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4166#issuecomment-358325854
https://github.com/broadinstitute/gatk/issues/4166#issuecomment-358325854:274,Integrability,adapter,adapter,274,"@magicDGS We will definitely be keeping the `GATKRead` interface around for the foreseeable future. When the HTSJDK 3.0 interfaces materialize we'll re-evaluate, but it's possible that we would continue to code against `GATKRead` even then, as our `SAMRecord` -> `GATKRead` adapter layer does some useful caching, and having our own interface has certain advantages (as well as disadvantages).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4166#issuecomment-358325854
https://github.com/broadinstitute/gatk/issues/4166#issuecomment-358325854:333,Integrability,interface,interface,333,"@magicDGS We will definitely be keeping the `GATKRead` interface around for the foreseeable future. When the HTSJDK 3.0 interfaces materialize we'll re-evaluate, but it's possible that we would continue to code against `GATKRead` even then, as our `SAMRecord` -> `GATKRead` adapter layer does some useful caching, and having our own interface has certain advantages (as well as disadvantages).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4166#issuecomment-358325854
https://github.com/broadinstitute/gatk/issues/4166#issuecomment-358325854:274,Modifiability,adapt,adapter,274,"@magicDGS We will definitely be keeping the `GATKRead` interface around for the foreseeable future. When the HTSJDK 3.0 interfaces materialize we'll re-evaluate, but it's possible that we would continue to code against `GATKRead` even then, as our `SAMRecord` -> `GATKRead` adapter layer does some useful caching, and having our own interface has certain advantages (as well as disadvantages).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4166#issuecomment-358325854
https://github.com/broadinstitute/gatk/pull/4167#issuecomment-358108007:34,Deployability,integrat,integration,34,@jamesemery Could you also add an integration test with the pipeline above? You'll need to run bash using `ProcessController` or similar,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4167#issuecomment-358108007
https://github.com/broadinstitute/gatk/pull/4167#issuecomment-358108007:60,Deployability,pipeline,pipeline,60,@jamesemery Could you also add an integration test with the pipeline above? You'll need to run bash using `ProcessController` or similar,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4167#issuecomment-358108007
https://github.com/broadinstitute/gatk/pull/4167#issuecomment-358108007:34,Integrability,integrat,integration,34,@jamesemery Could you also add an integration test with the pipeline above? You'll need to run bash using `ProcessController` or similar,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4167#issuecomment-358108007
https://github.com/broadinstitute/gatk/pull/4167#issuecomment-358108007:46,Testability,test,test,46,@jamesemery Could you also add an integration test with the pipeline above? You'll need to run bash using `ProcessController` or similar,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4167#issuecomment-358108007
https://github.com/broadinstitute/gatk/pull/4167#issuecomment-358339959:9,Deployability,Update,Updated,9,@droazen Updated the test so it's more stringent,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4167#issuecomment-358339959
https://github.com/broadinstitute/gatk/pull/4167#issuecomment-358339959:21,Testability,test,test,21,@droazen Updated the test so it's more stringent,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4167#issuecomment-358339959
https://github.com/broadinstitute/gatk/issues/4169#issuecomment-358079899:49,Testability,test,test,49,"This user is going to have to give us a runnable test case to reproduce this, as our own profiling shows that the 4.0 version of `HaplotypeCaller` is much faster than the later betas. You should also ask the user to try running with GATK3 and report the timing.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4169#issuecomment-358079899
https://github.com/broadinstitute/gatk/issues/4169#issuecomment-359944183:99,Performance,perform,performed,99,"Good news. User says this is no longer an issue:. `We found the reason why HaplotypeCaller 4.0.0.0 performed worse than 4.beta.2. We are scattering tools using intervals from a custom BED file. Before, each instance of HaplotypeCaller received a BAM file from ApplyBQSR that was produced using a specific interval, but not the interval itself. This worked for 4.beta.2, but was causing poor performance for 4.0.0.0. We now pass both the BAM and the interval to HaplotypeCaller 4.0.0.0 and it performs just as well as 4.beta.2 with the same amount of memory.`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4169#issuecomment-359944183
https://github.com/broadinstitute/gatk/issues/4169#issuecomment-359944183:391,Performance,perform,performance,391,"Good news. User says this is no longer an issue:. `We found the reason why HaplotypeCaller 4.0.0.0 performed worse than 4.beta.2. We are scattering tools using intervals from a custom BED file. Before, each instance of HaplotypeCaller received a BAM file from ApplyBQSR that was produced using a specific interval, but not the interval itself. This worked for 4.beta.2, but was causing poor performance for 4.0.0.0. We now pass both the BAM and the interval to HaplotypeCaller 4.0.0.0 and it performs just as well as 4.beta.2 with the same amount of memory.`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4169#issuecomment-359944183
https://github.com/broadinstitute/gatk/issues/4169#issuecomment-359944183:492,Performance,perform,performs,492,"Good news. User says this is no longer an issue:. `We found the reason why HaplotypeCaller 4.0.0.0 performed worse than 4.beta.2. We are scattering tools using intervals from a custom BED file. Before, each instance of HaplotypeCaller received a BAM file from ApplyBQSR that was produced using a specific interval, but not the interval itself. This worked for 4.beta.2, but was causing poor performance for 4.0.0.0. We now pass both the BAM and the interval to HaplotypeCaller 4.0.0.0 and it performs just as well as 4.beta.2 with the same amount of memory.`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4169#issuecomment-359944183
https://github.com/broadinstitute/gatk/issues/4169#issuecomment-359951577:208,Testability,log,logic,208,"Great, glad this mystery is solved!. It makes sense that running HC 4.0.0.0 without any intervals on a bam snippet would be slower than running without intervals in HC 4.beta.2, since HC 4.beta.2 lacked some logic that was present in GATK3 to handle uncovered loci.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4169#issuecomment-359951577
https://github.com/broadinstitute/gatk/issues/4170#issuecomment-459355056:204,Availability,avail,available,204,"@asmirnov239 has investigated clustering on Picard metrics, which he found to be informative. However, we've decided to go with clustering on coverage on a subset of bins, since this will be more readily available than the Picard metrics.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4170#issuecomment-459355056
https://github.com/broadinstitute/gatk/pull/4171#issuecomment-358451763:3561,Usability,Simpl,SimpleSVType,3561,31%)` | `3 <1> (ø)` | |; | [...ools/copynumber/DetermineGermlineContigPloidy.java](https://codecov.io/gh/broadinstitute/gatk/pull/4171/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL0RldGVybWluZUdlcm1saW5lQ29udGlnUGxvaWR5LmphdmE=) | `96.429% <100%> (+0.087%)` | `14 <1> (+1)` | :arrow_up: |; | [...hellbender/tools/copynumber/GermlineCNVCaller.java](https://codecov.io/gh/broadinstitute/gatk/pull/4171/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL0dlcm1saW5lQ05WQ2FsbGVyLmphdmE=) | `86.239% <100%> (+0.257%)` | `10 <1> (+1)` | :arrow_up: |; | [.../hellbender/utils/python/PythonScriptExecutor.java](https://codecov.io/gh/broadinstitute/gatk/pull/4171/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9weXRob24vUHl0aG9uU2NyaXB0RXhlY3V0b3IuamF2YQ==) | `63.636% <50%> (-1.07%)` | `10 <1> (+1)` | |; | [...er/tools/spark/sv/discovery/AlignmentInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/4171/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvQWxpZ25tZW50SW50ZXJ2YWwuamF2YQ==) | `88.889% <0%> (-0.383%)` | `72% <0%> (ø)` | |; | [...lbender/tools/spark/sv/discovery/SimpleSVType.java](https://codecov.io/gh/broadinstitute/gatk/pull/4171/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvU2ltcGxlU1ZUeXBlLmphdmE=) | `86.275% <0%> (-0.293%)` | `4% <0%> (+2%)` | |; | [.../sv/StructuralVariationDiscoveryPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4171/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9TdHJ1Y3R1cmFsVmFyaWF0aW9uRGlzY292ZXJ5UGlwZWxpbmVTcGFyay5qYXZh) | `91.351% <0%> (-0.158%)` | `15% <0%> (+7%)` | |; | ... and [38 more](https://codecov.io/gh/broadinstitute/gatk/pull/4171/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4171#issuecomment-358451763
https://github.com/broadinstitute/gatk/pull/4175#issuecomment-358271180:3112,Testability,test,test,3112,714% <100%> (+1.429%)` | `42 <0> (+2)` | :arrow_up: |; | [...er/tools/spark/sv/discovery/AlignmentInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/4175/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvQWxpZ25tZW50SW50ZXJ2YWwuamF2YQ==) | `89.272% <0%> (+0.383%)` | `73% <0%> (+1%)` | :arrow_up: |; | [...rg/broadinstitute/hellbender/utils/io/IOUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4175/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9pby9JT1V0aWxzLmphdmE=) | `61.616% <0%> (+1.01%)` | `50% <0%> (+1%)` | :arrow_up: |; | [...ender/utils/nio/SeekableByteChannelPrefetcher.java](https://codecov.io/gh/broadinstitute/gatk/pull/4175/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9uaW8vU2Vla2FibGVCeXRlQ2hhbm5lbFByZWZldGNoZXIuamF2YQ==) | `78.313% <0%> (+1.205%)` | `27% <0%> (+2%)` | :arrow_up: |; | [...te/hellbender/engine/spark/VariantWalkerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4175/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvVmFyaWFudFdhbGtlclNwYXJrLmphdmE=) | `74.468% <0%> (+2.128%)` | `14% <0%> (ø)` | :arrow_down: |; | [...der/engine/spark/datasources/ReadsSparkSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4175/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvUmVhZHNTcGFya1NvdXJjZS5qYXZh) | `80.198% <0%> (+2.97%)` | `38% <0%> (ø)` | :arrow_down: |; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/4175/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `64.925% <0%> (+2.985%)` | `33% <0%> (+3%)` | :arrow_up: |; | ... and [11 more](https://codecov.io/gh/broadinstitute/gatk/pull/4175/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4175#issuecomment-358271180
https://github.com/broadinstitute/gatk/issues/4179#issuecomment-358327019:119,Deployability,pipeline,pipelines,119,"@lelqz Why are you running `ConvertHeaderlessHadoopBamShardToBam`? This is a diagnostic tool meant for debugging Spark pipelines, and should not be part of your pipeline proper! It is likely corrupting your BAM file.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4179#issuecomment-358327019
https://github.com/broadinstitute/gatk/issues/4179#issuecomment-358327019:161,Deployability,pipeline,pipeline,161,"@lelqz Why are you running `ConvertHeaderlessHadoopBamShardToBam`? This is a diagnostic tool meant for debugging Spark pipelines, and should not be part of your pipeline proper! It is likely corrupting your BAM file.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4179#issuecomment-358327019
https://github.com/broadinstitute/gatk/issues/4179#issuecomment-358373874:11,Availability,error,error,11,"The actual error sounds like one of the bam split guesser errors. I thought we'd fixed most of those, but it seems like maybe a corrupt file is triggering it?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4179#issuecomment-358373874
https://github.com/broadinstitute/gatk/issues/4179#issuecomment-358373874:58,Availability,error,errors,58,"The actual error sounds like one of the bam split guesser errors. I thought we'd fixed most of those, but it seems like maybe a corrupt file is triggering it?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4179#issuecomment-358373874
https://github.com/broadinstitute/gatk/issues/4179#issuecomment-358606933:121,Testability,test,test,121,"I use gatk 4.0.0.0.; I don't think the crashing caused by running ConvertHeaderlessHadoopBamShardToBam .Beause I try the test with unalign Header-Bam file by picard tools , the BwaAndMarkDuplicatesPipelineSpark crashing is still",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4179#issuecomment-358606933
https://github.com/broadinstitute/gatk/pull/4181#issuecomment-358335145:1638,Usability,Simpl,SimpleSVType,1638,ranches 9747 10098 +351 ; ==============================================; + Hits 46958 47777 +819 ; - Misses 9103 9859 +756 ; - Partials 3777 3904 +127; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4181?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [.../DiscoverVariantsFromContigAlignmentsSAMSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4181/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvRGlzY292ZXJWYXJpYW50c0Zyb21Db250aWdBbGlnbm1lbnRzU0FNU3BhcmsuamF2YQ==) | `71.839% <0%> (-28.161%)` | `35% <0%> (+26%)` | |; | [...park/sv/discovery/alignment/AlignmentInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/4181/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvYWxpZ25tZW50L0FsaWdubWVudEludGVydmFsLmphdmE=) | `88.889% <0%> (-0.766%)` | `72% <0%> (-2%)` | |; | [...lbender/tools/spark/sv/discovery/SimpleSVType.java](https://codecov.io/gh/broadinstitute/gatk/pull/4181/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvU2ltcGxlU1ZUeXBlLmphdmE=) | `86.275% <0%> (-0.293%)` | `4% <0%> (+2%)` | |; | [.../tools/spark/sv/discovery/BreakEndVariantType.java](https://codecov.io/gh/broadinstitute/gatk/pull/4181/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvQnJlYWtFbmRWYXJpYW50VHlwZS5qYXZh) | `0% <0%> (ø)` | `0% <0%> (ø)` | :arrow_down: |; | [...er/tools/spark/sv/discovery/ChimericAlignment.java](https://codecov.io/gh/broadinstitute/gatk/pull/4181/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvQ2hpbWVyaWNBbGlnbm1lbnQuamF2YQ==) | `73.077% <0%> (ø)` | `46% <0%> (?)` | |; | [...ols/spark/sv/discovery/AlignedContigGenerator.java](https://codecov.io/gh/broadinstitute/gatk/pull/4181/d,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4181#issuecomment-358335145
https://github.com/broadinstitute/gatk/pull/4181#issuecomment-358451918:30,Availability,Robust,RobustBrentSolver,30,@samuelklee I'd like to keep `RobustBrentSolver` and `SynchronizedUnivariateSolver` + their dependencies. Everything else (ICG and linear operator) can go.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4181#issuecomment-358451918
https://github.com/broadinstitute/gatk/pull/4181#issuecomment-358451918:54,Integrability,Synchroniz,SynchronizedUnivariateSolver,54,@samuelklee I'd like to keep `RobustBrentSolver` and `SynchronizedUnivariateSolver` + their dependencies. Everything else (ICG and linear operator) can go.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4181#issuecomment-358451918
https://github.com/broadinstitute/gatk/pull/4181#issuecomment-358451918:92,Integrability,depend,dependencies,92,@samuelklee I'd like to keep `RobustBrentSolver` and `SynchronizedUnivariateSolver` + their dependencies. Everything else (ICG and linear operator) can go.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4181#issuecomment-358451918
https://github.com/broadinstitute/gatk/issues/4184#issuecomment-358350049:125,Availability,error,error,125,"Running `gatk IndexFeatureFile` with `--java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true'` reveals that the underlying error is:. ```; htsjdk.tribble.TribbleException: The provided VCF file is malformed at approximately line number 483650: unparsable vcf record with allele M; ```. Can you check whether the VCF is malformed at this location, as the error claims?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4184#issuecomment-358350049
https://github.com/broadinstitute/gatk/issues/4184#issuecomment-358350049:356,Availability,error,error,356,"Running `gatk IndexFeatureFile` with `--java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true'` reveals that the underlying error is:. ```; htsjdk.tribble.TribbleException: The provided VCF file is malformed at approximately line number 483650: unparsable vcf record with allele M; ```. Can you check whether the VCF is malformed at this location, as the error claims?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4184#issuecomment-358350049
https://github.com/broadinstitute/gatk/issues/4184#issuecomment-358353490:110,Availability,error,error,110,"Since the VCF in question is malformed, the task here becomes ""make IndexFeatureFile throw a more informative error message when the file being indexed is malformed""",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4184#issuecomment-358353490
https://github.com/broadinstitute/gatk/issues/4184#issuecomment-358353490:116,Integrability,message,message,116,"Since the VCF in question is malformed, the task here becomes ""make IndexFeatureFile throw a more informative error message when the file being indexed is malformed""",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4184#issuecomment-358353490
https://github.com/broadinstitute/gatk/issues/4185#issuecomment-358365117:37,Deployability,pipeline,pipeline,37,This tool was part of the legacy CNV pipeline that was deleted in https://github.com/broadinstitute/gatk/pull/3935. @samuelklee can point you to the appropriate replacement tool.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4185#issuecomment-358365117
https://github.com/broadinstitute/gatk/issues/4185#issuecomment-358366468:22,Deployability,pipeline,pipelines,22,"@svedziok The new CNV pipelines use the tool CollectFragmentCounts to collect coverage for both WES and WGS analysis. You should first use the tool PreprocessIntervals to specify padding (for WES) or bin size (for WGS) to create bins over which coverage will be collected. More generally, you can see how the tools are used in the CNV pipelines by studying the WDLs in scripts/cnv_wdl.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4185#issuecomment-358366468
https://github.com/broadinstitute/gatk/issues/4185#issuecomment-358366468:335,Deployability,pipeline,pipelines,335,"@svedziok The new CNV pipelines use the tool CollectFragmentCounts to collect coverage for both WES and WGS analysis. You should first use the tool PreprocessIntervals to specify padding (for WES) or bin size (for WGS) to create bins over which coverage will be collected. More generally, you can see how the tools are used in the CNV pipelines by studying the WDLs in scripts/cnv_wdl.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4185#issuecomment-358366468
https://github.com/broadinstitute/gatk/issues/4185#issuecomment-358660583:219,Availability,failure,failure,219,"We decided to replace SparkGenomeReadCounts with a relatively simple ReadWalker to avoid various bugs we were running into (some of which were due to Hadoop-BAM). We found that these bugs gave rise to a relatively high failure rate---roughly 1 in 50 TCGA BAMs. Like any ReadWalker, you can specify custom read filters using GATK engine arguments such as `--disable-default-read-filters` and `--read-filter ...` However, because we count fragment centers (rather than read starts, as in SparkGenomeReadCounts), disabling filters which check that reads are properly paired may lead to unexpected behavior. In principle, we could write a similar ReadWalkerSpark version of the tool. However, our experience running the tool showed that CollectFragmentCounts was already faster than SparkGenomeReadCounts in Spark local mode, sometimes by a factor of ~5 (and, more importantly, it didn't run into Hadoop-BAM failures). We may do some more careful profiling and roll a ReadWalkerSpark version in the future, but these aren't too high priority at the moment.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4185#issuecomment-358660583
https://github.com/broadinstitute/gatk/issues/4185#issuecomment-358660583:904,Availability,failure,failures,904,"We decided to replace SparkGenomeReadCounts with a relatively simple ReadWalker to avoid various bugs we were running into (some of which were due to Hadoop-BAM). We found that these bugs gave rise to a relatively high failure rate---roughly 1 in 50 TCGA BAMs. Like any ReadWalker, you can specify custom read filters using GATK engine arguments such as `--disable-default-read-filters` and `--read-filter ...` However, because we count fragment centers (rather than read starts, as in SparkGenomeReadCounts), disabling filters which check that reads are properly paired may lead to unexpected behavior. In principle, we could write a similar ReadWalkerSpark version of the tool. However, our experience running the tool showed that CollectFragmentCounts was already faster than SparkGenomeReadCounts in Spark local mode, sometimes by a factor of ~5 (and, more importantly, it didn't run into Hadoop-BAM failures). We may do some more careful profiling and roll a ReadWalkerSpark version in the future, but these aren't too high priority at the moment.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4185#issuecomment-358660583
https://github.com/broadinstitute/gatk/issues/4185#issuecomment-358660583:83,Safety,avoid,avoid,83,"We decided to replace SparkGenomeReadCounts with a relatively simple ReadWalker to avoid various bugs we were running into (some of which were due to Hadoop-BAM). We found that these bugs gave rise to a relatively high failure rate---roughly 1 in 50 TCGA BAMs. Like any ReadWalker, you can specify custom read filters using GATK engine arguments such as `--disable-default-read-filters` and `--read-filter ...` However, because we count fragment centers (rather than read starts, as in SparkGenomeReadCounts), disabling filters which check that reads are properly paired may lead to unexpected behavior. In principle, we could write a similar ReadWalkerSpark version of the tool. However, our experience running the tool showed that CollectFragmentCounts was already faster than SparkGenomeReadCounts in Spark local mode, sometimes by a factor of ~5 (and, more importantly, it didn't run into Hadoop-BAM failures). We may do some more careful profiling and roll a ReadWalkerSpark version in the future, but these aren't too high priority at the moment.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4185#issuecomment-358660583
https://github.com/broadinstitute/gatk/issues/4185#issuecomment-358660583:62,Usability,simpl,simple,62,"We decided to replace SparkGenomeReadCounts with a relatively simple ReadWalker to avoid various bugs we were running into (some of which were due to Hadoop-BAM). We found that these bugs gave rise to a relatively high failure rate---roughly 1 in 50 TCGA BAMs. Like any ReadWalker, you can specify custom read filters using GATK engine arguments such as `--disable-default-read-filters` and `--read-filter ...` However, because we count fragment centers (rather than read starts, as in SparkGenomeReadCounts), disabling filters which check that reads are properly paired may lead to unexpected behavior. In principle, we could write a similar ReadWalkerSpark version of the tool. However, our experience running the tool showed that CollectFragmentCounts was already faster than SparkGenomeReadCounts in Spark local mode, sometimes by a factor of ~5 (and, more importantly, it didn't run into Hadoop-BAM failures). We may do some more careful profiling and roll a ReadWalkerSpark version in the future, but these aren't too high priority at the moment.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4185#issuecomment-358660583
https://github.com/broadinstitute/gatk/issues/4186#issuecomment-358361262:97,Deployability,update,update,97,I've been told that this is solvable by bumping the dataproc version from 1.1 -> 1.2. We need to update this on jenkins assuming it works fine with spark 2.2.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4186#issuecomment-358361262
https://github.com/broadinstitute/gatk/issues/4186#issuecomment-358372207:193,Deployability,upgrade,upgrade,193,It might still be worth silencing this for people who are running spark 2.0.0 which is what we are doing on jenkins. (and what we officially support in our build.gradle). Ultimately we need to upgrade to spark 2.2.x #2555,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4186#issuecomment-358372207
https://github.com/broadinstitute/gatk/issues/4188#issuecomment-358438099:368,Usability,guid,guide,368,"Right @sooheelee, the template is certainly useful for that, but can just as easily be generated using `wdltool inputs`. Whatever you and @davidbenjamin decide, let me know if I should add the CNV templates back to be consistent. (But again, my vote is for removing the M2 template!). @LeeTL1220 can add whatever we decide about optional string type args to the style guide, but I'd prefer for this sort of thing to be automatically generated (#2480).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4188#issuecomment-358438099
https://github.com/broadinstitute/gatk/issues/4188#issuecomment-358481510:343,Usability,simpl,simple,343,"> [ ""${variants_for_contamination}"" == *.vcf ] does not allow *.vcf.gz files. It should accept either. I'm about to fix this in a PR. > Script calls for a Picard jar. I don't mind specifying this because I like controlling for the Picard version I use. However, users may want to call the Picard version within the GATK jar. I cannot fathom a simple way to allow switching this out in the script, but perhaps something like the gatk_override option could work. The goal would be to call the Picard tool from a Docker. This better enables provenance. The same PR is also going to call Picard from the gatk.; > (But again, my vote is for removing the M2 template!); ; I agree with @samuelklee about the template. > I just noticed the script doesn't run CollectSequencingArtifactMetrics nor GetPileupSummaries on the matched normal. . I should definitely use the normal for contamination. @sooheelee What's the case for CollectSequencingArtifactMetrics on the normal?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4188#issuecomment-358481510
https://github.com/broadinstitute/gatk/issues/4188#issuecomment-358488159:343,Energy Efficiency,reduce,reduce,343,"My $0.02:. 1. In general it's ok with me to not provide a template for WDLs in the GATK repo as long as you guys help us (ie @bshifaw) produce appropriate templates to include in the gatk-workflows repo and in FireCloud. . 2. Re: Picard tools, going forward they should be invoked from the GATK jar by default. Among other benefits, that will reduce support entropy wrt possible combination of versions of tools people might be using. 3. I like the idea of focusing on the auto-generated wrappers for improvements like the string variable for adding arbitrary extra args.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4188#issuecomment-358488159
https://github.com/broadinstitute/gatk/issues/4188#issuecomment-358488159:488,Integrability,wrap,wrappers,488,"My $0.02:. 1. In general it's ok with me to not provide a template for WDLs in the GATK repo as long as you guys help us (ie @bshifaw) produce appropriate templates to include in the gatk-workflows repo and in FireCloud. . 2. Re: Picard tools, going forward they should be invoked from the GATK jar by default. Among other benefits, that will reduce support entropy wrt possible combination of versions of tools people might be using. 3. I like the idea of focusing on the auto-generated wrappers for improvements like the string variable for adding arbitrary extra args.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4188#issuecomment-358488159
https://github.com/broadinstitute/gatk/issues/4188#issuecomment-358488159:530,Modifiability,variab,variable,530,"My $0.02:. 1. In general it's ok with me to not provide a template for WDLs in the GATK repo as long as you guys help us (ie @bshifaw) produce appropriate templates to include in the gatk-workflows repo and in FireCloud. . 2. Re: Picard tools, going forward they should be invoked from the GATK jar by default. Among other benefits, that will reduce support entropy wrt possible combination of versions of tools people might be using. 3. I like the idea of focusing on the auto-generated wrappers for improvements like the string variable for adding arbitrary extra args.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4188#issuecomment-358488159
https://github.com/broadinstitute/gatk/issues/4188#issuecomment-358877500:184,Deployability,install,installed,184,"If docker is needed to run M2 wdl, I wish it can run without docker.; I need to run M2 wdl using grid engine backend and an old version needed some modifications to run without docker installed.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4188#issuecomment-358877500
https://github.com/broadinstitute/gatk/issues/4188#issuecomment-358960833:122,Modifiability,config,config,122,"@byoo We run the M2 wdl without modification on a Broad SGE cluster for our internal evaluations all the time. A cromwell config file for SGE is required, but that's the case for every backend. You *do* need to supply a gatk docker image string as an input, but it is ignored. Please feel free to share your input json and config file if it doesn't work for you. I can't say I'm skilled enough to catch anything subtle, but I can check for obvious differences.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4188#issuecomment-358960833
https://github.com/broadinstitute/gatk/issues/4188#issuecomment-358960833:323,Modifiability,config,config,323,"@byoo We run the M2 wdl without modification on a Broad SGE cluster for our internal evaluations all the time. A cromwell config file for SGE is required, but that's the case for every backend. You *do* need to supply a gatk docker image string as an input, but it is ignored. Please feel free to share your input json and config file if it doesn't work for you. I can't say I'm skilled enough to catch anything subtle, but I can check for obvious differences.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4188#issuecomment-358960833
https://github.com/broadinstitute/gatk/issues/4188#issuecomment-358987029:335,Deployability,toggle,toggle,335,"> The version of Oncotator is not compatible with GRCh38. Please, can we have an option to switch this out with Funcotator?. @jonn-smith Is Funcotator ready to go in the wdl? Should it even *replace* Oncotator? Does it need its own docker or does one just invoke it like the rest of the GTK tools? Do we need to do anything special to toggle between references?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4188#issuecomment-358987029
https://github.com/broadinstitute/gatk/issues/4188#issuecomment-359019952:193,Availability,down,download,193,"@davidbenjamin Funcotator is not quite ready to outright replace Oncotator, but there is a test WDL for it in the M2/unsupported folder. . It can run off the same docker image, but you need to download the data sources (or provide your own - the default downloadable tar.gz is about 300MB and extracts to about 3GB). There is a short set of instructions in the tool doc for how to run it (I'm still working on the tutorial for the forum). . One current limitation is that it only consumes and produces VCF files, which may be an issue for some users. . I should add that while I have done _some_ testing with GRCh38, I have not extensively tested with that reference.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4188#issuecomment-359019952
https://github.com/broadinstitute/gatk/issues/4188#issuecomment-359019952:254,Availability,down,downloadable,254,"@davidbenjamin Funcotator is not quite ready to outright replace Oncotator, but there is a test WDL for it in the M2/unsupported folder. . It can run off the same docker image, but you need to download the data sources (or provide your own - the default downloadable tar.gz is about 300MB and extracts to about 3GB). There is a short set of instructions in the tool doc for how to run it (I'm still working on the tutorial for the forum). . One current limitation is that it only consumes and produces VCF files, which may be an issue for some users. . I should add that while I have done _some_ testing with GRCh38, I have not extensively tested with that reference.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4188#issuecomment-359019952
https://github.com/broadinstitute/gatk/issues/4188#issuecomment-359019952:91,Testability,test,test,91,"@davidbenjamin Funcotator is not quite ready to outright replace Oncotator, but there is a test WDL for it in the M2/unsupported folder. . It can run off the same docker image, but you need to download the data sources (or provide your own - the default downloadable tar.gz is about 300MB and extracts to about 3GB). There is a short set of instructions in the tool doc for how to run it (I'm still working on the tutorial for the forum). . One current limitation is that it only consumes and produces VCF files, which may be an issue for some users. . I should add that while I have done _some_ testing with GRCh38, I have not extensively tested with that reference.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4188#issuecomment-359019952
https://github.com/broadinstitute/gatk/issues/4188#issuecomment-359019952:596,Testability,test,testing,596,"@davidbenjamin Funcotator is not quite ready to outright replace Oncotator, but there is a test WDL for it in the M2/unsupported folder. . It can run off the same docker image, but you need to download the data sources (or provide your own - the default downloadable tar.gz is about 300MB and extracts to about 3GB). There is a short set of instructions in the tool doc for how to run it (I'm still working on the tutorial for the forum). . One current limitation is that it only consumes and produces VCF files, which may be an issue for some users. . I should add that while I have done _some_ testing with GRCh38, I have not extensively tested with that reference.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4188#issuecomment-359019952
https://github.com/broadinstitute/gatk/issues/4188#issuecomment-359019952:640,Testability,test,tested,640,"@davidbenjamin Funcotator is not quite ready to outright replace Oncotator, but there is a test WDL for it in the M2/unsupported folder. . It can run off the same docker image, but you need to download the data sources (or provide your own - the default downloadable tar.gz is about 300MB and extracts to about 3GB). There is a short set of instructions in the tool doc for how to run it (I'm still working on the tutorial for the forum). . One current limitation is that it only consumes and produces VCF files, which may be an issue for some users. . I should add that while I have done _some_ testing with GRCh38, I have not extensively tested with that reference.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4188#issuecomment-359019952
https://github.com/broadinstitute/gatk/issues/4188#issuecomment-359218363:230,Testability,test,tested,230,"> Furthermore, I'd like for the tool to automatically interpret this mode, when not given an -L intervals list, to not split reference contigs. I.e. a contig is an interval. (Perhaps already the tool behavior?). @sooheelee I just tested this and the `BALANCING_WITHOUT_INTERVAL_SUBDIVISION` already works the way you want it to.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4188#issuecomment-359218363
https://github.com/broadinstitute/gatk/issues/4188#issuecomment-360209849:162,Usability,simpl,simple,162,"Status as of PR #4238:. ## Remaining wants; - Outputs should allow either .vcf or .vcf.gz compression by user-specification. Alternatively, if we want to keep it simple and hardcode, then the preference is for compressed files. Some of us prefer to save on storage.; - The version of Oncotator is not compatible with GRCh38. Please, can we have an option to switch this out with Funcotator?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4188#issuecomment-360209849
https://github.com/broadinstitute/gatk/issues/4188#issuecomment-360544256:75,Deployability,install,installed,75,"@davidbenjamin mutect2_pon.wdl and mutect2.wdl worked great without docker installed. Thanks!. @samuelklee @sooheelee As a user, I found a json template useful for two reasons, though it may be up to how a wdl is written.; 1) womtool generates inputs from all the dependent wdls including unnecessary ones for the workflow. (e.g. mutect2_pon.wdl); 2) womtool didn't provide default values. Looking at mutect_resources.wdl, I wondered what the good value for minimum_allele_frequency is (or what GATK team used for creating the resource bundle). In addition, I thought a test to validate every wdl would be helpful. (womtool validate [a wdl])",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4188#issuecomment-360544256
https://github.com/broadinstitute/gatk/issues/4188#issuecomment-360544256:264,Integrability,depend,dependent,264,"@davidbenjamin mutect2_pon.wdl and mutect2.wdl worked great without docker installed. Thanks!. @samuelklee @sooheelee As a user, I found a json template useful for two reasons, though it may be up to how a wdl is written.; 1) womtool generates inputs from all the dependent wdls including unnecessary ones for the workflow. (e.g. mutect2_pon.wdl); 2) womtool didn't provide default values. Looking at mutect_resources.wdl, I wondered what the good value for minimum_allele_frequency is (or what GATK team used for creating the resource bundle). In addition, I thought a test to validate every wdl would be helpful. (womtool validate [a wdl])",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4188#issuecomment-360544256
https://github.com/broadinstitute/gatk/issues/4188#issuecomment-360544256:578,Security,validat,validate,578,"@davidbenjamin mutect2_pon.wdl and mutect2.wdl worked great without docker installed. Thanks!. @samuelklee @sooheelee As a user, I found a json template useful for two reasons, though it may be up to how a wdl is written.; 1) womtool generates inputs from all the dependent wdls including unnecessary ones for the workflow. (e.g. mutect2_pon.wdl); 2) womtool didn't provide default values. Looking at mutect_resources.wdl, I wondered what the good value for minimum_allele_frequency is (or what GATK team used for creating the resource bundle). In addition, I thought a test to validate every wdl would be helpful. (womtool validate [a wdl])",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4188#issuecomment-360544256
https://github.com/broadinstitute/gatk/issues/4188#issuecomment-360544256:624,Security,validat,validate,624,"@davidbenjamin mutect2_pon.wdl and mutect2.wdl worked great without docker installed. Thanks!. @samuelklee @sooheelee As a user, I found a json template useful for two reasons, though it may be up to how a wdl is written.; 1) womtool generates inputs from all the dependent wdls including unnecessary ones for the workflow. (e.g. mutect2_pon.wdl); 2) womtool didn't provide default values. Looking at mutect_resources.wdl, I wondered what the good value for minimum_allele_frequency is (or what GATK team used for creating the resource bundle). In addition, I thought a test to validate every wdl would be helpful. (womtool validate [a wdl])",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4188#issuecomment-360544256
https://github.com/broadinstitute/gatk/issues/4188#issuecomment-360544256:570,Testability,test,test,570,"@davidbenjamin mutect2_pon.wdl and mutect2.wdl worked great without docker installed. Thanks!. @samuelklee @sooheelee As a user, I found a json template useful for two reasons, though it may be up to how a wdl is written.; 1) womtool generates inputs from all the dependent wdls including unnecessary ones for the workflow. (e.g. mutect2_pon.wdl); 2) womtool didn't provide default values. Looking at mutect_resources.wdl, I wondered what the good value for minimum_allele_frequency is (or what GATK team used for creating the resource bundle). In addition, I thought a test to validate every wdl would be helpful. (womtool validate [a wdl])",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4188#issuecomment-360544256
https://github.com/broadinstitute/gatk/issues/4188#issuecomment-360577196:43,Usability,feedback,feedback,43,"@byoo Wonderful, we really appreciate your feedback!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4188#issuecomment-360577196
https://github.com/broadinstitute/gatk/pull/4192#issuecomment-358491943:1276,Usability,Simpl,SimpleSVType,1276,b8d38b223?src=pr&el=desc) will **decrease** coverage by `0.76%`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #4192 +/- ##; ==============================================; - Coverage 78.466% 77.707% -0.76% ; - Complexity 16637 17108 +471 ; ==============================================; Files 1058 1082 +24 ; Lines 59758 62508 +2750 ; Branches 9746 10264 +518 ; ==============================================; + Hits 46890 48573 +1683 ; - Misses 9091 9984 +893 ; - Partials 3777 3951 +174; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4192?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...er/tools/spark/sv/discovery/AlignmentInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/4192/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvQWxpZ25tZW50SW50ZXJ2YWwuamF2YQ==) | `88.889% <0%> (-0.383%)` | `72% <0%> (ø)` | |; | [...lbender/tools/spark/sv/discovery/SimpleSVType.java](https://codecov.io/gh/broadinstitute/gatk/pull/4192/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvU2ltcGxlU1ZUeXBlLmphdmE=) | `86.275% <0%> (-0.293%)` | `4% <0%> (+2%)` | |; | [.../sv/StructuralVariationDiscoveryPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4192/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9TdHJ1Y3R1cmFsVmFyaWF0aW9uRGlzY292ZXJ5UGlwZWxpbmVTcGFyay5qYXZh) | `91.351% <0%> (-0.158%)` | `15% <0%> (+7%)` | |; | [.../tools/spark/sv/discovery/BreakEndVariantType.java](https://codecov.io/gh/broadinstitute/gatk/pull/4192/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvQnJlYWtFbmRWYXJpYW50VHlwZS5qYXZh) | `0% <0%> (ø)` | `0% <0%> (ø)` | :arrow_down: |; | [...park/sv/discovery/alignment/AlignmentInterval.java](https://codecov.io/gh/broadin,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4192#issuecomment-358491943
https://github.com/broadinstitute/gatk/pull/4192#issuecomment-359051409:27,Testability,test,tests,27,"Did you confirm that these tests actually fail without your bug fix to hook up the argument, @davidbenjamin ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4192#issuecomment-359051409
https://github.com/broadinstitute/gatk/pull/4192#issuecomment-359052159:29,Testability,test,tests,29,"> Did you confirm that these tests actually fail without your bug fix to hook up the argument, @davidbenjamin ?. Yes, they fail.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4192#issuecomment-359052159
https://github.com/broadinstitute/gatk/pull/4193#issuecomment-358454879:66,Usability,guid,guide,66,"@davidbenjamin mind reviewing? @LeeTL1220 take note for the style guide, if necessary.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4193#issuecomment-358454879
https://github.com/broadinstitute/gatk/pull/4193#issuecomment-358679618:16,Testability,test,tests,16,"Will merge when tests pass, unless there are further objections.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4193#issuecomment-358679618
https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:241,Availability,Down,Downloading,241,"I'm also seeing this more often during the Docker build, not sure if it is related:. ````; Step 5/27 : RUN /gatk/gradlew clean compileTestJava installAll localJar createPythonPackageArchive -Drelease=$DRELEASE; ---> Running in d08cd7336c45; Downloading https://services.gradle.org/distributions/gradle-3.1-bin.zip; .......................................; Exception in thread ""main"" javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:77); 	at org.gradle.wrapper.Download.download(Download.java:44); 	at org.gradle.wrapper.Install$1.call(Install.java:61); 	at org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401
https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:619,Availability,avail,available,619,"I'm also seeing this more often during the Docker build, not sure if it is related:. ````; Step 5/27 : RUN /gatk/gradlew clean compileTestJava installAll localJar createPythonPackageArchive -Drelease=$DRELEASE; ---> Running in d08cd7336c45; Downloading https://services.gradle.org/distributions/gradle-3.1-bin.zip; .......................................; Exception in thread ""main"" javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:77); 	at org.gradle.wrapper.Download.download(Download.java:44); 	at org.gradle.wrapper.Install$1.call(Install.java:61); 	at org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401
https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:686,Availability,avail,available,686,"I'm also seeing this more often during the Docker build, not sure if it is related:. ````; Step 5/27 : RUN /gatk/gradlew clean compileTestJava installAll localJar createPythonPackageArchive -Drelease=$DRELEASE; ---> Running in d08cd7336c45; Downloading https://services.gradle.org/distributions/gradle-3.1-bin.zip; .......................................; Exception in thread ""main"" javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:77); 	at org.gradle.wrapper.Download.download(Download.java:44); 	at org.gradle.wrapper.Install$1.call(Install.java:61); 	at org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401
https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:757,Availability,avail,available,757,"I'm also seeing this more often during the Docker build, not sure if it is related:. ````; Step 5/27 : RUN /gatk/gradlew clean compileTestJava installAll localJar createPythonPackageArchive -Drelease=$DRELEASE; ---> Running in d08cd7336c45; Downloading https://services.gradle.org/distributions/gradle-3.1-bin.zip; .......................................; Exception in thread ""main"" javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:77); 	at org.gradle.wrapper.Download.download(Download.java:44); 	at org.gradle.wrapper.Install$1.call(Install.java:61); 	at org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401
https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:1049,Availability,Down,Download,1049,"ld, not sure if it is related:. ````; Step 5/27 : RUN /gatk/gradlew clean compileTestJava installAll localJar createPythonPackageArchive -Drelease=$DRELEASE; ---> Running in d08cd7336c45; Downloading https://services.gradle.org/distributions/gradle-3.1-bin.zip; .......................................; Exception in thread ""main"" javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:77); 	at org.gradle.wrapper.Download.download(Download.java:44); 	at org.gradle.wrapper.Install$1.call(Install.java:61); 	at org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStre",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401
https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:1058,Availability,down,downloadInternal,1058," is related:. ````; Step 5/27 : RUN /gatk/gradlew clean compileTestJava installAll localJar createPythonPackageArchive -Drelease=$DRELEASE; ---> Running in d08cd7336c45; Downloading https://services.gradle.org/distributions/gradle-3.1-bin.zip; .......................................; Exception in thread ""main"" javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:77); 	at org.gradle.wrapper.Download.download(Download.java:44); 	at org.gradle.wrapper.Install$1.call(Install.java:61); 	at org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401
https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:1075,Availability,Down,Download,1075," is related:. ````; Step 5/27 : RUN /gatk/gradlew clean compileTestJava installAll localJar createPythonPackageArchive -Drelease=$DRELEASE; ---> Running in d08cd7336c45; Downloading https://services.gradle.org/distributions/gradle-3.1-bin.zip; .......................................; Exception in thread ""main"" javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:77); 	at org.gradle.wrapper.Download.download(Download.java:44); 	at org.gradle.wrapper.Install$1.call(Install.java:61); 	at org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401
https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:1117,Availability,Down,Download,1117,"clean compileTestJava installAll localJar createPythonPackageArchive -Drelease=$DRELEASE; ---> Running in d08cd7336c45; Downloading https://services.gradle.org/distributions/gradle-3.1-bin.zip; .......................................; Exception in thread ""main"" javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:77); 	at org.gradle.wrapper.Download.download(Download.java:44); 	at org.gradle.wrapper.Install$1.call(Install.java:61); 	at org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.read1(BufferedInputStr",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401
https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:1126,Availability,down,download,1126,"estJava installAll localJar createPythonPackageArchive -Drelease=$DRELEASE; ---> Running in d08cd7336c45; Downloading https://services.gradle.org/distributions/gradle-3.1-bin.zip; .......................................; Exception in thread ""main"" javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:77); 	at org.gradle.wrapper.Download.download(Download.java:44); 	at org.gradle.wrapper.Install$1.call(Install.java:61); 	at org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401
https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:1135,Availability,Down,Download,1135,"estJava installAll localJar createPythonPackageArchive -Drelease=$DRELEASE; ---> Running in d08cd7336c45; Downloading https://services.gradle.org/distributions/gradle-3.1-bin.zip; .......................................; Exception in thread ""main"" javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:77); 	at org.gradle.wrapper.Download.download(Download.java:44); 	at org.gradle.wrapper.Install$1.call(Install.java:61); 	at org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401
https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:2550,Availability,Down,Download,2550,org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3368); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:62); 	... 7 more; Caused by: java.net.SocketException: Connection reset; 	at java.net.SocketInputStream.read(SocketInputStream.java:210); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	at sun.security.ssl.InputRecord.readV3Record(InputRecord.java:593); 	at sun.security.ssl.InputRecord.read(InputRecord.java:532); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:105); 	... 14 more,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401
https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:2559,Availability,down,downloadInternal,2559,org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3368); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:62); 	... 7 more; Caused by: java.net.SocketException: Connection reset; 	at java.net.SocketInputStream.read(SocketInputStream.java:210); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	at sun.security.ssl.InputRecord.readV3Record(InputRecord.java:593); 	at sun.security.ssl.InputRecord.read(InputRecord.java:532); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:105); 	... 14 more,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401
https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:2576,Availability,Down,Download,2576,org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3368); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:62); 	... 7 more; Caused by: java.net.SocketException: Connection reset; 	at java.net.SocketInputStream.read(SocketInputStream.java:210); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	at sun.security.ssl.InputRecord.readV3Record(InputRecord.java:593); 	at sun.security.ssl.InputRecord.read(InputRecord.java:532); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:105); 	... 14 more,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401
https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:143,Deployability,install,installAll,143,"I'm also seeing this more often during the Docker build, not sure if it is related:. ````; Step 5/27 : RUN /gatk/gradlew clean compileTestJava installAll localJar createPythonPackageArchive -Drelease=$DRELEASE; ---> Running in d08cd7336c45; Downloading https://services.gradle.org/distributions/gradle-3.1-bin.zip; .......................................; Exception in thread ""main"" javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:77); 	at org.gradle.wrapper.Download.download(Download.java:44); 	at org.gradle.wrapper.Install$1.call(Install.java:61); 	at org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401
https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:1177,Deployability,Install,Install,1177,"Archive -Drelease=$DRELEASE; ---> Running in d08cd7336c45; Downloading https://services.gradle.org/distributions/gradle-3.1-bin.zip; .......................................; Exception in thread ""main"" javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:77); 	at org.gradle.wrapper.Download.download(Download.java:44); 	at org.gradle.wrapper.Install$1.call(Install.java:61); 	at org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(Buffered",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401
https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:1192,Deployability,Install,Install,1192,"elease=$DRELEASE; ---> Running in d08cd7336c45; Downloading https://services.gradle.org/distributions/gradle-3.1-bin.zip; .......................................; Exception in thread ""main"" javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:77); 	at org.gradle.wrapper.Download.download(Download.java:44); 	at org.gradle.wrapper.Install$1.call(Install.java:61); 	at org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401
https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:1233,Deployability,Install,Install,1233,"5; Downloading https://services.gradle.org/distributions/gradle-3.1-bin.zip; .......................................; Exception in thread ""main"" javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:77); 	at org.gradle.wrapper.Download.download(Download.java:44); 	at org.gradle.wrapper.Install$1.call(Install.java:61); 	at org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.rea",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401
https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:1248,Deployability,Install,Install,1248,"ing https://services.gradle.org/distributions/gradle-3.1-bin.zip; .......................................; Exception in thread ""main"" javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:77); 	at org.gradle.wrapper.Download.download(Download.java:44); 	at org.gradle.wrapper.Install$1.call(Install.java:61); 	at org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStr",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401
https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:1383,Deployability,Install,Install,1383,x.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:77); 	at org.gradle.wrapper.Download.download(Download.java:44); 	at org.gradle.wrapper.Install$1.call(Install.java:61); 	at org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputS,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401
https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:1402,Deployability,Install,Install,1402,Exception: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:77); 	at org.gradle.wrapper.Download.download(Download.java:44); 	at org.gradle.wrapper.Install$1.call(Install.java:61); 	at org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(Htt,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401
https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:743,Energy Efficiency,Meter,MeteredStream,743,"I'm also seeing this more often during the Docker build, not sure if it is related:. ````; Step 5/27 : RUN /gatk/gradlew clean compileTestJava installAll localJar createPythonPackageArchive -Drelease=$DRELEASE; ---> Running in d08cd7336c45; Downloading https://services.gradle.org/distributions/gradle-3.1-bin.zip; .......................................; Exception in thread ""main"" javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:77); 	at org.gradle.wrapper.Download.download(Download.java:44); 	at org.gradle.wrapper.Install$1.call(Install.java:61); 	at org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401
https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:767,Energy Efficiency,Meter,MeteredStream,767,"I'm also seeing this more often during the Docker build, not sure if it is related:. ````; Step 5/27 : RUN /gatk/gradlew clean compileTestJava installAll localJar createPythonPackageArchive -Drelease=$DRELEASE; ---> Running in d08cd7336c45; Downloading https://services.gradle.org/distributions/gradle-3.1-bin.zip; .......................................; Exception in thread ""main"" javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:77); 	at org.gradle.wrapper.Download.download(Download.java:44); 	at org.gradle.wrapper.Install$1.call(Install.java:61); 	at org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401
https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:2221,Energy Efficiency,Meter,MeteredStream,2221,org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3368); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:62); 	... 7 more; Caused by: java.net.SocketException: Connection reset; 	at java.net.SocketInputStream.read(SocketInputStream.java:210); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	at sun.security.ssl.InputRecord.readV3Record(InputRecord.java:593); 	at sun.security.ssl.InputRecord.read(InputRecord.java:532); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:105); 	... 14 more,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401
https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:2240,Energy Efficiency,Meter,MeteredStream,2240,org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3368); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:62); 	... 7 more; Caused by: java.net.SocketException: Connection reset; 	at java.net.SocketInputStream.read(SocketInputStream.java:210); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	at sun.security.ssl.InputRecord.readV3Record(InputRecord.java:593); 	at sun.security.ssl.InputRecord.read(InputRecord.java:532); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:105); 	... 14 more,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401
https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:942,Integrability,protocol,protocol,942,"I'm also seeing this more often during the Docker build, not sure if it is related:. ````; Step 5/27 : RUN /gatk/gradlew clean compileTestJava installAll localJar createPythonPackageArchive -Drelease=$DRELEASE; ---> Running in d08cd7336c45; Downloading https://services.gradle.org/distributions/gradle-3.1-bin.zip; .......................................; Exception in thread ""main"" javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:77); 	at org.gradle.wrapper.Download.download(Download.java:44); 	at org.gradle.wrapper.Install$1.call(Install.java:61); 	at org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401
https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:1041,Integrability,wrap,wrapper,1041,"cker build, not sure if it is related:. ````; Step 5/27 : RUN /gatk/gradlew clean compileTestJava installAll localJar createPythonPackageArchive -Drelease=$DRELEASE; ---> Running in d08cd7336c45; Downloading https://services.gradle.org/distributions/gradle-3.1-bin.zip; .......................................; Exception in thread ""main"" javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:77); 	at org.gradle.wrapper.Download.download(Download.java:44); 	at org.gradle.wrapper.Install$1.call(Install.java:61); 	at org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(App",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401
https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:1109,Integrability,wrap,wrapper,1109,"gradlew clean compileTestJava installAll localJar createPythonPackageArchive -Drelease=$DRELEASE; ---> Running in d08cd7336c45; Downloading https://services.gradle.org/distributions/gradle-3.1-bin.zip; .......................................; Exception in thread ""main"" javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:77); 	at org.gradle.wrapper.Download.download(Download.java:44); 	at org.gradle.wrapper.Install$1.call(Install.java:61); 	at org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.read1(Buffere",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401
https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:1169,Integrability,wrap,wrapper,1169,"onPackageArchive -Drelease=$DRELEASE; ---> Running in d08cd7336c45; Downloading https://services.gradle.org/distributions/gradle-3.1-bin.zip; .......................................; Exception in thread ""main"" javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:77); 	at org.gradle.wrapper.Download.download(Download.java:44); 	at org.gradle.wrapper.Install$1.call(Install.java:61); 	at org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401
https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:1225,Integrability,wrap,wrapper,1225,"8cd7336c45; Downloading https://services.gradle.org/distributions/gradle-3.1-bin.zip; .......................................; Exception in thread ""main"" javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:77); 	at org.gradle.wrapper.Download.download(Download.java:44); 	at org.gradle.wrapper.Install$1.call(Install.java:61); 	at org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredS",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401
https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:1281,Integrability,wrap,wrapper,1281,"ributions/gradle-3.1-bin.zip; .......................................; Exception in thread ""main"" javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:77); 	at org.gradle.wrapper.Download.download(Download.java:44); 	at org.gradle.wrapper.Install$1.call(Install.java:61); 	at org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterIn",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401
https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:1375,Integrability,wrap,wrapper,1375,"in"" javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:77); 	at org.gradle.wrapper.Download.download(Download.java:44); 	at org.gradle.wrapper.Install$1.call(Install.java:61); 	at org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$Ht",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401
https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:1435,Integrability,wrap,wrapper,1435,: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:77); 	at org.gradle.wrapper.Download.download(Download.java:44); 	at org.gradle.wrapper.Install$1.call(Install.java:61); 	at org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at sun.net,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401
https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:1443,Integrability,Wrap,WrapperExecutor,1443,ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:77); 	at org.gradle.wrapper.Download.download(Download.java:44); 	at org.gradle.wrapper.Install$1.call(Install.java:61); 	at org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at sun.net.www.protoco,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401
https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:1467,Integrability,Wrap,WrapperExecutor,1467,va.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:77); 	at org.gradle.wrapper.Download.download(Download.java:44); 	at org.gradle.wrapper.Install$1.call(Install.java:61); 	at org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at sun.net.www.protocol.http.HttpURLConnec,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401
https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:1509,Integrability,wrap,wrapper,1509,	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:77); 	at org.gradle.wrapper.Download.download(Download.java:44); 	at org.gradle.wrapper.Install$1.call(Install.java:61); 	at org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnectio,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401
https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:2345,Integrability,protocol,protocol,2345,org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3368); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:62); 	... 7 more; Caused by: java.net.SocketException: Connection reset; 	at java.net.SocketInputStream.read(SocketInputStream.java:210); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	at sun.security.ssl.InputRecord.readV3Record(InputRecord.java:593); 	at sun.security.ssl.InputRecord.read(InputRecord.java:532); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:105); 	... 14 more,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401
https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:2444,Integrability,protocol,protocol,2444,org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3368); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:62); 	... 7 more; Caused by: java.net.SocketException: Connection reset; 	at java.net.SocketInputStream.read(SocketInputStream.java:210); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	at sun.security.ssl.InputRecord.readV3Record(InputRecord.java:593); 	at sun.security.ssl.InputRecord.read(InputRecord.java:532); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:105); 	... 14 more,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401
https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:2542,Integrability,wrap,wrapper,2542,org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3368); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:62); 	... 7 more; Caused by: java.net.SocketException: Connection reset; 	at java.net.SocketInputStream.read(SocketInputStream.java:210); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	at sun.security.ssl.InputRecord.readV3Record(InputRecord.java:593); 	at sun.security.ssl.InputRecord.read(InputRecord.java:532); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:105); 	... 14 more,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401
https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:521,Security,secur,security,521,"I'm also seeing this more often during the Docker build, not sure if it is related:. ````; Step 5/27 : RUN /gatk/gradlew clean compileTestJava installAll localJar createPythonPackageArchive -Drelease=$DRELEASE; ---> Running in d08cd7336c45; Downloading https://services.gradle.org/distributions/gradle-3.1-bin.zip; .......................................; Exception in thread ""main"" javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:77); 	at org.gradle.wrapper.Download.download(Download.java:44); 	at org.gradle.wrapper.Install$1.call(Install.java:61); 	at org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401
https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:591,Security,secur,security,591,"I'm also seeing this more often during the Docker build, not sure if it is related:. ````; Step 5/27 : RUN /gatk/gradlew clean compileTestJava installAll localJar createPythonPackageArchive -Drelease=$DRELEASE; ---> Running in d08cd7336c45; Downloading https://services.gradle.org/distributions/gradle-3.1-bin.zip; .......................................; Exception in thread ""main"" javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:77); 	at org.gradle.wrapper.Download.download(Download.java:44); 	at org.gradle.wrapper.Install$1.call(Install.java:61); 	at org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401
https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:1316,Security,access,access,1316,".....................; Exception in thread ""main"" javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.available(AppInputStream.java:60); 	at java.io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:77); 	at org.gradle.wrapper.Download.download(Download.java:44); 	at org.gradle.wrapper.Install$1.call(Install.java:61); 	at org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401
https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:1659,Security,secur,security,1659,io.BufferedInputStream.available(BufferedInputStream.java:410); 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:77); 	at org.gradle.wrapper.Download.download(Download.java:44); 	at org.gradle.wrapper.Install$1.call(Install.java:61); 	at org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3368); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:62); 	... 7 more; Caused by: java.net.SocketException: Connection reset; 	,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401
https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:1721,Security,secur,security,1721,; 	at sun.net.www.MeteredStream.available(MeteredStream.java:170); 	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:77); 	at org.gradle.wrapper.Download.download(Download.java:44); 	at org.gradle.wrapper.Install$1.call(Install.java:61); 	at org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3368); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:62); 	... 7 more; Caused by: java.net.SocketException: Connection reset; 	at java.net.SocketInputStream.read(SocketInputStream.java:210),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401
https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:1788,Security,secur,security,1788,	at sun.net.www.http.KeepAliveStream.close(KeepAliveStream.java:85); 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:77); 	at org.gradle.wrapper.Download.download(Download.java:44); 	at org.gradle.wrapper.Install$1.call(Install.java:61); 	at org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3368); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:62); 	... 7 more; Caused by: java.net.SocketException: Connection reset; 	at java.net.SocketInputStream.read(SocketInputStream.java:210); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); ,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401
https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:1855,Security,secur,security,1855,; 	at java.io.FilterInputStream.close(FilterInputStream.java:181); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:77); 	at org.gradle.wrapper.Download.download(Download.java:44); 	at org.gradle.wrapper.Install$1.call(Install.java:61); 	at org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3368); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:62); 	... 7 more; Caused by: java.net.SocketException: Connection reset; 	at java.net.SocketInputStream.read(SocketInputStream.java:210); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401
https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:1932,Security,secur,security,1932,t.www.protocol.http.HttpURLConnection$HttpInputStream.close(HttpURLConnection.java:3448); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:77); 	at org.gradle.wrapper.Download.download(Download.java:44); 	at org.gradle.wrapper.Install$1.call(Install.java:61); 	at org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3368); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:62); 	... 7 more; Caused by: java.net.SocketException: Connection reset; 	at java.net.SocketInputStream.read(SocketInputStream.java:210); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	at sun.security.ssl.InputRecord.readV3Record(InputRecord.java:593); 	at sun.s,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401
https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:2009,Security,secur,security,2009,.java:3448); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:77); 	at org.gradle.wrapper.Download.download(Download.java:44); 	at org.gradle.wrapper.Install$1.call(Install.java:61); 	at org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3368); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:62); 	... 7 more; Caused by: java.net.SocketException: Connection reset; 	at java.net.SocketInputStream.read(SocketInputStream.java:210); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	at sun.security.ssl.InputRecord.readV3Record(InputRecord.java:593); 	at sun.security.ssl.InputRecord.read(InputRecord.java:532); 	at sun.security.ssl.SSLS,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401
https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:2801,Security,secur,security,2801,org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3368); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:62); 	... 7 more; Caused by: java.net.SocketException: Connection reset; 	at java.net.SocketInputStream.read(SocketInputStream.java:210); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	at sun.security.ssl.InputRecord.readV3Record(InputRecord.java:593); 	at sun.security.ssl.InputRecord.read(InputRecord.java:532); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:105); 	... 14 more,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401
https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:2867,Security,secur,security,2867,org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3368); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:62); 	... 7 more; Caused by: java.net.SocketException: Connection reset; 	at java.net.SocketInputStream.read(SocketInputStream.java:210); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	at sun.security.ssl.InputRecord.readV3Record(InputRecord.java:593); 	at sun.security.ssl.InputRecord.read(InputRecord.java:532); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:105); 	... 14 more,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401
https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:2936,Security,secur,security,2936,org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3368); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:62); 	... 7 more; Caused by: java.net.SocketException: Connection reset; 	at java.net.SocketInputStream.read(SocketInputStream.java:210); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	at sun.security.ssl.InputRecord.readV3Record(InputRecord.java:593); 	at sun.security.ssl.InputRecord.read(InputRecord.java:532); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:105); 	... 14 more,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401
https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:2997,Security,secur,security,2997,org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3368); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:62); 	... 7 more; Caused by: java.net.SocketException: Connection reset; 	at java.net.SocketInputStream.read(SocketInputStream.java:210); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	at sun.security.ssl.InputRecord.readV3Record(InputRecord.java:593); 	at sun.security.ssl.InputRecord.read(InputRecord.java:532); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:105); 	... 14 more,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401
https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:3068,Security,secur,security,3068,org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3368); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:62); 	... 7 more; Caused by: java.net.SocketException: Connection reset; 	at java.net.SocketInputStream.read(SocketInputStream.java:210); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	at sun.security.ssl.InputRecord.readV3Record(InputRecord.java:593); 	at sun.security.ssl.InputRecord.read(InputRecord.java:532); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:105); 	... 14 more,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401
https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401:3143,Security,secur,security,3143,org.gradle.wrapper.Install$1.call(Install.java:48); 	at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:69); 	at org.gradle.wrapper.Install.createDist(Install.java:48); 	at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); 	at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); Caused by: javax.net.ssl.SSLException: java.net.SocketException: Connection reset; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1815); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:116); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3375); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3368); 	at org.gradle.wrapper.Download.downloadInternal(Download.java:62); 	... 7 more; Caused by: java.net.SocketException: Connection reset; 	at java.net.SocketInputStream.read(SocketInputStream.java:210); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	at sun.security.ssl.InputRecord.readV3Record(InputRecord.java:593); 	at sun.security.ssl.InputRecord.read(InputRecord.java:532); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:105); 	... 14 more,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4194#issuecomment-358498401
https://github.com/broadinstitute/gatk/pull/4195#issuecomment-359219837:3559,Usability,Simpl,SimpleSVType,3559,ools/walkers/mutect/SomaticLikelihoodsEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/4195/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9Tb21hdGljTGlrZWxpaG9vZHNFbmdpbmUuamF2YQ==) | `83.871% <0%> (-2.971%)` | `22% <0%> (+8%)` | |; | [...lignment/AssemblyContigAlignmentsConfigPicker.java](https://codecov.io/gh/broadinstitute/gatk/pull/4195/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvYWxpZ25tZW50L0Fzc2VtYmx5Q29udGlnQWxpZ25tZW50c0NvbmZpZ1BpY2tlci5qYXZh) | `72.8% <0%> (-1.427%)` | `39% <0%> (+10%)` | |; | [...tools/funcotator/dataSources/TableFuncotation.java](https://codecov.io/gh/broadinstitute/gatk/pull/4195/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL1RhYmxlRnVuY290YXRpb24uamF2YQ==) | `62.319% <0%> (-0.472%)` | `28% <0%> (+11%)` | |; | [...park/sv/discovery/alignment/AlignmentInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/4195/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvYWxpZ25tZW50L0FsaWdubWVudEludGVydmFsLmphdmE=) | `89.272% <0%> (-0.383%)` | `73% <0%> (-1%)` | |; | [...lbender/tools/spark/sv/discovery/SimpleSVType.java](https://codecov.io/gh/broadinstitute/gatk/pull/4195/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvU2ltcGxlU1ZUeXBlLmphdmE=) | `86.275% <0%> (-0.293%)` | `4% <0%> (+2%)` | |; | [.../hellbender/tools/genomicsdb/GenomicsDBImport.java](https://codecov.io/gh/broadinstitute/gatk/pull/4195/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9nZW5vbWljc2RiL0dlbm9taWNzREJJbXBvcnQuamF2YQ==) | `76.08% <0%> (-0.057%)` | `61% <0%> (+6%)` | |; | ... and [58 more](https://codecov.io/gh/broadinstitute/gatk/pull/4195/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4195#issuecomment-359219837
https://github.com/broadinstitute/gatk/issues/4198#issuecomment-900613847:21,Performance,perform,performance,21,I am not sure if any performance gained by having Spark versions of these tools is worth the support cost. Can reopen if we feel otherwise.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4198#issuecomment-900613847
https://github.com/broadinstitute/gatk/pull/4201#issuecomment-358696328:2565,Usability,Simpl,SimpleSVType,2565, (+5%)` | |; | [...tools/walkers/mutect/SomaticLikelihoodsEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/4201/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9Tb21hdGljTGlrZWxpaG9vZHNFbmdpbmUuamF2YQ==) | `83.871% <0%> (-2.971%)` | `25% <0%> (+11%)` | |; | [...tools/funcotator/dataSources/TableFuncotation.java](https://codecov.io/gh/broadinstitute/gatk/pull/4201/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL1RhYmxlRnVuY290YXRpb24uamF2YQ==) | `62.319% <0%> (-0.472%)` | `31% <0%> (+14%)` | |; | [...park/sv/discovery/alignment/AlignmentInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/4201/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvYWxpZ25tZW50L0FsaWdubWVudEludGVydmFsLmphdmE=) | `89.272% <0%> (-0.383%)` | `73% <0%> (-1%)` | |; | [...lbender/tools/spark/sv/discovery/SimpleSVType.java](https://codecov.io/gh/broadinstitute/gatk/pull/4201/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvU2ltcGxlU1ZUeXBlLmphdmE=) | `86.275% <0%> (-0.293%)` | `4% <0%> (+2%)` | |; | [.../hellbender/tools/genomicsdb/GenomicsDBImport.java](https://codecov.io/gh/broadinstitute/gatk/pull/4201/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9nZW5vbWljc2RiL0dlbm9taWNzREJJbXBvcnQuamF2YQ==) | `76.08% <0%> (-0.057%)` | `64% <0%> (+9%)` | |; | [...ynumber/models/AlleleFractionGlobalParameters.java](https://codecov.io/gh/broadinstitute/gatk/pull/4201/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL21vZGVscy9BbGxlbGVGcmFjdGlvbkdsb2JhbFBhcmFtZXRlcnMuamF2YQ==) | `100% <0%> (ø)` | `10% <0%> (ø)` | :arrow_down: |; | [.../tools/spark/sv/discovery/BreakEndVariantType.java](https://codecov.io/gh/broadinstitute/ga,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4201#issuecomment-358696328
https://github.com/broadinstitute/gatk/pull/4201#issuecomment-358766266:24,Availability,error,errors,24,@takutosato I fixed the errors you pointed out.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4201#issuecomment-358766266
https://github.com/broadinstitute/gatk/pull/4201#issuecomment-358775010:29,Testability,test,tests,29,"Great, please merge when the tests pass",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4201#issuecomment-358775010
https://github.com/broadinstitute/gatk/pull/4203#issuecomment-358765311:3295,Performance,Cache,CacheNode,3295,diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9NYXRoT2JqZWN0QXNzZXJ0cy5qYXZh) | `31.818% <0%> (ø)` | `5% <0%> (?)` | |; | [...e/hellbender/utils/icg/ComputableNodeFunction.java](https://codecov.io/gh/broadinstitute/gatk/pull/4203/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9pY2cvQ29tcHV0YWJsZU5vZGVGdW5jdGlvbi5qYXZh) | `100% <0%> (ø)` | `4% <0%> (?)` | |; | [...der/utils/linalg/GeneralLinearOperatorNDArray.java](https://codecov.io/gh/broadinstitute/gatk/pull/4203/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9saW5hbGcvR2VuZXJhbExpbmVhck9wZXJhdG9yTkRBcnJheS5qYXZh) | `66.667% <0%> (ø)` | `4% <0%> (?)` | |; | [...hellbender/utils/icg/ComputableGraphStructure.java](https://codecov.io/gh/broadinstitute/gatk/pull/4203/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9pY2cvQ29tcHV0YWJsZUdyYXBoU3RydWN0dXJlLmphdmE=) | `100% <0%> (ø)` | `63% <0%> (?)` | |; | [...ender/utils/icg/ImmutableComputableGraphUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4203/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9pY2cvSW1tdXRhYmxlQ29tcHV0YWJsZUdyYXBoVXRpbHMuamF2YQ==) | `81.081% <0%> (ø)` | `1% <0%> (?)` | |; | [...broadinstitute/hellbender/utils/icg/CacheNode.java](https://codecov.io/gh/broadinstitute/gatk/pull/4203/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9pY2cvQ2FjaGVOb2RlLmphdmE=) | `80.645% <0%> (ø)` | `9% <0%> (?)` | |; | [.../hellbender/utils/nd4j/Nd4jApacheAdapterUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4203/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9uZDRqL05kNGpBcGFjaGVBZGFwdGVyVXRpbHMuamF2YQ==) | `85.714% <0%> (ø)` | `12% <0%> (?)` | |; | ... and [15 more](https://codecov.io/gh/broadinstitute/gatk/pull/4203/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4203#issuecomment-358765311
https://github.com/broadinstitute/gatk/pull/4205#issuecomment-358979126:24,Deployability,integrat,integration,24,"@LeeTL1220 Just noticed integration tests are failing...perhaps I should continue reviewing, and you can address comments and the tests at the same time?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4205#issuecomment-358979126
https://github.com/broadinstitute/gatk/pull/4205#issuecomment-358979126:24,Integrability,integrat,integration,24,"@LeeTL1220 Just noticed integration tests are failing...perhaps I should continue reviewing, and you can address comments and the tests at the same time?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4205#issuecomment-358979126
https://github.com/broadinstitute/gatk/pull/4205#issuecomment-358979126:36,Testability,test,tests,36,"@LeeTL1220 Just noticed integration tests are failing...perhaps I should continue reviewing, and you can address comments and the tests at the same time?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4205#issuecomment-358979126
https://github.com/broadinstitute/gatk/pull/4205#issuecomment-358979126:130,Testability,test,tests,130,"@LeeTL1220 Just noticed integration tests are failing...perhaps I should continue reviewing, and you can address comments and the tests at the same time?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4205#issuecomment-358979126
https://github.com/broadinstitute/gatk/issues/4206#issuecomment-359011487:21,Testability,test,tests,21,Looks like some VQSR tests that are not properly cleaning up after themselves.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4206#issuecomment-359011487
https://github.com/broadinstitute/gatk/pull/4207#issuecomment-359069626:1251,Deployability,pipeline,pipelines,1251,4c898cb4c33fb4c4db?src=pr&el=desc) will **decrease** coverage by `0.409%`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #4207 +/- ##; ===============================================; - Coverage 78.477% 78.067% -0.409% ; + Complexity 16424 16352 -72 ; ===============================================; Files 1041 1041 ; Lines 59099 59099 ; Branches 9673 9673 ; ===============================================; - Hits 46379 46137 -242 ; - Misses 8978 9231 +253 ; + Partials 3742 3731 -11; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4207?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4207/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-75.51%)` | `0% <0%> (-17%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4207/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/4207/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...lbender/engine/datasources/ReferenceAPISource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4207/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `25.735% <0%> (-44.853%)` | `8% <0%> (-19%)` | |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/4207/diff?src=pr&el=tree#diff-c3J,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4207#issuecomment-359069626
https://github.com/broadinstitute/gatk/pull/4207#issuecomment-359069626:1567,Testability,test,test,1567,=====================; Files 1041 1041 ; Lines 59099 59099 ; Branches 9673 9673 ; ===============================================; - Hits 46379 46137 -242 ; - Misses 8978 9231 +253 ; + Partials 3742 3731 -11; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4207?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4207/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-75.51%)` | `0% <0%> (-17%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4207/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/4207/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...lbender/engine/datasources/ReferenceAPISource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4207/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `25.735% <0%> (-44.853%)` | `8% <0%> (-19%)` | |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/4207/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `50% <0%> (-30%)` | `1% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4207/diff?src=pr&el=tree#dif,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4207#issuecomment-359069626
https://github.com/broadinstitute/gatk/pull/4207#issuecomment-359069626:3353,Testability,test,test,3353,bmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `25.735% <0%> (-44.853%)` | `8% <0%> (-19%)` | |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/4207/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `50% <0%> (-30%)` | `1% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4207/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `54.194% <0%> (-25.806%)` | `30% <0%> (-9%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/4207/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `0% <0%> (-22.807%)` | `0% <0%> (-2%)` | |; | [...ender/engine/datasources/ReferenceMultiSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4207/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlTXVsdGlTb3VyY2UuamF2YQ==) | `61.538% <0%> (-15.385%)` | `9% <0%> (-2%)` | |; | [...titute/hellbender/utils/test/MiniClusterUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4207/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L01pbmlDbHVzdGVyVXRpbHMuamF2YQ==) | `78.947% <0%> (-10.526%)` | `6% <0%> (-1%)` | |; | [...institute/hellbender/exceptions/UserException.java](https://codecov.io/gh/broadinstitute/gatk/pull/4207/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9leGNlcHRpb25zL1VzZXJFeGNlcHRpb24uamF2YQ==) | `67.176% <0%> (-3.053%)` | `3% <0%> (ø)` | |; | ... and [10 more](https://codecov.io/gh/broadinstitute/gatk/pull/4207/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4207#issuecomment-359069626
https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359064404:573,Usability,simpl,simplest,573,"@byoo Thanks for reporting these issues. I'm going to move the R issue into a separate ticket, since its a bigger change than the python fix. I'm not sure I understand this part, though:. > Unzipping the package file locates both files in the same directory and, to me, it is natural to create the conda environment in the directory. There should be no need to manually unzip the package archive (maybe you did this as part of the workaround for bad path in the .yml ?). And you should be able to direct conda to create the env wherever you want it - we just suggested the simplest possible default case. Let me know if I'm misunderstanding your suggestion.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359064404
https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359073267:71,Deployability,release,release,71,"@cmnbroad Sorry I should have been clearer. I meant unzipping the gatk release file. Unzipping the gatk release file places both files in the sample directory as below. I tried to create the gatk conda environment in the directory, which was failed due to the path issue.; ```; $ unzip src/gatk-4.0.0.0.zip; Archive: src/gatk-4.0.0.0.zip; creating: gatk-4.0.0.0/; inflating: gatk-4.0.0.0/gatk-package-4.0.0.0-local.jar; inflating: gatk-4.0.0.0/gatk-package-4.0.0.0-spark.jar; inflating: gatk-4.0.0.0/gatk; inflating: gatk-4.0.0.0/README.md; inflating: gatk-4.0.0.0/gatk-completion.sh; inflating: gatk-4.0.0.0/gatkcondaenv.yml; inflating: gatk-4.0.0.0/gatkPythonPackageArchive.zip; $ cd gatk-4.0.0.0; $ conda env create -n gatk -f gatkcondaenv.yml; ```. It appears simpler to have conda manage both Python and R dependencies. I am not sure if it's easily possible to move away from R-3.2.5 though. Thank you!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359073267
https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359073267:104,Deployability,release,release,104,"@cmnbroad Sorry I should have been clearer. I meant unzipping the gatk release file. Unzipping the gatk release file places both files in the sample directory as below. I tried to create the gatk conda environment in the directory, which was failed due to the path issue.; ```; $ unzip src/gatk-4.0.0.0.zip; Archive: src/gatk-4.0.0.0.zip; creating: gatk-4.0.0.0/; inflating: gatk-4.0.0.0/gatk-package-4.0.0.0-local.jar; inflating: gatk-4.0.0.0/gatk-package-4.0.0.0-spark.jar; inflating: gatk-4.0.0.0/gatk; inflating: gatk-4.0.0.0/README.md; inflating: gatk-4.0.0.0/gatk-completion.sh; inflating: gatk-4.0.0.0/gatkcondaenv.yml; inflating: gatk-4.0.0.0/gatkPythonPackageArchive.zip; $ cd gatk-4.0.0.0; $ conda env create -n gatk -f gatkcondaenv.yml; ```. It appears simpler to have conda manage both Python and R dependencies. I am not sure if it's easily possible to move away from R-3.2.5 though. Thank you!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359073267
https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359073267:811,Integrability,depend,dependencies,811,"@cmnbroad Sorry I should have been clearer. I meant unzipping the gatk release file. Unzipping the gatk release file places both files in the sample directory as below. I tried to create the gatk conda environment in the directory, which was failed due to the path issue.; ```; $ unzip src/gatk-4.0.0.0.zip; Archive: src/gatk-4.0.0.0.zip; creating: gatk-4.0.0.0/; inflating: gatk-4.0.0.0/gatk-package-4.0.0.0-local.jar; inflating: gatk-4.0.0.0/gatk-package-4.0.0.0-spark.jar; inflating: gatk-4.0.0.0/gatk; inflating: gatk-4.0.0.0/README.md; inflating: gatk-4.0.0.0/gatk-completion.sh; inflating: gatk-4.0.0.0/gatkcondaenv.yml; inflating: gatk-4.0.0.0/gatkPythonPackageArchive.zip; $ cd gatk-4.0.0.0; $ conda env create -n gatk -f gatkcondaenv.yml; ```. It appears simpler to have conda manage both Python and R dependencies. I am not sure if it's easily possible to move away from R-3.2.5 though. Thank you!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359073267
https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359073267:35,Usability,clear,clearer,35,"@cmnbroad Sorry I should have been clearer. I meant unzipping the gatk release file. Unzipping the gatk release file places both files in the sample directory as below. I tried to create the gatk conda environment in the directory, which was failed due to the path issue.; ```; $ unzip src/gatk-4.0.0.0.zip; Archive: src/gatk-4.0.0.0.zip; creating: gatk-4.0.0.0/; inflating: gatk-4.0.0.0/gatk-package-4.0.0.0-local.jar; inflating: gatk-4.0.0.0/gatk-package-4.0.0.0-spark.jar; inflating: gatk-4.0.0.0/gatk; inflating: gatk-4.0.0.0/README.md; inflating: gatk-4.0.0.0/gatk-completion.sh; inflating: gatk-4.0.0.0/gatkcondaenv.yml; inflating: gatk-4.0.0.0/gatkPythonPackageArchive.zip; $ cd gatk-4.0.0.0; $ conda env create -n gatk -f gatkcondaenv.yml; ```. It appears simpler to have conda manage both Python and R dependencies. I am not sure if it's easily possible to move away from R-3.2.5 though. Thank you!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359073267
https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359073267:764,Usability,simpl,simpler,764,"@cmnbroad Sorry I should have been clearer. I meant unzipping the gatk release file. Unzipping the gatk release file places both files in the sample directory as below. I tried to create the gatk conda environment in the directory, which was failed due to the path issue.; ```; $ unzip src/gatk-4.0.0.0.zip; Archive: src/gatk-4.0.0.0.zip; creating: gatk-4.0.0.0/; inflating: gatk-4.0.0.0/gatk-package-4.0.0.0-local.jar; inflating: gatk-4.0.0.0/gatk-package-4.0.0.0-spark.jar; inflating: gatk-4.0.0.0/gatk; inflating: gatk-4.0.0.0/README.md; inflating: gatk-4.0.0.0/gatk-completion.sh; inflating: gatk-4.0.0.0/gatkcondaenv.yml; inflating: gatk-4.0.0.0/gatkPythonPackageArchive.zip; $ cd gatk-4.0.0.0; $ conda env create -n gatk -f gatkcondaenv.yml; ```. It appears simpler to have conda manage both Python and R dependencies. I am not sure if it's easily possible to move away from R-3.2.5 though. Thank you!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359073267
https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359074433:62,Deployability,install,installed,62,"I think we could probably change away from 3.25, I have 3.4.3 installed on my machine and tests run fine. We just chose one arbitrarily that worked and set it at that so that it wouldn't change out from under us.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359074433
https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359074433:90,Testability,test,tests,90,"I think we could probably change away from 3.25, I have 3.4.3 installed on my machine and tests run fine. We just chose one arbitrarily that worked and set it at that so that it wouldn't change out from under us.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359074433
https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359096527:47,Integrability,depend,depend,47,@lbergelson Do we actually have any tests that depend on R besides the RScriptExecutor tests (which don't do much). Also wondering if there would be inconsistencies with Picard R requirements.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359096527
https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359096527:36,Testability,test,tests,36,@lbergelson Do we actually have any tests that depend on R besides the RScriptExecutor tests (which don't do much). Also wondering if there would be inconsistencies with Picard R requirements.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359096527
https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359096527:87,Testability,test,tests,87,@lbergelson Do we actually have any tests that depend on R besides the RScriptExecutor tests (which don't do much). Also wondering if there would be inconsistencies with Picard R requirements.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359096527
https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359099269:138,Deployability,install,installation,138,"@cmnbroad There used to be, but I don't actually know for sure. I'm not sure how to figure it out either without just deleting R from the installation and running the test suite... I didn't know picard required R?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359099269
https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359099269:167,Testability,test,test,167,"@cmnbroad There used to be, but I don't actually know for sure. I'm not sure how to figure it out either without just deleting R from the installation and running the test suite... I didn't know picard required R?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359099269
https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359102155:105,Integrability,depend,dependencies,105,"There are tests for the CNV plotting tools, which use RScriptExecutor and uniquely require some of the R dependencies. There's also a test for the HMM code, which uses an HMM R package to generate expected results. I'd assume that tests for the other tools that use RScriptExecutor would also fail, but I don't know if they rely on any special dependencies or any particular version of R.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359102155
https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359102155:344,Integrability,depend,dependencies,344,"There are tests for the CNV plotting tools, which use RScriptExecutor and uniquely require some of the R dependencies. There's also a test for the HMM code, which uses an HMM R package to generate expected results. I'd assume that tests for the other tools that use RScriptExecutor would also fail, but I don't know if they rely on any special dependencies or any particular version of R.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359102155
https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359102155:10,Testability,test,tests,10,"There are tests for the CNV plotting tools, which use RScriptExecutor and uniquely require some of the R dependencies. There's also a test for the HMM code, which uses an HMM R package to generate expected results. I'd assume that tests for the other tools that use RScriptExecutor would also fail, but I don't know if they rely on any special dependencies or any particular version of R.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359102155
https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359102155:134,Testability,test,test,134,"There are tests for the CNV plotting tools, which use RScriptExecutor and uniquely require some of the R dependencies. There's also a test for the HMM code, which uses an HMM R package to generate expected results. I'd assume that tests for the other tools that use RScriptExecutor would also fail, but I don't know if they rely on any special dependencies or any particular version of R.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359102155
https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359102155:231,Testability,test,tests,231,"There are tests for the CNV plotting tools, which use RScriptExecutor and uniquely require some of the R dependencies. There's also a test for the HMM code, which uses an HMM R package to generate expected results. I'd assume that tests for the other tools that use RScriptExecutor would also fail, but I don't know if they rely on any special dependencies or any particular version of R.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359102155
https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359983165:48,Integrability,depend,dependency,48,"OK, I think I accidentally removed the `getopt` dependency in #3935. Not sure why tests didn't fail as expected. EDIT: I think this is because R dependencies are cached on Travis.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359983165
https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359983165:145,Integrability,depend,dependencies,145,"OK, I think I accidentally removed the `getopt` dependency in #3935. Not sure why tests didn't fail as expected. EDIT: I think this is because R dependencies are cached on Travis.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359983165
https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359983165:162,Performance,cache,cached,162,"OK, I think I accidentally removed the `getopt` dependency in #3935. Not sure why tests didn't fail as expected. EDIT: I think this is because R dependencies are cached on Travis.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359983165
https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359983165:82,Testability,test,tests,82,"OK, I think I accidentally removed the `getopt` dependency in #3935. Not sure why tests didn't fail as expected. EDIT: I think this is because R dependencies are cached on Travis.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359983165
https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359984275:35,Deployability,update,update,35,"Hmm, I also realize that I did not update the base Docker image at that time---although I commented in the PR that we should...and I don't think we updated it before release. So I *think* the latest base and the current 4.0.0.0 release Docker contain the getopt dependency, although it was removed from the installation script.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359984275
https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359984275:148,Deployability,update,updated,148,"Hmm, I also realize that I did not update the base Docker image at that time---although I commented in the PR that we should...and I don't think we updated it before release. So I *think* the latest base and the current 4.0.0.0 release Docker contain the getopt dependency, although it was removed from the installation script.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359984275
https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359984275:166,Deployability,release,release,166,"Hmm, I also realize that I did not update the base Docker image at that time---although I commented in the PR that we should...and I don't think we updated it before release. So I *think* the latest base and the current 4.0.0.0 release Docker contain the getopt dependency, although it was removed from the installation script.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359984275
https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359984275:228,Deployability,release,release,228,"Hmm, I also realize that I did not update the base Docker image at that time---although I commented in the PR that we should...and I don't think we updated it before release. So I *think* the latest base and the current 4.0.0.0 release Docker contain the getopt dependency, although it was removed from the installation script.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359984275
https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359984275:307,Deployability,install,installation,307,"Hmm, I also realize that I did not update the base Docker image at that time---although I commented in the PR that we should...and I don't think we updated it before release. So I *think* the latest base and the current 4.0.0.0 release Docker contain the getopt dependency, although it was removed from the installation script.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359984275
https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359984275:262,Integrability,depend,dependency,262,"Hmm, I also realize that I did not update the base Docker image at that time---although I commented in the PR that we should...and I don't think we updated it before release. So I *think* the latest base and the current 4.0.0.0 release Docker contain the getopt dependency, although it was removed from the installation script.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359984275
https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359985913:128,Integrability,depend,dependency,128,"Going to build and push a new 1.2.2 base image off of https://github.com/broadinstitute/gatk/tree/sl_getopt, which restores the dependency as it was previously.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359985913
https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359999441:215,Availability,error,error,215,"Regarding the non-Docker integration tests failing earlier today, I think this was because the R packages were added to the Travis cache in #3101. @cmnbroad cleared the cache to see if we could reproduce a compiler error introduced in #3934 on Travis (for the record, we could reproduce it on my local Ubuntu machine and gsa5, but not on Travis). This removed the cached getopt dependency, which then caused tests to fail. See #4246.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359999441
https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359999441:25,Deployability,integrat,integration,25,"Regarding the non-Docker integration tests failing earlier today, I think this was because the R packages were added to the Travis cache in #3101. @cmnbroad cleared the cache to see if we could reproduce a compiler error introduced in #3934 on Travis (for the record, we could reproduce it on my local Ubuntu machine and gsa5, but not on Travis). This removed the cached getopt dependency, which then caused tests to fail. See #4246.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359999441
https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359999441:25,Integrability,integrat,integration,25,"Regarding the non-Docker integration tests failing earlier today, I think this was because the R packages were added to the Travis cache in #3101. @cmnbroad cleared the cache to see if we could reproduce a compiler error introduced in #3934 on Travis (for the record, we could reproduce it on my local Ubuntu machine and gsa5, but not on Travis). This removed the cached getopt dependency, which then caused tests to fail. See #4246.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359999441
https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359999441:378,Integrability,depend,dependency,378,"Regarding the non-Docker integration tests failing earlier today, I think this was because the R packages were added to the Travis cache in #3101. @cmnbroad cleared the cache to see if we could reproduce a compiler error introduced in #3934 on Travis (for the record, we could reproduce it on my local Ubuntu machine and gsa5, but not on Travis). This removed the cached getopt dependency, which then caused tests to fail. See #4246.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359999441
https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359999441:131,Performance,cache,cache,131,"Regarding the non-Docker integration tests failing earlier today, I think this was because the R packages were added to the Travis cache in #3101. @cmnbroad cleared the cache to see if we could reproduce a compiler error introduced in #3934 on Travis (for the record, we could reproduce it on my local Ubuntu machine and gsa5, but not on Travis). This removed the cached getopt dependency, which then caused tests to fail. See #4246.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359999441
https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359999441:169,Performance,cache,cache,169,"Regarding the non-Docker integration tests failing earlier today, I think this was because the R packages were added to the Travis cache in #3101. @cmnbroad cleared the cache to see if we could reproduce a compiler error introduced in #3934 on Travis (for the record, we could reproduce it on my local Ubuntu machine and gsa5, but not on Travis). This removed the cached getopt dependency, which then caused tests to fail. See #4246.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359999441
https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359999441:364,Performance,cache,cached,364,"Regarding the non-Docker integration tests failing earlier today, I think this was because the R packages were added to the Travis cache in #3101. @cmnbroad cleared the cache to see if we could reproduce a compiler error introduced in #3934 on Travis (for the record, we could reproduce it on my local Ubuntu machine and gsa5, but not on Travis). This removed the cached getopt dependency, which then caused tests to fail. See #4246.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359999441
https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359999441:37,Testability,test,tests,37,"Regarding the non-Docker integration tests failing earlier today, I think this was because the R packages were added to the Travis cache in #3101. @cmnbroad cleared the cache to see if we could reproduce a compiler error introduced in #3934 on Travis (for the record, we could reproduce it on my local Ubuntu machine and gsa5, but not on Travis). This removed the cached getopt dependency, which then caused tests to fail. See #4246.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359999441
https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359999441:408,Testability,test,tests,408,"Regarding the non-Docker integration tests failing earlier today, I think this was because the R packages were added to the Travis cache in #3101. @cmnbroad cleared the cache to see if we could reproduce a compiler error introduced in #3934 on Travis (for the record, we could reproduce it on my local Ubuntu machine and gsa5, but not on Travis). This removed the cached getopt dependency, which then caused tests to fail. See #4246.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359999441
https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359999441:157,Usability,clear,cleared,157,"Regarding the non-Docker integration tests failing earlier today, I think this was because the R packages were added to the Travis cache in #3101. @cmnbroad cleared the cache to see if we could reproduce a compiler error introduced in #3934 on Travis (for the record, we could reproduce it on my local Ubuntu machine and gsa5, but not on Travis). This removed the cached getopt dependency, which then caused tests to fail. See #4246.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4209#issuecomment-359999441
https://github.com/broadinstitute/gatk/pull/4210#issuecomment-359070350:102,Deployability,upgrade,upgrade,102,@lbergelson The old File SequenceDictionaryExtractor methods are still there right ? If not we should upgrade picard as well.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4210#issuecomment-359070350
https://github.com/broadinstitute/gatk/pull/4210#issuecomment-359072893:71,Testability,test,tests,71,"Looks like these were just deprecated, so they should be ok. :+1: when tests pass.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4210#issuecomment-359072893
https://github.com/broadinstitute/gatk/pull/4210#issuecomment-359081841:1232,Deployability,Update,UpdateVCFSequenceDictionary,1232,35a3dcede3670208eb1a4c898cb4c33fb4c4db?src=pr&el=desc) will **decrease** coverage by `0.007%`.; > The diff coverage is `33.333%`. ```diff; @@ Coverage Diff @@; ## master #4210 +/- ##; ==============================================; - Coverage 78.477% 78.47% -0.007% ; + Complexity 16424 16423 -1 ; ==============================================; Files 1041 1041 ; Lines 59099 59099 ; Branches 9673 9673 ; ==============================================; - Hits 46379 46375 -4 ; - Misses 8978 8981 +3 ; - Partials 3742 3743 +1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4210?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...llbender/utils/test/SimpleIntervalTestFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/4210/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1NpbXBsZUludGVydmFsVGVzdEZhY3RvcnkuamF2YQ==) | `0% <0%> (ø)` | `0 <0> (ø)` | :arrow_down: |; | [...kers/variantutils/UpdateVCFSequenceDictionary.java](https://codecov.io/gh/broadinstitute/gatk/pull/4210/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9VcGRhdGVWQ0ZTZXF1ZW5jZURpY3Rpb25hcnkuamF2YQ==) | `86.957% <100%> (ø)` | `14 <0> (ø)` | :arrow_down: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/4210/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `71.233% <0%> (-2.74%)` | `11% <0%> (ø)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4210/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `78.71% <0%> (-1.29%)` | `39% <0%> (ø)` | |; | [...park/sv/discovery/alignment/AlignmentInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/4210/diff?src=pr&e,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4210#issuecomment-359081841
https://github.com/broadinstitute/gatk/pull/4210#issuecomment-359081841:928,Testability,test,test,928,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4210?src=pr&el=h1) Report; > Merging [#4210](https://codecov.io/gh/broadinstitute/gatk/pull/4210?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/9c35a3dcede3670208eb1a4c898cb4c33fb4c4db?src=pr&el=desc) will **decrease** coverage by `0.007%`.; > The diff coverage is `33.333%`. ```diff; @@ Coverage Diff @@; ## master #4210 +/- ##; ==============================================; - Coverage 78.477% 78.47% -0.007% ; + Complexity 16424 16423 -1 ; ==============================================; Files 1041 1041 ; Lines 59099 59099 ; Branches 9673 9673 ; ==============================================; - Hits 46379 46375 -4 ; - Misses 8978 8981 +3 ; - Partials 3742 3743 +1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4210?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...llbender/utils/test/SimpleIntervalTestFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/4210/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1NpbXBsZUludGVydmFsVGVzdEZhY3RvcnkuamF2YQ==) | `0% <0%> (ø)` | `0 <0> (ø)` | :arrow_down: |; | [...kers/variantutils/UpdateVCFSequenceDictionary.java](https://codecov.io/gh/broadinstitute/gatk/pull/4210/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9VcGRhdGVWQ0ZTZXF1ZW5jZURpY3Rpb25hcnkuamF2YQ==) | `86.957% <100%> (ø)` | `14 <0> (ø)` | :arrow_down: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/4210/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `71.233% <0%> (-2.74%)` | `11% <0%> (ø)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4210/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRp,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4210#issuecomment-359081841
https://github.com/broadinstitute/gatk/pull/4210#issuecomment-359081841:933,Usability,Simpl,SimpleIntervalTestFactory,933,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4210?src=pr&el=h1) Report; > Merging [#4210](https://codecov.io/gh/broadinstitute/gatk/pull/4210?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/9c35a3dcede3670208eb1a4c898cb4c33fb4c4db?src=pr&el=desc) will **decrease** coverage by `0.007%`.; > The diff coverage is `33.333%`. ```diff; @@ Coverage Diff @@; ## master #4210 +/- ##; ==============================================; - Coverage 78.477% 78.47% -0.007% ; + Complexity 16424 16423 -1 ; ==============================================; Files 1041 1041 ; Lines 59099 59099 ; Branches 9673 9673 ; ==============================================; - Hits 46379 46375 -4 ; - Misses 8978 8981 +3 ; - Partials 3742 3743 +1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4210?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...llbender/utils/test/SimpleIntervalTestFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/4210/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1NpbXBsZUludGVydmFsVGVzdEZhY3RvcnkuamF2YQ==) | `0% <0%> (ø)` | `0 <0> (ø)` | :arrow_down: |; | [...kers/variantutils/UpdateVCFSequenceDictionary.java](https://codecov.io/gh/broadinstitute/gatk/pull/4210/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9VcGRhdGVWQ0ZTZXF1ZW5jZURpY3Rpb25hcnkuamF2YQ==) | `86.957% <100%> (ø)` | `14 <0> (ø)` | :arrow_down: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/4210/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `71.233% <0%> (-2.74%)` | `11% <0%> (ø)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4210/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRp,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4210#issuecomment-359081841
https://github.com/broadinstitute/gatk/pull/4212#issuecomment-359098274:3078,Deployability,Update,UpdateVCFSequenceDictionary,3078,0aW9uL2NvdmFyaWF0ZXMvQ29udGV4dENvdmFyaWF0ZS5qYXZh) | `92.727% <ø> (ø)` | `34 <0> (ø)` | :arrow_down: |; | [...oadinstitute/hellbender/engine/AssemblyRegion.java](https://codecov.io/gh/broadinstitute/gatk/pull/4212/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvQXNzZW1ibHlSZWdpb24uamF2YQ==) | `85.475% <0%> (ø)` | `62 <0> (ø)` | :arrow_down: |; | [...er/tools/walkers/rnaseq/OverhangFixingManager.java](https://codecov.io/gh/broadinstitute/gatk/pull/4212/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3JuYXNlcS9PdmVyaGFuZ0ZpeGluZ01hbmFnZXIuamF2YQ==) | `94.079% <100%> (+1.268%)` | `67 <0> (+1)` | :arrow_up: |; | [...llbender/utils/test/SimpleIntervalTestFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/4212/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1NpbXBsZUludGVydmFsVGVzdEZhY3RvcnkuamF2YQ==) | `0% <0%> (ø)` | `0% <0%> (ø)` | :arrow_down: |; | [...park/sv/discovery/alignment/AlignmentInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/4212/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvYWxpZ25tZW50L0FsaWdubWVudEludGVydmFsLmphdmE=) | `89.655% <0%> (ø)` | `74% <0%> (ø)` | :arrow_down: |; | [...kers/variantutils/UpdateVCFSequenceDictionary.java](https://codecov.io/gh/broadinstitute/gatk/pull/4212/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9VcGRhdGVWQ0ZTZXF1ZW5jZURpY3Rpb25hcnkuamF2YQ==) | `93.846% <0%> (+6.89%)` | `15% <0%> (+1%)` | :arrow_up: |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/4212/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `90% <0%> (+10%)` | `3% <0%> (ø)` | :arrow_down: |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4212#issuecomment-359098274
https://github.com/broadinstitute/gatk/pull/4212#issuecomment-359098274:2443,Testability,test,test,2443,% <ø> (ø)` | `93 <0> (ø)` | :arrow_down: |; | [...ils/recalibration/covariates/ContextCovariate.java](https://codecov.io/gh/broadinstitute/gatk/pull/4212/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWNhbGlicmF0aW9uL2NvdmFyaWF0ZXMvQ29udGV4dENvdmFyaWF0ZS5qYXZh) | `92.727% <ø> (ø)` | `34 <0> (ø)` | :arrow_down: |; | [...oadinstitute/hellbender/engine/AssemblyRegion.java](https://codecov.io/gh/broadinstitute/gatk/pull/4212/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvQXNzZW1ibHlSZWdpb24uamF2YQ==) | `85.475% <0%> (ø)` | `62 <0> (ø)` | :arrow_down: |; | [...er/tools/walkers/rnaseq/OverhangFixingManager.java](https://codecov.io/gh/broadinstitute/gatk/pull/4212/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3JuYXNlcS9PdmVyaGFuZ0ZpeGluZ01hbmFnZXIuamF2YQ==) | `94.079% <100%> (+1.268%)` | `67 <0> (+1)` | :arrow_up: |; | [...llbender/utils/test/SimpleIntervalTestFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/4212/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1NpbXBsZUludGVydmFsVGVzdEZhY3RvcnkuamF2YQ==) | `0% <0%> (ø)` | `0% <0%> (ø)` | :arrow_down: |; | [...park/sv/discovery/alignment/AlignmentInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/4212/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvYWxpZ25tZW50L0FsaWdubWVudEludGVydmFsLmphdmE=) | `89.655% <0%> (ø)` | `74% <0%> (ø)` | :arrow_down: |; | [...kers/variantutils/UpdateVCFSequenceDictionary.java](https://codecov.io/gh/broadinstitute/gatk/pull/4212/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9VcGRhdGVWQ0ZTZXF1ZW5jZURpY3Rpb25hcnkuamF2YQ==) | `93.846% <0%> (+6.89%)` | `15% <0%> (+1%)` | :arrow_up: |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](h,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4212#issuecomment-359098274
https://github.com/broadinstitute/gatk/pull/4212#issuecomment-359098274:2448,Usability,Simpl,SimpleIntervalTestFactory,2448,% <ø> (ø)` | `93 <0> (ø)` | :arrow_down: |; | [...ils/recalibration/covariates/ContextCovariate.java](https://codecov.io/gh/broadinstitute/gatk/pull/4212/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWNhbGlicmF0aW9uL2NvdmFyaWF0ZXMvQ29udGV4dENvdmFyaWF0ZS5qYXZh) | `92.727% <ø> (ø)` | `34 <0> (ø)` | :arrow_down: |; | [...oadinstitute/hellbender/engine/AssemblyRegion.java](https://codecov.io/gh/broadinstitute/gatk/pull/4212/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvQXNzZW1ibHlSZWdpb24uamF2YQ==) | `85.475% <0%> (ø)` | `62 <0> (ø)` | :arrow_down: |; | [...er/tools/walkers/rnaseq/OverhangFixingManager.java](https://codecov.io/gh/broadinstitute/gatk/pull/4212/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3JuYXNlcS9PdmVyaGFuZ0ZpeGluZ01hbmFnZXIuamF2YQ==) | `94.079% <100%> (+1.268%)` | `67 <0> (+1)` | :arrow_up: |; | [...llbender/utils/test/SimpleIntervalTestFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/4212/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1NpbXBsZUludGVydmFsVGVzdEZhY3RvcnkuamF2YQ==) | `0% <0%> (ø)` | `0% <0%> (ø)` | :arrow_down: |; | [...park/sv/discovery/alignment/AlignmentInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/4212/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvYWxpZ25tZW50L0FsaWdubWVudEludGVydmFsLmphdmE=) | `89.655% <0%> (ø)` | `74% <0%> (ø)` | :arrow_down: |; | [...kers/variantutils/UpdateVCFSequenceDictionary.java](https://codecov.io/gh/broadinstitute/gatk/pull/4212/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9VcGRhdGVWQ0ZTZXF1ZW5jZURpY3Rpb25hcnkuamF2YQ==) | `93.846% <0%> (+6.89%)` | `15% <0%> (+1%)` | :arrow_up: |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](h,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4212#issuecomment-359098274
https://github.com/broadinstitute/gatk/pull/4212#issuecomment-420053841:44,Availability,error,error,44,@jamesemery This is failing with a compiler error:. ```; error: package org.testng.annotations does not exist; import org.testng.annotations.Test; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4212#issuecomment-420053841
https://github.com/broadinstitute/gatk/pull/4212#issuecomment-420053841:57,Availability,error,error,57,@jamesemery This is failing with a compiler error:. ```; error: package org.testng.annotations does not exist; import org.testng.annotations.Test; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4212#issuecomment-420053841
https://github.com/broadinstitute/gatk/pull/4212#issuecomment-420053841:76,Testability,test,testng,76,@jamesemery This is failing with a compiler error:. ```; error: package org.testng.annotations does not exist; import org.testng.annotations.Test; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4212#issuecomment-420053841
https://github.com/broadinstitute/gatk/pull/4212#issuecomment-420053841:122,Testability,test,testng,122,@jamesemery This is failing with a compiler error:. ```; error: package org.testng.annotations does not exist; import org.testng.annotations.Test; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4212#issuecomment-420053841
https://github.com/broadinstitute/gatk/pull/4212#issuecomment-420053841:141,Testability,Test,Test,141,@jamesemery This is failing with a compiler error:. ```; error: package org.testng.annotations does not exist; import org.testng.annotations.Test; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4212#issuecomment-420053841
https://github.com/broadinstitute/gatk/pull/4212#issuecomment-420295205:19,Availability,error,error,19,@droazen Fixed the error,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4212#issuecomment-420295205
https://github.com/broadinstitute/gatk/pull/4213#issuecomment-359306361:1597,Deployability,pipeline,pipelines,1597,nes 59099 59100 +1 ; Branches 9673 9673 ; ===============================================; - Hits 46374 46144 -230 ; - Misses 8983 9225 +242 ; + Partials 3742 3731 -11; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4213?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...s/haplotypecaller/graphs/CommonSuffixSplitter.java](https://codecov.io/gh/broadinstitute/gatk/pull/4213/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9ncmFwaHMvQ29tbW9uU3VmZml4U3BsaXR0ZXIuamF2YQ==) | `91.045% <100%> (+0.136%)` | `21 <0> (ø)` | :arrow_down: |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4213/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-75.51%)` | `0% <0%> (-17%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4213/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/4213/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...lbender/engine/datasources/ReferenceAPISource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4213/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `25.735% <0%> (-44.853%)` | `8% <0%> (-19%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4213/diff?src=pr&el=tree#diff-c3J,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4213#issuecomment-359306361
https://github.com/broadinstitute/gatk/pull/4213#issuecomment-359306361:1913,Testability,test,test,1913,---|---|; | [...s/haplotypecaller/graphs/CommonSuffixSplitter.java](https://codecov.io/gh/broadinstitute/gatk/pull/4213/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9ncmFwaHMvQ29tbW9uU3VmZml4U3BsaXR0ZXIuamF2YQ==) | `91.045% <100%> (+0.136%)` | `21 <0> (ø)` | :arrow_down: |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4213/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-75.51%)` | `0% <0%> (-17%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4213/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/4213/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...lbender/engine/datasources/ReferenceAPISource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4213/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `25.735% <0%> (-44.853%)` | `8% <0%> (-19%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4213/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `54.194% <0%> (-25.806%)` | `30% <0%> (-9%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/4213/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vc,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4213#issuecomment-359306361
https://github.com/broadinstitute/gatk/pull/4213#issuecomment-359306361:3391,Testability,test,test,3391,JvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...lbender/engine/datasources/ReferenceAPISource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4213/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `25.735% <0%> (-44.853%)` | `8% <0%> (-19%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4213/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `54.194% <0%> (-25.806%)` | `30% <0%> (-9%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/4213/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `0% <0%> (-22.807%)` | `0% <0%> (-2%)` | |; | [...ender/engine/datasources/ReferenceMultiSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4213/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlTXVsdGlTb3VyY2UuamF2YQ==) | `61.538% <0%> (-15.385%)` | `9% <0%> (-2%)` | |; | [...titute/hellbender/utils/test/MiniClusterUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4213/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L01pbmlDbHVzdGVyVXRpbHMuamF2YQ==) | `78.947% <0%> (-10.526%)` | `6% <0%> (-1%)` | |; | [...institute/hellbender/exceptions/UserException.java](https://codecov.io/gh/broadinstitute/gatk/pull/4213/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9leGNlcHRpb25zL1VzZXJFeGNlcHRpb24uamF2YQ==) | `67.176% <0%> (-3.053%)` | `3% <0%> (ø)` | |; | ... and [9 more](https://codecov.io/gh/broadinstitute/gatk/pull/4213/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4213#issuecomment-359306361
https://github.com/broadinstitute/gatk/pull/4213#issuecomment-359886591:102,Deployability,patch,patch,102,"Before we can accept a change like this, we need a good unit test to illustrate the problem that this patch fixes. The test should fail without the fix, and pass with it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4213#issuecomment-359886591
https://github.com/broadinstitute/gatk/pull/4213#issuecomment-359886591:61,Testability,test,test,61,"Before we can accept a change like this, we need a good unit test to illustrate the problem that this patch fixes. The test should fail without the fix, and pass with it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4213#issuecomment-359886591
https://github.com/broadinstitute/gatk/pull/4213#issuecomment-359886591:119,Testability,test,test,119,"Before we can accept a change like this, we need a good unit test to illustrate the problem that this patch fixes. The test should fail without the fix, and pass with it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4213#issuecomment-359886591
https://github.com/broadinstitute/gatk/pull/4213#issuecomment-453588508:71,Testability,test,test,71,"Closing this one, as we can't accept a change like this without a good test to illustrate the problem.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4213#issuecomment-453588508
https://github.com/broadinstitute/gatk/pull/4214#issuecomment-359307979:1589,Deployability,pipeline,pipelines,1589,1041 ; Lines 59099 59099 ; Branches 9673 9673 ; ===============================================; - Hits 46374 46140 -234 ; - Misses 8983 9228 +245 ; + Partials 3742 3731 -11; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4214?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...s/haplotypecaller/graphs/SharedSequenceMerger.java](https://codecov.io/gh/broadinstitute/gatk/pull/4214/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9ncmFwaHMvU2hhcmVkU2VxdWVuY2VNZXJnZXIuamF2YQ==) | `92.105% <100%> (ø)` | `11 <6> (ø)` | :arrow_down: |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4214/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-75.51%)` | `0% <0%> (-17%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4214/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/4214/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...lbender/engine/datasources/ReferenceAPISource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4214/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `25.735% <0%> (-44.853%)` | `8% <0%> (-19%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4214/diff?src=pr&el=tree#diff-c3J,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4214#issuecomment-359307979
https://github.com/broadinstitute/gatk/pull/4214#issuecomment-359307979:1905,Testability,test,test,1905,-|---|---|---|; | [...s/haplotypecaller/graphs/SharedSequenceMerger.java](https://codecov.io/gh/broadinstitute/gatk/pull/4214/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9ncmFwaHMvU2hhcmVkU2VxdWVuY2VNZXJnZXIuamF2YQ==) | `92.105% <100%> (ø)` | `11 <6> (ø)` | :arrow_down: |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4214/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-75.51%)` | `0% <0%> (-17%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4214/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/4214/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...lbender/engine/datasources/ReferenceAPISource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4214/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `25.735% <0%> (-44.853%)` | `8% <0%> (-19%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4214/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `54.194% <0%> (-25.806%)` | `30% <0%> (-9%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/4214/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vc,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4214#issuecomment-359307979
https://github.com/broadinstitute/gatk/pull/4214#issuecomment-359307979:3383,Testability,test,test,3383,JvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...lbender/engine/datasources/ReferenceAPISource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4214/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `25.735% <0%> (-44.853%)` | `8% <0%> (-19%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4214/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `54.194% <0%> (-25.806%)` | `30% <0%> (-9%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/4214/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `0% <0%> (-22.807%)` | `0% <0%> (-2%)` | |; | [...ender/engine/datasources/ReferenceMultiSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4214/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlTXVsdGlTb3VyY2UuamF2YQ==) | `61.538% <0%> (-15.385%)` | `9% <0%> (-2%)` | |; | [...titute/hellbender/utils/test/MiniClusterUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4214/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L01pbmlDbHVzdGVyVXRpbHMuamF2YQ==) | `78.947% <0%> (-10.526%)` | `6% <0%> (-1%)` | |; | [...institute/hellbender/exceptions/UserException.java](https://codecov.io/gh/broadinstitute/gatk/pull/4214/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9leGNlcHRpb25zL1VzZXJFeGNlcHRpb24uamF2YQ==) | `67.176% <0%> (-3.053%)` | `3% <0%> (ø)` | |; | ... and [8 more](https://codecov.io/gh/broadinstitute/gatk/pull/4214/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4214#issuecomment-359307979
https://github.com/broadinstitute/gatk/pull/4214#issuecomment-359886778:102,Deployability,patch,patch,102,"Before we can accept a change like this, we need a good unit test to illustrate the problem that this patch fixes. The test should fail without the fix, and pass with it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4214#issuecomment-359886778
https://github.com/broadinstitute/gatk/pull/4214#issuecomment-359886778:61,Testability,test,test,61,"Before we can accept a change like this, we need a good unit test to illustrate the problem that this patch fixes. The test should fail without the fix, and pass with it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4214#issuecomment-359886778
https://github.com/broadinstitute/gatk/pull/4214#issuecomment-359886778:119,Testability,test,test,119,"Before we can accept a change like this, we need a good unit test to illustrate the problem that this patch fixes. The test should fail without the fix, and pass with it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4214#issuecomment-359886778
https://github.com/broadinstitute/gatk/pull/4214#issuecomment-360353829:407,Testability,test,test,407,"I recode java to c (just haplotypecaller step 2), and will merge CommonSuffixSplitter.java SharedSequenceMerger.java in to one file, ; I'll just add vertex suffixVTemplate(graph.addVertex(suffixVTemplate)),then add in_edge to suffixVTemplate, last do something like this(this is not c code): final SeqVertex newV = new SeqVertex(ArrayUtils.addAll(suffixVTemplate.getSequence(), v.getSequence())).; for some test ,also the algorithm does,after process removePathsNotConnectedToRef(),; MergeTails() does not work!May be we can change MergeTails.java where logic like SharedSequenceMerger.java.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4214#issuecomment-360353829
https://github.com/broadinstitute/gatk/pull/4214#issuecomment-360353829:554,Testability,log,logic,554,"I recode java to c (just haplotypecaller step 2), and will merge CommonSuffixSplitter.java SharedSequenceMerger.java in to one file, ; I'll just add vertex suffixVTemplate(graph.addVertex(suffixVTemplate)),then add in_edge to suffixVTemplate, last do something like this(this is not c code): final SeqVertex newV = new SeqVertex(ArrayUtils.addAll(suffixVTemplate.getSequence(), v.getSequence())).; for some test ,also the algorithm does,after process removePathsNotConnectedToRef(),; MergeTails() does not work!May be we can change MergeTails.java where logic like SharedSequenceMerger.java.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4214#issuecomment-360353829
https://github.com/broadinstitute/gatk/pull/4214#issuecomment-453589751:46,Testability,test,test,46,"Closing this one, since we still don't have a test illustrating the problem, and @vruano doesn't see the problem after considerable back-and-forth on the forum.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4214#issuecomment-453589751
https://github.com/broadinstitute/gatk/pull/4215#issuecomment-359607092:3218,Usability,Simpl,SimpleNovelAdjacency,3218,igAlignmentsSAMSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4215/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvRGlzY292ZXJWYXJpYW50c0Zyb21Db250aWdBbGlnbm1lbnRzU0FNU3BhcmsuamF2YQ==) | `100% <100%> (ø)` | `13 <4> (+4)` | :arrow_up: |; | [...ark/sv/discovery/inference/CpxVariantDetector.java](https://codecov.io/gh/broadinstitute/gatk/pull/4215/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvaW5mZXJlbmNlL0NweFZhcmlhbnREZXRlY3Rvci5qYXZh) | `2.639% <100%> (ø)` | `2 <1> (ø)` | :arrow_down: |; | [...park/sv/discovery/inference/ChimericAlignment.java](https://codecov.io/gh/broadinstitute/gatk/pull/4215/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvaW5mZXJlbmNlL0NoaW1lcmljQWxpZ25tZW50LmphdmE=) | `70.922% <45.455%> (-2.155%)` | `48 <2> (+2)` | |; | [...k/sv/discovery/inference/SimpleNovelAdjacency.java](https://codecov.io/gh/broadinstitute/gatk/pull/4215/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvaW5mZXJlbmNlL1NpbXBsZU5vdmVsQWRqYWNlbmN5LmphdmE=) | `46.269% <46.269%> (ø)` | `5 <5> (?)` | |; | [...ery/inference/SimpleNovelAdjacencyInterpreter.java](https://codecov.io/gh/broadinstitute/gatk/pull/4215/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvaW5mZXJlbmNlL1NpbXBsZU5vdmVsQWRqYWNlbmN5SW50ZXJwcmV0ZXIuamF2YQ==) | `64.211% <64.211%> (ø)` | `19 <19> (?)` | |; | [...iscoverFromLocalAssemblyContigAlignmentsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4215/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvU3ZEaXNjb3ZlckZyb21Mb2NhbEFzc2VtYmx5Q29udGlnQWxpZ25tZW50c1NwYXJrLmphdmE=) | `75.214% <75.676%> (-2.314%)` | `10 <2> (+2)` | |; | ... and [13,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4215#issuecomment-359607092
https://github.com/broadinstitute/gatk/pull/4215#issuecomment-359607092:3529,Usability,Simpl,SimpleNovelAdjacencyInterpreter,3529,pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvRGlzY292ZXJWYXJpYW50c0Zyb21Db250aWdBbGlnbm1lbnRzU0FNU3BhcmsuamF2YQ==) | `100% <100%> (ø)` | `13 <4> (+4)` | :arrow_up: |; | [...ark/sv/discovery/inference/CpxVariantDetector.java](https://codecov.io/gh/broadinstitute/gatk/pull/4215/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvaW5mZXJlbmNlL0NweFZhcmlhbnREZXRlY3Rvci5qYXZh) | `2.639% <100%> (ø)` | `2 <1> (ø)` | :arrow_down: |; | [...park/sv/discovery/inference/ChimericAlignment.java](https://codecov.io/gh/broadinstitute/gatk/pull/4215/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvaW5mZXJlbmNlL0NoaW1lcmljQWxpZ25tZW50LmphdmE=) | `70.922% <45.455%> (-2.155%)` | `48 <2> (+2)` | |; | [...k/sv/discovery/inference/SimpleNovelAdjacency.java](https://codecov.io/gh/broadinstitute/gatk/pull/4215/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvaW5mZXJlbmNlL1NpbXBsZU5vdmVsQWRqYWNlbmN5LmphdmE=) | `46.269% <46.269%> (ø)` | `5 <5> (?)` | |; | [...ery/inference/SimpleNovelAdjacencyInterpreter.java](https://codecov.io/gh/broadinstitute/gatk/pull/4215/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvaW5mZXJlbmNlL1NpbXBsZU5vdmVsQWRqYWNlbmN5SW50ZXJwcmV0ZXIuamF2YQ==) | `64.211% <64.211%> (ø)` | `19 <19> (?)` | |; | [...iscoverFromLocalAssemblyContigAlignmentsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4215/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvU3ZEaXNjb3ZlckZyb21Mb2NhbEFzc2VtYmx5Q29udGlnQWxpZ25tZW50c1NwYXJrLmphdmE=) | `75.214% <75.676%> (-2.314%)` | `10 <2> (+2)` | |; | ... and [13 more](https://codecov.io/gh/broadinstitute/gatk/pull/4215/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4215#issuecomment-359607092
https://github.com/broadinstitute/gatk/pull/4217#issuecomment-359382718:1251,Deployability,pipeline,pipelines,1251,5a2958a7ad565fdd32?src=pr&el=desc) will **decrease** coverage by `0.396%`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #4217 +/- ##; ===============================================; - Coverage 78.479% 78.083% -0.396% ; + Complexity 16425 16356 -69 ; ===============================================; Files 1041 1041 ; Lines 59113 59113 ; Branches 9673 9673 ; ===============================================; - Hits 46391 46157 -234 ; - Misses 8983 9228 +245 ; + Partials 3739 3728 -11; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4217?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4217/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-75.51%)` | `0% <0%> (-17%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4217/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/4217/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...lbender/engine/datasources/ReferenceAPISource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4217/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `25.735% <0%> (-44.853%)` | `8% <0%> (-19%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4217/diff?src=pr&el=tree#diff-c3J,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4217#issuecomment-359382718
https://github.com/broadinstitute/gatk/pull/4217#issuecomment-359382718:1567,Testability,test,test,1567,=====================; Files 1041 1041 ; Lines 59113 59113 ; Branches 9673 9673 ; ===============================================; - Hits 46391 46157 -234 ; - Misses 8983 9228 +245 ; + Partials 3739 3728 -11; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4217?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4217/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-75.51%)` | `0% <0%> (-17%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4217/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/4217/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...lbender/engine/datasources/ReferenceAPISource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4217/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `25.735% <0%> (-44.853%)` | `8% <0%> (-19%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4217/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `54.194% <0%> (-25.806%)` | `30% <0%> (-9%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/4217/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vc,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4217#issuecomment-359382718
https://github.com/broadinstitute/gatk/pull/4217#issuecomment-359382718:3045,Testability,test,test,3045,JvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `25.735% <0%> (-44.853%)` | `8% <0%> (-19%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4217/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `54.194% <0%> (-25.806%)` | `30% <0%> (-9%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/4217/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `0% <0%> (-22.807%)` | `0% <0%> (-2%)` | |; | [...ender/engine/datasources/ReferenceMultiSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4217/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlTXVsdGlTb3VyY2UuamF2YQ==) | `61.538% <0%> (-15.385%)` | `9% <0%> (-2%)` | |; | [...titute/hellbender/utils/test/MiniClusterUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4217/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L01pbmlDbHVzdGVyVXRpbHMuamF2YQ==) | `78.947% <0%> (-10.526%)` | `6% <0%> (-1%)` | |; | [...institute/hellbender/exceptions/UserException.java](https://codecov.io/gh/broadinstitute/gatk/pull/4217/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9leGNlcHRpb25zL1VzZXJFeGNlcHRpb24uamF2YQ==) | `67.176% <0%> (-3.053%)` | `3% <0%> (ø)` | |; | [...adinstitute/hellbender/engine/ReadsDataSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4217/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUmVhZHNEYXRhU291cmNlLmphdmE=) | `89.394% <0%> (-3.03%)` | `61% <0%> (-2%)` | |; | ... and [7 more](https://codecov.io/gh/broadinstitute/gatk/pull/4217/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4217#issuecomment-359382718
https://github.com/broadinstitute/gatk/issues/4219#issuecomment-359544765:207,Security,access,access,207,"@micknudsen The splitting-bai is a different index from the bai. It's used to determine where spark should split the bam into shards when it's distributing work across the cluster. It doesn't provide random access support to the file, so it's a supplement to the bai instead of a replacement. Ideally we'd also output a normal bai as well, but due to the way the work is sharded it's not trivial to do so. . You can create the bai with `samtools index` if you use samtools, or `CreateHadoopBamSplittingIndex` has an option to output a bai. . The spark tools really should be creating it on the fly but we haven't gotten a chance to implement it yet. I opened a new ticket to track that since I didn't see one anywhere #4226",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4219#issuecomment-359544765
https://github.com/broadinstitute/gatk/issues/4219#issuecomment-359676296:163,Availability,down,downstream,163,"Thanks. Is the splitting-bai only of use for the tools that generates it (in this case ApplyBQSR), or should it be kept around for other tools (e.g. Mutect2) in a downstream analysis?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4219#issuecomment-359676296
https://github.com/broadinstitute/gatk/issues/4219#issuecomment-359826965:782,Performance,load,load,782,"explain what the splitting index is a bit better and then it will make more sense I think. Spark works by splitting files up into similar sized chunks and passing those chunks to different worker machines. ; Bam files are hard to split nicely into chunks. The way they're structured makes it hard to identify where safe boundaries are to split on. If you don't have a splitting index, we have an algorithm to start reading at essentially random locations and look for safe splitting points, but we've had some issues in the past where you can misidentify a split (which results in a crash) or miss good splits. The splitting index is a precomputed list of split points, which works around the problem of having to find the splits again next time. It's only used by spark tools that load bams, so it won't benefit Mutect2 because that's not built on spark. . We should add some documentation about this somewhere... #4235",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4219#issuecomment-359826965
https://github.com/broadinstitute/gatk/issues/4219#issuecomment-359826965:315,Safety,safe,safe,315,"explain what the splitting index is a bit better and then it will make more sense I think. Spark works by splitting files up into similar sized chunks and passing those chunks to different worker machines. ; Bam files are hard to split nicely into chunks. The way they're structured makes it hard to identify where safe boundaries are to split on. If you don't have a splitting index, we have an algorithm to start reading at essentially random locations and look for safe splitting points, but we've had some issues in the past where you can misidentify a split (which results in a crash) or miss good splits. The splitting index is a precomputed list of split points, which works around the problem of having to find the splits again next time. It's only used by spark tools that load bams, so it won't benefit Mutect2 because that's not built on spark. . We should add some documentation about this somewhere... #4235",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4219#issuecomment-359826965
https://github.com/broadinstitute/gatk/issues/4219#issuecomment-359826965:468,Safety,safe,safe,468,"explain what the splitting index is a bit better and then it will make more sense I think. Spark works by splitting files up into similar sized chunks and passing those chunks to different worker machines. ; Bam files are hard to split nicely into chunks. The way they're structured makes it hard to identify where safe boundaries are to split on. If you don't have a splitting index, we have an algorithm to start reading at essentially random locations and look for safe splitting points, but we've had some issues in the past where you can misidentify a split (which results in a crash) or miss good splits. The splitting index is a precomputed list of split points, which works around the problem of having to find the splits again next time. It's only used by spark tools that load bams, so it won't benefit Mutect2 because that's not built on spark. . We should add some documentation about this somewhere... #4235",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4219#issuecomment-359826965
https://github.com/broadinstitute/gatk/issues/4221#issuecomment-397080074:70,Safety,timeout,timeouts,70,Closed via https://github.com/broadinstitute/gatk/pull/4757 where the timeouts were removed altogether.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4221#issuecomment-397080074
https://github.com/broadinstitute/gatk/issues/4224#issuecomment-359544685:106,Availability,error,error,106,"@ldgauthier Is line 3889836 of your vcf corrupt (which is what is implied by the ""wrong number of tokens"" error)?. In general we only require an index in GATK4 if `-L` is specified.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4224#issuecomment-359544685
https://github.com/broadinstitute/gatk/issues/4224#issuecomment-359573544:40,Testability,log,log,40,"It looks perfectly reasonable from that log output and when I select that line in particular (granted, after I've added the index back in) it looks fine. I count 10 columns. I dug into this before I figured out the index fix. I don't know why it's expecting 8 (apparently it thinks `header == null`) or getting 9 (apparently that's what `condenseTrailingTokens` does) If I pad that site to get the VC above and below they all look well behaved, whitespace and everything:; ```; chr14^I24736867^Irs854413^IT^IC^I.^IPASS^IAC=2;AF=1.00;AN=2;DB;DP=31;ExcessHet=0.5837;FS=0.000;InbreedingCoeff=0.0411;MQ=59.97;MQRankSum=-1.800e-02;MQ_DP=24250;POSITIVE_TRAIN_SITE;QD=25.91;QUALapprox=616134;ReadPosRankSum=0.576;SOR=0.704;VQSLOD=2.30;VarDP=23778;culprit=MQRankSum^IGT:AD:DP:GQ:PGT:PID:PL:SB^I1/1:0,31:31:93:0|1:24736864_A_G:1036,93,0:0,0,15,16$; chr14^I24737838^Irs1101636^IC^IT^I.^IPASS^IAC=2;AF=1.00;AN=2;DB;DP=38;ExcessHet=0.7420;FS=0.000;InbreedingCoeff=0.0357;MQ=59.98;MQRankSum=0.026;MQ_DP=24332;POSITIVE_TRAIN_SITE;QD=22.41;QUALapprox=537499;ReadPosRankSum=0.567;SOR=0.685;VQSLOD=2.09;VarDP=23982;culprit=DP^IGT:AD:DP:GQ:PL:SB^I1/1:1,37:38:79:1150,79,0:0,1,17,20$; chr14^I24739444^Irs12435407^IA^IT^I.^IPASS^IAC=2;AF=1.00;AN=2;DB;DP=30;ExcessHet=0.4770;FS=0.000;InbreedingCoeff=0.0430;MQ=59.99;MQRankSum=-6.000e-02;MQ_DP=17420;POSITIVE_TRAIN_SITE;QD=27.90;QUALapprox=478116;ReadPosRankSum=0.293;SOR=0.698;VQSLOD=2.27;VarDP=17137;culprit=MQRankSum^IGT:AD:DP:GQ:PGT:PID:PL:SB^I1/1:1,29:30:21:0|1:24739444_A_T:1167,21,0:1,0,15,14$; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4224#issuecomment-359573544
https://github.com/broadinstitute/gatk/issues/4224#issuecomment-359849134:96,Availability,error,error,96,"An interesting note, when I run this on my own machine over the same input file I'm getting the error triggering at a different site. Namely at the site indicated in this stack trace:; ```; htsjdk.tribble.TribbleException: Line 2607098: there aren't enough columns for line ; chr8	95336218	rs4735361	C	G	PASS	AC=2;AF=1.00;AN=2;DB;DP=30;ExcessHet=6.5471;FS=0.000;InbreedingCoeff=-0.0338;MQ=60.00;MQRankSum=-5.200e-02;MQ_DP=19905;POSITIVE_TRAIN_SITE;QD=19.71;QUALapprox=388030;ReadP (we expected 9 tokens, and saw 8 ), for input source: gnomADaccuracyTest.SynDip.vcf.gz; 	at htsjdk.variant.vcf.AbstractVCFCodec.decodeLine(AbstractVCFCodec.java:281); 	at htsjdk.variant.vcf.AbstractVCFCodec.decode(AbstractVCFCodec.java:262); 	at htsjdk.variant.vcf.AbstractVCFCodec.decode(AbstractVCFCodec.java:64); 	at htsjdk.tribble.AsciiFeatureCodec.decode(AsciiFeatureCodec.java:70); 	at htsjdk.tribble.AsciiFeatureCodec.decode(AsciiFeatureCodec.java:37); 	at htsjdk.tribble.TribbleIndexedFeatureReader$WFIterator.readNextRecord(TribbleIndexedFeatureReader.java:372); 	at htsjdk.tribble.TribbleIndexedFeatureReader$WFIterator.next(TribbleIndexedFeatureReader.java:353); 	at htsjdk.tribble.TribbleIndexedFeatureReader$WFIterator.next(TribbleIndexedFeatureReader.java:314); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.traverse(VariantWalkerBase.java:108); 	at org.broadinsti",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4224#issuecomment-359849134
https://github.com/broadinstitute/gatk/issues/4224#issuecomment-359849134:1519,Integrability,wrap,wrapAndCopyInto,1519,gnomADaccuracyTest.SynDip.vcf.gz; 	at htsjdk.variant.vcf.AbstractVCFCodec.decodeLine(AbstractVCFCodec.java:281); 	at htsjdk.variant.vcf.AbstractVCFCodec.decode(AbstractVCFCodec.java:262); 	at htsjdk.variant.vcf.AbstractVCFCodec.decode(AbstractVCFCodec.java:64); 	at htsjdk.tribble.AsciiFeatureCodec.decode(AsciiFeatureCodec.java:70); 	at htsjdk.tribble.AsciiFeatureCodec.decode(AsciiFeatureCodec.java:37); 	at htsjdk.tribble.TribbleIndexedFeatureReader$WFIterator.readNextRecord(TribbleIndexedFeatureReader.java:372); 	at htsjdk.tribble.TribbleIndexedFeatureReader$WFIterator.next(TribbleIndexedFeatureReader.java:353); 	at htsjdk.tribble.TribbleIndexedFeatureReader$WFIterator.next(TribbleIndexedFeatureReader.java:314); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.traverse(VariantWalkerBase.java:108); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:893); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:136); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:152); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:195); 	at org.broadi,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4224#issuecomment-359849134
https://github.com/broadinstitute/gatk/issues/4224#issuecomment-359855307:276,Availability,down,down,276,"It's pretty clear at this point that there is a bug in tribble with iteration over block-compressed inputs that lack an index. This is a completely different codepath (and even a different `FeatureReader`) than you get if an index is present. To buy us some time to nail this down, we are going to patch GATK to always require an index for block-compressed tribble files, even if `-L` is not specified. This change will go out in the bug fix release this Friday.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4224#issuecomment-359855307
https://github.com/broadinstitute/gatk/issues/4224#issuecomment-359855307:298,Deployability,patch,patch,298,"It's pretty clear at this point that there is a bug in tribble with iteration over block-compressed inputs that lack an index. This is a completely different codepath (and even a different `FeatureReader`) than you get if an index is present. To buy us some time to nail this down, we are going to patch GATK to always require an index for block-compressed tribble files, even if `-L` is not specified. This change will go out in the bug fix release this Friday.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4224#issuecomment-359855307
https://github.com/broadinstitute/gatk/issues/4224#issuecomment-359855307:442,Deployability,release,release,442,"It's pretty clear at this point that there is a bug in tribble with iteration over block-compressed inputs that lack an index. This is a completely different codepath (and even a different `FeatureReader`) than you get if an index is present. To buy us some time to nail this down, we are going to patch GATK to always require an index for block-compressed tribble files, even if `-L` is not specified. This change will go out in the bug fix release this Friday.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4224#issuecomment-359855307
https://github.com/broadinstitute/gatk/issues/4224#issuecomment-359855307:12,Usability,clear,clear,12,"It's pretty clear at this point that there is a bug in tribble with iteration over block-compressed inputs that lack an index. This is a completely different codepath (and even a different `FeatureReader`) than you get if an index is present. To buy us some time to nail this down, we are going to patch GATK to always require an index for block-compressed tribble files, even if `-L` is not specified. This change will go out in the bug fix release this Friday.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4224#issuecomment-359855307
https://github.com/broadinstitute/gatk/issues/4224#issuecomment-360282461:716,Availability,avail,available,716,"@ldgauthier @yfarjoun We have an update on this! We've identified the bug:. * When `AbstractFeatureReader.getFeatureReader()` tries to open a `.vcf.gz` that doesn't have an index, it returns a `TribbleIndexedFeatureReader` instead of a `TabixFeatureReader`, because `methods.isTabix()` returns false when an index is not present.; * `TribbleIndexedFeatureReader`, in turn, opens a Java vanilla `GZIPInputStream`, instead of the `BlockCompressedInputStream` that gets opened when you create a `TabixFeatureReader`.; * `GZIPInputStream`, in turn, has a *confirmed bug* filed against it in Oracle's bug tracker (see https://bugs.java.com/bugdatabase/view_bug.do?bug_id=7036144#), that it inappropriately relies on the `available()` method to detect end-of-file, which is never safe to do given the contract of `available()`; * As the final piece in the ghastly puzzle, implementations of `SeekableStream` in htsjdk do not implement `available()` at all, instead using the default implementation which always returns 0. As a result of this combination of bugs in Java's `GZIPInputStream` itself and bugs in htsjdk's `SeekableStream` classes, end-of-file can be detected prematurely when within 26 bytes of the end of a block, due to the following code in `GZIPInputStream.readTrailer()`:. ```; if (this.in.available() > 0 || n > 26) {; ....; }; return true; // EOF; ```. Where `n` is the number of bytes left to inflate in the current block. The solution is to replace all usages of the bugged `GZIPInputStream` with `BlockCompressedInputStream` in tribble in htsjdk (at least, for points in the code where the input is known to be block-gzipped rather than regular gzipped). For due diligence we should also implement `available()` correctly for all implementations of `SeekableStream` in htsjdk.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4224#issuecomment-360282461
https://github.com/broadinstitute/gatk/issues/4224#issuecomment-360282461:808,Availability,avail,available,808,"@ldgauthier @yfarjoun We have an update on this! We've identified the bug:. * When `AbstractFeatureReader.getFeatureReader()` tries to open a `.vcf.gz` that doesn't have an index, it returns a `TribbleIndexedFeatureReader` instead of a `TabixFeatureReader`, because `methods.isTabix()` returns false when an index is not present.; * `TribbleIndexedFeatureReader`, in turn, opens a Java vanilla `GZIPInputStream`, instead of the `BlockCompressedInputStream` that gets opened when you create a `TabixFeatureReader`.; * `GZIPInputStream`, in turn, has a *confirmed bug* filed against it in Oracle's bug tracker (see https://bugs.java.com/bugdatabase/view_bug.do?bug_id=7036144#), that it inappropriately relies on the `available()` method to detect end-of-file, which is never safe to do given the contract of `available()`; * As the final piece in the ghastly puzzle, implementations of `SeekableStream` in htsjdk do not implement `available()` at all, instead using the default implementation which always returns 0. As a result of this combination of bugs in Java's `GZIPInputStream` itself and bugs in htsjdk's `SeekableStream` classes, end-of-file can be detected prematurely when within 26 bytes of the end of a block, due to the following code in `GZIPInputStream.readTrailer()`:. ```; if (this.in.available() > 0 || n > 26) {; ....; }; return true; // EOF; ```. Where `n` is the number of bytes left to inflate in the current block. The solution is to replace all usages of the bugged `GZIPInputStream` with `BlockCompressedInputStream` in tribble in htsjdk (at least, for points in the code where the input is known to be block-gzipped rather than regular gzipped). For due diligence we should also implement `available()` correctly for all implementations of `SeekableStream` in htsjdk.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4224#issuecomment-360282461
https://github.com/broadinstitute/gatk/issues/4224#issuecomment-360282461:930,Availability,avail,available,930,"@ldgauthier @yfarjoun We have an update on this! We've identified the bug:. * When `AbstractFeatureReader.getFeatureReader()` tries to open a `.vcf.gz` that doesn't have an index, it returns a `TribbleIndexedFeatureReader` instead of a `TabixFeatureReader`, because `methods.isTabix()` returns false when an index is not present.; * `TribbleIndexedFeatureReader`, in turn, opens a Java vanilla `GZIPInputStream`, instead of the `BlockCompressedInputStream` that gets opened when you create a `TabixFeatureReader`.; * `GZIPInputStream`, in turn, has a *confirmed bug* filed against it in Oracle's bug tracker (see https://bugs.java.com/bugdatabase/view_bug.do?bug_id=7036144#), that it inappropriately relies on the `available()` method to detect end-of-file, which is never safe to do given the contract of `available()`; * As the final piece in the ghastly puzzle, implementations of `SeekableStream` in htsjdk do not implement `available()` at all, instead using the default implementation which always returns 0. As a result of this combination of bugs in Java's `GZIPInputStream` itself and bugs in htsjdk's `SeekableStream` classes, end-of-file can be detected prematurely when within 26 bytes of the end of a block, due to the following code in `GZIPInputStream.readTrailer()`:. ```; if (this.in.available() > 0 || n > 26) {; ....; }; return true; // EOF; ```. Where `n` is the number of bytes left to inflate in the current block. The solution is to replace all usages of the bugged `GZIPInputStream` with `BlockCompressedInputStream` in tribble in htsjdk (at least, for points in the code where the input is known to be block-gzipped rather than regular gzipped). For due diligence we should also implement `available()` correctly for all implementations of `SeekableStream` in htsjdk.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4224#issuecomment-360282461
https://github.com/broadinstitute/gatk/issues/4224#issuecomment-360282461:1302,Availability,avail,available,1302,"@ldgauthier @yfarjoun We have an update on this! We've identified the bug:. * When `AbstractFeatureReader.getFeatureReader()` tries to open a `.vcf.gz` that doesn't have an index, it returns a `TribbleIndexedFeatureReader` instead of a `TabixFeatureReader`, because `methods.isTabix()` returns false when an index is not present.; * `TribbleIndexedFeatureReader`, in turn, opens a Java vanilla `GZIPInputStream`, instead of the `BlockCompressedInputStream` that gets opened when you create a `TabixFeatureReader`.; * `GZIPInputStream`, in turn, has a *confirmed bug* filed against it in Oracle's bug tracker (see https://bugs.java.com/bugdatabase/view_bug.do?bug_id=7036144#), that it inappropriately relies on the `available()` method to detect end-of-file, which is never safe to do given the contract of `available()`; * As the final piece in the ghastly puzzle, implementations of `SeekableStream` in htsjdk do not implement `available()` at all, instead using the default implementation which always returns 0. As a result of this combination of bugs in Java's `GZIPInputStream` itself and bugs in htsjdk's `SeekableStream` classes, end-of-file can be detected prematurely when within 26 bytes of the end of a block, due to the following code in `GZIPInputStream.readTrailer()`:. ```; if (this.in.available() > 0 || n > 26) {; ....; }; return true; // EOF; ```. Where `n` is the number of bytes left to inflate in the current block. The solution is to replace all usages of the bugged `GZIPInputStream` with `BlockCompressedInputStream` in tribble in htsjdk (at least, for points in the code where the input is known to be block-gzipped rather than regular gzipped). For due diligence we should also implement `available()` correctly for all implementations of `SeekableStream` in htsjdk.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4224#issuecomment-360282461
https://github.com/broadinstitute/gatk/issues/4224#issuecomment-360282461:1716,Availability,avail,available,1716,"@ldgauthier @yfarjoun We have an update on this! We've identified the bug:. * When `AbstractFeatureReader.getFeatureReader()` tries to open a `.vcf.gz` that doesn't have an index, it returns a `TribbleIndexedFeatureReader` instead of a `TabixFeatureReader`, because `methods.isTabix()` returns false when an index is not present.; * `TribbleIndexedFeatureReader`, in turn, opens a Java vanilla `GZIPInputStream`, instead of the `BlockCompressedInputStream` that gets opened when you create a `TabixFeatureReader`.; * `GZIPInputStream`, in turn, has a *confirmed bug* filed against it in Oracle's bug tracker (see https://bugs.java.com/bugdatabase/view_bug.do?bug_id=7036144#), that it inappropriately relies on the `available()` method to detect end-of-file, which is never safe to do given the contract of `available()`; * As the final piece in the ghastly puzzle, implementations of `SeekableStream` in htsjdk do not implement `available()` at all, instead using the default implementation which always returns 0. As a result of this combination of bugs in Java's `GZIPInputStream` itself and bugs in htsjdk's `SeekableStream` classes, end-of-file can be detected prematurely when within 26 bytes of the end of a block, due to the following code in `GZIPInputStream.readTrailer()`:. ```; if (this.in.available() > 0 || n > 26) {; ....; }; return true; // EOF; ```. Where `n` is the number of bytes left to inflate in the current block. The solution is to replace all usages of the bugged `GZIPInputStream` with `BlockCompressedInputStream` in tribble in htsjdk (at least, for points in the code where the input is known to be block-gzipped rather than regular gzipped). For due diligence we should also implement `available()` correctly for all implementations of `SeekableStream` in htsjdk.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4224#issuecomment-360282461
https://github.com/broadinstitute/gatk/issues/4224#issuecomment-360282461:33,Deployability,update,update,33,"@ldgauthier @yfarjoun We have an update on this! We've identified the bug:. * When `AbstractFeatureReader.getFeatureReader()` tries to open a `.vcf.gz` that doesn't have an index, it returns a `TribbleIndexedFeatureReader` instead of a `TabixFeatureReader`, because `methods.isTabix()` returns false when an index is not present.; * `TribbleIndexedFeatureReader`, in turn, opens a Java vanilla `GZIPInputStream`, instead of the `BlockCompressedInputStream` that gets opened when you create a `TabixFeatureReader`.; * `GZIPInputStream`, in turn, has a *confirmed bug* filed against it in Oracle's bug tracker (see https://bugs.java.com/bugdatabase/view_bug.do?bug_id=7036144#), that it inappropriately relies on the `available()` method to detect end-of-file, which is never safe to do given the contract of `available()`; * As the final piece in the ghastly puzzle, implementations of `SeekableStream` in htsjdk do not implement `available()` at all, instead using the default implementation which always returns 0. As a result of this combination of bugs in Java's `GZIPInputStream` itself and bugs in htsjdk's `SeekableStream` classes, end-of-file can be detected prematurely when within 26 bytes of the end of a block, due to the following code in `GZIPInputStream.readTrailer()`:. ```; if (this.in.available() > 0 || n > 26) {; ....; }; return true; // EOF; ```. Where `n` is the number of bytes left to inflate in the current block. The solution is to replace all usages of the bugged `GZIPInputStream` with `BlockCompressedInputStream` in tribble in htsjdk (at least, for points in the code where the input is known to be block-gzipped rather than regular gzipped). For due diligence we should also implement `available()` correctly for all implementations of `SeekableStream` in htsjdk.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4224#issuecomment-360282461
https://github.com/broadinstitute/gatk/issues/4224#issuecomment-360282461:795,Integrability,contract,contract,795,"@ldgauthier @yfarjoun We have an update on this! We've identified the bug:. * When `AbstractFeatureReader.getFeatureReader()` tries to open a `.vcf.gz` that doesn't have an index, it returns a `TribbleIndexedFeatureReader` instead of a `TabixFeatureReader`, because `methods.isTabix()` returns false when an index is not present.; * `TribbleIndexedFeatureReader`, in turn, opens a Java vanilla `GZIPInputStream`, instead of the `BlockCompressedInputStream` that gets opened when you create a `TabixFeatureReader`.; * `GZIPInputStream`, in turn, has a *confirmed bug* filed against it in Oracle's bug tracker (see https://bugs.java.com/bugdatabase/view_bug.do?bug_id=7036144#), that it inappropriately relies on the `available()` method to detect end-of-file, which is never safe to do given the contract of `available()`; * As the final piece in the ghastly puzzle, implementations of `SeekableStream` in htsjdk do not implement `available()` at all, instead using the default implementation which always returns 0. As a result of this combination of bugs in Java's `GZIPInputStream` itself and bugs in htsjdk's `SeekableStream` classes, end-of-file can be detected prematurely when within 26 bytes of the end of a block, due to the following code in `GZIPInputStream.readTrailer()`:. ```; if (this.in.available() > 0 || n > 26) {; ....; }; return true; // EOF; ```. Where `n` is the number of bytes left to inflate in the current block. The solution is to replace all usages of the bugged `GZIPInputStream` with `BlockCompressedInputStream` in tribble in htsjdk (at least, for points in the code where the input is known to be block-gzipped rather than regular gzipped). For due diligence we should also implement `available()` correctly for all implementations of `SeekableStream` in htsjdk.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4224#issuecomment-360282461
https://github.com/broadinstitute/gatk/issues/4224#issuecomment-360282461:739,Safety,detect,detect,739,"@ldgauthier @yfarjoun We have an update on this! We've identified the bug:. * When `AbstractFeatureReader.getFeatureReader()` tries to open a `.vcf.gz` that doesn't have an index, it returns a `TribbleIndexedFeatureReader` instead of a `TabixFeatureReader`, because `methods.isTabix()` returns false when an index is not present.; * `TribbleIndexedFeatureReader`, in turn, opens a Java vanilla `GZIPInputStream`, instead of the `BlockCompressedInputStream` that gets opened when you create a `TabixFeatureReader`.; * `GZIPInputStream`, in turn, has a *confirmed bug* filed against it in Oracle's bug tracker (see https://bugs.java.com/bugdatabase/view_bug.do?bug_id=7036144#), that it inappropriately relies on the `available()` method to detect end-of-file, which is never safe to do given the contract of `available()`; * As the final piece in the ghastly puzzle, implementations of `SeekableStream` in htsjdk do not implement `available()` at all, instead using the default implementation which always returns 0. As a result of this combination of bugs in Java's `GZIPInputStream` itself and bugs in htsjdk's `SeekableStream` classes, end-of-file can be detected prematurely when within 26 bytes of the end of a block, due to the following code in `GZIPInputStream.readTrailer()`:. ```; if (this.in.available() > 0 || n > 26) {; ....; }; return true; // EOF; ```. Where `n` is the number of bytes left to inflate in the current block. The solution is to replace all usages of the bugged `GZIPInputStream` with `BlockCompressedInputStream` in tribble in htsjdk (at least, for points in the code where the input is known to be block-gzipped rather than regular gzipped). For due diligence we should also implement `available()` correctly for all implementations of `SeekableStream` in htsjdk.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4224#issuecomment-360282461
https://github.com/broadinstitute/gatk/issues/4224#issuecomment-360282461:774,Safety,safe,safe,774,"@ldgauthier @yfarjoun We have an update on this! We've identified the bug:. * When `AbstractFeatureReader.getFeatureReader()` tries to open a `.vcf.gz` that doesn't have an index, it returns a `TribbleIndexedFeatureReader` instead of a `TabixFeatureReader`, because `methods.isTabix()` returns false when an index is not present.; * `TribbleIndexedFeatureReader`, in turn, opens a Java vanilla `GZIPInputStream`, instead of the `BlockCompressedInputStream` that gets opened when you create a `TabixFeatureReader`.; * `GZIPInputStream`, in turn, has a *confirmed bug* filed against it in Oracle's bug tracker (see https://bugs.java.com/bugdatabase/view_bug.do?bug_id=7036144#), that it inappropriately relies on the `available()` method to detect end-of-file, which is never safe to do given the contract of `available()`; * As the final piece in the ghastly puzzle, implementations of `SeekableStream` in htsjdk do not implement `available()` at all, instead using the default implementation which always returns 0. As a result of this combination of bugs in Java's `GZIPInputStream` itself and bugs in htsjdk's `SeekableStream` classes, end-of-file can be detected prematurely when within 26 bytes of the end of a block, due to the following code in `GZIPInputStream.readTrailer()`:. ```; if (this.in.available() > 0 || n > 26) {; ....; }; return true; // EOF; ```. Where `n` is the number of bytes left to inflate in the current block. The solution is to replace all usages of the bugged `GZIPInputStream` with `BlockCompressedInputStream` in tribble in htsjdk (at least, for points in the code where the input is known to be block-gzipped rather than regular gzipped). For due diligence we should also implement `available()` correctly for all implementations of `SeekableStream` in htsjdk.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4224#issuecomment-360282461
https://github.com/broadinstitute/gatk/issues/4224#issuecomment-360282461:1157,Safety,detect,detected,1157,"@ldgauthier @yfarjoun We have an update on this! We've identified the bug:. * When `AbstractFeatureReader.getFeatureReader()` tries to open a `.vcf.gz` that doesn't have an index, it returns a `TribbleIndexedFeatureReader` instead of a `TabixFeatureReader`, because `methods.isTabix()` returns false when an index is not present.; * `TribbleIndexedFeatureReader`, in turn, opens a Java vanilla `GZIPInputStream`, instead of the `BlockCompressedInputStream` that gets opened when you create a `TabixFeatureReader`.; * `GZIPInputStream`, in turn, has a *confirmed bug* filed against it in Oracle's bug tracker (see https://bugs.java.com/bugdatabase/view_bug.do?bug_id=7036144#), that it inappropriately relies on the `available()` method to detect end-of-file, which is never safe to do given the contract of `available()`; * As the final piece in the ghastly puzzle, implementations of `SeekableStream` in htsjdk do not implement `available()` at all, instead using the default implementation which always returns 0. As a result of this combination of bugs in Java's `GZIPInputStream` itself and bugs in htsjdk's `SeekableStream` classes, end-of-file can be detected prematurely when within 26 bytes of the end of a block, due to the following code in `GZIPInputStream.readTrailer()`:. ```; if (this.in.available() > 0 || n > 26) {; ....; }; return true; // EOF; ```. Where `n` is the number of bytes left to inflate in the current block. The solution is to replace all usages of the bugged `GZIPInputStream` with `BlockCompressedInputStream` in tribble in htsjdk (at least, for points in the code where the input is known to be block-gzipped rather than regular gzipped). For due diligence we should also implement `available()` correctly for all implementations of `SeekableStream` in htsjdk.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4224#issuecomment-360282461
https://github.com/broadinstitute/gatk/issues/4224#issuecomment-360304725:923,Availability,avail,available,923,"ng?. On Wed, Jan 24, 2018 at 4:39 PM droazen <notifications@github.com> wrote:. > @ldgauthier <https://github.com/ldgauthier> @yfarjoun; > <https://github.com/yfarjoun> We have an update on this! We've identified; > the bug:; >; > - When AbstractFeatureReader.getFeatureReader() tries to open a .vcf.gz; > that doesn't have an index, it returns a TribbleIndexedFeatureReader; > instead of a TabixFeatureReader, because methods.isTabix() returns; > false when an index is not present.; > - TribbleIndexedFeatureReader, in turn, opens a Java vanilla; > GZIPInputStream, instead of the BlockCompressedInputStream that gets; > opened when you create a TabixFeatureReader.; > - GZIPInputStream, in turn, has a *confirmed bug* filed against it in; > Oracle's bug tracker (see; > https://bugs.java.com/bugdatabase/view_bug.do?bug_id=7036144#), that; > it inappropriately relies on the available() method to detect; > end-of-file, which is never safe to do given the contract of; > available(); > - As the final piece in the ghastly puzzle, implementations of; > SeekableStream in htsjdk do not implement available() at all, instead; > using the default implementation which always returns 0.; >; > As a result of this combination of bugs in Java's GZIPInputStream itself; > and bugs in htsjdk's SeekableStream classes, end-of-file can be detected; > prematurely when within 26 bytes of the end of a block, due to the; > following code in GZIPInputStream.readTrailer():; >; > if (this.in.available() > 0 || n > 26) {; > ....; > }; > return true; // EOF; >; > Where n is the number of bytes left to inflate in the current block.; >; > The solution is to replace all usages of the bugged GZIPInputStream with; > BlockCompressedInputStream in tribble in htsjdk (at least, for points in; > the code where the input is known to be block-gzipped rather than regular; > gzipped). For due diligence we should also implement available(); > correctly for all implementations of SeekableStream in htsjdk.; >; > —; > You",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4224#issuecomment-360304725
https://github.com/broadinstitute/gatk/issues/4224#issuecomment-360304725:1019,Availability,avail,available,1019,"ng?. On Wed, Jan 24, 2018 at 4:39 PM droazen <notifications@github.com> wrote:. > @ldgauthier <https://github.com/ldgauthier> @yfarjoun; > <https://github.com/yfarjoun> We have an update on this! We've identified; > the bug:; >; > - When AbstractFeatureReader.getFeatureReader() tries to open a .vcf.gz; > that doesn't have an index, it returns a TribbleIndexedFeatureReader; > instead of a TabixFeatureReader, because methods.isTabix() returns; > false when an index is not present.; > - TribbleIndexedFeatureReader, in turn, opens a Java vanilla; > GZIPInputStream, instead of the BlockCompressedInputStream that gets; > opened when you create a TabixFeatureReader.; > - GZIPInputStream, in turn, has a *confirmed bug* filed against it in; > Oracle's bug tracker (see; > https://bugs.java.com/bugdatabase/view_bug.do?bug_id=7036144#), that; > it inappropriately relies on the available() method to detect; > end-of-file, which is never safe to do given the contract of; > available(); > - As the final piece in the ghastly puzzle, implementations of; > SeekableStream in htsjdk do not implement available() at all, instead; > using the default implementation which always returns 0.; >; > As a result of this combination of bugs in Java's GZIPInputStream itself; > and bugs in htsjdk's SeekableStream classes, end-of-file can be detected; > prematurely when within 26 bytes of the end of a block, due to the; > following code in GZIPInputStream.readTrailer():; >; > if (this.in.available() > 0 || n > 26) {; > ....; > }; > return true; // EOF; >; > Where n is the number of bytes left to inflate in the current block.; >; > The solution is to replace all usages of the bugged GZIPInputStream with; > BlockCompressedInputStream in tribble in htsjdk (at least, for points in; > the code where the input is known to be block-gzipped rather than regular; > gzipped). For due diligence we should also implement available(); > correctly for all implementations of SeekableStream in htsjdk.; >; > —; > You",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4224#issuecomment-360304725
https://github.com/broadinstitute/gatk/issues/4224#issuecomment-360304725:1142,Availability,avail,available,1142,"ng?. On Wed, Jan 24, 2018 at 4:39 PM droazen <notifications@github.com> wrote:. > @ldgauthier <https://github.com/ldgauthier> @yfarjoun; > <https://github.com/yfarjoun> We have an update on this! We've identified; > the bug:; >; > - When AbstractFeatureReader.getFeatureReader() tries to open a .vcf.gz; > that doesn't have an index, it returns a TribbleIndexedFeatureReader; > instead of a TabixFeatureReader, because methods.isTabix() returns; > false when an index is not present.; > - TribbleIndexedFeatureReader, in turn, opens a Java vanilla; > GZIPInputStream, instead of the BlockCompressedInputStream that gets; > opened when you create a TabixFeatureReader.; > - GZIPInputStream, in turn, has a *confirmed bug* filed against it in; > Oracle's bug tracker (see; > https://bugs.java.com/bugdatabase/view_bug.do?bug_id=7036144#), that; > it inappropriately relies on the available() method to detect; > end-of-file, which is never safe to do given the contract of; > available(); > - As the final piece in the ghastly puzzle, implementations of; > SeekableStream in htsjdk do not implement available() at all, instead; > using the default implementation which always returns 0.; >; > As a result of this combination of bugs in Java's GZIPInputStream itself; > and bugs in htsjdk's SeekableStream classes, end-of-file can be detected; > prematurely when within 26 bytes of the end of a block, due to the; > following code in GZIPInputStream.readTrailer():; >; > if (this.in.available() > 0 || n > 26) {; > ....; > }; > return true; // EOF; >; > Where n is the number of bytes left to inflate in the current block.; >; > The solution is to replace all usages of the bugged GZIPInputStream with; > BlockCompressedInputStream in tribble in htsjdk (at least, for points in; > the code where the input is known to be block-gzipped rather than regular; > gzipped). For due diligence we should also implement available(); > correctly for all implementations of SeekableStream in htsjdk.; >; > —; > You",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4224#issuecomment-360304725
https://github.com/broadinstitute/gatk/issues/4224#issuecomment-360304725:1525,Availability,avail,available,1525,"'t have an index, it returns a TribbleIndexedFeatureReader; > instead of a TabixFeatureReader, because methods.isTabix() returns; > false when an index is not present.; > - TribbleIndexedFeatureReader, in turn, opens a Java vanilla; > GZIPInputStream, instead of the BlockCompressedInputStream that gets; > opened when you create a TabixFeatureReader.; > - GZIPInputStream, in turn, has a *confirmed bug* filed against it in; > Oracle's bug tracker (see; > https://bugs.java.com/bugdatabase/view_bug.do?bug_id=7036144#), that; > it inappropriately relies on the available() method to detect; > end-of-file, which is never safe to do given the contract of; > available(); > - As the final piece in the ghastly puzzle, implementations of; > SeekableStream in htsjdk do not implement available() at all, instead; > using the default implementation which always returns 0.; >; > As a result of this combination of bugs in Java's GZIPInputStream itself; > and bugs in htsjdk's SeekableStream classes, end-of-file can be detected; > prematurely when within 26 bytes of the end of a block, due to the; > following code in GZIPInputStream.readTrailer():; >; > if (this.in.available() > 0 || n > 26) {; > ....; > }; > return true; // EOF; >; > Where n is the number of bytes left to inflate in the current block.; >; > The solution is to replace all usages of the bugged GZIPInputStream with; > BlockCompressedInputStream in tribble in htsjdk (at least, for points in; > the code where the input is known to be block-gzipped rather than regular; > gzipped). For due diligence we should also implement available(); > correctly for all implementations of SeekableStream in htsjdk.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/4224#issuecomment-360282461>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACnk0h8AF8wYzkbHSmAu4-8n5TE8GtOUks5tN6MfgaJpZM4RoUzm>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4224#issuecomment-360304725
https://github.com/broadinstitute/gatk/issues/4224#issuecomment-360304725:1953,Availability,avail,available,1953,"'t have an index, it returns a TribbleIndexedFeatureReader; > instead of a TabixFeatureReader, because methods.isTabix() returns; > false when an index is not present.; > - TribbleIndexedFeatureReader, in turn, opens a Java vanilla; > GZIPInputStream, instead of the BlockCompressedInputStream that gets; > opened when you create a TabixFeatureReader.; > - GZIPInputStream, in turn, has a *confirmed bug* filed against it in; > Oracle's bug tracker (see; > https://bugs.java.com/bugdatabase/view_bug.do?bug_id=7036144#), that; > it inappropriately relies on the available() method to detect; > end-of-file, which is never safe to do given the contract of; > available(); > - As the final piece in the ghastly puzzle, implementations of; > SeekableStream in htsjdk do not implement available() at all, instead; > using the default implementation which always returns 0.; >; > As a result of this combination of bugs in Java's GZIPInputStream itself; > and bugs in htsjdk's SeekableStream classes, end-of-file can be detected; > prematurely when within 26 bytes of the end of a block, due to the; > following code in GZIPInputStream.readTrailer():; >; > if (this.in.available() > 0 || n > 26) {; > ....; > }; > return true; // EOF; >; > Where n is the number of bytes left to inflate in the current block.; >; > The solution is to replace all usages of the bugged GZIPInputStream with; > BlockCompressedInputStream in tribble in htsjdk (at least, for points in; > the code where the input is known to be block-gzipped rather than regular; > gzipped). For due diligence we should also implement available(); > correctly for all implementations of SeekableStream in htsjdk.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/4224#issuecomment-360282461>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACnk0h8AF8wYzkbHSmAu4-8n5TE8GtOUks5tN6MfgaJpZM4RoUzm>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4224#issuecomment-360304725
https://github.com/broadinstitute/gatk/issues/4224#issuecomment-360304725:225,Deployability,update,update,225,"Wow. How on Earth did we avoid this for so long?. On Wed, Jan 24, 2018 at 4:39 PM droazen <notifications@github.com> wrote:. > @ldgauthier <https://github.com/ldgauthier> @yfarjoun; > <https://github.com/yfarjoun> We have an update on this! We've identified; > the bug:; >; > - When AbstractFeatureReader.getFeatureReader() tries to open a .vcf.gz; > that doesn't have an index, it returns a TribbleIndexedFeatureReader; > instead of a TabixFeatureReader, because methods.isTabix() returns; > false when an index is not present.; > - TribbleIndexedFeatureReader, in turn, opens a Java vanilla; > GZIPInputStream, instead of the BlockCompressedInputStream that gets; > opened when you create a TabixFeatureReader.; > - GZIPInputStream, in turn, has a *confirmed bug* filed against it in; > Oracle's bug tracker (see; > https://bugs.java.com/bugdatabase/view_bug.do?bug_id=7036144#), that; > it inappropriately relies on the available() method to detect; > end-of-file, which is never safe to do given the contract of; > available(); > - As the final piece in the ghastly puzzle, implementations of; > SeekableStream in htsjdk do not implement available() at all, instead; > using the default implementation which always returns 0.; >; > As a result of this combination of bugs in Java's GZIPInputStream itself; > and bugs in htsjdk's SeekableStream classes, end-of-file can be detected; > prematurely when within 26 bytes of the end of a block, due to the; > following code in GZIPInputStream.readTrailer():; >; > if (this.in.available() > 0 || n > 26) {; > ....; > }; > return true; // EOF; >; > Where n is the number of bytes left to inflate in the current block.; >; > The solution is to replace all usages of the bugged GZIPInputStream with; > BlockCompressedInputStream in tribble in htsjdk (at least, for points in; > the code where the input is known to be block-gzipped rather than regular; > gzipped). For due diligence we should also implement available(); > correctly for all implementations",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4224#issuecomment-360304725
https://github.com/broadinstitute/gatk/issues/4224#issuecomment-360304725:1004,Integrability,contract,contract,1004,"ng?. On Wed, Jan 24, 2018 at 4:39 PM droazen <notifications@github.com> wrote:. > @ldgauthier <https://github.com/ldgauthier> @yfarjoun; > <https://github.com/yfarjoun> We have an update on this! We've identified; > the bug:; >; > - When AbstractFeatureReader.getFeatureReader() tries to open a .vcf.gz; > that doesn't have an index, it returns a TribbleIndexedFeatureReader; > instead of a TabixFeatureReader, because methods.isTabix() returns; > false when an index is not present.; > - TribbleIndexedFeatureReader, in turn, opens a Java vanilla; > GZIPInputStream, instead of the BlockCompressedInputStream that gets; > opened when you create a TabixFeatureReader.; > - GZIPInputStream, in turn, has a *confirmed bug* filed against it in; > Oracle's bug tracker (see; > https://bugs.java.com/bugdatabase/view_bug.do?bug_id=7036144#), that; > it inappropriately relies on the available() method to detect; > end-of-file, which is never safe to do given the contract of; > available(); > - As the final piece in the ghastly puzzle, implementations of; > SeekableStream in htsjdk do not implement available() at all, instead; > using the default implementation which always returns 0.; >; > As a result of this combination of bugs in Java's GZIPInputStream itself; > and bugs in htsjdk's SeekableStream classes, end-of-file can be detected; > prematurely when within 26 bytes of the end of a block, due to the; > following code in GZIPInputStream.readTrailer():; >; > if (this.in.available() > 0 || n > 26) {; > ....; > }; > return true; // EOF; >; > Where n is the number of bytes left to inflate in the current block.; >; > The solution is to replace all usages of the bugged GZIPInputStream with; > BlockCompressedInputStream in tribble in htsjdk (at least, for points in; > the code where the input is known to be block-gzipped rather than regular; > gzipped). For due diligence we should also implement available(); > correctly for all implementations of SeekableStream in htsjdk.; >; > —; > You",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4224#issuecomment-360304725
https://github.com/broadinstitute/gatk/issues/4224#issuecomment-360304725:25,Safety,avoid,avoid,25,"Wow. How on Earth did we avoid this for so long?. On Wed, Jan 24, 2018 at 4:39 PM droazen <notifications@github.com> wrote:. > @ldgauthier <https://github.com/ldgauthier> @yfarjoun; > <https://github.com/yfarjoun> We have an update on this! We've identified; > the bug:; >; > - When AbstractFeatureReader.getFeatureReader() tries to open a .vcf.gz; > that doesn't have an index, it returns a TribbleIndexedFeatureReader; > instead of a TabixFeatureReader, because methods.isTabix() returns; > false when an index is not present.; > - TribbleIndexedFeatureReader, in turn, opens a Java vanilla; > GZIPInputStream, instead of the BlockCompressedInputStream that gets; > opened when you create a TabixFeatureReader.; > - GZIPInputStream, in turn, has a *confirmed bug* filed against it in; > Oracle's bug tracker (see; > https://bugs.java.com/bugdatabase/view_bug.do?bug_id=7036144#), that; > it inappropriately relies on the available() method to detect; > end-of-file, which is never safe to do given the contract of; > available(); > - As the final piece in the ghastly puzzle, implementations of; > SeekableStream in htsjdk do not implement available() at all, instead; > using the default implementation which always returns 0.; >; > As a result of this combination of bugs in Java's GZIPInputStream itself; > and bugs in htsjdk's SeekableStream classes, end-of-file can be detected; > prematurely when within 26 bytes of the end of a block, due to the; > following code in GZIPInputStream.readTrailer():; >; > if (this.in.available() > 0 || n > 26) {; > ....; > }; > return true; // EOF; >; > Where n is the number of bytes left to inflate in the current block.; >; > The solution is to replace all usages of the bugged GZIPInputStream with; > BlockCompressedInputStream in tribble in htsjdk (at least, for points in; > the code where the input is known to be block-gzipped rather than regular; > gzipped). For due diligence we should also implement available(); > correctly for all implementations",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4224#issuecomment-360304725
https://github.com/broadinstitute/gatk/issues/4224#issuecomment-360304725:945,Safety,detect,detect,945,"ng?. On Wed, Jan 24, 2018 at 4:39 PM droazen <notifications@github.com> wrote:. > @ldgauthier <https://github.com/ldgauthier> @yfarjoun; > <https://github.com/yfarjoun> We have an update on this! We've identified; > the bug:; >; > - When AbstractFeatureReader.getFeatureReader() tries to open a .vcf.gz; > that doesn't have an index, it returns a TribbleIndexedFeatureReader; > instead of a TabixFeatureReader, because methods.isTabix() returns; > false when an index is not present.; > - TribbleIndexedFeatureReader, in turn, opens a Java vanilla; > GZIPInputStream, instead of the BlockCompressedInputStream that gets; > opened when you create a TabixFeatureReader.; > - GZIPInputStream, in turn, has a *confirmed bug* filed against it in; > Oracle's bug tracker (see; > https://bugs.java.com/bugdatabase/view_bug.do?bug_id=7036144#), that; > it inappropriately relies on the available() method to detect; > end-of-file, which is never safe to do given the contract of; > available(); > - As the final piece in the ghastly puzzle, implementations of; > SeekableStream in htsjdk do not implement available() at all, instead; > using the default implementation which always returns 0.; >; > As a result of this combination of bugs in Java's GZIPInputStream itself; > and bugs in htsjdk's SeekableStream classes, end-of-file can be detected; > prematurely when within 26 bytes of the end of a block, due to the; > following code in GZIPInputStream.readTrailer():; >; > if (this.in.available() > 0 || n > 26) {; > ....; > }; > return true; // EOF; >; > Where n is the number of bytes left to inflate in the current block.; >; > The solution is to replace all usages of the bugged GZIPInputStream with; > BlockCompressedInputStream in tribble in htsjdk (at least, for points in; > the code where the input is known to be block-gzipped rather than regular; > gzipped). For due diligence we should also implement available(); > correctly for all implementations of SeekableStream in htsjdk.; >; > —; > You",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4224#issuecomment-360304725
https://github.com/broadinstitute/gatk/issues/4224#issuecomment-360304725:983,Safety,safe,safe,983,"ng?. On Wed, Jan 24, 2018 at 4:39 PM droazen <notifications@github.com> wrote:. > @ldgauthier <https://github.com/ldgauthier> @yfarjoun; > <https://github.com/yfarjoun> We have an update on this! We've identified; > the bug:; >; > - When AbstractFeatureReader.getFeatureReader() tries to open a .vcf.gz; > that doesn't have an index, it returns a TribbleIndexedFeatureReader; > instead of a TabixFeatureReader, because methods.isTabix() returns; > false when an index is not present.; > - TribbleIndexedFeatureReader, in turn, opens a Java vanilla; > GZIPInputStream, instead of the BlockCompressedInputStream that gets; > opened when you create a TabixFeatureReader.; > - GZIPInputStream, in turn, has a *confirmed bug* filed against it in; > Oracle's bug tracker (see; > https://bugs.java.com/bugdatabase/view_bug.do?bug_id=7036144#), that; > it inappropriately relies on the available() method to detect; > end-of-file, which is never safe to do given the contract of; > available(); > - As the final piece in the ghastly puzzle, implementations of; > SeekableStream in htsjdk do not implement available() at all, instead; > using the default implementation which always returns 0.; >; > As a result of this combination of bugs in Java's GZIPInputStream itself; > and bugs in htsjdk's SeekableStream classes, end-of-file can be detected; > prematurely when within 26 bytes of the end of a block, due to the; > following code in GZIPInputStream.readTrailer():; >; > if (this.in.available() > 0 || n > 26) {; > ....; > }; > return true; // EOF; >; > Where n is the number of bytes left to inflate in the current block.; >; > The solution is to replace all usages of the bugged GZIPInputStream with; > BlockCompressedInputStream in tribble in htsjdk (at least, for points in; > the code where the input is known to be block-gzipped rather than regular; > gzipped). For due diligence we should also implement available(); > correctly for all implementations of SeekableStream in htsjdk.; >; > —; > You",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4224#issuecomment-360304725
https://github.com/broadinstitute/gatk/issues/4224#issuecomment-360304725:1376,Safety,detect,detected,1376,"n't have an index, it returns a TribbleIndexedFeatureReader; > instead of a TabixFeatureReader, because methods.isTabix() returns; > false when an index is not present.; > - TribbleIndexedFeatureReader, in turn, opens a Java vanilla; > GZIPInputStream, instead of the BlockCompressedInputStream that gets; > opened when you create a TabixFeatureReader.; > - GZIPInputStream, in turn, has a *confirmed bug* filed against it in; > Oracle's bug tracker (see; > https://bugs.java.com/bugdatabase/view_bug.do?bug_id=7036144#), that; > it inappropriately relies on the available() method to detect; > end-of-file, which is never safe to do given the contract of; > available(); > - As the final piece in the ghastly puzzle, implementations of; > SeekableStream in htsjdk do not implement available() at all, instead; > using the default implementation which always returns 0.; >; > As a result of this combination of bugs in Java's GZIPInputStream itself; > and bugs in htsjdk's SeekableStream classes, end-of-file can be detected; > prematurely when within 26 bytes of the end of a block, due to the; > following code in GZIPInputStream.readTrailer():; >; > if (this.in.available() > 0 || n > 26) {; > ....; > }; > return true; // EOF; >; > Where n is the number of bytes left to inflate in the current block.; >; > The solution is to replace all usages of the bugged GZIPInputStream with; > BlockCompressedInputStream in tribble in htsjdk (at least, for points in; > the code where the input is known to be block-gzipped rather than regular; > gzipped). For due diligence we should also implement available(); > correctly for all implementations of SeekableStream in htsjdk.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/4224#issuecomment-360282461>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACnk0h8AF8wYzkbHSmAu4-8n5TE8GtOUks5tN6MfgaJpZM4RoUzm>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4224#issuecomment-360304725
https://github.com/broadinstitute/gatk/issues/4225#issuecomment-363436039:0,Deployability,Update,Update,0,"Update:; - [ ] A cool name! (Marduk, Clarendon, NeuroVar) ? maybe I'll do a slack poll of dsde methods?; - [x] Model training script (in Python, eventually in Java); - [x] Pretrained model for WGS; - [x] Pretrained model for WEx (still being validated and was only trained on NA12878); - [x] Model inference and VCF annotation (in Java); - [x] Solution for applying filters based on CNN score cutoff (tranches.py script); - [ ] Alternate joint calling WDL? Or for re-filtering? (ideally with a $$$ estimate); - [ ] Performance optimizations?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4225#issuecomment-363436039
https://github.com/broadinstitute/gatk/issues/4225#issuecomment-363436039:515,Performance,Perform,Performance,515,"Update:; - [ ] A cool name! (Marduk, Clarendon, NeuroVar) ? maybe I'll do a slack poll of dsde methods?; - [x] Model training script (in Python, eventually in Java); - [x] Pretrained model for WGS; - [x] Pretrained model for WEx (still being validated and was only trained on NA12878); - [x] Model inference and VCF annotation (in Java); - [x] Solution for applying filters based on CNN score cutoff (tranches.py script); - [ ] Alternate joint calling WDL? Or for re-filtering? (ideally with a $$$ estimate); - [ ] Performance optimizations?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4225#issuecomment-363436039
https://github.com/broadinstitute/gatk/issues/4225#issuecomment-363436039:527,Performance,optimiz,optimizations,527,"Update:; - [ ] A cool name! (Marduk, Clarendon, NeuroVar) ? maybe I'll do a slack poll of dsde methods?; - [x] Model training script (in Python, eventually in Java); - [x] Pretrained model for WGS; - [x] Pretrained model for WEx (still being validated and was only trained on NA12878); - [x] Model inference and VCF annotation (in Java); - [x] Solution for applying filters based on CNN score cutoff (tranches.py script); - [ ] Alternate joint calling WDL? Or for re-filtering? (ideally with a $$$ estimate); - [ ] Performance optimizations?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4225#issuecomment-363436039
https://github.com/broadinstitute/gatk/issues/4225#issuecomment-363436039:242,Security,validat,validated,242,"Update:; - [ ] A cool name! (Marduk, Clarendon, NeuroVar) ? maybe I'll do a slack poll of dsde methods?; - [x] Model training script (in Python, eventually in Java); - [x] Pretrained model for WGS; - [x] Pretrained model for WEx (still being validated and was only trained on NA12878); - [x] Model inference and VCF annotation (in Java); - [x] Solution for applying filters based on CNN score cutoff (tranches.py script); - [ ] Alternate joint calling WDL? Or for re-filtering? (ideally with a $$$ estimate); - [ ] Performance optimizations?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4225#issuecomment-363436039
https://github.com/broadinstitute/gatk/issues/4225#issuecomment-363560735:90,Performance,optimiz,optimize,90,My calculations give a runtime estimate of $0.18 for the 1D and... more for the 2D. We'll optimize later. It'll be fine.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4225#issuecomment-363560735
https://github.com/broadinstitute/gatk/issues/4225#issuecomment-377623706:663,Performance,optimiz,optimized,663,"Finished, [2D CNN inference](https://github.com/broadinstitute/gatk/blob/master/src/main/java/org/broadinstitute/hellbender/tools/walkers/vqsr/CNNScoreVariants.java) and training merged, many new issues spawned.:; - [X] A cool(?) name CNNScoreVariants; - [x] Model training script (in Python, eventually in Java); - [x] Pretrained model for WGS; - [x] Pretrained model for WEx (still being validated and was only trained on NA12878); - [x] Model inference and VCF annotation (in Java); - [x] Solution for applying filters based on CNN score cutoff (tranches.py script); - [x] Currently just re-filtering. Still no joint calling solution...; - [x] Hyperparameters optimized for small 2d model similar performance but .25 params.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4225#issuecomment-377623706
https://github.com/broadinstitute/gatk/issues/4225#issuecomment-377623706:700,Performance,perform,performance,700,"Finished, [2D CNN inference](https://github.com/broadinstitute/gatk/blob/master/src/main/java/org/broadinstitute/hellbender/tools/walkers/vqsr/CNNScoreVariants.java) and training merged, many new issues spawned.:; - [X] A cool(?) name CNNScoreVariants; - [x] Model training script (in Python, eventually in Java); - [x] Pretrained model for WGS; - [x] Pretrained model for WEx (still being validated and was only trained on NA12878); - [x] Model inference and VCF annotation (in Java); - [x] Solution for applying filters based on CNN score cutoff (tranches.py script); - [x] Currently just re-filtering. Still no joint calling solution...; - [x] Hyperparameters optimized for small 2d model similar performance but .25 params.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4225#issuecomment-377623706
https://github.com/broadinstitute/gatk/issues/4225#issuecomment-377623706:390,Security,validat,validated,390,"Finished, [2D CNN inference](https://github.com/broadinstitute/gatk/blob/master/src/main/java/org/broadinstitute/hellbender/tools/walkers/vqsr/CNNScoreVariants.java) and training merged, many new issues spawned.:; - [X] A cool(?) name CNNScoreVariants; - [x] Model training script (in Python, eventually in Java); - [x] Pretrained model for WGS; - [x] Pretrained model for WEx (still being validated and was only trained on NA12878); - [x] Model inference and VCF annotation (in Java); - [x] Solution for applying filters based on CNN score cutoff (tranches.py script); - [x] Currently just re-filtering. Still no joint calling solution...; - [x] Hyperparameters optimized for small 2d model similar performance but .25 params.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4225#issuecomment-377623706
https://github.com/broadinstitute/gatk/issues/4230#issuecomment-359823967:177,Deployability,update,updated,177,@ruoshuiwyl Typically the way we've been running if you want to run with the local master is to use ; `--spark-runner LOCAL --spark-master local[20]` Does that work for you? . (updated comment because I initially wrote the wrong thing...),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4230#issuecomment-359823967
https://github.com/broadinstitute/gatk/issues/4230#issuecomment-360197001:26,Integrability,Depend,Depending,26,Did that fix the problem? Depending on your shell you may have to escape the local bit. ```; --spark-master `local[20]`; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4230#issuecomment-360197001
https://github.com/broadinstitute/gatk/issues/4231#issuecomment-371410958:94,Modifiability,variab,variable,94,"@wangdy12 .I get the same issue: when use HaplotypeCallerSpark on a cluster, It lose a lot of variable sites and the result jitter to the same input bam. and running on local mode, the result is good.; But I fix the code according to your way. It does not work and get the same issue.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4231#issuecomment-371410958
https://github.com/broadinstitute/gatk/issues/4231#issuecomment-371415511:1280,Modifiability,extend,extends,1280,"You'd better verify the consistency of the results step by step, then you can find which step's result become diffierent, finally fix it.; For example, you want to see if the `JavaRDD<Shard<GATKRead>> readShards`results are always same. You can add debug info in `callVariantsWithHaplotypeCaller` just like this:. ```; ...... final JavaRDD<Shard<GATKRead>> readShards = SparkSharder.shard ....; //Debug; String path = ""./dubug/readShardsTest1"";; java.io.File debug = new File(path);; if (!debug.getParentFile().exists()); debug.getParentFile().mkdir();; try (PrintStream printStream = new PrintStream(debug)) {; printStream.println(""List<ShardBoundary> shardBoundaries size : "" + shardBoundaries.size());; printStream.printf(""NumPartitions : %d\n"", readShards.getNumPartitions());. List<ShardDebug> shardDebugs = readShards.mapToPair(shard -> new Tuple2<>(new ShardDebug(shard), null)); .sortByKey((Comparator<ShardDebug> & Serializable) (o1, o2) ->; IntervalUtils.compareLocatables(o1, o2, header.getSequenceDictionary()); ).keys().collect();; printStream.printf(""NumShard : %d\n"", shardDebugs.size());; for (ShardDebug shardDebug : shardDebugs) {; printStream.println(shardDebug.toString());; }; }catch (Exception e){; e.printStackTrace();; }; ```. ```; static class ShardDebug extends ShardBoundary{; int size;. public ShardDebug(Shard<GATKRead> shard) {; super(shard.getInterval(),shard.getPaddedInterval());; size = Iterators.size(shard.iterator());; }. @Override; public String toString() {; return this.getInterval().toString() + ""\t"" + size;; }; }; ```; ; Run twice and compare the differences, do this step by step, you will find the bug. Gook Luck!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4231#issuecomment-371415511
https://github.com/broadinstitute/gatk/issues/4231#issuecomment-371691142:24,Testability,test,tested,24,@wangdy12 thanks.I have tested and your fix is effective. By Calling HaplotypeCallerSpark I can get the good results on an cluster. The GATK version is 4.0.2.1-2.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4231#issuecomment-371691142
https://github.com/broadinstitute/gatk/issues/4231#issuecomment-464754012:28,Deployability,release,released,28,"This was fixed in #5475 and released in 4.1.0.0. HaplotypeCallerSpark can be run in ""strict"" mode (with the `--strict` flag) to closely match the walker version. Even when not run using strict mode the result is much better than it used to be (closer to the walker version, and shouldn't jitter).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4231#issuecomment-464754012
https://github.com/broadinstitute/gatk/pull/4232#issuecomment-359772526:1547,Deployability,pipeline,pipelines,1547,============================; Files 1041 1041 ; Lines 59122 59122 ; Branches 9674 9674 ; ===============================================; - Hits 46401 46165 -236 ; - Misses 8981 9229 +248 ; + Partials 3740 3728 -12; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4232?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...ellbender/cmdline/StandardArgumentDefinitions.java](https://codecov.io/gh/broadinstitute/gatk/pull/4232/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL1N0YW5kYXJkQXJndW1lbnREZWZpbml0aW9ucy5qYXZh) | `0% <ø> (ø)` | `0 <0> (ø)` | :arrow_down: |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4232/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-75.51%)` | `0% <0%> (-17%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4232/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/4232/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...lbender/engine/datasources/ReferenceAPISource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4232/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `25.735% <0%> (-44.853%)` | `8% <0%> (-19%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4232/diff?src=pr&el=tree#diff-c3J,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4232#issuecomment-359772526
https://github.com/broadinstitute/gatk/pull/4232#issuecomment-359772526:1863,Testability,test,test,1863,ree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...ellbender/cmdline/StandardArgumentDefinitions.java](https://codecov.io/gh/broadinstitute/gatk/pull/4232/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL1N0YW5kYXJkQXJndW1lbnREZWZpbml0aW9ucy5qYXZh) | `0% <ø> (ø)` | `0 <0> (ø)` | :arrow_down: |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4232/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-75.51%)` | `0% <0%> (-17%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4232/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/4232/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...lbender/engine/datasources/ReferenceAPISource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4232/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `25.735% <0%> (-44.853%)` | `8% <0%> (-19%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4232/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `54.194% <0%> (-25.806%)` | `30% <0%> (-9%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/4232/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vc,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4232#issuecomment-359772526
https://github.com/broadinstitute/gatk/pull/4232#issuecomment-359772526:3341,Testability,test,test,3341,JvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...lbender/engine/datasources/ReferenceAPISource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4232/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `25.735% <0%> (-44.853%)` | `8% <0%> (-19%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4232/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `54.194% <0%> (-25.806%)` | `30% <0%> (-9%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/4232/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `0% <0%> (-22.807%)` | `0% <0%> (-2%)` | |; | [...ender/engine/datasources/ReferenceMultiSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4232/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlTXVsdGlTb3VyY2UuamF2YQ==) | `61.538% <0%> (-15.385%)` | `9% <0%> (-2%)` | |; | [...titute/hellbender/utils/test/MiniClusterUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4232/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L01pbmlDbHVzdGVyVXRpbHMuamF2YQ==) | `78.947% <0%> (-10.526%)` | `6% <0%> (-1%)` | |; | [...institute/hellbender/exceptions/UserException.java](https://codecov.io/gh/broadinstitute/gatk/pull/4232/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9leGNlcHRpb25zL1VzZXJFeGNlcHRpb24uamF2YQ==) | `67.176% <0%> (-3.053%)` | `3% <0%> (ø)` | |; | ... and [9 more](https://codecov.io/gh/broadinstitute/gatk/pull/4232/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4232#issuecomment-359772526
https://github.com/broadinstitute/gatk/pull/4238#issuecomment-360180392:55,Modifiability,variab,variables,55,"> While we're at it, can we rename all of the ""is_xxx"" variables?. @takutosato Agreed. I renamed them all.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4238#issuecomment-360180392
https://github.com/broadinstitute/gatk/pull/4239#issuecomment-360589954:309,Availability,down,down,309,"Also, this seems to misbehave when run on a GZIP file that is NOT a block gzipped file. I get the following result which appears to be flawed in a number of ways:; ```; Block at file offset 0; 	- compressed size: 25442; 	- uncompressed size: 2114545489. 15:24:38.967 INFO PrintBGZFBlockInformation - Shutting down engine; [January 25, 2018 3:24:38 PM EST] org.broadinstitute.hellbender.tools.diagnostics.PrintBGZFBlockInformation done. Elapsed time: 0.00 minutes.; Runtime.totalMemory()=190840832; ***********************************************************************. A USER ERROR has occurred: Error while parsing BGZF file. Error message was: testBrokenFile/gnomADaccuracyTest.SynDip.unBlocked.vcf.gz has invalid uncompressedLength: -758824605. ***********************************************************************; Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace.; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4239#issuecomment-360589954
https://github.com/broadinstitute/gatk/pull/4239#issuecomment-360589954:578,Availability,ERROR,ERROR,578,"Also, this seems to misbehave when run on a GZIP file that is NOT a block gzipped file. I get the following result which appears to be flawed in a number of ways:; ```; Block at file offset 0; 	- compressed size: 25442; 	- uncompressed size: 2114545489. 15:24:38.967 INFO PrintBGZFBlockInformation - Shutting down engine; [January 25, 2018 3:24:38 PM EST] org.broadinstitute.hellbender.tools.diagnostics.PrintBGZFBlockInformation done. Elapsed time: 0.00 minutes.; Runtime.totalMemory()=190840832; ***********************************************************************. A USER ERROR has occurred: Error while parsing BGZF file. Error message was: testBrokenFile/gnomADaccuracyTest.SynDip.unBlocked.vcf.gz has invalid uncompressedLength: -758824605. ***********************************************************************; Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace.; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4239#issuecomment-360589954
https://github.com/broadinstitute/gatk/pull/4239#issuecomment-360589954:598,Availability,Error,Error,598,"Also, this seems to misbehave when run on a GZIP file that is NOT a block gzipped file. I get the following result which appears to be flawed in a number of ways:; ```; Block at file offset 0; 	- compressed size: 25442; 	- uncompressed size: 2114545489. 15:24:38.967 INFO PrintBGZFBlockInformation - Shutting down engine; [January 25, 2018 3:24:38 PM EST] org.broadinstitute.hellbender.tools.diagnostics.PrintBGZFBlockInformation done. Elapsed time: 0.00 minutes.; Runtime.totalMemory()=190840832; ***********************************************************************. A USER ERROR has occurred: Error while parsing BGZF file. Error message was: testBrokenFile/gnomADaccuracyTest.SynDip.unBlocked.vcf.gz has invalid uncompressedLength: -758824605. ***********************************************************************; Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace.; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4239#issuecomment-360589954
https://github.com/broadinstitute/gatk/pull/4239#issuecomment-360589954:629,Availability,Error,Error,629,"Also, this seems to misbehave when run on a GZIP file that is NOT a block gzipped file. I get the following result which appears to be flawed in a number of ways:; ```; Block at file offset 0; 	- compressed size: 25442; 	- uncompressed size: 2114545489. 15:24:38.967 INFO PrintBGZFBlockInformation - Shutting down engine; [January 25, 2018 3:24:38 PM EST] org.broadinstitute.hellbender.tools.diagnostics.PrintBGZFBlockInformation done. Elapsed time: 0.00 minutes.; Runtime.totalMemory()=190840832; ***********************************************************************. A USER ERROR has occurred: Error while parsing BGZF file. Error message was: testBrokenFile/gnomADaccuracyTest.SynDip.unBlocked.vcf.gz has invalid uncompressedLength: -758824605. ***********************************************************************; Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace.; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4239#issuecomment-360589954
https://github.com/broadinstitute/gatk/pull/4239#issuecomment-360589954:635,Integrability,message,message,635,"Also, this seems to misbehave when run on a GZIP file that is NOT a block gzipped file. I get the following result which appears to be flawed in a number of ways:; ```; Block at file offset 0; 	- compressed size: 25442; 	- uncompressed size: 2114545489. 15:24:38.967 INFO PrintBGZFBlockInformation - Shutting down engine; [January 25, 2018 3:24:38 PM EST] org.broadinstitute.hellbender.tools.diagnostics.PrintBGZFBlockInformation done. Elapsed time: 0.00 minutes.; Runtime.totalMemory()=190840832; ***********************************************************************. A USER ERROR has occurred: Error while parsing BGZF file. Error message was: testBrokenFile/gnomADaccuracyTest.SynDip.unBlocked.vcf.gz has invalid uncompressedLength: -758824605. ***********************************************************************; Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace.; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4239#issuecomment-360589954
https://github.com/broadinstitute/gatk/pull/4239#issuecomment-360589954:648,Testability,test,testBrokenFile,648,"Also, this seems to misbehave when run on a GZIP file that is NOT a block gzipped file. I get the following result which appears to be flawed in a number of ways:; ```; Block at file offset 0; 	- compressed size: 25442; 	- uncompressed size: 2114545489. 15:24:38.967 INFO PrintBGZFBlockInformation - Shutting down engine; [January 25, 2018 3:24:38 PM EST] org.broadinstitute.hellbender.tools.diagnostics.PrintBGZFBlockInformation done. Elapsed time: 0.00 minutes.; Runtime.totalMemory()=190840832; ***********************************************************************. A USER ERROR has occurred: Error while parsing BGZF file. Error message was: testBrokenFile/gnomADaccuracyTest.SynDip.unBlocked.vcf.gz has invalid uncompressedLength: -758824605. ***********************************************************************; Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace.; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4239#issuecomment-360589954
https://github.com/broadinstitute/gatk/pull/4239#issuecomment-453686695:134,Deployability,patch,patched,134,"@jamesemery I added a pretty comprehensive set of tests for various kinds of corrupt BGZF files (as well as a regular GZIP file), and patched the tool to report something sensible in these cases. You can see the new tool output in the `*.out` files included in the branch. Needs another review from you before we can merge.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4239#issuecomment-453686695
https://github.com/broadinstitute/gatk/pull/4239#issuecomment-453686695:50,Testability,test,tests,50,"@jamesemery I added a pretty comprehensive set of tests for various kinds of corrupt BGZF files (as well as a regular GZIP file), and patched the tool to report something sensible in these cases. You can see the new tool output in the `*.out` files included in the branch. Needs another review from you before we can merge.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4239#issuecomment-453686695
https://github.com/broadinstitute/gatk/pull/4240#issuecomment-360844547:3168,Usability,Simpl,SimpleNovelAdjacency,3168,alVariationDiscoveryPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4240/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9TdHJ1Y3R1cmFsVmFyaWF0aW9uRGlzY292ZXJ5UGlwZWxpbmVTcGFyay5qYXZh) | `88.482% <0%> (-0.324%)` | `15% <0%> (+5%)` | |; | [.../DiscoverVariantsFromContigAlignmentsSAMSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4240/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvRGlzY292ZXJWYXJpYW50c0Zyb21Db250aWdBbGlnbm1lbnRzU0FNU3BhcmsuamF2YQ==) | `100% <0%> (ø)` | `18% <0%> (+9%)` | :arrow_up: |; | [.../tools/spark/sv/discovery/BreakEndVariantType.java](https://codecov.io/gh/broadinstitute/gatk/pull/4240/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvQnJlYWtFbmRWYXJpYW50VHlwZS5qYXZh) | `0% <0%> (ø)` | `0% <0%> (ø)` | :arrow_down: |; | [...k/sv/discovery/inference/SimpleNovelAdjacency.java](https://codecov.io/gh/broadinstitute/gatk/pull/4240/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvaW5mZXJlbmNlL1NpbXBsZU5vdmVsQWRqYWNlbmN5LmphdmE=) | `46.269% <0%> (ø)` | `5% <0%> (?)` | |; | [...ery/inference/SimpleNovelAdjacencyInterpreter.java](https://codecov.io/gh/broadinstitute/gatk/pull/4240/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvaW5mZXJlbmNlL1NpbXBsZU5vdmVsQWRqYWNlbmN5SW50ZXJwcmV0ZXIuamF2YQ==) | `64.211% <0%> (ø)` | `19% <0%> (?)` | |; | [...ark/sv/discovery/inference/CpxVariantDetector.java](https://codecov.io/gh/broadinstitute/gatk/pull/4240/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvaW5mZXJlbmNlL0NweFZhcmlhbnREZXRlY3Rvci5qYXZh) | `2.74% <0%> (+0.101%)` | `3% <0%> (+1%)` | :arrow_up: |; | ... and [13 more](https://codecov.io/gh/,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4240#issuecomment-360844547
https://github.com/broadinstitute/gatk/pull/4240#issuecomment-360844547:3476,Usability,Simpl,SimpleNovelAdjacencyInterpreter,3476,gh/broadinstitute/gatk/pull/4240/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9TdHJ1Y3R1cmFsVmFyaWF0aW9uRGlzY292ZXJ5UGlwZWxpbmVTcGFyay5qYXZh) | `88.482% <0%> (-0.324%)` | `15% <0%> (+5%)` | |; | [.../DiscoverVariantsFromContigAlignmentsSAMSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4240/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvRGlzY292ZXJWYXJpYW50c0Zyb21Db250aWdBbGlnbm1lbnRzU0FNU3BhcmsuamF2YQ==) | `100% <0%> (ø)` | `18% <0%> (+9%)` | :arrow_up: |; | [.../tools/spark/sv/discovery/BreakEndVariantType.java](https://codecov.io/gh/broadinstitute/gatk/pull/4240/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvQnJlYWtFbmRWYXJpYW50VHlwZS5qYXZh) | `0% <0%> (ø)` | `0% <0%> (ø)` | :arrow_down: |; | [...k/sv/discovery/inference/SimpleNovelAdjacency.java](https://codecov.io/gh/broadinstitute/gatk/pull/4240/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvaW5mZXJlbmNlL1NpbXBsZU5vdmVsQWRqYWNlbmN5LmphdmE=) | `46.269% <0%> (ø)` | `5% <0%> (?)` | |; | [...ery/inference/SimpleNovelAdjacencyInterpreter.java](https://codecov.io/gh/broadinstitute/gatk/pull/4240/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvaW5mZXJlbmNlL1NpbXBsZU5vdmVsQWRqYWNlbmN5SW50ZXJwcmV0ZXIuamF2YQ==) | `64.211% <0%> (ø)` | `19% <0%> (?)` | |; | [...ark/sv/discovery/inference/CpxVariantDetector.java](https://codecov.io/gh/broadinstitute/gatk/pull/4240/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvaW5mZXJlbmNlL0NweFZhcmlhbnREZXRlY3Rvci5qYXZh) | `2.74% <0%> (+0.101%)` | `3% <0%> (+1%)` | :arrow_up: |; | ... and [13 more](https://codecov.io/gh/broadinstitute/gatk/pull/4240/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4240#issuecomment-360844547
https://github.com/broadinstitute/gatk/issues/4242#issuecomment-359955349:174,Modifiability,variab,variable,174,"You can detect whether a tool has failed in bash by checking whether the exit status code is non-zero. In bash, the exit status code of the last command run is stored in the variable `$?`; ; In general, you should ask questions like these on the GATK forum (https://gatkforums.broadinstitute.org/gatk) instead of here, however -- this is for bug reports rather than support requests.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4242#issuecomment-359955349
https://github.com/broadinstitute/gatk/issues/4242#issuecomment-359955349:8,Safety,detect,detect,8,"You can detect whether a tool has failed in bash by checking whether the exit status code is non-zero. In bash, the exit status code of the last command run is stored in the variable `$?`; ; In general, you should ask questions like these on the GATK forum (https://gatkforums.broadinstitute.org/gatk) instead of here, however -- this is for bug reports rather than support requests.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4242#issuecomment-359955349
https://github.com/broadinstitute/gatk/pull/4245#issuecomment-362679008:393,Availability,avail,available,393,"Okay tranche filtering and training script are in. They're pure python right now but it would be simple to wrap them in java CLP via PythonScriptExecutor. These scripts add several dependencies which will probably make the already big docker quite a bit bigger. Long term I think we can get rid of most of them as we already have for inference, but we want to have some training functionality available by AGBT which is the week after next. Ready for a first round review @cmnbroad.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4245#issuecomment-362679008
https://github.com/broadinstitute/gatk/pull/4245#issuecomment-362679008:107,Integrability,wrap,wrap,107,"Okay tranche filtering and training script are in. They're pure python right now but it would be simple to wrap them in java CLP via PythonScriptExecutor. These scripts add several dependencies which will probably make the already big docker quite a bit bigger. Long term I think we can get rid of most of them as we already have for inference, but we want to have some training functionality available by AGBT which is the week after next. Ready for a first round review @cmnbroad.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4245#issuecomment-362679008
https://github.com/broadinstitute/gatk/pull/4245#issuecomment-362679008:181,Integrability,depend,dependencies,181,"Okay tranche filtering and training script are in. They're pure python right now but it would be simple to wrap them in java CLP via PythonScriptExecutor. These scripts add several dependencies which will probably make the already big docker quite a bit bigger. Long term I think we can get rid of most of them as we already have for inference, but we want to have some training functionality available by AGBT which is the week after next. Ready for a first round review @cmnbroad.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4245#issuecomment-362679008
https://github.com/broadinstitute/gatk/pull/4245#issuecomment-362679008:97,Usability,simpl,simple,97,"Okay tranche filtering and training script are in. They're pure python right now but it would be simple to wrap them in java CLP via PythonScriptExecutor. These scripts add several dependencies which will probably make the already big docker quite a bit bigger. Long term I think we can get rid of most of them as we already have for inference, but we want to have some training functionality available by AGBT which is the week after next. Ready for a first round review @cmnbroad.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4245#issuecomment-362679008
https://github.com/broadinstitute/gatk/pull/4245#issuecomment-363434657:68,Deployability,integrat,integration,68,"Added basic java wrappers for training and tranches. I'm working on integration tests and docs today, but the other files should be ready for 1st round review.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4245#issuecomment-363434657
https://github.com/broadinstitute/gatk/pull/4245#issuecomment-363434657:17,Integrability,wrap,wrappers,17,"Added basic java wrappers for training and tranches. I'm working on integration tests and docs today, but the other files should be ready for 1st round review.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4245#issuecomment-363434657
https://github.com/broadinstitute/gatk/pull/4245#issuecomment-363434657:68,Integrability,integrat,integration,68,"Added basic java wrappers for training and tranches. I'm working on integration tests and docs today, but the other files should be ready for 1st round review.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4245#issuecomment-363434657
https://github.com/broadinstitute/gatk/pull/4245#issuecomment-363434657:80,Testability,test,tests,80,"Added basic java wrappers for training and tranches. I'm working on integration tests and docs today, but the other files should be ready for 1st round review.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4245#issuecomment-363434657
https://github.com/broadinstitute/gatk/pull/4245#issuecomment-367392708:37,Deployability,release,release,37,Would love to get this into Friday's release. @cmnbroad do you think it's possible?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4245#issuecomment-367392708
https://github.com/broadinstitute/gatk/pull/4245#issuecomment-367397138:395,Deployability,integrat,integration,395,"Given that the tools in this PR are marked as experimental, I think it should be possible @lucidtronix. It would be good, though, if we could recruit someone (@samuelklee ? @mbabadi ?) to do a review pass on the Python side of this branch, as I don't think it's had a proper code review yet. We should also make sure that @cmnbroad is satisfied that the new tools are covered by good end-to-end integration tests.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4245#issuecomment-367397138
https://github.com/broadinstitute/gatk/pull/4245#issuecomment-367397138:395,Integrability,integrat,integration,395,"Given that the tools in this PR are marked as experimental, I think it should be possible @lucidtronix. It would be good, though, if we could recruit someone (@samuelklee ? @mbabadi ?) to do a review pass on the Python side of this branch, as I don't think it's had a proper code review yet. We should also make sure that @cmnbroad is satisfied that the new tools are covered by good end-to-end integration tests.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4245#issuecomment-367397138
https://github.com/broadinstitute/gatk/pull/4245#issuecomment-367397138:407,Testability,test,tests,407,"Given that the tools in this PR are marked as experimental, I think it should be possible @lucidtronix. It would be good, though, if we could recruit someone (@samuelklee ? @mbabadi ?) to do a review pass on the Python side of this branch, as I don't think it's had a proper code review yet. We should also make sure that @cmnbroad is satisfied that the new tools are covered by good end-to-end integration tests.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4245#issuecomment-367397138
https://github.com/broadinstitute/gatk/pull/4245#issuecomment-367435050:212,Deployability,integrat,integration,212,"It looks like there have been some changes since I last looked at this, including one new tool, so I can make another pass on the java code. But I'd feel a lot better about taking this if there were at least one integration test for each of the tools (right now there are a couple of tests for the inference tool, and none for the other 3 tools). @lucidtronix is that possible to do that in the next day or so ? . As for type hinting,I'd love to see it in all of our Python code. I think it made the gcnv code much more readable (BTW, does anyone have mypy stubs for numpy, theano, tensorflow) ? We might want to run a type/checker linter as part of the build.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4245#issuecomment-367435050
https://github.com/broadinstitute/gatk/pull/4245#issuecomment-367435050:212,Integrability,integrat,integration,212,"It looks like there have been some changes since I last looked at this, including one new tool, so I can make another pass on the java code. But I'd feel a lot better about taking this if there were at least one integration test for each of the tools (right now there are a couple of tests for the inference tool, and none for the other 3 tools). @lucidtronix is that possible to do that in the next day or so ? . As for type hinting,I'd love to see it in all of our Python code. I think it made the gcnv code much more readable (BTW, does anyone have mypy stubs for numpy, theano, tensorflow) ? We might want to run a type/checker linter as part of the build.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4245#issuecomment-367435050
https://github.com/broadinstitute/gatk/pull/4245#issuecomment-367435050:224,Testability,test,test,224,"It looks like there have been some changes since I last looked at this, including one new tool, so I can make another pass on the java code. But I'd feel a lot better about taking this if there were at least one integration test for each of the tools (right now there are a couple of tests for the inference tool, and none for the other 3 tools). @lucidtronix is that possible to do that in the next day or so ? . As for type hinting,I'd love to see it in all of our Python code. I think it made the gcnv code much more readable (BTW, does anyone have mypy stubs for numpy, theano, tensorflow) ? We might want to run a type/checker linter as part of the build.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4245#issuecomment-367435050
https://github.com/broadinstitute/gatk/pull/4245#issuecomment-367435050:284,Testability,test,tests,284,"It looks like there have been some changes since I last looked at this, including one new tool, so I can make another pass on the java code. But I'd feel a lot better about taking this if there were at least one integration test for each of the tools (right now there are a couple of tests for the inference tool, and none for the other 3 tools). @lucidtronix is that possible to do that in the next day or so ? . As for type hinting,I'd love to see it in all of our Python code. I think it made the gcnv code much more readable (BTW, does anyone have mypy stubs for numpy, theano, tensorflow) ? We might want to run a type/checker linter as part of the build.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4245#issuecomment-367435050
https://github.com/broadinstitute/gatk/pull/4245#issuecomment-367435050:557,Testability,stub,stubs,557,"It looks like there have been some changes since I last looked at this, including one new tool, so I can make another pass on the java code. But I'd feel a lot better about taking this if there were at least one integration test for each of the tools (right now there are a couple of tests for the inference tool, and none for the other 3 tools). @lucidtronix is that possible to do that in the next day or so ? . As for type hinting,I'd love to see it in all of our Python code. I think it made the gcnv code much more readable (BTW, does anyone have mypy stubs for numpy, theano, tensorflow) ? We might want to run a type/checker linter as part of the build.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4245#issuecomment-367435050
https://github.com/broadinstitute/gatk/pull/4245#issuecomment-367444433:153,Deployability,release,release,153,"@samuelklee I think the original goal was to get this out into the world during or shortly after AGBT, hence the push to try to get this into the Friday release. If it doesn't make it in, though, we can easily cut another release for @lucidtronix next week, so not the end of the world. To clarify what I meant by ""high-level pass"": I'd be satisfied if someone just spent 15 minutes skimming over the Python code here, and then posted a single comment with a list of really obvious TODOs that @lucidtronix could then turn into tickets (perhaps you already have such a mental list?). If no one on your end has bandwidth to spare this week, though, then I defer to @cmnbroad on whether to wait until someone frees up. Since it's experimental code the bar should be pretty low, but I'd feel better if another user of these Python libraries had a brief look prior to merge.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4245#issuecomment-367444433
https://github.com/broadinstitute/gatk/pull/4245#issuecomment-367444433:222,Deployability,release,release,222,"@samuelklee I think the original goal was to get this out into the world during or shortly after AGBT, hence the push to try to get this into the Friday release. If it doesn't make it in, though, we can easily cut another release for @lucidtronix next week, so not the end of the world. To clarify what I meant by ""high-level pass"": I'd be satisfied if someone just spent 15 minutes skimming over the Python code here, and then posted a single comment with a list of really obvious TODOs that @lucidtronix could then turn into tickets (perhaps you already have such a mental list?). If no one on your end has bandwidth to spare this week, though, then I defer to @cmnbroad on whether to wait until someone frees up. Since it's experimental code the bar should be pretty low, but I'd feel better if another user of these Python libraries had a brief look prior to merge.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4245#issuecomment-367444433
https://github.com/broadinstitute/gatk/pull/4245#issuecomment-367449432:307,Deployability,release,release-style,307,"@cmnbroad I refactored the training java wrapper into separate wrappers to write tensors (CNNVariantWriteTensors.java) and to train (CNNVariantTrain.java) I think this simplified the meaning/necessity of many of the arguments, which was unclear when all those tools were rolled together. . I'm working on a release-style integration test that chains all the tools together, like @droazen discussed a few meetings ago, but for this PR I think I will have to do something simpler. Because of some issues with the GSA5 environment and GPU, I still have to write in a Python2/3 agnostic way, which precludes the use of type hints. I would like to update, but I'm blocked by BITs in the short term.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4245#issuecomment-367449432
https://github.com/broadinstitute/gatk/pull/4245#issuecomment-367449432:321,Deployability,integrat,integration,321,"@cmnbroad I refactored the training java wrapper into separate wrappers to write tensors (CNNVariantWriteTensors.java) and to train (CNNVariantTrain.java) I think this simplified the meaning/necessity of many of the arguments, which was unclear when all those tools were rolled together. . I'm working on a release-style integration test that chains all the tools together, like @droazen discussed a few meetings ago, but for this PR I think I will have to do something simpler. Because of some issues with the GSA5 environment and GPU, I still have to write in a Python2/3 agnostic way, which precludes the use of type hints. I would like to update, but I'm blocked by BITs in the short term.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4245#issuecomment-367449432
https://github.com/broadinstitute/gatk/pull/4245#issuecomment-367449432:643,Deployability,update,update,643,"@cmnbroad I refactored the training java wrapper into separate wrappers to write tensors (CNNVariantWriteTensors.java) and to train (CNNVariantTrain.java) I think this simplified the meaning/necessity of many of the arguments, which was unclear when all those tools were rolled together. . I'm working on a release-style integration test that chains all the tools together, like @droazen discussed a few meetings ago, but for this PR I think I will have to do something simpler. Because of some issues with the GSA5 environment and GPU, I still have to write in a Python2/3 agnostic way, which precludes the use of type hints. I would like to update, but I'm blocked by BITs in the short term.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4245#issuecomment-367449432
https://github.com/broadinstitute/gatk/pull/4245#issuecomment-367449432:41,Integrability,wrap,wrapper,41,"@cmnbroad I refactored the training java wrapper into separate wrappers to write tensors (CNNVariantWriteTensors.java) and to train (CNNVariantTrain.java) I think this simplified the meaning/necessity of many of the arguments, which was unclear when all those tools were rolled together. . I'm working on a release-style integration test that chains all the tools together, like @droazen discussed a few meetings ago, but for this PR I think I will have to do something simpler. Because of some issues with the GSA5 environment and GPU, I still have to write in a Python2/3 agnostic way, which precludes the use of type hints. I would like to update, but I'm blocked by BITs in the short term.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4245#issuecomment-367449432
https://github.com/broadinstitute/gatk/pull/4245#issuecomment-367449432:63,Integrability,wrap,wrappers,63,"@cmnbroad I refactored the training java wrapper into separate wrappers to write tensors (CNNVariantWriteTensors.java) and to train (CNNVariantTrain.java) I think this simplified the meaning/necessity of many of the arguments, which was unclear when all those tools were rolled together. . I'm working on a release-style integration test that chains all the tools together, like @droazen discussed a few meetings ago, but for this PR I think I will have to do something simpler. Because of some issues with the GSA5 environment and GPU, I still have to write in a Python2/3 agnostic way, which precludes the use of type hints. I would like to update, but I'm blocked by BITs in the short term.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4245#issuecomment-367449432
https://github.com/broadinstitute/gatk/pull/4245#issuecomment-367449432:321,Integrability,integrat,integration,321,"@cmnbroad I refactored the training java wrapper into separate wrappers to write tensors (CNNVariantWriteTensors.java) and to train (CNNVariantTrain.java) I think this simplified the meaning/necessity of many of the arguments, which was unclear when all those tools were rolled together. . I'm working on a release-style integration test that chains all the tools together, like @droazen discussed a few meetings ago, but for this PR I think I will have to do something simpler. Because of some issues with the GSA5 environment and GPU, I still have to write in a Python2/3 agnostic way, which precludes the use of type hints. I would like to update, but I'm blocked by BITs in the short term.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4245#issuecomment-367449432
https://github.com/broadinstitute/gatk/pull/4245#issuecomment-367449432:12,Modifiability,refactor,refactored,12,"@cmnbroad I refactored the training java wrapper into separate wrappers to write tensors (CNNVariantWriteTensors.java) and to train (CNNVariantTrain.java) I think this simplified the meaning/necessity of many of the arguments, which was unclear when all those tools were rolled together. . I'm working on a release-style integration test that chains all the tools together, like @droazen discussed a few meetings ago, but for this PR I think I will have to do something simpler. Because of some issues with the GSA5 environment and GPU, I still have to write in a Python2/3 agnostic way, which precludes the use of type hints. I would like to update, but I'm blocked by BITs in the short term.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4245#issuecomment-367449432
https://github.com/broadinstitute/gatk/pull/4245#issuecomment-367449432:333,Testability,test,test,333,"@cmnbroad I refactored the training java wrapper into separate wrappers to write tensors (CNNVariantWriteTensors.java) and to train (CNNVariantTrain.java) I think this simplified the meaning/necessity of many of the arguments, which was unclear when all those tools were rolled together. . I'm working on a release-style integration test that chains all the tools together, like @droazen discussed a few meetings ago, but for this PR I think I will have to do something simpler. Because of some issues with the GSA5 environment and GPU, I still have to write in a Python2/3 agnostic way, which precludes the use of type hints. I would like to update, but I'm blocked by BITs in the short term.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4245#issuecomment-367449432
https://github.com/broadinstitute/gatk/pull/4245#issuecomment-367449432:168,Usability,simpl,simplified,168,"@cmnbroad I refactored the training java wrapper into separate wrappers to write tensors (CNNVariantWriteTensors.java) and to train (CNNVariantTrain.java) I think this simplified the meaning/necessity of many of the arguments, which was unclear when all those tools were rolled together. . I'm working on a release-style integration test that chains all the tools together, like @droazen discussed a few meetings ago, but for this PR I think I will have to do something simpler. Because of some issues with the GSA5 environment and GPU, I still have to write in a Python2/3 agnostic way, which precludes the use of type hints. I would like to update, but I'm blocked by BITs in the short term.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4245#issuecomment-367449432
https://github.com/broadinstitute/gatk/pull/4245#issuecomment-367449432:470,Usability,simpl,simpler,470,"@cmnbroad I refactored the training java wrapper into separate wrappers to write tensors (CNNVariantWriteTensors.java) and to train (CNNVariantTrain.java) I think this simplified the meaning/necessity of many of the arguments, which was unclear when all those tools were rolled together. . I'm working on a release-style integration test that chains all the tools together, like @droazen discussed a few meetings ago, but for this PR I think I will have to do something simpler. Because of some issues with the GSA5 environment and GPU, I still have to write in a Python2/3 agnostic way, which precludes the use of type hints. I would like to update, but I'm blocked by BITs in the short term.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4245#issuecomment-367449432
https://github.com/broadinstitute/gatk/pull/4245#issuecomment-367470699:40,Deployability,update,updates,40,"Ah, just saw this last round of comment updates after I posted my last review. Type hinting can certainly wait - would be good to get there though. For the short term, I think the main things are the basic tests, and dealing with the model/json file distribution and argument defaults.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4245#issuecomment-367470699
https://github.com/broadinstitute/gatk/pull/4245#issuecomment-367470699:206,Testability,test,tests,206,"Ah, just saw this last round of comment updates after I posted my last review. Type hinting can certainly wait - would be good to get there though. For the short term, I think the main things are the basic tests, and dealing with the model/json file distribution and argument defaults.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4245#issuecomment-367470699
https://github.com/broadinstitute/gatk/pull/4245#issuecomment-370500208:43,Testability,test,tests,43,"Cleaned up most of the file writing in the tests and now metric plots are only created by the training script if java provides an image-dir argument. If tests pass, I think it's ready for another java review @cmnbroad.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4245#issuecomment-370500208
https://github.com/broadinstitute/gatk/pull/4245#issuecomment-370500208:153,Testability,test,tests,153,"Cleaned up most of the file writing in the tests and now metric plots are only created by the training script if java provides an image-dir argument. If tests pass, I think it's ready for another java review @cmnbroad.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4245#issuecomment-370500208
https://github.com/broadinstitute/gatk/pull/4245#issuecomment-372466321:442,Usability,simpl,simplifying,442,"Hey @lucidtronix, sorry for the delay. . I like the CNNVariant* basename in principle, as it makes it easy to understand which tools are related. CNNVariantWriteTensors and CNNVariantTrain are both quite straightforward so no objections there. However I have some reservations about CNNVariantScore because it's ambiguous as to whether it refers to a score called that, or whether it's the verb to score. As I see it we could resolve that by simplifying the basename to just CNN, and making the three tools CNNWriteTensors, CNNTrainModel and CNNScoreVariants. What do you think? Do we have any reason to believe we would need to be able to call something else CNN* where *!=Variant? If not, the overall process can still be called CNNVariant without needing to include Variant explicitly in the tool names. . For VariantTranchesFromInfoKey, I'd like to find a simpler way to express what it does -- would FilterVariantTranches sound appropriate to you? I'm still a bit fuzzy on exactly what are the inputs/outputs of this tool. Is it a direct analog to the VQSR ApplyRecalibration tool, ie does it take a sensitivity threshold? And can one use any arbitrary Info key? That's what the current name implies to me.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4245#issuecomment-372466321
https://github.com/broadinstitute/gatk/pull/4245#issuecomment-372466321:860,Usability,simpl,simpler,860,"Hey @lucidtronix, sorry for the delay. . I like the CNNVariant* basename in principle, as it makes it easy to understand which tools are related. CNNVariantWriteTensors and CNNVariantTrain are both quite straightforward so no objections there. However I have some reservations about CNNVariantScore because it's ambiguous as to whether it refers to a score called that, or whether it's the verb to score. As I see it we could resolve that by simplifying the basename to just CNN, and making the three tools CNNWriteTensors, CNNTrainModel and CNNScoreVariants. What do you think? Do we have any reason to believe we would need to be able to call something else CNN* where *!=Variant? If not, the overall process can still be called CNNVariant without needing to include Variant explicitly in the tool names. . For VariantTranchesFromInfoKey, I'd like to find a simpler way to express what it does -- would FilterVariantTranches sound appropriate to you? I'm still a bit fuzzy on exactly what are the inputs/outputs of this tool. Is it a direct analog to the VQSR ApplyRecalibration tool, ie does it take a sensitivity threshold? And can one use any arbitrary Info key? That's what the current name implies to me.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4245#issuecomment-372466321
https://github.com/broadinstitute/gatk/pull/4246#issuecomment-360001838:56,Testability,test,tests,56,"@SHuang-Broad If this looks OK, feel free to merge once tests pass.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4246#issuecomment-360001838
https://github.com/broadinstitute/gatk/pull/4247#issuecomment-360832234:743,Integrability,contract,contract,743,"@magigDGS There are 4 separate issues in here, and I have slightly different feelings about each of them. Some comments:. - Removing the RNA string seems fine.; - I deliberately left the GATK test program group in because even though there is a Picard one, its harmless, and easier for people to find.; - I have reservations about exposing and sharing the super category maps. The Picard docgen process is pretty much unused and unmaintained at this point. The `getSuperCategoryMap` mthod really shouldn't be public, and it may even be removed in the near future. The GATK supercategory map ""truth"" should be defined by GATK.; - I'm reluctant to make the GATK `getSuperCategoryMap` public, because I don't think it can have any kind of useful contract. Its tied to the GATK doc templates and doc process, which we need to be able to change freely. It seems much safer for ReadTools to define it's own set categories (the overlap would probably pretty minimal I think - maybe just ReadFilters, right ?).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4247#issuecomment-360832234
https://github.com/broadinstitute/gatk/pull/4247#issuecomment-360832234:862,Safety,safe,safer,862,"@magigDGS There are 4 separate issues in here, and I have slightly different feelings about each of them. Some comments:. - Removing the RNA string seems fine.; - I deliberately left the GATK test program group in because even though there is a Picard one, its harmless, and easier for people to find.; - I have reservations about exposing and sharing the super category maps. The Picard docgen process is pretty much unused and unmaintained at this point. The `getSuperCategoryMap` mthod really shouldn't be public, and it may even be removed in the near future. The GATK supercategory map ""truth"" should be defined by GATK.; - I'm reluctant to make the GATK `getSuperCategoryMap` public, because I don't think it can have any kind of useful contract. Its tied to the GATK doc templates and doc process, which we need to be able to change freely. It seems much safer for ReadTools to define it's own set categories (the overlap would probably pretty minimal I think - maybe just ReadFilters, right ?).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4247#issuecomment-360832234
https://github.com/broadinstitute/gatk/pull/4247#issuecomment-360832234:192,Testability,test,test,192,"@magigDGS There are 4 separate issues in here, and I have slightly different feelings about each of them. Some comments:. - Removing the RNA string seems fine.; - I deliberately left the GATK test program group in because even though there is a Picard one, its harmless, and easier for people to find.; - I have reservations about exposing and sharing the super category maps. The Picard docgen process is pretty much unused and unmaintained at this point. The `getSuperCategoryMap` mthod really shouldn't be public, and it may even be removed in the near future. The GATK supercategory map ""truth"" should be defined by GATK.; - I'm reluctant to make the GATK `getSuperCategoryMap` public, because I don't think it can have any kind of useful contract. Its tied to the GATK doc templates and doc process, which we need to be able to change freely. It seems much safer for ReadTools to define it's own set categories (the overlap would probably pretty minimal I think - maybe just ReadFilters, right ?).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4247#issuecomment-360832234
https://github.com/broadinstitute/gatk/pull/4247#issuecomment-360856661:434,Availability,down,downstream,434,"At the moment, ReadTools only documents and use `ReadFilters` but I am planning to probably add pack a couple of tools from the GATK/Picard tools at some point. In addition, I am working on another toolkit based on the GATK code, and it will include also annotations for variants (and probably some VCF tools). I just thought that it will be useful to been able to pull out the super-category map to re-use the GATK docgen code. If a downstream project with extra-categories wants to use the GATK templates and DocGen code might get into troubles without being able to access that. I am still working on how to document better my toolkits, but it is not a problem yet. Anyway, I don't really have any strong feeling about this; I just wanted to reduce a bit the complexity of the GATK code and do the same with my downstream projects. If it is something that you anticipate that it is going to change the contract often, feel free to close (the RNA Strings can be removed in other PR).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4247#issuecomment-360856661
https://github.com/broadinstitute/gatk/pull/4247#issuecomment-360856661:814,Availability,down,downstream,814,"At the moment, ReadTools only documents and use `ReadFilters` but I am planning to probably add pack a couple of tools from the GATK/Picard tools at some point. In addition, I am working on another toolkit based on the GATK code, and it will include also annotations for variants (and probably some VCF tools). I just thought that it will be useful to been able to pull out the super-category map to re-use the GATK docgen code. If a downstream project with extra-categories wants to use the GATK templates and DocGen code might get into troubles without being able to access that. I am still working on how to document better my toolkits, but it is not a problem yet. Anyway, I don't really have any strong feeling about this; I just wanted to reduce a bit the complexity of the GATK code and do the same with my downstream projects. If it is something that you anticipate that it is going to change the contract often, feel free to close (the RNA Strings can be removed in other PR).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4247#issuecomment-360856661
https://github.com/broadinstitute/gatk/pull/4247#issuecomment-360856661:745,Energy Efficiency,reduce,reduce,745,"At the moment, ReadTools only documents and use `ReadFilters` but I am planning to probably add pack a couple of tools from the GATK/Picard tools at some point. In addition, I am working on another toolkit based on the GATK code, and it will include also annotations for variants (and probably some VCF tools). I just thought that it will be useful to been able to pull out the super-category map to re-use the GATK docgen code. If a downstream project with extra-categories wants to use the GATK templates and DocGen code might get into troubles without being able to access that. I am still working on how to document better my toolkits, but it is not a problem yet. Anyway, I don't really have any strong feeling about this; I just wanted to reduce a bit the complexity of the GATK code and do the same with my downstream projects. If it is something that you anticipate that it is going to change the contract often, feel free to close (the RNA Strings can be removed in other PR).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4247#issuecomment-360856661
https://github.com/broadinstitute/gatk/pull/4247#issuecomment-360856661:905,Integrability,contract,contract,905,"At the moment, ReadTools only documents and use `ReadFilters` but I am planning to probably add pack a couple of tools from the GATK/Picard tools at some point. In addition, I am working on another toolkit based on the GATK code, and it will include also annotations for variants (and probably some VCF tools). I just thought that it will be useful to been able to pull out the super-category map to re-use the GATK docgen code. If a downstream project with extra-categories wants to use the GATK templates and DocGen code might get into troubles without being able to access that. I am still working on how to document better my toolkits, but it is not a problem yet. Anyway, I don't really have any strong feeling about this; I just wanted to reduce a bit the complexity of the GATK code and do the same with my downstream projects. If it is something that you anticipate that it is going to change the contract often, feel free to close (the RNA Strings can be removed in other PR).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4247#issuecomment-360856661
https://github.com/broadinstitute/gatk/pull/4247#issuecomment-360856661:569,Security,access,access,569,"At the moment, ReadTools only documents and use `ReadFilters` but I am planning to probably add pack a couple of tools from the GATK/Picard tools at some point. In addition, I am working on another toolkit based on the GATK code, and it will include also annotations for variants (and probably some VCF tools). I just thought that it will be useful to been able to pull out the super-category map to re-use the GATK docgen code. If a downstream project with extra-categories wants to use the GATK templates and DocGen code might get into troubles without being able to access that. I am still working on how to document better my toolkits, but it is not a problem yet. Anyway, I don't really have any strong feeling about this; I just wanted to reduce a bit the complexity of the GATK code and do the same with my downstream projects. If it is something that you anticipate that it is going to change the contract often, feel free to close (the RNA Strings can be removed in other PR).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4247#issuecomment-360856661
https://github.com/broadinstitute/gatk/issues/4248#issuecomment-360212288:408,Availability,error,error,408,"This seems like a compiler bug to me. It only produces a warning on some machines, and we're not sure which ones. It runs fine on travis which is running ubuntu 16.04 I think, and it runs fine on OSX. I'm not sure if producing the warning is the bug, or not producing the warning, but there's definitely a bug somewhere in one instance of the compiler. . You'll notice that the code it's referring to in the error message is NOT the code that's causing the issue, which is another manifestation of it's bugginess.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4248#issuecomment-360212288
https://github.com/broadinstitute/gatk/issues/4248#issuecomment-360212288:414,Integrability,message,message,414,"This seems like a compiler bug to me. It only produces a warning on some machines, and we're not sure which ones. It runs fine on travis which is running ubuntu 16.04 I think, and it runs fine on OSX. I'm not sure if producing the warning is the bug, or not producing the warning, but there's definitely a bug somewhere in one instance of the compiler. . You'll notice that the code it's referring to in the error message is NOT the code that's causing the issue, which is another manifestation of it's bugginess.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4248#issuecomment-360212288
https://github.com/broadinstitute/gatk/issues/4248#issuecomment-360244997:65,Availability,error,error,65,"We identified the piece of code that was causing the compilation error; it was removed in #4215, which was just merged. Can you update your master and try again?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4248#issuecomment-360244997
https://github.com/broadinstitute/gatk/issues/4248#issuecomment-360244997:128,Deployability,update,update,128,"We identified the piece of code that was causing the compilation error; it was removed in #4215, which was just merged. Can you update your master and try again?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4248#issuecomment-360244997
https://github.com/broadinstitute/gatk/issues/4248#issuecomment-360361170:39,Availability,failure,failures,39,"We still aren't sure why we didn't see failures on Travis, but since the offending code was removed, I'll go ahead and close.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4248#issuecomment-360361170
https://github.com/broadinstitute/gatk/issues/4250#issuecomment-406067920:69,Availability,avail,available,69,"With the exception of the HMM package, all of our R dependencies are available through the conda R or bioconda channels; the HMM package is available only through a user's custom channel. However, the HMM package is only used to generate truth for testing the Java HMM code by @vruano (which is currently unused, but we thought was worth keeping around). I'm sure we could easily rewrite the tests to load the truth from a file. I think we should get rid of the install_R_packages.R script altogether and just roll all of these dependencies into the conda environment.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4250#issuecomment-406067920
https://github.com/broadinstitute/gatk/issues/4250#issuecomment-406067920:140,Availability,avail,available,140,"With the exception of the HMM package, all of our R dependencies are available through the conda R or bioconda channels; the HMM package is available only through a user's custom channel. However, the HMM package is only used to generate truth for testing the Java HMM code by @vruano (which is currently unused, but we thought was worth keeping around). I'm sure we could easily rewrite the tests to load the truth from a file. I think we should get rid of the install_R_packages.R script altogether and just roll all of these dependencies into the conda environment.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4250#issuecomment-406067920
https://github.com/broadinstitute/gatk/issues/4250#issuecomment-406067920:52,Integrability,depend,dependencies,52,"With the exception of the HMM package, all of our R dependencies are available through the conda R or bioconda channels; the HMM package is available only through a user's custom channel. However, the HMM package is only used to generate truth for testing the Java HMM code by @vruano (which is currently unused, but we thought was worth keeping around). I'm sure we could easily rewrite the tests to load the truth from a file. I think we should get rid of the install_R_packages.R script altogether and just roll all of these dependencies into the conda environment.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4250#issuecomment-406067920
https://github.com/broadinstitute/gatk/issues/4250#issuecomment-406067920:528,Integrability,depend,dependencies,528,"With the exception of the HMM package, all of our R dependencies are available through the conda R or bioconda channels; the HMM package is available only through a user's custom channel. However, the HMM package is only used to generate truth for testing the Java HMM code by @vruano (which is currently unused, but we thought was worth keeping around). I'm sure we could easily rewrite the tests to load the truth from a file. I think we should get rid of the install_R_packages.R script altogether and just roll all of these dependencies into the conda environment.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4250#issuecomment-406067920
https://github.com/broadinstitute/gatk/issues/4250#issuecomment-406067920:380,Modifiability,rewrite,rewrite,380,"With the exception of the HMM package, all of our R dependencies are available through the conda R or bioconda channels; the HMM package is available only through a user's custom channel. However, the HMM package is only used to generate truth for testing the Java HMM code by @vruano (which is currently unused, but we thought was worth keeping around). I'm sure we could easily rewrite the tests to load the truth from a file. I think we should get rid of the install_R_packages.R script altogether and just roll all of these dependencies into the conda environment.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4250#issuecomment-406067920
https://github.com/broadinstitute/gatk/issues/4250#issuecomment-406067920:401,Performance,load,load,401,"With the exception of the HMM package, all of our R dependencies are available through the conda R or bioconda channels; the HMM package is available only through a user's custom channel. However, the HMM package is only used to generate truth for testing the Java HMM code by @vruano (which is currently unused, but we thought was worth keeping around). I'm sure we could easily rewrite the tests to load the truth from a file. I think we should get rid of the install_R_packages.R script altogether and just roll all of these dependencies into the conda environment.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4250#issuecomment-406067920
https://github.com/broadinstitute/gatk/issues/4250#issuecomment-406067920:248,Testability,test,testing,248,"With the exception of the HMM package, all of our R dependencies are available through the conda R or bioconda channels; the HMM package is available only through a user's custom channel. However, the HMM package is only used to generate truth for testing the Java HMM code by @vruano (which is currently unused, but we thought was worth keeping around). I'm sure we could easily rewrite the tests to load the truth from a file. I think we should get rid of the install_R_packages.R script altogether and just roll all of these dependencies into the conda environment.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4250#issuecomment-406067920
https://github.com/broadinstitute/gatk/issues/4250#issuecomment-406067920:392,Testability,test,tests,392,"With the exception of the HMM package, all of our R dependencies are available through the conda R or bioconda channels; the HMM package is available only through a user's custom channel. However, the HMM package is only used to generate truth for testing the Java HMM code by @vruano (which is currently unused, but we thought was worth keeping around). I'm sure we could easily rewrite the tests to load the truth from a file. I think we should get rid of the install_R_packages.R script altogether and just roll all of these dependencies into the conda environment.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4250#issuecomment-406067920
https://github.com/broadinstitute/gatk/issues/4252#issuecomment-364237834:1598,Energy Efficiency,monitor,monitorThreadEfficiency,1598,ed=false disableDithering=false maxRuntime=-1 maxRuntimeUnits=MINUTES downsampling_type=BY_SAMPLE downsample_to_fraction=null downsample_to_coverage=1000 baq=OFF baqGapOpenPenalty=40.0 refactor_NDN_cigar_string=false fix_misencoded_quality_scores=false allow_potentially_misencoded_quality_scores=false useOriginalQualities=false defaultBaseQualities=-1 performanceLog=null BQSR=null quantize_quals=0 static_quantized_quals=null round_down_quantized=false disable_indel_quals=false emit_original_quals=false preserve_qscores_less_than=6 globalQScorePrior=-1.0 validation_strictness=SILENT remove_program_records=false keep_program_records=false sample_rename_mapping_file=null unsafe=null disable_auto_index_creation_and_locking_when_reading_rods=false no_cmdline_in_header=false sites_only=true never_trim_vcf_format_field=false bcf=false bam_compression=null simplifyBAM=false disable_bam_indexing=false generate_md5=false num_threads=1 num_cpu_threads_per_data_thread=1 num_io_threads=0 monitorThreadEfficiency=false num_bam_file_handles=null read_group_black_list=null pedigree=[] pedigreeString=[] pedigreeValidationType=STRICT allow_intervals_with_unindexed_bam=false generateShadowBCF=false variant_index_type=DYNAMIC_SEEK variant_index_parameter=-1 reference_window_stop=0 logging_level=INFO log_to_file=null help=false version=false variant=(RodBinding name=variant source=/humgen/gsa-hpprojects/dev/gauthier/AS_GTEx/GTEx_AS/GTEx_AS.recal.multialleleics.AS.recalibrated.mixed.vcf) discordance=(RodBinding name= source=UNBOUND) concordance=(RodBinding name= source=UNBOUND) out=/humgen/gsa-hpprojects/dev/gauthier/AS_GTEx/VQSR.AStest.input.vcf sample_name=[] sample_expressions=null sample_file=null exclude_sample_name=[] exclude_sample_file=[] exclude_sample_expressions=[] selectexpressions=[] invertselect=false excludeNonVariants=false excludeFiltered=false preserveAlleles=false removeUnusedAlternates=false restrictAllelesTo=ALL keepOriginalAC=false keepOriginalDP=false mendelianViola,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4252#issuecomment-364237834
https://github.com/broadinstitute/gatk/issues/4252#issuecomment-364237834:4706,Energy Efficiency,monitor,monitorThreadEfficiency,4706,ed=false disableDithering=false maxRuntime=-1 maxRuntimeUnits=MINUTES downsampling_type=BY_SAMPLE downsample_to_fraction=null downsample_to_coverage=1000 baq=OFF baqGapOpenPenalty=40.0 refactor_NDN_cigar_string=false fix_misencoded_quality_scores=false allow_potentially_misencoded_quality_scores=false useOriginalQualities=false defaultBaseQualities=-1 performanceLog=null BQSR=null quantize_quals=0 static_quantized_quals=null round_down_quantized=false disable_indel_quals=false emit_original_quals=false preserve_qscores_less_than=6 globalQScorePrior=-1.0 validation_strictness=SILENT remove_program_records=false keep_program_records=false sample_rename_mapping_file=null unsafe=null disable_auto_index_creation_and_locking_when_reading_rods=false no_cmdline_in_header=false sites_only=false never_trim_vcf_format_field=false bcf=false bam_compression=null simplifyBAM=false disable_bam_indexing=false generate_md5=false num_threads=1 num_cpu_threads_per_data_thread=1 num_io_threads=0 monitorThreadEfficiency=false num_bam_file_handles=null read_group_black_list=null pedigree=[] pedigreeString=[] pedigreeValidationType=STRICT allow_intervals_with_unindexed_bam=false generateShadowBCF=false variant_index_type=DYNAMIC_SEEK variant_index_parameter=-1 reference_window_stop=0 logging_level=INFO log_to_file=null help=false version=false variant=(RodBinding name=variant source=/humgen/gsa-hpprojects/dev/gauthier/AS_GTEx/GTEx_AS/GTEx_AS.recal.multialleleics.AS.recalibrated.vcf) discordance=(RodBinding name= source=UNBOUND) concordance=(RodBinding name= source=UNBOUND) out=/humgen/gsa-hpprojects/dev/gauthier/AS_GTEx/GTEx_AS/GTEx_AS.recal.multialleleics.AS.recalibrated.mixed.vcf sample_name=[] sample_expressions=null sample_file=null exclude_sample_name=[] exclude_sample_file=[] exclude_sample_expressions=[] selectexpressions=[] invertselect=false excludeNonVariants=false excludeFiltered=false preserveAlleles=false removeUnusedAlternates=false restrictAllelesTo=ALL keepOriginalAC=false ,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4252#issuecomment-364237834
https://github.com/broadinstitute/gatk/issues/4252#issuecomment-364237834:962,Performance,perform,performanceLog,962,"Note that GATK3 uniquified the `GATKCommandLine` lines using a scheme like this:. ```; ##GATKCommandLine.SelectVariants.2=<ID=SelectVariants,Version=3.4-228-g2497091,Date=""Tue Jan 05 13:48:45 EST 2016"",Epoch=1452019725506,CommandLineOptions=""analysis_type=SelectVariants input_file=[] showFullBamList=false read_buffer_size=null phone_home=AWS gatk_key=null tag=NA read_filter=[] disable_read_filter=[] intervals=[3:113005755-195507036] excludeIntervals=null interval_set_rule=UNION interval_merging=ALL interval_padding=0 reference_sequence=/humgen/1kg/reference/human_g1k_v37.fasta nonDeterministicRandomSeed=false disableDithering=false maxRuntime=-1 maxRuntimeUnits=MINUTES downsampling_type=BY_SAMPLE downsample_to_fraction=null downsample_to_coverage=1000 baq=OFF baqGapOpenPenalty=40.0 refactor_NDN_cigar_string=false fix_misencoded_quality_scores=false allow_potentially_misencoded_quality_scores=false useOriginalQualities=false defaultBaseQualities=-1 performanceLog=null BQSR=null quantize_quals=0 static_quantized_quals=null round_down_quantized=false disable_indel_quals=false emit_original_quals=false preserve_qscores_less_than=6 globalQScorePrior=-1.0 validation_strictness=SILENT remove_program_records=false keep_program_records=false sample_rename_mapping_file=null unsafe=null disable_auto_index_creation_and_locking_when_reading_rods=false no_cmdline_in_header=false sites_only=true never_trim_vcf_format_field=false bcf=false bam_compression=null simplifyBAM=false disable_bam_indexing=false generate_md5=false num_threads=1 num_cpu_threads_per_data_thread=1 num_io_threads=0 monitorThreadEfficiency=false num_bam_file_handles=null read_group_black_list=null pedigree=[] pedigreeString=[] pedigreeValidationType=STRICT allow_intervals_with_unindexed_bam=false generateShadowBCF=false variant_index_type=DYNAMIC_SEEK variant_index_parameter=-1 reference_window_stop=0 logging_level=INFO log_to_file=null help=false version=false variant=(RodBinding name=variant source=/humgen/gsa",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4252#issuecomment-364237834
https://github.com/broadinstitute/gatk/issues/4252#issuecomment-364237834:4069,Performance,perform,performanceLog,4069,"e forceValidOutput=false filter_reads_with_N_cigar=false filter_mismatching_base_and_quals=false filter_bases_not_stored=false"">; ##GATKCommandLine.SelectVariants=<ID=SelectVariants,Version=3.4-228-g2497091,Date=""Tue Jan 05 13:29:45 EST 2016"",Epoch=1452018585661,CommandLineOptions=""analysis_type=SelectVariants input_file=[] showFullBamList=false read_buffer_size=null phone_home=AWS gatk_key=null tag=NA read_filter=[] disable_read_filter=[] intervals=null excludeIntervals=null interval_set_rule=UNION interval_merging=ALL interval_padding=0 reference_sequence=/humgen/1kg/reference/human_g1k_v37.fasta nonDeterministicRandomSeed=false disableDithering=false maxRuntime=-1 maxRuntimeUnits=MINUTES downsampling_type=BY_SAMPLE downsample_to_fraction=null downsample_to_coverage=1000 baq=OFF baqGapOpenPenalty=40.0 refactor_NDN_cigar_string=false fix_misencoded_quality_scores=false allow_potentially_misencoded_quality_scores=false useOriginalQualities=false defaultBaseQualities=-1 performanceLog=null BQSR=null quantize_quals=0 static_quantized_quals=null round_down_quantized=false disable_indel_quals=false emit_original_quals=false preserve_qscores_less_than=6 globalQScorePrior=-1.0 validation_strictness=SILENT remove_program_records=false keep_program_records=false sample_rename_mapping_file=null unsafe=null disable_auto_index_creation_and_locking_when_reading_rods=false no_cmdline_in_header=false sites_only=false never_trim_vcf_format_field=false bcf=false bam_compression=null simplifyBAM=false disable_bam_indexing=false generate_md5=false num_threads=1 num_cpu_threads_per_data_thread=1 num_io_threads=0 monitorThreadEfficiency=false num_bam_file_handles=null read_group_black_list=null pedigree=[] pedigreeString=[] pedigreeValidationType=STRICT allow_intervals_with_unindexed_bam=false generateShadowBCF=false variant_index_type=DYNAMIC_SEEK variant_index_parameter=-1 reference_window_stop=0 logging_level=INFO log_to_file=null help=false version=false variant=(RodBinding name=var",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4252#issuecomment-364237834
https://github.com/broadinstitute/gatk/issues/4252#issuecomment-364237834:1285,Safety,unsafe,unsafe,1285,ed=false disableDithering=false maxRuntime=-1 maxRuntimeUnits=MINUTES downsampling_type=BY_SAMPLE downsample_to_fraction=null downsample_to_coverage=1000 baq=OFF baqGapOpenPenalty=40.0 refactor_NDN_cigar_string=false fix_misencoded_quality_scores=false allow_potentially_misencoded_quality_scores=false useOriginalQualities=false defaultBaseQualities=-1 performanceLog=null BQSR=null quantize_quals=0 static_quantized_quals=null round_down_quantized=false disable_indel_quals=false emit_original_quals=false preserve_qscores_less_than=6 globalQScorePrior=-1.0 validation_strictness=SILENT remove_program_records=false keep_program_records=false sample_rename_mapping_file=null unsafe=null disable_auto_index_creation_and_locking_when_reading_rods=false no_cmdline_in_header=false sites_only=true never_trim_vcf_format_field=false bcf=false bam_compression=null simplifyBAM=false disable_bam_indexing=false generate_md5=false num_threads=1 num_cpu_threads_per_data_thread=1 num_io_threads=0 monitorThreadEfficiency=false num_bam_file_handles=null read_group_black_list=null pedigree=[] pedigreeString=[] pedigreeValidationType=STRICT allow_intervals_with_unindexed_bam=false generateShadowBCF=false variant_index_type=DYNAMIC_SEEK variant_index_parameter=-1 reference_window_stop=0 logging_level=INFO log_to_file=null help=false version=false variant=(RodBinding name=variant source=/humgen/gsa-hpprojects/dev/gauthier/AS_GTEx/GTEx_AS/GTEx_AS.recal.multialleleics.AS.recalibrated.mixed.vcf) discordance=(RodBinding name= source=UNBOUND) concordance=(RodBinding name= source=UNBOUND) out=/humgen/gsa-hpprojects/dev/gauthier/AS_GTEx/VQSR.AStest.input.vcf sample_name=[] sample_expressions=null sample_file=null exclude_sample_name=[] exclude_sample_file=[] exclude_sample_expressions=[] selectexpressions=[] invertselect=false excludeNonVariants=false excludeFiltered=false preserveAlleles=false removeUnusedAlternates=false restrictAllelesTo=ALL keepOriginalAC=false keepOriginalDP=false mendelianViola,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4252#issuecomment-364237834
https://github.com/broadinstitute/gatk/issues/4252#issuecomment-364237834:4392,Safety,unsafe,unsafe,4392,ed=false disableDithering=false maxRuntime=-1 maxRuntimeUnits=MINUTES downsampling_type=BY_SAMPLE downsample_to_fraction=null downsample_to_coverage=1000 baq=OFF baqGapOpenPenalty=40.0 refactor_NDN_cigar_string=false fix_misencoded_quality_scores=false allow_potentially_misencoded_quality_scores=false useOriginalQualities=false defaultBaseQualities=-1 performanceLog=null BQSR=null quantize_quals=0 static_quantized_quals=null round_down_quantized=false disable_indel_quals=false emit_original_quals=false preserve_qscores_less_than=6 globalQScorePrior=-1.0 validation_strictness=SILENT remove_program_records=false keep_program_records=false sample_rename_mapping_file=null unsafe=null disable_auto_index_creation_and_locking_when_reading_rods=false no_cmdline_in_header=false sites_only=false never_trim_vcf_format_field=false bcf=false bam_compression=null simplifyBAM=false disable_bam_indexing=false generate_md5=false num_threads=1 num_cpu_threads_per_data_thread=1 num_io_threads=0 monitorThreadEfficiency=false num_bam_file_handles=null read_group_black_list=null pedigree=[] pedigreeString=[] pedigreeValidationType=STRICT allow_intervals_with_unindexed_bam=false generateShadowBCF=false variant_index_type=DYNAMIC_SEEK variant_index_parameter=-1 reference_window_stop=0 logging_level=INFO log_to_file=null help=false version=false variant=(RodBinding name=variant source=/humgen/gsa-hpprojects/dev/gauthier/AS_GTEx/GTEx_AS/GTEx_AS.recal.multialleleics.AS.recalibrated.vcf) discordance=(RodBinding name= source=UNBOUND) concordance=(RodBinding name= source=UNBOUND) out=/humgen/gsa-hpprojects/dev/gauthier/AS_GTEx/GTEx_AS/GTEx_AS.recal.multialleleics.AS.recalibrated.mixed.vcf sample_name=[] sample_expressions=null sample_file=null exclude_sample_name=[] exclude_sample_file=[] exclude_sample_expressions=[] selectexpressions=[] invertselect=false excludeNonVariants=false excludeFiltered=false preserveAlleles=false removeUnusedAlternates=false restrictAllelesTo=ALL keepOriginalAC=false ,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4252#issuecomment-364237834
https://github.com/broadinstitute/gatk/issues/4252#issuecomment-364237834:1469,Usability,simpl,simplifyBAM,1469,ed=false disableDithering=false maxRuntime=-1 maxRuntimeUnits=MINUTES downsampling_type=BY_SAMPLE downsample_to_fraction=null downsample_to_coverage=1000 baq=OFF baqGapOpenPenalty=40.0 refactor_NDN_cigar_string=false fix_misencoded_quality_scores=false allow_potentially_misencoded_quality_scores=false useOriginalQualities=false defaultBaseQualities=-1 performanceLog=null BQSR=null quantize_quals=0 static_quantized_quals=null round_down_quantized=false disable_indel_quals=false emit_original_quals=false preserve_qscores_less_than=6 globalQScorePrior=-1.0 validation_strictness=SILENT remove_program_records=false keep_program_records=false sample_rename_mapping_file=null unsafe=null disable_auto_index_creation_and_locking_when_reading_rods=false no_cmdline_in_header=false sites_only=true never_trim_vcf_format_field=false bcf=false bam_compression=null simplifyBAM=false disable_bam_indexing=false generate_md5=false num_threads=1 num_cpu_threads_per_data_thread=1 num_io_threads=0 monitorThreadEfficiency=false num_bam_file_handles=null read_group_black_list=null pedigree=[] pedigreeString=[] pedigreeValidationType=STRICT allow_intervals_with_unindexed_bam=false generateShadowBCF=false variant_index_type=DYNAMIC_SEEK variant_index_parameter=-1 reference_window_stop=0 logging_level=INFO log_to_file=null help=false version=false variant=(RodBinding name=variant source=/humgen/gsa-hpprojects/dev/gauthier/AS_GTEx/GTEx_AS/GTEx_AS.recal.multialleleics.AS.recalibrated.mixed.vcf) discordance=(RodBinding name= source=UNBOUND) concordance=(RodBinding name= source=UNBOUND) out=/humgen/gsa-hpprojects/dev/gauthier/AS_GTEx/VQSR.AStest.input.vcf sample_name=[] sample_expressions=null sample_file=null exclude_sample_name=[] exclude_sample_file=[] exclude_sample_expressions=[] selectexpressions=[] invertselect=false excludeNonVariants=false excludeFiltered=false preserveAlleles=false removeUnusedAlternates=false restrictAllelesTo=ALL keepOriginalAC=false keepOriginalDP=false mendelianViola,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4252#issuecomment-364237834
https://github.com/broadinstitute/gatk/issues/4252#issuecomment-364237834:4577,Usability,simpl,simplifyBAM,4577,ed=false disableDithering=false maxRuntime=-1 maxRuntimeUnits=MINUTES downsampling_type=BY_SAMPLE downsample_to_fraction=null downsample_to_coverage=1000 baq=OFF baqGapOpenPenalty=40.0 refactor_NDN_cigar_string=false fix_misencoded_quality_scores=false allow_potentially_misencoded_quality_scores=false useOriginalQualities=false defaultBaseQualities=-1 performanceLog=null BQSR=null quantize_quals=0 static_quantized_quals=null round_down_quantized=false disable_indel_quals=false emit_original_quals=false preserve_qscores_less_than=6 globalQScorePrior=-1.0 validation_strictness=SILENT remove_program_records=false keep_program_records=false sample_rename_mapping_file=null unsafe=null disable_auto_index_creation_and_locking_when_reading_rods=false no_cmdline_in_header=false sites_only=false never_trim_vcf_format_field=false bcf=false bam_compression=null simplifyBAM=false disable_bam_indexing=false generate_md5=false num_threads=1 num_cpu_threads_per_data_thread=1 num_io_threads=0 monitorThreadEfficiency=false num_bam_file_handles=null read_group_black_list=null pedigree=[] pedigreeString=[] pedigreeValidationType=STRICT allow_intervals_with_unindexed_bam=false generateShadowBCF=false variant_index_type=DYNAMIC_SEEK variant_index_parameter=-1 reference_window_stop=0 logging_level=INFO log_to_file=null help=false version=false variant=(RodBinding name=variant source=/humgen/gsa-hpprojects/dev/gauthier/AS_GTEx/GTEx_AS/GTEx_AS.recal.multialleleics.AS.recalibrated.vcf) discordance=(RodBinding name= source=UNBOUND) concordance=(RodBinding name= source=UNBOUND) out=/humgen/gsa-hpprojects/dev/gauthier/AS_GTEx/GTEx_AS/GTEx_AS.recal.multialleleics.AS.recalibrated.mixed.vcf sample_name=[] sample_expressions=null sample_file=null exclude_sample_name=[] exclude_sample_file=[] exclude_sample_expressions=[] selectexpressions=[] invertselect=false excludeNonVariants=false excludeFiltered=false preserveAlleles=false removeUnusedAlternates=false restrictAllelesTo=ALL keepOriginalAC=false ,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4252#issuecomment-364237834
https://github.com/broadinstitute/gatk/issues/4252#issuecomment-365616512:1162,Availability,Error,Error,1162,"Not sure if this should be a separate tickets... It appears that `SelectVariants` duplicates the INFO/AF tag in the header, this results in an invalid vcf. At least according to some tools like [rtg](https://github.com/RealTimeGenomics/rtg-tools). This is with gatk 4.0.1.0. Example:. * Input has correct header:. ```; zcat gnomad.genomes.r2.0.2.sites.hg38.chr18.vcf.gz | grep 'ID=AF,'; ##INFO=<ID=AF,Number=A,Type=Float,Description=""Allele Frequency among genotypes, for each ALT allele, in the same order as listed"">; ```. * Run SelectVariants. Header has now two entries for INFO/AF. ```; gatk SelectVariants -V gnomad.genomes.r2.0.2.sites.hg38.chr18.vcf.gz -O gnomad.r2.0.2.biallelic.hg38.chr18.vcf.gz --restrict-alleles-to BIALLELIC. zcat gnomad.r2.0.2.biallelic.hg38.chr18.vcf.gz | grep 'ID=AF,'; ##INFO=<ID=AF,Number=A,Type=Float,Description=""Allele Frequency among genotypes, for each ALT allele, in the same order as listed"">; ##INFO=<ID=AF,Number=A,Type=Float,Description=""Allele Frequency, for each ALT allele, in the same order as listed"">; ```. * rtg complains:. ```; rtg vcfsubset -i gnomad.r2.0.2.biallelic.hg38.chr18.vcf.gz --keep-info AF -o - ; Error: Invalid VCF header. VCF header contains multiple field declarations with the same ID=AF; ##INFO=<ID=AF,Number=A,Type=Float,Description=""Allele Frequency among genotypes, for each ALT allele, in the same order as listed"">; ##INFO=<ID=AF,Number=A,Type=Float,Description=""Allele Frequency, for each ALT allele, in the same order as listed""> on line:##INFO=<ID=AF,Number=A,Type=Float,Description=""Allele Frequency, for each ALT allele, in the same order as listed"">; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4252#issuecomment-365616512
https://github.com/broadinstitute/gatk/issues/4252#issuecomment-365640704:789,Availability,error,error,789,"@cmnbroad thanks for the additional info. Some more detail from my side in case others stumble upon the same problem... * My input file comes from gnomad (`gs://gnomad-public/release/2.0.2/vcf/genomes/gnomad.genomes.r2.0.2.sites.chr18.vcf.bgz`). I editied it only to turn chromosome ""18"" into ""chr18"". * bcftools handles the duplicate INFO correctly and it fixes it! In case someone find it useful this is the command I used to retain only the AF tag and discard missing values:. ```; bcftools annotate -O z -i 'INFO/AF > 0' -x ^INFO/AF gnomad.r2.0.2.biallelic.hg38.chr18.vcf.gz > gnomad.r2.0.2.simple.hg38.chr18.vcf.gz; ```. * Unrelated to this particular issue, `gatk GetPileupSummaries` (next command in my workflow) doesn't like tags with missing values, I get a NumberFormatException error (I think, I don't have the logs). Hence the option `INFO/AF > 0` in bcftools.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4252#issuecomment-365640704
https://github.com/broadinstitute/gatk/issues/4252#issuecomment-365640704:175,Deployability,release,release,175,"@cmnbroad thanks for the additional info. Some more detail from my side in case others stumble upon the same problem... * My input file comes from gnomad (`gs://gnomad-public/release/2.0.2/vcf/genomes/gnomad.genomes.r2.0.2.sites.chr18.vcf.bgz`). I editied it only to turn chromosome ""18"" into ""chr18"". * bcftools handles the duplicate INFO correctly and it fixes it! In case someone find it useful this is the command I used to retain only the AF tag and discard missing values:. ```; bcftools annotate -O z -i 'INFO/AF > 0' -x ^INFO/AF gnomad.r2.0.2.biallelic.hg38.chr18.vcf.gz > gnomad.r2.0.2.simple.hg38.chr18.vcf.gz; ```. * Unrelated to this particular issue, `gatk GetPileupSummaries` (next command in my workflow) doesn't like tags with missing values, I get a NumberFormatException error (I think, I don't have the logs). Hence the option `INFO/AF > 0` in bcftools.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4252#issuecomment-365640704
https://github.com/broadinstitute/gatk/issues/4252#issuecomment-365640704:822,Testability,log,logs,822,"@cmnbroad thanks for the additional info. Some more detail from my side in case others stumble upon the same problem... * My input file comes from gnomad (`gs://gnomad-public/release/2.0.2/vcf/genomes/gnomad.genomes.r2.0.2.sites.chr18.vcf.bgz`). I editied it only to turn chromosome ""18"" into ""chr18"". * bcftools handles the duplicate INFO correctly and it fixes it! In case someone find it useful this is the command I used to retain only the AF tag and discard missing values:. ```; bcftools annotate -O z -i 'INFO/AF > 0' -x ^INFO/AF gnomad.r2.0.2.biallelic.hg38.chr18.vcf.gz > gnomad.r2.0.2.simple.hg38.chr18.vcf.gz; ```. * Unrelated to this particular issue, `gatk GetPileupSummaries` (next command in my workflow) doesn't like tags with missing values, I get a NumberFormatException error (I think, I don't have the logs). Hence the option `INFO/AF > 0` in bcftools.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4252#issuecomment-365640704
https://github.com/broadinstitute/gatk/issues/4252#issuecomment-365640704:595,Usability,simpl,simple,595,"@cmnbroad thanks for the additional info. Some more detail from my side in case others stumble upon the same problem... * My input file comes from gnomad (`gs://gnomad-public/release/2.0.2/vcf/genomes/gnomad.genomes.r2.0.2.sites.chr18.vcf.bgz`). I editied it only to turn chromosome ""18"" into ""chr18"". * bcftools handles the duplicate INFO correctly and it fixes it! In case someone find it useful this is the command I used to retain only the AF tag and discard missing values:. ```; bcftools annotate -O z -i 'INFO/AF > 0' -x ^INFO/AF gnomad.r2.0.2.biallelic.hg38.chr18.vcf.gz > gnomad.r2.0.2.simple.hg38.chr18.vcf.gz; ```. * Unrelated to this particular issue, `gatk GetPileupSummaries` (next command in my workflow) doesn't like tags with missing values, I get a NumberFormatException error (I think, I don't have the logs). Hence the option `INFO/AF > 0` in bcftools.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4252#issuecomment-365640704
https://github.com/broadinstitute/gatk/issues/4253#issuecomment-360359965:415,Usability,guid,guide,415,"Oops, did not realize that CRAM support required special treatment of the reference. This only needs to be added as an input to the CollectFragmentCounts task, then, correct? Why are the changes to the CreateReadCountPanelOfNormals task needed?. More generally, if we are aiming to support CRAMs passed via -I in all relevant GATKTools/walkers, then this is probably something that should be added to the WDL style guide. I guess it’d be overkill to make the reference required for these on the Java side.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4253#issuecomment-360359965
https://github.com/broadinstitute/gatk/issues/4253#issuecomment-360362374:68,Testability,test,tests,68,"Also, perhaps we could add CRAMs to the mix of BAMs used in the WDL tests. Should be addressed at the same time as #4007. However, I wouldn't want to just expand the test matrix, since those tests already run long enough.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4253#issuecomment-360362374
https://github.com/broadinstitute/gatk/issues/4253#issuecomment-360362374:166,Testability,test,test,166,"Also, perhaps we could add CRAMs to the mix of BAMs used in the WDL tests. Should be addressed at the same time as #4007. However, I wouldn't want to just expand the test matrix, since those tests already run long enough.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4253#issuecomment-360362374
https://github.com/broadinstitute/gatk/issues/4253#issuecomment-360362374:191,Testability,test,tests,191,"Also, perhaps we could add CRAMs to the mix of BAMs used in the WDL tests. Should be addressed at the same time as #4007. However, I wouldn't want to just expand the test matrix, since those tests already run long enough.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4253#issuecomment-360362374
https://github.com/broadinstitute/gatk/issues/4253#issuecomment-360364668:133,Deployability,pipeline,pipelines,133,"Also, I'm guessing any additional overhead from always requiring the reference (even for BAMs) is probably acceptable in the current pipelines, but it won't hurt to double check.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4253#issuecomment-360364668
https://github.com/broadinstitute/gatk/pull/4254#issuecomment-360533204:20,Testability,test,tests,20,"Also, let's restart tests after fixing the compilation warning and make sure those pass.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4254#issuecomment-360533204
https://github.com/broadinstitute/gatk/pull/4257#issuecomment-360530741:116,Testability,test,test,116,@samuelklee Looks good to me. I discussed w/ @cmnbroad and he thinks replacing the bams with crams is okay for this test.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4257#issuecomment-360530741
https://github.com/broadinstitute/gatk/pull/4259#issuecomment-360544364:1246,Deployability,pipeline,pipelines,1246,1a901076785b0259255a126?src=pr&el=desc) will **decrease** coverage by `0.39%`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #4259 +/- ##; ==============================================; - Coverage 78.458% 78.068% -0.39% ; + Complexity 16439 16368 -71 ; ==============================================; Files 1039 1039 ; Lines 59173 59173 ; Branches 9686 9686 ; ==============================================; - Hits 46426 46195 -231 ; - Misses 8996 9237 +241 ; + Partials 3751 3741 -10; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4259?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4259/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-75.51%)` | `0% <0%> (-17%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4259/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/4259/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...lbender/engine/datasources/ReferenceAPISource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4259/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `25.735% <0%> (-44.853%)` | `8% <0%> (-19%)` | |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/4259/diff?src=pr&el=tree#diff-c3J,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4259#issuecomment-360544364
https://github.com/broadinstitute/gatk/pull/4259#issuecomment-360544364:1562,Testability,test,test,1562,======================; Files 1039 1039 ; Lines 59173 59173 ; Branches 9686 9686 ; ==============================================; - Hits 46426 46195 -231 ; - Misses 8996 9237 +241 ; + Partials 3751 3741 -10; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4259?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4259/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-75.51%)` | `0% <0%> (-17%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4259/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/4259/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...lbender/engine/datasources/ReferenceAPISource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4259/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `25.735% <0%> (-44.853%)` | `8% <0%> (-19%)` | |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/4259/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `50% <0%> (-30%)` | `1% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4259/diff?src=pr&el=tree#dif,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4259#issuecomment-360544364
https://github.com/broadinstitute/gatk/pull/4259#issuecomment-360544364:3348,Testability,test,test,3348,bmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `25.735% <0%> (-44.853%)` | `8% <0%> (-19%)` | |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/4259/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `50% <0%> (-30%)` | `1% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4259/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `54.194% <0%> (-24.516%)` | `30% <0%> (-9%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/4259/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `0% <0%> (-22.807%)` | `0% <0%> (-2%)` | |; | [...ender/engine/datasources/ReferenceMultiSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4259/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlTXVsdGlTb3VyY2UuamF2YQ==) | `61.538% <0%> (-15.385%)` | `9% <0%> (-2%)` | |; | [...titute/hellbender/utils/test/MiniClusterUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4259/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L01pbmlDbHVzdGVyVXRpbHMuamF2YQ==) | `78.947% <0%> (-10.526%)` | `6% <0%> (-1%)` | |; | [...institute/hellbender/exceptions/UserException.java](https://codecov.io/gh/broadinstitute/gatk/pull/4259/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9leGNlcHRpb25zL1VzZXJFeGNlcHRpb24uamF2YQ==) | `67.176% <0%> (-3.053%)` | `3% <0%> (ø)` | |; | ... and [10 more](https://codecov.io/gh/broadinstitute/gatk/pull/4259/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4259#issuecomment-360544364
https://github.com/broadinstitute/gatk/pull/4259#issuecomment-379872013:59,Modifiability,variab,variables,59,At some point we deleted the lines in question because the variables are `false` by default.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4259#issuecomment-379872013
https://github.com/broadinstitute/gatk/issues/4260#issuecomment-360567998:33,Deployability,kill switch,kill switch,33,On it. Not intending to make the kill switch until test coverage is up.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4260#issuecomment-360567998
https://github.com/broadinstitute/gatk/issues/4260#issuecomment-360567998:51,Testability,test,test,51,On it. Not intending to make the kill switch until test coverage is up.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4260#issuecomment-360567998
https://github.com/broadinstitute/gatk/pull/4261#issuecomment-360582924:1249,Deployability,pipeline,pipelines,1249,752d2748eda14b079387?src=pr&el=desc) will **increase** coverage by `0.237%`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #4261 +/- ##; =============================================; + Coverage 78.463% 78.7% +0.237% ; - Complexity 16440 16480 +40 ; =============================================; Files 1039 1040 +1 ; Lines 59173 59338 +165 ; Branches 9686 9706 +20 ; =============================================; + Hits 46429 46699 +270 ; + Misses 8993 8888 -105 ; Partials 3751 3751; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4261?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4261/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-75.51%)` | `0% <0%> (-17%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4261/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/4261/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...lbender/engine/datasources/ReferenceAPISource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4261/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `25.735% <0%> (-44.853%)` | `8% <0%> (-19%)` | |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/4261/diff?src=pr&el=tree#diff-c3J,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4261#issuecomment-360582924
https://github.com/broadinstitute/gatk/pull/4261#issuecomment-360582924:1565,Testability,test,test,1565,=================; Files 1039 1040 +1 ; Lines 59173 59338 +165 ; Branches 9686 9706 +20 ; =============================================; + Hits 46429 46699 +270 ; + Misses 8993 8888 -105 ; Partials 3751 3751; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4261?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4261/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-75.51%)` | `0% <0%> (-17%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4261/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/4261/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...lbender/engine/datasources/ReferenceAPISource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4261/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `25.735% <0%> (-44.853%)` | `8% <0%> (-19%)` | |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/4261/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `50% <0%> (-30%)` | `1% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4261/diff?src=pr&el=tree#dif,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4261#issuecomment-360582924
https://github.com/broadinstitute/gatk/pull/4261#issuecomment-360582924:3351,Testability,test,test,3351,ZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `25.735% <0%> (-44.853%)` | `8% <0%> (-19%)` | |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/4261/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `50% <0%> (-30%)` | `1% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4261/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `54.194% <0%> (-24.516%)` | `30% <0%> (-9%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/4261/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `0% <0%> (-22.807%)` | `0% <0%> (-2%)` | |; | [...ender/engine/datasources/ReferenceMultiSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4261/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlTXVsdGlTb3VyY2UuamF2YQ==) | `61.538% <0%> (-15.385%)` | `9% <0%> (-2%)` | |; | [...titute/hellbender/utils/test/MiniClusterUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4261/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L01pbmlDbHVzdGVyVXRpbHMuamF2YQ==) | `78.947% <0%> (-10.526%)` | `6% <0%> (-1%)` | |; | [...bender/tools/copynumber/CallCopyRatioSegments.java](https://codecov.io/gh/broadinstitute/gatk/pull/4261/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL0NhbGxDb3B5UmF0aW9TZWdtZW50cy5qYXZh) | `90.909% <0%> (-9.091%)` | `2% <0%> (ø)` | |; | ... and [43 more](https://codecov.io/gh/broadinstitute/gatk/pull/4261/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4261#issuecomment-360582924
https://github.com/broadinstitute/gatk/pull/4261#issuecomment-360597705:20,Testability,test,test,20,There is a disabled test in `GenomicsDBImportIntegrationTest.testGenomicsDBAlleleSpecificAnnotations()` which compares the results to those of combineGVCFs over moderately sized files which you should should try out.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4261#issuecomment-360597705
https://github.com/broadinstitute/gatk/pull/4261#issuecomment-360597705:61,Testability,test,testGenomicsDBAlleleSpecificAnnotations,61,There is a disabled test in `GenomicsDBImportIntegrationTest.testGenomicsDBAlleleSpecificAnnotations()` which compares the results to those of combineGVCFs over moderately sized files which you should should try out.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4261#issuecomment-360597705
https://github.com/broadinstitute/gatk/pull/4261#issuecomment-360860432:180,Testability,test,tests,180,"@psfoley Did you just push another bug fix into this branch? Can you explain what the bug was, and create a github ticket with the bug description for our records?. We really need tests for each of the fixes in this branch, as well -- currently there are only tests for the allele-specific annotation support. I may attempt to add some tests later today if time permits.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4261#issuecomment-360860432
https://github.com/broadinstitute/gatk/pull/4261#issuecomment-360860432:260,Testability,test,tests,260,"@psfoley Did you just push another bug fix into this branch? Can you explain what the bug was, and create a github ticket with the bug description for our records?. We really need tests for each of the fixes in this branch, as well -- currently there are only tests for the allele-specific annotation support. I may attempt to add some tests later today if time permits.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4261#issuecomment-360860432
https://github.com/broadinstitute/gatk/pull/4261#issuecomment-360860432:336,Testability,test,tests,336,"@psfoley Did you just push another bug fix into this branch? Can you explain what the bug was, and create a github ticket with the bug description for our records?. We really need tests for each of the fixes in this branch, as well -- currently there are only tests for the allele-specific annotation support. I may attempt to add some tests later today if time permits.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4261#issuecomment-360860432
https://github.com/broadinstitute/gatk/pull/4261#issuecomment-360870965:71,Availability,error,error,71,@psfoley The branch is failing tests after your latest commit with the error:. ```; > Could not resolve all dependencies for configuration ':runtime'.; > Could not find com.intel:genomicsdb:0.9.2-proto-3.0.0-beta-1+uuid-static.; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4261#issuecomment-360870965
https://github.com/broadinstitute/gatk/pull/4261#issuecomment-360870965:125,Deployability,configurat,configuration,125,@psfoley The branch is failing tests after your latest commit with the error:. ```; > Could not resolve all dependencies for configuration ':runtime'.; > Could not find com.intel:genomicsdb:0.9.2-proto-3.0.0-beta-1+uuid-static.; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4261#issuecomment-360870965
https://github.com/broadinstitute/gatk/pull/4261#issuecomment-360870965:108,Integrability,depend,dependencies,108,@psfoley The branch is failing tests after your latest commit with the error:. ```; > Could not resolve all dependencies for configuration ':runtime'.; > Could not find com.intel:genomicsdb:0.9.2-proto-3.0.0-beta-1+uuid-static.; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4261#issuecomment-360870965
https://github.com/broadinstitute/gatk/pull/4261#issuecomment-360870965:125,Modifiability,config,configuration,125,@psfoley The branch is failing tests after your latest commit with the error:. ```; > Could not resolve all dependencies for configuration ':runtime'.; > Could not find com.intel:genomicsdb:0.9.2-proto-3.0.0-beta-1+uuid-static.; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4261#issuecomment-360870965
https://github.com/broadinstitute/gatk/pull/4261#issuecomment-360870965:31,Testability,test,tests,31,@psfoley The branch is failing tests after your latest commit with the error:. ```; > Could not resolve all dependencies for configuration ':runtime'.; > Could not find com.intel:genomicsdb:0.9.2-proto-3.0.0-beta-1+uuid-static.; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4261#issuecomment-360870965
https://github.com/broadinstitute/gatk/pull/4261#issuecomment-360881092:567,Availability,avail,available,567,"@jamesemery and @droazen thank you for reviewing. @jamesemery I have enabled `GenomicsDBImportIntegrationTest.testGenomicsDBAlleleSpecificAnnotations()` and this test is passing. Is anything else required?. @droazen I incremented the GenomicsDB release that incorporates a fix for resizing LUTs when dealing with spanning deletions - this was a single line change in GenomicsDB that should fall under the umbrella of enabling allele-specific annotation support [3707](https://github.com/broadinstitute/gatk/issues/3707). This updated jar has been uploaded, but isn't available on Maven yet (it should be within the next hour). I agree that additional tests should be added for the bugs that this PR addresses. I'll plan on adding tests for the two high priority fixes ([4160](https://github.com/broadinstitute/gatk/issues/4160) and [3736](https://github.com/broadinstitute/gatk/issues/3736)) this afternoon.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4261#issuecomment-360881092
https://github.com/broadinstitute/gatk/pull/4261#issuecomment-360881092:245,Deployability,release,release,245,"@jamesemery and @droazen thank you for reviewing. @jamesemery I have enabled `GenomicsDBImportIntegrationTest.testGenomicsDBAlleleSpecificAnnotations()` and this test is passing. Is anything else required?. @droazen I incremented the GenomicsDB release that incorporates a fix for resizing LUTs when dealing with spanning deletions - this was a single line change in GenomicsDB that should fall under the umbrella of enabling allele-specific annotation support [3707](https://github.com/broadinstitute/gatk/issues/3707). This updated jar has been uploaded, but isn't available on Maven yet (it should be within the next hour). I agree that additional tests should be added for the bugs that this PR addresses. I'll plan on adding tests for the two high priority fixes ([4160](https://github.com/broadinstitute/gatk/issues/4160) and [3736](https://github.com/broadinstitute/gatk/issues/3736)) this afternoon.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4261#issuecomment-360881092
https://github.com/broadinstitute/gatk/pull/4261#issuecomment-360881092:526,Deployability,update,updated,526,"@jamesemery and @droazen thank you for reviewing. @jamesemery I have enabled `GenomicsDBImportIntegrationTest.testGenomicsDBAlleleSpecificAnnotations()` and this test is passing. Is anything else required?. @droazen I incremented the GenomicsDB release that incorporates a fix for resizing LUTs when dealing with spanning deletions - this was a single line change in GenomicsDB that should fall under the umbrella of enabling allele-specific annotation support [3707](https://github.com/broadinstitute/gatk/issues/3707). This updated jar has been uploaded, but isn't available on Maven yet (it should be within the next hour). I agree that additional tests should be added for the bugs that this PR addresses. I'll plan on adding tests for the two high priority fixes ([4160](https://github.com/broadinstitute/gatk/issues/4160) and [3736](https://github.com/broadinstitute/gatk/issues/3736)) this afternoon.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4261#issuecomment-360881092
https://github.com/broadinstitute/gatk/pull/4261#issuecomment-360881092:110,Testability,test,testGenomicsDBAlleleSpecificAnnotations,110,"@jamesemery and @droazen thank you for reviewing. @jamesemery I have enabled `GenomicsDBImportIntegrationTest.testGenomicsDBAlleleSpecificAnnotations()` and this test is passing. Is anything else required?. @droazen I incremented the GenomicsDB release that incorporates a fix for resizing LUTs when dealing with spanning deletions - this was a single line change in GenomicsDB that should fall under the umbrella of enabling allele-specific annotation support [3707](https://github.com/broadinstitute/gatk/issues/3707). This updated jar has been uploaded, but isn't available on Maven yet (it should be within the next hour). I agree that additional tests should be added for the bugs that this PR addresses. I'll plan on adding tests for the two high priority fixes ([4160](https://github.com/broadinstitute/gatk/issues/4160) and [3736](https://github.com/broadinstitute/gatk/issues/3736)) this afternoon.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4261#issuecomment-360881092
https://github.com/broadinstitute/gatk/pull/4261#issuecomment-360881092:162,Testability,test,test,162,"@jamesemery and @droazen thank you for reviewing. @jamesemery I have enabled `GenomicsDBImportIntegrationTest.testGenomicsDBAlleleSpecificAnnotations()` and this test is passing. Is anything else required?. @droazen I incremented the GenomicsDB release that incorporates a fix for resizing LUTs when dealing with spanning deletions - this was a single line change in GenomicsDB that should fall under the umbrella of enabling allele-specific annotation support [3707](https://github.com/broadinstitute/gatk/issues/3707). This updated jar has been uploaded, but isn't available on Maven yet (it should be within the next hour). I agree that additional tests should be added for the bugs that this PR addresses. I'll plan on adding tests for the two high priority fixes ([4160](https://github.com/broadinstitute/gatk/issues/4160) and [3736](https://github.com/broadinstitute/gatk/issues/3736)) this afternoon.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4261#issuecomment-360881092
https://github.com/broadinstitute/gatk/pull/4261#issuecomment-360881092:651,Testability,test,tests,651,"@jamesemery and @droazen thank you for reviewing. @jamesemery I have enabled `GenomicsDBImportIntegrationTest.testGenomicsDBAlleleSpecificAnnotations()` and this test is passing. Is anything else required?. @droazen I incremented the GenomicsDB release that incorporates a fix for resizing LUTs when dealing with spanning deletions - this was a single line change in GenomicsDB that should fall under the umbrella of enabling allele-specific annotation support [3707](https://github.com/broadinstitute/gatk/issues/3707). This updated jar has been uploaded, but isn't available on Maven yet (it should be within the next hour). I agree that additional tests should be added for the bugs that this PR addresses. I'll plan on adding tests for the two high priority fixes ([4160](https://github.com/broadinstitute/gatk/issues/4160) and [3736](https://github.com/broadinstitute/gatk/issues/3736)) this afternoon.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4261#issuecomment-360881092
https://github.com/broadinstitute/gatk/pull/4261#issuecomment-360881092:730,Testability,test,tests,730,"@jamesemery and @droazen thank you for reviewing. @jamesemery I have enabled `GenomicsDBImportIntegrationTest.testGenomicsDBAlleleSpecificAnnotations()` and this test is passing. Is anything else required?. @droazen I incremented the GenomicsDB release that incorporates a fix for resizing LUTs when dealing with spanning deletions - this was a single line change in GenomicsDB that should fall under the umbrella of enabling allele-specific annotation support [3707](https://github.com/broadinstitute/gatk/issues/3707). This updated jar has been uploaded, but isn't available on Maven yet (it should be within the next hour). I agree that additional tests should be added for the bugs that this PR addresses. I'll plan on adding tests for the two high priority fixes ([4160](https://github.com/broadinstitute/gatk/issues/4160) and [3736](https://github.com/broadinstitute/gatk/issues/3736)) this afternoon.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4261#issuecomment-360881092
https://github.com/broadinstitute/gatk/pull/4263#issuecomment-360624176:1895,Usability,Simpl,SimpleCopyRatioCaller,1895,| |; |---|---|---|---|; | [...ynumber/formats/records/AlleleFractionSegment.java](https://codecov.io/gh/broadinstitute/gatk/pull/4263/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2Zvcm1hdHMvcmVjb3Jkcy9BbGxlbGVGcmFjdGlvblNlZ21lbnQuamF2YQ==) | `39.286% <ø> (ø)` | `6 <0> (ø)` | :arrow_down: |; | [...ls/copynumber/plotting/PlotDenoisedCopyRatios.java](https://codecov.io/gh/broadinstitute/gatk/pull/4263/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL3Bsb3R0aW5nL1Bsb3REZW5vaXNlZENvcHlSYXRpb3MuamF2YQ==) | `100% <ø> (ø)` | `6 <0> (ø)` | :arrow_down: |; | [...bender/tools/copynumber/CallCopyRatioSegments.java](https://codecov.io/gh/broadinstitute/gatk/pull/4263/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL0NhbGxDb3B5UmF0aW9TZWdtZW50cy5qYXZh) | `90.909% <50%> (-9.091%)` | `2 <1> (ø)` | |; | [...tools/copynumber/caller/SimpleCopyRatioCaller.java](https://codecov.io/gh/broadinstitute/gatk/pull/4263/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2NhbGxlci9TaW1wbGVDb3B5UmF0aW9DYWxsZXIuamF2YQ==) | `95.652% <90%> (-1.271%)` | `17 <3> (+2)` | |; | [...park/sv/discovery/alignment/AlignmentInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/4263/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvYWxpZ25tZW50L0FsaWdubWVudEludGVydmFsLmphdmE=) | `89.655% <0%> (+0.383%)` | `73% <0%> (ø)` | :arrow_down: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4263/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `80% <0%> (+1.29%)` | `39% <0%> (ø)` | :arrow_down: |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinsti,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4263#issuecomment-360624176
https://github.com/broadinstitute/gatk/pull/4266#issuecomment-362410847:2676,Testability,test,test,2676,UvaGVsbGJlbmRlci91dGlscy9yZWFkL1NBTVJlY29yZFRvR0FUS1JlYWRBZGFwdGVyLmphdmE=) | `92.43% <ø> (-0.03%)` | `135 <0> (-1)` | |; | [...broadinstitute/hellbender/utils/read/GATKRead.java](https://codecov.io/gh/broadinstitute/gatk/pull/4266/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWFkL0dBVEtSZWFkLmphdmE=) | `31.25% <ø> (-37.5%)` | `7 <0> (-6)` | |; | [...itute/hellbender/engine/spark/GATKRegistrator.java](https://codecov.io/gh/broadinstitute/gatk/pull/4266/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvR0FUS1JlZ2lzdHJhdG9yLmphdmE=) | `100% <ø> (ø)` | `2 <0> (ø)` | :arrow_down: |; | [...dinstitute/hellbender/utils/pileup/ReadPileup.java](https://codecov.io/gh/broadinstitute/gatk/pull/4266/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9waWxldXAvUmVhZFBpbGV1cC5qYXZh) | `91.946% <ø> (ø)` | `64 <0> (ø)` | :arrow_down: |; | [...utils/test/ReadsPreprocessingPipelineTestData.java](https://codecov.io/gh/broadinstitute/gatk/pull/4266/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1JlYWRzUHJlcHJvY2Vzc2luZ1BpcGVsaW5lVGVzdERhdGEuamF2YQ==) | `0.862% <0%> (+0.015%)` | `1 <1> (ø)` | :arrow_down: |; | [...ender/engine/datasources/ReferenceMultiSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4266/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlTXVsdGlTb3VyY2UuamF2YQ==) | `61.538% <0%> (-15.385%)` | `9 <0> (-2)` | |; | [...bender/engine/datasources/ReferenceFileSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4266/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlRmlsZVNvdXJjZS5qYXZh) | `88.462% <100%> (ø)` | `9 <0> (ø)` | :arrow_down: |; | [...titute/hellbender/engine/spark/JsonSerializer.java](https://codecov.io/gh/broadinstitut,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4266#issuecomment-362410847
https://github.com/broadinstitute/gatk/pull/4268#issuecomment-360648291:108,Testability,test,test,108,"Another one for you, @LeeTL1220, if you don't mind. It's not as long as it looks, most of the additions are test resources. Thanks in advance!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4268#issuecomment-360648291
https://github.com/broadinstitute/gatk/pull/4268#issuecomment-360810738:49,Deployability,release,release,49,@LeeTL1220 This should go in before in the point release.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4268#issuecomment-360810738
https://github.com/broadinstitute/gatk/pull/4270#issuecomment-360815340:34,Deployability,patch,patch,34,Have you confirmed that with this patch the original issue with picard interval lists + expansion is resolved? Can you add a test for that (using an actual Picard interval list) as well?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4270#issuecomment-360815340
https://github.com/broadinstitute/gatk/pull/4270#issuecomment-360815340:125,Testability,test,test,125,Have you confirmed that with this patch the original issue with picard interval lists + expansion is resolved? Can you add a test for that (using an actual Picard interval list) as well?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4270#issuecomment-360815340
https://github.com/broadinstitute/gatk/pull/4270#issuecomment-360892199:35,Testability,test,test,35,"The requested Picard interval list test already exists in GATKToolUnitTest (testPicardIntervalList). I put these new tests adjacent to that one, since they're kind of all inter-related. But you're right that really these should live in CommandLineProgramUnitTest, so I moved them.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4270#issuecomment-360892199
https://github.com/broadinstitute/gatk/pull/4270#issuecomment-360892199:76,Testability,test,testPicardIntervalList,76,"The requested Picard interval list test already exists in GATKToolUnitTest (testPicardIntervalList). I put these new tests adjacent to that one, since they're kind of all inter-related. But you're right that really these should live in CommandLineProgramUnitTest, so I moved them.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4270#issuecomment-360892199
https://github.com/broadinstitute/gatk/pull/4270#issuecomment-360892199:117,Testability,test,tests,117,"The requested Picard interval list test already exists in GATKToolUnitTest (testPicardIntervalList). I put these new tests adjacent to that one, since they're kind of all inter-related. But you're right that really these should live in CommandLineProgramUnitTest, so I moved them.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4270#issuecomment-360892199
https://github.com/broadinstitute/gatk/pull/4270#issuecomment-360927411:2251,Testability,test,test,2251,| [...rgumentcollections/IntervalArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/4270/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL2FyZ3VtZW50Y29sbGVjdGlvbnMvSW50ZXJ2YWxBcmd1bWVudENvbGxlY3Rpb24uamF2YQ==) | `95.833% <100%> (ø)` | `19 <0> (ø)` | :arrow_down: |; | [...ollections/RequiredIntervalArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/4270/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL2FyZ3VtZW50Y29sbGVjdGlvbnMvUmVxdWlyZWRJbnRlcnZhbEFyZ3VtZW50Q29sbGVjdGlvbi5qYXZh) | `83.333% <100%> (ø)` | `3 <0> (ø)` | :arrow_down: |; | [...ute/hellbender/tools/copynumber/ModelSegments.java](https://codecov.io/gh/broadinstitute/gatk/pull/4270/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL01vZGVsU2VnbWVudHMuamF2YQ==) | `66.421% <0%> (-33.027%)` | `14% <0%> (-27%)` | |; | [...hellbender/utils/test/VariantContextTestUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4270/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1ZhcmlhbnRDb250ZXh0VGVzdFV0aWxzLmphdmE=) | `79.73% <0%> (-2.703%)` | `57% <0%> (-3%)` | |; | [...ools/copynumber/DetermineGermlineContigPloidy.java](https://codecov.io/gh/broadinstitute/gatk/pull/4270/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL0RldGVybWluZUdlcm1saW5lQ29udGlnUGxvaWR5LmphdmE=) | `95.727% <0%> (-0.744%)` | `17% <0%> (+3%)` | |; | [...ools/copynumber/CreateReadCountPanelOfNormals.java](https://codecov.io/gh/broadinstitute/gatk/pull/4270/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL0NyZWF0ZVJlYWRDb3VudFBhbmVsT2ZOb3JtYWxzLmphdmE=) | `89.873% <0%> (-0.127%)` | `16% <0%> (+7%)` | |; | [...bender/engine/filters/AmbiguousBaseReadFilter.java](https://codecov.io/gh/broadinstitute/gat,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4270#issuecomment-360927411
https://github.com/broadinstitute/gatk/pull/4271#issuecomment-360860397:343,Testability,test,tests,343,@davidbenjamin What is the issue with subworkflows? We import some subworkflows in the CNV WDLs. I think sub-subworkflows are when things get hairy... @jonn-smith @LeeTL1220 Let me know at what point we should switch over to Funcotator (or make it an option) in the CNV WDLs as well. I'd also feel more comfortable if the Funcotator/Oncotator tests actually ran on Travis.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4271#issuecomment-360860397
https://github.com/broadinstitute/gatk/pull/4271#issuecomment-360865879:51,Testability,test,tests,51,"@davidbenjamin Oncotator runs in the M2 WDL travis tests (last I checked). It just uses no datasources. Oncotator is disabled for the CNV WDL travis tests. I did this because the CNV Oncotator uses a different docker image, which is fairly large. @davidbenjamin @samuelklee Life is only a little bit easier if the WDL is self-contained. The sub-...-workflows gets a little hairy for setting optional parameters (particularly runtime parameters).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4271#issuecomment-360865879
https://github.com/broadinstitute/gatk/pull/4271#issuecomment-360865879:149,Testability,test,tests,149,"@davidbenjamin Oncotator runs in the M2 WDL travis tests (last I checked). It just uses no datasources. Oncotator is disabled for the CNV WDL travis tests. I did this because the CNV Oncotator uses a different docker image, which is fairly large. @davidbenjamin @samuelklee Life is only a little bit easier if the WDL is self-contained. The sub-...-workflows gets a little hairy for setting optional parameters (particularly runtime parameters).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4271#issuecomment-360865879
https://github.com/broadinstitute/gatk/issues/4272#issuecomment-385084409:220,Availability,down,downsampled,220,"I ran GATK4 HC on /seq/picard_aggregation/C1827/MITO64/current/MITO64.bam, which has >=10,000X coverage over the mitochondrial genes. With Xmx4g Xms4g I had no problems. One called variant had DP=3719, which must be the downsampled coverage? IGV reports about 7200 coverage:; ![image](https://user-images.githubusercontent.com/6578548/39382302-0a284436-4a33-11e8-9628-47dc01dab44e.png); That same bam also ran fine with 2g and even 1g. I tried ploidy 20 ERC GVCF at 1G and that was slow, but also successful. Ploidy 100 revealed that there are some sites with two alts because then one gets dropped. That was also super slow, but successful at 1G. I wouldn't recommend 1G for general purpose, though. There are some Jira tickets complaining about running out of memory with GATK4 on Firehose with 1G (https://broadinstitute.atlassian.net/browse/PO-12076?jql=project%20in%20(PO%2C%20DSDEGP)%20AND%20text%20~%20memory). Mark's contaminated bam above is running now.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4272#issuecomment-385084409
https://github.com/broadinstitute/gatk/issues/4272#issuecomment-385489993:175,Performance,perform,performance,175,"@ldgauthier It does, but you should always run via the launch script and `--java-options`, since the script sets a number of important system properties, some of which affect performance. Do you know whether the GATK3 HC is able to run on the same bams without running out of memory in 4G/2G/1G?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4272#issuecomment-385489993
https://github.com/broadinstitute/gatk/issues/4272#issuecomment-385672647:563,Energy Efficiency,green,green,563,"I don't know. Do you want me to run them in GATK3?. It's hard to find bams run with GATK3 HC that needed more than 4GB memory because Zamboni has a memory retry loop, so one would have to parse the java options out of the logs like looking for a needle in a haystack. FWIW the Zamboni initial memory allocation is 3GB (https://github.com/broadinstitute/zamboni/blob/develop/Workflows/src/scala/org/broadinstitute/picard/steprunners/variantcalling/HaplotypeCaller.scala) seems to be applicable to exomes and genomes(?) I asked about finding problematic samples in green team slack.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4272#issuecomment-385672647
https://github.com/broadinstitute/gatk/issues/4272#issuecomment-385672647:222,Testability,log,logs,222,"I don't know. Do you want me to run them in GATK3?. It's hard to find bams run with GATK3 HC that needed more than 4GB memory because Zamboni has a memory retry loop, so one would have to parse the java options out of the logs like looking for a needle in a haystack. FWIW the Zamboni initial memory allocation is 3GB (https://github.com/broadinstitute/zamboni/blob/develop/Workflows/src/scala/org/broadinstitute/picard/steprunners/variantcalling/HaplotypeCaller.scala) seems to be applicable to exomes and genomes(?) I asked about finding problematic samples in green team slack.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4272#issuecomment-385672647
https://github.com/broadinstitute/gatk/issues/4273#issuecomment-374711024:16,Deployability,update,updates,16,@lbergelson Any updates on this? Still an issue in 4.0.1.2 and I need do some runs on DataProc.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4273#issuecomment-374711024
https://github.com/broadinstitute/gatk/pull/4276#issuecomment-361355746:2779,Security,Validat,ValidateBasicSomaticShortMutations,2779,0> (ø)` | :arrow_down: |; | [...tools/funcotator/dataSources/TableFuncotation.java](https://codecov.io/gh/broadinstitute/gatk/pull/4276/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL1RhYmxlRnVuY290YXRpb24uamF2YQ==) | `60% <100%> (ø)` | `20 <0> (ø)` | :arrow_down: |; | [.../tools/copynumber/utils/MergeAnnotatedRegions.java](https://codecov.io/gh/broadinstitute/gatk/pull/4276/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL3V0aWxzL01lcmdlQW5ub3RhdGVkUmVnaW9ucy5qYXZh) | `100% <100%> (ø)` | `3 <3> (?)` | |; | [...ils/annotatedinterval/AnnotatedIntervalHeader.java](https://codecov.io/gh/broadinstitute/gatk/pull/4276/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL3V0aWxzL2Fubm90YXRlZGludGVydmFsL0Fubm90YXRlZEludGVydmFsSGVhZGVyLmphdmE=) | `100% <100%> (ø)` | `6 <6> (?)` | |; | [...tmutpileup/ValidateBasicSomaticShortMutations.java](https://codecov.io/gh/broadinstitute/gatk/pull/4276/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vYmFzaWNzaG9ydG11dHBpbGV1cC9WYWxpZGF0ZUJhc2ljU29tYXRpY1Nob3J0TXV0YXRpb25zLmphdmE=) | `85.965% <100%> (ø)` | `7 <0> (ø)` | :arrow_down: |; | [...nder/tools/copynumber/utils/TagGermlineEvents.java](https://codecov.io/gh/broadinstitute/gatk/pull/4276/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL3V0aWxzL1RhZ0dlcm1saW5lRXZlbnRzLmphdmE=) | `100% <100%> (ø)` | `3 <3> (?)` | |; | [...ataSources/xsv/LocatableXsvFuncotationFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/4276/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL3hzdi9Mb2NhdGFibGVYc3ZGdW5jb3RhdGlvbkZhY3RvcnkuamF2YQ==) | `85.185% <61.538%> (+0.491%)` | `24 <0> (-4)` | :arrow_down: |; | [...g/broadi,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4276#issuecomment-361355746
https://github.com/broadinstitute/gatk/pull/4276#issuecomment-369709447:311,Integrability,interface,interface,311,"@samuelklee: @LeeTL1220 and I just had a discussion about the writer aspect of this branch, and we agreed on the following:. 1. Lee will introduce a new header type to encapsulate the information that's currently passed in individually to the `writeHeader()` method in `AnnotatedIntervalWriter`. This makes the interface cleaner and more future-proof, since the signature will just become `writeHeader(AnnotatedIntervalHeader)`. 2. Lee will start writing out 3 additional structured header lines (as comment lines) to every header, declaring the names of the chrom, start, and stop columns. These will not be respected on input yet (he will still be relying on a config file to get the names of these 3 columns), but it's the first step in the direction of storing all necessary schema information in the header of each file, rather than separately from each file. 3. Lee will file a github issue to eventually use these 3 header lines on input, when they are present, to get the names of the chrom/start/stop columns (possibly still with a fallback to a separate config file if they aren't, but that is a point we can debate in a future PR).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4276#issuecomment-369709447
https://github.com/broadinstitute/gatk/pull/4276#issuecomment-369709447:663,Modifiability,config,config,663,"@samuelklee: @LeeTL1220 and I just had a discussion about the writer aspect of this branch, and we agreed on the following:. 1. Lee will introduce a new header type to encapsulate the information that's currently passed in individually to the `writeHeader()` method in `AnnotatedIntervalWriter`. This makes the interface cleaner and more future-proof, since the signature will just become `writeHeader(AnnotatedIntervalHeader)`. 2. Lee will start writing out 3 additional structured header lines (as comment lines) to every header, declaring the names of the chrom, start, and stop columns. These will not be respected on input yet (he will still be relying on a config file to get the names of these 3 columns), but it's the first step in the direction of storing all necessary schema information in the header of each file, rather than separately from each file. 3. Lee will file a github issue to eventually use these 3 header lines on input, when they are present, to get the names of the chrom/start/stop columns (possibly still with a fallback to a separate config file if they aren't, but that is a point we can debate in a future PR).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4276#issuecomment-369709447
https://github.com/broadinstitute/gatk/pull/4276#issuecomment-369709447:1064,Modifiability,config,config,1064,"@samuelklee: @LeeTL1220 and I just had a discussion about the writer aspect of this branch, and we agreed on the following:. 1. Lee will introduce a new header type to encapsulate the information that's currently passed in individually to the `writeHeader()` method in `AnnotatedIntervalWriter`. This makes the interface cleaner and more future-proof, since the signature will just become `writeHeader(AnnotatedIntervalHeader)`. 2. Lee will start writing out 3 additional structured header lines (as comment lines) to every header, declaring the names of the chrom, start, and stop columns. These will not be respected on input yet (he will still be relying on a config file to get the names of these 3 columns), but it's the first step in the direction of storing all necessary schema information in the header of each file, rather than separately from each file. 3. Lee will file a github issue to eventually use these 3 header lines on input, when they are present, to get the names of the chrom/start/stop columns (possibly still with a fallback to a separate config file if they aren't, but that is a point we can debate in a future PR).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4276#issuecomment-369709447
https://github.com/broadinstitute/gatk/pull/4276#issuecomment-369734330:343,Modifiability,config,config,343,"Sorry @droazen @LeeTL1220, can you give me a bit more context? @LeeTL1220 is no longer using any of the CNV-specific collections classes that I had hoped might be Tribble-ized in the future, so I'm OK with any decisions you guys make that are specific to his classes (does @jonn-smith have an opinion?) I think that moving towards storing the config in the header is a good thing, in general. If we need to make corresponding changes to the CNV-specific collections classes, then we should talk more. Not all of those collections describe locatables, so I'm not sure how we could fit them in the Tribble framework.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4276#issuecomment-369734330
https://github.com/broadinstitute/gatk/pull/4276#issuecomment-369735007:681,Modifiability,config,config,681,"@samuelklee I'm not making any changes to the CNV collection classes. I; think none of this PR affects those classes. On Thu, Mar 1, 2018 at 4:19 PM, samuelklee <notifications@github.com> wrote:. > Sorry @droazen <https://github.com/droazen> @LeeTL1220; > <https://github.com/leetl1220>, can you give me a bit more context?; > @LeeTL1220 <https://github.com/leetl1220> is no longer using any of the; > CNV-specific collections classes that I had hoped might be Tribble-ized in; > the future, so I'm OK with any decisions you guys make that is specific to; > his classes (does @jonn-smith <https://github.com/jonn-smith> have an; > opinion?) I think that moving towards storing the config in the header is a; > good thing, in general.; >; > If we need to make corresponding changes to the CNV-specific collections; > classes, then we should talk more. Not all of those collections describe; > locatables, so I'm not sure how we could fit them in the Tribble framework.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/4276#issuecomment-369734330>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACDXkzoWV1fcDEucTdcNZ_DggL0UW4M9ks5taGXhgaJpZM4Ru2it>; > .; >. -- ; Lee Lichtenstein; Broad Institute; 75 Ames Street, Room 8011A; Cambridge, MA 02142; 617 714 8632",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4276#issuecomment-369735007
https://github.com/broadinstitute/gatk/pull/4276#issuecomment-377939130:175,Testability,test,test,175,"@LeeTL1220 Apologies, I don't think I have the bandwidth for a detailed re-review, but I'm OK with the XSV code if @jonn-smith approves. However, I still don't understand the test files and left some comments there.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4276#issuecomment-377939130
https://github.com/broadinstitute/gatk/pull/4278#issuecomment-361426641:1231,Availability,Down,DownsampleableSparkReadShard,1231,f96d4e13738aebc93c619c6b5e042a33bf4771?src=pr&el=desc) will **decrease** coverage by `0.008%`.; > The diff coverage is `64%`. ```diff; @@ Coverage Diff @@; ## master #4278 +/- ##; ===============================================; - Coverage 79.094% 79.086% -0.008% ; - Complexity 16549 16774 +225 ; ===============================================; Files 1040 1048 +8 ; Lines 59338 60132 +794 ; Branches 9706 9817 +111 ; ===============================================; + Hits 46933 47556 +623 ; - Misses 8643 8787 +144 ; - Partials 3762 3789 +27; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4278?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...oadinstitute/hellbender/engine/AssemblyRegion.java](https://codecov.io/gh/broadinstitute/gatk/pull/4278/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvQXNzZW1ibHlSZWdpb24uamF2YQ==) | `84.496% <ø> (-0.979%)` | `48 <0> (-14)` | |; | [...hellbender/tools/DownsampleableSparkReadShard.java](https://codecov.io/gh/broadinstitute/gatk/pull/4278/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9Eb3duc2FtcGxlYWJsZVNwYXJrUmVhZFNoYXJkLmphdmE=) | `81.818% <ø> (-9.091%)` | `3 <0> (-1)` | |; | [...nstitute/hellbender/engine/spark/SparkSharder.java](https://codecov.io/gh/broadinstitute/gatk/pull/4278/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtTaGFyZGVyLmphdmE=) | `90.972% <ø> (ø)` | `32 <0> (ø)` | :arrow_down: |; | [...bender/engine/spark/AssemblyRegionWalkerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4278/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvQXNzZW1ibHlSZWdpb25XYWxrZXJTcGFyay5qYXZh) | `0% <0%> (ø)` | `0 <0> (ø)` | :arrow_down: |; | [...ols/examples/ExampleAssemblyRegionWalkerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4278/diff?src=pr&el=tree#diff-c3JjL21h,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4278#issuecomment-361426641
https://github.com/broadinstitute/gatk/pull/4280#issuecomment-361012151:1875,Testability,test,test,1875,r&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/5627908ce0f8a0a438bdab5902dac26551575e26?src=pr&el=desc) will **increase** coverage by `0.01%`.; > The diff coverage is `100%`. ```diff; @@ Coverage Diff @@; ## master #4280 +/- ##; ==============================================; + Coverage 79.078% 79.088% +0.01% ; - Complexity 16608 16611 +3 ; ==============================================; Files 1048 1048 ; Lines 59579 59579 ; Branches 9730 9730 ; ==============================================; + Hits 47114 47120 +6 ; + Misses 8685 8681 -4 ; + Partials 3780 3778 -2; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4280?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [.../tools/copynumber/PostprocessGermlineCNVCalls.java](https://codecov.io/gh/broadinstitute/gatk/pull/4280/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL1Bvc3Rwcm9jZXNzR2VybWxpbmVDTlZDYWxscy5qYXZh) | `81.159% <100%> (ø)` | `10 <2> (?)` | |; | [...pynumber/gcnv/GermlineCNVPostprocessingEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/4280/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2djbnYvR2VybWxpbmVDTlZQb3N0cHJvY2Vzc2luZ0VuZ2luZS5qYXZh) | `97.143% <100%> (ø)` | `15 <0> (?)` | |; | [...park/sv/discovery/alignment/AlignmentInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/4280/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvYWxpZ25tZW50L0FsaWdubWVudEludGVydmFsLmphdmE=) | `89.272% <0%> (ø)` | `73% <0%> (ø)` | :arrow_down: |; | [...hellbender/utils/test/VariantContextTestUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4280/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1ZhcmlhbnRDb250ZXh0VGVzdFV0aWxzLmphdmE=) | `82.432% <0%> (+2.703%)` | `60% <0%> (+3%)` | :arrow_up: |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4280#issuecomment-361012151
https://github.com/broadinstitute/gatk/issues/4281#issuecomment-361069134:86,Security,validat,validate,86,"Yup, sorry about this---caught and fixed in #4280. I'd maybe count this as a `womtool validate` bug...?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4281#issuecomment-361069134
https://github.com/broadinstitute/gatk/pull/4282#issuecomment-361140567:3089,Testability,test,test,3089,2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9Db3ZlcmFnZS5qYXZh) | `87.5% <0%> (-12.5%)` | `5% <0%> (-1%)` | |; | [.../main/java/org/broadinstitute/hellbender/Main.java](https://codecov.io/gh/broadinstitute/gatk/pull/4282/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9NYWluLmphdmE=) | `60.733% <0%> (-9.733%)` | `35% <0%> (-8%)` | |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/4282/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `71.233% <0%> (-2.74%)` | `11% <0%> (ø)` | |; | [...er/engine/spark/datasources/VariantsSparkSink.java](https://codecov.io/gh/broadinstitute/gatk/pull/4282/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvVmFyaWFudHNTcGFya1NpbmsuamF2YQ==) | `83.333% <0%> (-2.713%)` | `13% <0%> (-4%)` | |; | [...hellbender/utils/test/VariantContextTestUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4282/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1ZhcmlhbnRDb250ZXh0VGVzdFV0aWxzLmphdmE=) | `79.73% <0%> (-2.703%)` | `57% <0%> (-3%)` | |; | [...bender/tools/walkers/annotator/StrandBiasTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/4282/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9TdHJhbmRCaWFzVGVzdC5qYXZh) | `85% <0%> (-2.5%)` | `32% <0%> (-1%)` | |; | [...e/hellbender/tools/walkers/vqsr/VQSLODTranche.java](https://codecov.io/gh/broadinstitute/gatk/pull/4282/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3Zxc3IvVlFTTE9EVHJhbmNoZS5qYXZh) | `82.178% <0%> (-1.98%)` | `17% <0%> (-1%)` | |; | ... and [51 more](https://codecov.io/gh/broadinstitute/gatk/pull/4282/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4282#issuecomment-361140567
https://github.com/broadinstitute/gatk/pull/4282#issuecomment-361753769:358,Availability,down,downstream,358,"Sorry for the confusion, here's what's happening: . In the stable version, we don't do this de-overlapping at all, so this won't change our `inv_del_ins.vcf`. For the experimental code path, without this PR, we are doing this de-overlapping step before inferencing the exact location of the breakpoints, hence two alignments never overlap when they are sent downstream for pinning down the locations; because homology by definition will cause the same part of a read map to two different locations, hence two alignments must overlap on the read if homology is present, thus the de-overlapping step causing the bug in #3894.; This PR removes that problematic de-overlapping step (done first the 1-liner commit, i.e. the 2nd commit, which doesn't use the de-overlapped alignments, then once the generated variants are reviewed to be OK, I removed the de-overlapping step in the 3rd commit).; The in the 4th commit, I experimented with removing, again only in the experimental code path, the alignment filter based on its alignment length. I personally think that is a better treatment, but don't have a strong opinion on it. So for the experimental code path, if we accept the first 3 commits, no de-overlapping is done on the alignments, just like the stable code path. The stable and the experimental version would only differ on which contigs are sent for this analysis, i.e. they differ in the preprocessing step. To be more specific, ; * the stable version calls into `ChimericAlignment.parseOneContig()` for turning all assembly contigs, no matter how many alignments it has, gets a list of chimeric pairs, and sends them down for breakpoint inference; * in the experimental tool, `ChimericAlignment.extractSimpleChimera()` takes **only** contigs with exactly **two** good alignments and turn it into a **single** pair, then send the pair down for inference. Regarding `ChimericAlignment.parseOneContig()`, it is good for extracting novel adjacencies and outputting BND records for contigs with mu",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4282#issuecomment-361753769
https://github.com/broadinstitute/gatk/pull/4282#issuecomment-361753769:381,Availability,down,down,381,"Sorry for the confusion, here's what's happening: . In the stable version, we don't do this de-overlapping at all, so this won't change our `inv_del_ins.vcf`. For the experimental code path, without this PR, we are doing this de-overlapping step before inferencing the exact location of the breakpoints, hence two alignments never overlap when they are sent downstream for pinning down the locations; because homology by definition will cause the same part of a read map to two different locations, hence two alignments must overlap on the read if homology is present, thus the de-overlapping step causing the bug in #3894.; This PR removes that problematic de-overlapping step (done first the 1-liner commit, i.e. the 2nd commit, which doesn't use the de-overlapped alignments, then once the generated variants are reviewed to be OK, I removed the de-overlapping step in the 3rd commit).; The in the 4th commit, I experimented with removing, again only in the experimental code path, the alignment filter based on its alignment length. I personally think that is a better treatment, but don't have a strong opinion on it. So for the experimental code path, if we accept the first 3 commits, no de-overlapping is done on the alignments, just like the stable code path. The stable and the experimental version would only differ on which contigs are sent for this analysis, i.e. they differ in the preprocessing step. To be more specific, ; * the stable version calls into `ChimericAlignment.parseOneContig()` for turning all assembly contigs, no matter how many alignments it has, gets a list of chimeric pairs, and sends them down for breakpoint inference; * in the experimental tool, `ChimericAlignment.extractSimpleChimera()` takes **only** contigs with exactly **two** good alignments and turn it into a **single** pair, then send the pair down for inference. Regarding `ChimericAlignment.parseOneContig()`, it is good for extracting novel adjacencies and outputting BND records for contigs with mu",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4282#issuecomment-361753769
https://github.com/broadinstitute/gatk/pull/4282#issuecomment-361753769:1626,Availability,down,down,1626," causing the bug in #3894.; This PR removes that problematic de-overlapping step (done first the 1-liner commit, i.e. the 2nd commit, which doesn't use the de-overlapped alignments, then once the generated variants are reviewed to be OK, I removed the de-overlapping step in the 3rd commit).; The in the 4th commit, I experimented with removing, again only in the experimental code path, the alignment filter based on its alignment length. I personally think that is a better treatment, but don't have a strong opinion on it. So for the experimental code path, if we accept the first 3 commits, no de-overlapping is done on the alignments, just like the stable code path. The stable and the experimental version would only differ on which contigs are sent for this analysis, i.e. they differ in the preprocessing step. To be more specific, ; * the stable version calls into `ChimericAlignment.parseOneContig()` for turning all assembly contigs, no matter how many alignments it has, gets a list of chimeric pairs, and sends them down for breakpoint inference; * in the experimental tool, `ChimericAlignment.extractSimpleChimera()` takes **only** contigs with exactly **two** good alignments and turn it into a **single** pair, then send the pair down for inference. Regarding `ChimericAlignment.parseOneContig()`, it is good for extracting novel adjacencies and outputting BND records for contigs with multiple (more than two) alignments, but it doesn't report the bigger picture (the new class `CpxVariantDetector` is trying to do that job, and it seems to be doing a good job based on manual review, I am not sure if there are tools available for evaluating such complex rearrangements).; So down the road, `ChimericAlignment.parseOneContig()` will probably be turned into other use; * turning the CPX variants we emit into BND's if so requested, and/or ; * dumpster diving on those contigs that we believe havn't assembled across the whole event&mdash;hence cannot tell the full story in a CPX var",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4282#issuecomment-361753769
https://github.com/broadinstitute/gatk/pull/4282#issuecomment-361753769:1843,Availability,down,down,1843,"done first the 1-liner commit, i.e. the 2nd commit, which doesn't use the de-overlapped alignments, then once the generated variants are reviewed to be OK, I removed the de-overlapping step in the 3rd commit).; The in the 4th commit, I experimented with removing, again only in the experimental code path, the alignment filter based on its alignment length. I personally think that is a better treatment, but don't have a strong opinion on it. So for the experimental code path, if we accept the first 3 commits, no de-overlapping is done on the alignments, just like the stable code path. The stable and the experimental version would only differ on which contigs are sent for this analysis, i.e. they differ in the preprocessing step. To be more specific, ; * the stable version calls into `ChimericAlignment.parseOneContig()` for turning all assembly contigs, no matter how many alignments it has, gets a list of chimeric pairs, and sends them down for breakpoint inference; * in the experimental tool, `ChimericAlignment.extractSimpleChimera()` takes **only** contigs with exactly **two** good alignments and turn it into a **single** pair, then send the pair down for inference. Regarding `ChimericAlignment.parseOneContig()`, it is good for extracting novel adjacencies and outputting BND records for contigs with multiple (more than two) alignments, but it doesn't report the bigger picture (the new class `CpxVariantDetector` is trying to do that job, and it seems to be doing a good job based on manual review, I am not sure if there are tools available for evaluating such complex rearrangements).; So down the road, `ChimericAlignment.parseOneContig()` will probably be turned into other use; * turning the CPX variants we emit into BND's if so requested, and/or ; * dumpster diving on those contigs that we believe havn't assembled across the whole event&mdash;hence cannot tell the full story in a CPX variant&mdash;but nonetheless we have breakpoints. ______. Do these sound reasonable?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4282#issuecomment-361753769
https://github.com/broadinstitute/gatk/pull/4282#issuecomment-361753769:2232,Availability,avail,available,2232,"done first the 1-liner commit, i.e. the 2nd commit, which doesn't use the de-overlapped alignments, then once the generated variants are reviewed to be OK, I removed the de-overlapping step in the 3rd commit).; The in the 4th commit, I experimented with removing, again only in the experimental code path, the alignment filter based on its alignment length. I personally think that is a better treatment, but don't have a strong opinion on it. So for the experimental code path, if we accept the first 3 commits, no de-overlapping is done on the alignments, just like the stable code path. The stable and the experimental version would only differ on which contigs are sent for this analysis, i.e. they differ in the preprocessing step. To be more specific, ; * the stable version calls into `ChimericAlignment.parseOneContig()` for turning all assembly contigs, no matter how many alignments it has, gets a list of chimeric pairs, and sends them down for breakpoint inference; * in the experimental tool, `ChimericAlignment.extractSimpleChimera()` takes **only** contigs with exactly **two** good alignments and turn it into a **single** pair, then send the pair down for inference. Regarding `ChimericAlignment.parseOneContig()`, it is good for extracting novel adjacencies and outputting BND records for contigs with multiple (more than two) alignments, but it doesn't report the bigger picture (the new class `CpxVariantDetector` is trying to do that job, and it seems to be doing a good job based on manual review, I am not sure if there are tools available for evaluating such complex rearrangements).; So down the road, `ChimericAlignment.parseOneContig()` will probably be turned into other use; * turning the CPX variants we emit into BND's if so requested, and/or ; * dumpster diving on those contigs that we believe havn't assembled across the whole event&mdash;hence cannot tell the full story in a CPX variant&mdash;but nonetheless we have breakpoints. ______. Do these sound reasonable?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4282#issuecomment-361753769
https://github.com/broadinstitute/gatk/pull/4282#issuecomment-361753769:2291,Availability,down,down,2291,"done first the 1-liner commit, i.e. the 2nd commit, which doesn't use the de-overlapped alignments, then once the generated variants are reviewed to be OK, I removed the de-overlapping step in the 3rd commit).; The in the 4th commit, I experimented with removing, again only in the experimental code path, the alignment filter based on its alignment length. I personally think that is a better treatment, but don't have a strong opinion on it. So for the experimental code path, if we accept the first 3 commits, no de-overlapping is done on the alignments, just like the stable code path. The stable and the experimental version would only differ on which contigs are sent for this analysis, i.e. they differ in the preprocessing step. To be more specific, ; * the stable version calls into `ChimericAlignment.parseOneContig()` for turning all assembly contigs, no matter how many alignments it has, gets a list of chimeric pairs, and sends them down for breakpoint inference; * in the experimental tool, `ChimericAlignment.extractSimpleChimera()` takes **only** contigs with exactly **two** good alignments and turn it into a **single** pair, then send the pair down for inference. Regarding `ChimericAlignment.parseOneContig()`, it is good for extracting novel adjacencies and outputting BND records for contigs with multiple (more than two) alignments, but it doesn't report the bigger picture (the new class `CpxVariantDetector` is trying to do that job, and it seems to be doing a good job based on manual review, I am not sure if there are tools available for evaluating such complex rearrangements).; So down the road, `ChimericAlignment.parseOneContig()` will probably be turned into other use; * turning the CPX variants we emit into BND's if so requested, and/or ; * dumpster diving on those contigs that we believe havn't assembled across the whole event&mdash;hence cannot tell the full story in a CPX variant&mdash;but nonetheless we have breakpoints. ______. Do these sound reasonable?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4282#issuecomment-361753769
https://github.com/broadinstitute/gatk/pull/4283#issuecomment-361224262:3607,Availability,Down,DownsampleableSparkReadShard,3607,GUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...lbender/engine/datasources/ReferenceAPISource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4283/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `25.735% <0%> (-44.853%)` | `8% <0%> (-19%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4283/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `54.194% <0%> (-25.806%)` | `30% <0%> (-9%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/4283/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `0% <0%> (-22.807%)` | `0% <0%> (-2%)` | |; | [...ender/engine/datasources/ReferenceMultiSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4283/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlTXVsdGlTb3VyY2UuamF2YQ==) | `61.538% <0%> (-15.385%)` | `9% <0%> (-2%)` | |; | [...titute/hellbender/utils/test/MiniClusterUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4283/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L01pbmlDbHVzdGVyVXRpbHMuamF2YQ==) | `78.947% <0%> (-10.526%)` | `6% <0%> (-1%)` | |; | [...hellbender/tools/DownsampleableSparkReadShard.java](https://codecov.io/gh/broadinstitute/gatk/pull/4283/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9Eb3duc2FtcGxlYWJsZVNwYXJrUmVhZFNoYXJkLmphdmE=) | `81.818% <0%> (-9.091%)` | `3% <0%> (-1%)` | |; | ... and [44 more](https://codecov.io/gh/broadinstitute/gatk/pull/4283/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4283#issuecomment-361224262
https://github.com/broadinstitute/gatk/pull/4283#issuecomment-361224262:1528,Deployability,pipeline,pipelines,1528,===============================================; Files 1048 1048 ; Lines 59579 59506 -73 ; Branches 9730 9718 -12 ; ===============================================; - Hits 47114 46833 -281 ; - Misses 8685 8908 +223 ; + Partials 3780 3765 -15; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4283?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [.../main/java/org/broadinstitute/hellbender/Main.java](https://codecov.io/gh/broadinstitute/gatk/pull/4283/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9NYWluLmphdmE=) | `70.466% <25%> (+9.733%)` | `43 <1> (+8)` | :arrow_up: |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4283/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-75.51%)` | `0% <0%> (-17%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4283/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/4283/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...lbender/engine/datasources/ReferenceAPISource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4283/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `25.735% <0%> (-44.853%)` | `8% <0%> (-19%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4283/diff?src=pr&el=tree#diff-c3J,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4283#issuecomment-361224262
https://github.com/broadinstitute/gatk/pull/4283#issuecomment-361224262:1844,Testability,test,test,1844,/gatk/pull/4283?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [.../main/java/org/broadinstitute/hellbender/Main.java](https://codecov.io/gh/broadinstitute/gatk/pull/4283/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9NYWluLmphdmE=) | `70.466% <25%> (+9.733%)` | `43 <1> (+8)` | :arrow_up: |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4283/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-75.51%)` | `0% <0%> (-17%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4283/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/4283/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...lbender/engine/datasources/ReferenceAPISource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4283/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `25.735% <0%> (-44.853%)` | `8% <0%> (-19%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4283/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `54.194% <0%> (-25.806%)` | `30% <0%> (-9%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/4283/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vc,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4283#issuecomment-361224262
https://github.com/broadinstitute/gatk/pull/4283#issuecomment-361224262:3322,Testability,test,test,3322,GUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...lbender/engine/datasources/ReferenceAPISource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4283/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `25.735% <0%> (-44.853%)` | `8% <0%> (-19%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4283/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `54.194% <0%> (-25.806%)` | `30% <0%> (-9%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/4283/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `0% <0%> (-22.807%)` | `0% <0%> (-2%)` | |; | [...ender/engine/datasources/ReferenceMultiSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4283/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlTXVsdGlTb3VyY2UuamF2YQ==) | `61.538% <0%> (-15.385%)` | `9% <0%> (-2%)` | |; | [...titute/hellbender/utils/test/MiniClusterUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4283/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L01pbmlDbHVzdGVyVXRpbHMuamF2YQ==) | `78.947% <0%> (-10.526%)` | `6% <0%> (-1%)` | |; | [...hellbender/tools/DownsampleableSparkReadShard.java](https://codecov.io/gh/broadinstitute/gatk/pull/4283/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9Eb3duc2FtcGxlYWJsZVNwYXJrUmVhZFNoYXJkLmphdmE=) | `81.818% <0%> (-9.091%)` | `3% <0%> (-1%)` | |; | ... and [44 more](https://codecov.io/gh/broadinstitute/gatk/pull/4283/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4283#issuecomment-361224262
https://github.com/broadinstitute/gatk/pull/4283#issuecomment-361661772:338,Availability,error,error,338,"Oh, I hadn't noticed that there was a compilation warning causing the test to fail. ```; /gatk/src/test/java/org/broadinstitute/hellbender/MainTest.java:55: warning: [serial] serializable class ExitNotAllowedExcepion has no definition of serialVersionUID; private static final class ExitNotAllowedExcepion extends SecurityException {; ^; error: warnings found and -Werror specified; ```. Please fix that also :)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4283#issuecomment-361661772
https://github.com/broadinstitute/gatk/pull/4283#issuecomment-361661772:306,Modifiability,extend,extends,306,"Oh, I hadn't noticed that there was a compilation warning causing the test to fail. ```; /gatk/src/test/java/org/broadinstitute/hellbender/MainTest.java:55: warning: [serial] serializable class ExitNotAllowedExcepion has no definition of serialVersionUID; private static final class ExitNotAllowedExcepion extends SecurityException {; ^; error: warnings found and -Werror specified; ```. Please fix that also :)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4283#issuecomment-361661772
https://github.com/broadinstitute/gatk/pull/4283#issuecomment-361661772:314,Security,Secur,SecurityException,314,"Oh, I hadn't noticed that there was a compilation warning causing the test to fail. ```; /gatk/src/test/java/org/broadinstitute/hellbender/MainTest.java:55: warning: [serial] serializable class ExitNotAllowedExcepion has no definition of serialVersionUID; private static final class ExitNotAllowedExcepion extends SecurityException {; ^; error: warnings found and -Werror specified; ```. Please fix that also :)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4283#issuecomment-361661772
https://github.com/broadinstitute/gatk/pull/4283#issuecomment-361661772:70,Testability,test,test,70,"Oh, I hadn't noticed that there was a compilation warning causing the test to fail. ```; /gatk/src/test/java/org/broadinstitute/hellbender/MainTest.java:55: warning: [serial] serializable class ExitNotAllowedExcepion has no definition of serialVersionUID; private static final class ExitNotAllowedExcepion extends SecurityException {; ^; error: warnings found and -Werror specified; ```. Please fix that also :)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4283#issuecomment-361661772
https://github.com/broadinstitute/gatk/pull/4283#issuecomment-361661772:99,Testability,test,test,99,"Oh, I hadn't noticed that there was a compilation warning causing the test to fail. ```; /gatk/src/test/java/org/broadinstitute/hellbender/MainTest.java:55: warning: [serial] serializable class ExitNotAllowedExcepion has no definition of serialVersionUID; private static final class ExitNotAllowedExcepion extends SecurityException {; ^; error: warnings found and -Werror specified; ```. Please fix that also :)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4283#issuecomment-361661772
https://github.com/broadinstitute/gatk/pull/4283#issuecomment-361891173:170,Availability,error,error,170,"@lbergelson - back to you!. I agree that the tests are a bit complicated, but the only way of testing this. In addition, the new static classes can be used to test other error codes, and thus it will be useful for testing `mainEntry` in another PR for other error codes.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4283#issuecomment-361891173
https://github.com/broadinstitute/gatk/pull/4283#issuecomment-361891173:258,Availability,error,error,258,"@lbergelson - back to you!. I agree that the tests are a bit complicated, but the only way of testing this. In addition, the new static classes can be used to test other error codes, and thus it will be useful for testing `mainEntry` in another PR for other error codes.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4283#issuecomment-361891173
https://github.com/broadinstitute/gatk/pull/4283#issuecomment-361891173:45,Testability,test,tests,45,"@lbergelson - back to you!. I agree that the tests are a bit complicated, but the only way of testing this. In addition, the new static classes can be used to test other error codes, and thus it will be useful for testing `mainEntry` in another PR for other error codes.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4283#issuecomment-361891173
https://github.com/broadinstitute/gatk/pull/4283#issuecomment-361891173:94,Testability,test,testing,94,"@lbergelson - back to you!. I agree that the tests are a bit complicated, but the only way of testing this. In addition, the new static classes can be used to test other error codes, and thus it will be useful for testing `mainEntry` in another PR for other error codes.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4283#issuecomment-361891173
https://github.com/broadinstitute/gatk/pull/4283#issuecomment-361891173:159,Testability,test,test,159,"@lbergelson - back to you!. I agree that the tests are a bit complicated, but the only way of testing this. In addition, the new static classes can be used to test other error codes, and thus it will be useful for testing `mainEntry` in another PR for other error codes.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4283#issuecomment-361891173
https://github.com/broadinstitute/gatk/pull/4283#issuecomment-361891173:214,Testability,test,testing,214,"@lbergelson - back to you!. I agree that the tests are a bit complicated, but the only way of testing this. In addition, the new static classes can be used to test other error codes, and thus it will be useful for testing `mainEntry` in another PR for other error codes.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4283#issuecomment-361891173
https://github.com/broadinstitute/gatk/pull/4283#issuecomment-361993531:28,Deployability,update,update,28,"@magicDGS Thank you for the update, I noticed one last minor thing I wanted to change so I just made the change myself, I'll merge when the test finish!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4283#issuecomment-361993531
https://github.com/broadinstitute/gatk/pull/4283#issuecomment-361993531:140,Testability,test,test,140,"@magicDGS Thank you for the update, I noticed one last minor thing I wanted to change so I just made the change myself, I'll merge when the test finish!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4283#issuecomment-361993531
https://github.com/broadinstitute/gatk/pull/4286#issuecomment-361620308:117,Testability,test,testing,117,"@lbergelson Please address the code review comments in a separate PR, since they mainly have to do with comments and testing -- I'm merging this as-is for now.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4286#issuecomment-361620308
https://github.com/broadinstitute/gatk/issues/4287#issuecomment-390729581:26,Deployability,update,update,26,@ruchim is there a status update on this?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4287#issuecomment-390729581
https://github.com/broadinstitute/gatk/pull/4288#issuecomment-361293506:26,Security,validat,validated,26,"@LeeTL1220 Note that I've validated with womtool, but as we've seen (#4281), changes of this sort (which deal with optional parameters, etc.) may slip through even if tests pass. You should take a careful look to make sure everything is in order!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4288#issuecomment-361293506
https://github.com/broadinstitute/gatk/pull/4288#issuecomment-361293506:167,Testability,test,tests,167,"@LeeTL1220 Note that I've validated with womtool, but as we've seen (#4281), changes of this sort (which deal with optional parameters, etc.) may slip through even if tests pass. You should take a careful look to make sure everything is in order!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4288#issuecomment-361293506
https://github.com/broadinstitute/gatk/pull/4288#issuecomment-361311013:41,Testability,test,tests,41,@samuelklee Should I be worried that the tests don't pass?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4288#issuecomment-361311013
https://github.com/broadinstitute/gatk/pull/4288#issuecomment-361345078:111,Deployability,release,release,111,Tests appear to be passing. Will rebase on master to remove commits from #4280 and merge so we don't delay the release.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4288#issuecomment-361345078
https://github.com/broadinstitute/gatk/pull/4288#issuecomment-361345078:0,Testability,Test,Tests,0,Tests appear to be passing. Will rebase on master to remove commits from #4280 and merge so we don't delay the release.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4288#issuecomment-361345078
https://github.com/broadinstitute/gatk/pull/4288#issuecomment-361348945:232,Availability,error,error-reference,232,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4288?src=pr&el=h1) Report; > :exclamation: No coverage uploaded for pull request base (`master@e955657`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `100%`. ```diff; @@ Coverage Diff @@; ## master #4288 +/- ##; ========================================; Coverage ? 79.1% ; Complexity ? 16614 ; ========================================; Files ? 1048 ; Lines ? 59579 ; Branches ? 9730 ; ========================================; Hits ? 47127 ; Misses ? 8675 ; Partials ? 3777; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4288?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...pynumber/gcnv/GermlineCNVPostprocessingEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/4288/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2djbnYvR2VybWxpbmVDTlZQb3N0cHJvY2Vzc2luZ0VuZ2luZS5qYXZh) | `97.143% <100%> (ø)` | `15 <0> (?)` | |; | [.../tools/copynumber/PostprocessGermlineCNVCalls.java](https://codecov.io/gh/broadinstitute/gatk/pull/4288/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL1Bvc3Rwcm9jZXNzR2VybWxpbmVDTlZDYWxscy5qYXZh) | `81.159% <100%> (ø)` | `10 <2> (?)` | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4288#issuecomment-361348945
https://github.com/broadinstitute/gatk/pull/4288#issuecomment-361348945:180,Usability,learn,learn,180,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4288?src=pr&el=h1) Report; > :exclamation: No coverage uploaded for pull request base (`master@e955657`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `100%`. ```diff; @@ Coverage Diff @@; ## master #4288 +/- ##; ========================================; Coverage ? 79.1% ; Complexity ? 16614 ; ========================================; Files ? 1048 ; Lines ? 59579 ; Branches ? 9730 ; ========================================; Hits ? 47127 ; Misses ? 8675 ; Partials ? 3777; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4288?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...pynumber/gcnv/GermlineCNVPostprocessingEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/4288/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2djbnYvR2VybWxpbmVDTlZQb3N0cHJvY2Vzc2luZ0VuZ2luZS5qYXZh) | `97.143% <100%> (ø)` | `15 <0> (?)` | |; | [.../tools/copynumber/PostprocessGermlineCNVCalls.java](https://codecov.io/gh/broadinstitute/gatk/pull/4288/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL1Bvc3Rwcm9jZXNzR2VybWxpbmVDTlZDYWxscy5qYXZh) | `81.159% <100%> (ø)` | `10 <2> (?)` | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4288#issuecomment-361348945
https://github.com/broadinstitute/gatk/pull/4289#issuecomment-361324203:106,Testability,test,tests,106,Thanks for adding this! I'm guessing you're still building the Docker image? Otherwise good to merge when tests pass.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4289#issuecomment-361324203
https://github.com/broadinstitute/gatk/pull/4289#issuecomment-361351790:33,Deployability,update,updated,33,@samuelklee I forgot to push the updated image :/,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4289#issuecomment-361351790
https://github.com/broadinstitute/gatk/pull/4289#issuecomment-361372292:1267,Testability,test,test,1267,master](https://codecov.io/gh/broadinstitute/gatk/commit/5627908ce0f8a0a438bdab5902dac26551575e26?src=pr&el=desc) will **increase** coverage by `0.023%`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #4289 +/- ##; ===============================================; + Coverage 79.078% 79.102% +0.024% ; - Complexity 16608 16615 +7 ; ===============================================; Files 1048 1048 ; Lines 59579 59579 ; Branches 9730 9730 ; ===============================================; + Hits 47114 47128 +14 ; + Misses 8685 8675 -10 ; + Partials 3780 3776 -4; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4289?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...park/sv/discovery/alignment/AlignmentInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/4289/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvYWxpZ25tZW50L0FsaWdubWVudEludGVydmFsLmphdmE=) | `90.038% <0%> (+0.766%)` | `75% <0%> (+2%)` | :arrow_up: |; | [...hellbender/utils/test/VariantContextTestUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4289/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1ZhcmlhbnRDb250ZXh0VGVzdFV0aWxzLmphdmE=) | `82.432% <0%> (+2.703%)` | `60% <0%> (+3%)` | :arrow_up: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/4289/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `73.973% <0%> (+2.74%)` | `11% <0%> (ø)` | :arrow_down: |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/4289/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `90% <0%> (+40%)` | `3% <0%> (+2%)` | :arrow_up: |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4289#issuecomment-361372292
https://github.com/broadinstitute/gatk/issues/4290#issuecomment-422126933:522,Modifiability,refactor,refactored,522,@davidbenjamin This is the issue I was talking about -- the relevant code is in `MannWhitneyU`:. ```; double sumOfAllSmallerBins = histo.get(testStatU).getValue() / 2.0;. for (final Histogram.Bin<Double> bin : histo.values()) {; if (bin.getId() < testStatU) sumOfAllSmallerBins += bin.getValue();; }. return sumOfAllSmallerBins / histo.getCount();; ```. Where `testStatU` is a double. This has caused issues like the one reported in https://github.com/broadinstitute/gatk/pull/5190. I'm wondering whether the class can be refactored to not use a double as a key.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4290#issuecomment-422126933
https://github.com/broadinstitute/gatk/issues/4290#issuecomment-422126933:141,Testability,test,testStatU,141,@davidbenjamin This is the issue I was talking about -- the relevant code is in `MannWhitneyU`:. ```; double sumOfAllSmallerBins = histo.get(testStatU).getValue() / 2.0;. for (final Histogram.Bin<Double> bin : histo.values()) {; if (bin.getId() < testStatU) sumOfAllSmallerBins += bin.getValue();; }. return sumOfAllSmallerBins / histo.getCount();; ```. Where `testStatU` is a double. This has caused issues like the one reported in https://github.com/broadinstitute/gatk/pull/5190. I'm wondering whether the class can be refactored to not use a double as a key.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4290#issuecomment-422126933
https://github.com/broadinstitute/gatk/issues/4290#issuecomment-422126933:247,Testability,test,testStatU,247,@davidbenjamin This is the issue I was talking about -- the relevant code is in `MannWhitneyU`:. ```; double sumOfAllSmallerBins = histo.get(testStatU).getValue() / 2.0;. for (final Histogram.Bin<Double> bin : histo.values()) {; if (bin.getId() < testStatU) sumOfAllSmallerBins += bin.getValue();; }. return sumOfAllSmallerBins / histo.getCount();; ```. Where `testStatU` is a double. This has caused issues like the one reported in https://github.com/broadinstitute/gatk/pull/5190. I'm wondering whether the class can be refactored to not use a double as a key.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4290#issuecomment-422126933
https://github.com/broadinstitute/gatk/issues/4290#issuecomment-422126933:361,Testability,test,testStatU,361,@davidbenjamin This is the issue I was talking about -- the relevant code is in `MannWhitneyU`:. ```; double sumOfAllSmallerBins = histo.get(testStatU).getValue() / 2.0;. for (final Histogram.Bin<Double> bin : histo.values()) {; if (bin.getId() < testStatU) sumOfAllSmallerBins += bin.getValue();; }. return sumOfAllSmallerBins / histo.getCount();; ```. Where `testStatU` is a double. This has caused issues like the one reported in https://github.com/broadinstitute/gatk/pull/5190. I'm wondering whether the class can be refactored to not use a double as a key.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4290#issuecomment-422126933
https://github.com/broadinstitute/gatk/issues/4290#issuecomment-422442649:47,Testability,test,test,47,"I quickly looked at the nature of Mann-Whitney test. Seems to me the current implementation is correct algorithmic-wise. @droazen , I guess your concern is that using double as the key to the look-up function in `map` is too fragile?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4290#issuecomment-422442649
https://github.com/broadinstitute/gatk/issues/4290#issuecomment-422444261:77,Availability,error,error,77,"@frank-y-liu Yes, I think it's not only fragile, but the direct cause of the error you're seeing. @davidbenjamin has agreed to attempt a refactor of the class when he has some free time.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4290#issuecomment-422444261
https://github.com/broadinstitute/gatk/issues/4290#issuecomment-422444261:137,Modifiability,refactor,refactor,137,"@frank-y-liu Yes, I think it's not only fragile, but the direct cause of the error you're seeing. @davidbenjamin has agreed to attempt a refactor of the class when he has some free time.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4290#issuecomment-422444261
https://github.com/broadinstitute/gatk/issues/4290#issuecomment-434011333:102,Modifiability,refactor,refactor,102,@davidbenjamin Have you had a chance to think about this one yet? Do you think it will be possible to refactor so that doubles are not used as keys? @frank-y-liu was asking about this today.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4290#issuecomment-434011333
https://github.com/broadinstitute/gatk/pull/4292#issuecomment-361359755:3366,Testability,test,test,3366, `18% <0%> (+3%)` | |; | [...ender/engine/datasources/ReferenceMultiSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4292/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlTXVsdGlTb3VyY2UuamF2YQ==) | `76.471% <0%> (-0.452%)` | `15% <0%> (+4%)` | |; | [...lbender/utils/read/SAMRecordToGATKReadAdapter.java](https://codecov.io/gh/broadinstitute/gatk/pull/4292/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWFkL1NBTVJlY29yZFRvR0FUS1JlYWRBZGFwdGVyLmphdmE=) | `92.027% <0%> (-0.433%)` | `270% <0%> (+134%)` | |; | [...ute/hellbender/utils/read/ArtificialReadUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4292/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWFkL0FydGlmaWNpYWxSZWFkVXRpbHMuamF2YQ==) | `93.909% <0%> (-0.186%)` | `122% <0%> (+52%)` | |; | [...itute/hellbender/engine/spark/GATKRegistrator.java](https://codecov.io/gh/broadinstitute/gatk/pull/4292/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvR0FUS1JlZ2lzdHJhdG9yLmphdmE=) | `100% <0%> (ø)` | `4% <0%> (+2%)` | :arrow_up: |; | [...utils/test/ReadsPreprocessingPipelineTestData.java](https://codecov.io/gh/broadinstitute/gatk/pull/4292/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1JlYWRzUHJlcHJvY2Vzc2luZ1BpcGVsaW5lVGVzdERhdGEuamF2YQ==) | `1.25% <0%> (+0.403%)` | `1% <0%> (ø)` | :arrow_down: |; | [...tructuralVariationDiscoveryArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/4292/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9TdHJ1Y3R1cmFsVmFyaWF0aW9uRGlzY292ZXJ5QXJndW1lbnRDb2xsZWN0aW9uLmphdmE=) | `97.143% <0%> (+0.476%)` | `0% <0%> (ø)` | :arrow_down: |; | ... and [15 more](https://codecov.io/gh/broadinstitute/gatk/pull/4292/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4292#issuecomment-361359755
https://github.com/broadinstitute/gatk/pull/4292#issuecomment-361394598:46,Deployability,release,release,46,@samuelklee I'm fine without this one in next release.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4292#issuecomment-361394598
https://github.com/broadinstitute/gatk/pull/4292#issuecomment-363828979:95,Deployability,release,release,95,"@LeeTL1220 OK, tweaked the message a bit. I think I'm OK with this going in for the next point release. This is the sort of thing for which it will be nice to have the automatic validations, as a sanity check.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4292#issuecomment-363828979
https://github.com/broadinstitute/gatk/pull/4292#issuecomment-363828979:27,Integrability,message,message,27,"@LeeTL1220 OK, tweaked the message a bit. I think I'm OK with this going in for the next point release. This is the sort of thing for which it will be nice to have the automatic validations, as a sanity check.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4292#issuecomment-363828979
https://github.com/broadinstitute/gatk/pull/4292#issuecomment-363828979:196,Safety,sanity check,sanity check,196,"@LeeTL1220 OK, tweaked the message a bit. I think I'm OK with this going in for the next point release. This is the sort of thing for which it will be nice to have the automatic validations, as a sanity check.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4292#issuecomment-363828979
https://github.com/broadinstitute/gatk/pull/4292#issuecomment-363828979:178,Security,validat,validations,178,"@LeeTL1220 OK, tweaked the message a bit. I think I'm OK with this going in for the next point release. This is the sort of thing for which it will be nice to have the automatic validations, as a sanity check.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4292#issuecomment-363828979
https://github.com/broadinstitute/gatk/pull/4292#issuecomment-365706839:41,Availability,error,error,41,"@samuelklee Is it possible to expand the error message a bit so that users get something actionable. For example, ""Does the interval list match what was covered in the bam file? Does this bam have coverage in all intervals?""",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4292#issuecomment-365706839
https://github.com/broadinstitute/gatk/pull/4292#issuecomment-365706839:47,Integrability,message,message,47,"@samuelklee Is it possible to expand the error message a bit so that users get something actionable. For example, ""Does the interval list match what was covered in the bam file? Does this bam have coverage in all intervals?""",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4292#issuecomment-365706839
https://github.com/broadinstitute/gatk/pull/4292#issuecomment-365726746:20,Integrability,message,message,20,"I'd rather keep the message more generic, and think of the check as simply defining what a valid `CopyRatio` object can be: an interval associated with a finite double value. One might imagine that someone would try to create such an object that does not originate from a BAM (perhaps for test data, or for imputing missing values in pre-existing data, etc.). This check says that they must create it with some finite value. A more appropriate place for the sort of message you suggest is in the relevant denoising method. In the edge case you encountered, you used a BAM that was almost completely uncovered in all bins at the specified resolution, resulting in a sample median of zero. Since one of the steps in standardization is dividing by the sample median, this results in a divide by zero. I've added the corresponding check.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4292#issuecomment-365726746
https://github.com/broadinstitute/gatk/pull/4292#issuecomment-365726746:466,Integrability,message,message,466,"I'd rather keep the message more generic, and think of the check as simply defining what a valid `CopyRatio` object can be: an interval associated with a finite double value. One might imagine that someone would try to create such an object that does not originate from a BAM (perhaps for test data, or for imputing missing values in pre-existing data, etc.). This check says that they must create it with some finite value. A more appropriate place for the sort of message you suggest is in the relevant denoising method. In the edge case you encountered, you used a BAM that was almost completely uncovered in all bins at the specified resolution, resulting in a sample median of zero. Since one of the steps in standardization is dividing by the sample median, this results in a divide by zero. I've added the corresponding check.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4292#issuecomment-365726746
https://github.com/broadinstitute/gatk/pull/4292#issuecomment-365726746:289,Testability,test,test,289,"I'd rather keep the message more generic, and think of the check as simply defining what a valid `CopyRatio` object can be: an interval associated with a finite double value. One might imagine that someone would try to create such an object that does not originate from a BAM (perhaps for test data, or for imputing missing values in pre-existing data, etc.). This check says that they must create it with some finite value. A more appropriate place for the sort of message you suggest is in the relevant denoising method. In the edge case you encountered, you used a BAM that was almost completely uncovered in all bins at the specified resolution, resulting in a sample median of zero. Since one of the steps in standardization is dividing by the sample median, this results in a divide by zero. I've added the corresponding check.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4292#issuecomment-365726746
https://github.com/broadinstitute/gatk/pull/4292#issuecomment-365726746:68,Usability,simpl,simply,68,"I'd rather keep the message more generic, and think of the check as simply defining what a valid `CopyRatio` object can be: an interval associated with a finite double value. One might imagine that someone would try to create such an object that does not originate from a BAM (perhaps for test data, or for imputing missing values in pre-existing data, etc.). This check says that they must create it with some finite value. A more appropriate place for the sort of message you suggest is in the relevant denoising method. In the edge case you encountered, you used a BAM that was almost completely uncovered in all bins at the specified resolution, resulting in a sample median of zero. Since one of the steps in standardization is dividing by the sample median, this results in a divide by zero. I've added the corresponding check.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4292#issuecomment-365726746
https://github.com/broadinstitute/gatk/pull/4293#issuecomment-361362648:1257,Deployability,pipeline,pipelines,1257,b0a564ef6595?src=pr&el=desc) will **decrease** coverage by `0.399%`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #4293 +/- ##; ===============================================; - Coverage 79.092% 78.693% -0.399% ; + Complexity 16611 16541 -70 ; ===============================================; Files 1048 1049 +1 ; Lines 59579 59580 +1 ; Branches 9730 9730 ; ===============================================; - Hits 47122 46885 -237 ; - Misses 8679 8927 +248 ; + Partials 3778 3768 -10; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4293?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4293/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-75.51%)` | `0% <0%> (-17%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4293/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/4293/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...lbender/engine/datasources/ReferenceAPISource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4293/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `25.735% <0%> (-44.853%)` | `8% <0%> (-19%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4293/diff?src=pr&el=tree#diff-c3J,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4293#issuecomment-361362648
https://github.com/broadinstitute/gatk/pull/4293#issuecomment-361362648:1573,Testability,test,test,1573,===============; Files 1048 1049 +1 ; Lines 59579 59580 +1 ; Branches 9730 9730 ; ===============================================; - Hits 47122 46885 -237 ; - Misses 8679 8927 +248 ; + Partials 3778 3768 -10; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4293?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4293/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-75.51%)` | `0% <0%> (-17%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4293/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/4293/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-60.87%)` | `2% <0%> (-6%)` | |; | [...lbender/engine/datasources/ReferenceAPISource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4293/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `25.735% <0%> (-44.853%)` | `8% <0%> (-19%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4293/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `54.194% <0%> (-25.806%)` | `30% <0%> (-9%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/4293/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vc,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4293#issuecomment-361362648
https://github.com/broadinstitute/gatk/pull/4293#issuecomment-361362648:3051,Testability,test,test,3051,vYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlQVBJU291cmNlLmphdmE=) | `25.735% <0%> (-44.853%)` | `8% <0%> (-19%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4293/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `54.194% <0%> (-25.806%)` | `30% <0%> (-9%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/4293/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `0% <0%> (-22.807%)` | `0% <0%> (-2%)` | |; | [...ender/engine/datasources/ReferenceMultiSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4293/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZGF0YXNvdXJjZXMvUmVmZXJlbmNlTXVsdGlTb3VyY2UuamF2YQ==) | `61.538% <0%> (-15.385%)` | `9% <0%> (-2%)` | |; | [...titute/hellbender/utils/test/MiniClusterUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4293/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L01pbmlDbHVzdGVyVXRpbHMuamF2YQ==) | `78.947% <0%> (-10.526%)` | `6% <0%> (-1%)` | |; | [...adinstitute/hellbender/engine/ReadsDataSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4293/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUmVhZHNEYXRhU291cmNlLmphdmE=) | `89.394% <0%> (-3.03%)` | `61% <0%> (-2%)` | |; | [...institute/hellbender/exceptions/UserException.java](https://codecov.io/gh/broadinstitute/gatk/pull/4293/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9leGNlcHRpb25zL1VzZXJFeGNlcHRpb24uamF2YQ==) | `67.669% <0%> (-3.008%)` | `3% <0%> (ø)` | |; | ... and [23 more](https://codecov.io/gh/broadinstitute/gatk/pull/4293/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4293#issuecomment-361362648
https://github.com/broadinstitute/gatk/issues/4294#issuecomment-460404012:107,Deployability,pipeline,pipeline,107,"Talked to @ldgauthier about this, and I'm not sure that this matters anymore for our current joint-calling pipeline. @ldgauthier would you be comfortable closing?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4294#issuecomment-460404012
https://github.com/broadinstitute/gatk/issues/4296#issuecomment-363201577:51,Performance,perform,performance,51,@tomwhite This seems like an easy way to get a big performance boost in `HaplotypeCallerSpark` -- what do you think?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4296#issuecomment-363201577
https://github.com/broadinstitute/gatk/pull/4297#issuecomment-361394130:37,Testability,test,tests,37,@davidbenjamin Feel free to merge if tests pass.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4297#issuecomment-361394130
https://github.com/broadinstitute/gatk/issues/4300#issuecomment-365974850:225,Availability,down,downsampling,225,"I can add that my (rather empirical) tests on 3.8 vs 4.0 show a noticeable increase in runtime (currently around 4-5 hours for an Agilent OneSeq enrichment on a non-AVX capable CPU). I can explain it in part with the lack of downsampling (as mentioned in the last comments of the above GH ticket), but it's still far more than what I used to see with 3.8. Unlike the original reporter, however, I did not test the betas. Is there a standardized way to profile these results, so I can give out more concrete data?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4300#issuecomment-365974850
https://github.com/broadinstitute/gatk/issues/4300#issuecomment-365974850:37,Testability,test,tests,37,"I can add that my (rather empirical) tests on 3.8 vs 4.0 show a noticeable increase in runtime (currently around 4-5 hours for an Agilent OneSeq enrichment on a non-AVX capable CPU). I can explain it in part with the lack of downsampling (as mentioned in the last comments of the above GH ticket), but it's still far more than what I used to see with 3.8. Unlike the original reporter, however, I did not test the betas. Is there a standardized way to profile these results, so I can give out more concrete data?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4300#issuecomment-365974850
https://github.com/broadinstitute/gatk/issues/4300#issuecomment-365974850:405,Testability,test,test,405,"I can add that my (rather empirical) tests on 3.8 vs 4.0 show a noticeable increase in runtime (currently around 4-5 hours for an Agilent OneSeq enrichment on a non-AVX capable CPU). I can explain it in part with the lack of downsampling (as mentioned in the last comments of the above GH ticket), but it's still far more than what I used to see with 3.8. Unlike the original reporter, however, I did not test the betas. Is there a standardized way to profile these results, so I can give out more concrete data?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4300#issuecomment-365974850
https://github.com/broadinstitute/gatk/issues/4300#issuecomment-365991967:92,Deployability,release,release,92,"There was a confirmed performance regression in `BaseRecalibratorSpark` just before the 4.0 release: https://github.com/broadinstitute/gatk/issues/4376. I suspect that's what's responsible for the results reported above. Until this is patched (most likely in the next GATK release), I'd recommend running the regular `BaseRecalibrator` instead of the spark version.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4300#issuecomment-365991967
https://github.com/broadinstitute/gatk/issues/4300#issuecomment-365991967:235,Deployability,patch,patched,235,"There was a confirmed performance regression in `BaseRecalibratorSpark` just before the 4.0 release: https://github.com/broadinstitute/gatk/issues/4376. I suspect that's what's responsible for the results reported above. Until this is patched (most likely in the next GATK release), I'd recommend running the regular `BaseRecalibrator` instead of the spark version.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4300#issuecomment-365991967
https://github.com/broadinstitute/gatk/issues/4300#issuecomment-365991967:273,Deployability,release,release,273,"There was a confirmed performance regression in `BaseRecalibratorSpark` just before the 4.0 release: https://github.com/broadinstitute/gatk/issues/4376. I suspect that's what's responsible for the results reported above. Until this is patched (most likely in the next GATK release), I'd recommend running the regular `BaseRecalibrator` instead of the spark version.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4300#issuecomment-365991967
https://github.com/broadinstitute/gatk/issues/4300#issuecomment-365991967:22,Performance,perform,performance,22,"There was a confirmed performance regression in `BaseRecalibratorSpark` just before the 4.0 release: https://github.com/broadinstitute/gatk/issues/4376. I suspect that's what's responsible for the results reported above. Until this is patched (most likely in the next GATK release), I'd recommend running the regular `BaseRecalibrator` instead of the spark version.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4300#issuecomment-365991967
https://github.com/broadinstitute/gatk/issues/4301#issuecomment-368830180:97,Performance,load,loading,97,"I might be missing something, but this looks like it iterates over assembly regions, rather than loading them all at once. `Utils.stream` converts an iterator to a stream, but even that doesn't load them all into memory as it basically creates a one-shot `Iterable` that just returns the passed in `Iterator` (this is what `() -> iterator` does).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4301#issuecomment-368830180
https://github.com/broadinstitute/gatk/issues/4301#issuecomment-368830180:194,Performance,load,load,194,"I might be missing something, but this looks like it iterates over assembly regions, rather than loading them all at once. `Utils.stream` converts an iterator to a stream, but even that doesn't load them all into memory as it basically creates a one-shot `Iterable` that just returns the passed in `Iterator` (this is what `() -> iterator` does).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4301#issuecomment-368830180
https://github.com/broadinstitute/gatk/pull/4306#issuecomment-362672065:205,Usability,clear,clear,205,"You are going to want to change all the ; `memory: machine_mem + "" GB""` ; lines to ; `memory: machine_mem + "" MB""`.; Otherwise you are going to be asking for massive amounts of memory 😄. Sorry if I wasn't clear the first time.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4306#issuecomment-362672065
https://github.com/broadinstitute/gatk/pull/4306#issuecomment-362872226:31,Usability,clear,clear,31,@jsotobroad You were perfectly clear. I must have made that change on a different branch by mistake!!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4306#issuecomment-362872226
https://github.com/broadinstitute/gatk/issues/4307#issuecomment-434440224:237,Deployability,release,release,237,"For the following variants: . `chr1 819955 . TTCACGAATT T . PASS .`; `chr1 819979 . CATGAGCAT C . PASS .`. _VEP_ seems to produce **incorrect** data: ; ```; ##fileformat=VCFv4.1; ##VEP=""v94"" time=""2018-10-30 19:13:50"" cache=""/nfs/public/release/ensweb-data/latest/tools/grch37/e94/vep/cache/homo_sapiens/94_GRCh37"" db=""homo_sapiens_core_94_37@hh-mysql-ens-grch37-web"" 1000genomes=""phase3"" COSMIC=""81"" ClinVar=""201706"" ESP=""20141103"" HGMD-PUBLIC=""20164"" assembly=""GRCh37.p13"" dbSNP=""150"" gencode=""GENCODE 19"" genebuild=""2011-04"" gnomAD=""170228"" polyphen=""2.2.2"" regbuild=""1.0"" sift=""sift5.2.2""; ##INFO=<ID=CSQ,Number=.,Type=String,Description=""Consequence annotations from Ensembl VEP. Format: Allele|Consequence|IMPACT|SYMBOL|Gene|Feature_type|Feature|BIOTYPE|EXON|INTRON|HGVSc|HGVSp|cDNA_position|CDS_position|Protein_position|Amino_acids|Codons|Existing_variation|DISTANCE|STRAND|FLAGS|SYMBOL_SOURCE|HGNC_ID|TSL|APPRIS|ENSP|SIFT|PolyPhen|AF|AFR_AF|AMR_AF|EAS_AF|EUR_AF|SAS_AF|AA_AF|EA_AF|gnomAD_AF|gnomAD_AFR_AF|gnomAD_AMR_AF|gnomAD_ASJ_AF|gnomAD_EAS_AF|gnomAD_FIN_AF|gnomAD_NFE_AF|gnomAD_OTH_AF|gnomAD_SAS_AF|CLIN_SIG|SOMATIC|PHENO|PUBMED|MOTIF_NAME|MOTIF_POS|HIGH_INF_POS|MOTIF_SCORE_CHANGE"">; #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO; chr1	819955	.	TTCACGAATT	T	.	PASS	CSQ=-|splice_acceptor_variant&coding_sequence_variant&intron_variant|HIGH|AL645608.2|ENSG00000269308|Transcript|ENST00000594233|protein_coding|3/3|2/2|||?-38|?-38|?-13|||||1||Clone_based_ensembl_gene||||ENSP00000470877|||||||||||||||||||||||||||; chr1	819979	.	CATGAGCAT	C	.	PASS	CSQ=-|coding_sequence_variant&3_prime_UTR_variant|MODIFIER|AL645608.2|ENSG00000269308|Transcript|ENST00000594233|protein_coding|3/3||||54-?|54-?|18-?|||||1||Clone_based_ensembl_gene||||ENSP00000470877|||||||||||||||||||||||||||; ```. There is no cDNA string / amino acid change and the positions have `?` characters in them (not 100% sure the question marks are wrong - there is no real spec for these fields). _Oncotator_ seems to produce **incorre",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4307#issuecomment-434440224
https://github.com/broadinstitute/gatk/issues/4307#issuecomment-434440224:218,Performance,cache,cache,218,"For the following variants: . `chr1 819955 . TTCACGAATT T . PASS .`; `chr1 819979 . CATGAGCAT C . PASS .`. _VEP_ seems to produce **incorrect** data: ; ```; ##fileformat=VCFv4.1; ##VEP=""v94"" time=""2018-10-30 19:13:50"" cache=""/nfs/public/release/ensweb-data/latest/tools/grch37/e94/vep/cache/homo_sapiens/94_GRCh37"" db=""homo_sapiens_core_94_37@hh-mysql-ens-grch37-web"" 1000genomes=""phase3"" COSMIC=""81"" ClinVar=""201706"" ESP=""20141103"" HGMD-PUBLIC=""20164"" assembly=""GRCh37.p13"" dbSNP=""150"" gencode=""GENCODE 19"" genebuild=""2011-04"" gnomAD=""170228"" polyphen=""2.2.2"" regbuild=""1.0"" sift=""sift5.2.2""; ##INFO=<ID=CSQ,Number=.,Type=String,Description=""Consequence annotations from Ensembl VEP. Format: Allele|Consequence|IMPACT|SYMBOL|Gene|Feature_type|Feature|BIOTYPE|EXON|INTRON|HGVSc|HGVSp|cDNA_position|CDS_position|Protein_position|Amino_acids|Codons|Existing_variation|DISTANCE|STRAND|FLAGS|SYMBOL_SOURCE|HGNC_ID|TSL|APPRIS|ENSP|SIFT|PolyPhen|AF|AFR_AF|AMR_AF|EAS_AF|EUR_AF|SAS_AF|AA_AF|EA_AF|gnomAD_AF|gnomAD_AFR_AF|gnomAD_AMR_AF|gnomAD_ASJ_AF|gnomAD_EAS_AF|gnomAD_FIN_AF|gnomAD_NFE_AF|gnomAD_OTH_AF|gnomAD_SAS_AF|CLIN_SIG|SOMATIC|PHENO|PUBMED|MOTIF_NAME|MOTIF_POS|HIGH_INF_POS|MOTIF_SCORE_CHANGE"">; #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO; chr1	819955	.	TTCACGAATT	T	.	PASS	CSQ=-|splice_acceptor_variant&coding_sequence_variant&intron_variant|HIGH|AL645608.2|ENSG00000269308|Transcript|ENST00000594233|protein_coding|3/3|2/2|||?-38|?-38|?-13|||||1||Clone_based_ensembl_gene||||ENSP00000470877|||||||||||||||||||||||||||; chr1	819979	.	CATGAGCAT	C	.	PASS	CSQ=-|coding_sequence_variant&3_prime_UTR_variant|MODIFIER|AL645608.2|ENSG00000269308|Transcript|ENST00000594233|protein_coding|3/3||||54-?|54-?|18-?|||||1||Clone_based_ensembl_gene||||ENSP00000470877|||||||||||||||||||||||||||; ```. There is no cDNA string / amino acid change and the positions have `?` characters in them (not 100% sure the question marks are wrong - there is no real spec for these fields). _Oncotator_ seems to produce **incorre",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4307#issuecomment-434440224
https://github.com/broadinstitute/gatk/issues/4307#issuecomment-434440224:285,Performance,cache,cache,285,"For the following variants: . `chr1 819955 . TTCACGAATT T . PASS .`; `chr1 819979 . CATGAGCAT C . PASS .`. _VEP_ seems to produce **incorrect** data: ; ```; ##fileformat=VCFv4.1; ##VEP=""v94"" time=""2018-10-30 19:13:50"" cache=""/nfs/public/release/ensweb-data/latest/tools/grch37/e94/vep/cache/homo_sapiens/94_GRCh37"" db=""homo_sapiens_core_94_37@hh-mysql-ens-grch37-web"" 1000genomes=""phase3"" COSMIC=""81"" ClinVar=""201706"" ESP=""20141103"" HGMD-PUBLIC=""20164"" assembly=""GRCh37.p13"" dbSNP=""150"" gencode=""GENCODE 19"" genebuild=""2011-04"" gnomAD=""170228"" polyphen=""2.2.2"" regbuild=""1.0"" sift=""sift5.2.2""; ##INFO=<ID=CSQ,Number=.,Type=String,Description=""Consequence annotations from Ensembl VEP. Format: Allele|Consequence|IMPACT|SYMBOL|Gene|Feature_type|Feature|BIOTYPE|EXON|INTRON|HGVSc|HGVSp|cDNA_position|CDS_position|Protein_position|Amino_acids|Codons|Existing_variation|DISTANCE|STRAND|FLAGS|SYMBOL_SOURCE|HGNC_ID|TSL|APPRIS|ENSP|SIFT|PolyPhen|AF|AFR_AF|AMR_AF|EAS_AF|EUR_AF|SAS_AF|AA_AF|EA_AF|gnomAD_AF|gnomAD_AFR_AF|gnomAD_AMR_AF|gnomAD_ASJ_AF|gnomAD_EAS_AF|gnomAD_FIN_AF|gnomAD_NFE_AF|gnomAD_OTH_AF|gnomAD_SAS_AF|CLIN_SIG|SOMATIC|PHENO|PUBMED|MOTIF_NAME|MOTIF_POS|HIGH_INF_POS|MOTIF_SCORE_CHANGE"">; #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO; chr1	819955	.	TTCACGAATT	T	.	PASS	CSQ=-|splice_acceptor_variant&coding_sequence_variant&intron_variant|HIGH|AL645608.2|ENSG00000269308|Transcript|ENST00000594233|protein_coding|3/3|2/2|||?-38|?-38|?-13|||||1||Clone_based_ensembl_gene||||ENSP00000470877|||||||||||||||||||||||||||; chr1	819979	.	CATGAGCAT	C	.	PASS	CSQ=-|coding_sequence_variant&3_prime_UTR_variant|MODIFIER|AL645608.2|ENSG00000269308|Transcript|ENST00000594233|protein_coding|3/3||||54-?|54-?|18-?|||||1||Clone_based_ensembl_gene||||ENSP00000470877|||||||||||||||||||||||||||; ```. There is no cDNA string / amino acid change and the positions have `?` characters in them (not 100% sure the question marks are wrong - there is no real spec for these fields). _Oncotator_ seems to produce **incorre",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4307#issuecomment-434440224
https://github.com/broadinstitute/gatk/pull/4308#issuecomment-361758142:926,Deployability,pipeline,pipelines,926,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4308?src=pr&el=h1) Report; > Merging [#4308](https://codecov.io/gh/broadinstitute/gatk/pull/4308?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/e455fd57e2c1270f250931206ae2bed47711139b?src=pr&el=desc) will **increase** coverage by `0.017%`.; > The diff coverage is `100%`. ```diff; @@ Coverage Diff @@; ## master #4308 +/- ##; ===============================================; + Coverage 80.073% 80.091% +0.017% ; - Complexity 17420 17437 +17 ; ===============================================; Files 1080 1081 +1 ; Lines 63131 63201 +70 ; Branches 10200 10215 +15 ; ===============================================; + Hits 50551 50618 +67 ; Misses 8587 8587 ; - Partials 3993 3996 +3; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4308?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...k/pipelines/BwaAndMarkDuplicatesPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4308/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQndhQW5kTWFya0R1cGxpY2F0ZXNQaXBlbGluZVNwYXJrLmphdmE=) | `78.947% <100%> (+1.17%)` | `5 <1> (+1)` | :arrow_up: |; | [...org/broadinstitute/hellbender/engine/GATKTool.java](https://codecov.io/gh/broadinstitute/gatk/pull/4308/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvR0FUS1Rvb2wuamF2YQ==) | `91.388% <100%> (+0.083%)` | `94 <1> (+1)` | :arrow_up: |; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4308/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `89.796% <100%> (+0.665%)` | `14 <2> (+2)` | :arrow_up: |; | [...institute/hellbender/tools/spark/bwa/BwaSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4308/diff?src=pr&el=tree#diff-c3JjL21h,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4308#issuecomment-361758142
https://github.com/broadinstitute/gatk/pull/4308#issuecomment-361758142:1563,Deployability,pipeline,pipelines,1563,=============; Files 1080 1081 +1 ; Lines 63131 63201 +70 ; Branches 10200 10215 +15 ; ===============================================; + Hits 50551 50618 +67 ; Misses 8587 8587 ; - Partials 3993 3996 +3; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4308?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...k/pipelines/BwaAndMarkDuplicatesPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4308/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQndhQW5kTWFya0R1cGxpY2F0ZXNQaXBlbGluZVNwYXJrLmphdmE=) | `78.947% <100%> (+1.17%)` | `5 <1> (+1)` | :arrow_up: |; | [...org/broadinstitute/hellbender/engine/GATKTool.java](https://codecov.io/gh/broadinstitute/gatk/pull/4308/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvR0FUS1Rvb2wuamF2YQ==) | `91.388% <100%> (+0.083%)` | `94 <1> (+1)` | :arrow_up: |; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4308/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `89.796% <100%> (+0.665%)` | `14 <2> (+2)` | :arrow_up: |; | [...institute/hellbender/tools/spark/bwa/BwaSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4308/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9id2EvQndhU3BhcmsuamF2YQ==) | `77.778% <100%> (+1.307%)` | `7 <1> (+1)` | :arrow_up: |; | [...equenceDictionaryValidationArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/4308/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL2FyZ3VtZW50Y29sbGVjdGlvbnMvU2VxdWVuY2VEaWN0aW9uYXJ5VmFsaWRhdGlvbkFyZ3VtZW50Q29sbGVjdGlvbi5qYXZh) | `100% <100%> (ø)` | `0 <0> (?)` | |; | [...stitute/hellbender/engine/spark/GATKSparkTool.java](https://codecov.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4308#issuecomment-361758142
https://github.com/broadinstitute/gatk/pull/4308#issuecomment-390007481:33,Testability,test,tests,33,"made it private, will merge when tests pass, thanks @cmnbroad",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4308#issuecomment-390007481
https://github.com/broadinstitute/gatk/pull/4310#issuecomment-361761293:89,Deployability,update,updates,89,"@davidbenjamin, @takutosato @vdauwera, would one of you be willing to review these minor updates? In particular, FilterByOrientationBias has a three-bullet list at the end that I summarized out of the detailed summary section. It seems the detailed summary section points may be out of date (a feeling of deja vu here also). Let me take a screenshot so you can see:. ![screenshot 2018-01-30 17 48 24](https://user-images.githubusercontent.com/11543866/35595769-d1f8d77e-05e5-11e8-8ed4-658c77c67018.png)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4310#issuecomment-361761293
https://github.com/broadinstitute/gatk/pull/4310#issuecomment-361770954:1236,Security,validat,validation,1236,6e7635897e1a6a773af5684511e2358d369af94?src=pr&el=desc) will **increase** coverage by `0.002%`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #4310 +/- ##; ===============================================; + Coverage 79.065% 79.067% +0.002% ; - Complexity 16582 16583 +1 ; ===============================================; Files 1048 1048 ; Lines 59504 59504 ; Branches 9717 9717 ; ===============================================; + Hits 47047 47048 +1 ; Misses 8682 8682 ; + Partials 3775 3774 -1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4310?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...bender/tools/walkers/mutect/FilterMutectCalls.java](https://codecov.io/gh/broadinstitute/gatk/pull/4310/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9GaWx0ZXJNdXRlY3RDYWxscy5qYXZh) | `95.833% <ø> (ø)` | `7 <0> (ø)` | :arrow_down: |; | [...llbender/tools/walkers/validation/Concordance.java](https://codecov.io/gh/broadinstitute/gatk/pull/4310/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vQ29uY29yZGFuY2UuamF2YQ==) | `88.542% <ø> (ø)` | `28 <0> (ø)` | :arrow_down: |; | [...itute/hellbender/tools/walkers/mutect/Mutect2.java](https://codecov.io/gh/broadinstitute/gatk/pull/4310/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9NdXRlY3QyLmphdmE=) | `92% <ø> (ø)` | `15 <0> (ø)` | :arrow_down: |; | [...ls/walkers/mutect/CreateSomaticPanelOfNormals.java](https://codecov.io/gh/broadinstitute/gatk/pull/4310/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9DcmVhdGVTb21hdGljUGFuZWxPZk5vcm1hbHMuamF2YQ==) | `87.273% <ø> (ø)` | `8 <0> (ø)` | :arrow_down: |; | [...ellbender/tools/exome/FilterByOrientationBias.java](https://codecov.io/gh/broadinstitute/gatk/pull/4310/di,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4310#issuecomment-361770954
https://github.com/broadinstitute/gatk/pull/4310#issuecomment-361987314:54,Deployability,release,release,54,"Thanks for the review @davidbenjamin. I just read the release notes for v4.0.1.0 and saw that there is a fix to allow `.list` extensions in addition to `.arg` extensions, so I added this to CreateSomaticPanelOfNormals.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4310#issuecomment-361987314
https://github.com/broadinstitute/gatk/pull/4310#issuecomment-362010747:68,Deployability,update,updates,68,"Given the thumbs up from David, I will go ahead and merge these doc updates.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4310#issuecomment-362010747
https://github.com/broadinstitute/gatk/issues/4312#issuecomment-361992446:39,Deployability,patch,patch,39,"Thanks @eitanbanks, we'll try to get a patch out this week for this one.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4312#issuecomment-361992446
https://github.com/broadinstitute/gatk/issues/4312#issuecomment-365632438:52,Availability,error,error,52,"Hi,. Any updates on this? I'm running into the same error with v4.0.1.2. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4312#issuecomment-365632438
https://github.com/broadinstitute/gatk/issues/4312#issuecomment-365632438:9,Deployability,update,updates,9,"Hi,. Any updates on this? I'm running into the same error with v4.0.1.2. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4312#issuecomment-365632438
https://github.com/broadinstitute/gatk/issues/4312#issuecomment-365650170:16,Deployability,patch,patch,16,"@thw17 I have a patch for this issue -- I am still testing it internally, but it should make it into the next GATK release.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4312#issuecomment-365650170
https://github.com/broadinstitute/gatk/issues/4312#issuecomment-365650170:115,Deployability,release,release,115,"@thw17 I have a patch for this issue -- I am still testing it internally, but it should make it into the next GATK release.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4312#issuecomment-365650170
https://github.com/broadinstitute/gatk/issues/4312#issuecomment-365650170:51,Testability,test,testing,51,"@thw17 I have a patch for this issue -- I am still testing it internally, but it should make it into the next GATK release.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4312#issuecomment-365650170
https://github.com/broadinstitute/gatk/pull/4313#issuecomment-362406085:0,Integrability,Depend,Depends,0,"Depends on what you mean by ""wrong"". They accurately report their truth sensitivity, it just may not do the best job achieving what was requested on the low end.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4313#issuecomment-362406085
https://github.com/broadinstitute/gatk/pull/4314#issuecomment-375064836:49,Testability,test,test,49,"@lbergelson As part of your current set of Spark test runs, can you also test whether this PR appears to work on dataproc?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4314#issuecomment-375064836
https://github.com/broadinstitute/gatk/pull/4314#issuecomment-375064836:73,Testability,test,test,73,"@lbergelson As part of your current set of Spark test runs, can you also test whether this PR appears to work on dataproc?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4314#issuecomment-375064836
https://github.com/broadinstitute/gatk/pull/4315#issuecomment-362048697:3167,Security,validat,validation,3167,YXRpb24vQ2FsY3VsYXRlQ29udGFtaW5hdGlvbi5qYXZh) | `97.207% <0%> (+1.339%)` | `56% <0%> (+18%)` | :arrow_up: |; | [...bender/tools/walkers/mutect/FilterMutectCalls.java](https://codecov.io/gh/broadinstitute/gatk/pull/4315/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9GaWx0ZXJNdXRlY3RDYWxscy5qYXZh) | `97.436% <0%> (+1.603%)` | `13% <0%> (+6%)` | :arrow_up: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/4315/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `73.973% <0%> (+2.74%)` | `11% <0%> (ø)` | :arrow_down: |; | [...ools/walkers/contamination/GetPileupSummaries.java](https://codecov.io/gh/broadinstitute/gatk/pull/4315/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2NvbnRhbWluYXRpb24vR2V0UGlsZXVwU3VtbWFyaWVzLmphdmE=) | `84.286% <0%> (+3.851%)` | `20% <0%> (+4%)` | :arrow_up: |; | [...ellbender/tools/exome/FilterByOrientationBias.java](https://codecov.io/gh/broadinstitute/gatk/pull/4315/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leG9tZS9GaWx0ZXJCeU9yaWVudGF0aW9uQmlhcy5qYXZh) | `86.905% <0%> (+3.886%)` | `21% <0%> (+7%)` | :arrow_up: |; | [...llbender/tools/walkers/validation/Concordance.java](https://codecov.io/gh/broadinstitute/gatk/pull/4315/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vQ29uY29yZGFuY2UuamF2YQ==) | `93.182% <0%> (+4.64%)` | `44% <0%> (+16%)` | :arrow_up: |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/4315/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `90% <0%> (+10%)` | `3% <0%> (ø)` | :arrow_down: |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4315#issuecomment-362048697
https://github.com/broadinstitute/gatk/issues/4317#issuecomment-416667374:51,Testability,test,tests,51,"This overlaps with #3841, so may only need MNP/SNP tests.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4317#issuecomment-416667374
https://github.com/broadinstitute/gatk/issues/4317#issuecomment-416667815:56,Testability,test,test,56,"Get GT from oncotator runs for the new standard somatic test dataset (hg38 trio), then run in Funcotator to compare.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4317#issuecomment-416667815
https://github.com/broadinstitute/gatk/issues/4317#issuecomment-424426872:0,Testability,Test,Test,0,Test with HLA / alternate contigs.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4317#issuecomment-424426872
https://github.com/broadinstitute/gatk/issues/4319#issuecomment-362071370:83,Security,validat,validate,83,"Grr, looks like this slipped by us in #4288. See my comments there---why does this validate in womtool? We got bit by a similar issue in #4281.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4319#issuecomment-362071370
https://github.com/broadinstitute/gatk/issues/4319#issuecomment-362072883:274,Availability,error,errors,274,"Also, the sooner Cromwell handles exposure of subworkflow task-level parameters, the better. I had to make these changes to bubble up and expose all optional parameters for all subworkflows, a process which adds an enormous amount of boilerplate and is (obviously) prone to errors. I plan to revert the changes when Cromwell is ready (#4287), so let me know!. I did not file an issue yet. @LeeTL1220 may have?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4319#issuecomment-362072883
https://github.com/broadinstitute/gatk/issues/4319#issuecomment-362072883:138,Security,expose,expose,138,"Also, the sooner Cromwell handles exposure of subworkflow task-level parameters, the better. I had to make these changes to bubble up and expose all optional parameters for all subworkflows, a process which adds an enormous amount of boilerplate and is (obviously) prone to errors. I plan to revert the changes when Cromwell is ready (#4287), so let me know!. I did not file an issue yet. @LeeTL1220 may have?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4319#issuecomment-362072883
https://github.com/broadinstitute/gatk/issues/4319#issuecomment-362074334:104,Testability,test,tests,104,"Also, @LeeTL1220 @davidbenjamin @jonn-smith I think we need to have some plan for running Oncotator WDL tests on Travis and/or moving everything over to a single Funcotator WDL in the near future.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4319#issuecomment-362074334
https://github.com/broadinstitute/gatk/issues/4319#issuecomment-362086043:91,Deployability,release,release,91,@ruchim would you be able to run the centaur tests on an arbitrary hash? That way we don't release bad WDL.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4319#issuecomment-362086043
https://github.com/broadinstitute/gatk/issues/4319#issuecomment-362086043:67,Security,hash,hash,67,@ruchim would you be able to run the centaur tests on an arbitrary hash? That way we don't release bad WDL.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4319#issuecomment-362086043
https://github.com/broadinstitute/gatk/issues/4319#issuecomment-362086043:45,Testability,test,tests,45,@ruchim would you be able to run the centaur tests on an arbitrary hash? That way we don't release bad WDL.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4319#issuecomment-362086043
https://github.com/broadinstitute/gatk/issues/4319#issuecomment-362118499:76,Deployability,configurat,configuration,76,"Fixing womtool is a bit more complicated, since it affects FireCloud method configuration parameters as well.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4319#issuecomment-362118499
https://github.com/broadinstitute/gatk/issues/4319#issuecomment-362118499:76,Modifiability,config,configuration,76,"Fixing womtool is a bit more complicated, since it affects FireCloud method configuration parameters as well.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4319#issuecomment-362118499
https://github.com/broadinstitute/gatk/pull/4324#issuecomment-362128625:176,Security,expose,exposed,176,"Also note that I decided to append `_for_oncotator` to `additional_args`, since this is sufficiently vague without the suffix. However, analogous suffixes were not appended to exposed optional arguments for other tasks, since their names were less ambiguous. This is the sort of grossness we can do away with once Cromwell handles this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4324#issuecomment-362128625
https://github.com/broadinstitute/gatk/issues/4325#issuecomment-368387079:108,Usability,simpl,simply,108,@cxfustc We have no plans for now to Sparkify Mutect2 because it is trivially parallelizable. In our wdl we simply scatter over disjoint intervals and merge the resulting vcfs. Is there an argument in favor of Spark over this approach?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4325#issuecomment-368387079
https://github.com/broadinstitute/gatk/issues/4325#issuecomment-379885003:241,Deployability,pipeline,pipeline,241,"@davidbenjamin It's actually worth exploring, I think -- with a Spark implementation it is much easier for end-users running the GATK directly to run with multiple cores. Multi-process interval-based parallelism is only trivial when using a pipeline runner. . There is already a beta `HaplotypeCallerSpark` implementation -- it would probably be pretty easy to adapt it to call into a `Mutect2Engine` instead of a `HaplotypeCallerEngine`, I think.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4325#issuecomment-379885003
https://github.com/broadinstitute/gatk/issues/4325#issuecomment-379885003:361,Energy Efficiency,adapt,adapt,361,"@davidbenjamin It's actually worth exploring, I think -- with a Spark implementation it is much easier for end-users running the GATK directly to run with multiple cores. Multi-process interval-based parallelism is only trivial when using a pipeline runner. . There is already a beta `HaplotypeCallerSpark` implementation -- it would probably be pretty easy to adapt it to call into a `Mutect2Engine` instead of a `HaplotypeCallerEngine`, I think.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4325#issuecomment-379885003
https://github.com/broadinstitute/gatk/issues/4325#issuecomment-379885003:361,Modifiability,adapt,adapt,361,"@davidbenjamin It's actually worth exploring, I think -- with a Spark implementation it is much easier for end-users running the GATK directly to run with multiple cores. Multi-process interval-based parallelism is only trivial when using a pipeline runner. . There is already a beta `HaplotypeCallerSpark` implementation -- it would probably be pretty easy to adapt it to call into a `Mutect2Engine` instead of a `HaplotypeCallerEngine`, I think.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4325#issuecomment-379885003
https://github.com/broadinstitute/gatk/issues/4325#issuecomment-382586592:485,Availability,redundant,redundant,485,"Thank you for replying!; I have parallelized the GATK4 Mutect2 using thread pools in Java. I tested the parallelized GATK4 Mutect2 using a WGS data with control. The result came out that, about 0.6% variants were different from the original results. I found that the difference was caused by the random number generator in ReservoirDownsampler. The order of the input intervals after parallelism were different from the original, so the random numbers generated for each position with redundant reads were possibly different. Is there any solutions for this problem?; Thank you very much!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4325#issuecomment-382586592
https://github.com/broadinstitute/gatk/issues/4325#issuecomment-382586592:485,Safety,redund,redundant,485,"Thank you for replying!; I have parallelized the GATK4 Mutect2 using thread pools in Java. I tested the parallelized GATK4 Mutect2 using a WGS data with control. The result came out that, about 0.6% variants were different from the original results. I found that the difference was caused by the random number generator in ReservoirDownsampler. The order of the input intervals after parallelism were different from the original, so the random numbers generated for each position with redundant reads were possibly different. Is there any solutions for this problem?; Thank you very much!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4325#issuecomment-382586592
https://github.com/broadinstitute/gatk/issues/4325#issuecomment-382586592:93,Testability,test,tested,93,"Thank you for replying!; I have parallelized the GATK4 Mutect2 using thread pools in Java. I tested the parallelized GATK4 Mutect2 using a WGS data with control. The result came out that, about 0.6% variants were different from the original results. I found that the difference was caused by the random number generator in ReservoirDownsampler. The order of the input intervals after parallelism were different from the original, so the random numbers generated for each position with redundant reads were possibly different. Is there any solutions for this problem?; Thank you very much!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4325#issuecomment-382586592
https://github.com/broadinstitute/gatk/issues/4325#issuecomment-382756006:104,Availability,down,downsampler,104,@cxfustc I'm curious what the overlap of `PASS` variants after `FilterMutectCalls` is. Usually when the downsampler is invoked the region has very high coverage from mapping errors and almost everything is a false positive. Were you using default parameters?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4325#issuecomment-382756006
https://github.com/broadinstitute/gatk/issues/4325#issuecomment-382756006:174,Availability,error,errors,174,@cxfustc I'm curious what the overlap of `PASS` variants after `FilterMutectCalls` is. Usually when the downsampler is invoked the region has very high coverage from mapping errors and almost everything is a false positive. Were you using default parameters?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4325#issuecomment-382756006
https://github.com/broadinstitute/gatk/issues/4325#issuecomment-385255586:315,Availability,down,downsampling,315,"Sorry for replying so late. I did not expect the reply for my question came so soon until I checked my GitHub today.; Yes, I am using the default parameters. I am not sure about the difference after FilterMutectCalls. I will deal with it next week after going back to work.; As for as I know, the default limit for downsampling is 50, so the theoretical maximum coverage is about 5000, assuming the length of reads are 100bp. This may be an abnormal value for NGS WGS datas, but many NGS panel datas have very high coverages and their average coverages on panel are possibly more than 5000. Is there a model for selecting a proper downsampling limit for these high coverage datas?; Thank you very much!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4325#issuecomment-385255586
https://github.com/broadinstitute/gatk/issues/4325#issuecomment-385255586:631,Availability,down,downsampling,631,"Sorry for replying so late. I did not expect the reply for my question came so soon until I checked my GitHub today.; Yes, I am using the default parameters. I am not sure about the difference after FilterMutectCalls. I will deal with it next week after going back to work.; As for as I know, the default limit for downsampling is 50, so the theoretical maximum coverage is about 5000, assuming the length of reads are 100bp. This may be an abnormal value for NGS WGS datas, but many NGS panel datas have very high coverages and their average coverages on panel are possibly more than 5000. Is there a model for selecting a proper downsampling limit for these high coverage datas?; Thank you very much!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4325#issuecomment-385255586
https://github.com/broadinstitute/gatk/pull/4326#issuecomment-362318471:1571,Usability,Simpl,SimpleNovelAdjacencyInterpreter,1571,=====; Files 1050 1049 -1 ; Lines 59971 60111 +140 ; Branches 9830 9856 +26 ; ===============================================; + Hits 47420 47534 +114 ; - Misses 8743 8758 +15 ; - Partials 3808 3819 +11; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4326?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...ender/tools/spark/sv/utils/GATKSVVCFConstants.java](https://codecov.io/gh/broadinstitute/gatk/pull/4326/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi91dGlscy9HQVRLU1ZWQ0ZDb25zdGFudHMuamF2YQ==) | `75% <ø> (ø)` | `1 <0> (ø)` | :arrow_down: |; | [...ark/sv/discovery/inference/CpxVariantDetector.java](https://codecov.io/gh/broadinstitute/gatk/pull/4326/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvaW5mZXJlbmNlL0NweFZhcmlhbnREZXRlY3Rvci5qYXZh) | `2.604% <0%> (-0.034%)` | `2 <0> (ø)` | |; | [...ery/inference/SimpleNovelAdjacencyInterpreter.java](https://codecov.io/gh/broadinstitute/gatk/pull/4326/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvaW5mZXJlbmNlL1NpbXBsZU5vdmVsQWRqYWNlbmN5SW50ZXJwcmV0ZXIuamF2YQ==) | `100% <100%> (ø)` | `7 <0> (ø)` | :arrow_down: |; | [.../DiscoverVariantsFromContigAlignmentsSAMSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4326/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvRGlzY292ZXJWYXJpYW50c0Zyb21Db250aWdBbGlnbm1lbnRzU0FNU3BhcmsuamF2YQ==) | `93.478% <100%> (+0.22%)` | `22 <1> (+1)` | :arrow_up: |; | [...der/tools/spark/sv/utils/GATKSVVCFHeaderLines.java](https://codecov.io/gh/broadinstitute/gatk/pull/4326/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi91dGlscy9HQVRLU1ZWQ0ZIZWFkZXJMaW5lcy5qYXZh) | `82.258% <100%> (+0.291%)` | `7 <0> (ø)` | :arrow_down: |; | [...ple,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4326#issuecomment-362318471
https://github.com/broadinstitute/gatk/pull/4326#issuecomment-364663550:33,Deployability,configurat,configurations,33,Is it guaranteed that one of the configurations won't include any of the MQ0 regions? Why is that?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4326#issuecomment-364663550
https://github.com/broadinstitute/gatk/pull/4326#issuecomment-364663550:33,Modifiability,config,configurations,33,Is it guaranteed that one of the configurations won't include any of the MQ0 regions? Why is that?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4326#issuecomment-364663550
https://github.com/broadinstitute/gatk/pull/4326#issuecomment-370923522:639,Deployability,configurat,configurations,639,"@cwhelan Thanks for the review! And I apologize for not clearly stating what problem is getting fixed here. I've addressed the comments in separate commit, changed the implementation, made more improvements that were discovered while reviewing the variants ; (https://github.com/SHuang-Broad/GATK-SV-callset-regressionTest/tree/master/Evaluation/Analysis/masterVSfeature/notes.xlsx); The implemented fixes are:; * for removing the hard-coded/explicit mentioning of ""chr"" in non-canonical versions, it is now fixed in 5eff782e4d582d516004fba2cee7535d984b1540; * for contigs whose alignments paint ambiguous picture, i.e. multiple alignment configurations offer equally good explanation:; 	1. if only one configuration has all alignment with MQ above a specified threshold, it is favored; this is implemented in ecc31f5fbec4e524b401fc9474a3a1b7ab08c561; 	2. if one configuration has alignment to non-canonical chromosome that explains the contig better than would-be-event-inducing mappings to canonical chromosomes, the canonical mappings are saved but the better non-canonical mappings are saved as SA tag as in SAM spec, and the VCF record produced is annotated accordingly; this is implemented in 65cdb523a2f9fa2026334713fed45381d76ffc82; * fixed a bug where sometimes an assembly contig as several alignments, only one of which has non-mediocre MQ but at the sametime this alignment contains a large gap, such contigs were previously incorrectly filtered away, they are now salvaged by commit b6b2f197b112981e00efd9d415f010c024d31b36. So, for the FN variants (FN in the sense that they are captured in the stable version of our interpretation tool but now goes missing in the experimental interpretation tool); that were curated in the above-mentioned review, only the following ones are not salvaged, with plans or comments attached. ```; asm012854:tig00000	missing	classified as ""incomplete""; fixable by finishing the last TODO in AssemblyContigAlignmentSignatureClassifier (same problem as face ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4326#issuecomment-370923522
https://github.com/broadinstitute/gatk/pull/4326#issuecomment-370923522:703,Deployability,configurat,configuration,703,"@cwhelan Thanks for the review! And I apologize for not clearly stating what problem is getting fixed here. I've addressed the comments in separate commit, changed the implementation, made more improvements that were discovered while reviewing the variants ; (https://github.com/SHuang-Broad/GATK-SV-callset-regressionTest/tree/master/Evaluation/Analysis/masterVSfeature/notes.xlsx); The implemented fixes are:; * for removing the hard-coded/explicit mentioning of ""chr"" in non-canonical versions, it is now fixed in 5eff782e4d582d516004fba2cee7535d984b1540; * for contigs whose alignments paint ambiguous picture, i.e. multiple alignment configurations offer equally good explanation:; 	1. if only one configuration has all alignment with MQ above a specified threshold, it is favored; this is implemented in ecc31f5fbec4e524b401fc9474a3a1b7ab08c561; 	2. if one configuration has alignment to non-canonical chromosome that explains the contig better than would-be-event-inducing mappings to canonical chromosomes, the canonical mappings are saved but the better non-canonical mappings are saved as SA tag as in SAM spec, and the VCF record produced is annotated accordingly; this is implemented in 65cdb523a2f9fa2026334713fed45381d76ffc82; * fixed a bug where sometimes an assembly contig as several alignments, only one of which has non-mediocre MQ but at the sametime this alignment contains a large gap, such contigs were previously incorrectly filtered away, they are now salvaged by commit b6b2f197b112981e00efd9d415f010c024d31b36. So, for the FN variants (FN in the sense that they are captured in the stable version of our interpretation tool but now goes missing in the experimental interpretation tool); that were curated in the above-mentioned review, only the following ones are not salvaged, with plans or comments attached. ```; asm012854:tig00000	missing	classified as ""incomplete""; fixable by finishing the last TODO in AssemblyContigAlignmentSignatureClassifier (same problem as face ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4326#issuecomment-370923522
https://github.com/broadinstitute/gatk/pull/4326#issuecomment-370923522:863,Deployability,configurat,configuration,863,"provements that were discovered while reviewing the variants ; (https://github.com/SHuang-Broad/GATK-SV-callset-regressionTest/tree/master/Evaluation/Analysis/masterVSfeature/notes.xlsx); The implemented fixes are:; * for removing the hard-coded/explicit mentioning of ""chr"" in non-canonical versions, it is now fixed in 5eff782e4d582d516004fba2cee7535d984b1540; * for contigs whose alignments paint ambiguous picture, i.e. multiple alignment configurations offer equally good explanation:; 	1. if only one configuration has all alignment with MQ above a specified threshold, it is favored; this is implemented in ecc31f5fbec4e524b401fc9474a3a1b7ab08c561; 	2. if one configuration has alignment to non-canonical chromosome that explains the contig better than would-be-event-inducing mappings to canonical chromosomes, the canonical mappings are saved but the better non-canonical mappings are saved as SA tag as in SAM spec, and the VCF record produced is annotated accordingly; this is implemented in 65cdb523a2f9fa2026334713fed45381d76ffc82; * fixed a bug where sometimes an assembly contig as several alignments, only one of which has non-mediocre MQ but at the sametime this alignment contains a large gap, such contigs were previously incorrectly filtered away, they are now salvaged by commit b6b2f197b112981e00efd9d415f010c024d31b36. So, for the FN variants (FN in the sense that they are captured in the stable version of our interpretation tool but now goes missing in the experimental interpretation tool); that were curated in the above-mentioned review, only the following ones are not salvaged, with plans or comments attached. ```; asm012854:tig00000	missing	classified as ""incomplete""; fixable by finishing the last TODO in AssemblyContigAlignmentSignatureClassifier (same problem as face by group represented by asm002398:tig00001); asm014580:tig00018	missing	classified as ""incomplete""; fixable by finishing the last TODO in AssemblyContigAlignmentSignatureClassifier (same problem ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4326#issuecomment-370923522
https://github.com/broadinstitute/gatk/pull/4326#issuecomment-370923522:639,Modifiability,config,configurations,639,"@cwhelan Thanks for the review! And I apologize for not clearly stating what problem is getting fixed here. I've addressed the comments in separate commit, changed the implementation, made more improvements that were discovered while reviewing the variants ; (https://github.com/SHuang-Broad/GATK-SV-callset-regressionTest/tree/master/Evaluation/Analysis/masterVSfeature/notes.xlsx); The implemented fixes are:; * for removing the hard-coded/explicit mentioning of ""chr"" in non-canonical versions, it is now fixed in 5eff782e4d582d516004fba2cee7535d984b1540; * for contigs whose alignments paint ambiguous picture, i.e. multiple alignment configurations offer equally good explanation:; 	1. if only one configuration has all alignment with MQ above a specified threshold, it is favored; this is implemented in ecc31f5fbec4e524b401fc9474a3a1b7ab08c561; 	2. if one configuration has alignment to non-canonical chromosome that explains the contig better than would-be-event-inducing mappings to canonical chromosomes, the canonical mappings are saved but the better non-canonical mappings are saved as SA tag as in SAM spec, and the VCF record produced is annotated accordingly; this is implemented in 65cdb523a2f9fa2026334713fed45381d76ffc82; * fixed a bug where sometimes an assembly contig as several alignments, only one of which has non-mediocre MQ but at the sametime this alignment contains a large gap, such contigs were previously incorrectly filtered away, they are now salvaged by commit b6b2f197b112981e00efd9d415f010c024d31b36. So, for the FN variants (FN in the sense that they are captured in the stable version of our interpretation tool but now goes missing in the experimental interpretation tool); that were curated in the above-mentioned review, only the following ones are not salvaged, with plans or comments attached. ```; asm012854:tig00000	missing	classified as ""incomplete""; fixable by finishing the last TODO in AssemblyContigAlignmentSignatureClassifier (same problem as face ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4326#issuecomment-370923522
https://github.com/broadinstitute/gatk/pull/4326#issuecomment-370923522:703,Modifiability,config,configuration,703,"@cwhelan Thanks for the review! And I apologize for not clearly stating what problem is getting fixed here. I've addressed the comments in separate commit, changed the implementation, made more improvements that were discovered while reviewing the variants ; (https://github.com/SHuang-Broad/GATK-SV-callset-regressionTest/tree/master/Evaluation/Analysis/masterVSfeature/notes.xlsx); The implemented fixes are:; * for removing the hard-coded/explicit mentioning of ""chr"" in non-canonical versions, it is now fixed in 5eff782e4d582d516004fba2cee7535d984b1540; * for contigs whose alignments paint ambiguous picture, i.e. multiple alignment configurations offer equally good explanation:; 	1. if only one configuration has all alignment with MQ above a specified threshold, it is favored; this is implemented in ecc31f5fbec4e524b401fc9474a3a1b7ab08c561; 	2. if one configuration has alignment to non-canonical chromosome that explains the contig better than would-be-event-inducing mappings to canonical chromosomes, the canonical mappings are saved but the better non-canonical mappings are saved as SA tag as in SAM spec, and the VCF record produced is annotated accordingly; this is implemented in 65cdb523a2f9fa2026334713fed45381d76ffc82; * fixed a bug where sometimes an assembly contig as several alignments, only one of which has non-mediocre MQ but at the sametime this alignment contains a large gap, such contigs were previously incorrectly filtered away, they are now salvaged by commit b6b2f197b112981e00efd9d415f010c024d31b36. So, for the FN variants (FN in the sense that they are captured in the stable version of our interpretation tool but now goes missing in the experimental interpretation tool); that were curated in the above-mentioned review, only the following ones are not salvaged, with plans or comments attached. ```; asm012854:tig00000	missing	classified as ""incomplete""; fixable by finishing the last TODO in AssemblyContigAlignmentSignatureClassifier (same problem as face ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4326#issuecomment-370923522
https://github.com/broadinstitute/gatk/pull/4326#issuecomment-370923522:863,Modifiability,config,configuration,863,"provements that were discovered while reviewing the variants ; (https://github.com/SHuang-Broad/GATK-SV-callset-regressionTest/tree/master/Evaluation/Analysis/masterVSfeature/notes.xlsx); The implemented fixes are:; * for removing the hard-coded/explicit mentioning of ""chr"" in non-canonical versions, it is now fixed in 5eff782e4d582d516004fba2cee7535d984b1540; * for contigs whose alignments paint ambiguous picture, i.e. multiple alignment configurations offer equally good explanation:; 	1. if only one configuration has all alignment with MQ above a specified threshold, it is favored; this is implemented in ecc31f5fbec4e524b401fc9474a3a1b7ab08c561; 	2. if one configuration has alignment to non-canonical chromosome that explains the contig better than would-be-event-inducing mappings to canonical chromosomes, the canonical mappings are saved but the better non-canonical mappings are saved as SA tag as in SAM spec, and the VCF record produced is annotated accordingly; this is implemented in 65cdb523a2f9fa2026334713fed45381d76ffc82; * fixed a bug where sometimes an assembly contig as several alignments, only one of which has non-mediocre MQ but at the sametime this alignment contains a large gap, such contigs were previously incorrectly filtered away, they are now salvaged by commit b6b2f197b112981e00efd9d415f010c024d31b36. So, for the FN variants (FN in the sense that they are captured in the stable version of our interpretation tool but now goes missing in the experimental interpretation tool); that were curated in the above-mentioned review, only the following ones are not salvaged, with plans or comments attached. ```; asm012854:tig00000	missing	classified as ""incomplete""; fixable by finishing the last TODO in AssemblyContigAlignmentSignatureClassifier (same problem as face by group represented by asm002398:tig00001); asm014580:tig00018	missing	classified as ""incomplete""; fixable by finishing the last TODO in AssemblyContigAlignmentSignatureClassifier (same problem ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4326#issuecomment-370923522
https://github.com/broadinstitute/gatk/pull/4326#issuecomment-370923522:56,Usability,clear,clearly,56,"@cwhelan Thanks for the review! And I apologize for not clearly stating what problem is getting fixed here. I've addressed the comments in separate commit, changed the implementation, made more improvements that were discovered while reviewing the variants ; (https://github.com/SHuang-Broad/GATK-SV-callset-regressionTest/tree/master/Evaluation/Analysis/masterVSfeature/notes.xlsx); The implemented fixes are:; * for removing the hard-coded/explicit mentioning of ""chr"" in non-canonical versions, it is now fixed in 5eff782e4d582d516004fba2cee7535d984b1540; * for contigs whose alignments paint ambiguous picture, i.e. multiple alignment configurations offer equally good explanation:; 	1. if only one configuration has all alignment with MQ above a specified threshold, it is favored; this is implemented in ecc31f5fbec4e524b401fc9474a3a1b7ab08c561; 	2. if one configuration has alignment to non-canonical chromosome that explains the contig better than would-be-event-inducing mappings to canonical chromosomes, the canonical mappings are saved but the better non-canonical mappings are saved as SA tag as in SAM spec, and the VCF record produced is annotated accordingly; this is implemented in 65cdb523a2f9fa2026334713fed45381d76ffc82; * fixed a bug where sometimes an assembly contig as several alignments, only one of which has non-mediocre MQ but at the sametime this alignment contains a large gap, such contigs were previously incorrectly filtered away, they are now salvaged by commit b6b2f197b112981e00efd9d415f010c024d31b36. So, for the FN variants (FN in the sense that they are captured in the stable version of our interpretation tool but now goes missing in the experimental interpretation tool); that were curated in the above-mentioned review, only the following ones are not salvaged, with plans or comments attached. ```; asm012854:tig00000	missing	classified as ""incomplete""; fixable by finishing the last TODO in AssemblyContigAlignmentSignatureClassifier (same problem as face ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4326#issuecomment-370923522
https://github.com/broadinstitute/gatk/pull/4326#issuecomment-370923522:2788,Usability,simpl,simple,2788,"ical chromosomes, the canonical mappings are saved but the better non-canonical mappings are saved as SA tag as in SAM spec, and the VCF record produced is annotated accordingly; this is implemented in 65cdb523a2f9fa2026334713fed45381d76ffc82; * fixed a bug where sometimes an assembly contig as several alignments, only one of which has non-mediocre MQ but at the sametime this alignment contains a large gap, such contigs were previously incorrectly filtered away, they are now salvaged by commit b6b2f197b112981e00efd9d415f010c024d31b36. So, for the FN variants (FN in the sense that they are captured in the stable version of our interpretation tool but now goes missing in the experimental interpretation tool); that were curated in the above-mentioned review, only the following ones are not salvaged, with plans or comments attached. ```; asm012854:tig00000	missing	classified as ""incomplete""; fixable by finishing the last TODO in AssemblyContigAlignmentSignatureClassifier (same problem as face by group represented by asm002398:tig00001); asm014580:tig00018	missing	classified as ""incomplete""; fixable by finishing the last TODO in AssemblyContigAlignmentSignatureClassifier (same problem as face by group represented by asm002398:tig00001); asm008185:tig00000	missing	classified as ""ambiguous""; unsure of how to deal with a general rule--exact same part of read coverred by one mapping to canonical, one to non-canonical (better AS); if save the canonical, a deletion would be called; asm018220:tig00004	missing	classified as ""ambiguous""; salvagable if re-analysed through old interpretation tool; asm026229:tig00000	missing	classified as ""ambiguous""; fixable if implement a special rule making all split alignments on non-canonical chromosomes as ""bad""; ```. They are relatively simple fixes so I clumped them into a single PR.; If you prefer to review them as separate PR's. I can do that too.; Thanks!; [report.sam.gz](https://github.com/broadinstitute/gatk/files/1786690/report.sam.gz)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4326#issuecomment-370923522
https://github.com/broadinstitute/gatk/issues/4327#issuecomment-376960734:66,Modifiability,refactor,refactoring,66,"@sooheelee As an initial attempt to address this without too much refactoring, what about a two-step process where the user runs M2 with all samples eg `-I normal.bam -I tumor1.bam -I tumor2.bam -tumor sample1 -tumor sample2` (this would require a small code change to specify `-tumor` more than once) and then uses the common set of variants in GGA mode (PR #4601) on each sample individually?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4327#issuecomment-376960734
https://github.com/broadinstitute/gatk/issues/4329#issuecomment-362531334:256,Testability,Test,Tests,256,"Maybe the way is to check the returned value inside `PicardCommandLineProgramExecutor` and throw a `PicardCommandNonZeroExit` exception containing a field with the exit code, that can be handled in `Main` with a special function (as user exception, etc.). Tests for checking the exit code returned by `mainEntry` can be found in https://github.com/broadinstitute/gatk/pull/4283.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4329#issuecomment-362531334
https://github.com/broadinstitute/gatk/pull/4330#issuecomment-372761525:211,Availability,avail,available,211,"Hi @cwhelan , I've expanded this PR to do more than what it originally was trying to fix, and separated the patches by commits as usual:. * the originally proposed fix, which brings back the annotation that are available to simple variants but go missing due to a careless bug, is now done in commit 50f1b640a31ddb528dc763b83b26a9d98dce8556; this commit also accordingly refactors the giant class `CpxVariantDetector` into three new classes; * in the 2nd commit 734516383fb665a79796de76535560fc03cb754b, I did more refactoring on how we group the descriptions for the annotation keys, and updated the test VCF files accordingly.; * because of the refactoring, the review comments were gone, so I added them back in the 3rd commit b7619c45a949dfba21d65a5ed876bc72e832aa77, which contains the comments and my replies. They come in as TODO's but are going to be removed ultimately; * in the following commits, I added tests for the CPX code path, selecting three representative cases (there's no limit how complex the scenario can go). One particular commit 224c97c7b736e94ed6b4d8b067ec830a9f8f2403 is large but most of it is for adding a flat file that contains the chromosome names in hg38 and their lengths for building a bare bone sequence dictionary used in building test data.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4330#issuecomment-372761525
https://github.com/broadinstitute/gatk/pull/4330#issuecomment-372761525:108,Deployability,patch,patches,108,"Hi @cwhelan , I've expanded this PR to do more than what it originally was trying to fix, and separated the patches by commits as usual:. * the originally proposed fix, which brings back the annotation that are available to simple variants but go missing due to a careless bug, is now done in commit 50f1b640a31ddb528dc763b83b26a9d98dce8556; this commit also accordingly refactors the giant class `CpxVariantDetector` into three new classes; * in the 2nd commit 734516383fb665a79796de76535560fc03cb754b, I did more refactoring on how we group the descriptions for the annotation keys, and updated the test VCF files accordingly.; * because of the refactoring, the review comments were gone, so I added them back in the 3rd commit b7619c45a949dfba21d65a5ed876bc72e832aa77, which contains the comments and my replies. They come in as TODO's but are going to be removed ultimately; * in the following commits, I added tests for the CPX code path, selecting three representative cases (there's no limit how complex the scenario can go). One particular commit 224c97c7b736e94ed6b4d8b067ec830a9f8f2403 is large but most of it is for adding a flat file that contains the chromosome names in hg38 and their lengths for building a bare bone sequence dictionary used in building test data.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4330#issuecomment-372761525
https://github.com/broadinstitute/gatk/pull/4330#issuecomment-372761525:589,Deployability,update,updated,589,"Hi @cwhelan , I've expanded this PR to do more than what it originally was trying to fix, and separated the patches by commits as usual:. * the originally proposed fix, which brings back the annotation that are available to simple variants but go missing due to a careless bug, is now done in commit 50f1b640a31ddb528dc763b83b26a9d98dce8556; this commit also accordingly refactors the giant class `CpxVariantDetector` into three new classes; * in the 2nd commit 734516383fb665a79796de76535560fc03cb754b, I did more refactoring on how we group the descriptions for the annotation keys, and updated the test VCF files accordingly.; * because of the refactoring, the review comments were gone, so I added them back in the 3rd commit b7619c45a949dfba21d65a5ed876bc72e832aa77, which contains the comments and my replies. They come in as TODO's but are going to be removed ultimately; * in the following commits, I added tests for the CPX code path, selecting three representative cases (there's no limit how complex the scenario can go). One particular commit 224c97c7b736e94ed6b4d8b067ec830a9f8f2403 is large but most of it is for adding a flat file that contains the chromosome names in hg38 and their lengths for building a bare bone sequence dictionary used in building test data.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4330#issuecomment-372761525
https://github.com/broadinstitute/gatk/pull/4330#issuecomment-372761525:371,Modifiability,refactor,refactors,371,"Hi @cwhelan , I've expanded this PR to do more than what it originally was trying to fix, and separated the patches by commits as usual:. * the originally proposed fix, which brings back the annotation that are available to simple variants but go missing due to a careless bug, is now done in commit 50f1b640a31ddb528dc763b83b26a9d98dce8556; this commit also accordingly refactors the giant class `CpxVariantDetector` into three new classes; * in the 2nd commit 734516383fb665a79796de76535560fc03cb754b, I did more refactoring on how we group the descriptions for the annotation keys, and updated the test VCF files accordingly.; * because of the refactoring, the review comments were gone, so I added them back in the 3rd commit b7619c45a949dfba21d65a5ed876bc72e832aa77, which contains the comments and my replies. They come in as TODO's but are going to be removed ultimately; * in the following commits, I added tests for the CPX code path, selecting three representative cases (there's no limit how complex the scenario can go). One particular commit 224c97c7b736e94ed6b4d8b067ec830a9f8f2403 is large but most of it is for adding a flat file that contains the chromosome names in hg38 and their lengths for building a bare bone sequence dictionary used in building test data.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4330#issuecomment-372761525
https://github.com/broadinstitute/gatk/pull/4330#issuecomment-372761525:515,Modifiability,refactor,refactoring,515,"Hi @cwhelan , I've expanded this PR to do more than what it originally was trying to fix, and separated the patches by commits as usual:. * the originally proposed fix, which brings back the annotation that are available to simple variants but go missing due to a careless bug, is now done in commit 50f1b640a31ddb528dc763b83b26a9d98dce8556; this commit also accordingly refactors the giant class `CpxVariantDetector` into three new classes; * in the 2nd commit 734516383fb665a79796de76535560fc03cb754b, I did more refactoring on how we group the descriptions for the annotation keys, and updated the test VCF files accordingly.; * because of the refactoring, the review comments were gone, so I added them back in the 3rd commit b7619c45a949dfba21d65a5ed876bc72e832aa77, which contains the comments and my replies. They come in as TODO's but are going to be removed ultimately; * in the following commits, I added tests for the CPX code path, selecting three representative cases (there's no limit how complex the scenario can go). One particular commit 224c97c7b736e94ed6b4d8b067ec830a9f8f2403 is large but most of it is for adding a flat file that contains the chromosome names in hg38 and their lengths for building a bare bone sequence dictionary used in building test data.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4330#issuecomment-372761525
https://github.com/broadinstitute/gatk/pull/4330#issuecomment-372761525:647,Modifiability,refactor,refactoring,647,"Hi @cwhelan , I've expanded this PR to do more than what it originally was trying to fix, and separated the patches by commits as usual:. * the originally proposed fix, which brings back the annotation that are available to simple variants but go missing due to a careless bug, is now done in commit 50f1b640a31ddb528dc763b83b26a9d98dce8556; this commit also accordingly refactors the giant class `CpxVariantDetector` into three new classes; * in the 2nd commit 734516383fb665a79796de76535560fc03cb754b, I did more refactoring on how we group the descriptions for the annotation keys, and updated the test VCF files accordingly.; * because of the refactoring, the review comments were gone, so I added them back in the 3rd commit b7619c45a949dfba21d65a5ed876bc72e832aa77, which contains the comments and my replies. They come in as TODO's but are going to be removed ultimately; * in the following commits, I added tests for the CPX code path, selecting three representative cases (there's no limit how complex the scenario can go). One particular commit 224c97c7b736e94ed6b4d8b067ec830a9f8f2403 is large but most of it is for adding a flat file that contains the chromosome names in hg38 and their lengths for building a bare bone sequence dictionary used in building test data.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4330#issuecomment-372761525
https://github.com/broadinstitute/gatk/pull/4330#issuecomment-372761525:601,Testability,test,test,601,"Hi @cwhelan , I've expanded this PR to do more than what it originally was trying to fix, and separated the patches by commits as usual:. * the originally proposed fix, which brings back the annotation that are available to simple variants but go missing due to a careless bug, is now done in commit 50f1b640a31ddb528dc763b83b26a9d98dce8556; this commit also accordingly refactors the giant class `CpxVariantDetector` into three new classes; * in the 2nd commit 734516383fb665a79796de76535560fc03cb754b, I did more refactoring on how we group the descriptions for the annotation keys, and updated the test VCF files accordingly.; * because of the refactoring, the review comments were gone, so I added them back in the 3rd commit b7619c45a949dfba21d65a5ed876bc72e832aa77, which contains the comments and my replies. They come in as TODO's but are going to be removed ultimately; * in the following commits, I added tests for the CPX code path, selecting three representative cases (there's no limit how complex the scenario can go). One particular commit 224c97c7b736e94ed6b4d8b067ec830a9f8f2403 is large but most of it is for adding a flat file that contains the chromosome names in hg38 and their lengths for building a bare bone sequence dictionary used in building test data.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4330#issuecomment-372761525
https://github.com/broadinstitute/gatk/pull/4330#issuecomment-372761525:915,Testability,test,tests,915,"Hi @cwhelan , I've expanded this PR to do more than what it originally was trying to fix, and separated the patches by commits as usual:. * the originally proposed fix, which brings back the annotation that are available to simple variants but go missing due to a careless bug, is now done in commit 50f1b640a31ddb528dc763b83b26a9d98dce8556; this commit also accordingly refactors the giant class `CpxVariantDetector` into three new classes; * in the 2nd commit 734516383fb665a79796de76535560fc03cb754b, I did more refactoring on how we group the descriptions for the annotation keys, and updated the test VCF files accordingly.; * because of the refactoring, the review comments were gone, so I added them back in the 3rd commit b7619c45a949dfba21d65a5ed876bc72e832aa77, which contains the comments and my replies. They come in as TODO's but are going to be removed ultimately; * in the following commits, I added tests for the CPX code path, selecting three representative cases (there's no limit how complex the scenario can go). One particular commit 224c97c7b736e94ed6b4d8b067ec830a9f8f2403 is large but most of it is for adding a flat file that contains the chromosome names in hg38 and their lengths for building a bare bone sequence dictionary used in building test data.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4330#issuecomment-372761525
https://github.com/broadinstitute/gatk/pull/4330#issuecomment-372761525:1269,Testability,test,test,1269,"Hi @cwhelan , I've expanded this PR to do more than what it originally was trying to fix, and separated the patches by commits as usual:. * the originally proposed fix, which brings back the annotation that are available to simple variants but go missing due to a careless bug, is now done in commit 50f1b640a31ddb528dc763b83b26a9d98dce8556; this commit also accordingly refactors the giant class `CpxVariantDetector` into three new classes; * in the 2nd commit 734516383fb665a79796de76535560fc03cb754b, I did more refactoring on how we group the descriptions for the annotation keys, and updated the test VCF files accordingly.; * because of the refactoring, the review comments were gone, so I added them back in the 3rd commit b7619c45a949dfba21d65a5ed876bc72e832aa77, which contains the comments and my replies. They come in as TODO's but are going to be removed ultimately; * in the following commits, I added tests for the CPX code path, selecting three representative cases (there's no limit how complex the scenario can go). One particular commit 224c97c7b736e94ed6b4d8b067ec830a9f8f2403 is large but most of it is for adding a flat file that contains the chromosome names in hg38 and their lengths for building a bare bone sequence dictionary used in building test data.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4330#issuecomment-372761525
https://github.com/broadinstitute/gatk/pull/4330#issuecomment-372761525:224,Usability,simpl,simple,224,"Hi @cwhelan , I've expanded this PR to do more than what it originally was trying to fix, and separated the patches by commits as usual:. * the originally proposed fix, which brings back the annotation that are available to simple variants but go missing due to a careless bug, is now done in commit 50f1b640a31ddb528dc763b83b26a9d98dce8556; this commit also accordingly refactors the giant class `CpxVariantDetector` into three new classes; * in the 2nd commit 734516383fb665a79796de76535560fc03cb754b, I did more refactoring on how we group the descriptions for the annotation keys, and updated the test VCF files accordingly.; * because of the refactoring, the review comments were gone, so I added them back in the 3rd commit b7619c45a949dfba21d65a5ed876bc72e832aa77, which contains the comments and my replies. They come in as TODO's but are going to be removed ultimately; * in the following commits, I added tests for the CPX code path, selecting three representative cases (there's no limit how complex the scenario can go). One particular commit 224c97c7b736e94ed6b4d8b067ec830a9f8f2403 is large but most of it is for adding a flat file that contains the chromosome names in hg38 and their lengths for building a bare bone sequence dictionary used in building test data.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4330#issuecomment-372761525
https://github.com/broadinstitute/gatk/issues/4331#issuecomment-371210732:7,Availability,ping,pinged,7,Nalini pinged me about this again. Any idea when someone will have the time?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4331#issuecomment-371210732
https://github.com/broadinstitute/gatk/issues/4331#issuecomment-372392590:0,Deployability,Update,Update,0,"Update on this: @kgururaj will try to provide us with a GATK branch that uses the GenomicsDB fork this week, and ask Gans's team for help if he's not able to build it himself.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4331#issuecomment-372392590
https://github.com/broadinstitute/gatk/issues/4332#issuecomment-362655529:117,Deployability,update,update,117,"I used to have it in there, but once I got copy performance up I assumed it was just clutter. I need to make a minor update to the scripts anyway (option to run the debug program instead of the full pipeline) so I can put back the option to not copy fastq files as well.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4332#issuecomment-362655529
https://github.com/broadinstitute/gatk/issues/4332#issuecomment-362655529:199,Deployability,pipeline,pipeline,199,"I used to have it in there, but once I got copy performance up I assumed it was just clutter. I need to make a minor update to the scripts anyway (option to run the debug program instead of the full pipeline) so I can put back the option to not copy fastq files as well.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4332#issuecomment-362655529
https://github.com/broadinstitute/gatk/issues/4332#issuecomment-362655529:48,Performance,perform,performance,48,"I used to have it in there, but once I got copy performance up I assumed it was just clutter. I need to make a minor update to the scripts anyway (option to run the debug program instead of the full pipeline) so I can put back the option to not copy fastq files as well.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4332#issuecomment-362655529
https://github.com/broadinstitute/gatk/issues/4334#issuecomment-364228046:190,Testability,test,testing,190,"@droazen I didn't specify `-Xmx`, just gave more memory to the server (up to 32GB). The most memory BQSR consumed before it failed was about 28GB: ``Runtime.totalMemory()=28631367680``. I'm testing to see if scattering BaseRecalibrator and then calling GatherBQSRReports would help",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4334#issuecomment-364228046
https://github.com/broadinstitute/gatk/pull/4335#issuecomment-362858342:50,Testability,log,log,50,hmm... travis python fails and very uninformative log (tests pass locally),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4335#issuecomment-362858342
https://github.com/broadinstitute/gatk/pull/4335#issuecomment-362858342:55,Testability,test,tests,55,hmm... travis python fails and very uninformative log (tests pass locally),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4335#issuecomment-362858342
https://github.com/broadinstitute/gatk/pull/4335#issuecomment-363108424:119,Deployability,integrat,integration,119,"Did you figure out why Travis is failing? Also, I think this PR needs at least one test---you can just add to the gCNV integration tests for now, but we should extract out the HMM code and its tests at some point.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4335#issuecomment-363108424
https://github.com/broadinstitute/gatk/pull/4335#issuecomment-363108424:119,Integrability,integrat,integration,119,"Did you figure out why Travis is failing? Also, I think this PR needs at least one test---you can just add to the gCNV integration tests for now, but we should extract out the HMM code and its tests at some point.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4335#issuecomment-363108424
https://github.com/broadinstitute/gatk/pull/4335#issuecomment-363108424:83,Testability,test,test---you,83,"Did you figure out why Travis is failing? Also, I think this PR needs at least one test---you can just add to the gCNV integration tests for now, but we should extract out the HMM code and its tests at some point.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4335#issuecomment-363108424
https://github.com/broadinstitute/gatk/pull/4335#issuecomment-363108424:131,Testability,test,tests,131,"Did you figure out why Travis is failing? Also, I think this PR needs at least one test---you can just add to the gCNV integration tests for now, but we should extract out the HMM code and its tests at some point.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4335#issuecomment-363108424
https://github.com/broadinstitute/gatk/pull/4335#issuecomment-363108424:193,Testability,test,tests,193,"Did you figure out why Travis is failing? Also, I think this PR needs at least one test---you can just add to the gCNV integration tests for now, but we should extract out the HMM code and its tests at some point.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4335#issuecomment-363108424
https://github.com/broadinstitute/gatk/pull/4335#issuecomment-363548654:219,Deployability,update,update,219,"@samuelklee this PR adds new features to `gcnvkernel` (postprocessing) that are not currently invoked by any GATK tool. Ideally, we need python unit tests for such PRs, but right now, perhaps the tests can wait until I update `PostprocessGermlineCNVCalls`?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4335#issuecomment-363548654
https://github.com/broadinstitute/gatk/pull/4335#issuecomment-363548654:149,Testability,test,tests,149,"@samuelklee this PR adds new features to `gcnvkernel` (postprocessing) that are not currently invoked by any GATK tool. Ideally, we need python unit tests for such PRs, but right now, perhaps the tests can wait until I update `PostprocessGermlineCNVCalls`?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4335#issuecomment-363548654
https://github.com/broadinstitute/gatk/pull/4335#issuecomment-363548654:196,Testability,test,tests,196,"@samuelklee this PR adds new features to `gcnvkernel` (postprocessing) that are not currently invoked by any GATK tool. Ideally, we need python unit tests for such PRs, but right now, perhaps the tests can wait until I update `PostprocessGermlineCNVCalls`?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4335#issuecomment-363548654
https://github.com/broadinstitute/gatk/issues/4337#issuecomment-363122927:88,Usability,simpl,simple,88,@stefandiederich Thanks for reporting this. We'll have to take a look if it's something simple that can be changed in our code or something fundamental in the way spark process filenames.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4337#issuecomment-363122927
https://github.com/broadinstitute/gatk/issues/4337#issuecomment-363331462:72,Usability,simpl,simple,72,"@lbergelson Thanks for your quick reply! Hopefully it is just something simple. But I think it's nothing to with spark, because SortReadFileSpark can process filepath with umlauts. For example a path like `/media/Ergebnisse/1399-17_Exom (Neuromuskulär)_NB501654_0052/1399-17.recal.bam`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4337#issuecomment-363331462
https://github.com/broadinstitute/gatk/issues/4340#issuecomment-363390940:931,Integrability,Interface,Interfaces,931,"Nice that HTSJDK is moving forward to version 3. The points that I would like to address are similar to yours, with some inclussions. * Regarding NIO support, I would go to remove completely `File` support. If API users need to use the `File` abstraction, they should convert to a `java.nio.Path` using the `toPath` method.; * In addition, I would like that HTTP/S and FTP is handled also with NIO. For HTTP/S, I am working in a simple `FileSystemProvider` that should be good enough for using in combination with HTSJDK ([jsr203-http](https://github.com/magicDGS/jsr203-http)), and I can speed up the development there for needs in HTSJDK; for FTP, maybe [ftp-fs](https://github.com/robtimus/ftp-fs) can be used or a simple implementation can be derived from the HTTP/S implementation (without credentials). This will remove the special handling of HTTP/S and FTP paths in HTSJDK in favor of a consistent and pluggable manner.; * Interfaces for the data types are great, and maybe it will be good to have codec interfaces for both encoding and decoding. For example, I am missing encoders in tribble (an attempt in https://github.com/samtools/htsjdk/pull/822 for writing support).; * For VCF, I would like to have a less diploid-centric interface and design, or at least a way of configure the catching of genotype-related attributes. Currently there are methods for homozygotes/heterozygotes that aren't really useful for triploids or even VCFs without variation (for example, in Pool-Seq data).; * Modular design for artifacts: thus, a project with only SAM/BAM requirements will require only `htsjdk-sam`, and if they also want CRAM support, `htsjdk-cram`. See https://github.com/samtools/htsjdk/issues/896 for more info about it.; * Common license for all HTSJDK, or at least for each module. This will be good for taking into account legal concerns when including the library, because now there is a mixture depending on the files that are used. This is what is coming to my mind now. Maybe I ad",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4340#issuecomment-363390940
https://github.com/broadinstitute/gatk/issues/4340#issuecomment-363390940:1012,Integrability,interface,interfaces,1012,"Nice that HTSJDK is moving forward to version 3. The points that I would like to address are similar to yours, with some inclussions. * Regarding NIO support, I would go to remove completely `File` support. If API users need to use the `File` abstraction, they should convert to a `java.nio.Path` using the `toPath` method.; * In addition, I would like that HTTP/S and FTP is handled also with NIO. For HTTP/S, I am working in a simple `FileSystemProvider` that should be good enough for using in combination with HTSJDK ([jsr203-http](https://github.com/magicDGS/jsr203-http)), and I can speed up the development there for needs in HTSJDK; for FTP, maybe [ftp-fs](https://github.com/robtimus/ftp-fs) can be used or a simple implementation can be derived from the HTTP/S implementation (without credentials). This will remove the special handling of HTTP/S and FTP paths in HTSJDK in favor of a consistent and pluggable manner.; * Interfaces for the data types are great, and maybe it will be good to have codec interfaces for both encoding and decoding. For example, I am missing encoders in tribble (an attempt in https://github.com/samtools/htsjdk/pull/822 for writing support).; * For VCF, I would like to have a less diploid-centric interface and design, or at least a way of configure the catching of genotype-related attributes. Currently there are methods for homozygotes/heterozygotes that aren't really useful for triploids or even VCFs without variation (for example, in Pool-Seq data).; * Modular design for artifacts: thus, a project with only SAM/BAM requirements will require only `htsjdk-sam`, and if they also want CRAM support, `htsjdk-cram`. See https://github.com/samtools/htsjdk/issues/896 for more info about it.; * Common license for all HTSJDK, or at least for each module. This will be good for taking into account legal concerns when including the library, because now there is a mixture depending on the files that are used. This is what is coming to my mind now. Maybe I ad",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4340#issuecomment-363390940
https://github.com/broadinstitute/gatk/issues/4340#issuecomment-363390940:1238,Integrability,interface,interface,1238,"ould like to address are similar to yours, with some inclussions. * Regarding NIO support, I would go to remove completely `File` support. If API users need to use the `File` abstraction, they should convert to a `java.nio.Path` using the `toPath` method.; * In addition, I would like that HTTP/S and FTP is handled also with NIO. For HTTP/S, I am working in a simple `FileSystemProvider` that should be good enough for using in combination with HTSJDK ([jsr203-http](https://github.com/magicDGS/jsr203-http)), and I can speed up the development there for needs in HTSJDK; for FTP, maybe [ftp-fs](https://github.com/robtimus/ftp-fs) can be used or a simple implementation can be derived from the HTTP/S implementation (without credentials). This will remove the special handling of HTTP/S and FTP paths in HTSJDK in favor of a consistent and pluggable manner.; * Interfaces for the data types are great, and maybe it will be good to have codec interfaces for both encoding and decoding. For example, I am missing encoders in tribble (an attempt in https://github.com/samtools/htsjdk/pull/822 for writing support).; * For VCF, I would like to have a less diploid-centric interface and design, or at least a way of configure the catching of genotype-related attributes. Currently there are methods for homozygotes/heterozygotes that aren't really useful for triploids or even VCFs without variation (for example, in Pool-Seq data).; * Modular design for artifacts: thus, a project with only SAM/BAM requirements will require only `htsjdk-sam`, and if they also want CRAM support, `htsjdk-cram`. See https://github.com/samtools/htsjdk/issues/896 for more info about it.; * Common license for all HTSJDK, or at least for each module. This will be good for taking into account legal concerns when including the library, because now there is a mixture depending on the files that are used. This is what is coming to my mind now. Maybe I added something else in https://github.com/samtools/htsjdk/issues/520",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4340#issuecomment-363390940
https://github.com/broadinstitute/gatk/issues/4340#issuecomment-363390940:1914,Integrability,depend,depending,1914,"ould like to address are similar to yours, with some inclussions. * Regarding NIO support, I would go to remove completely `File` support. If API users need to use the `File` abstraction, they should convert to a `java.nio.Path` using the `toPath` method.; * In addition, I would like that HTTP/S and FTP is handled also with NIO. For HTTP/S, I am working in a simple `FileSystemProvider` that should be good enough for using in combination with HTSJDK ([jsr203-http](https://github.com/magicDGS/jsr203-http)), and I can speed up the development there for needs in HTSJDK; for FTP, maybe [ftp-fs](https://github.com/robtimus/ftp-fs) can be used or a simple implementation can be derived from the HTTP/S implementation (without credentials). This will remove the special handling of HTTP/S and FTP paths in HTSJDK in favor of a consistent and pluggable manner.; * Interfaces for the data types are great, and maybe it will be good to have codec interfaces for both encoding and decoding. For example, I am missing encoders in tribble (an attempt in https://github.com/samtools/htsjdk/pull/822 for writing support).; * For VCF, I would like to have a less diploid-centric interface and design, or at least a way of configure the catching of genotype-related attributes. Currently there are methods for homozygotes/heterozygotes that aren't really useful for triploids or even VCFs without variation (for example, in Pool-Seq data).; * Modular design for artifacts: thus, a project with only SAM/BAM requirements will require only `htsjdk-sam`, and if they also want CRAM support, `htsjdk-cram`. See https://github.com/samtools/htsjdk/issues/896 for more info about it.; * Common license for all HTSJDK, or at least for each module. This will be good for taking into account legal concerns when including the library, because now there is a mixture depending on the files that are used. This is what is coming to my mind now. Maybe I added something else in https://github.com/samtools/htsjdk/issues/520",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4340#issuecomment-363390940
https://github.com/broadinstitute/gatk/issues/4340#issuecomment-363390940:1281,Modifiability,config,configure,1281,"ould like to address are similar to yours, with some inclussions. * Regarding NIO support, I would go to remove completely `File` support. If API users need to use the `File` abstraction, they should convert to a `java.nio.Path` using the `toPath` method.; * In addition, I would like that HTTP/S and FTP is handled also with NIO. For HTTP/S, I am working in a simple `FileSystemProvider` that should be good enough for using in combination with HTSJDK ([jsr203-http](https://github.com/magicDGS/jsr203-http)), and I can speed up the development there for needs in HTSJDK; for FTP, maybe [ftp-fs](https://github.com/robtimus/ftp-fs) can be used or a simple implementation can be derived from the HTTP/S implementation (without credentials). This will remove the special handling of HTTP/S and FTP paths in HTSJDK in favor of a consistent and pluggable manner.; * Interfaces for the data types are great, and maybe it will be good to have codec interfaces for both encoding and decoding. For example, I am missing encoders in tribble (an attempt in https://github.com/samtools/htsjdk/pull/822 for writing support).; * For VCF, I would like to have a less diploid-centric interface and design, or at least a way of configure the catching of genotype-related attributes. Currently there are methods for homozygotes/heterozygotes that aren't really useful for triploids or even VCFs without variation (for example, in Pool-Seq data).; * Modular design for artifacts: thus, a project with only SAM/BAM requirements will require only `htsjdk-sam`, and if they also want CRAM support, `htsjdk-cram`. See https://github.com/samtools/htsjdk/issues/896 for more info about it.; * Common license for all HTSJDK, or at least for each module. This will be good for taking into account legal concerns when including the library, because now there is a mixture depending on the files that are used. This is what is coming to my mind now. Maybe I added something else in https://github.com/samtools/htsjdk/issues/520",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4340#issuecomment-363390940
https://github.com/broadinstitute/gatk/issues/4340#issuecomment-363390940:429,Usability,simpl,simple,429,"Nice that HTSJDK is moving forward to version 3. The points that I would like to address are similar to yours, with some inclussions. * Regarding NIO support, I would go to remove completely `File` support. If API users need to use the `File` abstraction, they should convert to a `java.nio.Path` using the `toPath` method.; * In addition, I would like that HTTP/S and FTP is handled also with NIO. For HTTP/S, I am working in a simple `FileSystemProvider` that should be good enough for using in combination with HTSJDK ([jsr203-http](https://github.com/magicDGS/jsr203-http)), and I can speed up the development there for needs in HTSJDK; for FTP, maybe [ftp-fs](https://github.com/robtimus/ftp-fs) can be used or a simple implementation can be derived from the HTTP/S implementation (without credentials). This will remove the special handling of HTTP/S and FTP paths in HTSJDK in favor of a consistent and pluggable manner.; * Interfaces for the data types are great, and maybe it will be good to have codec interfaces for both encoding and decoding. For example, I am missing encoders in tribble (an attempt in https://github.com/samtools/htsjdk/pull/822 for writing support).; * For VCF, I would like to have a less diploid-centric interface and design, or at least a way of configure the catching of genotype-related attributes. Currently there are methods for homozygotes/heterozygotes that aren't really useful for triploids or even VCFs without variation (for example, in Pool-Seq data).; * Modular design for artifacts: thus, a project with only SAM/BAM requirements will require only `htsjdk-sam`, and if they also want CRAM support, `htsjdk-cram`. See https://github.com/samtools/htsjdk/issues/896 for more info about it.; * Common license for all HTSJDK, or at least for each module. This will be good for taking into account legal concerns when including the library, because now there is a mixture depending on the files that are used. This is what is coming to my mind now. Maybe I ad",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4340#issuecomment-363390940
https://github.com/broadinstitute/gatk/issues/4340#issuecomment-363390940:718,Usability,simpl,simple,718,"Nice that HTSJDK is moving forward to version 3. The points that I would like to address are similar to yours, with some inclussions. * Regarding NIO support, I would go to remove completely `File` support. If API users need to use the `File` abstraction, they should convert to a `java.nio.Path` using the `toPath` method.; * In addition, I would like that HTTP/S and FTP is handled also with NIO. For HTTP/S, I am working in a simple `FileSystemProvider` that should be good enough for using in combination with HTSJDK ([jsr203-http](https://github.com/magicDGS/jsr203-http)), and I can speed up the development there for needs in HTSJDK; for FTP, maybe [ftp-fs](https://github.com/robtimus/ftp-fs) can be used or a simple implementation can be derived from the HTTP/S implementation (without credentials). This will remove the special handling of HTTP/S and FTP paths in HTSJDK in favor of a consistent and pluggable manner.; * Interfaces for the data types are great, and maybe it will be good to have codec interfaces for both encoding and decoding. For example, I am missing encoders in tribble (an attempt in https://github.com/samtools/htsjdk/pull/822 for writing support).; * For VCF, I would like to have a less diploid-centric interface and design, or at least a way of configure the catching of genotype-related attributes. Currently there are methods for homozygotes/heterozygotes that aren't really useful for triploids or even VCFs without variation (for example, in Pool-Seq data).; * Modular design for artifacts: thus, a project with only SAM/BAM requirements will require only `htsjdk-sam`, and if they also want CRAM support, `htsjdk-cram`. See https://github.com/samtools/htsjdk/issues/896 for more info about it.; * Common license for all HTSJDK, or at least for each module. This will be good for taking into account legal concerns when including the library, because now there is a mixture depending on the files that are used. This is what is coming to my mind now. Maybe I ad",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4340#issuecomment-363390940
https://github.com/broadinstitute/gatk/issues/4340#issuecomment-371401288:100,Availability,down,downstream,100,"Another thing that just come to my mind is to rely on [SLF4J](https://www.slf4j.org/) for logging - downstream projects can configure which logger they want to use, and they can have their own ways of setting logging verbosity. If the logging system from HTSJDK wants to be maintain, it can also add a simple implementation of SLF4J with the verbosity levels that are in the current implementation.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4340#issuecomment-371401288
https://github.com/broadinstitute/gatk/issues/4340#issuecomment-371401288:124,Modifiability,config,configure,124,"Another thing that just come to my mind is to rely on [SLF4J](https://www.slf4j.org/) for logging - downstream projects can configure which logger they want to use, and they can have their own ways of setting logging verbosity. If the logging system from HTSJDK wants to be maintain, it can also add a simple implementation of SLF4J with the verbosity levels that are in the current implementation.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4340#issuecomment-371401288
https://github.com/broadinstitute/gatk/issues/4340#issuecomment-371401288:90,Testability,log,logging,90,"Another thing that just come to my mind is to rely on [SLF4J](https://www.slf4j.org/) for logging - downstream projects can configure which logger they want to use, and they can have their own ways of setting logging verbosity. If the logging system from HTSJDK wants to be maintain, it can also add a simple implementation of SLF4J with the verbosity levels that are in the current implementation.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4340#issuecomment-371401288
https://github.com/broadinstitute/gatk/issues/4340#issuecomment-371401288:140,Testability,log,logger,140,"Another thing that just come to my mind is to rely on [SLF4J](https://www.slf4j.org/) for logging - downstream projects can configure which logger they want to use, and they can have their own ways of setting logging verbosity. If the logging system from HTSJDK wants to be maintain, it can also add a simple implementation of SLF4J with the verbosity levels that are in the current implementation.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4340#issuecomment-371401288
https://github.com/broadinstitute/gatk/issues/4340#issuecomment-371401288:209,Testability,log,logging,209,"Another thing that just come to my mind is to rely on [SLF4J](https://www.slf4j.org/) for logging - downstream projects can configure which logger they want to use, and they can have their own ways of setting logging verbosity. If the logging system from HTSJDK wants to be maintain, it can also add a simple implementation of SLF4J with the verbosity levels that are in the current implementation.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4340#issuecomment-371401288
https://github.com/broadinstitute/gatk/issues/4340#issuecomment-371401288:235,Testability,log,logging,235,"Another thing that just come to my mind is to rely on [SLF4J](https://www.slf4j.org/) for logging - downstream projects can configure which logger they want to use, and they can have their own ways of setting logging verbosity. If the logging system from HTSJDK wants to be maintain, it can also add a simple implementation of SLF4J with the verbosity levels that are in the current implementation.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4340#issuecomment-371401288
https://github.com/broadinstitute/gatk/issues/4340#issuecomment-371401288:302,Usability,simpl,simple,302,"Another thing that just come to my mind is to rely on [SLF4J](https://www.slf4j.org/) for logging - downstream projects can configure which logger they want to use, and they can have their own ways of setting logging verbosity. If the logging system from HTSJDK wants to be maintain, it can also add a simple implementation of SLF4J with the verbosity levels that are in the current implementation.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4340#issuecomment-371401288
https://github.com/broadinstitute/gatk/issues/4341#issuecomment-363209925:600,Deployability,pipeline,pipeline,600,"This looks like a good start! I'm not quite sure how you are planning to handle dictionary validation, specifically, but you can take a look at the CNV plotting tools (PlotDenoisedCopyRatios and PlotModeledSegments) to see what level of validation we currently do. We can discuss further in person if you like. (Also, note that those tools take a sequence dictionary as an input to specify which contigs should be plotted; typically, this will be a subset of the full dictionary that excludes alt contigs, etc. Requiring this sequence-dictionary input is somewhat vestigial; previous versions of the pipeline did not include dictionaries in the headers of all CNV data files. Part of making these tools into GATKTools could include switching over to -L to specify regions for plotting.). Finally, are the changes to `-imr` mentioned in #2471 going to be addressed in a separate issue?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4341#issuecomment-363209925
https://github.com/broadinstitute/gatk/issues/4341#issuecomment-363209925:91,Security,validat,validation,91,"This looks like a good start! I'm not quite sure how you are planning to handle dictionary validation, specifically, but you can take a look at the CNV plotting tools (PlotDenoisedCopyRatios and PlotModeledSegments) to see what level of validation we currently do. We can discuss further in person if you like. (Also, note that those tools take a sequence dictionary as an input to specify which contigs should be plotted; typically, this will be a subset of the full dictionary that excludes alt contigs, etc. Requiring this sequence-dictionary input is somewhat vestigial; previous versions of the pipeline did not include dictionaries in the headers of all CNV data files. Part of making these tools into GATKTools could include switching over to -L to specify regions for plotting.). Finally, are the changes to `-imr` mentioned in #2471 going to be addressed in a separate issue?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4341#issuecomment-363209925
https://github.com/broadinstitute/gatk/issues/4341#issuecomment-363209925:237,Security,validat,validation,237,"This looks like a good start! I'm not quite sure how you are planning to handle dictionary validation, specifically, but you can take a look at the CNV plotting tools (PlotDenoisedCopyRatios and PlotModeledSegments) to see what level of validation we currently do. We can discuss further in person if you like. (Also, note that those tools take a sequence dictionary as an input to specify which contigs should be plotted; typically, this will be a subset of the full dictionary that excludes alt contigs, etc. Requiring this sequence-dictionary input is somewhat vestigial; previous versions of the pipeline did not include dictionaries in the headers of all CNV data files. Part of making these tools into GATKTools could include switching over to -L to specify regions for plotting.). Finally, are the changes to `-imr` mentioned in #2471 going to be addressed in a separate issue?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4341#issuecomment-363209925
https://github.com/broadinstitute/gatk/issues/4341#issuecomment-363219857:74,Performance,perform,perform,74,"Overriding the defaults would get us most of the way there. Right now, we perform the following check on the IAC and fail if the defaults aren't changed to values that the CNV tools require, which is awkward:. ```; /**; * Validate that the interval-argument collection parameters minimally modify the input intervals.; */; public static void validateIntervalArgumentCollection(final IntervalArgumentCollection intervalArgumentCollection) {; Utils.validateArg(intervalArgumentCollection.getIntervalSetRule() == IntervalSetRule.UNION,; ""Interval set rule must be set to UNION."");; Utils.validateArg(intervalArgumentCollection.getIntervalExclusionPadding() == 0,; ""Interval exclusion padding must be set to 0."");; Utils.validateArg(intervalArgumentCollection.getIntervalPadding() == 0,; ""Interval padding must be set to 0."");; Utils.validateArg(intervalArgumentCollection.getIntervalMergingRule() == IntervalMergingRule.OVERLAPPING_ONLY,; ""Interval merging rule must be set to OVERLAPPING_ONLY."");; }; ```. If we override defaults, we'd still perform the check to make sure the user didn't muck with them, but it'd still be nicer than forcing the user to change the original defaults on their own. However, there are still two more awkward points: 1) there is no value for `-interval-set-rule` that does *nothing* to the incoming intervals (you must either union or intersect), and 2) we have to specify our own `padding` argument in `PreprocessIntervals` that is distinct from `-interval-padding`, since we want to implement our own padding. The first can be easily addressed by adding an option to do nothing to the intervals; I'm not so sure what the best way to handle the second would be, so we can punt on it if it'd be more work than it's worth---these are relatively minor pain points, in the end.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4341#issuecomment-363219857
https://github.com/broadinstitute/gatk/issues/4341#issuecomment-363219857:1040,Performance,perform,perform,1040,"Overriding the defaults would get us most of the way there. Right now, we perform the following check on the IAC and fail if the defaults aren't changed to values that the CNV tools require, which is awkward:. ```; /**; * Validate that the interval-argument collection parameters minimally modify the input intervals.; */; public static void validateIntervalArgumentCollection(final IntervalArgumentCollection intervalArgumentCollection) {; Utils.validateArg(intervalArgumentCollection.getIntervalSetRule() == IntervalSetRule.UNION,; ""Interval set rule must be set to UNION."");; Utils.validateArg(intervalArgumentCollection.getIntervalExclusionPadding() == 0,; ""Interval exclusion padding must be set to 0."");; Utils.validateArg(intervalArgumentCollection.getIntervalPadding() == 0,; ""Interval padding must be set to 0."");; Utils.validateArg(intervalArgumentCollection.getIntervalMergingRule() == IntervalMergingRule.OVERLAPPING_ONLY,; ""Interval merging rule must be set to OVERLAPPING_ONLY."");; }; ```. If we override defaults, we'd still perform the check to make sure the user didn't muck with them, but it'd still be nicer than forcing the user to change the original defaults on their own. However, there are still two more awkward points: 1) there is no value for `-interval-set-rule` that does *nothing* to the incoming intervals (you must either union or intersect), and 2) we have to specify our own `padding` argument in `PreprocessIntervals` that is distinct from `-interval-padding`, since we want to implement our own padding. The first can be easily addressed by adding an option to do nothing to the intervals; I'm not so sure what the best way to handle the second would be, so we can punt on it if it'd be more work than it's worth---these are relatively minor pain points, in the end.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4341#issuecomment-363219857
https://github.com/broadinstitute/gatk/issues/4341#issuecomment-363219857:222,Security,Validat,Validate,222,"Overriding the defaults would get us most of the way there. Right now, we perform the following check on the IAC and fail if the defaults aren't changed to values that the CNV tools require, which is awkward:. ```; /**; * Validate that the interval-argument collection parameters minimally modify the input intervals.; */; public static void validateIntervalArgumentCollection(final IntervalArgumentCollection intervalArgumentCollection) {; Utils.validateArg(intervalArgumentCollection.getIntervalSetRule() == IntervalSetRule.UNION,; ""Interval set rule must be set to UNION."");; Utils.validateArg(intervalArgumentCollection.getIntervalExclusionPadding() == 0,; ""Interval exclusion padding must be set to 0."");; Utils.validateArg(intervalArgumentCollection.getIntervalPadding() == 0,; ""Interval padding must be set to 0."");; Utils.validateArg(intervalArgumentCollection.getIntervalMergingRule() == IntervalMergingRule.OVERLAPPING_ONLY,; ""Interval merging rule must be set to OVERLAPPING_ONLY."");; }; ```. If we override defaults, we'd still perform the check to make sure the user didn't muck with them, but it'd still be nicer than forcing the user to change the original defaults on their own. However, there are still two more awkward points: 1) there is no value for `-interval-set-rule` that does *nothing* to the incoming intervals (you must either union or intersect), and 2) we have to specify our own `padding` argument in `PreprocessIntervals` that is distinct from `-interval-padding`, since we want to implement our own padding. The first can be easily addressed by adding an option to do nothing to the intervals; I'm not so sure what the best way to handle the second would be, so we can punt on it if it'd be more work than it's worth---these are relatively minor pain points, in the end.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4341#issuecomment-363219857
https://github.com/broadinstitute/gatk/issues/4341#issuecomment-363219857:342,Security,validat,validateIntervalArgumentCollection,342,"Overriding the defaults would get us most of the way there. Right now, we perform the following check on the IAC and fail if the defaults aren't changed to values that the CNV tools require, which is awkward:. ```; /**; * Validate that the interval-argument collection parameters minimally modify the input intervals.; */; public static void validateIntervalArgumentCollection(final IntervalArgumentCollection intervalArgumentCollection) {; Utils.validateArg(intervalArgumentCollection.getIntervalSetRule() == IntervalSetRule.UNION,; ""Interval set rule must be set to UNION."");; Utils.validateArg(intervalArgumentCollection.getIntervalExclusionPadding() == 0,; ""Interval exclusion padding must be set to 0."");; Utils.validateArg(intervalArgumentCollection.getIntervalPadding() == 0,; ""Interval padding must be set to 0."");; Utils.validateArg(intervalArgumentCollection.getIntervalMergingRule() == IntervalMergingRule.OVERLAPPING_ONLY,; ""Interval merging rule must be set to OVERLAPPING_ONLY."");; }; ```. If we override defaults, we'd still perform the check to make sure the user didn't muck with them, but it'd still be nicer than forcing the user to change the original defaults on their own. However, there are still two more awkward points: 1) there is no value for `-interval-set-rule` that does *nothing* to the incoming intervals (you must either union or intersect), and 2) we have to specify our own `padding` argument in `PreprocessIntervals` that is distinct from `-interval-padding`, since we want to implement our own padding. The first can be easily addressed by adding an option to do nothing to the intervals; I'm not so sure what the best way to handle the second would be, so we can punt on it if it'd be more work than it's worth---these are relatively minor pain points, in the end.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4341#issuecomment-363219857
https://github.com/broadinstitute/gatk/issues/4341#issuecomment-363219857:447,Security,validat,validateArg,447,"Overriding the defaults would get us most of the way there. Right now, we perform the following check on the IAC and fail if the defaults aren't changed to values that the CNV tools require, which is awkward:. ```; /**; * Validate that the interval-argument collection parameters minimally modify the input intervals.; */; public static void validateIntervalArgumentCollection(final IntervalArgumentCollection intervalArgumentCollection) {; Utils.validateArg(intervalArgumentCollection.getIntervalSetRule() == IntervalSetRule.UNION,; ""Interval set rule must be set to UNION."");; Utils.validateArg(intervalArgumentCollection.getIntervalExclusionPadding() == 0,; ""Interval exclusion padding must be set to 0."");; Utils.validateArg(intervalArgumentCollection.getIntervalPadding() == 0,; ""Interval padding must be set to 0."");; Utils.validateArg(intervalArgumentCollection.getIntervalMergingRule() == IntervalMergingRule.OVERLAPPING_ONLY,; ""Interval merging rule must be set to OVERLAPPING_ONLY."");; }; ```. If we override defaults, we'd still perform the check to make sure the user didn't muck with them, but it'd still be nicer than forcing the user to change the original defaults on their own. However, there are still two more awkward points: 1) there is no value for `-interval-set-rule` that does *nothing* to the incoming intervals (you must either union or intersect), and 2) we have to specify our own `padding` argument in `PreprocessIntervals` that is distinct from `-interval-padding`, since we want to implement our own padding. The first can be easily addressed by adding an option to do nothing to the intervals; I'm not so sure what the best way to handle the second would be, so we can punt on it if it'd be more work than it's worth---these are relatively minor pain points, in the end.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4341#issuecomment-363219857
https://github.com/broadinstitute/gatk/issues/4341#issuecomment-363219857:585,Security,validat,validateArg,585,"Overriding the defaults would get us most of the way there. Right now, we perform the following check on the IAC and fail if the defaults aren't changed to values that the CNV tools require, which is awkward:. ```; /**; * Validate that the interval-argument collection parameters minimally modify the input intervals.; */; public static void validateIntervalArgumentCollection(final IntervalArgumentCollection intervalArgumentCollection) {; Utils.validateArg(intervalArgumentCollection.getIntervalSetRule() == IntervalSetRule.UNION,; ""Interval set rule must be set to UNION."");; Utils.validateArg(intervalArgumentCollection.getIntervalExclusionPadding() == 0,; ""Interval exclusion padding must be set to 0."");; Utils.validateArg(intervalArgumentCollection.getIntervalPadding() == 0,; ""Interval padding must be set to 0."");; Utils.validateArg(intervalArgumentCollection.getIntervalMergingRule() == IntervalMergingRule.OVERLAPPING_ONLY,; ""Interval merging rule must be set to OVERLAPPING_ONLY."");; }; ```. If we override defaults, we'd still perform the check to make sure the user didn't muck with them, but it'd still be nicer than forcing the user to change the original defaults on their own. However, there are still two more awkward points: 1) there is no value for `-interval-set-rule` that does *nothing* to the incoming intervals (you must either union or intersect), and 2) we have to specify our own `padding` argument in `PreprocessIntervals` that is distinct from `-interval-padding`, since we want to implement our own padding. The first can be easily addressed by adding an option to do nothing to the intervals; I'm not so sure what the best way to handle the second would be, so we can punt on it if it'd be more work than it's worth---these are relatively minor pain points, in the end.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4341#issuecomment-363219857
https://github.com/broadinstitute/gatk/issues/4341#issuecomment-363219857:717,Security,validat,validateArg,717,"Overriding the defaults would get us most of the way there. Right now, we perform the following check on the IAC and fail if the defaults aren't changed to values that the CNV tools require, which is awkward:. ```; /**; * Validate that the interval-argument collection parameters minimally modify the input intervals.; */; public static void validateIntervalArgumentCollection(final IntervalArgumentCollection intervalArgumentCollection) {; Utils.validateArg(intervalArgumentCollection.getIntervalSetRule() == IntervalSetRule.UNION,; ""Interval set rule must be set to UNION."");; Utils.validateArg(intervalArgumentCollection.getIntervalExclusionPadding() == 0,; ""Interval exclusion padding must be set to 0."");; Utils.validateArg(intervalArgumentCollection.getIntervalPadding() == 0,; ""Interval padding must be set to 0."");; Utils.validateArg(intervalArgumentCollection.getIntervalMergingRule() == IntervalMergingRule.OVERLAPPING_ONLY,; ""Interval merging rule must be set to OVERLAPPING_ONLY."");; }; ```. If we override defaults, we'd still perform the check to make sure the user didn't muck with them, but it'd still be nicer than forcing the user to change the original defaults on their own. However, there are still two more awkward points: 1) there is no value for `-interval-set-rule` that does *nothing* to the incoming intervals (you must either union or intersect), and 2) we have to specify our own `padding` argument in `PreprocessIntervals` that is distinct from `-interval-padding`, since we want to implement our own padding. The first can be easily addressed by adding an option to do nothing to the intervals; I'm not so sure what the best way to handle the second would be, so we can punt on it if it'd be more work than it's worth---these are relatively minor pain points, in the end.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4341#issuecomment-363219857
https://github.com/broadinstitute/gatk/issues/4341#issuecomment-363219857:830,Security,validat,validateArg,830,"Overriding the defaults would get us most of the way there. Right now, we perform the following check on the IAC and fail if the defaults aren't changed to values that the CNV tools require, which is awkward:. ```; /**; * Validate that the interval-argument collection parameters minimally modify the input intervals.; */; public static void validateIntervalArgumentCollection(final IntervalArgumentCollection intervalArgumentCollection) {; Utils.validateArg(intervalArgumentCollection.getIntervalSetRule() == IntervalSetRule.UNION,; ""Interval set rule must be set to UNION."");; Utils.validateArg(intervalArgumentCollection.getIntervalExclusionPadding() == 0,; ""Interval exclusion padding must be set to 0."");; Utils.validateArg(intervalArgumentCollection.getIntervalPadding() == 0,; ""Interval padding must be set to 0."");; Utils.validateArg(intervalArgumentCollection.getIntervalMergingRule() == IntervalMergingRule.OVERLAPPING_ONLY,; ""Interval merging rule must be set to OVERLAPPING_ONLY."");; }; ```. If we override defaults, we'd still perform the check to make sure the user didn't muck with them, but it'd still be nicer than forcing the user to change the original defaults on their own. However, there are still two more awkward points: 1) there is no value for `-interval-set-rule` that does *nothing* to the incoming intervals (you must either union or intersect), and 2) we have to specify our own `padding` argument in `PreprocessIntervals` that is distinct from `-interval-padding`, since we want to implement our own padding. The first can be easily addressed by adding an option to do nothing to the intervals; I'm not so sure what the best way to handle the second would be, so we can punt on it if it'd be more work than it's worth---these are relatively minor pain points, in the end.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4341#issuecomment-363219857
https://github.com/broadinstitute/gatk/issues/4341#issuecomment-367810395:91,Security,expose,exposed,91,"Note #4439, which concerns a Picard tool that might also need options for interval merging exposed. Just something to be aware of---I'm guessing that it's probably a bit ambitious to have identical options for all interval inputs to both Picard and GATK tools?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4341#issuecomment-367810395
https://github.com/broadinstitute/gatk/issues/4341#issuecomment-483829878:233,Modifiability,extend,extend,233,"One part of this ticket is done: https://github.com/broadinstitute/gatk/pull/4964 added accessors that allow direct descendants of `GATKTool` to directly access engine datasources, while still forbidding direct access for tools that extend a Walker base class (except for Walker types living in the engine package, which still have access).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4341#issuecomment-483829878
https://github.com/broadinstitute/gatk/issues/4341#issuecomment-483829878:88,Security,access,accessors,88,"One part of this ticket is done: https://github.com/broadinstitute/gatk/pull/4964 added accessors that allow direct descendants of `GATKTool` to directly access engine datasources, while still forbidding direct access for tools that extend a Walker base class (except for Walker types living in the engine package, which still have access).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4341#issuecomment-483829878
https://github.com/broadinstitute/gatk/issues/4341#issuecomment-483829878:154,Security,access,access,154,"One part of this ticket is done: https://github.com/broadinstitute/gatk/pull/4964 added accessors that allow direct descendants of `GATKTool` to directly access engine datasources, while still forbidding direct access for tools that extend a Walker base class (except for Walker types living in the engine package, which still have access).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4341#issuecomment-483829878
https://github.com/broadinstitute/gatk/issues/4341#issuecomment-483829878:211,Security,access,access,211,"One part of this ticket is done: https://github.com/broadinstitute/gatk/pull/4964 added accessors that allow direct descendants of `GATKTool` to directly access engine datasources, while still forbidding direct access for tools that extend a Walker base class (except for Walker types living in the engine package, which still have access).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4341#issuecomment-483829878
https://github.com/broadinstitute/gatk/issues/4341#issuecomment-483829878:332,Security,access,access,332,"One part of this ticket is done: https://github.com/broadinstitute/gatk/pull/4964 added accessors that allow direct descendants of `GATKTool` to directly access engine datasources, while still forbidding direct access for tools that extend a Walker base class (except for Walker types living in the engine package, which still have access).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4341#issuecomment-483829878
https://github.com/broadinstitute/gatk/issues/4344#issuecomment-417011954:74,Testability,test,test,74,This should be done in the soon-to-be-merged `FuncotatorEngine` as a unit test.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4344#issuecomment-417011954
https://github.com/broadinstitute/gatk/issues/4346#issuecomment-367372810:55,Deployability,release,release,55,@ameynert The fix just went in. It will be in the next release.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4346#issuecomment-367372810
https://github.com/broadinstitute/gatk/issues/4349#issuecomment-364556039:49,Deployability,release,release,49,"Hey David. This will be a tool again in the next release? Users have been asking about generating VCF index, and I have pointed them to IGV or tabix or samtools. I think this has been disabled in the latest point release.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4349#issuecomment-364556039
https://github.com/broadinstitute/gatk/issues/4349#issuecomment-364556039:213,Deployability,release,release,213,"Hey David. This will be a tool again in the next release? Users have been asking about generating VCF index, and I have pointed them to IGV or tabix or samtools. I think this has been disabled in the latest point release.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4349#issuecomment-364556039
https://github.com/broadinstitute/gatk/issues/4349#issuecomment-364556950:78,Deployability,release,releases,78,@chandrans `IndexFeatureFile` has been enabled and runnable in all of the 4.x releases so far. It was only disabled temporarily in one of the betas.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4349#issuecomment-364556950
https://github.com/broadinstitute/gatk/issues/4349#issuecomment-364564262:39,Testability,test,tested,39,"Yes, you are right. Sorry, I must have tested with a beta version and thought it was disabled. It does work in 4.0.1.1 :) I will have to let users know.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4349#issuecomment-364564262
https://github.com/broadinstitute/gatk/pull/4350#issuecomment-363248723:9,Security,expose,exposed,9,This has exposed a dumb bug in our tests. It turns out we rely on the exact output of VariantContext.toString() Will fix. https://storage.googleapis.com/hellbender-test-logs/build_reports/lb_update_to_htsjdk_2.14.2_17106.2/tests/test/index.html,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4350#issuecomment-363248723
https://github.com/broadinstitute/gatk/pull/4350#issuecomment-363248723:35,Testability,test,tests,35,This has exposed a dumb bug in our tests. It turns out we rely on the exact output of VariantContext.toString() Will fix. https://storage.googleapis.com/hellbender-test-logs/build_reports/lb_update_to_htsjdk_2.14.2_17106.2/tests/test/index.html,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4350#issuecomment-363248723
https://github.com/broadinstitute/gatk/pull/4350#issuecomment-363248723:164,Testability,test,test-logs,164,This has exposed a dumb bug in our tests. It turns out we rely on the exact output of VariantContext.toString() Will fix. https://storage.googleapis.com/hellbender-test-logs/build_reports/lb_update_to_htsjdk_2.14.2_17106.2/tests/test/index.html,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4350#issuecomment-363248723
https://github.com/broadinstitute/gatk/pull/4350#issuecomment-363248723:223,Testability,test,tests,223,This has exposed a dumb bug in our tests. It turns out we rely on the exact output of VariantContext.toString() Will fix. https://storage.googleapis.com/hellbender-test-logs/build_reports/lb_update_to_htsjdk_2.14.2_17106.2/tests/test/index.html,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4350#issuecomment-363248723
https://github.com/broadinstitute/gatk/pull/4350#issuecomment-363248723:229,Testability,test,test,229,This has exposed a dumb bug in our tests. It turns out we rely on the exact output of VariantContext.toString() Will fix. https://storage.googleapis.com/hellbender-test-logs/build_reports/lb_update_to_htsjdk_2.14.2_17106.2/tests/test/index.html,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4350#issuecomment-363248723
https://github.com/broadinstitute/gatk/pull/4352#issuecomment-363255647:64,Testability,log,logic,64,"@ldgauthier Could you take a look at this? I changed a bunch of logic to bring it inline with modern tool design. I think it's right, but maybe I'm breaking something that I didn't understand?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4352#issuecomment-363255647
https://github.com/broadinstitute/gatk/pull/4352#issuecomment-367117807:70,Testability,test,tests,70,@ldgauthier I undid that change that made no sense and added some new tests so it doesn't happen again.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4352#issuecomment-367117807
https://github.com/broadinstitute/gatk/pull/4354#issuecomment-363826093:47,Deployability,release,release,47,@mbabadi Can we get this in for the next point release? (I know it's a very long PR...) Thanks!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4354#issuecomment-363826093
https://github.com/broadinstitute/gatk/pull/4356#issuecomment-364257090:40,Deployability,continuous,continuous,40,This PR will have to wait until we have continuous testing up and running for the AVX2 implementation of `SmithWaterman`,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4356#issuecomment-364257090
https://github.com/broadinstitute/gatk/pull/4356#issuecomment-364257090:51,Testability,test,testing,51,This PR will have to wait until we have continuous testing up and running for the AVX2 implementation of `SmithWaterman`,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4356#issuecomment-364257090
https://github.com/broadinstitute/gatk/pull/4356#issuecomment-415862887:117,Modifiability,config,configure,117,I think we can finally unblock this using PAPIv2's ability to request machine types on Google Cloud. We just have to configure our jenkins server to use PAPIv2.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4356#issuecomment-415862887
https://github.com/broadinstitute/gatk/issues/4358#issuecomment-378327894:37,Deployability,update,update,37,This has since been fixed in another update.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4358#issuecomment-378327894
https://github.com/broadinstitute/gatk/issues/4359#issuecomment-400394943:384,Deployability,integrat,integrated,384,"- Add a CLI flag `--exclude-field-name` which can be specified multiple times.; For example `... --exclude-field-name Clinvar_bar --exclude-field-name Clinvar_foo ...`. We will specify the column names with the full field name: `<datasourcename>_<fieldname>`. For now, we specify via an `exclude`. If nothing is specified, then show everything. - Make sure that this new parameter is integrated into the config file framework as implemented by #4581",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4359#issuecomment-400394943
https://github.com/broadinstitute/gatk/issues/4359#issuecomment-400394943:384,Integrability,integrat,integrated,384,"- Add a CLI flag `--exclude-field-name` which can be specified multiple times.; For example `... --exclude-field-name Clinvar_bar --exclude-field-name Clinvar_foo ...`. We will specify the column names with the full field name: `<datasourcename>_<fieldname>`. For now, we specify via an `exclude`. If nothing is specified, then show everything. - Make sure that this new parameter is integrated into the config file framework as implemented by #4581",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4359#issuecomment-400394943
https://github.com/broadinstitute/gatk/issues/4359#issuecomment-400394943:404,Modifiability,config,config,404,"- Add a CLI flag `--exclude-field-name` which can be specified multiple times.; For example `... --exclude-field-name Clinvar_bar --exclude-field-name Clinvar_foo ...`. We will specify the column names with the full field name: `<datasourcename>_<fieldname>`. For now, we specify via an `exclude`. If nothing is specified, then show everything. - Make sure that this new parameter is integrated into the config file framework as implemented by #4581",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4359#issuecomment-400394943
https://github.com/broadinstitute/gatk/pull/4360#issuecomment-363621429:0,Testability,Test,Tests,0,Tests are failing. Should I still review?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4360#issuecomment-363621429
https://github.com/broadinstitute/gatk/pull/4360#issuecomment-363628675:245,Deployability,pipeline,pipelines,245,"Can I ask why you guys still have GetSampleName as a separate tool? At some point I cribbed the code there into a CNV utility method, MetadataUtils.readSampleName(samFileHeader). Is the point to support multi-sample BAMs as input to M2 (the CNV pipelines currently do not, should they)?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4360#issuecomment-363628675
https://github.com/broadinstitute/gatk/pull/4360#issuecomment-363792322:95,Testability,test,tests,95,"@LeeTL1220 Whoops, surprise side effects. I think I resolved them but you may as well wait for tests to pass.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4360#issuecomment-363792322
https://github.com/broadinstitute/gatk/pull/4360#issuecomment-363978914:95,Availability,down,downsides---I,95,"Gotcha. I was thinking that the order of the `-I` could be used, but that probably has its own downsides---I guess it's better to fail earlier than to accidentally run with the tumor and normal swapped.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4360#issuecomment-363978914
https://github.com/broadinstitute/gatk/issues/4361#issuecomment-363583464:129,Deployability,release,release,129,"@chandrans Please ask the user to repeat the test, with the following adjustments:. * Run both GATK 3.7 and GATK 4.0.1.1 (latest release) on the same machine, one right after another, on chromosome 20 only (using `-L` in both cases), and ensure that there are no other expensive processes running on this machine during the tests. Run each version 3 times, and take the average of the results.; * Add `-pairHMM AVX_LOGLESS_CACHING` to both the GATK3 and GATK4 command lines, to guarantee that the native PairHMM will be used in both cases.; * Get rid of the `--native-pair-hmm-threads 32` in the GATK 4 command line. Too many threads can sometimes make performance worse by introducing too much contention.; * Check both the GATK3 and GATK4 output to ensure that the Intel inflater and deflater were used in both cases.; * Check both the GATK3 and GATK4 command lines to be sure they are equivalent (eg., if one is running with -ERC GVCF, the other one should as well).; * Compute wall-clock time by running the Unix `time` command, if the user is not already doing so (eg., `time ./gatk HaplotypeCaller....`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4361#issuecomment-363583464
https://github.com/broadinstitute/gatk/issues/4361#issuecomment-363583464:653,Performance,perform,performance,653,"@chandrans Please ask the user to repeat the test, with the following adjustments:. * Run both GATK 3.7 and GATK 4.0.1.1 (latest release) on the same machine, one right after another, on chromosome 20 only (using `-L` in both cases), and ensure that there are no other expensive processes running on this machine during the tests. Run each version 3 times, and take the average of the results.; * Add `-pairHMM AVX_LOGLESS_CACHING` to both the GATK3 and GATK4 command lines, to guarantee that the native PairHMM will be used in both cases.; * Get rid of the `--native-pair-hmm-threads 32` in the GATK 4 command line. Too many threads can sometimes make performance worse by introducing too much contention.; * Check both the GATK3 and GATK4 output to ensure that the Intel inflater and deflater were used in both cases.; * Check both the GATK3 and GATK4 command lines to be sure they are equivalent (eg., if one is running with -ERC GVCF, the other one should as well).; * Compute wall-clock time by running the Unix `time` command, if the user is not already doing so (eg., `time ./gatk HaplotypeCaller....`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4361#issuecomment-363583464
https://github.com/broadinstitute/gatk/issues/4361#issuecomment-363583464:45,Testability,test,test,45,"@chandrans Please ask the user to repeat the test, with the following adjustments:. * Run both GATK 3.7 and GATK 4.0.1.1 (latest release) on the same machine, one right after another, on chromosome 20 only (using `-L` in both cases), and ensure that there are no other expensive processes running on this machine during the tests. Run each version 3 times, and take the average of the results.; * Add `-pairHMM AVX_LOGLESS_CACHING` to both the GATK3 and GATK4 command lines, to guarantee that the native PairHMM will be used in both cases.; * Get rid of the `--native-pair-hmm-threads 32` in the GATK 4 command line. Too many threads can sometimes make performance worse by introducing too much contention.; * Check both the GATK3 and GATK4 output to ensure that the Intel inflater and deflater were used in both cases.; * Check both the GATK3 and GATK4 command lines to be sure they are equivalent (eg., if one is running with -ERC GVCF, the other one should as well).; * Compute wall-clock time by running the Unix `time` command, if the user is not already doing so (eg., `time ./gatk HaplotypeCaller....`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4361#issuecomment-363583464
https://github.com/broadinstitute/gatk/issues/4361#issuecomment-363583464:324,Testability,test,tests,324,"@chandrans Please ask the user to repeat the test, with the following adjustments:. * Run both GATK 3.7 and GATK 4.0.1.1 (latest release) on the same machine, one right after another, on chromosome 20 only (using `-L` in both cases), and ensure that there are no other expensive processes running on this machine during the tests. Run each version 3 times, and take the average of the results.; * Add `-pairHMM AVX_LOGLESS_CACHING` to both the GATK3 and GATK4 command lines, to guarantee that the native PairHMM will be used in both cases.; * Get rid of the `--native-pair-hmm-threads 32` in the GATK 4 command line. Too many threads can sometimes make performance worse by introducing too much contention.; * Check both the GATK3 and GATK4 output to ensure that the Intel inflater and deflater were used in both cases.; * Check both the GATK3 and GATK4 command lines to be sure they are equivalent (eg., if one is running with -ERC GVCF, the other one should as well).; * Compute wall-clock time by running the Unix `time` command, if the user is not already doing so (eg., `time ./gatk HaplotypeCaller....`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4361#issuecomment-363583464
https://github.com/broadinstitute/gatk/issues/4363#issuecomment-371088787:2974,Availability,down,down,2974,"C_IO_WRITE_FOR_SAMTOOLS : true; 10:00:21.084 INFO FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 10:00:21.084 INFO FilterMutectCalls - Deflater: IntelDeflater; 10:00:21.084 INFO FilterMutectCalls - Inflater: IntelInflater; 10:00:21.084 INFO FilterMutectCalls - GCS max retries/reopens: 20; 10:00:21.084 INFO FilterMutectCalls - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 10:00:21.084 INFO FilterMutectCalls - Initializing engine; 10:00:21.437 INFO FeatureManager - Using codec VCFCodec to read file file:///scratch/dberaldi/projects/20170918_sgp_oesophageal/20171002_mutect/gatk4/WW00274.vep.vcf.gz; 10:00:21.673 INFO FilterMutectCalls - Done initializing engine; 10:00:21.734 INFO ProgressMeter - Starting traversal; 10:00:21.734 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 10:00:22.290 INFO FilterMutectCalls - Shutting down engine; [March 7, 2018 10:00:22 AM GMT] org.broadinstitute.hellbender.tools.walkers.mutect.FilterMutectCalls done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=934805504; org.broadinstitute.hellbender.exceptions.GATKException: INFO annotation 'MFRL' contains a non-int value '2.1472e+08'; 	at org.broadinstitute.hellbender.utils.GATKProtectedVariantContextUtils.lambda$attributeValueToIntArray$1(GATKProtectedVariantContextUtils.java:134); 	at java.util.stream.ReferencePipeline$4$1.accept(ReferencePipeline.java:210); 	at java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:545); 	at java.util.stream.AbstractPipeline.evaluateToArrayNode(AbstractPipeline.java:260); 	at java.util.stream.IntPipeline.toArray(IntPipeline.java:502); 	at org.b",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4363#issuecomment-371088787
https://github.com/broadinstitute/gatk/issues/4363#issuecomment-371088787:147,Deployability,release,releases,147,"Sorry to be a pain... I'm still getting this problem with 4.0.2.1, which according to the tag [description](https://github.com/broadinstitute/gatk/releases/tag/4.0.2.1) should have this issue fixed. ```; Using GATK jar /home/db291g/applications/gatk/gatk-4.0.2.1/gatk-package-4.0.2.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -jar /home/db291g/applications/gatk/gatk-4.0.2.1/gatk-package-4.0.2.1-local.jar FilterMutectCalls --variant gatk4/WW00274.vep.vcf.gz --output test.vcf.gz; 10:00:20.977 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/db291g/applications/gatk/gatk-4.0.2.1/gatk-package-4.0.2.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; 10:00:21.082 INFO FilterMutectCalls - ------------------------------------------------------------; 10:00:21.083 INFO FilterMutectCalls - The Genome Analysis Toolkit (GATK) v4.0.2.1; 10:00:21.083 INFO FilterMutectCalls - For support and documentation go to https://software.broadinstitute.org/gatk/; 10:00:21.083 INFO FilterMutectCalls - Executing as db291g@login01 on Linux v2.6.32-431.23.3.el6.x86_64 amd64; 10:00:21.083 INFO FilterMutectCalls - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_121-b13; 10:00:21.083 INFO FilterMutectCalls - Start Date/Time: March 7, 2018 10:00:20 AM GMT; 10:00:21.083 INFO FilterMutectCalls - ------------------------------------------------------------; 10:00:21.083 INFO FilterMutectCalls - ------------------------------------------------------------; 10:00:21.084 INFO FilterMutectCalls - HTSJDK Version: 2.14.3; 10:00:21.084 INFO FilterMutectCalls - Picard Version: 2.17.2; 10:00:21.084 INFO FilterMutectCalls - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 10:00:21.084 INFO FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 10:00:21.084 INFO FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOL",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4363#issuecomment-371088787
https://github.com/broadinstitute/gatk/issues/4363#issuecomment-371088787:2360,Deployability,patch,patch,2360,"alls - Start Date/Time: March 7, 2018 10:00:20 AM GMT; 10:00:21.083 INFO FilterMutectCalls - ------------------------------------------------------------; 10:00:21.083 INFO FilterMutectCalls - ------------------------------------------------------------; 10:00:21.084 INFO FilterMutectCalls - HTSJDK Version: 2.14.3; 10:00:21.084 INFO FilterMutectCalls - Picard Version: 2.17.2; 10:00:21.084 INFO FilterMutectCalls - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 10:00:21.084 INFO FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 10:00:21.084 INFO FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 10:00:21.084 INFO FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 10:00:21.084 INFO FilterMutectCalls - Deflater: IntelDeflater; 10:00:21.084 INFO FilterMutectCalls - Inflater: IntelInflater; 10:00:21.084 INFO FilterMutectCalls - GCS max retries/reopens: 20; 10:00:21.084 INFO FilterMutectCalls - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 10:00:21.084 INFO FilterMutectCalls - Initializing engine; 10:00:21.437 INFO FeatureManager - Using codec VCFCodec to read file file:///scratch/dberaldi/projects/20170918_sgp_oesophageal/20171002_mutect/gatk4/WW00274.vep.vcf.gz; 10:00:21.673 INFO FilterMutectCalls - Done initializing engine; 10:00:21.734 INFO ProgressMeter - Starting traversal; 10:00:21.734 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 10:00:22.290 INFO FilterMutectCalls - Shutting down engine; [March 7, 2018 10:00:22 AM GMT] org.broadinstitute.hellbender.tools.walkers.mutect.FilterMutectCalls done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=934805504; org.broadinstitute.hellbender.exceptions.GATKException: INFO annotation 'MFRL' contains a non-int value '2.1472e+08'; 	at org.broadinstitute.hellbender.utils.GATKProtectedVariantContextUtils.lambda$attributeValu",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4363#issuecomment-371088787
https://github.com/broadinstitute/gatk/issues/4363#issuecomment-371088787:3702,Integrability,wrap,wrapAndCopyInto,3702,"673 INFO FilterMutectCalls - Done initializing engine; 10:00:21.734 INFO ProgressMeter - Starting traversal; 10:00:21.734 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 10:00:22.290 INFO FilterMutectCalls - Shutting down engine; [March 7, 2018 10:00:22 AM GMT] org.broadinstitute.hellbender.tools.walkers.mutect.FilterMutectCalls done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=934805504; org.broadinstitute.hellbender.exceptions.GATKException: INFO annotation 'MFRL' contains a non-int value '2.1472e+08'; 	at org.broadinstitute.hellbender.utils.GATKProtectedVariantContextUtils.lambda$attributeValueToIntArray$1(GATKProtectedVariantContextUtils.java:134); 	at java.util.stream.ReferencePipeline$4$1.accept(ReferencePipeline.java:210); 	at java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:545); 	at java.util.stream.AbstractPipeline.evaluateToArrayNode(AbstractPipeline.java:260); 	at java.util.stream.IntPipeline.toArray(IntPipeline.java:502); 	at org.broadinstitute.hellbender.utils.GATKProtectedVariantContextUtils.attributeValueToIntArray(GATKProtectedVariantContextUtils.java:154); 	at org.broadinstitute.hellbender.utils.GATKProtectedVariantContextUtils.getAttributeAsIntArray(GATKProtectedVariantContextUtils.java:81); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.getIntArrayTumorField(Mutect2FilteringEngine.java:235); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.applyMedianFragmentLengthDifferenceFilter(Mutect2FilteringEngine.java:106); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.calculateFilters(Mutect2FilteringEngine.java:228); 	at org.broadinstitute.hellbender.tools.walkers.mu",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4363#issuecomment-371088787
https://github.com/broadinstitute/gatk/issues/4363#issuecomment-371088787:5301,Integrability,wrap,wrapAndCopyInto,5301,teringEngine.getIntArrayTumorField(Mutect2FilteringEngine.java:235); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.applyMedianFragmentLengthDifferenceFilter(Mutect2FilteringEngine.java:106); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.calculateFilters(Mutect2FilteringEngine.java:228); 	at org.broadinstitute.hellbender.tools.walkers.mutect.FilterMutectCalls.apply(FilterMutectCalls.java:113); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.lambda$traverse$0(VariantWalkerBase.java:110); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.traverse(VariantWalkerBase.java:108); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:893); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:135); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:180); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:199); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:159); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:202); 	at org.broadi,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4363#issuecomment-371088787
https://github.com/broadinstitute/gatk/issues/4363#issuecomment-371088787:660,Performance,Load,Loading,660,"Sorry to be a pain... I'm still getting this problem with 4.0.2.1, which according to the tag [description](https://github.com/broadinstitute/gatk/releases/tag/4.0.2.1) should have this issue fixed. ```; Using GATK jar /home/db291g/applications/gatk/gatk-4.0.2.1/gatk-package-4.0.2.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -jar /home/db291g/applications/gatk/gatk-4.0.2.1/gatk-package-4.0.2.1-local.jar FilterMutectCalls --variant gatk4/WW00274.vep.vcf.gz --output test.vcf.gz; 10:00:20.977 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/db291g/applications/gatk/gatk-4.0.2.1/gatk-package-4.0.2.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; 10:00:21.082 INFO FilterMutectCalls - ------------------------------------------------------------; 10:00:21.083 INFO FilterMutectCalls - The Genome Analysis Toolkit (GATK) v4.0.2.1; 10:00:21.083 INFO FilterMutectCalls - For support and documentation go to https://software.broadinstitute.org/gatk/; 10:00:21.083 INFO FilterMutectCalls - Executing as db291g@login01 on Linux v2.6.32-431.23.3.el6.x86_64 amd64; 10:00:21.083 INFO FilterMutectCalls - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_121-b13; 10:00:21.083 INFO FilterMutectCalls - Start Date/Time: March 7, 2018 10:00:20 AM GMT; 10:00:21.083 INFO FilterMutectCalls - ------------------------------------------------------------; 10:00:21.083 INFO FilterMutectCalls - ------------------------------------------------------------; 10:00:21.084 INFO FilterMutectCalls - HTSJDK Version: 2.14.3; 10:00:21.084 INFO FilterMutectCalls - Picard Version: 2.17.2; 10:00:21.084 INFO FilterMutectCalls - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 10:00:21.084 INFO FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 10:00:21.084 INFO FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOL",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4363#issuecomment-371088787
https://github.com/broadinstitute/gatk/issues/4363#issuecomment-371088787:607,Testability,test,test,607,"Sorry to be a pain... I'm still getting this problem with 4.0.2.1, which according to the tag [description](https://github.com/broadinstitute/gatk/releases/tag/4.0.2.1) should have this issue fixed. ```; Using GATK jar /home/db291g/applications/gatk/gatk-4.0.2.1/gatk-package-4.0.2.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=1 -jar /home/db291g/applications/gatk/gatk-4.0.2.1/gatk-package-4.0.2.1-local.jar FilterMutectCalls --variant gatk4/WW00274.vep.vcf.gz --output test.vcf.gz; 10:00:20.977 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/db291g/applications/gatk/gatk-4.0.2.1/gatk-package-4.0.2.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; 10:00:21.082 INFO FilterMutectCalls - ------------------------------------------------------------; 10:00:21.083 INFO FilterMutectCalls - The Genome Analysis Toolkit (GATK) v4.0.2.1; 10:00:21.083 INFO FilterMutectCalls - For support and documentation go to https://software.broadinstitute.org/gatk/; 10:00:21.083 INFO FilterMutectCalls - Executing as db291g@login01 on Linux v2.6.32-431.23.3.el6.x86_64 amd64; 10:00:21.083 INFO FilterMutectCalls - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_121-b13; 10:00:21.083 INFO FilterMutectCalls - Start Date/Time: March 7, 2018 10:00:20 AM GMT; 10:00:21.083 INFO FilterMutectCalls - ------------------------------------------------------------; 10:00:21.083 INFO FilterMutectCalls - ------------------------------------------------------------; 10:00:21.084 INFO FilterMutectCalls - HTSJDK Version: 2.14.3; 10:00:21.084 INFO FilterMutectCalls - Picard Version: 2.17.2; 10:00:21.084 INFO FilterMutectCalls - HTSJDK Defaults.COMPRESSION_LEVEL : 1; 10:00:21.084 INFO FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 10:00:21.084 INFO FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOL",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4363#issuecomment-371088787
https://github.com/broadinstitute/gatk/issues/4363#issuecomment-371170671:312,Testability,test,test,312,"Hi- The header reports `##FORMAT=<ID=MFRL,Number=R,Type=Float,Description=""median fragment length"">`. There is an example vcf file, `in.vcf`, [here](https://github.com/dariober/bioinformatics-cafe/tree/master/fixMFRLforMutect/test_data) which I used to hack together a script to fix an input vcf file (see also [test.md](https://github.com/dariober/bioinformatics-cafe/blob/master/fixMFRLforMutect/test.md)).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4363#issuecomment-371170671
https://github.com/broadinstitute/gatk/issues/4363#issuecomment-371170671:398,Testability,test,test,398,"Hi- The header reports `##FORMAT=<ID=MFRL,Number=R,Type=Float,Description=""median fragment length"">`. There is an example vcf file, `in.vcf`, [here](https://github.com/dariober/bioinformatics-cafe/tree/master/fixMFRLforMutect/test_data) which I used to hack together a script to fix an input vcf file (see also [test.md](https://github.com/dariober/bioinformatics-cafe/blob/master/fixMFRLforMutect/test.md)).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4363#issuecomment-371170671
https://github.com/broadinstitute/gatk/issues/4363#issuecomment-371203165:151,Deployability,release,release,151,@dariober The fix is in `Mutect2` itself because that's where the vcf header line for `MFRL` is created. If you're using an unfiltered vcf from an old release and using the 4.0.2.1 only for `FilterMutectCalls` the problem will remain.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4363#issuecomment-371203165
https://github.com/broadinstitute/gatk/pull/4364#issuecomment-363787268:28,Security,expose,exposed,28,"@LeeTL1220 I went ahead and exposed more mem_gb parameters, which is convenient when we want to go below 250bp and the pair WDL is used as a subworkflow. Please review carefully!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4364#issuecomment-363787268
https://github.com/broadinstitute/gatk/pull/4364#issuecomment-363806476:99,Testability,test,tests,99,"Thanks @LeeTL1220, I also added another commit to make some minor comment tweaks. Will merge after tests pass!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4364#issuecomment-363806476
https://github.com/broadinstitute/gatk/issues/4366#issuecomment-363851445:354,Safety,risk,risk,354,"@sooheelee That's a pitfall we haven't solved yet. I think we'll eventually infer the value locally from the AC of nearby variants in the germline resource. Until then, I would use the smaller value i.e. the one for coding regions. The only possible harm would be a very few rare germline events that aren't in gnomAD, whereas if you set it too high you risk filtering true somatic events.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4366#issuecomment-363851445
https://github.com/broadinstitute/gatk/issues/4367#issuecomment-367094730:106,Deployability,release,release,106,"@cmnbroad Could you get a PR in for this by Friday, if possible? I'd like to include it in the next point release.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4367#issuecomment-367094730
https://github.com/broadinstitute/gatk/issues/4369#issuecomment-385198863:43,Availability,error,error,43,"I just ran into this issue. I get the same error using my account and a service account. I can work around this by adding the following Java lines in runTool():. `; ctx.hadoopConfiguration().set(""fs.gs.project.id"", ""<PROJECT>"");; ctx.hadoopConfiguration().set(""google.cloud.auth.service.account.json.keyfile"", ""<KEYFILE>"");; `",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4369#issuecomment-385198863
https://github.com/broadinstitute/gatk/issues/4369#issuecomment-386095129:23,Availability,error,error,23,"Also, I do not get the error with non-spark tools.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4369#issuecomment-386095129
https://github.com/broadinstitute/gatk/issues/4369#issuecomment-386388889:45,Modifiability,config,configure,45,@jean-philippe-martin If the connector could configure itself with default credentials that would be amazing.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4369#issuecomment-386388889
https://github.com/broadinstitute/gatk/issues/4369#issuecomment-424004818:371,Availability,error,error,371,"We have [a researcher reporting that even when running locally, they are getting messages related to the GCS](https://gatkforums.broadinstitute.org/gatk/discussion/13015/failed-to-detect-whether-we-are-running-on-google-compute-engine#latest), which they find puzzling. > WARNING: Failed to detect whether we are running on Google Compute Engine. plus what looks like an error stacktrace in the middle of the stdout. Is this intentional?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4369#issuecomment-424004818
https://github.com/broadinstitute/gatk/issues/4369#issuecomment-424004818:81,Integrability,message,messages,81,"We have [a researcher reporting that even when running locally, they are getting messages related to the GCS](https://gatkforums.broadinstitute.org/gatk/discussion/13015/failed-to-detect-whether-we-are-running-on-google-compute-engine#latest), which they find puzzling. > WARNING: Failed to detect whether we are running on Google Compute Engine. plus what looks like an error stacktrace in the middle of the stdout. Is this intentional?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4369#issuecomment-424004818
https://github.com/broadinstitute/gatk/issues/4369#issuecomment-424004818:180,Safety,detect,detect-whether-we-are-running-on-google-compute-engine,180,"We have [a researcher reporting that even when running locally, they are getting messages related to the GCS](https://gatkforums.broadinstitute.org/gatk/discussion/13015/failed-to-detect-whether-we-are-running-on-google-compute-engine#latest), which they find puzzling. > WARNING: Failed to detect whether we are running on Google Compute Engine. plus what looks like an error stacktrace in the middle of the stdout. Is this intentional?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4369#issuecomment-424004818
https://github.com/broadinstitute/gatk/issues/4369#issuecomment-424004818:291,Safety,detect,detect,291,"We have [a researcher reporting that even when running locally, they are getting messages related to the GCS](https://gatkforums.broadinstitute.org/gatk/discussion/13015/failed-to-detect-whether-we-are-running-on-google-compute-engine#latest), which they find puzzling. > WARNING: Failed to detect whether we are running on Google Compute Engine. plus what looks like an error stacktrace in the middle of the stdout. Is this intentional?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4369#issuecomment-424004818
https://github.com/broadinstitute/gatk/issues/4369#issuecomment-424038095:5,Availability,error,error,5,"This error message is related to GATK's ability to load files on Google buckets (""gcs://bucket/file.bam""). This ability is enabled even when running locally (this aspect is intentional, because it's useful to be able to run a local GATK instance to process remote data without having to fire up a VM). As the bucket-reading code (""NIO"") initializes, it looks for credentials to use. Those can be set via an environment variable or via `gcloud auth`, as described in GATK's README. If neither of these are set, it checks whether it's currently running in a Google virtual machine (so it can figure out who owns the virtual machine that it's running on, and use those credentials). Apparently this code throws an exception if it runs out of ways to find credentials, and our code prints it out and moves on. The message is useful, for if we *were* running in a google VM and the credential-finding failed, we'd certainly like to know. Whether we need the full stack trace, now, that's a choice we have to make.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4369#issuecomment-424038095
https://github.com/broadinstitute/gatk/issues/4369#issuecomment-424038095:11,Integrability,message,message,11,"This error message is related to GATK's ability to load files on Google buckets (""gcs://bucket/file.bam""). This ability is enabled even when running locally (this aspect is intentional, because it's useful to be able to run a local GATK instance to process remote data without having to fire up a VM). As the bucket-reading code (""NIO"") initializes, it looks for credentials to use. Those can be set via an environment variable or via `gcloud auth`, as described in GATK's README. If neither of these are set, it checks whether it's currently running in a Google virtual machine (so it can figure out who owns the virtual machine that it's running on, and use those credentials). Apparently this code throws an exception if it runs out of ways to find credentials, and our code prints it out and moves on. The message is useful, for if we *were* running in a google VM and the credential-finding failed, we'd certainly like to know. Whether we need the full stack trace, now, that's a choice we have to make.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4369#issuecomment-424038095
https://github.com/broadinstitute/gatk/issues/4369#issuecomment-424038095:810,Integrability,message,message,810,"This error message is related to GATK's ability to load files on Google buckets (""gcs://bucket/file.bam""). This ability is enabled even when running locally (this aspect is intentional, because it's useful to be able to run a local GATK instance to process remote data without having to fire up a VM). As the bucket-reading code (""NIO"") initializes, it looks for credentials to use. Those can be set via an environment variable or via `gcloud auth`, as described in GATK's README. If neither of these are set, it checks whether it's currently running in a Google virtual machine (so it can figure out who owns the virtual machine that it's running on, and use those credentials). Apparently this code throws an exception if it runs out of ways to find credentials, and our code prints it out and moves on. The message is useful, for if we *were* running in a google VM and the credential-finding failed, we'd certainly like to know. Whether we need the full stack trace, now, that's a choice we have to make.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4369#issuecomment-424038095
https://github.com/broadinstitute/gatk/issues/4369#issuecomment-424038095:419,Modifiability,variab,variable,419,"This error message is related to GATK's ability to load files on Google buckets (""gcs://bucket/file.bam""). This ability is enabled even when running locally (this aspect is intentional, because it's useful to be able to run a local GATK instance to process remote data without having to fire up a VM). As the bucket-reading code (""NIO"") initializes, it looks for credentials to use. Those can be set via an environment variable or via `gcloud auth`, as described in GATK's README. If neither of these are set, it checks whether it's currently running in a Google virtual machine (so it can figure out who owns the virtual machine that it's running on, and use those credentials). Apparently this code throws an exception if it runs out of ways to find credentials, and our code prints it out and moves on. The message is useful, for if we *were* running in a google VM and the credential-finding failed, we'd certainly like to know. Whether we need the full stack trace, now, that's a choice we have to make.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4369#issuecomment-424038095
https://github.com/broadinstitute/gatk/issues/4369#issuecomment-424038095:51,Performance,load,load,51,"This error message is related to GATK's ability to load files on Google buckets (""gcs://bucket/file.bam""). This ability is enabled even when running locally (this aspect is intentional, because it's useful to be able to run a local GATK instance to process remote data without having to fire up a VM). As the bucket-reading code (""NIO"") initializes, it looks for credentials to use. Those can be set via an environment variable or via `gcloud auth`, as described in GATK's README. If neither of these are set, it checks whether it's currently running in a Google virtual machine (so it can figure out who owns the virtual machine that it's running on, and use those credentials). Apparently this code throws an exception if it runs out of ways to find credentials, and our code prints it out and moves on. The message is useful, for if we *were* running in a google VM and the credential-finding failed, we'd certainly like to know. Whether we need the full stack trace, now, that's a choice we have to make.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4369#issuecomment-424038095
https://github.com/broadinstitute/gatk/issues/4370#issuecomment-363922690:75,Usability,simpl,simply,75,"I didn't read the description of this tool well enough, apparently you can simply add a `--PROGRAM null` to remove the default list. Closing the issue.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4370#issuecomment-363922690
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-363920337:55,Testability,test,test,55,"@ldgauthier Excellent, these will definitely be a good test set.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-363920337
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-364234449:533,Availability,mask,mask,533,"OK, the first test run I tried was with 1kb bins and *no additional normals*. Coverage takes about an hour to collect per BAM and ploidy inference takes about 10 minutes. A few things:. 1) Looks like we are concordant with the truth CN on X for all but 3/40 of the samples. The GQs for these discordant calls are low (~3, 23, and 25 compared with ~400 for most of the others). 2) However, we are striking out on over half of the samples on Y. We mostly call 1 copy when the truth calls 0. Mehrtash thinks this is because a) I didn't mask out any PARs or otherwise troublesome regions on Y and b) I didn't include any other normals. I'll try rerunning with a mask first, then with other normals, and then with both. Hopefully this should clear up with just the mask. 3) There are a few samples where we strike out because the truth calls 2 copies on Y and we call 1. Mehrtash pointed out that this is most likely because the prior table we put together assumes Y can have at most 1 copy. So hopefully these are trivially recovered once we relax this. 4) The GQs are weirdly high on 1, X, and Y compared to the rest of the autosomes. @ldgauthier any idea why this might be? If there's no reason, then something funny is going on within the tool. I haven't gotten a chance to plot any of the counts data yet, either, which may make things more obvious. I'll do this today.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-364234449
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-364234449:658,Availability,mask,mask,658,"OK, the first test run I tried was with 1kb bins and *no additional normals*. Coverage takes about an hour to collect per BAM and ploidy inference takes about 10 minutes. A few things:. 1) Looks like we are concordant with the truth CN on X for all but 3/40 of the samples. The GQs for these discordant calls are low (~3, 23, and 25 compared with ~400 for most of the others). 2) However, we are striking out on over half of the samples on Y. We mostly call 1 copy when the truth calls 0. Mehrtash thinks this is because a) I didn't mask out any PARs or otherwise troublesome regions on Y and b) I didn't include any other normals. I'll try rerunning with a mask first, then with other normals, and then with both. Hopefully this should clear up with just the mask. 3) There are a few samples where we strike out because the truth calls 2 copies on Y and we call 1. Mehrtash pointed out that this is most likely because the prior table we put together assumes Y can have at most 1 copy. So hopefully these are trivially recovered once we relax this. 4) The GQs are weirdly high on 1, X, and Y compared to the rest of the autosomes. @ldgauthier any idea why this might be? If there's no reason, then something funny is going on within the tool. I haven't gotten a chance to plot any of the counts data yet, either, which may make things more obvious. I'll do this today.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-364234449
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-364234449:760,Availability,mask,mask,760,"OK, the first test run I tried was with 1kb bins and *no additional normals*. Coverage takes about an hour to collect per BAM and ploidy inference takes about 10 minutes. A few things:. 1) Looks like we are concordant with the truth CN on X for all but 3/40 of the samples. The GQs for these discordant calls are low (~3, 23, and 25 compared with ~400 for most of the others). 2) However, we are striking out on over half of the samples on Y. We mostly call 1 copy when the truth calls 0. Mehrtash thinks this is because a) I didn't mask out any PARs or otherwise troublesome regions on Y and b) I didn't include any other normals. I'll try rerunning with a mask first, then with other normals, and then with both. Hopefully this should clear up with just the mask. 3) There are a few samples where we strike out because the truth calls 2 copies on Y and we call 1. Mehrtash pointed out that this is most likely because the prior table we put together assumes Y can have at most 1 copy. So hopefully these are trivially recovered once we relax this. 4) The GQs are weirdly high on 1, X, and Y compared to the rest of the autosomes. @ldgauthier any idea why this might be? If there's no reason, then something funny is going on within the tool. I haven't gotten a chance to plot any of the counts data yet, either, which may make things more obvious. I'll do this today.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-364234449
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-364234449:1020,Availability,recover,recovered,1020,"OK, the first test run I tried was with 1kb bins and *no additional normals*. Coverage takes about an hour to collect per BAM and ploidy inference takes about 10 minutes. A few things:. 1) Looks like we are concordant with the truth CN on X for all but 3/40 of the samples. The GQs for these discordant calls are low (~3, 23, and 25 compared with ~400 for most of the others). 2) However, we are striking out on over half of the samples on Y. We mostly call 1 copy when the truth calls 0. Mehrtash thinks this is because a) I didn't mask out any PARs or otherwise troublesome regions on Y and b) I didn't include any other normals. I'll try rerunning with a mask first, then with other normals, and then with both. Hopefully this should clear up with just the mask. 3) There are a few samples where we strike out because the truth calls 2 copies on Y and we call 1. Mehrtash pointed out that this is most likely because the prior table we put together assumes Y can have at most 1 copy. So hopefully these are trivially recovered once we relax this. 4) The GQs are weirdly high on 1, X, and Y compared to the rest of the autosomes. @ldgauthier any idea why this might be? If there's no reason, then something funny is going on within the tool. I haven't gotten a chance to plot any of the counts data yet, either, which may make things more obvious. I'll do this today.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-364234449
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-364234449:1020,Safety,recover,recovered,1020,"OK, the first test run I tried was with 1kb bins and *no additional normals*. Coverage takes about an hour to collect per BAM and ploidy inference takes about 10 minutes. A few things:. 1) Looks like we are concordant with the truth CN on X for all but 3/40 of the samples. The GQs for these discordant calls are low (~3, 23, and 25 compared with ~400 for most of the others). 2) However, we are striking out on over half of the samples on Y. We mostly call 1 copy when the truth calls 0. Mehrtash thinks this is because a) I didn't mask out any PARs or otherwise troublesome regions on Y and b) I didn't include any other normals. I'll try rerunning with a mask first, then with other normals, and then with both. Hopefully this should clear up with just the mask. 3) There are a few samples where we strike out because the truth calls 2 copies on Y and we call 1. Mehrtash pointed out that this is most likely because the prior table we put together assumes Y can have at most 1 copy. So hopefully these are trivially recovered once we relax this. 4) The GQs are weirdly high on 1, X, and Y compared to the rest of the autosomes. @ldgauthier any idea why this might be? If there's no reason, then something funny is going on within the tool. I haven't gotten a chance to plot any of the counts data yet, either, which may make things more obvious. I'll do this today.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-364234449
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-364234449:14,Testability,test,test,14,"OK, the first test run I tried was with 1kb bins and *no additional normals*. Coverage takes about an hour to collect per BAM and ploidy inference takes about 10 minutes. A few things:. 1) Looks like we are concordant with the truth CN on X for all but 3/40 of the samples. The GQs for these discordant calls are low (~3, 23, and 25 compared with ~400 for most of the others). 2) However, we are striking out on over half of the samples on Y. We mostly call 1 copy when the truth calls 0. Mehrtash thinks this is because a) I didn't mask out any PARs or otherwise troublesome regions on Y and b) I didn't include any other normals. I'll try rerunning with a mask first, then with other normals, and then with both. Hopefully this should clear up with just the mask. 3) There are a few samples where we strike out because the truth calls 2 copies on Y and we call 1. Mehrtash pointed out that this is most likely because the prior table we put together assumes Y can have at most 1 copy. So hopefully these are trivially recovered once we relax this. 4) The GQs are weirdly high on 1, X, and Y compared to the rest of the autosomes. @ldgauthier any idea why this might be? If there's no reason, then something funny is going on within the tool. I haven't gotten a chance to plot any of the counts data yet, either, which may make things more obvious. I'll do this today.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-364234449
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-364234449:737,Usability,clear,clear,737,"OK, the first test run I tried was with 1kb bins and *no additional normals*. Coverage takes about an hour to collect per BAM and ploidy inference takes about 10 minutes. A few things:. 1) Looks like we are concordant with the truth CN on X for all but 3/40 of the samples. The GQs for these discordant calls are low (~3, 23, and 25 compared with ~400 for most of the others). 2) However, we are striking out on over half of the samples on Y. We mostly call 1 copy when the truth calls 0. Mehrtash thinks this is because a) I didn't mask out any PARs or otherwise troublesome regions on Y and b) I didn't include any other normals. I'll try rerunning with a mask first, then with other normals, and then with both. Hopefully this should clear up with just the mask. 3) There are a few samples where we strike out because the truth calls 2 copies on Y and we call 1. Mehrtash pointed out that this is most likely because the prior table we put together assumes Y can have at most 1 copy. So hopefully these are trivially recovered once we relax this. 4) The GQs are weirdly high on 1, X, and Y compared to the rest of the autosomes. @ldgauthier any idea why this might be? If there's no reason, then something funny is going on within the tool. I haven't gotten a chance to plot any of the counts data yet, either, which may make things more obvious. I'll do this today.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-364234449
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-365064461:53,Testability,test,testdata,53,CRAMs for 20 normals are in gs: //broad-dsde-methods/testdata/aneuploidy_samples_panel. These are all from the same project (G100345) so it will be interesting to see if there are any batch effects that show up in the GQs.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-365064461
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-365640616:286,Availability,robust,robust,286,"Built a PoN with those normals. Some tuning of parameters was required to get reasonable results. After discussion with @mbabadi, we decided that the current model has a little too much freedom and can probably be made simpler (negative binomial -> Poisson). This should result in more robust results and decrease the amount of tuning needed. Also note that normal sample 8007540251 has something going on in chr12.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-365640616
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-365640616:219,Usability,simpl,simpler,219,"Built a PoN with those normals. Some tuning of parameters was required to get reasonable results. After discussion with @mbabadi, we decided that the current model has a little too much freedom and can probably be made simpler (negative binomial -> Poisson). This should result in more robust results and decrease the amount of tuning needed. Also note that normal sample 8007540251 has something going on in chr12.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-365640616
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-371334890:117,Availability,robust,robust,117,"Just some notes before I forget:. Using these test samples, I made some tweaks to the ploidy model that made it more robust to incorrect ploidy calls and added a simple modeling of mosaicism:. ```` ; # per-contig bias; bias_j = Gamma('bias_j',; alpha=100.0,; beta=100.0,; shape=(ploidy_workspace.num_contigs,)); norm_bias_j = bias_j / tt.mean(bias_j). # per-sample depth; depth_s = Uniform('depth_s',; lower=0.0,; upper=10000.0,; shape=(ploidy_workspace.num_samples,)); ; # per-sample probability of mosaicism; pi_mosaicism_s = Beta(name='pi_mosaicism_s',; alpha=1.0,; beta=50.0,; shape=(ploidy_workspace.num_samples,)). # per-sample-and-contig mosaicism factor; f_mosaicism_sj = Beta(name='f_mosaicism_sj',; alpha=10.0,; beta=1.0,; shape=(ploidy_workspace.num_samples, ploidy_workspace.num_contigs,)); norm_f_mosaicism_sj = f_mosaicism_sj / tt.max(f_mosaicism_sj, axis=1).dimshuffle(0, 'x'). # per-contig mapping error; eps_j = HalfNormal('eps_j', sd=0.01, shape=(ploidy_workspace.num_contigs,)). # negative-binomial means; mu_sjk = depth_s.dimshuffle(0, 'x', 'x') * t_j.dimshuffle('x', 0, 'x') * norm_bias_j.dimshuffle('x', 0, 'x') * \; (ploidy_workspace.int_ploidy_values_k.dimshuffle('x', 'x', 0) + eps_j.dimshuffle('x', 0, 'x')); mu_mosaic_sjk = norm_f_mosaicism_sj.dimshuffle(0, 1, 'x') * mu_sjk. # ""unexplained variance""; psi = Uniform(name='psi', upper=10.0). # convert ""unexplained variance"" to negative binomial over-dispersion; alpha = tt.inv((tt.exp(psi) - 1.0)). def _get_logp_sjk(_n_sj):; _logp_sjk = logsumexp([tt.log(1 - pi_mosaicism_s.dimshuffle(0, 'x', 'x')) + commons.negative_binomial_logp(mu_sjk, alpha.dimshuffle('x', 'x', 'x'), _n_sj.dimshuffle(0, 1, 'x')),; tt.log(pi_mosaicism_s.dimshuffle(0, 'x', 'x')) + commons.negative_binomial_logp(mu_mosaic_sjk, alpha.dimshuffle('x', 'x', 'x'), _n_sj.dimshuffle(0, 1, 'x'))],; axis=0)[0]; return _logp_sjk. DensityDist(name='n_sj_obs',; logp=lambda _n_sj: tt.sum(q_ploidy_sjk * _get_logp_sjk(_n_sj), axis=2),; observed=n_sj); ````. Brie",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-371334890
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-371334890:914,Availability,error,error,914,"Just some notes before I forget:. Using these test samples, I made some tweaks to the ploidy model that made it more robust to incorrect ploidy calls and added a simple modeling of mosaicism:. ```` ; # per-contig bias; bias_j = Gamma('bias_j',; alpha=100.0,; beta=100.0,; shape=(ploidy_workspace.num_contigs,)); norm_bias_j = bias_j / tt.mean(bias_j). # per-sample depth; depth_s = Uniform('depth_s',; lower=0.0,; upper=10000.0,; shape=(ploidy_workspace.num_samples,)); ; # per-sample probability of mosaicism; pi_mosaicism_s = Beta(name='pi_mosaicism_s',; alpha=1.0,; beta=50.0,; shape=(ploidy_workspace.num_samples,)). # per-sample-and-contig mosaicism factor; f_mosaicism_sj = Beta(name='f_mosaicism_sj',; alpha=10.0,; beta=1.0,; shape=(ploidy_workspace.num_samples, ploidy_workspace.num_contigs,)); norm_f_mosaicism_sj = f_mosaicism_sj / tt.max(f_mosaicism_sj, axis=1).dimshuffle(0, 'x'). # per-contig mapping error; eps_j = HalfNormal('eps_j', sd=0.01, shape=(ploidy_workspace.num_contigs,)). # negative-binomial means; mu_sjk = depth_s.dimshuffle(0, 'x', 'x') * t_j.dimshuffle('x', 0, 'x') * norm_bias_j.dimshuffle('x', 0, 'x') * \; (ploidy_workspace.int_ploidy_values_k.dimshuffle('x', 'x', 0) + eps_j.dimshuffle('x', 0, 'x')); mu_mosaic_sjk = norm_f_mosaicism_sj.dimshuffle(0, 1, 'x') * mu_sjk. # ""unexplained variance""; psi = Uniform(name='psi', upper=10.0). # convert ""unexplained variance"" to negative binomial over-dispersion; alpha = tt.inv((tt.exp(psi) - 1.0)). def _get_logp_sjk(_n_sj):; _logp_sjk = logsumexp([tt.log(1 - pi_mosaicism_s.dimshuffle(0, 'x', 'x')) + commons.negative_binomial_logp(mu_sjk, alpha.dimshuffle('x', 'x', 'x'), _n_sj.dimshuffle(0, 1, 'x')),; tt.log(pi_mosaicism_s.dimshuffle(0, 'x', 'x')) + commons.negative_binomial_logp(mu_mosaic_sjk, alpha.dimshuffle('x', 'x', 'x'), _n_sj.dimshuffle(0, 1, 'x'))],; axis=0)[0]; return _logp_sjk. DensityDist(name='n_sj_obs',; logp=lambda _n_sj: tt.sum(q_ploidy_sjk * _get_logp_sjk(_n_sj), axis=2),; observed=n_sj); ````. Brie",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-371334890
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-371334890:2287,Availability,error,error,2287,"dy_workspace.int_ploidy_values_k.dimshuffle('x', 'x', 0) + eps_j.dimshuffle('x', 0, 'x')); mu_mosaic_sjk = norm_f_mosaicism_sj.dimshuffle(0, 1, 'x') * mu_sjk. # ""unexplained variance""; psi = Uniform(name='psi', upper=10.0). # convert ""unexplained variance"" to negative binomial over-dispersion; alpha = tt.inv((tt.exp(psi) - 1.0)). def _get_logp_sjk(_n_sj):; _logp_sjk = logsumexp([tt.log(1 - pi_mosaicism_s.dimshuffle(0, 'x', 'x')) + commons.negative_binomial_logp(mu_sjk, alpha.dimshuffle('x', 'x', 'x'), _n_sj.dimshuffle(0, 1, 'x')),; tt.log(pi_mosaicism_s.dimshuffle(0, 'x', 'x')) + commons.negative_binomial_logp(mu_mosaic_sjk, alpha.dimshuffle('x', 'x', 'x'), _n_sj.dimshuffle(0, 1, 'x'))],; axis=0)[0]; return _logp_sjk. DensityDist(name='n_sj_obs',; logp=lambda _n_sj: tt.sum(q_ploidy_sjk * _get_logp_sjk(_n_sj), axis=2),; observed=n_sj); ````. Briefly, the model includes 1) per-contig bias (normalized to unit mean for identifiability), 2) per-sample depth, 3) per-sample probability of mosaicism, 4) per-sample-and-contig mosaicism factor `f` (in [0, 1], normalized by the per-sample max for identifiability), 5) per-contig mapping error. The likelihood is then a negative-binomial mixture of non-mosaic and mosaic contigs, where the latter have their mean count depressed by the corresponding factor `f`. This model still requires some tuning of priors (which are currently hard coded above), but seems to correctly capture most of the mosaicism in the test samples. Also, I found that it was better to run the aneuploid samples as a cohort or to run them in combination with the 20 panel samples as a cohort, rather than to run them in case mode against the panel. We don't necessarily have to emit anything on the mosaicism inferences for the first revision of this model (or we may end up stripping those parts of the model out for now), but I thought it would be good to record this version of the model for posterity. However, note that this model differs from the one currently in ma",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-371334890
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-371334890:3237,Availability,robust,robust,3237,"l_logp(mu_sjk, alpha.dimshuffle('x', 'x', 'x'), _n_sj.dimshuffle(0, 1, 'x')),; tt.log(pi_mosaicism_s.dimshuffle(0, 'x', 'x')) + commons.negative_binomial_logp(mu_mosaic_sjk, alpha.dimshuffle('x', 'x', 'x'), _n_sj.dimshuffle(0, 1, 'x'))],; axis=0)[0]; return _logp_sjk. DensityDist(name='n_sj_obs',; logp=lambda _n_sj: tt.sum(q_ploidy_sjk * _get_logp_sjk(_n_sj), axis=2),; observed=n_sj); ````. Briefly, the model includes 1) per-contig bias (normalized to unit mean for identifiability), 2) per-sample depth, 3) per-sample probability of mosaicism, 4) per-sample-and-contig mosaicism factor `f` (in [0, 1], normalized by the per-sample max for identifiability), 5) per-contig mapping error. The likelihood is then a negative-binomial mixture of non-mosaic and mosaic contigs, where the latter have their mean count depressed by the corresponding factor `f`. This model still requires some tuning of priors (which are currently hard coded above), but seems to correctly capture most of the mosaicism in the test samples. Also, I found that it was better to run the aneuploid samples as a cohort or to run them in combination with the 20 panel samples as a cohort, rather than to run them in case mode against the panel. We don't necessarily have to emit anything on the mosaicism inferences for the first revision of this model (or we may end up stripping those parts of the model out for now), but I thought it would be good to record this version of the model for posterity. However, note that this model differs from the one currently in master in the treatment of depth. I think the treatment here is quite natural and may be more robust than the current treatment. @mbabadi is going to take over tuning and tweaking the model from this point in the sl_simple_ploidy branch. Note that I haven't cleaned up some of the code and comments yet, but hopefully the changes are relatively clear. I believe I rebased on one of your other branches, so you should remove the corresponding commit and rebase.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-371334890
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-371334890:46,Testability,test,test,46,"Just some notes before I forget:. Using these test samples, I made some tweaks to the ploidy model that made it more robust to incorrect ploidy calls and added a simple modeling of mosaicism:. ```` ; # per-contig bias; bias_j = Gamma('bias_j',; alpha=100.0,; beta=100.0,; shape=(ploidy_workspace.num_contigs,)); norm_bias_j = bias_j / tt.mean(bias_j). # per-sample depth; depth_s = Uniform('depth_s',; lower=0.0,; upper=10000.0,; shape=(ploidy_workspace.num_samples,)); ; # per-sample probability of mosaicism; pi_mosaicism_s = Beta(name='pi_mosaicism_s',; alpha=1.0,; beta=50.0,; shape=(ploidy_workspace.num_samples,)). # per-sample-and-contig mosaicism factor; f_mosaicism_sj = Beta(name='f_mosaicism_sj',; alpha=10.0,; beta=1.0,; shape=(ploidy_workspace.num_samples, ploidy_workspace.num_contigs,)); norm_f_mosaicism_sj = f_mosaicism_sj / tt.max(f_mosaicism_sj, axis=1).dimshuffle(0, 'x'). # per-contig mapping error; eps_j = HalfNormal('eps_j', sd=0.01, shape=(ploidy_workspace.num_contigs,)). # negative-binomial means; mu_sjk = depth_s.dimshuffle(0, 'x', 'x') * t_j.dimshuffle('x', 0, 'x') * norm_bias_j.dimshuffle('x', 0, 'x') * \; (ploidy_workspace.int_ploidy_values_k.dimshuffle('x', 'x', 0) + eps_j.dimshuffle('x', 0, 'x')); mu_mosaic_sjk = norm_f_mosaicism_sj.dimshuffle(0, 1, 'x') * mu_sjk. # ""unexplained variance""; psi = Uniform(name='psi', upper=10.0). # convert ""unexplained variance"" to negative binomial over-dispersion; alpha = tt.inv((tt.exp(psi) - 1.0)). def _get_logp_sjk(_n_sj):; _logp_sjk = logsumexp([tt.log(1 - pi_mosaicism_s.dimshuffle(0, 'x', 'x')) + commons.negative_binomial_logp(mu_sjk, alpha.dimshuffle('x', 'x', 'x'), _n_sj.dimshuffle(0, 1, 'x')),; tt.log(pi_mosaicism_s.dimshuffle(0, 'x', 'x')) + commons.negative_binomial_logp(mu_mosaic_sjk, alpha.dimshuffle('x', 'x', 'x'), _n_sj.dimshuffle(0, 1, 'x'))],; axis=0)[0]; return _logp_sjk. DensityDist(name='n_sj_obs',; logp=lambda _n_sj: tt.sum(q_ploidy_sjk * _get_logp_sjk(_n_sj), axis=2),; observed=n_sj); ````. Brie",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-371334890
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-371334890:1515,Testability,log,logsumexp,1515,"saicism; pi_mosaicism_s = Beta(name='pi_mosaicism_s',; alpha=1.0,; beta=50.0,; shape=(ploidy_workspace.num_samples,)). # per-sample-and-contig mosaicism factor; f_mosaicism_sj = Beta(name='f_mosaicism_sj',; alpha=10.0,; beta=1.0,; shape=(ploidy_workspace.num_samples, ploidy_workspace.num_contigs,)); norm_f_mosaicism_sj = f_mosaicism_sj / tt.max(f_mosaicism_sj, axis=1).dimshuffle(0, 'x'). # per-contig mapping error; eps_j = HalfNormal('eps_j', sd=0.01, shape=(ploidy_workspace.num_contigs,)). # negative-binomial means; mu_sjk = depth_s.dimshuffle(0, 'x', 'x') * t_j.dimshuffle('x', 0, 'x') * norm_bias_j.dimshuffle('x', 0, 'x') * \; (ploidy_workspace.int_ploidy_values_k.dimshuffle('x', 'x', 0) + eps_j.dimshuffle('x', 0, 'x')); mu_mosaic_sjk = norm_f_mosaicism_sj.dimshuffle(0, 1, 'x') * mu_sjk. # ""unexplained variance""; psi = Uniform(name='psi', upper=10.0). # convert ""unexplained variance"" to negative binomial over-dispersion; alpha = tt.inv((tt.exp(psi) - 1.0)). def _get_logp_sjk(_n_sj):; _logp_sjk = logsumexp([tt.log(1 - pi_mosaicism_s.dimshuffle(0, 'x', 'x')) + commons.negative_binomial_logp(mu_sjk, alpha.dimshuffle('x', 'x', 'x'), _n_sj.dimshuffle(0, 1, 'x')),; tt.log(pi_mosaicism_s.dimshuffle(0, 'x', 'x')) + commons.negative_binomial_logp(mu_mosaic_sjk, alpha.dimshuffle('x', 'x', 'x'), _n_sj.dimshuffle(0, 1, 'x'))],; axis=0)[0]; return _logp_sjk. DensityDist(name='n_sj_obs',; logp=lambda _n_sj: tt.sum(q_ploidy_sjk * _get_logp_sjk(_n_sj), axis=2),; observed=n_sj); ````. Briefly, the model includes 1) per-contig bias (normalized to unit mean for identifiability), 2) per-sample depth, 3) per-sample probability of mosaicism, 4) per-sample-and-contig mosaicism factor `f` (in [0, 1], normalized by the per-sample max for identifiability), 5) per-contig mapping error. The likelihood is then a negative-binomial mixture of non-mosaic and mosaic contigs, where the latter have their mean count depressed by the corresponding factor `f`. This model still requires some tuning of ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-371334890
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-371334890:1529,Testability,log,log,1529,"i_mosaicism_s',; alpha=1.0,; beta=50.0,; shape=(ploidy_workspace.num_samples,)). # per-sample-and-contig mosaicism factor; f_mosaicism_sj = Beta(name='f_mosaicism_sj',; alpha=10.0,; beta=1.0,; shape=(ploidy_workspace.num_samples, ploidy_workspace.num_contigs,)); norm_f_mosaicism_sj = f_mosaicism_sj / tt.max(f_mosaicism_sj, axis=1).dimshuffle(0, 'x'). # per-contig mapping error; eps_j = HalfNormal('eps_j', sd=0.01, shape=(ploidy_workspace.num_contigs,)). # negative-binomial means; mu_sjk = depth_s.dimshuffle(0, 'x', 'x') * t_j.dimshuffle('x', 0, 'x') * norm_bias_j.dimshuffle('x', 0, 'x') * \; (ploidy_workspace.int_ploidy_values_k.dimshuffle('x', 'x', 0) + eps_j.dimshuffle('x', 0, 'x')); mu_mosaic_sjk = norm_f_mosaicism_sj.dimshuffle(0, 1, 'x') * mu_sjk. # ""unexplained variance""; psi = Uniform(name='psi', upper=10.0). # convert ""unexplained variance"" to negative binomial over-dispersion; alpha = tt.inv((tt.exp(psi) - 1.0)). def _get_logp_sjk(_n_sj):; _logp_sjk = logsumexp([tt.log(1 - pi_mosaicism_s.dimshuffle(0, 'x', 'x')) + commons.negative_binomial_logp(mu_sjk, alpha.dimshuffle('x', 'x', 'x'), _n_sj.dimshuffle(0, 1, 'x')),; tt.log(pi_mosaicism_s.dimshuffle(0, 'x', 'x')) + commons.negative_binomial_logp(mu_mosaic_sjk, alpha.dimshuffle('x', 'x', 'x'), _n_sj.dimshuffle(0, 1, 'x'))],; axis=0)[0]; return _logp_sjk. DensityDist(name='n_sj_obs',; logp=lambda _n_sj: tt.sum(q_ploidy_sjk * _get_logp_sjk(_n_sj), axis=2),; observed=n_sj); ````. Briefly, the model includes 1) per-contig bias (normalized to unit mean for identifiability), 2) per-sample depth, 3) per-sample probability of mosaicism, 4) per-sample-and-contig mosaicism factor `f` (in [0, 1], normalized by the per-sample max for identifiability), 5) per-contig mapping error. The likelihood is then a negative-binomial mixture of non-mosaic and mosaic contigs, where the latter have their mean count depressed by the corresponding factor `f`. This model still requires some tuning of priors (which are currently hard coded ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-371334890
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-371334890:1685,Testability,log,log,1685,"osaicism_sj',; alpha=10.0,; beta=1.0,; shape=(ploidy_workspace.num_samples, ploidy_workspace.num_contigs,)); norm_f_mosaicism_sj = f_mosaicism_sj / tt.max(f_mosaicism_sj, axis=1).dimshuffle(0, 'x'). # per-contig mapping error; eps_j = HalfNormal('eps_j', sd=0.01, shape=(ploidy_workspace.num_contigs,)). # negative-binomial means; mu_sjk = depth_s.dimshuffle(0, 'x', 'x') * t_j.dimshuffle('x', 0, 'x') * norm_bias_j.dimshuffle('x', 0, 'x') * \; (ploidy_workspace.int_ploidy_values_k.dimshuffle('x', 'x', 0) + eps_j.dimshuffle('x', 0, 'x')); mu_mosaic_sjk = norm_f_mosaicism_sj.dimshuffle(0, 1, 'x') * mu_sjk. # ""unexplained variance""; psi = Uniform(name='psi', upper=10.0). # convert ""unexplained variance"" to negative binomial over-dispersion; alpha = tt.inv((tt.exp(psi) - 1.0)). def _get_logp_sjk(_n_sj):; _logp_sjk = logsumexp([tt.log(1 - pi_mosaicism_s.dimshuffle(0, 'x', 'x')) + commons.negative_binomial_logp(mu_sjk, alpha.dimshuffle('x', 'x', 'x'), _n_sj.dimshuffle(0, 1, 'x')),; tt.log(pi_mosaicism_s.dimshuffle(0, 'x', 'x')) + commons.negative_binomial_logp(mu_mosaic_sjk, alpha.dimshuffle('x', 'x', 'x'), _n_sj.dimshuffle(0, 1, 'x'))],; axis=0)[0]; return _logp_sjk. DensityDist(name='n_sj_obs',; logp=lambda _n_sj: tt.sum(q_ploidy_sjk * _get_logp_sjk(_n_sj), axis=2),; observed=n_sj); ````. Briefly, the model includes 1) per-contig bias (normalized to unit mean for identifiability), 2) per-sample depth, 3) per-sample probability of mosaicism, 4) per-sample-and-contig mosaicism factor `f` (in [0, 1], normalized by the per-sample max for identifiability), 5) per-contig mapping error. The likelihood is then a negative-binomial mixture of non-mosaic and mosaic contigs, where the latter have their mean count depressed by the corresponding factor `f`. This model still requires some tuning of priors (which are currently hard coded above), but seems to correctly capture most of the mosaicism in the test samples. Also, I found that it was better to run the aneuploid samples as a cohor",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-371334890
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-371334890:1902,Testability,log,logp,1902,"r-contig mapping error; eps_j = HalfNormal('eps_j', sd=0.01, shape=(ploidy_workspace.num_contigs,)). # negative-binomial means; mu_sjk = depth_s.dimshuffle(0, 'x', 'x') * t_j.dimshuffle('x', 0, 'x') * norm_bias_j.dimshuffle('x', 0, 'x') * \; (ploidy_workspace.int_ploidy_values_k.dimshuffle('x', 'x', 0) + eps_j.dimshuffle('x', 0, 'x')); mu_mosaic_sjk = norm_f_mosaicism_sj.dimshuffle(0, 1, 'x') * mu_sjk. # ""unexplained variance""; psi = Uniform(name='psi', upper=10.0). # convert ""unexplained variance"" to negative binomial over-dispersion; alpha = tt.inv((tt.exp(psi) - 1.0)). def _get_logp_sjk(_n_sj):; _logp_sjk = logsumexp([tt.log(1 - pi_mosaicism_s.dimshuffle(0, 'x', 'x')) + commons.negative_binomial_logp(mu_sjk, alpha.dimshuffle('x', 'x', 'x'), _n_sj.dimshuffle(0, 1, 'x')),; tt.log(pi_mosaicism_s.dimshuffle(0, 'x', 'x')) + commons.negative_binomial_logp(mu_mosaic_sjk, alpha.dimshuffle('x', 'x', 'x'), _n_sj.dimshuffle(0, 1, 'x'))],; axis=0)[0]; return _logp_sjk. DensityDist(name='n_sj_obs',; logp=lambda _n_sj: tt.sum(q_ploidy_sjk * _get_logp_sjk(_n_sj), axis=2),; observed=n_sj); ````. Briefly, the model includes 1) per-contig bias (normalized to unit mean for identifiability), 2) per-sample depth, 3) per-sample probability of mosaicism, 4) per-sample-and-contig mosaicism factor `f` (in [0, 1], normalized by the per-sample max for identifiability), 5) per-contig mapping error. The likelihood is then a negative-binomial mixture of non-mosaic and mosaic contigs, where the latter have their mean count depressed by the corresponding factor `f`. This model still requires some tuning of priors (which are currently hard coded above), but seems to correctly capture most of the mosaicism in the test samples. Also, I found that it was better to run the aneuploid samples as a cohort or to run them in combination with the 20 panel samples as a cohort, rather than to run them in case mode against the panel. We don't necessarily have to emit anything on the mosaicism inferences for t",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-371334890
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-371334890:2609,Testability,test,test,2609,"osaicism_s.dimshuffle(0, 'x', 'x')) + commons.negative_binomial_logp(mu_sjk, alpha.dimshuffle('x', 'x', 'x'), _n_sj.dimshuffle(0, 1, 'x')),; tt.log(pi_mosaicism_s.dimshuffle(0, 'x', 'x')) + commons.negative_binomial_logp(mu_mosaic_sjk, alpha.dimshuffle('x', 'x', 'x'), _n_sj.dimshuffle(0, 1, 'x'))],; axis=0)[0]; return _logp_sjk. DensityDist(name='n_sj_obs',; logp=lambda _n_sj: tt.sum(q_ploidy_sjk * _get_logp_sjk(_n_sj), axis=2),; observed=n_sj); ````. Briefly, the model includes 1) per-contig bias (normalized to unit mean for identifiability), 2) per-sample depth, 3) per-sample probability of mosaicism, 4) per-sample-and-contig mosaicism factor `f` (in [0, 1], normalized by the per-sample max for identifiability), 5) per-contig mapping error. The likelihood is then a negative-binomial mixture of non-mosaic and mosaic contigs, where the latter have their mean count depressed by the corresponding factor `f`. This model still requires some tuning of priors (which are currently hard coded above), but seems to correctly capture most of the mosaicism in the test samples. Also, I found that it was better to run the aneuploid samples as a cohort or to run them in combination with the 20 panel samples as a cohort, rather than to run them in case mode against the panel. We don't necessarily have to emit anything on the mosaicism inferences for the first revision of this model (or we may end up stripping those parts of the model out for now), but I thought it would be good to record this version of the model for posterity. However, note that this model differs from the one currently in master in the treatment of depth. I think the treatment here is quite natural and may be more robust than the current treatment. @mbabadi is going to take over tuning and tweaking the model from this point in the sl_simple_ploidy branch. Note that I haven't cleaned up some of the code and comments yet, but hopefully the changes are relatively clear. I believe I rebased on one of your other branc",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-371334890
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-371334890:162,Usability,simpl,simple,162,"Just some notes before I forget:. Using these test samples, I made some tweaks to the ploidy model that made it more robust to incorrect ploidy calls and added a simple modeling of mosaicism:. ```` ; # per-contig bias; bias_j = Gamma('bias_j',; alpha=100.0,; beta=100.0,; shape=(ploidy_workspace.num_contigs,)); norm_bias_j = bias_j / tt.mean(bias_j). # per-sample depth; depth_s = Uniform('depth_s',; lower=0.0,; upper=10000.0,; shape=(ploidy_workspace.num_samples,)); ; # per-sample probability of mosaicism; pi_mosaicism_s = Beta(name='pi_mosaicism_s',; alpha=1.0,; beta=50.0,; shape=(ploidy_workspace.num_samples,)). # per-sample-and-contig mosaicism factor; f_mosaicism_sj = Beta(name='f_mosaicism_sj',; alpha=10.0,; beta=1.0,; shape=(ploidy_workspace.num_samples, ploidy_workspace.num_contigs,)); norm_f_mosaicism_sj = f_mosaicism_sj / tt.max(f_mosaicism_sj, axis=1).dimshuffle(0, 'x'). # per-contig mapping error; eps_j = HalfNormal('eps_j', sd=0.01, shape=(ploidy_workspace.num_contigs,)). # negative-binomial means; mu_sjk = depth_s.dimshuffle(0, 'x', 'x') * t_j.dimshuffle('x', 0, 'x') * norm_bias_j.dimshuffle('x', 0, 'x') * \; (ploidy_workspace.int_ploidy_values_k.dimshuffle('x', 'x', 0) + eps_j.dimshuffle('x', 0, 'x')); mu_mosaic_sjk = norm_f_mosaicism_sj.dimshuffle(0, 1, 'x') * mu_sjk. # ""unexplained variance""; psi = Uniform(name='psi', upper=10.0). # convert ""unexplained variance"" to negative binomial over-dispersion; alpha = tt.inv((tt.exp(psi) - 1.0)). def _get_logp_sjk(_n_sj):; _logp_sjk = logsumexp([tt.log(1 - pi_mosaicism_s.dimshuffle(0, 'x', 'x')) + commons.negative_binomial_logp(mu_sjk, alpha.dimshuffle('x', 'x', 'x'), _n_sj.dimshuffle(0, 1, 'x')),; tt.log(pi_mosaicism_s.dimshuffle(0, 'x', 'x')) + commons.negative_binomial_logp(mu_mosaic_sjk, alpha.dimshuffle('x', 'x', 'x'), _n_sj.dimshuffle(0, 1, 'x'))],; axis=0)[0]; return _logp_sjk. DensityDist(name='n_sj_obs',; logp=lambda _n_sj: tt.sum(q_ploidy_sjk * _get_logp_sjk(_n_sj), axis=2),; observed=n_sj); ````. Brie",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-371334890
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-371334890:3488,Usability,clear,clear,3488,"l_logp(mu_sjk, alpha.dimshuffle('x', 'x', 'x'), _n_sj.dimshuffle(0, 1, 'x')),; tt.log(pi_mosaicism_s.dimshuffle(0, 'x', 'x')) + commons.negative_binomial_logp(mu_mosaic_sjk, alpha.dimshuffle('x', 'x', 'x'), _n_sj.dimshuffle(0, 1, 'x'))],; axis=0)[0]; return _logp_sjk. DensityDist(name='n_sj_obs',; logp=lambda _n_sj: tt.sum(q_ploidy_sjk * _get_logp_sjk(_n_sj), axis=2),; observed=n_sj); ````. Briefly, the model includes 1) per-contig bias (normalized to unit mean for identifiability), 2) per-sample depth, 3) per-sample probability of mosaicism, 4) per-sample-and-contig mosaicism factor `f` (in [0, 1], normalized by the per-sample max for identifiability), 5) per-contig mapping error. The likelihood is then a negative-binomial mixture of non-mosaic and mosaic contigs, where the latter have their mean count depressed by the corresponding factor `f`. This model still requires some tuning of priors (which are currently hard coded above), but seems to correctly capture most of the mosaicism in the test samples. Also, I found that it was better to run the aneuploid samples as a cohort or to run them in combination with the 20 panel samples as a cohort, rather than to run them in case mode against the panel. We don't necessarily have to emit anything on the mosaicism inferences for the first revision of this model (or we may end up stripping those parts of the model out for now), but I thought it would be good to record this version of the model for posterity. However, note that this model differs from the one currently in master in the treatment of depth. I think the treatment here is quite natural and may be more robust than the current treatment. @mbabadi is going to take over tuning and tweaking the model from this point in the sl_simple_ploidy branch. Note that I haven't cleaned up some of the code and comments yet, but hopefully the changes are relatively clear. I believe I rebased on one of your other branches, so you should remove the corresponding commit and rebase.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-371334890
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376278271:3460,Deployability,Update,Update,3460,"he per-contig coverage histograms (unfiltered bins in blue, bins retained after filtering in red, and negative-binomial fit in green) and a heatmap of per-contig ploidy probabilities. Both the panel (first 20) and case (remaining) samples are shown:. ![prototype-result](https://user-images.githubusercontent.com/11076296/37938642-e9fbd804-312c-11e8-8a6c-02ea4e4fa704.png). Although the prototype model is clearly a good fit to the filtered data, some care in choosing the optimizer and its learning parameters is required to achieve convergence to the correct solution. This is because the problem is inherently multimodal and thus there are many local minima. I found that using AdaMax with a naive strategy of warm restarts (to help kick us out of local minima) worked decently; we can achieve convergence in <10 minutes for 60 samples x 24 contigs x 250 count bins:. ![elbo](https://user-images.githubusercontent.com/11076296/37938658-fc176f12-312c-11e8-89e2-40c68e0f9953.png). I expect that @mbabadi's annealing implementation in the gcnvkernel package will handle the local minima much better. The course of action needed to implement this model should be as follows:. 1) Alter Java code to emit per-contig histograms. Change python code to consume histograms, perform filtering, and fit using the above model (or some variation).; 2) Choose learning parameters appropriate with annealing and check that results are still good.; 3) Update gCNV model to consume the depth emitted by this model properly, if necessary, and rerun evaluations. Other improvements enabled by mappability filtering (as discussed in #4558) or coverage collection can follow this initial model revision. In the meantime, we will continue the first round of evaluations using the old ploidy model, spot checking genotype calls as necessary. This will allow us to tune gCNV parameters (which will hopefully be largely unaffected by any changes to the ploidy model). How does this sound, @ldgauthier @mbabadi @asmirnov239?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376278271
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376278271:977,Energy Efficiency,power,powerful,977,"d by some of the discussion and work by @mbabadi in #4558, I quickly revisited the revision of the ploidy model. The key difference is now we use the per-contig coverage *histogram* (rather than just the per-contig total coverage). This histogram conveys a lot more information and, with some naive filtering (see more discussion in #4558), provides relatively easy peaks to fit. I think this is a better solution than subsampling intervals and fitting a model that would require modeling per-interval bias. Another key change I added was to provide *per-genotype* priors, rather than per-contig priors. For the autosomes, this is immaterial, but it's extremely useful for the allosomes. That is, we currently provide per-contig priors like so:. ````; CONTIG PLOIDY_0 PLOIDY_1 PLOIDY_2 PLOIDY_3; 1 0.0 0.0 1.0 0.0; ...; X 0.01 0.48 0.48 0.01; Y 0.48 0.48 0.01 0.01; ````. However, note that this implies that X and XXY are just as probable as XX and XY! It's much more powerful to be able to specify *per-genotype* priors (although this requires a bit more bookkeeping when translating to implications for per-contig histograms):. ````; CONTIG_SET PLOIDY_STATE RELATIVE_PROBABILITY; (1) (2) 1.0; ...; (X,Y) (2,0) 1.0; (X,Y) (1,1) 1.0; (X,Y) (1,0) 0.01; (X,Y) (2,1) 0.01; (X,Y) (1,2) 0.01; (X,Y) (3,0) 0.01; ````. We then fit the per-contig coverage histograms across all samples with the appropriate negative-binomial distributions corresponding to a sparse mixture of genotypes, while accounting for 1) sample-specific depth (which determines the means of the negative-binomial distributions), 2) multiplicative contig-specific bias (which is mild, at least for WGS), and 3) additive sample-contig-specific mosaicism or bias (note that the above genotype priors imply that mosaicism/bias on top of a baseline of CN = 2 is the only deviation allowed for the autosomes, which is somewhat restrictive but greatly aids convergence). I put together a pure PyMC3 prototype that seems to work relatively wel",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376278271
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376278271:2149,Energy Efficiency,green,green,2149,"s for per-contig histograms):. ````; CONTIG_SET PLOIDY_STATE RELATIVE_PROBABILITY; (1) (2) 1.0; ...; (X,Y) (2,0) 1.0; (X,Y) (1,1) 1.0; (X,Y) (1,0) 0.01; (X,Y) (2,1) 0.01; (X,Y) (1,2) 0.01; (X,Y) (3,0) 0.01; ````. We then fit the per-contig coverage histograms across all samples with the appropriate negative-binomial distributions corresponding to a sparse mixture of genotypes, while accounting for 1) sample-specific depth (which determines the means of the negative-binomial distributions), 2) multiplicative contig-specific bias (which is mild, at least for WGS), and 3) additive sample-contig-specific mosaicism or bias (note that the above genotype priors imply that mosaicism/bias on top of a baseline of CN = 2 is the only deviation allowed for the autosomes, which is somewhat restrictive but greatly aids convergence). I put together a pure PyMC3 prototype that seems to work relatively well. Here are the per-contig coverage histograms (unfiltered bins in blue, bins retained after filtering in red, and negative-binomial fit in green) and a heatmap of per-contig ploidy probabilities. Both the panel (first 20) and case (remaining) samples are shown:. ![prototype-result](https://user-images.githubusercontent.com/11076296/37938642-e9fbd804-312c-11e8-8a6c-02ea4e4fa704.png). Although the prototype model is clearly a good fit to the filtered data, some care in choosing the optimizer and its learning parameters is required to achieve convergence to the correct solution. This is because the problem is inherently multimodal and thus there are many local minima. I found that using AdaMax with a naive strategy of warm restarts (to help kick us out of local minima) worked decently; we can achieve convergence in <10 minutes for 60 samples x 24 contigs x 250 count bins:. ![elbo](https://user-images.githubusercontent.com/11076296/37938658-fc176f12-312c-11e8-89e2-40c68e0f9953.png). I expect that @mbabadi's annealing implementation in the gcnvkernel package will handle the local minima",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376278271
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376278271:2495,Performance,optimiz,optimizer,2495," accounting for 1) sample-specific depth (which determines the means of the negative-binomial distributions), 2) multiplicative contig-specific bias (which is mild, at least for WGS), and 3) additive sample-contig-specific mosaicism or bias (note that the above genotype priors imply that mosaicism/bias on top of a baseline of CN = 2 is the only deviation allowed for the autosomes, which is somewhat restrictive but greatly aids convergence). I put together a pure PyMC3 prototype that seems to work relatively well. Here are the per-contig coverage histograms (unfiltered bins in blue, bins retained after filtering in red, and negative-binomial fit in green) and a heatmap of per-contig ploidy probabilities. Both the panel (first 20) and case (remaining) samples are shown:. ![prototype-result](https://user-images.githubusercontent.com/11076296/37938642-e9fbd804-312c-11e8-8a6c-02ea4e4fa704.png). Although the prototype model is clearly a good fit to the filtered data, some care in choosing the optimizer and its learning parameters is required to achieve convergence to the correct solution. This is because the problem is inherently multimodal and thus there are many local minima. I found that using AdaMax with a naive strategy of warm restarts (to help kick us out of local minima) worked decently; we can achieve convergence in <10 minutes for 60 samples x 24 contigs x 250 count bins:. ![elbo](https://user-images.githubusercontent.com/11076296/37938658-fc176f12-312c-11e8-89e2-40c68e0f9953.png). I expect that @mbabadi's annealing implementation in the gcnvkernel package will handle the local minima much better. The course of action needed to implement this model should be as follows:. 1) Alter Java code to emit per-contig histograms. Change python code to consume histograms, perform filtering, and fit using the above model (or some variation).; 2) Choose learning parameters appropriate with annealing and check that results are still good.; 3) Update gCNV model to consume the d",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376278271
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376278271:3289,Performance,perform,perform,3289,"he per-contig coverage histograms (unfiltered bins in blue, bins retained after filtering in red, and negative-binomial fit in green) and a heatmap of per-contig ploidy probabilities. Both the panel (first 20) and case (remaining) samples are shown:. ![prototype-result](https://user-images.githubusercontent.com/11076296/37938642-e9fbd804-312c-11e8-8a6c-02ea4e4fa704.png). Although the prototype model is clearly a good fit to the filtered data, some care in choosing the optimizer and its learning parameters is required to achieve convergence to the correct solution. This is because the problem is inherently multimodal and thus there are many local minima. I found that using AdaMax with a naive strategy of warm restarts (to help kick us out of local minima) worked decently; we can achieve convergence in <10 minutes for 60 samples x 24 contigs x 250 count bins:. ![elbo](https://user-images.githubusercontent.com/11076296/37938658-fc176f12-312c-11e8-89e2-40c68e0f9953.png). I expect that @mbabadi's annealing implementation in the gcnvkernel package will handle the local minima much better. The course of action needed to implement this model should be as follows:. 1) Alter Java code to emit per-contig histograms. Change python code to consume histograms, perform filtering, and fit using the above model (or some variation).; 2) Choose learning parameters appropriate with annealing and check that results are still good.; 3) Update gCNV model to consume the depth emitted by this model properly, if necessary, and rerun evaluations. Other improvements enabled by mappability filtering (as discussed in #4558) or coverage collection can follow this initial model revision. In the meantime, we will continue the first round of evaluations using the old ploidy model, spot checking genotype calls as necessary. This will allow us to tune gCNV parameters (which will hopefully be largely unaffected by any changes to the ploidy model). How does this sound, @ldgauthier @mbabadi @asmirnov239?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376278271
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376278271:3865,Performance,tune,tune,3865,"he per-contig coverage histograms (unfiltered bins in blue, bins retained after filtering in red, and negative-binomial fit in green) and a heatmap of per-contig ploidy probabilities. Both the panel (first 20) and case (remaining) samples are shown:. ![prototype-result](https://user-images.githubusercontent.com/11076296/37938642-e9fbd804-312c-11e8-8a6c-02ea4e4fa704.png). Although the prototype model is clearly a good fit to the filtered data, some care in choosing the optimizer and its learning parameters is required to achieve convergence to the correct solution. This is because the problem is inherently multimodal and thus there are many local minima. I found that using AdaMax with a naive strategy of warm restarts (to help kick us out of local minima) worked decently; we can achieve convergence in <10 minutes for 60 samples x 24 contigs x 250 count bins:. ![elbo](https://user-images.githubusercontent.com/11076296/37938658-fc176f12-312c-11e8-89e2-40c68e0f9953.png). I expect that @mbabadi's annealing implementation in the gcnvkernel package will handle the local minima much better. The course of action needed to implement this model should be as follows:. 1) Alter Java code to emit per-contig histograms. Change python code to consume histograms, perform filtering, and fit using the above model (or some variation).; 2) Choose learning parameters appropriate with annealing and check that results are still good.; 3) Update gCNV model to consume the depth emitted by this model properly, if necessary, and rerun evaluations. Other improvements enabled by mappability filtering (as discussed in #4558) or coverage collection can follow this initial model revision. In the meantime, we will continue the first round of evaluations using the old ploidy model, spot checking genotype calls as necessary. This will allow us to tune gCNV parameters (which will hopefully be largely unaffected by any changes to the ploidy model). How does this sound, @ldgauthier @mbabadi @asmirnov239?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376278271
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376278271:2428,Usability,clear,clearly,2428," accounting for 1) sample-specific depth (which determines the means of the negative-binomial distributions), 2) multiplicative contig-specific bias (which is mild, at least for WGS), and 3) additive sample-contig-specific mosaicism or bias (note that the above genotype priors imply that mosaicism/bias on top of a baseline of CN = 2 is the only deviation allowed for the autosomes, which is somewhat restrictive but greatly aids convergence). I put together a pure PyMC3 prototype that seems to work relatively well. Here are the per-contig coverage histograms (unfiltered bins in blue, bins retained after filtering in red, and negative-binomial fit in green) and a heatmap of per-contig ploidy probabilities. Both the panel (first 20) and case (remaining) samples are shown:. ![prototype-result](https://user-images.githubusercontent.com/11076296/37938642-e9fbd804-312c-11e8-8a6c-02ea4e4fa704.png). Although the prototype model is clearly a good fit to the filtered data, some care in choosing the optimizer and its learning parameters is required to achieve convergence to the correct solution. This is because the problem is inherently multimodal and thus there are many local minima. I found that using AdaMax with a naive strategy of warm restarts (to help kick us out of local minima) worked decently; we can achieve convergence in <10 minutes for 60 samples x 24 contigs x 250 count bins:. ![elbo](https://user-images.githubusercontent.com/11076296/37938658-fc176f12-312c-11e8-89e2-40c68e0f9953.png). I expect that @mbabadi's annealing implementation in the gcnvkernel package will handle the local minima much better. The course of action needed to implement this model should be as follows:. 1) Alter Java code to emit per-contig histograms. Change python code to consume histograms, perform filtering, and fit using the above model (or some variation).; 2) Choose learning parameters appropriate with annealing and check that results are still good.; 3) Update gCNV model to consume the d",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376278271
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376278271:2513,Usability,learn,learning,2513," accounting for 1) sample-specific depth (which determines the means of the negative-binomial distributions), 2) multiplicative contig-specific bias (which is mild, at least for WGS), and 3) additive sample-contig-specific mosaicism or bias (note that the above genotype priors imply that mosaicism/bias on top of a baseline of CN = 2 is the only deviation allowed for the autosomes, which is somewhat restrictive but greatly aids convergence). I put together a pure PyMC3 prototype that seems to work relatively well. Here are the per-contig coverage histograms (unfiltered bins in blue, bins retained after filtering in red, and negative-binomial fit in green) and a heatmap of per-contig ploidy probabilities. Both the panel (first 20) and case (remaining) samples are shown:. ![prototype-result](https://user-images.githubusercontent.com/11076296/37938642-e9fbd804-312c-11e8-8a6c-02ea4e4fa704.png). Although the prototype model is clearly a good fit to the filtered data, some care in choosing the optimizer and its learning parameters is required to achieve convergence to the correct solution. This is because the problem is inherently multimodal and thus there are many local minima. I found that using AdaMax with a naive strategy of warm restarts (to help kick us out of local minima) worked decently; we can achieve convergence in <10 minutes for 60 samples x 24 contigs x 250 count bins:. ![elbo](https://user-images.githubusercontent.com/11076296/37938658-fc176f12-312c-11e8-89e2-40c68e0f9953.png). I expect that @mbabadi's annealing implementation in the gcnvkernel package will handle the local minima much better. The course of action needed to implement this model should be as follows:. 1) Alter Java code to emit per-contig histograms. Change python code to consume histograms, perform filtering, and fit using the above model (or some variation).; 2) Choose learning parameters appropriate with annealing and check that results are still good.; 3) Update gCNV model to consume the d",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376278271
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376278271:3370,Usability,learn,learning,3370,"he per-contig coverage histograms (unfiltered bins in blue, bins retained after filtering in red, and negative-binomial fit in green) and a heatmap of per-contig ploidy probabilities. Both the panel (first 20) and case (remaining) samples are shown:. ![prototype-result](https://user-images.githubusercontent.com/11076296/37938642-e9fbd804-312c-11e8-8a6c-02ea4e4fa704.png). Although the prototype model is clearly a good fit to the filtered data, some care in choosing the optimizer and its learning parameters is required to achieve convergence to the correct solution. This is because the problem is inherently multimodal and thus there are many local minima. I found that using AdaMax with a naive strategy of warm restarts (to help kick us out of local minima) worked decently; we can achieve convergence in <10 minutes for 60 samples x 24 contigs x 250 count bins:. ![elbo](https://user-images.githubusercontent.com/11076296/37938658-fc176f12-312c-11e8-89e2-40c68e0f9953.png). I expect that @mbabadi's annealing implementation in the gcnvkernel package will handle the local minima much better. The course of action needed to implement this model should be as follows:. 1) Alter Java code to emit per-contig histograms. Change python code to consume histograms, perform filtering, and fit using the above model (or some variation).; 2) Choose learning parameters appropriate with annealing and check that results are still good.; 3) Update gCNV model to consume the depth emitted by this model properly, if necessary, and rerun evaluations. Other improvements enabled by mappability filtering (as discussed in #4558) or coverage collection can follow this initial model revision. In the meantime, we will continue the first round of evaluations using the old ploidy model, spot checking genotype calls as necessary. This will allow us to tune gCNV parameters (which will hopefully be largely unaffected by any changes to the ploidy model). How does this sound, @ldgauthier @mbabadi @asmirnov239?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376278271
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376280402:183,Testability,test,testval,183,"For the record, here is the (uncommented and raw) code for the prototype model:. ````; mask_sjm, _ = construct_mask(hist_sjm). d_s = pm.Uniform('d_s', upper=1000., shape=num_samples, testval=40.). b_j = pm.Bound(pm.Gamma, lower=0.8, upper=1.2)('b_j', alpha=100, beta=100, shape=num_contigs); b_j_norm = pm.Deterministic('b_j_norm', var=b_j / tt.mean(b_j)). f_js = pm.Bound(pm.Normal, lower=-0.9, upper=0.5)('f_js', sd=0.01, shape=(num_contigs, num_samples)). pi_i_sk = [pm.Dirichlet('pi_%d_sk' % i, a=ploidy_concentration_scale * ploidy_priors_ik[i], ; shape=(num_samples, len(ploidy_states_ik[i])), ; transform=pm.distributions.transforms.t_stick_breaking(eps)); if len(contig_set) > 1 else pm.Deterministic('pi_%d_sk' % i, var=tt.ones((num_samples, 1))); for i, contig_set in enumerate(contig_sets)]. e_js = pm.Uniform('e_js', lower=0., upper=0.1, shape=(num_contigs, num_samples)). mu_j_sk = [d_s.dimshuffle(0, 'x') * b_j_norm[j] * \; (tt.maximum(ploidy_jk[j][np.newaxis, :] + f_js[j].dimshuffle(0, 'x') * (ploidy_jk[j][np.newaxis, :] > 0),; e_js[j].dimshuffle(0, 'x'))); for j in range(num_contigs)]; alpha_js = pm.Uniform('alpha_js', upper=10000., shape=(num_contigs, num_samples)); p_j_skm = [tt.exp(pm.NegativeBinomial.dist(mu=mu_j_sk[j].dimshuffle(0, 1, 'x') + eps,; alpha=alpha_js[j].dimshuffle(0, 'x', 'x')); .logp(tt.arange(min_count, max_count + 1).dimshuffle('x', 'x', 0))); for j in range(num_contigs)]. def _logp_sjm(_hist_sjm):; num_occurrences_tot_sj = tt.sum(_hist_sjm * mask_sjm, axis=2); logp_j_skm = [pm.Poisson.dist(mu=num_occurrences_tot_sj[:, j].dimshuffle(0, 'x', 'x') * p_j_skm[j] + eps) \; .logp(_hist_sjm[:, j, :].dimshuffle(0, 'x', 1)); for j in range(num_contigs)]; return tt.sum(; [pm.math.logsumexp(; mask_sjm[:, j, np.newaxis, :] * (tt.log(pi_i_sk[i][:, :, np.newaxis] + eps) + logp_j_skm[j]),; axis=1) ; for i, contig_set in enumerate(contig_sets) for j in contig_set]). pm.DensityDist(name='hist_sjm', logp=_logp_sjm, observed=hist_sjm); ````. We can probably tidy t",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376280402
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376280402:1320,Testability,log,logp,1320,"_norm', var=b_j / tt.mean(b_j)). f_js = pm.Bound(pm.Normal, lower=-0.9, upper=0.5)('f_js', sd=0.01, shape=(num_contigs, num_samples)). pi_i_sk = [pm.Dirichlet('pi_%d_sk' % i, a=ploidy_concentration_scale * ploidy_priors_ik[i], ; shape=(num_samples, len(ploidy_states_ik[i])), ; transform=pm.distributions.transforms.t_stick_breaking(eps)); if len(contig_set) > 1 else pm.Deterministic('pi_%d_sk' % i, var=tt.ones((num_samples, 1))); for i, contig_set in enumerate(contig_sets)]. e_js = pm.Uniform('e_js', lower=0., upper=0.1, shape=(num_contigs, num_samples)). mu_j_sk = [d_s.dimshuffle(0, 'x') * b_j_norm[j] * \; (tt.maximum(ploidy_jk[j][np.newaxis, :] + f_js[j].dimshuffle(0, 'x') * (ploidy_jk[j][np.newaxis, :] > 0),; e_js[j].dimshuffle(0, 'x'))); for j in range(num_contigs)]; alpha_js = pm.Uniform('alpha_js', upper=10000., shape=(num_contigs, num_samples)); p_j_skm = [tt.exp(pm.NegativeBinomial.dist(mu=mu_j_sk[j].dimshuffle(0, 1, 'x') + eps,; alpha=alpha_js[j].dimshuffle(0, 'x', 'x')); .logp(tt.arange(min_count, max_count + 1).dimshuffle('x', 'x', 0))); for j in range(num_contigs)]. def _logp_sjm(_hist_sjm):; num_occurrences_tot_sj = tt.sum(_hist_sjm * mask_sjm, axis=2); logp_j_skm = [pm.Poisson.dist(mu=num_occurrences_tot_sj[:, j].dimshuffle(0, 'x', 'x') * p_j_skm[j] + eps) \; .logp(_hist_sjm[:, j, :].dimshuffle(0, 'x', 1)); for j in range(num_contigs)]; return tt.sum(; [pm.math.logsumexp(; mask_sjm[:, j, np.newaxis, :] * (tt.log(pi_i_sk[i][:, :, np.newaxis] + eps) + logp_j_skm[j]),; axis=1) ; for i, contig_set in enumerate(contig_sets) for j in contig_set]). pm.DensityDist(name='hist_sjm', logp=_logp_sjm, observed=hist_sjm); ````. We can probably tidy this up in several ways (both in terms of code cleanliness and model cleanliness), but it works. Some of the priors can probably be cleaned up---especially note the awkward bounded prior for the additive mosaic factor `f_js`. Also note that I used list comprehension because of the differing number of ploidy states across c",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376280402
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376280402:1618,Testability,log,logp,1618,"Dirichlet('pi_%d_sk' % i, a=ploidy_concentration_scale * ploidy_priors_ik[i], ; shape=(num_samples, len(ploidy_states_ik[i])), ; transform=pm.distributions.transforms.t_stick_breaking(eps)); if len(contig_set) > 1 else pm.Deterministic('pi_%d_sk' % i, var=tt.ones((num_samples, 1))); for i, contig_set in enumerate(contig_sets)]. e_js = pm.Uniform('e_js', lower=0., upper=0.1, shape=(num_contigs, num_samples)). mu_j_sk = [d_s.dimshuffle(0, 'x') * b_j_norm[j] * \; (tt.maximum(ploidy_jk[j][np.newaxis, :] + f_js[j].dimshuffle(0, 'x') * (ploidy_jk[j][np.newaxis, :] > 0),; e_js[j].dimshuffle(0, 'x'))); for j in range(num_contigs)]; alpha_js = pm.Uniform('alpha_js', upper=10000., shape=(num_contigs, num_samples)); p_j_skm = [tt.exp(pm.NegativeBinomial.dist(mu=mu_j_sk[j].dimshuffle(0, 1, 'x') + eps,; alpha=alpha_js[j].dimshuffle(0, 'x', 'x')); .logp(tt.arange(min_count, max_count + 1).dimshuffle('x', 'x', 0))); for j in range(num_contigs)]. def _logp_sjm(_hist_sjm):; num_occurrences_tot_sj = tt.sum(_hist_sjm * mask_sjm, axis=2); logp_j_skm = [pm.Poisson.dist(mu=num_occurrences_tot_sj[:, j].dimshuffle(0, 'x', 'x') * p_j_skm[j] + eps) \; .logp(_hist_sjm[:, j, :].dimshuffle(0, 'x', 1)); for j in range(num_contigs)]; return tt.sum(; [pm.math.logsumexp(; mask_sjm[:, j, np.newaxis, :] * (tt.log(pi_i_sk[i][:, :, np.newaxis] + eps) + logp_j_skm[j]),; axis=1) ; for i, contig_set in enumerate(contig_sets) for j in contig_set]). pm.DensityDist(name='hist_sjm', logp=_logp_sjm, observed=hist_sjm); ````. We can probably tidy this up in several ways (both in terms of code cleanliness and model cleanliness), but it works. Some of the priors can probably be cleaned up---especially note the awkward bounded prior for the additive mosaic factor `f_js`. Also note that I used list comprehension because of the differing number of ploidy states across contig sets, which results in a ragged tensor; this does seem to add some overhead to theano, so we can probably pad the tensor and vectorize instead.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376280402
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376280402:1721,Testability,log,logsumexp,1721,"Dirichlet('pi_%d_sk' % i, a=ploidy_concentration_scale * ploidy_priors_ik[i], ; shape=(num_samples, len(ploidy_states_ik[i])), ; transform=pm.distributions.transforms.t_stick_breaking(eps)); if len(contig_set) > 1 else pm.Deterministic('pi_%d_sk' % i, var=tt.ones((num_samples, 1))); for i, contig_set in enumerate(contig_sets)]. e_js = pm.Uniform('e_js', lower=0., upper=0.1, shape=(num_contigs, num_samples)). mu_j_sk = [d_s.dimshuffle(0, 'x') * b_j_norm[j] * \; (tt.maximum(ploidy_jk[j][np.newaxis, :] + f_js[j].dimshuffle(0, 'x') * (ploidy_jk[j][np.newaxis, :] > 0),; e_js[j].dimshuffle(0, 'x'))); for j in range(num_contigs)]; alpha_js = pm.Uniform('alpha_js', upper=10000., shape=(num_contigs, num_samples)); p_j_skm = [tt.exp(pm.NegativeBinomial.dist(mu=mu_j_sk[j].dimshuffle(0, 1, 'x') + eps,; alpha=alpha_js[j].dimshuffle(0, 'x', 'x')); .logp(tt.arange(min_count, max_count + 1).dimshuffle('x', 'x', 0))); for j in range(num_contigs)]. def _logp_sjm(_hist_sjm):; num_occurrences_tot_sj = tt.sum(_hist_sjm * mask_sjm, axis=2); logp_j_skm = [pm.Poisson.dist(mu=num_occurrences_tot_sj[:, j].dimshuffle(0, 'x', 'x') * p_j_skm[j] + eps) \; .logp(_hist_sjm[:, j, :].dimshuffle(0, 'x', 1)); for j in range(num_contigs)]; return tt.sum(; [pm.math.logsumexp(; mask_sjm[:, j, np.newaxis, :] * (tt.log(pi_i_sk[i][:, :, np.newaxis] + eps) + logp_j_skm[j]),; axis=1) ; for i, contig_set in enumerate(contig_sets) for j in contig_set]). pm.DensityDist(name='hist_sjm', logp=_logp_sjm, observed=hist_sjm); ````. We can probably tidy this up in several ways (both in terms of code cleanliness and model cleanliness), but it works. Some of the priors can probably be cleaned up---especially note the awkward bounded prior for the additive mosaic factor `f_js`. Also note that I used list comprehension because of the differing number of ploidy states across contig sets, which results in a ragged tensor; this does seem to add some overhead to theano, so we can probably pad the tensor and vectorize instead.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376280402
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376280402:1769,Testability,log,log,1769,"Dirichlet('pi_%d_sk' % i, a=ploidy_concentration_scale * ploidy_priors_ik[i], ; shape=(num_samples, len(ploidy_states_ik[i])), ; transform=pm.distributions.transforms.t_stick_breaking(eps)); if len(contig_set) > 1 else pm.Deterministic('pi_%d_sk' % i, var=tt.ones((num_samples, 1))); for i, contig_set in enumerate(contig_sets)]. e_js = pm.Uniform('e_js', lower=0., upper=0.1, shape=(num_contigs, num_samples)). mu_j_sk = [d_s.dimshuffle(0, 'x') * b_j_norm[j] * \; (tt.maximum(ploidy_jk[j][np.newaxis, :] + f_js[j].dimshuffle(0, 'x') * (ploidy_jk[j][np.newaxis, :] > 0),; e_js[j].dimshuffle(0, 'x'))); for j in range(num_contigs)]; alpha_js = pm.Uniform('alpha_js', upper=10000., shape=(num_contigs, num_samples)); p_j_skm = [tt.exp(pm.NegativeBinomial.dist(mu=mu_j_sk[j].dimshuffle(0, 1, 'x') + eps,; alpha=alpha_js[j].dimshuffle(0, 'x', 'x')); .logp(tt.arange(min_count, max_count + 1).dimshuffle('x', 'x', 0))); for j in range(num_contigs)]. def _logp_sjm(_hist_sjm):; num_occurrences_tot_sj = tt.sum(_hist_sjm * mask_sjm, axis=2); logp_j_skm = [pm.Poisson.dist(mu=num_occurrences_tot_sj[:, j].dimshuffle(0, 'x', 'x') * p_j_skm[j] + eps) \; .logp(_hist_sjm[:, j, :].dimshuffle(0, 'x', 1)); for j in range(num_contigs)]; return tt.sum(; [pm.math.logsumexp(; mask_sjm[:, j, np.newaxis, :] * (tt.log(pi_i_sk[i][:, :, np.newaxis] + eps) + logp_j_skm[j]),; axis=1) ; for i, contig_set in enumerate(contig_sets) for j in contig_set]). pm.DensityDist(name='hist_sjm', logp=_logp_sjm, observed=hist_sjm); ````. We can probably tidy this up in several ways (both in terms of code cleanliness and model cleanliness), but it works. Some of the priors can probably be cleaned up---especially note the awkward bounded prior for the additive mosaic factor `f_js`. Also note that I used list comprehension because of the differing number of ploidy states across contig sets, which results in a ragged tensor; this does seem to add some overhead to theano, so we can probably pad the tensor and vectorize instead.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376280402
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376280402:1937,Testability,log,logp,1937,"Dirichlet('pi_%d_sk' % i, a=ploidy_concentration_scale * ploidy_priors_ik[i], ; shape=(num_samples, len(ploidy_states_ik[i])), ; transform=pm.distributions.transforms.t_stick_breaking(eps)); if len(contig_set) > 1 else pm.Deterministic('pi_%d_sk' % i, var=tt.ones((num_samples, 1))); for i, contig_set in enumerate(contig_sets)]. e_js = pm.Uniform('e_js', lower=0., upper=0.1, shape=(num_contigs, num_samples)). mu_j_sk = [d_s.dimshuffle(0, 'x') * b_j_norm[j] * \; (tt.maximum(ploidy_jk[j][np.newaxis, :] + f_js[j].dimshuffle(0, 'x') * (ploidy_jk[j][np.newaxis, :] > 0),; e_js[j].dimshuffle(0, 'x'))); for j in range(num_contigs)]; alpha_js = pm.Uniform('alpha_js', upper=10000., shape=(num_contigs, num_samples)); p_j_skm = [tt.exp(pm.NegativeBinomial.dist(mu=mu_j_sk[j].dimshuffle(0, 1, 'x') + eps,; alpha=alpha_js[j].dimshuffle(0, 'x', 'x')); .logp(tt.arange(min_count, max_count + 1).dimshuffle('x', 'x', 0))); for j in range(num_contigs)]. def _logp_sjm(_hist_sjm):; num_occurrences_tot_sj = tt.sum(_hist_sjm * mask_sjm, axis=2); logp_j_skm = [pm.Poisson.dist(mu=num_occurrences_tot_sj[:, j].dimshuffle(0, 'x', 'x') * p_j_skm[j] + eps) \; .logp(_hist_sjm[:, j, :].dimshuffle(0, 'x', 1)); for j in range(num_contigs)]; return tt.sum(; [pm.math.logsumexp(; mask_sjm[:, j, np.newaxis, :] * (tt.log(pi_i_sk[i][:, :, np.newaxis] + eps) + logp_j_skm[j]),; axis=1) ; for i, contig_set in enumerate(contig_sets) for j in contig_set]). pm.DensityDist(name='hist_sjm', logp=_logp_sjm, observed=hist_sjm); ````. We can probably tidy this up in several ways (both in terms of code cleanliness and model cleanliness), but it works. Some of the priors can probably be cleaned up---especially note the awkward bounded prior for the additive mosaic factor `f_js`. Also note that I used list comprehension because of the differing number of ploidy states across contig sets, which results in a ragged tensor; this does seem to add some overhead to theano, so we can probably pad the tensor and vectorize instead.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376280402
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376286536:883,Availability,down,down,883,"Looks great!. One quick note: I don't get the idea behind `Poisson` -- shouldn't we simply use negative binomials w/ modeled `mu_sj` and `alpha_sj`, evaluated at observed counts (`tt.arange(min_count, max_count + 1)`), and weighted with the number bins for each count (`_hist_sjm`)? i.e. if one observes an empirical distribution `P_obs(x)` rather than `x` draws, then the appropriate max likelihood objective function is `\sum_x P_obs(x) log P_model(x | \theta)`. Perhaps this is exactly what you've done and I don't get it. Another quick note: what I had in mind was _either_ modeling `mu_sj` at quantized ploidy states, _or_ let the ploidy state be unrestricted w/ a penalty via. a Bernoulli process (possibly w/ different per-contig penalties to account for e.g. higher rate of X/Y loss). We have enough samples in the cohort to select the quantized model (and those samples pin down the per-contig biases `b_j`). The samples that do not conform to quantized ploidy states can then choose whatever (variable) ploidy state they wish by paying a (hefty) price. We would also need to mask contigs that have variable ploidy calls from gCNV.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376286536
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376286536:1085,Availability,mask,mask,1085,"Looks great!. One quick note: I don't get the idea behind `Poisson` -- shouldn't we simply use negative binomials w/ modeled `mu_sj` and `alpha_sj`, evaluated at observed counts (`tt.arange(min_count, max_count + 1)`), and weighted with the number bins for each count (`_hist_sjm`)? i.e. if one observes an empirical distribution `P_obs(x)` rather than `x` draws, then the appropriate max likelihood objective function is `\sum_x P_obs(x) log P_model(x | \theta)`. Perhaps this is exactly what you've done and I don't get it. Another quick note: what I had in mind was _either_ modeling `mu_sj` at quantized ploidy states, _or_ let the ploidy state be unrestricted w/ a penalty via. a Bernoulli process (possibly w/ different per-contig penalties to account for e.g. higher rate of X/Y loss). We have enough samples in the cohort to select the quantized model (and those samples pin down the per-contig biases `b_j`). The samples that do not conform to quantized ploidy states can then choose whatever (variable) ploidy state they wish by paying a (hefty) price. We would also need to mask contigs that have variable ploidy calls from gCNV.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376286536
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376286536:1003,Modifiability,variab,variable,1003,"Looks great!. One quick note: I don't get the idea behind `Poisson` -- shouldn't we simply use negative binomials w/ modeled `mu_sj` and `alpha_sj`, evaluated at observed counts (`tt.arange(min_count, max_count + 1)`), and weighted with the number bins for each count (`_hist_sjm`)? i.e. if one observes an empirical distribution `P_obs(x)` rather than `x` draws, then the appropriate max likelihood objective function is `\sum_x P_obs(x) log P_model(x | \theta)`. Perhaps this is exactly what you've done and I don't get it. Another quick note: what I had in mind was _either_ modeling `mu_sj` at quantized ploidy states, _or_ let the ploidy state be unrestricted w/ a penalty via. a Bernoulli process (possibly w/ different per-contig penalties to account for e.g. higher rate of X/Y loss). We have enough samples in the cohort to select the quantized model (and those samples pin down the per-contig biases `b_j`). The samples that do not conform to quantized ploidy states can then choose whatever (variable) ploidy state they wish by paying a (hefty) price. We would also need to mask contigs that have variable ploidy calls from gCNV.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376286536
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376286536:1108,Modifiability,variab,variable,1108,"Looks great!. One quick note: I don't get the idea behind `Poisson` -- shouldn't we simply use negative binomials w/ modeled `mu_sj` and `alpha_sj`, evaluated at observed counts (`tt.arange(min_count, max_count + 1)`), and weighted with the number bins for each count (`_hist_sjm`)? i.e. if one observes an empirical distribution `P_obs(x)` rather than `x` draws, then the appropriate max likelihood objective function is `\sum_x P_obs(x) log P_model(x | \theta)`. Perhaps this is exactly what you've done and I don't get it. Another quick note: what I had in mind was _either_ modeling `mu_sj` at quantized ploidy states, _or_ let the ploidy state be unrestricted w/ a penalty via. a Bernoulli process (possibly w/ different per-contig penalties to account for e.g. higher rate of X/Y loss). We have enough samples in the cohort to select the quantized model (and those samples pin down the per-contig biases `b_j`). The samples that do not conform to quantized ploidy states can then choose whatever (variable) ploidy state they wish by paying a (hefty) price. We would also need to mask contigs that have variable ploidy calls from gCNV.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376286536
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376286536:439,Testability,log,log,439,"Looks great!. One quick note: I don't get the idea behind `Poisson` -- shouldn't we simply use negative binomials w/ modeled `mu_sj` and `alpha_sj`, evaluated at observed counts (`tt.arange(min_count, max_count + 1)`), and weighted with the number bins for each count (`_hist_sjm`)? i.e. if one observes an empirical distribution `P_obs(x)` rather than `x` draws, then the appropriate max likelihood objective function is `\sum_x P_obs(x) log P_model(x | \theta)`. Perhaps this is exactly what you've done and I don't get it. Another quick note: what I had in mind was _either_ modeling `mu_sj` at quantized ploidy states, _or_ let the ploidy state be unrestricted w/ a penalty via. a Bernoulli process (possibly w/ different per-contig penalties to account for e.g. higher rate of X/Y loss). We have enough samples in the cohort to select the quantized model (and those samples pin down the per-contig biases `b_j`). The samples that do not conform to quantized ploidy states can then choose whatever (variable) ploidy state they wish by paying a (hefty) price. We would also need to mask contigs that have variable ploidy calls from gCNV.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376286536
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376286536:84,Usability,simpl,simply,84,"Looks great!. One quick note: I don't get the idea behind `Poisson` -- shouldn't we simply use negative binomials w/ modeled `mu_sj` and `alpha_sj`, evaluated at observed counts (`tt.arange(min_count, max_count + 1)`), and weighted with the number bins for each count (`_hist_sjm`)? i.e. if one observes an empirical distribution `P_obs(x)` rather than `x` draws, then the appropriate max likelihood objective function is `\sum_x P_obs(x) log P_model(x | \theta)`. Perhaps this is exactly what you've done and I don't get it. Another quick note: what I had in mind was _either_ modeling `mu_sj` at quantized ploidy states, _or_ let the ploidy state be unrestricted w/ a penalty via. a Bernoulli process (possibly w/ different per-contig penalties to account for e.g. higher rate of X/Y loss). We have enough samples in the cohort to select the quantized model (and those samples pin down the per-contig biases `b_j`). The samples that do not conform to quantized ploidy states can then choose whatever (variable) ploidy state they wish by paying a (hefty) price. We would also need to mask contigs that have variable ploidy calls from gCNV.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376286536
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376291049:151,Availability,avail,available,151,"A technical note: as an alternative to equal-sized binning of the coverage distribution, we could use a non-uniform binning strategy that utilizes the available number of bins to represent the variations in the CDF in the most accurate way. Here's what I had written earlier:; ```; def get_counts_summary(counts, lo_cutoff=0.01, hi_cutoff=0.99, num_divisions=50):; sorted_counts = np.sort(counts); num_points = len(counts); lo_index = int(np.floor(lo_cutoff * num_points)); hi_index = min(int(np.ceil(hi_cutoff * num_points)), num_points - 1); lo_count = sorted_counts[lo_index]; hi_count = sorted_counts[hi_index]; abscissa_indices = np.round(np.linspace(lo_index, hi_index, num=num_divisions + 1)).astype(int); abscissa = np.asarray([sorted_counts[idx] for idx in abscissa_indices]); abscissa_counts = abscissa_indices[1:] - abscissa_indices[0:-1]; collapsed_abscissa, collapsed_abscissa_counts = collapse_abscissa_triplets(abscissa, abscissa_counts); return collapsed_abscissa, collapsed_abscissa_counts. def collapse_abscissa_triplets(abscissa, abscissa_counts):; if len(abscissa) < 3:; return abscissa, abscissa_counts; else:; pos = 0; collapsed_abscissa = [abscissa[pos]]; collapsed_abscissa_counts = []; while pos < len(abscissa) - 1:; first = abscissa[pos]; last = abscissa[pos + 1]; count = abscissa_counts[pos]; if first != last:; collapsed_abscissa += [last]; collapsed_abscissa_counts += [count]; pos += 1; else:; j = 1; while pos + j + 1 < len(abscissa):; if abscissa[pos + j + 1] == last:; count += abscissa_counts[pos + j]; j += 1; else:; break; collapsed_abscissa += [last]; collapsed_abscissa_counts += [count]; pos += j; return np.asarray(collapsed_abscissa), np.asarray(collapsed_abscissa_counts); ```; Here, `get_counts_summary` returns a tuple of `(abscissa, occurrences)`. The summary is interpreted as follows: there are `occurrences[m]` bins with counts >= `abscissa[m]` and <= `abscissa[m+1]`, for `m = 0, ...`, up to `num_divisions` (but could be smaller if some of the redun",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376291049
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376291049:1996,Availability,redundant,redundant,1996,"s the available number of bins to represent the variations in the CDF in the most accurate way. Here's what I had written earlier:; ```; def get_counts_summary(counts, lo_cutoff=0.01, hi_cutoff=0.99, num_divisions=50):; sorted_counts = np.sort(counts); num_points = len(counts); lo_index = int(np.floor(lo_cutoff * num_points)); hi_index = min(int(np.ceil(hi_cutoff * num_points)), num_points - 1); lo_count = sorted_counts[lo_index]; hi_count = sorted_counts[hi_index]; abscissa_indices = np.round(np.linspace(lo_index, hi_index, num=num_divisions + 1)).astype(int); abscissa = np.asarray([sorted_counts[idx] for idx in abscissa_indices]); abscissa_counts = abscissa_indices[1:] - abscissa_indices[0:-1]; collapsed_abscissa, collapsed_abscissa_counts = collapse_abscissa_triplets(abscissa, abscissa_counts); return collapsed_abscissa, collapsed_abscissa_counts. def collapse_abscissa_triplets(abscissa, abscissa_counts):; if len(abscissa) < 3:; return abscissa, abscissa_counts; else:; pos = 0; collapsed_abscissa = [abscissa[pos]]; collapsed_abscissa_counts = []; while pos < len(abscissa) - 1:; first = abscissa[pos]; last = abscissa[pos + 1]; count = abscissa_counts[pos]; if first != last:; collapsed_abscissa += [last]; collapsed_abscissa_counts += [count]; pos += 1; else:; j = 1; while pos + j + 1 < len(abscissa):; if abscissa[pos + j + 1] == last:; count += abscissa_counts[pos + j]; j += 1; else:; break; collapsed_abscissa += [last]; collapsed_abscissa_counts += [count]; pos += j; return np.asarray(collapsed_abscissa), np.asarray(collapsed_abscissa_counts); ```; Here, `get_counts_summary` returns a tuple of `(abscissa, occurrences)`. The summary is interpreted as follows: there are `occurrences[m]` bins with counts >= `abscissa[m]` and <= `abscissa[m+1]`, for `m = 0, ...`, up to `num_divisions` (but could be smaller if some of the redundant abscissa are collapsed). In the PyMC3 code, we could evaluate the `NegativeBinomial` the the midpoint of `abscissa[m]` and `abscissa[m+1]`.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376291049
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376291049:1996,Safety,redund,redundant,1996,"s the available number of bins to represent the variations in the CDF in the most accurate way. Here's what I had written earlier:; ```; def get_counts_summary(counts, lo_cutoff=0.01, hi_cutoff=0.99, num_divisions=50):; sorted_counts = np.sort(counts); num_points = len(counts); lo_index = int(np.floor(lo_cutoff * num_points)); hi_index = min(int(np.ceil(hi_cutoff * num_points)), num_points - 1); lo_count = sorted_counts[lo_index]; hi_count = sorted_counts[hi_index]; abscissa_indices = np.round(np.linspace(lo_index, hi_index, num=num_divisions + 1)).astype(int); abscissa = np.asarray([sorted_counts[idx] for idx in abscissa_indices]); abscissa_counts = abscissa_indices[1:] - abscissa_indices[0:-1]; collapsed_abscissa, collapsed_abscissa_counts = collapse_abscissa_triplets(abscissa, abscissa_counts); return collapsed_abscissa, collapsed_abscissa_counts. def collapse_abscissa_triplets(abscissa, abscissa_counts):; if len(abscissa) < 3:; return abscissa, abscissa_counts; else:; pos = 0; collapsed_abscissa = [abscissa[pos]]; collapsed_abscissa_counts = []; while pos < len(abscissa) - 1:; first = abscissa[pos]; last = abscissa[pos + 1]; count = abscissa_counts[pos]; if first != last:; collapsed_abscissa += [last]; collapsed_abscissa_counts += [count]; pos += 1; else:; j = 1; while pos + j + 1 < len(abscissa):; if abscissa[pos + j + 1] == last:; count += abscissa_counts[pos + j]; j += 1; else:; break; collapsed_abscissa += [last]; collapsed_abscissa_counts += [count]; pos += j; return np.asarray(collapsed_abscissa), np.asarray(collapsed_abscissa_counts); ```; Here, `get_counts_summary` returns a tuple of `(abscissa, occurrences)`. The summary is interpreted as follows: there are `occurrences[m]` bins with counts >= `abscissa[m]` and <= `abscissa[m+1]`, for `m = 0, ...`, up to `num_divisions` (but could be smaller if some of the redundant abscissa are collapsed). In the PyMC3 code, we could evaluate the `NegativeBinomial` the the midpoint of `abscissa[m]` and `abscissa[m+1]`.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376291049
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376307522:648,Availability,robust,robust,648,"The `Poisson` arises because we want to our model to generate the *occurrences*, assuming that each *count bin* provides equal weight---rather than the counts themselves. As usual, modeling each bin as Poisson is close enough to modeling all bins as multinomial for our purposes. If we directly use the NB likelihood and simply weight the count likelihood by occurrences, occurrences in the peak will strongly affect the result, adversely so if the count likelihood is actually misspecified there. As an example, consider trying to fit a Poisson to data that is actually zero-inflated Poisson---fitting the histogram will actually result in a more robust estimate for the mean. Another benefit is that truncated data (as we have here) is straightforwardly handled in an unbiased way. In the special case of complete, trivially-binned data, the full, unbinned likelihood is recovered. I think this sort of histogram fitting is pretty standard in the astro/particle community. We can certainly change up the model to include strictly quantized + free-floating states as you describe (rather than the ""fuzzily quantized"" states I use here), but I just wanted to avoid having another level of mixtures/logsumexps for this quick prototype. However, note that modeling mosaicism on the autosomes is desirable, but there we also want the strong diploid prior to nail down the depth and per-contig bias. So we will have to be a little careful about how we introduce free-floating states. Also, since I was not using gcnvkernel, I had to integrate out all discrete parameters. It may be that we can write down a nice model with discrete parameters if we use your inference framework. Finally, I did not further bin the counts here (or rather, the bin size is 1), which already yields the maximum information, but I did use a maximum-count cutoff. If we use the same cutoff for all samples, this allows us to simply pass a non-ragged matrix from Java (with dimensions of samples x contigs x maximum count) as a ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376307522
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376307522:873,Availability,recover,recovered,873,"The `Poisson` arises because we want to our model to generate the *occurrences*, assuming that each *count bin* provides equal weight---rather than the counts themselves. As usual, modeling each bin as Poisson is close enough to modeling all bins as multinomial for our purposes. If we directly use the NB likelihood and simply weight the count likelihood by occurrences, occurrences in the peak will strongly affect the result, adversely so if the count likelihood is actually misspecified there. As an example, consider trying to fit a Poisson to data that is actually zero-inflated Poisson---fitting the histogram will actually result in a more robust estimate for the mean. Another benefit is that truncated data (as we have here) is straightforwardly handled in an unbiased way. In the special case of complete, trivially-binned data, the full, unbinned likelihood is recovered. I think this sort of histogram fitting is pretty standard in the astro/particle community. We can certainly change up the model to include strictly quantized + free-floating states as you describe (rather than the ""fuzzily quantized"" states I use here), but I just wanted to avoid having another level of mixtures/logsumexps for this quick prototype. However, note that modeling mosaicism on the autosomes is desirable, but there we also want the strong diploid prior to nail down the depth and per-contig bias. So we will have to be a little careful about how we introduce free-floating states. Also, since I was not using gcnvkernel, I had to integrate out all discrete parameters. It may be that we can write down a nice model with discrete parameters if we use your inference framework. Finally, I did not further bin the counts here (or rather, the bin size is 1), which already yields the maximum information, but I did use a maximum-count cutoff. If we use the same cutoff for all samples, this allows us to simply pass a non-ragged matrix from Java (with dimensions of samples x contigs x maximum count) as a ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376307522
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376307522:1360,Availability,down,down,1360,"od and simply weight the count likelihood by occurrences, occurrences in the peak will strongly affect the result, adversely so if the count likelihood is actually misspecified there. As an example, consider trying to fit a Poisson to data that is actually zero-inflated Poisson---fitting the histogram will actually result in a more robust estimate for the mean. Another benefit is that truncated data (as we have here) is straightforwardly handled in an unbiased way. In the special case of complete, trivially-binned data, the full, unbinned likelihood is recovered. I think this sort of histogram fitting is pretty standard in the astro/particle community. We can certainly change up the model to include strictly quantized + free-floating states as you describe (rather than the ""fuzzily quantized"" states I use here), but I just wanted to avoid having another level of mixtures/logsumexps for this quick prototype. However, note that modeling mosaicism on the autosomes is desirable, but there we also want the strong diploid prior to nail down the depth and per-contig bias. So we will have to be a little careful about how we introduce free-floating states. Also, since I was not using gcnvkernel, I had to integrate out all discrete parameters. It may be that we can write down a nice model with discrete parameters if we use your inference framework. Finally, I did not further bin the counts here (or rather, the bin size is 1), which already yields the maximum information, but I did use a maximum-count cutoff. If we use the same cutoff for all samples, this allows us to simply pass a non-ragged matrix from Java (with dimensions of samples x contigs x maximum count) as a TSV. However, we may run into trouble if we hit a case sample with very high depth. So some sort of sparse representation of the histogram might indeed be desirable, but I think it should be an exact representation of the full histogram. This would require us to sync up code to emit and consume the representation",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376307522
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376307522:1596,Availability,down,down,1596," the count likelihood is actually misspecified there. As an example, consider trying to fit a Poisson to data that is actually zero-inflated Poisson---fitting the histogram will actually result in a more robust estimate for the mean. Another benefit is that truncated data (as we have here) is straightforwardly handled in an unbiased way. In the special case of complete, trivially-binned data, the full, unbinned likelihood is recovered. I think this sort of histogram fitting is pretty standard in the astro/particle community. We can certainly change up the model to include strictly quantized + free-floating states as you describe (rather than the ""fuzzily quantized"" states I use here), but I just wanted to avoid having another level of mixtures/logsumexps for this quick prototype. However, note that modeling mosaicism on the autosomes is desirable, but there we also want the strong diploid prior to nail down the depth and per-contig bias. So we will have to be a little careful about how we introduce free-floating states. Also, since I was not using gcnvkernel, I had to integrate out all discrete parameters. It may be that we can write down a nice model with discrete parameters if we use your inference framework. Finally, I did not further bin the counts here (or rather, the bin size is 1), which already yields the maximum information, but I did use a maximum-count cutoff. If we use the same cutoff for all samples, this allows us to simply pass a non-ragged matrix from Java (with dimensions of samples x contigs x maximum count) as a TSV. However, we may run into trouble if we hit a case sample with very high depth. So some sort of sparse representation of the histogram might indeed be desirable, but I think it should be an exact representation of the full histogram. This would require us to sync up code to emit and consume the representation in both Java and python, so I'd like to avoid it if possible---I think I'd prefer just emitting the ragged matrix, in that case.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376307522
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376307522:1529,Deployability,integrat,integrate,1529," the count likelihood is actually misspecified there. As an example, consider trying to fit a Poisson to data that is actually zero-inflated Poisson---fitting the histogram will actually result in a more robust estimate for the mean. Another benefit is that truncated data (as we have here) is straightforwardly handled in an unbiased way. In the special case of complete, trivially-binned data, the full, unbinned likelihood is recovered. I think this sort of histogram fitting is pretty standard in the astro/particle community. We can certainly change up the model to include strictly quantized + free-floating states as you describe (rather than the ""fuzzily quantized"" states I use here), but I just wanted to avoid having another level of mixtures/logsumexps for this quick prototype. However, note that modeling mosaicism on the autosomes is desirable, but there we also want the strong diploid prior to nail down the depth and per-contig bias. So we will have to be a little careful about how we introduce free-floating states. Also, since I was not using gcnvkernel, I had to integrate out all discrete parameters. It may be that we can write down a nice model with discrete parameters if we use your inference framework. Finally, I did not further bin the counts here (or rather, the bin size is 1), which already yields the maximum information, but I did use a maximum-count cutoff. If we use the same cutoff for all samples, this allows us to simply pass a non-ragged matrix from Java (with dimensions of samples x contigs x maximum count) as a TSV. However, we may run into trouble if we hit a case sample with very high depth. So some sort of sparse representation of the histogram might indeed be desirable, but I think it should be an exact representation of the full histogram. This would require us to sync up code to emit and consume the representation in both Java and python, so I'd like to avoid it if possible---I think I'd prefer just emitting the ragged matrix, in that case.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376307522
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376307522:1529,Integrability,integrat,integrate,1529," the count likelihood is actually misspecified there. As an example, consider trying to fit a Poisson to data that is actually zero-inflated Poisson---fitting the histogram will actually result in a more robust estimate for the mean. Another benefit is that truncated data (as we have here) is straightforwardly handled in an unbiased way. In the special case of complete, trivially-binned data, the full, unbinned likelihood is recovered. I think this sort of histogram fitting is pretty standard in the astro/particle community. We can certainly change up the model to include strictly quantized + free-floating states as you describe (rather than the ""fuzzily quantized"" states I use here), but I just wanted to avoid having another level of mixtures/logsumexps for this quick prototype. However, note that modeling mosaicism on the autosomes is desirable, but there we also want the strong diploid prior to nail down the depth and per-contig bias. So we will have to be a little careful about how we introduce free-floating states. Also, since I was not using gcnvkernel, I had to integrate out all discrete parameters. It may be that we can write down a nice model with discrete parameters if we use your inference framework. Finally, I did not further bin the counts here (or rather, the bin size is 1), which already yields the maximum information, but I did use a maximum-count cutoff. If we use the same cutoff for all samples, this allows us to simply pass a non-ragged matrix from Java (with dimensions of samples x contigs x maximum count) as a TSV. However, we may run into trouble if we hit a case sample with very high depth. So some sort of sparse representation of the histogram might indeed be desirable, but I think it should be an exact representation of the full histogram. This would require us to sync up code to emit and consume the representation in both Java and python, so I'd like to avoid it if possible---I think I'd prefer just emitting the ragged matrix, in that case.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376307522
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376307522:873,Safety,recover,recovered,873,"The `Poisson` arises because we want to our model to generate the *occurrences*, assuming that each *count bin* provides equal weight---rather than the counts themselves. As usual, modeling each bin as Poisson is close enough to modeling all bins as multinomial for our purposes. If we directly use the NB likelihood and simply weight the count likelihood by occurrences, occurrences in the peak will strongly affect the result, adversely so if the count likelihood is actually misspecified there. As an example, consider trying to fit a Poisson to data that is actually zero-inflated Poisson---fitting the histogram will actually result in a more robust estimate for the mean. Another benefit is that truncated data (as we have here) is straightforwardly handled in an unbiased way. In the special case of complete, trivially-binned data, the full, unbinned likelihood is recovered. I think this sort of histogram fitting is pretty standard in the astro/particle community. We can certainly change up the model to include strictly quantized + free-floating states as you describe (rather than the ""fuzzily quantized"" states I use here), but I just wanted to avoid having another level of mixtures/logsumexps for this quick prototype. However, note that modeling mosaicism on the autosomes is desirable, but there we also want the strong diploid prior to nail down the depth and per-contig bias. So we will have to be a little careful about how we introduce free-floating states. Also, since I was not using gcnvkernel, I had to integrate out all discrete parameters. It may be that we can write down a nice model with discrete parameters if we use your inference framework. Finally, I did not further bin the counts here (or rather, the bin size is 1), which already yields the maximum information, but I did use a maximum-count cutoff. If we use the same cutoff for all samples, this allows us to simply pass a non-ragged matrix from Java (with dimensions of samples x contigs x maximum count) as a ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376307522
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376307522:1159,Safety,avoid,avoid,1159,"nt bin* provides equal weight---rather than the counts themselves. As usual, modeling each bin as Poisson is close enough to modeling all bins as multinomial for our purposes. If we directly use the NB likelihood and simply weight the count likelihood by occurrences, occurrences in the peak will strongly affect the result, adversely so if the count likelihood is actually misspecified there. As an example, consider trying to fit a Poisson to data that is actually zero-inflated Poisson---fitting the histogram will actually result in a more robust estimate for the mean. Another benefit is that truncated data (as we have here) is straightforwardly handled in an unbiased way. In the special case of complete, trivially-binned data, the full, unbinned likelihood is recovered. I think this sort of histogram fitting is pretty standard in the astro/particle community. We can certainly change up the model to include strictly quantized + free-floating states as you describe (rather than the ""fuzzily quantized"" states I use here), but I just wanted to avoid having another level of mixtures/logsumexps for this quick prototype. However, note that modeling mosaicism on the autosomes is desirable, but there we also want the strong diploid prior to nail down the depth and per-contig bias. So we will have to be a little careful about how we introduce free-floating states. Also, since I was not using gcnvkernel, I had to integrate out all discrete parameters. It may be that we can write down a nice model with discrete parameters if we use your inference framework. Finally, I did not further bin the counts here (or rather, the bin size is 1), which already yields the maximum information, but I did use a maximum-count cutoff. If we use the same cutoff for all samples, this allows us to simply pass a non-ragged matrix from Java (with dimensions of samples x contigs x maximum count) as a TSV. However, we may run into trouble if we hit a case sample with very high depth. So some sort of spa",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376307522
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376307522:2356,Safety,avoid,avoid,2356," the count likelihood is actually misspecified there. As an example, consider trying to fit a Poisson to data that is actually zero-inflated Poisson---fitting the histogram will actually result in a more robust estimate for the mean. Another benefit is that truncated data (as we have here) is straightforwardly handled in an unbiased way. In the special case of complete, trivially-binned data, the full, unbinned likelihood is recovered. I think this sort of histogram fitting is pretty standard in the astro/particle community. We can certainly change up the model to include strictly quantized + free-floating states as you describe (rather than the ""fuzzily quantized"" states I use here), but I just wanted to avoid having another level of mixtures/logsumexps for this quick prototype. However, note that modeling mosaicism on the autosomes is desirable, but there we also want the strong diploid prior to nail down the depth and per-contig bias. So we will have to be a little careful about how we introduce free-floating states. Also, since I was not using gcnvkernel, I had to integrate out all discrete parameters. It may be that we can write down a nice model with discrete parameters if we use your inference framework. Finally, I did not further bin the counts here (or rather, the bin size is 1), which already yields the maximum information, but I did use a maximum-count cutoff. If we use the same cutoff for all samples, this allows us to simply pass a non-ragged matrix from Java (with dimensions of samples x contigs x maximum count) as a TSV. However, we may run into trouble if we hit a case sample with very high depth. So some sort of sparse representation of the histogram might indeed be desirable, but I think it should be an exact representation of the full histogram. This would require us to sync up code to emit and consume the representation in both Java and python, so I'd like to avoid it if possible---I think I'd prefer just emitting the ragged matrix, in that case.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376307522
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376307522:1198,Testability,log,logsumexps,1198,"nt bin* provides equal weight---rather than the counts themselves. As usual, modeling each bin as Poisson is close enough to modeling all bins as multinomial for our purposes. If we directly use the NB likelihood and simply weight the count likelihood by occurrences, occurrences in the peak will strongly affect the result, adversely so if the count likelihood is actually misspecified there. As an example, consider trying to fit a Poisson to data that is actually zero-inflated Poisson---fitting the histogram will actually result in a more robust estimate for the mean. Another benefit is that truncated data (as we have here) is straightforwardly handled in an unbiased way. In the special case of complete, trivially-binned data, the full, unbinned likelihood is recovered. I think this sort of histogram fitting is pretty standard in the astro/particle community. We can certainly change up the model to include strictly quantized + free-floating states as you describe (rather than the ""fuzzily quantized"" states I use here), but I just wanted to avoid having another level of mixtures/logsumexps for this quick prototype. However, note that modeling mosaicism on the autosomes is desirable, but there we also want the strong diploid prior to nail down the depth and per-contig bias. So we will have to be a little careful about how we introduce free-floating states. Also, since I was not using gcnvkernel, I had to integrate out all discrete parameters. It may be that we can write down a nice model with discrete parameters if we use your inference framework. Finally, I did not further bin the counts here (or rather, the bin size is 1), which already yields the maximum information, but I did use a maximum-count cutoff. If we use the same cutoff for all samples, this allows us to simply pass a non-ragged matrix from Java (with dimensions of samples x contigs x maximum count) as a TSV. However, we may run into trouble if we hit a case sample with very high depth. So some sort of spa",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376307522
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376307522:321,Usability,simpl,simply,321,"The `Poisson` arises because we want to our model to generate the *occurrences*, assuming that each *count bin* provides equal weight---rather than the counts themselves. As usual, modeling each bin as Poisson is close enough to modeling all bins as multinomial for our purposes. If we directly use the NB likelihood and simply weight the count likelihood by occurrences, occurrences in the peak will strongly affect the result, adversely so if the count likelihood is actually misspecified there. As an example, consider trying to fit a Poisson to data that is actually zero-inflated Poisson---fitting the histogram will actually result in a more robust estimate for the mean. Another benefit is that truncated data (as we have here) is straightforwardly handled in an unbiased way. In the special case of complete, trivially-binned data, the full, unbinned likelihood is recovered. I think this sort of histogram fitting is pretty standard in the astro/particle community. We can certainly change up the model to include strictly quantized + free-floating states as you describe (rather than the ""fuzzily quantized"" states I use here), but I just wanted to avoid having another level of mixtures/logsumexps for this quick prototype. However, note that modeling mosaicism on the autosomes is desirable, but there we also want the strong diploid prior to nail down the depth and per-contig bias. So we will have to be a little careful about how we introduce free-floating states. Also, since I was not using gcnvkernel, I had to integrate out all discrete parameters. It may be that we can write down a nice model with discrete parameters if we use your inference framework. Finally, I did not further bin the counts here (or rather, the bin size is 1), which already yields the maximum information, but I did use a maximum-count cutoff. If we use the same cutoff for all samples, this allows us to simply pass a non-ragged matrix from Java (with dimensions of samples x contigs x maximum count) as a ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376307522
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376307522:1899,Usability,simpl,simply,1899," the count likelihood is actually misspecified there. As an example, consider trying to fit a Poisson to data that is actually zero-inflated Poisson---fitting the histogram will actually result in a more robust estimate for the mean. Another benefit is that truncated data (as we have here) is straightforwardly handled in an unbiased way. In the special case of complete, trivially-binned data, the full, unbinned likelihood is recovered. I think this sort of histogram fitting is pretty standard in the astro/particle community. We can certainly change up the model to include strictly quantized + free-floating states as you describe (rather than the ""fuzzily quantized"" states I use here), but I just wanted to avoid having another level of mixtures/logsumexps for this quick prototype. However, note that modeling mosaicism on the autosomes is desirable, but there we also want the strong diploid prior to nail down the depth and per-contig bias. So we will have to be a little careful about how we introduce free-floating states. Also, since I was not using gcnvkernel, I had to integrate out all discrete parameters. It may be that we can write down a nice model with discrete parameters if we use your inference framework. Finally, I did not further bin the counts here (or rather, the bin size is 1), which already yields the maximum information, but I did use a maximum-count cutoff. If we use the same cutoff for all samples, this allows us to simply pass a non-ragged matrix from Java (with dimensions of samples x contigs x maximum count) as a TSV. However, we may run into trouble if we hit a case sample with very high depth. So some sort of sparse representation of the histogram might indeed be desirable, but I think it should be an exact representation of the full histogram. This would require us to sync up code to emit and consume the representation in both Java and python, so I'd like to avoid it if possible---I think I'd prefer just emitting the ragged matrix, in that case.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376307522
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376516485:263,Availability,robust,robust,263,Beautiful results @samuelklee -- and some of that data was really squirrely too!. I think continuing with the current round of evaluations makes sense. Those unusual sex genotype samples are pretty rare so spot checking should be fine. I'm excited about having a robust set of learning parameters so we can get this tool to users. We can work on catching the tricky and interesting but rare cases as a second phase.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376516485
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376516485:277,Usability,learn,learning,277,Beautiful results @samuelklee -- and some of that data was really squirrely too!. I think continuing with the current round of evaluations makes sense. Those unusual sex genotype samples are pretty rare so spot checking should be fine. I'm excited about having a robust set of learning parameters so we can get this tool to users. We can work on catching the tricky and interesting but rare cases as a second phase.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-376516485
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-414852311:1266,Availability,robust,robustness,1266,"@ldgauthier @mbabadi Revisiting this in detail in preparation for a Methods meeting presentation, I discovered that much of the initial poor model performance and the issue with the strange GQs on chr1 was actually fixed in #4335 via a seemingly innocuous change. . Prior to the change, the ploidy model used *lexicographical* sorting to determine contig order (see #4374), but the contig order of the per-contig counts matrix was determined by the *sequence dictionary*. This understandably leads to shenanigans, since the model needs to know things like the number of intervals on each contig. After the change, the sequence-dictionary order is properly used everywhere and most of the bad behavior seems to be resolved (not all of the unusual sex genotypes are resolved, but this may be partly due to mosaicism in those samples) . (@mbabadi, not sure if we actually realized this before? I don't recall nor do I see it discussed elsewhere, but if so, then consider this a note of it!). So the problems with this model are not as severe as we initially thought, and thus we can keep this issue at relatively low priority. Nevertheless, the improved model should still yield additional benefits, such as better depth estimates and ploidy qualities, as well as more robustness to unusual sex genotypes.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-414852311
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-414852311:147,Performance,perform,performance,147,"@ldgauthier @mbabadi Revisiting this in detail in preparation for a Methods meeting presentation, I discovered that much of the initial poor model performance and the issue with the strange GQs on chr1 was actually fixed in #4335 via a seemingly innocuous change. . Prior to the change, the ploidy model used *lexicographical* sorting to determine contig order (see #4374), but the contig order of the per-contig counts matrix was determined by the *sequence dictionary*. This understandably leads to shenanigans, since the model needs to know things like the number of intervals on each contig. After the change, the sequence-dictionary order is properly used everywhere and most of the bad behavior seems to be resolved (not all of the unusual sex genotypes are resolved, but this may be partly due to mosaicism in those samples) . (@mbabadi, not sure if we actually realized this before? I don't recall nor do I see it discussed elsewhere, but if so, then consider this a note of it!). So the problems with this model are not as severe as we initially thought, and thus we can keep this issue at relatively low priority. Nevertheless, the improved model should still yield additional benefits, such as better depth estimates and ploidy qualities, as well as more robustness to unusual sex genotypes.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-414852311
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-415068602:175,Deployability,pipeline,pipeline,175,"Great news! I'm looking forward to seeing your detailed results tomorrow. This can be low priority unless it's a dramatic improvement over what's in the current Talkowski Lab pipeline. (I remember when we met with Ryan and Harrison a while ago that their approach wasn't as sophisticated, but it seems to get the job done.) I'll talk to Harrison about it tomorrow.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-415068602
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-649726755:156,Availability,avail,available,156,Hi guys I am very interested in this discussion. It would be great to know:. 1. what were the results?; 2. is this contig-prior-probablity file you created available somehow?; 3. are the data for the samples you tested the pipeline on available?. Thank you so much in advance!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-649726755
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-649726755:235,Availability,avail,available,235,Hi guys I am very interested in this discussion. It would be great to know:. 1. what were the results?; 2. is this contig-prior-probablity file you created available somehow?; 3. are the data for the samples you tested the pipeline on available?. Thank you so much in advance!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-649726755
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-649726755:223,Deployability,pipeline,pipeline,223,Hi guys I am very interested in this discussion. It would be great to know:. 1. what were the results?; 2. is this contig-prior-probablity file you created available somehow?; 3. are the data for the samples you tested the pipeline on available?. Thank you so much in advance!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-649726755
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-649726755:212,Testability,test,tested,212,Hi guys I am very interested in this discussion. It would be great to know:. 1. what were the results?; 2. is this contig-prior-probablity file you created available somehow?; 3. are the data for the samples you tested the pipeline on available?. Thank you so much in advance!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-649726755
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-894432129:1700,Availability,avail,available,1700,"Hi @cccnrc, glad you found this discussion interesting and apologies for the very late reply. Unfortunately, there hasn't been much movement on this front, as I think we decided that the current model sufficed. I think we are moving in a direction so that we can obviate the need for a separate step to fit global (e.g., depth) and per-contig (e.g., contig ploidy) parameters for each sample. Recall that this is only necessary because each gCNV genomic shard needs these quantities to perform inference, but cannot infer them from the data they are responsible for fitting (which typically covers less than a contig). We are looking to reimplement gCNV in a more modern inference framework that could allow us to do away with such sharding entirely. We could thus fit global/per-contig quantities of interest jointly with the rest of the gCNV model. The timeframe for this work may be relatively long (~year), but I think it'll be worth it. That said, I think a key takeaway from this work is that genotype priors can be more powerful for breaking degeneracies than contig-ploidy priors, so we will probably try to incorporate that insight in future work. To answer your questions:; 1) There are no additional results much further beyond what is shown above.; 2) You can see snippets/comparisons of the genotype and contig-ploidy prior file above. If you're just looking for information about the contig-ploidy prior table used in the current pipeline, see an example at https://gatk.broadinstitute.org/hc/en-us/articles/360051304711-DetermineGermlineContigPloidy and feel free to modify it to be more/less strict as desired.; 3) Unfortunately I believe the samples discussed above are not publicly available. If you are having difficulties with the current model, it would probably be useful to hear about them!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-894432129
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-894432129:1444,Deployability,pipeline,pipeline,1444,"Hi @cccnrc, glad you found this discussion interesting and apologies for the very late reply. Unfortunately, there hasn't been much movement on this front, as I think we decided that the current model sufficed. I think we are moving in a direction so that we can obviate the need for a separate step to fit global (e.g., depth) and per-contig (e.g., contig ploidy) parameters for each sample. Recall that this is only necessary because each gCNV genomic shard needs these quantities to perform inference, but cannot infer them from the data they are responsible for fitting (which typically covers less than a contig). We are looking to reimplement gCNV in a more modern inference framework that could allow us to do away with such sharding entirely. We could thus fit global/per-contig quantities of interest jointly with the rest of the gCNV model. The timeframe for this work may be relatively long (~year), but I think it'll be worth it. That said, I think a key takeaway from this work is that genotype priors can be more powerful for breaking degeneracies than contig-ploidy priors, so we will probably try to incorporate that insight in future work. To answer your questions:; 1) There are no additional results much further beyond what is shown above.; 2) You can see snippets/comparisons of the genotype and contig-ploidy prior file above. If you're just looking for information about the contig-ploidy prior table used in the current pipeline, see an example at https://gatk.broadinstitute.org/hc/en-us/articles/360051304711-DetermineGermlineContigPloidy and feel free to modify it to be more/less strict as desired.; 3) Unfortunately I believe the samples discussed above are not publicly available. If you are having difficulties with the current model, it would probably be useful to hear about them!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-894432129
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-894432129:1027,Energy Efficiency,power,powerful,1027,"Hi @cccnrc, glad you found this discussion interesting and apologies for the very late reply. Unfortunately, there hasn't been much movement on this front, as I think we decided that the current model sufficed. I think we are moving in a direction so that we can obviate the need for a separate step to fit global (e.g., depth) and per-contig (e.g., contig ploidy) parameters for each sample. Recall that this is only necessary because each gCNV genomic shard needs these quantities to perform inference, but cannot infer them from the data they are responsible for fitting (which typically covers less than a contig). We are looking to reimplement gCNV in a more modern inference framework that could allow us to do away with such sharding entirely. We could thus fit global/per-contig quantities of interest jointly with the rest of the gCNV model. The timeframe for this work may be relatively long (~year), but I think it'll be worth it. That said, I think a key takeaway from this work is that genotype priors can be more powerful for breaking degeneracies than contig-ploidy priors, so we will probably try to incorporate that insight in future work. To answer your questions:; 1) There are no additional results much further beyond what is shown above.; 2) You can see snippets/comparisons of the genotype and contig-ploidy prior file above. If you're just looking for information about the contig-ploidy prior table used in the current pipeline, see an example at https://gatk.broadinstitute.org/hc/en-us/articles/360051304711-DetermineGermlineContigPloidy and feel free to modify it to be more/less strict as desired.; 3) Unfortunately I believe the samples discussed above are not publicly available. If you are having difficulties with the current model, it would probably be useful to hear about them!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-894432129
https://github.com/broadinstitute/gatk/issues/4371#issuecomment-894432129:486,Performance,perform,perform,486,"Hi @cccnrc, glad you found this discussion interesting and apologies for the very late reply. Unfortunately, there hasn't been much movement on this front, as I think we decided that the current model sufficed. I think we are moving in a direction so that we can obviate the need for a separate step to fit global (e.g., depth) and per-contig (e.g., contig ploidy) parameters for each sample. Recall that this is only necessary because each gCNV genomic shard needs these quantities to perform inference, but cannot infer them from the data they are responsible for fitting (which typically covers less than a contig). We are looking to reimplement gCNV in a more modern inference framework that could allow us to do away with such sharding entirely. We could thus fit global/per-contig quantities of interest jointly with the rest of the gCNV model. The timeframe for this work may be relatively long (~year), but I think it'll be worth it. That said, I think a key takeaway from this work is that genotype priors can be more powerful for breaking degeneracies than contig-ploidy priors, so we will probably try to incorporate that insight in future work. To answer your questions:; 1) There are no additional results much further beyond what is shown above.; 2) You can see snippets/comparisons of the genotype and contig-ploidy prior file above. If you're just looking for information about the contig-ploidy prior table used in the current pipeline, see an example at https://gatk.broadinstitute.org/hc/en-us/articles/360051304711-DetermineGermlineContigPloidy and feel free to modify it to be more/less strict as desired.; 3) Unfortunately I believe the samples discussed above are not publicly available. If you are having difficulties with the current model, it would probably be useful to hear about them!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4371#issuecomment-894432129
https://github.com/broadinstitute/gatk/issues/4375#issuecomment-900618432:201,Deployability,pipeline,pipeline,201,"I think the real challenge will be doing something worthwhile within the constraints of our Travis environment. Perhaps this sort of thing is best left to CARROT, even though it might not rise to the ""pipeline"" level.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4375#issuecomment-900618432
https://github.com/broadinstitute/gatk/issues/4376#issuecomment-364154763:125,Energy Efficiency,monitor,monitored,125,"@tomwhite How many physical cores are you using? Is it a whole genome task? I was able to finish BQSR in about an hour. From monitored activities, the CPU utilization rates are very high across all physical cores (so it's not bad). There is the long runtime of creating KnownSitesCache, as in #4264",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4376#issuecomment-364154763
https://github.com/broadinstitute/gatk/issues/4376#issuecomment-364179033:1821,Performance,perform,performance,1821,"@tomwhite That's interesting -- @lbergelson 's profiling on `HaplotypeCallerSpark` in isolation did not show any noticeable slowdown as a result of the switch to the new code path (in addition to the output being much more correct than before), and the walker version which uses the same codepath is as fast or faster than GATK3 at this point in all modes. We should try to see whether we can replicate your results on our end. Can you provide more details on how you ran the tools?. The new `HaplotypeCaller` code path does result in the tool doing more work in some cases as compared to the early betas, particularly for genomic locations not covered by any reads -- but this work is necessary in order to produce correct output without boundary effects, and the fact that the early betas didn't do it was an oversight. I wonder if that could explain what you're seeing -- see the full discussion in https://github.com/broadinstitute/gatk/issues/4169. There are also several ways in which `HaplotypeCallerSpark` currently makes suboptimal use of the new code path introduced in https://github.com/broadinstitute/gatk/pull/4278:. 1. It uses only a single interval per shard, instead of many intervals as the walker version does (https://github.com/broadinstitute/gatk/issues/4299). 2. It materializes all of the assembly regions in a shard at once (https://github.com/broadinstitute/gatk/issues/4301), as opposed to the walker version which materializes the regions in a shard as lazily as possible. 3. The default read shard size may need adjusting (https://github.com/broadinstitute/gatk/issues/4298). The walker version creates one shard per contig, and lazily creates the assembly regions within that shard. That's obviously not possible for the Spark version, but I don't think that the effect of the shard size on performance has been measured yet for the Spark version.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4376#issuecomment-364179033
https://github.com/broadinstitute/gatk/issues/4376#issuecomment-364187885:13,Testability,test,tests,13,@tomwhite My tests were running HaplotypeCallerSpark on an exome on gcs. It took ~40 minutes with and without the changes.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4376#issuecomment-364187885
https://github.com/broadinstitute/gatk/issues/4376#issuecomment-364188535:40,Deployability,pipeline,pipeline,40,"Also, interestingly, if you look at the pipeline we run nightly in jenkins, there hasn't been any performance regression there. https://gatk-jenkins.broadinstitute.org/view/Performance/job/gatk-perf-test-spark-readpipeline/buildTimeTrend",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4376#issuecomment-364188535
https://github.com/broadinstitute/gatk/issues/4376#issuecomment-364188535:98,Performance,perform,performance,98,"Also, interestingly, if you look at the pipeline we run nightly in jenkins, there hasn't been any performance regression there. https://gatk-jenkins.broadinstitute.org/view/Performance/job/gatk-perf-test-spark-readpipeline/buildTimeTrend",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4376#issuecomment-364188535
https://github.com/broadinstitute/gatk/issues/4376#issuecomment-364188535:173,Performance,Perform,Performance,173,"Also, interestingly, if you look at the pipeline we run nightly in jenkins, there hasn't been any performance regression there. https://gatk-jenkins.broadinstitute.org/view/Performance/job/gatk-perf-test-spark-readpipeline/buildTimeTrend",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4376#issuecomment-364188535
https://github.com/broadinstitute/gatk/issues/4376#issuecomment-364188535:199,Testability,test,test-spark-readpipeline,199,"Also, interestingly, if you look at the pipeline we run nightly in jenkins, there hasn't been any performance regression there. https://gatk-jenkins.broadinstitute.org/view/Performance/job/gatk-perf-test-spark-readpipeline/buildTimeTrend",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4376#issuecomment-364188535
https://github.com/broadinstitute/gatk/issues/4376#issuecomment-364382087:147,Deployability,pipeline,pipeline,147,"This is what I ran (note it's not using the HDFS codepath). Can you try reproducing please? I used to be able to run this in 40 minutes (the whole pipeline, not just HC, and even BQSR is taking a lot longer now). ```bash; gatk ReadsPipelineSpark -I gs://broad-spark-eval-test-data/exome/NA12878.ga2.exome.maq.raw.bam -O gs://broad-spark-eval-test-data/exome/NA12878.ga2.exome.maq.raw.vcf -R; gs://broad-spark-eval-test-data/exome/Homo_sapiens_assembly18.2bit --known-sites gs://broad-spark-eval-test-data/exome/dbsnp_138.hg18.vcf -pairHMM AVX_LOGLESS_CACHING --max-; reads-per-alignment-start 10 \; -- \; --spark-runner GCS --cluster tw-cluster-2 \; --num-executors 8 --executor-cores 8 --executor-memory 32g \; --driver-memory 4g \; --conf spark.dynamicAllocation.enabled=false; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4376#issuecomment-364382087
https://github.com/broadinstitute/gatk/issues/4376#issuecomment-364382087:271,Testability,test,test-data,271,"This is what I ran (note it's not using the HDFS codepath). Can you try reproducing please? I used to be able to run this in 40 minutes (the whole pipeline, not just HC, and even BQSR is taking a lot longer now). ```bash; gatk ReadsPipelineSpark -I gs://broad-spark-eval-test-data/exome/NA12878.ga2.exome.maq.raw.bam -O gs://broad-spark-eval-test-data/exome/NA12878.ga2.exome.maq.raw.vcf -R; gs://broad-spark-eval-test-data/exome/Homo_sapiens_assembly18.2bit --known-sites gs://broad-spark-eval-test-data/exome/dbsnp_138.hg18.vcf -pairHMM AVX_LOGLESS_CACHING --max-; reads-per-alignment-start 10 \; -- \; --spark-runner GCS --cluster tw-cluster-2 \; --num-executors 8 --executor-cores 8 --executor-memory 32g \; --driver-memory 4g \; --conf spark.dynamicAllocation.enabled=false; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4376#issuecomment-364382087
https://github.com/broadinstitute/gatk/issues/4376#issuecomment-364382087:342,Testability,test,test-data,342,"This is what I ran (note it's not using the HDFS codepath). Can you try reproducing please? I used to be able to run this in 40 minutes (the whole pipeline, not just HC, and even BQSR is taking a lot longer now). ```bash; gatk ReadsPipelineSpark -I gs://broad-spark-eval-test-data/exome/NA12878.ga2.exome.maq.raw.bam -O gs://broad-spark-eval-test-data/exome/NA12878.ga2.exome.maq.raw.vcf -R; gs://broad-spark-eval-test-data/exome/Homo_sapiens_assembly18.2bit --known-sites gs://broad-spark-eval-test-data/exome/dbsnp_138.hg18.vcf -pairHMM AVX_LOGLESS_CACHING --max-; reads-per-alignment-start 10 \; -- \; --spark-runner GCS --cluster tw-cluster-2 \; --num-executors 8 --executor-cores 8 --executor-memory 32g \; --driver-memory 4g \; --conf spark.dynamicAllocation.enabled=false; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4376#issuecomment-364382087
https://github.com/broadinstitute/gatk/issues/4376#issuecomment-364382087:414,Testability,test,test-data,414,"This is what I ran (note it's not using the HDFS codepath). Can you try reproducing please? I used to be able to run this in 40 minutes (the whole pipeline, not just HC, and even BQSR is taking a lot longer now). ```bash; gatk ReadsPipelineSpark -I gs://broad-spark-eval-test-data/exome/NA12878.ga2.exome.maq.raw.bam -O gs://broad-spark-eval-test-data/exome/NA12878.ga2.exome.maq.raw.vcf -R; gs://broad-spark-eval-test-data/exome/Homo_sapiens_assembly18.2bit --known-sites gs://broad-spark-eval-test-data/exome/dbsnp_138.hg18.vcf -pairHMM AVX_LOGLESS_CACHING --max-; reads-per-alignment-start 10 \; -- \; --spark-runner GCS --cluster tw-cluster-2 \; --num-executors 8 --executor-cores 8 --executor-memory 32g \; --driver-memory 4g \; --conf spark.dynamicAllocation.enabled=false; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4376#issuecomment-364382087
https://github.com/broadinstitute/gatk/issues/4376#issuecomment-364382087:495,Testability,test,test-data,495,"This is what I ran (note it's not using the HDFS codepath). Can you try reproducing please? I used to be able to run this in 40 minutes (the whole pipeline, not just HC, and even BQSR is taking a lot longer now). ```bash; gatk ReadsPipelineSpark -I gs://broad-spark-eval-test-data/exome/NA12878.ga2.exome.maq.raw.bam -O gs://broad-spark-eval-test-data/exome/NA12878.ga2.exome.maq.raw.vcf -R; gs://broad-spark-eval-test-data/exome/Homo_sapiens_assembly18.2bit --known-sites gs://broad-spark-eval-test-data/exome/dbsnp_138.hg18.vcf -pairHMM AVX_LOGLESS_CACHING --max-; reads-per-alignment-start 10 \; -- \; --spark-runner GCS --cluster tw-cluster-2 \; --num-executors 8 --executor-cores 8 --executor-memory 32g \; --driver-memory 4g \; --conf spark.dynamicAllocation.enabled=false; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4376#issuecomment-364382087
https://github.com/broadinstitute/gatk/issues/4376#issuecomment-365969330:52,Performance,perform,performance,52,"Using git bisect I found the commit that caused the performance regression: 8a366c7ba570c61338f7109b86c3284b80d5cf47. If I revert this, then both BQSR and HC both take the expected amount of time running on an exome (~15 min, ~10 min, respectively).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4376#issuecomment-365969330
https://github.com/broadinstitute/gatk/issues/4376#issuecomment-365992568:105,Testability,test,test,105,@tomwhite Very glad to hear that the cause of the regression is the same for both BQSR and HC! Could you test whether https://github.com/broadinstitute/gatk/pull/4314 resolves the issue as well (as opposed to an actual revert of https://github.com/broadinstitute/gatk/commit/8a366c7ba570c61338f7109b86c3284b80d5cf47),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4376#issuecomment-365992568
https://github.com/broadinstitute/gatk/issues/4376#issuecomment-366072491:83,Performance,perform,performance,83,"@tomwhite OOC, do you have any comment as to why bumping the ADAM version caused a performance regression? I'm not aware of any changes we've made in ADAM that would have impacted either BQSR or HC.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4376#issuecomment-366072491
https://github.com/broadinstitute/gatk/issues/4376#issuecomment-366078617:210,Performance,perform,performance,210,"IIRC, the main commit in ADAM that would effect BQSR or HC was https://github.com/bigdatagenomics/adam/commit/1eed8e8e464f8f92a6e87afc1d334e751423e810#diff-abb5cd690409453a589fa8aadbfd7151 which _improved_ the performance of extracting regions from a 2 bit file. I run GATK4 HC pretty regularly with this change and haven't seen performance issues on datasets ranging in size from small targeted datasets up to WGS. Anywho, let me know if there's anything I can do to help debug the perf issue.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4376#issuecomment-366078617
https://github.com/broadinstitute/gatk/issues/4376#issuecomment-366078617:329,Performance,perform,performance,329,"IIRC, the main commit in ADAM that would effect BQSR or HC was https://github.com/bigdatagenomics/adam/commit/1eed8e8e464f8f92a6e87afc1d334e751423e810#diff-abb5cd690409453a589fa8aadbfd7151 which _improved_ the performance of extracting regions from a 2 bit file. I run GATK4 HC pretty regularly with this change and haven't seen performance issues on datasets ranging in size from small targeted datasets up to WGS. Anywho, let me know if there's anything I can do to help debug the perf issue.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4376#issuecomment-366078617
https://github.com/broadinstitute/gatk/issues/4376#issuecomment-366294101:407,Availability,down,down,407,"@droazen I ran #4314 and it did not solve the problem. When I reverted the ADAM patch from the #4314 branch I got the normal performance. @fnothaft I wish I knew. @lbergelson said he saw more logs being produced. Another (untested) theory is that the Kryo registrations changed somehow. GATK only uses the 2bit code from ADAM, so it is surprising that it is having such an effect. I'm not sure how to track down the problem at this point.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4376#issuecomment-366294101
https://github.com/broadinstitute/gatk/issues/4376#issuecomment-366294101:80,Deployability,patch,patch,80,"@droazen I ran #4314 and it did not solve the problem. When I reverted the ADAM patch from the #4314 branch I got the normal performance. @fnothaft I wish I knew. @lbergelson said he saw more logs being produced. Another (untested) theory is that the Kryo registrations changed somehow. GATK only uses the 2bit code from ADAM, so it is surprising that it is having such an effect. I'm not sure how to track down the problem at this point.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4376#issuecomment-366294101
https://github.com/broadinstitute/gatk/issues/4376#issuecomment-366294101:125,Performance,perform,performance,125,"@droazen I ran #4314 and it did not solve the problem. When I reverted the ADAM patch from the #4314 branch I got the normal performance. @fnothaft I wish I knew. @lbergelson said he saw more logs being produced. Another (untested) theory is that the Kryo registrations changed somehow. GATK only uses the 2bit code from ADAM, so it is surprising that it is having such an effect. I'm not sure how to track down the problem at this point.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4376#issuecomment-366294101
https://github.com/broadinstitute/gatk/issues/4376#issuecomment-366294101:192,Testability,log,logs,192,"@droazen I ran #4314 and it did not solve the problem. When I reverted the ADAM patch from the #4314 branch I got the normal performance. @fnothaft I wish I knew. @lbergelson said he saw more logs being produced. Another (untested) theory is that the Kryo registrations changed somehow. GATK only uses the 2bit code from ADAM, so it is surprising that it is having such an effect. I'm not sure how to track down the problem at this point.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4376#issuecomment-366294101
https://github.com/broadinstitute/gatk/issues/4376#issuecomment-366308897:329,Deployability,patch,patches,329,"Hi @tomwhite! The serializer registrations in ADAM shouldn't effect any GATK serialization, unless you're serializing classes from ADAM (such as `org.bdgenomics.format.avro.AlignmentRecord`); additionally, we haven't seen any performance issues with serialization in ADAM 0.23.0 outside of the GATK. We actually made a number of patches to eliminate logging in 0.23.0 (relative to 0.22.0), so I'd doubt that is the culprit. The one exception to this is logging when writing Parquet out to disk, which greatly increased sometime between ADAM 0.21.0 and 0.23.0, due to a change in Parquet versions upstream in Spark. However, this would only impact you if you were writing Parquet, and additionally this issue was resolved with the release of Spark 2.2.0, so you should see the logging go away with #4314. If I had to hypothesize anything, I'd suggest that the 2bit file change is the one thing that could be biting you. That said, we've been running with this 2bit file code quite frequently on AWS and Azure for at least the last 6 months using GATK HC on WES and WGS data and haven't seen any performance issues. I show that the changes in the 2bit file code between ADAM 0.20.0 and 0.23.0 are API compatible, so if you check out ADAM 0.23.0 and then `git checkout adam-parent-spark2_2.11-0.20.0 adam-core/src/main/scala/org/bdgenomics/adam/util/TwoBitFile.scala` and build the ADAM JAR (and then package that jar into GATK), you should be able to test that hypothesis.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4376#issuecomment-366308897
https://github.com/broadinstitute/gatk/issues/4376#issuecomment-366308897:730,Deployability,release,release,730,"Hi @tomwhite! The serializer registrations in ADAM shouldn't effect any GATK serialization, unless you're serializing classes from ADAM (such as `org.bdgenomics.format.avro.AlignmentRecord`); additionally, we haven't seen any performance issues with serialization in ADAM 0.23.0 outside of the GATK. We actually made a number of patches to eliminate logging in 0.23.0 (relative to 0.22.0), so I'd doubt that is the culprit. The one exception to this is logging when writing Parquet out to disk, which greatly increased sometime between ADAM 0.21.0 and 0.23.0, due to a change in Parquet versions upstream in Spark. However, this would only impact you if you were writing Parquet, and additionally this issue was resolved with the release of Spark 2.2.0, so you should see the logging go away with #4314. If I had to hypothesize anything, I'd suggest that the 2bit file change is the one thing that could be biting you. That said, we've been running with this 2bit file code quite frequently on AWS and Azure for at least the last 6 months using GATK HC on WES and WGS data and haven't seen any performance issues. I show that the changes in the 2bit file code between ADAM 0.20.0 and 0.23.0 are API compatible, so if you check out ADAM 0.23.0 and then `git checkout adam-parent-spark2_2.11-0.20.0 adam-core/src/main/scala/org/bdgenomics/adam/util/TwoBitFile.scala` and build the ADAM JAR (and then package that jar into GATK), you should be able to test that hypothesis.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4376#issuecomment-366308897
https://github.com/broadinstitute/gatk/issues/4376#issuecomment-366308897:226,Performance,perform,performance,226,"Hi @tomwhite! The serializer registrations in ADAM shouldn't effect any GATK serialization, unless you're serializing classes from ADAM (such as `org.bdgenomics.format.avro.AlignmentRecord`); additionally, we haven't seen any performance issues with serialization in ADAM 0.23.0 outside of the GATK. We actually made a number of patches to eliminate logging in 0.23.0 (relative to 0.22.0), so I'd doubt that is the culprit. The one exception to this is logging when writing Parquet out to disk, which greatly increased sometime between ADAM 0.21.0 and 0.23.0, due to a change in Parquet versions upstream in Spark. However, this would only impact you if you were writing Parquet, and additionally this issue was resolved with the release of Spark 2.2.0, so you should see the logging go away with #4314. If I had to hypothesize anything, I'd suggest that the 2bit file change is the one thing that could be biting you. That said, we've been running with this 2bit file code quite frequently on AWS and Azure for at least the last 6 months using GATK HC on WES and WGS data and haven't seen any performance issues. I show that the changes in the 2bit file code between ADAM 0.20.0 and 0.23.0 are API compatible, so if you check out ADAM 0.23.0 and then `git checkout adam-parent-spark2_2.11-0.20.0 adam-core/src/main/scala/org/bdgenomics/adam/util/TwoBitFile.scala` and build the ADAM JAR (and then package that jar into GATK), you should be able to test that hypothesis.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4376#issuecomment-366308897
https://github.com/broadinstitute/gatk/issues/4376#issuecomment-366308897:1094,Performance,perform,performance,1094,"Hi @tomwhite! The serializer registrations in ADAM shouldn't effect any GATK serialization, unless you're serializing classes from ADAM (such as `org.bdgenomics.format.avro.AlignmentRecord`); additionally, we haven't seen any performance issues with serialization in ADAM 0.23.0 outside of the GATK. We actually made a number of patches to eliminate logging in 0.23.0 (relative to 0.22.0), so I'd doubt that is the culprit. The one exception to this is logging when writing Parquet out to disk, which greatly increased sometime between ADAM 0.21.0 and 0.23.0, due to a change in Parquet versions upstream in Spark. However, this would only impact you if you were writing Parquet, and additionally this issue was resolved with the release of Spark 2.2.0, so you should see the logging go away with #4314. If I had to hypothesize anything, I'd suggest that the 2bit file change is the one thing that could be biting you. That said, we've been running with this 2bit file code quite frequently on AWS and Azure for at least the last 6 months using GATK HC on WES and WGS data and haven't seen any performance issues. I show that the changes in the 2bit file code between ADAM 0.20.0 and 0.23.0 are API compatible, so if you check out ADAM 0.23.0 and then `git checkout adam-parent-spark2_2.11-0.20.0 adam-core/src/main/scala/org/bdgenomics/adam/util/TwoBitFile.scala` and build the ADAM JAR (and then package that jar into GATK), you should be able to test that hypothesis.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4376#issuecomment-366308897
https://github.com/broadinstitute/gatk/issues/4376#issuecomment-366308897:350,Testability,log,logging,350,"Hi @tomwhite! The serializer registrations in ADAM shouldn't effect any GATK serialization, unless you're serializing classes from ADAM (such as `org.bdgenomics.format.avro.AlignmentRecord`); additionally, we haven't seen any performance issues with serialization in ADAM 0.23.0 outside of the GATK. We actually made a number of patches to eliminate logging in 0.23.0 (relative to 0.22.0), so I'd doubt that is the culprit. The one exception to this is logging when writing Parquet out to disk, which greatly increased sometime between ADAM 0.21.0 and 0.23.0, due to a change in Parquet versions upstream in Spark. However, this would only impact you if you were writing Parquet, and additionally this issue was resolved with the release of Spark 2.2.0, so you should see the logging go away with #4314. If I had to hypothesize anything, I'd suggest that the 2bit file change is the one thing that could be biting you. That said, we've been running with this 2bit file code quite frequently on AWS and Azure for at least the last 6 months using GATK HC on WES and WGS data and haven't seen any performance issues. I show that the changes in the 2bit file code between ADAM 0.20.0 and 0.23.0 are API compatible, so if you check out ADAM 0.23.0 and then `git checkout adam-parent-spark2_2.11-0.20.0 adam-core/src/main/scala/org/bdgenomics/adam/util/TwoBitFile.scala` and build the ADAM JAR (and then package that jar into GATK), you should be able to test that hypothesis.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4376#issuecomment-366308897
https://github.com/broadinstitute/gatk/issues/4376#issuecomment-366308897:453,Testability,log,logging,453,"Hi @tomwhite! The serializer registrations in ADAM shouldn't effect any GATK serialization, unless you're serializing classes from ADAM (such as `org.bdgenomics.format.avro.AlignmentRecord`); additionally, we haven't seen any performance issues with serialization in ADAM 0.23.0 outside of the GATK. We actually made a number of patches to eliminate logging in 0.23.0 (relative to 0.22.0), so I'd doubt that is the culprit. The one exception to this is logging when writing Parquet out to disk, which greatly increased sometime between ADAM 0.21.0 and 0.23.0, due to a change in Parquet versions upstream in Spark. However, this would only impact you if you were writing Parquet, and additionally this issue was resolved with the release of Spark 2.2.0, so you should see the logging go away with #4314. If I had to hypothesize anything, I'd suggest that the 2bit file change is the one thing that could be biting you. That said, we've been running with this 2bit file code quite frequently on AWS and Azure for at least the last 6 months using GATK HC on WES and WGS data and haven't seen any performance issues. I show that the changes in the 2bit file code between ADAM 0.20.0 and 0.23.0 are API compatible, so if you check out ADAM 0.23.0 and then `git checkout adam-parent-spark2_2.11-0.20.0 adam-core/src/main/scala/org/bdgenomics/adam/util/TwoBitFile.scala` and build the ADAM JAR (and then package that jar into GATK), you should be able to test that hypothesis.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4376#issuecomment-366308897
https://github.com/broadinstitute/gatk/issues/4376#issuecomment-366308897:776,Testability,log,logging,776,"Hi @tomwhite! The serializer registrations in ADAM shouldn't effect any GATK serialization, unless you're serializing classes from ADAM (such as `org.bdgenomics.format.avro.AlignmentRecord`); additionally, we haven't seen any performance issues with serialization in ADAM 0.23.0 outside of the GATK. We actually made a number of patches to eliminate logging in 0.23.0 (relative to 0.22.0), so I'd doubt that is the culprit. The one exception to this is logging when writing Parquet out to disk, which greatly increased sometime between ADAM 0.21.0 and 0.23.0, due to a change in Parquet versions upstream in Spark. However, this would only impact you if you were writing Parquet, and additionally this issue was resolved with the release of Spark 2.2.0, so you should see the logging go away with #4314. If I had to hypothesize anything, I'd suggest that the 2bit file change is the one thing that could be biting you. That said, we've been running with this 2bit file code quite frequently on AWS and Azure for at least the last 6 months using GATK HC on WES and WGS data and haven't seen any performance issues. I show that the changes in the 2bit file code between ADAM 0.20.0 and 0.23.0 are API compatible, so if you check out ADAM 0.23.0 and then `git checkout adam-parent-spark2_2.11-0.20.0 adam-core/src/main/scala/org/bdgenomics/adam/util/TwoBitFile.scala` and build the ADAM JAR (and then package that jar into GATK), you should be able to test that hypothesis.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4376#issuecomment-366308897
https://github.com/broadinstitute/gatk/issues/4376#issuecomment-366308897:1449,Testability,test,test,1449,"Hi @tomwhite! The serializer registrations in ADAM shouldn't effect any GATK serialization, unless you're serializing classes from ADAM (such as `org.bdgenomics.format.avro.AlignmentRecord`); additionally, we haven't seen any performance issues with serialization in ADAM 0.23.0 outside of the GATK. We actually made a number of patches to eliminate logging in 0.23.0 (relative to 0.22.0), so I'd doubt that is the culprit. The one exception to this is logging when writing Parquet out to disk, which greatly increased sometime between ADAM 0.21.0 and 0.23.0, due to a change in Parquet versions upstream in Spark. However, this would only impact you if you were writing Parquet, and additionally this issue was resolved with the release of Spark 2.2.0, so you should see the logging go away with #4314. If I had to hypothesize anything, I'd suggest that the 2bit file change is the one thing that could be biting you. That said, we've been running with this 2bit file code quite frequently on AWS and Azure for at least the last 6 months using GATK HC on WES and WGS data and haven't seen any performance issues. I show that the changes in the 2bit file code between ADAM 0.20.0 and 0.23.0 are API compatible, so if you check out ADAM 0.23.0 and then `git checkout adam-parent-spark2_2.11-0.20.0 adam-core/src/main/scala/org/bdgenomics/adam/util/TwoBitFile.scala` and build the ADAM JAR (and then package that jar into GATK), you should be able to test that hypothesis.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4376#issuecomment-366308897
https://github.com/broadinstitute/gatk/issues/4376#issuecomment-367069808:245,Deployability,upgrade,upgrade,245,"@tomwhite Ignore my previous message, sorry -- I see that you commented above that you tested https://github.com/broadinstitute/gatk/pull/4314 and it had no effect. I've opened https://github.com/broadinstitute/gatk/pull/4428 to revert the ADAM upgrade for now until we understand the underlying cause of the performance regression. @fnothaft It seems to me that the serializer registrations in ADAM could in theory affect the GATK, since we both register serializers for core classes in htsjdk. It seems worth investigating as a possibility, at least, as it's the only candidate mentioned so far that seems to have the potential to cause such a massive performance difference.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4376#issuecomment-367069808
https://github.com/broadinstitute/gatk/issues/4376#issuecomment-367069808:29,Integrability,message,message,29,"@tomwhite Ignore my previous message, sorry -- I see that you commented above that you tested https://github.com/broadinstitute/gatk/pull/4314 and it had no effect. I've opened https://github.com/broadinstitute/gatk/pull/4428 to revert the ADAM upgrade for now until we understand the underlying cause of the performance regression. @fnothaft It seems to me that the serializer registrations in ADAM could in theory affect the GATK, since we both register serializers for core classes in htsjdk. It seems worth investigating as a possibility, at least, as it's the only candidate mentioned so far that seems to have the potential to cause such a massive performance difference.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4376#issuecomment-367069808
https://github.com/broadinstitute/gatk/issues/4376#issuecomment-367069808:309,Performance,perform,performance,309,"@tomwhite Ignore my previous message, sorry -- I see that you commented above that you tested https://github.com/broadinstitute/gatk/pull/4314 and it had no effect. I've opened https://github.com/broadinstitute/gatk/pull/4428 to revert the ADAM upgrade for now until we understand the underlying cause of the performance regression. @fnothaft It seems to me that the serializer registrations in ADAM could in theory affect the GATK, since we both register serializers for core classes in htsjdk. It seems worth investigating as a possibility, at least, as it's the only candidate mentioned so far that seems to have the potential to cause such a massive performance difference.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4376#issuecomment-367069808
https://github.com/broadinstitute/gatk/issues/4376#issuecomment-367069808:654,Performance,perform,performance,654,"@tomwhite Ignore my previous message, sorry -- I see that you commented above that you tested https://github.com/broadinstitute/gatk/pull/4314 and it had no effect. I've opened https://github.com/broadinstitute/gatk/pull/4428 to revert the ADAM upgrade for now until we understand the underlying cause of the performance regression. @fnothaft It seems to me that the serializer registrations in ADAM could in theory affect the GATK, since we both register serializers for core classes in htsjdk. It seems worth investigating as a possibility, at least, as it's the only candidate mentioned so far that seems to have the potential to cause such a massive performance difference.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4376#issuecomment-367069808
https://github.com/broadinstitute/gatk/issues/4376#issuecomment-367069808:87,Testability,test,tested,87,"@tomwhite Ignore my previous message, sorry -- I see that you commented above that you tested https://github.com/broadinstitute/gatk/pull/4314 and it had no effect. I've opened https://github.com/broadinstitute/gatk/pull/4428 to revert the ADAM upgrade for now until we understand the underlying cause of the performance regression. @fnothaft It seems to me that the serializer registrations in ADAM could in theory affect the GATK, since we both register serializers for core classes in htsjdk. It seems worth investigating as a possibility, at least, as it's the only candidate mentioned so far that seems to have the potential to cause such a massive performance difference.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4376#issuecomment-367069808
https://github.com/broadinstitute/gatk/issues/4376#issuecomment-367112827:755,Performance,perform,perform,755,"Hi @droazen! Again, I'm skeptical that it would be a serialization change as we have only made one change to serializer registration for htsjdk classes since 0.20.0:. ```; $ git diff adam-parent_2.10-0.20.0 adam-core/src/main/scala/org/bdgenomics/adam/serialization/ADAMKryoRegistrator.scala | grep htsjdk; kryo.register(classOf[scala.Array[htsjdk.variant.vcf.VCFHeader]]); ```. Additionally, the [Kryo version used in ADAM has been unchanged since 0.20.0](https://github.com/bigdatagenomics/adam/commit/295fb5cf7bf1f089e82a1624e2056053e817b5f3). Since we do not shuffle `SAMRecord`s, we do not register a serializer for `SAMRecord`, which would presumably be the main record that HaplotypeCaller is serializing. The GATK's implementation of BQSR doesn't perform any shuffles other than when reducing the recalibration tables, correct? If so, any performance regression in GATK's BQSR would be exceedingly unlikely to be caused by serializer registrations in ADAM.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4376#issuecomment-367112827
https://github.com/broadinstitute/gatk/issues/4376#issuecomment-367112827:847,Performance,perform,performance,847,"Hi @droazen! Again, I'm skeptical that it would be a serialization change as we have only made one change to serializer registration for htsjdk classes since 0.20.0:. ```; $ git diff adam-parent_2.10-0.20.0 adam-core/src/main/scala/org/bdgenomics/adam/serialization/ADAMKryoRegistrator.scala | grep htsjdk; kryo.register(classOf[scala.Array[htsjdk.variant.vcf.VCFHeader]]); ```. Additionally, the [Kryo version used in ADAM has been unchanged since 0.20.0](https://github.com/bigdatagenomics/adam/commit/295fb5cf7bf1f089e82a1624e2056053e817b5f3). Since we do not shuffle `SAMRecord`s, we do not register a serializer for `SAMRecord`, which would presumably be the main record that HaplotypeCaller is serializing. The GATK's implementation of BQSR doesn't perform any shuffles other than when reducing the recalibration tables, correct? If so, any performance regression in GATK's BQSR would be exceedingly unlikely to be caused by serializer registrations in ADAM.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4376#issuecomment-367112827
https://github.com/broadinstitute/gatk/issues/4376#issuecomment-367122365:1074,Deployability,install,install,1074,"I would like to reiterate that the one code path in ADAM that is. 1. changed between 0.20.0 and 0.23.0 and; 2. that is used in both the GATK BQSR and HC engines. is the two bit file parsing and extraction engine. The main commit that changed in that code path was https://github.com/bigdatagenomics/adam/commit/1eed8e8e464f8f92a6e87afc1d334e751423e810, which reverts cleanly on ADAM trunk. There are also some changes in the `ReferenceRegion` class, they appear to be mostly cosmetic, but this necessitated changing one parameter from `null` to `Strand.INDEPENDENT` in https://github.com/broadinstitute/gatk/commit/8a366c7ba570c61338f7109b86c3284b80d5cf47. The GATK does one lookup into the TwoBitFile (which creates one ReferenceRegion along the way) per read during BQSR and two per assembly region during HC, so this code is inside your inner loop. Again, all it should take to test this hypothesis is:. ```; git clone git@github.com:bigdatagenomics/adam.git; cd adam; git checkout adam-parent-spark2_2.10-0.23.0; git revert 1eed8e8e464f8f92a6e87afc1d334e751423e810; mvn install -DskipTests; ```. You'd then need to build the GATK with the JAR this generates. If this makes the perf regression go away, then we can easily revert this change in ADAM 0.24.0, which will release two weeks from now. Let me know if there's any way I can be of help.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4376#issuecomment-367122365
https://github.com/broadinstitute/gatk/issues/4376#issuecomment-367122365:1271,Deployability,release,release,1271,"I would like to reiterate that the one code path in ADAM that is. 1. changed between 0.20.0 and 0.23.0 and; 2. that is used in both the GATK BQSR and HC engines. is the two bit file parsing and extraction engine. The main commit that changed in that code path was https://github.com/bigdatagenomics/adam/commit/1eed8e8e464f8f92a6e87afc1d334e751423e810, which reverts cleanly on ADAM trunk. There are also some changes in the `ReferenceRegion` class, they appear to be mostly cosmetic, but this necessitated changing one parameter from `null` to `Strand.INDEPENDENT` in https://github.com/broadinstitute/gatk/commit/8a366c7ba570c61338f7109b86c3284b80d5cf47. The GATK does one lookup into the TwoBitFile (which creates one ReferenceRegion along the way) per read during BQSR and two per assembly region during HC, so this code is inside your inner loop. Again, all it should take to test this hypothesis is:. ```; git clone git@github.com:bigdatagenomics/adam.git; cd adam; git checkout adam-parent-spark2_2.10-0.23.0; git revert 1eed8e8e464f8f92a6e87afc1d334e751423e810; mvn install -DskipTests; ```. You'd then need to build the GATK with the JAR this generates. If this makes the perf regression go away, then we can easily revert this change in ADAM 0.24.0, which will release two weeks from now. Let me know if there's any way I can be of help.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4376#issuecomment-367122365
https://github.com/broadinstitute/gatk/issues/4376#issuecomment-367122365:881,Testability,test,test,881,"I would like to reiterate that the one code path in ADAM that is. 1. changed between 0.20.0 and 0.23.0 and; 2. that is used in both the GATK BQSR and HC engines. is the two bit file parsing and extraction engine. The main commit that changed in that code path was https://github.com/bigdatagenomics/adam/commit/1eed8e8e464f8f92a6e87afc1d334e751423e810, which reverts cleanly on ADAM trunk. There are also some changes in the `ReferenceRegion` class, they appear to be mostly cosmetic, but this necessitated changing one parameter from `null` to `Strand.INDEPENDENT` in https://github.com/broadinstitute/gatk/commit/8a366c7ba570c61338f7109b86c3284b80d5cf47. The GATK does one lookup into the TwoBitFile (which creates one ReferenceRegion along the way) per read during BQSR and two per assembly region during HC, so this code is inside your inner loop. Again, all it should take to test this hypothesis is:. ```; git clone git@github.com:bigdatagenomics/adam.git; cd adam; git checkout adam-parent-spark2_2.10-0.23.0; git revert 1eed8e8e464f8f92a6e87afc1d334e751423e810; mvn install -DskipTests; ```. You'd then need to build the GATK with the JAR this generates. If this makes the perf regression go away, then we can easily revert this change in ADAM 0.24.0, which will release two weeks from now. Let me know if there's any way I can be of help.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4376#issuecomment-367122365
https://github.com/broadinstitute/gatk/issues/4376#issuecomment-367150206:641,Performance,perform,performance,641,"I'd also note that in the example command that @tomwhite is running uses just 4GB of memory on the driver while using a broadcast join strategy, which I believe is the default strategy used by BQSR. The [GZIP'ed dbSnp build 138 VCF in the hg18 GATK bundle](ftp://ftp.broadinstitute.org/bundle/hg18/) is ~1.4GB, and the hg18 2bit file is probably going to be ballpark 1GB of data. That's a lot of data to collect onto a driver with just 4GB of memory, so I wouldn't be surprised if the driver is OOMing. @lbergelson you'd mentioned [above](https://github.com/broadinstitute/gatk/issues/4376#issuecomment-364187885) that you haven't seen said performance regression and that it isn't showing up in the regression tests kicked off by CI. Can you confirm what driver memory settings you are using?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4376#issuecomment-367150206
https://github.com/broadinstitute/gatk/issues/4376#issuecomment-367150206:711,Testability,test,tests,711,"I'd also note that in the example command that @tomwhite is running uses just 4GB of memory on the driver while using a broadcast join strategy, which I believe is the default strategy used by BQSR. The [GZIP'ed dbSnp build 138 VCF in the hg18 GATK bundle](ftp://ftp.broadinstitute.org/bundle/hg18/) is ~1.4GB, and the hg18 2bit file is probably going to be ballpark 1GB of data. That's a lot of data to collect onto a driver with just 4GB of memory, so I wouldn't be surprised if the driver is OOMing. @lbergelson you'd mentioned [above](https://github.com/broadinstitute/gatk/issues/4376#issuecomment-364187885) that you haven't seen said performance regression and that it isn't showing up in the regression tests kicked off by CI. Can you confirm what driver memory settings you are using?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4376#issuecomment-367150206
https://github.com/broadinstitute/gatk/issues/4376#issuecomment-367159861:60,Deployability,release,release,60,"I've been looking at 2bit performance today, comparing ADAM release version 0.20.0 to release version 0.23.0 and to git HEAD (0.24.0-SNAPSHOT), in various use cases, and do not see any performance differences. @tomwhite `loadReferenceFile` in ADAM only supports local 2bit files, what happens in between the file in `gs://` cloud storage to when you load it via ADAM APIs?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4376#issuecomment-367159861
https://github.com/broadinstitute/gatk/issues/4376#issuecomment-367159861:86,Deployability,release,release,86,"I've been looking at 2bit performance today, comparing ADAM release version 0.20.0 to release version 0.23.0 and to git HEAD (0.24.0-SNAPSHOT), in various use cases, and do not see any performance differences. @tomwhite `loadReferenceFile` in ADAM only supports local 2bit files, what happens in between the file in `gs://` cloud storage to when you load it via ADAM APIs?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4376#issuecomment-367159861
https://github.com/broadinstitute/gatk/issues/4376#issuecomment-367159861:26,Performance,perform,performance,26,"I've been looking at 2bit performance today, comparing ADAM release version 0.20.0 to release version 0.23.0 and to git HEAD (0.24.0-SNAPSHOT), in various use cases, and do not see any performance differences. @tomwhite `loadReferenceFile` in ADAM only supports local 2bit files, what happens in between the file in `gs://` cloud storage to when you load it via ADAM APIs?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4376#issuecomment-367159861
https://github.com/broadinstitute/gatk/issues/4376#issuecomment-367159861:185,Performance,perform,performance,185,"I've been looking at 2bit performance today, comparing ADAM release version 0.20.0 to release version 0.23.0 and to git HEAD (0.24.0-SNAPSHOT), in various use cases, and do not see any performance differences. @tomwhite `loadReferenceFile` in ADAM only supports local 2bit files, what happens in between the file in `gs://` cloud storage to when you load it via ADAM APIs?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4376#issuecomment-367159861
https://github.com/broadinstitute/gatk/issues/4376#issuecomment-367159861:221,Performance,load,loadReferenceFile,221,"I've been looking at 2bit performance today, comparing ADAM release version 0.20.0 to release version 0.23.0 and to git HEAD (0.24.0-SNAPSHOT), in various use cases, and do not see any performance differences. @tomwhite `loadReferenceFile` in ADAM only supports local 2bit files, what happens in between the file in `gs://` cloud storage to when you load it via ADAM APIs?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4376#issuecomment-367159861
https://github.com/broadinstitute/gatk/issues/4376#issuecomment-367159861:350,Performance,load,load,350,"I've been looking at 2bit performance today, comparing ADAM release version 0.20.0 to release version 0.23.0 and to git HEAD (0.24.0-SNAPSHOT), in various use cases, and do not see any performance differences. @tomwhite `loadReferenceFile` in ADAM only supports local 2bit files, what happens in between the file in `gs://` cloud storage to when you load it via ADAM APIs?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4376#issuecomment-367159861
https://github.com/broadinstitute/gatk/issues/4376#issuecomment-368564267:128,Deployability,release,release,128,@fnothaft I tried reverting 1eed8e8 and the performance was back to normal! So it would be worth reverting in ADAM for the next release if possible.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4376#issuecomment-368564267
https://github.com/broadinstitute/gatk/issues/4376#issuecomment-368564267:44,Performance,perform,performance,44,@fnothaft I tried reverting 1eed8e8 and the performance was back to normal! So it would be worth reverting in ADAM for the next release if possible.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4376#issuecomment-368564267
https://github.com/broadinstitute/gatk/pull/4377#issuecomment-364188060:2439,Deployability,update,update,2439,"77 +/- ##; ============================================; + Coverage 79.07% 79.08% +<.01% ; - Complexity 16594 16595 +1 ; ============================================; Files 1050 1050 ; Lines 59969 59969 ; Branches 9831 9831 ; ============================================; + Hits 47419 47424 +5 ; + Misses 8741 8738 -3 ; + Partials 3809 3807 -2; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4377?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...park/sv/discovery/alignment/AlignmentInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/4377/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvYWxpZ25tZW50L0FsaWdubWVudEludGVydmFsLmphdmE=) | `89.65% <0%> (+0.76%)` | `72% <0%> (+1%)` | :arrow_up: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4377/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `80% <0%> (+1.29%)` | `39% <0%> (ø)` | :arrow_down: |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/4377/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `90% <0%> (+10%)` | `3% <0%> (ø)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4377?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4377?src=pr&el=footer). Last update [1221e03...403ff93](https://codecov.io/gh/broadinstitute/gatk/pull/4377?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4377#issuecomment-364188060
https://github.com/broadinstitute/gatk/pull/4377#issuecomment-364188060:2342,Energy Efficiency,Power,Powered,2342,"77 +/- ##; ============================================; + Coverage 79.07% 79.08% +<.01% ; - Complexity 16594 16595 +1 ; ============================================; Files 1050 1050 ; Lines 59969 59969 ; Branches 9831 9831 ; ============================================; + Hits 47419 47424 +5 ; + Misses 8741 8738 -3 ; + Partials 3809 3807 -2; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4377?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...park/sv/discovery/alignment/AlignmentInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/4377/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvYWxpZ25tZW50L0FsaWdubWVudEludGVydmFsLmphdmE=) | `89.65% <0%> (+0.76%)` | `72% <0%> (+1%)` | :arrow_up: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4377/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `80% <0%> (+1.29%)` | `39% <0%> (ø)` | :arrow_down: |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/4377/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `90% <0%> (+10%)` | `3% <0%> (ø)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4377?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4377?src=pr&el=footer). Last update [1221e03...403ff93](https://codecov.io/gh/broadinstitute/gatk/pull/4377?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4377#issuecomment-364188060
https://github.com/broadinstitute/gatk/pull/4377#issuecomment-364188060:2205,Usability,learn,learn,2205,"77 +/- ##; ============================================; + Coverage 79.07% 79.08% +<.01% ; - Complexity 16594 16595 +1 ; ============================================; Files 1050 1050 ; Lines 59969 59969 ; Branches 9831 9831 ; ============================================; + Hits 47419 47424 +5 ; + Misses 8741 8738 -3 ; + Partials 3809 3807 -2; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4377?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...park/sv/discovery/alignment/AlignmentInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/4377/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvYWxpZ25tZW50L0FsaWdubWVudEludGVydmFsLmphdmE=) | `89.65% <0%> (+0.76%)` | `72% <0%> (+1%)` | :arrow_up: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4377/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `80% <0%> (+1.29%)` | `39% <0%> (ø)` | :arrow_down: |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/4377/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `90% <0%> (+10%)` | `3% <0%> (ø)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4377?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4377?src=pr&el=footer). Last update [1221e03...403ff93](https://codecov.io/gh/broadinstitute/gatk/pull/4377?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4377#issuecomment-364188060
https://github.com/broadinstitute/gatk/pull/4379#issuecomment-364256682:33,Performance,optimiz,optimizations,33,Can you provide a summary of the optimizations included here @pnvaidya ?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4379#issuecomment-364256682
https://github.com/broadinstitute/gatk/pull/4379#issuecomment-364265035:141,Availability,error,error,141,"Its the same optimizations for level as we discussed before, no new optimizations. The previous merge did not include all the optimizations (error on my part)... hence I have to do a new PR.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4379#issuecomment-364265035
https://github.com/broadinstitute/gatk/pull/4379#issuecomment-364265035:13,Performance,optimiz,optimizations,13,"Its the same optimizations for level as we discussed before, no new optimizations. The previous merge did not include all the optimizations (error on my part)... hence I have to do a new PR.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4379#issuecomment-364265035
https://github.com/broadinstitute/gatk/pull/4379#issuecomment-364265035:68,Performance,optimiz,optimizations,68,"Its the same optimizations for level as we discussed before, no new optimizations. The previous merge did not include all the optimizations (error on my part)... hence I have to do a new PR.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4379#issuecomment-364265035
https://github.com/broadinstitute/gatk/pull/4379#issuecomment-364265035:126,Performance,optimiz,optimizations,126,"Its the same optimizations for level as we discussed before, no new optimizations. The previous merge did not include all the optimizations (error on my part)... hence I have to do a new PR.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4379#issuecomment-364265035
https://github.com/broadinstitute/gatk/issues/4380#issuecomment-415085087:386,Energy Efficiency,reduce,reduce,386,Create a checksum to validate individual data sources based on the size of the data source files and some other meta attributes. Calculate the checksum for each data source in each data source package (somatic/germline). Store these checksums in the GATK jar and validate the data sources at runtime. Default to an exception if the checksums do not match. Have a command-line option to reduce the exception to a warning.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4380#issuecomment-415085087
https://github.com/broadinstitute/gatk/issues/4380#issuecomment-415085087:9,Security,checksum,checksum,9,Create a checksum to validate individual data sources based on the size of the data source files and some other meta attributes. Calculate the checksum for each data source in each data source package (somatic/germline). Store these checksums in the GATK jar and validate the data sources at runtime. Default to an exception if the checksums do not match. Have a command-line option to reduce the exception to a warning.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4380#issuecomment-415085087
https://github.com/broadinstitute/gatk/issues/4380#issuecomment-415085087:21,Security,validat,validate,21,Create a checksum to validate individual data sources based on the size of the data source files and some other meta attributes. Calculate the checksum for each data source in each data source package (somatic/germline). Store these checksums in the GATK jar and validate the data sources at runtime. Default to an exception if the checksums do not match. Have a command-line option to reduce the exception to a warning.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4380#issuecomment-415085087
https://github.com/broadinstitute/gatk/issues/4380#issuecomment-415085087:143,Security,checksum,checksum,143,Create a checksum to validate individual data sources based on the size of the data source files and some other meta attributes. Calculate the checksum for each data source in each data source package (somatic/germline). Store these checksums in the GATK jar and validate the data sources at runtime. Default to an exception if the checksums do not match. Have a command-line option to reduce the exception to a warning.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4380#issuecomment-415085087
https://github.com/broadinstitute/gatk/issues/4380#issuecomment-415085087:233,Security,checksum,checksums,233,Create a checksum to validate individual data sources based on the size of the data source files and some other meta attributes. Calculate the checksum for each data source in each data source package (somatic/germline). Store these checksums in the GATK jar and validate the data sources at runtime. Default to an exception if the checksums do not match. Have a command-line option to reduce the exception to a warning.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4380#issuecomment-415085087
https://github.com/broadinstitute/gatk/issues/4380#issuecomment-415085087:263,Security,validat,validate,263,Create a checksum to validate individual data sources based on the size of the data source files and some other meta attributes. Calculate the checksum for each data source in each data source package (somatic/germline). Store these checksums in the GATK jar and validate the data sources at runtime. Default to an exception if the checksums do not match. Have a command-line option to reduce the exception to a warning.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4380#issuecomment-415085087
https://github.com/broadinstitute/gatk/issues/4380#issuecomment-415085087:332,Security,checksum,checksums,332,Create a checksum to validate individual data sources based on the size of the data source files and some other meta attributes. Calculate the checksum for each data source in each data source package (somatic/germline). Store these checksums in the GATK jar and validate the data sources at runtime. Default to an exception if the checksums do not match. Have a command-line option to reduce the exception to a warning.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4380#issuecomment-415085087
https://github.com/broadinstitute/gatk/issues/4383#issuecomment-364497042:139,Modifiability,inherit,inherited,139,"I'll also mention that as part of https://github.com/broadinstitute/gatk/issues/4341 we plan to give tools more control over the arguments inherited from `GATKTool`, including selectively disabling and redefining engine arguments, so once a mechanism is in place for that `CalculateGenotypePosteriors` could make `--sequence-dictionary` required. Currently this ability only exists for a few `GATKTool` arguments, and the tool has to override methods like `requiresReads()` to make use of it. Until the ability to do this is generalized, recommend the stopgap solution with the check in `onTraversalStart()` + a note in the tool's docs.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4383#issuecomment-364497042
https://github.com/broadinstitute/gatk/pull/4384#issuecomment-364565484:167,Usability,Simpl,Simple,167,"@LeeTL1220 Hey Lee. There was some confusion, and my team thought Mutect2 is still in beta. Removing the beta tag will allow our docs to show the tool as not in beta. Simple fix :)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4384#issuecomment-364565484
https://github.com/broadinstitute/gatk/pull/4384#issuecomment-365646387:364,Deployability,release,release,364,"@chandrans @davidbenjamin I'm not actually objecting to the idea of taking `Mutect2` out of beta, for the record. I'm just trying to get people used to the idea that removing the `@BetaFeature` tag is actually a ""big step"" that requires careful evaluation, since it can't be undone. It's not just something that affects tool documentation -- it affects our entire release and development process now that we're out of beta. If a tool is marked stable, it needs to be kept in a constantly releasable state in master, and major changes to stable tools need to be done in such a way that existing functionality is not compromised. If the latest master version of `Mutect2` has been run through and passed whatever evaluation criteria/scripts your team relies on @davidbenjamin, and you are comfortable at this point with the additional restrictions that come with doing development on a stable tool, then by all means take it out of beta!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4384#issuecomment-365646387
https://github.com/broadinstitute/gatk/pull/4384#issuecomment-365646387:275,Usability,undo,undone,275,"@chandrans @davidbenjamin I'm not actually objecting to the idea of taking `Mutect2` out of beta, for the record. I'm just trying to get people used to the idea that removing the `@BetaFeature` tag is actually a ""big step"" that requires careful evaluation, since it can't be undone. It's not just something that affects tool documentation -- it affects our entire release and development process now that we're out of beta. If a tool is marked stable, it needs to be kept in a constantly releasable state in master, and major changes to stable tools need to be done in such a way that existing functionality is not compromised. If the latest master version of `Mutect2` has been run through and passed whatever evaluation criteria/scripts your team relies on @davidbenjamin, and you are comfortable at this point with the additional restrictions that come with doing development on a stable tool, then by all means take it out of beta!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4384#issuecomment-365646387
https://github.com/broadinstitute/gatk/pull/4384#issuecomment-365660852:119,Security,validat,validation,119,@LeeTL1220 The criteria in my opinion are being the best Mutect and being stable. Were you suggesting waiting for some validation like MC3?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4384#issuecomment-365660852
https://github.com/broadinstitute/gatk/pull/4385#issuecomment-364512439:1848,Testability,test,test,1848,pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...llbender/tools/spark/sv/evidence/ReadMetadata.java](https://codecov.io/gh/broadinstitute/gatk/pull/4385/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9ldmlkZW5jZS9SZWFkTWV0YWRhdGEuamF2YQ==) | `89.418% <100%> (+0.229%)` | `57 <0> (+1)` | :arrow_up: |; | [...er/tools/spark/sv/evidence/BreakpointEvidence.java](https://codecov.io/gh/broadinstitute/gatk/pull/4385/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9ldmlkZW5jZS9CcmVha3BvaW50RXZpZGVuY2UuamF2YQ==) | `81.844% <70%> (-0.08%)` | `12 <0> (ø)` | |; | [...institute/hellbender/exceptions/UserException.java](https://codecov.io/gh/broadinstitute/gatk/pull/4385/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9leGNlcHRpb25zL1VzZXJFeGNlcHRpb24uamF2YQ==) | `71.111% <0%> (-0.207%)` | `3% <0%> (ø)` | |; | [...utils/test/ReadsPreprocessingPipelineTestData.java](https://codecov.io/gh/broadinstitute/gatk/pull/4385/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1JlYWRzUHJlcHJvY2Vzc2luZ1BpcGVsaW5lVGVzdERhdGEuamF2YQ==) | `0.847% <0%> (-0.015%)` | `1% <0%> (ø)` | |; | [...dinstitute/hellbender/utils/pileup/ReadPileup.java](https://codecov.io/gh/broadinstitute/gatk/pull/4385/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9waWxldXAvUmVhZFBpbGV1cC5qYXZh) | `91.946% <0%> (ø)` | `64% <0%> (ø)` | :arrow_down: |; | [...itute/hellbender/engine/spark/GATKRegistrator.java](https://codecov.io/gh/broadinstitute/gatk/pull/4385/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvR0FUS1JlZ2lzdHJhdG9yLmphdmE=) | `100% <0%> (ø)` | `2% <0%> (ø)` | :arrow_down: |; | [...te/hellbender/utils/read/CigarConversionUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4385/diff?src=pr&el=tree#diff-,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4385#issuecomment-364512439
https://github.com/broadinstitute/gatk/issues/4387#issuecomment-453320358:45,Deployability,update,update,45,"Hi Chris,. We have a user enquiring about an update on this issue. Do we have a timeline for this?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4387#issuecomment-453320358
https://github.com/broadinstitute/gatk/issues/4389#issuecomment-364748538:585,Deployability,install,installed,585,"@wujh2017 Did you set up the appropriate conda environment as described in the README?. > Python 3.6.2, along with a set of additional Python packages, are required to run some tools and workflows. GATK uses the Conda package manager to establish and manage the environment and dependencies required by these tools. The GATK Docker image comes with this environment pre-configured. In order to establish an environment suitable to run these tools outside of the Docker image, the conda gatkcondaenv.yml file is provided. To establish the conda environment locally, Conda must first be installed. Then, create the gatk environment by running the command conda env create -n gatk -f gatkcondaenv.yml (developers should run ./gradlew createPythonPackageArchive, followed by conda env create -n gatk -f scripts/gatkcondaenv.yml from within the root of the repository clone). To activate the environment once it has been created, run the command source activate gatk. See the Conda documentation for additional information about using and managing Conda environments.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4389#issuecomment-364748538
https://github.com/broadinstitute/gatk/issues/4389#issuecomment-364748538:278,Integrability,depend,dependencies,278,"@wujh2017 Did you set up the appropriate conda environment as described in the README?. > Python 3.6.2, along with a set of additional Python packages, are required to run some tools and workflows. GATK uses the Conda package manager to establish and manage the environment and dependencies required by these tools. The GATK Docker image comes with this environment pre-configured. In order to establish an environment suitable to run these tools outside of the Docker image, the conda gatkcondaenv.yml file is provided. To establish the conda environment locally, Conda must first be installed. Then, create the gatk environment by running the command conda env create -n gatk -f gatkcondaenv.yml (developers should run ./gradlew createPythonPackageArchive, followed by conda env create -n gatk -f scripts/gatkcondaenv.yml from within the root of the repository clone). To activate the environment once it has been created, run the command source activate gatk. See the Conda documentation for additional information about using and managing Conda environments.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4389#issuecomment-364748538
https://github.com/broadinstitute/gatk/issues/4389#issuecomment-364748538:370,Modifiability,config,configured,370,"@wujh2017 Did you set up the appropriate conda environment as described in the README?. > Python 3.6.2, along with a set of additional Python packages, are required to run some tools and workflows. GATK uses the Conda package manager to establish and manage the environment and dependencies required by these tools. The GATK Docker image comes with this environment pre-configured. In order to establish an environment suitable to run these tools outside of the Docker image, the conda gatkcondaenv.yml file is provided. To establish the conda environment locally, Conda must first be installed. Then, create the gatk environment by running the command conda env create -n gatk -f gatkcondaenv.yml (developers should run ./gradlew createPythonPackageArchive, followed by conda env create -n gatk -f scripts/gatkcondaenv.yml from within the root of the repository clone). To activate the environment once it has been created, run the command source activate gatk. See the Conda documentation for additional information about using and managing Conda environments.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4389#issuecomment-364748538
https://github.com/broadinstitute/gatk/issues/4389#issuecomment-365117170:478,Deployability,pipeline,pipeline,478,"@wujh2017 thank you for trying out this beta tool! As @samuelklee mentioned above, your issue stems from not having the proper python conda env. I guess you have a python 2.x interpreter in your system environment which fails to parse GATK's python code (which requires python 3.6+). Please either follow the instructions in the README.md file, or use the official Docker image instead. Also, I would like to add that the default parameters for running the Germline CNV calling pipeline are currently being fine-tuned separately for WES and WGS data. The default parameters shipped with GATK 4.0.0.0 are preliminary and are not expected to yield optimal results.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4389#issuecomment-365117170
https://github.com/broadinstitute/gatk/issues/4389#issuecomment-365117170:512,Performance,tune,tuned,512,"@wujh2017 thank you for trying out this beta tool! As @samuelklee mentioned above, your issue stems from not having the proper python conda env. I guess you have a python 2.x interpreter in your system environment which fails to parse GATK's python code (which requires python 3.6+). Please either follow the instructions in the README.md file, or use the official Docker image instead. Also, I would like to add that the default parameters for running the Germline CNV calling pipeline are currently being fine-tuned separately for WES and WGS data. The default parameters shipped with GATK 4.0.0.0 are preliminary and are not expected to yield optimal results.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4389#issuecomment-365117170
https://github.com/broadinstitute/gatk/issues/4390#issuecomment-364926297:51,Deployability,release,release,51,@davidbenjamin That should really have been in the release notes! Which PR made that change?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4390#issuecomment-364926297
https://github.com/broadinstitute/gatk/issues/4390#issuecomment-364990476:79,Availability,down,down,79,"Ok, thanks -- I'll add a note to the release notes retroactively to try to cut down on user surprise.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4390#issuecomment-364990476
https://github.com/broadinstitute/gatk/issues/4390#issuecomment-364990476:37,Deployability,release,release,37,"Ok, thanks -- I'll add a note to the release notes retroactively to try to cut down on user surprise.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4390#issuecomment-364990476
https://github.com/broadinstitute/gatk/issues/4392#issuecomment-365032673:99,Deployability,pipeline,pipeline,99,"@erarroji Can you give us more information about exactly which GATK4 tools you are running in your pipeline? Some GATK4 tools (such as `MarkDuplicatesSpark` and `HaplotypeCallerSpark`) are still marked as `beta` and may not always give correct output. You should use the non-beta versions of these tools instead (eg., `MarkDuplicates` and `HaplotypeCaller`). . You can see which tools are marked as `beta` by running: `./gatk --list`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4392#issuecomment-365032673
https://github.com/broadinstitute/gatk/pull/4396#issuecomment-365728666:187,Testability,test,test,187,"@asmirnov239 @sooheelee Let's hold off on reviewing until the other PR (#4335) upon which this is rebased is merged. At that point, @mbabadi can rebase (it might also be helpful to split test files into their own commit, since there are a lot that have been changed) and then we can review. We can go ahead and start evaluations on this branch, though!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4396#issuecomment-365728666
https://github.com/broadinstitute/gatk/pull/4396#issuecomment-368637516:1273,Usability,Simpl,SimpleIntervalCollection,1273,?src=pr&el=desc) will **decrease** coverage by `0.642%`.; > The diff coverage is `84.221%`. ```diff; @@ Coverage Diff @@; ## master #4396 +/- ##; ===============================================; - Coverage 79.815% 79.173% -0.642% ; - Complexity 16933 17160 +227 ; ===============================================; Files 1058 1053 -5 ; Lines 61408 61790 +382 ; Branches 9967 10343 +376 ; ===============================================; - Hits 49013 48921 -92 ; - Misses 8512 8981 +469 ; - Partials 3883 3888 +5; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4396?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...ls/copynumber/gcnv/GermlineCNVNamingConstants.java](https://codecov.io/gh/broadinstitute/gatk/pull/4396/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2djbnYvR2VybWxpbmVDTlZOYW1pbmdDb25zdGFudHMuamF2YQ==) | `0% <ø> (ø)` | `0 <0> (ø)` | :arrow_down: |; | [.../formats/collections/SimpleIntervalCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/4396/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2Zvcm1hdHMvY29sbGVjdGlvbnMvU2ltcGxlSW50ZXJ2YWxDb2xsZWN0aW9uLmphdmE=) | `100% <ø> (ø)` | `5 <0> (ø)` | :arrow_down: |; | [...ools/copynumber/DetermineGermlineContigPloidy.java](https://codecov.io/gh/broadinstitute/gatk/pull/4396/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL0RldGVybWluZUdlcm1saW5lQ29udGlnUGxvaWR5LmphdmE=) | `96.471% <ø> (ø)` | `14 <0> (ø)` | :arrow_down: |; | [...hellbender/tools/copynumber/GermlineCNVCaller.java](https://codecov.io/gh/broadinstitute/gatk/pull/4396/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL0dlcm1saW5lQ05WQ2FsbGVyLmphdmE=) | `86.364% <ø> (ø)` | `10 <0> (ø)` | :arrow_down: |; | [...ollections/IntegerCopyNumberSegmentCollection.java](https://codecov.i,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4396#issuecomment-368637516
https://github.com/broadinstitute/gatk/pull/4396#issuecomment-369015522:28,Testability,test,tests,28,@samuelklee I'll write unit tests for segment quality calculation in a separate PR (issue #4464).,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4396#issuecomment-369015522
https://github.com/broadinstitute/gatk/issues/4397#issuecomment-391035245:135,Deployability,update,update,135,"@mwalker174 also mentioned to me that he's adjusted the scattering strategy so that he can run multiple blocks in one shard. If we can update the WDL with both fixes, that would be great.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4397#issuecomment-391035245
https://github.com/broadinstitute/gatk/issues/4397#issuecomment-391071615:310,Availability,down,down,310,"OK. However, don't forget that the denoising model is fit independently in each block. So introducing too many blocks could cause overfitting, in a sense. Also, you want to make sure that you have enough bins in each block to learn the model. 10k seems safe, but I'd spot check results first if you want to go down to 1k.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4397#issuecomment-391071615
https://github.com/broadinstitute/gatk/issues/4397#issuecomment-391071615:253,Safety,safe,safe,253,"OK. However, don't forget that the denoising model is fit independently in each block. So introducing too many blocks could cause overfitting, in a sense. Also, you want to make sure that you have enough bins in each block to learn the model. 10k seems safe, but I'd spot check results first if you want to go down to 1k.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4397#issuecomment-391071615
https://github.com/broadinstitute/gatk/issues/4397#issuecomment-391071615:226,Usability,learn,learn,226,"OK. However, don't forget that the denoising model is fit independently in each block. So introducing too many blocks could cause overfitting, in a sense. Also, you want to make sure that you have enough bins in each block to learn the model. 10k seems safe, but I'd spot check results first if you want to go down to 1k.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4397#issuecomment-391071615
https://github.com/broadinstitute/gatk/issues/4397#issuecomment-392119427:196,Availability,error,error,196,"I will try that as well. I just finished building a PoN at 250bp bin size with 1k intervals per block. This produces ~10k models and the PostprocessGermlineCNVCalls WDL task gets us the following error from Cromwell:. > The task run request has exceeded the maximum PAPI request size.If you have a task with a very large number of inputs and / or outputs in your workflow you should try; > to reduce it. Depending on your case you could: 1) Zip your input files together and unzip them in the command. 2) Use a file of file names and localize the files yourself. Who knew? So, we are also going to have to modify PostprocessGermlineCNVCalls and the case mode calling task to accept a tar archive containing all the models. @samuelklee @mbabadi Let me know if you have any opinions on this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4397#issuecomment-392119427
https://github.com/broadinstitute/gatk/issues/4397#issuecomment-392119427:393,Energy Efficiency,reduce,reduce,393,"I will try that as well. I just finished building a PoN at 250bp bin size with 1k intervals per block. This produces ~10k models and the PostprocessGermlineCNVCalls WDL task gets us the following error from Cromwell:. > The task run request has exceeded the maximum PAPI request size.If you have a task with a very large number of inputs and / or outputs in your workflow you should try; > to reduce it. Depending on your case you could: 1) Zip your input files together and unzip them in the command. 2) Use a file of file names and localize the files yourself. Who knew? So, we are also going to have to modify PostprocessGermlineCNVCalls and the case mode calling task to accept a tar archive containing all the models. @samuelklee @mbabadi Let me know if you have any opinions on this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4397#issuecomment-392119427
https://github.com/broadinstitute/gatk/issues/4397#issuecomment-392119427:404,Integrability,Depend,Depending,404,"I will try that as well. I just finished building a PoN at 250bp bin size with 1k intervals per block. This produces ~10k models and the PostprocessGermlineCNVCalls WDL task gets us the following error from Cromwell:. > The task run request has exceeded the maximum PAPI request size.If you have a task with a very large number of inputs and / or outputs in your workflow you should try; > to reduce it. Depending on your case you could: 1) Zip your input files together and unzip them in the command. 2) Use a file of file names and localize the files yourself. Who knew? So, we are also going to have to modify PostprocessGermlineCNVCalls and the case mode calling task to accept a tar archive containing all the models. @samuelklee @mbabadi Let me know if you have any opinions on this.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4397#issuecomment-392119427
https://github.com/broadinstitute/gatk/issues/4397#issuecomment-392154161:191,Performance,optimiz,optimize,191,"Yes, I'm not sure I would expect that to be true. My guess is that we continue to run long after suitable convergence with the current inference parameters (which we have not had a chance to optimize over for runtime). I think we can probably afford to be less conservative. @mbabadi do you have a better handle on this?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4397#issuecomment-392154161
https://github.com/broadinstitute/gatk/issues/4397#issuecomment-472862393:109,Modifiability,config,config,109,"@asmirnov239 I think that some of the optimizations that @vruano made to the postprocessing step concern the config JSONs, gCNV version, and interval list output added in #5176. These take a lot of time to localize when the number of shards is large but, aside from the interval list, aren't really used for anything, correct?. Were these just added for debugging purposes, or for reproducibility/provenance? Let's revisit whether it's necessary to pass these files on when we merge @vruano's changes into the canonical WDL.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4397#issuecomment-472862393
https://github.com/broadinstitute/gatk/issues/4397#issuecomment-472862393:38,Performance,optimiz,optimizations,38,"@asmirnov239 I think that some of the optimizations that @vruano made to the postprocessing step concern the config JSONs, gCNV version, and interval list output added in #5176. These take a lot of time to localize when the number of shards is large but, aside from the interval list, aren't really used for anything, correct?. Were these just added for debugging purposes, or for reproducibility/provenance? Let's revisit whether it's necessary to pass these files on when we merge @vruano's changes into the canonical WDL.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4397#issuecomment-472862393
https://github.com/broadinstitute/gatk/issues/4397#issuecomment-900624782:584,Performance,perform,performance,584,"I think issues with gCNV postprocessing initially stemmed from things like 1) taking large sample x shard transposes (which Cromwell may have had trouble with at some point), 2) localizing more files than necessary for each sample, 3) introduction of lexicographical globbing bugs, etc. I think various people have tried to address this via things like bundling, which we ended up reverting in favor of transposing. Unfortunately, I'm afraid I've lost the plot on this after so long; and not sure I ever had it---is there any documentation (e.g., of things like how bundling improved performance) elsewhere that might help us decide what's left to be done? Seems like I had some more coherent thoughts in https://github.com/broadinstitute/gatk/pull/6607#issuecomment-632303744. As before, if any remaining issues like the call caching mentioned above would best be addressed at the Cromwell level, I think it's at least worth an investigation of what might be involved.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4397#issuecomment-900624782
https://github.com/broadinstitute/gatk/issues/4397#issuecomment-928168236:381,Availability,reliab,reliably,381,"Most of the scaling issues in Cromwell/Terra have been resolved. Terra still has limitations on workflow metadata size, and passing long file arrays to ever task in large scatters (i.e. the full list of counts files is passed into every gCNV shard) can limit our batch sizes for workflows that embed gCNV (e.g. GatherBatchEvidence in gatk-sv). gCNV workflows also don't call cache reliably (presumably due to timeouts) probably again due to the large file arrays, including 2D arrays.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4397#issuecomment-928168236
https://github.com/broadinstitute/gatk/issues/4397#issuecomment-928168236:375,Performance,cache,cache,375,"Most of the scaling issues in Cromwell/Terra have been resolved. Terra still has limitations on workflow metadata size, and passing long file arrays to ever task in large scatters (i.e. the full list of counts files is passed into every gCNV shard) can limit our batch sizes for workflows that embed gCNV (e.g. GatherBatchEvidence in gatk-sv). gCNV workflows also don't call cache reliably (presumably due to timeouts) probably again due to the large file arrays, including 2D arrays.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4397#issuecomment-928168236
https://github.com/broadinstitute/gatk/issues/4397#issuecomment-928168236:409,Safety,timeout,timeouts,409,"Most of the scaling issues in Cromwell/Terra have been resolved. Terra still has limitations on workflow metadata size, and passing long file arrays to ever task in large scatters (i.e. the full list of counts files is passed into every gCNV shard) can limit our batch sizes for workflows that embed gCNV (e.g. GatherBatchEvidence in gatk-sv). gCNV workflows also don't call cache reliably (presumably due to timeouts) probably again due to the large file arrays, including 2D arrays.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4397#issuecomment-928168236
https://github.com/broadinstitute/gatk/issues/4400#issuecomment-420360969:45,Usability,simpl,simply,45,"From Lee:. he COSMIC datasource in oncotator simply finds all overlapping records and counts the protein change (""Mutation AA"") values. Like a histogram of all overlapping records. (edited). `mutation_AAs = collections.Counter([entry['Mutation AA'] for entry in overlapping_cosmic_entries])`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4400#issuecomment-420360969
https://github.com/broadinstitute/gatk/issues/4400#issuecomment-420741241:116,Deployability,update,update,116,"@LeeTL1220 Should the default funcotation here be an empty string, or ""0""? Currently it's the latter, but with this update it seems that with this change we should switch to empty string.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4400#issuecomment-420741241
https://github.com/broadinstitute/gatk/pull/4401#issuecomment-367117476:27,Testability,test,test,27,"woops, this should fix the test.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4401#issuecomment-367117476
https://github.com/broadinstitute/gatk/pull/4401#issuecomment-367136245:1853,Testability,test,test,1853,=================================; + Coverage 79.04% 79.05% +0.01% ; - Complexity 16447 16450 +3 ; ============================================; Files 1047 1047 ; Lines 59189 59188 -1 ; Branches 9672 9672 ; ============================================; + Hits 46783 46788 +5 ; + Misses 8644 8638 -6 ; Partials 3762 3762; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4401?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...nder/tools/examples/ExampleVariantWalkerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4401/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leGFtcGxlcy9FeGFtcGxlVmFyaWFudFdhbGtlclNwYXJrLmphdmE=) | `73.077% <100%> (-0.997%)` | `5 <0> (ø)` | |; | [...park/sv/discovery/alignment/AlignmentInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/4401/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvYWxpZ25tZW50L0FsaWdubWVudEludGVydmFsLmphdmE=) | `89.272% <0%> (ø)` | `73% <0%> (ø)` | :arrow_down: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4401/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `80% <0%> (+1.29%)` | `39% <0%> (ø)` | :arrow_down: |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/4401/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `78.261% <0%> (+4.348%)` | `9% <0%> (+1%)` | :arrow_up: |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/4401/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `80% <0%> (+30%)` | `3% <0%> (+2%)` | :arrow_up: |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4401#issuecomment-367136245
https://github.com/broadinstitute/gatk/issues/4405#issuecomment-389283259:9,Usability,clear,clear,9,"It's not clear what to do in this case - the MAF format spec has limited values in the `VariantClassification` field, so `GencodeGtfFeature.GeneTranscriptType` doesn't map 1:1 to `VariantClassification`. Will need to put off until later.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4405#issuecomment-389283259
https://github.com/broadinstitute/gatk/pull/4406#issuecomment-365397370:2492,Deployability,pipeline,pipelines,2492,%> (-100%)` | `0% <0%> (-13%)` | |; | [...ols/examples/ExampleAssemblyRegionWalkerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4406/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leGFtcGxlcy9FeGFtcGxlQXNzZW1ibHlSZWdpb25XYWxrZXJTcGFyay5qYXZh) | `0% <0%> (-93.103%)` | `0% <0%> (-8%)` | |; | [.../tools/spark/sv/discovery/BreakEndVariantType.java](https://codecov.io/gh/broadinstitute/gatk/pull/4406/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvQnJlYWtFbmRWYXJpYW50VHlwZS5qYXZh) | `0% <0%> (-92.381%)` | `0% <0%> (-14%)` | |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4406/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-74.257%)` | `0% <0%> (-17%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4406/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...pleNovelAdjacencyAndChimericAlignmentEvidence.java](https://codecov.io/gh/broadinstitute/gatk/pull/4406/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvaW5mZXJlbmNlL1NpbXBsZU5vdmVsQWRqYWNlbmN5QW5kQ2hpbWVyaWNBbGlnbm1lbnRFdmlkZW5jZS5qYXZh) | `24.324% <0%> (-63.176%)` | `5% <0%> (-5%)` | |; | [...ellbender/engine/filters/VariantFilterLibrary.java](https://codecov.io/gh/broadinstitute/gatk/pull/4406/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZmlsdGVycy9WYXJpYW50RmlsdGVyTGlicmFyeS5qYXZh) | `33.333% <0%> (-56.667%)` | `1% <0%> (ø)` | |; | [...walkers/genotyper/GenotypingGivenAllelesUtils.java](https:,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4406#issuecomment-365397370
https://github.com/broadinstitute/gatk/pull/4406#issuecomment-365397370:3787,Deployability,pipeline,pipelines,3787,spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4406/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-74.257%)` | `0% <0%> (-17%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4406/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...pleNovelAdjacencyAndChimericAlignmentEvidence.java](https://codecov.io/gh/broadinstitute/gatk/pull/4406/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvaW5mZXJlbmNlL1NpbXBsZU5vdmVsQWRqYWNlbmN5QW5kQ2hpbWVyaWNBbGlnbm1lbnRFdmlkZW5jZS5qYXZh) | `24.324% <0%> (-63.176%)` | `5% <0%> (-5%)` | |; | [...ellbender/engine/filters/VariantFilterLibrary.java](https://codecov.io/gh/broadinstitute/gatk/pull/4406/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZmlsdGVycy9WYXJpYW50RmlsdGVyTGlicmFyeS5qYXZh) | `33.333% <0%> (-56.667%)` | `1% <0%> (ø)` | |; | [...walkers/genotyper/GenotypingGivenAllelesUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4406/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9HZW5vdHlwaW5nR2l2ZW5BbGxlbGVzVXRpbHMuamF2YQ==) | `28.571% <0%> (-46.429%)` | `2% <0%> (-3%)` | |; | [...hellbender/tools/spark/pipelines/SortSamSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4406/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvU29ydFNhbVNwYXJrLmphdmE=) | `70.588% <0%> (-29.412%)` | `4% <0%> (-2%)` | |; | ... and [1259 more](https://codecov.io/gh/broadinstitute/gatk/pull/4406/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4406#issuecomment-365397370
https://github.com/broadinstitute/gatk/pull/4406#issuecomment-365730030:1764,Availability,avail,available,1764,"Here's how these scripts are organized and why they take the form it is now:. How to run; * `manage/project.sh` is the ""executable""; * paths for VCF files (zipped or not) from PacBio callsets on CHM haploids, and Manta's VCF on the mixture should be provided to `manage/project.sh`, and; * paths for two versions of GATK-SV callsets; one is fine, but scripts in the sub-directory `manage` must be modified. Two GATK-SV vcf files are requested because this would allow one to compare if a supposedly improvement would make our raw sensitivity/specificity better or worse, that was the use case [here](https://github.com/SHuang-Broad/GATK-SV-callset-regressionTest), and; * paths to where results are to be stored, one for each GATK-SV callset must be given and ; * path to where to store the results of comparing the two callsets; * several GNU bash utilities are expected, `guniq` and `gsort`, when run on a Mac, as well as `bedtools`. and what to expect; * the scripts checks the VCF files, prints to screen a slew of information that one can pipe, or simplely browse through.; * the scripts also outputs the ID's of variants from each of the two GATK callsets that are ""validated"" by PacBio haploid calls. Misc points:; * watch out for ""duplicated"" records, as sometimes different assembly contigs mapped to the same locations have slightly different alleles (SNP, for example) hence both would be output, but there aren't many such records based on experience; * there are also some variants that we output to the VCFs having size <50 or >50K, both of which are filtered upfront and saved separately.; * The scripts started when we first call insertions, deletions, inversions and small duplications, and back then PacBio call sets on the CHM haploids were not available, so Manta's calls were used as ""reference"", that explains why they are referred to throughout the project",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4406#issuecomment-365730030
https://github.com/broadinstitute/gatk/pull/4406#issuecomment-365730030:1172,Security,validat,validated,1172,"Here's how these scripts are organized and why they take the form it is now:. How to run; * `manage/project.sh` is the ""executable""; * paths for VCF files (zipped or not) from PacBio callsets on CHM haploids, and Manta's VCF on the mixture should be provided to `manage/project.sh`, and; * paths for two versions of GATK-SV callsets; one is fine, but scripts in the sub-directory `manage` must be modified. Two GATK-SV vcf files are requested because this would allow one to compare if a supposedly improvement would make our raw sensitivity/specificity better or worse, that was the use case [here](https://github.com/SHuang-Broad/GATK-SV-callset-regressionTest), and; * paths to where results are to be stored, one for each GATK-SV callset must be given and ; * path to where to store the results of comparing the two callsets; * several GNU bash utilities are expected, `guniq` and `gsort`, when run on a Mac, as well as `bedtools`. and what to expect; * the scripts checks the VCF files, prints to screen a slew of information that one can pipe, or simplely browse through.; * the scripts also outputs the ID's of variants from each of the two GATK callsets that are ""validated"" by PacBio haploid calls. Misc points:; * watch out for ""duplicated"" records, as sometimes different assembly contigs mapped to the same locations have slightly different alleles (SNP, for example) hence both would be output, but there aren't many such records based on experience; * there are also some variants that we output to the VCFs having size <50 or >50K, both of which are filtered upfront and saved separately.; * The scripts started when we first call insertions, deletions, inversions and small duplications, and back then PacBio call sets on the CHM haploids were not available, so Manta's calls were used as ""reference"", that explains why they are referred to throughout the project",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4406#issuecomment-365730030
https://github.com/broadinstitute/gatk/pull/4406#issuecomment-365730030:1053,Usability,simpl,simplely,1053,"Here's how these scripts are organized and why they take the form it is now:. How to run; * `manage/project.sh` is the ""executable""; * paths for VCF files (zipped or not) from PacBio callsets on CHM haploids, and Manta's VCF on the mixture should be provided to `manage/project.sh`, and; * paths for two versions of GATK-SV callsets; one is fine, but scripts in the sub-directory `manage` must be modified. Two GATK-SV vcf files are requested because this would allow one to compare if a supposedly improvement would make our raw sensitivity/specificity better or worse, that was the use case [here](https://github.com/SHuang-Broad/GATK-SV-callset-regressionTest), and; * paths to where results are to be stored, one for each GATK-SV callset must be given and ; * path to where to store the results of comparing the two callsets; * several GNU bash utilities are expected, `guniq` and `gsort`, when run on a Mac, as well as `bedtools`. and what to expect; * the scripts checks the VCF files, prints to screen a slew of information that one can pipe, or simplely browse through.; * the scripts also outputs the ID's of variants from each of the two GATK callsets that are ""validated"" by PacBio haploid calls. Misc points:; * watch out for ""duplicated"" records, as sometimes different assembly contigs mapped to the same locations have slightly different alleles (SNP, for example) hence both would be output, but there aren't many such records based on experience; * there are also some variants that we output to the VCFs having size <50 or >50K, both of which are filtered upfront and saved separately.; * The scripts started when we first call insertions, deletions, inversions and small duplications, and back then PacBio call sets on the CHM haploids were not available, so Manta's calls were used as ""reference"", that explains why they are referred to throughout the project",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4406#issuecomment-365730030
https://github.com/broadinstitute/gatk/pull/4406#issuecomment-368655983:3037,Availability,avail,available,3037,"ctually because IMO we are overly confident in the `<INV>` variants, and the new variant interpretation methods will not emit <INV> records at all&mdash;they become BND's with appripriate annotations and are submitted to a yet-to-be-implemented unit for further interpretation if it is a dispersed duplication or inversion. > What's the reason for storing compiled Rdata objects in with the scripts? I don't necessarily see anything that needs that, and it will make things very hard to maintain. Historical reason. They were used for storing R functions. Will remove them. **EDIT**: done in 546a36465f7860f8c85e28cf40ca8f3851ba9d4c. > `masterVsFeature.sh` appears to set its working directory in the parent directory of where it is run from. If these scripts are in the gatk repo that will end up being in the scripts/sv/evaluation dir and will look like an untracked directory by git there. Its location should be a parameter just like the other working directories. Will do as suggested. **EDIT**: done in 23da9d41667bc21a978134d92f49b65d9af55b35. > Running masterVsFeature should be optional; sometimes we'll just want to run master vs pacbio (ie in a Jenkins automated test). Will do as suggested. **EDIT**: done in 23da9d41667bc21a978134d92f49b65d9af55b35. > It might be helpful if the masterVsFeature logic also produced these lists of variants: TP (vs PacBio) gained in feature, TP lost in feature, FP gained in feature, FP lost in feature. . That's actually available. They are stored as: ; TP gained in feature&mdash;""featureOnly.gatkIDsWithMatchingPacBio.txt"", ; TP lost in feature&mdash;""masterOnly.gatkIDsWithMatchingPacBio.txt""; FP gained in feature&mdash;""featureOnly.gatkIDsNoMatchingPacBio.txt""; FP lost in feature&mdash;""masterOnly.gatkIDsNoMatchingPacBio.txt"". In addition, two files; ""shared.gatkIDsNOMatchingPacBio.txt""; ""shared.gatkIDsWithMatchingPacBio.txt""; shows the common TP's and FP's shared by GATK master and feature call sets. I think I just need to rename the outputs.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4406#issuecomment-368655983
https://github.com/broadinstitute/gatk/pull/4406#issuecomment-368655983:1528,Safety,avoid,avoid,1528,"ion methods. Agree. **EDIT**: done in d4d42444986aae848e98d19dfb8a4d3fd8031775. > I'm not sure we should filter out very small and very large variants, especially very large ones. We should get graded on making those calls. Very small ones I can see excluding because by definition they might not be in the truth set, but I don't think that applies to large ones. I agree it is not optimal, particularly for filtering out the huge variants. ; The huge variants come from 2 sources: `<DEL>`, `<INV>`.; For huge deletions, the 50% (or a custom value) reciprocal overlap should classify almost all of them as FP; actually the PacBio call sets (CHM1, CHM13, and the mixture) do not contain any deletion records that are over 30K in size.; For huge inversions though, I am not sure exactly what to do with them. The scripts currently avoid overlap analysis on the inversions actually because IMO we are overly confident in the `<INV>` variants, and the new variant interpretation methods will not emit <INV> records at all&mdash;they become BND's with appripriate annotations and are submitted to a yet-to-be-implemented unit for further interpretation if it is a dispersed duplication or inversion. > What's the reason for storing compiled Rdata objects in with the scripts? I don't necessarily see anything that needs that, and it will make things very hard to maintain. Historical reason. They were used for storing R functions. Will remove them. **EDIT**: done in 546a36465f7860f8c85e28cf40ca8f3851ba9d4c. > `masterVsFeature.sh` appears to set its working directory in the parent directory of where it is run from. If these scripts are in the gatk repo that will end up being in the scripts/sv/evaluation dir and will look like an untracked directory by git there. Its location should be a parameter just like the other working directories. Will do as suggested. **EDIT**: done in 23da9d41667bc21a978134d92f49b65d9af55b35. > Running masterVsFeature should be optional; sometimes we'll just want to run",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4406#issuecomment-368655983
https://github.com/broadinstitute/gatk/pull/4406#issuecomment-368655983:2744,Testability,test,test,2744,"ctually because IMO we are overly confident in the `<INV>` variants, and the new variant interpretation methods will not emit <INV> records at all&mdash;they become BND's with appripriate annotations and are submitted to a yet-to-be-implemented unit for further interpretation if it is a dispersed duplication or inversion. > What's the reason for storing compiled Rdata objects in with the scripts? I don't necessarily see anything that needs that, and it will make things very hard to maintain. Historical reason. They were used for storing R functions. Will remove them. **EDIT**: done in 546a36465f7860f8c85e28cf40ca8f3851ba9d4c. > `masterVsFeature.sh` appears to set its working directory in the parent directory of where it is run from. If these scripts are in the gatk repo that will end up being in the scripts/sv/evaluation dir and will look like an untracked directory by git there. Its location should be a parameter just like the other working directories. Will do as suggested. **EDIT**: done in 23da9d41667bc21a978134d92f49b65d9af55b35. > Running masterVsFeature should be optional; sometimes we'll just want to run master vs pacbio (ie in a Jenkins automated test). Will do as suggested. **EDIT**: done in 23da9d41667bc21a978134d92f49b65d9af55b35. > It might be helpful if the masterVsFeature logic also produced these lists of variants: TP (vs PacBio) gained in feature, TP lost in feature, FP gained in feature, FP lost in feature. . That's actually available. They are stored as: ; TP gained in feature&mdash;""featureOnly.gatkIDsWithMatchingPacBio.txt"", ; TP lost in feature&mdash;""masterOnly.gatkIDsWithMatchingPacBio.txt""; FP gained in feature&mdash;""featureOnly.gatkIDsNoMatchingPacBio.txt""; FP lost in feature&mdash;""masterOnly.gatkIDsNoMatchingPacBio.txt"". In addition, two files; ""shared.gatkIDsNOMatchingPacBio.txt""; ""shared.gatkIDsWithMatchingPacBio.txt""; shows the common TP's and FP's shared by GATK master and feature call sets. I think I just need to rename the outputs.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4406#issuecomment-368655983
https://github.com/broadinstitute/gatk/pull/4406#issuecomment-368655983:2878,Testability,log,logic,2878,"ctually because IMO we are overly confident in the `<INV>` variants, and the new variant interpretation methods will not emit <INV> records at all&mdash;they become BND's with appripriate annotations and are submitted to a yet-to-be-implemented unit for further interpretation if it is a dispersed duplication or inversion. > What's the reason for storing compiled Rdata objects in with the scripts? I don't necessarily see anything that needs that, and it will make things very hard to maintain. Historical reason. They were used for storing R functions. Will remove them. **EDIT**: done in 546a36465f7860f8c85e28cf40ca8f3851ba9d4c. > `masterVsFeature.sh` appears to set its working directory in the parent directory of where it is run from. If these scripts are in the gatk repo that will end up being in the scripts/sv/evaluation dir and will look like an untracked directory by git there. Its location should be a parameter just like the other working directories. Will do as suggested. **EDIT**: done in 23da9d41667bc21a978134d92f49b65d9af55b35. > Running masterVsFeature should be optional; sometimes we'll just want to run master vs pacbio (ie in a Jenkins automated test). Will do as suggested. **EDIT**: done in 23da9d41667bc21a978134d92f49b65d9af55b35. > It might be helpful if the masterVsFeature logic also produced these lists of variants: TP (vs PacBio) gained in feature, TP lost in feature, FP gained in feature, FP lost in feature. . That's actually available. They are stored as: ; TP gained in feature&mdash;""featureOnly.gatkIDsWithMatchingPacBio.txt"", ; TP lost in feature&mdash;""masterOnly.gatkIDsWithMatchingPacBio.txt""; FP gained in feature&mdash;""featureOnly.gatkIDsNoMatchingPacBio.txt""; FP lost in feature&mdash;""masterOnly.gatkIDsNoMatchingPacBio.txt"". In addition, two files; ""shared.gatkIDsNOMatchingPacBio.txt""; ""shared.gatkIDsWithMatchingPacBio.txt""; shows the common TP's and FP's shared by GATK master and feature call sets. I think I just need to rename the outputs.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4406#issuecomment-368655983
https://github.com/broadinstitute/gatk/pull/4406#issuecomment-454980969:44,Deployability,pipeline,pipeline,44,"closing at request, and we have an improved pipeline now somewhere else, and a plan for big improvements there.; Thanks for keeping an eye on this, @droazen!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4406#issuecomment-454980969
https://github.com/broadinstitute/gatk/issues/4409#issuecomment-365705851:91,Availability,avail,available,91,Is this a problem in docker? We control the image so it should have plenty of file handles available.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4409#issuecomment-365705851
https://github.com/broadinstitute/gatk/issues/4409#issuecomment-365993526:26,Safety,risk,risk,26,There's no reason to even risk it becoming a problem in the future -- let's just include the fully-packaged jars in the docker image (since that is our standard binary distribution format anyway).,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4409#issuecomment-365993526
https://github.com/broadinstitute/gatk/issues/4413#issuecomment-366009015:149,Deployability,update,update,149,"@jhl667 I'm looking into this. It looks like I neglected to set the sqlite connection to read only mode when connecting to the db file. I'm going to update it to do so. I'm not sure this applies when a read-only connection is created, but it looks like sqlite has some issues with NFS / distributed file systems:; - https://stackoverflow.com/questions/9907429/locking-sqlite-file-on-nfs-filesystem-possible ; - https://github.com/CGATOxford/CGATPipelines/issues/. One post in the github thread above mentions using `-o flock` when mounting Lustre partitions so that they all have concurrent locks. This _may_ be a workaround in the meantime. . I'll try to look at it on our NFS mounts - I don't have access to a Lustre fs.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4413#issuecomment-366009015
https://github.com/broadinstitute/gatk/issues/4413#issuecomment-366009015:580,Performance,concurren,concurrent,580,"@jhl667 I'm looking into this. It looks like I neglected to set the sqlite connection to read only mode when connecting to the db file. I'm going to update it to do so. I'm not sure this applies when a read-only connection is created, but it looks like sqlite has some issues with NFS / distributed file systems:; - https://stackoverflow.com/questions/9907429/locking-sqlite-file-on-nfs-filesystem-possible ; - https://github.com/CGATOxford/CGATPipelines/issues/. One post in the github thread above mentions using `-o flock` when mounting Lustre partitions so that they all have concurrent locks. This _may_ be a workaround in the meantime. . I'll try to look at it on our NFS mounts - I don't have access to a Lustre fs.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4413#issuecomment-366009015
https://github.com/broadinstitute/gatk/issues/4413#issuecomment-366009015:700,Security,access,access,700,"@jhl667 I'm looking into this. It looks like I neglected to set the sqlite connection to read only mode when connecting to the db file. I'm going to update it to do so. I'm not sure this applies when a read-only connection is created, but it looks like sqlite has some issues with NFS / distributed file systems:; - https://stackoverflow.com/questions/9907429/locking-sqlite-file-on-nfs-filesystem-possible ; - https://github.com/CGATOxford/CGATPipelines/issues/. One post in the github thread above mentions using `-o flock` when mounting Lustre partitions so that they all have concurrent locks. This _may_ be a workaround in the meantime. . I'll try to look at it on our NFS mounts - I don't have access to a Lustre fs.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4413#issuecomment-366009015
https://github.com/broadinstitute/gatk/issues/4413#issuecomment-376259220:8,Testability,test,test,8,Need to test the fix for this on a distributed file system.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4413#issuecomment-376259220
https://github.com/broadinstitute/gatk/issues/4413#issuecomment-413247125:62,Security,access,access,62,@droazen No objection here. It may be that my changing the db access to read only fixed the issue.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4413#issuecomment-413247125
https://github.com/broadinstitute/gatk/pull/4415#issuecomment-365746795:17,Testability,test,test,17,added round-trip test that fails without the fix.; responded to rename request with explicit documentation instead.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4415#issuecomment-365746795
https://github.com/broadinstitute/gatk/pull/4423#issuecomment-366379307:959,Testability,log,logging,959,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4423?src=pr&el=h1) Report; > Merging [#4423](https://codecov.io/gh/broadinstitute/gatk/pull/4423?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/6e7a9bec69184aca7a8884896e86af0ad21ed9fd?src=pr&el=desc) will **increase** coverage by `0.362%`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #4423 +/- ##; ==============================================; + Coverage 79.04% 79.402% +0.362% ; - Complexity 16447 17620 +1173 ; ==============================================; Files 1047 1055 +8 ; Lines 59189 63340 +4151 ; Branches 9672 10754 +1082 ; ==============================================; + Hits 46783 50293 +3510 ; - Misses 8645 9125 +480 ; - Partials 3761 3922 +161; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4423?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...titute/hellbender/utils/logging/OneShotLogger.java](https://codecov.io/gh/broadinstitute/gatk/pull/4423/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9sb2dnaW5nL09uZVNob3RMb2dnZXIuamF2YQ==) | `78.571% <0%> (-21.429%)` | `3% <0%> (ø)` | |; | [...ools/spark/sv/evidence/IntervalCoverageFinder.java](https://codecov.io/gh/broadinstitute/gatk/pull/4423/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9ldmlkZW5jZS9JbnRlcnZhbENvdmVyYWdlRmluZGVyLmphdmE=) | `82.222% <0%> (-6.239%)` | `19% <0%> (+11%)` | |; | [...er/tools/walkers/annotator/ReadPosRankSumTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/4423/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9SZWFkUG9zUmFua1N1bVRlc3QuamF2YQ==) | `94.231% <0%> (-5.769%)` | `25% <0%> (+15%)` | |; | [.../DiscoverVariantsFromContigAlignmentsSAMSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4423/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2Y,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4423#issuecomment-366379307
https://github.com/broadinstitute/gatk/pull/4423#issuecomment-366379307:3450,Usability,Simpl,SimpleSVType,3450,0%> (-5.128%)` | `28% <0%> (+15%)` | |; | [...ools/walkers/annotator/VariantAnnotatorEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/4423/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9WYXJpYW50QW5ub3RhdG9yRW5naW5lLmphdmE=) | `95.161% <0%> (-2.307%)` | `111% <0%> (+71%)` | |; | [...stitute/hellbender/utils/pileup/PileupElement.java](https://codecov.io/gh/broadinstitute/gatk/pull/4423/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9waWxldXAvUGlsZXVwRWxlbWVudC5qYXZh) | `93.939% <0%> (-1.713%)` | `146% <0%> (+70%)` | |; | [...dinstitute/hellbender/utils/pileup/ReadPileup.java](https://codecov.io/gh/broadinstitute/gatk/pull/4423/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9waWxldXAvUmVhZFBpbGV1cC5qYXZh) | `90.496% <0%> (-1.45%)` | `104% <0%> (+40%)` | |; | [...s/spark/sv/discovery/AnnotatedVariantProducer.java](https://codecov.io/gh/broadinstitute/gatk/pull/4423/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvQW5ub3RhdGVkVmFyaWFudFByb2R1Y2VyLmphdmE=) | `76.471% <0%> (-1.307%)` | `23% <0%> (+1%)` | |; | [...lbender/tools/spark/sv/discovery/SimpleSVType.java](https://codecov.io/gh/broadinstitute/gatk/pull/4423/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvU2ltcGxlU1ZUeXBlLmphdmE=) | `85.393% <0%> (-1.174%)` | `2% <0%> (ø)` | |; | [...ecaller/AssemblyBasedCallerArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/4423/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9Bc3NlbWJseUJhc2VkQ2FsbGVyQXJndW1lbnRDb2xsZWN0aW9uLmphdmE=) | `100% <0%> (ø)` | `1% <0%> (ø)` | :arrow_down: |; | ... and [80 more](https://codecov.io/gh/broadinstitute/gatk/pull/4423/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4423#issuecomment-366379307
https://github.com/broadinstitute/gatk/pull/4423#issuecomment-374646199:40,Testability,test,test,40,@davidbenjamin I also ran an additional test outside of our repo to make sure that this was working properly.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4423#issuecomment-374646199
https://github.com/broadinstitute/gatk/pull/4423#issuecomment-374648261:61,Deployability,release,released,61,"@brigranger @jnktsj Note when this gets into master and gets released. To keep the previous behavior, you will want to set `filter_oncotator_maf` to false. (The default is going to become `true`, since most cancer analysts will want it this way)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4423#issuecomment-374648261
https://github.com/broadinstitute/gatk/pull/4424#issuecomment-366381735:79,Testability,test,test,79,I confirmed this can output to GCS like so:. ```; $ ./gatk ApplyBQSR \; -I src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate.bam \; --bqsr-recal-file src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.20mb.1RG.table.gz \; -O gs://$BUCKET/test-output/applybqsr.bam ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4424#issuecomment-366381735
https://github.com/broadinstitute/gatk/pull/4424#issuecomment-366381735:197,Testability,test,test,197,I confirmed this can output to GCS like so:. ```; $ ./gatk ApplyBQSR \; -I src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate.bam \; --bqsr-recal-file src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.20mb.1RG.table.gz \; -O gs://$BUCKET/test-output/applybqsr.bam ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4424#issuecomment-366381735
https://github.com/broadinstitute/gatk/pull/4424#issuecomment-366381735:296,Testability,test,test-output,296,I confirmed this can output to GCS like so:. ```; $ ./gatk ApplyBQSR \; -I src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.1mb.1RG.2k_lines.alternate.bam \; --bqsr-recal-file src/test/resources/org/broadinstitute/hellbender/tools/BQSR/HiSeq.20mb.1RG.table.gz \; -O gs://$BUCKET/test-output/applybqsr.bam ; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4424#issuecomment-366381735
https://github.com/broadinstitute/gatk/pull/4424#issuecomment-366389594:1825,Testability,test,test,1825,codecov.io/gh/broadinstitute/gatk/pull/4424?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...roadinstitute/hellbender/utils/read/ReadUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4424/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWFkL1JlYWRVdGlscy5qYXZh) | `85.039% <100%> (+5.089%)` | `214 <3> (+30)` | :arrow_up: |; | [...itute/hellbender/tools/walkers/bqsr/ApplyBQSR.java](https://codecov.io/gh/broadinstitute/gatk/pull/4424/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Jxc3IvQXBwbHlCUVNSLmphdmE=) | `91.667% <100%> (ø)` | `6 <1> (ø)` | :arrow_down: |; | [...ava/org/broadinstitute/hellbender/utils/Utils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4424/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9VdGlscy5qYXZh) | `80.435% <33.333%> (-1.092%)` | `140 <2> (+1)` | |; | [...itute/hellbender/utils/test/SamAssertionUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4424/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1NhbUFzc2VydGlvblV0aWxzLmphdmE=) | `72.821% <77.273%> (-2.46%)` | `46 <11> (+6)` | |; | [...titute/hellbender/utils/logging/OneShotLogger.java](https://codecov.io/gh/broadinstitute/gatk/pull/4424/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9sb2dnaW5nL09uZVNob3RMb2dnZXIuamF2YQ==) | `78.571% <0%> (-21.429%)` | `3% <0%> (ø)` | |; | [...ellbender/engine/filters/VariantFilterLibrary.java](https://codecov.io/gh/broadinstitute/gatk/pull/4424/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZmlsdGVycy9WYXJpYW50RmlsdGVyTGlicmFyeS5qYXZh) | `33.333% <0%> (-16.667%)` | `1% <0%> (ø)` | |; | [...stitute/hellbender/engine/ReferenceDataSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4424/diff?src=pr&el=tree#diff-c3JjL21haW4v,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4424#issuecomment-366389594
https://github.com/broadinstitute/gatk/pull/4424#issuecomment-366389594:2120,Testability,log,logging,2120,sbGJlbmRlci91dGlscy9yZWFkL1JlYWRVdGlscy5qYXZh) | `85.039% <100%> (+5.089%)` | `214 <3> (+30)` | :arrow_up: |; | [...itute/hellbender/tools/walkers/bqsr/ApplyBQSR.java](https://codecov.io/gh/broadinstitute/gatk/pull/4424/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Jxc3IvQXBwbHlCUVNSLmphdmE=) | `91.667% <100%> (ø)` | `6 <1> (ø)` | :arrow_down: |; | [...ava/org/broadinstitute/hellbender/utils/Utils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4424/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9VdGlscy5qYXZh) | `80.435% <33.333%> (-1.092%)` | `140 <2> (+1)` | |; | [...itute/hellbender/utils/test/SamAssertionUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4424/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1NhbUFzc2VydGlvblV0aWxzLmphdmE=) | `72.821% <77.273%> (-2.46%)` | `46 <11> (+6)` | |; | [...titute/hellbender/utils/logging/OneShotLogger.java](https://codecov.io/gh/broadinstitute/gatk/pull/4424/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9sb2dnaW5nL09uZVNob3RMb2dnZXIuamF2YQ==) | `78.571% <0%> (-21.429%)` | `3% <0%> (ø)` | |; | [...ellbender/engine/filters/VariantFilterLibrary.java](https://codecov.io/gh/broadinstitute/gatk/pull/4424/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZmlsdGVycy9WYXJpYW50RmlsdGVyTGlicmFyeS5qYXZh) | `33.333% <0%> (-16.667%)` | `1% <0%> (ø)` | |; | [...stitute/hellbender/engine/ReferenceDataSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4424/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUmVmZXJlbmNlRGF0YVNvdXJjZS5qYXZh) | `70% <0%> (-10%)` | `7% <0%> (+3%)` | |; | [...stitute/hellbender/engine/ReferenceFileSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4424/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYn,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4424#issuecomment-366389594
https://github.com/broadinstitute/gatk/pull/4424#issuecomment-366389594:3274,Testability,test,test,3274,nJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1NhbUFzc2VydGlvblV0aWxzLmphdmE=) | `72.821% <77.273%> (-2.46%)` | `46 <11> (+6)` | |; | [...titute/hellbender/utils/logging/OneShotLogger.java](https://codecov.io/gh/broadinstitute/gatk/pull/4424/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9sb2dnaW5nL09uZVNob3RMb2dnZXIuamF2YQ==) | `78.571% <0%> (-21.429%)` | `3% <0%> (ø)` | |; | [...ellbender/engine/filters/VariantFilterLibrary.java](https://codecov.io/gh/broadinstitute/gatk/pull/4424/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZmlsdGVycy9WYXJpYW50RmlsdGVyTGlicmFyeS5qYXZh) | `33.333% <0%> (-16.667%)` | `1% <0%> (ø)` | |; | [...stitute/hellbender/engine/ReferenceDataSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4424/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUmVmZXJlbmNlRGF0YVNvdXJjZS5qYXZh) | `70% <0%> (-10%)` | `7% <0%> (+3%)` | |; | [...stitute/hellbender/engine/ReferenceFileSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4424/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUmVmZXJlbmNlRmlsZVNvdXJjZS5qYXZh) | `65.217% <0%> (-7.51%)` | `8% <0%> (+4%)` | |; | [...titute/hellbender/utils/test/ArgumentsBuilder.java](https://codecov.io/gh/broadinstitute/gatk/pull/4424/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0FyZ3VtZW50c0J1aWxkZXIuamF2YQ==) | `93.151% <0%> (-6.849%)` | `31% <0%> (+12%)` | |; | [...ools/spark/sv/evidence/IntervalCoverageFinder.java](https://codecov.io/gh/broadinstitute/gatk/pull/4424/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9ldmlkZW5jZS9JbnRlcnZhbENvdmVyYWdlRmluZGVyLmphdmE=) | `82.222% <0%> (-6.239%)` | `19% <0%> (+11%)` | |; | ... and [205 more](https://codecov.io/gh/broadinstitute/gatk/pull/4424/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4424#issuecomment-366389594
https://github.com/broadinstitute/gatk/pull/4424#issuecomment-381676296:171,Deployability,update,update,171,"Thank you very much @droazen! This should take care of all the comments, so once the checks are green I'll press ""squash and merge."" Then I'll move on to the next tool to update!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4424#issuecomment-381676296
https://github.com/broadinstitute/gatk/pull/4424#issuecomment-381676296:96,Energy Efficiency,green,green,96,"Thank you very much @droazen! This should take care of all the comments, so once the checks are green I'll press ""squash and merge."" Then I'll move on to the next tool to update!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4424#issuecomment-381676296
https://github.com/broadinstitute/gatk/issues/4425#issuecomment-367086178:61,Deployability,release,release,61,"By ""automate"" here we mean: make this a standard step in the release process",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4425#issuecomment-367086178
https://github.com/broadinstitute/gatk/issues/4425#issuecomment-370039562:123,Deployability,release,release,123,@vdauwera We'll need the command to actually upload the docs to the website before we can make this a standard step in our release process (as well as ensuring that we have the proper permissions).,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4425#issuecomment-370039562
https://github.com/broadinstitute/gatk/issues/4426#issuecomment-367486387:231,Usability,simpl,simply,231,"I can see why you'd change this; however, it breaks this particular legacy tool. VariantEval uses those labels to populate columns in the reports is creates. In GATK3, if there is no user-supplied label on in the argument, it will simply use the argument name, which ends up being either eval, comp or dbsnp. Those strings end up in most reports that are created. Switching these to the filepath doesnt strictly break function, but it's a lot less friendly to look at and doesnt add much value in most cases. Generally speaking, I agree there isnt much of a reason for a tool to reply on those user-supplied names as much of anything beyond a label. However, if this is essentially just a label, is there a situation where non-unique names is actually a problem? A tool probably shouldnt rely on this user-supplied value as a way to uniquely find an input. If this value if generally being used for things like populating user-facing values in a reports, having this extremely long filepath as the name isnt exactly user friendly. If a given tool accepts a list of FeatureInputs, it would seem like it's the responsibility of that developer to make sure that tools deals with the potential of overlapping labels appropriately. Perhaps a solution is to delegate some of this behavior back to the argument definition? A few thoughts/comments:. 1) Is there any reason name can't just be NULL (instead of file URI) if nothing was supplied, instead of filepath? . 2) Similar to 1, if FeatureInputs somehow tracked whether there was actually a user-supplied name or if name was NULL (defaulting to filename), then upstream code could potentially use this information to change behavior. 3) While this if more involved, perhaps ParsedArgument.of() could take another nullable ""defaultName"" argument, and if there is no user-supplied name in the argument value and if defaultName is non-null then it is used as the FeatureInput name instead of filepath? Then perhaps through either a flag in the tool, or bett",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4426#issuecomment-367486387
https://github.com/broadinstitute/gatk/issues/4426#issuecomment-367498695:635,Deployability,patch,patch,635,"Also - you asked about workarounds. The attached is not pretty, but it is a minimal way to let tools like VariantEval provide their old behavior. It essentially adds a method in FeatureInput to check whether the name matches the default value it would use. Upstream code can call FeautreInput.isUserSuppliedName() and act accordingly. Rather than use the scheme I do here with string matching, we could make it more explicit in ParsedArgument and actually pass a boolean it we detected one in the parsed argument value. Not necessarily advocating this as a production solution, just as one way to make it work; [FeatureInputWorkaround.patch.txt](https://github.com/broadinstitute/gatk/files/1745946/FeatureInputWorkaround.patch.txt); .",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4426#issuecomment-367498695
https://github.com/broadinstitute/gatk/issues/4426#issuecomment-367498695:722,Deployability,patch,patch,722,"Also - you asked about workarounds. The attached is not pretty, but it is a minimal way to let tools like VariantEval provide their old behavior. It essentially adds a method in FeatureInput to check whether the name matches the default value it would use. Upstream code can call FeautreInput.isUserSuppliedName() and act accordingly. Rather than use the scheme I do here with string matching, we could make it more explicit in ParsedArgument and actually pass a boolean it we detected one in the parsed argument value. Not necessarily advocating this as a production solution, just as one way to make it work; [FeatureInputWorkaround.patch.txt](https://github.com/broadinstitute/gatk/files/1745946/FeatureInputWorkaround.patch.txt); .",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4426#issuecomment-367498695
https://github.com/broadinstitute/gatk/issues/4426#issuecomment-367498695:477,Safety,detect,detected,477,"Also - you asked about workarounds. The attached is not pretty, but it is a minimal way to let tools like VariantEval provide their old behavior. It essentially adds a method in FeatureInput to check whether the name matches the default value it would use. Upstream code can call FeautreInput.isUserSuppliedName() and act accordingly. Rather than use the scheme I do here with string matching, we could make it more explicit in ParsedArgument and actually pass a boolean it we detected one in the parsed argument value. Not necessarily advocating this as a production solution, just as one way to make it work; [FeatureInputWorkaround.patch.txt](https://github.com/broadinstitute/gatk/files/1745946/FeatureInputWorkaround.patch.txt); .",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4426#issuecomment-367498695
https://github.com/broadinstitute/gatk/issues/4427#issuecomment-592757802:170,Deployability,release,release,170,"Closing this while I'm at it, since Michael fixed the underlying issue in Picard, and that Picard version has now been pulled into GATK and will surface in the next GATK release.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4427#issuecomment-592757802
https://github.com/broadinstitute/gatk/pull/4428#issuecomment-367067878:60,Performance,perform,performance,60,"@tomwhite Please review, and confirm that this resolves the performance issues you encountered.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4428#issuecomment-367067878
https://github.com/broadinstitute/gatk/pull/4429#issuecomment-367127035:81,Testability,log,logs,81,The one problem with using color in the output is that it makes it gross to read logs that aren't on an interactive terminal that supports color. We might want to make an attempt to tell if we're connected to a terminal or an output file and remove the colors if so.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4429#issuecomment-367127035
https://github.com/broadinstitute/gatk/pull/4429#issuecomment-367141169:395,Energy Efficiency,GREEN,GREEN,395,"I have this class from an ancient branch that makes dealing with colors nicer in some ways. It tries to avoid printing colors to non-interactive things and it makes it harder to forget a reset:. ```; /**; * Provides ANSI colors for the terminal output *; */; public final class TerminalColors {. private TerminalColors(){};. private enum TerminalColor{; CYAN(""\u001B[36m""),; RED(""\u001B[31m""),; GREEN(""\u001B[32m""),; WHITE(""\u001B[37m""),; BOLD(""\u001B[1m""),; RESET(""\u001B[0m""); // reset the colors. private final String color;. TerminalColor(String color){; this.color = color;; }. public String getColorString(){; return color;; }. }. public static boolean isInteractive(){; return !(System.console() == null);; }. public static String cyan(String toColor){; return colorString(toColor, TerminalColor.CYAN);; }. public static String red(String toColor){; return colorString(toColor, TerminalColor.RED);; }. public static String green(String toColor){; return colorString(toColor, TerminalColor.GREEN);; }. public static String white(String toColor){; return colorString(toColor, TerminalColor.WHITE);; }. public static String bold(String toBold){; return colorString(toBold, TerminalColor.BOLD);; }. public static String colorString(String toColor, TerminalColor color) {; if(isInteractive()) {; return color.getColorString() + toColor + TerminalColor.RESET.getColorString();; } else {; return toColor;; }; }. public static String stripColorsFromString(String colorString){; String stripped = colorString;; for(TerminalColor color : TerminalColor.values()) {; stripped = stripped.replace(color.getColorString(),"""");; }; return stripped;; }; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4429#issuecomment-367141169
https://github.com/broadinstitute/gatk/pull/4429#issuecomment-367141169:930,Energy Efficiency,green,green,930,"I have this class from an ancient branch that makes dealing with colors nicer in some ways. It tries to avoid printing colors to non-interactive things and it makes it harder to forget a reset:. ```; /**; * Provides ANSI colors for the terminal output *; */; public final class TerminalColors {. private TerminalColors(){};. private enum TerminalColor{; CYAN(""\u001B[36m""),; RED(""\u001B[31m""),; GREEN(""\u001B[32m""),; WHITE(""\u001B[37m""),; BOLD(""\u001B[1m""),; RESET(""\u001B[0m""); // reset the colors. private final String color;. TerminalColor(String color){; this.color = color;; }. public String getColorString(){; return color;; }. }. public static boolean isInteractive(){; return !(System.console() == null);; }. public static String cyan(String toColor){; return colorString(toColor, TerminalColor.CYAN);; }. public static String red(String toColor){; return colorString(toColor, TerminalColor.RED);; }. public static String green(String toColor){; return colorString(toColor, TerminalColor.GREEN);; }. public static String white(String toColor){; return colorString(toColor, TerminalColor.WHITE);; }. public static String bold(String toBold){; return colorString(toBold, TerminalColor.BOLD);; }. public static String colorString(String toColor, TerminalColor color) {; if(isInteractive()) {; return color.getColorString() + toColor + TerminalColor.RESET.getColorString();; } else {; return toColor;; }; }. public static String stripColorsFromString(String colorString){; String stripped = colorString;; for(TerminalColor color : TerminalColor.values()) {; stripped = stripped.replace(color.getColorString(),"""");; }; return stripped;; }; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4429#issuecomment-367141169
https://github.com/broadinstitute/gatk/pull/4429#issuecomment-367141169:996,Energy Efficiency,GREEN,GREEN,996,"I have this class from an ancient branch that makes dealing with colors nicer in some ways. It tries to avoid printing colors to non-interactive things and it makes it harder to forget a reset:. ```; /**; * Provides ANSI colors for the terminal output *; */; public final class TerminalColors {. private TerminalColors(){};. private enum TerminalColor{; CYAN(""\u001B[36m""),; RED(""\u001B[31m""),; GREEN(""\u001B[32m""),; WHITE(""\u001B[37m""),; BOLD(""\u001B[1m""),; RESET(""\u001B[0m""); // reset the colors. private final String color;. TerminalColor(String color){; this.color = color;; }. public String getColorString(){; return color;; }. }. public static boolean isInteractive(){; return !(System.console() == null);; }. public static String cyan(String toColor){; return colorString(toColor, TerminalColor.CYAN);; }. public static String red(String toColor){; return colorString(toColor, TerminalColor.RED);; }. public static String green(String toColor){; return colorString(toColor, TerminalColor.GREEN);; }. public static String white(String toColor){; return colorString(toColor, TerminalColor.WHITE);; }. public static String bold(String toBold){; return colorString(toBold, TerminalColor.BOLD);; }. public static String colorString(String toColor, TerminalColor color) {; if(isInteractive()) {; return color.getColorString() + toColor + TerminalColor.RESET.getColorString();; } else {; return toColor;; }; }. public static String stripColorsFromString(String colorString){; String stripped = colorString;; for(TerminalColor color : TerminalColor.values()) {; stripped = stripped.replace(color.getColorString(),"""");; }; return stripped;; }; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4429#issuecomment-367141169
https://github.com/broadinstitute/gatk/pull/4429#issuecomment-367141169:104,Safety,avoid,avoid,104,"I have this class from an ancient branch that makes dealing with colors nicer in some ways. It tries to avoid printing colors to non-interactive things and it makes it harder to forget a reset:. ```; /**; * Provides ANSI colors for the terminal output *; */; public final class TerminalColors {. private TerminalColors(){};. private enum TerminalColor{; CYAN(""\u001B[36m""),; RED(""\u001B[31m""),; GREEN(""\u001B[32m""),; WHITE(""\u001B[37m""),; BOLD(""\u001B[1m""),; RESET(""\u001B[0m""); // reset the colors. private final String color;. TerminalColor(String color){; this.color = color;; }. public String getColorString(){; return color;; }. }. public static boolean isInteractive(){; return !(System.console() == null);; }. public static String cyan(String toColor){; return colorString(toColor, TerminalColor.CYAN);; }. public static String red(String toColor){; return colorString(toColor, TerminalColor.RED);; }. public static String green(String toColor){; return colorString(toColor, TerminalColor.GREEN);; }. public static String white(String toColor){; return colorString(toColor, TerminalColor.WHITE);; }. public static String bold(String toBold){; return colorString(toBold, TerminalColor.BOLD);; }. public static String colorString(String toColor, TerminalColor color) {; if(isInteractive()) {; return color.getColorString() + toColor + TerminalColor.RESET.getColorString();; } else {; return toColor;; }; }. public static String stripColorsFromString(String colorString){; String stripped = colorString;; for(TerminalColor color : TerminalColor.values()) {; stripped = stripped.replace(color.getColorString(),"""");; }; return stripped;; }; }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4429#issuecomment-367141169
https://github.com/broadinstitute/gatk/pull/4429#issuecomment-367407823:2822,Testability,test,test,2822, | `77.966% <0%> (+0.847%)` | `43% <0%> (+1%)` | :arrow_up: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4429/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `80% <0%> (+1.29%)` | `39% <0%> (ø)` | :arrow_down: |; | [...nder/tools/examples/ExampleVariantWalkerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4429/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leGFtcGxlcy9FeGFtcGxlVmFyaWFudFdhbGtlclNwYXJrLmphdmE=) | `76.316% <0%> (+2.242%)` | `9% <0%> (+4%)` | :arrow_up: |; | [...institute/hellbender/engine/FeatureDataSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4429/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvRmVhdHVyZURhdGFTb3VyY2UuamF2YQ==) | `79.752% <0%> (+3.696%)` | `66% <0%> (+22%)` | :arrow_up: |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/4429/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `78.261% <0%> (+4.348%)` | `9% <0%> (+1%)` | :arrow_up: |; | [...kers/variantutils/CalculateGenotypePosteriors.java](https://codecov.io/gh/broadinstitute/gatk/pull/4429/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9DYWxjdWxhdGVHZW5vdHlwZVBvc3RlcmlvcnMuamF2YQ==) | `91.398% <0%> (+5.482%)` | `25% <0%> (+12%)` | :arrow_up: |; | [...hellbender/utils/test/VariantContextTestUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4429/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1ZhcmlhbnRDb250ZXh0VGVzdFV0aWxzLmphdmE=) | `89.053% <0%> (+6.621%)` | `83% <0%> (+23%)` | :arrow_up: |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/bro,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4429#issuecomment-367407823
https://github.com/broadinstitute/gatk/pull/4429#issuecomment-367407823:3443,Testability,test,test,3443,aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `80% <0%> (+1.29%)` | `39% <0%> (ø)` | :arrow_down: |; | [...nder/tools/examples/ExampleVariantWalkerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4429/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leGFtcGxlcy9FeGFtcGxlVmFyaWFudFdhbGtlclNwYXJrLmphdmE=) | `76.316% <0%> (+2.242%)` | `9% <0%> (+4%)` | :arrow_up: |; | [...institute/hellbender/engine/FeatureDataSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4429/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvRmVhdHVyZURhdGFTb3VyY2UuamF2YQ==) | `79.752% <0%> (+3.696%)` | `66% <0%> (+22%)` | :arrow_up: |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/4429/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `78.261% <0%> (+4.348%)` | `9% <0%> (+1%)` | :arrow_up: |; | [...kers/variantutils/CalculateGenotypePosteriors.java](https://codecov.io/gh/broadinstitute/gatk/pull/4429/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9DYWxjdWxhdGVHZW5vdHlwZVBvc3RlcmlvcnMuamF2YQ==) | `91.398% <0%> (+5.482%)` | `25% <0%> (+12%)` | :arrow_up: |; | [...hellbender/utils/test/VariantContextTestUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4429/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1ZhcmlhbnRDb250ZXh0VGVzdFV0aWxzLmphdmE=) | `89.053% <0%> (+6.621%)` | `83% <0%> (+23%)` | :arrow_up: |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/4429/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `90% <0%> (+40%)` | `3% <0%> (+2%)` | :arrow_up: |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4429#issuecomment-367407823
https://github.com/broadinstitute/gatk/pull/4430#issuecomment-367144253:36,Testability,test,tests,36,@droazen looks good. Merge when the tests pass,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4430#issuecomment-367144253
https://github.com/broadinstitute/gatk/pull/4430#issuecomment-367168210:1233,Testability,test,test,1233,107766f09ad58785c12fc28c54667028eb89?src=pr&el=desc) will **increase** coverage by `0.033%`.; > The diff coverage is `92.308%`. ```diff; @@ Coverage Diff @@; ## master #4430 +/- ##; ==============================================; + Coverage 79.04% 79.073% +0.033% ; - Complexity 16447 16471 +24 ; ==============================================; Files 1047 1047 ; Lines 59189 59238 +49 ; Branches 9672 9690 +18 ; ==============================================; + Hits 46783 46841 +58 ; + Misses 8644 8635 -9 ; Partials 3762 3762; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4430?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...institute/hellbender/engine/FeatureDataSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4430/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvRmVhdHVyZURhdGFTb3VyY2UuamF2YQ==) | `76.389% <100%> (+0.333%)` | `45 <1> (+1)` | :arrow_up: |; | [...hellbender/utils/test/VariantContextTestUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4430/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1ZhcmlhbnRDb250ZXh0VGVzdFV0aWxzLmphdmE=) | `82.833% <90.909%> (+0.4%)` | `63 <3> (+3)` | :arrow_up: |; | [...park/sv/discovery/alignment/AlignmentInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/4430/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvYWxpZ25tZW50L0FsaWdubWVudEludGVydmFsLmphdmE=) | `89.272% <0%> (ø)` | `73% <0%> (ø)` | :arrow_down: |; | [...kers/variantutils/PosteriorProbabilitiesUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4430/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9Qb3N0ZXJpb3JQcm9iYWJpbGl0aWVzVXRpbHMuamF2YQ==) | `77.966% <0%> (+0.847%)` | `43% <0%> (+1%)` | :arrow_up: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtil,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4430#issuecomment-367168210
https://github.com/broadinstitute/gatk/pull/4430#issuecomment-367168210:3139,Testability,test,test,3139,WxrZXJzL3ZhcmlhbnR1dGlscy9Qb3N0ZXJpb3JQcm9iYWJpbGl0aWVzVXRpbHMuamF2YQ==) | `77.966% <0%> (+0.847%)` | `43% <0%> (+1%)` | :arrow_up: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4430/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `80% <0%> (+1.29%)` | `39% <0%> (ø)` | :arrow_down: |; | [...nder/tools/examples/ExampleVariantWalkerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4430/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9leGFtcGxlcy9FeGFtcGxlVmFyaWFudFdhbGtlclNwYXJrLmphdmE=) | `76.316% <0%> (+2.242%)` | `9% <0%> (+4%)` | :arrow_up: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/4430/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `73.973% <0%> (+2.74%)` | `11% <0%> (ø)` | :arrow_down: |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/4430/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `78.261% <0%> (+4.348%)` | `9% <0%> (+1%)` | :arrow_up: |; | [...kers/variantutils/CalculateGenotypePosteriors.java](https://codecov.io/gh/broadinstitute/gatk/pull/4430/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9DYWxjdWxhdGVHZW5vdHlwZVBvc3RlcmlvcnMuamF2YQ==) | `91.667% <0%> (+5.751%)` | `25% <0%> (+12%)` | :arrow_up: |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/4430/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `90% <0%> (+40%)` | `3% <0%> (+2%)` | :arrow_up: |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4430#issuecomment-367168210
https://github.com/broadinstitute/gatk/pull/4431#issuecomment-367163802:232,Availability,error,error-reference,232,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4431?src=pr&el=h1) Report; > :exclamation: No coverage uploaded for pull request base (`master@7838ffd`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `100%`. ```diff; @@ Coverage Diff @@; ## master #4431 +/- ##; ==========================================; Coverage ? 79.062% ; Complexity ? 16456 ; ==========================================; Files ? 1047 ; Lines ? 59194 ; Branches ? 9675 ; ==========================================; Hits ? 46800 ; Misses ? 8635 ; Partials ? 3759; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4431?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...kers/variantutils/CalculateGenotypePosteriors.java](https://codecov.io/gh/broadinstitute/gatk/pull/4431/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9DYWxjdWxhdGVHZW5vdHlwZVBvc3RlcmlvcnMuamF2YQ==) | `92.308% <100%> (ø)` | `14 <0> (?)` | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4431#issuecomment-367163802
https://github.com/broadinstitute/gatk/pull/4431#issuecomment-367163802:180,Usability,learn,learn,180,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4431?src=pr&el=h1) Report; > :exclamation: No coverage uploaded for pull request base (`master@7838ffd`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `100%`. ```diff; @@ Coverage Diff @@; ## master #4431 +/- ##; ==========================================; Coverage ? 79.062% ; Complexity ? 16456 ; ==========================================; Files ? 1047 ; Lines ? 59194 ; Branches ? 9675 ; ==========================================; Hits ? 46800 ; Misses ? 8635 ; Partials ? 3759; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4431?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...kers/variantutils/CalculateGenotypePosteriors.java](https://codecov.io/gh/broadinstitute/gatk/pull/4431/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9DYWxjdWxhdGVHZW5vdHlwZVBvc3RlcmlvcnMuamF2YQ==) | `92.308% <100%> (ø)` | `14 <0> (?)` | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4431#issuecomment-367163802
https://github.com/broadinstitute/gatk/pull/4431#issuecomment-367342846:118,Availability,error,error,118,"Nice cleanup, thanks!. Also, yesterday I verified that passing in -V <hg38VCF> -supporting <b37VCF> does throw a user error:; `A USER ERROR has occurred: Badly formed genome unclippedLoc: Contig '1' does not match any contig in the GATK sequence dictionary derived from the reference; are you sure you are using the correct reference fasta file?`; I don't feel like the error text is entirely accurate, but at least no one is able to anything too crazy.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4431#issuecomment-367342846
https://github.com/broadinstitute/gatk/pull/4431#issuecomment-367342846:134,Availability,ERROR,ERROR,134,"Nice cleanup, thanks!. Also, yesterday I verified that passing in -V <hg38VCF> -supporting <b37VCF> does throw a user error:; `A USER ERROR has occurred: Badly formed genome unclippedLoc: Contig '1' does not match any contig in the GATK sequence dictionary derived from the reference; are you sure you are using the correct reference fasta file?`; I don't feel like the error text is entirely accurate, but at least no one is able to anything too crazy.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4431#issuecomment-367342846
https://github.com/broadinstitute/gatk/pull/4431#issuecomment-367342846:370,Availability,error,error,370,"Nice cleanup, thanks!. Also, yesterday I verified that passing in -V <hg38VCF> -supporting <b37VCF> does throw a user error:; `A USER ERROR has occurred: Badly formed genome unclippedLoc: Contig '1' does not match any contig in the GATK sequence dictionary derived from the reference; are you sure you are using the correct reference fasta file?`; I don't feel like the error text is entirely accurate, but at least no one is able to anything too crazy.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4431#issuecomment-367342846
https://github.com/broadinstitute/gatk/pull/4431#issuecomment-367366377:29,Availability,error,error,29,"Hmn. That's not the greatest error. It should be failing something more along the lines of ""Your sequence dictionaries don't match, please make sure your files are all aligned using the same reference""",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4431#issuecomment-367366377
https://github.com/broadinstitute/gatk/pull/4432#issuecomment-367184181:1565,Deployability,pipeline,pipelines,1565,==============; Files 1047 1047 ; Lines 59184 59186 +2 ; Branches 9670 9671 +1 ; ===============================================; - Hits 46786 46630 -156 ; - Misses 8640 8804 +164 ; + Partials 3758 3752 -6; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4432?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...bender/tools/walkers/annotator/StrandBiasTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/4432/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9TdHJhbmRCaWFzVGVzdC5qYXZh) | `85.366% <57.143%> (-2.134%)` | `33 <0> (ø)` | |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4432/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-75.51%)` | `0% <0%> (-17%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4432/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/4432/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-65.217%)` | `2% <0%> (-7%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4432/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `54.194% <0%> (-24.516%)` | `30% <0%> (-9%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/4432/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcm,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4432#issuecomment-367184181
https://github.com/broadinstitute/gatk/pull/4432#issuecomment-367184181:1881,Testability,test,test,1881,verage Δ | Complexity Δ | |; |---|---|---|---|; | [...bender/tools/walkers/annotator/StrandBiasTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/4432/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9TdHJhbmRCaWFzVGVzdC5qYXZh) | `85.366% <57.143%> (-2.134%)` | `33 <0> (ø)` | |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4432/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-75.51%)` | `0% <0%> (-17%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4432/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/4432/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-65.217%)` | `2% <0%> (-7%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4432/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `54.194% <0%> (-24.516%)` | `30% <0%> (-9%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/4432/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `0% <0%> (-22.807%)` | `0% <0%> (-2%)` | |; | [...titute/hellbender/utils/test/MiniClusterUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4432/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcm,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4432#issuecomment-367184181
https://github.com/broadinstitute/gatk/pull/4432#issuecomment-367184181:2747,Testability,test,test,2747,GFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/4432/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-65.217%)` | `2% <0%> (-7%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4432/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `54.194% <0%> (-24.516%)` | `30% <0%> (-9%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/4432/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `0% <0%> (-22.807%)` | `0% <0%> (-2%)` | |; | [...titute/hellbender/utils/test/MiniClusterUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4432/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L01pbmlDbHVzdGVyVXRpbHMuamF2YQ==) | `78.947% <0%> (-10.526%)` | `6% <0%> (-1%)` | |; | [...adinstitute/hellbender/engine/ReadsDataSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4432/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUmVhZHNEYXRhU291cmNlLmphdmE=) | `89.394% <0%> (-3.03%)` | `61% <0%> (-2%)` | |; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/4432/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `61.94% <0%> (-2.985%)` | `30% <0%> (-3%)` | |; | [...der/engine/spark/datasources/ReadsSparkSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4432/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4432#issuecomment-367184181
https://github.com/broadinstitute/gatk/pull/4432#issuecomment-367184181:3330,Testability,test,test,3330,iff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-65.217%)` | `2% <0%> (-7%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4432/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `54.194% <0%> (-24.516%)` | `30% <0%> (-9%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/4432/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `0% <0%> (-22.807%)` | `0% <0%> (-2%)` | |; | [...titute/hellbender/utils/test/MiniClusterUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4432/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L01pbmlDbHVzdGVyVXRpbHMuamF2YQ==) | `78.947% <0%> (-10.526%)` | `6% <0%> (-1%)` | |; | [...adinstitute/hellbender/engine/ReadsDataSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4432/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUmVhZHNEYXRhU291cmNlLmphdmE=) | `89.394% <0%> (-3.03%)` | `61% <0%> (-2%)` | |; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/4432/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `61.94% <0%> (-2.985%)` | `30% <0%> (-3%)` | |; | [...der/engine/spark/datasources/ReadsSparkSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4432/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvUmVhZHNTcGFya1NvdXJjZS5qYXZh) | `77.228% <0%> (-2.97%)` | `38% <0%> (ø)` | |; | ... and [6 more](https://codecov.io/gh/broadinstitute/gatk/pull/4432/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4432#issuecomment-367184181
https://github.com/broadinstitute/gatk/pull/4432#issuecomment-367345646:85,Integrability,depend,depending,85,"@fnothaft Thanks for the cleanup. I've seen that annotations take on different types depending on whether they were added during the current traversal or read in from a file, but I haven't run into any issues with the strand bias annotations so far. Do you have a specific use case for the int[] version?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4432#issuecomment-367345646
https://github.com/broadinstitute/gatk/pull/4432#issuecomment-367374828:131,Testability,test,test,131,"@fnothaft When you submit a PR, you should include a brief description of the motivation behind the change, as well as a good unit test covering it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4432#issuecomment-367374828
https://github.com/broadinstitute/gatk/pull/4432#issuecomment-453591621:71,Testability,test,test,71,"Closing this one, as it's been open for a year and there still isn't a test + description of the motivation behind the change.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4432#issuecomment-453591621
https://github.com/broadinstitute/gatk/issues/4433#issuecomment-367324573:131,Deployability,release,release,131,"Yes, the return value for Picard tools are not propagated properly when run through GATK. We'll try to get the fix in for the next release. Closing as a dup of https://github.com/broadinstitute/gatk/issues/4329.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4433#issuecomment-367324573
https://github.com/broadinstitute/gatk/issues/4434#issuecomment-367406877:88,Integrability,depend,dependent,88,We've definitely seen similar problems before with accented characters. Might be system dependent since I can't reproduce the issue... What OS are you building on?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4434#issuecomment-367406877
https://github.com/broadinstitute/gatk/issues/4434#issuecomment-367410334:48,Availability,error,error,48,"@droazen I followed your instructions, but same error, I'm sorry. @lbergelson ; Distributor ID:	Ubuntu; Description:	Ubuntu 16.04.3 LTS; Release:	16.04; Codename:	xenial. Anyway I remember that I faced this issue some months ago and I resolved it adding to .basrc this line; `export JAVA_OPTS=-Dfile.encoding=UTF8`, but now for some reason I don't know why when I use `./gradlew bundle` is not used this java encoding and so doesn't work (but if you have the possibility to modify that name, you should resolve definitely the issue).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4434#issuecomment-367410334
https://github.com/broadinstitute/gatk/issues/4434#issuecomment-367410334:137,Deployability,Release,Release,137,"@droazen I followed your instructions, but same error, I'm sorry. @lbergelson ; Distributor ID:	Ubuntu; Description:	Ubuntu 16.04.3 LTS; Release:	16.04; Codename:	xenial. Anyway I remember that I faced this issue some months ago and I resolved it adding to .basrc this line; `export JAVA_OPTS=-Dfile.encoding=UTF8`, but now for some reason I don't know why when I use `./gradlew bundle` is not used this java encoding and so doesn't work (but if you have the possibility to modify that name, you should resolve definitely the issue).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4434#issuecomment-367410334
https://github.com/broadinstitute/gatk/issues/4435#issuecomment-367411571:116,Deployability,configurat,configuration,116,"@jacobrh91 Thanks for the report! I believe this is the result of our (still-incomplete) transition to using a GATK configuration file for certain toolkit-wide settings. Could you please try making a copy of `src/main/resources/org/broadinstitute/hellbender/utils/config/GATKConfig.properties`, editing the `samjdk.use_async_io_read_samtools` line in that file to have a value of `true` rather than `false`, pass in the edited config file to GATK via the `--gatk-config-file` argument, and see if the setting gets changed at runtime?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4435#issuecomment-367411571
https://github.com/broadinstitute/gatk/issues/4435#issuecomment-367411571:116,Modifiability,config,configuration,116,"@jacobrh91 Thanks for the report! I believe this is the result of our (still-incomplete) transition to using a GATK configuration file for certain toolkit-wide settings. Could you please try making a copy of `src/main/resources/org/broadinstitute/hellbender/utils/config/GATKConfig.properties`, editing the `samjdk.use_async_io_read_samtools` line in that file to have a value of `true` rather than `false`, pass in the edited config file to GATK via the `--gatk-config-file` argument, and see if the setting gets changed at runtime?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4435#issuecomment-367411571
https://github.com/broadinstitute/gatk/issues/4435#issuecomment-367411571:264,Modifiability,config,config,264,"@jacobrh91 Thanks for the report! I believe this is the result of our (still-incomplete) transition to using a GATK configuration file for certain toolkit-wide settings. Could you please try making a copy of `src/main/resources/org/broadinstitute/hellbender/utils/config/GATKConfig.properties`, editing the `samjdk.use_async_io_read_samtools` line in that file to have a value of `true` rather than `false`, pass in the edited config file to GATK via the `--gatk-config-file` argument, and see if the setting gets changed at runtime?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4435#issuecomment-367411571
https://github.com/broadinstitute/gatk/issues/4435#issuecomment-367411571:427,Modifiability,config,config,427,"@jacobrh91 Thanks for the report! I believe this is the result of our (still-incomplete) transition to using a GATK configuration file for certain toolkit-wide settings. Could you please try making a copy of `src/main/resources/org/broadinstitute/hellbender/utils/config/GATKConfig.properties`, editing the `samjdk.use_async_io_read_samtools` line in that file to have a value of `true` rather than `false`, pass in the edited config file to GATK via the `--gatk-config-file` argument, and see if the setting gets changed at runtime?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4435#issuecomment-367411571
https://github.com/broadinstitute/gatk/issues/4435#issuecomment-367411571:463,Modifiability,config,config-file,463,"@jacobrh91 Thanks for the report! I believe this is the result of our (still-incomplete) transition to using a GATK configuration file for certain toolkit-wide settings. Could you please try making a copy of `src/main/resources/org/broadinstitute/hellbender/utils/config/GATKConfig.properties`, editing the `samjdk.use_async_io_read_samtools` line in that file to have a value of `true` rather than `false`, pass in the edited config file to GATK via the `--gatk-config-file` argument, and see if the setting gets changed at runtime?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4435#issuecomment-367411571
https://github.com/broadinstitute/gatk/issues/4435#issuecomment-367412275:181,Modifiability,config,config-file,181,"@jonn-smith Can you please chime in here as well to tell us whether it's currently possible to override a single system property setting in Owner on the command line, or is `--gatk-config-file` currently the only way?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4435#issuecomment-367412275
https://github.com/broadinstitute/gatk/issues/4435#issuecomment-367715460:27,Modifiability,config,config,27,"Currently the code for the config file parsing will override values passed in on the command-line, so that explains one reason this is happening. The fix should be pretty straightforward.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4435#issuecomment-367715460
https://github.com/broadinstitute/gatk/issues/4435#issuecomment-368036324:57,Modifiability,config,config-file,57,"Passing in the properties file did work (with the --gatk-config-file option). However, of the four tools I tested (MarkDuplicates, BaseRecalibrator, ApplyBQSR, and HaplotypeCaller) all of the tools accepted the --gatk-config-file option except for MarkDuplicates, which complains that it is not a recognized option. Perhaps this should be turned into a separate issue?. Thanks",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4435#issuecomment-368036324
https://github.com/broadinstitute/gatk/issues/4435#issuecomment-368036324:218,Modifiability,config,config-file,218,"Passing in the properties file did work (with the --gatk-config-file option). However, of the four tools I tested (MarkDuplicates, BaseRecalibrator, ApplyBQSR, and HaplotypeCaller) all of the tools accepted the --gatk-config-file option except for MarkDuplicates, which complains that it is not a recognized option. Perhaps this should be turned into a separate issue?. Thanks",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4435#issuecomment-368036324
https://github.com/broadinstitute/gatk/issues/4435#issuecomment-368036324:107,Testability,test,tested,107,"Passing in the properties file did work (with the --gatk-config-file option). However, of the four tools I tested (MarkDuplicates, BaseRecalibrator, ApplyBQSR, and HaplotypeCaller) all of the tools accepted the --gatk-config-file option except for MarkDuplicates, which complains that it is not a recognized option. Perhaps this should be turned into a separate issue?. Thanks",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4435#issuecomment-368036324
https://github.com/broadinstitute/gatk/pull/4437#issuecomment-368023391:3103,Deployability,pipeline,pipelines,3103,w_up: |; | [...lbender/exceptions/PicardNonZeroExitException.java](https://codecov.io/gh/broadinstitute/gatk/pull/4437/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9leGNlcHRpb25zL1BpY2FyZE5vblplcm9FeGl0RXhjZXB0aW9uLmphdmE=) | `80% <80%> (ø)` | `2 <2> (?)` | |; | [...der/tools/walkers/mutect/M2ArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/4437/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9NMkFyZ3VtZW50Q29sbGVjdGlvbi5qYXZh) | `100% <0%> (ø)` | `1% <0%> (ø)` | :arrow_down: |; | [...ecaller/AssemblyBasedCallerArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/4437/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9Bc3NlbWJseUJhc2VkQ2FsbGVyQXJndW1lbnRDb2xsZWN0aW9uLmphdmE=) | `100% <0%> (ø)` | `1% <0%> (ø)` | :arrow_down: |; | [...ls/walkers/mutect/M2FiltersArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/4437/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9NMkZpbHRlcnNBcmd1bWVudENvbGxlY3Rpb24uamF2YQ==) | `100% <0%> (ø)` | `1% <0%> (ø)` | :arrow_down: |; | [...hellbender/tools/spark/pipelines/SortSamSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4437/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvU29ydFNhbVNwYXJrLmphdmE=) | `70.588% <0%> (ø)` | `4% <0%> (?)` | |; | [...park/sv/discovery/alignment/AlignmentInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/4437/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvYWxpZ25tZW50L0FsaWdubWVudEludGVydmFsLmphdmE=) | `90.038% <0%> (+0.766%)` | `74% <0%> (+1%)` | :arrow_up: |; | ... and [4 more](https://codecov.io/gh/broadinstitute/gatk/pull/4437/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4437#issuecomment-368023391
https://github.com/broadinstitute/gatk/pull/4438#issuecomment-368637030:48,Energy Efficiency,reduce,reduceByKey,48,"It bothers me a bit that we're doing a shuffle (reduceByKey operation in FBES line 880) on the big int arrays of coverage counts. Would've been so much nicer to process each partition all the way to high-coverage intervals independently, but I understand why it's done this way: to handle counts that cross partition boundaries. Since it's a pretty quick step, and since I can't think of a straightforward way to handle partition boundary crossing any better than this, I'm giving it the thumbs up. I add a few niggles to particular lines and then add another general comment with the approval indication.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4438#issuecomment-368637030
https://github.com/broadinstitute/gatk/pull/4438#issuecomment-368979818:116,Testability,test,tests,116,"Thanks for the comments @tedsharpe , some good code cleanup here. I've addressed your comments and will merge after tests pass. I agree about the shuffle -- I'd originally implemented this without it but then found some places where high-depth intervals were getting clipped at the boundaries of depth window partitions due to overlapping counts. In practice it doesn't seem to take a discernible amount of runtime, at least on our development clusters.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4438#issuecomment-368979818
https://github.com/broadinstitute/gatk/issues/4439#issuecomment-785244420:205,Deployability,release,released,205,"I second the request for this, and I opened up the same request under the Picard GitHub project: https://github.com/broadinstitute/picard/issues/1647. Notably, this request was implemented in the recently-released Picard 2.24.0 for IntervalListTools specifically: https://github.com/broadinstitute/picard/pull/1608",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4439#issuecomment-785244420
https://github.com/broadinstitute/gatk/pull/4445#issuecomment-368063117:1229,Modifiability,config,config,1229,/commit/2bb2f50996e5e826268145d426e8edd697f9a46f?src=pr&el=desc) will **increase** coverage by `0.319%`.; > The diff coverage is `100%`. ```diff; @@ Coverage Diff @@; ## master #4445 +/- ##; ===============================================; + Coverage 79.156% 79.475% +0.319% ; - Complexity 16583 17182 +599 ; ===============================================; Files 1049 1050 +1 ; Lines 59510 60950 +1440 ; Branches 9747 10190 +443 ; ===============================================; + Hits 47106 48440 +1334 ; - Misses 8620 8690 +70 ; - Partials 3784 3820 +36; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4445?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [.../main/java/org/broadinstitute/hellbender/Main.java](https://codecov.io/gh/broadinstitute/gatk/pull/4445/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9NYWluLmphdmE=) | `77.703% <ø> (+5.764%)` | `62 <0> (+17)` | :arrow_up: |; | [...stitute/hellbender/utils/config/ConfigFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/4445/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9jb25maWcvQ29uZmlnRmFjdG9yeS5qYXZh) | `76.398% <100%> (-0.036%)` | `45 <3> (ø)` | |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/4445/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `50% <0%> (-40%)` | `1% <0%> (-2%)` | |; | [...nder/cmdline/PicardCommandLineProgramExecutor.java](https://codecov.io/gh/broadinstitute/gatk/pull/4445/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL1BpY2FyZENvbW1hbmRMaW5lUHJvZ3JhbUV4ZWN1dG9yLmphdmE=) | `60% <0%> (-10%)` | `4% <0%> (+1%)` | |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/4445/diff?src=pr&el=tree#diff-,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4445#issuecomment-368063117
https://github.com/broadinstitute/gatk/pull/4445#issuecomment-368063117:1236,Modifiability,Config,ConfigFactory,1236,/commit/2bb2f50996e5e826268145d426e8edd697f9a46f?src=pr&el=desc) will **increase** coverage by `0.319%`.; > The diff coverage is `100%`. ```diff; @@ Coverage Diff @@; ## master #4445 +/- ##; ===============================================; + Coverage 79.156% 79.475% +0.319% ; - Complexity 16583 17182 +599 ; ===============================================; Files 1049 1050 +1 ; Lines 59510 60950 +1440 ; Branches 9747 10190 +443 ; ===============================================; + Hits 47106 48440 +1334 ; - Misses 8620 8690 +70 ; - Partials 3784 3820 +36; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4445?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [.../main/java/org/broadinstitute/hellbender/Main.java](https://codecov.io/gh/broadinstitute/gatk/pull/4445/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9NYWluLmphdmE=) | `77.703% <ø> (+5.764%)` | `62 <0> (+17)` | :arrow_up: |; | [...stitute/hellbender/utils/config/ConfigFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/4445/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9jb25maWcvQ29uZmlnRmFjdG9yeS5qYXZh) | `76.398% <100%> (-0.036%)` | `45 <3> (ø)` | |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/4445/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `50% <0%> (-40%)` | `1% <0%> (-2%)` | |; | [...nder/cmdline/PicardCommandLineProgramExecutor.java](https://codecov.io/gh/broadinstitute/gatk/pull/4445/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL1BpY2FyZENvbW1hbmRMaW5lUHJvZ3JhbUV4ZWN1dG9yLmphdmE=) | `60% <0%> (-10%)` | `4% <0%> (+1%)` | |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/4445/diff?src=pr&el=tree#diff-,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4445#issuecomment-368063117
https://github.com/broadinstitute/gatk/issues/4447#issuecomment-368091726:116,Energy Efficiency,adapt,adapt,116,"No problems. The walkers have no built in parallelism so there's no problem with using state. It makes it harder to adapt to spark, but that's probably not a big deal.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4447#issuecomment-368091726
https://github.com/broadinstitute/gatk/issues/4447#issuecomment-368091726:116,Modifiability,adapt,adapt,116,"No problems. The walkers have no built in parallelism so there's no problem with using state. It makes it harder to adapt to spark, but that's probably not a big deal.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4447#issuecomment-368091726
https://github.com/broadinstitute/gatk/issues/4448#issuecomment-367984760:31,Performance,multi-thread,multi-thread,31,For the new GATK framework the multi-thread support is through Spark (see https://github.com/broadinstitute/gatk/issues/2345 for more details).,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4448#issuecomment-367984760
https://github.com/broadinstitute/gatk/issues/4448#issuecomment-368051007:793,Availability,avail,available,793,"Yes, that's true in general. The -nt / -ntc flags options were never very good in gatk3. They usually scaled very poorly with number of cores, and were the cause of a lot of complexity and bugs. We decided not to try to roll our own map reduce framework for gatk4, but use an existing much better one, ie spark. . We recommend multiprocess parallelism with an external job runner like [cromwell](https://github.com/broadinstitute/cromwell) if you want parallelism in tools that aren't ready in spark yet. This is more complicated to setup and run, but it results in much more efficient use of compute resources. There are few limited multithreaded options remaining in GATK4 outside of spark. One specific one is the option to use multiple threads with HaplotypeCaller's pairHmm. This is only available on linux systems and defaults to using 4 threads.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4448#issuecomment-368051007
https://github.com/broadinstitute/gatk/issues/4448#issuecomment-368051007:237,Energy Efficiency,reduce,reduce,237,"Yes, that's true in general. The -nt / -ntc flags options were never very good in gatk3. They usually scaled very poorly with number of cores, and were the cause of a lot of complexity and bugs. We decided not to try to roll our own map reduce framework for gatk4, but use an existing much better one, ie spark. . We recommend multiprocess parallelism with an external job runner like [cromwell](https://github.com/broadinstitute/cromwell) if you want parallelism in tools that aren't ready in spark yet. This is more complicated to setup and run, but it results in much more efficient use of compute resources. There are few limited multithreaded options remaining in GATK4 outside of spark. One specific one is the option to use multiple threads with HaplotypeCaller's pairHmm. This is only available on linux systems and defaults to using 4 threads.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4448#issuecomment-368051007
https://github.com/broadinstitute/gatk/issues/4448#issuecomment-368051007:576,Energy Efficiency,efficient,efficient,576,"Yes, that's true in general. The -nt / -ntc flags options were never very good in gatk3. They usually scaled very poorly with number of cores, and were the cause of a lot of complexity and bugs. We decided not to try to roll our own map reduce framework for gatk4, but use an existing much better one, ie spark. . We recommend multiprocess parallelism with an external job runner like [cromwell](https://github.com/broadinstitute/cromwell) if you want parallelism in tools that aren't ready in spark yet. This is more complicated to setup and run, but it results in much more efficient use of compute resources. There are few limited multithreaded options remaining in GATK4 outside of spark. One specific one is the option to use multiple threads with HaplotypeCaller's pairHmm. This is only available on linux systems and defaults to using 4 threads.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4448#issuecomment-368051007
https://github.com/broadinstitute/gatk/issues/4448#issuecomment-368054603:69,Testability,benchmark,benchmarking,69,"Thanks for the information.; For info, I asked because I'm currently benchmarking SGE cluster vs Spark usage.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4448#issuecomment-368054603
https://github.com/broadinstitute/gatk/issues/4453#issuecomment-410724975:118,Security,validat,validation,118,"It looks like the noGenotypes.vcf in GATK3 was derived from the v37 ref with decoy. In GATK4, the sequence dictionary validation requirement is that the input and reference have a common subset of contigs, so given your description of the difference I would expect it to pass that test. Feel free to reopen if you think I've missed something.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4453#issuecomment-410724975
https://github.com/broadinstitute/gatk/issues/4453#issuecomment-410724975:281,Testability,test,test,281,"It looks like the noGenotypes.vcf in GATK3 was derived from the v37 ref with decoy. In GATK4, the sequence dictionary validation requirement is that the input and reference have a common subset of contigs, so given your description of the difference I would expect it to pass that test. Feel free to reopen if you think I've missed something.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4453#issuecomment-410724975
https://github.com/broadinstitute/gatk/issues/4454#issuecomment-368648512:94,Security,secur,security,94,"Upon further investigating, the builds are indeed there. Dockerhub is deprecating their build security scan feature, and in the meantime it only allows one scan of an image a day. Because we tag each image with a different name they show up in the nightly build repository as being unscanned and thus get binned at the bottom of the page (after scrolling through everything since the beginning of time) to view the unscanned images.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4454#issuecomment-368648512
https://github.com/broadinstitute/gatk/issues/4454#issuecomment-370515447:35,Deployability,update,updated,35,It appears that the webUI has been updated to no longer show the scanned images first due to complaints. This seems to have resolved itself. Closing the ticket,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4454#issuecomment-370515447
https://github.com/broadinstitute/gatk/pull/4455#issuecomment-368157556:3542,Availability,down,downsampling,3542,ps://codecov.io/gh/broadinstitute/gatk/pull/4455/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `80% <0%> (+1.29%)` | `39% <0%> (ø)` | :arrow_down: |; | [...plotypecaller/HaplotypeCallerGenotypingEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/4455/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9IYXBsb3R5cGVDYWxsZXJHZW5vdHlwaW5nRW5naW5lLmphdmE=) | `77.536% <0%> (+1.449%)` | `32% <0%> (+1%)` | :arrow_up: |; | [...walkers/haplotypecaller/HaplotypeCallerEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/4455/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9IYXBsb3R5cGVDYWxsZXJFbmdpbmUuamF2YQ==) | `79.026% <0%> (+1.498%)` | `65% <0%> (+2%)` | :arrow_up: |; | [...ypecaller/AssemblyBasedCallerGenotypingEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/4455/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9Bc3NlbWJseUJhc2VkQ2FsbGVyR2Vub3R5cGluZ0VuZ2luZS5qYXZh) | `90.909% <0%> (+1.818%)` | `67% <0%> (+2%)` | :arrow_up: |; | [...ls/downsampling/AlleleBiasedDownsamplingUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4455/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvQWxsZWxlQmlhc2VkRG93bnNhbXBsaW5nVXRpbHMuamF2YQ==) | `79.31% <0%> (+2.299%)` | `24% <0%> (+1%)` | :arrow_up: |; | [...te/hellbender/utils/genotyper/ReadLikelihoods.java](https://codecov.io/gh/broadinstitute/gatk/pull/4455/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nZW5vdHlwZXIvUmVhZExpa2VsaWhvb2RzLmphdmE=) | `89.575% <0%> (+4.054%)` | `151% <0%> (+5%)` | :arrow_up: |; | ... and [2 more](https://codecov.io/gh/broadinstitute/gatk/pull/4455/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4455#issuecomment-368157556
https://github.com/broadinstitute/gatk/pull/4455#issuecomment-368604893:58,Testability,test,test,58,@droazen Back at you with a couple of questions about the test cases / explanations and one minor grammatical edit.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4455#issuecomment-368604893
https://github.com/broadinstitute/gatk/pull/4455#issuecomment-369983458:124,Deployability,integrat,integration,124,"I've added a bunch of additional unit tests for the `StandardCallerArgumentCollection`, and beefed up the `HaplotypeCaller` integration tests as well (we now check for concordance against the GATK3 contamination-corrected calls, in addition to just asserting that the calls in GATK4 improve with contamination correction on).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4455#issuecomment-369983458
https://github.com/broadinstitute/gatk/pull/4455#issuecomment-369983458:124,Integrability,integrat,integration,124,"I've added a bunch of additional unit tests for the `StandardCallerArgumentCollection`, and beefed up the `HaplotypeCaller` integration tests as well (we now check for concordance against the GATK3 contamination-corrected calls, in addition to just asserting that the calls in GATK4 improve with contamination correction on).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4455#issuecomment-369983458
https://github.com/broadinstitute/gatk/pull/4455#issuecomment-369983458:38,Testability,test,tests,38,"I've added a bunch of additional unit tests for the `StandardCallerArgumentCollection`, and beefed up the `HaplotypeCaller` integration tests as well (we now check for concordance against the GATK3 contamination-corrected calls, in addition to just asserting that the calls in GATK4 improve with contamination correction on).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4455#issuecomment-369983458
https://github.com/broadinstitute/gatk/pull/4455#issuecomment-369983458:136,Testability,test,tests,136,"I've added a bunch of additional unit tests for the `StandardCallerArgumentCollection`, and beefed up the `HaplotypeCaller` integration tests as well (we now check for concordance against the GATK3 contamination-corrected calls, in addition to just asserting that the calls in GATK4 improve with contamination correction on).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4455#issuecomment-369983458
https://github.com/broadinstitute/gatk/pull/4455#issuecomment-369983458:249,Testability,assert,asserting,249,"I've added a bunch of additional unit tests for the `StandardCallerArgumentCollection`, and beefed up the `HaplotypeCaller` integration tests as well (we now check for concordance against the GATK3 contamination-corrected calls, in addition to just asserting that the calls in GATK4 improve with contamination correction on).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4455#issuecomment-369983458
https://github.com/broadinstitute/gatk/issues/4457#issuecomment-368230264:662,Integrability,protocol,protocol,662,"Hi @wujh2017,. Note that the numbers in change30-model/mu_mean_bias_j_lowerbound__.tsv indicate the mean bias per *contig*, not per *sample*. It looks like you are providing only 4 samples to GermlineCNVCaller, even though you provided 30 samples to DetermineGermlineContigPloidy. Are these 4 samples included in those 30? Typically, you would just provide all 30 samples (along with their ploidy calls) to GermlineCNVCaller. Also, you mentioned that the read depth varies dramatically between samples. Remember that we are trying to model systematic sequencing bias using the samples in the cohort, so ideally they should have all been sequenced with a similar protocol.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4457#issuecomment-368230264
https://github.com/broadinstitute/gatk/issues/4457#issuecomment-369254401:284,Deployability,release,release,284,@wujh2017 Great! Let us know if you have any more feedback. Please be aware that both DetermineGermlineContigPloidy and GermlineCNVCaller are still in beta. There are some parameters that may need to be tuned appropriately for your data. We are currently running evaluations and will release some recommendations that we find suitable for data generated at the Broad.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4457#issuecomment-369254401
https://github.com/broadinstitute/gatk/issues/4457#issuecomment-369254401:203,Performance,tune,tuned,203,@wujh2017 Great! Let us know if you have any more feedback. Please be aware that both DetermineGermlineContigPloidy and GermlineCNVCaller are still in beta. There are some parameters that may need to be tuned appropriately for your data. We are currently running evaluations and will release some recommendations that we find suitable for data generated at the Broad.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4457#issuecomment-369254401
https://github.com/broadinstitute/gatk/issues/4457#issuecomment-369254401:50,Usability,feedback,feedback,50,@wujh2017 Great! Let us know if you have any more feedback. Please be aware that both DetermineGermlineContigPloidy and GermlineCNVCaller are still in beta. There are some parameters that may need to be tuned appropriately for your data. We are currently running evaluations and will release some recommendations that we find suitable for data generated at the Broad.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4457#issuecomment-369254401
https://github.com/broadinstitute/gatk/issues/4458#issuecomment-368541002:62,Availability,error,error,62,I'm able to create a dummy test data that reproduces the same error messages.; On it to fix now.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4458#issuecomment-368541002
https://github.com/broadinstitute/gatk/issues/4458#issuecomment-368541002:68,Integrability,message,messages,68,I'm able to create a dummy test data that reproduces the same error messages.; On it to fix now.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4458#issuecomment-368541002
https://github.com/broadinstitute/gatk/issues/4458#issuecomment-368541002:27,Testability,test,test,27,I'm able to create a dummy test data that reproduces the same error messages.; On it to fix now.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4458#issuecomment-368541002
https://github.com/broadinstitute/gatk/issues/4458#issuecomment-368560122:62,Testability,test,tested,62,"Found the problem. ; Essentially an edge case bug that wasn't tested in the unit tests:; For this strand-switch event, the `POS` was&mdash;expectedly&mdash;inferred to be a location 1 base before the left boundary of affected reference region; the left boundary in this case turns out to be `chrUn_JTFH01000312v1_decoy:1`.; Just need to add guards for these edge cases following the VCF specs. **EDIT**; Actually it is a different bug that could be fixed by #4322",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4458#issuecomment-368560122
https://github.com/broadinstitute/gatk/issues/4458#issuecomment-368560122:81,Testability,test,tests,81,"Found the problem. ; Essentially an edge case bug that wasn't tested in the unit tests:; For this strand-switch event, the `POS` was&mdash;expectedly&mdash;inferred to be a location 1 base before the left boundary of affected reference region; the left boundary in this case turns out to be `chrUn_JTFH01000312v1_decoy:1`.; Just need to add guards for these edge cases following the VCF specs. **EDIT**; Actually it is a different bug that could be fixed by #4322",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4458#issuecomment-368560122
https://github.com/broadinstitute/gatk/issues/4458#issuecomment-370449193:90,Deployability,update,updated,90,"@jjfarrell If possible, could you pull from the latest master branch of GATK and test the updated SV pipeline on your data? Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4458#issuecomment-370449193
https://github.com/broadinstitute/gatk/issues/4458#issuecomment-370449193:101,Deployability,pipeline,pipeline,101,"@jjfarrell If possible, could you pull from the latest master branch of GATK and test the updated SV pipeline on your data? Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4458#issuecomment-370449193
https://github.com/broadinstitute/gatk/issues/4458#issuecomment-370449193:81,Testability,test,test,81,"@jjfarrell If possible, could you pull from the latest master branch of GATK and test the updated SV pipeline on your data? Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4458#issuecomment-370449193
https://github.com/broadinstitute/gatk/issues/4458#issuecomment-370896619:21,Deployability,pipeline,pipeline,21,Thanks for using our pipeline and reporting the issue @jjfarrell !,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4458#issuecomment-370896619
https://github.com/broadinstitute/gatk/issues/4459#issuecomment-368538022:326,Integrability,message,message,326,"Hi @marchoeppner - a few questions. It does sounds like a bad conda or python environment. Is the workflow running from within the GATK conda env when you see this (you would have had to have manually created it using the gatkcondaenv.yml file shipped with GATK4). It would be helpful to see the command line that led to this message, and the context in which it appears. Although GATK4 requires the GATK4 conda environment for a handful of tools to work, GenomicsDBImport isn't one of them. If there are other GATK tools that trigger this (or that you know work fine in the same environment) that would also be useful to know.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4459#issuecomment-368538022
https://github.com/broadinstitute/gatk/pull/4463#issuecomment-383606630:3271,Testability,test,test,3271,erVariantsFromContigAlignmentsSAMSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4463/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvRGlzY292ZXJWYXJpYW50c0Zyb21Db250aWdBbGlnbm1lbnRzU0FNU3BhcmsuamF2YQ==) | `88.889% <0%> (-4.659%)` | `45% <0%> (+23%)` | |; | [...r/utils/read/markduplicates/sparkrecords/Pair.java](https://codecov.io/gh/broadinstitute/gatk/pull/4463/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWFkL21hcmtkdXBsaWNhdGVzL3NwYXJrcmVjb3Jkcy9QYWlyLmphdmE=) | `92.135% <0%> (-3.371%)` | `22% <0%> (ø)` | |; | [...transforms/markduplicates/MarkDuplicatesSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4463/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay90cmFuc2Zvcm1zL21hcmtkdXBsaWNhdGVzL01hcmtEdXBsaWNhdGVzU3BhcmsuamF2YQ==) | `94.118% <0%> (-1.004%)` | `23% <0%> (+8%)` | |; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/4463/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `62.921% <0%> (-0.988%)` | `49% <0%> (+16%)` | |; | [...stitute/hellbender/tools/walkers/CombineGVCFs.java](https://codecov.io/gh/broadinstitute/gatk/pull/4463/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL0NvbWJpbmVHVkNGcy5qYXZh) | `93.519% <0%> (-0.481%)` | `85% <0%> (+23%)` | |; | [...iscoverFromLocalAssemblyContigAlignmentsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4463/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvU3ZEaXNjb3ZlckZyb21Mb2NhbEFzc2VtYmx5Q29udGlnQWxpZ25tZW50c1NwYXJrLmphdmE=) | `76.048% <0%> (-0.474%)` | `6% <0%> (+1%)` | |; | ... and [74 more](https://codecov.io/gh/broadinstitute/gatk/pull/4463/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4463#issuecomment-383606630
https://github.com/broadinstitute/gatk/pull/4463#issuecomment-383606630:1917,Usability,Simpl,SimpleNovelAdjacencyInterpreter,1917,-|---|---|; | [...stitute/hellbender/tools/HaplotypeCallerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4463/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9IYXBsb3R5cGVDYWxsZXJTcGFyay5qYXZh) | `83.158% <100%> (-0.175%)` | `25 <3> (-1)` | |; | [...er/engine/spark/datasources/VariantsSparkSink.java](https://codecov.io/gh/broadinstitute/gatk/pull/4463/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvVmFyaWFudHNTcGFya1NpbmsuamF2YQ==) | `82.105% <66.667%> (-3.941%)` | `18 <2> (+1)` | |; | [...ce/AssemblyContigAlignmentSignatureClassifier.java](https://codecov.io/gh/broadinstitute/gatk/pull/4463/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvaW5mZXJlbmNlL0Fzc2VtYmx5Q29udGlnQWxpZ25tZW50U2lnbmF0dXJlQ2xhc3NpZmllci5qYXZh) | `58.602% <0%> (-25.269%)` | `30% <0%> (-10%)` | |; | [...ery/inference/SimpleNovelAdjacencyInterpreter.java](https://codecov.io/gh/broadinstitute/gatk/pull/4463/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvaW5mZXJlbmNlL1NpbXBsZU5vdmVsQWRqYWNlbmN5SW50ZXJwcmV0ZXIuamF2YQ==) | `80.435% <0%> (-19.565%)` | `16% <0%> (+9%)` | |; | [.../DiscoverVariantsFromContigAlignmentsSAMSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4463/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvRGlzY292ZXJWYXJpYW50c0Zyb21Db250aWdBbGlnbm1lbnRzU0FNU3BhcmsuamF2YQ==) | `88.889% <0%> (-4.659%)` | `45% <0%> (+23%)` | |; | [...r/utils/read/markduplicates/sparkrecords/Pair.java](https://codecov.io/gh/broadinstitute/gatk/pull/4463/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWFkL21hcmtkdXBsaWNhdGVzL3NwYXJrcmVjb3Jkcy9QYWlyLmphdmE=) | `92.135% <0%> (-3.371%)` | `22% <0%> (ø)` | |; | [...transforms/markdupl,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4463#issuecomment-383606630
https://github.com/broadinstitute/gatk/pull/4463#issuecomment-383618975:28,Availability,avail,available,28,"A new Hadoop-BAM release is available with the dependent fix in it, so this is ready to go in. Could you have a look please @lbergelson?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4463#issuecomment-383618975
https://github.com/broadinstitute/gatk/pull/4463#issuecomment-383618975:17,Deployability,release,release,17,"A new Hadoop-BAM release is available with the dependent fix in it, so this is ready to go in. Could you have a look please @lbergelson?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4463#issuecomment-383618975
https://github.com/broadinstitute/gatk/pull/4463#issuecomment-383618975:47,Integrability,depend,dependent,47,"A new Hadoop-BAM release is available with the dependent fix in it, so this is ready to go in. Could you have a look please @lbergelson?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4463#issuecomment-383618975
https://github.com/broadinstitute/gatk/pull/4463#issuecomment-385024632:176,Availability,down,down,176,The test is broken. It never checks that the actual file written was in the format that was expected. There's a bug where format isn't being set appropriately to bcf. Tracking down where that happens... I suspect we're not setting OUTPUT_VCF_FORMAT_PROPERTY correctly.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4463#issuecomment-385024632
https://github.com/broadinstitute/gatk/pull/4463#issuecomment-385024632:4,Testability,test,test,4,The test is broken. It never checks that the actual file written was in the format that was expected. There's a bug where format isn't being set appropriately to bcf. Tracking down where that happens... I suspect we're not setting OUTPUT_VCF_FORMAT_PROPERTY correctly.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4463#issuecomment-385024632
https://github.com/broadinstitute/gatk/pull/4463#issuecomment-385979240:80,Deployability,update,updated,80,"@lbergelson well spotted! I think the BCF bug has been around for a while. I've updated this PR to handle the compressed GVCF case, and opened https://github.com/broadinstitute/gatk/issues/4729 for BCF (should we choose to implement it sometime).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4463#issuecomment-385979240
https://github.com/broadinstitute/gatk/issues/4464#issuecomment-459532819:63,Testability,test,testing,63,I think this will be difficult and we don't have a python unit testing framework. Let's try for some simple tests in #4375.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4464#issuecomment-459532819
https://github.com/broadinstitute/gatk/issues/4464#issuecomment-459532819:108,Testability,test,tests,108,I think this will be difficult and we don't have a python unit testing framework. Let's try for some simple tests in #4375.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4464#issuecomment-459532819
https://github.com/broadinstitute/gatk/issues/4464#issuecomment-459532819:101,Usability,simpl,simple,101,I think this will be difficult and we don't have a python unit testing framework. Let's try for some simple tests in #4375.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4464#issuecomment-459532819
https://github.com/broadinstitute/gatk/issues/4465#issuecomment-369244401:85,Safety,avoid,avoid,85,"@lucidtronix Whats the motivation for wanting to keep it ? I think we really want to avoid it if at all possible, but if there is a reason its necessary let us know and we can discuss.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4465#issuecomment-369244401
https://github.com/broadinstitute/gatk/issues/4465#issuecomment-387157958:12,Integrability,Depend,Depends,12,"Also pysam. Depends on https://github.com/broadinstitute/gatk/issues/4533, https://github.com/broadinstitute/gatk/issues/4534 and https://github.com/broadinstitute/gatk/issues/4535.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4465#issuecomment-387157958
https://github.com/broadinstitute/gatk/issues/4467#issuecomment-369320265:17,Availability,error,error,17,"@Cashalow The GC error indicates that you are running out of memory. How much physical memory does your machine have, and how much are you allocating with `-Xmx`?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4467#issuecomment-369320265
https://github.com/broadinstitute/gatk/issues/4467#issuecomment-370462977:297,Performance,optimiz,optimizations,297,"@Cashalow Can you include the full command line? 50 human genomes (ploidy 2) would need less than 7GB memory in my experience, even for highly multi-allelic indel sites. I would expect ploidy 1 calls (as most users run microbial genomes) would require even less, but we have some diploid-specific optimizations. Are you using the `new-qual` argument? That QUAL calculation algorithm is less computationally intensive and I believe it is applicable to all ploidies.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4467#issuecomment-370462977
https://github.com/broadinstitute/gatk/issues/4467#issuecomment-370464854:258,Testability,log,log,258,"Thanks for your help ! I was not using the `new-qual` argument. Here are the different command I used: . ``` ; gatk-launch GenotypeGVCFs --java-options -Xmx23g -ploidy 1 -R $ref --annotations-to-exclude InbreedingCoeff -V gendb://gendb -O all_samples.vcf &> log; ```. You don't think using CombineGVCFs or GenomicDBImport will make any change then ? I will try now using `new-qual`. How long would your GenotypeGVCFs typically run with your 50 human genomes ? Mine ran for 25h for 50 samples and a genome of 5Mbp. Edit : wow ok apparently the new-qual did the trick, my 50 samples genome of 5Mbp then ran in 2 minutes instead of 25h. Pretty weird. Thanks a lot !",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4467#issuecomment-370464854
https://github.com/broadinstitute/gatk/issues/4467#issuecomment-370477452:39,Performance,optimiz,optimized,39,"It's possible that GenomicsDB was also optimized for diploids and thusly slower for other ploidies because a lot of the code was ported from GATK. I think `new-qual` is more likely to help, but you can certainly try CombineGVCFs. I don't have a lot of good benchmarks, honestly, but maybe @lbergelson does. GATK3 GenotypeGVCFs for 20,000 human samples took 113.54 hours for about 1.9Mbp, but that was on a CombinedGVCF already extracted from GenomicsDB. With that many samples there are a lot of multi-allelics so that part should be similar to your data. The java options were `java -XX:GCTimeLimit=50 -XX:GCHeapFreeLimit=10 -Xmx11500m`, so still less memory than your task seems to need. And without `new-qual`. It also seems to be much faster than your run, but it's hard to say how runtime should scale with the number of samples.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4467#issuecomment-370477452
https://github.com/broadinstitute/gatk/issues/4467#issuecomment-370477452:257,Testability,benchmark,benchmarks,257,"It's possible that GenomicsDB was also optimized for diploids and thusly slower for other ploidies because a lot of the code was ported from GATK. I think `new-qual` is more likely to help, but you can certainly try CombineGVCFs. I don't have a lot of good benchmarks, honestly, but maybe @lbergelson does. GATK3 GenotypeGVCFs for 20,000 human samples took 113.54 hours for about 1.9Mbp, but that was on a CombinedGVCF already extracted from GenomicsDB. With that many samples there are a lot of multi-allelics so that part should be similar to your data. The java options were `java -XX:GCTimeLimit=50 -XX:GCHeapFreeLimit=10 -Xmx11500m`, so still less memory than your task seems to need. And without `new-qual`. It also seems to be much faster than your run, but it's hard to say how runtime should scale with the number of samples.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4467#issuecomment-370477452
https://github.com/broadinstitute/gatk/pull/4468#issuecomment-369213597:1840,Deployability,pipeline,pipelines,1840,rc=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...ellbender/cmdline/StandardArgumentDefinitions.java](https://codecov.io/gh/broadinstitute/gatk/pull/4468/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL1N0YW5kYXJkQXJndW1lbnREZWZpbml0aW9ucy5qYXZh) | `0% <ø> (ø)` | `0 <0> (ø)` | :arrow_down: |; | [...stitute/hellbender/cmdline/CommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/4468/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0NvbW1hbmRMaW5lUHJvZ3JhbS5qYXZh) | `82.432% <100%> (ø)` | `43 <0> (ø)` | :arrow_down: |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4468/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-75.51%)` | `0% <0%> (-17%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4468/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/4468/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-65.217%)` | `2% <0%> (-7%)` | |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/4468/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `50% <0%> (-30%)` | `1% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4468/diff?src=pr&el=tree#diff,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4468#issuecomment-369213597
https://github.com/broadinstitute/gatk/pull/4468#issuecomment-369213597:2156,Testability,test,test,2156,W9ucy5qYXZh) | `0% <ø> (ø)` | `0 <0> (ø)` | :arrow_down: |; | [...stitute/hellbender/cmdline/CommandLineProgram.java](https://codecov.io/gh/broadinstitute/gatk/pull/4468/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0NvbW1hbmRMaW5lUHJvZ3JhbS5qYXZh) | `82.432% <100%> (ø)` | `43 <0> (ø)` | :arrow_down: |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4468/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-75.51%)` | `0% <0%> (-17%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4468/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/4468/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-65.217%)` | `2% <0%> (-7%)` | |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/4468/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `50% <0%> (-30%)` | `1% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4468/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `54.194% <0%> (-25.806%)` | `30% <0%> (-9%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/4468/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2Y,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4468#issuecomment-369213597
https://github.com/broadinstitute/gatk/pull/4468#issuecomment-369213597:3330,Testability,test,test,3330,vYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/test/XorWrapper.java](https://codecov.io/gh/broadinstitute/gatk/pull/4468/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1hvcldyYXBwZXIuamF2YQ==) | `13.043% <0%> (-65.217%)` | `2% <0%> (-7%)` | |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/4468/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `50% <0%> (-30%)` | `1% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4468/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `54.194% <0%> (-25.806%)` | `30% <0%> (-9%)` | |; | [...nder/tools/spark/BaseRecalibratorSparkSharded.java](https://codecov.io/gh/broadinstitute/gatk/pull/4468/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9CYXNlUmVjYWxpYnJhdG9yU3BhcmtTaGFyZGVkLmphdmE=) | `0% <0%> (-22.807%)` | `0% <0%> (-2%)` | |; | [...titute/hellbender/utils/test/MiniClusterUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4468/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L01pbmlDbHVzdGVyVXRpbHMuamF2YQ==) | `78.947% <0%> (-10.526%)` | `6% <0%> (-1%)` | |; | [...adinstitute/hellbender/engine/ReadsDataSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4468/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUmVhZHNEYXRhU291cmNlLmphdmE=) | `89.394% <0%> (-3.03%)` | `61% <0%> (-2%)` | |; | ... and [6 more](https://codecov.io/gh/broadinstitute/gatk/pull/4468/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4468#issuecomment-369213597
https://github.com/broadinstitute/gatk/pull/4469#issuecomment-374883868:27,Testability,test,tests,27,"Back to you, still without tests for tmp dir working with NIO due to lack of information: should it be at the tool level (e.g., running `MarkDuplicatesGATK` with NIO tmp dir - my main use case) or just checking the property value that is correctly set?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4469#issuecomment-374883868
https://github.com/broadinstitute/gatk/pull/4469#issuecomment-377577797:210,Integrability,depend,depends,210,"@droazen - please, clarify how the tests should be done. I'm going to be on vacation next week, so feel free to add them to this branch if you would like to speed up the process (taking into account that #3998 depends on this now). Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4469#issuecomment-377577797
https://github.com/broadinstitute/gatk/pull/4469#issuecomment-377577797:35,Testability,test,tests,35,"@droazen - please, clarify how the tests should be done. I'm going to be on vacation next week, so feel free to add them to this branch if you would like to speed up the process (taking into account that #3998 depends on this now). Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4469#issuecomment-377577797
https://github.com/broadinstitute/gatk/pull/4469#issuecomment-381657341:9,Availability,ping,ping,9,Friendly ping here @droazen,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4469#issuecomment-381657341
https://github.com/broadinstitute/gatk/pull/4469#issuecomment-385942269:38,Deployability,integrat,integration,38,"@droazen - Still some questions about integration tests (on the comment with your suggestion, but here too):. * I am not sure if the test that you are proposing will work with all the implementations of `createTempFile`: depends on how it is handle, as a `File` or as a `Path`; * I think that this depends a lot on the parts of the codebase that we are looking at, so maybe before accepting this a pass should be done for the usages and how the `java.io.tmpdir` is used. Waiting for your feedback before doing something that does not make sense...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4469#issuecomment-385942269
https://github.com/broadinstitute/gatk/pull/4469#issuecomment-385942269:38,Integrability,integrat,integration,38,"@droazen - Still some questions about integration tests (on the comment with your suggestion, but here too):. * I am not sure if the test that you are proposing will work with all the implementations of `createTempFile`: depends on how it is handle, as a `File` or as a `Path`; * I think that this depends a lot on the parts of the codebase that we are looking at, so maybe before accepting this a pass should be done for the usages and how the `java.io.tmpdir` is used. Waiting for your feedback before doing something that does not make sense...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4469#issuecomment-385942269
https://github.com/broadinstitute/gatk/pull/4469#issuecomment-385942269:221,Integrability,depend,depends,221,"@droazen - Still some questions about integration tests (on the comment with your suggestion, but here too):. * I am not sure if the test that you are proposing will work with all the implementations of `createTempFile`: depends on how it is handle, as a `File` or as a `Path`; * I think that this depends a lot on the parts of the codebase that we are looking at, so maybe before accepting this a pass should be done for the usages and how the `java.io.tmpdir` is used. Waiting for your feedback before doing something that does not make sense...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4469#issuecomment-385942269
https://github.com/broadinstitute/gatk/pull/4469#issuecomment-385942269:298,Integrability,depend,depends,298,"@droazen - Still some questions about integration tests (on the comment with your suggestion, but here too):. * I am not sure if the test that you are proposing will work with all the implementations of `createTempFile`: depends on how it is handle, as a `File` or as a `Path`; * I think that this depends a lot on the parts of the codebase that we are looking at, so maybe before accepting this a pass should be done for the usages and how the `java.io.tmpdir` is used. Waiting for your feedback before doing something that does not make sense...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4469#issuecomment-385942269
https://github.com/broadinstitute/gatk/pull/4469#issuecomment-385942269:50,Testability,test,tests,50,"@droazen - Still some questions about integration tests (on the comment with your suggestion, but here too):. * I am not sure if the test that you are proposing will work with all the implementations of `createTempFile`: depends on how it is handle, as a `File` or as a `Path`; * I think that this depends a lot on the parts of the codebase that we are looking at, so maybe before accepting this a pass should be done for the usages and how the `java.io.tmpdir` is used. Waiting for your feedback before doing something that does not make sense...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4469#issuecomment-385942269
https://github.com/broadinstitute/gatk/pull/4469#issuecomment-385942269:133,Testability,test,test,133,"@droazen - Still some questions about integration tests (on the comment with your suggestion, but here too):. * I am not sure if the test that you are proposing will work with all the implementations of `createTempFile`: depends on how it is handle, as a `File` or as a `Path`; * I think that this depends a lot on the parts of the codebase that we are looking at, so maybe before accepting this a pass should be done for the usages and how the `java.io.tmpdir` is used. Waiting for your feedback before doing something that does not make sense...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4469#issuecomment-385942269
https://github.com/broadinstitute/gatk/pull/4469#issuecomment-385942269:488,Usability,feedback,feedback,488,"@droazen - Still some questions about integration tests (on the comment with your suggestion, but here too):. * I am not sure if the test that you are proposing will work with all the implementations of `createTempFile`: depends on how it is handle, as a `File` or as a `Path`; * I think that this depends a lot on the parts of the codebase that we are looking at, so maybe before accepting this a pass should be done for the usages and how the `java.io.tmpdir` is used. Waiting for your feedback before doing something that does not make sense...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4469#issuecomment-385942269
https://github.com/broadinstitute/gatk/pull/4469#issuecomment-386412987:139,Testability,test,tests,139,"@magicDGS Could you add overloads of `IOUtils.createTempFile()` and `BaseTest.createTempFile()` that take a Path, and use them just in the tests you write for this PR? Once tests are in place, we can gradually migrate usages to the Path overloads in future PRs.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4469#issuecomment-386412987
https://github.com/broadinstitute/gatk/pull/4469#issuecomment-386412987:173,Testability,test,tests,173,"@magicDGS Could you add overloads of `IOUtils.createTempFile()` and `BaseTest.createTempFile()` that take a Path, and use them just in the tests you write for this PR? Once tests are in place, we can gradually migrate usages to the Path overloads in future PRs.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4469#issuecomment-386412987
https://github.com/broadinstitute/gatk/pull/4469#issuecomment-392004286:152,Testability,test,tests,152,"Sorry for the delay here, @droazen - I had some technical problems with my hardware and did not have time to work on this. Back to you with implemented tests!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4469#issuecomment-392004286
https://github.com/broadinstitute/gatk/pull/4469#issuecomment-415308713:20,Availability,ping,ping,20,@droazen - friendly ping here!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4469#issuecomment-415308713
https://github.com/broadinstitute/gatk/pull/4469#issuecomment-415833242:22,Testability,test,test,22,Rebased - waiting for test passing and hopefully you can hit merge @droazen!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4469#issuecomment-415833242
https://github.com/broadinstitute/gatk/pull/4473#issuecomment-369354277:2855,Usability,Simpl,SimpleSVType,2855,YQ==) | `95.041% <0%> (-4.959%)` | `29% <0%> (+16%)` | |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/4473/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `71.233% <0%> (-2.74%)` | `11% <0%> (ø)` | |; | [...ellbender/tools/walkers/annotator/QualByDepth.java](https://codecov.io/gh/broadinstitute/gatk/pull/4473/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9RdWFsQnlEZXB0aC5qYXZh) | `95.745% <0%> (-1.553%)` | `18% <0%> (+1%)` | |; | [...s/spark/sv/discovery/AnnotatedVariantProducer.java](https://codecov.io/gh/broadinstitute/gatk/pull/4473/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvQW5ub3RhdGVkVmFyaWFudFByb2R1Y2VyLmphdmE=) | `76.471% <0%> (-1.307%)` | `30% <0%> (+8%)` | |; | [...lbender/tools/spark/sv/discovery/SimpleSVType.java](https://codecov.io/gh/broadinstitute/gatk/pull/4473/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvU2ltcGxlU1ZUeXBlLmphdmE=) | `85.393% <0%> (-1.174%)` | `2% <0%> (ø)` | |; | [...iscoverFromLocalAssemblyContigAlignmentsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4473/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvU3ZEaXNjb3ZlckZyb21Mb2NhbEFzc2VtYmx5Q29udGlnQWxpZ25tZW50c1NwYXJrLmphdmE=) | `74.194% <0%> (-1.02%)` | `15% <0%> (+5%)` | |; | [...nder/utils/runtime/StreamingProcessController.java](https://codecov.io/gh/broadinstitute/gatk/pull/4473/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9ydW50aW1lL1N0cmVhbWluZ1Byb2Nlc3NDb250cm9sbGVyLmphdmE=) | `70.37% <0%> (-0.823%)` | `50% <0%> (-1%)` | |; | [...ark/sv/discovery/inference/CpxVariantDetector.java](https://code,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4473#issuecomment-369354277
https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371389979:72,Deployability,release,release,72,@droazen - can you have a look to thisone to try to make it to the next release? Thank you!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371389979
https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371570897:525,Integrability,wrap,wrapper,525,"This seems like a lot of machinery (introducing two new types and a new method) just to hide the config file argument. What if we just mark it `@Hidden` (I know thats prohibited, but this is kind of a special case). The only reason it even exists is because we wanted it to appear in the command lines we display on output and embed in output files. If its `@Hidden` it will still be reflected there when it's used, but it wouldn't be displayed in tool help/usage. Its already always displayed in help as an arg for the gatk wrapper.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371570897
https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371570897:97,Modifiability,config,config,97,"This seems like a lot of machinery (introducing two new types and a new method) just to hide the config file argument. What if we just mark it `@Hidden` (I know thats prohibited, but this is kind of a special case). The only reason it even exists is because we wanted it to appear in the command lines we display on output and embed in output files. If its `@Hidden` it will still be reflected there when it's used, but it wouldn't be displayed in tool help/usage. Its already always displayed in help as an arg for the gatk wrapper.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371570897
https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371730828:64,Availability,down,downstream,64,"@cmnbroad - it is not enough for me to make it `@Hidden`. In my downstream toolkits , I don't want it to appear wherever command line is printed (headers, logs, etc), because I am not supporting custom configuration files. In the case that `Main` is not accounting for the configuration file and an user provide their own, then the command line might indicate wrongly that the configuration was set, but it wasn't. I really need a way to remove completely the argument. If someone print the help with hidden arguments, then they will misunderstand that the configuration can be overwrite, even more if they know the configuration system of GATK. The only solution for my use case is to being able to remove completely the argument, not just reducing visibility.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371730828
https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371730828:202,Deployability,configurat,configuration,202,"@cmnbroad - it is not enough for me to make it `@Hidden`. In my downstream toolkits , I don't want it to appear wherever command line is printed (headers, logs, etc), because I am not supporting custom configuration files. In the case that `Main` is not accounting for the configuration file and an user provide their own, then the command line might indicate wrongly that the configuration was set, but it wasn't. I really need a way to remove completely the argument. If someone print the help with hidden arguments, then they will misunderstand that the configuration can be overwrite, even more if they know the configuration system of GATK. The only solution for my use case is to being able to remove completely the argument, not just reducing visibility.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371730828
https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371730828:273,Deployability,configurat,configuration,273,"@cmnbroad - it is not enough for me to make it `@Hidden`. In my downstream toolkits , I don't want it to appear wherever command line is printed (headers, logs, etc), because I am not supporting custom configuration files. In the case that `Main` is not accounting for the configuration file and an user provide their own, then the command line might indicate wrongly that the configuration was set, but it wasn't. I really need a way to remove completely the argument. If someone print the help with hidden arguments, then they will misunderstand that the configuration can be overwrite, even more if they know the configuration system of GATK. The only solution for my use case is to being able to remove completely the argument, not just reducing visibility.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371730828
https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371730828:377,Deployability,configurat,configuration,377,"@cmnbroad - it is not enough for me to make it `@Hidden`. In my downstream toolkits , I don't want it to appear wherever command line is printed (headers, logs, etc), because I am not supporting custom configuration files. In the case that `Main` is not accounting for the configuration file and an user provide their own, then the command line might indicate wrongly that the configuration was set, but it wasn't. I really need a way to remove completely the argument. If someone print the help with hidden arguments, then they will misunderstand that the configuration can be overwrite, even more if they know the configuration system of GATK. The only solution for my use case is to being able to remove completely the argument, not just reducing visibility.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371730828
https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371730828:557,Deployability,configurat,configuration,557,"@cmnbroad - it is not enough for me to make it `@Hidden`. In my downstream toolkits , I don't want it to appear wherever command line is printed (headers, logs, etc), because I am not supporting custom configuration files. In the case that `Main` is not accounting for the configuration file and an user provide their own, then the command line might indicate wrongly that the configuration was set, but it wasn't. I really need a way to remove completely the argument. If someone print the help with hidden arguments, then they will misunderstand that the configuration can be overwrite, even more if they know the configuration system of GATK. The only solution for my use case is to being able to remove completely the argument, not just reducing visibility.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371730828
https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371730828:616,Deployability,configurat,configuration,616,"@cmnbroad - it is not enough for me to make it `@Hidden`. In my downstream toolkits , I don't want it to appear wherever command line is printed (headers, logs, etc), because I am not supporting custom configuration files. In the case that `Main` is not accounting for the configuration file and an user provide their own, then the command line might indicate wrongly that the configuration was set, but it wasn't. I really need a way to remove completely the argument. If someone print the help with hidden arguments, then they will misunderstand that the configuration can be overwrite, even more if they know the configuration system of GATK. The only solution for my use case is to being able to remove completely the argument, not just reducing visibility.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371730828
https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371730828:202,Modifiability,config,configuration,202,"@cmnbroad - it is not enough for me to make it `@Hidden`. In my downstream toolkits , I don't want it to appear wherever command line is printed (headers, logs, etc), because I am not supporting custom configuration files. In the case that `Main` is not accounting for the configuration file and an user provide their own, then the command line might indicate wrongly that the configuration was set, but it wasn't. I really need a way to remove completely the argument. If someone print the help with hidden arguments, then they will misunderstand that the configuration can be overwrite, even more if they know the configuration system of GATK. The only solution for my use case is to being able to remove completely the argument, not just reducing visibility.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371730828
https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371730828:273,Modifiability,config,configuration,273,"@cmnbroad - it is not enough for me to make it `@Hidden`. In my downstream toolkits , I don't want it to appear wherever command line is printed (headers, logs, etc), because I am not supporting custom configuration files. In the case that `Main` is not accounting for the configuration file and an user provide their own, then the command line might indicate wrongly that the configuration was set, but it wasn't. I really need a way to remove completely the argument. If someone print the help with hidden arguments, then they will misunderstand that the configuration can be overwrite, even more if they know the configuration system of GATK. The only solution for my use case is to being able to remove completely the argument, not just reducing visibility.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371730828
https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371730828:377,Modifiability,config,configuration,377,"@cmnbroad - it is not enough for me to make it `@Hidden`. In my downstream toolkits , I don't want it to appear wherever command line is printed (headers, logs, etc), because I am not supporting custom configuration files. In the case that `Main` is not accounting for the configuration file and an user provide their own, then the command line might indicate wrongly that the configuration was set, but it wasn't. I really need a way to remove completely the argument. If someone print the help with hidden arguments, then they will misunderstand that the configuration can be overwrite, even more if they know the configuration system of GATK. The only solution for my use case is to being able to remove completely the argument, not just reducing visibility.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371730828
https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371730828:557,Modifiability,config,configuration,557,"@cmnbroad - it is not enough for me to make it `@Hidden`. In my downstream toolkits , I don't want it to appear wherever command line is printed (headers, logs, etc), because I am not supporting custom configuration files. In the case that `Main` is not accounting for the configuration file and an user provide their own, then the command line might indicate wrongly that the configuration was set, but it wasn't. I really need a way to remove completely the argument. If someone print the help with hidden arguments, then they will misunderstand that the configuration can be overwrite, even more if they know the configuration system of GATK. The only solution for my use case is to being able to remove completely the argument, not just reducing visibility.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371730828
https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371730828:616,Modifiability,config,configuration,616,"@cmnbroad - it is not enough for me to make it `@Hidden`. In my downstream toolkits , I don't want it to appear wherever command line is printed (headers, logs, etc), because I am not supporting custom configuration files. In the case that `Main` is not accounting for the configuration file and an user provide their own, then the command line might indicate wrongly that the configuration was set, but it wasn't. I really need a way to remove completely the argument. If someone print the help with hidden arguments, then they will misunderstand that the configuration can be overwrite, even more if they know the configuration system of GATK. The only solution for my use case is to being able to remove completely the argument, not just reducing visibility.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371730828
https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371730828:155,Testability,log,logs,155,"@cmnbroad - it is not enough for me to make it `@Hidden`. In my downstream toolkits , I don't want it to appear wherever command line is printed (headers, logs, etc), because I am not supporting custom configuration files. In the case that `Main` is not accounting for the configuration file and an user provide their own, then the command line might indicate wrongly that the configuration was set, but it wasn't. I really need a way to remove completely the argument. If someone print the help with hidden arguments, then they will misunderstand that the configuration can be overwrite, even more if they know the configuration system of GATK. The only solution for my use case is to being able to remove completely the argument, not just reducing visibility.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371730828
https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371819413:24,Modifiability,config,config,24,"@magicDGS Args like the config file that are truly optional (have no default value at all) do not show up in the command line or headers unless they're populated with some value. It should be pretty easy for ReadTools (which I think already has a common base class for its tools), to ensure a config file is never accepted by just precluding it via custom command line validation, or arg preprocessing. BTW, all tools built with GATK already have numerous common args that may or may not apply in a given tool context. For example, all of the ReadWalkers have a `--lenientVCFProcessing` arg. So I'm not even sure we need to make this hidden, since it will hide it from gatk users. My 2 cents. Others may feel differently.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371819413
https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371819413:293,Modifiability,config,config,293,"@magicDGS Args like the config file that are truly optional (have no default value at all) do not show up in the command line or headers unless they're populated with some value. It should be pretty easy for ReadTools (which I think already has a common base class for its tools), to ensure a config file is never accepted by just precluding it via custom command line validation, or arg preprocessing. BTW, all tools built with GATK already have numerous common args that may or may not apply in a given tool context. For example, all of the ReadWalkers have a `--lenientVCFProcessing` arg. So I'm not even sure we need to make this hidden, since it will hide it from gatk users. My 2 cents. Others may feel differently.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371819413
https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371819413:369,Security,validat,validation,369,"@magicDGS Args like the config file that are truly optional (have no default value at all) do not show up in the command line or headers unless they're populated with some value. It should be pretty easy for ReadTools (which I think already has a common base class for its tools), to ensure a config file is never accepted by just precluding it via custom command line validation, or arg preprocessing. BTW, all tools built with GATK already have numerous common args that may or may not apply in a given tool context. For example, all of the ReadWalkers have a `--lenientVCFProcessing` arg. So I'm not even sure we need to make this hidden, since it will hide it from gatk users. My 2 cents. Others may feel differently.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371819413
https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371822090:632,Availability,down,downstream,632,"That's why I am not using in ReadTools and other developmental toolkit the base class from GATK, due to the polluted command line with unused arguments. I think that for give flexibility, some of that arguments should be configurable by extending classes. For example, some tools that does not require reads at all should be able to turn off the read arguments. That will be very useful, although I am not sure how to do it in a proper way without adding more and more interfaces for argument collections. In context case of this PR, I think that adding it does not have any real effect on the GATK codebase, and a lot is gained by downstream projects. For example, if the wrapper script adds another argument that should be parsed in `Main` and documented, the GATK team just add it to its class. If a toolkit has a similar wrapper script, it can also add its own only-doc argument by simply overriding the method...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371822090
https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371822090:469,Integrability,interface,interfaces,469,"That's why I am not using in ReadTools and other developmental toolkit the base class from GATK, due to the polluted command line with unused arguments. I think that for give flexibility, some of that arguments should be configurable by extending classes. For example, some tools that does not require reads at all should be able to turn off the read arguments. That will be very useful, although I am not sure how to do it in a proper way without adding more and more interfaces for argument collections. In context case of this PR, I think that adding it does not have any real effect on the GATK codebase, and a lot is gained by downstream projects. For example, if the wrapper script adds another argument that should be parsed in `Main` and documented, the GATK team just add it to its class. If a toolkit has a similar wrapper script, it can also add its own only-doc argument by simply overriding the method...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371822090
https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371822090:673,Integrability,wrap,wrapper,673,"That's why I am not using in ReadTools and other developmental toolkit the base class from GATK, due to the polluted command line with unused arguments. I think that for give flexibility, some of that arguments should be configurable by extending classes. For example, some tools that does not require reads at all should be able to turn off the read arguments. That will be very useful, although I am not sure how to do it in a proper way without adding more and more interfaces for argument collections. In context case of this PR, I think that adding it does not have any real effect on the GATK codebase, and a lot is gained by downstream projects. For example, if the wrapper script adds another argument that should be parsed in `Main` and documented, the GATK team just add it to its class. If a toolkit has a similar wrapper script, it can also add its own only-doc argument by simply overriding the method...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371822090
https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371822090:825,Integrability,wrap,wrapper,825,"That's why I am not using in ReadTools and other developmental toolkit the base class from GATK, due to the polluted command line with unused arguments. I think that for give flexibility, some of that arguments should be configurable by extending classes. For example, some tools that does not require reads at all should be able to turn off the read arguments. That will be very useful, although I am not sure how to do it in a proper way without adding more and more interfaces for argument collections. In context case of this PR, I think that adding it does not have any real effect on the GATK codebase, and a lot is gained by downstream projects. For example, if the wrapper script adds another argument that should be parsed in `Main` and documented, the GATK team just add it to its class. If a toolkit has a similar wrapper script, it can also add its own only-doc argument by simply overriding the method...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371822090
https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371822090:221,Modifiability,config,configurable,221,"That's why I am not using in ReadTools and other developmental toolkit the base class from GATK, due to the polluted command line with unused arguments. I think that for give flexibility, some of that arguments should be configurable by extending classes. For example, some tools that does not require reads at all should be able to turn off the read arguments. That will be very useful, although I am not sure how to do it in a proper way without adding more and more interfaces for argument collections. In context case of this PR, I think that adding it does not have any real effect on the GATK codebase, and a lot is gained by downstream projects. For example, if the wrapper script adds another argument that should be parsed in `Main` and documented, the GATK team just add it to its class. If a toolkit has a similar wrapper script, it can also add its own only-doc argument by simply overriding the method...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371822090
https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371822090:237,Modifiability,extend,extending,237,"That's why I am not using in ReadTools and other developmental toolkit the base class from GATK, due to the polluted command line with unused arguments. I think that for give flexibility, some of that arguments should be configurable by extending classes. For example, some tools that does not require reads at all should be able to turn off the read arguments. That will be very useful, although I am not sure how to do it in a proper way without adding more and more interfaces for argument collections. In context case of this PR, I think that adding it does not have any real effect on the GATK codebase, and a lot is gained by downstream projects. For example, if the wrapper script adds another argument that should be parsed in `Main` and documented, the GATK team just add it to its class. If a toolkit has a similar wrapper script, it can also add its own only-doc argument by simply overriding the method...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371822090
https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371822090:886,Usability,simpl,simply,886,"That's why I am not using in ReadTools and other developmental toolkit the base class from GATK, due to the polluted command line with unused arguments. I think that for give flexibility, some of that arguments should be configurable by extending classes. For example, some tools that does not require reads at all should be able to turn off the read arguments. That will be very useful, although I am not sure how to do it in a proper way without adding more and more interfaces for argument collections. In context case of this PR, I think that adding it does not have any real effect on the GATK codebase, and a lot is gained by downstream projects. For example, if the wrapper script adds another argument that should be parsed in `Main` and documented, the GATK team just add it to its class. If a toolkit has a similar wrapper script, it can also add its own only-doc argument by simply overriding the method...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4474#issuecomment-371822090
https://github.com/broadinstitute/gatk/pull/4474#issuecomment-377341373:109,Modifiability,config,config,109,"@magicDGS Rather than have a special case for doc-only args, I think we should close this PR and include the config file arg as part of the arg collection you added in https://github.com/broadinstitute/gatk/pull/3998.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4474#issuecomment-377341373
https://github.com/broadinstitute/gatk/issues/4475#issuecomment-369654074:259,Availability,down,download,259,"@alrafaykhan Did you clone (this) repository with git, and if so, is the root of that clone the location from which you're running ./gradlew ? I'm not sure how that happened, but it seems like you have build.gradle, but not the rest of the repo. You also can download a [zip file with GATK already built](https://github.com/broadinstitute/gatk/releases) if you just want to run it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4475#issuecomment-369654074
https://github.com/broadinstitute/gatk/issues/4475#issuecomment-369654074:344,Deployability,release,releases,344,"@alrafaykhan Did you clone (this) repository with git, and if so, is the root of that clone the location from which you're running ./gradlew ? I'm not sure how that happened, but it seems like you have build.gradle, but not the rest of the repo. You also can download a [zip file with GATK already built](https://github.com/broadinstitute/gatk/releases) if you just want to run it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4475#issuecomment-369654074
https://github.com/broadinstitute/gatk/issues/4475#issuecomment-369675396:35,Availability,down,downloaded,35,@alrafaykhan I'm guessing that you downloaded the source code zip instead of actually cloning our git repository. You need to clone the repository to build GATK.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4475#issuecomment-369675396
https://github.com/broadinstitute/gatk/issues/4475#issuecomment-369815587:11,Availability,down,downloaded,11,Yes i have downloaded source code (zip) from https://github.com/broadinstitute/gatk/archive/4.0.2.0.zip,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4475#issuecomment-369815587
https://github.com/broadinstitute/gatk/pull/4477#issuecomment-369733374:1571,Usability,Simpl,SimpleNovelAdjacencyInterpreter,1571,===; Files 1050 1053 +3 ; Lines 59971 61074 +1103 ; Branches 9830 10124 +294 ; ===============================================; + Hits 47426 48215 +789 ; - Misses 8738 8995 +257 ; - Partials 3807 3864 +57; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4477?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...bender/tools/walkers/annotator/StrandArtifact.java](https://codecov.io/gh/broadinstitute/gatk/pull/4477/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9TdHJhbmRBcnRpZmFjdC5qYXZh) | `100% <100%> (ø)` | `30 <0> (ø)` | :arrow_down: |; | [...r/tools/walkers/mutect/Mutect2FilteringEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/4477/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9NdXRlY3QyRmlsdGVyaW5nRW5naW5lLmphdmE=) | `81.6% <100%> (ø)` | `36 <0> (ø)` | :arrow_down: |; | [...ery/inference/SimpleNovelAdjacencyInterpreter.java](https://codecov.io/gh/broadinstitute/gatk/pull/4477/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvaW5mZXJlbmNlL1NpbXBsZU5vdmVsQWRqYWNlbmN5SW50ZXJwcmV0ZXIuamF2YQ==) | `68.807% <0%> (-31.193%)` | `23% <0%> (+16%)` | |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/4477/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `50% <0%> (-30%)` | `1% <0%> (-2%)` | |; | [...rs/genotyper/StandardCallerArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/4477/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9TdGFuZGFyZENhbGxlckFyZ3VtZW50Q29sbGVjdGlvbi5qYXZh) | `75% <0%> (-14.474%)` | `16% <0%> (+1%)` | |; | [...e/hellbender/engine/spark/SparkContextFactor,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4477#issuecomment-369733374
https://github.com/broadinstitute/gatk/pull/4477#issuecomment-369733374:3187,Usability,Simpl,SimpleSVType,3187,0%)` | `1% <0%> (-2%)` | |; | [...rs/genotyper/StandardCallerArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/4477/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9TdGFuZGFyZENhbGxlckFyZ3VtZW50Q29sbGVjdGlvbi5qYXZh) | `75% <0%> (-14.474%)` | `16% <0%> (+1%)` | |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/4477/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `71.233% <0%> (-2.74%)` | `11% <0%> (ø)` | |; | [...park/sv/discovery/inference/ChimericAlignment.java](https://codecov.io/gh/broadinstitute/gatk/pull/4477/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvaW5mZXJlbmNlL0NoaW1lcmljQWxpZ25tZW50LmphdmE=) | `71.759% <0%> (-2.677%)` | `67% <0%> (+34%)` | |; | [...lbender/tools/spark/sv/discovery/SimpleSVType.java](https://codecov.io/gh/broadinstitute/gatk/pull/4477/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvU2ltcGxlU1ZUeXBlLmphdmE=) | `85.393% <0%> (-1.047%)` | `2% <0%> (ø)` | |; | [...hellbender/tools/copynumber/DenoiseReadCounts.java](https://codecov.io/gh/broadinstitute/gatk/pull/4477/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL0Rlbm9pc2VSZWFkQ291bnRzLmphdmE=) | `90.909% <0%> (-0.983%)` | `12% <0%> (+2%)` | |; | [...ce/AssemblyContigAlignmentSignatureClassifier.java](https://codecov.io/gh/broadinstitute/gatk/pull/4477/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvaW5mZXJlbmNlL0Fzc2VtYmx5Q29udGlnQWxpZ25tZW50U2lnbmF0dXJlQ2xhc3NpZmllci5qYXZh) | `57.621% <0%> (-0.621%)` | `27% <0%> (-2%)` | |; | ... and [15 more](https://codecov.io/gh/broadinstitute/gatk/pull/4477/,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4477#issuecomment-369733374
https://github.com/broadinstitute/gatk/issues/4478#issuecomment-374346073:93,Availability,error,error,93,"GCS NIO doesn't currently support appending to existing files. If you try, you will see this error:. ```; java.lang.UnsupportedOperationException: APPEND; ```. As you can see in [CloudStorageFileSystemProvider.java](https://github.com/GoogleCloudPlatform/google-cloud-java/blob/master/google-cloud-contrib/google-cloud-nio/src/main/java/com/google/cloud/storage/contrib/nio/CloudStorageFileSystemProvider.java#L351), the list of supported open options currently includes; - CREATE; - CREATE_NEW; - TRUNCATE_EXISTING; - WRITE; - SPARSE (ignored). Conceptually, GCS is designed to hold rarely-modified objects so append isn't a great fit, though it's not impossible.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4478#issuecomment-374346073
https://github.com/broadinstitute/gatk/issues/4479#issuecomment-369947491:137,Deployability,patch,patched,137,Possibly you are running into the Spark performance regression described in https://github.com/broadinstitute/gatk/issues/4376. This was patched in the latest release (4.0.2.0) -- could you try running with that release and see if the issue is resolved?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4479#issuecomment-369947491
https://github.com/broadinstitute/gatk/issues/4479#issuecomment-369947491:159,Deployability,release,release,159,Possibly you are running into the Spark performance regression described in https://github.com/broadinstitute/gatk/issues/4376. This was patched in the latest release (4.0.2.0) -- could you try running with that release and see if the issue is resolved?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4479#issuecomment-369947491
https://github.com/broadinstitute/gatk/issues/4479#issuecomment-369947491:212,Deployability,release,release,212,Possibly you are running into the Spark performance regression described in https://github.com/broadinstitute/gatk/issues/4376. This was patched in the latest release (4.0.2.0) -- could you try running with that release and see if the issue is resolved?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4479#issuecomment-369947491
https://github.com/broadinstitute/gatk/issues/4479#issuecomment-369947491:40,Performance,perform,performance,40,Possibly you are running into the Spark performance regression described in https://github.com/broadinstitute/gatk/issues/4376. This was patched in the latest release (4.0.2.0) -- could you try running with that release and see if the issue is resolved?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4479#issuecomment-369947491
https://github.com/broadinstitute/gatk/issues/4479#issuecomment-369994289:63,Deployability,deploy,deployed,63,"@droazen great! I faced this problem because I am using a self deployed Docker Swarm and so I was using a GATK version of few weeks ago. Sorry for opening an useful issue. For completeness, I used a VM with double of resources and it took 36,92 minutes, as predictable.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4479#issuecomment-369994289
https://github.com/broadinstitute/gatk/issues/4479#issuecomment-369994289:257,Safety,predict,predictable,257,"@droazen great! I faced this problem because I am using a self deployed Docker Swarm and so I was using a GATK version of few weeks ago. Sorry for opening an useful issue. For completeness, I used a VM with double of resources and it took 36,92 minutes, as predictable.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4479#issuecomment-369994289
https://github.com/broadinstitute/gatk/issues/4479#issuecomment-370001808:16,Usability,simpl,simply,16,"@droazen Yes, I simply re-cloned the GATK GitHub repository and executed `./gradlew bundle` as always. I used a 16 cores with 110 GB RAM VM",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4479#issuecomment-370001808
https://github.com/broadinstitute/gatk/issues/4480#issuecomment-369943177:114,Modifiability,refactor,refactor,114,This ties into the URI class design meeting we're having next week -- I'd say wait until then before starting any refactor of this part of the code.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4480#issuecomment-369943177
https://github.com/broadinstitute/gatk/issues/4481#issuecomment-369986160:555,Deployability,pipeline,pipeline,555,"Thanks for these suggestions, @sooheelee. Note that there's already an issue filed to add `@PG` tags at https://github.com/broadinstitute/gatk/issues/4117. As for the `@RG` tag, I was following the example of the SV team, which I saw introduced a custom RG ID (although this may only be used for tagging intermediate files---not sure?) Although not ideal, I think passing the sequence dictionary and sample name in this way allows us to reuse the relevant SAM header code and also prevents the possibility of users mixing up samples. (Recall that the old pipeline required the sample name to be passed in as a separate input to each tool and that no validation that each input came from the same sample was performed.). As for VCF output, we are also planning to add this to the ModelSegments pipeline (it is already in the gCNV pipeline). See https://github.com/broadinstitute/gatk/issues/4114. However, I think it makes sense for this to wait until the improved caller is in. I'll close this as a dupe for now, but we'll be able to reference your comments here from those issues in the future.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4481#issuecomment-369986160
https://github.com/broadinstitute/gatk/issues/4481#issuecomment-369986160:793,Deployability,pipeline,pipeline,793,"Thanks for these suggestions, @sooheelee. Note that there's already an issue filed to add `@PG` tags at https://github.com/broadinstitute/gatk/issues/4117. As for the `@RG` tag, I was following the example of the SV team, which I saw introduced a custom RG ID (although this may only be used for tagging intermediate files---not sure?) Although not ideal, I think passing the sequence dictionary and sample name in this way allows us to reuse the relevant SAM header code and also prevents the possibility of users mixing up samples. (Recall that the old pipeline required the sample name to be passed in as a separate input to each tool and that no validation that each input came from the same sample was performed.). As for VCF output, we are also planning to add this to the ModelSegments pipeline (it is already in the gCNV pipeline). See https://github.com/broadinstitute/gatk/issues/4114. However, I think it makes sense for this to wait until the improved caller is in. I'll close this as a dupe for now, but we'll be able to reference your comments here from those issues in the future.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4481#issuecomment-369986160
https://github.com/broadinstitute/gatk/issues/4481#issuecomment-369986160:829,Deployability,pipeline,pipeline,829,"Thanks for these suggestions, @sooheelee. Note that there's already an issue filed to add `@PG` tags at https://github.com/broadinstitute/gatk/issues/4117. As for the `@RG` tag, I was following the example of the SV team, which I saw introduced a custom RG ID (although this may only be used for tagging intermediate files---not sure?) Although not ideal, I think passing the sequence dictionary and sample name in this way allows us to reuse the relevant SAM header code and also prevents the possibility of users mixing up samples. (Recall that the old pipeline required the sample name to be passed in as a separate input to each tool and that no validation that each input came from the same sample was performed.). As for VCF output, we are also planning to add this to the ModelSegments pipeline (it is already in the gCNV pipeline). See https://github.com/broadinstitute/gatk/issues/4114. However, I think it makes sense for this to wait until the improved caller is in. I'll close this as a dupe for now, but we'll be able to reference your comments here from those issues in the future.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4481#issuecomment-369986160
https://github.com/broadinstitute/gatk/issues/4481#issuecomment-369986160:707,Performance,perform,performed,707,"Thanks for these suggestions, @sooheelee. Note that there's already an issue filed to add `@PG` tags at https://github.com/broadinstitute/gatk/issues/4117. As for the `@RG` tag, I was following the example of the SV team, which I saw introduced a custom RG ID (although this may only be used for tagging intermediate files---not sure?) Although not ideal, I think passing the sequence dictionary and sample name in this way allows us to reuse the relevant SAM header code and also prevents the possibility of users mixing up samples. (Recall that the old pipeline required the sample name to be passed in as a separate input to each tool and that no validation that each input came from the same sample was performed.). As for VCF output, we are also planning to add this to the ModelSegments pipeline (it is already in the gCNV pipeline). See https://github.com/broadinstitute/gatk/issues/4114. However, I think it makes sense for this to wait until the improved caller is in. I'll close this as a dupe for now, but we'll be able to reference your comments here from those issues in the future.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4481#issuecomment-369986160
https://github.com/broadinstitute/gatk/issues/4481#issuecomment-369986160:650,Security,validat,validation,650,"Thanks for these suggestions, @sooheelee. Note that there's already an issue filed to add `@PG` tags at https://github.com/broadinstitute/gatk/issues/4117. As for the `@RG` tag, I was following the example of the SV team, which I saw introduced a custom RG ID (although this may only be used for tagging intermediate files---not sure?) Although not ideal, I think passing the sequence dictionary and sample name in this way allows us to reuse the relevant SAM header code and also prevents the possibility of users mixing up samples. (Recall that the old pipeline required the sample name to be passed in as a separate input to each tool and that no validation that each input came from the same sample was performed.). As for VCF output, we are also planning to add this to the ModelSegments pipeline (it is already in the gCNV pipeline). See https://github.com/broadinstitute/gatk/issues/4114. However, I think it makes sense for this to wait until the improved caller is in. I'll close this as a dupe for now, but we'll be able to reference your comments here from those issues in the future.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4481#issuecomment-369986160
https://github.com/broadinstitute/gatk/issues/4487#issuecomment-398159225:48,Availability,error,error,48,"@jamesemery Hey James. Is it possible to add an error message stating that the user needs to set --TMP_DIR to a bigger disk? Another user posted ""It would be nice some warning about low disk space instead of crashing after running for so many hours.""",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4487#issuecomment-398159225
https://github.com/broadinstitute/gatk/issues/4487#issuecomment-398159225:54,Integrability,message,message,54,"@jamesemery Hey James. Is it possible to add an error message stating that the user needs to set --TMP_DIR to a bigger disk? Another user posted ""It would be nice some warning about low disk space instead of crashing after running for so many hours.""",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4487#issuecomment-398159225
https://github.com/broadinstitute/gatk/issues/4488#issuecomment-371403790:68,Deployability,pipeline,pipeline,68,@droazen Thanks. I use HaplotypeCaller and get the good results. my pipeline is :BwaAndMarkDuplicatesPipelineSpark-》BQSRPipelineSpark-》HaplotypeCaller.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4488#issuecomment-371403790
https://github.com/broadinstitute/gatk/issues/4488#issuecomment-371694170:66,Testability,test,tested,66,"@droazen . I have fixed the issue according Mr wangdy12 ' ways, I tested and the results is good . please reference A GATK4.0 Spark bug about HaplotypeCallerSpark and How to fix #4231 .",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4488#issuecomment-371694170
https://github.com/broadinstitute/gatk/issues/4488#issuecomment-426687487:137,Deployability,patch,patch,137,"@ggittu No, but we have plans to assign someone to work on `HaplotypeCallerSpark` this quarter. As part of this work, we'll consider the patch proposed by @lelqz",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4488#issuecomment-426687487
https://github.com/broadinstitute/gatk/issues/4488#issuecomment-426690366:100,Deployability,patch,patch,100,"@droazen That would be great, we are looking forward to it. And meanwhile, If I need to include the patch proposed by @lelqz what can I do? Is there any build that include that patch ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4488#issuecomment-426690366
https://github.com/broadinstitute/gatk/issues/4488#issuecomment-426690366:177,Deployability,patch,patch,177,"@droazen That would be great, we are looking forward to it. And meanwhile, If I need to include the patch proposed by @lelqz what can I do? Is there any build that include that patch ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4488#issuecomment-426690366
https://github.com/broadinstitute/gatk/issues/4488#issuecomment-426691478:92,Deployability,patch,patch,92,@ggittu We don't have such a build -- you could ask @lelqz if he has a fork/branch with his patch applied.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4488#issuecomment-426691478
https://github.com/broadinstitute/gatk/issues/4488#issuecomment-426693261:164,Deployability,patch,patch,164,"@droazen Thank you , and I appreciate your attention! Can we expect something by end of this month? Meanwhile, I will wait for @lelqz for a branch with the applied patch.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4488#issuecomment-426693261
https://github.com/broadinstitute/gatk/issues/4488#issuecomment-426694251:250,Deployability,patch,patch,250,"@ggittu Most likely not this month -- the effort to get `HaplotypeCallerSpark` out of beta will be starting up in November, and will be led by @jonn-smith, @jamesemery, and @tomwhite. It would be a good idea to remind one of them about this proposed patch via a github mention around November 1.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4488#issuecomment-426694251
https://github.com/broadinstitute/gatk/issues/4492#issuecomment-370504855:23,Safety,avoid,avoid,23,This might allow us to avoid the expensive final concatenation for outputs in Spark.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4492#issuecomment-370504855
https://github.com/broadinstitute/gatk/pull/4494#issuecomment-370527694:42,Testability,test,tests,42,:+1: seems reasonable to me -- merge when tests pass @lbergelson,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4494#issuecomment-370527694
https://github.com/broadinstitute/gatk/pull/4495#issuecomment-370539956:1282,Deployability,pipeline,pipelines,1282,sc) will **increase** coverage by `26.061%`.; > The diff coverage is `92.76%`. ```diff; @@ Coverage Diff @@; ## master #4495 +/- ##; ================================================; + Coverage 60.162% 86.223% +26.061% ; - Complexity 12772 28522 +15750 ; ================================================; Files 1095 1780 +685 ; Lines 64616 132279 +67663 ; Branches 10394 14733 +4339 ; ================================================; + Hits 38874 114055 +75181 ; + Misses 21504 12921 -8583 ; - Partials 4238 5303 +1065; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4495?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...s/walkers/variantutils/SelectVariantsUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/4495/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9TZWxlY3RWYXJpYW50c1VuaXRUZXN0LmphdmE=) | `100% <ø> (ø)` | `12 <0> (?)` | |; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4495/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `87.037% <0%> (ø)` | `17 <0> (ø)` | :arrow_down: |; | [...te/hellbender/engine/spark/VariantWalkerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4495/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvVmFyaWFudFdhbGtlclNwYXJrLmphdmE=) | `72.34% <0%> (-2.128%)` | `14 <0> (ø)` | |; | [...itute/hellbender/engine/spark/ReadWalkerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4495/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvUmVhZFdhbGtlclNwYXJrLmphdmE=) | `77.419% <0%> (ø)` | `10 <0> (ø)` | :arrow_down: |; | [...tools/spark/validation/CompareDuplicatesSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4495/diff?src=pr&el=tree#di,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4495#issuecomment-370539956
https://github.com/broadinstitute/gatk/pull/4495#issuecomment-370539956:2174,Security,validat,validation,2174,WxlY3RWYXJpYW50c1VuaXRUZXN0LmphdmE=) | `100% <ø> (ø)` | `12 <0> (?)` | |; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4495/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `87.037% <0%> (ø)` | `17 <0> (ø)` | :arrow_down: |; | [...te/hellbender/engine/spark/VariantWalkerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4495/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvVmFyaWFudFdhbGtlclNwYXJrLmphdmE=) | `72.34% <0%> (-2.128%)` | `14 <0> (ø)` | |; | [...itute/hellbender/engine/spark/ReadWalkerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4495/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvUmVhZFdhbGtlclNwYXJrLmphdmE=) | `77.419% <0%> (ø)` | `10 <0> (ø)` | :arrow_down: |; | [...tools/spark/validation/CompareDuplicatesSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4495/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay92YWxpZGF0aW9uL0NvbXBhcmVEdXBsaWNhdGVzU3BhcmsuamF2YQ==) | `84.946% <0%> (ø)` | `24 <0> (ø)` | :arrow_down: |; | [...tute/hellbender/engine/spark/LocusWalkerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4495/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvTG9jdXNXYWxrZXJTcGFyay5qYXZh) | `77.778% <0%> (ø)` | `12 <0> (ø)` | :arrow_down: |; | [...stitute/hellbender/tools/HaplotypeCallerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4495/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9IYXBsb3R5cGVDYWxsZXJTcGFyay5qYXZh) | `84% <0%> (+23%)` | `30 <0> (+14)` | :arrow_up: |; | [...ava/org/broadinstitute/hellbender/utils/Utils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4495/diff?src=pr&el=,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4495#issuecomment-370539956
https://github.com/broadinstitute/gatk/pull/4495#issuecomment-378318089:337,Modifiability,refactor,refactors,337,"@droazen and @cmnbroad: i completely understand that this is outside the main GATK dev cycle and priorities; however, do you have any guess as to when you might be able to review? I dont know how active development is, but I'd especially like to get that change in VariantWalker and MultiVariantWalker (which are currently really simple refactors) in before other development on them.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4495#issuecomment-378318089
https://github.com/broadinstitute/gatk/pull/4495#issuecomment-378318089:330,Usability,simpl,simple,330,"@droazen and @cmnbroad: i completely understand that this is outside the main GATK dev cycle and priorities; however, do you have any guess as to when you might be able to review? I dont know how active development is, but I'd especially like to get that change in VariantWalker and MultiVariantWalker (which are currently really simple refactors) in before other development on them.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4495#issuecomment-378318089
https://github.com/broadinstitute/gatk/pull/4495#issuecomment-379803776:133,Modifiability,inherit,inherit,133,"I havent published to github yet, pending getting these core changes in; however, the purpose is pretty simple: allow VariantEval to inherit from MultiVariantWalker, but not require it to include the required argument -V. this seemed comparable to VariantWalkerBase (no arguments), and VariantWalker (specifies -V). GATK3's VariantEval uses the --eval argument and I generally tried to keep everything in this port in sync with GATK3, within reason. If there is another way to subclasses to negate some @argument defined by a superclass this would work too. If you want to see more I'll push to github.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4495#issuecomment-379803776
https://github.com/broadinstitute/gatk/pull/4495#issuecomment-379803776:104,Usability,simpl,simple,104,"I havent published to github yet, pending getting these core changes in; however, the purpose is pretty simple: allow VariantEval to inherit from MultiVariantWalker, but not require it to include the required argument -V. this seemed comparable to VariantWalkerBase (no arguments), and VariantWalker (specifies -V). GATK3's VariantEval uses the --eval argument and I generally tried to keep everything in this port in sync with GATK3, within reason. If there is another way to subclasses to negate some @argument defined by a superclass this would work too. If you want to see more I'll push to github.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4495#issuecomment-379803776
https://github.com/broadinstitute/gatk/pull/4495#issuecomment-384687146:150,Safety,timeout,timeout,150,"ok, thanks. also - the travis build seems to have timed out. from the log i think that's just a travis CI issue, not due to my commit. is this travis timeout problem something you see frequently w/ GATK4?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4495#issuecomment-384687146
https://github.com/broadinstitute/gatk/pull/4495#issuecomment-384687146:70,Testability,log,log,70,"ok, thanks. also - the travis build seems to have timed out. from the log i think that's just a travis CI issue, not due to my commit. is this travis timeout problem something you see frequently w/ GATK4?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4495#issuecomment-384687146
https://github.com/broadinstitute/gatk/pull/4495#issuecomment-384694242:18,Safety,timeout,timeouts,18,"@bbimber Yes, the timeouts are not unusual. I restarted the (1 of the 8) jobs in the build matrix that failed on your PR. It will probably be fine, but I'll keep an eye on it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4495#issuecomment-384694242
https://github.com/broadinstitute/gatk/pull/4495#issuecomment-388127863:199,Availability,down,down,199,"@bbimber These changes look pretty good now except for a couple of things from the last round that didn't get done. I added new comments for those. Please make those changes, and also squash this PR down to single a commit, and rebase on current master. Thx.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4495#issuecomment-388127863
https://github.com/broadinstitute/gatk/pull/4495#issuecomment-397359678:970,Performance,Load,Load,970,"@bbimber There are still a lot of unaddressed comments from my review. Eg.,. https://github.com/broadinstitute/gatk/pull/4495#discussion_r189690850; https://github.com/broadinstitute/gatk/pull/4495#discussion_r189693827; https://github.com/broadinstitute/gatk/pull/4495#discussion_r189694685; https://github.com/broadinstitute/gatk/pull/4495#discussion_r189697161; https://github.com/broadinstitute/gatk/pull/4495#discussion_r193207051; https://github.com/broadinstitute/gatk/pull/4495#discussion_r195236794; https://github.com/broadinstitute/gatk/pull/4495#discussion_r195242052; https://github.com/broadinstitute/gatk/pull/4495#discussion_r195242436; https://github.com/broadinstitute/gatk/pull/4495#discussion_r195243668; https://github.com/broadinstitute/gatk/pull/4495#discussion_r195243837. You also missed a bunch of @cmnbroad 's comments from his earlier review. I'm guessing what's going on here is that you might not be expanding the `N Hidden Conversations...Load More` box that github inserts into the middle of the reviews to hide comments when there are more than a certain number of them?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4495#issuecomment-397359678
https://github.com/broadinstitute/gatk/pull/4495#issuecomment-404576289:80,Modifiability,refactor,refactor,80,"(As part of your final review @cmnbroad, you should open a ticket to eventually refactor the `MendelianViolation` class)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4495#issuecomment-404576289
https://github.com/broadinstitute/gatk/pull/4495#issuecomment-405675395:581,Energy Efficiency,efficient,efficient,581,"@cmnbroad - I rebased. as you'll see there are 2 spurious commits due to my earlier merge dealing w/ trunk conflicts; however, hopefully this is good enough. it will get squashed on the final merge. There's only 16 files touched and it seemed clean when i was trying to review it. Also: I have a local change staged that renamed hasIntervals() to hasUserSuppliedIntervals() and intervalsForTraversal to userIntervals (see @droazen comment above). I'm happy to add this now, though would be equally happy to close this and immediately open a separate PR to keep it cleaner and more efficient.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4495#issuecomment-405675395
https://github.com/broadinstitute/gatk/pull/4495#issuecomment-405699452:718,Availability,down,down,718,"@bbimber Thanks for rebasing (and point taken on the May 11 squash - we do sometimes ask for that to be done, we just generally try not to). I'm not sure what events lead to the 2 ""spurious"" commits, but they, as well as the extra ""correct bad merge"" commit, should be deleted. If we just squash them, the author attribution will be reflected incorrectly. It should be fairly easy to do (if you're accustomed to the command line, do: `git rebase -i HEAD~9`"", your editor will come up, just delete the 3 lines with those commits in your editor, and save). Feel free to also add the other (hasUserSuppliedIntervals) commit, since it should be part of this PR. I also wouldn't be opposed to you just squashing everything down to one commit at that point - up to you. Then I'll do what is hopefully the final pass to make sure we covered everything.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4495#issuecomment-405699452
https://github.com/broadinstitute/gatk/pull/4495#issuecomment-405703909:75,Availability,error,errors,75,"interesting - ok, that's done. and yes, the spurious commits are basically errors learning git rebase. hopefully this covers everything. the change in hasUserSuppliedIntervals() touched a lot of files, but it's a pretty trivial change in them.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4495#issuecomment-405703909
https://github.com/broadinstitute/gatk/pull/4495#issuecomment-405703909:82,Usability,learn,learning,82,"interesting - ok, that's done. and yes, the spurious commits are basically errors learning git rebase. hopefully this covers everything. the change in hasUserSuppliedIntervals() touched a lot of files, but it's a pretty trivial change in them.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4495#issuecomment-405703909
https://github.com/broadinstitute/gatk/pull/4496#issuecomment-371366878:62,Deployability,update,update,62,"Sorry if this is not the right place to ask, but is there any update on GenomicsDBImport being able to run on multiple intervals? I couldn't find an issue for this in the tracker. We have a lot of users for whom it's a deal-breaker.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4496#issuecomment-371366878
https://github.com/broadinstitute/gatk/pull/4496#issuecomment-377369275:2120,Testability,test,test,2120,i9lbmdpbmUvRmVhdHVyZURhdGFTb3VyY2UuamF2YQ==) | `76.871% <100%> (+0.482%)` | `45 <0> (ø)` | :arrow_down: |; | [...ellbender/engine/filters/VariantFilterLibrary.java](https://codecov.io/gh/broadinstitute/gatk/pull/4496/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZmlsdGVycy9WYXJpYW50RmlsdGVyTGlicmFyeS5qYXZh) | `33.333% <0%> (-16.667%)` | `1% <0%> (ø)` | |; | [...stitute/hellbender/engine/ReferenceDataSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4496/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUmVmZXJlbmNlRGF0YVNvdXJjZS5qYXZh) | `70% <0%> (-10%)` | `7% <0%> (+3%)` | |; | [...stitute/hellbender/engine/ReferenceFileSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4496/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUmVmZXJlbmNlRmlsZVNvdXJjZS5qYXZh) | `65.217% <0%> (-7.51%)` | `8% <0%> (+4%)` | |; | [...titute/hellbender/utils/test/ArgumentsBuilder.java](https://codecov.io/gh/broadinstitute/gatk/pull/4496/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0FyZ3VtZW50c0J1aWxkZXIuamF2YQ==) | `93.151% <0%> (-6.849%)` | `31% <0%> (+12%)` | |; | [.../tools/copynumber/gcnv/IntegerCopyNumberState.java](https://codecov.io/gh/broadinstitute/gatk/pull/4496/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2djbnYvSW50ZWdlckNvcHlOdW1iZXJTdGF0ZS5qYXZh) | `69.231% <0%> (-2.991%)` | `14% <0%> (+4%)` | |; | [...rmats/collections/AbstractLocatableCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/4496/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2Zvcm1hdHMvY29sbGVjdGlvbnMvQWJzdHJhY3RMb2NhdGFibGVDb2xsZWN0aW9uLmphdmE=) | `98.077% <0%> (-1.923%)` | `20% <0%> (+12%)` | |; | [...tools/funcotator/dataSources/TableFuncotation.java](https://codecov.io/gh/bro,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4496#issuecomment-377369275
https://github.com/broadinstitute/gatk/pull/4496#issuecomment-377613909:266,Testability,test,tests,266,"I commented on the issue (#3688) -- I'm happy with the output and the speedup. @droazen do you want to merge this as-is with the feature effectively hidden? I guess it will effectively get hooked up when the protobuf changes go in, at which point it should get some tests.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4496#issuecomment-377613909
https://github.com/broadinstitute/gatk/pull/4497#issuecomment-370585617:2246,Usability,Simpl,SimpleNovelAdjacencyInterpreter,2246,CpxVariantDetector.java](https://codecov.io/gh/broadinstitute/gatk/pull/4497/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvaW5mZXJlbmNlL0NweFZhcmlhbnREZXRlY3Rvci5qYXZh) | `1.835% <0%> (-0.804%)` | `2% <0%> (ø)` | |; | [...pleNovelAdjacencyAndChimericAlignmentEvidence.java](https://codecov.io/gh/broadinstitute/gatk/pull/4497/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvaW5mZXJlbmNlL1NpbXBsZU5vdmVsQWRqYWNlbmN5QW5kQ2hpbWVyaWNBbGlnbm1lbnRFdmlkZW5jZS5qYXZh) | `28% <0%> (-0.125%)` | `8% <0%> (+3%)` | |; | [...s/spark/sv/discovery/AnnotatedVariantProducer.java](https://codecov.io/gh/broadinstitute/gatk/pull/4497/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvQW5ub3RhdGVkVmFyaWFudFByb2R1Y2VyLmphdmE=) | `76.471% <0%> (ø)` | `31% <0%> (+8%)` | :arrow_up: |; | [...ery/inference/SimpleNovelAdjacencyInterpreter.java](https://codecov.io/gh/broadinstitute/gatk/pull/4497/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9kaXNjb3ZlcnkvaW5mZXJlbmNlL1NpbXBsZU5vdmVsQWRqYWNlbmN5SW50ZXJwcmV0ZXIuamF2YQ==) | `100% <0%> (ø)` | `8% <0%> (+1%)` | :arrow_up: |; | [...bender/tools/walkers/annotator/StrandArtifact.java](https://codecov.io/gh/broadinstitute/gatk/pull/4497/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9TdHJhbmRBcnRpZmFjdC5qYXZh) | `100% <0%> (ø)` | `42% <0%> (+12%)` | :arrow_up: |; | [.../tools/copynumber/denoising/SVDDenoisingUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4497/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2Rlbm9pc2luZy9TVkREZW5vaXNpbmdVdGlscy5qYXZh) | `79.92% <0%> (+0.521%)` | `51% <0%> (+4%)` | :arrow_up: |; | [...lbender/utils/variant/GATKVariantContextUtils.jav,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4497#issuecomment-370585617
https://github.com/broadinstitute/gatk/pull/4497#issuecomment-370811446:77,Testability,assert,assertions,77,@ldgauthier Thanks for the feedback -- I'll see if I can add some additional assertions about the actual alleles retained at each site that had more than the maximum.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4497#issuecomment-370811446
https://github.com/broadinstitute/gatk/pull/4497#issuecomment-370811446:27,Usability,feedback,feedback,27,@ldgauthier Thanks for the feedback -- I'll see if I can add some additional assertions about the actual alleles retained at each site that had more than the maximum.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4497#issuecomment-370811446
https://github.com/broadinstitute/gatk/pull/4497#issuecomment-371612858:66,Testability,assert,assertions,66,"@ldgauthier Ok, I've addressed your comments by adding some extra assertions about the alleles and genotypes post-allele-subsetting. Ready for another look!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4497#issuecomment-371612858
https://github.com/broadinstitute/gatk/pull/4498#issuecomment-370663327:4649,Deployability,update,update,4649,"WRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9ldmlkZW5jZS9FdmlkZW5jZVRhcmdldExpbmsuamF2YQ==) | `70.51% <0%> (-4.12%)` | `18% <0%> (+2%)` | |; | [...ools/copynumber/CreateReadCountPanelOfNormals.java](https://codecov.io/gh/broadinstitute/gatk/pull/4498/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL0NyZWF0ZVJlYWRDb3VudFBhbmVsT2ZOb3JtYWxzLmphdmE=) | `86.07% <0%> (-3.93%)` | `11% <0%> (+2%)` | |; | [...er/tools/copynumber/formats/records/CopyRatio.java](https://codecov.io/gh/broadinstitute/gatk/pull/4498/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2Zvcm1hdHMvcmVjb3Jkcy9Db3B5UmF0aW8uamF2YQ==) | `74.35% <0%> (-1.65%)` | `17% <0%> (+8%)` | |; | [...ellbender/tools/walkers/annotator/QualByDepth.java](https://codecov.io/gh/broadinstitute/gatk/pull/4498/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9RdWFsQnlEZXB0aC5qYXZh) | `95.74% <0%> (-1.56%)` | `20% <0%> (+3%)` | |; | [.../main/java/org/broadinstitute/hellbender/Main.java](https://codecov.io/gh/broadinstitute/gatk/pull/4498/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9NYWluLmphdmE=) | `70.62% <0%> (-1.32%)` | `71% <0%> (+26%)` | |; | ... and [170 more](https://codecov.io/gh/broadinstitute/gatk/pull/4498/diff?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4498?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4498?src=pr&el=footer). Last update [9eb1704...ff52e6b](https://codecov.io/gh/broadinstitute/gatk/pull/4498?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4498#issuecomment-370663327
https://github.com/broadinstitute/gatk/pull/4498#issuecomment-370663327:4552,Energy Efficiency,Power,Powered,4552,"WRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9ldmlkZW5jZS9FdmlkZW5jZVRhcmdldExpbmsuamF2YQ==) | `70.51% <0%> (-4.12%)` | `18% <0%> (+2%)` | |; | [...ools/copynumber/CreateReadCountPanelOfNormals.java](https://codecov.io/gh/broadinstitute/gatk/pull/4498/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL0NyZWF0ZVJlYWRDb3VudFBhbmVsT2ZOb3JtYWxzLmphdmE=) | `86.07% <0%> (-3.93%)` | `11% <0%> (+2%)` | |; | [...er/tools/copynumber/formats/records/CopyRatio.java](https://codecov.io/gh/broadinstitute/gatk/pull/4498/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2Zvcm1hdHMvcmVjb3Jkcy9Db3B5UmF0aW8uamF2YQ==) | `74.35% <0%> (-1.65%)` | `17% <0%> (+8%)` | |; | [...ellbender/tools/walkers/annotator/QualByDepth.java](https://codecov.io/gh/broadinstitute/gatk/pull/4498/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9RdWFsQnlEZXB0aC5qYXZh) | `95.74% <0%> (-1.56%)` | `20% <0%> (+3%)` | |; | [.../main/java/org/broadinstitute/hellbender/Main.java](https://codecov.io/gh/broadinstitute/gatk/pull/4498/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9NYWluLmphdmE=) | `70.62% <0%> (-1.32%)` | `71% <0%> (+26%)` | |; | ... and [170 more](https://codecov.io/gh/broadinstitute/gatk/pull/4498/diff?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4498?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4498?src=pr&el=footer). Last update [9eb1704...ff52e6b](https://codecov.io/gh/broadinstitute/gatk/pull/4498?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4498#issuecomment-370663327
https://github.com/broadinstitute/gatk/pull/4498#issuecomment-370663327:4415,Usability,learn,learn,4415,"WRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9ldmlkZW5jZS9FdmlkZW5jZVRhcmdldExpbmsuamF2YQ==) | `70.51% <0%> (-4.12%)` | `18% <0%> (+2%)` | |; | [...ools/copynumber/CreateReadCountPanelOfNormals.java](https://codecov.io/gh/broadinstitute/gatk/pull/4498/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL0NyZWF0ZVJlYWRDb3VudFBhbmVsT2ZOb3JtYWxzLmphdmE=) | `86.07% <0%> (-3.93%)` | `11% <0%> (+2%)` | |; | [...er/tools/copynumber/formats/records/CopyRatio.java](https://codecov.io/gh/broadinstitute/gatk/pull/4498/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2Zvcm1hdHMvcmVjb3Jkcy9Db3B5UmF0aW8uamF2YQ==) | `74.35% <0%> (-1.65%)` | `17% <0%> (+8%)` | |; | [...ellbender/tools/walkers/annotator/QualByDepth.java](https://codecov.io/gh/broadinstitute/gatk/pull/4498/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9RdWFsQnlEZXB0aC5qYXZh) | `95.74% <0%> (-1.56%)` | `20% <0%> (+3%)` | |; | [.../main/java/org/broadinstitute/hellbender/Main.java](https://codecov.io/gh/broadinstitute/gatk/pull/4498/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9NYWluLmphdmE=) | `70.62% <0%> (-1.32%)` | `71% <0%> (+26%)` | |; | ... and [170 more](https://codecov.io/gh/broadinstitute/gatk/pull/4498/diff?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4498?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4498?src=pr&el=footer). Last update [9eb1704...ff52e6b](https://codecov.io/gh/broadinstitute/gatk/pull/4498?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4498#issuecomment-370663327
https://github.com/broadinstitute/gatk/issues/4499#issuecomment-370886468:24,Integrability,message,message,24,Also note a typo in the message output.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4499#issuecomment-370886468
https://github.com/broadinstitute/gatk/pull/4501#issuecomment-371539936:6,Testability,log,logging,6,added logging output to the bam writing step for spark tools (#4501),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4501#issuecomment-371539936
https://github.com/broadinstitute/gatk/pull/4502#issuecomment-377926782:37,Deployability,release,release,37,@mbabadi Can we get this in the next release? Should be quick.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4502#issuecomment-377926782
https://github.com/broadinstitute/gatk/pull/4502#issuecomment-378678755:59,Testability,test,tests,59,"Thanks @mbabadi and @mwalker174! Rebased, will merge after tests pass.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4502#issuecomment-378678755
https://github.com/broadinstitute/gatk/pull/4503#issuecomment-377926776:37,Deployability,release,release,37,@mbabadi Can we get this in the next release? Should be quick.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4503#issuecomment-377926776
https://github.com/broadinstitute/gatk/issues/4504#issuecomment-371144113:681,Availability,error,error,681,"@stefandiederich, I think this is a problem with how your BED file is being interpreted. In general, with GATK, it's best to use 1-based coordinates intervals, e.g. that of a [Picard-style interval_list](https://gatkforums.broadinstitute.org/gatk/discussion/1319/collected-faqs-about-interval-lists). BED is 0-based. See https://www.biostars.org/p/84686/ for a clear illustration of the differences. . If provided a BED file, i.e. an intervals list with `.bed` extension, GATK will convert it to the expected 1-based format. So, if `chr2 29430911 29430911` is 0-based BED, then conversion to 1-based would yield `chr2 29430912 29430911`, making the stop less than the start as the error message says. . It seems though that your intervals are actually already 1-based, not 0-based (which the BED format implies). Make sure your coordinates are expected and try changing the file extension.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4504#issuecomment-371144113
https://github.com/broadinstitute/gatk/issues/4504#issuecomment-371144113:687,Integrability,message,message,687,"@stefandiederich, I think this is a problem with how your BED file is being interpreted. In general, with GATK, it's best to use 1-based coordinates intervals, e.g. that of a [Picard-style interval_list](https://gatkforums.broadinstitute.org/gatk/discussion/1319/collected-faqs-about-interval-lists). BED is 0-based. See https://www.biostars.org/p/84686/ for a clear illustration of the differences. . If provided a BED file, i.e. an intervals list with `.bed` extension, GATK will convert it to the expected 1-based format. So, if `chr2 29430911 29430911` is 0-based BED, then conversion to 1-based would yield `chr2 29430912 29430911`, making the stop less than the start as the error message says. . It seems though that your intervals are actually already 1-based, not 0-based (which the BED format implies). Make sure your coordinates are expected and try changing the file extension.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4504#issuecomment-371144113
https://github.com/broadinstitute/gatk/issues/4504#issuecomment-371144113:361,Usability,clear,clear,361,"@stefandiederich, I think this is a problem with how your BED file is being interpreted. In general, with GATK, it's best to use 1-based coordinates intervals, e.g. that of a [Picard-style interval_list](https://gatkforums.broadinstitute.org/gatk/discussion/1319/collected-faqs-about-interval-lists). BED is 0-based. See https://www.biostars.org/p/84686/ for a clear illustration of the differences. . If provided a BED file, i.e. an intervals list with `.bed` extension, GATK will convert it to the expected 1-based format. So, if `chr2 29430911 29430911` is 0-based BED, then conversion to 1-based would yield `chr2 29430912 29430911`, making the stop less than the start as the error message says. . It seems though that your intervals are actually already 1-based, not 0-based (which the BED format implies). Make sure your coordinates are expected and try changing the file extension.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4504#issuecomment-371144113
https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371224015:345,Integrability,depend,depends,345,"@jjfarrell You don't need splitting index for cram. The index works around a bam specific problem which makes it hard to find good split points in the file. Cram is designed in a way that makes it easier to find the split points so the index is unnecessary. . I don't have good numbers for how long it takes to find the split points for bam. It depends on your filesystem. If you have a low latency file system like a local disk or hdfs setup than finding split points takes very little time (~seconds), but if you have a high latency file system like something backed by google object store then finding split points may take a long time (on the order of minutes to tens of minutes depending on latency and file size).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371224015
https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371224015:683,Integrability,depend,depending,683,"@jjfarrell You don't need splitting index for cram. The index works around a bam specific problem which makes it hard to find good split points in the file. Cram is designed in a way that makes it easier to find the split points so the index is unnecessary. . I don't have good numbers for how long it takes to find the split points for bam. It depends on your filesystem. If you have a low latency file system like a local disk or hdfs setup than finding split points takes very little time (~seconds), but if you have a high latency file system like something backed by google object store then finding split points may take a long time (on the order of minutes to tens of minutes depending on latency and file size).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371224015
https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371224015:391,Performance,latency,latency,391,"@jjfarrell You don't need splitting index for cram. The index works around a bam specific problem which makes it hard to find good split points in the file. Cram is designed in a way that makes it easier to find the split points so the index is unnecessary. . I don't have good numbers for how long it takes to find the split points for bam. It depends on your filesystem. If you have a low latency file system like a local disk or hdfs setup than finding split points takes very little time (~seconds), but if you have a high latency file system like something backed by google object store then finding split points may take a long time (on the order of minutes to tens of minutes depending on latency and file size).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371224015
https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371224015:527,Performance,latency,latency,527,"@jjfarrell You don't need splitting index for cram. The index works around a bam specific problem which makes it hard to find good split points in the file. Cram is designed in a way that makes it easier to find the split points so the index is unnecessary. . I don't have good numbers for how long it takes to find the split points for bam. It depends on your filesystem. If you have a low latency file system like a local disk or hdfs setup than finding split points takes very little time (~seconds), but if you have a high latency file system like something backed by google object store then finding split points may take a long time (on the order of minutes to tens of minutes depending on latency and file size).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371224015
https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371224015:696,Performance,latency,latency,696,"@jjfarrell You don't need splitting index for cram. The index works around a bam specific problem which makes it hard to find good split points in the file. Cram is designed in a way that makes it easier to find the split points so the index is unnecessary. . I don't have good numbers for how long it takes to find the split points for bam. It depends on your filesystem. If you have a low latency file system like a local disk or hdfs setup than finding split points takes very little time (~seconds), but if you have a high latency file system like something backed by google object store then finding split points may take a long time (on the order of minutes to tens of minutes depending on latency and file size).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371224015
https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371280304:1845,Energy Efficiency,schedul,scheduler,1845,"u.edu, 42456, None); 18/03/07 13:24:27 INFO memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 247.0 KB, free 8.4 GB); 18/03/07 13:24:28 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 25.5 KB, free 8.4 GB); 18/03/07 13:24:28 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.48.225.55:32895 (size: 25.5 KB, free: 8.4 GB); 18/03/07 13:24:28 INFO spark.SparkContext: Created broadcast 0 from newAPIHadoopFile at ReadsSparkSource.java:112; 18/03/07 13:24:28 INFO hdfs.DFSClient: Created HDFS_DELEGATION_TOKEN token 7164 for farrell on ha-hdfs:scc; 18/03/07 13:24:28 INFO security.TokenCache: Got dt for hdfs://scc; Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:scc, Ident: (HDFS_DELEGATION_TOKEN token 7164 for farrell); 18/03/07 13:24:28 INFO input.FileInputFormat: Total input paths to process : 1; 18/03/07 13:59:26 INFO spark.SparkContext: Starting job: aggregate at FlagStatSpark.java:73; 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Got job 0 (aggregate at FlagStatSpark.java:73) with 252 output partitions; 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (aggregate at FlagStatSpark.java:73); 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Parents of final stage: List(); 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Missing parents: List(); 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at filter at GATKSparkTool.java:220), which has no missing parents; 18/03/07 13:59:26 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 1148.4 KB, free 8.4 GB); 18/03/07 13:59:26 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 345.8 KB, free 8.4 GB); 18/03/07 13:59:26 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.48.225.55:32895 (size: 345.8 KB, free: 8.4 GB); 18/03/07 13:59:26 INFO spark.SparkContext: Created broadcast 1 fr",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371280304
https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371280304:1967,Energy Efficiency,schedul,scheduler,1967," (estimated size 247.0 KB, free 8.4 GB); 18/03/07 13:24:28 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 25.5 KB, free 8.4 GB); 18/03/07 13:24:28 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.48.225.55:32895 (size: 25.5 KB, free: 8.4 GB); 18/03/07 13:24:28 INFO spark.SparkContext: Created broadcast 0 from newAPIHadoopFile at ReadsSparkSource.java:112; 18/03/07 13:24:28 INFO hdfs.DFSClient: Created HDFS_DELEGATION_TOKEN token 7164 for farrell on ha-hdfs:scc; 18/03/07 13:24:28 INFO security.TokenCache: Got dt for hdfs://scc; Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:scc, Ident: (HDFS_DELEGATION_TOKEN token 7164 for farrell); 18/03/07 13:24:28 INFO input.FileInputFormat: Total input paths to process : 1; 18/03/07 13:59:26 INFO spark.SparkContext: Starting job: aggregate at FlagStatSpark.java:73; 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Got job 0 (aggregate at FlagStatSpark.java:73) with 252 output partitions; 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (aggregate at FlagStatSpark.java:73); 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Parents of final stage: List(); 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Missing parents: List(); 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at filter at GATKSparkTool.java:220), which has no missing parents; 18/03/07 13:59:26 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 1148.4 KB, free 8.4 GB); 18/03/07 13:59:26 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 345.8 KB, free 8.4 GB); 18/03/07 13:59:26 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.48.225.55:32895 (size: 345.8 KB, free: 8.4 GB); 18/03/07 13:59:26 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:996; 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Submitting 252 missin",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371280304
https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371280304:2079,Energy Efficiency,schedul,scheduler,2079,"in memory (estimated size 25.5 KB, free 8.4 GB); 18/03/07 13:24:28 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.48.225.55:32895 (size: 25.5 KB, free: 8.4 GB); 18/03/07 13:24:28 INFO spark.SparkContext: Created broadcast 0 from newAPIHadoopFile at ReadsSparkSource.java:112; 18/03/07 13:24:28 INFO hdfs.DFSClient: Created HDFS_DELEGATION_TOKEN token 7164 for farrell on ha-hdfs:scc; 18/03/07 13:24:28 INFO security.TokenCache: Got dt for hdfs://scc; Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:scc, Ident: (HDFS_DELEGATION_TOKEN token 7164 for farrell); 18/03/07 13:24:28 INFO input.FileInputFormat: Total input paths to process : 1; 18/03/07 13:59:26 INFO spark.SparkContext: Starting job: aggregate at FlagStatSpark.java:73; 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Got job 0 (aggregate at FlagStatSpark.java:73) with 252 output partitions; 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (aggregate at FlagStatSpark.java:73); 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Parents of final stage: List(); 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Missing parents: List(); 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at filter at GATKSparkTool.java:220), which has no missing parents; 18/03/07 13:59:26 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 1148.4 KB, free 8.4 GB); 18/03/07 13:59:26 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 345.8 KB, free 8.4 GB); 18/03/07 13:59:26 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.48.225.55:32895 (size: 345.8 KB, free: 8.4 GB); 18/03/07 13:59:26 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:996; 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Submitting 252 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at filter at GATKSparkTool.java:220); 18/03/07 13:59:26 INFO cluster.YarnSched",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371280304
https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371280304:2158,Energy Efficiency,schedul,scheduler,2158,"24:28 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.48.225.55:32895 (size: 25.5 KB, free: 8.4 GB); 18/03/07 13:24:28 INFO spark.SparkContext: Created broadcast 0 from newAPIHadoopFile at ReadsSparkSource.java:112; 18/03/07 13:24:28 INFO hdfs.DFSClient: Created HDFS_DELEGATION_TOKEN token 7164 for farrell on ha-hdfs:scc; 18/03/07 13:24:28 INFO security.TokenCache: Got dt for hdfs://scc; Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:scc, Ident: (HDFS_DELEGATION_TOKEN token 7164 for farrell); 18/03/07 13:24:28 INFO input.FileInputFormat: Total input paths to process : 1; 18/03/07 13:59:26 INFO spark.SparkContext: Starting job: aggregate at FlagStatSpark.java:73; 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Got job 0 (aggregate at FlagStatSpark.java:73) with 252 output partitions; 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (aggregate at FlagStatSpark.java:73); 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Parents of final stage: List(); 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Missing parents: List(); 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at filter at GATKSparkTool.java:220), which has no missing parents; 18/03/07 13:59:26 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 1148.4 KB, free 8.4 GB); 18/03/07 13:59:26 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 345.8 KB, free 8.4 GB); 18/03/07 13:59:26 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.48.225.55:32895 (size: 345.8 KB, free: 8.4 GB); 18/03/07 13:59:26 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:996; 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Submitting 252 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at filter at GATKSparkTool.java:220); 18/03/07 13:59:26 INFO cluster.YarnScheduler: Adding task set 0.0 with 252 tasks; 18/03/07 13:59:26 I",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371280304
https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371280304:2230,Energy Efficiency,schedul,scheduler,2230,"0.48.225.55:32895 (size: 25.5 KB, free: 8.4 GB); 18/03/07 13:24:28 INFO spark.SparkContext: Created broadcast 0 from newAPIHadoopFile at ReadsSparkSource.java:112; 18/03/07 13:24:28 INFO hdfs.DFSClient: Created HDFS_DELEGATION_TOKEN token 7164 for farrell on ha-hdfs:scc; 18/03/07 13:24:28 INFO security.TokenCache: Got dt for hdfs://scc; Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:scc, Ident: (HDFS_DELEGATION_TOKEN token 7164 for farrell); 18/03/07 13:24:28 INFO input.FileInputFormat: Total input paths to process : 1; 18/03/07 13:59:26 INFO spark.SparkContext: Starting job: aggregate at FlagStatSpark.java:73; 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Got job 0 (aggregate at FlagStatSpark.java:73) with 252 output partitions; 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (aggregate at FlagStatSpark.java:73); 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Parents of final stage: List(); 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Missing parents: List(); 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at filter at GATKSparkTool.java:220), which has no missing parents; 18/03/07 13:59:26 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 1148.4 KB, free 8.4 GB); 18/03/07 13:59:26 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 345.8 KB, free 8.4 GB); 18/03/07 13:59:26 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.48.225.55:32895 (size: 345.8 KB, free: 8.4 GB); 18/03/07 13:59:26 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:996; 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Submitting 252 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at filter at GATKSparkTool.java:220); 18/03/07 13:59:26 INFO cluster.YarnScheduler: Adding task set 0.0 with 252 tasks; 18/03/07 13:59:26 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 0.0 (TID 0, scc-q0",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371280304
https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371280304:2897,Energy Efficiency,schedul,scheduler,2897,"gate at FlagStatSpark.java:73) with 252 output partitions; 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (aggregate at FlagStatSpark.java:73); 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Parents of final stage: List(); 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Missing parents: List(); 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at filter at GATKSparkTool.java:220), which has no missing parents; 18/03/07 13:59:26 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 1148.4 KB, free 8.4 GB); 18/03/07 13:59:26 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 345.8 KB, free 8.4 GB); 18/03/07 13:59:26 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.48.225.55:32895 (size: 345.8 KB, free: 8.4 GB); 18/03/07 13:59:26 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:996; 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Submitting 252 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at filter at GATKSparkTool.java:220); 18/03/07 13:59:26 INFO cluster.YarnScheduler: Adding task set 0.0 with 252 tasks; 18/03/07 13:59:26 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 0.0 (TID 0, scc-q05.scc.bu.edu, executor 4, partition 2, NODE_LOCAL, 6147 bytes); 18/03/07 13:59:26 INFO scheduler.TaskSetManager: Starting task 25.0 in stage 0.0 (TID 1, scc-q10.scc.bu.edu, executor 3, partition 25, NODE_LOCAL, 6147 bytes); 18/03/07 13:59:26 INFO scheduler.TaskSetManager: Starting task 15.0 in stage 0.0 (TID 2, scc-q07.scc.bu.edu, executor 1, partition 15, NODE_LOCAL, 6147 bytes); 18/03/07 13:59:26 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 0.0 (TID 3, scc-q16.scc.bu.edu, executor 8, partition 4, NODE_LOCAL, 6147 bytes); 18/03/07 13:59:26 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 0.0 (TID 4, scc-q14.scc.bu.edu, executor 2, partition 3, NODE_L",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371280304
https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371280304:3133,Energy Efficiency,schedul,scheduler,3133,"java:73) with 252 output partitions; 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (aggregate at FlagStatSpark.java:73); 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Parents of final stage: List(); 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Missing parents: List(); 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at filter at GATKSparkTool.java:220), which has no missing parents; 18/03/07 13:59:26 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 1148.4 KB, free 8.4 GB); 18/03/07 13:59:26 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 345.8 KB, free 8.4 GB); 18/03/07 13:59:26 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.48.225.55:32895 (size: 345.8 KB, free: 8.4 GB); 18/03/07 13:59:26 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:996; 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Submitting 252 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at filter at GATKSparkTool.java:220); 18/03/07 13:59:26 INFO cluster.YarnScheduler: Adding task set 0.0 with 252 tasks; 18/03/07 13:59:26 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 0.0 (TID 0, scc-q05.scc.bu.edu, executor 4, partition 2, NODE_LOCAL, 6147 bytes); 18/03/07 13:59:26 INFO scheduler.TaskSetManager: Starting task 25.0 in stage 0.0 (TID 1, scc-q10.scc.bu.edu, executor 3, partition 25, NODE_LOCAL, 6147 bytes); 18/03/07 13:59:26 INFO scheduler.TaskSetManager: Starting task 15.0 in stage 0.0 (TID 2, scc-q07.scc.bu.edu, executor 1, partition 15, NODE_LOCAL, 6147 bytes); 18/03/07 13:59:26 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 0.0 (TID 3, scc-q16.scc.bu.edu, executor 8, partition 4, NODE_LOCAL, 6147 bytes); 18/03/07 13:59:26 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 0.0 (TID 4, scc-q14.scc.bu.edu, executor 2, partition 3, NODE_LOCAL, 6147 bytes). ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371280304
https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371280304:3291,Energy Efficiency,schedul,scheduler,3291,"java:73) with 252 output partitions; 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (aggregate at FlagStatSpark.java:73); 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Parents of final stage: List(); 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Missing parents: List(); 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at filter at GATKSparkTool.java:220), which has no missing parents; 18/03/07 13:59:26 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 1148.4 KB, free 8.4 GB); 18/03/07 13:59:26 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 345.8 KB, free 8.4 GB); 18/03/07 13:59:26 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.48.225.55:32895 (size: 345.8 KB, free: 8.4 GB); 18/03/07 13:59:26 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:996; 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Submitting 252 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at filter at GATKSparkTool.java:220); 18/03/07 13:59:26 INFO cluster.YarnScheduler: Adding task set 0.0 with 252 tasks; 18/03/07 13:59:26 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 0.0 (TID 0, scc-q05.scc.bu.edu, executor 4, partition 2, NODE_LOCAL, 6147 bytes); 18/03/07 13:59:26 INFO scheduler.TaskSetManager: Starting task 25.0 in stage 0.0 (TID 1, scc-q10.scc.bu.edu, executor 3, partition 25, NODE_LOCAL, 6147 bytes); 18/03/07 13:59:26 INFO scheduler.TaskSetManager: Starting task 15.0 in stage 0.0 (TID 2, scc-q07.scc.bu.edu, executor 1, partition 15, NODE_LOCAL, 6147 bytes); 18/03/07 13:59:26 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 0.0 (TID 3, scc-q16.scc.bu.edu, executor 8, partition 4, NODE_LOCAL, 6147 bytes); 18/03/07 13:59:26 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 0.0 (TID 4, scc-q14.scc.bu.edu, executor 2, partition 3, NODE_LOCAL, 6147 bytes). ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371280304
https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371280304:3451,Energy Efficiency,schedul,scheduler,3451,"java:73) with 252 output partitions; 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (aggregate at FlagStatSpark.java:73); 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Parents of final stage: List(); 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Missing parents: List(); 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at filter at GATKSparkTool.java:220), which has no missing parents; 18/03/07 13:59:26 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 1148.4 KB, free 8.4 GB); 18/03/07 13:59:26 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 345.8 KB, free 8.4 GB); 18/03/07 13:59:26 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.48.225.55:32895 (size: 345.8 KB, free: 8.4 GB); 18/03/07 13:59:26 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:996; 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Submitting 252 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at filter at GATKSparkTool.java:220); 18/03/07 13:59:26 INFO cluster.YarnScheduler: Adding task set 0.0 with 252 tasks; 18/03/07 13:59:26 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 0.0 (TID 0, scc-q05.scc.bu.edu, executor 4, partition 2, NODE_LOCAL, 6147 bytes); 18/03/07 13:59:26 INFO scheduler.TaskSetManager: Starting task 25.0 in stage 0.0 (TID 1, scc-q10.scc.bu.edu, executor 3, partition 25, NODE_LOCAL, 6147 bytes); 18/03/07 13:59:26 INFO scheduler.TaskSetManager: Starting task 15.0 in stage 0.0 (TID 2, scc-q07.scc.bu.edu, executor 1, partition 15, NODE_LOCAL, 6147 bytes); 18/03/07 13:59:26 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 0.0 (TID 3, scc-q16.scc.bu.edu, executor 8, partition 4, NODE_LOCAL, 6147 bytes); 18/03/07 13:59:26 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 0.0 (TID 4, scc-q14.scc.bu.edu, executor 2, partition 3, NODE_LOCAL, 6147 bytes). ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371280304
https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371280304:3611,Energy Efficiency,schedul,scheduler,3611,"java:73) with 252 output partitions; 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (aggregate at FlagStatSpark.java:73); 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Parents of final stage: List(); 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Missing parents: List(); 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at filter at GATKSparkTool.java:220), which has no missing parents; 18/03/07 13:59:26 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 1148.4 KB, free 8.4 GB); 18/03/07 13:59:26 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 345.8 KB, free 8.4 GB); 18/03/07 13:59:26 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.48.225.55:32895 (size: 345.8 KB, free: 8.4 GB); 18/03/07 13:59:26 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:996; 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Submitting 252 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at filter at GATKSparkTool.java:220); 18/03/07 13:59:26 INFO cluster.YarnScheduler: Adding task set 0.0 with 252 tasks; 18/03/07 13:59:26 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 0.0 (TID 0, scc-q05.scc.bu.edu, executor 4, partition 2, NODE_LOCAL, 6147 bytes); 18/03/07 13:59:26 INFO scheduler.TaskSetManager: Starting task 25.0 in stage 0.0 (TID 1, scc-q10.scc.bu.edu, executor 3, partition 25, NODE_LOCAL, 6147 bytes); 18/03/07 13:59:26 INFO scheduler.TaskSetManager: Starting task 15.0 in stage 0.0 (TID 2, scc-q07.scc.bu.edu, executor 1, partition 15, NODE_LOCAL, 6147 bytes); 18/03/07 13:59:26 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 0.0 (TID 3, scc-q16.scc.bu.edu, executor 8, partition 4, NODE_LOCAL, 6147 bytes); 18/03/07 13:59:26 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 0.0 (TID 4, scc-q14.scc.bu.edu, executor 2, partition 3, NODE_LOCAL, 6147 bytes). ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371280304
https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371280304:3769,Energy Efficiency,schedul,scheduler,3769,"java:73) with 252 output partitions; 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (aggregate at FlagStatSpark.java:73); 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Parents of final stage: List(); 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Missing parents: List(); 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at filter at GATKSparkTool.java:220), which has no missing parents; 18/03/07 13:59:26 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 1148.4 KB, free 8.4 GB); 18/03/07 13:59:26 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 345.8 KB, free 8.4 GB); 18/03/07 13:59:26 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.48.225.55:32895 (size: 345.8 KB, free: 8.4 GB); 18/03/07 13:59:26 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:996; 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Submitting 252 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at filter at GATKSparkTool.java:220); 18/03/07 13:59:26 INFO cluster.YarnScheduler: Adding task set 0.0 with 252 tasks; 18/03/07 13:59:26 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 0.0 (TID 0, scc-q05.scc.bu.edu, executor 4, partition 2, NODE_LOCAL, 6147 bytes); 18/03/07 13:59:26 INFO scheduler.TaskSetManager: Starting task 25.0 in stage 0.0 (TID 1, scc-q10.scc.bu.edu, executor 3, partition 25, NODE_LOCAL, 6147 bytes); 18/03/07 13:59:26 INFO scheduler.TaskSetManager: Starting task 15.0 in stage 0.0 (TID 2, scc-q07.scc.bu.edu, executor 1, partition 15, NODE_LOCAL, 6147 bytes); 18/03/07 13:59:26 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 0.0 (TID 3, scc-q16.scc.bu.edu, executor 8, partition 4, NODE_LOCAL, 6147 bytes); 18/03/07 13:59:26 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 0.0 (TID 4, scc-q14.scc.bu.edu, executor 2, partition 3, NODE_LOCAL, 6147 bytes). ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371280304
https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371280304:1499,Security,secur,security,1499,":///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa -- --spark-runner SPARK --spark-master yarn --executor-memory 48G --driver-memory 16g --driver-cores 2 --executor-cores 8 --num-executors 8. ```; 18/03/07 13:24:26 INFO storage.BlockManagerMasterEndpoint: Registering block manager scc-q14.scc.bu.edu:42456 with 25.4 GB RAM, BlockManagerId(2, scc-q14.scc.bu.edu, 42456, None); 18/03/07 13:24:27 INFO memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 247.0 KB, free 8.4 GB); 18/03/07 13:24:28 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 25.5 KB, free 8.4 GB); 18/03/07 13:24:28 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.48.225.55:32895 (size: 25.5 KB, free: 8.4 GB); 18/03/07 13:24:28 INFO spark.SparkContext: Created broadcast 0 from newAPIHadoopFile at ReadsSparkSource.java:112; 18/03/07 13:24:28 INFO hdfs.DFSClient: Created HDFS_DELEGATION_TOKEN token 7164 for farrell on ha-hdfs:scc; 18/03/07 13:24:28 INFO security.TokenCache: Got dt for hdfs://scc; Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:scc, Ident: (HDFS_DELEGATION_TOKEN token 7164 for farrell); 18/03/07 13:24:28 INFO input.FileInputFormat: Total input paths to process : 1; 18/03/07 13:59:26 INFO spark.SparkContext: Starting job: aggregate at FlagStatSpark.java:73; 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Got job 0 (aggregate at FlagStatSpark.java:73) with 252 output partitions; 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (aggregate at FlagStatSpark.java:73); 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Parents of final stage: List(); 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Missing parents: List(); 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at filter at GATKSparkTool.java:220), which has no missing parents; 18/03/07 13:59:26 INFO memory.MemoryStore: Block broadcast_1 stored as values in mem",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371280304
https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371280304:102,Testability,log,log,102,"On our hadoop system, there is a long delay of about 30+ minutes before the tasks begin. See delay in log in job log between 13:24 and 13:59. Once the tasks start, it takes a few minutes. During the delay, the executors are not active and waiting for the tasks to start. Just surprised on how long getting the splits are taking.... This is the commandline...; gatk FlagStatSpark --input adni/cram/ADNI_002_S_0413.hg38.realign.bqsr.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa -- --spark-runner SPARK --spark-master yarn --executor-memory 48G --driver-memory 16g --driver-cores 2 --executor-cores 8 --num-executors 8. ```; 18/03/07 13:24:26 INFO storage.BlockManagerMasterEndpoint: Registering block manager scc-q14.scc.bu.edu:42456 with 25.4 GB RAM, BlockManagerId(2, scc-q14.scc.bu.edu, 42456, None); 18/03/07 13:24:27 INFO memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 247.0 KB, free 8.4 GB); 18/03/07 13:24:28 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 25.5 KB, free 8.4 GB); 18/03/07 13:24:28 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.48.225.55:32895 (size: 25.5 KB, free: 8.4 GB); 18/03/07 13:24:28 INFO spark.SparkContext: Created broadcast 0 from newAPIHadoopFile at ReadsSparkSource.java:112; 18/03/07 13:24:28 INFO hdfs.DFSClient: Created HDFS_DELEGATION_TOKEN token 7164 for farrell on ha-hdfs:scc; 18/03/07 13:24:28 INFO security.TokenCache: Got dt for hdfs://scc; Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:scc, Ident: (HDFS_DELEGATION_TOKEN token 7164 for farrell); 18/03/07 13:24:28 INFO input.FileInputFormat: Total input paths to process : 1; 18/03/07 13:59:26 INFO spark.SparkContext: Starting job: aggregate at FlagStatSpark.java:73; 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Got job 0 (aggregate at FlagStatSpark.java:73) with 252 output partitions; 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Final stag",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371280304
https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371280304:113,Testability,log,log,113,"On our hadoop system, there is a long delay of about 30+ minutes before the tasks begin. See delay in log in job log between 13:24 and 13:59. Once the tasks start, it takes a few minutes. During the delay, the executors are not active and waiting for the tasks to start. Just surprised on how long getting the splits are taking.... This is the commandline...; gatk FlagStatSpark --input adni/cram/ADNI_002_S_0413.hg38.realign.bqsr.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa -- --spark-runner SPARK --spark-master yarn --executor-memory 48G --driver-memory 16g --driver-cores 2 --executor-cores 8 --num-executors 8. ```; 18/03/07 13:24:26 INFO storage.BlockManagerMasterEndpoint: Registering block manager scc-q14.scc.bu.edu:42456 with 25.4 GB RAM, BlockManagerId(2, scc-q14.scc.bu.edu, 42456, None); 18/03/07 13:24:27 INFO memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 247.0 KB, free 8.4 GB); 18/03/07 13:24:28 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 25.5 KB, free 8.4 GB); 18/03/07 13:24:28 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.48.225.55:32895 (size: 25.5 KB, free: 8.4 GB); 18/03/07 13:24:28 INFO spark.SparkContext: Created broadcast 0 from newAPIHadoopFile at ReadsSparkSource.java:112; 18/03/07 13:24:28 INFO hdfs.DFSClient: Created HDFS_DELEGATION_TOKEN token 7164 for farrell on ha-hdfs:scc; 18/03/07 13:24:28 INFO security.TokenCache: Got dt for hdfs://scc; Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:scc, Ident: (HDFS_DELEGATION_TOKEN token 7164 for farrell); 18/03/07 13:24:28 INFO input.FileInputFormat: Total input paths to process : 1; 18/03/07 13:59:26 INFO spark.SparkContext: Starting job: aggregate at FlagStatSpark.java:73; 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Got job 0 (aggregate at FlagStatSpark.java:73) with 252 output partitions; 18/03/07 13:59:26 INFO scheduler.DAGScheduler: Final stag",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371280304
https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371292714:147,Safety,avoid,avoid,147,@jjfarrell Huh. I expected that sort of annoying delay from splitting on a cloud system but not on a hadoop one. Does running with splitting index avoid the delay?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371292714
https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888:1603,Availability,AVAIL,AVAILABLE,1603,"til.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41567.; 18/03/07 20:31:40 INFO netty.NettyBlockTransferService: Server created on 10.48.225.55:41567; 18/03/07 20:31:40 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy; 18/03/07 20:31:40 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.48.225.55, 41567, None); 18/03/07 20:31:40 INFO storage.BlockManagerMasterEndpoint: Registering block manager 10.48.225.55:41567 with 8.4 GB RAM, BlockManagerId(driver, 10.48.225.55, 41567, None); 18/03/07 20:31:40 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.48.225.55, 41567, None); 18/03/07 20:31:40 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.48.225.55, 41567, None); 18/03/07 20:31:40 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4d9cf71d{/metrics/json,null,AVAILABLE}; 18/03/07 20:31:48 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(null) (192.168.18.186:36002) with ID 8; 18/03/07 20:31:48 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(null) (192.168.18.196:45956) with ID 2; 18/03/07 20:31:48 INFO storage.BlockManagerMasterEndpoint: Registering block manager scc-q02.scc.bu.edu:37393 with 25.4 GB RAM, BlockManagerId(8, scc-q02.scc.bu.edu, 37393, None); 18/03/07 20:31:48 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(null) (192.168.18.197:57832) with ID 3; 18/03/07 20:31:48 INFO storage.BlockManagerMasterEndpoint: Registering block manager scc-q12.scc.bu.edu:36422 with 25.4 GB RAM, BlockManagerId(2, scc-q12.scc.bu.edu, 36422, None); 18/03/07 20:31:48 INFO storage.BlockManagerMasterEndpoint: Registering block manager scc-q13.scc.bu.edu:42480 with 25.4 GB RAM, BlockManagerId(3, scc-q13.scc.bu.edu, 424",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888
https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888:8921,Availability,failure,failure,8921,"AL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 13.0 in stage 0.0 (TID 8, scc-q03.scc.bu.edu, executor 4, partition 13, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 7.0 in stage 0.0 (TID 9, scc-q13.scc.bu.edu, executor 3, partition 7, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 8.0 in stage 0.0 (TID 10, scc-q14.scc.bu.edu, executor 7, partition 8, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 14.0 in stage 0.0 (TID 11, scc-q12.scc.bu.edu, executor 2, partition 14, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 9.0 in stage 0.0 (TID 12, scc-q09.scc.bu.edu, executor 1, parti; ```. Processed 1,2 billion reads in less than 2 minutes..... ```; 18/03/07 20:32:55 INFO scheduler.DAGScheduler: Job 0 finished: aggregate at FlagStatSpark.java:73, took 64.566359 s; 1205535516 in total; 0 QC failure; 37791118 duplicates; 1157122594 mapped (95.98%); 1205535516 paired in sequencing; 602767758 read1; 602767758 read2; 1145853318 properly paired (95.05%); 1150449216 with itself and mate mapped; 6673378 singletons (0.55%); 4595898 with mate mapped to a different chr; 3316623 with mate mapped to a different chr (mapQ>=5); 18/03/07 20:32:55 INFO server.ServerConnector: Stopped ServerConnector@79f5a6ed{HTTP/1.1}{0.0.0.0:4041}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@221ca495{/stages/stage/kill,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@28b458e6{/jobs/job/kill,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@3ccb12d{/api,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@1544ded3{/,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHand",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888
https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888:12754,Availability,down,down,12754,"AVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@c5e69a5{/stages/json,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@10131289{/stages,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@50f4b83d{/jobs/job/json,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@5d66ae3a{/jobs/job,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@30159886{/jobs/json,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@33de7f3d{/jobs,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO ui.SparkUI: Stopped Spark web UI at http://10.48.225.55:4041; 18/03/07 20:32:55 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread; 18/03/07 20:32:55 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors; 18/03/07 20:32:55 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down; 18/03/07 20:32:55 INFO cluster.SchedulerExtensionServices: Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 18/03/07 20:32:55 INFO cluster.YarnClientSchedulerBackend: Stopped; 18/03/07 20:32:55 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 18/03/07 20:32:55 INFO memory.MemoryStore: MemoryStore cleared; 18/03/07 20:32:55 INFO storage.BlockManager: BlockManager stopped; 18/03/07 20:32:55 INFO storage.BlockManagerMaster: BlockManagerMaster stopped; 18/03/07 20:32:55 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 18/03/07 20:32:55 INFO spark.SparkContext: Successfully stopped SparkContext; 20:32:55.769 INFO FlagStatSpark - Shutting down engine; [March 7, 2018 8:32:55 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.FlagSta",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888
https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888:12875,Availability,down,down,12875,"c5e69a5{/stages/json,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@10131289{/stages,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@50f4b83d{/jobs/job/json,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@5d66ae3a{/jobs/job,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@30159886{/jobs/json,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@33de7f3d{/jobs,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO ui.SparkUI: Stopped Spark web UI at http://10.48.225.55:4041; 18/03/07 20:32:55 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread; 18/03/07 20:32:55 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors; 18/03/07 20:32:55 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down; 18/03/07 20:32:55 INFO cluster.SchedulerExtensionServices: Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 18/03/07 20:32:55 INFO cluster.YarnClientSchedulerBackend: Stopped; 18/03/07 20:32:55 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 18/03/07 20:32:55 INFO memory.MemoryStore: MemoryStore cleared; 18/03/07 20:32:55 INFO storage.BlockManager: BlockManager stopped; 18/03/07 20:32:55 INFO storage.BlockManagerMaster: BlockManagerMaster stopped; 18/03/07 20:32:55 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 18/03/07 20:32:55 INFO spark.SparkContext: Successfully stopped SparkContext; 20:32:55.769 INFO FlagStatSpark - Shutting down engine; [March 7, 2018 8:32:55 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.FlagStatSpark done. Elapsed time: 1.60 minutes.; Runtime.totalMemory()=2091384832; 18/03/07 20:32:55 INFO",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888
https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888:13658,Availability,down,down,13658,"ServletContextHandler@50f4b83d{/jobs/job/json,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@5d66ae3a{/jobs/job,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@30159886{/jobs/json,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@33de7f3d{/jobs,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO ui.SparkUI: Stopped Spark web UI at http://10.48.225.55:4041; 18/03/07 20:32:55 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread; 18/03/07 20:32:55 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors; 18/03/07 20:32:55 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down; 18/03/07 20:32:55 INFO cluster.SchedulerExtensionServices: Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 18/03/07 20:32:55 INFO cluster.YarnClientSchedulerBackend: Stopped; 18/03/07 20:32:55 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 18/03/07 20:32:55 INFO memory.MemoryStore: MemoryStore cleared; 18/03/07 20:32:55 INFO storage.BlockManager: BlockManager stopped; 18/03/07 20:32:55 INFO storage.BlockManagerMaster: BlockManagerMaster stopped; 18/03/07 20:32:55 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 18/03/07 20:32:55 INFO spark.SparkContext: Successfully stopped SparkContext; 20:32:55.769 INFO FlagStatSpark - Shutting down engine; [March 7, 2018 8:32:55 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.FlagStatSpark done. Elapsed time: 1.60 minutes.; Runtime.totalMemory()=2091384832; 18/03/07 20:32:55 INFO util.ShutdownHookManager: Shutdown hook called; 18/03/07 20:32:55 INFO util.ShutdownHookManager: Deleting directory /tmp/farrell/spark-9e0f0525-00f3-4b37-b1d2-4cf55b4c8cb0. real 1m41.113s; user 0m49.698s; sys 0m4.432s. ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888
https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888:13744,Deployability,pipeline,pipelines,13744,"ServletContextHandler@50f4b83d{/jobs/job/json,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@5d66ae3a{/jobs/job,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@30159886{/jobs/json,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@33de7f3d{/jobs,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO ui.SparkUI: Stopped Spark web UI at http://10.48.225.55:4041; 18/03/07 20:32:55 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread; 18/03/07 20:32:55 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors; 18/03/07 20:32:55 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down; 18/03/07 20:32:55 INFO cluster.SchedulerExtensionServices: Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 18/03/07 20:32:55 INFO cluster.YarnClientSchedulerBackend: Stopped; 18/03/07 20:32:55 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 18/03/07 20:32:55 INFO memory.MemoryStore: MemoryStore cleared; 18/03/07 20:32:55 INFO storage.BlockManager: BlockManager stopped; 18/03/07 20:32:55 INFO storage.BlockManagerMaster: BlockManagerMaster stopped; 18/03/07 20:32:55 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 18/03/07 20:32:55 INFO spark.SparkContext: Successfully stopped SparkContext; 20:32:55.769 INFO FlagStatSpark - Shutting down engine; [March 7, 2018 8:32:55 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.FlagStatSpark done. Elapsed time: 1.60 minutes.; Runtime.totalMemory()=2091384832; 18/03/07 20:32:55 INFO util.ShutdownHookManager: Shutdown hook called; 18/03/07 20:32:55 INFO util.ShutdownHookManager: Deleting directory /tmp/farrell/spark-9e0f0525-00f3-4b37-b1d2-4cf55b4c8cb0. real 1m41.113s; user 0m49.698s; sys 0m4.432s. ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888
https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888:3818,Energy Efficiency,Schedul,SchedulerBackend,3818,"q06.scc.bu.edu:39736 with 25.4 GB RAM, BlockManagerId(5, scc-q06.scc.bu.edu, 39736, None); 18/03/07 20:31:48 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(null) (192.168.18.193:34094) with ID 1; 18/03/07 20:31:48 INFO storage.BlockManagerMasterEndpoint: Registering block manager scc-q09.scc.bu.edu:38854 with 25.4 GB RAM, BlockManagerId(1, scc-q09.scc.bu.edu, 38854, None); 18/03/07 20:31:49 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(null) (192.168.18.187:33854) with ID 4; 18/03/07 20:31:49 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(null) (192.168.18.198:41138) with ID 7; 18/03/07 20:31:49 INFO storage.BlockManagerMasterEndpoint: Registering block manager scc-q03.scc.bu.edu:35635 with 25.4 GB RAM, BlockManagerId(4, scc-q03.scc.bu.edu, 35635, None); 18/03/07 20:31:49 INFO cluster.YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8; 18/03/07 20:31:49 INFO storage.BlockManagerMasterEndpoint: Registering block manager scc-q14.scc.bu.edu:36726 with 25.4 GB RAM, BlockManagerId(7, scc-q14.scc.bu.edu, 36726, None); 18/03/07 20:31:49 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(null) (192.168.18.195:47862) with ID 6; 18/03/07 20:31:49 INFO storage.BlockManagerMasterEndpoint: Registering block manager scc-q11.scc.bu.edu:46002 with 25.4 GB RAM, BlockManagerId(6, scc-q11.scc.bu.edu, 46002, None); 18/03/07 20:31:49 INFO memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 246.6 KB, free 8.4 GB); 18/03/07 20:31:50 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 25.3 KB, free 8.4 GB); 18/03/07 20:31:50 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.48.225.55:41567 (size: 25.3 KB, free: 8.4 GB); 18/03/07 20:31:50 INFO sp",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888
https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888:3848,Energy Efficiency,schedul,scheduling,3848,"q06.scc.bu.edu:39736 with 25.4 GB RAM, BlockManagerId(5, scc-q06.scc.bu.edu, 39736, None); 18/03/07 20:31:48 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(null) (192.168.18.193:34094) with ID 1; 18/03/07 20:31:48 INFO storage.BlockManagerMasterEndpoint: Registering block manager scc-q09.scc.bu.edu:38854 with 25.4 GB RAM, BlockManagerId(1, scc-q09.scc.bu.edu, 38854, None); 18/03/07 20:31:49 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(null) (192.168.18.187:33854) with ID 4; 18/03/07 20:31:49 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(null) (192.168.18.198:41138) with ID 7; 18/03/07 20:31:49 INFO storage.BlockManagerMasterEndpoint: Registering block manager scc-q03.scc.bu.edu:35635 with 25.4 GB RAM, BlockManagerId(4, scc-q03.scc.bu.edu, 35635, None); 18/03/07 20:31:49 INFO cluster.YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8; 18/03/07 20:31:49 INFO storage.BlockManagerMasterEndpoint: Registering block manager scc-q14.scc.bu.edu:36726 with 25.4 GB RAM, BlockManagerId(7, scc-q14.scc.bu.edu, 36726, None); 18/03/07 20:31:49 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(null) (192.168.18.195:47862) with ID 6; 18/03/07 20:31:49 INFO storage.BlockManagerMasterEndpoint: Registering block manager scc-q11.scc.bu.edu:46002 with 25.4 GB RAM, BlockManagerId(6, scc-q11.scc.bu.edu, 46002, None); 18/03/07 20:31:49 INFO memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 246.6 KB, free 8.4 GB); 18/03/07 20:31:50 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 25.3 KB, free 8.4 GB); 18/03/07 20:31:50 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.48.225.55:41567 (size: 25.3 KB, free: 8.4 GB); 18/03/07 20:31:50 INFO sp",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888
https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888:5419,Energy Efficiency,schedul,scheduler,5419,"u.edu, 46002, None); 18/03/07 20:31:49 INFO memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 246.6 KB, free 8.4 GB); 18/03/07 20:31:50 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 25.3 KB, free 8.4 GB); 18/03/07 20:31:50 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.48.225.55:41567 (size: 25.3 KB, free: 8.4 GB); 18/03/07 20:31:50 INFO spark.SparkContext: Created broadcast 0 from newAPIHadoopFile at ReadsSparkSource.java:112; 18/03/07 20:31:50 INFO hdfs.DFSClient: Created HDFS_DELEGATION_TOKEN token 7175 for farrell on ha-hdfs:scc; 18/03/07 20:31:50 INFO security.TokenCache: Got dt for hdfs://scc; Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:scc, Ident: (HDFS_DELEGATION_TOKEN token 7175 for farrell); 18/03/07 20:31:50 INFO input.FileInputFormat: Total input paths to process : 1; 18/03/07 20:31:51 INFO spark.SparkContext: Starting job: aggregate at FlagStatSpark.java:73; 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Got job 0 (aggregate at FlagStatSpark.java:73) with 629 output partitions; 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (aggregate at FlagStatSpark.java:73); 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Parents of final stage: List(); 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Missing parents: List(); 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at filter at GATKSparkTool.java:220), which has no missing parents; 18/03/07 20:31:51 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 53.9 KB, free 8.4 GB); 18/03/07 20:31:51 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 15.5 KB, free 8.4 GB); 18/03/07 20:31:51 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.48.225.55:41567 (size: 15.5 KB, free: 8.4 GB); 18/03/07 20:31:51 INFO spark.SparkContext: Created broadcast 1 from b",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888
https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888:5541,Energy Efficiency,schedul,scheduler,5541," (estimated size 246.6 KB, free 8.4 GB); 18/03/07 20:31:50 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 25.3 KB, free 8.4 GB); 18/03/07 20:31:50 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.48.225.55:41567 (size: 25.3 KB, free: 8.4 GB); 18/03/07 20:31:50 INFO spark.SparkContext: Created broadcast 0 from newAPIHadoopFile at ReadsSparkSource.java:112; 18/03/07 20:31:50 INFO hdfs.DFSClient: Created HDFS_DELEGATION_TOKEN token 7175 for farrell on ha-hdfs:scc; 18/03/07 20:31:50 INFO security.TokenCache: Got dt for hdfs://scc; Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:scc, Ident: (HDFS_DELEGATION_TOKEN token 7175 for farrell); 18/03/07 20:31:50 INFO input.FileInputFormat: Total input paths to process : 1; 18/03/07 20:31:51 INFO spark.SparkContext: Starting job: aggregate at FlagStatSpark.java:73; 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Got job 0 (aggregate at FlagStatSpark.java:73) with 629 output partitions; 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (aggregate at FlagStatSpark.java:73); 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Parents of final stage: List(); 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Missing parents: List(); 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at filter at GATKSparkTool.java:220), which has no missing parents; 18/03/07 20:31:51 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 53.9 KB, free 8.4 GB); 18/03/07 20:31:51 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 15.5 KB, free 8.4 GB); 18/03/07 20:31:51 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.48.225.55:41567 (size: 15.5 KB, free: 8.4 GB); 18/03/07 20:31:51 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:996; 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Submitting 629 missing ta",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888
https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888:5653,Energy Efficiency,schedul,scheduler,5653,"in memory (estimated size 25.3 KB, free 8.4 GB); 18/03/07 20:31:50 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.48.225.55:41567 (size: 25.3 KB, free: 8.4 GB); 18/03/07 20:31:50 INFO spark.SparkContext: Created broadcast 0 from newAPIHadoopFile at ReadsSparkSource.java:112; 18/03/07 20:31:50 INFO hdfs.DFSClient: Created HDFS_DELEGATION_TOKEN token 7175 for farrell on ha-hdfs:scc; 18/03/07 20:31:50 INFO security.TokenCache: Got dt for hdfs://scc; Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:scc, Ident: (HDFS_DELEGATION_TOKEN token 7175 for farrell); 18/03/07 20:31:50 INFO input.FileInputFormat: Total input paths to process : 1; 18/03/07 20:31:51 INFO spark.SparkContext: Starting job: aggregate at FlagStatSpark.java:73; 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Got job 0 (aggregate at FlagStatSpark.java:73) with 629 output partitions; 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (aggregate at FlagStatSpark.java:73); 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Parents of final stage: List(); 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Missing parents: List(); 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at filter at GATKSparkTool.java:220), which has no missing parents; 18/03/07 20:31:51 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 53.9 KB, free 8.4 GB); 18/03/07 20:31:51 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 15.5 KB, free 8.4 GB); 18/03/07 20:31:51 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.48.225.55:41567 (size: 15.5 KB, free: 8.4 GB); 18/03/07 20:31:51 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:996; 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Submitting 629 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at filter at GATKSparkTool.java:220); 18/03/07 20:31:51 INFO cluster.YarnScheduler",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888
https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888:5732,Energy Efficiency,schedul,scheduler,5732,"31:50 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.48.225.55:41567 (size: 25.3 KB, free: 8.4 GB); 18/03/07 20:31:50 INFO spark.SparkContext: Created broadcast 0 from newAPIHadoopFile at ReadsSparkSource.java:112; 18/03/07 20:31:50 INFO hdfs.DFSClient: Created HDFS_DELEGATION_TOKEN token 7175 for farrell on ha-hdfs:scc; 18/03/07 20:31:50 INFO security.TokenCache: Got dt for hdfs://scc; Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:scc, Ident: (HDFS_DELEGATION_TOKEN token 7175 for farrell); 18/03/07 20:31:50 INFO input.FileInputFormat: Total input paths to process : 1; 18/03/07 20:31:51 INFO spark.SparkContext: Starting job: aggregate at FlagStatSpark.java:73; 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Got job 0 (aggregate at FlagStatSpark.java:73) with 629 output partitions; 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (aggregate at FlagStatSpark.java:73); 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Parents of final stage: List(); 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Missing parents: List(); 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at filter at GATKSparkTool.java:220), which has no missing parents; 18/03/07 20:31:51 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 53.9 KB, free 8.4 GB); 18/03/07 20:31:51 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 15.5 KB, free 8.4 GB); 18/03/07 20:31:51 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.48.225.55:41567 (size: 15.5 KB, free: 8.4 GB); 18/03/07 20:31:51 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:996; 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Submitting 629 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at filter at GATKSparkTool.java:220); 18/03/07 20:31:51 INFO cluster.YarnScheduler: Adding task set 0.0 with 629 tasks; 18/03/07 20:31:51 INFO ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888
https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888:5804,Energy Efficiency,schedul,scheduler,5804,"0.48.225.55:41567 (size: 25.3 KB, free: 8.4 GB); 18/03/07 20:31:50 INFO spark.SparkContext: Created broadcast 0 from newAPIHadoopFile at ReadsSparkSource.java:112; 18/03/07 20:31:50 INFO hdfs.DFSClient: Created HDFS_DELEGATION_TOKEN token 7175 for farrell on ha-hdfs:scc; 18/03/07 20:31:50 INFO security.TokenCache: Got dt for hdfs://scc; Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:scc, Ident: (HDFS_DELEGATION_TOKEN token 7175 for farrell); 18/03/07 20:31:50 INFO input.FileInputFormat: Total input paths to process : 1; 18/03/07 20:31:51 INFO spark.SparkContext: Starting job: aggregate at FlagStatSpark.java:73; 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Got job 0 (aggregate at FlagStatSpark.java:73) with 629 output partitions; 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (aggregate at FlagStatSpark.java:73); 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Parents of final stage: List(); 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Missing parents: List(); 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at filter at GATKSparkTool.java:220), which has no missing parents; 18/03/07 20:31:51 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 53.9 KB, free 8.4 GB); 18/03/07 20:31:51 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 15.5 KB, free 8.4 GB); 18/03/07 20:31:51 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.48.225.55:41567 (size: 15.5 KB, free: 8.4 GB); 18/03/07 20:31:51 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:996; 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Submitting 629 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at filter at GATKSparkTool.java:220); 18/03/07 20:31:51 INFO cluster.YarnScheduler: Adding task set 0.0 with 629 tasks; 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 0.0 (TID 0, scc-q03.sc",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888
https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888:6467,Energy Efficiency,schedul,scheduler,6467,"ggregate at FlagStatSpark.java:73) with 629 output partitions; 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (aggregate at FlagStatSpark.java:73); 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Parents of final stage: List(); 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Missing parents: List(); 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at filter at GATKSparkTool.java:220), which has no missing parents; 18/03/07 20:31:51 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 53.9 KB, free 8.4 GB); 18/03/07 20:31:51 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 15.5 KB, free 8.4 GB); 18/03/07 20:31:51 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.48.225.55:41567 (size: 15.5 KB, free: 8.4 GB); 18/03/07 20:31:51 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:996; 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Submitting 629 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at filter at GATKSparkTool.java:220); 18/03/07 20:31:51 INFO cluster.YarnScheduler: Adding task set 0.0 with 629 tasks; 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 0.0 (TID 0, scc-q03.scc.bu.edu, executor 4, partition 1, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 6.0 in stage 0.0 (TID 1, scc-q13.scc.bu.edu, executor 3, partition 6, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 0.0 (TID 2, scc-q14.scc.bu.edu, executor 7, partition 4, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 5.0 in stage 0.0 (TID 3, scc-q12.scc.bu.edu, executor 2, partition 5, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 0.0 (TID 4, scc-q09.scc.bu.edu, executor 1, partition 2, NODE_LOCAL",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888
https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888:6703,Energy Efficiency,schedul,scheduler,6703," final stage: List(); 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Missing parents: List(); 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at filter at GATKSparkTool.java:220), which has no missing parents; 18/03/07 20:31:51 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 53.9 KB, free 8.4 GB); 18/03/07 20:31:51 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 15.5 KB, free 8.4 GB); 18/03/07 20:31:51 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.48.225.55:41567 (size: 15.5 KB, free: 8.4 GB); 18/03/07 20:31:51 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:996; 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Submitting 629 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at filter at GATKSparkTool.java:220); 18/03/07 20:31:51 INFO cluster.YarnScheduler: Adding task set 0.0 with 629 tasks; 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 0.0 (TID 0, scc-q03.scc.bu.edu, executor 4, partition 1, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 6.0 in stage 0.0 (TID 1, scc-q13.scc.bu.edu, executor 3, partition 6, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 0.0 (TID 2, scc-q14.scc.bu.edu, executor 7, partition 4, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 5.0 in stage 0.0 (TID 3, scc-q12.scc.bu.edu, executor 2, partition 5, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 0.0 (TID 4, scc-q09.scc.bu.edu, executor 1, partition 2, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 17.0 in stage 0.0 (TID 5, scc-q11.scc.bu.edu, executor 6, partition 17, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888
https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888:6861,Energy Efficiency,schedul,scheduler,6861," Submitting ResultStage 0 (MapPartitionsRDD[3] at filter at GATKSparkTool.java:220), which has no missing parents; 18/03/07 20:31:51 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 53.9 KB, free 8.4 GB); 18/03/07 20:31:51 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 15.5 KB, free 8.4 GB); 18/03/07 20:31:51 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.48.225.55:41567 (size: 15.5 KB, free: 8.4 GB); 18/03/07 20:31:51 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:996; 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Submitting 629 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at filter at GATKSparkTool.java:220); 18/03/07 20:31:51 INFO cluster.YarnScheduler: Adding task set 0.0 with 629 tasks; 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 0.0 (TID 0, scc-q03.scc.bu.edu, executor 4, partition 1, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 6.0 in stage 0.0 (TID 1, scc-q13.scc.bu.edu, executor 3, partition 6, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 0.0 (TID 2, scc-q14.scc.bu.edu, executor 7, partition 4, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 5.0 in stage 0.0 (TID 3, scc-q12.scc.bu.edu, executor 2, partition 5, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 0.0 (TID 4, scc-q09.scc.bu.edu, executor 1, partition 2, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 17.0 in stage 0.0 (TID 5, scc-q11.scc.bu.edu, executor 6, partition 17, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 6, scc-q06.scc.bu.edu, executor 5, partition 0, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSe",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888
https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888:7019,Energy Efficiency,schedul,scheduler,7019,"Block broadcast_1 stored as values in memory (estimated size 53.9 KB, free 8.4 GB); 18/03/07 20:31:51 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 15.5 KB, free 8.4 GB); 18/03/07 20:31:51 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.48.225.55:41567 (size: 15.5 KB, free: 8.4 GB); 18/03/07 20:31:51 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:996; 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Submitting 629 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at filter at GATKSparkTool.java:220); 18/03/07 20:31:51 INFO cluster.YarnScheduler: Adding task set 0.0 with 629 tasks; 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 0.0 (TID 0, scc-q03.scc.bu.edu, executor 4, partition 1, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 6.0 in stage 0.0 (TID 1, scc-q13.scc.bu.edu, executor 3, partition 6, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 0.0 (TID 2, scc-q14.scc.bu.edu, executor 7, partition 4, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 5.0 in stage 0.0 (TID 3, scc-q12.scc.bu.edu, executor 2, partition 5, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 0.0 (TID 4, scc-q09.scc.bu.edu, executor 1, partition 2, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 17.0 in stage 0.0 (TID 5, scc-q11.scc.bu.edu, executor 6, partition 17, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 6, scc-q06.scc.bu.edu, executor 5, partition 0, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 0.0 (TID 7, scc-q02.scc.bu.edu, executor 8, partition 3, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSe",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888
https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888:7177,Energy Efficiency,schedul,scheduler,7177," as bytes in memory (estimated size 15.5 KB, free 8.4 GB); 18/03/07 20:31:51 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.48.225.55:41567 (size: 15.5 KB, free: 8.4 GB); 18/03/07 20:31:51 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:996; 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Submitting 629 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at filter at GATKSparkTool.java:220); 18/03/07 20:31:51 INFO cluster.YarnScheduler: Adding task set 0.0 with 629 tasks; 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 0.0 (TID 0, scc-q03.scc.bu.edu, executor 4, partition 1, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 6.0 in stage 0.0 (TID 1, scc-q13.scc.bu.edu, executor 3, partition 6, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 0.0 (TID 2, scc-q14.scc.bu.edu, executor 7, partition 4, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 5.0 in stage 0.0 (TID 3, scc-q12.scc.bu.edu, executor 2, partition 5, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 0.0 (TID 4, scc-q09.scc.bu.edu, executor 1, partition 2, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 17.0 in stage 0.0 (TID 5, scc-q11.scc.bu.edu, executor 6, partition 17, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 6, scc-q06.scc.bu.edu, executor 5, partition 0, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 0.0 (TID 7, scc-q02.scc.bu.edu, executor 8, partition 3, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 13.0 in stage 0.0 (TID 8, scc-q03.scc.bu.edu, executor 4, partition 13, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.Task",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888
https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888:7335,Energy Efficiency,schedul,scheduler,7335,":41567 (size: 15.5 KB, free: 8.4 GB); 18/03/07 20:31:51 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:996; 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Submitting 629 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at filter at GATKSparkTool.java:220); 18/03/07 20:31:51 INFO cluster.YarnScheduler: Adding task set 0.0 with 629 tasks; 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 0.0 (TID 0, scc-q03.scc.bu.edu, executor 4, partition 1, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 6.0 in stage 0.0 (TID 1, scc-q13.scc.bu.edu, executor 3, partition 6, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 0.0 (TID 2, scc-q14.scc.bu.edu, executor 7, partition 4, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 5.0 in stage 0.0 (TID 3, scc-q12.scc.bu.edu, executor 2, partition 5, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 0.0 (TID 4, scc-q09.scc.bu.edu, executor 1, partition 2, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 17.0 in stage 0.0 (TID 5, scc-q11.scc.bu.edu, executor 6, partition 17, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 6, scc-q06.scc.bu.edu, executor 5, partition 0, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 0.0 (TID 7, scc-q02.scc.bu.edu, executor 8, partition 3, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 13.0 in stage 0.0 (TID 8, scc-q03.scc.bu.edu, executor 4, partition 13, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 7.0 in stage 0.0 (TID 9, scc-q13.scc.bu.edu, executor 3, partition 7, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.Task",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888
https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888:7493,Energy Efficiency,schedul,scheduler,7493,"51 INFO scheduler.DAGScheduler: Submitting 629 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at filter at GATKSparkTool.java:220); 18/03/07 20:31:51 INFO cluster.YarnScheduler: Adding task set 0.0 with 629 tasks; 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 0.0 (TID 0, scc-q03.scc.bu.edu, executor 4, partition 1, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 6.0 in stage 0.0 (TID 1, scc-q13.scc.bu.edu, executor 3, partition 6, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 0.0 (TID 2, scc-q14.scc.bu.edu, executor 7, partition 4, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 5.0 in stage 0.0 (TID 3, scc-q12.scc.bu.edu, executor 2, partition 5, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 0.0 (TID 4, scc-q09.scc.bu.edu, executor 1, partition 2, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 17.0 in stage 0.0 (TID 5, scc-q11.scc.bu.edu, executor 6, partition 17, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 6, scc-q06.scc.bu.edu, executor 5, partition 0, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 0.0 (TID 7, scc-q02.scc.bu.edu, executor 8, partition 3, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 13.0 in stage 0.0 (TID 8, scc-q03.scc.bu.edu, executor 4, partition 13, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 7.0 in stage 0.0 (TID 9, scc-q13.scc.bu.edu, executor 3, partition 7, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 8.0 in stage 0.0 (TID 10, scc-q14.scc.bu.edu, executor 7, partition 8, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.Tas",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888
https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888:7653,Energy Efficiency,schedul,scheduler,7653,"FO cluster.YarnScheduler: Adding task set 0.0 with 629 tasks; 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 0.0 (TID 0, scc-q03.scc.bu.edu, executor 4, partition 1, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 6.0 in stage 0.0 (TID 1, scc-q13.scc.bu.edu, executor 3, partition 6, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 0.0 (TID 2, scc-q14.scc.bu.edu, executor 7, partition 4, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 5.0 in stage 0.0 (TID 3, scc-q12.scc.bu.edu, executor 2, partition 5, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 0.0 (TID 4, scc-q09.scc.bu.edu, executor 1, partition 2, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 17.0 in stage 0.0 (TID 5, scc-q11.scc.bu.edu, executor 6, partition 17, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 6, scc-q06.scc.bu.edu, executor 5, partition 0, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 0.0 (TID 7, scc-q02.scc.bu.edu, executor 8, partition 3, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 13.0 in stage 0.0 (TID 8, scc-q03.scc.bu.edu, executor 4, partition 13, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 7.0 in stage 0.0 (TID 9, scc-q13.scc.bu.edu, executor 3, partition 7, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 8.0 in stage 0.0 (TID 10, scc-q14.scc.bu.edu, executor 7, partition 8, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 14.0 in stage 0.0 (TID 11, scc-q12.scc.bu.edu, executor 2, partition 14, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.Ta",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888
https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888:7811,Energy Efficiency,schedul,scheduler,7811,"cc.bu.edu, executor 4, partition 1, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 6.0 in stage 0.0 (TID 1, scc-q13.scc.bu.edu, executor 3, partition 6, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 0.0 (TID 2, scc-q14.scc.bu.edu, executor 7, partition 4, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 5.0 in stage 0.0 (TID 3, scc-q12.scc.bu.edu, executor 2, partition 5, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 0.0 (TID 4, scc-q09.scc.bu.edu, executor 1, partition 2, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 17.0 in stage 0.0 (TID 5, scc-q11.scc.bu.edu, executor 6, partition 17, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 6, scc-q06.scc.bu.edu, executor 5, partition 0, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 0.0 (TID 7, scc-q02.scc.bu.edu, executor 8, partition 3, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 13.0 in stage 0.0 (TID 8, scc-q03.scc.bu.edu, executor 4, partition 13, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 7.0 in stage 0.0 (TID 9, scc-q13.scc.bu.edu, executor 3, partition 7, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 8.0 in stage 0.0 (TID 10, scc-q14.scc.bu.edu, executor 7, partition 8, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 14.0 in stage 0.0 (TID 11, scc-q12.scc.bu.edu, executor 2, partition 14, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 9.0 in stage 0.0 (TID 12, scc-q09.scc.bu.edu, executor 1, parti; ```. Processed 1,2 billion reads in less than 2 minutes..... ```;",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888
https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888:7969,Energy Efficiency,schedul,scheduler,7969,"cc.bu.edu, executor 3, partition 6, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 0.0 (TID 2, scc-q14.scc.bu.edu, executor 7, partition 4, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 5.0 in stage 0.0 (TID 3, scc-q12.scc.bu.edu, executor 2, partition 5, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 0.0 (TID 4, scc-q09.scc.bu.edu, executor 1, partition 2, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 17.0 in stage 0.0 (TID 5, scc-q11.scc.bu.edu, executor 6, partition 17, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 6, scc-q06.scc.bu.edu, executor 5, partition 0, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 0.0 (TID 7, scc-q02.scc.bu.edu, executor 8, partition 3, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 13.0 in stage 0.0 (TID 8, scc-q03.scc.bu.edu, executor 4, partition 13, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 7.0 in stage 0.0 (TID 9, scc-q13.scc.bu.edu, executor 3, partition 7, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 8.0 in stage 0.0 (TID 10, scc-q14.scc.bu.edu, executor 7, partition 8, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 14.0 in stage 0.0 (TID 11, scc-q12.scc.bu.edu, executor 2, partition 14, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 9.0 in stage 0.0 (TID 12, scc-q09.scc.bu.edu, executor 1, parti; ```. Processed 1,2 billion reads in less than 2 minutes..... ```; 18/03/07 20:32:55 INFO scheduler.DAGScheduler: Job 0 finished: aggregate at FlagStatSpark.java:73, took 64.566359 s; 1205535516 in total; 0 QC failure; 37791",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888
https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888:8129,Energy Efficiency,schedul,scheduler,8129,"c.bu.edu, executor 7, partition 4, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 5.0 in stage 0.0 (TID 3, scc-q12.scc.bu.edu, executor 2, partition 5, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 0.0 (TID 4, scc-q09.scc.bu.edu, executor 1, partition 2, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 17.0 in stage 0.0 (TID 5, scc-q11.scc.bu.edu, executor 6, partition 17, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 6, scc-q06.scc.bu.edu, executor 5, partition 0, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 0.0 (TID 7, scc-q02.scc.bu.edu, executor 8, partition 3, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 13.0 in stage 0.0 (TID 8, scc-q03.scc.bu.edu, executor 4, partition 13, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 7.0 in stage 0.0 (TID 9, scc-q13.scc.bu.edu, executor 3, partition 7, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 8.0 in stage 0.0 (TID 10, scc-q14.scc.bu.edu, executor 7, partition 8, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 14.0 in stage 0.0 (TID 11, scc-q12.scc.bu.edu, executor 2, partition 14, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 9.0 in stage 0.0 (TID 12, scc-q09.scc.bu.edu, executor 1, parti; ```. Processed 1,2 billion reads in less than 2 minutes..... ```; 18/03/07 20:32:55 INFO scheduler.DAGScheduler: Job 0 finished: aggregate at FlagStatSpark.java:73, took 64.566359 s; 1205535516 in total; 0 QC failure; 37791118 duplicates; 1157122594 mapped (95.98%); 1205535516 paired in sequencing; 602767758 read1; 602767758 read2; 1145853318 properly paired (95.05%); 1150449216 w",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888
https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888:8287,Energy Efficiency,schedul,scheduler,8287,".bu.edu, executor 2, partition 5, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 0.0 (TID 4, scc-q09.scc.bu.edu, executor 1, partition 2, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 17.0 in stage 0.0 (TID 5, scc-q11.scc.bu.edu, executor 6, partition 17, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 6, scc-q06.scc.bu.edu, executor 5, partition 0, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 0.0 (TID 7, scc-q02.scc.bu.edu, executor 8, partition 3, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 13.0 in stage 0.0 (TID 8, scc-q03.scc.bu.edu, executor 4, partition 13, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 7.0 in stage 0.0 (TID 9, scc-q13.scc.bu.edu, executor 3, partition 7, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 8.0 in stage 0.0 (TID 10, scc-q14.scc.bu.edu, executor 7, partition 8, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 14.0 in stage 0.0 (TID 11, scc-q12.scc.bu.edu, executor 2, partition 14, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 9.0 in stage 0.0 (TID 12, scc-q09.scc.bu.edu, executor 1, parti; ```. Processed 1,2 billion reads in less than 2 minutes..... ```; 18/03/07 20:32:55 INFO scheduler.DAGScheduler: Job 0 finished: aggregate at FlagStatSpark.java:73, took 64.566359 s; 1205535516 in total; 0 QC failure; 37791118 duplicates; 1157122594 mapped (95.98%); 1205535516 paired in sequencing; 602767758 read1; 602767758 read2; 1145853318 properly paired (95.05%); 1150449216 with itself and mate mapped; 6673378 singletons (0.55%); 4595898 with mate mapped to a different chr; 3316623 with mate mapped to a different chr (mapQ>=5); 18",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888
https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888:8446,Energy Efficiency,schedul,scheduler,8446,"bu.edu, executor 1, partition 2, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 17.0 in stage 0.0 (TID 5, scc-q11.scc.bu.edu, executor 6, partition 17, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 6, scc-q06.scc.bu.edu, executor 5, partition 0, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 0.0 (TID 7, scc-q02.scc.bu.edu, executor 8, partition 3, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 13.0 in stage 0.0 (TID 8, scc-q03.scc.bu.edu, executor 4, partition 13, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 7.0 in stage 0.0 (TID 9, scc-q13.scc.bu.edu, executor 3, partition 7, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 8.0 in stage 0.0 (TID 10, scc-q14.scc.bu.edu, executor 7, partition 8, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 14.0 in stage 0.0 (TID 11, scc-q12.scc.bu.edu, executor 2, partition 14, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 9.0 in stage 0.0 (TID 12, scc-q09.scc.bu.edu, executor 1, parti; ```. Processed 1,2 billion reads in less than 2 minutes..... ```; 18/03/07 20:32:55 INFO scheduler.DAGScheduler: Job 0 finished: aggregate at FlagStatSpark.java:73, took 64.566359 s; 1205535516 in total; 0 QC failure; 37791118 duplicates; 1157122594 mapped (95.98%); 1205535516 paired in sequencing; 602767758 read1; 602767758 read2; 1145853318 properly paired (95.05%); 1150449216 with itself and mate mapped; 6673378 singletons (0.55%); 4595898 with mate mapped to a different chr; 3316623 with mate mapped to a different chr (mapQ>=5); 18/03/07 20:32:55 INFO server.ServerConnector: Stopped ServerConnector@79f5a6ed{HTTP/1.1}{0.0.0.0:4041}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888
https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888:8607,Energy Efficiency,schedul,scheduler,8607,"u.edu, executor 6, partition 17, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 6, scc-q06.scc.bu.edu, executor 5, partition 0, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 0.0 (TID 7, scc-q02.scc.bu.edu, executor 8, partition 3, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 13.0 in stage 0.0 (TID 8, scc-q03.scc.bu.edu, executor 4, partition 13, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 7.0 in stage 0.0 (TID 9, scc-q13.scc.bu.edu, executor 3, partition 7, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 8.0 in stage 0.0 (TID 10, scc-q14.scc.bu.edu, executor 7, partition 8, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 14.0 in stage 0.0 (TID 11, scc-q12.scc.bu.edu, executor 2, partition 14, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 9.0 in stage 0.0 (TID 12, scc-q09.scc.bu.edu, executor 1, parti; ```. Processed 1,2 billion reads in less than 2 minutes..... ```; 18/03/07 20:32:55 INFO scheduler.DAGScheduler: Job 0 finished: aggregate at FlagStatSpark.java:73, took 64.566359 s; 1205535516 in total; 0 QC failure; 37791118 duplicates; 1157122594 mapped (95.98%); 1205535516 paired in sequencing; 602767758 read1; 602767758 read2; 1145853318 properly paired (95.05%); 1150449216 with itself and mate mapped; 6673378 singletons (0.55%); 4595898 with mate mapped to a different chr; 3316623 with mate mapped to a different chr (mapQ>=5); 18/03/07 20:32:55 INFO server.ServerConnector: Stopped ServerConnector@79f5a6ed{HTTP/1.1}{0.0.0.0:4041}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@221ca495{/stages/stage/kill,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888
https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888:8801,Energy Efficiency,schedul,scheduler,8801,"03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 0.0 (TID 7, scc-q02.scc.bu.edu, executor 8, partition 3, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 13.0 in stage 0.0 (TID 8, scc-q03.scc.bu.edu, executor 4, partition 13, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 7.0 in stage 0.0 (TID 9, scc-q13.scc.bu.edu, executor 3, partition 7, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 8.0 in stage 0.0 (TID 10, scc-q14.scc.bu.edu, executor 7, partition 8, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 14.0 in stage 0.0 (TID 11, scc-q12.scc.bu.edu, executor 2, partition 14, NODE_LOCAL, 6107 bytes); 18/03/07 20:31:51 INFO scheduler.TaskSetManager: Starting task 9.0 in stage 0.0 (TID 12, scc-q09.scc.bu.edu, executor 1, parti; ```. Processed 1,2 billion reads in less than 2 minutes..... ```; 18/03/07 20:32:55 INFO scheduler.DAGScheduler: Job 0 finished: aggregate at FlagStatSpark.java:73, took 64.566359 s; 1205535516 in total; 0 QC failure; 37791118 duplicates; 1157122594 mapped (95.98%); 1205535516 paired in sequencing; 602767758 read1; 602767758 read2; 1145853318 properly paired (95.05%); 1150449216 with itself and mate mapped; 6673378 singletons (0.55%); 4595898 with mate mapped to a different chr; 3316623 with mate mapped to a different chr (mapQ>=5); 18/03/07 20:32:55 INFO server.ServerConnector: Stopped ServerConnector@79f5a6ed{HTTP/1.1}{0.0.0.0:4041}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@221ca495{/stages/stage/kill,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@28b458e6{/jobs/job/kill,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@3ccb12d{/api,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888
https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888:12670,Energy Efficiency,monitor,monitor,12670,"ler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@64a1116a{/stages/stage,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@c5e69a5{/stages/json,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@10131289{/stages,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@50f4b83d{/jobs/job/json,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@5d66ae3a{/jobs/job,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@30159886{/jobs/json,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@33de7f3d{/jobs,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO ui.SparkUI: Stopped Spark web UI at http://10.48.225.55:4041; 18/03/07 20:32:55 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread; 18/03/07 20:32:55 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors; 18/03/07 20:32:55 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down; 18/03/07 20:32:55 INFO cluster.SchedulerExtensionServices: Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 18/03/07 20:32:55 INFO cluster.YarnClientSchedulerBackend: Stopped; 18/03/07 20:32:55 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 18/03/07 20:32:55 INFO memory.MemoryStore: MemoryStore cleared; 18/03/07 20:32:55 INFO storage.BlockManager: BlockManager stopped; 18/03/07 20:32:55 INFO storage.BlockManagerMaster: BlockManagerMaster stopped; 18/03/07 20:32:55 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 18/03/07 20:32:55 INFO spark.SparkContext: Successfully stopped SparkContext; 20:32:55.769 INFO FlagStatSpark - Shutting down engine; [M",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888
https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888:12912,Energy Efficiency,Schedul,SchedulerExtensionServices,12912,"289{/stages,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@50f4b83d{/jobs/job/json,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@5d66ae3a{/jobs/job,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@30159886{/jobs/json,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@33de7f3d{/jobs,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO ui.SparkUI: Stopped Spark web UI at http://10.48.225.55:4041; 18/03/07 20:32:55 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread; 18/03/07 20:32:55 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors; 18/03/07 20:32:55 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down; 18/03/07 20:32:55 INFO cluster.SchedulerExtensionServices: Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 18/03/07 20:32:55 INFO cluster.YarnClientSchedulerBackend: Stopped; 18/03/07 20:32:55 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 18/03/07 20:32:55 INFO memory.MemoryStore: MemoryStore cleared; 18/03/07 20:32:55 INFO storage.BlockManager: BlockManager stopped; 18/03/07 20:32:55 INFO storage.BlockManagerMaster: BlockManagerMaster stopped; 18/03/07 20:32:55 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 18/03/07 20:32:55 INFO spark.SparkContext: Successfully stopped SparkContext; 20:32:55.769 INFO FlagStatSpark - Shutting down engine; [March 7, 2018 8:32:55 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.FlagStatSpark done. Elapsed time: 1.60 minutes.; Runtime.totalMemory()=2091384832; 18/03/07 20:32:55 INFO util.ShutdownHookManager: Shutdown hook called; 18/03/07 20:32:55 INFO util.ShutdownHookManager: Deleting directory /tmp/farrell",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888
https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888:12949,Energy Efficiency,Schedul,SchedulerExtensionServices,12949,"289{/stages,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@50f4b83d{/jobs/job/json,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@5d66ae3a{/jobs/job,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@30159886{/jobs/json,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@33de7f3d{/jobs,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO ui.SparkUI: Stopped Spark web UI at http://10.48.225.55:4041; 18/03/07 20:32:55 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread; 18/03/07 20:32:55 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors; 18/03/07 20:32:55 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down; 18/03/07 20:32:55 INFO cluster.SchedulerExtensionServices: Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 18/03/07 20:32:55 INFO cluster.YarnClientSchedulerBackend: Stopped; 18/03/07 20:32:55 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 18/03/07 20:32:55 INFO memory.MemoryStore: MemoryStore cleared; 18/03/07 20:32:55 INFO storage.BlockManager: BlockManager stopped; 18/03/07 20:32:55 INFO storage.BlockManagerMaster: BlockManagerMaster stopped; 18/03/07 20:32:55 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 18/03/07 20:32:55 INFO spark.SparkContext: Successfully stopped SparkContext; 20:32:55.769 INFO FlagStatSpark - Shutting down engine; [March 7, 2018 8:32:55 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.FlagStatSpark done. Elapsed time: 1.60 minutes.; Runtime.totalMemory()=2091384832; 18/03/07 20:32:55 INFO util.ShutdownHookManager: Shutdown hook called; 18/03/07 20:32:55 INFO util.ShutdownHookManager: Deleting directory /tmp/farrell",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888
https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888:13436,Energy Efficiency,schedul,scheduler,13436,"ServletContextHandler@50f4b83d{/jobs/job/json,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@5d66ae3a{/jobs/job,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@30159886{/jobs/json,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@33de7f3d{/jobs,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO ui.SparkUI: Stopped Spark web UI at http://10.48.225.55:4041; 18/03/07 20:32:55 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread; 18/03/07 20:32:55 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors; 18/03/07 20:32:55 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down; 18/03/07 20:32:55 INFO cluster.SchedulerExtensionServices: Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 18/03/07 20:32:55 INFO cluster.YarnClientSchedulerBackend: Stopped; 18/03/07 20:32:55 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 18/03/07 20:32:55 INFO memory.MemoryStore: MemoryStore cleared; 18/03/07 20:32:55 INFO storage.BlockManager: BlockManager stopped; 18/03/07 20:32:55 INFO storage.BlockManagerMaster: BlockManagerMaster stopped; 18/03/07 20:32:55 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 18/03/07 20:32:55 INFO spark.SparkContext: Successfully stopped SparkContext; 20:32:55.769 INFO FlagStatSpark - Shutting down engine; [March 7, 2018 8:32:55 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.FlagStatSpark done. Elapsed time: 1.60 minutes.; Runtime.totalMemory()=2091384832; 18/03/07 20:32:55 INFO util.ShutdownHookManager: Shutdown hook called; 18/03/07 20:32:55 INFO util.ShutdownHookManager: Deleting directory /tmp/farrell/spark-9e0f0525-00f3-4b37-b1d2-4cf55b4c8cb0. real 1m41.113s; user 0m49.698s; sys 0m4.432s. ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888
https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888:5073,Security,secur,security,5073," with 25.4 GB RAM, BlockManagerId(7, scc-q14.scc.bu.edu, 36726, None); 18/03/07 20:31:49 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(null) (192.168.18.195:47862) with ID 6; 18/03/07 20:31:49 INFO storage.BlockManagerMasterEndpoint: Registering block manager scc-q11.scc.bu.edu:46002 with 25.4 GB RAM, BlockManagerId(6, scc-q11.scc.bu.edu, 46002, None); 18/03/07 20:31:49 INFO memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 246.6 KB, free 8.4 GB); 18/03/07 20:31:50 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 25.3 KB, free 8.4 GB); 18/03/07 20:31:50 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.48.225.55:41567 (size: 25.3 KB, free: 8.4 GB); 18/03/07 20:31:50 INFO spark.SparkContext: Created broadcast 0 from newAPIHadoopFile at ReadsSparkSource.java:112; 18/03/07 20:31:50 INFO hdfs.DFSClient: Created HDFS_DELEGATION_TOKEN token 7175 for farrell on ha-hdfs:scc; 18/03/07 20:31:50 INFO security.TokenCache: Got dt for hdfs://scc; Kind: HDFS_DELEGATION_TOKEN, Service: ha-hdfs:scc, Ident: (HDFS_DELEGATION_TOKEN token 7175 for farrell); 18/03/07 20:31:50 INFO input.FileInputFormat: Total input paths to process : 1; 18/03/07 20:31:51 INFO spark.SparkContext: Starting job: aggregate at FlagStatSpark.java:73; 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Got job 0 (aggregate at FlagStatSpark.java:73) with 629 output partitions; 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (aggregate at FlagStatSpark.java:73); 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Parents of final stage: List(); 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Missing parents: List(); 18/03/07 20:31:51 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at filter at GATKSparkTool.java:220), which has no missing parents; 18/03/07 20:31:51 INFO memory.MemoryStore: Block broadcast_1 stored as values in mem",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888
https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888:258,Testability,test,testing,258,"@lbergelson . I ran the FlagStatSpark tool on a bam with a splitting-index on the hdfs. It ran blazing fast with no delay at all with a total time of 1m41s. So it looks like it must be related to the splits on the cram. I see a similar delay(30-40 min) when testing the StructuralVariationDiscoveryPipelineSpark jobs on 50 crams. Below are some excerpts from the log of the fast FlagStatSpark on the bam. . No delay and tasks start right up....; ```; 18/03/07 20:31:40 INFO cluster.YarnClientSchedulerBackend: Application application_1507317228518_0369 has started running.; 18/03/07 20:31:40 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41567.; 18/03/07 20:31:40 INFO netty.NettyBlockTransferService: Server created on 10.48.225.55:41567; 18/03/07 20:31:40 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy; 18/03/07 20:31:40 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.48.225.55, 41567, None); 18/03/07 20:31:40 INFO storage.BlockManagerMasterEndpoint: Registering block manager 10.48.225.55:41567 with 8.4 GB RAM, BlockManagerId(driver, 10.48.225.55, 41567, None); 18/03/07 20:31:40 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.48.225.55, 41567, None); 18/03/07 20:31:40 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.48.225.55, 41567, None); 18/03/07 20:31:40 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4d9cf71d{/metrics/json,null,AVAILABLE}; 18/03/07 20:31:48 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(null) (192.168.18.186:36002) with ID 8; 18/03/07 20:31:48 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(null) (192.168.18.196:45956) with ID 2; 18/03/07 20:31:48 INFO storage.BlockManagerMasterEndpoint: Registering block manag",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888
https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888:363,Testability,log,log,363,"@lbergelson . I ran the FlagStatSpark tool on a bam with a splitting-index on the hdfs. It ran blazing fast with no delay at all with a total time of 1m41s. So it looks like it must be related to the splits on the cram. I see a similar delay(30-40 min) when testing the StructuralVariationDiscoveryPipelineSpark jobs on 50 crams. Below are some excerpts from the log of the fast FlagStatSpark on the bam. . No delay and tasks start right up....; ```; 18/03/07 20:31:40 INFO cluster.YarnClientSchedulerBackend: Application application_1507317228518_0369 has started running.; 18/03/07 20:31:40 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41567.; 18/03/07 20:31:40 INFO netty.NettyBlockTransferService: Server created on 10.48.225.55:41567; 18/03/07 20:31:40 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy; 18/03/07 20:31:40 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.48.225.55, 41567, None); 18/03/07 20:31:40 INFO storage.BlockManagerMasterEndpoint: Registering block manager 10.48.225.55:41567 with 8.4 GB RAM, BlockManagerId(driver, 10.48.225.55, 41567, None); 18/03/07 20:31:40 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.48.225.55, 41567, None); 18/03/07 20:31:40 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.48.225.55, 41567, None); 18/03/07 20:31:40 INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4d9cf71d{/metrics/json,null,AVAILABLE}; 18/03/07 20:31:48 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(null) (192.168.18.186:36002) with ID 8; 18/03/07 20:31:48 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(null) (192.168.18.196:45956) with ID 2; 18/03/07 20:31:48 INFO storage.BlockManagerMasterEndpoint: Registering block manag",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888
https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888:13258,Usability,clear,cleared,13258,"ServletContextHandler@50f4b83d{/jobs/job/json,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@5d66ae3a{/jobs/job,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@30159886{/jobs/json,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@33de7f3d{/jobs,null,UNAVAILABLE}; 18/03/07 20:32:55 INFO ui.SparkUI: Stopped Spark web UI at http://10.48.225.55:4041; 18/03/07 20:32:55 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread; 18/03/07 20:32:55 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors; 18/03/07 20:32:55 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down; 18/03/07 20:32:55 INFO cluster.SchedulerExtensionServices: Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 18/03/07 20:32:55 INFO cluster.YarnClientSchedulerBackend: Stopped; 18/03/07 20:32:55 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 18/03/07 20:32:55 INFO memory.MemoryStore: MemoryStore cleared; 18/03/07 20:32:55 INFO storage.BlockManager: BlockManager stopped; 18/03/07 20:32:55 INFO storage.BlockManagerMaster: BlockManagerMaster stopped; 18/03/07 20:32:55 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 18/03/07 20:32:55 INFO spark.SparkContext: Successfully stopped SparkContext; 20:32:55.769 INFO FlagStatSpark - Shutting down engine; [March 7, 2018 8:32:55 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.FlagStatSpark done. Elapsed time: 1.60 minutes.; Runtime.totalMemory()=2091384832; 18/03/07 20:32:55 INFO util.ShutdownHookManager: Shutdown hook called; 18/03/07 20:32:55 INFO util.ShutdownHookManager: Deleting directory /tmp/farrell/spark-9e0f0525-00f3-4b37-b1d2-4cf55b4c8cb0. real 1m41.113s; user 0m49.698s; sys 0m4.432s. ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-371353888
https://github.com/broadinstitute/gatk/issues/4506#issuecomment-373078699:822,Deployability,Configurat,Configuration,822,"@cmnbroad @lbergelson The cram index looks like it has all the info required to generate the splits without using the CramContainerIterator to look at the cram file directly. . Could using the crai index for splits be a potential solution to the glacially slow cram split generation? ; ; CRAM index. A CRAM index is a gzipped tab delimited file containing the following columns:; 1. Sequence id; 2. Alignment start; 3. Alignment span; 4. **Container start byte offset in the file**; 5. Slice start byte offset in the container data (‘blocks’); 6. Slice bytes; Each line represents a slice in the CRAM file. Please note that all slices must be listed in index file. In Hadoop-bam this code could read the crai instead of the cram to find the container boundaries. public List<InputSplit> getSplits(List<InputSplit> splits, Configuration conf); throws IOException {; // update splits to align with CRAM container boundaries; List<InputSplit> newSplits = new ArrayList<InputSplit>();; Map<Path, List<Long>> fileToOffsets = new HashMap<Path, List<Long>>();; for (InputSplit split : splits) {; FileSplit fileSplit = (FileSplit) split;; Path path = fileSplit.getPath();; List<Long> containerOffsets = fileToOffsets.get(path);; if (containerOffsets == null) {; containerOffsets = getContainerOffsets(conf, path);; fileToOffsets.put(path, containerOffsets);; }; long newStart = nextContainerOffset(containerOffsets, fileSplit.getStart());; long newEnd = nextContainerOffset(containerOffsets, fileSplit.getStart() +; fileSplit.getLength());; long newLength = newEnd - newStart;; if (newLength == 0) { // split is wholly within a container; continue;; }; FileSplit newSplit = new FileSplit(fileSplit.getPath(), newStart, newLength,; fileSplit.getLocations());; newSplits.add(newSplit);; }; return newSplits;; }",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-373078699
https://github.com/broadinstitute/gatk/issues/4506#issuecomment-373078699:868,Deployability,update,update,868,"@cmnbroad @lbergelson The cram index looks like it has all the info required to generate the splits without using the CramContainerIterator to look at the cram file directly. . Could using the crai index for splits be a potential solution to the glacially slow cram split generation? ; ; CRAM index. A CRAM index is a gzipped tab delimited file containing the following columns:; 1. Sequence id; 2. Alignment start; 3. Alignment span; 4. **Container start byte offset in the file**; 5. Slice start byte offset in the container data (‘blocks’); 6. Slice bytes; Each line represents a slice in the CRAM file. Please note that all slices must be listed in index file. In Hadoop-bam this code could read the crai instead of the cram to find the container boundaries. public List<InputSplit> getSplits(List<InputSplit> splits, Configuration conf); throws IOException {; // update splits to align with CRAM container boundaries; List<InputSplit> newSplits = new ArrayList<InputSplit>();; Map<Path, List<Long>> fileToOffsets = new HashMap<Path, List<Long>>();; for (InputSplit split : splits) {; FileSplit fileSplit = (FileSplit) split;; Path path = fileSplit.getPath();; List<Long> containerOffsets = fileToOffsets.get(path);; if (containerOffsets == null) {; containerOffsets = getContainerOffsets(conf, path);; fileToOffsets.put(path, containerOffsets);; }; long newStart = nextContainerOffset(containerOffsets, fileSplit.getStart());; long newEnd = nextContainerOffset(containerOffsets, fileSplit.getStart() +; fileSplit.getLength());; long newLength = newEnd - newStart;; if (newLength == 0) { // split is wholly within a container; continue;; }; FileSplit newSplit = new FileSplit(fileSplit.getPath(), newStart, newLength,; fileSplit.getLocations());; newSplits.add(newSplit);; }; return newSplits;; }",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-373078699
https://github.com/broadinstitute/gatk/issues/4506#issuecomment-373078699:822,Modifiability,Config,Configuration,822,"@cmnbroad @lbergelson The cram index looks like it has all the info required to generate the splits without using the CramContainerIterator to look at the cram file directly. . Could using the crai index for splits be a potential solution to the glacially slow cram split generation? ; ; CRAM index. A CRAM index is a gzipped tab delimited file containing the following columns:; 1. Sequence id; 2. Alignment start; 3. Alignment span; 4. **Container start byte offset in the file**; 5. Slice start byte offset in the container data (‘blocks’); 6. Slice bytes; Each line represents a slice in the CRAM file. Please note that all slices must be listed in index file. In Hadoop-bam this code could read the crai instead of the cram to find the container boundaries. public List<InputSplit> getSplits(List<InputSplit> splits, Configuration conf); throws IOException {; // update splits to align with CRAM container boundaries; List<InputSplit> newSplits = new ArrayList<InputSplit>();; Map<Path, List<Long>> fileToOffsets = new HashMap<Path, List<Long>>();; for (InputSplit split : splits) {; FileSplit fileSplit = (FileSplit) split;; Path path = fileSplit.getPath();; List<Long> containerOffsets = fileToOffsets.get(path);; if (containerOffsets == null) {; containerOffsets = getContainerOffsets(conf, path);; fileToOffsets.put(path, containerOffsets);; }; long newStart = nextContainerOffset(containerOffsets, fileSplit.getStart());; long newEnd = nextContainerOffset(containerOffsets, fileSplit.getStart() +; fileSplit.getLength());; long newLength = newEnd - newStart;; if (newLength == 0) { // split is wholly within a container; continue;; }; FileSplit newSplit = new FileSplit(fileSplit.getPath(), newStart, newLength,; fileSplit.getLocations());; newSplits.add(newSplit);; }; return newSplits;; }",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-373078699
https://github.com/broadinstitute/gatk/issues/4506#issuecomment-373078699:1024,Security,Hash,HashMap,1024,"@cmnbroad @lbergelson The cram index looks like it has all the info required to generate the splits without using the CramContainerIterator to look at the cram file directly. . Could using the crai index for splits be a potential solution to the glacially slow cram split generation? ; ; CRAM index. A CRAM index is a gzipped tab delimited file containing the following columns:; 1. Sequence id; 2. Alignment start; 3. Alignment span; 4. **Container start byte offset in the file**; 5. Slice start byte offset in the container data (‘blocks’); 6. Slice bytes; Each line represents a slice in the CRAM file. Please note that all slices must be listed in index file. In Hadoop-bam this code could read the crai instead of the cram to find the container boundaries. public List<InputSplit> getSplits(List<InputSplit> splits, Configuration conf); throws IOException {; // update splits to align with CRAM container boundaries; List<InputSplit> newSplits = new ArrayList<InputSplit>();; Map<Path, List<Long>> fileToOffsets = new HashMap<Path, List<Long>>();; for (InputSplit split : splits) {; FileSplit fileSplit = (FileSplit) split;; Path path = fileSplit.getPath();; List<Long> containerOffsets = fileToOffsets.get(path);; if (containerOffsets == null) {; containerOffsets = getContainerOffsets(conf, path);; fileToOffsets.put(path, containerOffsets);; }; long newStart = nextContainerOffset(containerOffsets, fileSplit.getStart());; long newEnd = nextContainerOffset(containerOffsets, fileSplit.getStart() +; fileSplit.getLength());; long newLength = newEnd - newStart;; if (newLength == 0) { // split is wholly within a container; continue;; }; FileSplit newSplit = new FileSplit(fileSplit.getPath(), newStart, newLength,; fileSplit.getLocations());; newSplits.add(newSplit);; }; return newSplits;; }",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-373078699
https://github.com/broadinstitute/gatk/issues/4506#issuecomment-374324770:294,Usability,clear,clear,294,"@tomwhite I just took a look and I did overstate the case when I said CramContainerIterator materializes SAMRecords. It stops short of doing that, but it does crack each container open and iterate through and decompress each data block in each slice in each container as it goes along. Its not clear to me how much this affects the difference in split calc time vs. bam.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-374324770
https://github.com/broadinstitute/gatk/issues/4506#issuecomment-378888320:567,Availability,avail,available,567,"I wrote an alternative to `CramContainerIterator` called `CramContainerHeaderIterator` that doesn't decompress blocks: . https://github.com/tomwhite/Hadoop-BAM/blob/new-bam-other-formats/src/main/java/org/seqdoop/hadoop_bam/spark/CramContainerHeaderIterator.java. On a 6GB CRAM file, `CramContainerIterator` took around 10 minutes to read all the offsets, while `CramContainerHeaderIterator` took less than a minute. Using the `.crai` file took less than a minute too. This was on HDFS; I haven't tried on cloud yet. So I think we should use the `.crai` file if it's available, and fallback to `CramContainerHeaderIterator`.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-378888320
https://github.com/broadinstitute/gatk/issues/4506#issuecomment-379034481:79,Usability,clear,clear,79,"@tomwhite That sounds like a pretty good improvement! For reasons that are not clear to me, htsjdk doesn't generate .crai index files, only .bai, so we'd definitely want something like the CramContainerHeaderIterator method for those. One other thought that occurs to me is that we should think about how to ensure that mates are kept together for CRAM. The spec doesn't require that mates be contained in the same slice, and since the default slices-per-container for both htslib and htsjdk is 1, they don't even have to be in the same container.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-379034481
https://github.com/broadinstitute/gatk/issues/4506#issuecomment-436014646:19,Deployability,release,release,19,There is a initial release of the faster and more accurate replacement for Hadoop-Bam at:. https://github.com/disq-bio/disq. It would be great to see faster reading of crams in spark GATK with this. Any plans for testing this release?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-436014646
https://github.com/broadinstitute/gatk/issues/4506#issuecomment-436014646:226,Deployability,release,release,226,There is a initial release of the faster and more accurate replacement for Hadoop-Bam at:. https://github.com/disq-bio/disq. It would be great to see faster reading of crams in spark GATK with this. Any plans for testing this release?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-436014646
https://github.com/broadinstitute/gatk/issues/4506#issuecomment-436014646:213,Testability,test,testing,213,There is a initial release of the faster and more accurate replacement for Hadoop-Bam at:. https://github.com/disq-bio/disq. It would be great to see faster reading of crams in spark GATK with this. Any plans for testing this release?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4506#issuecomment-436014646
https://github.com/broadinstitute/gatk/pull/4510#issuecomment-371297497:111,Testability,test,test,111,"@sooheelee Are you comfortable reviewing this? The code changes are minimal. Note that there is no ""regression test"" since the test files do not give rise to the scenario you encountered in https://github.com/broadinstitute/dsde-docs/issues/2891. Perhaps we can make sure that we include such a test case when we address https://github.com/broadinstitute/gatk/issues/4007.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4510#issuecomment-371297497
https://github.com/broadinstitute/gatk/pull/4510#issuecomment-371297497:127,Testability,test,test,127,"@sooheelee Are you comfortable reviewing this? The code changes are minimal. Note that there is no ""regression test"" since the test files do not give rise to the scenario you encountered in https://github.com/broadinstitute/dsde-docs/issues/2891. Perhaps we can make sure that we include such a test case when we address https://github.com/broadinstitute/gatk/issues/4007.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4510#issuecomment-371297497
https://github.com/broadinstitute/gatk/pull/4510#issuecomment-371297497:295,Testability,test,test,295,"@sooheelee Are you comfortable reviewing this? The code changes are minimal. Note that there is no ""regression test"" since the test files do not give rise to the scenario you encountered in https://github.com/broadinstitute/dsde-docs/issues/2891. Perhaps we can make sure that we include such a test case when we address https://github.com/broadinstitute/gatk/issues/4007.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4510#issuecomment-371297497
https://github.com/broadinstitute/gatk/pull/4510#issuecomment-371535111:153,Testability,test,test,153,"I'm only in an introductory Java class, geared towards Android app development. So I cannot comment on the code. What I have done is take the branch and test it against the data that I have and I can say the counts now match up to the lower expected value. Furthermore, the four questionable sites are now absent. Before:; ![screenshot 2018-03-08 11 05 38](https://user-images.githubusercontent.com/11543866/37161473-c63273c6-22c0-11e8-9ac6-aeb817fa1a35.png). With changes:; ![screenshot 2018-03-08 11 06 06](https://user-images.githubusercontent.com/11543866/37161478-ca9842f6-22c0-11e8-84d5-6fbebcac1b4c.png). Let me know if and how I can help with your efforts in creating a test if you decide to test for such a scenario.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4510#issuecomment-371535111
https://github.com/broadinstitute/gatk/pull/4510#issuecomment-371535111:678,Testability,test,test,678,"I'm only in an introductory Java class, geared towards Android app development. So I cannot comment on the code. What I have done is take the branch and test it against the data that I have and I can say the counts now match up to the lower expected value. Furthermore, the four questionable sites are now absent. Before:; ![screenshot 2018-03-08 11 05 38](https://user-images.githubusercontent.com/11543866/37161473-c63273c6-22c0-11e8-9ac6-aeb817fa1a35.png). With changes:; ![screenshot 2018-03-08 11 06 06](https://user-images.githubusercontent.com/11543866/37161478-ca9842f6-22c0-11e8-84d5-6fbebcac1b4c.png). Let me know if and how I can help with your efforts in creating a test if you decide to test for such a scenario.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4510#issuecomment-371535111
https://github.com/broadinstitute/gatk/pull/4510#issuecomment-371535111:700,Testability,test,test,700,"I'm only in an introductory Java class, geared towards Android app development. So I cannot comment on the code. What I have done is take the branch and test it against the data that I have and I can say the counts now match up to the lower expected value. Furthermore, the four questionable sites are now absent. Before:; ![screenshot 2018-03-08 11 05 38](https://user-images.githubusercontent.com/11543866/37161473-c63273c6-22c0-11e8-9ac6-aeb817fa1a35.png). With changes:; ![screenshot 2018-03-08 11 06 06](https://user-images.githubusercontent.com/11543866/37161478-ca9842f6-22c0-11e8-84d5-6fbebcac1b4c.png). Let me know if and how I can help with your efforts in creating a test if you decide to test for such a scenario.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4510#issuecomment-371535111
https://github.com/broadinstitute/gatk/issues/4511#issuecomment-371816136:140,Usability,learn,learning-in-,140,Here is a blog regarding the Deep CNN model used for variant filtering.... https://gatkforums.broadinstitute.org/gatk/discussion/10996/deep-learning-in-gatk4,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4511#issuecomment-371816136
https://github.com/broadinstitute/gatk/issues/4511#issuecomment-371836412:95,Usability,simpl,simpler,95,@daquang -- Sam (@lucidtronix ) has already merged the code to run the model inference for his simpler 1D model architecture. I think src/main/resources/org/broadinstitute/hellbender/tools/walkers/vqsr/cnn_1d_annotations.hd5 is what you're looking for. He currently has a PR in review (https://github.com/broadinstitute/gatk/pull/4245) to add the more sophisticated 2D model and a GATK walker to do the training (CNNVariantTrain). That PR should get finalized and merged any day now.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4511#issuecomment-371836412
https://github.com/broadinstitute/gatk/issues/4511#issuecomment-375091383:32,Performance,load,loaded,32,"Thanks, I found the weights and loaded the 1D model. Would it also be possible to get the original training script that generated this model?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4511#issuecomment-375091383
https://github.com/broadinstitute/gatk/issues/4511#issuecomment-375344420:41,Testability,test,test,41,"We've been having some problems with the test server,; but the PR should get merged soon: (https://github.com/broadinstitute/gatk/pull/4245/).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4511#issuecomment-375344420
https://github.com/broadinstitute/gatk/issues/4511#issuecomment-376642209:79,Deployability,release,release,79,"@daquang The Java model training tool was just merged in. We'll probably cut a release soon, but you can build from master if you just can't wait.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4511#issuecomment-376642209
https://github.com/broadinstitute/gatk/issues/4512#issuecomment-371588108:137,Testability,test,test,137,@chandrans Someone will have to take a look in a profiler to see what's going on with these particular samples. Can you add a *runnable* test case that reproduces the issue here (and confirm yourself that you can reproduce it).,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4512#issuecomment-371588108
https://github.com/broadinstitute/gatk/issues/4512#issuecomment-371601351:25,Testability,test,test,25,"Hey David. Yes, I have a test case described in https://github.com/broadinstitute/dsde-docs/issues/2985 that has files and commands that reproduce this. I reproduced it myself last night with 4.0.2.0. I Hope that is okay. If you need me to try 4.0.2.1 I can.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4512#issuecomment-371601351
https://github.com/broadinstitute/gatk/issues/4513#issuecomment-371635375:43,Modifiability,inherit,inherited,43,"Oh, interesting. That's a real problem. We inherited that code from picard and I don't think anyone ever paid attention to it. I'm assuming it's in there because someone encountered a tmp dir they couldn't read/write to but could set permissions on at some point, which seems weird. . At most we should be setting it for owner only I think.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4513#issuecomment-371635375
https://github.com/broadinstitute/gatk/issues/4513#issuecomment-371644801:164,Availability,error,error,164,@andrew-niaid Would changing the setting to only make it read/writeable by the owner of the gatk process be sufficient for you? I'm afraid changing the behavior to error on a non-writable tmpdir would cause people's pipelines to start failing.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4513#issuecomment-371644801
https://github.com/broadinstitute/gatk/issues/4513#issuecomment-371644801:216,Deployability,pipeline,pipelines,216,@andrew-niaid Would changing the setting to only make it read/writeable by the owner of the gatk process be sufficient for you? I'm afraid changing the behavior to error on a non-writable tmpdir would cause people's pipelines to start failing.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4513#issuecomment-371644801
https://github.com/broadinstitute/gatk/issues/4513#issuecomment-371655935:155,Availability,error,error,155,"@lbergelson I think that would be fine. Even now, if gatk is given a TMP_DIR that it can't write to and can't change the permissions on, it fails with the error:. htsjdk.samtools.SAMException: Exception creating temporary directory.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4513#issuecomment-371655935
https://github.com/broadinstitute/gatk/issues/4514#issuecomment-371831740:212,Availability,error,error,212,"Hi Christina (@cristinaluengoagullo ),. The GenomicsDBImport in version 4.0.0.0 has a few bugs that you may or may not encounter, but I'd recommend you run GATK 4.0.1.0 or later. That's admittedly a very cryptic error message. We're working on doing a better job wrapping the GenomicsDB errors into readable GATK User Errors. In the meantime, I have a few ideas. Do you have any unusual annotations in that GVCF? The Vidmap takes information from the VCF header annotation descriptions to figure out how to store annotation values after they're parsed. It's complaining that something is wrong with the type of one of your annotations, so my guess is that there's an annotation that's not described correctly in the header. Can you send the gdbworkspace-gatk/vidmap.json file? A snippet of the input GVCF (ideally with the header) would be good too.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4514#issuecomment-371831740
https://github.com/broadinstitute/gatk/issues/4514#issuecomment-371831740:287,Availability,error,errors,287,"Hi Christina (@cristinaluengoagullo ),. The GenomicsDBImport in version 4.0.0.0 has a few bugs that you may or may not encounter, but I'd recommend you run GATK 4.0.1.0 or later. That's admittedly a very cryptic error message. We're working on doing a better job wrapping the GenomicsDB errors into readable GATK User Errors. In the meantime, I have a few ideas. Do you have any unusual annotations in that GVCF? The Vidmap takes information from the VCF header annotation descriptions to figure out how to store annotation values after they're parsed. It's complaining that something is wrong with the type of one of your annotations, so my guess is that there's an annotation that's not described correctly in the header. Can you send the gdbworkspace-gatk/vidmap.json file? A snippet of the input GVCF (ideally with the header) would be good too.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4514#issuecomment-371831740
https://github.com/broadinstitute/gatk/issues/4514#issuecomment-371831740:318,Availability,Error,Errors,318,"Hi Christina (@cristinaluengoagullo ),. The GenomicsDBImport in version 4.0.0.0 has a few bugs that you may or may not encounter, but I'd recommend you run GATK 4.0.1.0 or later. That's admittedly a very cryptic error message. We're working on doing a better job wrapping the GenomicsDB errors into readable GATK User Errors. In the meantime, I have a few ideas. Do you have any unusual annotations in that GVCF? The Vidmap takes information from the VCF header annotation descriptions to figure out how to store annotation values after they're parsed. It's complaining that something is wrong with the type of one of your annotations, so my guess is that there's an annotation that's not described correctly in the header. Can you send the gdbworkspace-gatk/vidmap.json file? A snippet of the input GVCF (ideally with the header) would be good too.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4514#issuecomment-371831740
https://github.com/broadinstitute/gatk/issues/4514#issuecomment-371831740:218,Integrability,message,message,218,"Hi Christina (@cristinaluengoagullo ),. The GenomicsDBImport in version 4.0.0.0 has a few bugs that you may or may not encounter, but I'd recommend you run GATK 4.0.1.0 or later. That's admittedly a very cryptic error message. We're working on doing a better job wrapping the GenomicsDB errors into readable GATK User Errors. In the meantime, I have a few ideas. Do you have any unusual annotations in that GVCF? The Vidmap takes information from the VCF header annotation descriptions to figure out how to store annotation values after they're parsed. It's complaining that something is wrong with the type of one of your annotations, so my guess is that there's an annotation that's not described correctly in the header. Can you send the gdbworkspace-gatk/vidmap.json file? A snippet of the input GVCF (ideally with the header) would be good too.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4514#issuecomment-371831740
https://github.com/broadinstitute/gatk/issues/4514#issuecomment-371831740:263,Integrability,wrap,wrapping,263,"Hi Christina (@cristinaluengoagullo ),. The GenomicsDBImport in version 4.0.0.0 has a few bugs that you may or may not encounter, but I'd recommend you run GATK 4.0.1.0 or later. That's admittedly a very cryptic error message. We're working on doing a better job wrapping the GenomicsDB errors into readable GATK User Errors. In the meantime, I have a few ideas. Do you have any unusual annotations in that GVCF? The Vidmap takes information from the VCF header annotation descriptions to figure out how to store annotation values after they're parsed. It's complaining that something is wrong with the type of one of your annotations, so my guess is that there's an annotation that's not described correctly in the header. Can you send the gdbworkspace-gatk/vidmap.json file? A snippet of the input GVCF (ideally with the header) would be good too.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4514#issuecomment-371831740
https://github.com/broadinstitute/gatk/issues/4514#issuecomment-372215582:165,Availability,error,error,165,"Hi @ldgauthier,. Thanks for the fast reply. After updating GATK to the latest version and using GenomicsDB 0.9.2, the command works. However, now I get the previous error when I try to run this command:. gatk GenotypeGVCFs -R hsapiens.hs37d5.fasta -V gendb://gdbworkspace -O multi-germline-genotyped.vcf.gz. Here's the vidmap file that was generated with th GenomicsDBImport command:. {; ""fields"":[; {; ""name"":""ID"",; ""type"":[; ""char""; ],; ""length"":[; {; ""variable_length_descriptor"":""var""; }; ]; },; {; ""name"":""LowQual"",; ""type"":[; ""int""; ],; ""vcf_field_class"":[; ""FILTER""; ]; },; {; ""name"":""PASS"",; ""type"":[; ""int""; ],; ""vcf_field_class"":[; ""FILTER""; ]; },; {; ""name"":""AD"",; ""type"":[; ""Integer""; ],; ""vcf_field_class"":[; ""FORMAT""; ],; ""length"":[; {; ""variable_length_descriptor"":""R""; }; ]; },; {; ""name"":""GQ"",; ""type"":[; ""Integer""; ],; ""vcf_field_class"":[; ""FORMAT""; ],; ""length"":[; {; ""variable_length_descriptor"":""1""; }; ]; },; {; ""name"":""GT"",; ""type"":[; ""int""; ],; ""vcf_field_class"":[; ""FORMAT""; ],; ""length"":[; {; ""variable_length_descriptor"":""PP""; }; ]; },; {; ""name"":""MIN_DP"",; ""type"":[; ""Integer""; ],; ""vcf_field_class"":[; ""FORMAT""; ],; ""length"":[; {; ""variable_length_descriptor"":""1""; }; ]; },; {; ""name"":""PGT"",; ""type"":[; ""String""; ],; ""vcf_field_class"":[; ""FORMAT""; ],; ""length"":[; {; ""variable_length_descriptor"":""VAR""; }; ]; },; {; ""name"":""PID"",; ""type"":[; ""String""; ],; ""vcf_field_class"":[; ""FORMAT""; ],; ""length"":[; {; ""variable_length_descriptor"":""VAR""; }; ]; },; {; ""name"":""PL"",; ""type"":[; ""Integer""; ],; ""vcf_field_class"":[; ""FORMAT""; ],; ""length"":[; {; ""variable_length_descriptor"":""G""; }; ]; },; {; ""name"":""SB"",; ""type"":[; ""Integer""; ],; ""vcf_field_class"":[; ""FORMAT""; ],; ""length"":[; {; ""variable_length_descriptor"":""4""; }; ]; },; {; ""name"":""BaseQRankSum"",; ""type"":[; ""Float""; ],; ""vcf_field_class"":[; ""INFO""; ],; ""length"":[; {; ""variable_length_descriptor"":""1""; }; ]; },; {; ""name"":""ClippingRankSum"",; ""type"":[; ""Float""; ],; ""vcf_field_class"":[; ""INFO""; ],; ""length"":[; {; ""varia",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4514#issuecomment-372215582
https://github.com/broadinstitute/gatk/issues/4514#issuecomment-372215582:16016,Availability,down,downsampled,16016,"Block9-10=minGQ=9(inclusive),maxGQ=10(exclusive); ##GVCFBlock90-99=minGQ=90(inclusive),maxGQ=99(exclusive); ##GVCFBlock99-100=minGQ=99(inclusive),maxGQ=100(exclusive); ##INFO=<ID=BaseQRankSum,Number=1,Type=Float,Description=""Z-score from Wilcoxon rank sum test of Alt Vs. Ref base qualities"">; ##INFO=<ID=ClippingRankSum,Number=1,Type=Float,Description=""Z-score From Wilcoxon rank sum test of Alt vs. Ref number of hard clipped bases"">; ##INFO=<ID=DP,Number=1,Type=Integer,Description=""Approximate read depth; some reads may have been filtered"">; ##INFO=<ID=DS,Number=0,Type=Flag,Description=""Were any of the samples downsampled?"">; ##INFO=<ID=END,Number=1,Type=Integer,Description=""Stop position of the interval"">; ##INFO=<ID=ExcessHet,Number=1,Type=Float,Description=""Phred-scaled p-value for exact test of excess heterozygosity"">; ##INFO=<ID=InbreedingCoeff,Number=1,Type=Float,Description=""Inbreeding coefficient as estimated from the genotype likelihoods per-sample when compared against the Hardy-Weinberg expectation"">; ##INFO=<ID=MLEAC,Number=A,Type=Integer,Description=""Maximum likelihood expectation (MLE) for the allele counts (not necessarily the same as the AC), for each ALT allele, in the same order as listed"">; ##INFO=<ID=MLEAF,Number=A,Type=Float,Description=""Maximum likelihood expectation (MLE) for the allele frequency (not necessarily the same as the AF), for each ALT allele, in the same order as listed"">; ##INFO=<ID=MQ,Number=1,Type=Float,Description=""RMS Mapping Quality"">; ##INFO=<ID=MQRankSum,Number=1,Type=Float,Description=""Z-score From Wilcoxon rank sum test of Alt vs. Ref read mapping qualities"">; ##INFO=<ID=RAW_MQ,Number=1,Type=Float,Description=""Raw data for RMS Mapping Quality"">; ##INFO=<ID=ReadPosRankSum,Number=1,Type=Float,Description=""Z-score from Wilcoxon rank sum test of Alt vs. Ref read position bias"">; ##bcftools_normCommand=norm -m +any -O z -o AD0616.10.norm.g.vcf.gz AD0616.10.g.vcf.gz; ##bcftools_normVersion=1.2+htslib-1.2.1; ##contig=<ID=1,length",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4514#issuecomment-372215582
https://github.com/broadinstitute/gatk/issues/4514#issuecomment-372215582:11810,Safety,detect,detect,11810,""":3101046070; },; {; ""name"":""GL000192.1"",; ""length"":547496,; ""tiledb_column_offset"":3101257243; },; {; ""name"":""NC_007605"",; ""length"":171823,; ""tiledb_column_offset"":3101804739; },; {; ""name"":""hs37d5"",; ""length"":35477943,; ""tiledb_column_offset"":3101976562; }; ]; }. And the header generated with GenomicsDBImport is:. ##fileformat=VCFv4.2; ##ALT=<ID=NON_REF,Description=""Represents any possible alternative allele at this location"">; ##FILTER=<ID=LowQual,Description=""Low quality"">; ##FILTER=<ID=PASS,Description=""All filters passed"">; ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Allelic depths for the ref and alt alleles in the order listed"">; ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Approximate read depth (reads with MQ=255 or with bad mates are filtered)"">; ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Genotype Quality"">; ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">; ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block"">; ##FORMAT=<ID=PGT,Number=1,Type=String,Description=""Physical phasing haplotype information, describing how the alternate alleles are phased in relation to one another"">; ##FORMAT=<ID=PID,Number=1,Type=String,Description=""Physical phasing ID information, where each unique ID within a given sample (but not across samples) connects records within a phasing group"">; ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification"">; ##FORMAT=<ID=SB,Number=4,Type=Integer,Description=""Per-sample component statistics which comprise the Fisher's Exact Test to detect strand bias."">; ##GVCFBlock0-1=minGQ=0(inclusive),maxGQ=1(exclusive); ##GVCFBlock1-2=minGQ=1(inclusive),maxGQ=2(exclusive); ##GVCFBlock10-11=minGQ=10(inclusive),maxGQ=11(exclusive); ##GVCFBlock11-12=minGQ=11(inclusive),maxGQ=12(exclusive); ##GVCFBlock12-13=minGQ=12(inclusive),maxGQ=13(exclusive); ##GVCFBlock13-14=minGQ=13(inclusive),maxGQ=14(exclu",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4514#issuecomment-372215582
https://github.com/broadinstitute/gatk/issues/4514#issuecomment-372215582:11802,Testability,Test,Test,11802,""":3101046070; },; {; ""name"":""GL000192.1"",; ""length"":547496,; ""tiledb_column_offset"":3101257243; },; {; ""name"":""NC_007605"",; ""length"":171823,; ""tiledb_column_offset"":3101804739; },; {; ""name"":""hs37d5"",; ""length"":35477943,; ""tiledb_column_offset"":3101976562; }; ]; }. And the header generated with GenomicsDBImport is:. ##fileformat=VCFv4.2; ##ALT=<ID=NON_REF,Description=""Represents any possible alternative allele at this location"">; ##FILTER=<ID=LowQual,Description=""Low quality"">; ##FILTER=<ID=PASS,Description=""All filters passed"">; ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Allelic depths for the ref and alt alleles in the order listed"">; ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Approximate read depth (reads with MQ=255 or with bad mates are filtered)"">; ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Genotype Quality"">; ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">; ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block"">; ##FORMAT=<ID=PGT,Number=1,Type=String,Description=""Physical phasing haplotype information, describing how the alternate alleles are phased in relation to one another"">; ##FORMAT=<ID=PID,Number=1,Type=String,Description=""Physical phasing ID information, where each unique ID within a given sample (but not across samples) connects records within a phasing group"">; ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification"">; ##FORMAT=<ID=SB,Number=4,Type=Integer,Description=""Per-sample component statistics which comprise the Fisher's Exact Test to detect strand bias."">; ##GVCFBlock0-1=minGQ=0(inclusive),maxGQ=1(exclusive); ##GVCFBlock1-2=minGQ=1(inclusive),maxGQ=2(exclusive); ##GVCFBlock10-11=minGQ=10(inclusive),maxGQ=11(exclusive); ##GVCFBlock11-12=minGQ=11(inclusive),maxGQ=12(exclusive); ##GVCFBlock12-13=minGQ=12(inclusive),maxGQ=13(exclusive); ##GVCFBlock13-14=minGQ=13(inclusive),maxGQ=14(exclu",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4514#issuecomment-372215582
https://github.com/broadinstitute/gatk/issues/4514#issuecomment-372215582:15655,Testability,test,test,15655,"e); ##GVCFBlock38-39=minGQ=38(inclusive),maxGQ=39(exclusive); ##GVCFBlock39-40=minGQ=39(inclusive),maxGQ=40(exclusive); ##GVCFBlock4-5=minGQ=4(inclusive),maxGQ=5(exclusive); ##GVCFBlock40-41=minGQ=40(inclusive),maxGQ=41(exclusive); ##GVCFBlock41-42=minGQ=41(inclusive),maxGQ=42(exclusive); ##GVCFBlock42-43=minGQ=42(inclusive),maxGQ=43(exclusive); ##GVCFBlock43-44=minGQ=43(inclusive),maxGQ=44(exclusive); ##GVCFBlock44-45=minGQ=44(inclusive),maxGQ=45(exclusive); ##GVCFBlock45-46=minGQ=45(inclusive),maxGQ=46(exclusive); ##GVCFBlock46-47=minGQ=46(inclusive),maxGQ=47(exclusive); ##GVCFBlock47-48=minGQ=47(inclusive),maxGQ=48(exclusive); ##GVCFBlock48-49=minGQ=48(inclusive),maxGQ=49(exclusive); ##GVCFBlock49-50=minGQ=49(inclusive),maxGQ=50(exclusive); ##GVCFBlock5-6=minGQ=5(inclusive),maxGQ=6(exclusive); ##GVCFBlock50-51=minGQ=50(inclusive),maxGQ=51(exclusive); ##GVCFBlock51-52=minGQ=51(inclusive),maxGQ=52(exclusive); ##GVCFBlock52-53=minGQ=52(inclusive),maxGQ=53(exclusive); ##GVCFBlock53-54=minGQ=53(inclusive),maxGQ=54(exclusive); ##GVCFBlock54-55=minGQ=54(inclusive),maxGQ=55(exclusive); ##GVCFBlock55-56=minGQ=55(inclusive),maxGQ=56(exclusive); ##GVCFBlock56-57=minGQ=56(inclusive),maxGQ=57(exclusive); ##GVCFBlock57-58=minGQ=57(inclusive),maxGQ=58(exclusive); ##GVCFBlock58-59=minGQ=58(inclusive),maxGQ=59(exclusive); ##GVCFBlock59-60=minGQ=59(inclusive),maxGQ=60(exclusive); ##GVCFBlock6-7=minGQ=6(inclusive),maxGQ=7(exclusive); ##GVCFBlock60-70=minGQ=60(inclusive),maxGQ=70(exclusive); ##GVCFBlock7-8=minGQ=7(inclusive),maxGQ=8(exclusive); ##GVCFBlock70-80=minGQ=70(inclusive),maxGQ=80(exclusive); ##GVCFBlock8-9=minGQ=8(inclusive),maxGQ=9(exclusive); ##GVCFBlock80-90=minGQ=80(inclusive),maxGQ=90(exclusive); ##GVCFBlock9-10=minGQ=9(inclusive),maxGQ=10(exclusive); ##GVCFBlock90-99=minGQ=90(inclusive),maxGQ=99(exclusive); ##GVCFBlock99-100=minGQ=99(inclusive),maxGQ=100(exclusive); ##INFO=<ID=BaseQRankSum,Number=1,Type=Float,Description=""Z-score from Wilcoxon rank sum test of Alt Vs.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4514#issuecomment-372215582
https://github.com/broadinstitute/gatk/issues/4514#issuecomment-372215582:15784,Testability,test,test,15784,"(inclusive),maxGQ=55(exclusive); ##GVCFBlock55-56=minGQ=55(inclusive),maxGQ=56(exclusive); ##GVCFBlock56-57=minGQ=56(inclusive),maxGQ=57(exclusive); ##GVCFBlock57-58=minGQ=57(inclusive),maxGQ=58(exclusive); ##GVCFBlock58-59=minGQ=58(inclusive),maxGQ=59(exclusive); ##GVCFBlock59-60=minGQ=59(inclusive),maxGQ=60(exclusive); ##GVCFBlock6-7=minGQ=6(inclusive),maxGQ=7(exclusive); ##GVCFBlock60-70=minGQ=60(inclusive),maxGQ=70(exclusive); ##GVCFBlock7-8=minGQ=7(inclusive),maxGQ=8(exclusive); ##GVCFBlock70-80=minGQ=70(inclusive),maxGQ=80(exclusive); ##GVCFBlock8-9=minGQ=8(inclusive),maxGQ=9(exclusive); ##GVCFBlock80-90=minGQ=80(inclusive),maxGQ=90(exclusive); ##GVCFBlock9-10=minGQ=9(inclusive),maxGQ=10(exclusive); ##GVCFBlock90-99=minGQ=90(inclusive),maxGQ=99(exclusive); ##GVCFBlock99-100=minGQ=99(inclusive),maxGQ=100(exclusive); ##INFO=<ID=BaseQRankSum,Number=1,Type=Float,Description=""Z-score from Wilcoxon rank sum test of Alt Vs. Ref base qualities"">; ##INFO=<ID=ClippingRankSum,Number=1,Type=Float,Description=""Z-score From Wilcoxon rank sum test of Alt vs. Ref number of hard clipped bases"">; ##INFO=<ID=DP,Number=1,Type=Integer,Description=""Approximate read depth; some reads may have been filtered"">; ##INFO=<ID=DS,Number=0,Type=Flag,Description=""Were any of the samples downsampled?"">; ##INFO=<ID=END,Number=1,Type=Integer,Description=""Stop position of the interval"">; ##INFO=<ID=ExcessHet,Number=1,Type=Float,Description=""Phred-scaled p-value for exact test of excess heterozygosity"">; ##INFO=<ID=InbreedingCoeff,Number=1,Type=Float,Description=""Inbreeding coefficient as estimated from the genotype likelihoods per-sample when compared against the Hardy-Weinberg expectation"">; ##INFO=<ID=MLEAC,Number=A,Type=Integer,Description=""Maximum likelihood expectation (MLE) for the allele counts (not necessarily the same as the AC), for each ALT allele, in the same order as listed"">; ##INFO=<ID=MLEAF,Number=A,Type=Float,Description=""Maximum likelihood expectation (MLE) for the allele freque",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4514#issuecomment-372215582
https://github.com/broadinstitute/gatk/issues/4514#issuecomment-372215582:16200,Testability,test,test,16200,"Block9-10=minGQ=9(inclusive),maxGQ=10(exclusive); ##GVCFBlock90-99=minGQ=90(inclusive),maxGQ=99(exclusive); ##GVCFBlock99-100=minGQ=99(inclusive),maxGQ=100(exclusive); ##INFO=<ID=BaseQRankSum,Number=1,Type=Float,Description=""Z-score from Wilcoxon rank sum test of Alt Vs. Ref base qualities"">; ##INFO=<ID=ClippingRankSum,Number=1,Type=Float,Description=""Z-score From Wilcoxon rank sum test of Alt vs. Ref number of hard clipped bases"">; ##INFO=<ID=DP,Number=1,Type=Integer,Description=""Approximate read depth; some reads may have been filtered"">; ##INFO=<ID=DS,Number=0,Type=Flag,Description=""Were any of the samples downsampled?"">; ##INFO=<ID=END,Number=1,Type=Integer,Description=""Stop position of the interval"">; ##INFO=<ID=ExcessHet,Number=1,Type=Float,Description=""Phred-scaled p-value for exact test of excess heterozygosity"">; ##INFO=<ID=InbreedingCoeff,Number=1,Type=Float,Description=""Inbreeding coefficient as estimated from the genotype likelihoods per-sample when compared against the Hardy-Weinberg expectation"">; ##INFO=<ID=MLEAC,Number=A,Type=Integer,Description=""Maximum likelihood expectation (MLE) for the allele counts (not necessarily the same as the AC), for each ALT allele, in the same order as listed"">; ##INFO=<ID=MLEAF,Number=A,Type=Float,Description=""Maximum likelihood expectation (MLE) for the allele frequency (not necessarily the same as the AF), for each ALT allele, in the same order as listed"">; ##INFO=<ID=MQ,Number=1,Type=Float,Description=""RMS Mapping Quality"">; ##INFO=<ID=MQRankSum,Number=1,Type=Float,Description=""Z-score From Wilcoxon rank sum test of Alt vs. Ref read mapping qualities"">; ##INFO=<ID=RAW_MQ,Number=1,Type=Float,Description=""Raw data for RMS Mapping Quality"">; ##INFO=<ID=ReadPosRankSum,Number=1,Type=Float,Description=""Z-score from Wilcoxon rank sum test of Alt vs. Ref read position bias"">; ##bcftools_normCommand=norm -m +any -O z -o AD0616.10.norm.g.vcf.gz AD0616.10.g.vcf.gz; ##bcftools_normVersion=1.2+htslib-1.2.1; ##contig=<ID=1,length",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4514#issuecomment-372215582
https://github.com/broadinstitute/gatk/issues/4514#issuecomment-372215582:16984,Testability,test,test,16984,"Block9-10=minGQ=9(inclusive),maxGQ=10(exclusive); ##GVCFBlock90-99=minGQ=90(inclusive),maxGQ=99(exclusive); ##GVCFBlock99-100=minGQ=99(inclusive),maxGQ=100(exclusive); ##INFO=<ID=BaseQRankSum,Number=1,Type=Float,Description=""Z-score from Wilcoxon rank sum test of Alt Vs. Ref base qualities"">; ##INFO=<ID=ClippingRankSum,Number=1,Type=Float,Description=""Z-score From Wilcoxon rank sum test of Alt vs. Ref number of hard clipped bases"">; ##INFO=<ID=DP,Number=1,Type=Integer,Description=""Approximate read depth; some reads may have been filtered"">; ##INFO=<ID=DS,Number=0,Type=Flag,Description=""Were any of the samples downsampled?"">; ##INFO=<ID=END,Number=1,Type=Integer,Description=""Stop position of the interval"">; ##INFO=<ID=ExcessHet,Number=1,Type=Float,Description=""Phred-scaled p-value for exact test of excess heterozygosity"">; ##INFO=<ID=InbreedingCoeff,Number=1,Type=Float,Description=""Inbreeding coefficient as estimated from the genotype likelihoods per-sample when compared against the Hardy-Weinberg expectation"">; ##INFO=<ID=MLEAC,Number=A,Type=Integer,Description=""Maximum likelihood expectation (MLE) for the allele counts (not necessarily the same as the AC), for each ALT allele, in the same order as listed"">; ##INFO=<ID=MLEAF,Number=A,Type=Float,Description=""Maximum likelihood expectation (MLE) for the allele frequency (not necessarily the same as the AF), for each ALT allele, in the same order as listed"">; ##INFO=<ID=MQ,Number=1,Type=Float,Description=""RMS Mapping Quality"">; ##INFO=<ID=MQRankSum,Number=1,Type=Float,Description=""Z-score From Wilcoxon rank sum test of Alt vs. Ref read mapping qualities"">; ##INFO=<ID=RAW_MQ,Number=1,Type=Float,Description=""Raw data for RMS Mapping Quality"">; ##INFO=<ID=ReadPosRankSum,Number=1,Type=Float,Description=""Z-score from Wilcoxon rank sum test of Alt vs. Ref read position bias"">; ##bcftools_normCommand=norm -m +any -O z -o AD0616.10.norm.g.vcf.gz AD0616.10.g.vcf.gz; ##bcftools_normVersion=1.2+htslib-1.2.1; ##contig=<ID=1,length",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4514#issuecomment-372215582
https://github.com/broadinstitute/gatk/issues/4514#issuecomment-372215582:17207,Testability,test,test,17207,"l"">; ##INFO=<ID=ExcessHet,Number=1,Type=Float,Description=""Phred-scaled p-value for exact test of excess heterozygosity"">; ##INFO=<ID=InbreedingCoeff,Number=1,Type=Float,Description=""Inbreeding coefficient as estimated from the genotype likelihoods per-sample when compared against the Hardy-Weinberg expectation"">; ##INFO=<ID=MLEAC,Number=A,Type=Integer,Description=""Maximum likelihood expectation (MLE) for the allele counts (not necessarily the same as the AC), for each ALT allele, in the same order as listed"">; ##INFO=<ID=MLEAF,Number=A,Type=Float,Description=""Maximum likelihood expectation (MLE) for the allele frequency (not necessarily the same as the AF), for each ALT allele, in the same order as listed"">; ##INFO=<ID=MQ,Number=1,Type=Float,Description=""RMS Mapping Quality"">; ##INFO=<ID=MQRankSum,Number=1,Type=Float,Description=""Z-score From Wilcoxon rank sum test of Alt vs. Ref read mapping qualities"">; ##INFO=<ID=RAW_MQ,Number=1,Type=Float,Description=""Raw data for RMS Mapping Quality"">; ##INFO=<ID=ReadPosRankSum,Number=1,Type=Float,Description=""Z-score from Wilcoxon rank sum test of Alt vs. Ref read position bias"">; ##bcftools_normCommand=norm -m +any -O z -o AD0616.10.norm.g.vcf.gz AD0616.10.g.vcf.gz; ##bcftools_normVersion=1.2+htslib-1.2.1; ##contig=<ID=1,length=249250621>; ##contig=<ID=2,length=243199373>; ##contig=<ID=3,length=198022430>; ##contig=<ID=4,length=191154276>; ##contig=<ID=5,length=180915260>; ##contig=<ID=6,length=171115067>; ##contig=<ID=7,length=159138663>; ##contig=<ID=8,length=146364022>; ##contig=<ID=9,length=141213431>; ##contig=<ID=10,length=135534747>; ##contig=<ID=11,length=135006516>; ##contig=<ID=12,length=133851895>; ##contig=<ID=13,length=115169878>; ##contig=<ID=14,length=107349540>; ##contig=<ID=15,length=102531392>; ##contig=<ID=16,length=90354753>; ##contig=<ID=17,length=81195210>; ##contig=<ID=18,length=78077248>; ##contig=<ID=19,length=59128983>; ##contig=<ID=20,length=63025520>; ##contig=<ID=21,length=48129895>; ##contig=<ID=",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4514#issuecomment-372215582
https://github.com/broadinstitute/gatk/issues/4514#issuecomment-372380414:190,Availability,error,error,190,"I tried removing the workspace I had and running GenomicsDBImport and GenotypeGVCFs with the same GATK version (4.0.2.1 and GenomicsDB version 0.9.2), and unfortunately I still get the same error when I run the GenotypeGVCFs command (the GenomicsDBImport command finishes correctly). I will check the instructions to share data and generate a smaller example with random data that can resproduce the error, since the files I'm using are private. ; Thanks again!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4514#issuecomment-372380414
https://github.com/broadinstitute/gatk/issues/4514#issuecomment-372380414:400,Availability,error,error,400,"I tried removing the workspace I had and running GenomicsDBImport and GenotypeGVCFs with the same GATK version (4.0.2.1 and GenomicsDB version 0.9.2), and unfortunately I still get the same error when I run the GenotypeGVCFs command (the GenomicsDBImport command finishes correctly). I will check the instructions to share data and generate a smaller example with random data that can resproduce the error, since the files I'm using are private. ; Thanks again!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4514#issuecomment-372380414
https://github.com/broadinstitute/gatk/issues/4514#issuecomment-372703813:38,Availability,error,error,38,I uploaded the files to reproduce the error following the instructions in: https://software.broadinstitute.org/gatk/documentation/article.php?id=1894. The file I uploaded to the ftp is called issue4514.tar.gz.; Thanks.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4514#issuecomment-372703813
https://github.com/broadinstitute/gatk/issues/4514#issuecomment-373122582:90,Availability,error,error,90,"@cristinaluengoagullo Hi Cristina. I just tried running your files, and I did not get any error. I used version 4.0.2.0 and ran the command in your command.txt file",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4514#issuecomment-373122582
https://github.com/broadinstitute/gatk/issues/4514#issuecomment-373131454:112,Availability,error,errors,112,"Hi @chandrans, thanks for the reply! Could you try with GATK 4.0.2.1 please? It's the version that gives me the errors. ; Thanks again,. Cristina.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4514#issuecomment-373131454
https://github.com/broadinstitute/gatk/issues/4515#issuecomment-373250134:102,Availability,error,error,102,"@Tintest Sorry for the slow reply. I'm not sure exactly what the issue is. I've never seen this exact error before. . I have two guesses, one is that there's something really weird going on in spark that's causing that null pointer exception which is killing the heartbeat. I'm not sure how to debug that without your access to your input data . The other theory which I think is more likely, is that you're running out of memory and it's causing weird errors to occur. How much memory is available to your job? You can set the java -Xmx value with `--java-options ""-Xmx120g""` as a GATK option. I would check that you're not running out of memory on your machine, or giving the job too little. I think for BaseRecalibratorSpark you want at least 2-4g per core, but haven't tested it in a long time so I might be wrong about that.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4515#issuecomment-373250134
https://github.com/broadinstitute/gatk/issues/4515#issuecomment-373250134:263,Availability,heartbeat,heartbeat,263,"@Tintest Sorry for the slow reply. I'm not sure exactly what the issue is. I've never seen this exact error before. . I have two guesses, one is that there's something really weird going on in spark that's causing that null pointer exception which is killing the heartbeat. I'm not sure how to debug that without your access to your input data . The other theory which I think is more likely, is that you're running out of memory and it's causing weird errors to occur. How much memory is available to your job? You can set the java -Xmx value with `--java-options ""-Xmx120g""` as a GATK option. I would check that you're not running out of memory on your machine, or giving the job too little. I think for BaseRecalibratorSpark you want at least 2-4g per core, but haven't tested it in a long time so I might be wrong about that.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4515#issuecomment-373250134
https://github.com/broadinstitute/gatk/issues/4515#issuecomment-373250134:453,Availability,error,errors,453,"@Tintest Sorry for the slow reply. I'm not sure exactly what the issue is. I've never seen this exact error before. . I have two guesses, one is that there's something really weird going on in spark that's causing that null pointer exception which is killing the heartbeat. I'm not sure how to debug that without your access to your input data . The other theory which I think is more likely, is that you're running out of memory and it's causing weird errors to occur. How much memory is available to your job? You can set the java -Xmx value with `--java-options ""-Xmx120g""` as a GATK option. I would check that you're not running out of memory on your machine, or giving the job too little. I think for BaseRecalibratorSpark you want at least 2-4g per core, but haven't tested it in a long time so I might be wrong about that.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4515#issuecomment-373250134
https://github.com/broadinstitute/gatk/issues/4515#issuecomment-373250134:489,Availability,avail,available,489,"@Tintest Sorry for the slow reply. I'm not sure exactly what the issue is. I've never seen this exact error before. . I have two guesses, one is that there's something really weird going on in spark that's causing that null pointer exception which is killing the heartbeat. I'm not sure how to debug that without your access to your input data . The other theory which I think is more likely, is that you're running out of memory and it's causing weird errors to occur. How much memory is available to your job? You can set the java -Xmx value with `--java-options ""-Xmx120g""` as a GATK option. I would check that you're not running out of memory on your machine, or giving the job too little. I think for BaseRecalibratorSpark you want at least 2-4g per core, but haven't tested it in a long time so I might be wrong about that.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4515#issuecomment-373250134
https://github.com/broadinstitute/gatk/issues/4515#issuecomment-373250134:318,Security,access,access,318,"@Tintest Sorry for the slow reply. I'm not sure exactly what the issue is. I've never seen this exact error before. . I have two guesses, one is that there's something really weird going on in spark that's causing that null pointer exception which is killing the heartbeat. I'm not sure how to debug that without your access to your input data . The other theory which I think is more likely, is that you're running out of memory and it's causing weird errors to occur. How much memory is available to your job? You can set the java -Xmx value with `--java-options ""-Xmx120g""` as a GATK option. I would check that you're not running out of memory on your machine, or giving the job too little. I think for BaseRecalibratorSpark you want at least 2-4g per core, but haven't tested it in a long time so I might be wrong about that.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4515#issuecomment-373250134
https://github.com/broadinstitute/gatk/issues/4515#issuecomment-373250134:773,Testability,test,tested,773,"@Tintest Sorry for the slow reply. I'm not sure exactly what the issue is. I've never seen this exact error before. . I have two guesses, one is that there's something really weird going on in spark that's causing that null pointer exception which is killing the heartbeat. I'm not sure how to debug that without your access to your input data . The other theory which I think is more likely, is that you're running out of memory and it's causing weird errors to occur. How much memory is available to your job? You can set the java -Xmx value with `--java-options ""-Xmx120g""` as a GATK option. I would check that you're not running out of memory on your machine, or giving the job too little. I think for BaseRecalibratorSpark you want at least 2-4g per core, but haven't tested it in a long time so I might be wrong about that.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4515#issuecomment-373250134
https://github.com/broadinstitute/gatk/issues/4515#issuecomment-373298078:245,Energy Efficiency,power,powerful,245,"Thank you @lbergelson for your answer. The memory I'm using is specified by nextflow, but I could also force it to Java. . My machine got 64 go of memory and 24 cores. 2go by cores is ok but more could be problematic. Maybe I will try on a more powerful one and I will tell you how is it going. Does the Spark strategy really needs more memory ? I've seen memory usage peaks around 60 go before crash with the spark tool and around 25go with the ""classic"" version (which complete the run without any issue). Thank you.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4515#issuecomment-373298078
https://github.com/broadinstitute/gatk/issues/4515#issuecomment-421544535:239,Availability,ERROR,ERROR,239,I got the same problem during init the reference; The total memory is 991428608???. ```; org.broadinstitute.hellbender.tools.spark.BaseRecalibratorSpark done. Elapsed time: 0.13 minutes.; Runtime.totalMemory()=991428608; 18/09/15 17:21:28 ERROR yarn.ApplicationMaster: User class threw exception: java.lang.OutOfMemoryError: Java heap space; java.lang.OutOfMemoryError: Java heap space; 	at java.util.Arrays.copyOf(Arrays.java:3236); 	at java.io.ByteArrayOutputStream.grow(ByteArrayOutputStream.java:118); 	at java.io.ByteArrayOutputStream.ensureCapacity(ByteArrayOutputStream.java:93); 	at java.io.ByteArrayOutputStream.write(ByteArrayOutputStream.java:153); 	at org.broadinstitute.hellbender.relocated.com.google.common.io.ByteStreams.copy(ByteStreams.java:74); 	at org.broadinstitute.hellbender.relocated.com.google.common.io.ByteStreams.toByteArray(ByteStreams.java:115); 	at org.broadinstitute.hellbender.engine.spark.datasources.ReferenceTwoBitSource.<init>(ReferenceTwoBitSource.java:40); 	at org.broadinstitute.hellbender.engine.datasources.ReferenceMultiSource.<init>(ReferenceMultiSource.java:42); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeReference(GATKSparkTool.java:500); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeToolInputs(GATKSparkTool.java:468); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:459); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:30); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:135); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:188); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:207); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4515#issuecomment-421544535
https://github.com/broadinstitute/gatk/issues/4515#issuecomment-421544535:2367,Deployability,deploy,deploy,2367,"org.broadinstitute.hellbender.engine.spark.datasources.ReferenceTwoBitSource.<init>(ReferenceTwoBitSource.java:40); 	at org.broadinstitute.hellbender.engine.datasources.ReferenceMultiSource.<init>(ReferenceMultiSource.java:42); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeReference(GATKSparkTool.java:500); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeToolInputs(GATKSparkTool.java:468); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:459); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:30); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:135); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:188); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:207); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.yarn.ApplicationMaster$$anon$2.run(ApplicationMaster.scala:635); 18/09/15 17:21:28 INFO yarn.ApplicationMaster: Final app status: FAILED, exitCode: 15, (reason: User class threw exception: java.lang.OutOfMemoryError: Java heap space); 18/09/15 17:21:28 INFO util.ShutdownHookManager: Shutdown hook called; 18/09/15 17:21:28 INFO util.ShutdownHookManager: Deleting directory /tmp/hadoop-test/nm-local-dir/usercache/test/appcache/application_1537046459822_0001/spark-d0ea2344-815c-4bbf-a11b-35031a9c4940; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4515#issuecomment-421544535
https://github.com/broadinstitute/gatk/issues/4515#issuecomment-421544535:2760,Testability,test,test,2760,"org.broadinstitute.hellbender.engine.spark.datasources.ReferenceTwoBitSource.<init>(ReferenceTwoBitSource.java:40); 	at org.broadinstitute.hellbender.engine.datasources.ReferenceMultiSource.<init>(ReferenceMultiSource.java:42); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeReference(GATKSparkTool.java:500); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeToolInputs(GATKSparkTool.java:468); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:459); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:30); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:135); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:188); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:207); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.yarn.ApplicationMaster$$anon$2.run(ApplicationMaster.scala:635); 18/09/15 17:21:28 INFO yarn.ApplicationMaster: Final app status: FAILED, exitCode: 15, (reason: User class threw exception: java.lang.OutOfMemoryError: Java heap space); 18/09/15 17:21:28 INFO util.ShutdownHookManager: Shutdown hook called; 18/09/15 17:21:28 INFO util.ShutdownHookManager: Deleting directory /tmp/hadoop-test/nm-local-dir/usercache/test/appcache/application_1537046459822_0001/spark-d0ea2344-815c-4bbf-a11b-35031a9c4940; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4515#issuecomment-421544535
https://github.com/broadinstitute/gatk/issues/4515#issuecomment-421544535:2788,Testability,test,test,2788,"org.broadinstitute.hellbender.engine.spark.datasources.ReferenceTwoBitSource.<init>(ReferenceTwoBitSource.java:40); 	at org.broadinstitute.hellbender.engine.datasources.ReferenceMultiSource.<init>(ReferenceMultiSource.java:42); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeReference(GATKSparkTool.java:500); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeToolInputs(GATKSparkTool.java:468); 	at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:459); 	at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:30); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:135); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:188); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:207); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.apache.spark.deploy.yarn.ApplicationMaster$$anon$2.run(ApplicationMaster.scala:635); 18/09/15 17:21:28 INFO yarn.ApplicationMaster: Final app status: FAILED, exitCode: 15, (reason: User class threw exception: java.lang.OutOfMemoryError: Java heap space); 18/09/15 17:21:28 INFO util.ShutdownHookManager: Shutdown hook called; 18/09/15 17:21:28 INFO util.ShutdownHookManager: Deleting directory /tmp/hadoop-test/nm-local-dir/usercache/test/appcache/application_1537046459822_0001/spark-d0ea2344-815c-4bbf-a11b-35031a9c4940; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4515#issuecomment-421544535
https://github.com/broadinstitute/gatk/issues/4516#issuecomment-371856207:242,Performance,perform,performance,242,"Interesting. At some point we do expect to see diminishing returns when adding more cores, because the parts that parellelize poorly will start to dominate, but I would hope that it's with more than 16 cores... . One thing we've seen is that performance can be harmed by using to many cores / executor. We've seen problems due to lock contention within spark on executors that have more than ~8 cores. I might try running 4 executors with 8 cores each and seeing if that's an improvement vs 2 executors with 16 cores each. . We're currently heavily re-writing MarkDuplicatesSpark which may be an improvement in the near future.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4516#issuecomment-371856207
https://github.com/broadinstitute/gatk/pull/4517#issuecomment-371862381:2131,Testability,test,test,2131,cy93YWxrZXJzL3Zxc3IvVmFyaWFudFJlY2FsaWJyYXRvci5qYXZh) | `59.223% <ø> (ø)` | `58 <0> (ø)` | :arrow_down: |; | [...ellbender/engine/filters/VariantFilterLibrary.java](https://codecov.io/gh/broadinstitute/gatk/pull/4517/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZmlsdGVycy9WYXJpYW50RmlsdGVyTGlicmFyeS5qYXZh) | `33.333% <0%> (-16.667%)` | `1% <0%> (ø)` | |; | [...stitute/hellbender/engine/ReferenceDataSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4517/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUmVmZXJlbmNlRGF0YVNvdXJjZS5qYXZh) | `70% <0%> (-10%)` | `7% <0%> (+3%)` | |; | [...stitute/hellbender/engine/ReferenceFileSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4517/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUmVmZXJlbmNlRmlsZVNvdXJjZS5qYXZh) | `65.217% <0%> (-7.51%)` | `8% <0%> (+4%)` | |; | [...titute/hellbender/utils/test/ArgumentsBuilder.java](https://codecov.io/gh/broadinstitute/gatk/pull/4517/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0FyZ3VtZW50c0J1aWxkZXIuamF2YQ==) | `93.151% <0%> (-6.849%)` | `31% <0%> (+12%)` | |; | [...der/tools/walkers/mutect/M2ArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/4517/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9NMkFyZ3VtZW50Q29sbGVjdGlvbi5qYXZh) | `96.774% <0%> (-3.226%)` | `3% <0%> (+2%)` | |; | [.../tools/copynumber/gcnv/IntegerCopyNumberState.java](https://codecov.io/gh/broadinstitute/gatk/pull/4517/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2djbnYvSW50ZWdlckNvcHlOdW1iZXJTdGF0ZS5qYXZh) | `69.231% <0%> (-2.991%)` | `14% <0%> (+4%)` | |; | [...rmats/collections/AbstractLocatableCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/4517/diff?sr,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4517#issuecomment-371862381
https://github.com/broadinstitute/gatk/pull/4517#issuecomment-371871762:138,Integrability,wrap,wrap,138,"Good clarification, but can you clean up the format a little? I'd like to see a colon instead of a comma after note and a hard return two wrap the long line (so that it lines up with the lines above).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4517#issuecomment-371871762
https://github.com/broadinstitute/gatk/pull/4517#issuecomment-386409306:0,Availability,ping,ping,0,ping @chandrans,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4517#issuecomment-386409306
https://github.com/broadinstitute/gatk/issues/4518#issuecomment-372014808:122,Availability,error,error,122,"Repeating the GenotypeGVCFs run on exactly the same input data results in success, so it appears to be a nondeterministic error.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4518#issuecomment-372014808
https://github.com/broadinstitute/gatk/issues/4518#issuecomment-374035037:20,Performance,multi-thread,multi-threading,20,"We aren't using any multi-threading inside the GenomicsDB jar. If there is a way to reproduce this, we can take a look.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4518#issuecomment-374035037
https://github.com/broadinstitute/gatk/issues/4518#issuecomment-425560459:31,Availability,error,errors,31,"Here's some reports of similar errors:. https://sourceware.org/ml/libc-help/2008-05/msg00072.html; https://stackoverflow.com/questions/36221574/random-error-on-mutex-lock. It seems like most commonly this error is caused by forgetting to initialize a `pthread_mutexattr_t`. Although the second answer on this thread claims that it might be due to using the default mutex type instead of a recursive mutex. https://stackoverflow.com/questions/21825291/threading-issues. GenomicsDB may not use pthreads directly, but both tileDB and htslib do, so I think it's worth looking into it. I haven't found any instances of htslib or tileDb using an uninitialized `pthread_mutexattr_t` but it does look like tiledb uses default attributes for pthread_mutex_t instead of setting `PTHREAD_MUTEX_RECURSIVE`, so if that really is an issue maybe that's the problem?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4518#issuecomment-425560459
https://github.com/broadinstitute/gatk/issues/4518#issuecomment-425560459:151,Availability,error,error-on-mutex-lock,151,"Here's some reports of similar errors:. https://sourceware.org/ml/libc-help/2008-05/msg00072.html; https://stackoverflow.com/questions/36221574/random-error-on-mutex-lock. It seems like most commonly this error is caused by forgetting to initialize a `pthread_mutexattr_t`. Although the second answer on this thread claims that it might be due to using the default mutex type instead of a recursive mutex. https://stackoverflow.com/questions/21825291/threading-issues. GenomicsDB may not use pthreads directly, but both tileDB and htslib do, so I think it's worth looking into it. I haven't found any instances of htslib or tileDb using an uninitialized `pthread_mutexattr_t` but it does look like tiledb uses default attributes for pthread_mutex_t instead of setting `PTHREAD_MUTEX_RECURSIVE`, so if that really is an issue maybe that's the problem?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4518#issuecomment-425560459
https://github.com/broadinstitute/gatk/issues/4518#issuecomment-425560459:205,Availability,error,error,205,"Here's some reports of similar errors:. https://sourceware.org/ml/libc-help/2008-05/msg00072.html; https://stackoverflow.com/questions/36221574/random-error-on-mutex-lock. It seems like most commonly this error is caused by forgetting to initialize a `pthread_mutexattr_t`. Although the second answer on this thread claims that it might be due to using the default mutex type instead of a recursive mutex. https://stackoverflow.com/questions/21825291/threading-issues. GenomicsDB may not use pthreads directly, but both tileDB and htslib do, so I think it's worth looking into it. I haven't found any instances of htslib or tileDb using an uninitialized `pthread_mutexattr_t` but it does look like tiledb uses default attributes for pthread_mutex_t instead of setting `PTHREAD_MUTEX_RECURSIVE`, so if that really is an issue maybe that's the problem?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4518#issuecomment-425560459
https://github.com/broadinstitute/gatk/issues/4518#issuecomment-436579324:249,Safety,abort,abort,249,"The last call stack that could be gathered with @droazen pointers to a docker image was -; ```; (gdb) bt; #0 0x00007f1124858067 in __GI_raise (sig=sig@entry=6) at ../nptl/sysdeps/unix/sysv/linux/raise.c:56; #1 0x00007f1124859448 in __GI_abort () at abort.c:89; #2 0x00007f1124851266 in __assert_fail_base (fmt=0x7f1124989f18 ""%s%s%s:%u: %s%sAssertion `%s' failed.\n%n"", ; assertion=assertion@entry=0x7f112520df60 ""new_prio == -1 || (new_prio >= __sched_fifo_min_prio && new_prio <= __sched_fifo_max_prio)"", file=file@entry=0x7f112520df54 ""tpp.c"", line=line@entry=62, ; function=function@entry=0x7f112520e030 <__PRETTY_FUNCTION__.8458> ""__pthread_tpp_change_priority""); at assert.c:92; #3 0x00007f1124851312 in __GI___assert_fail (; assertion=assertion@entry=0x7f112520df60 ""new_prio == -1 || (new_prio >= __sched_fifo_min_prio && new_prio <= __sched_fifo_max_prio)"", file=file@entry=0x7f112520df54 ""tpp.c"", line=line@entry=62, ; function=function@entry=0x7f112520e030 <__PRETTY_FUNCTION__.8458> ""__pthread_tpp_change_priority""); at assert.c:101; #4 0x00007f112520c5ef in __pthread_tpp_change_priority (previous_prio=previous_prio@entry=-1, ; new_prio=new_prio@entry=6271) at tpp.c:60; #5 0x00007f1125201e5f in __pthread_mutex_lock_full (mutex=0x7f111cd7e340) at ../nptl/pthread_mutex_lock.c:453; #6 0x00007f10f4f83a2d in mutex_lock(pthread_mutex_t*) (); from /cromwell_root/tmp.034550cf/root/libtiledbgenomicsdb5206530589131345400.so; #7 0x00007f10f4efe245 in StorageManager::array_close(std::string const&) (); from /cromwell_root/tmp.034550cf/root/libtiledbgenomicsdb5206530589131345400.so; #8 0x00007f10f4efe8b7 in StorageManager::array_iterator_finalize(ArrayIterator*) (); from /cromwell_root/tmp.034550cf/root/libtiledbgenomicsdb5206530589131345400.so; #9 0x00007f10f4ef77af in tiledb_array_iterator_finalize (); from /cromwell_root/tmp.034550cf/root/libtiledbgenomicsdb5206530589131345400.so; #10 0x00007f10f4e44730 in GenomicsDBBCFGenerator::~GenomicsDBBCFGenerator() (); from /cromwell_root/t",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4518#issuecomment-436579324
https://github.com/broadinstitute/gatk/issues/4518#issuecomment-436579324:372,Testability,assert,assertion,372,"The last call stack that could be gathered with @droazen pointers to a docker image was -; ```; (gdb) bt; #0 0x00007f1124858067 in __GI_raise (sig=sig@entry=6) at ../nptl/sysdeps/unix/sysv/linux/raise.c:56; #1 0x00007f1124859448 in __GI_abort () at abort.c:89; #2 0x00007f1124851266 in __assert_fail_base (fmt=0x7f1124989f18 ""%s%s%s:%u: %s%sAssertion `%s' failed.\n%n"", ; assertion=assertion@entry=0x7f112520df60 ""new_prio == -1 || (new_prio >= __sched_fifo_min_prio && new_prio <= __sched_fifo_max_prio)"", file=file@entry=0x7f112520df54 ""tpp.c"", line=line@entry=62, ; function=function@entry=0x7f112520e030 <__PRETTY_FUNCTION__.8458> ""__pthread_tpp_change_priority""); at assert.c:92; #3 0x00007f1124851312 in __GI___assert_fail (; assertion=assertion@entry=0x7f112520df60 ""new_prio == -1 || (new_prio >= __sched_fifo_min_prio && new_prio <= __sched_fifo_max_prio)"", file=file@entry=0x7f112520df54 ""tpp.c"", line=line@entry=62, ; function=function@entry=0x7f112520e030 <__PRETTY_FUNCTION__.8458> ""__pthread_tpp_change_priority""); at assert.c:101; #4 0x00007f112520c5ef in __pthread_tpp_change_priority (previous_prio=previous_prio@entry=-1, ; new_prio=new_prio@entry=6271) at tpp.c:60; #5 0x00007f1125201e5f in __pthread_mutex_lock_full (mutex=0x7f111cd7e340) at ../nptl/pthread_mutex_lock.c:453; #6 0x00007f10f4f83a2d in mutex_lock(pthread_mutex_t*) (); from /cromwell_root/tmp.034550cf/root/libtiledbgenomicsdb5206530589131345400.so; #7 0x00007f10f4efe245 in StorageManager::array_close(std::string const&) (); from /cromwell_root/tmp.034550cf/root/libtiledbgenomicsdb5206530589131345400.so; #8 0x00007f10f4efe8b7 in StorageManager::array_iterator_finalize(ArrayIterator*) (); from /cromwell_root/tmp.034550cf/root/libtiledbgenomicsdb5206530589131345400.so; #9 0x00007f10f4ef77af in tiledb_array_iterator_finalize (); from /cromwell_root/tmp.034550cf/root/libtiledbgenomicsdb5206530589131345400.so; #10 0x00007f10f4e44730 in GenomicsDBBCFGenerator::~GenomicsDBBCFGenerator() (); from /cromwell_root/t",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4518#issuecomment-436579324
https://github.com/broadinstitute/gatk/issues/4518#issuecomment-436579324:382,Testability,assert,assertion,382,"The last call stack that could be gathered with @droazen pointers to a docker image was -; ```; (gdb) bt; #0 0x00007f1124858067 in __GI_raise (sig=sig@entry=6) at ../nptl/sysdeps/unix/sysv/linux/raise.c:56; #1 0x00007f1124859448 in __GI_abort () at abort.c:89; #2 0x00007f1124851266 in __assert_fail_base (fmt=0x7f1124989f18 ""%s%s%s:%u: %s%sAssertion `%s' failed.\n%n"", ; assertion=assertion@entry=0x7f112520df60 ""new_prio == -1 || (new_prio >= __sched_fifo_min_prio && new_prio <= __sched_fifo_max_prio)"", file=file@entry=0x7f112520df54 ""tpp.c"", line=line@entry=62, ; function=function@entry=0x7f112520e030 <__PRETTY_FUNCTION__.8458> ""__pthread_tpp_change_priority""); at assert.c:92; #3 0x00007f1124851312 in __GI___assert_fail (; assertion=assertion@entry=0x7f112520df60 ""new_prio == -1 || (new_prio >= __sched_fifo_min_prio && new_prio <= __sched_fifo_max_prio)"", file=file@entry=0x7f112520df54 ""tpp.c"", line=line@entry=62, ; function=function@entry=0x7f112520e030 <__PRETTY_FUNCTION__.8458> ""__pthread_tpp_change_priority""); at assert.c:101; #4 0x00007f112520c5ef in __pthread_tpp_change_priority (previous_prio=previous_prio@entry=-1, ; new_prio=new_prio@entry=6271) at tpp.c:60; #5 0x00007f1125201e5f in __pthread_mutex_lock_full (mutex=0x7f111cd7e340) at ../nptl/pthread_mutex_lock.c:453; #6 0x00007f10f4f83a2d in mutex_lock(pthread_mutex_t*) (); from /cromwell_root/tmp.034550cf/root/libtiledbgenomicsdb5206530589131345400.so; #7 0x00007f10f4efe245 in StorageManager::array_close(std::string const&) (); from /cromwell_root/tmp.034550cf/root/libtiledbgenomicsdb5206530589131345400.so; #8 0x00007f10f4efe8b7 in StorageManager::array_iterator_finalize(ArrayIterator*) (); from /cromwell_root/tmp.034550cf/root/libtiledbgenomicsdb5206530589131345400.so; #9 0x00007f10f4ef77af in tiledb_array_iterator_finalize (); from /cromwell_root/tmp.034550cf/root/libtiledbgenomicsdb5206530589131345400.so; #10 0x00007f10f4e44730 in GenomicsDBBCFGenerator::~GenomicsDBBCFGenerator() (); from /cromwell_root/t",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4518#issuecomment-436579324
https://github.com/broadinstitute/gatk/issues/4518#issuecomment-436579324:672,Testability,assert,assert,672,"The last call stack that could be gathered with @droazen pointers to a docker image was -; ```; (gdb) bt; #0 0x00007f1124858067 in __GI_raise (sig=sig@entry=6) at ../nptl/sysdeps/unix/sysv/linux/raise.c:56; #1 0x00007f1124859448 in __GI_abort () at abort.c:89; #2 0x00007f1124851266 in __assert_fail_base (fmt=0x7f1124989f18 ""%s%s%s:%u: %s%sAssertion `%s' failed.\n%n"", ; assertion=assertion@entry=0x7f112520df60 ""new_prio == -1 || (new_prio >= __sched_fifo_min_prio && new_prio <= __sched_fifo_max_prio)"", file=file@entry=0x7f112520df54 ""tpp.c"", line=line@entry=62, ; function=function@entry=0x7f112520e030 <__PRETTY_FUNCTION__.8458> ""__pthread_tpp_change_priority""); at assert.c:92; #3 0x00007f1124851312 in __GI___assert_fail (; assertion=assertion@entry=0x7f112520df60 ""new_prio == -1 || (new_prio >= __sched_fifo_min_prio && new_prio <= __sched_fifo_max_prio)"", file=file@entry=0x7f112520df54 ""tpp.c"", line=line@entry=62, ; function=function@entry=0x7f112520e030 <__PRETTY_FUNCTION__.8458> ""__pthread_tpp_change_priority""); at assert.c:101; #4 0x00007f112520c5ef in __pthread_tpp_change_priority (previous_prio=previous_prio@entry=-1, ; new_prio=new_prio@entry=6271) at tpp.c:60; #5 0x00007f1125201e5f in __pthread_mutex_lock_full (mutex=0x7f111cd7e340) at ../nptl/pthread_mutex_lock.c:453; #6 0x00007f10f4f83a2d in mutex_lock(pthread_mutex_t*) (); from /cromwell_root/tmp.034550cf/root/libtiledbgenomicsdb5206530589131345400.so; #7 0x00007f10f4efe245 in StorageManager::array_close(std::string const&) (); from /cromwell_root/tmp.034550cf/root/libtiledbgenomicsdb5206530589131345400.so; #8 0x00007f10f4efe8b7 in StorageManager::array_iterator_finalize(ArrayIterator*) (); from /cromwell_root/tmp.034550cf/root/libtiledbgenomicsdb5206530589131345400.so; #9 0x00007f10f4ef77af in tiledb_array_iterator_finalize (); from /cromwell_root/tmp.034550cf/root/libtiledbgenomicsdb5206530589131345400.so; #10 0x00007f10f4e44730 in GenomicsDBBCFGenerator::~GenomicsDBBCFGenerator() (); from /cromwell_root/t",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4518#issuecomment-436579324
https://github.com/broadinstitute/gatk/issues/4518#issuecomment-436579324:732,Testability,assert,assertion,732,"The last call stack that could be gathered with @droazen pointers to a docker image was -; ```; (gdb) bt; #0 0x00007f1124858067 in __GI_raise (sig=sig@entry=6) at ../nptl/sysdeps/unix/sysv/linux/raise.c:56; #1 0x00007f1124859448 in __GI_abort () at abort.c:89; #2 0x00007f1124851266 in __assert_fail_base (fmt=0x7f1124989f18 ""%s%s%s:%u: %s%sAssertion `%s' failed.\n%n"", ; assertion=assertion@entry=0x7f112520df60 ""new_prio == -1 || (new_prio >= __sched_fifo_min_prio && new_prio <= __sched_fifo_max_prio)"", file=file@entry=0x7f112520df54 ""tpp.c"", line=line@entry=62, ; function=function@entry=0x7f112520e030 <__PRETTY_FUNCTION__.8458> ""__pthread_tpp_change_priority""); at assert.c:92; #3 0x00007f1124851312 in __GI___assert_fail (; assertion=assertion@entry=0x7f112520df60 ""new_prio == -1 || (new_prio >= __sched_fifo_min_prio && new_prio <= __sched_fifo_max_prio)"", file=file@entry=0x7f112520df54 ""tpp.c"", line=line@entry=62, ; function=function@entry=0x7f112520e030 <__PRETTY_FUNCTION__.8458> ""__pthread_tpp_change_priority""); at assert.c:101; #4 0x00007f112520c5ef in __pthread_tpp_change_priority (previous_prio=previous_prio@entry=-1, ; new_prio=new_prio@entry=6271) at tpp.c:60; #5 0x00007f1125201e5f in __pthread_mutex_lock_full (mutex=0x7f111cd7e340) at ../nptl/pthread_mutex_lock.c:453; #6 0x00007f10f4f83a2d in mutex_lock(pthread_mutex_t*) (); from /cromwell_root/tmp.034550cf/root/libtiledbgenomicsdb5206530589131345400.so; #7 0x00007f10f4efe245 in StorageManager::array_close(std::string const&) (); from /cromwell_root/tmp.034550cf/root/libtiledbgenomicsdb5206530589131345400.so; #8 0x00007f10f4efe8b7 in StorageManager::array_iterator_finalize(ArrayIterator*) (); from /cromwell_root/tmp.034550cf/root/libtiledbgenomicsdb5206530589131345400.so; #9 0x00007f10f4ef77af in tiledb_array_iterator_finalize (); from /cromwell_root/tmp.034550cf/root/libtiledbgenomicsdb5206530589131345400.so; #10 0x00007f10f4e44730 in GenomicsDBBCFGenerator::~GenomicsDBBCFGenerator() (); from /cromwell_root/t",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4518#issuecomment-436579324
https://github.com/broadinstitute/gatk/issues/4518#issuecomment-436579324:742,Testability,assert,assertion,742,"The last call stack that could be gathered with @droazen pointers to a docker image was -; ```; (gdb) bt; #0 0x00007f1124858067 in __GI_raise (sig=sig@entry=6) at ../nptl/sysdeps/unix/sysv/linux/raise.c:56; #1 0x00007f1124859448 in __GI_abort () at abort.c:89; #2 0x00007f1124851266 in __assert_fail_base (fmt=0x7f1124989f18 ""%s%s%s:%u: %s%sAssertion `%s' failed.\n%n"", ; assertion=assertion@entry=0x7f112520df60 ""new_prio == -1 || (new_prio >= __sched_fifo_min_prio && new_prio <= __sched_fifo_max_prio)"", file=file@entry=0x7f112520df54 ""tpp.c"", line=line@entry=62, ; function=function@entry=0x7f112520e030 <__PRETTY_FUNCTION__.8458> ""__pthread_tpp_change_priority""); at assert.c:92; #3 0x00007f1124851312 in __GI___assert_fail (; assertion=assertion@entry=0x7f112520df60 ""new_prio == -1 || (new_prio >= __sched_fifo_min_prio && new_prio <= __sched_fifo_max_prio)"", file=file@entry=0x7f112520df54 ""tpp.c"", line=line@entry=62, ; function=function@entry=0x7f112520e030 <__PRETTY_FUNCTION__.8458> ""__pthread_tpp_change_priority""); at assert.c:101; #4 0x00007f112520c5ef in __pthread_tpp_change_priority (previous_prio=previous_prio@entry=-1, ; new_prio=new_prio@entry=6271) at tpp.c:60; #5 0x00007f1125201e5f in __pthread_mutex_lock_full (mutex=0x7f111cd7e340) at ../nptl/pthread_mutex_lock.c:453; #6 0x00007f10f4f83a2d in mutex_lock(pthread_mutex_t*) (); from /cromwell_root/tmp.034550cf/root/libtiledbgenomicsdb5206530589131345400.so; #7 0x00007f10f4efe245 in StorageManager::array_close(std::string const&) (); from /cromwell_root/tmp.034550cf/root/libtiledbgenomicsdb5206530589131345400.so; #8 0x00007f10f4efe8b7 in StorageManager::array_iterator_finalize(ArrayIterator*) (); from /cromwell_root/tmp.034550cf/root/libtiledbgenomicsdb5206530589131345400.so; #9 0x00007f10f4ef77af in tiledb_array_iterator_finalize (); from /cromwell_root/tmp.034550cf/root/libtiledbgenomicsdb5206530589131345400.so; #10 0x00007f10f4e44730 in GenomicsDBBCFGenerator::~GenomicsDBBCFGenerator() (); from /cromwell_root/t",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4518#issuecomment-436579324
https://github.com/broadinstitute/gatk/issues/4518#issuecomment-436579324:1032,Testability,assert,assert,1032,"stack that could be gathered with @droazen pointers to a docker image was -; ```; (gdb) bt; #0 0x00007f1124858067 in __GI_raise (sig=sig@entry=6) at ../nptl/sysdeps/unix/sysv/linux/raise.c:56; #1 0x00007f1124859448 in __GI_abort () at abort.c:89; #2 0x00007f1124851266 in __assert_fail_base (fmt=0x7f1124989f18 ""%s%s%s:%u: %s%sAssertion `%s' failed.\n%n"", ; assertion=assertion@entry=0x7f112520df60 ""new_prio == -1 || (new_prio >= __sched_fifo_min_prio && new_prio <= __sched_fifo_max_prio)"", file=file@entry=0x7f112520df54 ""tpp.c"", line=line@entry=62, ; function=function@entry=0x7f112520e030 <__PRETTY_FUNCTION__.8458> ""__pthread_tpp_change_priority""); at assert.c:92; #3 0x00007f1124851312 in __GI___assert_fail (; assertion=assertion@entry=0x7f112520df60 ""new_prio == -1 || (new_prio >= __sched_fifo_min_prio && new_prio <= __sched_fifo_max_prio)"", file=file@entry=0x7f112520df54 ""tpp.c"", line=line@entry=62, ; function=function@entry=0x7f112520e030 <__PRETTY_FUNCTION__.8458> ""__pthread_tpp_change_priority""); at assert.c:101; #4 0x00007f112520c5ef in __pthread_tpp_change_priority (previous_prio=previous_prio@entry=-1, ; new_prio=new_prio@entry=6271) at tpp.c:60; #5 0x00007f1125201e5f in __pthread_mutex_lock_full (mutex=0x7f111cd7e340) at ../nptl/pthread_mutex_lock.c:453; #6 0x00007f10f4f83a2d in mutex_lock(pthread_mutex_t*) (); from /cromwell_root/tmp.034550cf/root/libtiledbgenomicsdb5206530589131345400.so; #7 0x00007f10f4efe245 in StorageManager::array_close(std::string const&) (); from /cromwell_root/tmp.034550cf/root/libtiledbgenomicsdb5206530589131345400.so; #8 0x00007f10f4efe8b7 in StorageManager::array_iterator_finalize(ArrayIterator*) (); from /cromwell_root/tmp.034550cf/root/libtiledbgenomicsdb5206530589131345400.so; #9 0x00007f10f4ef77af in tiledb_array_iterator_finalize (); from /cromwell_root/tmp.034550cf/root/libtiledbgenomicsdb5206530589131345400.so; #10 0x00007f10f4e44730 in GenomicsDBBCFGenerator::~GenomicsDBBCFGenerator() (); from /cromwell_root/tmp.034550cf/r",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4518#issuecomment-436579324
https://github.com/broadinstitute/gatk/issues/4518#issuecomment-460418712:41,Availability,error,errors,41,4.1 has the improved reporting on system errors. Not sure if it fixes this issue. Would it be possible to include new logs by running 4.1 if you encounter the issue again?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4518#issuecomment-460418712
https://github.com/broadinstitute/gatk/issues/4518#issuecomment-460418712:118,Testability,log,logs,118,4.1 has the improved reporting on system errors. Not sure if it fixes this issue. Would it be possible to include new logs by running 4.1 if you encounter the issue again?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4518#issuecomment-460418712
https://github.com/broadinstitute/gatk/issues/4518#issuecomment-590922424:63,Availability,error,error,63,"I don't remember an explicit fix, but I haven't seen seen that error in a long time and it hasn't come up in production. We can reopen if it pops up again.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4518#issuecomment-590922424
https://github.com/broadinstitute/gatk/issues/4519#issuecomment-372064064:407,Availability,down,download,407,"Thank you for looking into this and sharing the analysis. I always believed that there is _a lot_ to be gained from a decent coverage collection strategy. For example, I have seen Genome STRiP cleanly resolving cases that are essentially impossible to resolve from our raw data. Perhaps we should:. (1) Include genome mappability analysis tracks as a filtering strategy w/ or w/o MQ-based filtering. We can download fairly accurate mappability data based on noisy Illumina-like paired-end reads from here:; https://sourceforge.net/p/gma-bio/wiki/Home/; They have a decent publication too. (2) While a simple fragment-based coverage collection has major pitfalls, I am not quite convinced that one must throw away fragment information altogether. By theoretically considering various SV events (tandem duplication, disperse duplication, deletion, inversion, inter- and intra-contig translocation, etc.), and studying paired-end reads coming from various parts of such SVs case by case and how they would theoretically align to the reference, we can come up with a heuristic counting strategy that gives the most consistent signal for downstream tools. This analysis requires taking into account basic summary statistics such as read and fragment length distribution in order to resolve anomalous fragments to putative SV events. I have worked out a few cases and this is fairly doable.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4519#issuecomment-372064064
https://github.com/broadinstitute/gatk/issues/4519#issuecomment-372064064:1133,Availability,down,downstream,1133,"Thank you for looking into this and sharing the analysis. I always believed that there is _a lot_ to be gained from a decent coverage collection strategy. For example, I have seen Genome STRiP cleanly resolving cases that are essentially impossible to resolve from our raw data. Perhaps we should:. (1) Include genome mappability analysis tracks as a filtering strategy w/ or w/o MQ-based filtering. We can download fairly accurate mappability data based on noisy Illumina-like paired-end reads from here:; https://sourceforge.net/p/gma-bio/wiki/Home/; They have a decent publication too. (2) While a simple fragment-based coverage collection has major pitfalls, I am not quite convinced that one must throw away fragment information altogether. By theoretically considering various SV events (tandem duplication, disperse duplication, deletion, inversion, inter- and intra-contig translocation, etc.), and studying paired-end reads coming from various parts of such SVs case by case and how they would theoretically align to the reference, we can come up with a heuristic counting strategy that gives the most consistent signal for downstream tools. This analysis requires taking into account basic summary statistics such as read and fragment length distribution in order to resolve anomalous fragments to putative SV events. I have worked out a few cases and this is fairly doable.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4519#issuecomment-372064064
https://github.com/broadinstitute/gatk/issues/4519#issuecomment-372064064:601,Usability,simpl,simple,601,"Thank you for looking into this and sharing the analysis. I always believed that there is _a lot_ to be gained from a decent coverage collection strategy. For example, I have seen Genome STRiP cleanly resolving cases that are essentially impossible to resolve from our raw data. Perhaps we should:. (1) Include genome mappability analysis tracks as a filtering strategy w/ or w/o MQ-based filtering. We can download fairly accurate mappability data based on noisy Illumina-like paired-end reads from here:; https://sourceforge.net/p/gma-bio/wiki/Home/; They have a decent publication too. (2) While a simple fragment-based coverage collection has major pitfalls, I am not quite convinced that one must throw away fragment information altogether. By theoretically considering various SV events (tandem duplication, disperse duplication, deletion, inversion, inter- and intra-contig translocation, etc.), and studying paired-end reads coming from various parts of such SVs case by case and how they would theoretically align to the reference, we can come up with a heuristic counting strategy that gives the most consistent signal for downstream tools. This analysis requires taking into account basic summary statistics such as read and fragment length distribution in order to resolve anomalous fragments to putative SV events. I have worked out a few cases and this is fairly doable.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4519#issuecomment-372064064
https://github.com/broadinstitute/gatk/issues/4519#issuecomment-372413152:154,Availability,error,error,154,"(1) I am studying GMS mappability scores. To the best of my knowledge, it is the only such analysis that considers both paired-end reads and base calling error rate characteristic of Illumina machines. We could feed the GMS score as a feature file to the coverage collector tool for filtering. (2) I am also working on the ""optimal strategy"" for different SV types. (3) @samuelklee, do we get the same wavy pattern in other samples in the same region? in other words, it is sample-specific or region-specific?. (4) While fragment-based GC correction is difficult (and probably unnecessary) to perform without keeping a full index of aligned reads (like GS), it might be worthwhile to at least collect per-sample per-interval fragment-based average GC content (perhaps along with other summaries such as average fragment length, MQ, etc). It is easy to show that that the difference between full fragment-based GC correction and correction only using the observed average fragment GC content for the pile-up is of the order of the curvature of the GC curve, which is presumably small. We could collect these statistics either on-the-go during coverage collection, or from the sparse counts table as you suggested before (most sensible approach, once we figure out a way to represent sparse tensors).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4519#issuecomment-372413152
https://github.com/broadinstitute/gatk/issues/4519#issuecomment-372413152:593,Performance,perform,perform,593,"(1) I am studying GMS mappability scores. To the best of my knowledge, it is the only such analysis that considers both paired-end reads and base calling error rate characteristic of Illumina machines. We could feed the GMS score as a feature file to the coverage collector tool for filtering. (2) I am also working on the ""optimal strategy"" for different SV types. (3) @samuelklee, do we get the same wavy pattern in other samples in the same region? in other words, it is sample-specific or region-specific?. (4) While fragment-based GC correction is difficult (and probably unnecessary) to perform without keeping a full index of aligned reads (like GS), it might be worthwhile to at least collect per-sample per-interval fragment-based average GC content (perhaps along with other summaries such as average fragment length, MQ, etc). It is easy to show that that the difference between full fragment-based GC correction and correction only using the observed average fragment GC content for the pile-up is of the order of the curvature of the GC curve, which is presumably small. We could collect these statistics either on-the-go during coverage collection, or from the sparse counts table as you suggested before (most sensible approach, once we figure out a way to represent sparse tensors).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4519#issuecomment-372413152
https://github.com/broadinstitute/gatk/issues/4519#issuecomment-372875222:246,Availability,recover,recover,246,"Hmm, looks like we lose events 1 and 3 with CollectReadCounts at 250bp using analogous ModelSegments parameters. However, I experimented with tweaking the segmentation to work on the copy ratios (rather than the log2 copy ratios), which seems to recover them. Although one of the goals of having evaluations backed by SV truth sets is to tune such parameters/methods, I'm beginning to think that SV integration might benefit from using the CNV tools in a more customized pipeline---especially if maximizing sensitivity at resolutions of ~100bp jointly with breakpoint evidence is the goal. For example, you might imagine a tool that directly uses CNV backend code to collect coverage over regions specified by `-L`, builds a PoN, denoises, and segments on the fly. Or we can put together a custom WDL optimized for sensitivity. Let's discuss in person?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4519#issuecomment-372875222
https://github.com/broadinstitute/gatk/issues/4519#issuecomment-372875222:399,Deployability,integrat,integration,399,"Hmm, looks like we lose events 1 and 3 with CollectReadCounts at 250bp using analogous ModelSegments parameters. However, I experimented with tweaking the segmentation to work on the copy ratios (rather than the log2 copy ratios), which seems to recover them. Although one of the goals of having evaluations backed by SV truth sets is to tune such parameters/methods, I'm beginning to think that SV integration might benefit from using the CNV tools in a more customized pipeline---especially if maximizing sensitivity at resolutions of ~100bp jointly with breakpoint evidence is the goal. For example, you might imagine a tool that directly uses CNV backend code to collect coverage over regions specified by `-L`, builds a PoN, denoises, and segments on the fly. Or we can put together a custom WDL optimized for sensitivity. Let's discuss in person?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4519#issuecomment-372875222
https://github.com/broadinstitute/gatk/issues/4519#issuecomment-372875222:471,Deployability,pipeline,pipeline---especially,471,"Hmm, looks like we lose events 1 and 3 with CollectReadCounts at 250bp using analogous ModelSegments parameters. However, I experimented with tweaking the segmentation to work on the copy ratios (rather than the log2 copy ratios), which seems to recover them. Although one of the goals of having evaluations backed by SV truth sets is to tune such parameters/methods, I'm beginning to think that SV integration might benefit from using the CNV tools in a more customized pipeline---especially if maximizing sensitivity at resolutions of ~100bp jointly with breakpoint evidence is the goal. For example, you might imagine a tool that directly uses CNV backend code to collect coverage over regions specified by `-L`, builds a PoN, denoises, and segments on the fly. Or we can put together a custom WDL optimized for sensitivity. Let's discuss in person?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4519#issuecomment-372875222
https://github.com/broadinstitute/gatk/issues/4519#issuecomment-372875222:399,Integrability,integrat,integration,399,"Hmm, looks like we lose events 1 and 3 with CollectReadCounts at 250bp using analogous ModelSegments parameters. However, I experimented with tweaking the segmentation to work on the copy ratios (rather than the log2 copy ratios), which seems to recover them. Although one of the goals of having evaluations backed by SV truth sets is to tune such parameters/methods, I'm beginning to think that SV integration might benefit from using the CNV tools in a more customized pipeline---especially if maximizing sensitivity at resolutions of ~100bp jointly with breakpoint evidence is the goal. For example, you might imagine a tool that directly uses CNV backend code to collect coverage over regions specified by `-L`, builds a PoN, denoises, and segments on the fly. Or we can put together a custom WDL optimized for sensitivity. Let's discuss in person?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4519#issuecomment-372875222
https://github.com/broadinstitute/gatk/issues/4519#issuecomment-372875222:338,Performance,tune,tune,338,"Hmm, looks like we lose events 1 and 3 with CollectReadCounts at 250bp using analogous ModelSegments parameters. However, I experimented with tweaking the segmentation to work on the copy ratios (rather than the log2 copy ratios), which seems to recover them. Although one of the goals of having evaluations backed by SV truth sets is to tune such parameters/methods, I'm beginning to think that SV integration might benefit from using the CNV tools in a more customized pipeline---especially if maximizing sensitivity at resolutions of ~100bp jointly with breakpoint evidence is the goal. For example, you might imagine a tool that directly uses CNV backend code to collect coverage over regions specified by `-L`, builds a PoN, denoises, and segments on the fly. Or we can put together a custom WDL optimized for sensitivity. Let's discuss in person?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4519#issuecomment-372875222
https://github.com/broadinstitute/gatk/issues/4519#issuecomment-372875222:801,Performance,optimiz,optimized,801,"Hmm, looks like we lose events 1 and 3 with CollectReadCounts at 250bp using analogous ModelSegments parameters. However, I experimented with tweaking the segmentation to work on the copy ratios (rather than the log2 copy ratios), which seems to recover them. Although one of the goals of having evaluations backed by SV truth sets is to tune such parameters/methods, I'm beginning to think that SV integration might benefit from using the CNV tools in a more customized pipeline---especially if maximizing sensitivity at resolutions of ~100bp jointly with breakpoint evidence is the goal. For example, you might imagine a tool that directly uses CNV backend code to collect coverage over regions specified by `-L`, builds a PoN, denoises, and segments on the fly. Or we can put together a custom WDL optimized for sensitivity. Let's discuss in person?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4519#issuecomment-372875222
https://github.com/broadinstitute/gatk/issues/4519#issuecomment-372875222:246,Safety,recover,recover,246,"Hmm, looks like we lose events 1 and 3 with CollectReadCounts at 250bp using analogous ModelSegments parameters. However, I experimented with tweaking the segmentation to work on the copy ratios (rather than the log2 copy ratios), which seems to recover them. Although one of the goals of having evaluations backed by SV truth sets is to tune such parameters/methods, I'm beginning to think that SV integration might benefit from using the CNV tools in a more customized pipeline---especially if maximizing sensitivity at resolutions of ~100bp jointly with breakpoint evidence is the goal. For example, you might imagine a tool that directly uses CNV backend code to collect coverage over regions specified by `-L`, builds a PoN, denoises, and segments on the fly. Or we can put together a custom WDL optimized for sensitivity. Let's discuss in person?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4519#issuecomment-372875222
https://github.com/broadinstitute/gatk/issues/4521#issuecomment-372345798:27,Availability,error,error,27,@jason-weirather I see the error in the config file - this is definitely a bug in the data source release. There will need to be another data sources release to fix this and another data sources bug. I expect that this will be released by end of week. I will run through some additional tests on hg38 data to see if I can duplicate the null pointer exception.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4521#issuecomment-372345798
https://github.com/broadinstitute/gatk/issues/4521#issuecomment-372345798:98,Deployability,release,release,98,@jason-weirather I see the error in the config file - this is definitely a bug in the data source release. There will need to be another data sources release to fix this and another data sources bug. I expect that this will be released by end of week. I will run through some additional tests on hg38 data to see if I can duplicate the null pointer exception.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4521#issuecomment-372345798
https://github.com/broadinstitute/gatk/issues/4521#issuecomment-372345798:150,Deployability,release,release,150,@jason-weirather I see the error in the config file - this is definitely a bug in the data source release. There will need to be another data sources release to fix this and another data sources bug. I expect that this will be released by end of week. I will run through some additional tests on hg38 data to see if I can duplicate the null pointer exception.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4521#issuecomment-372345798
https://github.com/broadinstitute/gatk/issues/4521#issuecomment-372345798:227,Deployability,release,released,227,@jason-weirather I see the error in the config file - this is definitely a bug in the data source release. There will need to be another data sources release to fix this and another data sources bug. I expect that this will be released by end of week. I will run through some additional tests on hg38 data to see if I can duplicate the null pointer exception.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4521#issuecomment-372345798
https://github.com/broadinstitute/gatk/issues/4521#issuecomment-372345798:40,Modifiability,config,config,40,@jason-weirather I see the error in the config file - this is definitely a bug in the data source release. There will need to be another data sources release to fix this and another data sources bug. I expect that this will be released by end of week. I will run through some additional tests on hg38 data to see if I can duplicate the null pointer exception.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4521#issuecomment-372345798
https://github.com/broadinstitute/gatk/issues/4521#issuecomment-372345798:287,Testability,test,tests,287,@jason-weirather I see the error in the config file - this is definitely a bug in the data source release. There will need to be another data sources release to fix this and another data sources bug. I expect that this will be released by end of week. I will run through some additional tests on hg38 data to see if I can duplicate the null pointer exception.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4521#issuecomment-372345798
https://github.com/broadinstitute/gatk/issues/4521#issuecomment-375059321:52,Availability,avail,available,52,"@jason-weirather There is a new set of data sources available in the data sources area (v1.1). I still haven't tested very thoroughly, but it should have all required files for hg38. I'm planning to test this further later this week / early next week.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4521#issuecomment-375059321
https://github.com/broadinstitute/gatk/issues/4521#issuecomment-375059321:111,Testability,test,tested,111,"@jason-weirather There is a new set of data sources available in the data sources area (v1.1). I still haven't tested very thoroughly, but it should have all required files for hg38. I'm planning to test this further later this week / early next week.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4521#issuecomment-375059321
https://github.com/broadinstitute/gatk/issues/4521#issuecomment-375059321:199,Testability,test,test,199,"@jason-weirather There is a new set of data sources available in the data sources area (v1.1). I still haven't tested very thoroughly, but it should have all required files for hg38. I'm planning to test this further later this week / early next week.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4521#issuecomment-375059321
https://github.com/broadinstitute/gatk/issues/4521#issuecomment-375162106:143,Availability,error,error,143,"Thanks @jonn-smith, I really appreciate your work in supporting hg38. In case its helpful, I gave your files a go was met with a pretty abrupt error and exit. ... testing on 4.0.2.1. ```; 02:48:07.582 INFO Funcotator - Initializing engine; 02:48:07.988 INFO FeatureManager - Using codec VCFCodec to read file file:///cluster/jasonw/Work/pd.vcf; 02:48:08.012 INFO Funcotator - Done initializing engine; 02:48:08.047 INFO Funcotator - Shutting down engine; [March 22, 2018 2:48:08 AM UTC] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=1948254208; java.lang.NullPointerException; 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.closeTool(Funcotator.java:330); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:897); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:135); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:180); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:199); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:159); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:202); 	at org.broadinstitute.hellbender.Main.main(Main.java:288); ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4521#issuecomment-375162106
https://github.com/broadinstitute/gatk/issues/4521#issuecomment-375162106:442,Availability,down,down,442,"Thanks @jonn-smith, I really appreciate your work in supporting hg38. In case its helpful, I gave your files a go was met with a pretty abrupt error and exit. ... testing on 4.0.2.1. ```; 02:48:07.582 INFO Funcotator - Initializing engine; 02:48:07.988 INFO FeatureManager - Using codec VCFCodec to read file file:///cluster/jasonw/Work/pd.vcf; 02:48:08.012 INFO Funcotator - Done initializing engine; 02:48:08.047 INFO Funcotator - Shutting down engine; [March 22, 2018 2:48:08 AM UTC] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=1948254208; java.lang.NullPointerException; 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.closeTool(Funcotator.java:330); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:897); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:135); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:180); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:199); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:159); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:202); 	at org.broadinstitute.hellbender.Main.main(Main.java:288); ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4521#issuecomment-375162106
https://github.com/broadinstitute/gatk/issues/4521#issuecomment-375162106:163,Testability,test,testing,163,"Thanks @jonn-smith, I really appreciate your work in supporting hg38. In case its helpful, I gave your files a go was met with a pretty abrupt error and exit. ... testing on 4.0.2.1. ```; 02:48:07.582 INFO Funcotator - Initializing engine; 02:48:07.988 INFO FeatureManager - Using codec VCFCodec to read file file:///cluster/jasonw/Work/pd.vcf; 02:48:08.012 INFO Funcotator - Done initializing engine; 02:48:08.047 INFO Funcotator - Shutting down engine; [March 22, 2018 2:48:08 AM UTC] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=1948254208; java.lang.NullPointerException; 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.closeTool(Funcotator.java:330); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:897); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:135); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:180); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:199); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:159); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:202); 	at org.broadinstitute.hellbender.Main.main(Main.java:288); ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4521#issuecomment-375162106
https://github.com/broadinstitute/gatk/issues/4521#issuecomment-375437407:68,Availability,error,error,68,"Alright, I've at least found (and fixed) a bug that was causing the error message to be so vague. . I may have found the error you're running into as well, if so it should be fixed pretty quickly.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4521#issuecomment-375437407
https://github.com/broadinstitute/gatk/issues/4521#issuecomment-375437407:121,Availability,error,error,121,"Alright, I've at least found (and fixed) a bug that was causing the error message to be so vague. . I may have found the error you're running into as well, if so it should be fixed pretty quickly.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4521#issuecomment-375437407
https://github.com/broadinstitute/gatk/issues/4521#issuecomment-375437407:74,Integrability,message,message,74,"Alright, I've at least found (and fixed) a bug that was causing the error message to be so vague. . I may have found the error you're running into as well, if so it should be fixed pretty quickly.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4521#issuecomment-375437407
https://github.com/broadinstitute/gatk/issues/4521#issuecomment-375469404:246,Availability,error,errors,246,"@jason-weirather OK, I found the problem. It was _another_ issue with the data sources. I've fixed it in my local copy - we'll have to release another version tomorrow. I have also made a few logging upgrades so you'll get more information about errors. I'm opening the PR for this now.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4521#issuecomment-375469404
https://github.com/broadinstitute/gatk/issues/4521#issuecomment-375469404:135,Deployability,release,release,135,"@jason-weirather OK, I found the problem. It was _another_ issue with the data sources. I've fixed it in my local copy - we'll have to release another version tomorrow. I have also made a few logging upgrades so you'll get more information about errors. I'm opening the PR for this now.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4521#issuecomment-375469404
https://github.com/broadinstitute/gatk/issues/4521#issuecomment-375469404:200,Deployability,upgrade,upgrades,200,"@jason-weirather OK, I found the problem. It was _another_ issue with the data sources. I've fixed it in my local copy - we'll have to release another version tomorrow. I have also made a few logging upgrades so you'll get more information about errors. I'm opening the PR for this now.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4521#issuecomment-375469404
https://github.com/broadinstitute/gatk/issues/4521#issuecomment-375469404:192,Testability,log,logging,192,"@jason-weirather OK, I found the problem. It was _another_ issue with the data sources. I've fixed it in my local copy - we'll have to release another version tomorrow. I have also made a few logging upgrades so you'll get more information about errors. I'm opening the PR for this now.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4521#issuecomment-375469404
https://github.com/broadinstitute/gatk/issues/4521#issuecomment-383387645:242,Availability,error,error,242,Hi @jonn-smith I had some success getting outputs with this. However ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/funcotator/ is no longer accessible. The most recent version of I accessed on 3/19/2018 still contained at least one error. I'm trying to correct them myself as I go using a more recent build of GATK but it would be helpful if the data files required by this program were available. The one I found is in `gencode_xrefseq.config` where it references a source that doesn't exist and I fixed that. After that I was able to get outputs with hg38. Thanks for your work on this!. I'd also point out there are a lot of fields in the MAF with `__UNKNOWN__` as the entry,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4521#issuecomment-383387645
https://github.com/broadinstitute/gatk/issues/4521#issuecomment-383387645:397,Availability,avail,available,397,Hi @jonn-smith I had some success getting outputs with this. However ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/funcotator/ is no longer accessible. The most recent version of I accessed on 3/19/2018 still contained at least one error. I'm trying to correct them myself as I go using a more recent build of GATK but it would be helpful if the data files required by this program were available. The one I found is in `gencode_xrefseq.config` where it references a source that doesn't exist and I fixed that. After that I was able to get outputs with hg38. Thanks for your work on this!. I'd also point out there are a lot of fields in the MAF with `__UNKNOWN__` as the entry,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4521#issuecomment-383387645
https://github.com/broadinstitute/gatk/issues/4521#issuecomment-383387645:447,Modifiability,config,config,447,Hi @jonn-smith I had some success getting outputs with this. However ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/funcotator/ is no longer accessible. The most recent version of I accessed on 3/19/2018 still contained at least one error. I'm trying to correct them myself as I go using a more recent build of GATK but it would be helpful if the data files required by this program were available. The one I found is in `gencode_xrefseq.config` where it references a source that doesn't exist and I fixed that. After that I was able to get outputs with hg38. Thanks for your work on this!. I'd also point out there are a lot of fields in the MAF with `__UNKNOWN__` as the entry,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4521#issuecomment-383387645
https://github.com/broadinstitute/gatk/issues/4521#issuecomment-383387645:150,Security,access,accessible,150,Hi @jonn-smith I had some success getting outputs with this. However ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/funcotator/ is no longer accessible. The most recent version of I accessed on 3/19/2018 still contained at least one error. I'm trying to correct them myself as I go using a more recent build of GATK but it would be helpful if the data files required by this program were available. The one I found is in `gencode_xrefseq.config` where it references a source that doesn't exist and I fixed that. After that I was able to get outputs with hg38. Thanks for your work on this!. I'd also point out there are a lot of fields in the MAF with `__UNKNOWN__` as the entry,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4521#issuecomment-383387645
https://github.com/broadinstitute/gatk/issues/4521#issuecomment-383387645:191,Security,access,accessed,191,Hi @jonn-smith I had some success getting outputs with this. However ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/funcotator/ is no longer accessible. The most recent version of I accessed on 3/19/2018 still contained at least one error. I'm trying to correct them myself as I go using a more recent build of GATK but it would be helpful if the data files required by this program were available. The one I found is in `gencode_xrefseq.config` where it references a source that doesn't exist and I fixed that. After that I was able to get outputs with hg38. Thanks for your work on this!. I'd also point out there are a lot of fields in the MAF with `__UNKNOWN__` as the entry,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4521#issuecomment-383387645
https://github.com/broadinstitute/gatk/issues/4521#issuecomment-383404016:108,Availability,error,error,108,"@jason-weirather Interesting. I have no trouble accessing the FTP site from outside the Broad. What kind of error message are you getting?. There is a new version from 3/29 that has several fixes in it, in addition you'll need to make sure you have the latest GATK code (you may need to pull the source code rather than a release - I'm not sure when the last release was and some fixes required both data source changes and code changes). If you can wait a few days we're planning on doing another minor / bugfix release this week. In general it's probably not worth trying to fix errors in the data sources - you may find yourself going down a rabbit hole. That said, one of the things that was fixed was that data source line in the gencode file. There shouldn't be very many __UNKNOWN__ fields (if any at all) - at least there aren't when running with the latest version of everything.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4521#issuecomment-383404016
https://github.com/broadinstitute/gatk/issues/4521#issuecomment-383404016:581,Availability,error,errors,581,"@jason-weirather Interesting. I have no trouble accessing the FTP site from outside the Broad. What kind of error message are you getting?. There is a new version from 3/29 that has several fixes in it, in addition you'll need to make sure you have the latest GATK code (you may need to pull the source code rather than a release - I'm not sure when the last release was and some fixes required both data source changes and code changes). If you can wait a few days we're planning on doing another minor / bugfix release this week. In general it's probably not worth trying to fix errors in the data sources - you may find yourself going down a rabbit hole. That said, one of the things that was fixed was that data source line in the gencode file. There shouldn't be very many __UNKNOWN__ fields (if any at all) - at least there aren't when running with the latest version of everything.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4521#issuecomment-383404016
https://github.com/broadinstitute/gatk/issues/4521#issuecomment-383404016:638,Availability,down,down,638,"@jason-weirather Interesting. I have no trouble accessing the FTP site from outside the Broad. What kind of error message are you getting?. There is a new version from 3/29 that has several fixes in it, in addition you'll need to make sure you have the latest GATK code (you may need to pull the source code rather than a release - I'm not sure when the last release was and some fixes required both data source changes and code changes). If you can wait a few days we're planning on doing another minor / bugfix release this week. In general it's probably not worth trying to fix errors in the data sources - you may find yourself going down a rabbit hole. That said, one of the things that was fixed was that data source line in the gencode file. There shouldn't be very many __UNKNOWN__ fields (if any at all) - at least there aren't when running with the latest version of everything.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4521#issuecomment-383404016
https://github.com/broadinstitute/gatk/issues/4521#issuecomment-383404016:322,Deployability,release,release,322,"@jason-weirather Interesting. I have no trouble accessing the FTP site from outside the Broad. What kind of error message are you getting?. There is a new version from 3/29 that has several fixes in it, in addition you'll need to make sure you have the latest GATK code (you may need to pull the source code rather than a release - I'm not sure when the last release was and some fixes required both data source changes and code changes). If you can wait a few days we're planning on doing another minor / bugfix release this week. In general it's probably not worth trying to fix errors in the data sources - you may find yourself going down a rabbit hole. That said, one of the things that was fixed was that data source line in the gencode file. There shouldn't be very many __UNKNOWN__ fields (if any at all) - at least there aren't when running with the latest version of everything.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4521#issuecomment-383404016
https://github.com/broadinstitute/gatk/issues/4521#issuecomment-383404016:359,Deployability,release,release,359,"@jason-weirather Interesting. I have no trouble accessing the FTP site from outside the Broad. What kind of error message are you getting?. There is a new version from 3/29 that has several fixes in it, in addition you'll need to make sure you have the latest GATK code (you may need to pull the source code rather than a release - I'm not sure when the last release was and some fixes required both data source changes and code changes). If you can wait a few days we're planning on doing another minor / bugfix release this week. In general it's probably not worth trying to fix errors in the data sources - you may find yourself going down a rabbit hole. That said, one of the things that was fixed was that data source line in the gencode file. There shouldn't be very many __UNKNOWN__ fields (if any at all) - at least there aren't when running with the latest version of everything.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4521#issuecomment-383404016
https://github.com/broadinstitute/gatk/issues/4521#issuecomment-383404016:513,Deployability,release,release,513,"@jason-weirather Interesting. I have no trouble accessing the FTP site from outside the Broad. What kind of error message are you getting?. There is a new version from 3/29 that has several fixes in it, in addition you'll need to make sure you have the latest GATK code (you may need to pull the source code rather than a release - I'm not sure when the last release was and some fixes required both data source changes and code changes). If you can wait a few days we're planning on doing another minor / bugfix release this week. In general it's probably not worth trying to fix errors in the data sources - you may find yourself going down a rabbit hole. That said, one of the things that was fixed was that data source line in the gencode file. There shouldn't be very many __UNKNOWN__ fields (if any at all) - at least there aren't when running with the latest version of everything.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4521#issuecomment-383404016
https://github.com/broadinstitute/gatk/issues/4521#issuecomment-383404016:114,Integrability,message,message,114,"@jason-weirather Interesting. I have no trouble accessing the FTP site from outside the Broad. What kind of error message are you getting?. There is a new version from 3/29 that has several fixes in it, in addition you'll need to make sure you have the latest GATK code (you may need to pull the source code rather than a release - I'm not sure when the last release was and some fixes required both data source changes and code changes). If you can wait a few days we're planning on doing another minor / bugfix release this week. In general it's probably not worth trying to fix errors in the data sources - you may find yourself going down a rabbit hole. That said, one of the things that was fixed was that data source line in the gencode file. There shouldn't be very many __UNKNOWN__ fields (if any at all) - at least there aren't when running with the latest version of everything.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4521#issuecomment-383404016
https://github.com/broadinstitute/gatk/issues/4521#issuecomment-383404016:48,Security,access,accessing,48,"@jason-weirather Interesting. I have no trouble accessing the FTP site from outside the Broad. What kind of error message are you getting?. There is a new version from 3/29 that has several fixes in it, in addition you'll need to make sure you have the latest GATK code (you may need to pull the source code rather than a release - I'm not sure when the last release was and some fixes required both data source changes and code changes). If you can wait a few days we're planning on doing another minor / bugfix release this week. In general it's probably not worth trying to fix errors in the data sources - you may find yourself going down a rabbit hole. That said, one of the things that was fixed was that data source line in the gencode file. There shouldn't be very many __UNKNOWN__ fields (if any at all) - at least there aren't when running with the latest version of everything.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4521#issuecomment-383404016
https://github.com/broadinstitute/gatk/pull/4522#issuecomment-373074373:96,Testability,log,logic,96,"Just to clarify @davidbenjamin @takutosato, the normal sample calling uses:. 1. HaplotypeCaller logic for _germline_ calling OR; 2. Mutect2 sensitive calling?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4522#issuecomment-373074373
https://github.com/broadinstitute/gatk/pull/4523#issuecomment-416311827:75,Deployability,patch,patch,75,"@cmnbroad This change seems fine, but this is blocked until the underlying patch is merged into barclay and released. Re-assigning to you until that happens.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4523#issuecomment-416311827
https://github.com/broadinstitute/gatk/pull/4523#issuecomment-416311827:108,Deployability,release,released,108,"@cmnbroad This change seems fine, but this is blocked until the underlying patch is merged into barclay and released. Re-assigning to you until that happens.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4523#issuecomment-416311827
https://github.com/broadinstitute/gatk/pull/4523#issuecomment-454157311:81,Deployability,release,released,81,Unfortunately we can't merge this until we get the corresponding Barclay changes released in Barclay and integrated into GATK.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4523#issuecomment-454157311
https://github.com/broadinstitute/gatk/pull/4523#issuecomment-454157311:105,Deployability,integrat,integrated,105,Unfortunately we can't merge this until we get the corresponding Barclay changes released in Barclay and integrated into GATK.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4523#issuecomment-454157311
https://github.com/broadinstitute/gatk/pull/4523#issuecomment-454157311:105,Integrability,integrat,integrated,105,Unfortunately we can't merge this until we get the corresponding Barclay changes released in Barclay and integrated into GATK.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4523#issuecomment-454157311
https://github.com/broadinstitute/gatk/issues/4525#issuecomment-377809797:113,Availability,error,error,113,A second user has reported it as well. https://gatkforums.broadinstitute.org/gatk/discussion/11693/combine-gvcfs-error,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4525#issuecomment-377809797
https://github.com/broadinstitute/gatk/issues/4525#issuecomment-377963524:24,Security,access,access,24,"@chandrans I don't have access to dsde-docs so I can't see the ticket/test files (we asked @vdauwera to give me access last week for a different issue, but I don't have it yet).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4525#issuecomment-377963524
https://github.com/broadinstitute/gatk/issues/4525#issuecomment-377963524:112,Security,access,access,112,"@chandrans I don't have access to dsde-docs so I can't see the ticket/test files (we asked @vdauwera to give me access last week for a different issue, but I don't have it yet).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4525#issuecomment-377963524
https://github.com/broadinstitute/gatk/issues/4525#issuecomment-377963524:70,Testability,test,test,70,"@chandrans I don't have access to dsde-docs so I can't see the ticket/test files (we asked @vdauwera to give me access last week for a different issue, but I don't have it yet).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4525#issuecomment-377963524
https://github.com/broadinstitute/gatk/pull/4530#issuecomment-374238158:119,Testability,test,test,119,"I added a check to build.gradle to verify that the large (runtime) resources are not lfs pointer files. I also added a test to verify that there is a .git folder, and non-null ToolProvider classLoader (fixes https://github.com/broadinstitute/gatk/issues/4532). To test the pointer file check, I created a branch of this branch with a temporary commit that reverts the addition of the large resources to the Docker staging area, and [submitted](https://travis-ci.org/broadinstitute/gatk/builds/354495062) it to Travis to verify that the build fails when they're not present.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4530#issuecomment-374238158
https://github.com/broadinstitute/gatk/pull/4530#issuecomment-374238158:264,Testability,test,test,264,"I added a check to build.gradle to verify that the large (runtime) resources are not lfs pointer files. I also added a test to verify that there is a .git folder, and non-null ToolProvider classLoader (fixes https://github.com/broadinstitute/gatk/issues/4532). To test the pointer file check, I created a branch of this branch with a temporary commit that reverts the addition of the large resources to the Docker staging area, and [submitted](https://travis-ci.org/broadinstitute/gatk/builds/354495062) it to Travis to verify that the build fails when they're not present.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4530#issuecomment-374238158
https://github.com/broadinstitute/gatk/pull/4530#issuecomment-374715768:35,Deployability,update,updated,35,@droazen please take a look at the updated README.md in this PR.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4530#issuecomment-374715768
https://github.com/broadinstitute/gatk/pull/4530#issuecomment-375670798:79,Testability,test,test,79,Back to @droazen. Responded to all of the comments. I did an interim commit to test the lfs changes on docker/travis so there are two commits for this round.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4530#issuecomment-375670798
https://github.com/broadinstitute/gatk/issues/4531#issuecomment-373795692:357,Deployability,install,installing,357,"Hi @jjfarrell . We took a look through our code and libraries we're depending on and the only place we could find any logging message that would produce those lines in any related repo we could find is in the `TestBAM` example tool from the Hadoop-BAM library. Is there any chance you ran that tool on one of your files (one with 76bp reads), perhaps after installing Hadoop-BAM and following the examples README, and that's what filled up the log?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4531#issuecomment-373795692
https://github.com/broadinstitute/gatk/issues/4531#issuecomment-373795692:68,Integrability,depend,depending,68,"Hi @jjfarrell . We took a look through our code and libraries we're depending on and the only place we could find any logging message that would produce those lines in any related repo we could find is in the `TestBAM` example tool from the Hadoop-BAM library. Is there any chance you ran that tool on one of your files (one with 76bp reads), perhaps after installing Hadoop-BAM and following the examples README, and that's what filled up the log?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4531#issuecomment-373795692
https://github.com/broadinstitute/gatk/issues/4531#issuecomment-373795692:126,Integrability,message,message,126,"Hi @jjfarrell . We took a look through our code and libraries we're depending on and the only place we could find any logging message that would produce those lines in any related repo we could find is in the `TestBAM` example tool from the Hadoop-BAM library. Is there any chance you ran that tool on one of your files (one with 76bp reads), perhaps after installing Hadoop-BAM and following the examples README, and that's what filled up the log?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4531#issuecomment-373795692
https://github.com/broadinstitute/gatk/issues/4531#issuecomment-373795692:118,Testability,log,logging,118,"Hi @jjfarrell . We took a look through our code and libraries we're depending on and the only place we could find any logging message that would produce those lines in any related repo we could find is in the `TestBAM` example tool from the Hadoop-BAM library. Is there any chance you ran that tool on one of your files (one with 76bp reads), perhaps after installing Hadoop-BAM and following the examples README, and that's what filled up the log?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4531#issuecomment-373795692
https://github.com/broadinstitute/gatk/issues/4531#issuecomment-373795692:210,Testability,Test,TestBAM,210,"Hi @jjfarrell . We took a look through our code and libraries we're depending on and the only place we could find any logging message that would produce those lines in any related repo we could find is in the `TestBAM` example tool from the Hadoop-BAM library. Is there any chance you ran that tool on one of your files (one with 76bp reads), perhaps after installing Hadoop-BAM and following the examples README, and that's what filled up the log?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4531#issuecomment-373795692
https://github.com/broadinstitute/gatk/issues/4531#issuecomment-373795692:444,Testability,log,log,444,"Hi @jjfarrell . We took a look through our code and libraries we're depending on and the only place we could find any logging message that would produce those lines in any related repo we could find is in the `TestBAM` example tool from the Hadoop-BAM library. Is there any chance you ran that tool on one of your files (one with 76bp reads), perhaps after installing Hadoop-BAM and following the examples README, and that's what filled up the log?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4531#issuecomment-373795692
https://github.com/broadinstitute/gatk/issues/4531#issuecomment-373807025:53,Modifiability,config,configured,53,"Also, could you provide at what level is the logging configured @jjfarrell ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4531#issuecomment-373807025
https://github.com/broadinstitute/gatk/issues/4531#issuecomment-373807025:45,Testability,log,logging,45,"Also, could you provide at what level is the logging configured @jjfarrell ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4531#issuecomment-373807025
https://github.com/broadinstitute/gatk/issues/4531#issuecomment-373809285:31,Testability,test,test,31,"Yes, I did run that Hadoop-Bam test in the midst of runs of the StructuralVariationDiscoveryPipelineSpark. When I was notified of the issue, I assumed it was those jobs and not the TestBAM runs. There was a 30-40 minute delay of GATK Spark jobs reading crams relative to bams that I was looking into (https://github.com/broadinstitute/gatk/issues/4506).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4531#issuecomment-373809285
https://github.com/broadinstitute/gatk/issues/4531#issuecomment-373809285:181,Testability,Test,TestBAM,181,"Yes, I did run that Hadoop-Bam test in the midst of runs of the StructuralVariationDiscoveryPipelineSpark. When I was notified of the issue, I assumed it was those jobs and not the TestBAM runs. There was a 30-40 minute delay of GATK Spark jobs reading crams relative to bams that I was looking into (https://github.com/broadinstitute/gatk/issues/4506).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4531#issuecomment-373809285
https://github.com/broadinstitute/gatk/issues/4535#issuecomment-391044481:144,Modifiability,rewrite,rewrite,144,Seems like something like https://github.com/broadinstitute/gatk/issues/4794 could be avoided if we rewrote this. It seems like a pretty simple rewrite too...,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4535#issuecomment-391044481
https://github.com/broadinstitute/gatk/issues/4535#issuecomment-391044481:86,Safety,avoid,avoided,86,Seems like something like https://github.com/broadinstitute/gatk/issues/4794 could be avoided if we rewrote this. It seems like a pretty simple rewrite too...,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4535#issuecomment-391044481
https://github.com/broadinstitute/gatk/issues/4535#issuecomment-391044481:137,Usability,simpl,simple,137,Seems like something like https://github.com/broadinstitute/gatk/issues/4794 could be avoided if we rewrote this. It seems like a pretty simple rewrite too...,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4535#issuecomment-391044481
https://github.com/broadinstitute/gatk/issues/4539#issuecomment-376588932:67,Testability,test,test,67,"Also, it might be a good idea to separate the various CNN java and test files and resources from the VQSR package and files.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4539#issuecomment-376588932
https://github.com/broadinstitute/gatk/issues/4540#issuecomment-429074231:670,Availability,down,downsampling,670,"@ldgauthier @lucidtronix I'm updating this with a proposed list of CNNScoreVariants issues I think need to be resolved before we can remove the `@Beta` tag (actually is currently marked `@Experimental`). Let me know what you think:. - https://github.com/broadinstitute/gatk/issues/4538 (Python factoring/PEP-8/code review); - factor python args handling (minimally factor out the inference args); - there is only one 2D test, which I think has no reads overlapping any of the variants; - we should add a test that specifies one or more intervals; - the tool currently adds standard VQSR header lines via addVQSRStandardHeaderLines, which is unnecssary; - integrate read downsampling; - determine/handle the failure mode when the user supplies a mix (of mismatched) 1D/2D arch and weights inputs. Other (not necessarily blockers):; - establish all defaults (weights/arch/etc) in Java code; - default arch is 1D - should this change to 2D ?; - see if we can remove the artificially small inference/batch sizes (1) used in the tests. I think we added these due to timeouts which should no longer be an issue.; - remove the `newExpectations` code paths in integration tests",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4540#issuecomment-429074231
https://github.com/broadinstitute/gatk/issues/4540#issuecomment-429074231:707,Availability,failure,failure,707,"@ldgauthier @lucidtronix I'm updating this with a proposed list of CNNScoreVariants issues I think need to be resolved before we can remove the `@Beta` tag (actually is currently marked `@Experimental`). Let me know what you think:. - https://github.com/broadinstitute/gatk/issues/4538 (Python factoring/PEP-8/code review); - factor python args handling (minimally factor out the inference args); - there is only one 2D test, which I think has no reads overlapping any of the variants; - we should add a test that specifies one or more intervals; - the tool currently adds standard VQSR header lines via addVQSRStandardHeaderLines, which is unnecssary; - integrate read downsampling; - determine/handle the failure mode when the user supplies a mix (of mismatched) 1D/2D arch and weights inputs. Other (not necessarily blockers):; - establish all defaults (weights/arch/etc) in Java code; - default arch is 1D - should this change to 2D ?; - see if we can remove the artificially small inference/batch sizes (1) used in the tests. I think we added these due to timeouts which should no longer be an issue.; - remove the `newExpectations` code paths in integration tests",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4540#issuecomment-429074231
https://github.com/broadinstitute/gatk/issues/4540#issuecomment-429074231:655,Deployability,integrat,integrate,655,"@ldgauthier @lucidtronix I'm updating this with a proposed list of CNNScoreVariants issues I think need to be resolved before we can remove the `@Beta` tag (actually is currently marked `@Experimental`). Let me know what you think:. - https://github.com/broadinstitute/gatk/issues/4538 (Python factoring/PEP-8/code review); - factor python args handling (minimally factor out the inference args); - there is only one 2D test, which I think has no reads overlapping any of the variants; - we should add a test that specifies one or more intervals; - the tool currently adds standard VQSR header lines via addVQSRStandardHeaderLines, which is unnecssary; - integrate read downsampling; - determine/handle the failure mode when the user supplies a mix (of mismatched) 1D/2D arch and weights inputs. Other (not necessarily blockers):; - establish all defaults (weights/arch/etc) in Java code; - default arch is 1D - should this change to 2D ?; - see if we can remove the artificially small inference/batch sizes (1) used in the tests. I think we added these due to timeouts which should no longer be an issue.; - remove the `newExpectations` code paths in integration tests",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4540#issuecomment-429074231
https://github.com/broadinstitute/gatk/issues/4540#issuecomment-429074231:1152,Deployability,integrat,integration,1152,"@ldgauthier @lucidtronix I'm updating this with a proposed list of CNNScoreVariants issues I think need to be resolved before we can remove the `@Beta` tag (actually is currently marked `@Experimental`). Let me know what you think:. - https://github.com/broadinstitute/gatk/issues/4538 (Python factoring/PEP-8/code review); - factor python args handling (minimally factor out the inference args); - there is only one 2D test, which I think has no reads overlapping any of the variants; - we should add a test that specifies one or more intervals; - the tool currently adds standard VQSR header lines via addVQSRStandardHeaderLines, which is unnecssary; - integrate read downsampling; - determine/handle the failure mode when the user supplies a mix (of mismatched) 1D/2D arch and weights inputs. Other (not necessarily blockers):; - establish all defaults (weights/arch/etc) in Java code; - default arch is 1D - should this change to 2D ?; - see if we can remove the artificially small inference/batch sizes (1) used in the tests. I think we added these due to timeouts which should no longer be an issue.; - remove the `newExpectations` code paths in integration tests",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4540#issuecomment-429074231
https://github.com/broadinstitute/gatk/issues/4540#issuecomment-429074231:655,Integrability,integrat,integrate,655,"@ldgauthier @lucidtronix I'm updating this with a proposed list of CNNScoreVariants issues I think need to be resolved before we can remove the `@Beta` tag (actually is currently marked `@Experimental`). Let me know what you think:. - https://github.com/broadinstitute/gatk/issues/4538 (Python factoring/PEP-8/code review); - factor python args handling (minimally factor out the inference args); - there is only one 2D test, which I think has no reads overlapping any of the variants; - we should add a test that specifies one or more intervals; - the tool currently adds standard VQSR header lines via addVQSRStandardHeaderLines, which is unnecssary; - integrate read downsampling; - determine/handle the failure mode when the user supplies a mix (of mismatched) 1D/2D arch and weights inputs. Other (not necessarily blockers):; - establish all defaults (weights/arch/etc) in Java code; - default arch is 1D - should this change to 2D ?; - see if we can remove the artificially small inference/batch sizes (1) used in the tests. I think we added these due to timeouts which should no longer be an issue.; - remove the `newExpectations` code paths in integration tests",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4540#issuecomment-429074231
https://github.com/broadinstitute/gatk/issues/4540#issuecomment-429074231:1152,Integrability,integrat,integration,1152,"@ldgauthier @lucidtronix I'm updating this with a proposed list of CNNScoreVariants issues I think need to be resolved before we can remove the `@Beta` tag (actually is currently marked `@Experimental`). Let me know what you think:. - https://github.com/broadinstitute/gatk/issues/4538 (Python factoring/PEP-8/code review); - factor python args handling (minimally factor out the inference args); - there is only one 2D test, which I think has no reads overlapping any of the variants; - we should add a test that specifies one or more intervals; - the tool currently adds standard VQSR header lines via addVQSRStandardHeaderLines, which is unnecssary; - integrate read downsampling; - determine/handle the failure mode when the user supplies a mix (of mismatched) 1D/2D arch and weights inputs. Other (not necessarily blockers):; - establish all defaults (weights/arch/etc) in Java code; - default arch is 1D - should this change to 2D ?; - see if we can remove the artificially small inference/batch sizes (1) used in the tests. I think we added these due to timeouts which should no longer be an issue.; - remove the `newExpectations` code paths in integration tests",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4540#issuecomment-429074231
https://github.com/broadinstitute/gatk/issues/4540#issuecomment-429074231:1061,Safety,timeout,timeouts,1061,"@ldgauthier @lucidtronix I'm updating this with a proposed list of CNNScoreVariants issues I think need to be resolved before we can remove the `@Beta` tag (actually is currently marked `@Experimental`). Let me know what you think:. - https://github.com/broadinstitute/gatk/issues/4538 (Python factoring/PEP-8/code review); - factor python args handling (minimally factor out the inference args); - there is only one 2D test, which I think has no reads overlapping any of the variants; - we should add a test that specifies one or more intervals; - the tool currently adds standard VQSR header lines via addVQSRStandardHeaderLines, which is unnecssary; - integrate read downsampling; - determine/handle the failure mode when the user supplies a mix (of mismatched) 1D/2D arch and weights inputs. Other (not necessarily blockers):; - establish all defaults (weights/arch/etc) in Java code; - default arch is 1D - should this change to 2D ?; - see if we can remove the artificially small inference/batch sizes (1) used in the tests. I think we added these due to timeouts which should no longer be an issue.; - remove the `newExpectations` code paths in integration tests",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4540#issuecomment-429074231
https://github.com/broadinstitute/gatk/issues/4540#issuecomment-429074231:420,Testability,test,test,420,"@ldgauthier @lucidtronix I'm updating this with a proposed list of CNNScoreVariants issues I think need to be resolved before we can remove the `@Beta` tag (actually is currently marked `@Experimental`). Let me know what you think:. - https://github.com/broadinstitute/gatk/issues/4538 (Python factoring/PEP-8/code review); - factor python args handling (minimally factor out the inference args); - there is only one 2D test, which I think has no reads overlapping any of the variants; - we should add a test that specifies one or more intervals; - the tool currently adds standard VQSR header lines via addVQSRStandardHeaderLines, which is unnecssary; - integrate read downsampling; - determine/handle the failure mode when the user supplies a mix (of mismatched) 1D/2D arch and weights inputs. Other (not necessarily blockers):; - establish all defaults (weights/arch/etc) in Java code; - default arch is 1D - should this change to 2D ?; - see if we can remove the artificially small inference/batch sizes (1) used in the tests. I think we added these due to timeouts which should no longer be an issue.; - remove the `newExpectations` code paths in integration tests",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4540#issuecomment-429074231
https://github.com/broadinstitute/gatk/issues/4540#issuecomment-429074231:504,Testability,test,test,504,"@ldgauthier @lucidtronix I'm updating this with a proposed list of CNNScoreVariants issues I think need to be resolved before we can remove the `@Beta` tag (actually is currently marked `@Experimental`). Let me know what you think:. - https://github.com/broadinstitute/gatk/issues/4538 (Python factoring/PEP-8/code review); - factor python args handling (minimally factor out the inference args); - there is only one 2D test, which I think has no reads overlapping any of the variants; - we should add a test that specifies one or more intervals; - the tool currently adds standard VQSR header lines via addVQSRStandardHeaderLines, which is unnecssary; - integrate read downsampling; - determine/handle the failure mode when the user supplies a mix (of mismatched) 1D/2D arch and weights inputs. Other (not necessarily blockers):; - establish all defaults (weights/arch/etc) in Java code; - default arch is 1D - should this change to 2D ?; - see if we can remove the artificially small inference/batch sizes (1) used in the tests. I think we added these due to timeouts which should no longer be an issue.; - remove the `newExpectations` code paths in integration tests",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4540#issuecomment-429074231
https://github.com/broadinstitute/gatk/issues/4540#issuecomment-429074231:1024,Testability,test,tests,1024,"@ldgauthier @lucidtronix I'm updating this with a proposed list of CNNScoreVariants issues I think need to be resolved before we can remove the `@Beta` tag (actually is currently marked `@Experimental`). Let me know what you think:. - https://github.com/broadinstitute/gatk/issues/4538 (Python factoring/PEP-8/code review); - factor python args handling (minimally factor out the inference args); - there is only one 2D test, which I think has no reads overlapping any of the variants; - we should add a test that specifies one or more intervals; - the tool currently adds standard VQSR header lines via addVQSRStandardHeaderLines, which is unnecssary; - integrate read downsampling; - determine/handle the failure mode when the user supplies a mix (of mismatched) 1D/2D arch and weights inputs. Other (not necessarily blockers):; - establish all defaults (weights/arch/etc) in Java code; - default arch is 1D - should this change to 2D ?; - see if we can remove the artificially small inference/batch sizes (1) used in the tests. I think we added these due to timeouts which should no longer be an issue.; - remove the `newExpectations` code paths in integration tests",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4540#issuecomment-429074231
https://github.com/broadinstitute/gatk/issues/4540#issuecomment-429074231:1164,Testability,test,tests,1164,"@ldgauthier @lucidtronix I'm updating this with a proposed list of CNNScoreVariants issues I think need to be resolved before we can remove the `@Beta` tag (actually is currently marked `@Experimental`). Let me know what you think:. - https://github.com/broadinstitute/gatk/issues/4538 (Python factoring/PEP-8/code review); - factor python args handling (minimally factor out the inference args); - there is only one 2D test, which I think has no reads overlapping any of the variants; - we should add a test that specifies one or more intervals; - the tool currently adds standard VQSR header lines via addVQSRStandardHeaderLines, which is unnecssary; - integrate read downsampling; - determine/handle the failure mode when the user supplies a mix (of mismatched) 1D/2D arch and weights inputs. Other (not necessarily blockers):; - establish all defaults (weights/arch/etc) in Java code; - default arch is 1D - should this change to 2D ?; - see if we can remove the artificially small inference/batch sizes (1) used in the tests. I think we added these due to timeouts which should no longer be an issue.; - remove the `newExpectations` code paths in integration tests",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4540#issuecomment-429074231
https://github.com/broadinstitute/gatk/issues/4544#issuecomment-376314262:691,Availability,error,errors,691,"Jumping on to report I've also been having issues using GATK 4 genotyping. CombineGVCFs (v4.0.1.1) runs fine no matter how many samples I use, but GenotypeGVCFs chokes at some limit. I iteratively subsetted my sample list to see at what point it begins to choke. I used line count of the final vcf file as an approximation of how far the genotyper got. Even at the 110 samples, though, CombineGVCFs ran for several hours. It just produced a final, genotyped VCF file that was severely truncated with few variants. See the graph at this image attached.; ![iterative memory loss](https://user-images.githubusercontent.com/5849554/37933389-e15935ac-30ff-11e8-91ea-80fffd8deb48.png). As for the errors:. `Exception in thread ""main"" java.lang.OutOfMemoryError: GC overhead limit exceeded`; and several; `at java.util....` and `at org.broadinstitute.hellbender.tools.walkers.genotyper....`. I attached three of these error files so you can see the full list of memory problems. `genotype55.e...` is the log file with the most number of samples that worked. `genotype60.e...` ends abruptly. `genotype65.e...` contains the memory errors. Note that these error/log files include both CombineGVCFs and GenotypeGVCFs. [genotype55.e5195822.txt](https://github.com/broadinstitute/gatk/files/1849559/genotype55.e5195822.txt); [genotype60.e5195820.txt](https://github.com/broadinstitute/gatk/files/1849560/genotype60.e5195820.txt); [genotype65.e5195821.txt](https://github.com/broadinstitute/gatk/files/1849561/genotype65.e5195821.txt). For reference, genotyping using GATK 3.8.0 on all 108 of my samples produced a final vcf file 2784 lines long in *36 seconds* with *no issue.* Let me know if you have any other questions!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-376314262
https://github.com/broadinstitute/gatk/issues/4544#issuecomment-376314262:911,Availability,error,error,911,"Jumping on to report I've also been having issues using GATK 4 genotyping. CombineGVCFs (v4.0.1.1) runs fine no matter how many samples I use, but GenotypeGVCFs chokes at some limit. I iteratively subsetted my sample list to see at what point it begins to choke. I used line count of the final vcf file as an approximation of how far the genotyper got. Even at the 110 samples, though, CombineGVCFs ran for several hours. It just produced a final, genotyped VCF file that was severely truncated with few variants. See the graph at this image attached.; ![iterative memory loss](https://user-images.githubusercontent.com/5849554/37933389-e15935ac-30ff-11e8-91ea-80fffd8deb48.png). As for the errors:. `Exception in thread ""main"" java.lang.OutOfMemoryError: GC overhead limit exceeded`; and several; `at java.util....` and `at org.broadinstitute.hellbender.tools.walkers.genotyper....`. I attached three of these error files so you can see the full list of memory problems. `genotype55.e...` is the log file with the most number of samples that worked. `genotype60.e...` ends abruptly. `genotype65.e...` contains the memory errors. Note that these error/log files include both CombineGVCFs and GenotypeGVCFs. [genotype55.e5195822.txt](https://github.com/broadinstitute/gatk/files/1849559/genotype55.e5195822.txt); [genotype60.e5195820.txt](https://github.com/broadinstitute/gatk/files/1849560/genotype60.e5195820.txt); [genotype65.e5195821.txt](https://github.com/broadinstitute/gatk/files/1849561/genotype65.e5195821.txt). For reference, genotyping using GATK 3.8.0 on all 108 of my samples produced a final vcf file 2784 lines long in *36 seconds* with *no issue.* Let me know if you have any other questions!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-376314262
https://github.com/broadinstitute/gatk/issues/4544#issuecomment-376314262:1122,Availability,error,errors,1122,"Jumping on to report I've also been having issues using GATK 4 genotyping. CombineGVCFs (v4.0.1.1) runs fine no matter how many samples I use, but GenotypeGVCFs chokes at some limit. I iteratively subsetted my sample list to see at what point it begins to choke. I used line count of the final vcf file as an approximation of how far the genotyper got. Even at the 110 samples, though, CombineGVCFs ran for several hours. It just produced a final, genotyped VCF file that was severely truncated with few variants. See the graph at this image attached.; ![iterative memory loss](https://user-images.githubusercontent.com/5849554/37933389-e15935ac-30ff-11e8-91ea-80fffd8deb48.png). As for the errors:. `Exception in thread ""main"" java.lang.OutOfMemoryError: GC overhead limit exceeded`; and several; `at java.util....` and `at org.broadinstitute.hellbender.tools.walkers.genotyper....`. I attached three of these error files so you can see the full list of memory problems. `genotype55.e...` is the log file with the most number of samples that worked. `genotype60.e...` ends abruptly. `genotype65.e...` contains the memory errors. Note that these error/log files include both CombineGVCFs and GenotypeGVCFs. [genotype55.e5195822.txt](https://github.com/broadinstitute/gatk/files/1849559/genotype55.e5195822.txt); [genotype60.e5195820.txt](https://github.com/broadinstitute/gatk/files/1849560/genotype60.e5195820.txt); [genotype65.e5195821.txt](https://github.com/broadinstitute/gatk/files/1849561/genotype65.e5195821.txt). For reference, genotyping using GATK 3.8.0 on all 108 of my samples produced a final vcf file 2784 lines long in *36 seconds* with *no issue.* Let me know if you have any other questions!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-376314262
https://github.com/broadinstitute/gatk/issues/4544#issuecomment-376314262:1146,Availability,error,error,1146,"Jumping on to report I've also been having issues using GATK 4 genotyping. CombineGVCFs (v4.0.1.1) runs fine no matter how many samples I use, but GenotypeGVCFs chokes at some limit. I iteratively subsetted my sample list to see at what point it begins to choke. I used line count of the final vcf file as an approximation of how far the genotyper got. Even at the 110 samples, though, CombineGVCFs ran for several hours. It just produced a final, genotyped VCF file that was severely truncated with few variants. See the graph at this image attached.; ![iterative memory loss](https://user-images.githubusercontent.com/5849554/37933389-e15935ac-30ff-11e8-91ea-80fffd8deb48.png). As for the errors:. `Exception in thread ""main"" java.lang.OutOfMemoryError: GC overhead limit exceeded`; and several; `at java.util....` and `at org.broadinstitute.hellbender.tools.walkers.genotyper....`. I attached three of these error files so you can see the full list of memory problems. `genotype55.e...` is the log file with the most number of samples that worked. `genotype60.e...` ends abruptly. `genotype65.e...` contains the memory errors. Note that these error/log files include both CombineGVCFs and GenotypeGVCFs. [genotype55.e5195822.txt](https://github.com/broadinstitute/gatk/files/1849559/genotype55.e5195822.txt); [genotype60.e5195820.txt](https://github.com/broadinstitute/gatk/files/1849560/genotype60.e5195820.txt); [genotype65.e5195821.txt](https://github.com/broadinstitute/gatk/files/1849561/genotype65.e5195821.txt). For reference, genotyping using GATK 3.8.0 on all 108 of my samples produced a final vcf file 2784 lines long in *36 seconds* with *no issue.* Let me know if you have any other questions!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-376314262
https://github.com/broadinstitute/gatk/issues/4544#issuecomment-376314262:997,Testability,log,log,997,"Jumping on to report I've also been having issues using GATK 4 genotyping. CombineGVCFs (v4.0.1.1) runs fine no matter how many samples I use, but GenotypeGVCFs chokes at some limit. I iteratively subsetted my sample list to see at what point it begins to choke. I used line count of the final vcf file as an approximation of how far the genotyper got. Even at the 110 samples, though, CombineGVCFs ran for several hours. It just produced a final, genotyped VCF file that was severely truncated with few variants. See the graph at this image attached.; ![iterative memory loss](https://user-images.githubusercontent.com/5849554/37933389-e15935ac-30ff-11e8-91ea-80fffd8deb48.png). As for the errors:. `Exception in thread ""main"" java.lang.OutOfMemoryError: GC overhead limit exceeded`; and several; `at java.util....` and `at org.broadinstitute.hellbender.tools.walkers.genotyper....`. I attached three of these error files so you can see the full list of memory problems. `genotype55.e...` is the log file with the most number of samples that worked. `genotype60.e...` ends abruptly. `genotype65.e...` contains the memory errors. Note that these error/log files include both CombineGVCFs and GenotypeGVCFs. [genotype55.e5195822.txt](https://github.com/broadinstitute/gatk/files/1849559/genotype55.e5195822.txt); [genotype60.e5195820.txt](https://github.com/broadinstitute/gatk/files/1849560/genotype60.e5195820.txt); [genotype65.e5195821.txt](https://github.com/broadinstitute/gatk/files/1849561/genotype65.e5195821.txt). For reference, genotyping using GATK 3.8.0 on all 108 of my samples produced a final vcf file 2784 lines long in *36 seconds* with *no issue.* Let me know if you have any other questions!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-376314262
https://github.com/broadinstitute/gatk/issues/4544#issuecomment-376314262:1152,Testability,log,log,1152,"Jumping on to report I've also been having issues using GATK 4 genotyping. CombineGVCFs (v4.0.1.1) runs fine no matter how many samples I use, but GenotypeGVCFs chokes at some limit. I iteratively subsetted my sample list to see at what point it begins to choke. I used line count of the final vcf file as an approximation of how far the genotyper got. Even at the 110 samples, though, CombineGVCFs ran for several hours. It just produced a final, genotyped VCF file that was severely truncated with few variants. See the graph at this image attached.; ![iterative memory loss](https://user-images.githubusercontent.com/5849554/37933389-e15935ac-30ff-11e8-91ea-80fffd8deb48.png). As for the errors:. `Exception in thread ""main"" java.lang.OutOfMemoryError: GC overhead limit exceeded`; and several; `at java.util....` and `at org.broadinstitute.hellbender.tools.walkers.genotyper....`. I attached three of these error files so you can see the full list of memory problems. `genotype55.e...` is the log file with the most number of samples that worked. `genotype60.e...` ends abruptly. `genotype65.e...` contains the memory errors. Note that these error/log files include both CombineGVCFs and GenotypeGVCFs. [genotype55.e5195822.txt](https://github.com/broadinstitute/gatk/files/1849559/genotype55.e5195822.txt); [genotype60.e5195820.txt](https://github.com/broadinstitute/gatk/files/1849560/genotype60.e5195820.txt); [genotype65.e5195821.txt](https://github.com/broadinstitute/gatk/files/1849561/genotype65.e5195821.txt). For reference, genotyping using GATK 3.8.0 on all 108 of my samples produced a final vcf file 2784 lines long in *36 seconds* with *no issue.* Let me know if you have any other questions!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-376314262
https://github.com/broadinstitute/gatk/issues/4544#issuecomment-376620043:0,Deployability,UPDATE,UPDATE,0,"UPDATE: I solved the issue on my end. A collaborator was having the same issue with their haploid data, but not their diploid. The problems I described above were for haploid data. He added ""--new-qual"" to his GenotypeGVCFs command and that solved the issue. It did for me as well! Using the same combined GVCF file as I was before, genotyping finished in less than half a minute after adding the new-qual parameter. Thought it would be useful to know that:. 1, this issue appears to affect non-diploids more than diploids. 2, using --new-qual solved the issue, at least for me. I've attached the log-file generated from this new output, hopefully it helps in debugging.; [genotype108_newqual.e5290702.txt](https://github.com/broadinstitute/gatk/files/1853188/genotype108_newqual.e5290702.txt)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-376620043
https://github.com/broadinstitute/gatk/issues/4544#issuecomment-376620043:597,Testability,log,log-file,597,"UPDATE: I solved the issue on my end. A collaborator was having the same issue with their haploid data, but not their diploid. The problems I described above were for haploid data. He added ""--new-qual"" to his GenotypeGVCFs command and that solved the issue. It did for me as well! Using the same combined GVCF file as I was before, genotyping finished in less than half a minute after adding the new-qual parameter. Thought it would be useful to know that:. 1, this issue appears to affect non-diploids more than diploids. 2, using --new-qual solved the issue, at least for me. I've attached the log-file generated from this new output, hopefully it helps in debugging.; [genotype108_newqual.e5290702.txt](https://github.com/broadinstitute/gatk/files/1853188/genotype108_newqual.e5290702.txt)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-376620043
https://github.com/broadinstitute/gatk/issues/4544#issuecomment-379313294:143,Integrability,depend,depend,143,"Another user reported back with some information in the same thread. . ` When not using the '-new-qual' option the memory overrun does seem to depend on the inclusion of non-diploid samples in the cohort (haploid males in my case). I have now separately analyzed the 37 diploid females in the dataset. The script ran successfully with the following specs`. `...ncpus=1:mem=12g...; gatk CombineGVCFs...; gatk --java-options ""-Xmx8g"" GenotypeGVCFs...; Peak memory use of the job was 9.5gb. A previous job with 8gb total memory was terminated due to memory overrun at the CombineGVCFs stage.`",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-379313294
https://github.com/broadinstitute/gatk/issues/4544#issuecomment-401904928:1589,Availability,down,down,1589,"ssion.so from jar:file:/home/vojta/bin/gatk/gatk-package-4.0.5.2-local.jar!/com/intel/gkl/native/libgkl_compression.so; 21:10:43.152 INFO GenotypeGVCFs - ------------------------------------------------------------; 21:10:43.153 INFO GenotypeGVCFs - The Genome Analysis Toolkit (GATK) v4.0.5.2; 21:10:43.153 INFO GenotypeGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 21:10:44.334 INFO GenotypeGVCFs - Initializing engine; 21:10:44.849 INFO FeatureManager - Using codec VCFCodec to read file file:///home/vojta/dokumenty/fakulta/botanika/arabidopsis/samples/lib_2018_06/4_joined/rad34test.comb2.raw.vcf.gz; 21:10:44.979 INFO GenotypeGVCFs - Done initializing engine; 21:10:45.057 INFO ProgressMeter - Starting traversal; 21:10:45.057 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 21:10:45.344 WARN InbreedingCoeff - Annotation will not be calculated, must provide at least 10 samples; 21:10:47.780 INFO GenotypeGVCFs - Shutting down engine; [2. července 2018 21:10:47 CEST] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 0.13 minutes.; Runtime.totalMemory()=501219328; java.lang.IllegalArgumentException: log10LikelihoodsOfAC are bad 6.911788849595091E-17,NaN; at org.broadinstitute.hellbender.tools.walkers.genotyper.afcalc.AFCalculationResult.<init>(AFCalculationResult.java:72); at org.broadinstitute.hellbender.tools.walkers.genotyper.afcalc.AlleleFrequencyCalculator.getLog10PNonRef(AlleleFrequencyCalculator.java:143); at org.broadinstitute.hellbender.tools.walkers.genotyper.GenotypingEngine.calculateGenotypes(GenotypingEngine.java:255); at org.broadinstitute.hellbender.tools.walkers.genotyper.GenotypingEngine.calculateGenotypes(GenotypingEngine.java:210); at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs.calculateGenotypes(GenotypeGVCFs.java:266); at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs.regenotypeVC(GenotypeGVCFs.java:222); at org.broadinsti",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-401904928
https://github.com/broadinstitute/gatk/issues/4544#issuecomment-401904928:3328,Integrability,wrap,wrapAndCopyInto,3328,ine.java:210); at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs.calculateGenotypes(GenotypeGVCFs.java:266); at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs.regenotypeVC(GenotypeGVCFs.java:222); at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs.apply(GenotypeGVCFs.java:201); at org.broadinstitute.hellbender.engine.VariantWalkerBase.lambda$traverse$0(VariantWalkerBase.java:151); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); at org.broadinstitute.hellbender.engine.VariantWalkerBase.traverse(VariantWalkerBase.java:149); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:984); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:135); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:180); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:199); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hel,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-401904928
https://github.com/broadinstitute/gatk/issues/4544#issuecomment-401904928:559,Performance,Load,Loading,559,"@Neato-Nick ~~No, it's very same.~~ Sorry, typing too fast. I tried it again and it crashes:. Using GATK jar /home/vojta/bin/gatk/gatk-package-4.0.5.2-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/vojta/bin/gatk/gatk-package-4.0.5.2-local.jar GenotypeGVCFs -O rad34test.comb2.raw.g.vcf.gz -R ../../../jic_reference/alygenomes.fasta -V rad34test.comb2.raw.vcf.gz -new-qual; 21:10:39.975 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/vojta/bin/gatk/gatk-package-4.0.5.2-local.jar!/com/intel/gkl/native/libgkl_compression.so; 21:10:43.152 INFO GenotypeGVCFs - ------------------------------------------------------------; 21:10:43.153 INFO GenotypeGVCFs - The Genome Analysis Toolkit (GATK) v4.0.5.2; 21:10:43.153 INFO GenotypeGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 21:10:44.334 INFO GenotypeGVCFs - Initializing engine; 21:10:44.849 INFO FeatureManager - Using codec VCFCodec to read file file:///home/vojta/dokumenty/fakulta/botanika/arabidopsis/samples/lib_2018_06/4_joined/rad34test.comb2.raw.vcf.gz; 21:10:44.979 INFO GenotypeGVCFs - Done initializing engine; 21:10:45.057 INFO ProgressMeter - Starting traversal; 21:10:45.057 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 21:10:45.344 WARN InbreedingCoeff - Annotation will not be calculated, must provide at least 10 samples; 21:10:47.780 INFO GenotypeGVCFs - Shutting down engine; [2. července 2018 21:10:47 CEST] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 0.13 minutes.; Runtime.totalMemory()=501219328; java.lang.IllegalArgumentException: log10LikelihoodsOfAC are bad 6.911788849595091E-17,NaN; at org.broadinstitute.hellbender.tools.walkers.genotyper.afcalc.AFCalculationResult.<init>(AFCalculationResult.java:72); at org.broadinstitute.hellb",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-401904928
https://github.com/broadinstitute/gatk/issues/4544#issuecomment-401931618:9,Availability,error,error,9,"@V-Z The error you encountered is a regression in `new-qual` that was introduced in `4.0.5.0`. You can track this issue here: https://github.com/broadinstitute/gatk/issues/4975. For the purposes of this ticket, you might want to do a test with GATK 4.0.4.0 and `new-qual`, and see if that works.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-401931618
https://github.com/broadinstitute/gatk/issues/4544#issuecomment-401931618:234,Testability,test,test,234,"@V-Z The error you encountered is a regression in `new-qual` that was introduced in `4.0.5.0`. You can track this issue here: https://github.com/broadinstitute/gatk/issues/4975. For the purposes of this ticket, you might want to do a test with GATK 4.0.4.0 and `new-qual`, and see if that works.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-401931618
https://github.com/broadinstitute/gatk/issues/4544#issuecomment-402183492:84,Deployability,upgrade,upgrade,84,"@V-Z As I suspected -- in that case I recommend running with `4.0.4.0` for now, and upgrade once https://github.com/broadinstitute/gatk/issues/4975 is fixed.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-402183492
https://github.com/broadinstitute/gatk/issues/4544#issuecomment-402199745:132,Availability,error,error,132,"@V-Z Would you mind sharing your GVCF, or just the offending chunk, with me so I can debug? I'm pretty sure it's a finite precision error and have a simple fix in mind but I would like to confirm on real data.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-402199745
https://github.com/broadinstitute/gatk/issues/4544#issuecomment-402199745:149,Usability,simpl,simple,149,"@V-Z Would you mind sharing your GVCF, or just the offending chunk, with me so I can debug? I'm pretty sure it's a finite precision error and have a simple fix in mind but I would like to confirm on real data.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-402199745
https://github.com/broadinstitute/gatk/issues/4544#issuecomment-402249931:210,Availability,down,download,210,Thanks @V-Z. I also just noticed that it's not a reference that I'm familiar with (I work on human cancer; Arabidopsis doesn't come up all that often). Could you send me the reference fasta or tell me where to download it?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-402249931
https://github.com/broadinstitute/gatk/issues/4544#issuecomment-408959663:39,Usability,feedback,feedback,39,"Thank you so much @Neato-Nick for your feedback, highly useful indeed! I was just worried that all these locations with warning signs are getting bypassed which as per your feedback should not be the case.; Regards,; Sanjeev",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-408959663
https://github.com/broadinstitute/gatk/issues/4544#issuecomment-408959663:173,Usability,feedback,feedback,173,"Thank you so much @Neato-Nick for your feedback, highly useful indeed! I was just worried that all these locations with warning signs are getting bypassed which as per your feedback should not be the case.; Regards,; Sanjeev",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-408959663
https://github.com/broadinstitute/gatk/issues/4544#issuecomment-409255344:1061,Availability,down,downstream,1061,"My GenotypeGVCFs run for a single chromosome returned the following completion statement:; 18:54:40.516 INFO ProgressMeter - Traversal complete. Processed 606308 total variants in 75.2 minutes. However, there are only 46814 variant rows (excluding 52 header rows) in the corresponding vcf file. Does the above figure of 606308 correspond to a multiple of 'variants x number of samples'?. Also, there are only 16863 lines in my log file, does this mean that the 'Current Locus' column in the log file doesn't correspond to a single genomic location (bp) in the fasta file?. I am curious to know what is the relation between all these figures to fully understand what is happening while processing the gCVF files. Also, on the inbreeding coefficient warning issue, I understand from your @Neato-Nick feedback that the variants with these warnings may still be fine and can be retained. However, this still leaves me worrying that out of 384 samples the locus doesn't even have 10 samples for generating the required metrics. Such variants won't be of any use for downstream analyses anyway where any variants with more than 80% missing samples will be removed. Therefore, I wish to seek some more information about this 10 sample thing - does it have some other context or does it literally mean that there are only less than 10 samples carrying that variant?. Regards,; Sanjeev",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-409255344
https://github.com/broadinstitute/gatk/issues/4544#issuecomment-409255344:427,Testability,log,log,427,"My GenotypeGVCFs run for a single chromosome returned the following completion statement:; 18:54:40.516 INFO ProgressMeter - Traversal complete. Processed 606308 total variants in 75.2 minutes. However, there are only 46814 variant rows (excluding 52 header rows) in the corresponding vcf file. Does the above figure of 606308 correspond to a multiple of 'variants x number of samples'?. Also, there are only 16863 lines in my log file, does this mean that the 'Current Locus' column in the log file doesn't correspond to a single genomic location (bp) in the fasta file?. I am curious to know what is the relation between all these figures to fully understand what is happening while processing the gCVF files. Also, on the inbreeding coefficient warning issue, I understand from your @Neato-Nick feedback that the variants with these warnings may still be fine and can be retained. However, this still leaves me worrying that out of 384 samples the locus doesn't even have 10 samples for generating the required metrics. Such variants won't be of any use for downstream analyses anyway where any variants with more than 80% missing samples will be removed. Therefore, I wish to seek some more information about this 10 sample thing - does it have some other context or does it literally mean that there are only less than 10 samples carrying that variant?. Regards,; Sanjeev",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-409255344
https://github.com/broadinstitute/gatk/issues/4544#issuecomment-409255344:491,Testability,log,log,491,"My GenotypeGVCFs run for a single chromosome returned the following completion statement:; 18:54:40.516 INFO ProgressMeter - Traversal complete. Processed 606308 total variants in 75.2 minutes. However, there are only 46814 variant rows (excluding 52 header rows) in the corresponding vcf file. Does the above figure of 606308 correspond to a multiple of 'variants x number of samples'?. Also, there are only 16863 lines in my log file, does this mean that the 'Current Locus' column in the log file doesn't correspond to a single genomic location (bp) in the fasta file?. I am curious to know what is the relation between all these figures to fully understand what is happening while processing the gCVF files. Also, on the inbreeding coefficient warning issue, I understand from your @Neato-Nick feedback that the variants with these warnings may still be fine and can be retained. However, this still leaves me worrying that out of 384 samples the locus doesn't even have 10 samples for generating the required metrics. Such variants won't be of any use for downstream analyses anyway where any variants with more than 80% missing samples will be removed. Therefore, I wish to seek some more information about this 10 sample thing - does it have some other context or does it literally mean that there are only less than 10 samples carrying that variant?. Regards,; Sanjeev",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-409255344
https://github.com/broadinstitute/gatk/issues/4544#issuecomment-409255344:798,Usability,feedback,feedback,798,"My GenotypeGVCFs run for a single chromosome returned the following completion statement:; 18:54:40.516 INFO ProgressMeter - Traversal complete. Processed 606308 total variants in 75.2 minutes. However, there are only 46814 variant rows (excluding 52 header rows) in the corresponding vcf file. Does the above figure of 606308 correspond to a multiple of 'variants x number of samples'?. Also, there are only 16863 lines in my log file, does this mean that the 'Current Locus' column in the log file doesn't correspond to a single genomic location (bp) in the fasta file?. I am curious to know what is the relation between all these figures to fully understand what is happening while processing the gCVF files. Also, on the inbreeding coefficient warning issue, I understand from your @Neato-Nick feedback that the variants with these warnings may still be fine and can be retained. However, this still leaves me worrying that out of 384 samples the locus doesn't even have 10 samples for generating the required metrics. Such variants won't be of any use for downstream analyses anyway where any variants with more than 80% missing samples will be removed. Therefore, I wish to seek some more information about this 10 sample thing - does it have some other context or does it literally mean that there are only less than 10 samples carrying that variant?. Regards,; Sanjeev",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-409255344
https://github.com/broadinstitute/gatk/issues/4544#issuecomment-409271340:136,Availability,error,errors,136,"Your best bet is to just start analyzing your data with this VCF. Doesn't; sound like your output log file showed any truly problematic errors. Things; like VCF Tools or vcfR (if you're familiar with R or want to start learning; it) give you some basic stats about your vcf file very quickly. This will; alleviate many of your concerns. On Tue, Jul 31, 2018, 11:10 AM sanjeevksh <notifications@github.com> wrote:. > My GenotypeGVCFs run for a single chromosome returned the following; > completion statement:; > 18:54:40.516 INFO ProgressMeter - Traversal complete. Processed 606308; > total variants in 75.2 minutes.; >; > However, there are only 46814 variant rows (excluding 52 header rows) in; > the corresponding vcf file. Does the above figure of 606308 correspond to a; > multiple of 'variants x number of samples'?; >; > Also, there are only 16863 lines in my log file, does this mean that the; > 'Current Locus' column in the log file doesn't correspond to a single; > genomic location (bp) in the fasta file?; >; > I am curious to know what is the relation between all these figures to; > fully understand what is happening while processing the gCVF files.; >; > Also, on the inbreeding coefficient warning issue, I understand from your; > @Neato-Nick <https://github.com/Neato-Nick> feedback that the variants; > with these warnings may still be fine and can be retained. However, this; > still leaves me worrying that out of 384 samples the locus doesn't even; > have 10 samples for generating the required metrics. Such variants won't be; > of any use for downstream analyses anyway where any variants with more than; > 80% missing samples will be removed. Therefore, I wish to seek some more; > information about this 10 sample thing - does it have some other context or; > does it literally mean that there are only less than 10 samples carrying; > that variant?; >; > Regards,; > Sanjeev; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, vi",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-409271340
https://github.com/broadinstitute/gatk/issues/4544#issuecomment-409271340:1569,Availability,down,downstream,1569,"ive you some basic stats about your vcf file very quickly. This will; alleviate many of your concerns. On Tue, Jul 31, 2018, 11:10 AM sanjeevksh <notifications@github.com> wrote:. > My GenotypeGVCFs run for a single chromosome returned the following; > completion statement:; > 18:54:40.516 INFO ProgressMeter - Traversal complete. Processed 606308; > total variants in 75.2 minutes.; >; > However, there are only 46814 variant rows (excluding 52 header rows) in; > the corresponding vcf file. Does the above figure of 606308 correspond to a; > multiple of 'variants x number of samples'?; >; > Also, there are only 16863 lines in my log file, does this mean that the; > 'Current Locus' column in the log file doesn't correspond to a single; > genomic location (bp) in the fasta file?; >; > I am curious to know what is the relation between all these figures to; > fully understand what is happening while processing the gCVF files.; >; > Also, on the inbreeding coefficient warning issue, I understand from your; > @Neato-Nick <https://github.com/Neato-Nick> feedback that the variants; > with these warnings may still be fine and can be retained. However, this; > still leaves me worrying that out of 384 samples the locus doesn't even; > have 10 samples for generating the required metrics. Such variants won't be; > of any use for downstream analyses anyway where any variants with more than; > 80% missing samples will be removed. Therefore, I wish to seek some more; > information about this 10 sample thing - does it have some other context or; > does it literally mean that there are only less than 10 samples carrying; > that variant?; >; > Regards,; > Sanjeev; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/4544#issuecomment-409255344>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AFlB0vsaHipT7i0GC5BcMgDZsS2DHbpaks5uMHNmgaJpZM4SyZJV>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-409271340
https://github.com/broadinstitute/gatk/issues/4544#issuecomment-409271340:98,Testability,log,log,98,"Your best bet is to just start analyzing your data with this VCF. Doesn't; sound like your output log file showed any truly problematic errors. Things; like VCF Tools or vcfR (if you're familiar with R or want to start learning; it) give you some basic stats about your vcf file very quickly. This will; alleviate many of your concerns. On Tue, Jul 31, 2018, 11:10 AM sanjeevksh <notifications@github.com> wrote:. > My GenotypeGVCFs run for a single chromosome returned the following; > completion statement:; > 18:54:40.516 INFO ProgressMeter - Traversal complete. Processed 606308; > total variants in 75.2 minutes.; >; > However, there are only 46814 variant rows (excluding 52 header rows) in; > the corresponding vcf file. Does the above figure of 606308 correspond to a; > multiple of 'variants x number of samples'?; >; > Also, there are only 16863 lines in my log file, does this mean that the; > 'Current Locus' column in the log file doesn't correspond to a single; > genomic location (bp) in the fasta file?; >; > I am curious to know what is the relation between all these figures to; > fully understand what is happening while processing the gCVF files.; >; > Also, on the inbreeding coefficient warning issue, I understand from your; > @Neato-Nick <https://github.com/Neato-Nick> feedback that the variants; > with these warnings may still be fine and can be retained. However, this; > still leaves me worrying that out of 384 samples the locus doesn't even; > have 10 samples for generating the required metrics. Such variants won't be; > of any use for downstream analyses anyway where any variants with more than; > 80% missing samples will be removed. Therefore, I wish to seek some more; > information about this 10 sample thing - does it have some other context or; > does it literally mean that there are only less than 10 samples carrying; > that variant?; >; > Regards,; > Sanjeev; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, vi",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-409271340
https://github.com/broadinstitute/gatk/issues/4544#issuecomment-409271340:868,Testability,log,log,868,"Your best bet is to just start analyzing your data with this VCF. Doesn't; sound like your output log file showed any truly problematic errors. Things; like VCF Tools or vcfR (if you're familiar with R or want to start learning; it) give you some basic stats about your vcf file very quickly. This will; alleviate many of your concerns. On Tue, Jul 31, 2018, 11:10 AM sanjeevksh <notifications@github.com> wrote:. > My GenotypeGVCFs run for a single chromosome returned the following; > completion statement:; > 18:54:40.516 INFO ProgressMeter - Traversal complete. Processed 606308; > total variants in 75.2 minutes.; >; > However, there are only 46814 variant rows (excluding 52 header rows) in; > the corresponding vcf file. Does the above figure of 606308 correspond to a; > multiple of 'variants x number of samples'?; >; > Also, there are only 16863 lines in my log file, does this mean that the; > 'Current Locus' column in the log file doesn't correspond to a single; > genomic location (bp) in the fasta file?; >; > I am curious to know what is the relation between all these figures to; > fully understand what is happening while processing the gCVF files.; >; > Also, on the inbreeding coefficient warning issue, I understand from your; > @Neato-Nick <https://github.com/Neato-Nick> feedback that the variants; > with these warnings may still be fine and can be retained. However, this; > still leaves me worrying that out of 384 samples the locus doesn't even; > have 10 samples for generating the required metrics. Such variants won't be; > of any use for downstream analyses anyway where any variants with more than; > 80% missing samples will be removed. Therefore, I wish to seek some more; > information about this 10 sample thing - does it have some other context or; > does it literally mean that there are only less than 10 samples carrying; > that variant?; >; > Regards,; > Sanjeev; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, vi",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-409271340
https://github.com/broadinstitute/gatk/issues/4544#issuecomment-409271340:935,Testability,log,log,935,"Your best bet is to just start analyzing your data with this VCF. Doesn't; sound like your output log file showed any truly problematic errors. Things; like VCF Tools or vcfR (if you're familiar with R or want to start learning; it) give you some basic stats about your vcf file very quickly. This will; alleviate many of your concerns. On Tue, Jul 31, 2018, 11:10 AM sanjeevksh <notifications@github.com> wrote:. > My GenotypeGVCFs run for a single chromosome returned the following; > completion statement:; > 18:54:40.516 INFO ProgressMeter - Traversal complete. Processed 606308; > total variants in 75.2 minutes.; >; > However, there are only 46814 variant rows (excluding 52 header rows) in; > the corresponding vcf file. Does the above figure of 606308 correspond to a; > multiple of 'variants x number of samples'?; >; > Also, there are only 16863 lines in my log file, does this mean that the; > 'Current Locus' column in the log file doesn't correspond to a single; > genomic location (bp) in the fasta file?; >; > I am curious to know what is the relation between all these figures to; > fully understand what is happening while processing the gCVF files.; >; > Also, on the inbreeding coefficient warning issue, I understand from your; > @Neato-Nick <https://github.com/Neato-Nick> feedback that the variants; > with these warnings may still be fine and can be retained. However, this; > still leaves me worrying that out of 384 samples the locus doesn't even; > have 10 samples for generating the required metrics. Such variants won't be; > of any use for downstream analyses anyway where any variants with more than; > 80% missing samples will be removed. Therefore, I wish to seek some more; > information about this 10 sample thing - does it have some other context or; > does it literally mean that there are only less than 10 samples carrying; > that variant?; >; > Regards,; > Sanjeev; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, vi",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-409271340
https://github.com/broadinstitute/gatk/issues/4544#issuecomment-409271340:219,Usability,learn,learning,219,"Your best bet is to just start analyzing your data with this VCF. Doesn't; sound like your output log file showed any truly problematic errors. Things; like VCF Tools or vcfR (if you're familiar with R or want to start learning; it) give you some basic stats about your vcf file very quickly. This will; alleviate many of your concerns. On Tue, Jul 31, 2018, 11:10 AM sanjeevksh <notifications@github.com> wrote:. > My GenotypeGVCFs run for a single chromosome returned the following; > completion statement:; > 18:54:40.516 INFO ProgressMeter - Traversal complete. Processed 606308; > total variants in 75.2 minutes.; >; > However, there are only 46814 variant rows (excluding 52 header rows) in; > the corresponding vcf file. Does the above figure of 606308 correspond to a; > multiple of 'variants x number of samples'?; >; > Also, there are only 16863 lines in my log file, does this mean that the; > 'Current Locus' column in the log file doesn't correspond to a single; > genomic location (bp) in the fasta file?; >; > I am curious to know what is the relation between all these figures to; > fully understand what is happening while processing the gCVF files.; >; > Also, on the inbreeding coefficient warning issue, I understand from your; > @Neato-Nick <https://github.com/Neato-Nick> feedback that the variants; > with these warnings may still be fine and can be retained. However, this; > still leaves me worrying that out of 384 samples the locus doesn't even; > have 10 samples for generating the required metrics. Such variants won't be; > of any use for downstream analyses anyway where any variants with more than; > 80% missing samples will be removed. Therefore, I wish to seek some more; > information about this 10 sample thing - does it have some other context or; > does it literally mean that there are only less than 10 samples carrying; > that variant?; >; > Regards,; > Sanjeev; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, vi",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-409271340
https://github.com/broadinstitute/gatk/issues/4544#issuecomment-409271340:1294,Usability,feedback,feedback,1294,"ive you some basic stats about your vcf file very quickly. This will; alleviate many of your concerns. On Tue, Jul 31, 2018, 11:10 AM sanjeevksh <notifications@github.com> wrote:. > My GenotypeGVCFs run for a single chromosome returned the following; > completion statement:; > 18:54:40.516 INFO ProgressMeter - Traversal complete. Processed 606308; > total variants in 75.2 minutes.; >; > However, there are only 46814 variant rows (excluding 52 header rows) in; > the corresponding vcf file. Does the above figure of 606308 correspond to a; > multiple of 'variants x number of samples'?; >; > Also, there are only 16863 lines in my log file, does this mean that the; > 'Current Locus' column in the log file doesn't correspond to a single; > genomic location (bp) in the fasta file?; >; > I am curious to know what is the relation between all these figures to; > fully understand what is happening while processing the gCVF files.; >; > Also, on the inbreeding coefficient warning issue, I understand from your; > @Neato-Nick <https://github.com/Neato-Nick> feedback that the variants; > with these warnings may still be fine and can be retained. However, this; > still leaves me worrying that out of 384 samples the locus doesn't even; > have 10 samples for generating the required metrics. Such variants won't be; > of any use for downstream analyses anyway where any variants with more than; > 80% missing samples will be removed. Therefore, I wish to seek some more; > information about this 10 sample thing - does it have some other context or; > does it literally mean that there are only less than 10 samples carrying; > that variant?; >; > Regards,; > Sanjeev; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/4544#issuecomment-409255344>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AFlB0vsaHipT7i0GC5BcMgDZsS2DHbpaks5uMHNmgaJpZM4SyZJV>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-409271340
https://github.com/broadinstitute/gatk/issues/4544#issuecomment-413285177:59,Integrability,message,message,59,"Hi @Neato-Nick @davidbenjamin . Apologies for posting this message here. I have posted this message few days before at the regular GATK forum and also using the direct inbox option but have got no response so maybe something wrong with my account. The issue is - I have done variant calling on 384 potato samples following, mostly, GATK best ##practices and have applied hard filters to select SNPs for further usage. However, I am noticing that '--max-nocall-fraction', '--max-nocall-number' and '--max-fraction-filtered-genotypes' arguments for 'SelectVariants' are not working properly. I have tried with various cutoff settings and every time I am observing SNPs with a much larger number of genotypes (~246 out of 384 with 0.10 setting) with 'no call' than the set thresholds. I have searched the forum first but couldn't find any relevant threads. I am using the latest GATK version (4.0.7.0). I am attaching three example sets of (1) log files (2) subset vcf files and (3) vcf index file for the three main vcfs. I would appreciate if you could provide any feedback on this issue and/or if this behaviour has been observed by some other users also. The link to the original post is here:; https://gatkforums.broadinstitute.org/gatk/discussion/12688/possible-bug-in-selectvariants-tool#latest; [SelectVariantBugReport.zip](https://github.com/broadinstitute/gatk/files/2291206/SelectVariantBugReport.zip). Regards,; Sanjeev",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-413285177
https://github.com/broadinstitute/gatk/issues/4544#issuecomment-413285177:92,Integrability,message,message,92,"Hi @Neato-Nick @davidbenjamin . Apologies for posting this message here. I have posted this message few days before at the regular GATK forum and also using the direct inbox option but have got no response so maybe something wrong with my account. The issue is - I have done variant calling on 384 potato samples following, mostly, GATK best ##practices and have applied hard filters to select SNPs for further usage. However, I am noticing that '--max-nocall-fraction', '--max-nocall-number' and '--max-fraction-filtered-genotypes' arguments for 'SelectVariants' are not working properly. I have tried with various cutoff settings and every time I am observing SNPs with a much larger number of genotypes (~246 out of 384 with 0.10 setting) with 'no call' than the set thresholds. I have searched the forum first but couldn't find any relevant threads. I am using the latest GATK version (4.0.7.0). I am attaching three example sets of (1) log files (2) subset vcf files and (3) vcf index file for the three main vcfs. I would appreciate if you could provide any feedback on this issue and/or if this behaviour has been observed by some other users also. The link to the original post is here:; https://gatkforums.broadinstitute.org/gatk/discussion/12688/possible-bug-in-selectvariants-tool#latest; [SelectVariantBugReport.zip](https://github.com/broadinstitute/gatk/files/2291206/SelectVariantBugReport.zip). Regards,; Sanjeev",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-413285177
https://github.com/broadinstitute/gatk/issues/4544#issuecomment-413285177:941,Testability,log,log,941,"Hi @Neato-Nick @davidbenjamin . Apologies for posting this message here. I have posted this message few days before at the regular GATK forum and also using the direct inbox option but have got no response so maybe something wrong with my account. The issue is - I have done variant calling on 384 potato samples following, mostly, GATK best ##practices and have applied hard filters to select SNPs for further usage. However, I am noticing that '--max-nocall-fraction', '--max-nocall-number' and '--max-fraction-filtered-genotypes' arguments for 'SelectVariants' are not working properly. I have tried with various cutoff settings and every time I am observing SNPs with a much larger number of genotypes (~246 out of 384 with 0.10 setting) with 'no call' than the set thresholds. I have searched the forum first but couldn't find any relevant threads. I am using the latest GATK version (4.0.7.0). I am attaching three example sets of (1) log files (2) subset vcf files and (3) vcf index file for the three main vcfs. I would appreciate if you could provide any feedback on this issue and/or if this behaviour has been observed by some other users also. The link to the original post is here:; https://gatkforums.broadinstitute.org/gatk/discussion/12688/possible-bug-in-selectvariants-tool#latest; [SelectVariantBugReport.zip](https://github.com/broadinstitute/gatk/files/2291206/SelectVariantBugReport.zip). Regards,; Sanjeev",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-413285177
https://github.com/broadinstitute/gatk/issues/4544#issuecomment-413285177:1064,Usability,feedback,feedback,1064,"Hi @Neato-Nick @davidbenjamin . Apologies for posting this message here. I have posted this message few days before at the regular GATK forum and also using the direct inbox option but have got no response so maybe something wrong with my account. The issue is - I have done variant calling on 384 potato samples following, mostly, GATK best ##practices and have applied hard filters to select SNPs for further usage. However, I am noticing that '--max-nocall-fraction', '--max-nocall-number' and '--max-fraction-filtered-genotypes' arguments for 'SelectVariants' are not working properly. I have tried with various cutoff settings and every time I am observing SNPs with a much larger number of genotypes (~246 out of 384 with 0.10 setting) with 'no call' than the set thresholds. I have searched the forum first but couldn't find any relevant threads. I am using the latest GATK version (4.0.7.0). I am attaching three example sets of (1) log files (2) subset vcf files and (3) vcf index file for the three main vcfs. I would appreciate if you could provide any feedback on this issue and/or if this behaviour has been observed by some other users also. The link to the original post is here:; https://gatkforums.broadinstitute.org/gatk/discussion/12688/possible-bug-in-selectvariants-tool#latest; [SelectVariantBugReport.zip](https://github.com/broadinstitute/gatk/files/2291206/SelectVariantBugReport.zip). Regards,; Sanjeev",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4544#issuecomment-413285177
https://github.com/broadinstitute/gatk/pull/4545#issuecomment-374774747:1275,Deployability,pipeline,pipelines,1275,?src=pr&el=desc) will **increase** coverage by `0.287%`.; > The diff coverage is `87.097%`. ```diff; @@ Coverage Diff @@; ## master #4545 +/- ##; ===============================================; + Coverage 80.355% 80.642% +0.287% ; - Complexity 17714 18478 +764 ; ===============================================; Files 1088 1089 +1 ; Lines 63975 66116 +2141 ; Branches 10313 10913 +600 ; ===============================================; + Hits 51407 53317 +1910 ; - Misses 8555 8661 +106 ; - Partials 4013 4138 +125; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4545?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...ender/engine/spark/datasources/ReadsSparkSink.java](https://codecov.io/gh/broadinstitute/gatk/pull/4545/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvUmVhZHNTcGFya1NpbmsuamF2YQ==) | `77.027% <ø> (ø)` | `33 <0> (ø)` | :arrow_down: |; | [...hellbender/tools/spark/pipelines/SortSamSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4545/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvU29ydFNhbVNwYXJrLmphdmE=) | `100% <100%> (+29.412%)` | `6 <3> (+2)` | :arrow_up: |; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/4545/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `65.541% <40%> (-0.432%)` | `39 <1> (+2)` | |; | [...der/engine/spark/datasources/ReadsSparkSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4545/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvUmVhZHNTcGFya1NvdXJjZS5qYXZh) | `80.208% <87.5%> (+0.663%)` | `31 <0> (ø)` | :arrow_down: |; | [...itute/hellbender/utils/test/SamAssertionUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4545/diff?src=pr&el,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4545#issuecomment-374774747
https://github.com/broadinstitute/gatk/pull/4545#issuecomment-374774747:1591,Testability,test,test,1591,====; Files 1088 1089 +1 ; Lines 63975 66116 +2141 ; Branches 10313 10913 +600 ; ===============================================; + Hits 51407 53317 +1910 ; - Misses 8555 8661 +106 ; - Partials 4013 4138 +125; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4545?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...ender/engine/spark/datasources/ReadsSparkSink.java](https://codecov.io/gh/broadinstitute/gatk/pull/4545/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvUmVhZHNTcGFya1NpbmsuamF2YQ==) | `77.027% <ø> (ø)` | `33 <0> (ø)` | :arrow_down: |; | [...hellbender/tools/spark/pipelines/SortSamSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4545/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvU29ydFNhbVNwYXJrLmphdmE=) | `100% <100%> (+29.412%)` | `6 <3> (+2)` | :arrow_up: |; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/4545/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `65.541% <40%> (-0.432%)` | `39 <1> (+2)` | |; | [...der/engine/spark/datasources/ReadsSparkSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4545/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvUmVhZHNTcGFya1NvdXJjZS5qYXZh) | `80.208% <87.5%> (+0.663%)` | `31 <0> (ø)` | :arrow_down: |; | [...itute/hellbender/utils/test/SamAssertionUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4545/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1NhbUFzc2VydGlvblV0aWxzLmphdmE=) | `70.256% <0%> (-2.564%)` | `42% <0%> (-4%)` | |; | [...nder/tools/funcotator/TranscriptSelectionMode.java](https://codecov.io/gh/broadinstitute/gatk/pull/4545/diff?src=pr&el=tree#diff-c3Jj,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4545#issuecomment-374774747
https://github.com/broadinstitute/gatk/pull/4545#issuecomment-374774747:2180,Testability,test,test,2180,msuamF2YQ==) | `77.027% <ø> (ø)` | `33 <0> (ø)` | :arrow_down: |; | [...hellbender/tools/spark/pipelines/SortSamSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/4545/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvU29ydFNhbVNwYXJrLmphdmE=) | `100% <100%> (+29.412%)` | `6 <3> (+2)` | :arrow_up: |; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/4545/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `65.541% <40%> (-0.432%)` | `39 <1> (+2)` | |; | [...der/engine/spark/datasources/ReadsSparkSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4545/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvUmVhZHNTcGFya1NvdXJjZS5qYXZh) | `80.208% <87.5%> (+0.663%)` | `31 <0> (ø)` | :arrow_down: |; | [...itute/hellbender/utils/test/SamAssertionUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4545/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L1NhbUFzc2VydGlvblV0aWxzLmphdmE=) | `70.256% <0%> (-2.564%)` | `42% <0%> (-4%)` | |; | [...nder/tools/funcotator/TranscriptSelectionMode.java](https://codecov.io/gh/broadinstitute/gatk/pull/4545/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL1RyYW5zY3JpcHRTZWxlY3Rpb25Nb2RlLmphdmE=) | `89.326% <0%> (-1.15%)` | `1% <0%> (ø)` | |; | [...tools/funcotator/DataSourceFuncotationFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/4545/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL0RhdGFTb3VyY2VGdW5jb3RhdGlvbkZhY3RvcnkuamF2YQ==) | `89.655% <0%> (-0.345%)` | `21% <0%> (+4%)` | |; | [...adinstitute/hellbender/utils/R/RScriptLibrary.java](https://codecov.io/gh/broadinstitute/gatk/pull/4545/diff?sr,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4545#issuecomment-374774747
https://github.com/broadinstitute/gatk/pull/4545#issuecomment-395166345:27,Testability,test,tests,27,@lbergelson looks like the tests passed this time around. We should open a ticket in Hadoop-Bam to fix the issue,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4545#issuecomment-395166345
https://github.com/broadinstitute/gatk/pull/4545#issuecomment-395191688:310,Testability,test,test,310,"@jamesemery I've opened a ticket in hadoop bam.; @droazen Could you re-review this when you get a chance? It's super useful functionality. If we don't trust the fix for sharded files, we could globally disable them for cram/sam instead. I think the problem is not unique to this branch, it's just the first to test the file order or reading sharded cram/sam.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4545#issuecomment-395191688
https://github.com/broadinstitute/gatk/pull/4546#issuecomment-374743257:25,Testability,test,test,25,"@cmnbroad I didn't add a test case here because it seemed like overkill, but I can do so if you think it's necessary.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4546#issuecomment-374743257
https://github.com/broadinstitute/gatk/pull/4547#issuecomment-374994787:76,Testability,test,test,76,"@jonn-smith I forgot to change the default in the GATKConfig.java, and your test caught it. That's awesome!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4547#issuecomment-374994787
https://github.com/broadinstitute/gatk/issues/4549#issuecomment-415085395:52,Availability,down,download,52,"For initial 1.0 release, just have a tool that will download the zipped data source package specified by the user from the bucket/ftp site.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4549#issuecomment-415085395
https://github.com/broadinstitute/gatk/issues/4549#issuecomment-415085395:16,Deployability,release,release,16,"For initial 1.0 release, just have a tool that will download the zipped data source package specified by the user from the bucket/ftp site.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4549#issuecomment-415085395
https://github.com/broadinstitute/gatk/issues/4550#issuecomment-375061877:127,Modifiability,refactor,refactored,127,"@jonn-smith Can you be more specific? If we come back to this ticket in 3 months, we won't remember exactly how it needs to be refactored.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4550#issuecomment-375061877
https://github.com/broadinstitute/gatk/issues/4551#issuecomment-375122976:1265,Deployability,update,update,1265,"Interesting! Thanks for generating these. I am already convinced by #4519 we should at least switch over to a ‘CollectReadCounts’ strategy for initial evaluations. A few comments:. -I’m guessing that the equal insert size and uniform sampling is enhancing many of these artifacts to a level that we probably don’t see in the real world. Can we take a look at some real-world examples?. -Same goes for the fact that homs will be unlikely. -Not sure about the dropouts. Might be worth running without SNPs as a confounding factor. -How flexible is SVGen? Might be worth putting together a more realistic simulated data set. Any chance @MartonKN might be able to use it to cook up some realistic tumor data?. -I don’t recall having a `CollectBaseCallCoverage` type tool in beta—which tool are you thinking of? On a related note, it seems there is some demand to port `DepthOfCoverage` from GATK3. However, I’d prefer that we roll a CNV-specific version of the tool even if it does get ported. In any case, I think along with findings from the other issue, we should issue a quick PR for `CollectReadCounts` and go ahead to change the `CollectCounts` WDL task to call it—it’s for this very reason that the task is named generically! @sooheelee note that we may have to update the tutorials, etc. at some point, but perhaps the right time will be until all evaluations are more complete. Speaking of which, this PR should not delay getting the first round of automated evaluations up and running. Again, the whole point of those is to have a reproducible baseline metric against which we can easily experiment with and adopt these sorts of changes. Although these sorts of theoretical/simulated/thought experiments are clearly useful to us, unfortunately, they may not be as compelling to some of our users as demonstrable improvement seems on real data!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4551#issuecomment-375122976
https://github.com/broadinstitute/gatk/issues/4551#issuecomment-375122976:534,Modifiability,flexible,flexible,534,"Interesting! Thanks for generating these. I am already convinced by #4519 we should at least switch over to a ‘CollectReadCounts’ strategy for initial evaluations. A few comments:. -I’m guessing that the equal insert size and uniform sampling is enhancing many of these artifacts to a level that we probably don’t see in the real world. Can we take a look at some real-world examples?. -Same goes for the fact that homs will be unlikely. -Not sure about the dropouts. Might be worth running without SNPs as a confounding factor. -How flexible is SVGen? Might be worth putting together a more realistic simulated data set. Any chance @MartonKN might be able to use it to cook up some realistic tumor data?. -I don’t recall having a `CollectBaseCallCoverage` type tool in beta—which tool are you thinking of? On a related note, it seems there is some demand to port `DepthOfCoverage` from GATK3. However, I’d prefer that we roll a CNV-specific version of the tool even if it does get ported. In any case, I think along with findings from the other issue, we should issue a quick PR for `CollectReadCounts` and go ahead to change the `CollectCounts` WDL task to call it—it’s for this very reason that the task is named generically! @sooheelee note that we may have to update the tutorials, etc. at some point, but perhaps the right time will be until all evaluations are more complete. Speaking of which, this PR should not delay getting the first round of automated evaluations up and running. Again, the whole point of those is to have a reproducible baseline metric against which we can easily experiment with and adopt these sorts of changes. Although these sorts of theoretical/simulated/thought experiments are clearly useful to us, unfortunately, they may not be as compelling to some of our users as demonstrable improvement seems on real data!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4551#issuecomment-375122976
https://github.com/broadinstitute/gatk/issues/4551#issuecomment-375122976:1714,Usability,clear,clearly,1714,"Interesting! Thanks for generating these. I am already convinced by #4519 we should at least switch over to a ‘CollectReadCounts’ strategy for initial evaluations. A few comments:. -I’m guessing that the equal insert size and uniform sampling is enhancing many of these artifacts to a level that we probably don’t see in the real world. Can we take a look at some real-world examples?. -Same goes for the fact that homs will be unlikely. -Not sure about the dropouts. Might be worth running without SNPs as a confounding factor. -How flexible is SVGen? Might be worth putting together a more realistic simulated data set. Any chance @MartonKN might be able to use it to cook up some realistic tumor data?. -I don’t recall having a `CollectBaseCallCoverage` type tool in beta—which tool are you thinking of? On a related note, it seems there is some demand to port `DepthOfCoverage` from GATK3. However, I’d prefer that we roll a CNV-specific version of the tool even if it does get ported. In any case, I think along with findings from the other issue, we should issue a quick PR for `CollectReadCounts` and go ahead to change the `CollectCounts` WDL task to call it—it’s for this very reason that the task is named generically! @sooheelee note that we may have to update the tutorials, etc. at some point, but perhaps the right time will be until all evaluations are more complete. Speaking of which, this PR should not delay getting the first round of automated evaluations up and running. Again, the whole point of those is to have a reproducible baseline metric against which we can easily experiment with and adopt these sorts of changes. Although these sorts of theoretical/simulated/thought experiments are clearly useful to us, unfortunately, they may not be as compelling to some of our users as demonstrable improvement seems on real data!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4551#issuecomment-375122976
https://github.com/broadinstitute/gatk/issues/4551#issuecomment-375126971:79,Deployability,pipeline,pipeline,79,"Also, just to provide some context to all tagged: certain users of the old CNV pipeline expressed somewhat vague concerns with the non-fragment-based coverage collection strategies—which also differed across WES and WGS, to boot—-but didn’t offer any compelling demonstrations that fragment-based strategies were better. For the new version of the pipelines, the main priority was to pick a single strategy to unify WES/WGS coverage collection. We decided to give a simple fragment-based strategy a shot—-with the intention of using automated evaluations to test it in a rigorous manner. Although those aren’t in place yet, I’m comfortable with making the call against it at this point.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4551#issuecomment-375126971
https://github.com/broadinstitute/gatk/issues/4551#issuecomment-375126971:348,Deployability,pipeline,pipelines,348,"Also, just to provide some context to all tagged: certain users of the old CNV pipeline expressed somewhat vague concerns with the non-fragment-based coverage collection strategies—which also differed across WES and WGS, to boot—-but didn’t offer any compelling demonstrations that fragment-based strategies were better. For the new version of the pipelines, the main priority was to pick a single strategy to unify WES/WGS coverage collection. We decided to give a simple fragment-based strategy a shot—-with the intention of using automated evaluations to test it in a rigorous manner. Although those aren’t in place yet, I’m comfortable with making the call against it at this point.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4551#issuecomment-375126971
https://github.com/broadinstitute/gatk/issues/4551#issuecomment-375126971:558,Testability,test,test,558,"Also, just to provide some context to all tagged: certain users of the old CNV pipeline expressed somewhat vague concerns with the non-fragment-based coverage collection strategies—which also differed across WES and WGS, to boot—-but didn’t offer any compelling demonstrations that fragment-based strategies were better. For the new version of the pipelines, the main priority was to pick a single strategy to unify WES/WGS coverage collection. We decided to give a simple fragment-based strategy a shot—-with the intention of using automated evaluations to test it in a rigorous manner. Although those aren’t in place yet, I’m comfortable with making the call against it at this point.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4551#issuecomment-375126971
https://github.com/broadinstitute/gatk/issues/4551#issuecomment-375126971:466,Usability,simpl,simple,466,"Also, just to provide some context to all tagged: certain users of the old CNV pipeline expressed somewhat vague concerns with the non-fragment-based coverage collection strategies—which also differed across WES and WGS, to boot—-but didn’t offer any compelling demonstrations that fragment-based strategies were better. For the new version of the pipelines, the main priority was to pick a single strategy to unify WES/WGS coverage collection. We decided to give a simple fragment-based strategy a shot—-with the intention of using automated evaluations to test it in a rigorous manner. Although those aren’t in place yet, I’m comfortable with making the call against it at this point.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4551#issuecomment-375126971
https://github.com/broadinstitute/gatk/issues/4551#issuecomment-375720743:245,Availability,error,error,245,"**Update:**. Here's how the coverage looks like using `CollectReadCounts` (w/ and w/o MQ > 30 filter) vs. `CollectFragmentCounts`. The lines are offset by +10 and +20 for better visibility. Summary: marked improvement in all cases, however, the error modes are different. `CollectFragmentCounts` tends to underestimate the size of SV regions and uniformly leads to coverage depletion near the breakpoints, `CollectReadCounts` estimates the size of SV regions better, however, coverage near the breakpoints tend to be less predictable (sometimes depletion, sometimes accumulation). Still, IGV seems to do the best job. Any improvement over `CollectReadCounts` requires using supplementary alignment information (e.g. weight sharing among supplementary alignments; this will likely fix the coverage asymmetry of translocation breakpoints), read clipping information, and mismatches. The latter two require a base-level coverage collection strategy (like IGV and `CollectTargetBaseCallCoverage`). _Unbalanced translocation:_. ![unbtr-1](https://user-images.githubusercontent.com/15305869/37840319-1aba29ce-2e93-11e8-9d41-b9eafe450b6d.png). ![unbtr-2](https://user-images.githubusercontent.com/15305869/37840320-1bfff9a8-2e93-11e8-9842-39824f9fad64.png). ![unbtr-3](https://user-images.githubusercontent.com/15305869/37840321-1d82fa00-2e93-11e8-88ec-d7c40876594e.png). _Balanced translocation:_. ![baltr-1](https://user-images.githubusercontent.com/15305869/37840331-26a0962e-2e93-11e8-8dcf-0e69c8e45146.png). _Inversion:_. ![inv-1](https://user-images.githubusercontent.com/15305869/37840347-2f0d2f8e-2e93-11e8-8d36-64367951e7f2.png). ![inv-2](https://user-images.githubusercontent.com/15305869/37840350-306dedbe-2e93-11e8-9837-53369f5fb1f0.png). _Deletion:_. ![del-1](https://user-images.githubusercontent.com/15305869/37840366-3a32c0ea-2e93-11e8-99dc-d949985616d9.png). _Tandem Duplication:_. ![dup-1](https://user-images.githubusercontent.com/15305869/37840373-42052542-2e93-11e8-8891-fa9f79cc9f70.png",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4551#issuecomment-375720743
https://github.com/broadinstitute/gatk/issues/4551#issuecomment-375720743:2,Deployability,Update,Update,2,"**Update:**. Here's how the coverage looks like using `CollectReadCounts` (w/ and w/o MQ > 30 filter) vs. `CollectFragmentCounts`. The lines are offset by +10 and +20 for better visibility. Summary: marked improvement in all cases, however, the error modes are different. `CollectFragmentCounts` tends to underestimate the size of SV regions and uniformly leads to coverage depletion near the breakpoints, `CollectReadCounts` estimates the size of SV regions better, however, coverage near the breakpoints tend to be less predictable (sometimes depletion, sometimes accumulation). Still, IGV seems to do the best job. Any improvement over `CollectReadCounts` requires using supplementary alignment information (e.g. weight sharing among supplementary alignments; this will likely fix the coverage asymmetry of translocation breakpoints), read clipping information, and mismatches. The latter two require a base-level coverage collection strategy (like IGV and `CollectTargetBaseCallCoverage`). _Unbalanced translocation:_. ![unbtr-1](https://user-images.githubusercontent.com/15305869/37840319-1aba29ce-2e93-11e8-9d41-b9eafe450b6d.png). ![unbtr-2](https://user-images.githubusercontent.com/15305869/37840320-1bfff9a8-2e93-11e8-9842-39824f9fad64.png). ![unbtr-3](https://user-images.githubusercontent.com/15305869/37840321-1d82fa00-2e93-11e8-88ec-d7c40876594e.png). _Balanced translocation:_. ![baltr-1](https://user-images.githubusercontent.com/15305869/37840331-26a0962e-2e93-11e8-8dcf-0e69c8e45146.png). _Inversion:_. ![inv-1](https://user-images.githubusercontent.com/15305869/37840347-2f0d2f8e-2e93-11e8-8d36-64367951e7f2.png). ![inv-2](https://user-images.githubusercontent.com/15305869/37840350-306dedbe-2e93-11e8-9837-53369f5fb1f0.png). _Deletion:_. ![del-1](https://user-images.githubusercontent.com/15305869/37840366-3a32c0ea-2e93-11e8-99dc-d949985616d9.png). _Tandem Duplication:_. ![dup-1](https://user-images.githubusercontent.com/15305869/37840373-42052542-2e93-11e8-8891-fa9f79cc9f70.png",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4551#issuecomment-375720743
https://github.com/broadinstitute/gatk/issues/4551#issuecomment-375720743:522,Safety,predict,predictable,522,"**Update:**. Here's how the coverage looks like using `CollectReadCounts` (w/ and w/o MQ > 30 filter) vs. `CollectFragmentCounts`. The lines are offset by +10 and +20 for better visibility. Summary: marked improvement in all cases, however, the error modes are different. `CollectFragmentCounts` tends to underestimate the size of SV regions and uniformly leads to coverage depletion near the breakpoints, `CollectReadCounts` estimates the size of SV regions better, however, coverage near the breakpoints tend to be less predictable (sometimes depletion, sometimes accumulation). Still, IGV seems to do the best job. Any improvement over `CollectReadCounts` requires using supplementary alignment information (e.g. weight sharing among supplementary alignments; this will likely fix the coverage asymmetry of translocation breakpoints), read clipping information, and mismatches. The latter two require a base-level coverage collection strategy (like IGV and `CollectTargetBaseCallCoverage`). _Unbalanced translocation:_. ![unbtr-1](https://user-images.githubusercontent.com/15305869/37840319-1aba29ce-2e93-11e8-9d41-b9eafe450b6d.png). ![unbtr-2](https://user-images.githubusercontent.com/15305869/37840320-1bfff9a8-2e93-11e8-9842-39824f9fad64.png). ![unbtr-3](https://user-images.githubusercontent.com/15305869/37840321-1d82fa00-2e93-11e8-88ec-d7c40876594e.png). _Balanced translocation:_. ![baltr-1](https://user-images.githubusercontent.com/15305869/37840331-26a0962e-2e93-11e8-8dcf-0e69c8e45146.png). _Inversion:_. ![inv-1](https://user-images.githubusercontent.com/15305869/37840347-2f0d2f8e-2e93-11e8-8d36-64367951e7f2.png). ![inv-2](https://user-images.githubusercontent.com/15305869/37840350-306dedbe-2e93-11e8-9837-53369f5fb1f0.png). _Deletion:_. ![del-1](https://user-images.githubusercontent.com/15305869/37840366-3a32c0ea-2e93-11e8-99dc-d949985616d9.png). _Tandem Duplication:_. ![dup-1](https://user-images.githubusercontent.com/15305869/37840373-42052542-2e93-11e8-8891-fa9f79cc9f70.png",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4551#issuecomment-375720743
https://github.com/broadinstitute/gatk/issues/4551#issuecomment-375722179:145,Availability,down,downstream,145,"Also, MQ filtering results in stochastic coverage dropout. It is likely that low MQ regions significantly overlap across samples, in which case, downstream CNV can learn such biases and correct the coverage. Will test this in validations.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4551#issuecomment-375722179
https://github.com/broadinstitute/gatk/issues/4551#issuecomment-375722179:226,Security,validat,validations,226,"Also, MQ filtering results in stochastic coverage dropout. It is likely that low MQ regions significantly overlap across samples, in which case, downstream CNV can learn such biases and correct the coverage. Will test this in validations.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4551#issuecomment-375722179
https://github.com/broadinstitute/gatk/issues/4551#issuecomment-375722179:213,Testability,test,test,213,"Also, MQ filtering results in stochastic coverage dropout. It is likely that low MQ regions significantly overlap across samples, in which case, downstream CNV can learn such biases and correct the coverage. Will test this in validations.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4551#issuecomment-375722179
https://github.com/broadinstitute/gatk/issues/4551#issuecomment-375722179:164,Usability,learn,learn,164,"Also, MQ filtering results in stochastic coverage dropout. It is likely that low MQ regions significantly overlap across samples, in which case, downstream CNV can learn such biases and correct the coverage. Will test this in validations.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4551#issuecomment-375722179
https://github.com/broadinstitute/gatk/issues/4551#issuecomment-376203065:38,Deployability,update,update,38,"> @sooheelee note that we may have to update the tutorials, etc. at some point, but perhaps the right time will be until all evaluations are more complete. Thanks, @samuelklee for keeping me updated.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4551#issuecomment-376203065
https://github.com/broadinstitute/gatk/issues/4551#issuecomment-376203065:191,Deployability,update,updated,191,"> @sooheelee note that we may have to update the tutorials, etc. at some point, but perhaps the right time will be until all evaluations are more complete. Thanks, @samuelklee for keeping me updated.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4551#issuecomment-376203065
https://github.com/broadinstitute/gatk/issues/4555#issuecomment-375935335:104,Modifiability,inherit,inherited,104,"@sooheelee [Commenting on the forum discussion] `--alleles`, `--genotyping-mode`, and `--consensus` are inherited from a common parent class of Mutect2 and HaplotypeCaller and are inactive in GATK 4 Mutect2. I should fix this misleading situation. @cbao-bi's use case is important and the work-around that I gave on the forum is not satisfactory. I'm convinced that it's worth doing it right. Let me tentatively guess that I can put in a good force-calling mode within two months.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4555#issuecomment-375935335
https://github.com/broadinstitute/gatk/issues/4555#issuecomment-375988400:54,Deployability,update,updated,54,Thanks @davidbenjamin and @sooheelee ! Please keep me updated.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4555#issuecomment-375988400
https://github.com/broadinstitute/gatk/issues/4555#issuecomment-378370696:153,Deployability,pipeline,pipeline,153,Cool! Thanks @davidbenjamin. I like the wdl because I can use the vcf from M2 and do not need to generate interval list (Interval list is required in M1 pipeline). Hope to get the docker soon.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4555#issuecomment-378370696
https://github.com/broadinstitute/gatk/issues/4556#issuecomment-375432298:77,Deployability,configurat,configuration,77,The problem seems to be fixed in picard with @cmnbroad's change to the cloud configuration. Thew pom for 2.18.1+ looks like it won't include nio.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4556#issuecomment-375432298
https://github.com/broadinstitute/gatk/issues/4556#issuecomment-375432298:77,Modifiability,config,configuration,77,The problem seems to be fixed in picard with @cmnbroad's change to the cloud configuration. Thew pom for 2.18.1+ looks like it won't include nio.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4556#issuecomment-375432298
https://github.com/broadinstitute/gatk/issues/4558#issuecomment-375387033:116,Deployability,pipeline,pipeline,116,@samuelklee mappability filtering is highly likely to get rid of a lot of the deletion calls in the `ModelSegments` pipeline.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4558#issuecomment-375387033
https://github.com/broadinstitute/gatk/issues/4558#issuecomment-375881040:344,Availability,mask,masking,344,"A few comments to add on to what we discussed in person:. I think the coverage distribution is indeed the correct summary statistic to model for this problem. Total coverage just doesn't provide enough information, but subsampling bins or fitting a per-bin bias model is overkill. However, I think a straightforward, self-contained modeling or masking approach (which need not rely on a mappability track) within the ploidy-determination tool is still quite feasible. I think that if we can easily solve the problem without requiring a mappability track then we should try to do it, as that is a relatively expensive resource to create. For example, some very naive hard filtering (red) of the histogram yields a peak that is easily fit by a negative binomial (green)---even a Poisson fit does not appear to bias the depth estimates, and certainly does not result in incorrect ploidy estimates:. ![masked_fit](https://user-images.githubusercontent.com/11076296/37863641-827a6e8a-2f37-11e8-83d5-cb4af32a898b.png). (Incidentally, it is helpful to plot on a log scale when checking the fit of these distributions.). This strategy also gives us a way to ignore low-level mosaicism or large germline events, which filtering on mappability may not address:. ![mosaic](https://user-images.githubusercontent.com/11076296/37863649-d0ac378c-2f37-11e8-8e98-45e1fa9a3d7a.png). So let's try to encapsulate changes to the ploidy tool. I agree that the histogram creation can be easily done on the Java side, to save on intermediate file writing. We can probably just cap the maximum bin to `k` and pass a samples x contig TSV where each entry is a vector with `k + 1` elements. I agree that there is still a lot of important work to be done in exploring our best practices for coverage collection, and I know that you have been interested in improving them for a while. Ultimately, we may want to consider incorporating mappability or other informative metadata, as we've discussed. However, this will require some ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4558#issuecomment-375881040
https://github.com/broadinstitute/gatk/issues/4558#issuecomment-375881040:2209,Deployability,release,release,2209,"d try to do it, as that is a relatively expensive resource to create. For example, some very naive hard filtering (red) of the histogram yields a peak that is easily fit by a negative binomial (green)---even a Poisson fit does not appear to bias the depth estimates, and certainly does not result in incorrect ploidy estimates:. ![masked_fit](https://user-images.githubusercontent.com/11076296/37863641-827a6e8a-2f37-11e8-83d5-cb4af32a898b.png). (Incidentally, it is helpful to plot on a log scale when checking the fit of these distributions.). This strategy also gives us a way to ignore low-level mosaicism or large germline events, which filtering on mappability may not address:. ![mosaic](https://user-images.githubusercontent.com/11076296/37863649-d0ac378c-2f37-11e8-8e98-45e1fa9a3d7a.png). So let's try to encapsulate changes to the ploidy tool. I agree that the histogram creation can be easily done on the Java side, to save on intermediate file writing. We can probably just cap the maximum bin to `k` and pass a samples x contig TSV where each entry is a vector with `k + 1` elements. I agree that there is still a lot of important work to be done in exploring our best practices for coverage collection, and I know that you have been interested in improving them for a while. Ultimately, we may want to consider incorporating mappability or other informative metadata, as we've discussed. However, this will require some non-trivial investment in method/tool development time. Since our preliminary evaluations show that even with the current, naive strategies the tool is performing reasonably well, I am prioritizing cutting a release and improving/automating the evaluations. As we discussed, this will both allow users to start using the tool (which will hopefully result in useful feedback) and establish a baseline for us. This will ultimately provide the necessary foundation for future exploratory work and method development---which always takes more time than we think it will!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4558#issuecomment-375881040
https://github.com/broadinstitute/gatk/issues/4558#issuecomment-375881040:761,Energy Efficiency,green,green,761,"A few comments to add on to what we discussed in person:. I think the coverage distribution is indeed the correct summary statistic to model for this problem. Total coverage just doesn't provide enough information, but subsampling bins or fitting a per-bin bias model is overkill. However, I think a straightforward, self-contained modeling or masking approach (which need not rely on a mappability track) within the ploidy-determination tool is still quite feasible. I think that if we can easily solve the problem without requiring a mappability track then we should try to do it, as that is a relatively expensive resource to create. For example, some very naive hard filtering (red) of the histogram yields a peak that is easily fit by a negative binomial (green)---even a Poisson fit does not appear to bias the depth estimates, and certainly does not result in incorrect ploidy estimates:. ![masked_fit](https://user-images.githubusercontent.com/11076296/37863641-827a6e8a-2f37-11e8-83d5-cb4af32a898b.png). (Incidentally, it is helpful to plot on a log scale when checking the fit of these distributions.). This strategy also gives us a way to ignore low-level mosaicism or large germline events, which filtering on mappability may not address:. ![mosaic](https://user-images.githubusercontent.com/11076296/37863649-d0ac378c-2f37-11e8-8e98-45e1fa9a3d7a.png). So let's try to encapsulate changes to the ploidy tool. I agree that the histogram creation can be easily done on the Java side, to save on intermediate file writing. We can probably just cap the maximum bin to `k` and pass a samples x contig TSV where each entry is a vector with `k + 1` elements. I agree that there is still a lot of important work to be done in exploring our best practices for coverage collection, and I know that you have been interested in improving them for a while. Ultimately, we may want to consider incorporating mappability or other informative metadata, as we've discussed. However, this will require some ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4558#issuecomment-375881040
https://github.com/broadinstitute/gatk/issues/4558#issuecomment-375881040:2153,Performance,perform,performing,2153,"d try to do it, as that is a relatively expensive resource to create. For example, some very naive hard filtering (red) of the histogram yields a peak that is easily fit by a negative binomial (green)---even a Poisson fit does not appear to bias the depth estimates, and certainly does not result in incorrect ploidy estimates:. ![masked_fit](https://user-images.githubusercontent.com/11076296/37863641-827a6e8a-2f37-11e8-83d5-cb4af32a898b.png). (Incidentally, it is helpful to plot on a log scale when checking the fit of these distributions.). This strategy also gives us a way to ignore low-level mosaicism or large germline events, which filtering on mappability may not address:. ![mosaic](https://user-images.githubusercontent.com/11076296/37863649-d0ac378c-2f37-11e8-8e98-45e1fa9a3d7a.png). So let's try to encapsulate changes to the ploidy tool. I agree that the histogram creation can be easily done on the Java side, to save on intermediate file writing. We can probably just cap the maximum bin to `k` and pass a samples x contig TSV where each entry is a vector with `k + 1` elements. I agree that there is still a lot of important work to be done in exploring our best practices for coverage collection, and I know that you have been interested in improving them for a while. Ultimately, we may want to consider incorporating mappability or other informative metadata, as we've discussed. However, this will require some non-trivial investment in method/tool development time. Since our preliminary evaluations show that even with the current, naive strategies the tool is performing reasonably well, I am prioritizing cutting a release and improving/automating the evaluations. As we discussed, this will both allow users to start using the tool (which will hopefully result in useful feedback) and establish a baseline for us. This will ultimately provide the necessary foundation for future exploratory work and method development---which always takes more time than we think it will!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4558#issuecomment-375881040
https://github.com/broadinstitute/gatk/issues/4558#issuecomment-375881040:1055,Testability,log,log,1055,"hink the coverage distribution is indeed the correct summary statistic to model for this problem. Total coverage just doesn't provide enough information, but subsampling bins or fitting a per-bin bias model is overkill. However, I think a straightforward, self-contained modeling or masking approach (which need not rely on a mappability track) within the ploidy-determination tool is still quite feasible. I think that if we can easily solve the problem without requiring a mappability track then we should try to do it, as that is a relatively expensive resource to create. For example, some very naive hard filtering (red) of the histogram yields a peak that is easily fit by a negative binomial (green)---even a Poisson fit does not appear to bias the depth estimates, and certainly does not result in incorrect ploidy estimates:. ![masked_fit](https://user-images.githubusercontent.com/11076296/37863641-827a6e8a-2f37-11e8-83d5-cb4af32a898b.png). (Incidentally, it is helpful to plot on a log scale when checking the fit of these distributions.). This strategy also gives us a way to ignore low-level mosaicism or large germline events, which filtering on mappability may not address:. ![mosaic](https://user-images.githubusercontent.com/11076296/37863649-d0ac378c-2f37-11e8-8e98-45e1fa9a3d7a.png). So let's try to encapsulate changes to the ploidy tool. I agree that the histogram creation can be easily done on the Java side, to save on intermediate file writing. We can probably just cap the maximum bin to `k` and pass a samples x contig TSV where each entry is a vector with `k + 1` elements. I agree that there is still a lot of important work to be done in exploring our best practices for coverage collection, and I know that you have been interested in improving them for a while. Ultimately, we may want to consider incorporating mappability or other informative metadata, as we've discussed. However, this will require some non-trivial investment in method/tool development time. Sinc",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4558#issuecomment-375881040
https://github.com/broadinstitute/gatk/issues/4558#issuecomment-375881040:2366,Usability,feedback,feedback,2366,"d try to do it, as that is a relatively expensive resource to create. For example, some very naive hard filtering (red) of the histogram yields a peak that is easily fit by a negative binomial (green)---even a Poisson fit does not appear to bias the depth estimates, and certainly does not result in incorrect ploidy estimates:. ![masked_fit](https://user-images.githubusercontent.com/11076296/37863641-827a6e8a-2f37-11e8-83d5-cb4af32a898b.png). (Incidentally, it is helpful to plot on a log scale when checking the fit of these distributions.). This strategy also gives us a way to ignore low-level mosaicism or large germline events, which filtering on mappability may not address:. ![mosaic](https://user-images.githubusercontent.com/11076296/37863649-d0ac378c-2f37-11e8-8e98-45e1fa9a3d7a.png). So let's try to encapsulate changes to the ploidy tool. I agree that the histogram creation can be easily done on the Java side, to save on intermediate file writing. We can probably just cap the maximum bin to `k` and pass a samples x contig TSV where each entry is a vector with `k + 1` elements. I agree that there is still a lot of important work to be done in exploring our best practices for coverage collection, and I know that you have been interested in improving them for a while. Ultimately, we may want to consider incorporating mappability or other informative metadata, as we've discussed. However, this will require some non-trivial investment in method/tool development time. Since our preliminary evaluations show that even with the current, naive strategies the tool is performing reasonably well, I am prioritizing cutting a release and improving/automating the evaluations. As we discussed, this will both allow users to start using the tool (which will hopefully result in useful feedback) and establish a baseline for us. This will ultimately provide the necessary foundation for future exploratory work and method development---which always takes more time than we think it will!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4558#issuecomment-375881040
https://github.com/broadinstitute/gatk/issues/4558#issuecomment-375917669:1604,Deployability,release,release,1604,"dian count is significantly away from the main peak (due to the abundance of low mappability bins with small counts). . Also, the second peak of chrX coverage in XY samples that you show above is not a large germline event -- it is simply a low mappable PAR-like region that borrows reads from chrY. Here's how the X coverage distribution looks like on an XY sample after mappability filtering (which removes most of all approximate homologies):; ![chrx](https://user-images.githubusercontent.com/15305869/37867778-54e3d196-2f73-11e8-8345-d8964b39a17e.png). **The second spurious peak is gone and range of NB-like behavior is pretty much perfect. Without mappability filtering, all of the bins on the second mode _will_ show up as CN = 2 events (in fact, if you look at gCNV calls on a typical XY samples, there are tons of CN = 2 calls).**. Most, if not all, of the non-NB-like coverage before/after the main peak in your plots are reads from unmappable regions, many of which show up as real CNV events if we do not filter them (reads in these regions do not follow from the coverage model and we are at the mercy of BWA). I strongly believe Genome STRiP has achieved ~ 99% experimental validation accuracy because of aggressive filtering, not because of a superior model (it's an elementary Gaussian mixture mix). Garbage in, garbage out. Anyhow, I am not comfortable at all with cutting a non-Beta release without taking care of about:. 1. Mappability-based bin/read filtering (for WGS), and; 2. Trying out and evaluating a bait-based coverage collection (for WES), so that the raw coverage distribution is more NB-like to begin with. These are both perfectly achievable goals before May 15. I'd be happy to leave stuff such as different coverage collection strategies (e.g. base call coverage) and fragment-based per-sample GC content estimation for later. These are other areas where significant improvements come from. For the record -- I am working full steam on evaluations, as we discussed.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4558#issuecomment-375917669
https://github.com/broadinstitute/gatk/issues/4558#issuecomment-375917669:1391,Security,validat,validation,1391,"dian count is significantly away from the main peak (due to the abundance of low mappability bins with small counts). . Also, the second peak of chrX coverage in XY samples that you show above is not a large germline event -- it is simply a low mappable PAR-like region that borrows reads from chrY. Here's how the X coverage distribution looks like on an XY sample after mappability filtering (which removes most of all approximate homologies):; ![chrx](https://user-images.githubusercontent.com/15305869/37867778-54e3d196-2f73-11e8-8345-d8964b39a17e.png). **The second spurious peak is gone and range of NB-like behavior is pretty much perfect. Without mappability filtering, all of the bins on the second mode _will_ show up as CN = 2 events (in fact, if you look at gCNV calls on a typical XY samples, there are tons of CN = 2 calls).**. Most, if not all, of the non-NB-like coverage before/after the main peak in your plots are reads from unmappable regions, many of which show up as real CNV events if we do not filter them (reads in these regions do not follow from the coverage model and we are at the mercy of BWA). I strongly believe Genome STRiP has achieved ~ 99% experimental validation accuracy because of aggressive filtering, not because of a superior model (it's an elementary Gaussian mixture mix). Garbage in, garbage out. Anyhow, I am not comfortable at all with cutting a non-Beta release without taking care of about:. 1. Mappability-based bin/read filtering (for WGS), and; 2. Trying out and evaluating a bait-based coverage collection (for WES), so that the raw coverage distribution is more NB-like to begin with. These are both perfectly achievable goals before May 15. I'd be happy to leave stuff such as different coverage collection strategies (e.g. base call coverage) and fragment-based per-sample GC content estimation for later. These are other areas where significant improvements come from. For the record -- I am working full steam on evaluations, as we discussed.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4558#issuecomment-375917669
https://github.com/broadinstitute/gatk/issues/4558#issuecomment-375917669:434,Usability,simpl,simply,434,"Thanks for sharing your analysis. What is your criterion for choosing the main peak? I have seen quite a few WGS samples, which before mappability filtering, have their coverage peak at 0, and/or the median count is significantly away from the main peak (due to the abundance of low mappability bins with small counts). . Also, the second peak of chrX coverage in XY samples that you show above is not a large germline event -- it is simply a low mappable PAR-like region that borrows reads from chrY. Here's how the X coverage distribution looks like on an XY sample after mappability filtering (which removes most of all approximate homologies):; ![chrx](https://user-images.githubusercontent.com/15305869/37867778-54e3d196-2f73-11e8-8345-d8964b39a17e.png). **The second spurious peak is gone and range of NB-like behavior is pretty much perfect. Without mappability filtering, all of the bins on the second mode _will_ show up as CN = 2 events (in fact, if you look at gCNV calls on a typical XY samples, there are tons of CN = 2 calls).**. Most, if not all, of the non-NB-like coverage before/after the main peak in your plots are reads from unmappable regions, many of which show up as real CNV events if we do not filter them (reads in these regions do not follow from the coverage model and we are at the mercy of BWA). I strongly believe Genome STRiP has achieved ~ 99% experimental validation accuracy because of aggressive filtering, not because of a superior model (it's an elementary Gaussian mixture mix). Garbage in, garbage out. Anyhow, I am not comfortable at all with cutting a non-Beta release without taking care of about:. 1. Mappability-based bin/read filtering (for WGS), and; 2. Trying out and evaluating a bait-based coverage collection (for WES), so that the raw coverage distribution is more NB-like to begin with. These are both perfectly achievable goals before May 15. I'd be happy to leave stuff such as different coverage collection strategies (e.g. base call coverage) ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4558#issuecomment-375917669
https://github.com/broadinstitute/gatk/issues/4558#issuecomment-375919317:147,Availability,robust,robustness,147,"Just to clarify -- your proposed approach is certainly useful for filtering large germline events, etc, and must be part of the solution (for more robustness). What I'm saying here is that some elementary filtering gives us great mileage, both in terms of our ease of mind in determining the hard-filtering region in the ploidy tool, and for reducing false calls.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4558#issuecomment-375919317
https://github.com/broadinstitute/gatk/issues/4558#issuecomment-375923639:2352,Deployability,release,release,2352,"just to clarify, the weird mosaic examples are the bottom two plots out of the four above---you can see the shifted (non-X, in one of the examples) single peaks. However, it's interesting that the PARs are still showing up in XY---I'm pretty sure I used the blacklist you provided, although I will double check. Did that only include the ""official"" PARs, or also the additional ones you found?. In any case, are we comfortable calling in those regions (here I'm talking about gCNV, not ploidy)? As I show above, I don't think we need mappability to nail the baseline ploidy. Can we then rely on the per-bin bias to account for these regions in gCNV (pinning them back to the correct CN) without mappability filtering? And with mappability filtering, how substantial is the hit to coverage in these regions? Should we blacklist them for the time being?. To summarize, I think the order of events I'd like to see is this:. 1. Cut an **initial Beta** release that incorporates CollectReadCounts, streamline evaluations for the AACR poster, do a bit of tuning, establish a baseline. Hopefully the current ploidy calls suffice, if not, maybe issue a quick PR that implements the naive bin filtering (or whatever is necessary to get good ploidy calls). At the same time, get preliminary feedback from some users running on *small test cohorts* after we have some parameter recommendations.; 2. Do a round of method/model improvement. Start with quick and dirty fixes (e.g., blacklisting PARs) and work our way to more non-trivial changes. This will include many of the suggestions you have brought up, but we should also review user feedback and prioritize accordingly---they may find something that is not even on our radar. Demonstrate improvement (hopefully substantial!) over baseline, cut **second Beta** release.; 3. Run on larger cohorts, iron out remaining minor issues, and then productionize. By this time, @asmirnov239 will have hopefully made some progress on the PoN clustering front as well. *",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4558#issuecomment-375923639
https://github.com/broadinstitute/gatk/issues/4558#issuecomment-375923639:3208,Deployability,release,release,3208,"t gCNV, not ploidy)? As I show above, I don't think we need mappability to nail the baseline ploidy. Can we then rely on the per-bin bias to account for these regions in gCNV (pinning them back to the correct CN) without mappability filtering? And with mappability filtering, how substantial is the hit to coverage in these regions? Should we blacklist them for the time being?. To summarize, I think the order of events I'd like to see is this:. 1. Cut an **initial Beta** release that incorporates CollectReadCounts, streamline evaluations for the AACR poster, do a bit of tuning, establish a baseline. Hopefully the current ploidy calls suffice, if not, maybe issue a quick PR that implements the naive bin filtering (or whatever is necessary to get good ploidy calls). At the same time, get preliminary feedback from some users running on *small test cohorts* after we have some parameter recommendations.; 2. Do a round of method/model improvement. Start with quick and dirty fixes (e.g., blacklisting PARs) and work our way to more non-trivial changes. This will include many of the suggestions you have brought up, but we should also review user feedback and prioritize accordingly---they may find something that is not even on our radar. Demonstrate improvement (hopefully substantial!) over baseline, cut **second Beta** release.; 3. Run on larger cohorts, iron out remaining minor issues, and then productionize. By this time, @asmirnov239 will have hopefully made some progress on the PoN clustering front as well. **When we are ready, then we will take gCNV out of Beta.** With our current staffing situation, I do not expect this to happen before May 15, but I do enjoy pleasant surprises. :); 4. Run on gnomAD, world domination, etc. Again, getting a **initial Beta** release and some reasonable parameters to users is a high priority, so thanks for kicking off the evaluations, and thanks for your willingness to discuss our options. Let me know if you agree with the rest of the plan!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4558#issuecomment-375923639
https://github.com/broadinstitute/gatk/issues/4558#issuecomment-375923639:3660,Deployability,release,release,3660,"t gCNV, not ploidy)? As I show above, I don't think we need mappability to nail the baseline ploidy. Can we then rely on the per-bin bias to account for these regions in gCNV (pinning them back to the correct CN) without mappability filtering? And with mappability filtering, how substantial is the hit to coverage in these regions? Should we blacklist them for the time being?. To summarize, I think the order of events I'd like to see is this:. 1. Cut an **initial Beta** release that incorporates CollectReadCounts, streamline evaluations for the AACR poster, do a bit of tuning, establish a baseline. Hopefully the current ploidy calls suffice, if not, maybe issue a quick PR that implements the naive bin filtering (or whatever is necessary to get good ploidy calls). At the same time, get preliminary feedback from some users running on *small test cohorts* after we have some parameter recommendations.; 2. Do a round of method/model improvement. Start with quick and dirty fixes (e.g., blacklisting PARs) and work our way to more non-trivial changes. This will include many of the suggestions you have brought up, but we should also review user feedback and prioritize accordingly---they may find something that is not even on our radar. Demonstrate improvement (hopefully substantial!) over baseline, cut **second Beta** release.; 3. Run on larger cohorts, iron out remaining minor issues, and then productionize. By this time, @asmirnov239 will have hopefully made some progress on the PoN clustering front as well. **When we are ready, then we will take gCNV out of Beta.** With our current staffing situation, I do not expect this to happen before May 15, but I do enjoy pleasant surprises. :); 4. Run on gnomAD, world domination, etc. Again, getting a **initial Beta** release and some reasonable parameters to users is a high priority, so thanks for kicking off the evaluations, and thanks for your willingness to discuss our options. Let me know if you agree with the rest of the plan!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4558#issuecomment-375923639
https://github.com/broadinstitute/gatk/issues/4558#issuecomment-375923639:1327,Safety,avoid,avoid,1327," can hopefully rely on per-bin bias modeling to at least partially account for mappability in gCNV calling (and we certainly wouldn't want to filter out a significant fraction of the genome, in any case). Do we agree?. To answer your first question, the criterion for choosing the peak is quite hacky at the moment, but I found that filtering low-count bins to first check for the presence of a high peak and then falling back to the peak at zero works perfectly fine in practice. . We can certainly try to do something smarter, since, as you say, bin filtering may be desirable---even if we implement mappability filtering---to remove large germline events (it's true that the ""example"" I showed above is indeed from the PAR-like region on X, as you point out, but this is roughly how a large arm-level event would appear even after mappability filtering.) Although the model I fit above, which is simply a sparse mixture of NBs with regularly-spaced means (modulo some sample-specific and contig-specific jitter), could conceivably capture such events as well, we want to avoid models where a single NB might try to capture two or more peaks. Also, just to clarify, the weird mosaic examples are the bottom two plots out of the four above---you can see the shifted (non-X, in one of the examples) single peaks. However, it's interesting that the PARs are still showing up in XY---I'm pretty sure I used the blacklist you provided, although I will double check. Did that only include the ""official"" PARs, or also the additional ones you found?. In any case, are we comfortable calling in those regions (here I'm talking about gCNV, not ploidy)? As I show above, I don't think we need mappability to nail the baseline ploidy. Can we then rely on the per-bin bias to account for these regions in gCNV (pinning them back to the correct CN) without mappability filtering? And with mappability filtering, how substantial is the hit to coverage in these regions? Should we blacklist them for the time bein",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4558#issuecomment-375923639
https://github.com/broadinstitute/gatk/issues/4558#issuecomment-375923639:2728,Testability,test,test,2728,"d that only include the ""official"" PARs, or also the additional ones you found?. In any case, are we comfortable calling in those regions (here I'm talking about gCNV, not ploidy)? As I show above, I don't think we need mappability to nail the baseline ploidy. Can we then rely on the per-bin bias to account for these regions in gCNV (pinning them back to the correct CN) without mappability filtering? And with mappability filtering, how substantial is the hit to coverage in these regions? Should we blacklist them for the time being?. To summarize, I think the order of events I'd like to see is this:. 1. Cut an **initial Beta** release that incorporates CollectReadCounts, streamline evaluations for the AACR poster, do a bit of tuning, establish a baseline. Hopefully the current ploidy calls suffice, if not, maybe issue a quick PR that implements the naive bin filtering (or whatever is necessary to get good ploidy calls). At the same time, get preliminary feedback from some users running on *small test cohorts* after we have some parameter recommendations.; 2. Do a round of method/model improvement. Start with quick and dirty fixes (e.g., blacklisting PARs) and work our way to more non-trivial changes. This will include many of the suggestions you have brought up, but we should also review user feedback and prioritize accordingly---they may find something that is not even on our radar. Demonstrate improvement (hopefully substantial!) over baseline, cut **second Beta** release.; 3. Run on larger cohorts, iron out remaining minor issues, and then productionize. By this time, @asmirnov239 will have hopefully made some progress on the PoN clustering front as well. **When we are ready, then we will take gCNV out of Beta.** With our current staffing situation, I do not expect this to happen before May 15, but I do enjoy pleasant surprises. :); 4. Run on gnomAD, world domination, etc. Again, getting a **initial Beta** release and some reasonable parameters to users is a high p",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4558#issuecomment-375923639
https://github.com/broadinstitute/gatk/issues/4558#issuecomment-375923639:1152,Usability,simpl,simply,1152," can hopefully rely on per-bin bias modeling to at least partially account for mappability in gCNV calling (and we certainly wouldn't want to filter out a significant fraction of the genome, in any case). Do we agree?. To answer your first question, the criterion for choosing the peak is quite hacky at the moment, but I found that filtering low-count bins to first check for the presence of a high peak and then falling back to the peak at zero works perfectly fine in practice. . We can certainly try to do something smarter, since, as you say, bin filtering may be desirable---even if we implement mappability filtering---to remove large germline events (it's true that the ""example"" I showed above is indeed from the PAR-like region on X, as you point out, but this is roughly how a large arm-level event would appear even after mappability filtering.) Although the model I fit above, which is simply a sparse mixture of NBs with regularly-spaced means (modulo some sample-specific and contig-specific jitter), could conceivably capture such events as well, we want to avoid models where a single NB might try to capture two or more peaks. Also, just to clarify, the weird mosaic examples are the bottom two plots out of the four above---you can see the shifted (non-X, in one of the examples) single peaks. However, it's interesting that the PARs are still showing up in XY---I'm pretty sure I used the blacklist you provided, although I will double check. Did that only include the ""official"" PARs, or also the additional ones you found?. In any case, are we comfortable calling in those regions (here I'm talking about gCNV, not ploidy)? As I show above, I don't think we need mappability to nail the baseline ploidy. Can we then rely on the per-bin bias to account for these regions in gCNV (pinning them back to the correct CN) without mappability filtering? And with mappability filtering, how substantial is the hit to coverage in these regions? Should we blacklist them for the time bein",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4558#issuecomment-375923639
https://github.com/broadinstitute/gatk/issues/4558#issuecomment-375923639:2685,Usability,feedback,feedback,2685,"d that only include the ""official"" PARs, or also the additional ones you found?. In any case, are we comfortable calling in those regions (here I'm talking about gCNV, not ploidy)? As I show above, I don't think we need mappability to nail the baseline ploidy. Can we then rely on the per-bin bias to account for these regions in gCNV (pinning them back to the correct CN) without mappability filtering? And with mappability filtering, how substantial is the hit to coverage in these regions? Should we blacklist them for the time being?. To summarize, I think the order of events I'd like to see is this:. 1. Cut an **initial Beta** release that incorporates CollectReadCounts, streamline evaluations for the AACR poster, do a bit of tuning, establish a baseline. Hopefully the current ploidy calls suffice, if not, maybe issue a quick PR that implements the naive bin filtering (or whatever is necessary to get good ploidy calls). At the same time, get preliminary feedback from some users running on *small test cohorts* after we have some parameter recommendations.; 2. Do a round of method/model improvement. Start with quick and dirty fixes (e.g., blacklisting PARs) and work our way to more non-trivial changes. This will include many of the suggestions you have brought up, but we should also review user feedback and prioritize accordingly---they may find something that is not even on our radar. Demonstrate improvement (hopefully substantial!) over baseline, cut **second Beta** release.; 3. Run on larger cohorts, iron out remaining minor issues, and then productionize. By this time, @asmirnov239 will have hopefully made some progress on the PoN clustering front as well. **When we are ready, then we will take gCNV out of Beta.** With our current staffing situation, I do not expect this to happen before May 15, but I do enjoy pleasant surprises. :); 4. Run on gnomAD, world domination, etc. Again, getting a **initial Beta** release and some reasonable parameters to users is a high p",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4558#issuecomment-375923639
https://github.com/broadinstitute/gatk/issues/4558#issuecomment-375923639:3031,Usability,feedback,feedback,3031,"t gCNV, not ploidy)? As I show above, I don't think we need mappability to nail the baseline ploidy. Can we then rely on the per-bin bias to account for these regions in gCNV (pinning them back to the correct CN) without mappability filtering? And with mappability filtering, how substantial is the hit to coverage in these regions? Should we blacklist them for the time being?. To summarize, I think the order of events I'd like to see is this:. 1. Cut an **initial Beta** release that incorporates CollectReadCounts, streamline evaluations for the AACR poster, do a bit of tuning, establish a baseline. Hopefully the current ploidy calls suffice, if not, maybe issue a quick PR that implements the naive bin filtering (or whatever is necessary to get good ploidy calls). At the same time, get preliminary feedback from some users running on *small test cohorts* after we have some parameter recommendations.; 2. Do a round of method/model improvement. Start with quick and dirty fixes (e.g., blacklisting PARs) and work our way to more non-trivial changes. This will include many of the suggestions you have brought up, but we should also review user feedback and prioritize accordingly---they may find something that is not even on our radar. Demonstrate improvement (hopefully substantial!) over baseline, cut **second Beta** release.; 3. Run on larger cohorts, iron out remaining minor issues, and then productionize. By this time, @asmirnov239 will have hopefully made some progress on the PoN clustering front as well. **When we are ready, then we will take gCNV out of Beta.** With our current staffing situation, I do not expect this to happen before May 15, but I do enjoy pleasant surprises. :); 4. Run on gnomAD, world domination, etc. Again, getting a **initial Beta** release and some reasonable parameters to users is a high priority, so thanks for kicking off the evaluations, and thanks for your willingness to discuss our options. Let me know if you agree with the rest of the plan!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4558#issuecomment-375923639
https://github.com/broadinstitute/gatk/issues/4559#issuecomment-375647411:189,Deployability,release,release,189,"Hi @aderzelle. Thanks for your interest in NeuralNetInference. The tool currently has pre-beta`Experimental` status, so for now it should be used for evaluation purposes only. We expect to release another version of GATK, probably within the next week, that will include an updated version of the tool that will include a default architecture file, along with some additional tools for things like training. The tools will still be `Experimental`, but should be a bit easier to use. In the meantime, there is a bit more information about how to access the existing hd5 file [here](https://github.com/broadinstitute/gatk/issues/4511). Note that in the next release, the name of the tool will have changed to CNNScoreVariants. @lucidtronix anything else to add here?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4559#issuecomment-375647411
https://github.com/broadinstitute/gatk/issues/4559#issuecomment-375647411:274,Deployability,update,updated,274,"Hi @aderzelle. Thanks for your interest in NeuralNetInference. The tool currently has pre-beta`Experimental` status, so for now it should be used for evaluation purposes only. We expect to release another version of GATK, probably within the next week, that will include an updated version of the tool that will include a default architecture file, along with some additional tools for things like training. The tools will still be `Experimental`, but should be a bit easier to use. In the meantime, there is a bit more information about how to access the existing hd5 file [here](https://github.com/broadinstitute/gatk/issues/4511). Note that in the next release, the name of the tool will have changed to CNNScoreVariants. @lucidtronix anything else to add here?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4559#issuecomment-375647411
https://github.com/broadinstitute/gatk/issues/4559#issuecomment-375647411:656,Deployability,release,release,656,"Hi @aderzelle. Thanks for your interest in NeuralNetInference. The tool currently has pre-beta`Experimental` status, so for now it should be used for evaluation purposes only. We expect to release another version of GATK, probably within the next week, that will include an updated version of the tool that will include a default architecture file, along with some additional tools for things like training. The tools will still be `Experimental`, but should be a bit easier to use. In the meantime, there is a bit more information about how to access the existing hd5 file [here](https://github.com/broadinstitute/gatk/issues/4511). Note that in the next release, the name of the tool will have changed to CNNScoreVariants. @lucidtronix anything else to add here?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4559#issuecomment-375647411
https://github.com/broadinstitute/gatk/issues/4559#issuecomment-375647411:545,Security,access,access,545,"Hi @aderzelle. Thanks for your interest in NeuralNetInference. The tool currently has pre-beta`Experimental` status, so for now it should be used for evaluation purposes only. We expect to release another version of GATK, probably within the next week, that will include an updated version of the tool that will include a default architecture file, along with some additional tools for things like training. The tools will still be `Experimental`, but should be a bit easier to use. In the meantime, there is a bit more information about how to access the existing hd5 file [here](https://github.com/broadinstitute/gatk/issues/4511). Note that in the next release, the name of the tool will have changed to CNNScoreVariants. @lucidtronix anything else to add here?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4559#issuecomment-375647411
https://github.com/broadinstitute/gatk/pull/4562#issuecomment-376937414:113,Testability,test,test,113,"@SHuang-Broad The `testSAMWriter_chr20.bam` bam that you added here should probably have gone into git lfs (`src/test/resources/large`), rather than directly into the repo. It's too late to fix (once it's in master, it's in the git history forever), but in the future please try to store test data bigger than ~1-2 MB or so in lfs.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4562#issuecomment-376937414
https://github.com/broadinstitute/gatk/pull/4562#issuecomment-376937414:288,Testability,test,test,288,"@SHuang-Broad The `testSAMWriter_chr20.bam` bam that you added here should probably have gone into git lfs (`src/test/resources/large`), rather than directly into the repo. It's too late to fix (once it's in master, it's in the git history forever), but in the future please try to store test data bigger than ~1-2 MB or so in lfs.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4562#issuecomment-376937414
https://github.com/broadinstitute/gatk/pull/4563#issuecomment-375688881:969,Testability,test,test,969,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4563?src=pr&el=h1) Report; > Merging [#4563](https://codecov.io/gh/broadinstitute/gatk/pull/4563?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/3806e15c5626e6bc5379b2b1dad705617057a7fd?src=pr&el=desc) will **increase** coverage by `0.075%`.; > The diff coverage is `43.802%`. ```diff; @@ Coverage Diff @@; ## master #4563 +/- ##; ===============================================; + Coverage 79.857% 79.932% +0.075% ; - Complexity 17054 17347 +293 ; ===============================================; Files 1067 1067 ; Lines 62031 63140 +1109 ; Branches 10039 10311 +272 ; ===============================================; + Hits 49536 50469 +933 ; - Misses 8582 8696 +114 ; - Partials 3913 3975 +62; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4563?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...broadinstitute/hellbender/utils/test/BaseTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/4563/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Jhc2VUZXN0LmphdmE=) | `64.444% <0%> (-0.481%)` | `33 <0> (ø)` | |; | [...r/dataSources/cosmic/CosmicFuncotationFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/4563/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL2Nvc21pYy9Db3NtaWNGdW5jb3RhdGlvbkZhY3RvcnkuamF2YQ==) | `76.238% <0%> (-4.815%)` | `21 <0> (ø)` | |; | [...ncotator/mafOutput/MafOutputRendererConstants.java](https://codecov.io/gh/broadinstitute/gatk/pull/4563/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL21hZk91dHB1dC9NYWZPdXRwdXRSZW5kZXJlckNvbnN0YW50cy5qYXZh) | `98.98% <100%> (ø)` | `1 <0> (ø)` | :arrow_down: |; | [...tools/funcotator/DataSourceFuncotationFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/4563/diff?src=pr&el=tree#diff-,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4563#issuecomment-375688881
https://github.com/broadinstitute/gatk/pull/4563#issuecomment-375688881:3491,Usability,Simpl,SimpleKeyXsvFuncotationFactory,3491,adinstitute/gatk/pull/4563/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL0Z1bmNvdGF0b3IuamF2YQ==) | `76.351% <100%> (ø)` | `30 <2> (ø)` | :arrow_down: |; | [.../tools/funcotator/dataSources/DataSourceUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/4563/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL0RhdGFTb3VyY2VVdGlscy5qYXZh) | `56.432% <29.73%> (-11.616%)` | `33 <7> (+7)` | |; | [...cotator/dataSources/vcf/VcfFuncotationFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/4563/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL3ZjZi9WY2ZGdW5jb3RhdGlvbkZhY3RvcnkuamF2YQ==) | `85.333% <58.333%> (-4.219%)` | `23 <2> (+1)` | |; | [...dataSources/gencode/GencodeFuncotationFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/4563/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL2dlbmNvZGUvR2VuY29kZUZ1bmNvdGF0aW9uRmFjdG9yeS5qYXZh) | `81.997% <75%> (+1.209%)` | `146 <1> (+4)` | :arrow_up: |; | [...ataSources/xsv/SimpleKeyXsvFuncotationFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/4563/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL3hzdi9TaW1wbGVLZXlYc3ZGdW5jb3RhdGlvbkZhY3RvcnkuamF2YQ==) | `87.097% <77.778%> (-0.403%)` | `27 <2> (+1)` | |; | [...ataSources/xsv/LocatableXsvFuncotationFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/4563/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL3hzdi9Mb2NhdGFibGVYc3ZGdW5jb3RhdGlvbkZhY3RvcnkuamF2YQ==) | `84.694% <88.889%> (+0.823%)` | `28 <3> (+2)` | :arrow_up: |; | ... and [20 more](https://codecov.io/gh/broadinstitute/gatk/pull/4563/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4563#issuecomment-375688881
https://github.com/broadinstitute/gatk/pull/4563#issuecomment-376939652:125,Deployability,release,release,125,"@LeeTL1220 that's totally fair. There are a few problems with putting in the tests, though. I don't know that I can publicly release the data that are being tested because of their provenance (pretty sure I can't). . The second reason is that the whole reference sequences are not checked into git lfs. Without it I can't annotate on a set of variants from around the whole genome, and the whole reference is pretty big. . The last thing I can think of is a data source problem - I don't have all the data sources checked into git lfs (for similar reasons, especially now with dbSNP in there). Also, these have already made their way into master. So if this is really a problem, we should get them out of there ASAP.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4563#issuecomment-376939652
https://github.com/broadinstitute/gatk/pull/4563#issuecomment-376939652:77,Testability,test,tests,77,"@LeeTL1220 that's totally fair. There are a few problems with putting in the tests, though. I don't know that I can publicly release the data that are being tested because of their provenance (pretty sure I can't). . The second reason is that the whole reference sequences are not checked into git lfs. Without it I can't annotate on a set of variants from around the whole genome, and the whole reference is pretty big. . The last thing I can think of is a data source problem - I don't have all the data sources checked into git lfs (for similar reasons, especially now with dbSNP in there). Also, these have already made their way into master. So if this is really a problem, we should get them out of there ASAP.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4563#issuecomment-376939652
https://github.com/broadinstitute/gatk/pull/4563#issuecomment-376939652:157,Testability,test,tested,157,"@LeeTL1220 that's totally fair. There are a few problems with putting in the tests, though. I don't know that I can publicly release the data that are being tested because of their provenance (pretty sure I can't). . The second reason is that the whole reference sequences are not checked into git lfs. Without it I can't annotate on a set of variants from around the whole genome, and the whole reference is pretty big. . The last thing I can think of is a data source problem - I don't have all the data sources checked into git lfs (for similar reasons, especially now with dbSNP in there). Also, these have already made their way into master. So if this is really a problem, we should get them out of there ASAP.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4563#issuecomment-376939652
https://github.com/broadinstitute/gatk/issues/4565#issuecomment-375725088:212,Modifiability,extend,extend,212,"@magicDGS We talked with our ops people and it looks like we periodically purge anything older than 60 days, so this snapshot is gone. We're going to try to streamline what we upload, which will then allow us to extend the retention time for these things. Hopefully in the meantime you can rebuild what you need.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/4565#issuecomment-375725088
https://github.com/broadinstitute/gatk/pull/4571#issuecomment-454184426:232,Availability,error,error-reference,232,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4571?src=pr&el=h1) Report; > :exclamation: No coverage uploaded for pull request base (`master@4416fd5`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `11.765%`. ```diff; @@ Coverage Diff @@; ## master #4571 +/- ##; ==========================================; Coverage ? 17.915% ; Complexity ? 8536 ; ==========================================; Files ? 1943 ; Lines ? 146209 ; Branches ? 16146 ; ==========================================; Hits ? 26194 ; Misses ? 117360 ; Partials ? 2655; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4571?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...e/hellbender/engine/FeatureDataSourceUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/4571/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvRmVhdHVyZURhdGFTb3VyY2VVbml0VGVzdC5qYXZh) | `1.488% <0%> (ø)` | `2 <0> (?)` | |; | [...institute/hellbender/engine/FeatureDataSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4571/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvRmVhdHVyZURhdGFTb3VyY2UuamF2YQ==) | `57.246% <66.667%> (ø)` | `32 <0> (?)` | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4571#issuecomment-454184426
https://github.com/broadinstitute/gatk/pull/4571#issuecomment-454184426:180,Usability,learn,learn,180,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/4571?src=pr&el=h1) Report; > :exclamation: No coverage uploaded for pull request base (`master@4416fd5`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `11.765%`. ```diff; @@ Coverage Diff @@; ## master #4571 +/- ##; ==========================================; Coverage ? 17.915% ; Complexity ? 8536 ; ==========================================; Files ? 1943 ; Lines ? 146209 ; Branches ? 16146 ; ==========================================; Hits ? 26194 ; Misses ? 117360 ; Partials ? 2655; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/4571?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...e/hellbender/engine/FeatureDataSourceUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/4571/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvRmVhdHVyZURhdGFTb3VyY2VVbml0VGVzdC5qYXZh) | `1.488% <0%> (ø)` | `2 <0> (?)` | |; | [...institute/hellbender/engine/FeatureDataSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/4571/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvRmVhdHVyZURhdGFTb3VyY2UuamF2YQ==) | `57.246% <66.667%> (ø)` | `32 <0> (?)` | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4571#issuecomment-454184426
https://github.com/broadinstitute/gatk/pull/4571#issuecomment-455234300:44,Testability,test,tests,44,@jonn-smith Can you explain briefly why the tests are failing? It seems like this is the sort of change that our test code should just ignore.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4571#issuecomment-455234300
https://github.com/broadinstitute/gatk/pull/4571#issuecomment-455234300:113,Testability,test,test,113,@jonn-smith Can you explain briefly why the tests are failing? It seems like this is the sort of change that our test code should just ignore.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4571#issuecomment-455234300
https://github.com/broadinstitute/gatk/pull/4571#issuecomment-461579140:408,Testability,test,tests,408,"Yes. We have two methods to compare whether variant context objects are equal. I wanted to make it so that there was only 1 method that does this, so I tried to change the calls to only use one of them. However they do not actually check the same things. I am going to move the changes into another branch / PR, but I haven't yet. After doing so I'll revert so that both comparisons remain and make sure the tests pass again.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4571#issuecomment-461579140
https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565:20,Availability,failure,failures,20,Travis reported job failures from build [28408](https://travis-ci.com/broadinstitute/gatk/builds/141654561); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28408.13](https://travis-ci.com/broadinstitute/gatk/jobs/268686081) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.13/tests/test/index.html) |; | integration | oraclejdk8 | [28408.11](https://travis-ci.com/broadinstitute/gatk/jobs/268686079) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.11/tests/test/index.html) |; | integration | openjdk11 | [28408.12](https://travis-ci.com/broadinstitute/gatk/jobs/268686080) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.12/tests/test/index.html) |; | unit | openjdk8 | [28408.3](https://travis-ci.com/broadinstitute/gatk/jobs/268686071) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.3/tests/test/index.html) |; | python | openjdk8 | [28408.5](https://travis-ci.com/broadinstitute/gatk/jobs/268686073) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.5/tests/test/index.html) |; | integration | openjdk8 | [28408.2](https://travis-ci.com/broadinstitute/gatk/jobs/268686070) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565
https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565:109,Availability,Failure,Failures,109,Travis reported job failures from build [28408](https://travis-ci.com/broadinstitute/gatk/builds/141654561); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28408.13](https://travis-ci.com/broadinstitute/gatk/jobs/268686081) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.13/tests/test/index.html) |; | integration | oraclejdk8 | [28408.11](https://travis-ci.com/broadinstitute/gatk/jobs/268686079) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.11/tests/test/index.html) |; | integration | openjdk11 | [28408.12](https://travis-ci.com/broadinstitute/gatk/jobs/268686080) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.12/tests/test/index.html) |; | unit | openjdk8 | [28408.3](https://travis-ci.com/broadinstitute/gatk/jobs/268686071) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.3/tests/test/index.html) |; | python | openjdk8 | [28408.5](https://travis-ci.com/broadinstitute/gatk/jobs/268686073) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.5/tests/test/index.html) |; | integration | openjdk8 | [28408.2](https://travis-ci.com/broadinstitute/gatk/jobs/268686070) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565
https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565:425,Deployability,integrat,integration,425,Travis reported job failures from build [28408](https://travis-ci.com/broadinstitute/gatk/builds/141654561); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28408.13](https://travis-ci.com/broadinstitute/gatk/jobs/268686081) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.13/tests/test/index.html) |; | integration | oraclejdk8 | [28408.11](https://travis-ci.com/broadinstitute/gatk/jobs/268686079) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.11/tests/test/index.html) |; | integration | openjdk11 | [28408.12](https://travis-ci.com/broadinstitute/gatk/jobs/268686080) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.12/tests/test/index.html) |; | unit | openjdk8 | [28408.3](https://travis-ci.com/broadinstitute/gatk/jobs/268686071) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.3/tests/test/index.html) |; | python | openjdk8 | [28408.5](https://travis-ci.com/broadinstitute/gatk/jobs/268686073) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.5/tests/test/index.html) |; | integration | openjdk8 | [28408.2](https://travis-ci.com/broadinstitute/gatk/jobs/268686070) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565
https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565:640,Deployability,integrat,integration,640,Travis reported job failures from build [28408](https://travis-ci.com/broadinstitute/gatk/builds/141654561); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28408.13](https://travis-ci.com/broadinstitute/gatk/jobs/268686081) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.13/tests/test/index.html) |; | integration | oraclejdk8 | [28408.11](https://travis-ci.com/broadinstitute/gatk/jobs/268686079) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.11/tests/test/index.html) |; | integration | openjdk11 | [28408.12](https://travis-ci.com/broadinstitute/gatk/jobs/268686080) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.12/tests/test/index.html) |; | unit | openjdk8 | [28408.3](https://travis-ci.com/broadinstitute/gatk/jobs/268686071) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.3/tests/test/index.html) |; | python | openjdk8 | [28408.5](https://travis-ci.com/broadinstitute/gatk/jobs/268686073) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.5/tests/test/index.html) |; | integration | openjdk8 | [28408.2](https://travis-ci.com/broadinstitute/gatk/jobs/268686070) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565
https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565:1264,Deployability,integrat,integration,1264,Travis reported job failures from build [28408](https://travis-ci.com/broadinstitute/gatk/builds/141654561); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28408.13](https://travis-ci.com/broadinstitute/gatk/jobs/268686081) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.13/tests/test/index.html) |; | integration | oraclejdk8 | [28408.11](https://travis-ci.com/broadinstitute/gatk/jobs/268686079) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.11/tests/test/index.html) |; | integration | openjdk11 | [28408.12](https://travis-ci.com/broadinstitute/gatk/jobs/268686080) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.12/tests/test/index.html) |; | unit | openjdk8 | [28408.3](https://travis-ci.com/broadinstitute/gatk/jobs/268686071) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.3/tests/test/index.html) |; | python | openjdk8 | [28408.5](https://travis-ci.com/broadinstitute/gatk/jobs/268686073) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.5/tests/test/index.html) |; | integration | openjdk8 | [28408.2](https://travis-ci.com/broadinstitute/gatk/jobs/268686070) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565
https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565:425,Integrability,integrat,integration,425,Travis reported job failures from build [28408](https://travis-ci.com/broadinstitute/gatk/builds/141654561); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28408.13](https://travis-ci.com/broadinstitute/gatk/jobs/268686081) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.13/tests/test/index.html) |; | integration | oraclejdk8 | [28408.11](https://travis-ci.com/broadinstitute/gatk/jobs/268686079) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.11/tests/test/index.html) |; | integration | openjdk11 | [28408.12](https://travis-ci.com/broadinstitute/gatk/jobs/268686080) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.12/tests/test/index.html) |; | unit | openjdk8 | [28408.3](https://travis-ci.com/broadinstitute/gatk/jobs/268686071) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.3/tests/test/index.html) |; | python | openjdk8 | [28408.5](https://travis-ci.com/broadinstitute/gatk/jobs/268686073) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.5/tests/test/index.html) |; | integration | openjdk8 | [28408.2](https://travis-ci.com/broadinstitute/gatk/jobs/268686070) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565
https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565:640,Integrability,integrat,integration,640,Travis reported job failures from build [28408](https://travis-ci.com/broadinstitute/gatk/builds/141654561); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28408.13](https://travis-ci.com/broadinstitute/gatk/jobs/268686081) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.13/tests/test/index.html) |; | integration | oraclejdk8 | [28408.11](https://travis-ci.com/broadinstitute/gatk/jobs/268686079) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.11/tests/test/index.html) |; | integration | openjdk11 | [28408.12](https://travis-ci.com/broadinstitute/gatk/jobs/268686080) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.12/tests/test/index.html) |; | unit | openjdk8 | [28408.3](https://travis-ci.com/broadinstitute/gatk/jobs/268686071) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.3/tests/test/index.html) |; | python | openjdk8 | [28408.5](https://travis-ci.com/broadinstitute/gatk/jobs/268686073) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.5/tests/test/index.html) |; | integration | openjdk8 | [28408.2](https://travis-ci.com/broadinstitute/gatk/jobs/268686070) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565
https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565:1264,Integrability,integrat,integration,1264,Travis reported job failures from build [28408](https://travis-ci.com/broadinstitute/gatk/builds/141654561); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28408.13](https://travis-ci.com/broadinstitute/gatk/jobs/268686081) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.13/tests/test/index.html) |; | integration | oraclejdk8 | [28408.11](https://travis-ci.com/broadinstitute/gatk/jobs/268686079) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.11/tests/test/index.html) |; | integration | openjdk11 | [28408.12](https://travis-ci.com/broadinstitute/gatk/jobs/268686080) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.12/tests/test/index.html) |; | unit | openjdk8 | [28408.3](https://travis-ci.com/broadinstitute/gatk/jobs/268686071) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.3/tests/test/index.html) |; | python | openjdk8 | [28408.5](https://travis-ci.com/broadinstitute/gatk/jobs/268686073) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.5/tests/test/index.html) |; | integration | openjdk8 | [28408.2](https://travis-ci.com/broadinstitute/gatk/jobs/268686070) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565
https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565:144,Testability,Test,Test,144,Travis reported job failures from build [28408](https://travis-ci.com/broadinstitute/gatk/builds/141654561); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28408.13](https://travis-ci.com/broadinstitute/gatk/jobs/268686081) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.13/tests/test/index.html) |; | integration | oraclejdk8 | [28408.11](https://travis-ci.com/broadinstitute/gatk/jobs/268686079) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.11/tests/test/index.html) |; | integration | openjdk11 | [28408.12](https://travis-ci.com/broadinstitute/gatk/jobs/268686080) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.12/tests/test/index.html) |; | unit | openjdk8 | [28408.3](https://travis-ci.com/broadinstitute/gatk/jobs/268686071) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.3/tests/test/index.html) |; | python | openjdk8 | [28408.5](https://travis-ci.com/broadinstitute/gatk/jobs/268686073) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.5/tests/test/index.html) |; | integration | openjdk8 | [28408.2](https://travis-ci.com/broadinstitute/gatk/jobs/268686070) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565
https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565:171,Testability,Log,Logs,171,Travis reported job failures from build [28408](https://travis-ci.com/broadinstitute/gatk/builds/141654561); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28408.13](https://travis-ci.com/broadinstitute/gatk/jobs/268686081) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.13/tests/test/index.html) |; | integration | oraclejdk8 | [28408.11](https://travis-ci.com/broadinstitute/gatk/jobs/268686079) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.11/tests/test/index.html) |; | integration | openjdk11 | [28408.12](https://travis-ci.com/broadinstitute/gatk/jobs/268686080) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.12/tests/test/index.html) |; | unit | openjdk8 | [28408.3](https://travis-ci.com/broadinstitute/gatk/jobs/268686071) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.3/tests/test/index.html) |; | python | openjdk8 | [28408.5](https://travis-ci.com/broadinstitute/gatk/jobs/268686073) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.5/tests/test/index.html) |; | integration | openjdk8 | [28408.2](https://travis-ci.com/broadinstitute/gatk/jobs/268686070) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565
https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565:309,Testability,log,logs,309,Travis reported job failures from build [28408](https://travis-ci.com/broadinstitute/gatk/builds/141654561); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28408.13](https://travis-ci.com/broadinstitute/gatk/jobs/268686081) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.13/tests/test/index.html) |; | integration | oraclejdk8 | [28408.11](https://travis-ci.com/broadinstitute/gatk/jobs/268686079) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.11/tests/test/index.html) |; | integration | openjdk11 | [28408.12](https://travis-ci.com/broadinstitute/gatk/jobs/268686080) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.12/tests/test/index.html) |; | unit | openjdk8 | [28408.3](https://travis-ci.com/broadinstitute/gatk/jobs/268686071) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.3/tests/test/index.html) |; | python | openjdk8 | [28408.5](https://travis-ci.com/broadinstitute/gatk/jobs/268686073) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.5/tests/test/index.html) |; | integration | openjdk8 | [28408.2](https://travis-ci.com/broadinstitute/gatk/jobs/268686070) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565
https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565:357,Testability,test,test-logs,357,Travis reported job failures from build [28408](https://travis-ci.com/broadinstitute/gatk/builds/141654561); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28408.13](https://travis-ci.com/broadinstitute/gatk/jobs/268686081) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.13/tests/test/index.html) |; | integration | oraclejdk8 | [28408.11](https://travis-ci.com/broadinstitute/gatk/jobs/268686079) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.11/tests/test/index.html) |; | integration | openjdk11 | [28408.12](https://travis-ci.com/broadinstitute/gatk/jobs/268686080) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.12/tests/test/index.html) |; | unit | openjdk8 | [28408.3](https://travis-ci.com/broadinstitute/gatk/jobs/268686071) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.3/tests/test/index.html) |; | python | openjdk8 | [28408.5](https://travis-ci.com/broadinstitute/gatk/jobs/268686073) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.5/tests/test/index.html) |; | integration | openjdk8 | [28408.2](https://travis-ci.com/broadinstitute/gatk/jobs/268686070) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565
https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565:397,Testability,test,tests,397,Travis reported job failures from build [28408](https://travis-ci.com/broadinstitute/gatk/builds/141654561); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28408.13](https://travis-ci.com/broadinstitute/gatk/jobs/268686081) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.13/tests/test/index.html) |; | integration | oraclejdk8 | [28408.11](https://travis-ci.com/broadinstitute/gatk/jobs/268686079) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.11/tests/test/index.html) |; | integration | openjdk11 | [28408.12](https://travis-ci.com/broadinstitute/gatk/jobs/268686080) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.12/tests/test/index.html) |; | unit | openjdk8 | [28408.3](https://travis-ci.com/broadinstitute/gatk/jobs/268686071) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.3/tests/test/index.html) |; | python | openjdk8 | [28408.5](https://travis-ci.com/broadinstitute/gatk/jobs/268686073) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.5/tests/test/index.html) |; | integration | openjdk8 | [28408.2](https://travis-ci.com/broadinstitute/gatk/jobs/268686070) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565
https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565:403,Testability,test,test,403,Travis reported job failures from build [28408](https://travis-ci.com/broadinstitute/gatk/builds/141654561); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28408.13](https://travis-ci.com/broadinstitute/gatk/jobs/268686081) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.13/tests/test/index.html) |; | integration | oraclejdk8 | [28408.11](https://travis-ci.com/broadinstitute/gatk/jobs/268686079) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.11/tests/test/index.html) |; | integration | openjdk11 | [28408.12](https://travis-ci.com/broadinstitute/gatk/jobs/268686080) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.12/tests/test/index.html) |; | unit | openjdk8 | [28408.3](https://travis-ci.com/broadinstitute/gatk/jobs/268686071) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.3/tests/test/index.html) |; | python | openjdk8 | [28408.5](https://travis-ci.com/broadinstitute/gatk/jobs/268686073) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.5/tests/test/index.html) |; | integration | openjdk8 | [28408.2](https://travis-ci.com/broadinstitute/gatk/jobs/268686070) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565
https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565:524,Testability,log,logs,524,Travis reported job failures from build [28408](https://travis-ci.com/broadinstitute/gatk/builds/141654561); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28408.13](https://travis-ci.com/broadinstitute/gatk/jobs/268686081) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.13/tests/test/index.html) |; | integration | oraclejdk8 | [28408.11](https://travis-ci.com/broadinstitute/gatk/jobs/268686079) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.11/tests/test/index.html) |; | integration | openjdk11 | [28408.12](https://travis-ci.com/broadinstitute/gatk/jobs/268686080) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.12/tests/test/index.html) |; | unit | openjdk8 | [28408.3](https://travis-ci.com/broadinstitute/gatk/jobs/268686071) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.3/tests/test/index.html) |; | python | openjdk8 | [28408.5](https://travis-ci.com/broadinstitute/gatk/jobs/268686073) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.5/tests/test/index.html) |; | integration | openjdk8 | [28408.2](https://travis-ci.com/broadinstitute/gatk/jobs/268686070) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565
https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565:572,Testability,test,test-logs,572,Travis reported job failures from build [28408](https://travis-ci.com/broadinstitute/gatk/builds/141654561); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28408.13](https://travis-ci.com/broadinstitute/gatk/jobs/268686081) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.13/tests/test/index.html) |; | integration | oraclejdk8 | [28408.11](https://travis-ci.com/broadinstitute/gatk/jobs/268686079) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.11/tests/test/index.html) |; | integration | openjdk11 | [28408.12](https://travis-ci.com/broadinstitute/gatk/jobs/268686080) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.12/tests/test/index.html) |; | unit | openjdk8 | [28408.3](https://travis-ci.com/broadinstitute/gatk/jobs/268686071) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.3/tests/test/index.html) |; | python | openjdk8 | [28408.5](https://travis-ci.com/broadinstitute/gatk/jobs/268686073) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.5/tests/test/index.html) |; | integration | openjdk8 | [28408.2](https://travis-ci.com/broadinstitute/gatk/jobs/268686070) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565
https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565:612,Testability,test,tests,612,Travis reported job failures from build [28408](https://travis-ci.com/broadinstitute/gatk/builds/141654561); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28408.13](https://travis-ci.com/broadinstitute/gatk/jobs/268686081) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.13/tests/test/index.html) |; | integration | oraclejdk8 | [28408.11](https://travis-ci.com/broadinstitute/gatk/jobs/268686079) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.11/tests/test/index.html) |; | integration | openjdk11 | [28408.12](https://travis-ci.com/broadinstitute/gatk/jobs/268686080) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.12/tests/test/index.html) |; | unit | openjdk8 | [28408.3](https://travis-ci.com/broadinstitute/gatk/jobs/268686071) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.3/tests/test/index.html) |; | python | openjdk8 | [28408.5](https://travis-ci.com/broadinstitute/gatk/jobs/268686073) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.5/tests/test/index.html) |; | integration | openjdk8 | [28408.2](https://travis-ci.com/broadinstitute/gatk/jobs/268686070) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565
https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565:618,Testability,test,test,618,Travis reported job failures from build [28408](https://travis-ci.com/broadinstitute/gatk/builds/141654561); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28408.13](https://travis-ci.com/broadinstitute/gatk/jobs/268686081) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.13/tests/test/index.html) |; | integration | oraclejdk8 | [28408.11](https://travis-ci.com/broadinstitute/gatk/jobs/268686079) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.11/tests/test/index.html) |; | integration | openjdk11 | [28408.12](https://travis-ci.com/broadinstitute/gatk/jobs/268686080) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.12/tests/test/index.html) |; | unit | openjdk8 | [28408.3](https://travis-ci.com/broadinstitute/gatk/jobs/268686071) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.3/tests/test/index.html) |; | python | openjdk8 | [28408.5](https://travis-ci.com/broadinstitute/gatk/jobs/268686073) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.5/tests/test/index.html) |; | integration | openjdk8 | [28408.2](https://travis-ci.com/broadinstitute/gatk/jobs/268686070) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565
https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565:738,Testability,log,logs,738,Travis reported job failures from build [28408](https://travis-ci.com/broadinstitute/gatk/builds/141654561); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28408.13](https://travis-ci.com/broadinstitute/gatk/jobs/268686081) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.13/tests/test/index.html) |; | integration | oraclejdk8 | [28408.11](https://travis-ci.com/broadinstitute/gatk/jobs/268686079) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.11/tests/test/index.html) |; | integration | openjdk11 | [28408.12](https://travis-ci.com/broadinstitute/gatk/jobs/268686080) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.12/tests/test/index.html) |; | unit | openjdk8 | [28408.3](https://travis-ci.com/broadinstitute/gatk/jobs/268686071) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.3/tests/test/index.html) |; | python | openjdk8 | [28408.5](https://travis-ci.com/broadinstitute/gatk/jobs/268686073) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.5/tests/test/index.html) |; | integration | openjdk8 | [28408.2](https://travis-ci.com/broadinstitute/gatk/jobs/268686070) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565
https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565:786,Testability,test,test-logs,786,Travis reported job failures from build [28408](https://travis-ci.com/broadinstitute/gatk/builds/141654561); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28408.13](https://travis-ci.com/broadinstitute/gatk/jobs/268686081) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.13/tests/test/index.html) |; | integration | oraclejdk8 | [28408.11](https://travis-ci.com/broadinstitute/gatk/jobs/268686079) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.11/tests/test/index.html) |; | integration | openjdk11 | [28408.12](https://travis-ci.com/broadinstitute/gatk/jobs/268686080) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.12/tests/test/index.html) |; | unit | openjdk8 | [28408.3](https://travis-ci.com/broadinstitute/gatk/jobs/268686071) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.3/tests/test/index.html) |; | python | openjdk8 | [28408.5](https://travis-ci.com/broadinstitute/gatk/jobs/268686073) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.5/tests/test/index.html) |; | integration | openjdk8 | [28408.2](https://travis-ci.com/broadinstitute/gatk/jobs/268686070) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565
https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565:826,Testability,test,tests,826,Travis reported job failures from build [28408](https://travis-ci.com/broadinstitute/gatk/builds/141654561); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28408.13](https://travis-ci.com/broadinstitute/gatk/jobs/268686081) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.13/tests/test/index.html) |; | integration | oraclejdk8 | [28408.11](https://travis-ci.com/broadinstitute/gatk/jobs/268686079) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.11/tests/test/index.html) |; | integration | openjdk11 | [28408.12](https://travis-ci.com/broadinstitute/gatk/jobs/268686080) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.12/tests/test/index.html) |; | unit | openjdk8 | [28408.3](https://travis-ci.com/broadinstitute/gatk/jobs/268686071) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.3/tests/test/index.html) |; | python | openjdk8 | [28408.5](https://travis-ci.com/broadinstitute/gatk/jobs/268686073) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.5/tests/test/index.html) |; | integration | openjdk8 | [28408.2](https://travis-ci.com/broadinstitute/gatk/jobs/268686070) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565
https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565:832,Testability,test,test,832,Travis reported job failures from build [28408](https://travis-ci.com/broadinstitute/gatk/builds/141654561); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28408.13](https://travis-ci.com/broadinstitute/gatk/jobs/268686081) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.13/tests/test/index.html) |; | integration | oraclejdk8 | [28408.11](https://travis-ci.com/broadinstitute/gatk/jobs/268686079) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.11/tests/test/index.html) |; | integration | openjdk11 | [28408.12](https://travis-ci.com/broadinstitute/gatk/jobs/268686080) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.12/tests/test/index.html) |; | unit | openjdk8 | [28408.3](https://travis-ci.com/broadinstitute/gatk/jobs/268686071) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.3/tests/test/index.html) |; | python | openjdk8 | [28408.5](https://travis-ci.com/broadinstitute/gatk/jobs/268686073) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.5/tests/test/index.html) |; | integration | openjdk8 | [28408.2](https://travis-ci.com/broadinstitute/gatk/jobs/268686070) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565
https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565:943,Testability,log,logs,943,Travis reported job failures from build [28408](https://travis-ci.com/broadinstitute/gatk/builds/141654561); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28408.13](https://travis-ci.com/broadinstitute/gatk/jobs/268686081) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.13/tests/test/index.html) |; | integration | oraclejdk8 | [28408.11](https://travis-ci.com/broadinstitute/gatk/jobs/268686079) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.11/tests/test/index.html) |; | integration | openjdk11 | [28408.12](https://travis-ci.com/broadinstitute/gatk/jobs/268686080) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.12/tests/test/index.html) |; | unit | openjdk8 | [28408.3](https://travis-ci.com/broadinstitute/gatk/jobs/268686071) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.3/tests/test/index.html) |; | python | openjdk8 | [28408.5](https://travis-ci.com/broadinstitute/gatk/jobs/268686073) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.5/tests/test/index.html) |; | integration | openjdk8 | [28408.2](https://travis-ci.com/broadinstitute/gatk/jobs/268686070) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565
https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565:991,Testability,test,test-logs,991,Travis reported job failures from build [28408](https://travis-ci.com/broadinstitute/gatk/builds/141654561); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28408.13](https://travis-ci.com/broadinstitute/gatk/jobs/268686081) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.13/tests/test/index.html) |; | integration | oraclejdk8 | [28408.11](https://travis-ci.com/broadinstitute/gatk/jobs/268686079) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.11/tests/test/index.html) |; | integration | openjdk11 | [28408.12](https://travis-ci.com/broadinstitute/gatk/jobs/268686080) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.12/tests/test/index.html) |; | unit | openjdk8 | [28408.3](https://travis-ci.com/broadinstitute/gatk/jobs/268686071) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.3/tests/test/index.html) |; | python | openjdk8 | [28408.5](https://travis-ci.com/broadinstitute/gatk/jobs/268686073) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.5/tests/test/index.html) |; | integration | openjdk8 | [28408.2](https://travis-ci.com/broadinstitute/gatk/jobs/268686070) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565
https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565:1030,Testability,test,tests,1030,Travis reported job failures from build [28408](https://travis-ci.com/broadinstitute/gatk/builds/141654561); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28408.13](https://travis-ci.com/broadinstitute/gatk/jobs/268686081) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.13/tests/test/index.html) |; | integration | oraclejdk8 | [28408.11](https://travis-ci.com/broadinstitute/gatk/jobs/268686079) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.11/tests/test/index.html) |; | integration | openjdk11 | [28408.12](https://travis-ci.com/broadinstitute/gatk/jobs/268686080) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.12/tests/test/index.html) |; | unit | openjdk8 | [28408.3](https://travis-ci.com/broadinstitute/gatk/jobs/268686071) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.3/tests/test/index.html) |; | python | openjdk8 | [28408.5](https://travis-ci.com/broadinstitute/gatk/jobs/268686073) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.5/tests/test/index.html) |; | integration | openjdk8 | [28408.2](https://travis-ci.com/broadinstitute/gatk/jobs/268686070) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565
https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565:1036,Testability,test,test,1036,Travis reported job failures from build [28408](https://travis-ci.com/broadinstitute/gatk/builds/141654561); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28408.13](https://travis-ci.com/broadinstitute/gatk/jobs/268686081) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.13/tests/test/index.html) |; | integration | oraclejdk8 | [28408.11](https://travis-ci.com/broadinstitute/gatk/jobs/268686079) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.11/tests/test/index.html) |; | integration | openjdk11 | [28408.12](https://travis-ci.com/broadinstitute/gatk/jobs/268686080) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.12/tests/test/index.html) |; | unit | openjdk8 | [28408.3](https://travis-ci.com/broadinstitute/gatk/jobs/268686071) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.3/tests/test/index.html) |; | python | openjdk8 | [28408.5](https://travis-ci.com/broadinstitute/gatk/jobs/268686073) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.5/tests/test/index.html) |; | integration | openjdk8 | [28408.2](https://travis-ci.com/broadinstitute/gatk/jobs/268686070) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565
https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565:1149,Testability,log,logs,1149,Travis reported job failures from build [28408](https://travis-ci.com/broadinstitute/gatk/builds/141654561); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28408.13](https://travis-ci.com/broadinstitute/gatk/jobs/268686081) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.13/tests/test/index.html) |; | integration | oraclejdk8 | [28408.11](https://travis-ci.com/broadinstitute/gatk/jobs/268686079) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.11/tests/test/index.html) |; | integration | openjdk11 | [28408.12](https://travis-ci.com/broadinstitute/gatk/jobs/268686080) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.12/tests/test/index.html) |; | unit | openjdk8 | [28408.3](https://travis-ci.com/broadinstitute/gatk/jobs/268686071) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.3/tests/test/index.html) |; | python | openjdk8 | [28408.5](https://travis-ci.com/broadinstitute/gatk/jobs/268686073) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.5/tests/test/index.html) |; | integration | openjdk8 | [28408.2](https://travis-ci.com/broadinstitute/gatk/jobs/268686070) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565
https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565:1197,Testability,test,test-logs,1197,Travis reported job failures from build [28408](https://travis-ci.com/broadinstitute/gatk/builds/141654561); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28408.13](https://travis-ci.com/broadinstitute/gatk/jobs/268686081) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.13/tests/test/index.html) |; | integration | oraclejdk8 | [28408.11](https://travis-ci.com/broadinstitute/gatk/jobs/268686079) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.11/tests/test/index.html) |; | integration | openjdk11 | [28408.12](https://travis-ci.com/broadinstitute/gatk/jobs/268686080) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.12/tests/test/index.html) |; | unit | openjdk8 | [28408.3](https://travis-ci.com/broadinstitute/gatk/jobs/268686071) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.3/tests/test/index.html) |; | python | openjdk8 | [28408.5](https://travis-ci.com/broadinstitute/gatk/jobs/268686073) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.5/tests/test/index.html) |; | integration | openjdk8 | [28408.2](https://travis-ci.com/broadinstitute/gatk/jobs/268686070) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565
https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565:1236,Testability,test,tests,1236,Travis reported job failures from build [28408](https://travis-ci.com/broadinstitute/gatk/builds/141654561); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28408.13](https://travis-ci.com/broadinstitute/gatk/jobs/268686081) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.13/tests/test/index.html) |; | integration | oraclejdk8 | [28408.11](https://travis-ci.com/broadinstitute/gatk/jobs/268686079) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.11/tests/test/index.html) |; | integration | openjdk11 | [28408.12](https://travis-ci.com/broadinstitute/gatk/jobs/268686080) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.12/tests/test/index.html) |; | unit | openjdk8 | [28408.3](https://travis-ci.com/broadinstitute/gatk/jobs/268686071) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.3/tests/test/index.html) |; | python | openjdk8 | [28408.5](https://travis-ci.com/broadinstitute/gatk/jobs/268686073) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.5/tests/test/index.html) |; | integration | openjdk8 | [28408.2](https://travis-ci.com/broadinstitute/gatk/jobs/268686070) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565
https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565:1242,Testability,test,test,1242,Travis reported job failures from build [28408](https://travis-ci.com/broadinstitute/gatk/builds/141654561); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28408.13](https://travis-ci.com/broadinstitute/gatk/jobs/268686081) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.13/tests/test/index.html) |; | integration | oraclejdk8 | [28408.11](https://travis-ci.com/broadinstitute/gatk/jobs/268686079) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.11/tests/test/index.html) |; | integration | openjdk11 | [28408.12](https://travis-ci.com/broadinstitute/gatk/jobs/268686080) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.12/tests/test/index.html) |; | unit | openjdk8 | [28408.3](https://travis-ci.com/broadinstitute/gatk/jobs/268686071) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.3/tests/test/index.html) |; | python | openjdk8 | [28408.5](https://travis-ci.com/broadinstitute/gatk/jobs/268686073) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.5/tests/test/index.html) |; | integration | openjdk8 | [28408.2](https://travis-ci.com/broadinstitute/gatk/jobs/268686070) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565
https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565:1360,Testability,log,logs,1360,Travis reported job failures from build [28408](https://travis-ci.com/broadinstitute/gatk/builds/141654561); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28408.13](https://travis-ci.com/broadinstitute/gatk/jobs/268686081) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.13/tests/test/index.html) |; | integration | oraclejdk8 | [28408.11](https://travis-ci.com/broadinstitute/gatk/jobs/268686079) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.11/tests/test/index.html) |; | integration | openjdk11 | [28408.12](https://travis-ci.com/broadinstitute/gatk/jobs/268686080) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.12/tests/test/index.html) |; | unit | openjdk8 | [28408.3](https://travis-ci.com/broadinstitute/gatk/jobs/268686071) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.3/tests/test/index.html) |; | python | openjdk8 | [28408.5](https://travis-ci.com/broadinstitute/gatk/jobs/268686073) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.5/tests/test/index.html) |; | integration | openjdk8 | [28408.2](https://travis-ci.com/broadinstitute/gatk/jobs/268686070) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565
https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565:1408,Testability,test,test-logs,1408,Travis reported job failures from build [28408](https://travis-ci.com/broadinstitute/gatk/builds/141654561); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28408.13](https://travis-ci.com/broadinstitute/gatk/jobs/268686081) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.13/tests/test/index.html) |; | integration | oraclejdk8 | [28408.11](https://travis-ci.com/broadinstitute/gatk/jobs/268686079) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.11/tests/test/index.html) |; | integration | openjdk11 | [28408.12](https://travis-ci.com/broadinstitute/gatk/jobs/268686080) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.12/tests/test/index.html) |; | unit | openjdk8 | [28408.3](https://travis-ci.com/broadinstitute/gatk/jobs/268686071) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.3/tests/test/index.html) |; | python | openjdk8 | [28408.5](https://travis-ci.com/broadinstitute/gatk/jobs/268686073) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.5/tests/test/index.html) |; | integration | openjdk8 | [28408.2](https://travis-ci.com/broadinstitute/gatk/jobs/268686070) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565
https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565:1447,Testability,test,tests,1447,Travis reported job failures from build [28408](https://travis-ci.com/broadinstitute/gatk/builds/141654561); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28408.13](https://travis-ci.com/broadinstitute/gatk/jobs/268686081) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.13/tests/test/index.html) |; | integration | oraclejdk8 | [28408.11](https://travis-ci.com/broadinstitute/gatk/jobs/268686079) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.11/tests/test/index.html) |; | integration | openjdk11 | [28408.12](https://travis-ci.com/broadinstitute/gatk/jobs/268686080) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.12/tests/test/index.html) |; | unit | openjdk8 | [28408.3](https://travis-ci.com/broadinstitute/gatk/jobs/268686071) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.3/tests/test/index.html) |; | python | openjdk8 | [28408.5](https://travis-ci.com/broadinstitute/gatk/jobs/268686073) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.5/tests/test/index.html) |; | integration | openjdk8 | [28408.2](https://travis-ci.com/broadinstitute/gatk/jobs/268686070) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565
https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565:1453,Testability,test,test,1453,Travis reported job failures from build [28408](https://travis-ci.com/broadinstitute/gatk/builds/141654561); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28408.13](https://travis-ci.com/broadinstitute/gatk/jobs/268686081) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.13/tests/test/index.html) |; | integration | oraclejdk8 | [28408.11](https://travis-ci.com/broadinstitute/gatk/jobs/268686079) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.11/tests/test/index.html) |; | integration | openjdk11 | [28408.12](https://travis-ci.com/broadinstitute/gatk/jobs/268686080) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.12/tests/test/index.html) |; | unit | openjdk8 | [28408.3](https://travis-ci.com/broadinstitute/gatk/jobs/268686071) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.3/tests/test/index.html) |; | python | openjdk8 | [28408.5](https://travis-ci.com/broadinstitute/gatk/jobs/268686073) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.5/tests/test/index.html) |; | integration | openjdk8 | [28408.2](https://travis-ci.com/broadinstitute/gatk/jobs/268686070) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28408.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4571#issuecomment-567198565
https://github.com/broadinstitute/gatk/pull/4571#issuecomment-789760761:219,Testability,test,tests,219,"@droazen @cmnbroad This PR is blocking #6973, and it's been stuck for a while. I would like to offer my help in doing any work to get this closed out. #7021 is related and I could offer help on that and updating needed tests if this could help get all this closed out.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/4571#issuecomment-789760761
